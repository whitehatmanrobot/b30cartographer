 WCHAR StaticRedirectionBuffer[DOS_MAX_PATH_LENGTH];
    UNICODE_STRING StaticRedirectionString;
    UNICODE_STRING DynamicRedirectionString;
    PUNICODE_STRING DllNameToUse;
    BOOLEAN Redirected = FALSE;

    DllData = NULL;

    RtlInitUnicodeString (
        &DllName,
        DllString);

    DynamicRedirectionString.Buffer = NULL;
    DynamicRedirectionString.Length = 0;
    DynamicRedirectionString.MaximumLength = 0;

    StaticRedirectionString.Length = 0;
    StaticRedirectionString.MaximumLength = sizeof(StaticRedirectionBuffer);
    StaticRedirectionString.Buffer = StaticRedirectionBuffer;

    DllNameToUse = &DllName;

    Status = RtlDosApplyFileIsolationRedirection_Ustr(
            RTL_DOS_APPLY_FILE_REDIRECTION_USTR_FLAG_RESPECT_DOT_LOCAL,
            &DllName,
            &DefaultExtension,
            &StaticRedirectionString,
            &DynamicRedirectionString,
            &DllNameToUse,
            NULL,
            NULL,
            NULL);
    if (NT_SUCCESS(Status)) {
        Redirected = TRUE;
    } else if (Status == STATUS_SXS_KEY_NOT_FOUND) {
        Status = STATUS_SUCCESS;
    }

    if (NT_SUCCESS(Status)) {
        Result = LdrpCheckForLoadedDll (
            NULL,
            DllNameToUse,
            TRUE,
            Redirected,
            &DllData);

        if (DynamicRedirectionString.Buffer != NULL)
            RtlFreeUnicodeString(&DynamicRedirectionString);
    }

    if (Result == FALSE) {
        return FALSE;
    }

    Base = DllData->DllBase;

    Directory = RtlImageDirectoryEntryToData (
        DllData->DllBase,
        TRUE,
        IMAGE_DIRECTORY_ENTRY_EXPORT,
        &Size
        );

    if (Directory == NULL) {
        return FALSE;
    }

    for (CurrentSnapName = SnapNames; CurrentSnapName->Name; CurrentSnapName += 1) {

        for (Index = 0; Index < Directory->NumberOfFunctions; Index += 1) {

            NameAddress = Base + Directory->AddressOfNames;
            NameAddress = Base + ((ULONG *)NameAddress)[Index];

            IndexAddress = Base + Directory->AddressOfNameOrdinals;
            RealIndex = (ULONG)(((USHORT *)IndexAddress)[Index]);

            if (_stricmp (NameAddress, CurrentSnapName->Name) == 0) {

                FunctionAddress = Base + Directory->AddressOfFunctions;
                FunctionAddress = Base + ((ULONG *)FunctionAddress)[RealIndex];

                AVrfpDphSnapRoutines[CurrentSnapName->Index] = FunctionAddress;
                
                if ((AVrfpDebug & AVRF_DBG_SHOW_PAGE_HEAP_DETAILS)) {
                    
                    DbgPrint ("Page heap: found %s @ address %p \n", 
                                NameAddress, 
                                FunctionAddress);
                }
            }
        }
    }

    return TRUE;
}

NTSTATUS
AVrfpDphSnapImports (
    PLDR_DATA_TABLE_ENTRY LdrDataTableEntry,
    BOOLEAN CallToDetectCrtHeap
    )
{
    PVOID IATBase;
    SIZE_T BigIATSize;
    ULONG  LittleIATSize;
    PVOID *ProcAddresses;
    ULONG NumberOfProcAddresses;
    ULONG OldProtect;
    NTSTATUS st;

    st = STATUS_SUCCESS;

    //
    // Determine the location and size of the IAT.  If found, scan the
    // IAT address to see if any are pointing to alloc/free functions
    // and replace those thunks.
    //

    IATBase = RtlImageDirectoryEntryToData(
        LdrDataTableEntry->DllBase,
        TRUE,
        IMAGE_DIRECTORY_ENTRY_IAT,
        &LittleIATSize);

    if (IATBase != NULL) {

        BigIATSize = LittleIATSize;

        st = NtProtectVirtualMemory (NtCurrentProcess(),
                                     &IATBase,
                                     &BigIATSize,
                                     PAGE_READWRITE,
                                     &OldProtect);

        if (!NT_SUCCESS(st)) {
            
            InterlockedIncrement ((PLONG)(&AVrfpVirtualProtectFailures));

            if ((AVrfpDebug & AVRF_DBG_SHOW_PAGE_HEAP_DETAILS)) {

                DbgPrint ("Page heap: Unable to unprotect IAT to enable per DLL page heap.\n" );
            }

            return st;
        }
        else {
            ProcAddresses = (PVOID *)IATBase;
            NumberOfProcAddresses = (ULONG)(BigIATSize / sizeof(PVOID));
            while (NumberOfProcAddresses--) {

                //
                // If we find a null in the import table we skip over it.
                // Otherwise we will erroneously think it is a malloc() routine
                // to be replaced. This can happen if msvcrt was not loaded yet
                // and therefore the address of malloc() is also null.
                //

                if (*ProcAddresses == NULL) {
                    ProcAddresses += 1;
                    continue;
                }

                if (CallToDetectCrtHeap) {
                    if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_HEAPCREATE]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllHeapCreate;

                        if ((AVrfpDebug & AVRF_DBG_SHOW_PAGE_HEAP_DETAILS)) {

                            DbgPrint ("Page heap: Snapped (%ws) HeapCreate ... \n",
                                        LdrDataTableEntry->BaseDllName.Buffer);
                        }
                    }
                } else {

                    //
                    // ntdll imports
                    //

                    if (*ProcAddresses == RtlAllocateHeap) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllHeapAlloc;
                    } else if (*ProcAddresses == RtlReAllocateHeap) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllHeapReAlloc;
                    } else if (*ProcAddresses == RtlFreeHeap) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllHeapFree;
                    }

                    //
                    // kernel32 imports
                    //

                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_HEAPALLOC]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllHeapAlloc;
                    } else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_HEAPREALLOC]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllHeapReAlloc;
                    } else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_HEAPFREE]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllHeapFree;
                    }

                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_LOCALALLOC]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllLocalAlloc;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_LOCALREALLOC]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllLocalReAlloc;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_LOCALFREE]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllLocalFree;
                    }

                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_GLOBALALLOC]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllGlobalAlloc;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_GLOBALREALLOC]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllGlobalReAlloc;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_GLOBALFREE]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllGlobalFree;
                    }

                    //
                    // msvcrt imports
                    //

                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_MALLOC]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllmalloc;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_REALLOC]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllrealloc;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_CALLOC]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllcalloc;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_FREE]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllfree;
                    }

                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_NEW]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllNew;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_DELETE]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllDelete;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_NEW_ARRAY]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllNewArray;
                    } 
                    else if (*ProcAddresses == AVrfpDphSnapRoutines[SNAP_ROUTINE_DELETE_ARRAY]) {
                        *ProcAddresses = (PVOID) (ULONG_PTR) AVrfpDphDllDeleteArray;
                    }
                }

                ProcAddresses += 1;
            }

            //
            // We do not complain for protecting the import table back  because
            // we can live with that.
            //

            NtProtectVirtualMemory (NtCurrentProcess(),
                                    &IATBase,
                                    &BigIATSize,
                                    OldProtect,
                                    &OldProtect);
        }
    }

    return st;
}

NTSTATUS
AVrfPageHeapDllNotification (
    PLDR_DATA_TABLE_ENTRY LoadedDllData
    )
/*++

Routine description:

    This routine is the DLL load hook for page heap per dll. It gets called
    whenever a dll got loaded in the process space and after its import
    descriptors have been walked.

Parameters:

    LoadedDllData - LDR loader structure for the dll.
    
Return value:

    None.
            
--*/
{
    BOOLEAN Kernel32JustSnapped = FALSE;
    BOOLEAN MsvcrtJustSnapped = FALSE;
    NTSTATUS Status = STATUS_SUCCESS;

    //
    // If we do not have per dll page heap feature enabled
    // we return immediately.
    //

    if (! (RtlpDphGlobalFlags & PAGE_HEAP_USE_DLL_NAMES)) {
        return Status;
    }

    if (! AVrfpDphKernel32Snapped) {

        Kernel32JustSnapped = AVrfpDphDetectSnapRoutines (
            Kernel32String.Buffer,
            AVrfpDphSnapNamesForKernel32);

        AVrfpDphKernel32Snapped = Kernel32JustSnapped;
    }

    if (! AVrfpDphMsvcrtSnapped) {

        MsvcrtJustSnapped = AVrfpDphDetectSnapRoutines (
            L"msvcrt.dll",
            AVrfpDphSnapNamesForMsvcrt);

        AVrfpDphMsvcrtSnapped = MsvcrtJustSnapped;
    }

    //
    // Snap everything already loaded if we just managed
    // to detect snap routines.
    //

    if (Kernel32JustSnapped || MsvcrtJustSnapped) {

        //
        // ISSUE: SilviuC: I need to think if this code path is needed. If a dll
        // imports something from the exports of interest that dll will get loaded
        // (and exports detected) first. So in case of kernel32/msvcrt we will
        // take this code path and snap their imports and then redundantly
        // snap them again in the end of the function (that is the general case).
        //

        PWSTR Current;
        PWSTR End;
        WCHAR SavedChar;
        PLDR_DATA_TABLE_ENTRY DllData;
        BOOLEAN Result;
        UNICODE_STRING DllName;
        WCHAR StaticRedirectionBuffer[DOS_MAX_PATH_LENGTH];
        UNICODE_STRING StaticRedirectionString;
        UNICODE_STRING DynamicRedirectionString;
        PUNICODE_STRING DllNameToUse;
        BOOLEAN Redirected = FALSE;

        DynamicRedirectionString.Buffer = NULL;
        DynamicRedirectionString.Length = 0;
        DynamicRedirectionString.MaximumLength = 0;

        StaticRedirectionString.Length = 0;
        StaticRedirectionString.MaximumLength = sizeof(StaticRedirectionBuffer);
        StaticRedirectionString.Buffer = StaticRedirectionBuffer;

        Current = RtlpDphTargetDlls;

        while (*Current) {

            while (*Current == L' ') {
                Current += 1;
            }

            End = Current;

            while (*End && *End != L' ') {
                End += 1;
            }

            if (*Current == L'\0') {
                break;
            }

            SavedChar = *End;
            *End = L'\0';

            RtlInitUnicodeString (
                &DllName,
                Current);

            Result = FALSE;
            DllData = NULL;
            DllNameToUse = &DllName;

            Status = RtlDosApplyFileIsolationRedirection_Ustr(
                    RTL_DOS_APPLY_FILE_REDIRECTION_USTR_FLAG_RESPECT_DOT_LOCAL,
                    &DllName,
                    &DefaultExtension,
                    &StaticRedirectionString,
                    &DynamicRedirectionString,
                    &DllNameToUse,
                    NULL,
                    NULL,
                    NULL);
            if (NT_SUCCESS(Status)) {
                Redirected = TRUE;
            } else if (Status == STATUS_SXS_KEY_NOT_FOUND) {
                Status = STATUS_SUCCESS;
            }

            if (NT_SUCCESS(Status)) {
                Result = LdrpCheckForLoadedDll (
                    NULL,
                    DllNameToUse,
                    TRUE,
                    Redirected,
                    &DllData);

                if (DynamicRedirectionString.Buffer != NULL)
                    RtlFreeUnicodeString(&DynamicRedirectionString);
            }

            if (Result) {

                if (DllData->DllBase == LoadedDllData->DllBase) {
                    
                    if ((AVrfpDebug & AVRF_DBG_SHOW_PAGE_HEAP_DETAILS)) {

                        DbgPrint ("Page heap: oversnapping %ws \n", 
                                    DllData->BaseDllName);
                    }
                }

                Status = AVrfpDphSnapImports (DllData, FALSE);

                if (!NT_SUCCESS(Status)) {

                    return Status;
                }
            }

            *End = SavedChar;
            Current = End;
        }
    }

    //
    // If we just loaded msvcrt.dll we need to redirect HeapCreate call
    // in order to detect when the CRT heap gets created.
    //

    if (_wcsicmp (LoadedDllData->BaseDllName.Buffer, L"msvcrt.dll") == 0) {

        Status = AVrfpDphSnapImports (LoadedDllData, TRUE);
        
        if (!NT_SUCCESS(Status)) {
            return Status;
        }
    }

    //
    // Call back into page heap manager to figure out if the
    // currently loaded dll is a target for page heap.
    //

    if (RtlpDphIsDllTargeted (LoadedDllData->BaseDllName.Buffer)) {

        Status = AVrfpDphSnapImports (LoadedDllData, FALSE);

        if (!NT_SUCCESS(Status)) {
            return Status;
        }
    }

    return Status;
}

/////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////// Snap routines
/////////////////////////////////////////////////////////////////////

//
// A biased heap pointer signals to the page heap manager that
// this allocation needs to get into page heap (not normal heap).
// This needs to happen only for allocation function (not free, delete).
//

#define BIAS_POINTER(p) ((PVOID)((ULONG_PTR)(p) | 0x01))

PVOID
AVrfpDphDllHeapAlloc (
    IN PVOID  HeapHandle,
    IN ULONG  Flags,
    IN SIZE_T Size
    )
{
    return RtlpDebugPageHeapAllocate (
        BIAS_POINTER(HeapHandle),
        Flags,
        Size);
}

PVOID
AVrfpDphDllHeapReAlloc (
    IN PVOID  HeapHandle,
    IN ULONG  Flags,
    IN PVOID Address,
    IN SIZE_T Size
    )
{
    return RtlpDebugPageHeapReAllocate (
        BIAS_POINTER(HeapHandle),
        Flags,
        Address,
        Size);
}

BOOLEAN
AVrfpDphDllHeapFree(
    IN PVOID HeapHandle,
    IN ULONG Flags,
    IN PVOID Address
    )
{
    return RtlpDebugPageHeapFree (
        HeapHandle,
        Flags,
        Address);
}

//
// LocalAlloc, LocalReAlloc, LocalFree
// GlobalAlloc, GlobalReAlloc, GlobalFree
//
// The following macros are copied from sdk\inc\winbase.h
// There is very low probability that anybody will ever change
// these values for application compatibility reasons.
//

#define LMEM_MOVEABLE       0x0002
#define LMEM_ZEROINIT       0x0040

#if defined(_AMD64_) || defined(_IA64_)
#define BASE_HANDLE_MARK_BIT 0x08
#else
#define BASE_HANDLE_MARK_BIT 0x04
#endif

typedef PVOID
(* FUN_LOCAL_ALLOC) (
    IN ULONG  Flags,
    IN SIZE_T Size
    );

typedef PVOID
(* FUN_LOCAL_REALLOC) (
    IN PVOID Address,
    IN SIZE_T Size,
    IN ULONG  Flags
    );

typedef PVOID
(* FUN_LOCAL_FREE)(
    IN PVOID Address
    );

typedef PVOID
(* FUN_GLOBAL_ALLOC) (
    IN ULONG  Flags,
    IN SIZE_T Size
    );

typedef PVOID
(* FUN_GLOBAL_REALLOC) (
    IN PVOID Address,
    IN SIZE_T Size,
    IN ULONG  Flags
    );

typedef PVOID
(* FUN_GLOBAL_FREE)(
    IN PVOID Address
    );

PVOID
AVrfpDphDllLocalAlloc (
    IN ULONG  Flags,
    IN SIZE_T Size
    )
{
    PVOID Block;
    FUN_LOCAL_ALLOC Original;

    if (!(Flags & LMEM_MOVEABLE)) {

        Block = RtlpDebugPageHeapAllocate (
            BIAS_POINTER(RtlProcessHeap()),
            0,
            Size);

        if (Block && (Flags & LMEM_ZEROINIT)) {
            RtlZeroMemory (Block, Size);
        }

        return Block;
    }
    else {

        Original = (FUN_LOCAL_ALLOC)(ULONG_PTR)(AVrfpDphSnapRoutines[SNAP_ROUTINE_LOCALALLOC]);
        return (* Original) (Flags, Size);
    }
}

PVOID
AVrfpDphDllLocalReAlloc (
    IN PVOID Address,
    IN SIZE_T Size,
    IN ULONG  Flags
    )
{
    PVOID Block;
    FUN_LOCAL_REALLOC Original;

    if (!(Flags & LMEM_MOVEABLE)) {

        Block = RtlpDebugPageHeapReAllocate (
            BIAS_POINTER(RtlProcessHeap()),
            0,
            Address,
            Size);

        return Block;
    }
    else {

        Original = (FUN_LOCAL_REALLOC)(ULONG_PTR)(AVrfpDphSnapRoutines[SNAP_ROUTINE_LOCALREALLOC]);
        return (* Original) (Address, Size, Flags);
    }
}

PVOID
AVrfpDphDllLocalFree(
    IN PVOID Address
    )
{
    BOOLEAN Result;
    FUN_LOCAL_FREE Original;

    if ((ULONG_PTR)Address & BASE_HANDLE_MARK_BIT) {

        Original = (FUN_LOCAL_FREE)(ULONG_PTR)(AVrfpDphSnapRoutines[SNAP_ROUTINE_LOCALFREE]);
        return (* Original) (Address);
    }
    else {

        Result = RtlpDebugPageHeapFree (
            RtlProcessHeap(),
            0,
            Address);

        if (Result) {
            return NULL;
        }
        else {
            return Address;
        }
    }
}

PVOID
AVrfpDphDllGlobalAlloc (
    IN ULONG  Flags,
    IN SIZE_T Size
    )
{
    PVOID Block;
    FUN_GLOBAL_ALLOC Original;

    if (!(Flags & LMEM_MOVEABLE)) {

        Block = RtlpDebugPageHeapAllocate (
            BIAS_POINTER(RtlProcessHeap()),
            0,
            Size);

        if (Block && (Flags & LMEM_ZEROINIT)) {
            RtlZeroMemory (Block, Size);
        }

        return Block;
    }
    else {

        Original = (FUN_GLOBAL_ALLOC)(ULONG_PTR)(AVrfpDphSnapRoutines[SNAP_ROUTINE_GLOBALALLOC]);
        return (* Original) (Flags, Size);
    }
}

PVOID
AVrfpDphDllGlobalReAlloc (
    IN PVOID Address,
    IN SIZE_T Size,
    IN ULONG  Flags
    )
{
    PVOID Block;
    FUN_GLOBAL_REALLOC Original;

    if (!(Flags & LMEM_MOVEABLE)) {

        Block = RtlpDebugPageHeapReAllocate (
            BIAS_POINTER(RtlProcessHeap()),
            0,
            Address,
            Size);

        return Block;
    }
    else {

        Original = (FUN_GLOBAL_REALLOC)(ULONG_PTR)(AVrfpDphSnapRoutines[SNAP_ROUTINE_GLOBALREALLOC]);
        return (* Original) (Address, Size, Flags);
    }
}

PVOID
AVrfpDphDllGlobalFree(
    IN PVOID Address
    )
{
    BOOLEAN Result;
    FUN_GLOBAL_FREE Original;

    if ((ULONG_PTR)Address & BASE_HANDLE_MARK_BIT) {

        Original = (FUN_GLOBAL_FREE)(ULONG_PTR)(AVrfpDphSnapRoutines[SNAP_ROUTINE_GLOBALFREE]);
        return (* Original) (Address);
    }
    else {

        Result = RtlpDebugPageHeapFree (
            RtlProcessHeap(),
            0,
            Address);

        if (Result) {
            return NULL;
        }
        else {
            return Address;
        }
    }
}

//
// malloc, calloc, realloc, free
//

PVOID __cdecl
AVrfpDphDllmalloc (
    IN SIZE_T Size
    )
{
    PVOID Block;

    ASSERT(AVrfpDphMsvcrtHeap != NULL);

    Block = RtlpDebugPageHeapAllocate (
        BIAS_POINTER(AVrfpDphMsvcrtHeap),
        0,
        Size);

    return Block;
}

PVOID __cdecl
AVrfpDphDllcalloc (
    IN SIZE_T Number,
    IN SIZE_T Size
    )
{
    PVOID Block;

    ASSERT(AVrfpDphMsvcrtHeap != NULL);

    Block =  RtlpDebugPageHeapAllocate (
        BIAS_POINTER(AVrfpDphMsvcrtHeap),
        0,
        Size * Number);

    if (Block) {
        RtlZeroMemory (Block, Size * Number);
    }

    return Block;
}

PVOID __cdecl
AVrfpDphDllrealloc (
    IN PVOID Address,
    IN SIZE_T Size
    )
{
    PVOID Block;

    ASSERT(AVrfpDphMsvcrtHeap != NULL);

    if (Address == NULL) {

        Block = RtlpDebugPageHeapAllocate (
            BIAS_POINTER(AVrfpDphMsvcrtHeap),
            0,
            Size);
    }
    else {

        Block = RtlpDebugPageHeapReAllocate (
            BIAS_POINTER(AVrfpDphMsvcrtHeap),
            0,
            Address,
            Size);
    }

    return Block;
}

VOID __cdecl
AVrfpDphDllfree (
    IN PVOID Address
    )
{
    ASSERT(AVrfpDphMsvcrtHeap != NULL);

    RtlpDebugPageHeapFree (
        AVrfpDphMsvcrtHeap,
        0,
        Address);
}

//
// operator new, delete
// operator new[], delete[]
//

PVOID __cdecl
AVrfpDphDllNew (
    IN SIZE_T Size
    )
{
    PVOID Block;

    ASSERT(AVrfpDphMsvcrtHeap != NULL);

    Block = RtlpDebugPageHeapAllocate (
        BIAS_POINTER(AVrfpDphMsvcrtHeap),
        0,
        Size);

    return Block;
}

VOID __cdecl
AVrfpDphDllDelete (
    IN PVOID Address
    )
{
    ASSERT(AVrfpDphMsvcrtHeap != NULL);

    RtlpDebugPageHeapFree (
        AVrfpDphMsvcrtHeap,
        0,
        Address);
}

PVOID __cdecl
AVrfpDphDllNewArray (
    IN SIZE_T Size
    )
{
    ASSERT(AVrfpDphMsvcrtHeap != NULL);

    return RtlpDebugPageHeapAllocate (
        BIAS_POINTER(AVrfpDphMsvcrtHeap),
        0,
        Size);
}

VOID __cdecl
AVrfpDphDllDeleteArray (
    IN PVOID Address
    )
{
    ASSERT(AVrfpDphMsvcrtHeap != NULL);

    RtlpDebugPageHeapFree (
        AVrfpDphMsvcrtHeap,
        0,
        Address);
}

//
// HeapCreate
//

typedef PVOID
(* FUN_HEAP_CREATE) (
    ULONG Options,
    SIZE_T InitialSize,
    SIZE_T MaximumSize
    );

PVOID
AVrfpDphDllHeapCreate (
    ULONG Options,
    SIZE_T InitialSize,
    SIZE_T MaximumSize
    )
{
    PVOID Heap;
    FUN_HEAP_CREATE Original;

    Original = (FUN_HEAP_CREATE)(ULONG_PTR)(AVrfpDphSnapRoutines[SNAP_ROUTINE_HEAPCREATE]);
    Heap = (* Original) (Options, InitialSize, MaximumSize);

    AVrfpDphMsvcrtHeap = Heap;

    if ((AVrfpDebug & AVRF_DBG_SHOW_PAGE_HEAP_DETAILS)) {

        DbgPrint ("Page heap: detected CRT heap @ %p \n", 
                    AVrfpDphMsvcrtHeap);
    }

    return Heap;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\tenv.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    tenv.c

Abstract:

    Test program for the NT OS Runtime Library (RTL) Environment API Calls

Author:

    Steve Wood (stevewo) 30-Jan-1991

Revision History:

--*/

#include <nt.h>
#include <ntrtl.h>
#include <nturtl.h>
#include <stdio.h>

VOID
DumpEnvironment( PVOID env )
{
    PWCHAR s = env;

    while (*s) {
        printf( "%79.79ws\n", s );
        while (*s++) {
            }
        }
}

VOID
SetEnvironment(
    PVOID *env,
    PCHAR Name,
    PCHAR Value
    );

VOID
SetEnvironment(
    PVOID *env,
    PCHAR Name,
    PCHAR Value
    )
{
    NTSTATUS Status;
    STRING NameString, ValueString;
    UNICODE_STRING uNameString, uValueString;

    RtlInitString( &NameString, Name );
    Status = RtlAnsiStringToUnicodeString(&uNameString, &NameString, TRUE);
    if (!NT_SUCCESS( Status )) {
        printf( " - failed converting to Unicode, Status == %X\n", Status );
	DumpEnvironment(*env);
	printf( "\n" );
	return;
    }
    if (Value != NULL) {
        RtlInitString( &ValueString, Value );
	Status = RtlAnsiStringToUnicodeString(&uValueString, &ValueString, TRUE);
        printf( "TENV: set variable (%X) %Z=%Z\n", *env, &NameString, &ValueString );
        Status = RtlSetEnvironmentVariable( env, &uNameString, &uValueString );
        printf( "TENV: (%X)", *env);
	RtlFreeUnicodeString(&uNameString);
	RtlFreeUnicodeString(&uValueString);
        }
    else {
        printf( "TENV: delete variable (%X) %Z\n", *env, &NameString );
        Status = RtlSetEnvironmentVariable( env, &uNameString, NULL );
        printf( "TENV: (%X)", *env, &NameString, &ValueString );
	RtlFreeUnicodeString(&uNameString);
        }

    if (NT_SUCCESS( Status )) {
        printf( "\n" );
        }
    else {
        printf( " - failed, Status == %X\n", Status );
        }
    DumpEnvironment(*env);
    printf( "\n" );
}


int
_cdecl
main(
    int argc,
    char **argv,
    char **envp
    )
{
    int i;
    PVOID env;
    PVOID nenv;
    NTSTATUS Status;
    char bigbuf[4100];

    for (i=0; i<argc; i++) {
        printf( "argv[ %d ] = %s\n", i, argv[ i ] );
        }

    i = 0;
    while (envp[ i ]) {
        printf( "envp[ %d ] = %s\n", i, envp[ i ] );
        i++;
        }
    
    for (i=0 ; i<4099 ; i++)
	bigbuf[i] = (i%26) + (((i&1) == 0) ? 'a' : 'A');
    bigbuf[4099] = '\0';

    env = NtCurrentPeb()->ProcessParameters->Environment;
    Status = RtlCreateEnvironment(TRUE, &nenv);	// clone current
    if (!NT_SUCCESS( Status )) {
        printf( "Unable to create clone environment - %X\n", Status );
	return 1;
    }

    // First, check with process environment
    DumpEnvironment( &env);
    SetEnvironment( &env, "aaaa", "12345" );
    SetEnvironment( &env, "aaaa", "1234567890" );
    SetEnvironment( &env, "aaaa", "1" );
    SetEnvironment( &env, "aaaa", "" );
    SetEnvironment( &env, "aaaa", NULL );
    SetEnvironment( &env, "AAAA", "12345" );
    SetEnvironment( &env, "AAAA", "1234567890" );
    SetEnvironment( &env, "AAAA", "1" );
    SetEnvironment( &env, "AAAA", "" );
    SetEnvironment( &env, "AAAA", NULL );
    SetEnvironment( &env, "MMMM", "12345" );
    SetEnvironment( &env, "MMMM", "1234567890" );
    SetEnvironment( &env, "MMMM", "1" );
    SetEnvironment( &env, "MMMM", "" );
    SetEnvironment( &env, "MMMM", NULL );
    SetEnvironment( &env, "ZZZZ", "12345" );
    SetEnvironment( &env, "ZZZZ", "1234567890" );
    SetEnvironment( &env, "ZZZZ", "1" );
    SetEnvironment( &env, "ZZZZ", "" );
    SetEnvironment( &env, "ZZZZ", NULL );
    SetEnvironment( &env, "BIGBUF", bigbuf );
    SetEnvironment( &env, "BIGBUF", NULL );

    // Second, check with non-process environment
    DumpEnvironment(nenv);
    SetEnvironment( &nenv, "aaaa", "12345" );
    SetEnvironment( &nenv, "aaaa", "1234567890" );
    SetEnvironment( &nenv, "aaaa", "1" );
    SetEnvironment( &nenv, "aaaa", "" );
    SetEnvironment( &nenv, "aaaa", NULL );
    SetEnvironment( &nenv, "AAAA", "12345" );
    SetEnvironment( &nenv, "AAAA", "1234567890" );
    SetEnvironment( &nenv, "AAAA", "1" );
    SetEnvironment( &nenv, "AAAA", "" );
    SetEnvironment( &nenv, "AAAA", NULL );
    SetEnvironment( &nenv, "MMMM", "12345" );
    SetEnvironment( &nenv, "MMMM", "1234567890" );
    SetEnvironment( &nenv, "MMMM", "1" );
    SetEnvironment( &nenv, "MMMM", "" );
    SetEnvironment( &nenv, "MMMM", NULL );
    SetEnvironment( &nenv, "ZZZZ", "12345" );
    SetEnvironment( &nenv, "ZZZZ", "1234567890" );
    SetEnvironment( &nenv, "ZZZZ", "1" );
    SetEnvironment( &nenv, "ZZZZ", "" );
    SetEnvironment( &nenv, "ZZZZ", NULL );
    SetEnvironment( &nenv, "BIGBUF", bigbuf );
    SetEnvironment( &nenv, "BIGBUF", NULL );
    return( 0 );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\w64misc.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    w64misc.c

Abstract:

    Miscallaneous Wow64 routines.

Author:

    Samer Arafeh (samera) 12-Dec-2002

Revision History:

--*/

#include "ldrp.h"
#include <ntos.h>
#include <nt.h>
#include <ntrtl.h>
#include <nturtl.h>
#include <wow64t.h>



NTSTATUS
RtlpWow64EnableFsRedirection (
    IN BOOLEAN Wow64FsEnableRedirection
    )

/*++

Routine Description:

    This function enables/disables Wow64 file system redirection.
    
    Wow64 redirects all accesses to %windir%\system32 to %windir%\syswow64.
    This API is useful  for 32-bit applications which want to gain access to the
    native system32 directory. By default, Wow64 file system redirection is enabled.
    
    File redirection is only affected for the thread calling this API.
    
    Note : You must enable file system redirection after disabling it. Once you have
           a file handle, you must enable file system redirection back. 
    
    Example:
    
    NTSTATUS Status = RtlpWow64EnableFsRedirection (FALSE);
    if (NT_SUCCESS (Status)) {
        
        //
        // Open the file handle
        //
        
        CreateFile (..."c:\\windows\\system32\\notepad.exe"...)
        
        //
        // Enable Wow64 file system redirection.
        //
        
        RtlpWow64EnableFsRedirection (TRUE);
    }
    
    //
    // Use the file handle
    //
    

Arguments:

    Wow64FsEnableRedirection - Boolean to indicate whether to enable Wow64 file system
        redirection. Specify FALSE if you want to disable Wow64 file system redirection,
        otherwise TRUE to enable it.
        

Return Value:

    NTSTATUS.
    
--*/

{
#if !defined(BUILD_WOW6432)
  
    UNREFERENCED_PARAMETER (Wow64FsEnableRedirection);

    //
    // If this is not a wow64 process, then this is api is not supported.
    //

    return STATUS_NOT_IMPLEMENTED;
#else
  
    NTSTATUS NtStatus;

    
    NtStatus = STATUS_SUCCESS;

    try {
        if (Wow64FsEnableRedirection == FALSE) {
            Wow64SetFilesystemRedirectorEx (WOW64_FILE_SYSTEM_DISABLE_REDIRECT);
        } else {
            Wow64SetFilesystemRedirectorEx (WOW64_FILE_SYSTEM_ENABLE_REDIRECT);
        }
    } except (EXCEPTION_EXECUTE_HANDLER) {
        NtStatus = GetExceptionCode ();
    }

    return NtStatus;
#endif
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\amd64\critsect.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    critsect.asm

Abstract:

    This module implements functions to support user mode critical sections.

Author:

    David N. Cutler (davec) 25-Jun-2000

Environment:

    Any mode.

Revision History:

--*/

#include "ldrp.h"
#include "ntos.h"

NTSTATUS
RtlEnterCriticalSection(
    IN PRTL_CRITICAL_SECTION CriticalSection
    )

/*++

Routine Description:

    This function enters a critical section.

Arguments:

    CriticalSection - Supplies a pointer to a critical section.

Return Value:

    STATUS_SUCCESS is returned or a exception can be raised if the wait
    for the resoruce fails.

--*/

{

    ULONG64 SpinCount;
    HANDLE Thread;

    //
    // If the current thread owns the critical section, then increment
    // the lock count and the recursion count and return success.
    //

    Thread = NtCurrentTeb()->ClientId.UniqueThread;
    if (Thread == CriticalSection->OwningThread) {

        ASSERT(CriticalSection->LockCount >= 0);

        InterlockedIncrement(&CriticalSection->LockCount);
        CriticalSection->RecursionCount += 1;
        return STATUS_SUCCESS;
    }

    //
    // If the critical section spin count is nonzero, then spin attempting
    // to enter critical section until the critical section is entered, the
    // spin count reaches zero, or there are waiters for the critical section.
    //

    SpinCount = CriticalSection->SpinCount;
    if (SpinCount != 0) {
        do {

            //
            // If the critical section is free, then attempt to enter the
            // critical section. Otherwise, spin if the spin count is not
            // zero and there are no waiters for the critical section.
            //

            if (CriticalSection->LockCount == - 1) {
                if (InterlockedCompareExchange(&CriticalSection->LockCount,
                                               0,
                                               - 1) == - 1) {
                    CriticalSection->OwningThread = Thread;
                    CriticalSection->RecursionCount = 1;
                    return STATUS_SUCCESS;
                }

            } else if (CriticalSection->LockCount > 0) {
                break;
            }

            SpinCount -= 1;
        } while (SpinCount != 0);
    }

    //
    // Attempt to enter the critical section. If the critical section is not
    // free, then wait for ownership to be granted.
    //

    if (InterlockedIncrement(&CriticalSection->LockCount) != 0) {
        RtlpWaitForCriticalSection(CriticalSection);
    }

    //
    // Set owning thread, initialization the recusrion count, and return
    // success.
    //

    CriticalSection->OwningThread = Thread;
    CriticalSection->RecursionCount = 1;
    return STATUS_SUCCESS;
}

NTSTATUS
RtlLeaveCriticalSection(
    IN PRTL_CRITICAL_SECTION CriticalSection
    )

/*++

Routine Description:

    This function leaves a critical section.

Arguments:

    CriticalSection - Supplies a pointer to a critical section.

Return Value:

   STATUS_SUCCESS is returned.

--*/

{

    //
    // Decrement the recursion count. If the resultant recursion count is
    // zero, then leave the critical section.
    //

    ASSERT(NtCurrentTeb()->ClientId.UniqueThread == CriticalSection->OwningThread);

    if ((CriticalSection->RecursionCount -= 1) == 0) {
        CriticalSection->OwningThread = NULL;
        if (InterlockedDecrement(&CriticalSection->LockCount) >= 0) {
            RtlpUnWaitCriticalSection(CriticalSection);
        }

    } else {
        InterlockedDecrement(&CriticalSection->LockCount);
    }

    return STATUS_SUCCESS;
}

BOOLEAN
RtlTryEnterCriticalSection (
    IN PRTL_CRITICAL_SECTION CriticalSection
    )

/*++

Routine Description:

    This function attempts to enter a critical section without blocking.

Arguments:

    CriticalSection (a0) - Supplies a pointer to a critical section.

Return Value:

    If the critical section was successfully entered, then a value of TRUE
    is returned. Otherwise, a value of FALSE is returned.

--*/

{

    HANDLE Thread;

    //
    // If the current thread owns the critical section, then increment
    // the lock count and the recursion count and return TRUE.
    //

    Thread = NtCurrentTeb()->ClientId.UniqueThread;
    if (Thread == CriticalSection->OwningThread) {

        ASSERT(CriticalSection->LockCount >= 0);

        InterlockedIncrement(&CriticalSection->LockCount);
        CriticalSection->RecursionCount += 1;
        return TRUE;
    }

    //
    // Attempt to enter the critical section. If the attempt is successful,
    // then set the owning thread, initialize the recursion count, and return
    // TRUE. Otherwise, return FALSE.
    //

    if (InterlockedCompareExchange(&CriticalSection->LockCount,
                                   0,
                                   - 1) == - 1) {
        CriticalSection->OwningThread = Thread;
        CriticalSection->RecursionCount = 1;
        return TRUE;

    } else {
        return FALSE;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\uilist.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    uilist.c

Abstract:

    Contains routine to convert a list of workstation names from UI/Service
    list format to API list format

    Contents:
        RtlConvertUiListToApiList
        (NextElement)
        (ValidateName)

Author:

    Richard L Firth (rfirth) 01-May-1992

Environment:

    User mode (makes Windows calls)

Revision History:

--*/

#pragma warning(disable:4127)   // condition expression is constant

#include <nt.h>
#include <ntrtl.h>
#include <nturtl.h>
#include <windows.h>
#include <wchar.h>

//
// macros
//

#define IS_DELIMITER(c,_BlankOk) \
    (((c) == L' ' && (_BlankOk)) || \
    ((c) == L'\t') || ((c) == L',') || ((c) == L';'))


//
// prototypes
//

static
ULONG
NextElement(
    IN OUT PWSTR* InputBuffer,
    IN OUT PULONG InputBufferLength,
    OUT PWSTR OutputBuffer,
    IN ULONG OutputBufferLength,
    IN BOOLEAN BlankIsDelimiter
    );

static
BOOLEAN
ValidateName(
    IN  PWSTR Name,
    IN  ULONG Length
    );

//
// functions
//


NTSTATUS
RtlConvertUiListToApiList(
    IN  PUNICODE_STRING UiList OPTIONAL,
    OUT PUNICODE_STRING ApiList,
    IN BOOLEAN BlankIsDelimiter
    )

/*++

Routine Description:

    Converts a list of workstation names in UI/Service format into a list of
    canonicalized names in API list format. UI/Service list format allows
    multiple delimiters, leading and trailing delimiters. Delimiters are the
    set "\t,;". API list format has no leading or trailing delimiters and
    elements are delimited by a single comma character.

    For each name parsed from UiList, the name is canonicalized (which checks
    the character set and name length) as a workstation name. If this fails,
    an error is returned. No information is returned as to which element
    failed canonicalization: the list should be discarded and a new one re-input

Arguments:

    UiList  - The list to canonicalize in UI/Service list format
    ApiList - The place to store the canonicalized version of the list in
              API list format.  The list will have a trailing zero character.
    BlankIsDelimiter - TRUE indicates blank should be considered a delimiter
              character.

Return Value:

    NTSTATUS
        Success = STATUS_SUCCESS
                    List converted ok

        Failure = STATUS_INVALID_PARAMETER
                    UiList parameter is in error

                  STATUS_INVALID_COMPUTER_NAME
                    A name parsed from UiList has an incorrect format for a
                    computer (aka workstation) name
--*/

{
    NTSTATUS status = STATUS_SUCCESS;
    ULONG inLen = 0;
    PWSTR input;
    PWSTR buffer;
    PWSTR output;
    ULONG cLen;
    ULONG len;
    ULONG outLen = 0;
    WCHAR element[MAX_COMPUTERNAME_LENGTH+1];
    BOOLEAN firstElement = TRUE;
    BOOLEAN ok;

    try {
        if (ARGUMENT_PRESENT(UiList)) {
            inLen = UiList->MaximumLength;  // read memory test
            inLen = UiList->Length;
            input = UiList->Buffer;
            if (inLen & sizeof(WCHAR)-1) {
                status = STATUS_INVALID_PARAMETER;
            }
        }
        RtlInitUnicodeString(ApiList, NULL);
    } except (EXCEPTION_EXECUTE_HANDLER) {
        status = STATUS_ACCESS_VIOLATION;
    }
    if (NT_SUCCESS(status) && ARGUMENT_PRESENT(UiList) && inLen) {
        buffer = RtlAllocateHeap(RtlProcessHeap(), 0, inLen + sizeof(WCHAR));
        if (buffer == NULL) {
            status = STATUS_NO_MEMORY;
        } else {
            ApiList->Buffer = buffer;
            ApiList->MaximumLength = (USHORT)inLen + sizeof(WCHAR);
            output = buffer;
            ok = TRUE;
            while (TRUE) {
                len = NextElement(&input,
                                     &inLen,
                                     element,
                                     sizeof(element) - sizeof(element[0]),
                                     BlankIsDelimiter );
                if (len == (ULONG)-1L) {
                    cLen = 0;
                    ok = FALSE;
                } else {
                    if (len == 0) {
                        break;
                    }
                    cLen = len/sizeof(WCHAR);
                    element[cLen] = 0;
                    ok = ValidateName(element, cLen);
                }
                if (ok) {
                    if (!firstElement) {
                        *output++ = L',';

                        outLen += sizeof(WCHAR);
                    } else {
                        firstElement = FALSE;
                    }
                    wcscpy(output, element);
                    outLen += len;
                    output += cLen;
                } else {
                    RtlFreeHeap(RtlProcessHeap(), 0, buffer);
                    ApiList->Buffer = NULL;
                    status = STATUS_INVALID_COMPUTER_NAME;
                    break;
                }
            }
        }
        if (NT_SUCCESS(status)) {
            ApiList->Length = (USHORT)outLen;
            if (!outLen) {
                ApiList->MaximumLength = 0;
                ApiList->Buffer = NULL;
                RtlFreeHeap(RtlProcessHeap(), 0, buffer);
            }
        }
    }
    return status;
}


static
ULONG
NextElement(
    IN OUT PWSTR* InputBuffer,
    IN OUT PULONG InputBufferLength,
    OUT PWSTR OutputBuffer,
    IN ULONG OutputBufferLength,
    IN BOOLEAN BlankIsDelimiter
    )

/*++

Routine Description:

    Locates the next (non-delimiter) element in a string and extracts it to a
    buffer. Delimiters are the set [\t,;]

Arguments:

    InputBuffer         - pointer to pointer to input buffer including delimiters
                          Updated on successful return
    InputBufferLength   - pointer to length of characters in InputBuffer.
                          Updated on successful return
    OutputBuffer        - pointer to buffer where next element is copied
    OutputBufferLength  - size of OutputBuffer (in bytes)
    BlankIsDelimiter    - TRUE indicates blank should be considered a delimiter
              character.

Return Value:

    ULONG
                           -1 = error - extracted element breaks OutputBuffer
                            0 = no element extracted (buffer is empty or all
                                delimiters)
        1..OutputBufferLength = OutputBuffer contains extracted element

--*/

{
    ULONG elementLength = 0;
    ULONG inputLength = *InputBufferLength;
    PWSTR input = *InputBuffer;

    while (inputLength && IS_DELIMITER(*input, BlankIsDelimiter)) {
        ++input;
        inputLength -= sizeof(*input);
    }
    while (inputLength && (!IS_DELIMITER(*input, BlankIsDelimiter))) {
        if (!OutputBufferLength) {
            return (ULONG)-1L;
        }
        *OutputBuffer++ = *input++;
        OutputBufferLength -= sizeof(*input);
        elementLength += sizeof(*input);
        inputLength -= sizeof(*input);
    }
    *InputBuffer = input;
    *InputBufferLength = inputLength;
    return elementLength;
}

//
// Illegal names characters same as those in net\api. Move to common
// include directory
//

#define ILLEGAL_NAME_CHARS      L"\001\002\003\004\005\006\007" \
                            L"\010\011\012\013\014\015\016\017" \
                            L"\020\021\022\023\024\025\026\027" \
                            L"\030\031\032\033\034\035\036\037" \
                            L"\"/\\[]:|<>+=;,?*"


static
BOOLEAN
ValidateName(
    IN  PWSTR Name,
    IN  ULONG Length
    )

/*++

Routine Description:

    Determines whether a computer name is valid or not

Arguments:

    Name    - pointer to zero terminated wide-character computer name
    Length  - of Name in characters, excluding zero-terminator

Return Value:

    BOOLEAN
        TRUE    Name is valid computer name
        FALSE   Name is not valid computer name

--*/

{
    if (Length > MAX_COMPUTERNAME_LENGTH || Length < 1) {
        return FALSE;
    }

    //
    // Don't allow leading or trailing blanks in the computername.
    //

    if ( Name[0] == ' ' || Name[Length-1] == ' ' ) {
        return(FALSE);
    }

    return (BOOLEAN)((ULONG)wcscspn(Name, ILLEGAL_NAME_CHARS) == Length);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\wow64apc.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    wow64apc.c

Abstract:

    This module implements APC queuing to 32-bit target threads from
    native 64-bit threads.

Author:

    Samer Arafeh (samera) 9-Oct-2000

Revision History:

--*/

#include "ldrp.h"
#include <ntos.h>
#include <nt.h>
#include <ntrtl.h>
#include <nturtl.h>
#include <heap.h>
#include <apcompat.h>

#if defined(_WIN64)
extern PVOID Wow64ApcRoutine;
#endif




#if defined(_WIN64)
VOID
RtlpWow64Apc(
    IN PVOID Argument1,
    IN PVOID Argument2,
    IN PVOID Argument3
    )

/*++

Routine Description:

    This function is called as a result of firing a usermode APC that's targeted to 
    a thread running inside Wow64.

Arguments:

    ApcArgument1 - The 1st argument of the APC. This includes both the 32-bit APC and
        the original 1st argument.

    ApcArgument2 - The second argument of the APC

    ApcArgument3 - The third argument of the APC

Return Value:

    None
    
--*/

{
    if (Wow64ApcRoutine)
    {
        (*(PPS_APC_ROUTINE) (ULONG_PTR)Wow64ApcRoutine) (
            Argument1,
            Argument2,
            Argument3);
    }
}

#endif

NTSTATUS
RtlQueueApcWow64Thread(
    IN HANDLE ThreadHandle,
    IN PPS_APC_ROUTINE ApcRoutine,
    IN PVOID ApcArgument1,
    IN PVOID ApcArgument2,
    IN PVOID ApcArgument3
    )

/*++

Routine Description:

    This function is used to queue a 32-bit user-mode APC to the specified thread. The APC
    will fire when the specified thread does an alertable wait.
    
    Note: This function is only used by 64-bit components that want to queue an APC to 
          a thread running inside Wow64.

Arguments:

    ThreadHandle - Supplies a handle to a thread object.  The caller
        must have THREAD_SET_CONTEXT access to the thread.

    ApcRoutine - Supplies the address of the APC routine to execute when the
        APC fires.

    ApcArgument1 - Supplies the first PVOID passed to the APC

    ApcArgument2 - Supplies the second PVOID passed to the APC

    ApcArgument3 - Supplies the third PVOID passed to the APC

Return Value:

    Returns an NT Status code indicating success or failure of the API
    
--*/

{
#if defined(_WIN64)

    //
    // Setup the jacket routine inside ntdll
    //

    ApcArgument1 = (PVOID)((ULONG_PTR) ApcArgument1 | 
                           ((ULONG_PTR) ApcRoutine << 32 ));

    ApcRoutine = RtlpWow64Apc;
#endif

    return NtQueueApcThread (
        ThreadHandle,
        ApcRoutine,
        ApcArgument1,
        ApcArgument2,
        ApcArgument3);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\amd64\ldrctx.c ===
/*++

Copyright (c) 1998  Microsoft Corporation

Module Name:

    ldrctx.c

Abstract:

    This module contains support for relocating executables.

Author:

    Landy Wang (landyw) 8-Jul-1998

Environment:

    User Mode only

--*/

#include <ldrp.h>
#include <ntos.h>

VOID
LdrpRelocateStartContext (
    IN PCONTEXT Context,
    IN LONG_PTR Diff
    )
/*++

Routine Description:

   This routine adjustss the initial function address to correspond to the
   an executable that has just been relocated.

Arguments:

   Context - Supplies a pointer to a context record.

   Diff - Supplies the difference from the based address to the relocated
          address.

Return Value:

   None.

--*/
{
    Context->Rcx += Diff;
}

VOID
LdrpCorReplaceStartContext (
    IN PCONTEXT Context
    )

/*++

Routine Description:

   This routine replaces the initial function address in the specified context
   record.

Arguments:

   Context - Supplies a pointer to a context record.

Return Value:

   None.

--*/
{
    Context->Rcx = (ULONG64)CorExeMain;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\amd64\ldrthunk.asm ===
title   "LdrInitializeThunk"
;++
;
; Copyright (c) 1989  Microsoft Corporation
;
; Module Name:
;
;   ldrthunk.s
;
; Abstract:
;
;   This module implements the thunk for the loader staetup APC routine.
;
; Author:
;
;   David N. Cutler (davec) 25-Jun-2000
;
;  Environment:
;
;    Any mode.
;
;--

include ksamd64.inc

        extrn   LdrpInitialize:proc

        subttl  "Initialize Thunk"
;++
;
; VOID
; LdrInitializeThunk(
;     IN PVOID NormalContext,
;     IN PVOID SystemArgument1,
;     IN PVOID SystemArgument2
;     )
;
; Routine Description:
;
;   This function computes a pointer to the context record on the stack
;   and jumps to the LdrpInitialize function with that pointer as its
;   parameter.
;
; Arguments:
;
;   NormalContext (rcx) - User Mode APC context parameter (ignored).
;
;   SystemArgument1 (rdx) - User Mode APC system argument 1 (ignored).
;
;   SystemArgument2 (r8) - User Mode APC system argument 2 (ignored).
;
; Return Value:
;
;   None.
;
;--

        LEAF_ENTRY LdrInitializeThunk, _TEXT$00

        lea     rcx, [rsp+8]            ; set context record address
        jmp     LdrpInitialize          ; finish in common common

        LEAF_END LdrInitializeThunk, _TEXT$00

        end
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emarith.asm ===
subttl  emarith.asm - Arithmetic Operations
	page
;*******************************************************************************
;emarith.asm - Arithmetic Operations
;
;        Microsoft Confidential
;
;        Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Purpose:
;       Arithmetic Operations
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************

	NextStackWrap   esi,TwoOp       ;Tied to NextStackElem below

EM_ENTRY eFPREM
eFPREM:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset PremCont		;Return address if normal
PremPointTopTwo:
	push	offset PremSpclDone	;Return address if special
	mov	ebp,offset tFpremDisp
PointTopTwo:
	mov	esi,edi
	NextStackElem   esi,TwoOp
TwoOpSiDi:
	mov	ecx,EMSEG:[esi].ExpSgn
	mov	ebx,EMSEG:[esi].lManHi
	mov	esi,EMSEG:[esi].lManLo
TwoOpSetResult:
	mov	EMSEG:[Result],edi		;Save result pointer
TwoOpResultSet:
	mov     ah,EMSEG:[edi].bTag
TwoOpDispAh:
	mov	al,cl
TwoOpDispatch:
	and     eax,TAG_MASK + 100H*TAG_MASK	;Look at internal tags only
	shl     al,TAG_SHIFT
	or      al,ah
	xor	ah,ah			;Zero ah
;UNDONE:  masm bug!  ebp + scaled index requires a displacement.
;UNDONE:  No displacement is needed here, so masm should generate a
;UNDONE:  zero.  It doesn't!  dec eax so we can add 4*1 back.
	dec	eax			;UNDONE
	jmp     dword ptr cs:[ebp+4*eax+4];UNDONE Go to appropriate routine.

EM_ENTRY eFPREM1
eFPREM1:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset Prem1Cont	;Return address if normal
	jmp	PremPointTopTwo

EM_ENTRY eFSCALE
eFSCALE:
	mov	ebp,offset tFscaleDisp
	jmp	PointTopTwo

EM_ENTRY eFPATAN
eFPATAN:
	mov	ebp,offset tFpatanDisp
TopTwoPop:
	push	offset PopWhenDone
	mov	esi,edi
	add	edi,Reg87Len		;edi = ST(1)
        cmp     edi,ENDstk
	jb	TwoOpSiDi
        mov     edi,BEGstk
	jmp	TwoOpSiDi

EM_ENTRY eFYL2X
eFYL2X:
	mov	ebp,offset tFyl2xDisp
	jmp	TopTwoPop

EM_ENTRY eFYL2XP1
eFYL2XP1:
	mov	ebp,offset tFyl2xp1Disp
	jmp	TopTwoPop

;*******************************************************************************

page
;-----------------------------------------------------------;
;                                                           ;
;       Special Case Routines for Arithmetic Functions      ;
;                                                           ;
;-----------------------------------------------------------;

;There are four kinds of "specials", encoded in the tag:
;
;	Empty
; 	Infinity
;	NAN (which can be QNAN or SNAN)
;	Denormal
;
;Empty always results in an Invalid Operation exception with Stack Flag set
;and C1 (O/U#) bit clear, and returns Indefinite (a specific QNAN).
;
;Operations on NAN return the same NAN except it is always modified to a 
;QNAN.  If both  operands are NAN, the one with the larger mantissa is
;returned.  An SNAN causes an Invalid Operation exception except for
;internal FP stack operations, FCHS, and FABS.  A QNAN does not cause
;and exception.  
;
;Operations on Infinity return a result depending on the operation.
;
;UNDONE: Old code plays with sign of NAN when two NANs with equal
;mantissas are used.  Why?

;"***" means entry point from dispatch tables

;***
DivSpclSource:
	cmp	cl,bTAG_INF
	jnz	SpclSource
;Division by infinity always returns zero
	xor	ch,EMSEG:[edi].bSgn
	jmp	SignedZero		;in emfmul.asm

;***
MulSpclSource:
	cmp	cl,bTAG_INF
	jnz	SpclSource
MulByInf:
	cmp	EMSEG:[edi].bTag,bTAG_ZERO	;Infinity * zero?
	jz	ReturnIndefinite
XorSourceSign:
	xor	ch,EMSEG:[edi].bSgn
	jmp	SaveResultEdi

;***
AddSpclSource:
	cmp	cl,bTAG_INF
	jnz	SpclSource
	xor	ch,dl			;Flip sign of infinity if subtracting
	jmp	SaveResultEdi

DenormalSource:
	mov	cl,bTAG_VALID		;Change denormal to DOUBLE
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is denormal exception masked?
	jnz	TwoOpResultSet
AbortOp:
	mov	cl,bTAG_NOPOP		;Unmasked, don't pop stack
	ret

DenormalDisp:
;Repeat dispatch, but for normal ops
	jmp     dword ptr cs:[ebp+4*(TAG_VALID + TAG_VALID shl TAG_SHIFT)]

;***
DivrSpclSource:
	cmp	cl,bTAG_INF
	jz	XorSourceSign		;Return infinity
SpclSource:
	cmp	cl,bTAG_DEN
	jz	DenormalSource
	cmp	cl,bTAG_EMPTY
	jz	StackError
;Must be a NAN
SourceNAN:
	test	ebx,1 shl 30		;Check for SNAN
	jnz	SaveResultEdi		;If QNAN, just use it as result
SourceSNAN:
	or	EMSEG:[CURerr],Invalid	;Flag the error
	or	ebx,1 shl 30		;Make it into a QNAN
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jnz	SaveResultEdi		;If so, update with masked response
	mov	cl,bTAG_NOPOP		;Unmasked, don't pop stack
	ret


;***
DivrSpclDest:
	mov	eax,EMSEG:[edi].ExpSgn	;Pick up tag
	cmp	al,bTAG_INF
	jnz	SpclDest
;Division by infinity always returns zero
	xor	ch,ah
	jmp	SignedZero		;in emfmul.asm

;***
MulSpclDest:
	mov	al,EMSEG:[edi].bTag	;Pick up tag
	cmp	al,bTAG_INF
	jnz	SpclDest
	cmp	cl,bTAG_ZERO		;Infinity * zero?
	jz	ReturnIndefinite
XorDestSign:
	xor	EMSEG:[edi].bSgn,ch	;Xor signs
	ret

;***
AddSpclDest:
	mov	al,EMSEG:[edi].bTag	;Pick up tag
	cmp	al,bTAG_INF
	jnz	SpclDest
	xor	EMSEG:[edi].bSgn,dh	;Flip sign of infinity if subtracting
	ret

DenormalDest:
	mov	ah,bTAG_VALID		;Change denormal to DOUBLE
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is denormal exception masked?
	jnz	TwoOpDispAh
	mov	cl,bTAG_NOPOP		;Unmasked, don't pop stack
	ret

;***
DivSpclDest:
	mov	al,EMSEG:[edi].bTag	;Pick up tag
	cmp	al,bTAG_INF
	jz	XorDestSign		;Return infinity
SpclDest:
	cmp	al,bTAG_DEN
	jz	DenormalDest
SpclDestNotDen:
	cmp	al,bTAG_EMPTY
	jz	StackError
;Must be a NAN
DestNAN:
	test	EMSEG:[edi].bMan7,40H	;Check for SNAN
	jnz	ReturnDest		;If QNAN, just use it as result
DestSNAN:
	or	EMSEG:[CURerr],Invalid	;Flag the error
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	AbortOp			;No - preserve value
	or	EMSEG:[edi].bMan7,40H	;Make it into a QNAN
	ret

StackError:
	mov	EMSEG:[CURerr],Invalid+StackFlag
ReturnIndefinite:
	or 	EMSEG:[CURerr],Invalid
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	AbortOp			;No - preserve value
	mov	EMSEG:[edi].lManLo,0
	mov	EMSEG:[edi].lManHi,0C0000000H
	mov	EMSEG:[edi].ExpSgn,TexpMax shl 16 + bSign shl 8 + bTAG_NAN
ReturnDest:
	ret


AddTwoInf:
;Adding two infinites.
;If signs are the same, return that infinity.  Otherwise, Invalid Operation.
	xor	ch,dl			;Possibly subtracting source
	xor	ah,dh			;Possibly subtracting dest
	xor	ch,ah			;Compare signs
	js	ReturnIndefinite
	mov	EMSEG:[edi].bSgn,ah	;Correct the sign if subtracting
	ret

;***
TwoOpBothSpcl:
;ebp = dispatch table address
	mov	al,EMSEG:[edi].bTag
	mov	ah,cl
	cmp	ax,(bTAG_NAN shl 8) + bTag_NAN	;Are both NAN?
	jz	TwoNANs
	cmp	cl,bTAG_EMPTY
	jz	StackError
	cmp	al,bTAG_EMPTY
	jz	StackError
	cmp	cl,bTAG_NAN
	jz	SourceNAN
	cmp	al,bTAG_NAN
	jz	DestNAN
	cmp	ax,(bTAG_INF shl 8) + bTag_INF	;Are both infinity?
	jz	TwoInfs
;At least one of the operands is a denormal
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is denormal exception masked?
	jz	AbortOp			;If not, don't do operation
;Denormal exception is masked, treat denormals as VALID
;Dispatch through operation table in ebp again
	cmp	ax,(bTAG_DEN shl 8) + bTag_DEN	;Are both denormal?
	jz	DenormalDisp
;Have an infinity and a denormal
	cmp	al,bTAG_INF
	jz	DestInf
;Source is denormal, Dest is infinity
	jmp	dword ptr [ebp+4*(TAG_SPCL + TAG_VALID shl TAG_SHIFT)]

DestInf:
;Source is infinity, Dest is denormal
	jmp	dword ptr [ebp+4*(TAG_VALID + TAG_SPCL shl TAG_SHIFT)]

TwoNANs:
;Two NANs. Use largest mantissa
	cmp	ebx,EMSEG:[edi].lManHi
	ja	BiggerNAN
	jb	DestBigger
;Now we know they're both the same type, SNAN or QNAN
	cmp	esi,EMSEG:[edi].lManLo
	ja	SourceNAN
;UNDONE: Old code did funny business with signs when mantissas were equal
	jmp	DestNAN

BiggerNAN:
	test	EMSEG:[edi].bMan7,40H		;Is smaller one SNAN?
	jz	SourceSNAN
	jmp	SourceNAN

DestBigger:
	test	ebx,40H			;Is smaller one SNAN?
	jz	DestSNAN
	jmp	DestNAN

TwoInfs:
        mov     ah,EMSEG:[edi].bSgn
	jmp	dword ptr [ebp+4*16]	;Go do code for two infinites


;***
DivideByMinusZero:
	mov	ch,bSign
;***
DivideByZero:
	or	EMSEG:[CURerr],ZeroDivide
	test	EMSEG:[CWmask],ZeroDivide	;Is exception masked?
	jz	AbortOp			;No - preserve value
;Set up a signed infinity
	xor	ch,EMSEG:[edi].bSgn		;Get result sign
	and	ecx,1 shl 15		;Keep only sign bit
	or	ecx,(4000H+TexpBias) shl 16 + bTAG_INF	;ExpSgn of infinity
	mov	ebx,1 shl 31
	xor	esi,esi
	jmp	SaveResultEdi
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\daytona\makefile.inc ===
!include ..\makefile.inc
!if exist(..\$(TARGET_DIRECTORY).inc)
!include ..\$(TARGET_DIRECTORY).inc
!endif

SERVICES_DIR=$(O)
SERVICES_TAB=$(SERVICES_DIR)\services.tab
SERVICES_STB=..\..\ntos\ke\$(TARGET_DIRECTORY)\services.stb
NTDLL_XTR=$(O)\ntdll.xtr

$(SERVICES_TAB): ..\..\ntos\ke\services.tab
    @echo Creating $@ from $**
    $(C_PREPROCESSOR) $** > $@

$(O)\usrstubs.obj: \
    $(O)\usrstubs.$(ASM_SUFFIX) $(O)\ntdll.def

$(NTDLL_XTR): $(SERVICES_TAB)
    gensrv -f $(NTDLL_XTR) -s ..\..\ntos\ke $(SERVICES_DIR)

$(O)\usrstubs.$(ASM_SUFFIX): $(SERVICES_TAB) $(SERVICES_STB)
    gensrv -d $(O) -e $(ASM_SUFFIX) $(TARGET_BRACES) -s ..\..\ntos\ke\$(TARGET_DIRECTORY) $(SERVICES_DIR)

$(DLLDEF): ..\ntdlldef.src ..\$(TARGET_DIRECTORY)def.src $(NTDLL_XTR)
    copy ..\ntdlldef.src+..\$(TARGET_DIRECTORY)def.src+$(NTDLL_XTR) $(O)\$(TARGETNAME).pp
    $(TARGET_CPP) /EP $(CDEFINES) $(O)\$(TARGETNAME).pp > $@
    -del $(O)\$(TARGETNAME).pp

..\ntdll.rc: $(PROJECT_ROOT)\published\$(O)\ntstatus.rc $(PROJECT_ROOT)\published\$(O)\ntstatus_MSG00001.bin
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emdecode.asm ===
subttl	emdecode.asm - Instruction decoding
	page
;***
;emdecode.asm - Instruction decoding
;
;	 Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;
;	 All Rights Reserved
;
;Purpose:
;	Further decoding of instructions done here.
;
;Revision History:
;
;    8/23/91  TP    Rewritten for 32 bits
;
;*******************************************************************************

;On entry, eax = r/m bits * 4.  This is used to jump directly to the
;correct instruction within the group.

GroupFCHS:
	jmp	tGroupFCHSdisp[eax]

GroupFLD1:
	jmp	tGroupFLD1disp[eax]

GroupF2XM1:
	jmp	tGroupF2XM1disp[eax]

GroupFPREM:
	jmp	tGroupFPREMdisp[eax]

GroupFENI:
	jmp	tGroupFENIdisp[eax]
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\critsect.asm ===
title   "Critical Section Support"
;++
;
;  Copyright (c) 1991  Microsoft Corporation
;
;  Module Name:
;
;     critsect.asm
;
;  Abstract:
;
;     This module implements functions to support user mode critical sections.
;
;  Author:
;
;     Bryan M. Willman (bryanwi) 2-Oct-91
;
;  Environment:
;
;     Any mode.
;
;  Revision History:
;
;--

.486p
        .xlist
include ks386.inc
include callconv.inc                    ; calling convention macros
include mac386.inc
        .list

;
; FUTURE-2002/03/12-DavidFie
; This is for SmashLock and can go away since we no longer smash locks at
; install time.  When it does get removed, there's a lot more stuff to cleanup
; in several DLL's
;
_DATA   SEGMENT DWORD PUBLIC 'DATA'
    public _LdrpLockPrefixTable
_LdrpLockPrefixTable    label dword
        dd offset FLAT:Lock1
        dd offset FLAT:Lock2
        dd offset FLAT:Lock3
        dd offset FLAT:Lock4
        dd offset FLAT:Lock5
        dd offset FLAT:Lock6
        dd offset FLAT:Lock7
        dd 0
_DATA   ENDS

_TEXT   SEGMENT PARA PUBLIC 'CODE'
        ASSUME  DS:FLAT, ES:FLAT, SS:NOTHING, FS:NOTHING, GS:NOTHING

        EXTRNP  _RtlpWaitForCriticalSection,1
        EXTRNP  _RtlpUnWaitCriticalSection,1
if DEVL
        EXTRNP  _RtlpNotOwnerCriticalSection,1
endif
if DBG
        EXTRNP  _RtlpCriticalSectionIsOwned,1
endif

CriticalSection equ     [esp + 4]

        page , 132
        subttl  "RtlEnterCriticalSection"

;++
;
; NTSTATUS
; RtlEnterCriticalSection(
;    IN PRTL_CRITICAL_SECTION CriticalSection
;    )
;
; Routine Description:
;
;    This function enters a critical section.
;
; Arguments:
;
;    CriticalSection - supplies a pointer to a critical section.
;
; Return Value:
;
;   STATUS_SUCCESS or raises an exception if an error occured.
;
;--

        align   16
cPublicProc _RtlEnterCriticalSection,1
cPublicFpo 1,0

        mov     ecx,fs:PcTeb            ; get current TEB address
        mov     edx,CriticalSection     ; get address of critical section
        cmp     CsSpinCount[edx],0      ; check if spin count is zero
        jne     short Ent40             ; if ne, spin count specified

;
; Attempt to acquire critical section.
;

Lock1:                                  ;
   lock inc     dword ptr CsLockCount[edx] ; increment lock count
        jnz     short Ent20             ; if nz, already owned

;
; Set critical section owner and initialize recursion count.
;

Ent10:
if DBG
        cmp     CsOwningThread[edx],0
        je      @F
        stdCall _RtlpCriticalSectionIsOwned, <edx>
        mov     ecx,fs:PcTeb            ; get current TEB address
        mov     edx,CriticalSection     ; get address of critical section
@@:
endif ; DBG
        mov     eax,TbClientId + 4[ecx] ; get current client ID
        mov     CsOwningThread[edx],eax ; set critical section owner
        mov     dword ptr CsRecursionCount[edx],1 ; set recursion count

if DBG

        inc     dword ptr TbCountOfOwnedCriticalSections[ecx] ; increment owned count
        mov     eax,CsDebugInfo[edx]    ; get debug information address
        inc     dword ptr CsEntryCount[eax] ; increment entry count

endif ; DBG

        xor     eax,eax                 ; set success status

        stdRET  _RtlEnterCriticalSection

;
; The critical section is already owned, but may be owned by the current thread.
;

        align   16
Ent20:  mov     eax,TbClientId + 4[ecx] ; get current client ID
        cmp     CsOwningThread[edx],eax ; check if current thread is owner
        jne     short Ent30             ; if ne, current thread not owner
        inc     dword ptr CsRecursionCount[edx] ; increment recursion count

if DBG

        mov     eax,CsDebugInfo[edx]    ; get debug information address
        inc     dword ptr CsEntryCount[eax] ; increment entry count

endif ; DBG

        xor     eax,eax                 ; set success status

        stdRET  _RtlEnterCriticalSection

;
; The critcal section is owned by another thread and the current thread must
; wait for ownership.
;

Ent30:  stdCall _RtlpWaitForCriticalSection, <edx> ; wait for ownership
        mov     ecx,fs:PcTeb            ; get current TEB address
        mov     edx,CriticalSection     ; get address of critical section
        jmp     Ent10                   ; set owner and recursion count

;
; A nonzero spin count is specified.
;

        align   16
Ent40:  mov     eax,TbClientId + 4[ecx] ; get current client ID
        cmp     CsOwningThread[edx],eax ; check if current thread is owner
        jne     short Ent50             ; if ne, current thread not owner

;
; The critical section is owned by the current thread. Increment the lock
; count and the recursion count.
;

Lock6:                                  ;
   lock inc     dword ptr CsLockCount[edx] ; increment lock count
        inc     dword ptr CsRecursionCount[edx] ; increment recursion count

if DBG

        mov     eax,CsDebugInfo[edx]    ; get debug information address
        inc     dword ptr CsEntryCount[eax] ; increment entry count

endif ; DBG

        xor     eax,eax                 ; set success status

        stdRET  _RtlEnterCriticalSection

;
; A nonzero spin count is specified and the current thread is not the owner.
;

        align   16
Ent50:  push    CsSpinCount[edx]        ; get spin count value
Ent60:  mov     eax,-1                  ; set comparand value
        mov     ecx,0                   ; set exchange value

Lock7:
   lock cmpxchg dword ptr CsLockCount[edx],ecx ; attempt to acquire critical section
        jnz     short Ent70             ; if nz, critical section not acquired

;
; The critical section has been acquired. Set the owning thread and the initial
; recursion count.
;

        add     esp,4                   ; remove spin count from stack
        mov     ecx,fs:PcTeb            ; get current TEB address
        mov     eax,TbClientId + 4[ecx] ; get current client ID
        mov     CsOwningThread[edx],eax ; set critical section owner
        mov     dword ptr CsRecursionCount[edx],1 ; set recursion count

if DBG

        inc     dword ptr TbCountOfOwnedCriticalSections[ecx] ; increment owned count
        mov     eax,CsDebugInfo[edx]    ; get debug information address
        inc     dword ptr CsEntryCount[eax] ; increment entry count

endif ; DBG

        xor     eax,eax                 ; set success status

        stdRET  _RtlEnterCriticalSection

;
; The critical section is currently owned. Spin until it is either unowned
; or the spin count has reached zero.
;
; If waiters are present, don't spin on the lock since we will never see it go free
;

Ent70:  cmp     CsLockCount[edx],1      ; check if waiters are present,
        jge     short Ent76             ; if ge 1, then do not spin

Ent75:  YIELD
        cmp     CsLockCount[edx],-1     ; check if lock is owned
        je      short Ent60             ; if e, lock is not owned
        dec     dword ptr [esp]         ; decrement spin count
        jnz     short Ent75             ; if nz, continue spinning
Ent76:  add     esp,4                   ; remove spin count from stack
        mov     ecx,fs:PcTeb            ; get current TEB address
        jmp     Lock1                   ;

stdENDP _RtlEnterCriticalSection


        page , 132
        subttl  "RtlLeaveCriticalSection"
;++
;
; NTSTATUS
; RtlLeaveCriticalSection(
;    IN PRTL_CRITICAL_SECTION CriticalSection
;    )
;
; Routine Description:
;
;    This function leaves a critical section.
;
; Arguments:
;
;    CriticalSection - supplies a pointer to a critical section.
;
; Return Value:
;
;   STATUS_SUCCESS or raises an exception if an error occured.
;
;--

        align   16
cPublicProc _RtlLeaveCriticalSection,1
cPublicFpo 1,0

        mov     edx,CriticalSection
if DBG
        mov     ecx,fs:PcTeb                ; (ecx) == NtCurrentTeb()
        mov     eax,TbClientId+4[ecx]       ; (eax) == NtCurrentTeb()->ClientId.UniqueThread
        cmp     eax,CsOwningThread[edx]
        je      @F
        stdCall _RtlpNotOwnerCriticalSection, <edx>
        mov     eax,STATUS_INVALID_OWNER
        stdRET  _RtlLeaveCriticalSection
@@:
endif ; DBG
        xor     eax,eax                     ; Assume STATUS_SUCCESS
        dec     dword ptr CsRecursionCount[edx]
        jnz     leave_recurs                ; skip if only leaving recursion

        mov     CsOwningThread[edx],eax     ; clear owning thread id

if DBG
        mov     ecx,fs:PcTeb                ; (ecx) == NtCurrentTeb()
        dec     dword ptr TbCountOfOwnedCriticalSections[ecx]
endif ; DBG

Lock2:
   lock dec     dword ptr CsLockCount[edx]  ; interlocked dec of
                                            ; ... CriticalSection->LockCount
        jge     @F
        stdRET  _RtlLeaveCriticalSection

@@:
        stdCall _RtlpUnWaitCriticalSection, <edx>
        xor     eax,eax                     ; return STATUS_SUCCESS
        stdRET  _RtlLeaveCriticalSection

        align   16
leave_recurs:
Lock3:
   lock dec     dword ptr CsLockCount[edx]  ; interlocked dec of
                                            ; ... CriticalSection->LockCount
        stdRET  _RtlLeaveCriticalSection

_RtlLeaveCriticalSection    endp

        page    ,132
        subttl  "RtlTryEnterCriticalSection"
;++
;
; BOOL
; RtlTryEnterCriticalSection(
;    IN PRTL_CRITICAL_SECTION CriticalSection
;    )
;
; Routine Description:
;
;    This function attempts to enter a critical section without blocking.
;
; Arguments:
;
;    CriticalSection (a0) - Supplies a pointer to a critical section.
;
; Return Value:
;
;    If the critical section was successfully entered, then a value of TRUE
;    is returned as the function value. Otherwise, a value of FALSE is returned.
;
;--

CriticalSection equ     [esp + 4]

cPublicProc _RtlTryEnterCriticalSection,1
cPublicFpo 1,0

        mov     ecx,CriticalSection         ; interlocked inc of
        mov     eax, -1                     ; set value to compare against
        mov     edx, 0                      ; set value to set
Lock4:
   lock cmpxchg dword ptr CsLockCount[ecx],edx  ; Attempt to acquire critsect
        jnz     short tec10                 ; if nz, critsect already owned

        mov     eax,fs:TbClientId+4         ; (eax) == NtCurrentTeb()->ClientId.UniqueThread
        mov     CsOwningThread[ecx],eax
        mov     dword ptr CsRecursionCount[ecx],1

if DBG
        mov     eax,fs:PcTeb                ; (eax) == NtCurrentTeb()
        inc     dword ptr TbCountOfOwnedCriticalSections[eax]
        mov     eax,CsDebugInfo[ecx]    ; get debug information address
        inc     dword ptr CsEntryCount[eax] ; increment entry count
endif ; DBG

        mov     eax, 1                      ; set successful status

        stdRET  _RtlTryEnterCriticalSection

tec10:
;
; The critical section is already owned. If it is owned by another thread,
; return FALSE immediately. If it is owned by this thread, we must increment
; the lock count here.
;
        mov     eax, fs:TbClientId+4        ; (eax) == NtCurrentTeb()->ClientId.UniqueThread
        cmp     CsOwningThread[ecx], eax
        jz      tec20                       ; if eq, this thread is already the owner
        xor     eax, eax                    ; set failure status
        YIELD
        stdRET  _RtlTryEnterCriticalSection

tec20:
;
; This thread is already the owner of the critical section. Perform an atomic
; increment of the LockCount and a normal increment of the RecursionCount and
; return success.
;
Lock5:
   lock inc     dword ptr CsLockCount[ecx]
        inc     dword ptr CsRecursionCount[ecx]

if DBG
        mov     eax,CsDebugInfo[ecx]    ; get debug information address
        inc     dword ptr CsEntryCount[eax] ; increment entry count
endif ; DBG

        mov     eax, 1
        stdRET  _RtlTryEnterCriticalSection

stdENDP _RtlTryEnterCriticalSection


_TEXT   ends
        end
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emdisp.asm ===
subttl	emdisp.asm - Emulator Dispatch Tables
	page
;
;	 IBM/Microsoft Confidential
;
;	 Copyright (c) IBM Corporation 1987, 1989
;	 Copyright (c) Microsoft Corporation 1987, 1989
;
;	 All Rights Reserved
;
;Revision History:  (also see emulator.hst)
;
;    1/21/92  JWM   Minor modifications for DOSX32 emulator
;    8/23/91  TP    Direct dispatch off of 6-bit opcode
;   10/30/89  WAJ   Added this header.
;
;*******************************************************************************

;*********************************************************************;
;								      ;
;		Dispatch Tables 				      ;
;								      ;
;*********************************************************************;


;   These tables are based upon the layout of the 8087 instructions
;
;      8087 instruction fields:   |escape|MF|Arith|MOD|Op|r/m|disp1|disp2|
;	  field length in bits:       5    2   1    2	3   3	8     8
;
;   Disp1 and Disp2  are optional address bytes present only if MOD <> 11.
;   When (MOD <> 11) r/m describes which regs (SI,DI,BX,BP) are added to
;	Disp1 and Disp2 to calculate the effective address. This form
;	(memory format) is used for Loads, Stores, Compares, and Arithmetic
;   When using memory format MF determines the Type of the Memory operand
;	i.e. Single Real, Double real, Single Integer, or Double Integer
;   Arith is 0 for Arithmetic opetations (and compares), set to 1 otherwise
;   Op mostly determines which type of operation to do though when not in
;	memory format some of that is coded into MF and r/m
;   All of the tables are set up to do a jump based upon one or more of the
;	above fields. The outline for decoding instructions is:
;
;	    IF (memory format) THEN
;	       Assemble Effective Address (using MOD and r/m and EffectiveAddressTab)
;	       Jump through table to operation, using MF, Arith and Op bits
;	    ELSE (Register format)
;	       Jump through table to operation, using MF, Arith and Op bits

	ALIGN	4

;*********************************************************************;
;
; Memory address calculation tables

EA386Tab	label	dword			; Uses |r/m|MOD+1| for indexing
	dd	NoEffectiveAddress
	dd	Exx00			; eax
	dd	Exx01
	dd	Exx10
	dd	NoEffectiveAddress
	dd	Exx00			; ecx
	dd	Exx01
	dd	Exx10
	dd	NoEffectiveAddress
	dd	Exx00			; edx
	dd	Exx01
	dd	Exx10
	dd	NoEffectiveAddress
	dd	Exx00			; ebx
	dd	Exx01
	dd	Exx10
	dd	NoEffectiveAddress
	dd	SIB00			; esp (S-I-B follows)
	dd	SIB01
	dd	SIB10
	dd	NoEffectiveAddress
	dd	Direct386		; ebp (00 = direct addressing)
	dd	Exx01
	dd	Exx10
	dd	NoEffectiveAddress
	dd	Exx00			; esi
	dd	Exx01
	dd	Exx10
	dd	NoEffectiveAddress
	dd	Exx00			; edi
	dd	Exx01
	dd	Exx10

;*********************************************************************;
;
;Opcode dispatching tables
;Indexed by  | op1 | op2 |0 0|  (op1 = MF|Arith)

	public	tOpRegDisp
tOpRegDisp	label	dword
	dd	eFADDtop
	dd	eFMULtop
	dd	eFCOM
	dd	eFCOMP
	dd	eFSUBtop
	dd	eFSUBRtop
	dd	eFDIVtop
	dd	eFDIVRtop

	dd	eFLDreg
	dd	eFXCH
	dd	eFNOP		;UNDONE: also reserved on 387
	dd	eFSTP		;Special form 1
	dd	GroupFCHS	;FCHS,FABS,FTST,FXAM
	dd	GroupFLD1	;FLD1,FLDL2T,FLDL2E,FLDPI,FLDLG2,FLDLN2,FLDZ
	dd	GroupF2XM1	;F2XM1,FYL2X,FPTAN,FPATAN,FXTRACT,FPREM1,FDECSTP,FINCSTP
	dd	GroupFPREM	;FPREM,FYL2XP1,FSQRT,FSINCOS,FRNDINT,FSCALE,FSIN,FCOS

	dd	UNUSED
	dd	UNUSED
	dd	UNUSED
	dd	UNUSED
	dd	UNUSED
	dd	eFUCOMPP	;UNDONE: also reserved on 387
	dd	UNUSED
	dd	UNUSED

	dd	UNUSED
	dd	UNUSED
	dd	UNUSED
	dd	UNUSED
	dd	GroupFENI	;FENI,FDISI,FCLEX,FINIT
	dd	UNUSED
	dd	UNUSED
	dd	UNUSED

	dd	eFADDreg
	dd	eFMULreg
	dd	eFCOM		;Special form  2
	dd	eFCOMP		;Special form  3
	dd	eFSUBRreg
	dd	eFSUBreg
	dd	eFDIVRreg
	dd	eFDIVreg

	dd	eFFREE
	dd	eFXCH		;Special form 4
	dd	eFST
	dd	eFSTP
	dd	eFUCOM
	dd	eFUCOMP
	dd	UNUSED
	dd	UNUSED

	dd	eFADDPreg
	dd	eFMULPreg
	dd	eFCOMP		;Special form 5
	dd	eFCOMPP		;UNDONE: also reserved on 387
	dd	eFSUBRPreg
	dd	eFSUBPreg
	dd	eFDIVRPreg
	dd	eFDIVPreg

	dd	eFFREE		;Special form 6 UNDONE: "and pop stack"?
	dd	eFXCH		;Special form 7
	dd	eFSTP		;Special form 8
	dd	eFSTP		;Special form 9
	dd	eFSTSWax	;UNDONE: also reserved on 387
	dd	UNUSED
	dd	UNUSED
	dd	UNUSED


tOpMemDisp	label	dword
;MF = 00 (32-bit Real), Arith = 0
	dd	eFADD32
	dd	eFMUL32
	dd	eFCOM32
	dd	eFCOMP32
	dd	eFSUB32
	dd	eFSUBR32
	dd	eFDIV32
	dd	eFDIVR32
;MF = 00 (32-bit Real), Arith = 1
	dd	eFLD32
	dd	UNUSED
	dd	eFST32
	dd	eFSTP32
	dd	eFLDENV
	dd	eFLDCW
	dd	eFSTENV
	dd	eFSTCW
;MF = 01 (32-bit Int), Arith = 0
	dd	eFIADD32
	dd	eFIMUL32
	dd	eFICOM32
	dd	eFICOMP32
	dd	eFISUB32
	dd	eFISUBR32
	dd	eFIDIV32
	dd	eFIDIVR32
;MF = 01 (32-bit Int), Arith = 1
	dd	eFILD32
	dd	UNUSED
	dd	eFIST32
	dd	eFISTP32
	dd	UNUSED
	dd	eFLD80
	dd	UNUSED
	dd	eFSTP80
;MF = 10 (64-bit Real), Arith = 0
	dd	eFADD64
	dd	eFMUL64
	dd	eFCOM64
	dd	eFCOMP64
	dd	eFSUB64
	dd	eFSUBR64
	dd	eFDIV64
	dd	eFDIVR64
;MF = 10 (64-bit Real), Arith = 1
	dd	eFLD64
	dd	UNUSED
	dd	eFST64
	dd	eFSTP64
	dd	eFRSTOR
	dd	UNUSED
	dd	eFSAVE
	dd	eFSTSW
;MF = 11 (16-bit Int), Arith = 0
	dd	eFIADD16
	dd	eFIMUL16
	dd	eFICOM16
	dd	eFICOMP16
	dd	eFISUB16
	dd	eFISUBR16
	dd	eFIDIV16
	dd	eFIDIVR16
;MF = 11 (16-bit Int), Arith = 1
	dd	eFILD16
	dd	UNUSED
	dd	eFIST16
	dd	eFISTP16
	dd	eFBLD
	dd	eFILD64
	dd	eFBSTP
	dd	eFISTP64


tGroupFLD1disp	label	dword
	dd	eFLD1
	dd	eFLDL2T
	dd	eFLDL2E
	dd	eFLDPI
	dd	eFLDLG2
	dd	eFLDLN2
	dd	eFLDZ
	dd	UNUSED


tGroupF2XM1disp	label	dword
	dd	eF2XM1
	dd	eFYL2X
	dd	eFPTAN
	dd	eFPATAN
	dd	eFXTRACT
	dd	eFPREM1
	dd	eFDECSTP
	dd	eFINCSTP


tGroupFCHSdisp	label	dword
	dd	eFCHS
	dd	eFABS
	dd	UNUSED
	dd	UNUSED
	dd	eFTST
	dd	eFXAM
	dd	UNUSED
	dd	UNUSED


tGroupFPREMdisp	label	dword
	dd	eFPREM
	dd	eFYL2XP1
	dd	eFSQRT
	dd	eFSINCOS
	dd	eFRNDINT
	dd	eFSCALE
	dd	eFSIN
	dd	eFCOS


tGroupFENIdisp	label	dword
	dd	eFENI
	dd	eFDISI
	dd	eFCLEX
	dd	eFINIT
	dd	eFSETPM
	dd	UNUSED
	dd	UNUSED
	dd	UNUSED
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emerror.asm ===
page    ,132
        subttl  emerror.asm - Emulator error handler
;***
;emerror.asm - Emulator error handler
;
;        Microsoft Confidential
;
;        Copyright (c) Microsoft Corporation 1987, 1991
;
;        All Rights Reserved
;
;Purpose:
;       Emulator error handler
;
;Revision History:  (also see emulator.hst)
;
;   10/30/89  WAJ   Added this header.
;   11/15/89  WAJ   Major changes for Dos32RaiseExcpetion().
;   12/01/89  WAJ   Now set cbExceptionInfo correctly.
;   02/08/90  WAJ   Fixed GP fault in 32 bit exception handler.
;   09/03/91  JWM   Modified entry/exit sequence for DOSX32.
;   02/15/92  JWM   Adapted for NT.
;
;*******************************************************************************

ifdef   _DOS32EXT
include except32.inc
endif

;***    error_return - return to user code (regardless of error)
;
;       This macro returns to user code.  It goes to some lengths
;       to restore the flags on the instruction immediately before
;       the return so that any pending trace trap will be
;       acknowledged immediately after the retfd (and before the
;       next user instruction) instead of after the instruction
;       following the return as would be the case if we returned
;       using iretd.
;
;       ENTRY   ((SS:ESP)) = user's EAX
;               ((SS:ESP)+4) = return EIP
;               ((SS:ESP)+8) = return CS
;               ((SS:ESP)+12) = user's EFLAGS
;       EXIT    return to user program, above arguments
;               popped off stack, user's EAX and EFLAGS
;               restored.

error_return    macro   noerror
ifdef   _DOS32EXT
        sti                                     ; JWM, 9/3/91
        push    dword ptr [esp+8]               ; JWM, 9/6/91
        popfd                                   ; JWM, 9/6/91
endif                                           ; DOS32EXT

ifdef NT386
if DBG
        push    dword ptr [esp+8]               ; On checked build, allow
        popfd                                   ; single step to work
endif
endif
        iretd
        endm


TESTif  macro   nam
        mov     bl,err&nam      ; default error number
   if (nam ge 100h)
        test    ah,nam/256
   else ;not (nam ge 100h)
        test    al,nam
   endif ;(nam ge 100h)
        JSNZ    signalerror
        endm

EM_ENTRY eCommonExceptions
CommonExceptions:
        mov     ebx,[esp].[OldLongStatus]
        and		ebx,LongSavedFlags		;preserve condition codes, error flags
        or		EMSEG:[LongStatusWord],ebx					;merge saved status word, condition codes
        pop     eax
        pop     ecx
        pop     edx
        pop     ebx
        add     esp,4                   ; toss esp value
        pop     ebp
        pop     esi
        pop     edi
        add     esp,8                   ;toss old PrevCodeOff and StatusWord
        pop     ds
        call    Emexcept
        error_return    noerror

ifdef _DOS32EXT

EmExcept PROC C, OldEIP:DWORD, OldCS:DWORD, OldFlags:DWORD

LOCAL   SSAR:DWORD
LOCAL   ec:_DX32_CONTEXT

    ;*
    ;*  Set up SS access rights.
    ;*

        push    ds
        mov     [ec.R_Eax], eax
        GetEmData   ds,ax

        mov     eax, ss
        lar     eax, eax
        mov     [SSAR], eax

    ;*
    ;*  Fill in ExceptionContext structure.
    ;*


        mov     [ec.NPXContextFlags], NPX_CONTEXT_FULL
        mov     [ec.R_Edi], edi
        mov     [ec.R_Esi], esi

        mov     eax, [ebp]
        mov     [ec.R_Ebp], eax

        lea     eax, [OldFlags+4]
        mov     [ec.R_Esp], eax

        mov     [ec.R_Ebx], ebx
        mov     [ec.R_Edx], edx
        mov     [ec.R_Ecx], ecx

        mov     eax, EMSEG:[PrevCodeOff]

        mov     [ec.R_Eip], eax
        mov     eax, [OldFlags]
        mov     [ec.EFlags], eax

        mov     eax, [OldCS]
        movzx   eax,ax
        mov     [ec.SegCs], eax
        mov     ax,ss
        movzx   eax,ax
        mov     [ec.SegSs], eax

        pop     eax
        movzx   eax,ax
        mov     [ec.SegDs], eax         ; ds was pushed on entry.

        mov     ax,es
        movzx   eax,ax
        mov     [ec.SegEs], eax

        mov     ax,fs
        movzx   eax,ax
        mov     [ec.SegFs], eax

        mov     ax,gs
        movzx   eax,ax
        mov     [ec.SegGs], eax

        lea     esi, [ec]
        add     esi, 4

        push    ebp
        call    SaveState
        pop     ebp

        lea     eax, [ec]
        push    ds
        push    es

        mov     bx, seg FLAT:CURstk
        mov     ds, ebx
        mov     es, ebx
        push    eax

        call    DOS32RAISEEXCEPTION

        add     esp, 4

        pop     es
        pop     ds

RaiseExceptRet:
        or      eax, eax
        JZ      ExceptNotHandled

    ;*
    ;* Copy new flags, cs, eip to new stack.
    ;*

        mov     ds, [ec.SegSs]
        mov     esi, [ec.R_Esp]     ; ds:esi == new ss:esp

        mov     eax, [ec.Eflags]            ; set up iretd frame
        mov     [esi-4], eax

        mov     eax, [ec.SegCs]
        mov     [esi-8], eax

        mov     eax, [ec.R_Eip]
        mov     [esi-12], eax

    ;*
    ;*  Put new stack pointer on stack.
    ;*

        push    ds
        sub     esi, 12
        push    esi

    ;*
    ;*  Reset other registers.
    ;*

        mov     edi, [ec.R_Edi]
        mov     esi, [ec.R_Esi]
        mov     ebx, [ec.R_Ebx]
        mov     edx, [ec.R_Edx]
        mov     ecx, [ec.R_Ecx]
        mov     eax, [ec.R_Eax]
        mov     ds, [ec.SegDs]
        mov     es, [ec.SegEs]
        mov     fs, [ec.SegFs]
        mov     gs, [ec.SegGs]

        mov     ebp, [ec.R_Ebp]    ; must do this last.

        lss     esp, fword ptr [esp] ; reset ss:esp

        sti                             ; JWM, 9/3/91
        push    [esp+8]                 ; JWM, 9/6/91
        popfd                           ; JWM, 9/6/91

        iretd                       ; reset flags, cs, eip

ExceptNotHandled:
EmExcept        ENDP

endif                   ; ifdef _DOS32EXT

ifdef NT386

ISIZE                   equ     4
ISizeEC                 equ     (ContextFrameLength + ISIZE - 1) and (not (ISIZE - 1))
ISizeExceptStruct       equ     (ExceptionRecordLength + ISIZE - 1) and (not (ISIZE - 1))

ec_off          EQU     4+ISizeEc
estruct_off     EQU     ec_off+ISizeExceptStruct

SSAR            EQU     <[ebp][-4]>
ec              EQU     <[ebp][-ec_off]>
eStruct         EQU     <[ebp][-estruct_off]>

OldEIP          EQU     <ebp+8>
OldCS           EQU     <ebp+12>
OldFlags        EQU     <ebp+16>


EmExcept PROC   NEAR

        push    ebp
        mov     ebp,esp
        sub     esp,estruct_off


    ;*
    ;*  Set up SS access rights.
    ;*

        push    ds
        mov     [ec.ctx_RegEax], eax
        GetEmData   ds,ax

        mov     eax, ss
        lar     eax, eax
        mov     [SSAR], eax

    ;*
    ;*  Fill in ExceptionContext structure.
    ;*


        mov     dword ptr [ec.ContextFlags], NPX_CONTEXT_FULL
        mov     dword ptr [ec.ctx_Cr0NpxState], CR0_EM
        mov     [ec.ctx_RegEdi], edi
        mov     [ec.ctx_RegEsi], esi

        mov     eax, [ebp]
        mov     [ec.ctx_RegEbp], eax

        lea     eax, [OldFlags+4]
        mov     [ec.ctx_RegEsp], eax

        mov     [ec.ctx_RegEbx], ebx
        mov     [ec.ctx_RegEdx], edx
        mov     [ec.ctx_RegEcx], ecx

        mov     eax, [OldEIP]

        mov     [ec.ctx_RegEip], eax
        mov     eax, [OldFlags]
        mov     [ec.ctx_EFlags], eax

        mov     eax, [OldCS]
        movzx   eax,ax
        mov     [ec.ctx_SegCs], eax
        mov     ax,ss
        movzx   eax,ax
        mov     [ec.ctx_SegSs], eax

        pop     eax
        movzx   eax,ax
        mov     [ec.ctx_SegDs], eax             ; ds was pushed on entry.

        mov     ax,es
        movzx   eax,ax
        mov     [ec.ctx_SegEs], eax

        mov     ax,fs
        movzx   eax,ax
        mov     [ec.ctx_SegFs], eax

        mov     ax,gs
        movzx   eax,ax
        mov     [ec.ctx_SegGs], eax

        lea     esi, [ec]
        add     esi, ctx_env

        or      EMSEG:[StatusWord], 8000H		; set 'busy' bit
        or      EMSEG:[SWerr], Summary                  ; set Summary bit
        or      EMSEG:[CURerr], Summary

        mov     cl, EMSEG:[ErrMask]
        push    ecx
        push    ebp
        call    SaveState
        pop     ebp
        pop     ecx

        call    GetEMSEGStatusWord                      ; EAX = status word
        test    al, cl                          ; test status word against mask
        jne     short Err00

ifdef TRACENPX
        mov     edx, 0C1020304h                 ; Raise bogus exception code, to trace with
        jmp     short Err50
endif
        mov     al, Invalid

;
; According to the floating error priority, we test what is the cause of
; the NPX error and raise an appropriate exception.
;

Err00:
        test    al, Invalid                     ; Invalid Op?
        jz      short Err10                     ; No, go check next

        mov     edx, XCPT_FLOAT_INVALID_OPERATION
        test    al, StackFlag                   ; Stack fault?
        jz      short Err50                     ; No, go raise invalid op
        mov     edx, XCPT_FLOAT_STACK_CHECK
        jmp     short Err50                     ; Go raise stack fault

Err10:  mov     edx, XCPT_FLOAT_DIVIDE_BY_ZERO
        test    al, ZeroDivide
        jnz     short Err50
        mov     edx, XCPT_FLOAT_DENORMAL_OPERAND
        test    al, Denormal
        jnz     short Err50
        mov     edx, XCPT_FLOAT_OVERFLOW
        test    al, Overflow
        jnz     short Err50
        mov     edx, XCPT_FLOAT_UNDERFLOW
        test    al, Underflow
        jnz     short Err50
        mov     edx, XCPT_FLOAT_INEXACT_RESULT

Err50:  mov     [eStruct.ExceptionNum], edx

        xor     eax,eax
        mov     [eStruct.fHandlerFlags], eax
        mov     [eStruct.NestedExceptionReportRecord], eax
        mov     dword ptr [eStruct.CParameters], 1      ; GeorgioP convention
        mov     [eStruct.ErExceptionInformation], eax   ; GeorgioP convention

        mov     eax, EMSEG:[PrevCodeOff]
        mov     [eStruct.ExceptionAddress], eax

        lea     edx, [eStruct]

        lea     eax, [ec]
        push    ds
        push    es


;TRUE, this is a first-chance exception

        stdCall _NtRaiseException,<edx, eax, 1>
        stdCall _RtlRaiseStatus, <eax>

        pop     es
        pop     ds

RaiseExceptRet:
        or      eax, eax
        JZ      ExceptNotHandled

    ;*
    ;* Copy new flags, cs, eip to new stack.
    ;*

        mov     ds, [ec.ctx_SegSs]
        mov     esi, [ec.ctx_RegEsp]        ; ds:esi == new ss:esp

        mov     eax, [ec.ctx_Eflags]        ; set up iretd frame
        mov     [esi-4], eax

        mov     eax, [ec.ctx_SegCs]
        mov     [esi-8], eax

        mov     eax, [ec.ctx_RegEip]
        mov     [esi-12], eax

    ;*
    ;*  Put new stack pointer on stack.
    ;*

        push    ds
        sub     esi, 12
        push    esi

    ;*
    ;*  Reset other registers.
    ;*

        mov     edi, [ec.ctx_RegEdi]
        mov     esi, [ec.ctx_RegEsi]
        mov     ebx, [ec.ctx_RegEbx]
        mov     edx, [ec.ctx_RegEdx]
        mov     ecx, [ec.ctx_RegEcx]
        mov     eax, [ec.ctx_RegEax]
        mov     ds, [ec.ctx_SegDs]
        mov     es, [ec.ctx_SegEs]
        mov     fs, [ec.ctx_SegFs]
        mov     gs, [ec.ctx_SegGs]

        mov     ebp, [ec.ctx_RegEbp]    ; must do this last.

        lss     esp, fword ptr [esp] ; reset ss:esp

        sti                             ; JWM, 9/3/91
        push    [esp+8]                 ; JWM, 9/6/91
        popfd                           ; JWM, 9/6/91

        iretd                       ; reset flags, cs, eip

ExceptNotHandled:
EmExcept        ENDP

endif                   ; ifdef NT386

        int 3	                ; Added For BBT, a return here is needed or BBT
        ret	                ; has a flow problem.
ifdef  DEBUG

lab PageFault
        mov     al, byte ptr cs:[iax]
        ret
endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emfcom.asm ===
subttl  emfcom.asm - Comparison Instructions
	page
;*******************************************************************************
;emfcom.asm - Comparison Instructions
;
;        Microsoft Confidential
;
;        Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Purpose:
;       FCOM,FCOMP,FCOMPP,FUCOM,FUCOMP,FUCOMPP,FTST,FXAM instructions
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;*******************************************************************************
;Dispatch table for compare
;
;One operand has been loaded into ecx:ebx:esi ("source"), the other is
;pointed to by edi ("dest").  
;
;Tag of source is shifted.  Tag values are as follows:
.erre   TAG_SNGL        eq      0       ;SINGLE: low 32 bits are zero
.erre   TAG_VALID       eq      1
.erre   TAG_ZERO        eq      2
.erre   TAG_SPCL        eq      3       ;NAN, Infinity, Denormal, Empty
;Any special case routines not found in this file are in emarith.asm
tFcomDisp       label   dword           ;Source (reg)   Dest (*[di] = ST)
        dd      ComDouble               ;single         single
        dd      ComDouble               ;single         double
	dd	ComDestZero		;single		zero
        dd      ComSpclDest             ;single         special
        dd      ComDouble               ;double         single
        dd      ComDouble               ;double         double
        dd      ComDestZero             ;double         zero
        dd      ComSpclDest             ;double         special
        dd      ComSrcZero              ;zero           single
        dd      ComSrcZero              ;zero           double
        dd      ComEqual                ;zero           zero
	dd	ComSpclDest		;zero		special
	dd	ComSpclSource		;special	single
	dd	ComSpclSource		;special	double
	dd	ComSpclSource		;special	zero
	dd	ComBothSpcl		;special	special


EM_ENTRY eFICOMP16
eFICOMP16:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset PopWhenDone
	push	offset ComOpLoaded
	jmp	Load16Int		;Returns to ComOpLoaded

EM_ENTRY eFICOM16
eFICOM16:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset ComOpLoaded
	jmp	Load16Int		;Returns to ComOpLoaded

EM_ENTRY eFICOMP32
eFICOMP32:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset PopWhenDone
	push	offset ComOpLoaded
	jmp	Load32Int		;Returns to ComOpLoaded

EM_ENTRY eFICOM32
eFICOM32:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset ComOpLoaded
	jmp	Load32Int		;Returns to ComOpLoaded

EM_ENTRY eFCOMP32
eFCOMP32:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset PopWhenDone
	push	offset ComOpLoaded
	jmp	Load32Real		;Returns to ComOpLoaded

EM_ENTRY eFCOM32
eFCOM32:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset ComOpLoaded
	jmp	Load32Real		;Returns to ComOpLoaded

EM_ENTRY eFCOMP64
eFCOMP64:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset PopWhenDone
	push	offset ComOpLoaded
	jmp	Load64Real		;Returns to ComOpLoaded

EM_ENTRY eFCOM64
eFCOM64:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset ComOpLoaded
	jmp	Load64Real		;Returns to ComOpLoaded

EM_ENTRY eFUCOMPP
eFUCOMPP:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset ComPop2
	jmp	eFUCOM0

EM_ENTRY eFUCOMP
eFUCOMP:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset PopWhenDone
	jmp	eFUCOM0

EM_ENTRY eFUCOM
eFUCOM:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
eFUCOM0:	
;esi = pointer to st(i) from instruction field
;edi = [CURstk]
	mov	ecx,EMSEG:[esi].ExpSgn
	mov	ebx,EMSEG:[esi].lManHi
	mov	esi,EMSEG:[esi].lManLo
	mov	dl,40H			;Flag FUCOM - Look for SNAN
	jmp	UComOpLoaded

EM_ENTRY eFCOMPP
eFCOMPP:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset ComPop2
	jmp	eFCOM0

EM_ENTRY eFCOMP
eFCOMP:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	push	offset PopWhenDone
	jmp	eFCOM0

EM_ENTRY eFCOM
eFCOM:
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
eFCOM0:
;esi = pointer to st(i) from instruction field
;edi = [CURstk]
	mov	ecx,EMSEG:[esi].ExpSgn
	mov	ebx,EMSEG:[esi].lManHi
	mov	esi,EMSEG:[esi].lManLo

ComOpLoaded:
;	mov	EMSEG:[UpdateCCodes],1
	mov	dl,0			;flag FCOM - Look for any NAN
UComOpLoaded:
	mov     ebp,offset tFcomDisp
	mov	al,cl
	mov     ah,EMSEG:[edi].bTag
	test	ax,ZEROorSPCL * 100H + ZEROorSPCL
	jnz	TwoOpDispatch

;.erre	ComDouble eq $			;Fall into ComDouble

;*********
ComDouble:
;*********
;
;ebx:esi = op1 mantissa
;ecx = op1 sign in bit 15, exponent in high half
;edi = pointer to op2
	mov	eax,EMSEG:[edi].ExpSgn
	and	ax,bSign shl 8		;Keep sign only
	and	cx,bSign shl 8
	cmp	ah,ch			;Are signs the same?
	jnz	StBigger
	cmp	eax,ecx			;Are exponents the same?
	jl	StSmaller
	jg	StBigger
	cmp	EMSEG:[edi].lManHi,ebx	;Compare mantissas
	jnz	MantDif
	cmp	EMSEG:[edi].lManLo,esi	;Set flags for ST - src
	jz	ComEqual
MantDif:
	adc	al,al			;Copy CY flag to bit 0
	rol	ah,1			;Rotate sign to bit 0
	xor	al,ah			;Flip saved CY bit if negative
	mov	EMSEG:[SWcc],al		;Set condition code
	ret

StSmaller:
	not	ah
StBigger:
;ah = sign of ST
;ch = sign of other operand
;ST is bigger if it is positive (smaller if it is negative).
;Use the sign bit directly as the "less than" bit C0.
.erre	C0 eq 1
	shr	ah,7			;Bring sign down to bit 0, clear CY
	mov	EMSEG:[SWcc],ah		;Bit set if ST smaller (negative)
	ret

ComEqual:
	mov	EMSEG:[SWcc],CCequal
	ret



PopWhenDone:
.erre	bTAG_NOPOP eq -1
	inc	cl			;OK to pop?
	jz	ComPopX			;No - had unmasked Invalid Operation

	POPSTret

ComPop2:
.erre	bTAG_NOPOP eq -1
	inc	cl			;OK to pop?
	jz	ComPopX			;No - had unmasked Invalid Operation
	mov	esi,EMSEG:[CURstk]
	mov	EMSEG:[esi].bTag,bTAG_EMPTY
	add	esi,Reg87Len*2
	cmp	esi,ENDstk			;JWM
	je	PopOneOver
	ja	PopTwoOver
	mov	EMSEG:[esi-Reg87Len].bTag,bTAG_EMPTY
	mov	EMSEG:[CURstk],esi
ComPopX:
	ret

PopOneOver:
	mov	EMSEG:[CURstk],BEGstk		;JWM
ifdef NT386
	mov	EMSEG:[INITstk].bTAG,bTAG_EMPTY
else
	mov	EMSEG:[XINITstk].bTAG,bTAG_EMPTY
endif
	ret

PopTwoOver:
	mov	EMSEG:[CURstk],BEGstk+Reg87Len	;JWM
ifdef NT386
	mov	EMSEG:[BEGstk].bTAG,bTAG_EMPTY
else
	mov	EMSEG:[XBEGstk].bTAG,bTAG_EMPTY
endif
	ret

;*******************************************************************************
;Special cases for FCOM/FUCOM.
;These don't share with those in emarith.asm because NANs are treated
;differently.
ComDestZero:
;ST is zero, so Src is bigger if it is positive (smaller if it is negative).
;Use the sign bit directly as the "less than" bit C0.
	not	ch			;C0 is 1 if ST < Src
.erre	C0 eq 1
	shr	ch,7			;Bring sign down to bit 0
	mov	EMSEG:[SWcc],ch		;Bit set if Src smaller (negative)
	ret

ComSrcZero:
;ST is bigger if it is positive (smaller if it is negative).
;Use the sign bit directly as the "less than" bit C0.
	mov	al,EMSEG:[edi].bSgn
.erre	C0 eq 1
	shr	al,7			;Bring sign down to bit 0
	mov	EMSEG:[SWcc],al		;Bit set if ST smaller (negative)
	ret

ComSpclSource:
	cmp	cl,bTAG_NAN
	jz	ComSrcNAN
	cmp	cl,bTAG_INF
	jz	ComDestZero
	cmp	cl,bTAG_DEN
	jz	ComDenormal
;Must be empty
ComEmpty:
	mov	EMSEG:[CURerr],Invalid+StackFlag
	jmp	ComChkMask

ComSrcNAN:
	shl	edx,24			;Move dl to high byte
	test	ebx,edx			;See if we report error with this NAN
ComChkNAN:
	jnz	Incomp
ComInvalid:
	mov	EMSEG:[CURerr],Invalid	;Flag the error
ComChkMask:
	test	EMSEG:[CWmask],Invalid	;Is exception masked?
	jnz	Incomp
	mov	cl,bTAG_NOPOP		;Unmasked, don't pop stack
Incomp:
	mov	EMSEG:[SWcc],CCincomprable
	ret

ComSpclDest:
	mov	al,EMSEG:[edi].bTag
	cmp	al,bTAG_INF
	jz	ComSrcZero
	cmp	al,bTAG_Empty
	jz	ComEmpty
	cmp	al,bTAG_DEN
	jz	ComDenormal
;Must be NAN
ComDestNAN:
	test	EMSEG:[edi].bMan7,dl		;See if we report error with this NAN
	jmp	ComChkNAN

ComBothSpcl:
	mov	al,EMSEG:[edi].bTag
	cmp	cl,bTAG_EMPTY
	jz	ComEmpty
	cmp	al,bTAG_EMPTY
	jz	ComEmpty
	cmp	cl,bTAG_NAN
	jz	ComSrcNAN
	cmp	al,bTAG_NAN
	jz	ComDestNAN
	mov	ah,cl
	cmp	ax,(bTAG_INF shl 8) + bTag_INF	;Are both Infinity?
	jz	ComDouble		;If so, compare their signs
;Must have at least one denormal
ComDenormal:
	or	EMSEG:[CURerr],Denormal
        jmp     ComDouble

;*******************************************************************************

XAM_Unsupported	equ	0
XAM_NAN		equ	C0
XAM_Norm	equ	C2
XAM_Inf		equ	C2+C0
XAM_Zero	equ	C3
XAM_Empty	equ	C3+C0
XAM_Den		equ	C3+C2

tXamTag	label	byte
.erre	TAG_SNGL	eq	$-tXamTag
	db	XAM_Norm		;TAG_SNGL
.erre	TAG_VALID	eq	$-tXamTag
	db	XAM_Norm		;TAG_VALID
.erre	TAG_ZERO	eq	$-tXamTag
	db	XAM_Zero		;TAG_ZERO
.erre	TAG_EMPTY	eq	$-tXamTag
	db	XAM_Empty		;TAG_EMPTY
	db	0
	db	0
	db	0
.erre	TAG_INF 	eq	$-tXamTag
	db	XAM_Inf 		;TAG_INF
	db	0
	db	0
	db	0
.erre	TAG_NAN 	eq	$-tXamTag
	db	XAM_NAN 		;TAG_NAN
	db	0
	db	0
	db	0
.erre	TAG_DEN 	eq	$-tXamTag
	db	XAM_Den 		;TAG_DEN

EM_ENTRY eFXAM
eFXAM:
;edi = [CURstk]
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	mov	eax,EMSEG:[edi].ExpSgn	;Get sign and tag
	mov	bl,ah			;Save sign
	and	bl,bSign		;Keep only sign bit
	and	eax,0FH			;Save low 4 bits of tag
	mov	al,tXamTag[eax]		;Lookup cond. codes for this tag
.erre	C1 eq 2		;Bit 1
.erre	bSign eq 80H	;Bit 7
	shr	bl,7-1			;Move sign bit to CC C1
	or	al,bl
	mov	EMSEG:[SWcc],al
	ret

;*******************************************************************************

EM_ENTRY eFTST
eFTST:
;edi = [CURstk]
    and		[esp].[OldLongStatus+4],NOT(ConditionCode SHL 16)	;clear C0,C1,C2,C3
	mov	eax,EMSEG:[edi].ExpSgn
	cmp	al,bTAG_ZERO
	jz	ComEqual
	ja	TestSpcl
;Either single or double, non-zero.  Just check sign.
TestSign:
	shr	ah,7			;Bring sign down to bit 0
	mov	EMSEG:[SWcc],ah		;Bit set if negative
	ret

TestSpcl:
	cmp	al,bTAG_INF
	jz	TestSign		;Normal test for Infinity
	cmp	al,bTAG_EMPTY
	jz	ComEmpty
	cmp	al,bTAG_NAN
	jz	ComInvalid
;Must be denormal
	mov	EMSEG:[CURerr],Denormal
	jmp	TestSign
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emfinit.asm ===
subttl	emfinit.asm - Emulator initialization and FINIT instruction
        page
;*******************************************************************************
;emfinit.asm - Emulator initialization and FINIT instruction
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


EM_ENTRY eEmulatorInit
EmulatorInit:
EM_ENTRY eFINIT
eFINIT:
	mov	esi,BEGstk
	mov	EMSEG:[CURstk],INITstk
	mov	ecx,Numlev
	xor	eax,eax

EmInitLoop:
	mov	EMSEG:[esi].ExpSgn,bTAG_EMPTY		;Exponent and sign are zero
	mov	EMSEG:[esi].lManHi,eax
	mov	EMSEG:[esi].lManLo,eax

	add	esi, Reg87Len
	loop	EmInitLoop

	mov	EMSEG:[StatusWord],ax			; clear status word
	mov	[esp+4].OldStatus,ax			; clear saved status word.
	mov	EMSEG:[PrevCodeOff],eax
	mov	EMSEG:[PrevDataOff],eax
	mov	EMSEG:[LongControlWord],InitControlWord
	mov	eax,offset Round64near
	mov	EMSEG:[RoundMode],eax			;Address of round routine
	mov	EMSEG:[TransRound],eax			;Address of round routine
	mov	EMSEG:[SavedRoundMode],eax
	mov	EMSEG:[ZeroVector],offset SaveResult
	mov	EMSEG:[Einstall], 1
	ret
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emfmul.asm ===
subttl  emfmul.asm - Multiplication
	page
;*******************************************************************************
;	 Copyright (c) Microsoft Corporation 1991
;	 All Rights Reserved
;
;emfmul.asm - long double multiply
;	by Tim Paterson
;
;Purpose:
;	Long double multiplication.
;Inputs:
;	ebx:esi = op1 mantissa
;	ecx = op1 sign in bit 15, exponent in high half
;	edi = pointer to op2 and result location
;	[Result] = edi
;
;	Exponents are unbiased.  Denormals have been normalized using
;	this expanded exponent range.  Neither operand is allowed to be zero.
;Outputs:
;	Jumps to [RoundMode] to round and store result.
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************

;Dispatch table for multiply
;
;One operand has been loaded into ecx:ebx:esi ("source"), the other is
;pointed to by edi ("dest").  
;
;Tag of source is shifted.  Tag values are as follows:

.erre	TAG_SNGL	eq	0	;SINGLE: low 32 bits are zero
.erre	TAG_VALID	eq	1
.erre	TAG_ZERO	eq	2
.erre	TAG_SPCL	eq	3	;NAN, Infinity, Denormal, Empty

;Any special case routines not found in this file are in emarith.asm

tFmulDisp	label	dword		;Source (reg)	Dest (*[di])
	dd	MulSingle		;single		single
	dd	MulDouble		;single		double
	dd	XorDestSign		;single		zero
	dd	MulSpclDest		;single		special
	dd	MulDouble		;double		single
	dd	MulDouble		;double		double
	dd	XorDestSign		;double		zero
	dd	MulSpclDest		;double		special
	dd	XorSourceSign		;zero		single
	dd	XorSourceSign		;zero		double
	dd	XorDestSign		;zero		zero
	dd	MulSpclDest		;zero		special
	dd	MulSpclSource		;special	single
	dd	MulSpclSource		;special	double
	dd	MulSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	XorDestSign		;Two infinities


EM_ENTRY eFIMUL16
eFIMUL16:
	push	offset MulSetResult
	jmp	Load16Int			;Returns to MulSetResult

EM_ENTRY eFIMUL32
eFIMUL32:
	push	offset MulSetResult
	jmp	Load32Int			;Returns to MulSetResult

EM_ENTRY eFMUL32
eFMUL32:
	push	offset MulSetResult
	jmp	Load32Real			;Returns to MulSetResult

EM_ENTRY eFMUL64
eFMUL64:
	push	offset MulSetResult
	jmp	Load64Real			;Returns to MulSetResult

EM_ENTRY eFMULPreg
eFMULPreg:
	push	offset PopWhenDone

EM_ENTRY eFMULreg
eFMULreg:
	xchg	esi,edi

EM_ENTRY eFMULtop
eFMULtop:
	mov	ecx,EMSEG:[esi].ExpSgn
	mov	ebx,EMSEG:[esi].lManHi
	mov	esi,EMSEG:[esi].lManLo
MulSetResult:
	mov     ebp,offset tFmulDisp
	mov	EMSEG:[Result],edi		;Save result pointer
	mov	al,cl
	or	al,EMSEG:[edi].bTag
	cmp	al,bTAG_VALID
.erre	bTAG_VALID	eq	1
.erre	bTAG_SNGL	eq	0
	jz	MulDouble
	ja	TwoOpResultSet
;.erre	MulSingle eq $			;Fall into MulSingle


;*********
MulSingle:
;*********

	mov	edx,EMSEG:[edi].ExpSgn
	mov	eax,EMSEG:[edi].lManHi

;op1 mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7
;op2 high mantissa in eax, exponent in high edx, sign in dh bit 7

	xor	ch,dh			;Compute result sign
	xor	dx,dx			;Clear out sign and tag
	add	ecx,edx			;Result exponent
.erre	TexpBias eq 0			;Exponents not biased
	jo	SMulBigUnderflow	;Multiplying two denormals
ContSmul:

;Value in ecx is correct exponent if result is not normalized.
;If result comes out normalized, 1 will be added.

	mul	ebx			;Compute product
	mov	ebx,edx
	mov	esi,eax
	xor	eax,eax			;Extend with zero

;Result in ebx:esi:eax
;ecx = exponent minus one in high half, sign in ch
	or	ebx,ebx			;Check for normalization
	jns	ShiftOneBit		;In emfadd.asm
	add	ecx,1 shl 16		;Adjust exponent
	jmp	EMSEG:[RoundMode]

SMulBigUnderflow:
	or	EMSEG:[CURerr],Underflow
	add	ecx,Underbias shl 16	;Fix up exponent
	test	EMSEG:[CWmask],Underflow	;Is exception masked?
	jz	ContSmul		;No, continue with multiply
UnderflowZero:
	or	EMSEG:[CURerr],Precision
SignedZero:
	and	ecx,bSign shl 8		;Preserve sign bit
	xor	ebx,ebx
	mov	esi,ebx
	mov	cl,bTAG_ZERO
	jmp	EMSEG:[ZeroVector]

;*******************************************************************************

DMulBigUnderflow:
;Overflow flag set could only occur with denormals (true exp < -32768)
	or	EMSEG:[CURerr],Underflow
	test	EMSEG:[CWmask],Underflow	;Is exception masked?
	jnz	UnderflowZero		;Yes, return zero
	add	ecx,Underbias shl 16	;Fix up exponent
	jmp	ContDmul		;Continue with multiply

PolyMulToZero:
	ret				;Return the zero in registers

PolyMulDouble:
;This entry point is used by polynomial evaluator.
;It checks the operand in registers for zero.
	cmp	cl,bTAG_ZERO		;Adding to zero?
	jz	PolyMulToZero

;*********
MulDouble:
;*********

	mov	eax,EMSEG:[edi].ExpSgn
	mov	edx,EMSEG:[edi].lManHi
	mov	edi,EMSEG:[edi].lManLo

MulDoubleReg:				;Entry point used by transcendentals
;op1 mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7
;op2 mantissa in edx:edi, exponent in high eax, sign in ah bit 7

	xor	ch,ah			;Compute result sign
	xor	ax,ax			;Clear out sign and tag
	add	ecx,eax			;Result exponent
.erre	TexpBias eq 0			;Exponents not biased
	jo	DMulBigUnderflow	;Multiplying two denormals
ContDmul:

;Value in ecx is correct exponent if result is not normalized.
;If result comes out normalized, 1 will be added.

	mov	ebp,edx			;edx is used by MUL instruction

;Generate and sum partial products, from least to most significant

	mov	eax,edi
	mul	esi			;Lowest partial product
	add	eax,-1			;CY set IFF eax<>0
	sbb	cl,cl			;Sticky bit: 0 if zero, -1 if nz
	xchg	edi,edx			;Save high result

;First product: cl reflects low dword non-zero (sticky bit), edi has high dword

	mov	eax,ebx
	mul	edx
	add	edi,eax
	adc	edx,0			;Sum first results
	xchg	edx,esi			;High result to esi

;Second product: accumulated in esi:edi:cl

	mov	eax,ebp			;Next mult. to eax
	mul	edx
	add	edi,eax			;Sum low results
	adc	esi,edx			;Sum high results
	mov	eax,ebx
	mov	ebx,0			;Preserve CY flag
	adc	ebx,ebx			;Keep carry out of high sum

;Third product: accumulated in ebx:esi:edi:cl

	mul	ebp
	add	esi,eax
	adc	ebx,edx
	mov	eax,edi
	or	al,cl			;Collapse sticky bits into eax

;Result in ebx:esi:eax
;ecx = exponent minus one in high half, sign in ch
MulDivNorm:
	or	ebx,ebx			;Check for normalization
	jns	ShiftOneBit		;In emfadd.asm
	add	ecx,1 shl 16		;Adjust exponent
	jmp	EMSEG:[RoundMode]
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emfmisc.asm ===
subttl  emfmisc.asm - FABS, FCHS, FFREE, FXCH
        page
;*******************************************************************************
;emfmisc.asm - FABS, FCHS, FFREE, FXCH
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Purpose:
;       FABS, FCHS, FFREE, FXCH instructions
;Inputs:
;	edi = [CURstk]
;	esi = pointer to st(i) from instruction field
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;******
EM_ENTRY eFABS
eFABS:
;******
	cmp	EMSEG:[edi].bTag,bTAG_EMPTY
	jz	StackError		;in emarith.asm
	mov	EMSEG:[edi].bSgn,0		;Turn sign bit off
	ret

;******
EM_ENTRY eFCHS
eFCHS:
;******
	cmp	EMSEG:[edi].bTag,bTAG_EMPTY
	jz	StackError		;in emarith.asm
	not	EMSEG:[edi].bSgn		;Flip the sign
	ret

;******
EM_ENTRY eFFREE
eFFREE:
;******
	mov	EMSEG:[esi].bTag,bTAG_EMPTY
	ret

;******
EM_ENTRY eFXCH
eFXCH:
;******
	cmp	EMSEG:[esi].bTag,bTAG_EMPTY
	jz	XchDestEmpty
XchgChkSrc:
	cmp	EMSEG:[edi].bTag,bTAG_EMPTY
	jz	XchSrcEmpty
DoSwap:
;Swap [esi] with [edi]
	mov	eax,EMSEG:[edi]
	xchg	eax,EMSEG:[esi]
	mov	EMSEG:[edi],eax
	mov	eax,EMSEG:[edi+4]
	xchg	eax,EMSEG:[esi+4]
	mov	EMSEG:[edi+4],eax
	mov	eax,EMSEG:[edi+8]
	xchg	eax,EMSEG:[esi+8]
	mov	EMSEG:[edi+8],eax
	ret

XchDestEmpty:
	call	ReturnIndefinite	;in emarith.asm - ZF set if unmasked
	jnz	XchgChkSrc		;Continue if masked
	ret

XchSrcEmpty:
	xchg	edi,esi			;pass pointer in esi
	call	ReturnIndefinite	;in emarith.asm - ZF set if unmasked
	xchg	edi,esi
	jnz	DoSwap			;Continue if masked
	ret
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emf386.asm ===
subttl  emf386.asm - 32 bit Emulator Interrupt Handler
        page
;***
;emf386.asm - 32 bit Emulator Interrupt Handler
;
;        IBM/Microsoft Confidential
;
;        Copyright (c) IBM Corporation 1987, 1989
;        Copyright (c) Microsoft Corporation 1987, 1989
;
;        All Rights Reserved
;
;Purpose:
;       32 bit Emulator Interrupt Handler
;
;Revision History:  (also see emulator.hst)
;
;    1/21/92  JWM   Minor modifications for DOSX32 emulator
;    8/23/91  TP    Reduce to only two decoding steps
;
;*******************************************************************************


;*********************************************************************;
;                                                                     ;
;         Main Entry Point and Address Calculation Procedure          ;
;                                                                     ;
;               80386 version                                         ;
;                                                                     ;
;*********************************************************************;
;
; This routine fetches the 8087 instruction, calculates memory address
; if necessary into ES:ESI and calls a routine to emulate the instruction.
; Most of the dispatching is done through tables. (see comments in CONST)
;
; The instruction dispatching is designed to favor the 386 addressing modes


ifdef _DOS32EXT                 ; JWM
public __astart
__astart:
        mov     eax, 1
        ret

public _Ms32KrnlHandler
_Ms32KrnlHandler:
endif

ifdef   NT386

;
; NPXEmulatorTable is a table read by the Windows/NT kernel in
; order to support the R3 emulator
;
public _NPXEMULATORTABLE
_NPXEMULATORTABLE   label   dword
        dd      offset NpxNpHandler     ; Address of Ring3 Trap7 handler
        dd      offset tRoundMode       ; Address of rounding vector table
endif

public NPXNPHandler
NPXNPHandler:

ifdef  DEBUG
        int     3
endif
        cld                             ; clear direction flag forever

ifdef NT386


;-- bryanwi - 16Oct91 - Hack FP fix, not pointing IDT:7 at this
;   routine for 16bit code is the right thing to do.
;
;   Check to see if we are running on flat SS.  If so, assume things
;   are OK and proceed.  (If a 16bit app loads the flat SS and then
;   does an FP instruction, they're hosed, no skin off our nose.)
;
;   If SS not what we expect, then either (a) a flat apps is *very*
;   confused, or (b) a 16 bit app has hit an FP instuction.  In either
;   case, this emulator is not going to work.  Therefore, raise an exception.
;

        push    ax                      ; use form that will word with any SS
        mov     ax,ss
        or      ax,RPL_MASK
        cmp     ax,(KGDT_R3_DATA OR RPL_MASK)
        pop     ax
        jz      OK_Segment              ; Segments are OK, proceed normally.

        jmp     Around

_DATA   SEGMENT  DWORD USE32 PUBLIC 'DATA'

    align 4

EmerStk         db      1024 dup (?)                    ; *** SaveContext is assumed to be
SaveContext     db  size ContextFrameLength  dup (?)    ; *** at the top of the EmerStk by
SaveException   db  size ExceptionRecordLength dup (?)  ; *** the function @ 13f:0

_DATA   ENDS

Around:
;
;   Trap occured in 16bit code, get to flat environment and raise exception
;

        push    eax                             ; save EAX on old stack
        mov     ax, ds
        push    eax                             ; Save DS on old stack

        mov     ax,(KGDT_R3_DATA OR RPL_MASK)
        mov     ds,ax
    ASSUME  DS:FLAT

        pop     dword ptr [SaveContext.CsSegDs] ; remove ds  from old stack
        pop     dword ptr [SaveContext.CsEax]   ; remove eax from old stack
        pop     dword ptr [SaveContext.CsEip]   ; copy eip   from old stack
        pop     dword ptr [SaveContext.CsSegCs] ; copy cs    from old stack
        pop     dword ptr [SaveContext.CsEflags] ; copy eflag from old stack

        push    dword ptr [SaveContext.CsEFlags] ; restore eflag to old stack
        push    dword ptr [SaveContext.CsSegCs] ; restore cs    to old stack
        push    dword ptr [SaveContext.CsEip]   ; restore eip   to old stack
        mov     dword ptr [SaveContext.CsEsp], esp

;
; Build rest of context frame
;

        mov     dword ptr [SaveContext.CsContextFlags],CONTEXT_CONTROL OR CONTEXT_SEGMENTS OR CONTEXT_INTEGER
        mov     dword ptr [SaveContext.CsEbx], ebx
        mov     dword ptr [SaveContext.CsEcx], ecx
        mov     dword ptr [SaveContext.CsEdx], edx
        mov     dword ptr [SaveContext.CsEsi], esi
        mov     dword ptr [SaveContext.CsEdi], edi
        mov     dword ptr [SaveContext.CsEbp], ebp
        mov     dword ptr [SaveContext.CsSegEs], es
        mov     dword ptr [SaveContext.CsSegFs], fs
        mov     dword ptr [SaveContext.CsSegGs], gs
        mov     dword ptr [SaveContext.CsSegSs], ss

        mov     ss,ax                   ; Switch to new stack
        mov     esp,(OFFSET FLAT:EmerStk) + 1024
    ASSUME  SS:FLAT

;
;   ss: flat, esp -> EmerStk
;

        mov     ax,KGDT_R3_TEB OR RPL_MASK
        mov     fs, ax
        mov     ecx, fs:[TbVdm]
        or      ecx, ecx
        jne     short DoVdmFault

        mov     ecx, offset SaveContext         ; (ecx) -> context record
        mov     edx, offset SaveException       ; (edx) -> exception record

        mov     dword ptr [edx.ErExceptionCode],STATUS_ILLEGAL_FLOAT_CONTEXT
        mov     dword ptr [edx.ErExceptionFlags],0
        mov     dword ptr [edx.ErExceptionRecord],0
        mov     ebx, [ecx.CsEip]
        mov     [edx.ErExceptionAddress],ebx
        mov     [edx.ErNumberParameters],0

;
;   ZwRaiseException(edx=ExceptionRecord, ecx=ContextRecord, TRUE=FirstChance)
;

        stdCall _ZwRaiseException, <edx, ecx, 1>

;
;   If we come back HERE, things are hosed.  We cannot bugcheck because
;   we are in user space, so int-3 and loop forever instead.
;

Forever:
        int     3
        jmp     short Forever

DoVdmFault:
;
; Does the VDM want the fault, or should the instruction be skipped
;
        test    ds:[ecx].VtVdmContext.CsFloatSave.FpCr0NpxState, CR0_EM
        jz      short SkipNpxInstruction

        add     dword ptr [SaveContext.CsEsp], 12   ; remove from old stack

; jump to the dos extender NPX exception handler

;       jmp     far ptr 013fh:0
        db      0eah
        dd      0
        dw      013fh

SkipNpxInstruction:
        mov     ax,(KGDT_R3_DATA OR RPL_MASK)
        mov     es,ax

        stdCall _NpxNpSkipInstruction, <offset SaveContext>

        mov     ebx, dword ptr [SaveContext.CsEbx]
        mov     ecx, dword ptr [SaveContext.CsEcx]
        mov     edx, dword ptr [SaveContext.CsEdx]
        mov     edi, dword ptr [SaveContext.CsEdi]
        mov     esi, dword ptr [SaveContext.CsEsi]
        mov     ebp, dword ptr [SaveContext.CsEbp]
        mov     gs,  dword ptr [SaveContext.CsSegGs]
        mov     fs,  dword ptr [SaveContext.CsSegFs]
        mov     es,  dword ptr [SaveContext.CsSegEs]

        mov     eax, dword ptr [SaveContext.CsEsp]
        mov     ss,  dword ptr [SaveContext.CsSegSs]  ; switch to original stack
        mov     esp, eax

        add     esp, 12                     ; remove eflag, cs, eip
        push    dword ptr [SaveContext.CsEflags]
        push    dword ptr [SaveContext.CsSegCs]
        push    dword ptr [SaveContext.CsEip]
        mov     eax, dword ptr [SaveContext.CsEax]
        mov     ds,  dword ptr [SaveContext.CsSegDs]

        iretd                               ; restore eflag, cs, eip

OK_Segment:
endif


        push    ds                      ; save segment registers

        GetEmData   ds

        push    EMSEG:[LongStatusWord]  ;In case we're saving status
        push    EMSEG:[PrevCodeOff]     ;In case we save environment
;Save registers in order of their index number
        push    edi
        push    esi
        push    ebp
        push    esp
        add     dword ptr [esp],regFlg-regESP   ; adjust to original esp
        push    ebx
        push    edx
        push    ecx
        push    eax

        cmp     EMSEG:[Einstall], 0     ; Make sure emulator is initialized.
        je      InstalEm

EmInstalled:
        mov     edi,[esp].regEIP            ;edi = 387 instruction address
        movzx   edx, word ptr cseg:[edi]    ;dx = esc and opcode

; Check for unmasked errors
        mov     al, EMSEG:[CURerr]      ; fetch errors
        and     al, EMSEG:[ErrMask]
        jnz     short PossibleException

; UNDONE: rip test for FWAIT in final version
        cmp     dl, 9bh                 ;FWAIT?
        je      sawFWAIT

NoException:
Execute387inst:
;Enter here if look-ahead found another 387 instruction
        mov     EMSEG:[PrevCodeOff],edi
        mov     EMSEG:[CurErrCond],0    ;clear error and cond. codes, show busy
        add     edi, 2                  ; point past opcode
        
;CONSIDER:  remove the two instruction below and muck with EA386Tab
;CONSIDER:  to optimize for mem ops instead of reg ops.
        add     dh,40h                  ; No effective address?
        jc      NoEffectiveAddress0     ;  yes, go do instruction
        rol     dh,2                    ; rotate MOD field next to r/m field
        mov     bl,dh
        and     ebx,1FH                 ; Mask to MOD and r/m fields
MemModeDispatch:                        ;Label for debugging
        jmp     EA386Tab[4*ebx]


InstalEm:
        call    EmulatorInit
        mov     edi,DefaultControlWord  ; Default mode to start in
        mov     eax, edi
        call    SetControlWord          ; Set it
        mov     EMSEG:[LongControlWord], edi    ; reset reserved bits
        jmp     EmInstalled

; ************************

;
; We are about to execute a new FP instruction and there is an
; unmasked expcetion.  Check to see if the new FP instruction is
; a "no wait" instruction.   If so, let it proceede; otherwise, raise
; the exception.
;

PossibleException:
        cmp     edx, 0E3DBh             ; if fninit, no exception
        je      short NoException

        cmp     edx, 0E2DBh             ; if fnclex, no exception
        je      short NoException

        cmp     edx, 0E0DFh             ; if "fnstsw ax", no exception
        je      short NoException

        cmp     dl, 0D9h                ; possible encoding for fnstenv or fnstcw?
        je      short pe20              ; yes, check mod r/m
        cmp     dl, 0DDh                ; possible encoding for fnsave or fnstsw?
        jne     short pe30

pe20:   mov     bl, dh                  ; bl = op2
        shr     bl, 3
        and     bl, 7                   ; bl = mod r/m
        cmp     bl, 6                   ; is it a 6 or 7?
        jnc     short NoException       ; yes, no exception

pe30:
        jmp     CommonExceptions        ; unmasked exception is pending, raise it

; ************************



;       386 address modes

;       SIB does not handle SS overrides for ebp

SIB     macro   modval
        local   SIBindex,SIBbase

        movzx   ebx,byte ptr cseg:[edi] ; ebx = SIB field
        inc     edi                     ; bump past SIB field
        mov     eax,ebx
        and     al,7                    ; mask down to base register

if      modval eq 0
        cmp     al,5                    ; base = ebp
        jne     short SIBbase           ;   yes - get base register value
        mov     eax,cseg:[edi]          ; eax = disp32
        add     edi,4                   ; bump past displacement
        jmp     SIBindex                ; Added to support bbt, 
                                        ;   replacing    SKIP    3,SIBindex
endif

SIBbase:
        mov     eax,[esp+4*eax]         ; eax = base register value

SIBindex:
        mov     [esp].regESP,0          ; no esp indexing allowed
        mov     cl,bl
        shr     cl,6                    ; cl = scale factor
        and     bl,7 shl 3              ; ebx = 8 * index register
        shr     bl,1
        mov     esi,[esp+1*ebx]         ; esi = index register value
        shl     esi,cl                  ; esi = scaled index register value
        add     esi,eax                 ; esi = SIB address value
        endm


        ALIGN   4

SIB00:
        SIB     00                      ; decode SIB field
        jmp     CommonMemory

        ALIGN   4

SIB01:
        SIB     01                      ; decode SIB field
        movsx   eax,byte ptr cseg:[edi]
        inc     edi
        add     esi,eax
        jmp     short CommonMemory

        ALIGN   4

SIB10:
        SIB     10                      ; decode SIB field
        mov     eax,cseg:[edi]
        add     edi,4
        add     esi,eax
        jmp     short CommonMemory


;       386 single register addressing

        ALIGN   4

Exx00:
        and     bl,7 shl 2              ; mask off mod bits
        mov     esi,[esp+1*ebx]
        jmp     short CommonMemory

        ALIGN   4

Exx01:
        and     bl,7 shl 2              ; mask off mod bits
        mov     esi,[esp+1*ebx]
        movsx   eax,byte ptr cseg:[edi]
        inc     edi
        add     esi,eax
        jmp     short CommonMemory

        ALIGN   4

Exx10:
        and     bl,7 shl 2              ; mask off mod bits
        mov     esi,[esp+1*ebx]
        add     esi,cseg:[edi]
        add     edi,4
        jmp     short CommonMemory


;       386 direct addressing

        ALIGN   4

Direct386:
        mov     esi,cseg:[edi]
        add     edi,4

CommonMemory:
        MOV     [esp].regEIP,edi        ; final return offset


; At this point ESI = memory address, dx = |Op|r/m|MOD|escape|MF|Arith|
; Current format of opcode and address mode bytes (after rol dh,2)
;
;  7 6 5 4 3 2 1 0
; |1 1 0 1 1| op1 |   dl
;
;  7 6 5 4 3 2 1 0
; | op2 | r/m |mod|   dh
;
;op1 and op2 fields together make the FP opcode

        rol     dx,5                    ; dl = | op1 | op2 |? ?|
        and     edx,0FCH                ;Keep only op1 & op2 bits
        push    offset EMLFINISH
        mov     edi,EMSEG:[CURstk]
MemOpDisp:                              ;Debugging label
;edi = [CURstk]
        jmp     tOpMemDisp[edx]


        ALIGN   4


NoEffectiveAddress0:
        rol     dh,2
NoEffectiveAddress:                     ; Either Register op or Miscellaneous
        mov     [esp].regEIP,edi        ; final return offset

;Current format of opcode and address mode bytes (after rol dh,2)
;
;  7 6 5 4 3 2 1 0
; |1 1 0 1 1| op1 |   dl
;
;  7 6 5 4 3 2 1 0
; | op2 | r/m |mod|   dh
;
;op1 and op2 fields together make the FP opcode

        mov     al,dh                   ;Save r/m bits (contains reg. no.)
        rol     dx,5                    ; dl = | op1 | op2 |? ?|
        and     edx,0FCH                ;Keep only op1 & op2 bits
        push    offset EMLFINISH
        and     eax,7 shl 2             ;Mask to register number * 4
        mov     edi,EMSEG:[CURstk]
        lea     esi,[2*eax+eax]         ;Register no. * 12
        add     esi,edi
        cmp     esi,ENDstk              ;Run past end?
        jae     RegWrap
RegOpDisp:                              ;Debugging label
;eax = r/m bits * 4
;esi = FP register address
;edi = [CURstk]
        jmp     tOpRegDisp[edx]

        ALIGN   4
RegWrap:
        sub     esi,ENDstk - BEGstk     ;Wrap around    JWM
RegOpDispWrap:                          ;Debugging label
        jmp     tOpRegDisp[edx]


SawFwait:
        inc     edi                     ; bump past FWAIT
        mov     [esp].regEIP,edi        ; final return offset
        mov     EMSEG:[CURErr],0        ; clear current error and cond. codes

; return from routine;  restore registers and return

        align   4
EMLFINISH:
; check for errors
        mov     al, EMSEG:[CURerr]      ; fetch errors
        or      al, EMSEG:[SWerr]
        mov     EMSEG:[SWerr],al        ; set errors in sticky error flag
        and     al,EMSEG:[ErrMask]
        jnz     CommonExceptions

ifdef TRACENPX
        jmp     CommonExceptions
endif

if DBG eq 0

;
; On a free build, look ahead to next instruction
;

;09BH is FWAIT - just skip it
;0D8H - 0DFH is 387 instruction, emulate it
        mov     edi,[esp].regEIP        ;edi = 387 instruction address
        mov     dx,cseg:[edi]
        cmp     dl,09BH                 ;FWAIT?
        jz      short SawFwait
        sub     dl,0D8H
        cmp     dl,8
        jb      ReExecute
endif
        mov     ebx,[esp].[OldLongStatus]
        and		ebx,LongSavedFlags		;preserve condition codes, error flags
        or		EMSEG:[LongStatusWord],ebx	;merge saved status word, condition codes
        
        pop     eax
        pop     ecx
        pop     edx
        pop     ebx
        add     esp,4                   ; toss esp value
        pop     ebp
        pop     esi
        pop     edi
        add     esp,8                   ;toss old PrevCodeOff and StatusWord
        mov     EMSEG:[CURerr],Summary  ;Indicate we are not busy
        pop     ds
        error_return                    ; common exit sequence

ReExecute:
        mov     eax,EMSEG:[LongStatusWord]
        mov     ebx,[esp].[OldLongStatus]
        and		ebx,LongSavedFlags		;preserve condition codes, error flags
        or		eax,ebx					;merge saved status word, condition codes
        mov     [esp].OldLongStatus,eax
        mov     eax,EMSEG:[PrevCodeOff]
        mov     [esp].OldCodeOff,eax
        lea		eax,[esp+regFlg+4]		;must restore "saved" esp
        mov		[esp].RegEsp,eax
        jmp     Execute387inst
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emfadd.asm ===
subttl  emfadd.asm - Addition and Subtraction
	page
;*******************************************************************************
;	 Copyright (c) Microsoft Corporation 1991
;	 All Rights Reserved
;
;emfadd.asm - long double add and subtract
;	by Tim Paterson
;
;Purpose:
;	Long double add/subtract.
;Outputs:
;	Jumps to [RoundMode] to round and store result.
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************

;*******************************************************************************
; Dispatch for Add/Sub/Subr
;
; Signs are passed in dx:
;       xor source sign with dl
;       xor dest sign with dh
;
;One operand has been loaded into ecx:ebx:esi ("source"), the other is
;pointed to by edi ("dest").  
;
;Tag of source is shifted.  Tag values are as follows:
.erre   TAG_SNGL        eq      0       ;SINGLE: low 32 bits are zero
.erre   TAG_VALID       eq      1
.erre   TAG_ZERO        eq      2
.erre   TAG_SPCL        eq      3       ;NAN, Infinity, Denormal, Empty
;Any special case routines not found in this file are in emarith.asm
tFaddDisp	label	dword		;Source (reg)	Dest (*[di])
	dd	AddDouble		;single		single
	dd	AddDouble		;single		double
	dd	AddSourceSign		;single		zero
	dd	AddSpclDest		;single		special
	dd	AddDouble		;double		single
	dd	AddDouble		;double		double
	dd	AddSourceSign		;double		zero
	dd	AddSpclDest		;double		special
	dd	AddDestSign		;zero		single
	dd	AddDestSign		;zero		double
	dd	AddZeroZero		;zero		zero
	dd	AddSpclDest		;zero		special
	dd	AddSpclSource		;special	single
	dd	AddSpclSource		;special	double
	dd	AddSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	AddTwoInf		;Two infinities

EM_ENTRY eFISUB16
eFISUB16:
        call    Load16Int
        mov     dx,bSign                ;Change sign of source
        jmp     AddSetResult

EM_ENTRY eFISUBR16
eFISUBR16:
        call    Load16Int
        mov     dx,bSign shl 8          ;Change sign of dest
        jmp     AddSetResult

EM_ENTRY eFIADD16
eFIADD16:
        call    Load16Int
        xor     edx,edx                 ;Both signs positive
        jmp     AddSetResult

EM_ENTRY eFISUB32
eFISUB32:
        call    Load32Int
        mov     dx,bSign                ;Change sign of source
        jmp     AddSetResult

EM_ENTRY eFISUBR32
eFISUBR32:
        call    Load32Int
        mov     dx,bSign shl 8          ;Change sign of dest
        jmp     AddSetResult

EM_ENTRY eFIADD32
eFIADD32:
        call    Load32Int
        xor     edx,edx                 ;Both signs positive
        jmp     AddSetResult

EM_ENTRY eFSUB32
eFSUB32:
        call    Load32Real
        mov     dx,bSign                ;Change sign of source
        jmp     AddSetResult

EM_ENTRY eFSUBR32
eFSUBR32:
        call    Load32Real
        mov     dx,bSign shl 8          ;Change sign of dest
        jmp     AddSetResult

EM_ENTRY eFADD32
eFADD32:
        call    Load32Real
        xor     edx,edx                 ;Both signs positive
        jmp     AddSetResult

EM_ENTRY eFSUB64
eFSUB64:
        call    Load64Real
        mov     dx,bSign                ;Change sign of source
        jmp     AddSetResult

EM_ENTRY eFSUBR64
eFSUBR64:
        call    Load64Real
        mov     dx,bSign shl 8          ;Change sign of dest
        jmp     AddSetResult

EM_ENTRY eFADD64
eFADD64:
        call    Load64Real
        xor     edx,edx                 ;Both signs positive
        jmp     AddSetResult


PolyAddDouble:
;This entry point is used by polynomial evaluator.
;It checks the operand in registers for zero, and doesn't require
;signs to be set up in dx.
;
;op1 mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7, tag in cl
;edi = pointer to op2 in ds
	xor	edx,edx			;Addition
	cmp	cl,bTAG_ZERO		;Adding to zero?
        jnz     AddDouble
;Number in registers is zero, so just return value from memory.
        mov     ecx,EMSEG:[edi].ExpSgn
        mov     ebx,EMSEG:[edi].lManHi
        mov     esi,EMSEG:[edi].lManLo
        ret

EM_ENTRY eFSUBPreg
eFSUBPreg:
        push    offset PopWhenDone

EM_ENTRY eFSUBreg
eFSUBreg:
        xchg    esi,edi

EM_ENTRY eFSUBtop
eFSUBtop:
        mov     dx,bSign                ;Change sign of source
        jmp     AddHaveSgn

EM_ENTRY eFSUBRPreg
eFSUBRPreg:
        push    offset PopWhenDone

EM_ENTRY eFSUBRreg
eFSUBRreg:
        xchg    esi,edi

EM_ENTRY eFSUBRtop
eFSUBRtop:
        mov     dx,bSign shl 8          ;Change sign of dest
        jmp     AddHaveSgn


InsignifAdd:
	mov	eax,1			;Set sticky bit
	shl	ch,1			;Get sign, CY set IFF subtracting mant.
	jnc	ReturnOp1
	sub	esi,eax			;Subtract 1 from mantissa
	sbb	ebx,0
	neg	eax
ReturnOp1:
;ebx:esi:eax = normalized unrounded mantissa
;high half of ecx = exponent
;high bit of ch = sign
	jmp	EMSEG:[RoundMode]

EM_ENTRY eFADDPreg
eFADDPreg:
        push    offset PopWhenDone

EM_ENTRY eFADDreg
eFADDreg:
        xchg    esi,edi

EM_ENTRY eFADDtop
eFADDtop:
        xor     edx,edx                 ;Both signs positive
AddHaveSgn:
        mov     ecx,EMSEG:[esi].ExpSgn
        mov     ebx,EMSEG:[esi].lManHi
        mov     esi,EMSEG:[esi].lManLo
AddSetResult:
        mov     ebp,offset tFaddDisp
        mov     EMSEG:[Result],edi            ;Save result pointer
        mov     al,cl
        mov     ah,EMSEG:[edi].bTag
        test    ax,ZEROorSPCL * 100H + ZEROorSPCL
        jnz     TwoOpDispatch

;.erre   AddDouble eq $                  ;Fall into AddDouble

;*********
AddDouble:
;*********
;
;op1 mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7
;dl = sign change for op1
;dh = sign change for op2
;edi = pointer to op2

	xor	ch,dl			;Flip sign if subtracting
	mov	eax,EMSEG:[edi].ExpSgn
	xor	ah,dh			;Flip sign if subtracting
	mov	edx,EMSEG:[edi].lManHi
	mov	edi,EMSEG:[edi].lManLo

AddDoubleReg:
;op1 mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7
;op2 mantissa in edx:edi, exponent in high eax, sign in ah bit 7

	cmp	eax,ecx			;Compare exponents
.erre	TexpBias eq 0			;Not biased, use signed jump
	jle	short HavLg		;op1 is larger, we have the right order
	xchg	esi,edi
	xchg	ebx,edx
	xchg	eax,ecx
HavLg:
;Larger in ebx:esi.  Note that if the exponents were equal, things like
;the sign bit or tag may have determined which is "larger".  It doesn't
;matter which is which if the exponents are equal, however.
	and	ah,80H			;Keep sign bit
	sar	ch,1			;Extend sign into bit 6 of byte
	xor	ch,ah			;See if signs are the same
	xor	ax,ax			;Clear out sign and tag
	neg	eax			;ax still 0
	add	eax,ecx			;Get exponent difference
	shr	eax,16			;Bring exp. difference down to low end
	jz	short Aligned
	cmp	eax,64+1		;Is difference in range?
;CONSIDER: tell me again why 1/4 LSB could have effect.  It seems like
;CONSIDER: 1/2 LSB is the limit.
	ja	short InsignifAdd	;  (Even 1/4 LSB could have effect)
	mov	cl,al			;Shift count to cl
;High half ecx = exponent
;ch bit 7 = sign difference
;ch bit 6 = sign
;cl = shift count
	xor	eax,eax			;Prepare to take bits shifted out
	cmp	cl,32			;More than a whole word?
	jb	short ShortShift
	xchg	eax,edx			;Save bits shifted out in eax
	xchg	edi,eax
	sub	cl,32
	cmp	cl,8			;Safe to shift this much
	jb	short ShortSticky
;Collapse all (sticky) bits of eax into LSB of edi
	neg	eax			;Sets CY if eax was not zero
	sbb	eax,eax			;-1 if CY was set, zero otherwise
	neg	eax			;Sticky bit in LSB only
	or	di,ax			;Move sticky bit up
	cmp	cl,32			;Less than another Dword?
	jb	short ShortShift
	mov	eax,edi
	xor	edi,edi			;edx = edi = 0
ShortSticky:
;Shift will not be more than 8 bits
	or	ah,al			;Move up sticky bits
ShortShift:
	shrd	eax,edi,cl		;Save bits shifted out in eax
	shrd	edi,edx,cl
	shr	edx,cl
Aligned:
	shl	ch,1			;Were signs the same?
	jc	short SubMant		;No--go subtract mantissas
;Add mantissas
	add	esi,edi
	adc	ebx,edx
	jnc	short AddExit
;Addition of mantissas overflowed. Bump exponent and shift right
	shrd	eax,esi,1
	shrd	esi,ebx,1		;Faster than RCR
	sar	ebx,1
	or	ebx,1 shl 31		;Set MSB
	add	ecx,1 shl 16
AddExit:
;ebx:esi:eax = normalized unrounded mantissa
;high half of ecx = exponent
;high bit of ch = sign
	jmp	EMSEG:[RoundMode]

NegMant:
;To get here, exponents must have been equal and op2 was bigger than op1.
;Note that this means nothing ever got shifted into eax.
	not	ch			;Change sign of result
	not	ebx
	neg	esi
	sbb	ebx,-1
	js	short AddExit		;Already normalized?
	test	ebx,40000000H		;Only one bit out of normal?
	jz	short NormalizeAdd
	jmp	short NormOneBit

SubMant:
;Subtract mantissas
	neg	eax			;Pretend minuend is zero extended
	sbb	esi,edi
	sbb	ebx,edx
	jc	short NegMant
	js	short AddExit		;Already normalized?
NormChk:
	test	ebx,40000000H		;Only one bit out of normal?
	jz	short NormalizeAdd
;One bit normalization
NormOneBit:
	sub	ecx,1 shl 16		;Adjust exponent
ShiftOneBit:				;Entry point from emfmul.asm
	shld	ebx,esi,1
	shld	esi,eax,1
	shl	eax,1
	jmp	EMSEG:[RoundMode]

;***********
AddZeroZero:				;Entry point for adding two zeros
;***********
	mov	ah,EMSEG:[edi].bSgn	;Get sign of op
	xor	ch,dl			;Possibly subtracting source
	xor	ah,dh			;Possibly subtracting dest
	xor	ch,ah			;Do signs match?
	js	FindZeroSign		;No - use rounding mode to set sign
	mov	EMSEG:[edi].bSgn,ah	;Correct the sign if subtracting
	ret				;Result at [edi] is now correct

ZeroChk:
;Upper 64 bits were all zero, but there could be 1 bit in the MSB
;of eax.
	or	eax,eax
	jnz	short OneBitLeft
	mov	ebx,eax
	mov	esi,eax			;Zero mantissa
FindZeroSign:
;Round to -0 if "round down" mode, round to +0 otherwise
	xor	ecx,ecx			;Zero exponent, positive sign
	mov	dl,EMSEG:[CWcntl]	;Get control word
	and	dl,RoundControl
        cmp	dl,RCdown		;Rounding down?
	jnz	ZeroJmp
	mov	ch,80H			;Set sign bit
ZeroJmp:
	mov	cl,bTAG_ZERO
	jmp	EMSEG:[ZeroVector]

OneBitLeft:
	xchg	ebx,eax			;Bit now normalized
	sub	ecx,64 shl 16		;Adjust exponent
	jmp	EMSEG:[RoundMode]

NormalizeAdd:
;Inputs:
;	ebx:esi:eax = 65-bit number
;	ecx high half = exponent
;
;Since we are more than 1 bit out of normalization, exponents must have
;differed by 0 or 1.  Thus rounding will not be necessary for 64 bits.
	bsr	edx,ebx			;Scan for MSB
	jnz	short ShortNorm
	bsr	edx,esi
	jz	short ZeroChk
	sub	ecx,32 shl 16		;Adjust exponent
	mov	ebx,esi			;Push it up 32 bits
	mov	esi,eax
ShortNorm:
;Bit number in edx ranges from 0 to 31
	mov	cl,dl
	not	cl			;Convert bit number to shift count
	shld	ebx,esi,cl
	shld	esi,eax,cl
	shl	edx,16			;Move exp. adjustment to high end
	lea	ecx,[ecx+edx-(31 shl 16)] ;Adjust exponent
	xor	eax,eax			;No extra bits
	jmp	EMSEG:[RoundMode]

AddDestSign:
	xor	EMSEG:[edi].bSgn,dh
	ret

AddSourceSign:
	xor	ch,dl
	jmp	SaveResult
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emfconst.asm ===
subttl	emfconst.asm - Loading of 387 on chip constants
        page
;*******************************************************************************
;emfconst.asm - Loading of 387 on chip constants
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Purpose:
;       FLDZ, FLD1, FLDPI, FLDL2T, FLDL2E, FLDLG2, FLDLN2 instructions
;Inputs:
;	edi = [CURstk]
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


	PrevStackWrap	edi,Ld1		;Tied to PrevStackElem below

EM_ENTRY eFLD1
eFLD1:
;edi = [CURstk]
	PrevStackElem	edi,Ld1		;Point to receiving location
	cmp	EMSEG:[edi].bTag,bTAG_EMPTY	;Is it empty?
	jnz	FldErr			;in emload.asm
	mov	EMSEG:[CURstk],edi
	mov	EMSEG:[edi].lManLo,0
	mov	EMSEG:[edi].lManHi,1 shl 31
	mov	EMSEG:[edi].ExpSgn,bTAG_SNGL	;Exponent and sign are zero
	ret


	PrevStackWrap	edi,Ldz		;Tied to PrevStackElem below

EM_ENTRY eFLDZ
eFLDZ:
;edi = [CURstk]
	PrevStackElem	edi,Ldz		;Point to receiving location
	cmp	EMSEG:[edi].bTag,bTAG_EMPTY	;Is it empty?
	jnz	FldErr			;in emload.asm
	mov	EMSEG:[CURstk],edi
	mov	EMSEG:[edi].lManLo,0
	mov	EMSEG:[edi].lManHi,0
	mov	EMSEG:[edi].ExpSgn,bTAG_ZERO	;Exponent and sign are zero
	ret

;*******************************************************************************

;The 5 irrational constants need to be adjusted according to rounding mode.

DefConst	macro	cName,low,high,expon,round
c&cName&lo	equ	low
c&cName&hi	equ	high
c&cName&exp     equ     expon
c&cName&rnd     equ     round
	endm

DefConst	FLDL2T,0CD1B8AFEH,0D49A784BH,00001H,0

DefConst	FLDL2E,05C17F0BCH,0B8AA3B29H,00000H,1

DefConst	FLDLG2,0FBCFF799H,09A209A84H,0FFFEH,1

DefConst	FLDLN2,0D1CF79ACH,0B17217F7H,0FFFFH,1

DefConst	FLDPI,02168C235H,0C90FDAA2H,00001H,1


LoadConstant   macro   cName,nojmp
EM_ENTRY e&cName
e&cName:
	mov	ebx,c&cName&hi
	mov	edx,c&cName&lo
        mov     ecx,c&cName&exp shl 16 + c&cName&rnd
ifb	<nojmp>
	jmp	CommonConst
endif
	endm

LoadConstant	FLDL2T

LoadConstant	FLDL2E

LoadConstant	FLDLG2

LoadConstant	FLDLN2

LoadConstant	FLDPI,nojmp

CommonConst:
;ebx:edx = mantissa of constant, rounded to nearest
;high ecx = exponent 
;ch = sign
;cl = rounding flag: 1 indicates roundup occured for round nearest, else 0
;edi = [CURstk]
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearConst		;Adjust constant if not round nearest
StoreConst:
	mov	cl,bTAG_VALID
	mov	esi,edx
	jmp	FldCont			;In emload.asm

NotNearConst:
;It is known that the five constants positive irrational numbers.
;This means they are never exact, and chop and round down always
;produce the same answer.  It is also know that the values are such
;that rounding only alters bits in the last byte.
;
;A flag in cl indicates if the number has been rounded up for round
;nearest (1 = rounded up, 0 = rounded down).  In chop and round down 
;modes, this flag can be directly subtracted to reverse the rounding.  
;In round up mode, we want to add (1-flag) = -(flag-1).
.erre	RCchop eq 0CH			;Two bits set only for chop
	test	EMSEG:[CWcntl],RCdown	;DOWN bit set?
	jnz	DirectRoundConst	;If so, it's chop or down
;Round Up mode
	dec	cl			;-1 if round up needed, else 0
DirectRoundConst:
	sub	dl,cl			;Directed rounding
	jmp	StoreConst
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emfprem.asm ===
subttl emfprem.asm - FPREM and FPREM1 instructions
	page
;*******************************************************************************
;emfprem.asm - FPREM and FPREM1 instructions
;	by Tim Paterson
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;	 All Rights Reserved
;
;Inputs:
;	edi = [CURstk]
;	ST(1) loaded into ebx:esi & ecx
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************

;Dispatch table for remainder
;
;One operand has been loaded into ecx:ebx:esi ("source"), the other is
;pointed to by edi ("dest").  
;
;Tag of source is shifted.  Tag values are as follows:

.erre   TAG_SNGL        eq      0       ;SINGLE: low 32 bits are zero
.erre   TAG_VALID       eq      1
.erre   TAG_ZERO        eq      2
.erre   TAG_SPCL        eq      3       ;NAN, Infinity, Denormal, Empty

;Any special case routines not found in this file are in emarith.asm

					;Divisor	Dividend
tFpremDisp	label	dword		;Source(ST(1))	Dest (ST(0))
	dd	PremDouble		;single		single
	dd	PremDouble		;single		double
	dd	PremX			;single		zero
	dd	PremSpclDest		;single		special
	dd	PremDouble		;double		single
	dd	PremDouble		;double		double
	dd	PremX			;double		zero
	dd	PremSpclDest		;double		special
	dd	ReturnIndefinite	;zero		single
	dd	ReturnIndefinite	;zero		double
	dd	ReturnIndefinite	;zero		zero
	dd	PremSpclDest		;zero		special
	dd	PremSpclSource		;special	single
	dd	PremSpclSource		;special	double
	dd	PremSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	ReturnIndefinite	;Two infinites


PremSpclDone:
	add	sp,4			;Clean off return address for normal
	ret

;***
PremSpclDest:
	mov	al,EMSEG:[edi].bTag		;Pick up tag
	cmp	al,bTAG_INF		;Dividing infinity?
	jz	ReturnIndefinite	;Invalid operation if so
	jmp	SpclDest		;In emarith.asm

;***
PremSpclSource:
	cmp	cl,bTAG_INF		;Dividing by infinity?
	jnz	SpclSource		;in emarith.asm
PremX:
;Return Dest unchanged, quotient = 0
	mov     EMSEG:[SWcc],0
	ret
;*******************************************************************************

;Map quotient bits to condition codes

Q0	equ	C1
Q1	equ	C3
Q2	equ	C0

MapQuo	label	byte
	db	0
	db	Q0
	db	Q1
	db	Q1+Q0
	db	Q2
	db	Q2+Q0
	db	Q2+Q1
	db	Q2+Q1+Q0

Prem1Cont:

;edx:eax = remainder, normalized
;ebx:esi = divisor
;ebp = quotient
;edi = exponent difference, zero or less
;ecx = 0 (positive sign)
;
;At this point, 0 <= remainder < divisor.  However, for FPREM1 we need
; -divisor/2 <= remainder <= divisor/2.  If remainder = divisor/2, whether
;we choose + or - is dependent on whichever gives us an even quotient
;(the usual IEEE rounding rule).  Quotient must be incremented if we
;use negative remainder.

	cmp	edi,-1
	jl	PremCont		;Remainder < divisor/2
	jg	NegRemainExp0		;Remainder > divisor/2
;Exponent is -1
	cmp	edx,ebx
	jl	PremCont		;Remainder < divisor/2
	jg	NegRemain		;Remainder > divisor/2
	cmp	eax,esi
	jl	PremCont		;Remainder < divisor/2
	jg	NegRemain		;Remainder > divisor/2
;Remainder = divisor/2.  Ensure quotient is even
	test	ebp,1			;Even?
	jz	PremCont
NegRemain:
;Theoretically we subtract divisor from remainder once more, leaving us
;with a negative remainder.  But since we use sign/magnitude representation,
;we want the abs() of that with sign bit set--so subtract remainder from
;(larger) divisor.  Note that exponent difference is -1, so we must align
;binary points first.
	add	esi,esi
	adc	ebx,ebx			;Double divisor to align binary points
NegRemainExp0:
	sub	esi,eax
	sbb	ebx,edx			;Subtract remainder
	mov	eax,esi
	mov	edx,ebx			;Result in edx:eax
	mov	ch,bSign		;Flip sign of remainder
	inc	ebp			;Increase quotient
;Must normalize result of subtraction
	bsr	ecx,edx			;Look for 1 bit
	jnz	@F
	sub	edi,32
	xchg	edx,eax			;Shift left 32 bits
	bsr	ecx,edx
@@:
	lea     edi,[edi+ecx-31]        ;Fix up exponent for normalization
	not     cl
	shld	edx,eax,cl
	shl	eax,cl
	mov	ch,bSign		;Flip sign of remainder

PremCont:
;edx:eax = remainder, normalized
;ebp = quotient
;edi = exponent difference, zero or less
;ch = sign
	or	eax,eax			;Low bits zero?
.erre	bTAG_VALID eq 1
.erre	bTAG_SNGL eq 0
	setnz   cl                      ;if low half==0 then cl=0 else cl=1
	mov	esi,EMSEG:[CURstk]
	mov     ebx,esi
	NextStackElem   ebx,Prem
	add	di,EMSEG:[ebx].wExp		;Compute result exponent
	cmp	di,IexpMin-IexpBias
	jle	PremUnderflow
SavePremResult:
	mov	EMSEG:[esi].lManLo,eax
	xor	EMSEG:[esi].bSgn,ch
	mov	EMSEG:[esi].lManHi,edx
	and	ebp,7			;Keep last 3 bits of quotient only
					;  and give write buffers a break
	mov	EMSEG:[esi].wExp,di
	mov	EMSEG:[esi].bTag,cl
	mov	al,MapQuo[ebp]		;Get cond. codes for this quotient
	mov	EMSEG:[SWcc],al
	ret

	NextStackWrap   ebx,Prem        ;Tied to NextStackElem above

PremUnderflow:
	test	EMSEG:[CWmask],Underflow	;Is exception unmasked?
	jz	UnmaskedPremUnder
	mov	cl,bTAG_DEN
	jmp	SavePremResult

UnmaskedPremUnder:
	add	edi,UnderBias		;Additional exp. bias for unmasked resp.
	or	EMSEG:[CURerr],Underflow
	jmp	SavePremResult

;*******************************************************************************

PremDouble:
;edi = [CURstk]
;ebx:esi = ST(1) mantissa, ecx = ExpSgn

	add	sp,4			;Clean off return address for special
	mov	eax,EMSEG:[edi].lManLo
	mov	edx,EMSEG:[edi].lManHi
	movsx	edi,EMSEG:[edi].wExp
	xor	ebp,ebp			;Quotient, in case we skip stage 1
	sar	ecx,16			;Bring exponent down
	sub	edi,ecx			;Get exponent difference
	jl	ExitPremLoop		;If dividend is smaller, return it.

;FPREM is performed in two stages.  The first stage is used only if the
;exponent difference is greater than 31.  It reduces the exponent difference
;by 32, and repeats until the difference is less than 32.  Note that
;unlike the hardware FPREM instruction, we are not limited to reducing
;the exponent by only 63--we just keep looping until it's done.
;
;The second stage performs ordinary 1-bit-at-a-time long division.
;It stops when the exponent difference is zero, meaning we have an
;integer quotient and the final remainder.
;
;edx:eax = dividend
;ebx:esi = divisor
;edi = exponent difference
;ebp = 0 (initial quotient)

	cmp	edi,32			;Do we need to do stage 1?
	jl	FitDivisor		;No, start stage 2

;FPREM stage 1
;
;Exponent difference is at least 32.  Use 32-bit division to compute
;quotient and exact remainder, reducing exponent difference by 32.

;DIV instruction will overflow if dividend >= divisor.  In this case,
;subtract divisor from dividend to ensure no overflow.  This will change
;the quotient, but that doesn't matter because we only need the last
;3 bits of the quotient (and we're about to calculate 32 quotient bits).
;This subtraction will not affect the remainder.

	sub	eax,esi
	sbb	edx,ebx	
	jnc	FpremReduce32		;Was dividend big?
	add	eax,esi			;Restore dividend, it was smaller
	adc	edx,ebx

;Division algorithm from Knuth vol. 2, p. 237, using 32-bit "digits":
;Guess a quotient digit by dividing two MSDs of dividend by the MSD of
;divisor.  If divisor is >= 1/2 the radix (radix = 2^32 in this case), then
;this guess will be no more than 2 larger than the correct value of that
;quotient digit (and never smaller).  Divisor meets magnitude condition 
;because it's normalized.
;
;This loop typically takes 117 clocks.

;edx:eax = dividend
;ebx:esi = divisor
;edi = exponent difference
;ebp = quotient (zero)

FpremReduce32:
;We know that dividend < divisor, but it is still possible that 
;high dividend == high divisor, which will cause the DIV instruction
;to overflow.
	cmp	edx,ebx			;Will DIV instruction overflow?
	jae	PremOvfl
	div	ebx			;Guess a quotient "digit"

;Currently, remainder in edx = dividend - (quotient * high half divisor).
;The definition of remainder is dividend - (quotient * all divisor).  So
;if we subtract (quotient * low half divisor) from edx, we'll get
;the true remainder.  If it's negative, our guess was too big.

	mov	ebp,eax			;Save quotient
	mov	ecx,edx			;Save remainder
	mul	esi			;Quotient * low half divisor
	neg	eax			;Subtract from dividend extended with 0
	sbb	ecx,edx			;Subtract from remainder
	mov	edx,ecx			;Remainder back to edx:eax
	jnc	HavPremQuo		;Was quotient OK?
FpremCorrect:
	dec	ebp			;Quotient was too big
	add	eax,esi			;Add divisor back into remainder
	adc	edx,ebx
	jnc	FpremCorrect		;Repeat if quotient is still too big
HavPremQuo:
	sub	edi,32			;Exponent reduced
	cmp	edi,32			;Exponent difference within 31?
	jl	PremNormalize		;Do it a bit a time
	or	edx,edx			;Check for zero remainder
	jnz	FpremReduce32
	or	eax,eax			;Remainder 0?
	jz	ExactPrem
	xchg	edx,eax			;Shift left 32 bits
	sub	edi,32			;Another 32 bits reduced
	cmp	edi,32
	jge	FpremReduce32
	xor	ebp,ebp			;No quotient bits are valid
	jmp	PremNormalize

PremOvfl:
;edx:eax = dividend
;ebx:esi = divisor
;On exit, ebp = second quotient "digit"
;
;Come here if divide instruction would overflow. This must mean that edx == ebx,
;i.e., the high halves of the dividend and divisor are equal. Assume a result
;of 2^32-1, thus remainder = dividend - ( divisor * (2^32-1) )
; = dividend - divisor * 2^32 + divisor. Since the high halves of the dividend
;and divisor are equal, dividend - divisor * 2^32 can be computed by
;subtracting only the low halves. When adding divisor (in ebx) to this, note
;that edx == ebx, and we want the result in edx anyway.
;
;Note also that since dividend < divisor, the
;dividend - divisor * 2^32 calculation must always be negative. Thus the 
;addition of divisor back to it should generate a carry if it goes positive.

	mov	ebp,-1			;Max quotient digit
	sub	eax,esi			;Calculate correct remainder
	add	edx,eax			;Should set CY if quotient fit
	mov	eax,esi			;edx:eax has new remainder
	jc	HavPremQuo		;Remainder was positive
	jmp	FpremCorrect

ExactPrem:
;eax = 0
	mov	esi,EMSEG:[CURstk]
	mov	EMSEG:[esi].lManLo,eax
	mov	EMSEG:[esi].lManHi,eax
	add	sp,4			;Clean off first return address
	mov	EMSEG:[esi].wExp,ax
	mov	EMSEG:[esi].bTag,bTAG_ZERO
	ret


;FPREM stage 2
;
;Exponent difference is less than 32.  Use restoring long division to
;compute quotient bits until exponent difference is zero.  Note that we
;often get more than one bit/loop:  BSR is used to scan off leading
;zeros each time around.  Since the divisor is normalized, we can
;instantly compute a zero quotient bit for each leading zero bit.
;
;For reductions of 1 to 31 bits per loop, this loop requires 41 or 59 clocks
;plus 3 clocks/bit (BSR time).  If we had to use this for 32-bit reductions
;(without stage 1), we could expect (50+6)*16 = 896 clocks typ (2 bits/loop)
;instead of the 112 required by stage 1!

FpremLoop:
;edx:eax = dividend (remainder) minus divisor
;ebx:esi = divisor
;ebp = quotient
;edi = exponent difference, less than 32
;
;If R is current remainder and d is divisor, then we have edx:eax = R - d, 
;which is negative.  We want 2*R - d, which is positive.  
;2*R - d = 2*(R - d) + d.
	add	eax,eax			;2*(R - d)
	adc	edx,edx
	add	eax,esi			;2*(R-d) + d = 2*R - d
	adc	edx,ebx	
	add	ebp,ebp			;Double quotient too
	dec	edi			;Decrement exponent difference
DivisorFit:
	inc	ebp			;Count one in quotient
PremNormalize:
	bsr	ecx,edx			;Find first 1 bit
	jz	PremHighZero
	not     cl
	and     cl,1FH                  ;Convert bit no. to shift count
	shld	edx,eax,cl		;Normalize
	shl	eax,cl
	sub	edi,ecx			;Reduce exponent difference
	jl	PremTooFar
	shl	ebp,cl			;Shift quotient
FitDivisor:
;Dividend could be larger or smaller than divisor
	sub	eax,esi
	sbb	edx,ebx
	jnc	DivisorFit
;Couldn't subtract divisor from dividend.
	or	edi,edi			;Is exponent difference zero or less?
	jg	FpremLoop
	add	eax,esi			;Restore dividend
	adc	edx,ebx
	xor	ecx,ecx			;Sign is positive
	ret

PremTooFar:
;Exponent difference in edi went negative when reduced by shift count in ecx.
;We need a quotient corresponding to exponent difference of zero.
	add	ecx,edi			;Restore exponent difference
	shl	ebp,cl			;Fix up quotient
ExitPremLoop:
;edx:eax = remainder, normalized
;ebp = quotient
;edi = exponent difference, zero or less
	xor	ecx,ecx			;Sign is positive
	ret

PremHighZero:
;High half of remainder is all zero, so we've reduced exponent difference
;by 32 bits and overshot.  We need a quotient corresponding to exponent 
;difference of zero, so we just shift it by the original difference.  Then
;we need to normalize the low half remainder.
	mov	ecx,edi
	shl	ebp,cl			;Fix up quotient
	bsr	ecx,eax
	jz	ExactPrem
	lea     edi,[edi+ecx-63]        ;Fix up exponent for normalization
	xchg	eax,edx			;Shift by 32 bits
	not     cl
        shl     edx,cl                  ;Normalize remainder
        xor     ecx,ecx                 ;Sign is positive
        ret
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emfdiv.asm ===
subttl  emfdiv.asm - Division
	page
;*******************************************************************************
;	 Copyright (c) Microsoft Corporation 1991
;	 All Rights Reserved
;
;emfdiv.asm - long double divide
;	by Tim Paterson
;
;Purpose:
;	Long double division.
;Inputs:
;	ebx:esi = op1 mantissa
;	ecx = op1 sign in bit 15, exponent in high half
;	edi = pointer to op2 and result location
;	[Result] = edi
;
;	Exponents are unbiased.  Denormals have been normalized using
;	this expanded exponent range.  Neither operand is allowed to be zero.
;Outputs:
;	Jumps to [RoundMode] to round and store result.
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;Dispatch tables for division
;
;One operand has been loaded into ecx:ebx:esi ("source"), the other is
;pointed to by edi ("dest").  edi points to dividend for fdiv,
;to divisor for fdivr.  
;
;Tag of source is shifted.  Tag values are as follows:
;
.erre	TAG_SNGL	eq	0	;SINGLE: low 32 bits are zero
.erre	TAG_VALID	eq	1
.erre	TAG_ZERO	eq	2
.erre	TAG_SPCL	eq	3	;NAN, Infinity, Denormal, Empty

;dest = dest / source
tFdivDisp	label	dword		;Source (reg)	Dest (*[di])
	dd	DivSingle		;single		single
	dd	DivSingle		;single		double
	dd	XorDestSign		;single		zero
	dd	DivSpclDest		;single		special
	dd	DivDouble		;double		single
	dd	DivDouble		;double		double
	dd	XorDestSign		;double		zero
	dd	DivSpclDest		;double		special
	dd	DivideByZero		;zero		single
	dd	DivideByZero		;zero		double
	dd	ReturnIndefinite	;zero		zero
	dd	DivSpclDest		;zero		special
	dd	DivSpclSource		;special	single
	dd	DivSpclSource		;special	double
	dd	DivSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	ReturnIndefinite	;Two infinities

;dest = source / dest
tFdivrDisp	label	dword		;Source (reg)	Dest (*[di])
	dd	DivrSingle		;single		single
	dd	DivrDouble		;single		double
	dd	DivideByZero		;single		zero
	dd	DivrSpclDest		;single		special
	dd	DivrSingle		;double		single
	dd	DivrDouble		;double		double
	dd	DivideByZero		;double		zero
	dd	DivrSpclDest		;double		special
	dd	XorSourceSign		;zero		single
	dd	XorSourceSign		;zero		double
	dd	ReturnIndefinite	;zero		zero
	dd	DivrSpclDest		;zero		special
	dd	DivrSpclSource		;special	single
	dd	DivrSpclSource		;special	double
	dd	DivrSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	ReturnIndefinite	;Two infinities


EM_ENTRY eFIDIV16
eFIDIV16:
	push	offset DivSetResult
	jmp	Load16Int		;Returns to DivSetResult

EM_ENTRY eFIDIVR16
eFIDIVR16:
	push	offset DivrSetResult
	jmp	Load16Int

EM_ENTRY eFIDIV32
eFIDIV32:
	push	offset DivSetResult
	jmp	Load32Int

EM_ENTRY eFIDIVR32
eFIDIVR32:
	push	offset DivrSetResult
	jmp	Load32Int

EM_ENTRY eFDIV32
eFDIV32:
	push	offset DivSetResult
	jmp	Load32Real			;Returns to DivSetResult

EM_ENTRY eFDIVR32
eFDIVR32:
	push	offset DivrSetResult		;Returns to DivrSetResult
	jmp	Load32Real

EM_ENTRY eFDIV64
eFDIV64:
	push	offset DivSetResult
	jmp	Load64Real			;Returns to DivSetResult

EM_ENTRY eFDIVR64
eFDIVR64:
	push	offset DivrSetResult
	jmp	Load64Real			;Returns to DivrSetResult


EM_ENTRY eFDIVRPreg
eFDIVRPreg:
	push	offset PopWhenDone

EM_ENTRY eFDIVRreg
eFDIVRreg:
	xchg	esi,edi

EM_ENTRY eFDIVRtop
eFDIVRtop:
	mov	ecx,EMSEG:[esi].ExpSgn
	mov	ebx,EMSEG:[esi].lManHi
	mov	esi,EMSEG:[esi].lManLo
DivrSetResult:
;cl has tag of dividend
	mov     ebp,offset tFdivrDisp
	mov	EMSEG:[Result],edi		;Save result pointer
	mov	ah,cl
	mov     al,EMSEG:[edi].bTag
	and	ah,not 1		;Ignore single vs. double on dividend
	cmp	ax,1
.erre	bTAG_VALID	eq	1
.erre	bTAG_SNGL	eq	0
	jz	DivrDouble		;Divisor was double
	ja	TwoOpResultSet
;.erre	DivrSingle eq $			;Fall into DivrSingle

;*********
DivrSingle:
;*********
;Computes op1/op2
;Op1 is double, op2 is single (low 32 bits are zero)
	mov	edx,ebx
	mov	eax,esi			;Mantissa in edx:eax
	mov	ebx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManHi
	jmp	DivSingleReg


SDivBigUnderflow:
;Overflow flag set could only occur with denormals (true exp < -32768)
	or	EMSEG:[CURerr],Underflow
	test	EMSEG:[CWmask],Underflow	;Is exception masked?
	jnz	UnderflowZero		;Yes, return zero (in emfmul.asm)
	add	ecx,Underbias shl 16	;Fix up exponent
	jmp	ContSdiv		;Continue with multiply


EM_ENTRY eFDIVPreg
eFDIVPreg:
	push	offset PopWhenDone

EM_ENTRY eFDIVreg
eFDIVreg:
	xchg	esi,edi

EM_ENTRY eFDIVtop
eFDIVtop:
	mov	ecx,EMSEG:[esi].ExpSgn
	mov	ebx,EMSEG:[esi].lManHi
	mov	esi,EMSEG:[esi].lManLo
DivSetResult:
;cl has tag of divisor
	mov     ebp,offset tFdivDisp
	mov	EMSEG:[Result],edi		;Save result pointer
	mov	al,cl
	mov     ah,EMSEG:[edi].bTag
	and	ah,not 1		;Ignore single vs. double on dividend
	cmp	ax,1
.erre	bTAG_VALID	eq	1
.erre	bTAG_SNGL	eq	0
	jz	DivDouble		;Divisor was double
	ja	TwoOpResultSet
;.erre	DivSingle eq $			;Fall into DivSingle

;*********
DivSingle:
;*********
;Computes op2/op1
;Op2 is double, op1 is single (low 32 bits are zero)
	xchg	edi,ebx			;Mantissa in edi, op2 ptr to ebx
	xchg	ebx,ecx			;ExpSgn to ebx, op2 ptr to ecx
	mov	edx,EMSEG:[ecx].lManHi
	mov	eax,EMSEG:[ecx].lManLo
	mov	ecx,EMSEG:[ecx].ExpSgn	;Op2 loaded

DivSingleReg:
;dividend mantissa in edx:eax, exponent in high ecx, sign in ch bit 7
;divisor mantissa in edi, exponent in high ebx, sign in bh bit 7

	xor	ch,bh			;Compute result sign
	xor	bx,bx			;Clear out sign and tag
	sub	ecx,1 shl 16		;Exponent adjustment needed
	sub	ecx,ebx			;Compute result exponent
.erre	TexpBias eq 0			;Exponents not biased
	jo	SDivBigUnderflow	;Dividing denormal by large number
ContSdiv:

;If dividend >= divisor, the DIV instruction will overflow.  Check for
;this condition and shift the dividend right one bit if necessary.
;
;In previous versions of this algorithm for 24-bit and 53-bit mantissas,
;this shift was always performed without a test.  This meant that a 1-bit
;normalization might be required at the end.  This worked fine because
;32 or 64 bits were calculated, so extra precision was available for
;normalization.  However, this version needs all 64 bits that are calculated, 
;so we can't afford a normalization shift at the end.  This test tells us
;up front how to align so we'll be normalized.
	xor	ebx,ebx			;Extend dividend
	cmp	edi,edx			;Will DIV overflow?
	ja	DoSdiv			;No, we're safe
	shrd	ebx,eax,1
	shrd	eax,edx,1
	shr	edx,1
	add	ecx,1 shl 16		;Bump exponent to account for shift
DoSdiv:
	div	edi
	xchg	ebx,eax			;Save quotient in ebx, extend remainder
	div	edi
	mov	esi,eax
;We have a 64-bit quotient in ebx:esi.  Now compare remainder*2 with divisor
;to compute round and sticky bits.
	mov	eax,-1			;Set round and sticky bits
	shl	edx,1			;Double remainder
	jc	RoundJmp		;If too big, round & sticky set
	cmp	edx,edi			;Is remainder*2 > divisor?
	ja	RoundJmp

;Observe, oh wondering one, how you can assume the result of this last
;compare is not equality.  Use the following notation: n=numerator,
;d=denominator,q=quotient,r=remainder,b=base(2^64 here).  If
;initially we had n < d then there was no shift and we will find q and r
;so that q*d+r=n*b, if initially we had n >= d then there was a shift and
;we will find q and r so that q*d+r=n*b/2.  If we have equality here
;then r=d/2  ==>  n={possibly 2*}(2*q+1)*d/(2*b), since this can only
;be integral if d is a multiple of b, but by definition b/2 <= d < b, we
;have a contradiction.	Equality is thus impossible at this point.

	cmp	edx,1			;Check for zero remainder
	sbb	eax,-2			;eax==0 if CY, ==1 if NC (was -1)
RoundJmp:
	jmp	EMSEG:[RoundMode]

;*******************************************************************************

DDivBigUnderflow:
;Overflow flag set could only occur with denormals (true exp < -32768)
	or	EMSEG:[CURerr],Underflow
	test	EMSEG:[CWmask],Underflow	;Is exception masked?
	jnz	UnderflowZero		;Yes, return zero (in emfmul.asm)
	add	ecx,Underbias shl 16	;Fix up exponent
	jmp	ContDdiv		;Continue with multiply

DivrDoubleSetFlag:
;Special entry point used by FPATAN to set bit 6 of flag dword pushed
;on stack before call.
	or	byte ptr [esp+4],40H
;*********
DivrDouble:
;*********
;Computes op1/op2
	mov	edx,ebx
	mov	eax,esi			;Mantissa in edx:eax
	mov	ebx,EMSEG:[edi].ExpSgn
	mov	esi,EMSEG:[edi].lManHi
	mov	edi,EMSEG:[edi].lManLo
	jmp	short DivDoubleReg

HighHalfEqual:
;edx:eax:ebp = dividend
;esi:edi = divisor
;ecx = exponent and sign of result
;
;High half of dividend is equal to high half of divisor.  This will cause
;the DIV instruction to overflow.  If whole dividend >= whole divisor, then
;we just shift the dividend right 1 bit.
	cmp	eax,edi			;Is dividend >= divisor?
	jae	ShiftDividend		;Yes, divide it by two
;DIV instruction would overflow, so skip it and calculate the effective
;result.  Assume a quotient of 2^32-1 and calculate the remainder.  See
;detailed comments under MaxQuo below--this is a copy of that code.
	push	ecx			;Save exp. and sign
	mov	ebx,-1			;Max quotient digit
	sub	eax,edi			;Calculate correct remainder
;Currently edx == esi, but the next instruction ensures that is no longer
;true, since eax != 0.  This will allow us to skip the MaxQuo check at
;DivFirstDigit.
	add	edx,eax			;Should set CY if quotient fit
	mov	eax,edi			;ecx:eax has new remainder
	jc	ComputeSecond		;Remainder was positive
;Quotient doesn't fit.  Note that we can no longer ensure that edx != esi
;after making a correction.
	mov	ecx,edx			;Need remainder in ecx:eax
	jmp	DivCorrect1

;*********
DivDouble:
;*********
;Computes op2/op1
	mov	eax,edi			;Move op2 pointer
	mov	edi,esi
	mov	esi,ebx			;Mantissa in esi:edi
	mov	ebx,ecx			;ExpSgn to ebx
	mov	ecx,EMSEG:[eax].ExpSgn	;Op2 loaded
	mov	edx,EMSEG:[eax].lManHi
	mov	eax,EMSEG:[eax].lManLo

DivDoubleReg:
;dividend mantissa in edx:eax, exponent in high ecx, sign in ch bit 7
;divisor mantissa in esi:edi, exponent in high ebx, sign in bh bit 7

	xor	ch,bh			;Compute result sign
	xor	bx,bx			;Clear out sign and tag
	sub	ecx,1 shl 16		;Exponent adjustment needed
	sub	ecx,ebx			;Compute result exponent
.erre	TexpBias eq 0			;Exponents not biased
	jo	DDivBigUnderflow	;Dividing denormal by large number
ContDdiv:

;If dividend >= divisor, we must shift the dividend right one bit.
;This will ensure the result is normalized.
;
;In previous versions of this algorithm for 24-bit and 53-bit mantissas,
;this shift was always performed without a test.  This meant that a 1-bit
;normalization might be required at the end.  This worked fine because
;32 or 64 bits were calculated, so extra precision was available for
;normalization.  However, this version needs all 64 bits that are calculated, 
;so we can't afford a normalization shift at the end.  This test tells us
;up front how to align so we'll be normalized.
	xor	ebp,ebp			;Extend dividend
	cmp	esi,edx			;Dividend > divisor
	ja	DoDdiv
	jz	HighHalfEqual		;Go compare low halves
ShiftDividend:
	shrd	ebp,eax,1
	shrd	eax,edx,1
	shr	edx,1
	add	ecx,1 shl 16		;Bump exponent to account for shift
DoDdiv:
	push	ecx			;Save exp. and sign

;edx:eax:ebp = dividend
;esi:edi = divisor
;
;Division algorithm from Knuth vol. 2, p. 237, using 32-bit "digits":
;Guess a quotient digit by dividing two MSDs of dividend by the MSD of
;divisor.  If divisor is >= 1/2 the radix (radix = 2^32 in this case), then
;this guess will be no more than 2 larger than the correct value of that
;quotient digit (and never smaller).  Divisor meets magnitude condition 
;because it's normalized.

	div	esi			;Guess first quotient "digit"

;Check out our guess.  
;Currently, remainder in edx = dividend - (quotient * high half divisor).
;The definition of remainder is dividend - (quotient * all divisor).  So
;if we subtract (quotient * low half divisor) from edx, we'll get
;the true remainder.  If it's negative, our guess was too big.

	mov	ebx,eax			;Save quotient
	mov	ecx,edx			;Save remainder
	mul	edi			;Quotient * low half divisor
	sub	ebp,eax			;Subtract from dividend extension
	sbb	ecx,edx			;Subtract from remainder
	mov	eax,ebp			;Low remainder to eax
	jnc	DivFirstDigit		;Was quotient OK?
DivCorrect1:
	dec	ebx			;Quotient was too big
	add	eax,edi			;Add divisor back into remainder
	adc	ecx,esi
	jnc	DivCorrect1		;Repeat if quotient is still too big
DivFirstDigit:
	cmp	ecx,esi			;Would DIV instruction overflow?
	jae	short MaxQuo		;Yes, figure alternate quotient
	mov	edx,ecx			;Remainder back to edx:eax

;Compute 2nd quotient "digit"

ComputeSecond:
	div	esi			;Guess 2nd quotient "digit"
	mov	ebp,eax			;Save quotient
	mov	ecx,edx			;Save remainder
	mul	edi			;Quotient * low half divisor
	neg	eax			;Subtract from dividend extended with 0
	sbb	ecx,edx			;Subtract from remainder
	jnc	DivSecondDigit		;Was quotient OK?
DivCorrect2:
	dec	ebp			;Quotient was too big
	add	eax,edi			;Add divisor back into remainder
	adc	ecx,esi
	jnc	DivCorrect2		;Repeat if quotient is still too big
DivSecondDigit:
;ebx:ebp = quotient
;ecx:eax = remainder
;esi:edi = divisor
;Now compare remainder*2 with divisor to compute round and sticky bits.
	mov	edx,-1			;Set round and sticky bits
	shld	ecx,eax,1		;Double remainder
	jc	DDivEnd			;If too big, round & sticky set
	shl	eax,1
	sub	edi,eax
	sbb	esi,ecx			;Subtract remainder*2 from divisor
	jb	DDivEnd			;If <0, use round & sticky bits set

;Observe, oh wondering one, how you can assume the result of this last
;compare is not equality.  Use the following notation: n=numerator,
;d=denominator,q=quotient,r=remainder,b=base(2^64 here).  If
;initially we had n < d then there was no shift and we will find q and r
;so that q*d+r=n*b, if initially we had n >= d then there was a shift and
;we will find q and r so that q*d+r=n*b/2.  If we have equality here
;then r=d/2  ==>  n={possibly 2*}(2*q+1)*d/(2*b), since this can only
;be integral if d is a multiple of b, but by definition b/2 <= d < b, we
;have a contradiction.	Equality is thus impossible at this point.

;No round bit, but set sticky bit if remainder != 0.
	or	eax,ecx			;Is remainder zero?
	add	eax,-1			;Set CY if non-zero
	adc	edx,1			;edx==0 if NC, ==1 if CY (was -1)
DDivEnd:
	mov	esi,ebp			;Result in ebx:esi
	mov	eax,edx			;Round/sticky bits to eax
	pop	ecx			;Recover sign/exponent
	jmp	EMSEG:[RoundMode]


MaxQuo:
;ebx = first quotient "digit"
;ecx:eax = remainder
;esi:edi = divisor
;On exit, ebp = second quotient "digit"
;
;Come here if divide instruction would overflow. This must mean that ecx == esi,
;i.e., the high halves of the dividend and divisor are equal. Assume a result
;of 2^32-1, thus remainder = dividend - ( divisor * (2^32-1) )
; = dividend - divisor * 2^32 + divisor. Since the high halves of the dividend
;and divisor are equal, dividend - divisor * 2^32 can be computed by
;subtracting only the low halves. When adding divisor (in esi) to this, note
;that ecx == esi, and we want the result in ecx anyway.
;
;Note also that since the dividend is a previous remainder, the
;dividend - divisor * 2^32 calculation must always be negative. Thus the 
;addition of divisor back to it should generate a carry if it goes positive.

	mov	ebp,-1			;Max quotient digit
	sub	eax,edi			;Calculate correct remainder
	add	ecx,eax			;Should set CY if quotient fit
	mov	eax,edi			;ecx:eax has new remainder
	jc	DivSecondDigit		;Remainder was positive
	jmp	DivCorrect2
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emlsbcd.asm ===
subttl	emlsbcd.asm - FBSTP and FBLD instructions
        page
;*******************************************************************************
;emlsbcd.asm - FBSTP and FBLD instructions
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Purpose:
;	FBSTP and FBLD instructions.
;
;	These routines convert between 64-bit integer and 18-digit packed BCD
;	format.  They work by splitting the number being converted in half
;	and converting the two halves separately.  This works well because
;	9 decimal digits fit nicely within 30 binary bits, so converion of
;	each half is strictly a 32-bit operation.
;
;Inputs:
;	edi = [CURstk]
;	dseg:esi = pointer to memory operand
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;******
eFBLD:
;******
	mov	eax,dseg:[esi+5]		;Get high 8 digits
	or	eax,eax			;Anything there?
	jz	HighDigitsZero
	mov	ecx,8
	call	ReadDigits		;Convert first 8 digits to binary
	mov	eax,dseg:[esi+1]		;Get next 8 digits
	xor	edi,edi
	shld	edi,eax,4		;Shift ninth digit into edi
	imul	ebx,10
	add	edi,ebx			;Accumulate ninth digit
SecondNineDigits:
	xor	ebx,ebx			;In case eax==0
	shl	eax,4			;Keep digits left justified
	jz	LastTwoDigits
	mov	ecx,7
	call	ReadDigits		;Convert next 7 digits to binary
LastTwoDigits:
	mov	al,dseg:[esi]		;Get last two digits
	shl	eax,24			;Left justify
	mov	ecx,2
	call	InDigitLoop		;Accumulate last two digits
;edi = binary value of high 9 digits
;ebx = binary value of low 9 digits
	mov	eax,1000000000		;One billion: shift nine digits left
	mul	edi			;Left shift 9 digits. 9 cl. if edi==0
	add	ebx,eax			;Add in low digits
	adc	edx,0
BcdReadyToNorm:
;edx:ebx = integer converted to binary
	mov	eax,dseg:[esi+6]		;Get sign to high bit of eax
	mov	esi,ebx
	mov	ebx,edx
	mov     edi,EMSEG:[CURstk]
;mantissa in ebx:esi, sign in high bit of eax
;edi = [CURstk]
	jmp	NormQuadInt		;in emload.asm

HighDigitsZero:
	mov	eax,dseg:[esi+1]		;Get next 8 digits
	or	eax,eax			;Anything there?
	jz	CheckLastTwo
	xor	edi,edi
	shld	edi,eax,4		;Shift ninth digit into edi
	jmp	SecondNineDigits
       
CheckLastTwo:
	mov	bl,dseg:[esi]		;Get last two digits
	or	bl,bl
	jz	ZeroBCD
	mov	al,bl
	shr	al,4			;Bring down upper digit
	imul	eax,10
	and	ebx,0FH			;Keep lowest digit only
	add	ebx,eax
	xor	edx,edx
	jmp	BcdReadyToNorm
	
ZeroBCD:
	mov	ecx,bTAG_ZERO		;Exponent is zero
	mov	ch,dseg:[esi+9]		;Get sign byte to ch
	xor	ebx,ebx
	mov	esi,ebx
;mantissa in ebx:esi, exp/sign in ecx
;edi = [CURstk]
	jmp	FldCont			;in emload.asm

			
;*** ReadDigits
;
;Inputs:
;	eax = packed BCD digits, left justified, non-zero
;	ecx = no. of digits, 7 or 8
;Outputs:
;	ebx = number

SkipZeroDigits:
        sub     ecx,3
        shl     eax,12
ReadDigits:
;We start by scanning off leading zeros.  This costs 16 cl./nybble in
;the ScanZero loop.  To reduce this cost for many leading zeros, we
;check for three leading zeros at a time.  Adding this test saves
;26 cl. for 3 leading zeros, 57 cl. for 6 leading zeros, at a cost
;of only 5 cl. if less than 3 zeros.  We choose 3 at a time so we
;can repeat it once (there are never more than 7 zeros).
	test    eax,0FFF00000H          ;Check first 3 nybbles for zero
	jz      SkipZeroDigits
	xor	ebx,ebx
ScanZero:
;Note that bsr is 3 cl/bit, or 12 cl/nybble.  Add in the overhead and
;this loop of 16 cl/nybble is cheaper for the 1 - 3 digits it does.
	dec	ecx
	shld	ebx,eax,4		;Shift digit into ebx
	rol	eax,4			;Left justify **Doesn't affect ZF!**
	jz	ScanZero		;Skip to next digit if zero
	jecxz	ReadDigitsX
InDigitLoop:
;eax = digits to convert, left justified
;ebx = result accumulation
;ecx = number of digits to convert
	xor	edx,edx
	shld	edx,eax,4		;Shift digit into edx
	shl	eax,4			;Keep digits left justified
	imul	ebx,10			;Only 10 clocks on 386!
	add	ebx,edx			;Accumulate number
	dec	ecx
	jnz	InDigitLoop
ReadDigitsX:
	ret
		
;*******************************************************************************

ChkInvalidBCD:
	ja	SetInvalidBCD
	cmp	edi,0A7640000H		;(1000000000*1000000000) and 0ffffffffh
	jb	ValidBCD
SetInvalidBCD:
	mov	EMSEG:[CURerr],Invalid
InvalidBCD:
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	ReadDigitsX		;No--leave memory unchanged
;Store Indefinite
	mov	dword ptr dseg:[esi],0
	mov	dword ptr dseg:[esi+4],0
	mov	word ptr dseg:[esi+8],-1	;0FF00000000H for packed BCD indefinite
	jmp	PopStack		;in emstore.asm

;******
eFBSTP:
;******
	call	RoundToInteger		;Get integer in ebx:edi, sign in ch
	jc	InvalidBCD
	cmp	ebx,0DE0B6B3H		;(1000000000*1000000000) shr 32
	jae	ChkInvalidBCD
ValidBCD:
	and	ch,bSign
	mov	dseg:[esi+9],ch		;Fill in sign byte
	mov	edx,ebx
	mov	eax,edi			;Get number to edx:eax for division
	mov	ebx,1000000000
	div	ebx			;Break into two 9-digit halves
	xor	ecx,ecx			;Initial digits
	mov	edi,eax			;Save quotient
	mov	eax,edx
	or	eax,eax
	jz	SaveLowBCD
	call	WriteDigits
	shrd	ecx,eax,4		;Pack 8th digit
	xor	al,al
	shl	eax,20			;Move digit in ah to high end
SaveLowBCD:
	mov	dseg:[esi],ecx		;Save low 8 digits
	mov	ecx,eax			;Get ready for next 8 digits
	mov	eax,edi
	or	eax,eax
	jz	ZeroHighBCD
	call	WriteDigits
	shl	ah,4			;Move digit to upper nybble
	or	al,ah			;Combine last two digits
SaveHighBCD:
	mov	dseg:[esi+4],ecx		;Save lower 8 digits
	mov	dseg:[esi+8],al
	jmp	PopStack

ZeroHighBCD:
	shr	ecx,28			;Position 9th digit
	jmp	SaveHighBCD


;*** WriteDigits
;
;Inputs:
;	eax = binary number < 1,000,000,000 and > 0
;	ecx = Zero or had one BCD digit left justified
;Purpose:
;	Convert binary integer to BCD.
;
;	The time required for the DIV instruction is dependent on operand
;	size, at 6 + (no. of bits) clocks for 386.  (In contrast, multiply
;	by 10 as used in FBLD/ReadDigits above takes the same amount of
;	time regardless of operand size--only 10 clocks.)
;
;	The easy way to do this conversion would be to repeatedly do a
;	32-bit division by 10 (at 38 clocks/divide).  Instead, the number
;	is broken down so that mostly 8-bit division is used (only 14 clocks).
;	AAM (17 clocks) is also used to save us from having to load the 
;	constant 10 and zero ah.  AAM is faster than DIV on the 486sx.
;
;Outputs:
;	ecx has seven more digits packed into it (from left)
;	ah:al = most significant two digits (unpacked)
;esi,edi preserved

WriteDigits:
;eax = binary number < 1,000,000,000
	cdq				;Zero edx
	mov	ebx,10000
	div	ebx			;Break into 4-digit and 5-digit pieces
	mov	bl,100
	or	edx,edx
	jz	ZeroLowDigits
	xchg	edx,eax			;Get 4-digit remainder to eax
;Compute low 4 digits
; 0 < eax < 10000
	div	bl			;Get two 2-digit pieces. 14cl on 386
	mov	bh,al			;Save high 2 digits
	mov	al,ah			;Get low digits
	aam
	shl	ah,4			;Move digit to upper nybble
	or	al,ah
	shrd	ecx,eax,8
	mov	al,bh			;Get high 2 digits
	aam
	shl	ah,4			;Move digit to upper nybble
	or	al,ah
	shrd	ecx,eax,8
;Compute high 5 digits
	mov	eax,edx			;5-digit quotient to eax
	or	eax,eax
	jz	ZeroHighDigits
ConvHigh5:
	cdq				;Zero edx
	shld	edx,eax,16		;Put quotient in dx:ax
	xor	bh,bh			;bx = 100
	div	bx			;Get 2- and 3-digit pieces. 22cl on 386
	xchg	edx,eax			;Save high 3 digits, get log 2 digits
	aam
	shl	ah,4			;Move digit to upper nybble
	or	al,ah
	shrd	ecx,eax,8
	mov	eax,edx			;Get high 3 digits
	mov	bl,10
	div	bl
	mov	bl,ah			;Remainder is next digit
	shrd	ecx,ebx,4
	aam				;Get last two digits
;Last two digits in ah:al
	ret

ZeroLowDigits:
	shr	ecx,16
	jmp	ConvHigh5

ZeroHighDigits:
	shr	ecx,12
	ret
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emfsqrt.asm ===
subttl	emfsqrt.asm - FSQRT instruction
	page
;*******************************************************************************
;emfsqrt.asm - FSQRT instruction
;	by Tim Paterson
;
;	 Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;	 All Rights Reserved
;
;Inputs:
;	edi = [CURstk]
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;A linear approximation of the square root function is used to get the
;intial value for Newton-Raphson iteration.  This approximation gives
;nearly 5-bit accuracy over the required input interval, [1,4).  The
;equation for the linear approximation of y = sqrt(x) is y = mx + b,
;where m is the slope (named SQRT_COEF) and b is the y-intercept (named
;SQRT_INTERCEPT).
;
;(The values for m and b were computed with Excel Solver in two passes: 
;the first pass computed them full precision, minimizing absolute error;
;the second computed only b after m was rounded to an 8-bit value.)
;
;The resulting values have the following maximum error:
;
;inp. value -->		1		 2.18972	3.82505
;----------------------------------------------------------------
;abs. err., full prec.	0.04544		-0.03233	0.04423
;abs. err., truncated	0.04544		-0.04546	0.04423
;
;The three input values shown represent the left end point, the maximum 
;error (derivative of absolute error == 0), and the right end point.  
;The right end point is not 4 because the approximation reaches 2.000
;at the value given--we abandon the linear approximation at that point
;and use that same value for all greater input values.	This linear
;approximation is computed with 8-bit operations, so truncations can
;add a negative error.  This increases maximum error only when it is
;already negative, as shown in the table.
;
;Each iteration of Newton-Raphson approximation more than doubles the
;number of bits of accuracy.  Suppose the current guess is A, and it has
;an absolute error of e (i.e., A+e or A-e is the root).  Then the absolute
;error after the next iteration is e^2/2A.  This error is always positive.
;However, the divide instruction truncates, which introduces an error
;that is always negative.  Sometimes a constant or rounding bit is added
;to balance the positive and negative errors.  The maximum possible error 
;is given in comments below for each iteration.  (Note that when we compute 
;the error from e^2/2A, A could be in the range 1 to 2--we use 1 to get
;max error.)  Remember that the binary point is to the RIGHT of the MSB
;when looking at these error numbers.


;SQRT_INTERCEPT is used when the binary point is to the right of the MSB.
;Multiplying it by 64K would put the binary point to the left of the MSB,
;so it must be divided by two to be aligned.
SQRT_INTERCEPT	equ	23185		; 0.70755 * 65536 / 2

;SQRT_COEF would have the binary point to the left of the MSB if multiplied
;by 256.  However, this would leave it with a leading zero, so we multiply
;it by two more to normalize it.
SQRT_COEF	equ	173		; 0.33789 * 256 * 2

SqrtSpcl:
	cmp	al,bTAG_DEN
	jz	SqrtDen
	cmp	al,bTAG_INF
	jnz	SpclDestNotDen
;Have infinity
	or	ah,ah			;Is it negative?
	js	ReturnIndefinite
SqrtRet:
	ret


MaxStartRoot:
;The first iteration is calculated as  (ax / bh) * 100H + bx.  The first 
;trial root in bx should be 10000H (which is too big).  But it's very
;easy to calculate (ax / 100H) * 100H + 10000H = ax.
	mov	bx,ax
	cmp	ax,-1			;Would subsequent DIV overflow?
	jb	FirstTrialRoot
;The reduced argument is so close to 4.0 that the 16-bit DIV instruction
;used in the next iteration would overflow.  If the argument is 4-A 
;then a guess of 2.0 is in error by approximately A/4.  [This is not
;an upper bound.  The error is a little by more than this by an
;addition with the magnitude of A^2.  This is an insignificant amount
;when A is small.]  This means that the first guess of 2.0 is quite
;accurate, and we'll use it to bypass some of the iteration steps. 
;This will eliminate the DIV overflow by skipping the DIV.
;
;One iteration is performed by: (Arg/Guess + Guess)/2.  When Guess = 2,
;this becomes (Arg/2 + 2)/2 = Arg/4 + 1.  We get Arg/2 just by assuming
;the binary point is one bit further left; then a single right shift is
;needed to get Arg/4.  By shifting in a 1 bit on the left, we account for
;adding 1 at the same time.  [Note that if Arg = 4 - A, then Arg/4 + 1
; = (4 - A)/4 + 1 = 1 - A/4 + 1 = 2 - A/4.  In other words, we just
;subtract out exactly what we estimate our error to be, A/4.]
;
;Since the upper 16 bits are 0FFFFH, A <= 2^-14, so error <= 2^-16 =
; +0.00001526, -0.
	mov	ebx,esi			;Return root in ebx
	sar	ebx,1			;Trial root = arg/2
	cmp	esi,ebx			;Will 32-bit division overflow?
	jb	StartThirdIteration	;No, our 32-bit guess is good
;Argument is really, really close to 4.0: with an initial trial root of
;2.0, max absolute error is 2^-32 = +2.328E-10, -0.  One trivial
;iteration will get us 65-bit accuracy, max abs. error = +2.71E-20, -0.
	mov	ebx,esi
	mov	eax,ecx			;65-bit root*2 in ebx:eax (MSB implied)
	shl	ecx,2			;ecx = low half*4
	jmp	RoundRoot

SqrtDen:
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal ;Is denormal exception masked?
	jnz	SqrtRet			;If not, quit

;******
EM_ENTRY eFSQRT
eFSQRT:
;******
	mov	eax,EMSEG:[edi].ExpSgn
	cmp	al,bTAG_ZERO
	jz	SqrtRet
	ja	SqrtSpcl
	or	ah,ah
	js	ReturnIndefinite
	mov	esi,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].lManLo
	sar	EMSEG:[edi].wExp,1	;Divide exponent by two
	mov	edi,0			;Extend mantissa
	jc	RootAligned		;If odd exponent, leave it normalized
	shrd	edi,ecx,1
	shrd	ecx,esi,1
	shr	esi,1			;Denormalize, extending into edi
RootAligned:
;esi:ecx:edi has mantissa, 2 MSBs are left of binary point. Range is [1,4).
	shld	eax,esi,16		;Get high word of mantissa
	movzx	ebx,ah			;High byte to bl
;UNDONE:  MASM 6 bug!!
;UNDONE:  SQRT_COEF (=0AEH) get sign extended!!
	mov	dx,SQRT_COEF		;UNDONE
	imul	bx,dx			;UNDONE
;UNDONE imul	bx,SQRT_COEF		;Product in bx
;Multiply by SQRT_COEF causes binary point to shift left 1 bit.
	add	bx,SQRT_INTERCEPT	;5-bit approx. square root in bh
	jc	MaxStartRoot
;Max absolute error is +/- 0.04546
	div	bh			;See how close we are
	add	bh,al			;quotient + divisor (always sets CY)
FirstTrialRoot:
;Avoid RCR because it takes 9 clocks on 386.  Use SHRD (3 clocks) instead.
	mov	dl,1			;Need bit set
	shrd	bx,dx,1			;(quotient + divisor)/2
;bx has 9-bit approx. square root, normalized
;Max absolute error is +0.001033, -0.003906
	movzx	eax,si
	shld	edx,esi,16		;dx:ax has high half mantissa
	div	bx			;Test our approximation
	add	ebx,eax			;quotient + divisor
	shl	ebx,15			;Normalize (quotient + divisor)/2
;ebx has 17-bit approx. square root, normalized
;Max absolute error is +0.000007629, -0.00001526
;Add adjustment factor to center the error range at +/-0.00001144
	or	bh,20H			;Add in 0.000003815
StartThirdIteration:
	mov	edx,esi
	mov	eax,ecx
	div	ebx			;Test approximation
	stc				;Set bit for rounding (= 2.328E-10)
	adc	ebx,eax			;quotient + divisor + round bit
;Avoid RCR because it takes 9 clocks on 386.  Use SHRD (3 clocks) instead.
	mov	dl,1			;Need bit set
	shrd	ebx,edx,1		;(quotient + divisor)/2, rounded
;ebx has 32-bit approx. square root, normalized
;Max absolute error is +2.983E-10, -2.328E-10
	mov	edx,esi			;Last time we need high half
	mov	eax,ecx
	shld	ecx,edi,2		;ecx = low half*4, w/extension back in
	div	ebx			;Test approximation
	xchg	edi,eax			;Save 1st quotient, get extension
	mov	esi,eax
	or	esi,edx			;Any remainder?
	jz	HaveRoot		;Result is ebx:esi
	div	ebx			;edi:eax is 64-bit quotient
	add	ebx,edi			;quotient + divisor (always sets CY)
RoundRoot:
	mov	esi,eax			;Save low half root*2

;We have 65-bit root*2 in ebx:esi (eax==esi) (MSB is implied one).
;Max absolute error is +4.450E-20, -5.421E-20.	This maximum error 
;corresponds to just less than +/- 1 in the last (65th) bit.  
;	
;We have to determine if this error is positive or negative so
;we can tell if we rounded up or down (and set the status bit
;accordingly).	This is done by squaring the root and comparing the
;that result with the input.
;
;Squaring the sample root requires summing partial products:
; lo*lo + lo*hi + hi*lo + hi*hi.  lo*hi == hi*lo, so only one multiply
;is needed there.  The low half of lo*lo isn't relevant, we know it
;is non-zero.  Only the low few bits of hi*hi are needed, so we can use
;an 8-bit multiply there.  Since the MSB is implied, we need to add in
;two 1*lo products (shifted up 64 bits).  We only need bits 64 - 71 of
;the 130-bit product (the action happens near bit 65).	What we're 
;squaring is root*2, so the result is square*4.  ecx already has arg*4.

	mul	eax			;Low partial product of square
	mov	edi,edx			;Only high half counts
	mov	eax,ebx
	mul	esi			;Middle partial product of square
	add	eax,eax			;There are two of these
	adc	edx,edx
	add	edi,eax
	adc	edx,0			;edx:edi = lo*lo + lo*hi + hi*lo
	add	edx,esi			;lo*implied msb
	add	edx,esi			;lo*implied msb again
	mov	al,bl
	mul	al			;hi*hi - only low 8 bits are valid
	add	al,dl			;Bits 64 - 71 of product
	or	al,1			;Account for sticky bits 0 - 63
	sub	cl,al			;Compare product with argument
;Sign flag set if product is larger.  In this case, subtract 1 from root.
	add	cl,cl			;Set CY if sign is set
SubOneFromRoot:
	sbb	esi,0			;Reduce root if product was too big
	sbb	ebx,0
ShiftRoot:
;ebx:esi = root*2
;Absolute error is in the range (0, -5.421E-20).  This is equivalent to
;less than +1, -0 in last bit.	Thus LSB is correct rounding bit as 
;long as we set a sticky bit below it.
;
;Now divide root*2 by 2, preserving LSB as rounding bit and filling
;eax with 1's as sticky bits.
;
;Avoid RCR because it takes 9 clocks on 386.  Use SHRD (3 clocks) instead.
	mov	eax,-1
	shrd	eax,esi,1		;Move round bit to MSB of eax
	shrd	esi,ebx,1
	shrd	ebx,eax,1		;Shift 1 into MSB of ebx
StoreRoot:
	mov	edi,EMSEG:[CURstk]
	mov	EMSEG:[Result],edi
	mov	ecx,EMSEG:[edi].ExpSgn
;mantissa in ebx:esi:eax, exponent in high ebx, sign in bh bit 7
	jmp	EMSEG:[RoundMode]

HaveRoot:
;esi = eax = edx = 0
	cmp	edi,ebx			;Does quotient == divisor?
	jz	StoreRoot		;If so, we're done
;Quotient != divisor, so answer is not exact.  Since remainder is zero,
;the division was exact.  The only error in the result is e^2/2A, which
;is always positive.  We need the error to be only negative so that
;the rounding routine can properly tell if it rounded up.
	add	ebx,edi			;quotient + divisor (always sets CY)
	jmp	SubOneFromRoot		;Reduce root to ensure negative error
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emload.asm ===
subttl  emload.asm - FLD and FILD instructions
        page
;*******************************************************************************
;emload.asm - FLD and FILD instructions
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Purpose:
;       FLD and FILD instructions
;Inputs:
;	edi = [CURstk]
;	dseg:esi = pointer to memory operand
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


	PrevStackWrap	edi,LdStk	;Tied to PrevStackElem below

;*******
EM_ENTRY eFLDreg
eFLDreg:
;*******
;	edi = [CURstk]
;	esi = pointer to st(i) from instruction field

	PrevStackElem	edi,LdStk	;Point to receiving location
	cmp	EMSEG:[edi].bTag,bTAG_EMPTY	;Is it empty?
	jnz	FldErr
	mov	ecx,EMSEG:[esi].ExpSgn
	cmp	cl,bTAG_EMPTY
	jz	FldErr
	mov	ebx,EMSEG:[esi].lManHi
	mov	esi,EMSEG:[esi].lManLo
	mov	EMSEG:[CURstk],edi
	mov	EMSEG:[edi].lManLo,esi
	mov	EMSEG:[edi].lManHi,ebx
	mov	EMSEG:[edi].ExpSgn,ecx
	ret


;This is common code that stores a value into the stack after being loaded
;into registers by the appropriate routine.

	PrevStackWrap	edi,Load	;Tied to PrevStackElem below

FldCont:
;mantissa in ebx:esi, exp/sign in ecx
;edi = [CURstk]
	PrevStackElem	edi,Load	;Point to receiving location
	cmp	EMSEG:[edi].bTag,bTAG_EMPTY	;Is it empty?
	jnz	FldErr
	cmp	cl,bTAG_NAN		;Returning a NAN?
	jz	FldNAN
SaveStack:
	mov	EMSEG:[CURstk],edi
	mov	EMSEG:[edi].lManLo,esi
	mov	EMSEG:[edi].lManHi,ebx
	mov	EMSEG:[edi].ExpSgn,ecx
	ret

FldErr:
	or	EMSEG:[SWcc],C1		;Signal overflow
	mov	EMSEG:[CURerr],StackFlag;Kills possible denormal exception
Unsupported:
	call	ReturnIndefinite	;in emarith.asm
	jz	FldExit			;Unmasked, do nothing
	mov	EMSEG:[CURstk],edi	;Update top of stack
FldExit:
	ret

FldNAN:
;Is it a signaling NAN?
	test	ebx,1 shl 30		;Check for SNAN
	jnz	SaveStack		;If QNAN, just use it as result
	or	EMSEG:[CURerr],Invalid	;Flag the error
	or	ebx,1 shl 30		;Make it into a QNAN
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jnz	SaveStack		;If so, update with masked response
	ret


;****************
;Load Single Real
;****************

EM_ENTRY eFLD32
eFLD32:
	push	offset FldCont		;Return address
					;Fall into Load32Real
Load32Real:
;dseg:esi points to IEEE 32-bit real number
;On exit:
;	mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7, tag in cl
;preserves edi.

        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ecx,dseg:[esi]		;Get number
	mov	ebx,ecx			;Save copy of mantissa
	shl	ebx,8			;Normalize
	shr	ecx,7			;Bring exponent down
	and	ecx,0FFH shl 16		;Look at just exponent
	mov	ch,dseg:[esi+3]		;Get sign again
	jz	short ZeroOrDenorm32	;Exponent is zero
	xor	esi,esi			;Zero out the low bits
	or	ebx,1 shl 31		;Set implied bit
	cmp	ecx,SexpMax shl 16
	jge	NANorInf		;Max exp., must be NAN or Infinity
	add	ecx,(TexpBias-SexpBias) shl 16	;Change to extended format bias
	mov	cl,bTAG_SNGL
	ret

ZeroOrDenorm32:
;Exponent is zero. Number is either zero or denormalized
	xor	esi,esi			;Zero out the low bits
	and	ebx,not (1 shl 31)	;Keep just mantissa
	jnz	Norm32
	mov	cl,bTAG_ZERO
	ret

Norm32:
	add	ecx,(TexpBias-SexpBias+1-31) shl 16	;Fix up bias
	jmp	FixDenorm


NANorInf:
;Shared by single and double real
	and	ecx,bSign shl 8		;Save only sign in ch
	or	ecx,TexpMax shl 16 + bTAG_NAN	;Max exp.
	cmp	ebx,1 shl 31		;Only 1 bit set means infinity
	jnz	@F
	or	esi,esi
	jnz	@F
	mov	cl,bTAG_INF
@@:
	ret

;****************
;Load Double Real
;****************

EM_ENTRY eFLD64
eFLD64:
	push	offset FldCont		;Return address
					;Fall into Load64Real
Load64Real:
;dseg:esi points to IEEE 64-bit real number
;On exit:
;	mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7, tag in cl
;preserves edi.

        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ecx,dseg:[esi+4]		;Get sign, exp., and high mantissa
	mov	ebx,ecx			;Save copy of mantissa
	shr	ecx,4			;Bring exponent down
	and	ecx,7FFH shl 16		;Look at just exponent
	mov	ch,dseg:[esi+7]		;Get sign again
	mov	esi,dseg:[esi]		;Get low 32 bits of op
	jz	short ZeroOrDenorm64	;Exponent is zero
	shld	ebx,esi,31-20
	shl	esi,31-20		;Normalize
	or	ebx,1 shl 31		;Set implied bit
	cmp	ecx,DexpMax shl 16
	jge	NANorInf		;Max exp., must be NAN or Infinity
	add	ecx,(TexpBias-DexpBias) shl 16	;Change to extended format bias
SetNormTag:
	or	esi,esi			;Any bits in low half?
.erre	bTAG_VALID eq 1
.erre	bTAG_SNGL eq 0
	setnz   cl                      ;if low half==0 then cl=0 else cl=1
	ret

ZeroOrDenorm64:
;Exponent is zero. Number is either zero or denormalized
	and	ebx,0FFFFFH		;Keep just mantissa
	jnz	ShortNorm64		;Are top 20 bits zero?
	or	esi,esi			;Are low 32 bits zero too?
	jnz	LongNorm64
	mov	cl,bTAG_ZERO
	ret

LongNorm64:
	xchg	ebx,esi			;Shift up 32 bits
	sub	ecx,32 shl 16		;Correct exponent
ShortNorm64:
	add	ecx,(TexpBias-DexpBias+12-31) shl 16	;Fix up bias
FixDenorm:
	or	EMSEG:[CURerr],Denormal	;Set Denormal Exception
	bsr	edx,ebx			;Scan for MSB
;Bit number in edx ranges from 0 to 31
	mov	cl,dl
	not	cl			;Convert bit number to shift count
	shld	ebx,esi,cl
	shl	esi,cl
	shl	edx,16			;Move exp. adjustment to high end
	add	ecx,edx			;Adjust exponent
	jmp	SetNormTag


;******************
;Load Short Integer
;******************

EM_ENTRY eFILD16
eFILD16:
	push	offset FldCont		;Return address
					;Fall into Load16Int
Load16Int:
;dseg:esi points to 16-bit integer
;On exit:
;	mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7, tag in cl
;preserves edi.

        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ax,dseg:[esi]
NormInt16:
	xor	esi,esi			;Extend with zero
	cwd				;extend sign through dx
	xor	ax,dx
	sub	ax,dx			;Take ABS() of integer
	bsr	cx,ax			;Find MSB
	jz	ZeroInt
;Bit number in cx ranges from 0 to 15
	not	ecx			;Convert to shift count
	shl	eax,cl			;Normalize
	not	ecx
.erre	TexpBias eq 0
	shl	ecx,16			;Move exponent to high half
	mov	ch,dh			;Set sign
	mov	ebx,eax			;Mantissa to ebx
	mov	cl,bTAG_SNGL
	ret

ZeroInt:
	xor	ebx,ebx
	mov	ecx,ebx
	mov	cl,bTAG_ZERO
	ret


;******************
;Load Long Integer
;******************

EM_ENTRY eFILD32
eFILD32:
	push	offset FldCont		;Return address
					;Fall into Load32Int
Load32Int:
;dseg:esi points to 32-bit integer
;On exit:
;	mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7, tag in cl
;preserves edi.

        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	eax,dseg:[esi]
	xor	esi,esi			;Extend with zero
	or	eax,eax			;It it zero?
	jz	ZeroInt
	cdq				;extend sign through edx
	xor	eax,edx
	sub	eax,edx			;Take ABS() of integer
	mov	ebx,eax			;Mantissa to ebx
;BSR uses 3 clocks/bit, so speed it up by checking the top half
;This saves 36 clocks on 386 (42 on 486sx)
;Cost is 13 clocks on 386 if high word isn't zero (5 on 486sx)
.erre	TexpBias eq 0
	xor	eax,eax			;Initialize exponent
	cmp	ebx,0FFFFH		;Upper bits zero?
	ja	@F
	shl	ebx,16
	sub	eax,16
@@:
	bsr	ecx,ebx			;Find MSB
	add	eax,ecx			;Compute expoment
	not	cl			;Convert bit number to shift count
	shl	ebx,cl			;Normalize
	shrd	ecx,eax,16		;Move exponent to high half of ecx
	mov	ch,dh			;Set sign
	mov	cl,bTAG_SNGL
	ret


;*****************
;Load Quad Integer
;*****************

EM_ENTRY eFILD64
eFILD64:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ebx,dseg:[esi+4]		;Get high 32 bits
	mov	eax,ebx			;Make copy of sign
	mov	esi,dseg:[esi]		;Get low 32 bits
	mov	ecx,ebx
	or	ecx,esi			;Is it zero?
	jz	ZeroQuad
NormQuadInt:
;Entry point from eFBLD
;eax bit 31 = sign
;ebx:esi = integer
;edi = [CURstk]
.erre	TexpBias eq 0
	mov     ax,32                   ;Initialize exponent
	or	ebx,ebx			;Check sign
	jz	LongNormInt
	jns	FindBit
	not	ebx
	neg	esi			;CY set if non-zero
	sbb	ebx,-1			;Add one if esi == 0
	jnz	FindBit			;Check for high bits zero
LongNormInt:
	xchg	ebx,esi			;Normalize 32 bits
	xor     ax,ax                   ;Reduce exponent by 32
FindBit:
;BSR uses 3 clocks/bit, so speed it up by checking the top half
;This saves 35 clocks on 386 (41 on 486sx)
;Cost is 11 clocks on 386 if high word isn't zero (4 on 486sx)
	cmp	ebx,0FFFFH		;Upper bits zero?
	ja	@F
	shld	ebx,esi,16
	shl	esi,16
	sub	eax,16
@@:
	bsr	ecx,ebx			;Find MSB
	add	eax,ecx			;Compute expoment
	not	cl			;Convert bit number to shift count
	shld	ebx,esi,cl		;Normalize
	shl	esi,cl
	mov     ecx,eax                 ;Move sign and exponent to ecx
	rol     ecx,16                  ;Swap sign and exponent halves
	or	esi,esi			;Any bits in low half?
.erre	bTAG_VALID eq 1
.erre	bTAG_SNGL eq 0
	setnz   cl                      ;if low half==0 then cl=0 else cl=1
	jmp	FldCont

ZeroQuad:
	mov	cl,bTAG_ZERO
	jmp	FldCont


;****************
;Load Temp Real
;****************

	PrevStackWrap	edi,Ld80	;Tied to PrevStackElem below

EM_ENTRY eFLD80
eFLD80:
;This is not considered an "arithmetic" operation (like all the others are),
;so SNANs do NOT cause an exception.  However, unsupported formats do.
        mov     EMSEG:[PrevDataOff],esi	;Save operand pointer
	PrevStackElem	edi,Ld80	;Point to receiving location
	cmp	EMSEG:[edi].bTag,bTAG_EMPTY	;Is it empty?
	jnz	FldErr
LoadTempReal:
	mov	ebx,dseg:[esi+4]	;Get high half of mantissa
	mov	cx,dseg:[esi+8]		;Get exponent and sign
	mov	esi,dseg:[esi]		;Get low half of mantissa
	mov	eax,ecx	
	and	ch,7FH			;Mask off sign bit
	shl	ecx,16			;Move exponent to high end
	mov	ch,ah			;Restore sign
	jz	ZeroOrDenorm80
;Check for unsupported format: unnormals (MSB not set)
	or	ebx,ebx
	jns	Unsupported
	sub	ecx,(IexpBias-TexpBias) shl 16	;Correct the bias
	cmp	ecx,TexpMax shl 16
	jge	NANorInf80
SetupTag:
	or	esi,esi			;Any bits in low half?
.erre	bTAG_VALID eq 1
.erre	bTAG_SNGL eq 0
	setnz   cl                      ;if low half==0 then cl=0 else cl=1
	jmp	SaveStack

NANorInf80:
	mov	cl,bTAG_NAN
	cmp	ebx,1 shl 31		;Only 1 bit set means infinity
	jnz	SaveStack
	or	esi,esi
	jnz	SaveStack
	mov	cl,bTAG_INF
	jmp	SaveStack

ZeroOrDenorm80:
;Exponent is zero. Number is either zero or denormalized
	or	ebx,ebx
	jnz	ShortNorm80		;Are top 32 bits zero?
	or	esi,esi			;Are low 32 bits zero too?
	jnz	LongNorm80
	mov	cl,bTAG_ZERO
	jmp	SaveStack

;This code accepts and works correctly with pseudo-denormals (MSB already set)
LongNorm80:
	xchg	ebx,esi			;Shift up 32 bits
	sub	ecx,32 shl 16		;Correct exponent
ShortNorm80:
	add	ecx,(TexpBias-IexpBias+1-31) shl 16	;Fix up bias
	bsr	edx,ebx			;Scan for MSB
;Bit number in edx ranges from 0 to 31
	mov	cl,dl
	not	cl			;Convert bit number to shift count
	shld	ebx,esi,cl
	shl	esi,cl
	shl	edx,16			;Move exp. adjustment to high end
	add	ecx,edx			;Adjust exponent
	jmp	SetUpTag
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emftran.asm ===
subttl  emftran.asm - Transcendental instructions
	page
;*******************************************************************************
;	 Copyright (c) Microsoft Corporation 1991
;	 All Rights Reserved
;
;emftran.asm - Transcendental instructions
;	by Tim Paterson
;
;Purpose:
;	F2XM1, FPATAN, FYL2X, FYL2XP1 instructions
;Inputs:
;	edi = [CURstk]
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;********************* Polynomial Coefficients *********************

;These polynomial coefficients were all taken from "Computer Approximations"
;by J.F. Hart (reprinted 1978 w/corrections).  All calculations and 
;conversions to hexadecimal were done with a character-string calculator
;written in Visual Basic with precision set to 30 digits.  Once the constants
;were typed into this file, all transfers were done with cut-and-paste
;operations to and from the calculator to help eliminate any typographical
;errors.


tAtanPoly	label	word

;These constants are from Hart #5056: atan(x) = x * P(x^2) / Q(x^2),
;accurate to 20.78 digits over interval [0, tan(pi/12)].

	dd	4			;P() is degree four

;  Hart constant
;
;+.16241 70218 72227 96595 08	      E0
;Hex value:    0.A650A5D5050DE43A2C25A8C00 HFFFE
	dq	0A650A5D5050DE43AH
	dw	bTAG_VALID,0FFFEH-1

;+.65293 76545 29069 63960 675	      E1
;Hex value:    0.D0F0A714A9604993AC4AC49A0 H3
	dq	0D0F0A714A9604994H
	dw	bTAG_VALID,03H-1

;+.39072 57269 45281 71734 92684      E2
;Hex value:    0.9C4A507F16530AC3CDDEFA3DE H6
	dq	09C4A507F16530AC4H
	dw	bTAG_VALID,06H-1

;+.72468 55912 17450 17145 90416 9    E2
;Hex value:    0.90EFE6FB30465042CF089D1310 H7
	dq	090EFE6FB30465043H
	dw	bTAG_VALID,07H-1

;+.41066 29181 34876 24224 77349 62   E2
;Hex value:    0.A443E2004BB000B84A5154D44 H6
	dq	0A443E2004BB000B8H
	dw	bTAG_VALID,06H-1

	dd	4			;Q() is degree four

;  Hart constant
;
;+.15023 99905 56978 85827 4928	      E2
;Hex value:    0.F0624CD575B782643AFB912D0 H4
	dq	0F0624CD575B78264H
	dw	bTAG_VALID,04H-1

;+.59578 42201 83554 49303 22456      E2
;Hex value:    0.EE504DDC907DEAEB7D7473B82 H6
	dq	0EE504DDC907DEAEBH
	dw	bTAG_VALID,06H-1

;+.86157 32305 95742 25062 42472      E2
;Hex value:    0.AC508CA5E78E504AB2032E864 H7
	dq	0AC508CA5E78E504BH
	dw	bTAG_VALID,07H-1

;+.41066 29181 34876 24224 84140 84   E2
;Hex value:    0.A443E2004BB000B84F542813C H6
	dq	0A443E2004BB000B8H
	dw	bTAG_VALID,06H-1


;tan(pi/12) = tan(15 deg.) = 2 - sqrt(3) 
;= 0.26794 91924 31122 70647 25536 58494 12763	;From Hart appendix
;Hex value:    0.8930A2F4F66AB189B517A51F2 HFFFF
Tan15Hi		equ	08930A2F4H
Tan15Lo		equ	0F66AB18AH
Tan15exp	equ	0FFFFH-1

;1/tan(pi/6) = sqrt(3) = 1.73205 08075 68877 29352 74463 41505 87236	;From Hart appendix
;Hex value:    0.DDB3D742C265539D92BA16B8 H1
Sqrt3Hi		equ	0DDB3D742H
Sqrt3Lo		equ	0C265539EH
Sqrt3exp	equ	01H-1

;pi = +3.14159265358979323846264338328
;Hex value:    0.C90FDAA22168C234C4C6628B8 H2
PiHi		equ	0C90FDAA2H
PiLo		equ	02168C235H
PiExp		equ	02H-1

;3*pi = +9.42477796076937971538793014984
;Hex value:    0.96CBE3F9990E91A79394C9E890 H4
XThreePiHi	equ	096CBE3F9H
XThreePiMid	equ	0990E91A7H
XThreePiLo	equ	090000000H
ThreePiExp	equ	04H-1


;This is a table of multiples of pi/6.  It is used to adjust the
;final result angle after atan().  Derived from Hart appendix
;pi/180 = 0.01745 32925 19943 29576 92369 07684 88612
;
;When the reduced argument for atan() is very small, these correction
;constants simply become the result.  These constants have all been
;rounded to nearest, but the user may have selected a different rounding
;mode.  The tag byte is not needed for these constants, so its space
;is used to indicate if it was rounded.  To determine if a constant 
;was rounded, 7FH is subtracted from this flag; CY set means it was
;rounded up.

RoundedUp	equ	040H
RoundedDown	equ	0C0H

tAtanPiFrac	label	dword
;pi/2 = +1.57079632679489661923132169163
;Hex value:    0.C90FDAA22168C234C4C6628B0 H1
	dq	0C90FDAA22168C235H
	dw	RoundedUp,01H-1

;2*pi/3 = +2.09439510239319549230842892218
;Hex value:    0.860A91C16B9B2C232DD997078 H2
	dq	0860A91C16B9B2C23H
	dw	RoundedDown,02H-1

;none
	dd	0,0,0

;pi/6 = +0.523598775598298873077107230544E0
;Hex value:    0.860A91C16B9B2C232DD99707A H0
	dq	0860A91C16B9B2C23H
	dw	RoundedDown,00H-1

;pi/2 = +1.57079632679489661923132169163
;Hex value:    0.C90FDAA22168C234C4C6628B0 H1
	dq	0C90FDAA22168C235H
	dw	RoundedUp,01H-1

;pi/3 = +1.04719755119659774615421446109
;Hex value:    0.860A91C16B9B2C232DD997078 H1
	dq	0860A91C16B9B2C23H
	dw	RoundedDown,01H-1

;pi = +3.14159265358979323846264338328
;Hex value:    0.C90FDAA22168C234C4C6628B8 H2
	dq	0C90FDAA22168C235H
	dw	RoundedUp,02H-1

;5*pi/6 = +2.61799387799149436538553615272
;Hex value:    0.A78D3631C681F72BF94FFCC96 H2
	dq	0A78D3631C681F72CH
	dw	RoundedUp,02H-1

;*********************

tExpPoly	label	word

;These constants are from Hart #1324: 2^x - 1 = 
; 2 * x * P(x^2) / ( Q(x^2) - x * P(x^2) )
;accurate to 21.54 digits over interval [0, 0.5].

	dd	2			;P() is degree two

;  Hart constant
;
;+.60613 30790 74800 42574 84896 07	E2
;Hex value:    0.F27406FCF405189818F68BB78 H6
	dq	0F27406FCF4051898H
	dw	bTAG_VALID,06H-1

;+.30285 61978 21164 59206 24269 927	E5
;Hex value:    0.EC9B3D5414E1AD0852E432A18 HF
	dq	0EC9B3D5414E1AD08H
	dw	bTAG_VALID,0FH-1

;+.20802 83036 50596 27128 55955 242	E7
;Hex value:    0.FDF0D84AC3A35FAF89A690CC4 H15
	dq	0FDF0D84AC3A35FB0H
	dw	bTAG_VALID,015H-1

	dd	3			;Q() is degree three.  First 
					;coefficient is 1.0 and is not listed.
;  Hart constant
;
;+.17492 20769 51057 14558 99141 717	E4
;Hex value:    0.DAA7108B387B776F212ECFBEC HB
	dq	0DAA7108B387B776FH
	dw	bTAG_VALID,0BH-1

;+.32770 95471 93281 18053 40200 719	E6
;Hex value:    0.A003B1829B7BE85CC81BD5309 H13
	dq	0A003B1829B7BE85DH
	dw	bTAG_VALID,013H-1

;+.60024 28040 82517 36653 36946 908	E7
;Hex value:    0.B72DF814E709837E066855BDD H17
	dq	0B72DF814E709837EH
	dw	bTAG_VALID,017H-1


;sqrt(2) = 1.41421 35623 73095 04880 16887 24209 69808	;From Hart appendix
;Hex value:    0.B504F333F9DE6484597D89B30 H1
Sqrt2Hi		equ	0B504F333H
Sqrt2Lo		equ	0F9DE6484H
Sqrt2Exp	equ	01H-1

;sqrt(2) - 1 = +0.4142135623730950488016887242E0
;Hex value:    0.D413CCCFE779921165F626CC4 HFFFF
Sqrt2m1Hi	equ	0D413CCCFH
Sqrt2m1Lo	equ	0E7799211H
XSqrt2m1Lo	equ	060000000H
Sqrt2m1Exp	equ	0FFFFH-1

;2 - sqrt(2) = +0.5857864376269049511983112758E0
;Hex value:    0.95F619980C4336F74D04EC9A0 H0
TwoMinusSqrt2Hi	equ	095F61998H
TwoMinusSqrt2Lo	equ	00C4336F7H
TwoMinusSqrt2Exp equ	00H-1

;*********************

tLogPoly	label	dword

;These constants are derived from Hart #2355: log2(x) = z * P(z^2) / Q(z^2),
; z = (x+1) / (x-1) accurate to 19.74 digits over interval 
;[1/sqrt(2), sqrt(2)].  The original Hart coefficients were for log10(); 
;the P() coefficients have been scaled by log2(10) to compute log2().
;
;log2(10) = 3.32192 80948 87362 34787 03194 29489 39017	;From Hart appendix

	dd	3			;P() is degree three

;  Original Hart constant	 	Scaled value
;
;+.18287 59212 09199 9337	 E0	+0.607500660543248917834110566373E0
;Hex value:    0.9B8529CD54E72022A12BAEC53 H0
	dq	09B8529CD54E72023H
	dw	bTAG_VALID,00H-1

;-.41855 96001 31266 20633	 E1	-13.9042489506087332809657007634
;Hex value:    0.DE77CDBF64E8C53F0DCD458D0 H4
	dq	0DE77CDBF64E8C53FH
	dw	bSign shl 8 + bTAG_VALID,04H-1

;+.13444 58152 27503 62236	 E2	+44.6619330844279438866067340334
;Hex value:    0.B2A5D1C95708A0C9FE50F6F97 H6
	dq	0B2A5D1C95708A0CAH
	dw	bTAG_VALID,06H-1

;-.10429 11213 72526 69497 44122 E2	-34.6447606134704282123622236943
;Hex value:    0.8A943C20526AE439A98B30F6A H6
	dq	08A943C20526AE43AH
	dw	bSign shl 8 + bTAG_VALID,06H-1


	dd	3			;Q() is degree three.  First 
					;coefficient is 1.0 and is not listed.
;  Hart constant
;
;-.89111 09060 90270 85654	 E1
;Hex value:    0.8E93E7183AA998D74F45CDFF0 H4
	dq	08E93E7183AA998D7H
	dw	bSign shl 8 + bTAG_VALID,04H-1

;+.19480 96618 79809 36524 155	 E2
;Hex value:    0.9BD904CCFEE118D4BEF319716 H5
	dq	09BD904CCFEE118D5H
	dw	bTAG_VALID,05H-1

;-.12006 95907 02006 34243 4218	 E2
;Hex value:    0.C01C811D2EC1B5806304B1858 H4
	dq	0C01C811D2EC1B580H
	dw	bSign shl 8 + bTAG_VALID,04H-1

;Log2(e) = 1.44269 50408 88963 40735 99246 81001 89213	;From Hart appendix
;Hex value:    0.B8AA3B295C17F0BBBE87FED04 H1
Log2OfEHi	equ	0B8AA3B29H
Log2OfELo	equ	05C17F0BCH
Log2OfEexp	equ	01H-1


;********************* Generic polynomial evaluation *********************
;
;EvalPoly, EvalPolyAdd, EvalPolySetup, Eval2Poly
;
;Inputs:
;	ebx:esi,ecx = floating point number, internal format
;	edi = pointer to polynomial degree and coefficients
;Outputs:
;	result in ebx:esi,ecx
;	edi incremented to start of last coefficient in list
;
;EvalPoly is the basic polynomial evaluator, using Horner's rule.  The
;polynomial pointer in edi points to a list: the first dword in the list
;is the degree of the polynomial (n); it is followed by the n+1 
;coefficients in internal (12-byte) format.  The argment for EvalPoly
;must be stored in the static FloatTemp in addition to being in
;registers.
;
;EvalPolyAdd is an alternate entry point into the middle of EvalPoly.
;It is used when the first coefficient is 1.0, so it skips the first
;multiplication.  It requires that the degree of the polynomial be
;already loaded into ebp.
;
;EvalPolySetup store a copy of the argument in the static ArgTemp,
;and stores the square of the argument in the static FloatTemp.  
;Then it falls into EvalPoly to evaluate the polynomial on the square.
;
;Eval2Poly evaluate two polynomials on its argument.  The first 
;polynomial is  x * P(x^2), and its result is left at [[CURstk]].
;The second polynomial is Q(x^2), and its result is left in registers.
;The most significant coefficient of Q() is 1.
;
;Polynomial evaluation uses a slight variation on the standard add
;and multiply routines.  PolyAddDouble and PolyMulDouble both check
;to see if the argument in registers (the current accumulation) is 
;zero.  The argument pointed to by edi is a coefficient and is never
;zero.
;
;In addition, the [RoundMode] and [ZeroVector] vectors are "trapped",
;i.e., redirected to special handlers for polynomial evaluation.
;[RoundMode] ordinarily points to the routine that handles the
;the current rounding mode and precision control; however, during
;polynomial evaluation, we always want full precision and round
;nearest.  The normal rounding routines also store their result
;at [[Result]], but we want the result left in registers.
;[ZeroVector] exists solely so polynomial evaluation can trap
;when AddDouble results of zero.  The normal response is to store
;a zero at [[Result]], but we need the zero left in registers.
;PolyRound and PolyZero handle these traps.


EvalPolySetup:
;Save x in ArgTemp
	mov	EMSEG:[ArgTemp].ExpSgn,ecx
	mov	EMSEG:[ArgTemp].lManHi,ebx
	mov	EMSEG:[ArgTemp].lManLo,esi
	mov	EMSEG:[RoundMode],offset PolyRound
	mov	EMSEG:[ZeroVector],offset PolyZero
	push	edi			;Save pointer to  polynomials
;op1 mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7
	mov	edx,ebx
	mov	edi,esi
	mov	eax,ecx
;op2 mantissa in edx:edi, exponent in high eax, sign in ah bit 7
	call	MulDoubleReg		;Compute x^2
;Save x^2 in FloatTemp
	mov	EMSEG:[FloatTemp].ExpSgn,ecx
	mov	EMSEG:[FloatTemp].lManHi,ebx
	mov	EMSEG:[FloatTemp].lManLo,esi
	pop	edi
EvalPoly:
;ebx:esi,ecx = arg to evaluate, also in FloatTemp
;edi = pointer to degree and list of coefficients.
	push	edi
	mov	eax,cs:[edi+4].ExpSgn
	mov	edx,cs:[edi+4].lManHi
	mov	edi,cs:[edi+4].lManLo
	call	MulDoubleReg		;Multiply arg by first coef.
	pop	edi
	mov	ebp,cs:[edi]		;Get polynomial degree
	add	edi,4+Reg87Len		;Point to second coefficient
	jmp	EvalPolyAdd

PolyLoop:
	push	ebp			;Save loop count
ifdef NT386
        mov	edi,YFloatTemp
else
	mov	edi,offset edata:FloatTemp
endif
        call	PolyMulDouble
	pop	ebp
	pop	edi
	add	di,Reg87Len
EvalPolyAdd:
	push	edi
	mov	eax,cs:[edi].ExpSgn
	mov	edx,cs:[edi].lManHi
	mov	edi,cs:[edi].lManLo
	cmp	cl,bTAG_ZERO		;Adding to zero?
	jz	AddToZero
	call	AddDoubleReg		;ebp preserved
ContPolyLoop:
	dec	ebp
	jnz	PolyLoop
	pop	edi
	ret

AddToZero:
;Number in registers is zero, so just return value from memory.
	mov	ecx,eax
	mov	ebx,edx
	mov	esi,edi
	jmp	ContPolyLoop


Eval2Poly:
	call	EvalPolySetup
	push	edi
ifdef NT386
        mov	edi,YArgTemp
else
	mov	edi,offset edata:ArgTemp
endif
	call	PolyMulDouble		;Multiply first result by argument
	pop	edi
;Save result of first polynomial at [[CURstk]]
	mov	edx,EMSEG:[CURstk]
	mov	EMSEG:[edx].ExpSgn,ecx
	mov	EMSEG:[edx].lManHi,ebx
	mov	EMSEG:[edx].lManLo,esi
;Load x^2 back into registers
	mov	ecx,EMSEG:[FloatTemp].ExpSgn
	mov	ebx,EMSEG:[FloatTemp].lManHi
	mov	esi,EMSEG:[FloatTemp].lManLo
;Start second polynomial evaluation
	add	edi,4+Reg87Len		;Point to coefficient
	mov	ebp,cs:[edi-4]		;Get polynomial degree
	jmp	EvalPolyAdd


PolyRound:
;This routine handles all rounding during polynomial evaluation.
;It performs 64-but round nearest, with result left in registers.
;
;Inputs:
;	mantissa in ebx:esi:eax, exponent in high ecx, sign in ch bit 7
;Outputs:
;	same, plus tag in cl.
;
;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.  This rounding rule is implemented by adding RoundBit-1
;(7F..FFH), setting CY if round up.  
;
;This routine needs to be reversible in case we're at the last step
;in the polynomial and final rounding uses a different rounding mode.
;We do this by copying the LSB of esi into al.  While the rounding is 
;reversible, you can't tell if the answer was exact.

	mov	edx,esi
	and	dl,1			;Look at LSB
	or	al,dl			;Set LSB as sticky bit
	add	eax,(1 shl 31)-1	;Sum LSB & sticky bits--CY if round up
	adc	esi,0
	adc	ebx,0
	jc	PolyBumpExponent	;Overflowed, increment exponent
	or      esi,esi			;Any bits in low half?
.erre   bTAG_VALID eq 1
.erre   bTAG_SNGL eq 0
	setnz   cl			;if low half==0 then cl=0 else cl=1
	ret

PolyBumpExponent:
	add	ecx,1 shl 16		;Mantissa overflowed, bump exponent
	or	ebx,1 shl 31		;Set MSB
	mov     cl,bTAG_SNGL
PolyZero:
;Enter here when result is zero
	ret

;*******************************************************************************

;FPATAN instruction

;Actual instruction entry point is in emarith.asm

tFpatanDisp	label	dword		;Source (ST(0))	Dest (*[di] = ST(1))
	dd	AtanDouble		;single		single
	dd	AtanDouble		;single		double
	dd	AtanZeroDest		;single		zero
	dd	AtanSpclDest		;single		special
	dd	AtanDouble		;double		single
	dd	AtanDouble		;double		double
	dd	AtanZeroDest		;double		zero
	dd	AtanSpclDest		;double		special
	dd	AtanZeroSource		;zero		single
	dd	AtanZeroSource		;zero		double
	dd	AtanZeroDest		;zero		zero
	dd	AtanSpclDest		;zero		special
	dd	AtanSpclSource		;special	single
	dd	AtanSpclSource		;special	double
	dd	AtanSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	AtanTwoInf		;Two infinites

;Compute atan( st(1)/st(0) ).  Neither st(0) or st(1) are zero or
;infinity at this point.
;
;Argument reduction starts by dividing the smaller by the larger,
;ensuring that the result x is <= 1.  The absolute value of the quotient
;is used and the quadrant is fixed up later.  If x = st(0)/st(1), then 
;the final atan result is subtracted from pi/2 (and normalized for the
;correct range of -pi to +pi).  
;
;The range of x is further reduced using the formulas:
;	t = (x - k) / (1 + kx)
;	atan(x) = atan(k) + atan(t)
;
;Given that x <= 1, if we choose k = tan(pi/6) = 1/sqrt(3), then we
;are assured that t <= tan(pi/12) = 2 - sqrt(3), and
;for x >= tan(pi/12) = 2 - sqrt(3), t >= -tan(pi/12).
;Thus we can always reduce the argument to abs(t) <= tan(pi/12).
;
;Since k = 1/sqrt(3), it is convenient to multiply the numerator
;and denominator of t by 1/k, which gives
;t = (x/k - 1) / (1/k + x) = ( x*sqrt(3) - 1 ) / ( sqrt(3) + x ).
;This is the form found in Cody and Waite and in previous versions
;of the emulator.  It requires one each add, subtract, multiply, and
;divide.
;
;Hart has derived a simpler version of this formula:
;t = 1/k - (1/k^2 + 1) / (1/k + x) = sqrt(3) - 4 / ( sqrt(3) + x ).
;Note that this computation requires one each add, subtract, and
;divide, but no multiply.

;st(0) mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7
;[edi] points to st(1), where result is returned

AtanDouble:
	mov	EMSEG:[Result],edi
	mov	EMSEG:[RoundMode],offset PolyRound
	mov	EMSEG:[ZeroVector],offset PolyZero
	mov	ah,EMSEG:[edi].bSgn	;Sign of result
	mov	al,ch			;Affects quadrant of result
	and	al,bSign		;Zero other bits, used as flags
	push	eax			;Save flag
;First figure out which is larger
	push	offset AtanQuo		;Return address for DivDouble
	shld	edx,ecx,16		;Get exponent to ax
	cmp	dx,EMSEG:[edi].wExp	;Compare exponents
	jl	DivrDoubleSetFlag	;ST(0) is smaller, make it dividend
	jg	DivDouble		;   ...is bigger, make it divisor
;Exponents are equal, compare mantissas
	cmp	ebx,EMSEG:[edi].lManHi
	jb	DivrDoubleSetFlag	;ST(0) is smaller, make it dividend
	ja	DivDouble		;   ...is bigger, make it divisor
	cmp	esi,EMSEG:[edi].lManLo
	jbe	DivrDoubleSetFlag	;ST(0) is smaller, make it dividend
	jmp	DivDouble

TinyAtan:
;Come here if the angle was reduced to zero, or the divide resulted in
;unmasked underflow so that the quotient exponent was biased.
;Note that an angle of zero means reduction was performed, and the
;result will be corrected to a non-zero value.
	mov	dl,[esp]		;Get flag byte
	or	dl,dl			;No correction needed?
	jz	AtanSetSign		;Just return result of divide
	and	EMSEG:[CURerr],not Underflow
;Angle in registers is too small to affect correction amount.  Just
;load up correction angle instead of adding it in.
	add	dl,40H			;Change flags for correction lookup
	shr	dl,5-2			;Now in bits 2,3,4
	and	edx,7 shl 2
	mov	ebx,[edx+2*edx+tAtanPiFrac].lManHi
	mov	esi,[edx+2*edx+tAtanPiFrac].lManLo
	mov	ecx,[edx+2*edx+tAtanPiFrac].ExpSgn
	shrd	eax,ecx,8		;Copy rounding flag to high eax
	jmp	AtanSetSign

AtanQuo:
;Return here after divide.  Underflow flag is set only for "big underflow",
;meaning the (15-bit) exponent couldn't even be kept in 16 bits.  This can
;only happen dividing a denormal by one of the largest numbers.
;
;Rounded mantissa in ebx:esi:eax, exp/sign in high ecx
	test	EMSEG:[CURerr],Underflow;Did we underflow?
	jnz	TinyAtan
;Now compare quotient in ebx:esi,ecx with tan(pi/12) = 2 - sqrt(3)
	xor	cx,cx			;Use absolute value
	cmp	ecx,Tan15exp shl 16
	jg	AtnNeedReduce
	jl	AtnReduced
	cmp	ebx,Tan15Hi
	ja	AtnNeedReduce
	jb	AtnReduced
	cmp	esi,Tan15Lo
	jbe	AtnReduced
AtnNeedReduce:
	or	byte ptr [esp],20H	;Note reduction in flags on stack
;Compute t = sqrt(3) - 4 / ( sqrt(3) + x ).
	mov	eax,Sqrt3exp shl 16
	mov	edx,Sqrt3Hi
	mov	edi,Sqrt3Lo
	call	AddDoubleReg		;x + sqrt(3)
	mov	edi,esi
	mov	esi,ebx			;Mantissa in esi:edi
	mov	ebx,ecx			;ExpSgn to ebx
	mov	ecx,(2+TexpBias) shl 16
	mov	edx,1 shl 31
	xor	eax,eax			;edx:edi,eax = 4.0
;dividend mantissa in edx:eax, exponent in high ecx, sign in ch bit 7
;divisor mantissa in esi:edi, exponent in high ebx, sign in bh bit 7
	call	DivDoubleReg		;4 / ( x + sqrt(3) )
	not	ch			;Flip sign
	mov	eax,Sqrt3exp shl 16
	mov	edx,Sqrt3Hi
	mov	edi,Sqrt3Lo
	call	AddDoubleReg		;sqrt(3) - 4 / ( x + sqrt(3) )
;Result in ebx:esi,ecx could be very small (or zero) if arg was near tan(pi/6).
	cmp	cl,bTAG_ZERO
	jz	TinyAtan
AtnReduced:
;If angle is small, skip the polynomial. atan(x) = x when x - x^3/3 = x
;[or 1 - x^2/3 = 1], which happens when x < 2^-32.  This prevents underflow
;in computing x^2.
TinyAtanArg	equ	-32
	cmp	ecx,TinyAtanArg shl 16
	jl	AtanCorrection
	mov	edi,offset tAtanPoly
	call	Eval2Poly
	mov	edi,EMSEG:[CURstk]	;Point to first result
	call	DivDouble		;x * P(x^2) / Q(x^2)
AtanCorrection:
;Rounded mantissa in ebx:esi:eax, exp/sign in high ecx
;
;Correct sign and add fraction of pi to account for various angle reductions:
;
;    flag bit	   indicates		correction
;----------------------------------------------------
;	5	arg > tan(pi/12)	add pi/6
;	6	st(1) > st(0)		sub from pi/2
;	7	st(0) < 0		sub from pi
;
;This results in the following correction for the result R:
;
;bit  7 6 5	correction
;---------------------------
;     0 0 0	none
;     0 0 1	pi/6 + R
;     0 1 0	pi/2 - R
;     0 1 1	pi/3 - R
;     1 0 0	pi - R
;     1 0 1	5*pi/6 - R
;     1 1 0	pi/2 + R
;     1 1 1	2*pi/3 + R

	mov	dl,[esp]		;Get flag byte
	or	dl,dl			;No correction needed?
	jz	AtanSetSign
	add	dl,40H			;Set bit 7 for all -R cases

;This changes the meaning of the flag bits to the following:
;
;bit  7 6 5	correction
;---------------------------
;     0 0 0	pi/2 + R
;     0 0 1	2*pi/3 + R
;     0 1 0	none
;     0 1 1	pi/6 + R
;     1 0 0	pi/2 - R
;     1 0 1	pi/3 - R
;     1 1 0	pi - R
;     1 1 1	5*pi/6 - R

	xor	ch,dl			;Flip sign bit in cases 4 - 7
	shr	dl,5-2			;Now in bits 2,3,4
	and	edx,7 shl 2
	mov	eax,[edx+2*edx+tAtanPiFrac].ExpSgn
	mov	edi,[edx+2*edx+tAtanPiFrac].lManLo
	mov	edx,[edx+2*edx+tAtanPiFrac].lManHi
	call	AddDoubleReg		;Add in correction angle
AtanSetSign:
	pop	edx			;Get flags again
	mov	ch,dh			;Set sign to original ST(1)
;Rounded mantissa in ebx:esi:eax, exp/sign in ecx
	jmp     TransUnround


;***
AtanSpclDest:
	mov	al,EMSEG:[edi].bTag	;Pick up tag
;	cmp     cl,bTAG_INF		;Is argument infinity?
	cmp     al,bTAG_INF		;Is argument infinity?
	jnz	SpclDest		;In emarith.asm
AtanZeroSource:
;Dividend is infinity or divisor is zero.  Return pi/2 with 
;same sign as dividend.
	mov	ecx,(PiExp-1) shl 16 + bTAG_VALID	;Exponent for pi/2
PiMant:
;For storing multiples of pi.  Exponent/tag is in ecx.
	mov	ch,EMSEG:[edi].bSgn	;Get dividend's sign
	mov	ebx,XPiHi
	mov	esi,XPiMid
	mov	eax,XPiLo
;A jump through [TransRound] is only valid if the number is known not to
;underflow.  Unmasked underflow requires [RoundMode] be set.
	jmp	EMSEG:[TransRound]

;***
AtanSpclSource:
	cmp	cl,bTAG_INF		;Scaling by infinity?
	jnz	SpclSource		;in emarith.asm
AtanZeroDest:
;Divisor is infinity or dividend is zero.  Return zero for +divisor, 
;pi for -divisor.  Result sign is same is dividend.
	or	ch,ch			;Check divisor's sign
	mov	ecx,PiExp shl 16 + bTAG_VALID	;Exponent for pi
	js	PiMant			;Store pi
;Result is zero
	mov	EMSEG:[edi].lManHi,0
	mov	EMSEG:[edi].lManLo,0
	mov	EMSEG:[edi].wExp,0
	mov	EMSEG:[edi].bTAG,bTAG_ZERO
	ret

;***
AtanTwoInf:
;Return pi/4 for +infinity divisor, 3*pi/4 for -infinity divisor.
;Result sign is same is dividend infinity.
	or	ch,ch			;Check divisor's sign
	mov	ecx,(PiExp-2) shl 16 + bTAG_VALID	;Exponent for pi/4
	jns	PiMant			;Store pi/4
	mov	ecx,(ThreePiExp-2) shl 16 + bTAG_VALID	;Exponent for 3*pi/4
	mov	ch,EMSEG:[edi].bSgn	;Get dividend's sign
	mov	ebx,XThreePiHi
	mov	esi,XThreePiMid
	mov	eax,XThreePiLo
;A jump through [TransRound] is only valid if the number is known not to
;underflow.  Unmasked underflow requires [RoundMode] be set.
	jmp	EMSEG:[TransRound]

;*******************************************************************************

ExpSpcl:
;Tagged special
	cmp	cl,bTAG_DEN
	jz	ExpDenorm
	cmp	cl,bTAG_INF
        mov     al, cl
	jnz	SpclDestNotDen		;Check for Empty or NAN
;Have infinity, check its sign.  
;Return -1 for -infinity, no change if +infinity
	or	ch,ch			;Check sign
	jns	ExpRet			;Just return the +inifinity
	mov	EMSEG:[edi].lManLo,0
	mov	EMSEG:[edi].lManHi,1 shl 31
	mov	EMSEG:[edi].ExpSgn,bSign shl 8 + bTAG_SNGL	;-1.0 (exponent is zero)
	ret

ExpDenorm:
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is denormal exception masked?
	jnz	ExpCont			;Yes, continue
ExpRet:
	ret

EM_ENTRY eF2XM1
eF2XM1:
;edi = [CURstk]
	mov	ecx,EMSEG:[edi].ExpSgn
	cmp	cl,bTAG_ZERO
	jz	ExpRet			;Return same zero
	ja	ExpSpcl
ExpCont:

;The input range specified for the function is (-1, +1).  The polynomial 
;used for this function is valid only over the range [0, +0.5], so range
;reduction is needed.  Range reduction is based on the identity:
;
;  2^(a+b) = 2^a * 2^b
;
;1.0 or 0.5 can be added/subtracted from the argument to bring it into
;range.  We calculate 2^x - 1 with a polynomial, and then adjust the
;result according to the amount added or subtracted, as shown in the table:
;
;Arg range	Adj	Polynomial result	Required result, 2^x - 1
;
; (-1, -0.5]	+1	P = 2^(x+1) - 1		(P - 1)/2
;
; (-0.5, 0)	+0.5	P = 2^(x+0.5) - 1	P * sqrt(2)/2 + (sqrt(2)/2 - 1)
;
; (0, 0.5)	0	P = 2^x - 1		P
;
; [0.5, 1)	-0.5	P = 2^(x-0.5) - 1	P * sqrt(2) + (sqrt(2)-1)
;
;Since the valid input range does not include +1.0 or -1.0, and zero is
;handled separately, the precision exception will always be set.

	mov	EMSEG:[Result],edi
	mov	EMSEG:[RoundMode],offset PolyRound
	mov	EMSEG:[ZeroVector],offset PolyZero
	push	offset TransUnround		;Always exit through here
	mov	ebx,EMSEG:[edi].lManHi
	mov	esi,EMSEG:[edi].lManLo
;Check for small argument, so that x^2 does not underflow.  Note that 
;e^x = 1+x for small x, where small x means  x + x^2/2 = x  [or 1 + x/2 = 1], 
;which happens when x < 2^-64, so 2^x - 1 = x * ln(2) for small x.
TinyExpArg	equ	-64
	cmp	ecx,TinyExpArg shl 16
	jl	TinyExp
	cmp	ecx,-1 shl 16 + bSign shl 8	;See if positive, < 0.5
	jl	ExpReduced
;Argument was not in range (0, 0.5), so we need some kind of reduction
	or	ecx,ecx			;Exp >= 0 means arg >= 1.0 --> too big
;CONSIDER: this returns through TransUnround which restores the rounding
;vectors, but it also randomly rounds the result becase eax is not set.
	jge	ExpRet			;Give up if arg out of range
;We're going to need to add/subtract 1.0 or 0.5, so load up the constant
	mov	edx,1 shl 31
	xor	edi,edi
	mov	eax,-1 shl 16 + bSign shl 8	;edx:edi,eax = -0.5
	mov	ebp,offset ExpReducedMinusHalf
	or	ch,ch			;If it's positive, must be [0.5, 1)
	jns	ExpReduction
	xor	ah,ah			;edx:edi,eax = +0.5
	mov	ebp,offset ExpReducedPlusHalf
	cmp	ecx,eax			;See if abs(arg) >= 0.5
	jl	ExpReduction		;No, adjust by .5
	xor	eax,eax			;edx:edi,eax = 1.0
	mov	ebp,offset ExpReducedPlusOne
ExpReduction:
	call	AddDoubleReg		;Argument now in range [0, 0.5]
	cmp	cl,bTAG_ZERO		;Did reduction result in zero?
	jz	ExpHalf			;If so, must have been exactly 0.5
	push	ebp			;Address of reduction cleanup
ExpReduced:
	mov	edi,offset tExpPoly
	call	Eval2Poly
;2^x - 1 is approximated with 2 * x*P(x^2) / ( Q(x^2) - x*P(x^2) )
;Q(x^2) is in registers, P(x^2) is at [[CURstk]]
	mov	edi,EMSEG:[CURstk]
	mov	dx,bSign shl 8		;Subtract memory operand
;Note that Q() and P() have no roots over the input range
;(they will never be zero).
	call	AddDouble		;Q(x^2) - x*P(x^2)
	sub	ecx,1 shl 16		;Divide by two
	mov	edi,EMSEG:[CURstk]
	jmp	DivDouble		;2 * x*P(x^2) / ( Q(x^2) - x*P(x^2) )
;Returns to correct argument reduction correction routine or TransUnround

TinyExp:
;Exponent is very small (and was not reduced)
	mov	edx,cFLDLN2hi
	mov	edi,cFLDLN2lo
	mov	eax,cFLDLN2exp shl 16
;This could underflow (but not big time)
	jmp	MulDoubleReg		;Returns to TransUnround

ExpHalf:
;Argument of exactly 0.5 was reduced to zero.  Just return result.
	mov	ebx,Sqrt2m1Hi
	mov	esi,Sqrt2m1Lo
	mov	eax,XSqrt2m1Lo + 1 shl 31 - 1
	mov	ecx,Sqrt2m1Exp shl 16
	ret				;Exit through TransUnround

ExpReducedPlusOne:
;Correct result is (P - 1)/2
	sub	ecx,1 shl 16		;Divide by two
	mov	edx,1 shl 31
	xor	edi,edi
	mov	eax,-1 shl 16 + bSign shl 8	;edx:edi,eax = -0.5
	jmp	AddDoubleReg

ExpReducedPlusHalf:
;Correct result is P * sqrt(2)/2 - (1 - sqrt(2)/2)
	mov	edx,Sqrt2Hi
	mov	edi,Sqrt2Lo
	mov	eax,Sqrt2exp-1 shl 16	;sqrt(2)/2
	call	MulDoubleReg
	mov	edx,TwoMinusSqrt2Hi
	mov	edi,TwoMinusSqrt2Lo
	mov	eax,(TwoMinusSqrt2Exp-1) shl 16 + bSign shl 8	;(2-sqrt(2))/2
	jmp	AddDoubleReg

ExpReducedMinusHalf:
;Correct result is P * sqrt(2) + (sqrt(2)-1)
	mov	edx,Sqrt2Hi
	mov	edi,Sqrt2Lo
	mov	eax,Sqrt2exp shl 16
	call	MulDoubleReg
	mov	edx,Sqrt2m1Hi
	mov	edi,Sqrt2m1Lo
	mov	eax,Sqrt2m1Exp shl 16
	jmp	AddDoubleReg

;*******************************************************************************

;Dispatch table for log(x+1)
;
;One operand has been loaded into ecx:ebx:esi ("source"), the other is
;pointed to by edi ("dest").  
;
;Tag of source is shifted.  Tag values are as follows:

.erre	TAG_SNGL	eq	0	;SINGLE: low 32 bits are zero
.erre	TAG_VALID	eq	1
.erre	TAG_ZERO	eq	2
.erre	TAG_SPCL	eq	3	;NAN, Infinity, Denormal, Empty

;Any special case routines not found in this file are in emarith.asm

tFyl2xp1Disp	label	dword		;Source (ST(0))	Dest (*[di] = ST(1))
	dd	LogP1Double		;single		single
	dd	LogP1Double		;single		double
	dd	LogP1ZeroDest		;single		zero
	dd	LogP1SpclDest		;single		special
	dd	LogP1Double		;double		single
	dd	LogP1Double		;double		double
	dd	LogP1ZeroDest		;double		zero
	dd	LogP1SpclDest		;double		special
	dd	XorSourceSign		;zero		single
	dd	XorSourceSign		;zero		double
	dd	XorDestSign		;zero		zero
	dd	LogP1SpclDest		;zero		special
	dd	LogSpclSource		;special	single
	dd	LogSpclSource		;special	double
	dd	LogSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	LogTwoInf		;Two infinites


LogP1Double:
;st(0) mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7
;[edi] points to st(1), where result is returned
;
;This instruction is defined only for x+1 in the range [1/sqrt(2), sqrt(2)]
;The approximation used (valid over exactly this range) is
; log2(x) = z * P(z^2) / Q(z^2), z = (x-1) / (x+1), which is
; log2(x+1) = r * P(r^2) / Q(r^2), r = x / (x+2)
;
;We're not too picky about this range check because the function is simply
;"undefined" if out of range--EXCEPT, we're supposed to check for -1 and
;signal Invalid if less, -infinity if equal.
	or	ecx,ecx			;abs(x) >= 1.0?
	jge	LogP1OutOfRange		;Valid range is approx [-0.3, +0.4]
	mov	EMSEG:[Result],edi
	mov	EMSEG:[RoundMode],offset PolyRound
	mov	EMSEG:[ZeroVector],offset PolyZero
	mov	eax,1 shl 16		;Exponent of 1 for adding 2.0
	push	offset TotalLog		;Return address for BasicLog
;	jmp	BasicLog		;Fall into BasicLog
;.erre	BasicLog eq $

;BasicLog is used by eFYL2X and eFYL2XP1.
;eax has exponent and sign to add 1.0 or 2.0 to argument
;ebx:esi,ecx has argument, non-zero, tag not set
;ST has argument to take log2 of, minus 1.  (This is the actual argument
;of eFYL2XP1, or argument minus 1 of eFYL2X.)

BasicLog:
	mov	edx,1 shl 31
	xor	edi,edi			;edx:edi,eax = +1.0 or +2.0
	call	AddDoubleReg
	mov	edi,EMSEG:[CURstk]	;Point to x-1
	call	DivDouble		;Compute (x-1) / (x+1)
;Result in registers is z = (x-1)/(x+1).  For tiny z, ln(x) = 2*z, so
; log2(x) = 2 * log2(e) * z.  Tiny z is such that z + z^3/3 = z.
	cmp	ecx,-32 shl 16		;Smallest exponent to bother with
	jl	LogSkipPoly
	mov	edi,offset tLogPoly
	call	Eval2Poly
	mov	edi,EMSEG:[CURstk]	;Point to first result, r * P(r^2)
	jmp	DivDouble		;Compute r * P(r^2) / Q(r^2)

LogSkipPoly:
;Multiply r by 2 * log2(e)
	mov	edx,Log2OfEHi
	mov	edi,Log2OfELo
	mov	eax,(Log2OfEexp+1) shl 16
	jmp	MulDoubleReg

LogP1OutOfRange:
;Input range isn't valid, so we can return anything we want--EXCEPT, for
;numbers < -1 we must signal Invalid Operation, and Divide By Zero for
;-1.  Otherwise, we return an effective log of one by just leaving the
;second operand as the return value.
;
;Exponent in ecx >= 0  ( abs(x) >= 1 )
	or	ch,ch			;Is it positive?
	jns	LogP1Ret		;If so, skip it
	and	ecx,0FFFFH shl 16	;Look at exponent only: 0 for -1.0
	sub	ebx,1 shl 31		;Kill MSB
	or	ebx,esi
	or	ebx,ecx
	jnz	ReturnIndefinite	;Must be < -1.0
	jmp	DivideByMinusZero

LogP1Ret:
	ret
	
;***
LogP1ZeroDest:
	or	ch,ch			;Is it negative?
	jns	LogP1Ret		;If not, just leave it zero
	or	ecx,ecx			;abs(x) >= 1.0?
	jl	XorDestSign		;Flip sign of zero
;Argument is <= -1
	jmp	ReturnIndefinite	;Have 0 * log( <=0 )

;***
LogP1SpclDest:
	mov	al,EMSEG:[edi].bTag		;Pick up tag
	cmp	al,bTAG_INF		;Is argument infinity?
	jnz	SpclDest		;In emarith.asm
;Multiplying log(x+1) * infinity.
;If x > 0, return original infinity.
;If -1 <= x < 0, return infinity with sign flipped.
;If x < -1 or x == 0, invalid operation.
	cmp	cl,bTAG_ZERO
	jz	ReturnIndefinite
	or	ch,ch			;Is it positive?
	jns	LogP1Ret
	test	ecx,0FFFFH shl 16	;Is exponent zero?
	jl	XorDestSign
	jg	ReturnIndefinite
	sub	ebx,1 shl 31		;Kill MSB
	or	ebx,esi
	jnz	ReturnIndefinite	;Must be < -1.0
	jmp	XorDestSign

;***
LogSpclSource:
	cmp	cl,bTAG_INF		;Is argument infinity?
	jnz	SpclSource		;in emarith.asm
	or	ch,ch			;Is it negative infinity?
	js	ReturnIndefinite
	jmp	MulByInf

;***
LogTwoInf:
	or	ch,ch			;Is it negative infinity?
	js	ReturnIndefinite
	jmp	XorDestSign

;*******************************************************************************

;Dispatch table for log(x)
;
;One operand has been loaded into ecx:ebx:esi ("source"), the other is
;pointed to by edi ("dest").  
;
;Tag of source is shifted.  Tag values are as follows:

.erre	TAG_SNGL	eq	0	;SINGLE: low 32 bits are zero
.erre	TAG_VALID	eq	1
.erre	TAG_ZERO	eq	2
.erre	TAG_SPCL	eq	3	;NAN, Infinity, Denormal, Empty

;Any special case routines not found in this file are in emarith.asm

tFyl2xDisp	label	dword		;Source (ST(0))	Dest (*[di] = ST(1))
	dd	LogDouble		;single		single
	dd	LogDouble		;single		double
	dd	LogZeroDest		;single		zero
	dd	LogSpclDest		;single		special
	dd	LogDouble		;double		single
	dd	LogDouble		;double		double
	dd	LogZeroDest		;double		zero
	dd	LogSpclDest		;double		special
	dd	DivideByMinusZero	;zero		single
	dd	DivideByMinusZero	;zero		double
	dd	ReturnIndefinite	;zero		zero
	dd	LogSpclDest		;zero		special
	dd	LogSpclSource		;special	single
	dd	LogSpclSource		;special	double
	dd	LogSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	LogTwoInf		;Two infinites


LogDouble:
;st(0) mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7
;[edi] points to st(1), where result is returned
;
;Must reduce the argument to the range [1/sqrt(2), sqrt(2)]
	or	ch,ch			;Is it positive?
	js	ReturnIndefinite	;Can't take log of negative number
	mov	EMSEG:[Result],edi
	mov	EMSEG:[RoundMode],offset PolyRound
	mov	EMSEG:[ZeroVector],offset PolyZero
	shld	eax,ecx,16		;Save exponent in ax as int part of log2
	xor	ecx,ecx			;Zero exponent: 1 <= x < 2
	cmp	ebx,Sqrt2Hi		;x > sqrt(2)?
	jb	LogReduced
	ja	LogReduceOne
	cmp	esi,Sqrt2Lo
	jb	LogReduced
LogReduceOne:
	sub	ecx,1 shl 16		;1/sqrt(2) < x < 1
	inc	eax
LogReduced:
	push	eax			;Save integer part of log2
	mov	ebp,ecx 		;Save reduced exponent (tag is wrong!)
	mov	edx,1 shl 31
	mov	eax,bSign shl 8		;Exponent of 0, negaitve
	xor	edi,edi			;edx:edi,eax = -1.0
	call	AddDoubleReg
	cmp	cl,bTAG_ZERO		;Was it exact power of two?
	jz	LogDone			;Skip log if power of two
;Save (x - 1), reload x with reduced exponent
	mov	edi,EMSEG:[CURstk]	;Point to original x again
	xchg	EMSEG:[edi].lManHi,ebx
	xchg	EMSEG:[edi].lManLo,esi
	mov	EMSEG:[edi].ExpSgn,ecx
	mov	ecx,ebp			;Get reduced exponent
	xor	eax,eax			;Exponent of 0, positive
	call	BasicLog
LogDone:
	pop	eax			;Get integer part back
	cwde
	or	eax,eax			;Is it zero?
	jz	TotalLog
;Next 3 instructions take abs() of integer
	cdq				;Extend sign through edx
	xor	eax,edx			;Complement...
	sub	eax,edx			;  and increment if negative
	bsr	dx,ax			;Look for MSB to normalize integer
;Bit number in dx ranges from 0 to 15
	mov	cl,dl
	not	cl			;Convert to shift count
	shl	eax,cl			;Normalize
.erre	TexpBias eq 0
	rol	edx,16			;Move exponent high, sign low
	or	ebx,ebx			;Was log zero?
	jz	ExactPower
	xchg	edx,eax			;Exp/sign to eax, mantissa to edx
	xor	edi,edi			;Extend with zero
	call	AddDoubleReg
TotalLog:
;Registers could be zero if input was exactly 1.0
	cmp	cl,bTAG_ZERO
	jz	ZeroLog
TotalLogNotZero:
	mov	edi,EMSEG:[Result]	;Point to second arg
	push	offset TransUnround
	jmp	MulDouble

ExactPower:
;Arg was a power of two, so log is exact (but not zero).
	mov     ebx,eax			;Mantissa to ebx
	mov     ecx,edx			;Exponent to ecx
	xor     esi,esi			;Extend with zero
;Exponent of arg [= log2(arg)] is now normalized in ebx:esi,ecx
;
;The result log is exact, so we don't want TransUnround, which is designed 
;to ensure the result is never exact.  Instead we set the [RoundMode]
;vector to [TransRound] before the final multiply.
	mov	eax,EMSEG:[TransRound]
	mov	EMSEG:[RoundMode],eax
	mov	edi,EMSEG:[Result]	;Point to second arg
	push	offset RestoreRound	;Return addr. for MulDouble in emtrig.asm
	jmp	MulDouble

ZeroLog:
	mov	eax,EMSEG:[SavedRoundMode]
	mov	EMSEG:[RoundMode],eax
	mov	EMSEG:[ZeroVector],offset SaveResult
	jmp	SaveResult

;***
LogZeroDest:
	or	ch,ch			;Is it negative?
	js	ReturnIndefinite	;Can't take log of negative numbers
;See if log is + or - so we can get correct sign of zero
	or	ecx,ecx			;Is exponent >= 0?
	jge	LogRet			;If so, keep present zero sign
FlipDestSign:
	not	EMSEG:[edi].bSgn
	ret

;***
LogSpclDest:
	mov	al,EMSEG:[edi].bTag		;Pick up tag
	cmp	al,bTAG_INF		;Is argument infinity?
	jnz	SpclDest		;In emarith.asm
;Multiplying log(x) * infinity.
;If x > 1, return original infinity.
;If 0 <= x < 1, return infinity with sign flipped.
;If x < 0 or x == 1, invalid operation.
	cmp	cl,bTAG_ZERO
	jz	FlipDestSign
	or	ch,ch			;Is it positive?
	js	ReturnIndefinite
	test	ecx,0FFFFH shl 16	;Is exponent zero?
	jg	LogRet			;x > 1, just return infinity
	jl	FlipDestSign
	sub	ebx,1 shl 31		;Kill MSB
	or	ebx,esi
	jz	ReturnIndefinite	;x == 1.0
LogRet:
	ret
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emlsenv.asm ===
subttl	emlsenv.asm - Emulator Save/Restore
	page
;***
;emlsenv.asm - Emulator Save/Restore
;
;
;	 Copyright (c) Microsoft Corporation 1991
;
;	 All Rights Reserved
;
;Purpose:
;	FLDCW, FSTCW, FSTSW, FSTENV, FLDENV, FSAVE, FRSTOR instructions
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;
;*******************************************************************************


;When setting the control word, the [RoundMode] vector must be set
;according to the rounding and precision modes.

tRoundMode	label	dword
	irp	RC,<near,down,up,chop>
	irp	PC,<24,24,53,64>
	dd	Round&&PC&&RC
	endm
	endm


EM_ENTRY eFLDCW
eFLDCW:
;Uses only eax and ebx
	mov	ax, dseg:[esi]		; Fetch control word from user memory
SetControlWord:
	and	ax,0F3FH		; Limit to valid values
	mov	EMSEG:[ControlWord], ax	; Store in the emulated control word
	not	al			;Flip mask bits for fast compare
        and     al,3FH                  ;Limit to valid mask bits
	mov	EMSEG:[ErrMask],al
	and	eax,(RoundControl + PrecisionControl) shl 8
.erre	RoundControl eq 1100B
.erre	PrecisionControl eq 0011B
	shr	eax,6			;Put PC and RC in bits 2-5
	mov	ebx,tRoundMode[eax]	;Get correct RoundMode vector
	mov	EMSEG:[RoundMode],ebx
	mov	EMSEG:[SavedRoundMode],ebx
	and	eax,RoundControl shl (8-6)	;Mask off precision control
	mov	ebx,tRoundMode[eax+PC64 shl (8-6)];Get correct RoundMode vector
	mov	EMSEG:[TransRound],ebx	;Round mode w/o precision
	ret


EM_ENTRY eFSTCW
eFSTCW:
;Uses only eax 
	mov	ax, EMSEG:[ControlWord]	; Fetch user control word
	mov	dseg:[esi], ax		; Store into user memory
	ret


EM_ENTRY eFSTSW
eFSTSW:
;Uses only eax and ebx
	call	GetStatusWord		; Fetch emulated Status word
	mov	dseg:[esi], ax		; Store into user memory
	ret


eFSTSWax:
;Uses only eax and ebx
	call	GetStatusWord		; Fetch emulated Status word
	mov	[esp+4].regAX,ax
	ret


EM_ENTRY eFDECSTP
eFDECSTP:
;edi = [CURstk]
	cmp	edi,BEGstk
	jbe	DecWrap
	sub	EMSEG:[CURstk],Reg87Len
	ret

DecWrap:
	mov	EMSEG:[CURstk],INITstk
	ret


EM_ENTRY eFINCSTP
eFINCSTP:
;edi = [CURstk]
	cmp	edi,INITstk
	jae	IncWrap
	add	EMSEG:[CURstk],Reg87Len
	ret

IncWrap:
	mov	EMSEG:[CURstk],BEGstk
	ret


eFCLEX:
	mov	EMSEG:[SWerr],0
	and	[esp+4].OldLongStatus,0FFFF00FFH		; clear saved SWerr
	ret


;*** eFSTENV - emulate FSTENV	[address]
;
;   ARGUMENTS
;	    dseg:esi  = where to store environment
;
;
;   DESCRIPTION
;	    This routine emulates an 80387 FSTENV (store environment)
;

EM_ENTRY eFSTENV
eFSTENV:
	mov	ax,[esp+4].OldStatus
	mov	EMSEG:[StatusWord],ax
SaveEnv:
	xor	ax,ax
	mov	dseg:[esi.reserved1],ax
	mov	dseg:[esi.reserved2],ax
	mov	dseg:[esi.reserved3],ax
	mov	dseg:[esi.reserved4],ax
	mov	dseg:[esi.reserved5],ax
	mov	ax,EMSEG:[ControlWord]
	mov	dseg:[esi.E32_ControlWord],ax
	call	GetEMSEGStatusWord
	mov	dseg:[esi.E32_StatusWord],ax
	call	GetTagWord
	mov	dseg:[esi.E32_TagWord],ax
	mov	ax,cs
	mov	dseg:[esi.E32_CodeSeg],ax
	mov	ax,ss
	mov	dseg:[esi.E32_DataSeg],ax
	mov	eax,EMSEG:[PrevCodeOff]
	mov	dseg:[esi.E32_CodeOff],eax
	mov	eax,EMSEG:[PrevDataOff]
	mov	dseg:[esi.E32_DataOff],eax
        mov     EMSEG:[CWmask],03FH        ;Set all mask bits
	mov	EMSEG:[ErrMask],0
	ret


;*** eFSAVE - emulate FSAVE   [address]
;
;   ARGUMENTS
;	    dseg:esi  = where to store environment
;
;
;   DESCRIPTION
;	    This routine emulates an 80387 FSAVE (store environment)
;	    Once the data is stored an finit is executed.
;
;   REGISTERS
;	destroys ALL.

EM_ENTRY eFSAVE
eFSAVE:
	mov	ax,[esp+4].OldStatus
	mov	EMSEG:[StatusWord],ax
        mov     eax,[esp+4].OldCodeOff
        mov     EMSEG:[PrevCodeOff],eax
	push	offset eFINIT		; After fsave we must do a finit
SaveState:				; Enter here for debugger save state
	call	SaveEnv
	add	esi,size Env80x87_32	;Skip over environment
	mov	ebp,NumLev		;Save entire stack
	mov	edi,EMSEG:[CURstk]
FsaveStoreLoop:
	mov	eax,EMSEG:[edi].ExpSgn
	call	StoreTempReal		;in emstore.asm
        add     esi,10

        mov     edi,EMSEG:[CURstk]
        NextStackElem   edi,FSave
        mov     EMSEG:[CURstk],edi

        dec     ebp
	jnz	FsaveStoreLoop
	ret

WrapFSave:                              ; tied to NextStackElem above
        mov     edi, BEGstk
        mov     EMSEG:[CURstk],edi
        dec     ebp
        jnz     FsaveStoreLoop
        ret


;*** eFRSTOR - emulate FRSTOR  [address]
;
;   ARGUMENTS
;	    dseg:esi  = where to get the environment
;
;   DESCRIPTION
;	    This routine emulates an 80387 FRSTOR (restore state)

	NextStackWrap	edi,Frstor

EM_ENTRY eFRSTOR
eFRSTOR:
;First we set up the status word so that [CURstk] is initialized.
;The floating-point registers are stored in logical ST(0) - ST(7) order,
;not physical register order.  We don't do a full load of the environment
;because we're not ready to use the tag word yet.

    and		[esp+4].[OldLongStatus], NOT(LongSavedFlags)	;clear saved codes, errs
	mov	ax, dseg:[esi.E32_StatusWord]
	call	SetEmStatusWord		;Initialize [CURstk]
	add	esi,size Env80x87_32	;Skip over environment

;Load of temp real has one difference from real math chip: it is an invalid
;operation to load an unsupported format.  By ensuring the exception is
;masked, we will convert unsupported format to Indefinite.  Note that the
;mask and [CURerr] will be completely restored by the FLDENV at the end.

        mov     EMSEG:[CWmask],3FH              ;Mask off invalid operation exception
	mov	edi,EMSEG:[CURstk]
	mov	ebp,NumLev
FrstorLoadLoop:
	push	esi
	call	LoadTempReal		;In emload.asm
	pop	esi
	add	esi,10		;Point to next temp real
	NextStackElem	edi,Frstor
	dec	ebp
	jnz	FrstorLoadLoop
	sub	esi,NumLev*10+size Env80x87_32	;Point to start of env.
        jmp     eFLDENV                 ;Fall into eFLDENV


;***	eFLDENV - emulate FLDENV   [address]
;
;	ARGUMENTS
;	       dseg:si	= where to store environment
;
;	       This routine emulates an 80387 FLDENV (load environment)

EM_ENTRY eFLDENV
eFLDENV:
    and		[esp+4].[OldLongStatus], NOT(LongSavedFlags)	;clear saved codes, errs
	mov		ax, dseg:[esi.E32_StatusWord]
	call	SetEmStatusWord			; set up status word
	mov		ax, dseg:[esi.E32_ControlWord]
	call	SetControlWord
	mov		ax, dseg:[esi.E32_TagWord]
	call	UseTagWord
	mov		eax, dseg:[esi.E32_CodeOff]
	mov     EMSEG:[PrevCodeOff], eax
	mov		eax, dseg:[esi.E32_DataOff]
	mov     EMSEG:[PrevDataOff], eax
	ret


;***	GetTagWord - figures out what the tag word is from the numeric stack
;		   and returns the value of the tag word in ax.
;

GetTagWord:
	push	esi
	xor	eax, eax
	mov	ecx, NumLev		; get tags for regs. 0, 7 - 1
	mov	esi,INITstk
GetTagLoop:
	mov	bh, EMSEG:[esi.bTag]	; The top 2 bits of Tag are the X87 tag bits.
	shld	ax, bx, 2
	sub	esi, Reg87Len
	loop	GetTagLoop
	rol	ax, 2			; This moves Tag(0) into the low 2 bits
	pop	esi
	ret


;***	UseTagWord - Set up tags using tag word from environment
;
;	ARGUMENTS
;	       ax - should contain the tag word
;
;	Destroys ax,bx,cx,dx,di

UseTagWord:
	ror	ax, 2			; mov Tag(0) into top bits of ax
	mov	edi,INITstk
	mov	ecx, NumLev
UseTagLoop:
	mov	dl,bTAG_EMPTY
	cmp	ah, 0c0h		;Is register to be tagged Empty?
	jae	SetTag			;Yes, go mark it
	mov	dl,EMSEG:[edi].bTag	;Get current tag
	cmp	dl,bTAG_EMPTY		;Is register currently Empty?
	je	SetTagNotEmpty		;If so, go figure out tag for it
SetTag:
	mov	EMSEG:[edi].bTag,dl
UseTagLoopCheck:
	sub	edi, Reg87Len
	shl	eax, 2
	loop	UseTagLoop
	ret

SetTagEmpty:
	mov	EMSEG:[edi.bTag], bTAG_EMPTY
	jmp	UseTagLoopCheck

SetTagNotEmpty:
;Register is currently tagged empty, but new tag word says it is not empty.
;Figure out a new tag for it.  The rules are:
;
;1. Everything is either normalized or zero--unnormalized formats cannot
;get in.  So if the high half mantissa is zero, the number is zero.
;
;2. Although the exponent bias is different, NANs and Infinities are in
;standard IEEE format - exponent is TexpMax, mantissa indicates NAN vs.
;infinity (mantissa for infinity is 800..000H).
;
;3. Denormals have an exponent less than TexpMin.
;
;4. If the low half of the mantissa is zero, it is tagged bTAG_SNGL
;
;5. Everything else is bTAG_VALID

	mov	ebx,EMSEG:[edi].lManHi
	mov	dl,bTAG_ZERO		;Try zero first
	or	ebx,ebx			;Is mantissa zero?
	jz	SetTag
	mov	edx,EMSEG:[edi].ExpSgn
	mov	dl,bTAG_DEN
	cmp	edx,TexpMin shl 16	;Is it denormal?
	jl	SetTag
	cmp	EMSEG:[edi].lManLo,0	;Is low half zero?
.erre	bTAG_VALID eq 1
.erre	bTAG_SNGL eq 0
	setnz	dl			;if low half==0 then dl=0 else dl=1
	cmp	edx,TexpMax shl 16	;Is it NAN or Infinity?
	jl	SetTag			;If not, it's valid
.erre	(bTAG_VALID - bTAG_SNGL) shl TAG_SHIFT eq (bTAG_NAN - bTAG_INF)
	shl	dl,TAG_SHIFT
	add	dl,bTAG_INF - bTAG_SNGL
;If the low bits were zero we have just changed bTAG_SNGL to bTAG_INF
;If the low bits weren't zero, we changed bTAG_VALID to bTAG_NAN
;See if infinity is really possible: is high half 80..00H?
	cmp	ebx,1 shl 31		;Is it infinity?
	jz	SetTag			;Store tag for infinity or NAN
	mov	dl,bTAG_NAN
	jmp	SetTag


;***	GetStatusWord -
;
; User status word returned in ax.
; Destroys ebx only.

GetStatusWord:
	mov	eax, EMSEG:[CURstk]
	sub	eax, BEGstk
	mov	bl,Reg87Len
	div	bl
        inc     eax                     ; adjust for emulator's stack layout
	and	eax, 7			; eax is now the stack number
	shl	ax, 11
	or	ax,[esp+8].OldStatus	; or in the rest of the status word.
	ret


;***	GetEMSEGStatusWord -
;
; User status word returned in ax.
; Destroys ebx only.
; Uses status word in per-thread data area, otherwise
;   identical to GetStatusWord

EM_ENTRY eGetStatusWord
GetEMSEGStatusWord:
	mov	eax, EMSEG:[CURstk]
	sub	eax, BEGstk
	mov	bl,Reg87Len
	div	bl
        inc     eax                     ; adjust for emulator's stack layout
	and	eax, 7			; eax is now the stack number
	shl	ax, 11
	or	ax, EMSEG:[StatusWord]	; or in the rest of the status word.
	ret


;***	SetEmStatusWord -
;
; Given user status word in ax, set into emulator.
; Destroys ebx only.


SetEmStatusWord:
	and	ax,7F7FH
	mov	bx,ax
        and     bx,3FH                  ; set up CURerr in case user
	mov	EMSEG:[CURerr],bl	; wants to force an exception
	mov	ebx, eax
	and	ebx, not (7 shl 11)	; remove stack field.
	mov	EMSEG:[StatusWord], bx

	sub	ah, 8  			; adjust for emulator's stack layout
	and	ah, 7 shl 3
	mov	al, ah
	shr	ah, 1
	add	al, ah			; stack field * 3 * 4
.erre	Reg87Len eq 12	
	and	eax, 255	   	; eax is now 12*stack number
        add     eax, BEGstk
	mov	EMSEG:[CURstk], eax
	ret


public _SaveEm87Context
_SaveEm87Context PROC

	push	ebp
	mov	ebp, esp
	push	ebx
	push	edi
	push	esi
	mov	esi, [ebp+8]
	call	SaveState
	test	EMSEG:[CURErr], Summary
	jne	RetSaveEmIdle
	mov	eax, Em87Busy
	jmp	RetSaveEm
RetSaveEmIdle:
	mov	eax, Em87Idle
RetSaveEm:
	pop	esi
	pop	edi
	pop	ebx
	pop	ebp
	ret
_SaveEm87Context ENDP


public _RestoreEm87Context
_RestoreEm87Context PROC
	push	ebp
	mov	ebp, esp
	push	ebx
	push	edi
	push	esi
	mov	esi, [ebp+8]
	call	eFRSTOR
	pop	esi
	pop	edi
	pop	ebx
	pop	ebp
	ret
_RestoreEm87Context  ENDP
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emstack.inc ===
subttl	emstack.asm - Emulator Stack Management Macros
	page
;***
;emstack.asm - Emulator Stack Management Area
;
;	 Microsoft Confidential
;	 Copyright (c) Microsoft Corporation 1991
;	 All Rights Reserved
;
;Purpose:
;	Handles emulator stack.
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;POPSTret:  pops the stack and returns.  Uses esi.

POPSTret        macro	reg
        local   stackwrap
IFB	<reg>
        mov     esi,EMSEG:[CURstk]
_popreg	equ	esi
ELSE
_popreg	equ	reg
ENDIF
	mov     EMSEG:[_popreg].bTag,bTAG_EMPTY
        NextStackElem   _popreg,stackwrap
        mov     EMSEG:[CURstk],_popreg
        ret

Wrap&stackwrap:
	mov	EMSEG:[CURstk],BEGstk
	ret
	endm

;NextStackElem:  Given pST(0) = [CURstk] in reg, returns pST(1)
;Requires NextStackWrap macro with same arguments

NextStackElem	macro	reg,stackwrap
	cmp	reg,INITstk			;JWM
	jae	Wrap&stackwrap
	add	reg,Reg87Len
Cont&stackwrap:
	endm

NextStackWrap	macro	reg,stackwrap
Wrap&stackwrap:
	mov	reg,BEGstk			;JWM
	jmp	Cont&stackwrap
	endm


;PrevStackElem:  Given pST(0) = [CURstk] in reg, returns new pST(0) 
;after a push onto on the stack.
;Requires PrevStackWrap macro with same arguments

PrevStackElem	macro	reg,stackwrap
	cmp	reg,BEGstk			;JWM
	jbe	Wrap&stackwrap
	sub	reg,Reg87Len
Cont&stackwrap:
	endm

PrevStackWrap	macro	reg,stackwrap
Wrap&stackwrap:
	mov	reg,INITstk			;JWM
	jmp	Cont&stackwrap
	endm
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emsincos.asm ===
;      SCCSID = @(#)emsincos.asm	       13.5 90/03/27
	page	,132
	subttl	emsincos - fsin, fcos and fsincos
;***
;emulator.asm -  80387 emulator
;
;	 IBM/Microsoft Confidential
;
;	 Copyright (c) IBM Corporation 1987, 1989
;	 Copyright (c) Microsoft Corporation 1987, 1989
;
;	 All Rights Reserved
;
;Purpose:
;	Code for fsin, fcos and fsincos
;
;Revision History:
;	See emulator.hst
;
;*******************************************************************************

lab eFsincosStackOver
	or	SEL[CURerr], StackFlag or Invalid
	test	SEL[CWmask], Invalid
	JSZ	eFsincosStackOverRet

	mov	SEL[rsi.lMan0], 0			; st(0) = Ind
	mov	SEL[rsi.lMan1], 0c0000000h
	mov	SEL[rsi.wExp], 7fffh - IexpBias
	mov	SEL[rsi.bTag], bTAG_NAN
	mov	SEL[rsi.bFlags], bSign

	mov	SEL[rdi.lMan0], 0			; st(-1) = Ind
	mov	SEL[rdi.lMan1], 0c0000000h
	mov	SEL[rdi.wExp], 7fffh - IexpBias
	mov	SEL[rdi.bTag], bTAG_NAN
	mov	SEL[rdi.bFlags], bSign

	mov	SEL[CURstk], rdi		; push stack
lab eFsincosStackOverRet
	ret


lab eFSINCOS
	mov	esi, SEL[CURStk]    ; esi = st(0)
	mov	edi, esi
	PrevStackElem	 edi	    ; edi = st(-1)

	cmp	SEL[edi.bTag], bTAG_EMPTY
	JSNE	eFsincosStackOver

	cmp	SEL[esi.bTag], bTAG_NAN
	JSNE	eFsincosNotSNaN

	test	SEL[esi.bMan7], 40h
	JSNZ	eFsincosNotSNaN

	test	SEL[CWmask], Invalid
	JSNZ	eFsincosNotSNaN

	or	SEL[CURerr], Invalid
	ret

lab eFsincosNotSNaN
ifdef NT386
        push    eax
        mov     eax, dword ptr SEL[rsi]
        mov     dword ptr SEL[rdi], eax
        mov     eax, dword ptr SEL[rsi+4]
        mov     dword ptr SEL[rdi+4], eax
        mov     eax, dword ptr SEL[rsi+8]
        mov     dword ptr SEL[rdi+8], eax
        add     rsi, Reg87Len
        add     rdi, Reg87Len
        pop     eax
else
        push	ds		    ; Copy current stack into st(-1)
	pop	es
	movsd
	movsd
	movsd
endif

	call	eFSIN
	PUSHST
	call	eFCOS

	ret


lab eFcosSpecial
	mov	esp, ebp
	pop	ebp

	mov	SEL[RESULT], esi

	mov	al, SEL[esi.bTag]
	cmp	al, bTAG_ZERO
	JSNE	eFcosInf

lab eFcosRetOne
	mov	SEL[esi.lMan0], 0
	mov	SEL[esi.lMan1], 080000000h
	mov	SEL[esi.wExp], 3fffh - IexpBias
	mov	SEL[esi.bFlags], 0
	mov	SEL[esi.bTag], bTAG_VALID
	ret

lab eFcosInf
	cmp	al, bTAG_INF
	JE	RetIndInv

lab eFcosNaN
	jmp	OneArgOpNaNRet


cProc  eFCOS,<PLM,PUBLIC>,<>

	localT	temp
	localB	SignFlag

cBegin
	mov	esi, SEL[CURstk]

	cmp	SEL[esi.bTag], bTAG_VALID
	jne	eFcosSpecial

	or	SEL[CURerr], Precision

	and	SEL[esi].bFlags, not bSign ; st(0) = fabs( st(0) );

	call	SinCosReduce		; Set ah to condition code.

	add	SEL[esi].wExp, IExpBias

	push	SEL[esi].wExp
	push	SEL[esi].lMan1
	push	SEL[esi].lMan0
	lea	ecx, [temp]
	push	ecx

	mov	bl, ah			; if octant 2, 3, 4, or 5 then final
	and	bl, bOCT2 or bOCT4	; result must be negative
	mov	[SignFlag], bl

	test	ah, bOCT1 or bOCT2	; if octant is 1, 2, 5, 6 then must
	jpo	CosCallSin		; do sin()

	call	__FASTLDCOS
	jmp	short CosCopyRes

CosCallSin:
	call	__FASTLDSIN

CosCopyRes:
	mov	eax, dword ptr [temp]
	mov	SEL[esi].lMan0, eax
	mov	eax, dword ptr [temp+4]
	mov	SEL[esi].lMan1, eax

	mov	ax,  word ptr [temp+8]
	sub	ax, IExpBias
	mov	SEL[esi].wExp, ax

	cmp	[SignFlag], 0
	jpe	CosDone

	or	SEL[esi].bFlags, bSign	; Make result negative.
CosDone:

cEnd





lab eFsinSpecial
	mov	esp, ebp
	pop	ebp

	mov	al, SEL[esi.bTag]
	cmp	al, bTAG_ZERO
	JSNE	eFsinInf

lab eFsinZero
	ret

lab eFsinInf
	cmp	al, bTAG_INF
	JE	RetIndInv

lab eFsinNaN
	jmp	OneArgOpNaNRet


cProc  eFSIN,<PLM,PUBLIC>,<>

	localT	temp
	localB	SignFlag

cBegin
	mov	esi, SEL[CURstk]

	cmp	SEL[esi.bTag], bTAG_VALID
	jne	eFsinSpecial

	or	SEL[CURerr], Precision

	mov	al, SEL[esi].bFlags
	and	SEL[esi].bFlags, not bSign

	shl	al, 1		    ; shift sign into carry.
	sbb	cl, cl		    ; set cl to -1 if argument is negative.

	push	ecx
	call	SinCosReduce	    ; Set ah to condition code.
	pop	ecx

	cmp	SEL[esi].bTag, bTAG_ZERO
	je	SinDone

	add	SEL[esi].wExp, IExpBias

	push	SEL[esi].wExp
	push	SEL[esi].lMan1
	push	SEL[esi].lMan0
	lea	ebx, [temp]
	push	ebx

	mov	bl, ah			; if octant 4, 5, 6 or 7 then final
	and	bl, bOCT4		; result must be negative

	neg	cl			; set cl to odd parity if arg was < 0.0
	xor	bl, cl			; set bl to odd parity if result must be negative

	mov	[SignFlag], bl

	test	ah, bOCT1 or bOCT2	; if octant is 1, 2, 5, 6 then must
	jpo	SinCallCos		; do cos()

	call	__FASTLDSIN
	jmp	short SinCopyResult

SinCallCos:
	call	__FASTLDCOS

SinCopyResult:
	mov	eax, dword ptr [temp]
	mov	SEL[esi].lMan0, eax
	mov	eax, dword ptr [temp+4]
	mov	SEL[esi].lMan1, eax

	mov	ax, word ptr [temp+8]
	sub	ax, IExpBias
	mov	SEL[esi].wExp, ax

	cmp	[SignFlag], 0
	jpe	SinDone

	or	SEL[esi].bFlags, bSign	; Make result negative.
SinDone:

cEnd



lab SinCosReduce
	mov	SEL[TEMP1.bFlags], 0		; TEMP1 = pi/4
	mov	SEL[TEMP1.bTag], bTAG_VALID
	mov	SEL[TEMP1.wExp], 3ffeh-IExpBias
	mov	SEL[TEMP1.wMan3], 0c90fh
	mov	SEL[TEMP1.wMan2], 0daa2h
	mov	SEL[TEMP1.wMan1],	2168h
	mov	SEL[TEMP1.wMan0], 0c235h

ifdef NT386
        mov     edi, TEMP1
else
	mov	edi, edataOFFSET TEMP1
endif

	push	esi
	call	InternFPREM		    ; rsi = st(0), rdi = st(0)
	pop	esi

	mov	ah, SEL[SWcc]

	test	ah, bOCT1		; check for even octant
	jz	EvenOct 		;   yes

	add	SEL[esi.wExp], IExpBias	; convert to true long double

	push	ds
	push	esi
	push	cs
	push	ecodeOFFSET PIBY4
	push	ds
	push	esi
	push	-1
	call	__FASTLDADD		; st(0) = pi/4 - st(0)
	mov	ah, SEL[SWcc]

	sub	SEL[esi.wExp], IExpBias	; convert to squirly emulator long double

EvenOct:
	retn



labelW	PIBY4
    dw	    0c235h, 02168h, 0daa2h, 0c90fh, 3ffeh

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; NOTE tedm:   NT masm can't handle floating-point constants  ;
;              because strtod and _strtold C-runtimes aren't  ;
;              there.  So the constants below must be pre-    ;
;              assembled and defined as a byte stream.        ;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
ifdef NOTDEF

staticT  FourByPI, +0.1273239544735162686151e+01

staticT  SinP0, +0.7853981633974483096141845e+00
staticT  SinP1, -0.8074551218828078152025820e-01
staticT  SinP2, +0.2490394570192716275251900e-02
staticT  SinP3, -0.3657620418214640005290000e-04
staticT  SinP4, +0.3133616889173253480000000e-06
staticT  SinP5, -0.1757247417617080600000000e-08
staticT  SinP6, +0.6948152035052200000000000e-11
staticT  SinP7, -0.2022531292930000000000000e-13

staticT  CosP0, +0.99999999999999999996415e+00
staticT  CosP1, -0.30842513753404245242414e+00
staticT  CosP2, +0.15854344243815410897540e-01
staticT  CosP3, -0.32599188692668755044000e-03
staticT  CosP4, +0.35908604458858195300000e-05
staticT  CosP5, -0.24611363826370050000000e-07
staticT  CosP6, +0.11500497024263000000000e-09
staticT  CosP7, -0.38577620372000000000000e-12

else

staticB  FourByPI, <02Ah,015h,044h,04Eh,06Eh,083h,0F9h,0A2h,0FFh,03Fh>

staticB  SinP0   , <035h,0C2h,068h,021h,0A2h,0DAh,00Fh,0C9h,0FEh,03Fh>
staticB  SinP1   , <0DAh,095h,0F2h,02Dh,031h,0E7h,05Dh,0A5h,0FBh,0BFh>
staticB  SinP2   , <0E9h,0C6h,056h,0ADh,03Bh,0E3h,035h,0A3h,0F6h,03Fh>
staticB  SinP3   , <0D5h,0E7h,05Dh,015h,073h,066h,069h,099h,0F0h,0BFh>
staticB  SinP4   , <0BCh,032h,069h,0E1h,042h,01Ah,03Ch,0A8h,0E9h,03Fh>
staticB  SinP5   , <021h,077h,004h,05Fh,0A1h,0A5h,083h,0F1h,0E1h,0BFh>
staticB  SinP6   , <0FCh,01Ah,0D1h,006h,0CCh,063h,077h,0F4h,0D9h,03Fh>
staticB  SinP7   , <04Ah,003h,086h,040h,07Ch,065h,02Ch,0B6h,0D1h,0BFh>

staticB  CosP0   , <0FFh,0FFh,0FFh,0FFh,0FFh,0FFh,0FFh,0FFh,0FEh,03Fh>
staticB  CosP1   , <02Fh,0F2h,02Eh,0F2h,04Dh,0E6h,0E9h,09Dh,0FDh,0BFh>
staticB  CosP2   , <02Fh,04Eh,0D5h,0DAh,040h,0F8h,0E0h,081h,0F9h,03Fh>
staticB  CosP3   , <09Dh,0DEh,06Ah,0E4h,0F1h,0E3h,0E9h,0AAh,0F3h,0BFh>
staticB  CosP4   , <031h,01Eh,0F9h,081h,041h,083h,0FAh,0F0h,0ECh,03Fh>
staticB  CosP5   , <076h,0B1h,000h,0A4h,01Eh,0F6h,068h,0D3h,0E5h,0BFh>
staticB  CosP6   , <0D8h,005h,06Fh,08Ah,0EAh,00Ah,0E6h,0FCh,0DDh,03Fh>
staticB  CosP7   , <003h,0D5h,00Ah,0ACh,0CCh,035h,02Ch,0D9h,0D5h,0BFh>

endif

cProc __FASTLDSIN,<PLM,PUBLIC>,<isi,idi>

	parmT	x
	parmI	RetOff

	localT	x2
	localT	poly
	localI	count

cBegin

	lea	isi, [x]		    ; x = x * (4/PI)
	push	ss
	push	isi

	push	ss
	push	isi

	mov	iax, codeOFFSET FourByPI
	push	cs
	push	iax

	call	__FASTLDMULT


	lea	idi, [x2]		    ; x2 = x * x
	push	ss
	push	idi

	push	ss
	push	isi

	push	ss
	push	isi

	call	__FASTLDMULT

if 0
	push	ss
	pop	es
	lea	idi, [poly]
	mov	isi, codeOFFSET SinP7
	movsw
	movsw
	movsw
	movsw
	movsw
endif
	mov	eax, dword ptr [SinP7]	    ; poly = SinP7
	mov	dword ptr [poly], eax
	mov	eax, dword ptr [SinP7+4]
	mov	dword ptr [poly+4], eax
	mov	ax, word ptr [SinP7+8]
	mov	word ptr [poly+8], ax

	lea	isi, [poly]
	mov	idi, codeOFFSET SinP6

	mov	[count], 7

SinPolyLoop:
	push	ss
	push	isi		    ; poly = poly * x2

	push	ss
	push	isi

	lea	iax, [x2]
	push	ss
	push	iax

	call	__FASTLDMULT


	push	ss
	push	isi		    ; poly = poly + SinP[n]

	push	ss
	push	isi

	push	cs
	push	idi

	xor	iax, iax
	push	iax
	call	__FASTLDADD

	sub	idi, 10

	dec	[count]
	jnz	SinPolyLoop

	push	ss
	push	[RetOff]		; return x * poly

	lea	iax, [x]
	push	ss
	push	iax

	push	ss
	push	isi

	call	__FASTLDMULT

	mov	iax, [RetOff]
	mov	idx, ss
cEnd




cProc  __FASTLDCOS,<PLM,PUBLIC>,<isi,idi>

	parmT	x
	parmI	RetOff

	localT	x2
	localI	count

cBegin

	lea	isi, [x]		    ; x = x * (4/PI)
	push	ss
	push	isi

	push	ss
	push	isi

	mov	iax, codeOFFSET FourByPI
	push	cs
	push	iax

	call	__FASTLDMULT


	lea	idi, [x2]		    ; x2 = x * x
	push	ss
	push	idi

	push	ss
	push	isi

	push	ss
	push	isi

	call	__FASTLDMULT

if 0
	push	ss			    ; (return) = CosP7
	pop	es
	mov	idi, [RetOff]
	mov	isi, codeOFFSET CosP7
	movsw
	movsw
	movsw
	movsw
	movsw
endif
	mov	isi, [RetOff]
	mov	eax, dword ptr [CosP7]
	mov	dword ptr ss:[isi], eax
	mov	eax, dword ptr [CosP7+4]
	mov	dword ptr ss:[isi+4], eax
	mov	ax, word ptr [CosP7+8]
	mov	word ptr ss:[isi+8], ax

	mov	idi, codeOFFSET CosP6

	mov	[count], 7

CosPolyLoop:
	push	ss
	push	isi		    ; (return) = (return) * x2

	push	ss
	push	isi

	lea	iax, [x2]
	push	ss
	push	iax

	call	__FASTLDMULT


	push	ss
	push	isi		    ; (return) = (return) + SinP[n]

	push	ss
	push	isi

	push	cs
	push	idi

	xor	iax, iax
	push	iax

	call	__FASTLDADD


	sub	idi, 10

	dec	[count]
	jnz	CosPolyLoop

	mov	iax, isi
	mov	idx, ss
cEnd
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emround.asm ===
subttl  emround.asm - Rounding and Precision Control and FRNDINT
        page
;*******************************************************************************
;emround.asm - Rounding and Precision Control
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Purpose:
;       Rounding and precision control.  The correct routine is jumped
;	to through the [RoundMode] vector.
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;	02/28/92  JWM   Minor bug fix in NotNearLow
;
;*******************************************************************************


RndIntSpcl:
	cmp	cl,bTAG_INF
	jz	RndIntX			;Leave infinity unchanged
	cmp	cl,bTAG_DEN
	jnz	SpclDestNotDen		;Handle NAN & empty - in emarith.asm
;Handle denormal
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is it masked?
	jnz	NormRndInt		;If so, ignore denormalization
RndIntX:
	ret

;********
EM_ENTRY eFRNDINT
eFRNDINT:
;********
;edi points to top of stack
	mov	ecx,EMSEG:[edi].ExpSgn
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
	jz	RndIntX	
	ja	RndIntSpcl
	cmp	ecx,63 shl 16		;Is it already integer?
	jge	RndIntX
NormRndInt:
	mov	ebx,EMSEG:[edi].lManHi
	mov	esi,EMSEG:[edi].lManLo
	mov	EMSEG:[Result],edi	;Save result pointer
	xor	eax,eax			;Extend mantissa
	push	offset SaveResult
	jmp	RoundToBit

;*******************************************************************************

ResultOverflow:
;mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7, tag in cl.
;We were all ready to save the rounded result, but the exponent turned out
;to be too large.
	or	EMSEG:[CURerr],Overflow
	sub	ecx,UnderBias shl 16	;Unmasked response
	test	EMSEG:[CWmask],Overflow	;Is exception unmasked?
	jz	SaveResult		;If so, we're ready
;Produce masked overflow response
	mov	ebx,1 shl 31		;Assume infinity
	xor	esi,esi
	mov	cl,bTAG_INF
	mov	al,EMSEG:[CWcntl]	;Get rounding control
	mov	ah,al
	and	ah,RCchop			;Rounding control only
;Return max value if RCup bit = 1 and -, or RCdown bit = 1 and +
;i.e., RCup & sign OR RCdown & not sign
.erre	RCchop eq RCup + RCdown		;Always return max value
.erre	RCnear eq 0			;Never return max value
	sar	ch,7			;Expand sign through whole byte
.erre	(RCdown and bSign) eq 0		;Don't want to change real sign
	xor	ch,RCdown		;Flip sign for RCdown bit
	and	ah,ch			;RCup & sign  OR  RCdown & not sign
	jnz	SaveMax
	and	ecx,0FFFFH
	or	ecx,TexpMax shl 16
	jmp	SaveResult		;Save Infinity
SaveMax:
;Get max value for current precision
	mov	ebx,0FFFFFF00H		;Max value for 24 bits
	and	ecx,bSign shl 8		;Preserve only sign
	or	ecx,(IexpMax-IexpBias-1) shl 16 + bTAG_VALID ;Set up max value
	and	al,PrecisionControl
.erre	PC24 eq 0
	jz	SaveResult		;Save 24-bit max value
	dec	esi			;esi == -1
	mov	ebx,esi
	cmp	al,PC53
	jnz	SaveResult		;Save 64-bit max value
	mov	esi,0FFFFF800H
	jmp	SaveResult		;Save 53-bit max value

;*******************************************************************************
;
;64-bit rounding routines
;

;***********
Round64down:
;***********
	cmp	ecx,(IexpMin-IexpBias+1) shl 16	;Test for Underflow
	jl	RndDenorm64
	or	eax,eax			;Exact result?
	jz	SaveValidResult
	or	EMSEG:[CURerr],Precision 	;Set flag on inexact result
;Chop if positive, increase mantissa if negative
	test	ch,bSign
	jz	SaveValidResult		;Positive, so chop
	jmp	RoundUp64		;Round up if negative

RndDenorm64:
	test	EMSEG:[CWmask],Underflow ;Is exception unmasked?
	jz	RndSetUnder
Denormalize:
;We don't really store in denormalized format, but we need the number 
;to be rounded as if we do.  If the exponent were -IexpBias, we would
;lose 1 bit of precision; as it gets more negative, we lose more bits.
;We'll do this by adjusting the exponent so that the bits we want to 
;keep look like integer bits, and performing round-to-integer.
	add	ecx,(IexpBias+62) shl 16 ;Adjust exponent so we're integer
	call	RoundToBit
;Set underflow exception if precision exception is set
	mov	al,EMSEG:[CURerr]
	and	al,Precision
	ror	al,Precision-Underflow	;Move Precision bit to Underflow pos.
	or	EMSEG:[CURerr],al	;Signal Underflow if inexact
	cmp	cl,bTAG_ZERO
	jz	SaveResult
	sub	ecx,(IexpBias+62) shl 16;Restore unbiased exponent
	cmp	ecx,TexpMin shl 16	;Did we round out of denorm?
	jae	SaveResult
	mov	cl,bTAG_DEN
	jmp	SaveResult

RndSetUnder:
;Underflow exception not masked.  Adjust exponent and try again.
	or	EMSEG:[CURerr],Underflow
	add	ecx,UnderBias shl 16
	jmp	EMSEG:[RoundMode]	;Try again with revised exponent

;***********
Round64near:
;***********
;mantissa in ebx:esi:eax, exponent in high ecx, sign in ch bit 7
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm64
	or	eax,eax			;Exact result?
	jz	short SaveValidResult
	or	EMSEG:[CURerr],Precision ;Set flag on inexact result

;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.  This rounding rule is implemented by adding RoundBit-1
;(7F..FFH), setting CY if round up.  

	bt	esi,0			;Is mantissa even or odd? (set CY)
	adc	eax,(1 shl 31)-1	;Sum LSB & sticky bits--CY if round up
	jnc	SaveValidResult
RoundUp64:
	mov	EMSEG:[SWcc],RoundUp
	add	esi,1
	adc	ebx,0
	jc	BumpExponent		;Overflowed, increment exponent

SaveValidResult:			;A jump to here requires 9 clocks
	or	esi,esi			;Any bits in low half?
.erre	bTAG_VALID eq 1
.erre	bTAG_SNGL eq 0
	setnz   cl                      ;if low half==0 then cl=0 else cl=1
	cmp	ecx,TexpMax shl 16	;Test for overflow
	jge	ResultOverflow

SaveResult:				;A jump to here requires 10 clocks
;mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7, tag in cl
	mov	edi,EMSEG:[Result]
SaveResultEdi:
	mov	EMSEG:[edi].lManLo,esi
	mov	EMSEG:[edi].lManHi,ebx
SaveExpSgn:
	mov	EMSEG:[edi].ExpSgn,ecx
	ret

;***********
Round64up:
;***********
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm64
	or	eax,eax			;Exact result?
	jz	short SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
;Chop if negative, increase mantissa if positive
	cmp	ch,bSign		;No CY iff sign bit is set
	jc	RoundUp64		;Round up if positive
	jmp	short SaveValidResult

;***********
Round64chop:
;***********
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm64
	or	eax,eax			;Exact result?
	jz	short SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
	jmp	short SaveValidResult

;*******************************************************************************
;
;53-bit rounding routines
;

;***********
Round53down:
;***********
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm53
	mov	edx,esi			;Get low bits
	and	edx,(1 shl 11) - 1	;Mask to last 11 bits
	or	edx,eax			;Throwing away any bits?
	jz	SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
;Chop if positive, increase mantissa if negative
	and	esi,not ((1 shl 11)-1)	;Mask off low 11 bits
	test	ch,bSign
	jz	SaveValidResult		;Positive, go chop
	jmp	RoundUp53

RndDenorm53:
	test	EMSEG:[CWmask],Underflow;Is exception unmasked?
	jz	RndSetUnder
;We don't really store in denormalized format, but we need the number 
;to be rounded as if we do.  If the exponent were -IexpBias, we would
;lose 1 bit of precision; as it gets more negative, we lose more bits.
;We'll do this by adjusting the exponent so that the bits we want to 
;keep look like integer bits, and performing round-to-integer.
	add	ecx,(IexpBias+51) shl 16 ;Adjust exponent so we're integer
	call	RoundToBit
;Set underflow exception if precision exception is set
	mov	al,EMSEG:[CURerr]
	and	al,Precision
	ror	al,Precision-Underflow	;Move Precision bit to Underflow pos.
	or	EMSEG:[CURerr],al	;Signal Underflow if inexact
	cmp	cl,bTAG_ZERO
	jz	SaveResult
	sub	ecx,(IexpBias+51) shl 16;Restore unbiased exponent
	cmp	ecx,(IexpMin-IexpBias+1) shl 16	;Did we round out of denorm?
	jae	SaveResult
	mov	cl,bTAG_DEN
	jmp	SaveResult

;***********
Round53near:
;***********
;mantissa in ebx:esi:eax, exponent in high ecx, sign in ch bit 7
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm53
	mov	edx,esi			;Get low bits
	and	edx,(1 shl 11) - 1	;Mask to last 11 bits
	or	edx,eax			;Throwing away any bits?
	jz	SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result

;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.

	mov	edx,esi
	and	esi,not ((1 shl 11)-1)	;Mask off low 11 bits
	test	edx,1 shl 10		;Is round bit set?
	jz	SaveValidResult
	and	edx,(3 shl 10)-1	;Keep only sticky bits and LSB
	or	eax,edx			;Combine with other sticky bits
	jz	SaveValidResult
RoundUp53:
	mov	EMSEG:[SWcc],RoundUp
	add	esi,1 shl 11		;Round
	adc	ebx,0
	jnc	SaveValidResult
BumpExponent:
	add	ecx,1 shl 16		;Mantissa overflowed, bump exponent
	or	ebx,1 shl 31		;Set MSB
	jmp	SaveValidResult

;***********
Round53up:
;***********
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm53
	mov	edx,esi			;Get low bits
	and	edx,(1 shl 11) - 1	;Mask to last 11 bits
	or	edx,eax			;Throwing away any bits?
	jz	SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
;Chop if negative, increase mantissa if positive
	and	esi,not ((1 shl 11)-1)	;Mask off low 11 bits
	test	ch,bSign
	jz	RoundUp53		;Round up if positive
	jmp	SaveValidResult

;***********
Round53chop:
;***********
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm53
	mov	edx,esi			;Get low bits
	and	edx,(1 shl 11) - 1	;Mask to last 11 bits
	or	edx,eax			;Throwing away any bits?
	jz	SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
	and	esi,not ((1 shl 11)-1)	;Mask off low 11 bits
	jmp	SaveValidResult

;*******************************************************************************
;
;24-bit rounding routines
;

;***********
Round24down:
;***********
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm24
	or	eax,esi			;Low dword is just sticky bits
	mov	edx,ebx			;Get low bits
	and	edx,(1 shl 8) - 1	;Mask to last 8 bits
	or	edx,eax			;Throwing away any bits?
	jz	SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
;Chop if positive, increase mantissa if negative
	xor	esi,esi
	and	ebx,not ((1 shl 8)-1)	;Mask off low 8 bits
	test	ch,bSign
	jz	SaveValidResult		;Chop if positive
	jmp	RoundUp24

RndDenorm24:
	test	EMSEG:[CWmask],Underflow;Is exception unmasked?
	jz	RndSetUnder
;We don't really store in denormalized format, but we need the number 
;to be rounded as if we do.  If the exponent were -IexpBias, we would
;lose 1 bit of precision; as it gets more negative, we lose more bits.
;We'll do this by adjusting the exponent so that the bits we want to 
;keep look like integer bits, and performing round-to-integer.
	add	ecx,(IexpBias+22) shl 16 ;Adjust exponent so we're integer
	call	RoundToBit
;Set underflow exception if precision exception is set
	mov	al,EMSEG:[CURerr]
	and	al,Precision
	ror	al,Precision-Underflow	;Move Precision bit to Underflow pos.
	or	EMSEG:[CURerr],al	;Signal Underflow if inexact
	cmp	cl,bTAG_ZERO
	jz	SaveResult
	sub	ecx,(IexpBias+22) shl 16;Restore unbiased exponent
	cmp	ecx,(IexpMin-IexpBias+1) shl 16	;Did we round out of denorm?
	jae	SaveResult
	mov	cl,bTAG_DEN
	jmp	SaveResult

;***********
Round24near:
;***********
;mantissa in ebx:esi:eax, exponent in high ecx, sign in ch bit 7
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm24
	or	eax,esi			;Low dword is just sticky bits
	mov	edx,ebx			;Get low bits
	and	edx,(1 shl 8) - 1	;Mask to last 8 bits
	or	edx,eax			;Throwing away any bits?
	jz	SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
	xor	esi,esi

;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.  

	mov	edx,ebx
	and	ebx,not ((1 shl 8)-1)	;Mask off low 8 bits
	test	dl,1 shl 7		;Round bit set?
	jz	SaveValidResult
	and	edx,(3 shl 7)-1		;Mask to LSB and sticky bits
	or	eax,edx			;Combine all sticky bits
	jz	SaveValidResult
RoundUp24:
	mov	EMSEG:[SWcc],RoundUp
	add	ebx,1 shl 8
	jnc	SaveValidResult
	jmp	BumpExponent		;Overflowed, increment exponent

;***********
Round24up:
;***********
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm24
	or	eax,esi			;Low dword is just sticky bits
	mov	edx,ebx			;Get low bits
	and	edx,(1 shl 8) - 1	;Mask to last 8 bits
	or	edx,eax			;Throwing away any bits?
	jz	SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
;Chop if negative, increase mantissa if positive
	xor	esi,esi
	and	ebx,not ((1 shl 8)-1)	;Mask off low 8 bits
	test	ch,bSign
	jz	RoundUp24		;Round up if positive
	jmp	SaveValidResult

;***********
Round24chop:
;***********
	cmp	ecx,TexpMin shl 16	;Test for Underflow
	jl	RndDenorm24
	or	eax,esi			;Low dword is just sticky bits
	mov	edx,ebx			;Get low bits
	and	edx,(1 shl 8) - 1	;Mask to last 8 bits
	or	edx,eax			;Throwing away any bits?
	jz	SaveValidResult
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
	xor	esi,esi
	and	ebx,not ((1 shl 8)-1)	;Mask off low 8 bits
	jmp	SaveValidResult

;*******************************************************************************

;*** RoundToInteger
;
;This routine is used by FISTP Int64 and BSTP.  Unlike RoundToBit, this
;unnormalizes the number into a 64-bit integer.
;
;Inputs:
;	edi = pointer to number to round in stack
;Outputs:
;	CY set if invalid operation
;	ebx:edi = rounded integer if CY clear
;	ch = sign if CY clear
;Note:
;	FIST/FISTP/BSTP exception rules are used:  If the number is too big,
;	Invalid Operation occurs.  Denormals are ignored.
;
;esi preserved

RoundSpcl64Int:
	cmp	cl,bTAG_DEN
	jz	NormRound64Int		;Ignore denormal
	cmp	cl,bTAG_EMPTY
	jnz	RoundInvalid		;All other specials are invalid
	mov	EMSEG:[CURerr],StackFlag+Invalid
	stc				;Flag exception to caller
	ret

RoundInvalid:
;Overflow on integer store is invalid according to IEEE
	mov	EMSEG:[CURerr],Invalid
	stc				;Flag exception to caller
	ret

RoundToInteger:
	mov	ebx,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high ecx, sign in ch bit 7, tag in cl
	mov	al,ch			;Save sign bit
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
	jz	RoundIntX		;Just return zero
	ja	RoundSpcl64Int
NormRound64Int:
	xor	edx,edx
	sar	ecx,16			;Bring exponent down
	cmp	ecx,-1			;Is it less than 1?
	jle	Under64Int
	cmp	ecx,63
	jg	RoundInvalid
	sub	ecx,63
	neg	ecx			;cl = amount to shift right
	mov	ch,al			;Get sign out of al
	xor	eax,eax
	cmp	cl,32			;Too big for one shift?
	jl	ShortShft64
;32-bit shift right
	xchg	edx,edi
	xchg	ebx,edi			;ebx=0 now
	shrd	eax,edx,cl
;Max total shift is 63 bits, so we know that the LSB of eax is still zero.
;We can rotate this zero to the MSB so the sticky bits in eax can be combined
;with those in edx without affecting the rounding bit in the MSB of edx.
	ror	eax,1			;MSB is now zero
ShortShft64:
;Shift count in cl is modulo-32
	shrd	edx,edi,cl
	shrd	edi,ebx,cl
	shr	ebx,cl
	or	edx,eax			;Collapse sticky bits into one dword
	jz	RoundIntX		;No sticky or round bits, so don't round
;Result will not be exact--check rounding mode
Round64Int:
	mov	EMSEG:[CURerr],Precision;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearest64Int		;Not just round-to-nearest

;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.

	bt	edi,0			;Look at LSB (for round even)
	adc	edx,(1 shl 31)-1	;CY set if round up
	jnc	RoundIntX
	mov	EMSEG:[SWcc],RoundUp
	add	edi,1			;Round
	adc	ebx,0
	jc	RoundInvalid
RoundIntX:
	ret				;CY clear, no Invalid exception

Shift64Round:
	or	edi,edi
	setnz	dl			;Set sticky bit in edx
	xor	edi,edi			;Mantissa is all zero
	jmp	Round64Int

Under64Int:
;ZF set if exponent is -1
	xchg	ebx,edx			;64-bit right shift
	mov	ch,al			;Restore sign to ch
	jz	Shift64Round		;Exp. is -1, could need to round up
	xor	edi,edi			;Mantissa is all zero
	mov	EMSEG:[CURerr],Precision;Set flag on inexact result
NotNearest64Int:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	al,EMSEG:[CWcntl]	;Get rounding control
.erre	(not RCup and RoundControl) eq RCdown
	sar	ch,7			;Expand sign through whole byte
	xor	al,ch			;Flip round mode if -
	and	al,RoundControl
	cmp	al,RCup			;Rounding up?
	jnz	RoundIntOk		;No, chop it
	mov	EMSEG:[SWcc],RoundUp
	add	edi,1
	adc	ebx,0
	jc	RoundInvalid
RoundIntOk:
	clc
	ret

;*******************************************************************************

;*** RoundToBit
;
;This is a relatively low performance routine used by FRNDINT and to
;generate internal-format denormals.  It can round to any bit position.
;
;Inputs:
;	mantissa in ebx:esi:eax, exponent in high ecx, sign in ch bit 7
;Purpose:
;	Round number to integer.  Zero exponent means number is in the
;	range [1,2), so only the MSB will survive (MSB-1 is round bit).  
;	Larger exponents keep more bits; 63 would mean no rounding.
;Outputs:
;	mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7, tag in cl
;
;Does NOT detect overflow.

NoSigBits:
;Exponent was negative: no integer part
	and	ecx,bSign shl 8		;Zero exponent, preserve sign
	mov	cl,bTAG_ZERO
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearNoSig		;Not just round-to-nearest
	cmp	edx,-1			;Exponent of -1 ==> range [.5,1)
	je	HalfBitRound
RndIntToZero:
	xor	ebx,ebx
	mov	esi,ebx			;Just return zero
	ret

NotNearNoSig:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	al,EMSEG:[CWcntl]	;Get rounding control
	sar	ch,7			;Expand sign through whole byte
	xor	al,ch			;Flip rounding bits if negative
	and	al,RoundControl
	cmp	al,RCup			;Rounding up?
	jnz	RndIntToZero		;No, chop it
RndIntToOne:
	mov	ebx,1 shl 31
	xor	esi,esi
	mov	cl,bTAG_SNGL
	mov	EMSEG:[SWcc],RoundUp
	ret

HalfBitRound:
	add	ebx,ebx			;Shift off MSB (round bit)
	or	ebx,esi
	or	ebx,eax
	jnz	RndIntToOne
	ret				;Return zero

;**********
RoundToBit:
;**********
	mov	edx,ecx			;Make copy of exponent
	sar	edx,16			;Bring rounding exponent down
	jl	NoSigBits
	mov	cl,dl
	cmp	cl,32			;Rounding in low word?
	jae	RoundLow
;When cl = 31, the RoundBit is in the low half while the LSB is in the 
;high half.  We must preserve the RoundBit when we move it to eax.
	xchg    eax,esi                 ;Low half becomes sticky bits
	or      ah,al                   ;Preserve lowest bits in ah
	add     esi,-1                  ;Set CY if any original sticky bits
	sbb     al,al                   ;Put original sticky bits in al
	mov	esi,ebx
	xor	ebx,ebx			;Shift mantissa right 32 bits
RoundLow:
	mov	edx,(1 shl 31) - 1
	shr	edx,cl			;Make mask
;Note in the case of cl = 31, edx is now zero.
	mov	edi,esi
	and	edi,edx
	or	edi,eax			;Any bits being lost?
	jz	RndSetTag		;All done
	inc	edx			;Mask for LSB
	or	EMSEG:[CURerr],Precision;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearLow		;Not just round-to-nearest
	mov	edi,edx			;Save LSB mask
	shr	edi,1			;Mask for round bit
	jc	SplitRound		;Round bit in eax?
	test	esi,edi			;Round bit set?
	jz	MaskOffLow
	dec	edi			;Mask for sticky bits
	or	edi,edx			;Sticky bits + LSB
	and	edi,esi
	or	edi,eax			;Any sticky bits set?
	jz	MaskOffLow
RoundUpThenMask:
	mov	EMSEG:[SWcc],RoundUp
	add	esi,edx			;Round up
	adc	ebx,0
	jc	RoundBumpExp
MaskOffLow:
	dec	edx			;Mask for round & sticky bits
	not	edx
	and	esi,edx			;Zero out low bits
RndSetTag:
	or	ebx,ebx			;Is it normalized?
        jns     RoundedHighHalf
        or      esi,esi                 ;Any bits in low half?
.erre   bTAG_VALID eq 1
.erre   bTAG_SNGL eq 0
        setnz   cl                      ;if low half==0 then cl=0 else cl=1
        ret

SplitRound:
;Rounding high half in esi on rounding bit in eax
	bt	esi,0			;Look at LSB
	adc	eax,(1 shl 31) - 1	;Set CY if round up
	jc	RoundUpThenMask
        or      ebx,ebx                 ;Will set ZF for jnz below
RoundedHighHalf:
;Rounding occured in high half, which had been moved low.
;Move it back up high.
;
;ZF set here on content of ebx.  If not zero, rounding high half in esi
;rippled forward into zero in ebx.
        mov     cl,bTAG_SNGL
        jnz     RndIntNorm              ;Present high half should be zero
        xchg    ebx,esi                 ;Shift left 32 bits
        ret

RndIntNorm:
;Rounded up high half of mantissa, which rolled over to 0.
	add	ecx,1 shl 16		;Increase exponent
	mov	ebx,1 shl 31		;Restore MSB
	ret				;Tag already set to SNGL

RoundBumpExp:
;Mantissa was FFFFF... and rolled over to 0 when we rounded
	add	ecx,1 shl 16		;Increase exponent
	mov	ebx,1 shl 31		;Restore MSB
	jmp	MaskOffLow

NotNearLow:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	al,EMSEG:[CWcntl]	;Get rounding control
	sar	ch,7			;Expand sign through whole byte
.erre	(not RCup and RoundControl) eq RCdown
	xor	al,ch			;Flip rounding bits if negative
	and	al,RoundControl
	cmp	al,RCup			;Rounding up?
	jz	RoundUpThenMask		;yes
	jmp	MaskOffLow		;No, chop it
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emulator.asm ===
page    78,132
        title   emulator - 80387 emulator for flat 32-bit OS
;*******************************************************************************
;        Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;emulator.asm -  80387 emulator
;       by Tim Paterson
;
;Revision History:
;
; []    09/05/91  TP    Initial 32-bit version.
; []    11/13/92  JWM   Bug fixes for esp-indexed addressing, handling of denormals.
; []    01/18/93  JWM   Bug fixes for preservation of condition & error codes.
;
;*******************************************************************************

        .386p
        .387
        .model  flat,Pascal
        option oldstructs                               ;JWM

;*******************************************************************************
;
;   Define segments.
;
;*******************************************************************************


;These equates give access to the program that's using floating point.
dseg    equ     ss                      ;Segment of program's data
cseg    equ     es                      ;Segment of program's code

edata           segment dword public 'FAR_DATA'
edata           ends

ecode           segment dword public 'CODE'
ecode           ends


assume  cs:ecode

ifdef NT386
assume ds:nothing
assume fs:edata
else
assume ds:edata
assume fs:nothing
endif

assume  es:nothing
assume  gs:nothing
assume  ss:nothing

ifdef NT386
        include  ks386.inc
        include  nt386npx.inc
        include  callconv.inc
        include  vdmtib.inc
endif                           ; NT386

;*******************************************************************************
;
;   List external functions.
;
;*******************************************************************************

ifdef  NT386
        EXTRNP   _NtRaiseException,3
        EXTRNP   _RtlRaiseStatus,1
        EXTRNP   _ZwRaiseException,3
        EXTRNP   _NpxNpSkipInstruction,1
endif           ; NT386

ifdef _DOS32EXT
        extern  _SelKrnGetEmulData:NEAR
        extern  DOS32RAISEEXCEPTION:NEAR
endif           ; _DOS32EXT

ifdef _CRUISER
        extern  DOS32IRAISEEXCEPTION:near
endif           ; CRUISER


;*******************************************************************************
;
;   Segment override macro (for NT)
;
;*******************************************************************************

ifdef NT386
        EMSEG EQU FS
else
        EMSEG EQU DS
endif

;;*******************************************************************************
;;
;;   Include some more macros and constants.
;;
;;*******************************************************************************
;
        include em387.inc
        include emstack.inc             ; stack management macros
;**************************************************************************
;**************************************************************************
;**************************************************************************
subttl  emulator.asm - Emulator Task DATA Segment
page
;*********************************************************************;
;                                                                     ;
;                 Emulator Task DATA Segment                          ;
;                                                                     ;
;*********************************************************************;

edata   segment

ifdef NT386
        db size EmulatorTebData dup (?) ; Make space for varibles
else					; ifdef NT386

Numlev          equ     8               ; Number of stack registers

InitControlWord	equ	37FH		; Default - Round near,
					; 64 bits, all exceptions masked

RoundMode       dd      ?               ;Address of rounding routine
SavedRoundMode  dd      ?               ;For restoring RoundMode
ZeroVector      dd      ?               ;Address of sum-to-zero routine
TransRound      dd      ?               ;Round mode w/o precision
Result          dd      ?               ;Result pointer

PrevCodeOff     dd      ?
PrevDataOff     dd      ?

(See note below on 'Emulator stack area')
CURstk          dd      ?

XBEGstk		db	(Numlev-1)*Reg87Len dup(?)	;Allocate register 1 - 7

BEGstk EQU offset edata:XBEGstk
INITstk EQU offset edata:XINITstk
ENDstk EQU offset edata:XENDstk

FloatTemp       db      Reg87Len dup(?)
ArgTemp         db      Reg87Len dup(?)

public Trap7Handler
Trap7Handler    dd      0

;We're DWORD aligned at this point

LongStatusWord  label   dword           ;Combined Einstall, CURerr, StatusWord
.erre   Einstall eq $
.erre   StatusWord eq $+1
.erre   CURerr eq $+3

Einstall        db      0               ; Emulator installed flag

StatusWord      label   word
    SWerr       db      ?               ; Initially no exceptions (sticky flags)
CurErrCond      label   word            ; Combined error and condition codes
    SWcc        db      ?               ; Condition codes from various operations

    CURerr      db      ?               ; initially 8087 exception flags clear
                                        ; this is the internal flag reset after
                                        ; each operation to detect per instruction
                                        ; errors

LongControlWord label   dword           ;Combined ControlWord and ErrMask
.erre   ControlWord eq $
.erre   ErrMask eq $+2

ControlWord     label   word
    CWmask      db      ?               ; exception masks
    CWcntl      db      ?               ; arithmetic control flags

    ErrMask     db      ?
    dummy       db      ?

endif                                   ; ifdef NT386 else

;*******************************************************************************
;
; Emulator stack area
;
;The top of stack pointer CURstk is initialized to the last register 
;in the list; on a real 8087, this corresponds to hardware register 0.
;The stack grows toward lower addresses, so the first push (which is
;hardware register 7) is stored into the second-to-last slot.  This gives
;the following relationship between hardware registers and memory
;locations:
;
; BEGstk --> |    reg 1    |  (lowest memory address)
; 	     |    reg 2    |
; 	     |    reg 3    |
; 	     |    reg 4    |
; 	     |    reg 5    |
; 	     |    reg 6    |
; 	     |    reg 7    |
; 	     |    reg 0    |  <-- Initial top of stack (empty)
; ENDstk -->
;
;This means that the wrap-around case on decrementing CURstk will not
;occur until the last (8th) item is pushed.
;
;Note that the physical register numbers are only used in regard to
;the tag word.  All other operations are relative the current top.


edata	ends

subttl  emulator.asm
page
;*********************************************************************;
;                                                                     ;
;               Start of Code Segment                                 ;
;                                                                     ;
;*********************************************************************;


ecode segment

;         public  __fpemulatorbegin       ; unused code label commented out for BBT
;__fpemulatorbegin equ       $            ; emulator really starts here   


        include emfinit.asm
        include emerror.asm             ; error handler
        include emdisp.asm              ; dispatch tables

        include emf386.asm              ; Flat 386 emulation entry
        include emdecode.asm            ; instruction decoder

        include emarith.asm             ; arithmetic dispatcher
        include emfadd.asm              ; add and subtract
        include emfmul.asm              ; multiply
        include emfdiv.asm              ; division
        include emround.asm             ; rounding
        include emload.asm              ; load memory operands
        include emstore.asm             ; store memory operands
        include emfmisc.asm             ; miscellaneous instructions
        include emfcom.asm              ; compare
        include emfconst.asm            ; constant loading
        include emlsbcd.asm             ; packed BCD conversion
        include emxtract.asm            ; xtract and scale
        include emfprem.asm             ; partial remainder
        include emtrig.asm              ; trig instructions
        include emftran.asm             ; transcendentals
        include emlsenv.asm
        include emfsqrt.asm             ; square root
ifndef NT386
        include emccall.asm
endif

UNUSED:
eFSETPM:
eFNOP:
eFENI:
eFDISI:
        ret                     ;Return to EMLFINISH


;        public  __fpemulatorend         ; unused code label commented out for BBT
;__fpemulatorend equ     $               ; emulator ends here  ; commented out for BBT

ecode   ends
END
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emxtract.asm ===
subttl	emxtract - FXTRACT and FSCALE instructions
        page
;*******************************************************************************
;emxtract - FXTRACT and FSCALE instructions
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Inputs:
;	edi = [CURstk]
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


XtractStackOver:
	mov	EMSEG:[SWcc],C1		;Flag stack overflow
XtractEmpty:
;Result is two Indefinites (if exception masked)
	call	StackError		;Put first indefinite at [edi] = ST(0)
	jz	XtractExit		;Error was unmasked--just exit
	mov	EMSEG:[CURstk],edi
        mov     eax,EMSEG:[edi].ExpSgn
        mov     EMSEG:[esi].ExpSgn,eax
        mov     eax,EMSEG:[edi].lManHi
        mov     EMSEG:[esi].lManHi,eax
        mov     eax,EMSEG:[edi].lManLo
        mov     EMSEG:[esi].lManLo,eax
	ret

	PrevStackWrap	edi,Xtract

EM_ENTRY eFXTRACT
eFXTRACT:
;edi = [CURstk]
	mov	esi,edi			;Save current ST
	PrevStackElem	edi,Xtract
;edi = ST(0)
;esi = ST(1) (operand)
	mov	eax,EMSEG:[esi].ExpSgn
;Exception priority requires reporting stack underflow (i.e., using an EMPTY)
;before stack overflow (i.e., no place for result).  Yes, both can happen
;together if they've messed with the stack! (ST empty when ST(-1) isn't).
	cmp	al,bTAG_EMPTY		;Is operand empty?
	jz	XtractEmpty
	cmp	EMSEG:[edi].bTag,bTAG_EMPTY	;Is there an empty spot?
	jnz	XtractStackOver
	cmp	al,bTAG_ZERO		;Is it special?
	jae	XtractSpclOrZero
XtractNormal:
	mov	EMSEG:[CURstk],edi
.erre   TexpBias eq 0
        movzx   ebx,ax                  ;Zero exponent
;Save mantissa in ST(0)
        mov     EMSEG:[edi].ExpSgn,ebx
        mov     ebx,EMSEG:[esi].lManHi
        mov     EMSEG:[edi].lManHi,ebx
        mov     ebx,EMSEG:[esi].lManLo
        mov     EMSEG:[edi].lManLo,ebx
	mov	edi,esi			;Save ST(1) pointer in edi
	shr	eax,16			;Move exponent down
	call	NormInt16		;in emload.asm
;mantissa in ebx:esi, exponent in high ecx, sign in ch bit 7, tag in cl
	mov	EMSEG:[edi].lManLo,esi
	mov	EMSEG:[edi].lManHi,ebx
	mov	EMSEG:[edi].ExpSgn,ecx
XtractExit:
	ret

XtractSpcl:
	cmp	al,bTAG_INF
	jz	XtractInf
	cmp	al,bTAG_NAN
	jz	XtractNAN
;Must be denormal.  Change tag to VALID or SNGL.
	cmp	EMSEG:[esi].lManLo,0		;Any bits in low half?
.erre	bTAG_VALID eq 1
.erre	bTAG_SNGL eq 0
	setnz	al			;if low half==0 then al=0 else al=1
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is it masked?
	jnz	XtractNormal		;If so, ignore denormalization
	ret

XtractSpclOrZero:
	ja	XtractSpcl
;Operand is zero.  Result is ST(0) = 0 (same sign), ST(1) = -infinity
	mov	EMSEG:[CURerr],ZeroDivide
	test	EMSEG:[CWmask],ZeroDivide	;Exception masked?
	jz	XtractExit
	mov	EMSEG:[CURstk],edi
        mov     EMSEG:[edi].ExpSgn,eax
        mov     eax,EMSEG:[esi].lManHi
        mov     EMSEG:[edi].lManHi,eax
        mov     eax,EMSEG:[esi].lManLo
        mov     EMSEG:[edi].lManLo,eax
	mov	EMSEG:[esi].ExpSgn,(IexpMax-IexpBias+TexpBias) shl 16 + bSign shl 8 + bTAG_INF
	mov	EMSEG:[esi].bMan7,80H	;Change zero to infinity
	ret

XtractInf:
;Result is ST(0) = infinity (same sign), ST(1) = +infinity
        mov     EMSEG:[esi].bSgn,0            ;Ensure ST(1) is positive
XtractQNAN:
        mov     EMSEG:[CURstk],edi
        mov     EMSEG:[edi].ExpSgn,eax
        mov     eax,EMSEG:[esi].lManHi
        mov     EMSEG:[edi].lManHi,eax
        mov     eax,EMSEG:[esi].lManLo
        mov     EMSEG:[edi].lManLo,eax
        ret

XtractNAN:
;Result is two QNANs, signal Invalid Operation if SNAN
	test	EMSEG:[esi].bMan7,40H		;Is it SNAN?
	jnz	XtractQNAN
	mov	EMSEG:[CURerr],Invalid
	test	EMSEG:[CWmask],Invalid
	jz	XtractExit
	or	EMSEG:[esi].bMan7,40H		;Change to QNAN
        jmp     XtractQNAN

;*******************************************************************************
;
;FSCALE instruction

;Actual instruction entry point is in emarith.asm

;Dispatch table for scale
;
;One operand has been loaded into ecx:ebx:esi ("source"), the other is
;pointed to by edi ("dest").  
;
;Tag of source is shifted.  Tag values are as follows:

.erre	TAG_SNGL	eq	0	;SINGLE: low 32 bits are zero
.erre	TAG_VALID	eq	1
.erre	TAG_ZERO	eq	2
.erre	TAG_SPCL	eq	3	;NAN, Infinity, Denormal, Empty

;Any special case routines not found in this file are in emarith.asm

tFscaleDisp	label	dword		;Source (reg)	Dest (*[di] = ST)
	dd	ScaleDouble		;single		single
	dd	ScaleDouble		;single		double
	dd	ScaleX			;single		zero
	dd	ScaleSpclDest		;single		special
	dd	ScaleDouble		;double		single
	dd	ScaleDouble		;double		double
	dd	ScaleX			;double		zero
	dd	ScaleSpclDest		;double		special
	dd	ScaleX			;zero		single
	dd	ScaleX			;zero		double
	dd	ScaleX			;zero		zero
	dd	ScaleSpclDest		;zero		special
	dd	ScaleSpclSource		;special	single
	dd	ScaleSpclSource		;special	double
	dd	ScaleSpclSource		;special	zero
	dd	TwoOpBothSpcl		;special	special
	dd	ScaleTwoInf		;Two infinites


;The unmasked response to overflow and underflow with FSCALE is complicated 
;by the extreme range it can generate.  Normally, the exponent is biased
;by 24,576 in the appropriate direction to bring it back into range.
;This may not be enough, however.  If it isn't, a result of infinity
;(with the correct sign) is returned for overflow, regardless of the 
;rounding mode.  For underflow, zero (with the correct sign) is returned,
;even if it could be represented as a denormal.  This may be the only 
;operation in which the unmasked response destroys the operands beyond 
;recovery.

BigScale:
;Scale factor is much too big.  Just shift mantissa right two bits to get
;MSB out of sign bit and ensure no overflow when we add.
	mov	cl,2			;Always shift 2 bits if it's big
	jmp	ScaleCont

ScaleDouble:
;ebx:esi = ST(1) mantissa
;ecx = ST(1) sign in bit 15, exponent in high half
;edi = pointer to ST(0)
	rol	ecx,16			;Bring exponent down, sign to top
	or	ch,ch			;Check sign of exponent
	js	ScaleX			;No work if less than zero
	cmp	cx,30			;Scale factor exceed 30 bits?
	jge	BigScale
	not	cl			;cl = amount to shift right (mod 32)
ScaleCont:
	shr	ebx,cl			;ebx = exponent adjustment for ST(0)
;Use two's complement if negative (complement and increment)
	mov     eax,ecx
	cdq				;Extend sign through edx
	xor	ebx,edx			;Complement if negative
	sub	ebx,edx			;Increment if negative
;Scale exponent
	movsx	eax,EMSEG:[edi].wExp		;Get exponent to adjust
	add	eax,ebx			;Can't overflow
	cmp	eax,IexpMax-IexpBias	;Within normal range?
	jge	ScaleOverflow
	cmp	eax,IexpMin-IexpBias
	jle	ScaleUnderflow
SaveScaledExp:
;Result fit withing normal range
	mov	EMSEG:[edi].wExp,ax		;Update exponent of ST(0)
ScaleX:
	ret

ScaleOverflow:
;eax = exponent that's too big
	mov	EMSEG:[CURerr],Overflow
	test	EMSEG:[CWmask],Overflow	;Is exception unmasked?
	jz	UnmaskedScaleOvfl
;Produce masked overflow response
	mov	al,EMSEG:[CWcntl]		;Get rounding control
	mov	ah,al
;Return max value if RCup bit = 1 and -, or RCdown bit = 1 and +
;i.e., RCup & sign OR RCdown & not sign
.erre	RCchop eq RCup + RCdown		;Always return max value
.erre	RCnear eq 0			;Never return max value
	sar	ch,7			;Expand sign through whole byte
.erre	(RCdown and bSign) eq 0		;Don't want to change real sign
	xor	ch,RCdown		;Flip sign for RCdown bit
	and	ah,ch			;RCup & sign  OR  RCdown & not sign
	jz	ScaleToInfinity		;Save Infinity
;Get max value
	sub	ecx,1 shl 16		;Drop exponent by 1
	xor	esi,esi
	dec	esi			;esi == -1
	mov	ebx,esi
SaveScaleMax:
	mov	EMSEG:[edi].lManLo,esi
	mov	EMSEG:[edi].lManHi,ebx
	mov	EMSEG:[edi].ExpSgn,ecx
	ret

UnmaskedScaleOvfl:
	sub	eax,UnderBias		;Unmasked response
	cmp	eax,IexpMax-IexpBias	;Within normal range now?
	jl	SaveScaledExp		;Use exponent biased by 24K
ScaleToInfinity:
	mov	ebx,1 shl 31
	xor	esi,esi
	mov	ecx,(IexpMax-IexpBias+TexpBias) shl 16 + bTAG_INF
	mov	ch,EMSEG:[edi].bSgn		;Give it same sign
	jmp	SaveScaleMax		;Use infinity

ScaleUnderflow:
;eax = exponent that's too big
	test	EMSEG:[CWmask],Underflow	;Is exception unmasked?
	jz	ScaleSetUnder
	cmp	eax,-32768		;Does exponent fit in 16 bits?
	jg	@F
	mov	ax,-32768		;Max value
@@:
;Set up for denormalizer
	mov	ebx,EMSEG:[edi].lManHi
	mov	esi,EMSEG:[edi].lManLo
	shrd	ecx,eax,16		;Move exponent to high end of ecx
	mov	ch,EMSEG:[edi].bSgn		;Keep sign
	xor	eax,eax			;No sticky bits
	mov	EMSEG:[Result],edi
	jmp	Denormalize		;In emround.asm

ScaleSetUnder:
;Underflow exception not masked.  Adjust exponent and try again.
	mov	EMSEG:[CURerr],Underflow
	add	eax,UnderBias		;Unmasked response
	cmp	eax,IexpMin-IexpBias	;Within normal range now?
	jg	SaveScaledExp		;Use exponent biased by 24K
	mov	EMSEG:[CURerr],Underflow
ScaleToZero:
	mov	ecx,bTAG_ZERO
	mov	ch,EMSEG:[edi].bSgn		;Give it same sign
	xor	ebx,ebx
	mov	esi,ebx
	jmp	SaveScaleMax		;Set to zero

;***
ScaleSpclDest:
	mov	al,EMSEG:[edi].bTag		;Pick up tag
	cmp	al,bTAG_INF		;Scaling infinity?
	jz	ScaleRet		;No change if so
	jmp	SpclDest		;In emarith.asm

ScaleRet:
	ret

;***
ScaleSpclSource:
	cmp	cl,bTAG_INF		;Scaling by infinity?
	jnz	SpclSource		;in emarith.asm
	or	ch,ch			;Scaling by -infinity?
	js	ScaleToZero
	cmp	EMSEG:[edi].bTag,bTAG_ZERO	;Zero scaled by +infinity?
	jnz	ScaleToInfinity
	jmp	ReturnIndefinite	;Invalid operation

;***
ScaleTwoInf:
	or	ch,ch			;Scaling by +infinity?
	jns	ScaleRet		;All done then
;Scaling infinity by -infinity
	jmp	ReturnIndefinite	;Invalid operation
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\ldrctx.c ===
/*++

Copyright (c) 1998  Microsoft Corporation

Module Name:

    ldrctx.c

Abstract:

    This module contains support for relocating executables.

Author:

    Landy Wang (landyw) 8-Jul-1998

Environment:

    User Mode only

Revision History:

--*/

#include <ldrp.h>
#include <ntos.h>

VOID
LdrpRelocateStartContext (
    IN PCONTEXT Context,
    IN LONG_PTR Diff
    )
/*++

Routine Description:

   This routine relocates the start context to mesh with the
   executable that has just been relocated.

Arguments:

   Context - Supplies a context that needs editing.

   Diff - Supplies the difference from the based address to the relocated
          address.

Return Value:

   None.

--*/
{
    Context->Eax += (ULONG)Diff;
}

VOID
LdrpCorReplaceStartContext (
    IN PCONTEXT Context
    )
/*++

Routine Description:

   This routine replaces the initial address to run by one in mscoree.dll.

Arguments:

   Context - Supplies a context that needs editing.

Return Value:

   None.

--*/
{
    Context->Eax = (ULONG)CorExeMain;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\ldrthunk.asm ===
title   "LdrInitializeThunk"
;++
;
;  Copyright (c) 1989  Microsoft Corporation
;
;  Module Name:
;
;     ldrthunk.s
;
;  Abstract:
;
;     This module implements the thunk for the LdrpInitialize APC routine.
;
;  Author:
;
;     Steven R. Wood (stevewo) 27-Apr-1990
;
;  Environment:
;
;     Any mode.
;
;  Revision History:
;
;--

.386p
        .xlist
include ks386.inc
include callconv.inc                    ; calling convention macros
        .list

        EXTRNP  _LdrpInitialize,3

_TEXT   SEGMENT DWORD PUBLIC 'CODE'
        ASSUME  DS:FLAT, ES:FLAT, SS:NOTHING, FS:NOTHING, GS:NOTHING

        page , 132

;++
;
; VOID
; LdrInitializeThunk(
;    IN PVOID NormalContext,
;    IN PVOID SystemArgument1,
;    IN PVOID SystemArgument2
;    )
;
; Routine Description:
;
;    This function computes a pointer to the context record on the stack
;    and jumps to the LdrpInitialize function with that pointer as its
;    parameter.
;
; Arguments:
;
;    NormalContext - User Mode APC context parameter (ignored).
;
;    SystemArgument1 - User Mode APC system argument 1 (ignored).
;
;    SystemArgument2 - User Mode APC system argument 2 (ignored).
;
; Return Value:
;
;    None.
;
;--

cPublicProc _LdrInitializeThunk , 4

NormalContext   equ [esp + 4]
SystemArgument1 equ [esp + 8]
SystemArgument2 equ [esp + 12]
Context         equ [esp + 16]

        lea     eax,Context             ; Calculate address of context record
        mov     NormalContext,eax       ; Pass as first parameter to
if DEVL
        xor     ebp,ebp                 ; Mark end of frame pointer list
endif
        jmp     _LdrpInitialize@12      ; LdrpInitialize

stdENDP _LdrInitializeThunk

;++
;
; VOID
; LdrpCallInitRoutine(
;    IN PDLL_INIT_ROUTINE InitRoutine,
;    IN PVOID DllHandle,
;    IN ULONG Reason,
;    IN PCONTEXT Context OPTIONAL
;    )
;
; Routine Description:
;
;    This function calls an x86 DLL init routine.  It is robust
;    against DLLs that don't preserve EBX or fail to clean up
;    enough stack.
;
;    The only register that the DLL init routine cannot trash is ESI.
;
; Arguments:
;
;    InitRoutine - Address of init routine to call
;
;    DllHandle - Handle of DLL to call
;
;    Reason - one of the DLL_PROCESS_... or DLL_THREAD... values
;
;    Context - context pointer or NULL
;
; Return Value:
;
;    FALSE if the init routine fails, TRUE for success.
;
;--

cPublicProc _LdrpCallInitRoutine , 4

InitRoutine     equ [ebp + 8]
DllHandle       equ [ebp + 12]
Reason          equ [ebp + 16]
Context         equ [ebp + 20]

stdENDP _LdrpCallInitRoutine
        push    ebp
        mov     ebp, esp
        push    esi         ; save esi across the call
        push    edi         ; save edi across the call
        push    ebx         ; save ebx on the stack across the call
        mov     esi,esp     ; save the stack pointer in esi across the call
        push    Context
        push    Reason
        push    DllHandle
        call    InitRoutine
        mov     esp,esi     ; restore the stack pointer in case callee forgot to clean up
        pop     ebx         ; restore ebx
        pop     edi         ; restore edi
        pop     esi         ; restore esi
        pop     ebp
        stdRET  _LdrpCallInitRoutine

_TEXT   ends
        end
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emtrig.asm ===
subttl	emtrig.asm - Trig functions sine, cosine, tangent
	page
;*******************************************************************************
;	 Copyright (c) Microsoft Corporation 1991
;	 All Rights Reserved
;
;emtrig.asm - Trig functions sine, cosine, tangent
;	by Tim Paterson
;
;Purpose:
;	FCOS, FPTAN, FSIN, FSINCOS instructions
;Inputs:
;	edi = [CURstk]
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;XPi is the 66-bit value of Pi from the Intel manual
XPiHi		equ	0C90FDAA2H
XPiMid		equ	02168C234H
XPiLo		equ	0C0000000H	;Extension of pi
PiOver4exp	equ	-1		;Pi/4 ~= 3/4, so exponent is -1

TinyAngleExp	equ	-32		;Smallest angle we bother with
MaxAngleExp	equ	63		;Angle that's too big

Trig1Result:
;Trig function reduction routine used by functions returning 1 value
;(FSIN and FCOS)
;edi = [CURstk] = argument pointer
;Argument has already been checked for zero.
;ZF = (tag == bTAG_ZERO)
	jb	TrigPrem
;Tagged special
	mov	al,EMSEG:[edi].bTAG
	cmp	al,bTAG_DEN
	jz	TrigDenorm
	add	sp,4			;Don't return to caller
	cmp	al,bTAG_INF
	jnz	SpclDestNotDen		;Check for Empty or NAN
	mov	EMSEG:[SWcc],C2		;Can't reduce infinity
	jmp	ReturnIndefinite

TrigDenorm:
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is denormal exception masked?
	jnz	TrigPrem		;Yes, continue
	add	sp,4			;Don't return to caller
TrigRet:
	ret


Trig2Inf:
	mov	EMSEG:[SWcc],C2		;Can't reduce infinity
	jmp	Trig2Indefinite

Trig2StackOver:
	mov	EMSEG:[SWcc],C1		;Signal overflow
Trig2StackUnder:
	mov	EMSEG:[CURerr],Invalid+StackFlag
Trig2Indefinite:
	add	sp,4			;Don't return to caller
	call	ReturnIndefinite
	jz	TrigRet			;Unmasked, don't change registers
;Produce masked response
	mov	EMSEG:[CURstk],esi		;Push stack
	mov	edi,esi
	jmp	ReturnIndefinite

Trig2Special:
	cmp	al,bTAG_DEN
	jz	TrigDenorm
	cmp	al,bTAG_INF
	jz	Trig2Inf
;Must be a NAN
	add	sp,4			;Don't return to caller
	call	DestNAN
	jz	TrigRet			;Unmasked, don't change registers
;Produce masked response
	mov	EMSEG:[CURstk],esi		;Push stack
        mov     eax,EMSEG:[edi].ExpSgn
        mov     EMSEG:[esi].ExpSgn,eax
        mov     eax,EMSEG:[edi].lManHi
        mov     EMSEG:[esi].lManHi,eax
        mov     eax,EMSEG:[edi].lManLo
        mov     EMSEG:[esi].lManLo,eax
	ret

Trig2Zero:
	add	sp,4			;Don't return to caller
	mov	EMSEG:[CURstk],esi
	mov	edi,esi
;Amazing coincidence: both FSINCOS and FPTAN return the same result for
;a zero argument:
;	FSINCOS returns ST(0) = cos(0) = 1, ST(1) = sin(0) = 0.
;	FPTAN returns ST(0) = 1 always, ST(1) = tan(0) = 0.
;Return zero has same sign as argument zero, so we don't need to touch
;it -- just push +1.0.
	jmp	ReturnOne

TrigOutOfRange:
	mov	EMSEG:[SWcc],C2		;Signal argument not reduced
	add	sp,4
	ret

PrevStackWrap	esi,Trig2		;Tied to PrevStackElem below

Trig2Result:
;Trig function reduction routine used by functions returning 2 values
;(FSINCOS and FPTAN)
;edi = [CURstk] = argument pointer
	mov	esi,edi
	PrevStackElem	esi,Trig2	;esi points to second result location
	mov	al,EMSEG:[edi].bTAG	;Get tag
	cmp	al,bTAG_EMPTY		;Stack underflow if empty
	jz	Trig2StackUnder
	cmp	EMSEG:[esi].bTAG,bTAG_EMPTY	;Stack overflow if not empty
	jnz	Trig2StackOver
	cmp	al,bTAG_ZERO		;Is it Special?
	ja	Trig2Special
	jz	Trig2Zero
;Fall into TrigPrem

;****
;TrigPrem
;
;This routine reduces an angle in radians to the range [0, pi/4].
;Angles in odd-numbered octants have been subtracted from pi/4.
;It uses a 66-bit value for pi, as required by the 387.
;TrigPrem uses the same two-stage algorithm as FPREM (see 
;emfprem.asm).	However, it is limited to an argument < 2^63.
;
;Inputs:
;	edi = [CURstk]
;Outputs:
;	ebx:esi = remainder, normalized
;	high ecx = exponent, cl = tag
;	al = octant
;	edi = [CURstk]

TrigPrem:
	mov	EMSEG:[Result],edi
	mov	eax,EMSEG:[edi].lManLo
	mov	edx,EMSEG:[edi].lManHi
	movsx	ebx,EMSEG:[edi].wExp
	cmp	ebx,MaxAngleExp
	jge	TrigOutOfRange
	xor	edi,edi			;Extend dividend
	xor	esi,esi			;Quotient, in case we skip stage 1
.erre	PiOver4exp eq -1
	inc	ebx			;Subtract exponent of pi/4
	jl	ExitTrigPrem		;If dividend is smaller, return it.
;We now know that 0 <= ExpDif < 64, so it fits in bl.
	cmp	bl,31			;Do we need to do stage 1?
	jl	FitPi			;No, start stage 2

;FPREM stage 1
;
;Exponent difference is at least 31.  Use 32-bit division to compute
;quotient and exact remainder, reducing exponent difference by 31.
;
;edx:eax = dividend
;ebx = exponent difference

;Shift dividend right one bit to be sure DIV instruction won't overflow
;This means we'll be reducing the exponent difference by 31, not 32
	xor	ebp,ebp			;Dividend extension
	shrd	ebp,eax,1
	shrd	eax,edx,1
	shr	edx,1

	sub	bl,31			;Exponent reduced
	mov	ecx,XPiHi
	div	ecx			;Guess a quotient "digit"

;Check out our guess.  
;Currently, remainder in edx = (high dividend) - (quotient * high pi).
;(High dividend is the upper 64 bits--ebp has 1 bit.)  The definition 
;of remainder is (all dividend) - (quotient * all pi).  So if we
;subtract (quotient * low pi) from edx:ebp, we'll get the true 
;remainder.  If it's negative, our guess was too big.

	mov	esi,eax			;Save quotient
	mov	ecx,edx			;Save remainder

;The pi/4 we use has two bits set below the first 64 bits.  This means
;we must add another 3/4 of the quotient into the amount to subtract,
;which we'll compute by rounding the low 32 bits up 1, then subtracting 
;1/4 of quotient.  But since we're computing the amount to subtract from
;the remainder, we'll add the 1/4 of the quotient to the remainder instead
;of subtracting it from the amount to subtract.

.erre	XPiLo eq (3 shl 30)
	mov	eax,XPiMid+1
	mul	esi			;Quotient * low pi
;Note that ebp is either 0 or 800...00H
	shr	ebp,30			;Move down to low end
	shld	ebp,esi,30		;Move back up, adding 1/4 of quotient
	mov	edi,esi			;Another copy of quotient
	shl	edi,30			;Keep last two bits
;edx:eax has amount to subtract to get correct remainder from ecx:ebp:edi
	sub	ebp,eax
	sbb	ecx,edx			;Subtract from remainder
	mov	eax,ebp
	mov	edx,ecx			;Remainder back to edx:eax:edi
	jnc	TrigPremNorm		;Was quotient OK?
TrigCorrect:
	dec	esi			;Quotient was too big
	add	edi,XPiLo
	adc	eax,XPiMid		;Add divisor back into remainder
	adc	edx,XPiHi
	jnc	TrigCorrect		;Repeat if quotient is still too big
	jmp	TrigPremNorm

;FPREM stage 2
;
;Exponent difference is less than 32.  Use restoring long division to
;compute quotient bits until exponent difference is zero.  Note that we
;often get more than one bit/loop:  BSR is used to scan off leading
;zeros each time around.  Since the divisor is normalized, we can
;instantly compute a zero quotient bit for each leading zero bit.

TrigPremLoop:
;edx:eax:edi = dividend (remainder) minus pi/4
;esi = quotient
;ebx = exponent difference
;
;If D is current dividend and p is pi/4, then we have edx:eax:edi = D - p, 
;which is negative.  We want 2*D - p, which is positive.  
;2*D - p = 2*(D - p) + p.
	add	edi,edi			;2*(D - p)
	adc	eax,eax
	adc	edx,edx

	add	edi,XPiLo		;2*(D-p) + p = 2*D - p
	adc	eax,XPiMid
	adc	edx,XPiHi

	add	esi,esi			;Double quotient too
	dec	ebx			;Decrement exponent difference
PiFit:
	inc	esi
TrigPremNorm:
	bsr	ecx,edx			;Find first 1 bit
	jz	TrigPremZero
	not	cl
	and	cl,1FH			;Convert bit no. to shift count
	sub	ebx,ecx			;Reduce exponent difference
	jl	TrigTooFar
	shld	edx,eax,cl
	shld	eax,edi,cl
	shl	edi,cl			;Finish normalize shift
	shl	esi,cl			;Shift quotient
FitPi:
;Dividend could be larger or smaller than divisor
	sub	edi,XPiLo
	sbb	eax,XPiMid
	sbb	edx,XPiHi
	jnc	PiFit
;Couldn't subtract pi/2 from dividend.	
;edx:eax:edi = dividend - pi/4, which is negative
	or	ebx,ebx			;Is exponent difference zero?
	jg	TrigPremLoop
;If quotient (octant number) is odd, we have subtracted an odd number of
;pi/4's.  However, simple angle reductions work in multiples of pi/2.
;We will keep the extra pi/4 we just subtracted if the octant was odd.
;This will give a result range of [-pi/4, pi/4].  
	test	esi,1			;Is octant odd?
	jz	EvenOctant
NegPremResult:
;-pi/4 < dividend < 0.  Negate this since we use sign-magnitude representation.
	not	edx			;96-bit negation
	not	eax
	neg	edi
	sbb	eax,-1
	sbb	edx,-1
;May need to normalize
	bsr	ecx,edx
	jz	TrigNorm32
	lea	ebx,[ebx+ecx-31]	;Fix up exponent for normalization
	not	cl			;Convert bit no. to shift count
TrigShortNorm:
	shld	edx,eax,cl
	shld	eax,edi,cl
	shl	edi,cl			;Finish normalize shift
RoundPrem:
;Must round 66-bit result to 64 bits.
;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.  This rounding rule is implemented by adding RoundBit-1
;(7F..FFH), setting CY if round up.  
	bt	eax,0			;Is mantissa even or odd? (set CY)
	adc	edi,(1 shl 31)-1	;Sum LSB & sticky bits--CY if round up
	adc	eax,0
	adc	edx,0
ExitTrigPrem:
;edx:eax = remainder, normalized
;esi = quotient
;ebx = exponent difference, zero or less
.erre	PiOver4exp eq -1
	dec	ebx			;True exponent
.erre	bTAG_SNGL eq 0
	shrd	ecx,ebx,16		;Exponent to high ecx
	mov	ebx,edx			;High mant. to ebx
	xchg	esi,eax			;Low mant. to esi, octant to eax
	or      esi,esi			;Any bits in low half?
.erre   bTAG_VALID eq 1
.erre   bTAG_SNGL eq 0
	setnz   cl			;if low half==0 then cl=0 else cl=1
	mov	edi,EMSEG:[CURstk]
	test	EMSEG:[edi].bSgn,bSign	;Was angle negative?
	jnz	FlipOct			;Yes, flip octant over
	ret

FlipOct:
;Angle was negative.  Subtract octant from 7.
	neg	al
	add	al,7
	ret

EvenOctant:
;Restore dividend
	add	edi,XPiLo
	adc	eax,XPiMid
	adc	edx,XPiHi
	jmp	RoundPrem

TrigTooFar:
;Exponent difference in ebx went negative when reduced by shift count in ecx.
;We need a quotient corresponding to exponent difference of zero.
	add	ecx,ebx			;Compute previous exponent difference
	shl	esi,cl			;Fix up quotient
	sub	ecx,ebx			;Restore shift count
	test	esi,1			;Is octant odd?
	jz	TrigShortNorm		;No, go normalize
	xor	ebx,ebx			;Restore old exponent difference (zero)
SubPiOver4:
;We are here if exponent difference was zero and octant is odd.
;As noted above, we need to reduce the angle by a multiple of pi/2,
;not pi/4.  We will subtract one more pi/4, which will make the
;result range [-pi/4, pi/4].
	sub	edi,XPiLo
	sbb	eax,XPiMid
	sbb	edx,XPiHi
	jmp	NegPremResult

TrigPremZero:
;High dword of remainder is all zero, so we've reduced exponent difference
;by 32 bits and overshot.  We need a quotient corresponding to exponent 
;difference of zero, so we just shift it by the original difference.  Then
;we need to normalize the rest of the remainder.
	mov	ecx,ebx			;Get exponent difference
	shl	esi,cl			;Fix up quotient
	test	esi,1			;Is octant odd?
	jnz	SubPiOver4		;Yes, go subtract another pi/4
TrigNorm32:
	bsr	ecx,eax
	jz	TinyTrig
	lea	ebx,[ebx+ecx-31-32]	;Fix up exponent for normalization
	mov	edx,eax
	mov	eax,edi			;Shift left by 32 bits
	not	cl			;Convert bit no. to shift count
	shld	edx,eax,cl		;Normalize remainder
	shl	eax,cl
	jmp	ExitTrigPrem

TinyTrig:
;Upper 64 bits of remainder are all zero.  We are assured that the extended
;remainder is never zero, though.
	mov	edx,edi			;Shift left 64 bits
	bsr	ecx,edi
	lea	ebx,[ebx+ecx-31-64]	;Fix up exponent for normalization
	not	cl			;Convert bit no. to shift count
	shl	edx,cl			;Normalize
	jmp	ExitTrigPrem

;*******************************************************************************

EM_ENTRY eFCOS
eFCOS:
    and		[esp].[OldLongStatus+4],NOT(C2 SHL 16)	;clear C2
	cmp	EMSEG:[edi].bTAG,bTAG_ZERO
	jz	ReturnOne
	call	Trig1Result
;ebx:esi,ecx = reduced argument
;eax = octant
	mov	ch,80H			;Assume negative
	test	al,110B			;Negative in octants 2 - 5
	jpo	@F			;Occurs when 1 of these bits are set
	xor	ch,ch			;Actually positve
@@:
	test	al,011B			;Look for octants 0,3,4,7
	jpo	TakeSine		;Use sine if not
TakeCosine:
	cmp	ecx,TinyAngleExp shl 16	;Is angle really small?
	jl	CosReturnOne		;cos(x) = 1 for tiny x
CosNotTiny:
	mov	edi,offset tCosPoly
;Note that argument needs to be saved in ArgTemp (by EvalPolySetup) in case 
;we were called from eFSINCOS and we'll need the arg for the sine.  Argument
;is not needed for cosine, however (just its square).
	call	EvalPolySetup		;In emftran.asm
	mov	ch,EMSEG:[ArgTemp].bSgn	;Get sign we already figured out
TransUnround:
;The last operation performed a simple round nearest, without setting the 
;C1 status bit if round up occured.  We reverse this last rounding now
;so we can do the user's selected rounding mode.  We also ensure that
;the answer is never exact.
	sub	eax,(1 shl 31)-1	;Sum LSB & sticky bits--CY if round up
	jz	UnroundExact		;Answer looks exact, but it's not
	sbb	esi,0
	sbb	ebx,0
	jns	PolyDropExponent	;We had rounded up exponent too
FinalTransRound:
;A jump through [TransRound] is only valid if the number is known not to
;underflow.  Unmasked underflow requires [RoundMode] be set.
	mov	edx,EMSEG:[TransRound]
	mov	EMSEG:[RoundMode],edx
	call	edx			;Perform user's rounding
RestoreRound:
;Restore rounding vectors
	mov	EMSEG:[ZeroVector],offset SaveResult
	mov	eax,EMSEG:[SavedRoundMode]
	mov	EMSEG:[RoundMode],eax
	ret

UnroundExact:
	inc	eax			;Let's say our answer is a bit small
	jmp	FinalTransRound

PolyDropExponent:
	sub	ecx,1 shl 16		;Decrement exponent
	or	ebx,1 shl 31		;Set MSB
	jmp	FinalTransRound


SinRet:
	ret

SaveTinySin:
;Argument in ebx:esi,ecx is small enough so that sin(x) = x, which happens
;when x - x^3/6 = x [or 1 - x^2/6 = 1].  Note that the infinitely precise
;result is slightly less than the argument.  To get the correct answer for
;any rounding mode, we decrement the argument and set up for rounding.
	mov	eax,-1			;Set up rounding bits
	sub	esi,1
	sbb	ebx,0			;Drop mantissa by one
	js	FinalTransRound		;Still normalized?
;mantissa must have been 800..000H, set it to 0FFF...FFFH and drop exponent
	mov	ebx,eax			;ebx = -1
	sub	ecx,1 shl 16		;Drop exponent by one
	jmp	FinalTransRound


EM_ENTRY eFSIN
eFSIN:
    and		[esp].[OldLongStatus+4],NOT(C2 SHL 16)	;clear C2
	cmp	EMSEG:[edi].bTAG,bTAG_ZERO
	jz	SinRet			;Return zero for zero argument
	call	Trig1Result
	mov	ch,al
	shl	ch,7-2			;Move bit 2 to bit 7 as sign bit
ReducedSine:
;ebx:esi,ecx = reduced argument
;ch = correct sign
;eax = octant
	test	al,011B			;Look for octants 0,3,4,7
	jpo	TakeCosine		;Use cosine if not
TakeSine:
	cmp	ecx,TinyAngleExp shl 16	;Is angle really small?
	jl	SaveTinySin		;sin(x) = x for tiny x

;The polynomial for sine is  sin(x) = x * P(x^2).  However, the degree zero
;coefficient of P() is 1, so  P() = R() + 1, where R() has no degree zero
;term.	Thus  sin(x) = x * [R(x^2) + 1] = x * R(x^2) + x.
;
;What's important here is that adding 1 to R(x^2) can blow away a lot of
;precision just before we do that last multiply by x.  Note that x < pi/4 < 1,
;so that x^2 is often << 1.  The precision is lost when R(x^2) is shifted
;right to align its binary point with 1.0.  This can cause a loss of at
;least 1 bit of precision after the final multiply by x in addition to 
;rounding errors.
;
;To avoid this precision loss, we use the alternate form given above,
;sin(x) = x * R(x^2) + x.  Instead of adding 1.0 and multiplying by x,
;we multiply by x and add x--exactly the same level of difficulty.  But
;the mulitply has all of R(x^2)'s precision available.
;
;Because the polynomial R() has no zero-degree term, we give EvalPoly
;one degree less (so we don't have to add zero as the last term).
;Then we have to multiply once more by x^2 since we left the loop early.

SineNotTiny:
	mov	edi,offset tSinPoly
	call	EvalPolySetup		;In emftran.asm
SineFinish:

ifdef NT386
        mov	edi,YFloatTemp
else
	mov	edi,offset edata:FloatTemp
endif
	call	PolyMulDouble		;Last coefficient in R(x^2)

ifdef NT386
	mov	edi,YArgTemp		;Point to original x
else
	mov	edi,offset edata:ArgTemp ;Point to original x
endif

	call	PolyMulDouble		;Compute x * R(x^2)

ifdef NT386
	mov	edi,YArgTemp		;Point to original x
else
	mov	edi,offset edata:ArgTemp ;Point to original x
endif

	push	offset TransUnround
	jmp	PolyAddDouble		;Compute x * R(x^2) + x


EM_ENTRY eFPTAN
eFPTAN:
    and		[esp].[OldLongStatus+4],NOT(C2 SHL 16)	;clear C2
	call	Trig2Result
	push	offset TanPushOne	; Push 1.0 when we're all done
;ebx:esi,ecx = reduced argument
;eax = octant
	mov	ch,al
	shl	ch,7-1			;Move bit 1 to bit 7 as sign bit
;Note that ch bit 6 now has even/odd octant, which we'll need when we're
;done to see if we should take reciprocal.
	cmp	ecx,TinyAngleExp shl 16	;Is angle really small?
	jl	TinyTan
	mov	edi,offset tTanPoly
	call	Eval2Poly		;In emftran.asm
	mov	edi,EMSEG:[CURstk]	;Point to first result
	push	offset TransUnround	;Return address of divide
	test	EMSEG:[ArgTemp].bSgn,0C0H	;Check low 2 bits of octant
;Given the reduced input range, the result can never overflow or underflow.
;It is must then be safe to assume neither operand is zero.
	jpe	DivDouble		;Tan() octants 0,3,4,7
	jmp	DivrDouble		;CoTan()

TinyTan:
	test	ch,0C0H			;Check low 2 bits of octant
	jpe	SaveTinySin		;Octants 0,3,4,7: tan(x) = x for tiny x
;Need reciprocal of reduced argument
	mov	edi,esi
	mov	esi,ebx			;Mantissa in esi:edi
	mov	ebx,ecx			;ExpSgn to ebx
	mov	edx,1 shl 31		;Load 1.0
	xor	eax,eax
.erre	TexpBias eq 0
	xor	ecx,ecx			;Sign and exponent are zero
;dividend mantissa in edx:eax, exponent in high ecx, sign in ch bit 7
;divisor mantissa in esi:edi, exponent in high ebx, sign in bh bit 7
	push	offset TransUnround	;Return address of divide
;Note that this can never overflow, because the reduced argument is never
;smaller than about 2^-65.
	jmp	DivDoubleReg


PrevStackWrap	edi,Tan			;Tied to PrevStackElem below

TanPushOne:
	PrevStackElem	edi,Tan		;edi points to second result location
	mov	EMSEG:[CURstk],edi
ReturnOne:
	mov	EMSEG:[edi].lManLo,0
	mov	EMSEG:[edi].lManHi,1 shl 31
	mov	EMSEG:[edi].ExpSgn,(0-TexpBias) shl 16 + bTAG_SNGL
	ret


PrevStackWrap	edi,SinCos		;Tied to PrevStackElem below

eFSINCOS:
    and		[esp].[OldLongStatus+4],NOT(C2 SHL 16)	;clear C2
	call	Trig2Result
;Figure out signs
	mov	ch,al			;Start with sign of sine
	shl	ch,7-2			;Move bit 2 to bit 7 as sign bit
	mov	ah,80H			;Assume sign of cosine is negative
	test	al,110B			;Negative in octants 2 - 5
	jpo	@F			;Occurs when 1 of these bits are set
	xor	ah,ah			;Actually positve
@@:
;ch = sign of sine
;ah = sign of cosine
	cmp	ecx,TinyAngleExp shl 16	;Is angle really small?
	jl	TinySinCos
	push	eax			;Save octant and sign of cosine
	call	ReducedSine		;On exit, edi = [CURstk]
	pop	eax
;The Sin() funcion restored the rounding vectors to normal.  Set them back.
	mov	EMSEG:[RoundMode],offset PolyRound
	mov	EMSEG:[ZeroVector],offset PolyZero
	PrevStackElem	edi,SinCos	;edi points to second result location
	mov	EMSEG:[CURstk],edi
	mov	EMSEG:[Result],edi
;Load x^2 back into registers
	mov	ecx,EMSEG:[FloatTemp].ExpSgn
	mov	ebx,EMSEG:[FloatTemp].lManHi
	mov	esi,EMSEG:[FloatTemp].lManLo
	mov	EMSEG:[ArgTemp].bSgn,ah	;Save sign
	test	al,011B			;Look for octants 0,3,4,7
	jpo	FastSine		;Use sine if not
	mov	edi,offset tCosPoly
	call	EvalPoly		;In emftran.asm
	mov	ch,EMSEG:[ArgTemp].bSgn	;Get sign we already figured out
	jmp	TransUnround

FastSine:
	mov	edi,offset tSinPoly
	push	offset SineFinish
	jmp	EvalPoly		;In emftran.asm

TinySinCos:
;ch = sign of sine
;ah = sign of cosine
;ebx:esi,high ecx = reduced argument
;edi = [CURstk]
	test	al,011B			;Look for octants 0,3,4,7
	jpo	TinyCosSin		;Take cosine first if not
	push	eax
	call	SaveTinySin		;For sine, arg is result
	pop	ecx
;edi = [CURstk]
;ch = sign of cosine
;Set cosine to 1.0
	PrevStackElem	edi,TinySinCos	;edi points to second result location
	mov	EMSEG:[CURstk],edi
	mov	EMSEG:[Result],edi
CosReturnOne:
;Cosine is nearly equal to 1.0.  Put in next smaller value and round it.
	mov	ebx,-1
	mov	esi,ebx			;Set mantissa to -1
	mov	eax,ebx			;Set up rounding bits
.erre	TexpBias eq 0
	and	ecx,bSign shl 8		;Keep only sign
	sub	ecx,1 shl 16		;Exponent of -1
;A jump through [TransRound] is only valid if the number is known not to
;underflow.  Unmasked underflow requires [RoundMode] be set.
	jmp	EMSEG:[TransRound]

	PrevStackWrap	edi,TinySinCos

	PrevStackWrap	edi,TinyCosSin

TinyCosSin:
;Sine is nearly 1.0, cosine is argument
;
;ch = sign of sine
;ah = sign of cosine
;ebx:esi,high ecx = reduced argument
;edi = [CURstk]
	xchg	ah,ch			;Cosine sign to ch, sine sign to ah
	push	edi			;Save place for sine
	PrevStackElem	edi,TinyCosSin	;edi points to second result location
	mov	EMSEG:[CURstk],edi
	mov	EMSEG:[Result],edi
	push	eax
	call	SaveTinySin		;For sine, arg is result
	pop	ecx
;ch = sign of sine
	pop	EMSEG:[Result]		;Set up location for sine
	jmp	CosReturnOne

;*******************************************************************************

;********************* Polynomial Coefficients *********************

;These polynomial coefficients were all taken from "Computer Approximations"
;by J.F. Hart (reprinted 1978 w/corrections).  All calculations and 
;conversions to hexadecimal were done with a character-string calculator
;written in Visual Basic with precision set to 30 digits.  Once the constants
;were typed into this file, all transfers were done with cut-and-paste
;operations to and from the calculator to help eliminate any typographical
;errors.


tCosPoly	label	word

;These constants are derived from Hart #3824: cos(x) = P(x^2),
;accurate to 19.45 digits over interval [0, pi/4].  The original 
;constants in Hart required that the argument x be divided by pi/4.  
;These constants have been scaled so this is no longer required.
;Scaling is done by multiplying the constant by a power of 4/pi.
;The power is given in the table.

	dd	7			;Degree seven

;  Original Hart constant	      power	Scaled constant
;
;-0.38577 62037 2		 E-12  14  -0.113521232057839395845871741043E-10
;Hex value:    0.C7B56AF786699CF1BD13FD290 HFFDC
	dq	0C7B56AF786699CF2H
	dw	(bSign shl 8)+bTAG_VALID,0FFDCH-1

;+0.11500 49702 4263		  E-9  12  +0.208755551456778828747793797596E-8
;Hex value:    0.8F74AA3CCE49E68D6F5444A18 HFFE4
	dq	08F74AA3CCE49E68DH
	dw	bTAG_VALID,0FFE4H-1

;-0.24611 36382 63700 5		  E-7  10  -0.275573128656960822243472872247E-6
;Hex value:    0.93F27B7F10CC8A1703EFC8A04 HFFEB
	dq	093F27B7F10CC8A17H
	dw	(bSign shl 8)+bTAG_VALID,0FFEBH-1

;+0.35908 60445 88581 953	  E-5	8  +0.248015872828994630247806807317E-4
;Hex value:    0.D00D00CD6BB3ECD17E10D5830 HFFF1
	dq	0D00D00CD6BB3ECD1H
	dw	bTAG_VALID,0FFF1H-1

;-0.32599 18869 26687 55044	  E-3	6  -0.138888888888589604343951947246E-2
;Hex value:    0.B60B60B609B165894CFE522AC HFFF7
	dq	0B60B60B609B16589H
	dw	(bSign shl 8)+bTAG_VALID,0FFF7H-1

;+0.15854 34424 38154 10897 54	  E-1	4  +0.416666666666664302573692446873E-1
;Hex value:    0.AAAAAAAAAAA99A1AF53042B08 HFFFC
	dq	0AAAAAAAAAAA99A1BH
	dw	bTAG_VALID,0FFFCH-1

;-0.30842 51375 34042 45242 414	  E0	2  -0.499999999999999992843582920899E0
;Hex value:    0.FFFFFFFFFFFFFEF7F98D3BFA8 HFFFF
	dq	0FFFFFFFFFFFFFEF8H
	dw	(bSign shl 8)+bTAG_VALID,0FFFFH-1

;+0.99999 99999 99999 99996 415	  E0	0  (no change)
;Hex value     0.FFFFFFFFFFFFFFFF56B402618 H0
	dq	0FFFFFFFFFFFFFFFFH
	dw	bTAG_VALID,00H-1


tSinPoly	label	word

;These constants are derived from Hart #3044: sin(x) = x * P(x^2),
;accurate to 20.73 digits over interval [0, pi/4].  The original 
;constants in Hart required that the argument x be divided by pi/4.  
;These constants have been scaled so this is no longer required.
;Scaling is done by multiplying the constant by a power of 4/pi.
;The power is given in the table.

	dd	7-1			;Degree seven, but the last coefficient
					;is 1.0 and is not listed here.

;  Original Hart constant	      power	Scaled constant
;
;-0.20225 31292 93		 E-13  15  -0.757786788401271156262125540409E-12
;Hex value:    0.D54C4AF2B524F0F2D6411C90A HFFD8
	dq	0D54C4AF2B524F0F3H
	dw	(bSign shl 8)+bTAG_VALID,0FFD8H-1

;+0.69481 52035 0522		 E-11  13  +0.160583476232246065559545749398E-9
;Hex value:    0.B0903AF085DA66030F16E43BC HFFE0
	dq	0B0903AF085DA6603H
	dw	bTAG_VALID,0FFE0H-1

;-0.17572 47417 61708 06	  E-8  11  -0.250521047382673309542092418731E-7
;Hex value:    0.D73229320D2AF05971AC96FF4 HFFE7
	dq	0D73229320D2AF059H
	dw	(bSign shl 8)+bTAG_VALID,0FFE7H-1

;+0.31336 16889 17325 348	  E-6	9  +0.275573192133901687156480447942E-5
;Hex value:    0.B8EF1D2984D2FBA28A9CC9DEE HFFEE
	dq	0B8EF1D2984D2FBA3H
	dw	bTAG_VALID,0FFEEH-1

;-0.36576 20418 21464 00052 9	  E-4	7  -0.198412698412531058609618529749E-3
;Hex value:    0.D00D00D00C3FDDD7916E5CB28 HFFF4
	dq	0D00D00D00C3FDDD8H
	dw	(bSign shl 8)+bTAG_VALID,0FFF4H-1

;+0.24903 94570 19271 62752 519	  E-2	5  +0.83333333333333203341753387264E-2
;Hex value:    0.8888888888884C95D619A0343 HFFFA
	dq	08888888888884C96H
	dw	bTAG_VALID,0FFFAH-1

;-0.80745 51218 82807 81520 2582  E-1	3  -0.166666666666666666281276062229E0
;Hex value:    0.AAAAAAAAAAAAAA8E3AD80EAB8 HFFFE
	dq	0AAAAAAAAAAAAAA8EH
	dw	(bSign shl 8)+bTAG_VALID,0FFFEH-1

;+0.78539 81633 97448 30961 41845 E0	1  +0.99999999999999999999812025812E0
;Hex value:    0.FFFFFFFFFFFFFFFFF71F88110 H0
;	dq	8000000000000000H	;This constant of 1.0 omitted here.
;	dw	bTAG_VALID,0		;   It is handled in code.


tTanPoly	label	word

;These constants are derived from Hart #4286: tan(x) = x * P(x^2) / Q(x^2),
;accurate to 19.94 digits over interval [0, pi/4].  The original 
;constants in Hart required that the argument x be divided by pi/4.  
;These constants have been scaled so this is no longer required.
;Scaling is done by multiplying the constant by the same power of 4/pi
;as the power of x the constant is used on.  However, the highest
;degree coefficient of Q() is 1, and after scaling this way it would
;become (4/pi)^8.  In order to keep this coefficient equal to one,
;we scale everything again by (pi/4)^8.  This scaling is partially
;canceled by the original scaling by powers of 4/pi, and the net
;resulting power of pi/4 is given in the table.


	dd	3			;First poly is degree 3

;  Original Hart constant	        power	Scaled constant
;
;-.45649 31943 86656 31873 96113 7    E2  1  -35.8528916474714232910463077546
;Hex value:    0.8F695C6D93AF6F97B6E022AB3 H6
        dq      08F695C6D93AF6F98H
        dw      (bSign shl 8)+bTAG_VALID,06H-1

;+.14189 85425 27617 78388 00394 831  E5  3  +6874.60229709782436592720603503
;Hex value:    0.D6D4D181240D0D08C88DF4AA6 HD
        dq      0D6D4D181240D0D09H
        dw      bTAG_VALID,0DH-1

;-.89588 84400 67680 41087 29639 541  E6  5  -267733.884797157298951145495276
;Hex value:    0.82BABC504220C62B1D0722684 H13
        dq      082BABC504220C62BH
        dw      (bSign shl 8)+bTAG_VALID,013H-1

;+.10888 60043 72816 87521 38857 983  E8  7  +2007248.9111748838841548144685
;Hex value:    0.F506874A160EB9C0994AADD6A H15
        dq      0F506874A160EB9C1H
        dw      bTAG_VALID,015H-1



	dd	4			;Second poly is degree 4
;NOTE: Eval2Poly assumes the first coefficient is 1.0, so it is omitted

;  Original Hart constant	        power	Scaled constant
;
;-.10146 56190 25288 53387 54401 947  E4  2  -625.890950057027419879480354834
;Hex value:    0.9C790553635355A95241A5324 HA
        dq      09C790553635355A9H
        dw      (bSign shl 8)+bTAG_VALID,0AH-1

;+.13538 27128 05119 09382 89294 872  E6  4  +51513.6992033752080924797647367
;Hex value:    0.C939B2FEFE0DC585E649870FE H10
        dq      0C939B2FEFE0DC586H
        dw      bTAG_VALID,010H-1

;-.39913 09518 03516 51504 43427 94   E7  6  -936816.855188785264866481436899
;Hex value:    0.E4B70DAEDA6F89E5A7CE626FA H14
        dq      0E4B70DAEDA6F89E6H
        dw      (bSign shl 8)+bTAG_VALID,014H-1

;+.13863 79666 35676 29165 33913 361  E8  8  +2007248.91117488388417770850458
;Hex value:    0.F506874A160EB9C0CCD8313BC H15
        dq      0F506874A160EB9C1H
        dw      bTAG_VALID,015H-1
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\npxnp.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    npxnp.c

Abstract:

    This module contains support for non-Flat mode NPX faults when
    the application has it's CR0_EM bit clear.

Author:

    Ken Reneris (kenr) 8-Dec-1994

Environment:

    User Mode only

Revision History:

--*/


#pragma warning(disable:4201)   // nameless struct/union

#include "csrdll.h"

static UCHAR MOD16[] = { 0, 1, 2, 0 };
static UCHAR MOD32[] = { 0, 1, 4, 0 };

UCHAR
NpxNpReadCSEip (
    IN PCONTEXT Context
    )
#pragma warning(disable:4035)
{
    _asm {
        push    es
        mov     ecx, Context
        mov     eax, [ecx] CONTEXT.SegCs
        mov     es, ax
        mov     eax, [ecx] CONTEXT.Eip
        inc     dword ptr [ecx] CONTEXT.Eip     ; Advance EIP
        mov     al, es:[eax]
        pop     es
    }
}
#pragma warning(default:4035)


VOID
NpxNpSkipInstruction (
    IN PCONTEXT Context
    )
/*++

Routine Description:

    This functions gains control when the system has no installed
    NPX support, but the thread has cleared it's EM bit in CR0.

    The purpose of this function is to move the instruction
    pointer forward over the current NPX instruction.

Enviroment:

    16:16 mode

Arguments:

Return Value:

--*/
{
    BOOLEAN     fPrefix;
    UCHAR       ibyte, Mod, rm;
    UCHAR       Address32Bits;
    ULONG       CallerCs;

    Address32Bits = 0;                          // assume called from 16:16

    //
    // Lookup and determine callers default mode
    //

    CallerCs = Context->SegCs;
    _asm {
        mov     eax, CallerCs
        lar     eax, eax
        test    eax, 400000h
        jz      short IsDefault16Bit

        mov     Address32Bits, 1

IsDefault16Bit:
    }

    //
    // No sense in using a try-except since we are not on the
    // correct stack.  A fault here could occur if the start
    // of an NPX instruction is near the end of a selector, and the
    // end of the instruction is past the selectors end.  This
    // would kill the app anyway.
    //

    //
    // Read any instruction prefixes
    //

    fPrefix = TRUE;
    while (fPrefix) {
        ibyte = NpxNpReadCSEip(Context);

        switch (ibyte) {
            case 0x2e:  // cs override, skip it
            case 0x36:  // ss override, skip it
            case 0x3e:  // ds override, skip it
            case 0x26:  // es override, skip it
            case 0x64:  // fs override, skip it
            case 0x65:  // gs override, skip it
            case 0x66:  // operand size override, skip it
                break;

            case 0x67:
                // address size override
                Address32Bits ^= 1;
                break;

            default:
                fPrefix = FALSE;
                break;
        }
    }

    //
    // Handle first byte of NPX instruction
    //

    if (ibyte == 0x9b) {

        //
        // FWait instruction - single byte opcode - all done
        //

        return;
    }

    if (ibyte < 0xD8 || ibyte > 0xDF) {

        //
        // Not an ESC instruction
        //

#if DBG
        DbgPrint ("P5_FPU_PATCH: 16: Not NPX ESC instruction\n");
#endif
        return;
    }

    //
    // Get ModR/M byte for NPX opcode
    //

    ibyte = NpxNpReadCSEip(Context);

    if (ibyte > 0xbf) {
        //
        // Outside of ModR/M range for addressing, all done
        //

        return;
    }

    Mod = ibyte >> 6;
    rm  = ibyte & 0x7;
    if (Address32Bits) {
        Context->Eip += MOD32 [Mod];
        if (Mod == 0  &&  rm == 5) {
            // disp 32
            Context->Eip += 4;
        }

        //
        // If SIB byte, read it
        //

        if (rm == 4) {
            ibyte = NpxNpReadCSEip(Context);

            if (Mod == 0  &&  (ibyte & 7) == 5) {
                // disp 32
                Context->Eip += 4;
            }
        }

    } else {
        Context->Eip += MOD16 [Mod];
        if (Mod == 0  &&  rm == 6) {
            // disp 16
            Context->Eip += 2;
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\nt386npx.inc ===
NPX_CONTEXT_FULL		EQU 00001000Fh	;/ Full context

ContextFlags equ CsContextFlags
ctx_env      equ CsFloatSave
ctx_stack    equ CsFloatSave+FpRegisterArea  ;need to change this puppy
ctx_Cr0NpxState equ CsFloatSave+FpCr0NpxState
ctx_SegGs    equ CsSegGs
ctx_SegFs    equ CsSegFs
ctx_SegEs    equ CsSegEs
ctx_SegDs    equ CsSegDs
ctx_RegEdi   equ CsEdi
ctx_RegEsi   equ CsEsi
ctx_RegEbp   equ CsEbp
ctx_RegEbx   equ CsEbx
ctx_RegEdx   equ CsEdx
ctx_RegEcx   equ CsEcx
ctx_RegEax   equ CsEax
ctx_RegEip   equ CsEip
ctx_SegCs    equ CsSegCs
ctx_EFlags   equ CsEflags
ctx_RegEsp   equ CsEsp
ctx_SegSs    equ CsSegSs

XCPT_FLOAT_INVALID_OPERATION    EQU STATUS_FLOAT_INVALID_OPERATION
XCPT_FLOAT_DENORMAL_OPERAND     EQU STATUS_FLOAT_DENORMAL_OPERAND
XCPT_FLOAT_DIVIDE_BY_ZERO       EQU STATUS_FLOAT_DIVIDE_BY_ZERO
XCPT_FLOAT_OVERFLOW             EQU STATUS_FLOAT_OVERFLOW
XCPT_FLOAT_UNDERFLOW            EQU STATUS_FLOAT_UNDERFLOW
XCPT_FLOAT_INEXACT_RESULT       EQU STATUS_FLOAT_INEXACT_RESULT
XCPT_FLOAT_STACK_CHECK          EQU STATUS_FLOAT_STACK_CHECK

ExceptionNum                equ ErExceptionCode
FHandlerFlags               equ ErExceptionFlags
NestedExceptionReportRecord equ ErExceptionRecord
ExceptionAddress            equ ErExceptionAddress
CParameters                 equ ErNumberParameters


Em87Busy    equ     1
Em87Idle    equ     0
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\i386\emstore.asm ===
subttl  emstore.asm - FST, FSTP, FIST, FISTP instructions
        page
;*******************************************************************************
;emstore.asm - FST, FSTP, FIST, FISTP instructions
;
;        Microsoft Confidential
;
;	 Copyright (c) Microsoft Corporation 1991
;        All Rights Reserved
;
;Purpose:
;       FST, FSTP, FIST, FISTP instructions
;Inputs:
;	edi = [CURstk]
;	dseg:esi = pointer to memory destination
;
;Revision History:
;
; []	09/05/91  TP	Initial 32-bit version.
;
;*******************************************************************************


;******
EM_ENTRY eFSTP
eFSTP:
;******
;	edi = [CURstk]
;	esi = pointer to st(i) from instruction field

	cmp	EMSEG:[edi].bTag,bTAG_EMPTY
        jz      short efstp_StackError
;UNDONE: temporary hack to preserve condition codes
        mov     ax,[esp+4].OldStatus
        mov     EMSEG:[StatusWord],ax
;UNDONE: end of hack

;A common use of this instruction is FSTP st(0) just to pop the stack.
;We check for this case and optimize it.
        cmp     esi,edi
        jz      short JustPop
;Copy the register
        mov     eax,EMSEG:[edi].ExpSgn
        mov     EMSEG:[esi].ExpSgn,eax
        mov     eax,EMSEG:[edi].lManHi
        mov     EMSEG:[esi].lManHi,eax
        mov     eax,EMSEG:[edi].lManLo
        mov     EMSEG:[esi].lManLo,eax
JustPop:
	POPSTret	edi

efstp_StackError:
	mov	EMSEG:[CURerr],Invalid+StackFlag
	ret


;******
EM_ENTRY eFST
eFST:
;******
;	edi = [CURstk]
;	esi = pointer to st(i) from instruction field

	cmp	EMSEG:[edi].bTag,bTAG_EMPTY
	jz	StackError		;In emarith.asm
;Copy the register
        mov     eax,EMSEG:[edi].ExpSgn
        mov     EMSEG:[esi].ExpSgn,eax
        mov     eax,EMSEG:[edi].lManHi
        mov     EMSEG:[esi].lManHi,eax
        mov     eax,EMSEG:[edi].lManLo
        mov     EMSEG:[esi].lManLo,eax
DontPop:
	ret


;Come here if the instruction wants to pop the stack

PopStackChk:
	jc	DontPop			;Get unmasked error?
PopStack:
	mov	edi,EMSEG:[CURstk]
	POPSTret	edi


StoreSpcl64:
	cmp	cl,bTAG_DEN
	jz	Denorm64
.erre	bTAG_NAN lt bTAG_EMPTY
.erre	bTAG_NAN gt bTAG_INF
	cmp	cl,bTAG_NAN
	mov	ecx,DexpMax shl 16	;Insert special exponent for NAN/Inf.
	jb	StoreIEEE64		;Go handle infinity
	ja	Empty64
;Have a NAN.
	test	ebx,1 shl 30		;Check for SNAN
	jnz	StoreIEEE64		;Go store QNAN
	or	ebx,1 shl 30		;Make SNAN into a QNAN
	mov	EMSEG:[CURerr],Invalid	;Flag the exception
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jnz	StoreIEEE64		;If so, update with masked response
	stc				;Don't pop stack
	ret

Empty64:
;It's empty--signal invalid operation
	mov	EMSEG:[CURerr],StackFlag+Invalid
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing64		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],0
	mov	dword ptr dseg:[esi+4],0FFF80000H	;64-bit IEEE indefinite
	ret				;CY clear

Denorm64:
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is it masked?
	jnz	NormStore64		;If so, ignore denormalization
DoNothing64:
	stc				;Don't pop stack
	ret

;*****************
;Store Double Real
;*****************

EM_ENTRY eFSTP64
eFSTP64:
	push	offset PopStackChk	;Return here after store

EM_ENTRY eFST64
eFST64:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ebx,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high ecx, sign in ch bit 7, tag in cl
;memory destination is dseg:esi
	mov	al,ch			;Save sign bit
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
        jz      short SignAndStore64    ;Just set sign and exit
        ja      StoreSpcl64
NormStore64:
;Note that we could have a denormal exception at this point.
;Thus any additional exceptions must OR into [CURerr], not MOV.
	xor	cx,cx
	add	ecx,(DexpBias-TexpBias) shl 16	;Correct bias
        jl      short Under64
        cmp     ecx,DexpMax shl 16      ;Exponent too big?
        jge     Over64
	test	edi,(1 shl 11) - 1	;Any bits to round?
        jz      short StoreIEEE64

Round64:
	or	EMSEG:[CURerr],Precision 	;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
        jnz     NotNearest64            ;Not just round-to-nearest
	test	edi,1 shl 10		;Check rounding bit
        jz      short StoreIEEE64       ;If zero, don't round up
	test	edi,(3 shl 10)-1	;Test LSB and sticky bits
        jnz     RoundUp64b

StoreIEEE64:
        or      ecx, ecx                ;now that value is rounded,
        je      short Under64           ;check exponent for underflow

StoreIEEE64Continue:
	and	ebx,not (1 shl 31)	;Clear MSB--it's implied in IEEE64
	shrd	edi,ebx,11
	shr	ebx,11			;Move mantissa down
	shl	ecx,4			;Exponent up to position
	or	ebx,ecx			;Combine exponent
SignAndStore64:
	and	al,bSign		;Just sign bit
	shl	eax,24			;Sign to MSB
	or	ebx,eax			;Combine sign
	mov	dseg:[esi],edi
	mov	dseg:[esi+4],ebx
;CY clear indicate no error
	ret

SetUnderflow:
	or	EMSEG:[CURerr],Underflow	;Unmasked underflow--do nothing
DoNothing:
	stc				;Indicate nothing was done
	ret

Under64:
        dec     cl                      ; Is cx == 1?
        jz      short StoreIEEE64Continue   ; Yes, we've alread been here

	test	EMSEG:[CWmask],Underflow	;Is underflow masked?
	jz	SetUnderflow		;No, do nothing more
;Produce masked underflow response
;Note that the underflow exception does not occur if the number can be
;represented exactly as a denormal.

	sar	ecx,16			;Bring exponent down
	cmp	ecx,DexpMin-52	;Allow for shift down to rounding bit
	jl	BigUnder64		;Too small, just make it zero
.erre	DexpMin eq 0
	neg	ecx			;Use as shift count
	inc	ecx			;Shift by at least one
	xor	edx,edx			;Place for sticky bits
	cmp	cl,32			;Long shift?
	jb	ShortDenorm
	neg	edi			;CY set if non-zero
	sbb	edx,edx			;-1 if bits shifted off, else zero
	mov	edi,ebx
	xor	ebx,ebx			;32-bit right shift
ShortDenorm:
;Shift count is modulo-32
	shrd	edx,edi,cl
	shrd	edi,ebx,cl
	shr	ebx,cl
	cmp	edx,1			;CY set if zero, else clear
	sbb	edx,edx			;Zero if bits shifted off, else -1
	inc	edx			;1 if bits shifted off, else zero
	or	edi,edx			;Collapse sticky bits into edi

        mov     ecx, 1                  ;Biased exponent is zero, put 1 into CL (noticed by Under64)
	test	edi,(1 shl 11) - 1	;Any bits to round?
	jz	StoreIEEE64		;If not, no exception
	or	EMSEG:[CURerr],Underflow
	jmp	Round64

Over64:
	test	EMSEG:[CWmask],Overflow	;Is overflow masked?
	jz	SetOverflow		;No, do nothing more
;Produce masked overflow response
	or	EMSEG:[CURerr],Overflow+Precision
	mov	ebx,DexpMax shl 20
	xor	edi,edi			;ebx:edi = positive infinity
	mov	ah,EMSEG:[CWcntl]	;Get rounding control
;Return max value if RCup bit = 1 and -, or RCdown bit = 1 and +
;i.e., RCup & sign OR RCdown & not sign
.erre	RCchop eq RCup + RCdown		;Always return max value
.erre	RCnear eq 0			;Never return max value
	sar	al,7			;Expand sign through whole byte
.erre	(RCdown and bSign) eq 0		;Don't want to change real sign
	xor	al,RCdown		;Flip sign for RCdown bit
	and	ah,al			;RCup & sign  OR  RCdown & not sign
	test	ah,RoundControl		;Look only at RC bits
	jz	SignAndStore64		;Return infinity
	dec	ebx
	dec	edi			;Max value == infinity-1
	jmp	SignAndStore64

SetOverflow:
	or	EMSEG:[CURerr],Overflow
	stc				;Indicate nothing was done
	ret

BigUnder64:
	or	EMSEG:[CURerr],Underflow+Precision
	xor	ebx,ebx
	mov	edi,ebx			;Set it to zero
	mov	ecx,ebx			;Including exponent
NotNearest64:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
	sar	al,7			;Expand sign through whole byte
.erre	(not RCup and RoundControl) eq RCdown
	xor	ah,al			;Flip rounding bits if negative
	and	ah,RoundControl
	cmp	ah,RCup
        jnz     StoreIEEE64             ;No, chop it

RoundUp64b:
        mov     EMSEG:[SWcc],RoundUp
	add	edi,1 shl 11		;Round up
	adc	ebx,0
        jnc     StoreIEEE64

	add	ecx,1 shl 16		;Mantissa overflowed, bump exponent
        cmp     ecx,DexpMax shl 16      ;Exponent too big?
        jge     Over64
        jmp     StoreIEEE64

;*******************************************************************************

StoreSpcl32:
	cmp	cl,bTAG_DEN
	jz	Denorm32
.erre	bTAG_NAN lt bTAG_EMPTY
.erre	bTAG_NAN gt bTAG_INF
	cmp	cl,bTAG_NAN
	mov	ecx,SexpMax shl 16	;Insert special exponent
	jb	StoreIEEE32
	ja	Empty64
;Have a NAN.
	test	ebx,1 shl 30		;Check for SNAN
	jnz	StoreIEEE32		;Go store QNAN
	or	ebx,1 shl 30		;Make SNAN into a QNAN
	mov	EMSEG:[CURerr],Invalid	;Flag the exception
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jnz	StoreIEEE32		;If so, update with masked response
	stc				;Don't pop stack
	ret

Empty32:
;It's empty--signal invalid operation
	mov	EMSEG:[CURerr],StackFlag+Invalid
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing32		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],0FFC00000H	;32-bit IEEE indefinite
	ret				;CY clear

Denorm32:
	mov	EMSEG:[CURerr],Denormal
	test	EMSEG:[CWmask],Denormal	;Is it masked?
	jnz	NormStore32		;If so, ignore denormalization
DoNothing32:
	stc				;Don't pop stack
	ret

;*****************
;Store Single Real
;*****************

EM_ENTRY eFSTP32
eFSTP32:
	push	offset PopStackChk	;Return here after store

EM_ENTRY eFST32
eFST32:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ebx,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high ecx, sign in ch bit 7, tag in cl
;memory destination is dseg:esi
	mov	al,ch			;Save sign bit
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
	jz	SignAndStore32		;Just set sign and exit
	ja	StoreSpcl32
NormStore32:
;Note that we could have a denormal exception at this point.
;Thus any additional exceptions must OR into [CURerr], not MOV.
	xor	cx,cx
	add	ecx,(SexpBias-TexpBias) shl 16	;Correct bias
	jle	Under32
	cmp	ecx,SexpMax shl 16	;Exponent too big?
	jge	Over32
;See if we need to round
	mov	edx,ebx			;Get low bits
	and	edx,(1 shl 8) - 1	;Mask to last 8 bits
	or	edx,edi			;Throwing away any bits?
	jz	StoreIEEE32
;Result will not be exact--check rounding mode
Round32:
	or	EMSEG:[CURerr],Precision 	;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearest32		;Not just round-to-nearest
	test	bl,1 shl 7		;Round bit set?
	jz	StoreIEEE32
	mov	edx,ebx
	and	edx,(3 shl 7)-1		;Mask to LSB and sticky bits
	or	edx,edi			;Combine with remaining sticky bits
	jz	StoreIEEE32
	mov	EMSEG:[SWcc],RoundUp
	add	ebx,1 shl 8		;Round up
	jc	AddOneExp32
StoreIEEE32:
	and	ebx,not (1 shl 31)	;Clear MSB--it's implied in IEEE32
	shr	ebx,8			;Move mantissa down
	shl	ecx,7			;Exponent up to position
	or	ebx,ecx			;Combine exponent
SignAndStore32:
	and	al,bSign		;Just sign bit
	shl	eax,24			;Sign to MSB
	or	ebx,eax			;Combine sign
	mov	dseg:[esi],ebx
;CY clear indicate no error
	ret

Under32:
	test	EMSEG:[CWmask],Underflow	;Is underflow masked?
	jz	SetUnderflow		;No, do nothing more
;Produce masked underflow response
;Note that the underflow exception does not occur if the number can be
;represented exactly as a denormal.
	sar	ecx,16			;Bring exponent down
	cmp	ecx,SexpMin-23	;Allow for shift down to rounding bit
	jl	BigUnder32		;Too small, just make it zero
.erre	SexpMin eq 0
	neg	ecx			;Use as shift count
	inc	ecx			;Shift by at least one
	xor	edx,edx			;Place for sticky bits
	shrd	edx,ebx,cl
	shr	ebx,cl
	xor	ecx,ecx			;Biased exponent is zero
	or	edi,edx			;Combine sticky bits
	mov	edx,ebx			;Get low bits
	and	edx,(1 shl 8) - 1	;Mask to last 8 bits
	or	edx,edi			;Throwing away any bits?
	jz	StoreIEEE32
	or	EMSEG:[CURerr],Underflow
	jmp	Round32

AddOneExp32:
	add	ecx,1 shl 16		;Mantissa overflowed, bump exponent
	cmp	ecx,SexpMax shl 16	;Exponent too big?
	jl	StoreIEEE32
Over32:
	test	EMSEG:[CWmask],Overflow	;Is overflow masked?
	jz	SetOverflow		;No, do nothing more
;Produce masked overflow response
	or	EMSEG:[CURerr],Overflow+Precision
	mov	ebx,SexpMax shl 23
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
;Return max value if RCup bit = 1 and -, or RCdown bit = 1 and +
;i.e., RCup & sign OR RCdown & not sign
.erre	RCchop eq RCup + RCdown		;Always return max value
.erre	RCnear eq 0			;Never return max value
	sar	al,7			;Expand sign through whole byte
.erre	(RCdown and bSign) eq 0		;Don't want to change real sign
	xor	al,RCdown		;Flip sign for RCdown bit
	and	ah,al			;RCup & sign  OR  RCdown & not sign
	test	ah,RoundControl		;Look only at RC bits
	jz	SignAndStore32		;Return infinity
	dec	ebx			;Max value == infinity-1
	jmp	SignAndStore32

BigUnder32:
	or	EMSEG:[CURerr],Underflow+Precision
	xor	ebx,ebx			;Set it to zero
	xor	ecx,ecx			;Exponent too
NotNearest32:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
	sar	al,7			;Expand sign through whole byte
.erre	(not RCup and RoundControl) eq RCdown
	xor	ah,al			;Flip rounding bits if negative
	and	ah,RoundControl
	cmp	ah,RCup
	jnz	StoreIEEE32		;No, chop it
	mov	EMSEG:[SWcc],RoundUp
	add	ebx,1 shl 8		;Round up
	jnc	StoreIEEE32
	jmp	AddOneExp32

;*******************************************************************************

StoreSpcl32Int:
	cmp	cl,bTAG_DEN
	jz	NormStore32Int		;Ignore denormal
	cmp	cl,bTAG_EMPTY
	jnz	Over32Int		;All other specials are invalid
	mov	EMSEG:[CURerr],StackFlag+Invalid
	jmp	Invalid32Int

DoNothing32Int:
	stc				;Don't pop stack
	ret

CheckMax32:
	ja	Over32Int
	test	al,bSign		;Is it negative?
	jnz	Store32Int		;If so, answer is OK
Over32Int:
;Overflow on integer store is invalid according to IEEE
	mov	EMSEG:[CURerr],Invalid	;Must remove precision exception
Invalid32Int:
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing32Int		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],80000000H	;32-bit integer indefinite
	ret				;CY clear

;******************
;Store Long Integer
;******************

EM_ENTRY eFISTP32
eFISTP32:
	push	offset PopStackChk	;Return here after store

EM_ENTRY eFIST32
eFIST32:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ebx,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high ecx, sign in ch bit 7, tag in cl
;memory destination is dseg:esi
	mov	al,ch			;Save sign bit
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
	jz	Store32Int		;Just store zero and exit
	ja	StoreSpcl32Int
NormStore32Int:
	xor	edx,edx
	sar	ecx,16			;Bring exponent down
	cmp	ecx,-1			;Is it less than 1?
	jle	Under32Int
	cmp	ecx,31
	jg	Over32Int
	sub	ecx,31
	neg	ecx			;cl = amount to shift right
	shrd	edx,edi,cl
	shrd	edi,ebx,cl		;Collect round and sticky bits
	shr	ebx,cl			;Align integer
;See if we need to round
	mov	ecx,edi
	or	ecx,edx			;Throwing away any bits?
	jz	StoreIEEE32Int
;Result will not be exact--check rounding mode
Round32Int:
	mov	EMSEG:[CURerr],Precision 	;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearest32Int		;Not just round-to-nearest

;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.

	bt	ebx,0			;Look at LSB (for round even)
	adc	edx,-1			;CY set if sticky bits <>0
	adc	edi,(1 shl 31)-1	;CY set if round up
	jnc	StoreIEEE32Int
	mov	EMSEG:[SWcc],RoundUp
	inc	ebx
	jz	Over32Int
StoreIEEE32Int:
	cmp	ebx,1 shl 31		;Check for max value
	jae	CheckMax32
SignAndStore32Int:
	shl	eax,24			;Sign to MSB
	cdq				;Extend sign through edx
	xor	ebx,edx			;Complement
	sub	ebx,edx			;  and increment if negative
	clc
Store32Int:
	mov	dseg:[esi],ebx
;CY clear indicates no error
	ret

Under32Int:
;ZF set if exponent is -1
	xchg	edx,edi			;32-bit right shift
	xchg	edi,ebx			;ebx = 0 now
	jz	Round32Int		;If exponent was -1, ready to round
	mov	EMSEG:[CURerr],Precision 	;Set flag on inexact result
NotNearest32Int:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
	sar	al,7			;Expand sign through whole byte
.erre	(not RCup and RoundControl) eq RCdown
	xor	ah,al			;Flip rounding bits if negative
	and	ah,RoundControl
	cmp	ah,RCup			;Rounding up?
	jnz	StoreIEEE32Int		;No, chop it
	mov	EMSEG:[SWcc],RoundUp
	inc	ebx
	jnc	StoreIEEE32Int
	jmp	Over32Int

;*******************************************************************************

StoreSpcl16Int:
	cmp	cl,bTAG_DEN
	jz	NormStore16Int		;Ignore denormal
	cmp	cl,bTAG_EMPTY
	jnz	Over16Int		;All other specials are invalid
	mov	EMSEG:[CURerr],StackFlag+Invalid
	jmp	Invalid16Int

DoNothing16Int:
	stc				;Don't pop stack
	ret

CheckMax16:
	ja	Over16Int
	test	al,bSign		;Is it negative?
	jnz	Store16Int		;If so, answer is OK
Over16Int:
;Overflow on integer store is invalid according to IEEE
	mov	EMSEG:[CURerr],Invalid
Invalid16Int:
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing16Int		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	word ptr dseg:[esi],8000H	;16-bit integer indefinite
	ret				;CY clear

;*******************
;Store Short Integer
;*******************

EM_ENTRY eFISTP16
eFISTP16:
	push	offset PopStackChk	;Return here after store

EM_ENTRY eFIST16
eFIST16:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	ebx,EMSEG:[edi].lManHi
	mov	ecx,EMSEG:[edi].ExpSgn
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high ecx, sign in ch bit 7, tag in cl
;memory destination is dseg:esi
	mov	al,ch			;Save sign bit
	cmp	cl,bTAG_ZERO
.erre	bTAG_VALID lt bTAG_ZERO
.erre	bTAG_SNGL lt bTAG_ZERO
	jz	Store16Int		;Just store zero and exit
	ja	StoreSpcl16Int
NormStore16Int:
	xor	edx,edx
	sar	ecx,16			;Bring exponent down
	cmp	ecx,-1			;Is it less than 1?
	jle	Under16Int
	cmp	ecx,15
	jg	Over16Int
	sub	ecx,31
	neg	ecx			;cl = amount to shift right
	shrd	edx,edi,cl
	shrd	edi,ebx,cl		;Collect round and sticky bits
	shr	ebx,cl			;Align integer
;See if we need to round
	mov	ecx,edi
	or	ecx,edx			;Throwing away any bits?
	jz	StoreIEEE16Int
;Result will not be exact--check rounding mode
Round16Int:
	mov	EMSEG:[CURerr],Precision 	;Set flag on inexact result
	test	EMSEG:[CWcntl],RoundControl	;Check rounding control bits
.erre	RCnear eq 0
	jnz	NotNearest16Int		;Not just round-to-nearest

;To perform "round even" when the round bit is set and the sticky bits
;are zero, we treat the LSB as if it were a sticky bit.  Thus if the LSB
;is set, that will always force a round up (to even) if the round bit is
;set.  If the LSB is zero, then the sticky bits remain zero and we always
;round down.

	bt	ebx,0			;Look at LSB (for round even)
	adc	edx,-1			;CY set if sticky bits <>0
	adc	edi,(1 shl 31)-1	;CY set if round up
	jnc	StoreIEEE16Int
	mov	EMSEG:[SWcc],RoundUp
	inc	ebx
StoreIEEE16Int:
	cmp	ebx,1 shl 15		;Check for max value
	jae	CheckMax16
SignAndStore16Int:
	shl	eax,24			;Sign to MSB
	cdq				;Extend sign through edx
	xor	ebx,edx			;Complement
	sub	ebx,edx			;  and increment if negative
	clc
Store16Int:
	mov	dseg:[esi],bx
;CY clear indicates no error
	ret

Under16Int:
;ZF set if exponent is -1
	xchg	edx,edi			;16-bit right shift
	xchg	edi,ebx			;ebx = 0 now
	jz	Round16Int		;If exponent was -1, ready to round
	mov	EMSEG:[CURerr],Precision 	;Set flag on inexact result
NotNearest16Int:
;We want to increase the magnitude if RCup and +, or RCdown and -
	mov	ah,EMSEG:[CWcntl]		;Get rounding control
	sar	al,7			;Expand sign through whole byte
.erre	(not RCup and RoundControl) eq RCdown
	xor	ah,al			;Flip rounding bits if negative
	and	ah,RoundControl
	cmp	ah,RCup			;Rounding up?
	jnz	StoreIEEE16Int		;No, chop it
	mov	EMSEG:[SWcc],RoundUp
	inc	ebx
	jnc	StoreIEEE16Int
	jmp	Over16Int

;*******************************************************************************

;******************
;Store Quad Integer
;******************

EM_ENTRY eFISTP64
eFISTP64:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	call	RoundToInteger
	jc	Invalid64Int
;Have integer in ebx:edi
;Sign in ch
	cmp	ebx,1 shl 31		;Check for max value
	jae	CheckMax64
	or	ch,ch			;Check sign
	jns	Store64Int
;64-bit negation
	not	ebx
	neg	edi
	sbb	ebx,-1
Store64Int:
	mov	dseg:[esi],edi
	mov	dseg:[esi+4],ebx
	jmp	PopStack

CheckMax64:
	ja	Over64Int
	test	al,bSign		;Is it negative?
	jnz	Store64Int		;If so, answer is OK
Over64Int:
;Overflow on integer store is invalid according to IEEE
	mov	EMSEG:[CURerr],Invalid
Invalid64Int:
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing80		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],0
	mov	dword ptr dseg:[esi+4],80000000H	;64-bit integer indefinite
	jmp	PopStack

;*******************************************************************************

Empty80:
;It's empty--signal invalid operation
	mov	EMSEG:[CURerr],StackFlag+Invalid
	test	EMSEG:[CWmask],Invalid	;Is it masked?
	jz	DoNothing80		;No--leave memory unchanged
;Store Indefinite
;For FSTP, we go ahead and do the pop even though it's empty
	mov	dword ptr dseg:[esi],0
	mov	dword ptr dseg:[esi+4],0C0000000H
	mov	word ptr dseg:[esi+8],0FFFFH	;80-bit IEEE indefinite
	jmp	PopStack

DoNothing80:
	ret

;***************
;Store Temp Real
;***************

EM_ENTRY eFSTP80
eFSTP80:
        mov     EMSEG:[PrevDataOff],esi       ;Save operand pointer
	mov	eax,EMSEG:[edi].ExpSgn
	cmp	al,bTAG_EMPTY
	jz	Empty80

        push    offset PopStack

StoreTempReal:
	mov	ebx,EMSEG:[edi].lManHi
	mov	edi,EMSEG:[edi].lManLo
;mantissa in ebx:edi, exponent in high eax, sign in ah bit 7, tag in al
;memory destination is dseg:esi
	mov	ecx,eax			;get copy of sign and tag
	shr	ecx,16			;Bring exponent down
	cmp	al,bTAG_ZERO
	jz	StoreIEEE80		;Skip bias if zero
	add	ecx,IexpBias-TexpBias	;Correct bias
	cmp	al,bTAG_DEN
	jz	Denorm80
StoreIEEE80:
	and	eax,bSign shl 8
	or	ecx,eax			;Combine sign with exponent
	mov	dseg:[esi],edi
	mov	dseg:[esi+4],ebx
	mov	dseg:[esi+8],cx

;	jmp	PopStack
        ret

Denorm80:
;Must change it to a denormal
	dec	ecx
	neg	ecx			;Use as shift count
	cmp	cl,32			;Long shift?
	jae	LongDenorm
	shrd	edi,ebx,cl
	shr	ebx,cl
	xor	ecx,ecx			;Exponent is zero
	jmp	StoreIEEE80

LongDenorm:
;edi must be zero if we have 32 bits to shift
	xchg	ebx,edi			;32-bit right shift
	shr	edi,cl			;shift count is modulo-32
	xor	ecx,ecx			;Exponent is zero
	jmp	StoreIEEE80
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\ia64\ldrthunk.s ===
//++
//
// Copyright (c) 1996  Intel Corporation
// Copyright (c) 1989  Microsoft Corporation
//
// Module Name:
//
//    ldrthunk.s
//
// Abstract:
//
//    This module implements the thunk for the LdrpInitialize APC routine.
//
// Author:
//
//    William K. Cheung (wcheung) 19-Sep-95
//
// Revision History:
//
//    08-Feb-96    Updated to EAS2.1
//
//--

#include "ksia64.h"

        .file    "ldrthunk.s"

        PublicFunction(LdrpInitialize)

//++
//
// VOID
// LdrInitializeThunk(
//    IN PVOID NormalContext,
//    IN PVOID SystemArgument1,
//    IN PVOID SystemArgument2
//    )
//
// Routine Description:
//
//    This function computes a pointer to the context record on the stack
//    and jumps to the LdrpInitialize function with that pointer as its
//    parameter.
//
// Arguments:
//
//    NormalContext (a0) - User Mode APC context parameter
//
//    SystemArgument1 (a1) - User Mode APC system argument 1
//
//    SystemArgument2 (a2) - User Mode APC system argument 2
//
// Return Value:
//
//    None.
//
//--

        NESTED_ENTRY(LdrInitializeThunk)

        NESTED_SETUP(3,2,3,0)
        mov         out2 = a2
        ;;

        PROLOGUE_END

//
// SP points at stack scratch area followed by context record.
//

        add         out0 = STACK_SCRATCH_AREA, sp       // pointer to context
        mov         out1 = a1                           // copy args
        br.call.sptk.many brp = LdrpInitialize

//
// S0 in the context record contains the PLabel.  Fix IIP/GP in the context
// record with the entry point and gp values pointed to by S0.
//

        add         t7 = CxIntGp+STACK_SCRATCH_AREA, sp     // -> global pointer
        add         t2 = CxIntS0+STACK_SCRATCH_AREA, sp     // -> PLabel pointer
        add         t11 = CxStIIP+STACK_SCRATCH_AREA, sp    // -> func pointer
        ;;

        ld8         t8 = [t2]                   // get the function pointer
        mov         brp = savedbrp              // restore brp
        mov         ar.pfs = savedpfs           // restore pfs
        ;;

        ld8         t5 = [t8], PlGlobalPointer-PlEntryPoint  // get entry point
        ;;
        ld8         t6 = [t8]                   // get gp
        nop.i       0
        ;;

        st8         [t11] = t5                  // set iip to entry point
        st8         [t7] = t6                   // set gp
        br.ret.sptk.clr brp

        NESTED_EXIT(LdrInitializeThunk)
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\ia64\critsect.s ===
//++
//
// Copyright (c) 1989  Microsoft Corporation
//
// Module Name:
//
//     critsect.s
//
// Abstract:
//
//    This module implements functions to support user mode critical sections.
//
// Author:
//
//    William K. Cheung (wcheung) 18-Sep-95
//
// Revision History:
//
//    07-Jul-97  bl    Updated to EAS2.3
//
//    08-Feb-96        Updated to EAS2.1
//
//--

#include "ksia64.h"

        .file    "critsect.s"

        //
        // intra-module functions to be called.
        //

        PublicFunction(RtlpWaitForCriticalSection)
        PublicFunction(RtlpUnWaitCriticalSection)


//++
//
// NTSTATUS
// RtlEnterCriticalSection(
//     IN PRTL_CRITICAL_SECTION CriticalSection
//     )
//
// Routine Description:
//
//     This function enters a critical section.
//
// Arguments:
//
//     CriticalSection (a0) - supplies a pointer to a critical section.
//
// Return Value:
//
//     STATUS_SUCCESS or raises an exception if an error occured.
//
// Algorithm in C:
//
// NTSTATUS
// RtlEnterCriticalSection(
//     IN PRTL_CRITICAL_SECTION CriticalSection
//     )
// {
//     PTEB     Teb;
//     LONG     OriginalValue;
//     HANDLE   CurrentThreadId;
//     DWORD    SpinCount;
//
//     Teb = NtCurrentTeb();
//     CurrentThreadId = Teb->ClientId.UniqueThread;
//     SpinCount = CriticalSection->SpinCount;
//
//     if (SpinCount == 0) {
// nospin:
//           OriginalValue = AtomicIncrement(CriticalSection->LockCount);
//      
//           if (OriginalValue != -1) {
//               if (CriticalSection->OwningThread != CurrentThreadId) {
//                   RtlpWaitForCriticalSection(CriticalSection);
//                   CriticalSection->OwningThread = CurrentThreadId;
//                   CriticalSection->RecursionCount = 0;
//               } else {
//                   CriticalSection->RecursionCount++;
//               }
//           } else {
//               CriticalSection->OwningThread = CurrentThreadId;
//               CriticalSection->RecursionCount = 0;
//           }
//       
//           return STATUS_SUCCESS;
//
//     } else { /* spin count not 0 */
//
//           if (CriticalSection->OwningThread == CurrentThread) {
//               AtomicIncrement(CriticalSection->LockCount);
//               CriticalSection->RecursionCount++;
//               return STATUS_SUCCESS;
//           } else {
//             do {
//               if (!CmpXchg(CriticalSection->LockCount,0,-1)) {
//                  Lock acquired
//                  CriticalSection->OwningThread = CurrentThreadId;
//                  CriticalSection->RecursionCount = 0;
//                  return STATUS_SUCCESS;
//               }
//               if (CriticalSection->LockCount >= 1) goto nospin;
//
//               while (CriticalSection->LockCount == 0) {
//                  if (!--SpinCount) goto nospin;
//               }
//             } while (1) // CriticalSection->LockCount == -1,  not owned
//           }
//     } 
// }
//
//--



        NESTED_ENTRY(RtlEnterCriticalSection)

        //
        // register aliases
        //

        rpThreadId=t3
        rOldLockCount=t4
        rpLockCount=t5
        rRecursionCount=t6
        rOwnerId=t7
        rpSpinCount=t9
        rSpinCount=t10
        rT1=t11
        rT2=t12
        
        pSpin=pt0
        pNoSpin=pt1
        pNotOwn=pt2
        pNotAcq=pt3
        pFree=pt5
        pHeld=pt6
        pGo=pt7
        pWait=pt8

//
// alloc regs and save brp & pfs
//

        NESTED_SETUP(1,5,1,0)
        add         rpLockCount = CsLockCount, a0
        ;;

        //
        // more register aliases
        //

        rThreadId   = loc2
        rpOwner     = loc3
        rpCsRecursion = loc4

        PROLOGUE_END

//
// Swizzle pointers to address the RecursionCount and
// LockCount fields in the critical section structure.
//

        lfetch.nt1  [rpLockCount]
        nop.f       0
        add         rpSpinCount = CsSpinCount, a0

        add         rpCsRecursion = CsRecursionCount, a0
        nop.f       0
        add         rpThreadId = TeClientId+CidUniqueThread, teb
        ;;

//
// Load the id of the currently running thread, anticipating
// that it may be needed.
//

        ld8         rThreadId = [rpThreadId]
        ld4         rSpinCount = [rpSpinCount]
        add         rpOwner = CsOwningThread, a0
        ;;
        
//
// Branch out if spin count is non-zero
//      
        cmp4.ne     pSpin, pNoSpin = rSpinCount, zero
        mov         v0 = STATUS_SUCCESS
(pSpin) br.spnt     RecsSpin

//
// Atomically increment the lock count at location (rpLockCount)
// and put the old value in register "rOldLockCount".
// Swizzle a pointer to address the thread id field in teb structure.
//

RecsNoSpin:
        fetchadd4.acq rOldLockCount = [rpLockCount], 1
        ld4.nt1     rRecursionCount = [rpCsRecursion]
        ;;
        
//
// Check the original value of lock count to determine if the
// lock is free.  If the value is -1, it is free.
//

        cmp4.eq     pFree, pHeld = -1, rOldLockCount
        ;;

//
// if lock is not free, get the thread id of its current owner
// otherwise, save the currently running thread's id.
//

(pHeld) ld8         rOwnerId = [rpOwner]
(pFree) st8         [rpOwner] = rThreadId
(pFree) st4         [rpCsRecursion] = zero
(pFree) br.ret.sptk.clr brp                     // return
        ;;

//
// if lock is not free, compare the owner id of the critical section against 
// that of the thread to determine if this thread is the owner.
// otherwise, return to caller.
//

        cmp.eq      pGo, pWait = rThreadId, rOwnerId
        mov         out0 = a0
        add         rRecursionCount = 1, rRecursionCount
        ;;

//
// if the thread has already owned the lock, save the updated 
// recursion count and return.
// otherwise, wait for the critical section to be released.
//

(pGo)   st4         [rpCsRecursion] = rRecursionCount  
(pGo)   br.ret.sptk brp
(pWait) br.call.spnt.many brp = RtlpWaitForCriticalSection
        ;;

        st8.rel     [rpOwner] = rThreadId
        st4         [rpCsRecursion] = zero
        mov         v0 = STATUS_SUCCESS

        NESTED_RETURN

// A nonzero spin count is specified
//

RecsSpin:

        ld8         rOwnerId = [rpOwner]
        mov         rT1 = -1
        ;;
        zxt4        rT1 = rT1                   // zero extend for compare with
        ;;                                      // 4 byte lock value

        mov         ar.ccv = rT1                // compare value
        cmp.ne      pNotOwn = rOwnerId, rThreadId        
(pNotOwn) br.spnt   RecsNotOwn

//
// The critical section is owned by the current thread. Increment the lock
// count and the recursion count.
//
        
        ld4         rRecursionCount = [rpCsRecursion]
        fetchadd4.acq rOldLockCount = [rpLockCount], 1
        ;;
        add         rRecursionCount = 1, rRecursionCount
        ;;

        st4         [rpCsRecursion] = rRecursionCount
        br.ret.sptk.clr brp                     // return

//
// A nonzero spin count is specified and the current thread is not the owner.
//

RecsNotOwn:
        cmpxchg4.acq rT1 = [rpLockCount], zero  // try to acquire lock
        ;;
        
        cmp4.ne     pNotAcq = -1, rT1
(pNotAcq) br.spnt   RecsNotAcq

        
//
// The critical section has been acquired. Set the owning thread and the initial
// recursion count and return success.
//

        st8         [rpOwner] = rThreadId
        st4         [rpCsRecursion] = zero
        br.ret.sptk.clr brp                     // return

//
// The critical section is currently owned. Spin until it is either unowned
// or the spin count has reached zero. 
//
// If LockCount > 0, then there are waiters. Don't spin because
// the lock will not free.
//

RecsNotAcq:
        YIELD        
        ld4         rOldLockCount = [rpLockCount]
        ;;

        cmp4.eq     pNotOwn = -1, rOldLockCount
        cmp4.gt     pNoSpin = rOldLockCount, zero
(pNoSpin) br.spnt   RecsNoSpin
(pNotOwn) br.spnt   RecsNotOwn

        add         rSpinCount = -1, rSpinCount
        ;;

        cmp4.eq     pNoSpin, pSpin = zero, rSpinCount
(pNoSpin) br.spnt   RecsNoSpin
(pSpin) br.sptk     RecsNotAcq
        ;;

        NESTED_EXIT(RtlEnterCriticalSection)

//++
//
// NTSTATUS
// RtlLeaveCriticalSection(
//    IN PRTL_CRITICAL_SECTION CriticalSection
//    )
//
// Routine Description:
//
//    This function enters a critical section.
//
//    N.B. This function is duplicated in the runtime library.
//
// Arguments:
//
//    CriticalSection (a0) - Supplies a pointer to a critical section.
//
// Return Value:
//
//    STATUS_SUCCESS is returned as the function value.
//
// Algorithm in C:
//
// NTSTATUS
// RtlLeaveCriticalSection(
//     IN PRTL_CRITICAL_SECTION CriticalSection
//     )
// {
//     LONG NewRecursionCount;
//     LONG OldLockCount;
//     BOOL ToRelease;
// 
//     ASSERT(CriticalSection->RecursionCount >= 0)
//
//     if (CriticalSection->RecursionCount != 0) {
//         CriticalSection->RecursionCount -= 1;
//         AtomicDecrement(CriticalSection->LockCount);
//         return STATUS_SUCCESS;
//     }
// 
//     CriticalSection->OwningThread = 0; 
//     OldLockCount = AtomicDecrement(CriticalSection->LockCount);
// 
//     if ( OldLockCount != 0 ) {
//         RtlpUnWaitCriticalSection(CriticalSection);
//     }
// 
//     return STATUS_SUCCESS;
// }
// 
//--

//
// register aliases
//


        NESTED_ENTRY(RtlLeaveCriticalSection)

        rpOwner=t0
        rOldLockCount=t1
        rRecursionCount=t2
        rpLockCount=t5
        rpCsRecursion=t9

        pHold=pt0
        pRel=pt1
        pGo=pt7
        pWait=pt8

        NESTED_SETUP(1,2,1,0)
        add         rpCsRecursion = CsRecursionCount, a0
        ;;

        PROLOGUE_END

//
// load recursion count
// swizzle pointers to address the LockCount and OwningThread
// fields in the critical section structure.
//

        ld4         rRecursionCount = [rpCsRecursion]
        add         rpOwner = CsOwningThread, a0
        add         rpLockCount = CsLockCount, a0
        ;;

//
// check if the original value of the recursion count to determine
// if the lock is to be released.
//
// decrement the register copy of recursion count by 1 and save
// the new value in temp register
//

        cmp.ne      pHold, pRel = zero, rRecursionCount
        add         rRecursionCount = -1, rRecursionCount
        add         v0 = STATUS_SUCCESS, zero   // return STATUS_SUCCESS
        ;;

//
// save the updated recursion count into the critical section structure.
//
// atomically decrement the lock count.
//
// if lock is still held, return to caller.
//
// Note: An atomic fetch & add with release form is used here
//       all previous memory accesses are visible at this point.
//
// Note: All updates to the Critical Section structure MUST be complete
//       prior to the lock count being decremented which releases the
//       lock.
//

(pHold) st4         [rpCsRecursion] = rRecursionCount
(pRel)  st8         [rpOwner] = zero            // clear the owner field
        ;;
        fetchadd4.rel rOldLockCount = [rpLockCount], -1
(pHold) br.ret.sptk.clr brp                     // return to caller
        ;;

//
// The lock is now free, check the original value of the lock count to
// determine if any other thread is waiting for this critical section.
// If no thread is waiting, return to caller immediately.
// 

        cmp4.ge     pGo, pWait = zero, rOldLockCount
  (pGo) br.ret.sptk.clr brp                     // return to caller

        mov         out0 = a0
(pWait) br.call.spnt.many brp = RtlpUnWaitCriticalSection
 
        mov         v0 = STATUS_SUCCESS         // return STATUS_SUCCESS

        NESTED_RETURN
        ;;

        NESTED_EXIT(RtlLeaveCriticalSection)


//++
//
// BOOL
// RtlTryEnterCriticalSection(
//    IN PRTL_CRITICAL_SECTION CriticalSection
//    )
//
// Routine Description:
//
//    This function attempts to enter a critical section without blocking.
//
// Arguments:
//
//    CriticalSection (a0) - Supplies a pointer to a critical section.
//
// Return Value:
//
//    If the critical section was successfully entered, then a value of TRUE
//    is returned as the function value. Otherwise, a value of FALSE is returned
//
//--

        LEAF_ENTRY(RtlTryEnterCriticalSection)

        //
        // register aliases
        //

        rT0=t0
        rT1=t1
        rpThreadId=t3
        rOldLockCount=t4
        rpLockCount=t5
        rRecursionCount=t6
        rOwnerId=t7
        rpCsRecursion=t8
        rThreadId=t9
        rpOwner=t10
 
        pFree=pt5
        pHeld=pt6
        pOwn=pt7
        pFail=pt8

        alloc       rT0 = ar.pfs, 1, 0, 0, 0
        movl        rT1 = 0xffffffff
        ;;

        mov         ar.ccv = rT1
        add         rpOwner = CsOwningThread, a0
        add         rpLockCount = CsLockCount, a0
        ;;

        cmpxchg4.acq rOldLockCount = [rpLockCount], r0, ar.ccv
        add         rpCsRecursion = CsRecursionCount, a0
        add         rpThreadId = TeClientId+CidUniqueThread, teb
        ;;
 
        ld8         rOwnerId = [rpOwner]
        cmp4.eq     pFree, pHeld = rT1, rOldLockCount
        ;;


        ld8.nt1     rThreadId = [rpThreadId]
(pHeld) ld4.nt1     rRecursionCount = [rpCsRecursion]
        mov         v0 = TRUE
        ;;

(pFree) st4         [rpCsRecursion] = zero
(pFree) st8         [rpOwner] = rThreadId
(pHeld) cmp.eq      pOwn, pFail = rThreadId, rOwnerId
(pFree) br.ret.sptk.clr brp
        ;;

(pOwn)  fetchadd4.acq rT0 = [rpLockCount], 1
(pOwn)  add         rRecursionCount = 1, rRecursionCount
        nop.i       0
        ;;

(pOwn)  st4.rel     [rpCsRecursion] = rRecursionCount  
(pFail) mov         v0 = FALSE
        br.ret.sptk.clr brp

        LEAF_EXIT(RtlTryEnterCriticalSection)
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\wow6432\ntwow64.h ===
/*++

Copyright (c) Microsoft Corporation

Module Name:

    ntwow64.h

Abstract:

    This module contains headers for fake kernel entrypoints(wow64 BOPS) in ntdll.

Author:

    Michael Zoran (mzoran) 22-NOV-1998

Environment:

    User Mode only

Revision History:

    May 07, 2001   SamerA     Added NtWow64GetNativeSystemInformation()
    July 2002 JayKrell
        removed NtWow64QuerySection64
        added NtWow64QueryInformationProcess64
        publish it, ifndef guard, pragma once, subsection ifdef guards

--*/

#ifndef _NTWOW64_
#define _NTWOW64_

#if _MSC_VER > 1000
#pragma once
#endif

#if defined(_NTCSRMSG_)

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrClientConnectToServer(
    IN PWSTR ObjectDirectory,
    IN ULONG ServerDllIndex,
    IN PVOID ConnectionInformation,
    IN OUT PULONG ConnectionInformationLength OPTIONAL,
    OUT PBOOLEAN CalledFromServer OPTIONAL
    );

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrNewThread(
    VOID
    );

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrIdentifyAlertableThread(
    VOID
    );

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrClientCallServer(
    IN OUT PCSR_API_MSG m,
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer OPTIONAL,
    IN CSR_API_NUMBER ApiNumber,
    IN ULONG ArgLength
    );

NTSYSAPI
PCSR_CAPTURE_HEADER
NTAPI
NtWow64CsrAllocateCaptureBuffer(
    IN ULONG CountMessagePointers,
    IN ULONG Size
    );

NTSYSAPI
VOID
NTAPI
NtWow64CsrFreeCaptureBuffer(
    IN PCSR_CAPTURE_HEADER CaptureBuffer
    );

NTSYSAPI
ULONG
NTAPI
NtWow64CsrAllocateMessagePointer(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN ULONG Length,
    OUT PVOID *Pointer
    );

NTSYSAPI
VOID
NTAPI
NtWow64CsrCaptureMessageBuffer(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN PVOID Buffer OPTIONAL,
    IN ULONG Length,
    OUT PVOID *CapturedBuffer
    );

NTSYSAPI
VOID
NTAPI
NtWow64CsrCaptureMessageString(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN PCSTR String OPTIONAL,
    IN ULONG Length,
    IN ULONG MaximumLength,
    OUT PSTRING CapturedString
    );

NTSYSAPI
NTSTATUS
NTAPI
NtWow64CsrSetPriorityClass(
    IN HANDLE ProcessHandle,
    IN OUT PULONG PriorityClass
    );

NTSYSAPI
HANDLE
NTAPI
NtWow64CsrGetProcessId(
    VOID
    );

#endif /* _NTCSRMSG_ */

#if defined(_NTDBG_)

NTSYSAPI
NTSTATUS
NTAPI
NtDbgUiConnectToDbg( VOID );

NTSTATUS
NtDbgUiWaitStateChange (
    OUT PDBGUI_WAIT_STATE_CHANGE StateChange,
    IN PLARGE_INTEGER Timeout OPTIONAL
    );

NTSYSAPI
NTSTATUS
NTAPI
NtDbgUiContinue (
    IN PCLIENT_ID AppClientId,
    IN NTSTATUS ContinueStatus
    );

NTSYSAPI
NTSTATUS
NTAPI
NtDbgUiStopDebugging (
    IN HANDLE Process
    );

NTSYSAPI
NTSTATUS
NTAPI
NtDbgUiDebugActiveProcess (
    IN HANDLE Process
    );

NTSYSAPI
VOID
NTAPI
NtDbgUiRemoteBreakin (
    IN PVOID Context
    );

NTSYSAPI
HANDLE
NTAPI
NtDbgUiGetThreadDebugObject (
    VOID
    );

#endif /* _NTDBG_ */


// This is used in place of INT 2D
NTSYSAPI
NTSTATUS
NTAPI
NtWow64DebuggerCall (
    IN ULONG ServiceClass,
    IN ULONG Arg1,
    IN ULONG Arg2,
    IN ULONG Arg3,
    IN ULONG Arg4
    );


NTSYSAPI
NTSTATUS
NTAPI
NtWow64GetNativeSystemInformation(
    IN SYSTEM_INFORMATION_CLASS SystemInformationClass,
    OUT PVOID NativeSystemInformation,
    IN ULONG InformationLength,
    OUT PULONG ReturnLength OPTIONAL
    );

#if defined(BUILD_WOW6432)
typedef VOID * __ptr64 NATIVE_PVOID;
#else
typedef PVOID NATIVE_PVOID;
#endif
typedef ULONGLONG SIZE_T64,*PSIZE_T64;

#if defined(BUILD_WOW6432)

#if defined(_NTPSAPI_)

NTSYSAPI
NTSTATUS
NTAPI
NtWow64QueryInformationProcess64(
    IN HANDLE ProcessHandle,
    IN PROCESSINFOCLASS ProcessInformationClass,
    OUT PVOID ProcessInformation,
    IN ULONG ProcessInformationLength,
    OUT PULONG ReturnLength OPTIONAL
    );

#endif

NTSYSAPI
NTSTATUS
NTAPI
NtWow64ReadVirtualMemory64(
    IN HANDLE ProcessHandle,
    IN NATIVE_PVOID BaseAddress,
    OUT PVOID Buffer,
    IN SIZE_T64 BufferSize,
    OUT PSIZE_T64 NumberOfBytesRead OPTIONAL
    );

#if defined(_NTMMAPI_)

NTSYSAPI
NTSTATUS
NTAPI
NtWow64QueryVirtualMemory64(
    IN HANDLE ProcessHandle,
    IN NATIVE_PVOID BaseAddress,
    IN MEMORY_INFORMATION_CLASS MemoryInformationClass,
    OUT PVOID MemoryInformation,
    IN SIZE_T64 MemoryInformationLength,
    OUT PSIZE_T64 ReturnLength OPTIONAL
    );

#endif

#endif

#endif /* _NTWOW64_ */
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdllsym\makefile.inc ===
$(O)\ntdll.c : syminfo.c
    $(CXX_COMPILER_NAME) @<<$(CL_RSP) /E $** > $@
$(CXX_COMPILER_FLAGS: =
)
<<NOKEEP
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\wow6432\wow64csr.c ===
/*++

Copyright (c) 1998  Microsoft Corporation

Module Name:

    wow64csr.c

Abstract:

    This module contains the WOW64 versions of the code for the Windows Client.
    See csr* files in ntos\dll for more function comments.

Author:

    Michael Zoran (mzoran) 2-JUN-1998

Environment:

    User Mode only

Revision History:

--*/

#include "ldrp.h"
#include "csrdll.h"
#include "ntwow64.h"

NTSTATUS
CsrClientConnectToServer(
    IN PWSTR ObjectDirectory,
    IN ULONG ServerDllIndex,
    IN PVOID ConnectionInformation,
    IN OUT PULONG ConnectionInformationLength OPTIONAL,
    OUT PBOOLEAN CalledFromServer OPTIONAL
    )

{
    return NtWow64CsrClientConnectToServer(ObjectDirectory,
                                           ServerDllIndex,
                                           ConnectionInformation,
                                           ConnectionInformationLength,
                                           CalledFromServer);
}

NTSTATUS
CsrNewThread(
    VOID
    )
{
    return NtWow64CsrNewThread();
}

NTSTATUS
CsrIdentifyAlertableThread( VOID )
{
    return NtWow64CsrIdentifyAlertableThread();
}

NTSTATUS
CsrSetPriorityClass(
    IN HANDLE ProcessHandle,
    IN OUT PULONG PriorityClass
    )
{

   return NtWow64CsrSetPriorityClass(ProcessHandle, PriorityClass);

}

NTSTATUS
CsrClientCallServer(
    IN OUT PCSR_API_MSG m,
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer OPTIONAL,
    IN CSR_API_NUMBER ApiNumber,
    IN ULONG ArgLength
    )
{

    return NtWow64CsrClientCallServer(m,CaptureBuffer,ApiNumber,ArgLength);
}


PCSR_CAPTURE_HEADER
CsrAllocateCaptureBuffer(
    IN ULONG CountMessagePointers,
    IN ULONG Sizecd
    )
{
   return NtWow64CsrAllocateCaptureBuffer(CountMessagePointers, Sizecd);
}


VOID
CsrFreeCaptureBuffer(
    IN PCSR_CAPTURE_HEADER CaptureBuffer
    )

{

    NtWow64CsrFreeCaptureBuffer(CaptureBuffer);
}


ULONG
CsrAllocateMessagePointer(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN ULONG Length,
    OUT PVOID *Pointer
    )
{

   return NtWow64CsrAllocateMessagePointer(CaptureBuffer, Length, Pointer);

}


VOID
CsrCaptureMessageBuffer(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN PVOID Buffer OPTIONAL,
    IN ULONG Length,
    OUT PVOID *CapturedBuffer
    )
{

   NtWow64CsrCaptureMessageBuffer(CaptureBuffer,Buffer,Length,CapturedBuffer);

}

VOID
CsrCaptureMessageString(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN PCSTR String OPTIONAL,
    IN ULONG Length,
    IN ULONG MaximumLength,
    OUT PSTRING CapturedString
    )

{

  NtWow64CsrCaptureMessageString(CaptureBuffer, String, Length, MaximumLength, CapturedString);

}



PLARGE_INTEGER
CsrCaptureTimeout(
    IN ULONG MilliSeconds,
    OUT PLARGE_INTEGER Timeout
    )
{
    if (MilliSeconds == -1) {
        return( NULL );
        }
    else {
        Timeout->QuadPart = Int32x32To64( MilliSeconds, -10000 );
        return( (PLARGE_INTEGER)Timeout );
        }
}

VOID
CsrProbeForWrite(
    IN PVOID Address,
    IN ULONG Length,
    IN ULONG Alignment
    )

/*++

Routine Description:

    This function probes a structure for read accessibility.
    If the structure is not accessible, then an exception is raised.

Arguments:

    Address - Supplies a pointer to the structure to be probed.

    Length - Supplies the length of the structure.

    Alignment - Supplies the required alignment of the structure expressed
        as the number of bytes in the primitive datatype (e.g., 1 for char,
        2 for short, 4 for long, and 8 for quad).

Return Value:

    None.

--*/

{
    volatile CHAR *StartAddress;
    volatile CHAR *EndAddress;
    CHAR Temp;

    //
    // If the structure has zero length, then do not probe the structure for
    // write accessibility or alignment.
    //

    if (Length != 0) {

        //
        // If the structure is not properly aligned, then raise a data
        // misalignment exception.
        //

        ASSERT((Alignment == 1) || (Alignment == 2) ||
               (Alignment == 4) || (Alignment == 8));
        StartAddress = (volatile CHAR *)Address;

        if (((ULONG_PTR)StartAddress & (Alignment - 1)) != 0) {
            RtlRaiseStatus(STATUS_DATATYPE_MISALIGNMENT);
        } else {
            //
            // BUG, BUG - this should not be necessary once the 386 kernel
            // makes system space inaccessable to user mode.
            //
            if ((ULONG_PTR)StartAddress > CsrNtSysInfo.MaximumUserModeAddress) {
                RtlRaiseStatus(STATUS_ACCESS_VIOLATION);
            }

            Temp = *StartAddress;
            *StartAddress = Temp;
            EndAddress = StartAddress + Length - 1;
            Temp = *EndAddress;
            *EndAddress = Temp;
        }
    }
}

VOID
CsrProbeForRead(
    IN PVOID Address,
    IN ULONG Length,
    IN ULONG Alignment
    )

/*++

Routine Description:

    This function probes a structure for read accessibility.
    If the structure is not accessible, then an exception is raised.

Arguments:

    Address - Supplies a pointer to the structure to be probed.

    Length - Supplies the length of the structure.

    Alignment - Supplies the required alignment of the structure expressed
        as the number of bytes in the primitive datatype (e.g., 1 for char,
        2 for short, 4 for long, and 8 for quad).

Return Value:

    None.

--*/

{
    volatile CHAR *StartAddress;
    volatile CHAR *EndAddress;
    CHAR Temp;

    //
    // If the structure has zero length, then do not probe the structure for
    // read accessibility or alignment.
    //

    if (Length != 0) {

        //
        // If the structure is not properly aligned, then raise a data
        // misalignment exception.
        //

        ASSERT((Alignment == 1) || (Alignment == 2) ||
               (Alignment == 4) || (Alignment == 8));
        StartAddress = (volatile CHAR *)Address;

        if (((ULONG_PTR)StartAddress & (Alignment - 1)) != 0) {
            RtlRaiseStatus(STATUS_DATATYPE_MISALIGNMENT);
        } else {
            Temp = *StartAddress;
            EndAddress = StartAddress + Length - 1;
            Temp = *EndAddress;
        }
    }
}

HANDLE
CsrGetProcessId(
    VOID
    )
{
    return NtWow64CsrGetProcessId ();
}


VOID
CsrCaptureMessageUnicodeStringInPlace(
    IN OUT PCSR_CAPTURE_HEADER CaptureBuffer,
    IN OUT PUNICODE_STRING     String
    )
/*++

Routine Description:

    This function captures an ASCII string into a counted string data
    structure located in an API request message.

Arguments:

    CaptureBuffer - Pointer to a capture buffer allocated by
        CsrAllocateCaptureBuffer.

    String - Optional pointer to the Unicode string.  If this parameter is
        not present, then the counted string data structure is set to
        the null string.

    Length - Length of the Unicode string in bytes, ignored if String is NULL.

    MaximumLength - Maximum length of the string.  Different for null
        terminated strings, where Length does not include the null and
        MaximumLength does. This is always how much space is allocated
        from the capture buffer.

    CaptureString - Pointer to the counted string data structure that will
        be filled in to point to the captured Unicode string.

Return Value:

    None, but if you don't trust the String parameter, use a __try block.

--*/
{
    ASSERT(String != NULL);

    CsrCaptureMessageString(
        CaptureBuffer,
        (PCSTR)String->Buffer,
        String->Length,
        String->MaximumLength,
        (PSTRING)String
        );

    // test > before substraction due to unsignedness
    if (String->MaximumLength > String->Length) {
        if ((String->MaximumLength - String->Length) >= sizeof(WCHAR)) {
            String->Buffer[ String->Length / sizeof(WCHAR) ] = 0;
            }
    }
}


NTSTATUS
CsrCaptureMessageMultiUnicodeStringsInPlace(
    IN OUT PCSR_CAPTURE_HEADER* InOutCaptureBuffer,
    IN ULONG                    NumberOfStringsToCapture,
    IN const PUNICODE_STRING*   StringsToCapture
    )
/*++

Routine Description:

    Capture multiple unicode strings.
    If the CaptureBuffer hasn't been allocated yet (passed as NULL), first
        allocate it.

Arguments:

    CaptureBuffer - Pointer to a capture buffer allocated by
        CsrAllocateCaptureBuffer, or NULL, in which case we call CsrAllocateCaptureBuffer
        for you; this is the case if you are only capturing these strings
        and nothing else.

    NumberOfStringsToCapture - 

    StringsToCapture - 

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    ULONG Length = 0;
    ULONG i = 0;
    PCSR_CAPTURE_HEADER CaptureBuffer = NULL;

    if (InOutCaptureBuffer == NULL) {
        Status = STATUS_INVALID_PARAMETER;
        goto Exit;
    }

    CaptureBuffer = *InOutCaptureBuffer;

    if (CaptureBuffer == NULL) {
        Length = 0;
        for (i = 0 ; i != NumberOfStringsToCapture ; ++i) {
            if (StringsToCapture[i] != NULL) {
                Length += StringsToCapture[i]->MaximumLength;
            }
        }
        CaptureBuffer = CsrAllocateCaptureBuffer(NumberOfStringsToCapture, Length);
        if (CaptureBuffer == NULL) {
            Status = STATUS_NO_MEMORY;
            goto Exit;
        }
        *InOutCaptureBuffer = CaptureBuffer;
    }
    for (i = 0 ; i != NumberOfStringsToCapture ; ++i) {
        if (StringsToCapture[i] != NULL) {
            CsrCaptureMessageUnicodeStringInPlace(
                CaptureBuffer,
                StringsToCapture[i]
                );
        } else {
        }
    }
    Status = STATUS_SUCCESS;
Exit:
    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\ia64\ldrctx.c ===
/*++

Copyright (c) 1998  Microsoft Corporation

Module Name:

    ldrctx.c

Abstract:

    This module contains support for relocating executables.

Author:

    Landy Wang (landyw) 8-Jul-1998

Environment:

    User Mode only

Revision History:

--*/

#include <ldrp.h>
#include <ntos.h>

VOID
LdrpRelocateStartContext (
    IN PCONTEXT Context,
    IN LONG_PTR Diff
    )
/*++

Routine Description:

   This routine relocates the start context to mesh with the
   executable that has just been relocated.

Arguments:

   Context - Supplies a context that needs editing.

   Diff - Supplies the difference from the based address to the relocated
          address.

Return Value:

   None.

--*/
{
    Context->IntS1 += (ULONGLONG)Diff;
}

VOID
LdrpCorReplaceStartContext (
    IN PCONTEXT Context
    )
/*++

Routine Description:

   This routine replaces the initial address to run by one in mscoree.dll.

Arguments:

   Context - Supplies a context that needs editing.

Return Value:

   None.

--*/
{
    Context->IntS1 = (ULONGLONG)CorExeMain;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\wow6432\makefile.inc ===
!include ..\makefile.inc
!if exist(..\$(TARGET_DIRECTORY).inc)
!include ..\$(TARGET_DIRECTORY).inc
!endif

TEMP_DIR=$(O)
SERVICES_DIR=$(O)
SERVICES_TAB=$(SERVICES_DIR)\services.tab
KESVC_TAB=$(O)\kesvc32.tab
NTDLL_XTR=$(O)\ntdll.xtr

clean:
    -del $(KESVC32_TAB)

$(SERVICES_TAB): ..\..\ntos\ke\services.tab
    @echo Creating $@ from $**
    $(C_PREPROCESSOR) $** > $@
    del $(SERVICES_DIR)\kesvc32.tab

# generate and binplace kesvc32.tab, which copywow64 uses to validate that
# the x86 and Win64 sides of the build process agree
$(KESVC_TAB): ..\..\ntos\ke\services.tab
    $(C_PREPROCESSOR) $** > $@
    binplace $@

$(O)\usrstubs.obj: \
    $(O)\usrstubs.$(ASM_SUFFIX) $(O)\ntdll.def

$(NTDLL_XTR): $(SERVICES_TAB)
    gensrv -f $(NTDLL_XTR) -s $(MAKEDIR) $(SERVICES_DIR)

$(O)\usrstubs.$(ASM_SUFFIX): $(SERVICES_TAB) ntwow64.tab
    copy $(SERVICES_TAB)+ntwow64.tab $(TEMP_DIR)\services.tab
    gensrv -d $(O) -e $(ASM_SUFFIX) $(TARGET_BRACES) -s $(MAKEDIR)\$(TARGET_DIRECTORY) $(TEMP_DIR)

$(O)\ntdll.def: ..\ntdlldef.src ..\$(TARGET_DIRECTORY)def.src $(NTDLL_XTR)
    copy ..\ntdlldef.src+..\$(TARGET_DIRECTORY)def.src+$(NTDLL_XTR) $(O)\ntdll.pp
    $(TARGET_CPP) /EP $(CDEFINES) $(O)\ntdll.pp > $(O)\ntdll.def
    -del $(O)\ntdll.pp

..\ntdll.rc: $(PROJECT_ROOT)\published\$(O)\ntstatus.rc $(PROJECT_ROOT)\published\$(O)\ntstatus_MSG00001.bin
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdll\wow6432\wow64nt.c ===
/*++

Copyright (c) Microsoft Corporation

Module Name:

    wow64nt.c

Abstract:

    This module contains the Wow64 thunks to retreive information about the
    native system without actually thunking the values.

Author:

    Samer Arafeh (samera) 5-May-2001

Environment:

    User Mode only

Revision History:

--*/

#include "ldrp.h"
#include "csrdll.h"
#include "ntwow64.h"


NTSTATUS
RtlpWow64GetNativeSystemInformation(
    IN SYSTEM_INFORMATION_CLASS SystemInformationClass,
    IN PVOID NativeSystemInformation,
    IN ULONG InformationLength,
    OUT PULONG ReturnLength OPTIONAL
    )

/*++

Routine Description:

    This function queries information about the native system. This function has the same
    semantics as NtQuerySystemInformation.

Arguments:

    SystemInformationClass - The system information class about which
        to retrieve information.

    NativeSystemInformation - A pointer to a buffer which receives the specified
        information.  The format and content of the buffer depend on the
        specified system information class.
        
    SystemInformationLength - Specifies the length in bytes of the system
        information buffer.

    ReturnLength - An optional pointer which, if specified, receives the
        number of bytes placed in the system information buffer.
    
Return Value:

    NTSTATUS

--*/
{
    return NtWow64GetNativeSystemInformation(
        SystemInformationClass,
        NativeSystemInformation,
        InformationLength,
        ReturnLength
        );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ntoskrnl.inc ===
!if defined (BUILD_CHECKED_KERNEL)
NTDEBUG=ntsd
FREEBUILD=0
!endif


!if 0

#
# Enable later to turn on "inline IRQL manipulation" for MP kernels
#

!if !defined(NT_UP)
NT_UP=1
!endif

!if !$(NT_UP) && $(386)
C_DEFINES=$(C_DEFINES) -D_APIC_TPR_
ASM_DEFINES=$(ASM_DEFINES) -D_APIC_TPR_
!endif
!endif

!if !$(FREEBUILD)
NT_UP=0
!endif

GPSIZE=32

VC7_SYMBOLS=1

# No overflow checking for the kernel
BUFFER_OVERFLOW_CHECKS=0

!if $(IA64)
# Emit LTCG codegen
LINK_TIME_CODE_GENERATION=1
!endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntdllsym\syminfo.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    syminfo.c

--*/


#include "ntos.h"
#include <nt.h>
#include <ntrtl.h>
#include <nturtl.h>
#include <heap.h>
#include "heappage.h"
#include "heappagi.h"
#include "stktrace.h"
#include "tracedbp.h"
#include <winsnmp.h>
#include <winsafer.h>
                    
#define DECLARE_TYPE(Name) Name _DECL_##Name

//
// General types needed by various extensions.
//

DECLARE_TYPE (KUSER_SHARED_DATA);
DECLARE_TYPE (LDR_DATA_TABLE_ENTRY);
DECLARE_TYPE (PEB);
DECLARE_TYPE (PEB_LDR_DATA);
DECLARE_TYPE (TEB);
DECLARE_TYPE (HEAP);
DECLARE_TYPE (STACK_TRACE_DATABASE);

//
// ntdll.dll types needed by verifier extensions.
//

DECLARE_TYPE (RTL_CRITICAL_SECTION);
DECLARE_TYPE (RTL_CRITICAL_SECTION_DEBUG);
DECLARE_TYPE (RTL_STACK_TRACE_ENTRY);
DECLARE_TYPE (RTL_TRACE_DATABASE);
DECLARE_TYPE (RTL_TRACE_BLOCK);
DECLARE_TYPE (STACK_TRACE_DATABASE);
DECLARE_TYPE (DPH_HEAP_ROOT);
DECLARE_TYPE (DPH_HEAP_BLOCK);
DECLARE_TYPE (DPH_BLOCK_INFORMATION);
DECLARE_TYPE (ULONG_PTR);
DECLARE_TYPE (UNICODE_STRING);

//
// Make it build
//

int __cdecl main() { 
    return 0; 
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\arb\sources.inc ===
MAJORCOMP=ntos
MINORCOMP=arb

TARGETNAME=arb
TARGETTYPE=LIBRARY
TARGETPATH=obj

BUILD_PRODUCES=ntosarb$(NT_UP)

C_DEFINES=$(C_DEFINES) /DNTOS_KERNEL

INCLUDES=..\..\inc;$(DDK_INC_PATH)

MSC_WARNING_LEVEL=/W4 /WX

SOURCES=..\arbiter.c \
        ..\debug.c

# No overflow checking for the kernel
BUFFER_OVERFLOW_CHECKS=0
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\arb\arbp.h ===
#ifndef _ARBP_
#define _ARBP_

#ifndef FAR
#define FAR
#endif

#if DBG
#define ARB_DBG 1 // DBG
#endif

#pragma warning(disable:4214)   // bit field types other than int
#pragma warning(disable:4201)   // nameless struct/union
#pragma warning(disable:4115)   // named type definition in parentheses
#pragma warning(disable:4127)   // condition expression is constant
#if 0
#pragma warning(disable:4324)   // alignment sensitive to declspec
#pragma warning(disable:4232)   // dllimport not static
#pragma warning(disable:4206)   // translation unit empty
#endif

#if NTOS_KERNEL

//
// If we are in the kernel use the in-kernel headers so we get the efficient
// definitions of things
//

#include "ntos.h"
#include "zwapi.h"

#else

//
// If we are building the library for bus drivers to use make sure we use the 
// same definitions of things as them
//

#include "ntddk.h"

#endif

#include "arbiter.h"
#include <stdlib.h>     // for __min and __max


#if ARB_DBG

extern const CHAR* ArbpActionStrings[];
extern ULONG ArbStopOnError;
extern ULONG ArbReplayOnError;

VOID
ArbDumpArbiterInstance(
    LONG Level,
    PARBITER_INSTANCE Arbiter
    );

VOID
ArbDumpArbiterRange(
    LONG Level,
    PRTL_RANGE_LIST List,
    PCHAR RangeText
    );

VOID
ArbDumpArbitrationList(
    LONG Level,
    PLIST_ENTRY ArbitrationList
    );

#endif // ARB_DBG

#endif _ARBP_
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\arb\arbiter.c ===
/*++

Copyright (c) 1997  Microsoft Corporation

Module Name:

    arbiter.c

Abstract:

    This module contains support routines for the Pnp resource arbiters.

Author:

    Andrew Thornton (andrewth) 1-April-1997


Environment:

    Kernel mode

Revision History:

--*/

#include "arbp.h"

#define REGSTR_KEY_ROOTENUM             L"ROOT"
//
// Conditional compilation constants
//

#define ALLOW_BOOT_ALLOC_CONFLICTS      1
#define PLUG_FEST_HACKS                 0

//
// Pool Tags
//

#define ARBITER_ALLOCATION_STATE_TAG    'AbrA'
#define ARBITER_ORDERING_LIST_TAG       'LbrA'
#define ARBITER_MISC_TAG                'MbrA'
#define ARBITER_RANGE_LIST_TAG          'RbrA'
#define ARBITER_CONFLICT_INFO_TAG       'CbrA'

//
// Constants
//

#define PATH_ARBITERS            L"\\Registry\\Machine\\System\\CurrentControlSet\\Control\\Arbiters"
#define KEY_ALLOCATIONORDER      L"AllocationOrder"
#define KEY_RESERVEDRESOURCES    L"ReservedResources"
#define ARBITER_ORDERING_GROW_SIZE  8


//
// Macros
//

//
// PVOID
// FULL_INFO_DATA(
//    IN PKEY_VALUE_FULL_INFORMATION k
// );
//
// This macro returns the pointer to the beginning of the data area of a
// KEY_VALUE_FULL_INFORMATION structure.
//

#define FULL_INFO_DATA(k) ((PCHAR)(k) + (k)->DataOffset)

//
// BOOLEAN
// DISJOINT(
//      IN ULONGLONG s1,
//      IN ULONGLONG e1,
//      IN ULONGLONG s2,
//      IN ULONGLONG e2
//      );
//
#define DISJOINT(s1,e1,s2,e2)                                           \
    ( ((s1) < (s2) && (e1) < (s2))                                      \
    ||((s2) < (s1) && (e2) < (s1)) )

//
// VOID
// ArbpWstrToUnicodeString(
//      IN PUNICODE_STRING u,
//      IN PWSTR p
//      );
//

#define ArbpWstrToUnicodeString(u, p)                                   \
    (u)->Length = ((u)->MaximumLength =                                 \
        (USHORT) (sizeof((p))) - sizeof(WCHAR));                        \
    (u)->Buffer = (p)

//
// ULONG
// INDEX_FROM_PRIORITY(
//     LONG Priority
// );
//

#define ORDERING_INDEX_FROM_PRIORITY(P)                                 \
    ( (ULONG) ( (P) > 0 ? (P) - 1 : ((P) * -1) - 1) )

//
// Prototypes
//

NTSTATUS
ArbpBuildAllocationStack(
    IN PARBITER_INSTANCE Arbiter,
    IN PLIST_ENTRY ArbitrationList,
    IN ULONG ArbitrationListCount
    );

NTSTATUS
ArbpGetRegistryValue(
    IN HANDLE KeyHandle,
    IN PWSTR  ValueName,
    OUT PKEY_VALUE_FULL_INFORMATION *Information
    );

NTSTATUS
ArbpBuildAlternative(
    IN PARBITER_INSTANCE Arbiter,
    IN PIO_RESOURCE_DESCRIPTOR Requirement,
    OUT PARBITER_ALTERNATIVE Alternative
    );

VOID
ArbpUpdatePriority(
    PARBITER_INSTANCE Arbiter,
    PARBITER_ALTERNATIVE Alternative
    );

BOOLEAN
ArbpQueryConflictCallback(
    IN PVOID Context,
    IN PRTL_RANGE Range
    );

BOOLEAN
ArbShareDriverExclusive(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    );

//
// Make everything pageable
//

#ifdef ALLOC_PRAGMA

VOID
ArbDereferenceArbiterInstance(
    IN PARBITER_INSTANCE Arbiter
    );

#pragma alloc_text(PAGE, ArbInitializeArbiterInstance)
#pragma alloc_text(PAGE, ArbDereferenceArbiterInstance)
#pragma alloc_text(PAGE, ArbDeleteArbiterInstance)
#pragma alloc_text(PAGE, ArbTestAllocation)
#pragma alloc_text(PAGE, ArbpBuildAlternative)
#pragma alloc_text(PAGE, ArbpBuildAllocationStack)
#pragma alloc_text(PAGE, ArbSortArbitrationList)
#pragma alloc_text(PAGE, ArbCommitAllocation)
#pragma alloc_text(PAGE, ArbRollbackAllocation)
#pragma alloc_text(PAGE, ArbRetestAllocation)
#pragma alloc_text(PAGE, ArbBootAllocation)
#pragma alloc_text(PAGE, ArbArbiterHandler)
#pragma alloc_text(PAGE, ArbBuildAssignmentOrdering)
#pragma alloc_text(PAGE, ArbFindSuitableRange)
#pragma alloc_text(PAGE, ArbAddAllocation)
#pragma alloc_text(PAGE, ArbBacktrackAllocation)
#pragma alloc_text(PAGE, ArbPreprocessEntry)
#pragma alloc_text(PAGE, ArbAllocateEntry)
#pragma alloc_text(PAGE, ArbGetNextAllocationRange)
#pragma alloc_text(PAGE, ArbpGetRegistryValue)
#pragma alloc_text(PAGE, ArbInitializeOrderingList)
#pragma alloc_text(PAGE, ArbCopyOrderingList)
#pragma alloc_text(PAGE, ArbAddOrdering)
#pragma alloc_text(PAGE, ArbPruneOrdering)
#pragma alloc_text(PAGE, ArbFreeOrderingList)
#pragma alloc_text(PAGE, ArbOverrideConflict)
#pragma alloc_text(PAGE, ArbpUpdatePriority)
#pragma alloc_text(PAGE, ArbAddReserved)
#pragma alloc_text(PAGE, ArbpQueryConflictCallback)
#pragma alloc_text(PAGE, ArbQueryConflict)
#pragma alloc_text(PAGE, ArbStartArbiter)
#pragma alloc_text(PAGE, ArbShareDriverExclusive)

#endif // ALLOC_PRAGMA

//
// Implementation
//


NTSTATUS
ArbInitializeArbiterInstance(
    OUT PARBITER_INSTANCE Arbiter,
    IN PDEVICE_OBJECT BusDeviceObject,
    IN CM_RESOURCE_TYPE ResourceType,
    IN PWSTR Name,
    IN PWSTR OrderingName,
    IN PARBITER_TRANSLATE_ALLOCATION_ORDER TranslateOrdering OPTIONAL
    )

/*++

Routine Description:

    This routine initializes an arbiter instance and fills in any optional NULL
    dispatch table entries with system default functions.

Parameters:

    Arbiter - A caller allocated arbiter instance structure.
        The UnpackRequirement, PackResource, UnpackResource and ScoreRequirement
        entries should be initialized with the appropriate routines as should
        any other entries if the default system routines are not sufficient.

    BusDeviceObject - The device object that exposes this arbiter - normally an
        FDO.

    ResourceType - The resource type this arbiter arbitrates.

    Name - A string used to identify the arbiter, used in debug messages and
        for registry storage

    OrderingName - The name of the preferred assignment ordering list under
        HKLM\System\CurrentControlSet\Control\SystemResources\AssignmentOrdering


    TranslateOrdering - Function that, if present, will be called to translate
        each descriptor from the ordering list

Return Value:

    Status code that indicates whether or not the function was successful.

Notes:


--*/

{
    NTSTATUS status;

    PAGED_CODE();

    ASSERT(Arbiter->UnpackRequirement);
    ASSERT(Arbiter->PackResource);
    ASSERT(Arbiter->UnpackResource);

    ARB_PRINT(2,("Initializing %S Arbiter...\n", Name));

    //
    // Initialize all pool allocation pointers to NULL so we can cleanup
    //

    ASSERT(Arbiter->MutexEvent == NULL
           && Arbiter->Allocation == NULL
           && Arbiter->PossibleAllocation == NULL
           && Arbiter->AllocationStack == NULL
           );

    //
    // We are an arbiter
    //

    Arbiter->Signature = ARBITER_INSTANCE_SIGNATURE;

    //
    // Remember the bus that produced us
    //

    Arbiter->BusDeviceObject = BusDeviceObject;

    //
    // Initialize state lock (KEVENT must be non-paged)
    //

    Arbiter->MutexEvent = ExAllocatePoolWithTag(NonPagedPool,
                                                sizeof(KEVENT),
                                                ARBITER_MISC_TAG
                                                );

    if (!Arbiter->MutexEvent) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    KeInitializeEvent(Arbiter->MutexEvent, SynchronizationEvent, TRUE);

    //
    // Initialize the allocation stack to a reasonable size
    //

    Arbiter->AllocationStack = ExAllocatePoolWithTag(PagedPool,
                                                     INITIAL_ALLOCATION_STATE_SIZE,
                                                     ARBITER_ALLOCATION_STATE_TAG
                                                     );

    if (!Arbiter->AllocationStack) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    Arbiter->AllocationStackMaxSize = INITIAL_ALLOCATION_STATE_SIZE;


    //
    // Allocate buffers to hold the range lists
    //

    Arbiter->Allocation = ExAllocatePoolWithTag(PagedPool,
                                                sizeof(RTL_RANGE_LIST),
                                                ARBITER_RANGE_LIST_TAG
                                                );

    if (!Arbiter->Allocation) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    Arbiter->PossibleAllocation = ExAllocatePoolWithTag(PagedPool,
                                                        sizeof(RTL_RANGE_LIST),
                                                        ARBITER_RANGE_LIST_TAG
                                                        );

    if (!Arbiter->PossibleAllocation) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Initialize the range lists
    //

    RtlInitializeRangeList(Arbiter->Allocation);
    RtlInitializeRangeList(Arbiter->PossibleAllocation);

    //
    // Initialize the data fields
    //
    Arbiter->TransactionInProgress = FALSE;
    Arbiter->Name = Name;
    Arbiter->ResourceType = ResourceType;

    //
    // If the caller has not supplied the optional functions set them to the
    // defaults (If this were C++ we'd just inherit this loit but seeing as its
    // not we'll do it the old fashioned way...)
    //

    if (!Arbiter->TestAllocation) {
        Arbiter->TestAllocation = ArbTestAllocation;
    }

    if (!Arbiter->RetestAllocation) {
        Arbiter->RetestAllocation = ArbRetestAllocation;
    }

    if (!Arbiter->CommitAllocation) {
        Arbiter->CommitAllocation = ArbCommitAllocation;
    }

    if (!Arbiter->RollbackAllocation) {
        Arbiter->RollbackAllocation = ArbRollbackAllocation;
    }

    if (!Arbiter->AddReserved) {
        Arbiter->AddReserved = ArbAddReserved;
    }

    if (!Arbiter->PreprocessEntry) {
        Arbiter->PreprocessEntry = ArbPreprocessEntry;
    }

    if (!Arbiter->AllocateEntry) {
        Arbiter->AllocateEntry = ArbAllocateEntry;
    }

    if (!Arbiter->GetNextAllocationRange) {
        Arbiter->GetNextAllocationRange = ArbGetNextAllocationRange;
    }

    if (!Arbiter->FindSuitableRange) {
        Arbiter->FindSuitableRange = ArbFindSuitableRange;
    }

    if (!Arbiter->AddAllocation) {
        Arbiter->AddAllocation = ArbAddAllocation;
    }

    if (!Arbiter->BacktrackAllocation) {
        Arbiter->BacktrackAllocation = ArbBacktrackAllocation;
    }

    if (!Arbiter->OverrideConflict) {
        Arbiter->OverrideConflict = ArbOverrideConflict;
    }

    if (!Arbiter->BootAllocation) {
        Arbiter->BootAllocation = ArbBootAllocation;
    }

    if (!Arbiter->QueryConflict) {
        Arbiter->QueryConflict = ArbQueryConflict;
    }

    if (!Arbiter->StartArbiter) {
        Arbiter->StartArbiter = ArbStartArbiter;
    }

    //
    // Build the prefered assignment ordering - we assume that the reserved
    // ranges have the same name as the assignment ordering
    //

    status = ArbBuildAssignmentOrdering(Arbiter,
                                        OrderingName,
                                        OrderingName,
                                        TranslateOrdering
                                        );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    return STATUS_SUCCESS;

cleanup:

    if (Arbiter->MutexEvent) {
        ExFreePool(Arbiter->MutexEvent);
    }

    if (Arbiter->Allocation) {
        ExFreePool(Arbiter->Allocation);
    }

    if (Arbiter->PossibleAllocation) {
        ExFreePool(Arbiter->PossibleAllocation);
    }

    if (Arbiter->AllocationStack) {
        ExFreePool(Arbiter->AllocationStack);
    }

    return status;

}

VOID
ArbReferenceArbiterInstance(
    IN PARBITER_INSTANCE Arbiter
    )
{
    InterlockedIncrement(&Arbiter->ReferenceCount);
}

VOID
ArbDereferenceArbiterInstance(
    IN PARBITER_INSTANCE Arbiter
    )
{
    PAGED_CODE();

    InterlockedDecrement(&Arbiter->ReferenceCount);

    if (Arbiter->ReferenceCount == 0) {
        ArbDeleteArbiterInstance(Arbiter);
    }
}

VOID
ArbDeleteArbiterInstance(
    IN PARBITER_INSTANCE Arbiter
    )
{

    PAGED_CODE();

    if (Arbiter->MutexEvent) {
        ExFreePool(Arbiter->MutexEvent);
    }

    if (Arbiter->Allocation) {
        RtlFreeRangeList(Arbiter->Allocation);
        ExFreePool(Arbiter->Allocation);
    }

    if (Arbiter->PossibleAllocation) {
        RtlFreeRangeList(Arbiter->PossibleAllocation);
        ExFreePool(Arbiter->PossibleAllocation);
    }

    if (Arbiter->AllocationStack) {
        ExFreePool(Arbiter->AllocationStack);
    }

    ArbFreeOrderingList(&Arbiter->OrderingList);
    ArbFreeOrderingList(&Arbiter->ReservedList);

#if ARB_DBG

    RtlFillMemory(Arbiter, sizeof(ARBITER_INSTANCE), 'A');

#endif

}

NTSTATUS
ArbTestAllocation(
    IN PARBITER_INSTANCE Arbiter,
    IN OUT PLIST_ENTRY ArbitrationList
    )

/*++

Routine Description:

    This is the default implementation of the arbiter Test Allocation action.
    It takes a list of requests for resources for particular devices and attempts
    to satisfy them.

Parameters:

    Arbiter - The instance of the arbiter being called.

    ArbitrationList - A list of ARBITER_LIST_ENTRY entries which contain the
        requirements and associated devices.

Return Value:

    Status code that indicates whether or not the function was successful.
    These include:

    STATUS_SUCCESSFUL - Arbitration suceeded and an allocation has been made for
        all the entries in the arbitration list.

    STATUS_UNSUCCESSFUL - Arbitration failed to find an allocation for all
        entries.

    STATUS_ARBITRATION_UNHANDLED - If returning this error the arbiter is
        partial (and therefore must have set the ARBITER_PARTIAL flag in its
        interface.)  This status indicates that this arbiter doesn't handle the
        resources requested and the next arbiter towards the root of the device
        tree should be asked instead.

--*/

{

    NTSTATUS status;
    PARBITER_LIST_ENTRY current;
    PIO_RESOURCE_DESCRIPTOR alternative;
    ULONG count;
    PDEVICE_OBJECT previousOwner;
    PDEVICE_OBJECT currentOwner;
    LONG score;

    PAGED_CODE();
    ASSERT(Arbiter);

    //
    // Copy the current allocation
    //

    ARB_PRINT(3, ("Copy current allocation\n"));
    status = RtlCopyRangeList(Arbiter->PossibleAllocation, Arbiter->Allocation);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Free all the resources currently allocated to all the devices we
    // are arbitrating for
    //

    count = 0;
    previousOwner = NULL;

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        count++;

        currentOwner = current->PhysicalDeviceObject;

        if (previousOwner != currentOwner) {

            previousOwner = currentOwner;

            ARB_PRINT(3,
                        ("Delete 0x%08x's resources\n",
                        currentOwner
                        ));

            status = RtlDeleteOwnersRanges(Arbiter->PossibleAllocation,
                                           (PVOID)currentOwner
                                           );

            if (!NT_SUCCESS(status)) {
                goto cleanup;
            }
        }

        //
        // Score the entries in the arbitration list if a scoring function was
        // provided and this is not a legacy request (which is guaranteed to be
        // made of all fixed requests so sorting is pointless)
        //

        //
        // ISSUE-2000/03/06-andrewth
        // Ensure that in the start and enum cleanup the RequestSource is correctly passed in
        // so we can safely skip the unnecesary scoring and sorting
        // && !LEGACY_REQUEST(current);
        //
        current->WorkSpace = 0;

        if (Arbiter->ScoreRequirement != NULL) {

            FOR_ALL_IN_ARRAY(current->Alternatives,
                             current->AlternativeCount,
                             alternative) {

                ARB_PRINT(3,
                            ("Scoring entry %p\n",
                            currentOwner
                            ));



                score = Arbiter->ScoreRequirement(alternative);

                //
                // Ensure the score is valid
                //

                if (score < 0) {
                    status = STATUS_DEVICE_CONFIGURATION_ERROR;
                    goto cleanup;
                }

                current->WorkSpace += score;
            }
        }
    }

    status = ArbSortArbitrationList(ArbitrationList);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Build the arbitration stack
    //

    status = ArbpBuildAllocationStack(Arbiter,
                                     ArbitrationList,
                                     count
                                     );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Attempt allocation
    //

    status = Arbiter->AllocateEntry(Arbiter, Arbiter->AllocationStack);

    if (NT_SUCCESS(status)) {

        //
        // Success.
        //

        return status;
    }

cleanup:

    //
    // We didn't succeed so empty the possible allocation list...
    //

    RtlFreeRangeList(Arbiter->PossibleAllocation);

    return status;
}


NTSTATUS
ArbpBuildAlternative(
    IN PARBITER_INSTANCE Arbiter,
    IN PIO_RESOURCE_DESCRIPTOR Requirement,
    OUT PARBITER_ALTERNATIVE Alternative
    )

/*++

Routine Description:

    This routine initializes a arbiter alternative from a given resource
    requirement descriptor

Parameters:

    Arbiter - The arbiter instance data where the allocation stack should be
        placed.

    Requirement - The requirement descriptor describing this requirement

    Alternative - The alternative to be initialized

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{

    NTSTATUS status;

    PAGED_CODE();
    ASSERT(Alternative && Requirement);

    Alternative->Descriptor = Requirement;

    //
    // Unpack the requirement into the alternatives table
    //

    status = Arbiter->UnpackRequirement(Requirement,
                                        &Alternative->Minimum,
                                        &Alternative->Maximum,
                                        &Alternative->Length,
                                        &Alternative->Alignment
                                        );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Align the minimum if necessary
    //

    if (Alternative->Minimum % Alternative->Alignment != 0) {
        ALIGN_ADDRESS_UP(Alternative->Minimum,
                         Alternative->Alignment
                         );
    }

    Alternative->Flags = 0;

    //
    // Check if this alternative is shared
    //

    if(Requirement->ShareDisposition == CmResourceShareShared) {
        Alternative->Flags |= ARBITER_ALTERNATIVE_FLAG_SHARED;
    }

    //
    // Check if this alternative is fixed
    //

    if (Alternative->Maximum - Alternative->Minimum + 1 == Alternative->Length) {
        Alternative->Flags |= ARBITER_ALTERNATIVE_FLAG_FIXED;
    }

    //
    // Check for validity
    //

    if (Alternative->Maximum < Alternative->Minimum) {
        Alternative->Flags |= ARBITER_ALTERNATIVE_FLAG_INVALID;
    }

    return STATUS_SUCCESS;

cleanup:

    return status;
}


NTSTATUS
ArbpBuildAllocationStack(
    IN PARBITER_INSTANCE Arbiter,
    IN PLIST_ENTRY ArbitrationList,
    IN ULONG ArbitrationListCount
    )

/*++

Routine Description:

    This routine initializes the allocation stack for the requests in
    ArbitrationList.  It overwrites any previous allocation stack and allocates
    additional memory if more is required.  Arbiter->AllocationStack contains
    the initialized stack on success.

Parameters:

    Arbiter - The arbiter instance data where the allocation stack should be
        placed.

    ArbitrationList - A list of ARBITER_LIST_ENTRY entries which contain the
        requirements and associated devices.

    ArbitrationListCount - The number of entries in the ArbitrationList

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    NTSTATUS status;
    PARBITER_LIST_ENTRY currentEntry;
    PARBITER_ALLOCATION_STATE currentState;
    ULONG stackSize = 0, allocationCount = ArbitrationListCount + 1;
    PARBITER_ALTERNATIVE currentAlternative;
    PIO_RESOURCE_DESCRIPTOR currentDescriptor;

    PAGED_CODE();

    //
    // Calculate the size the stack needs to be and the
    //

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, currentEntry) {

        if (currentEntry->AlternativeCount > 0) {
            stackSize += currentEntry->AlternativeCount
                            * sizeof(ARBITER_ALTERNATIVE);
        } else {
            allocationCount--;
        }
    }

    stackSize += allocationCount * sizeof(ARBITER_ALLOCATION_STATE);

    //
    // Make sure the allocation stack is large enough
    //

    if (Arbiter->AllocationStackMaxSize < stackSize) {

        PARBITER_ALLOCATION_STATE temp;

        //
        // Enlarge the allocation stack
        //

        temp = ExAllocatePoolWithTag(PagedPool,
                                     stackSize,
                                     ARBITER_ALLOCATION_STATE_TAG
                                     );
        if (!temp) {
            return STATUS_INSUFFICIENT_RESOURCES;
        }

        ExFreePool(Arbiter->AllocationStack);
        Arbiter->AllocationStack = temp;
    }

    RtlZeroMemory(Arbiter->AllocationStack, stackSize);

    //
    // Fill in the locations
    //

    currentState = Arbiter->AllocationStack;
    currentAlternative = (PARBITER_ALTERNATIVE) (Arbiter->AllocationStack
        + ArbitrationListCount + 1);

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, currentEntry) {

        //
        // Do we need to allocate anything for this entry?
        //

        if (currentEntry->AlternativeCount > 0) {

            //
            // Initialize the stack location
            //

            currentState->Entry = currentEntry;
            currentState->AlternativeCount = currentEntry->AlternativeCount;
            currentState->Alternatives = currentAlternative;

            //
            // Initialize the start and end values to an invalid range so
            // that we don't skip the range 0-0 every time...
            //

            currentState->Start = 1;
            ASSERT(currentState->End == 0);  // From RtlZeroMemory

            //
            // Initialize the alternatives table
            //

            FOR_ALL_IN_ARRAY(currentEntry->Alternatives,
                             currentEntry->AlternativeCount,
                             currentDescriptor) {


                status = ArbpBuildAlternative(Arbiter,
                                            currentDescriptor,
                                            currentAlternative
                                            );

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }

                //
                // Initialize the priority
                //

                currentAlternative->Priority = ARBITER_PRIORITY_NULL;

                //
                // Advance to the next alternative
                //

                currentAlternative++;

            }
        }
        currentState++;
    }

    //
    // Terminate the stack with NULL entry
    //

    currentState->Entry = NULL;

    return STATUS_SUCCESS;

cleanup:

    //
    // We don't need to free the buffer as it is attached to the arbiter and
    // will be used next time
    //

    return status;
}

NTSTATUS
ArbSortArbitrationList(
    IN OUT PLIST_ENTRY ArbitrationList
    )

/*++

Routine Description:

    This routine sorts the arbitration list in order of each entry's
    WorkSpace value.

Parameters:

    ArbitrationList - The list to be sorted.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    BOOLEAN sorted = FALSE;
    PARBITER_LIST_ENTRY current, next;

    PAGED_CODE();

    ARB_PRINT(3, ("IoSortArbiterList(%p)\n", ArbitrationList));

    while (!sorted) {

        sorted = TRUE;

        for (current=(PARBITER_LIST_ENTRY) ArbitrationList->Flink,
               next=(PARBITER_LIST_ENTRY) current->ListEntry.Flink;

            (PLIST_ENTRY) current != ArbitrationList
               && (PLIST_ENTRY) next != ArbitrationList;

            current = (PARBITER_LIST_ENTRY) current->ListEntry.Flink,
                next = (PARBITER_LIST_ENTRY)current->ListEntry.Flink) {


            if (current->WorkSpace > next->WorkSpace) {

                PLIST_ENTRY before = current->ListEntry.Blink;
                PLIST_ENTRY after = next->ListEntry.Flink;

                //
                // Swap the locations of current and next
                //

                before->Flink = (PLIST_ENTRY) next;
                after->Blink = (PLIST_ENTRY) current;
                current->ListEntry.Flink = after;
                current->ListEntry.Blink = (PLIST_ENTRY) next;
                next->ListEntry.Flink = (PLIST_ENTRY) current;
                next->ListEntry.Blink = before;

                sorted = FALSE;
            }
        }
    }

    return STATUS_SUCCESS;
}

NTSTATUS
ArbCommitAllocation(
    PARBITER_INSTANCE Arbiter
    )

/*++

Routine Description:

    This provides the default implementation of the CommitAllocation action.
    It frees the old allocation and replaces it with the new allocation.

Parameters:

    Arbiter - The arbiter instance data for the arbiter being called.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    PRTL_RANGE_LIST temp;

    PAGED_CODE();

    //
    // Free up the current allocation
    //

    RtlFreeRangeList(Arbiter->Allocation);

    //
    // Swap the allocated and duplicate lists
    //

    temp = Arbiter->Allocation;
    Arbiter->Allocation = Arbiter->PossibleAllocation;
    Arbiter->PossibleAllocation = temp;

    return STATUS_SUCCESS;
}

NTSTATUS
ArbRollbackAllocation(
    IN PARBITER_INSTANCE Arbiter
    )

/*++

Routine Description:

    This provides the default implementation of the RollbackAllocation action.
    It frees the possible allocation the last TestAllocation provided.

Parameters:

    Arbiter - The arbiter instance data for the arbiter being called.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{

    PAGED_CODE();

    //
    // Free up the possible allocation
    //

    RtlFreeRangeList(Arbiter->PossibleAllocation);

    return STATUS_SUCCESS;
}

NTSTATUS
ArbRetestAllocation(
    IN PARBITER_INSTANCE Arbiter,
    IN OUT PLIST_ENTRY ArbitrationList
    )

/*++

Routine Description:

    This provides the default implementation of the RetestAllocation action.
    It walks the arbitration list and updates the possible allocation to reflect
    the allocation entries of the list.  For these entries to be valid
    TestAllocation must have been performed on this arbitration list.

Parameters:

    Arbiter - The arbiter instance data for the arbiter being called.

    ArbitrationList - A list of ARBITER_LIST_ENTRY entries which contain the
        requirements and associated devices.  TestAllocation for this arbiter
        should have been called on this list.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    NTSTATUS status;
    PARBITER_LIST_ENTRY current;
    ARBITER_ALLOCATION_STATE state;
    ARBITER_ALTERNATIVE alternative;
    ULONG length;

    PAGED_CODE();

    //
    // Initialize the state
    //

    RtlZeroMemory(&state, sizeof(ARBITER_ALLOCATION_STATE));
    RtlZeroMemory(&alternative, sizeof(ARBITER_ALTERNATIVE));
    state.AlternativeCount = 1;
    state.Alternatives = &alternative;
    state.CurrentAlternative = &alternative;
    state.Flags = ARBITER_STATE_FLAG_RETEST;

    //
    // Copy the current allocation and reserved
    //

    ARB_PRINT(2, ("Retest: Copy current allocation\n"));
    status = RtlCopyRangeList(Arbiter->PossibleAllocation, Arbiter->Allocation);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Free all the resources currently allocated to all the devices we
    // are arbitrating for
    //

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        ARB_PRINT(3,
                    ("Retest: Delete 0x%08x's resources\n",
                    current->PhysicalDeviceObject
                    ));

        status = RtlDeleteOwnersRanges(Arbiter->PossibleAllocation,
                                       (PVOID) current->PhysicalDeviceObject
                                       );

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }
    }

    //
    // Build an allocation state for the allocation and call AddAllocation to
    // update the range lists accordingly
    //

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        ASSERT(current->Assignment && current->SelectedAlternative);

        state.WorkSpace = 0;
        state.Entry = current;

        //
        // Initialize the alternative
        //

        status = ArbpBuildAlternative(Arbiter,
                                    current->SelectedAlternative,
                                    &alternative
                                    );

        ASSERT(NT_SUCCESS(status));

        //
        // Update it with our allocation
        //

        status = Arbiter->UnpackResource(current->Assignment,
                                         &state.Start,
                                         &length
                                         );

        ASSERT(NT_SUCCESS(status));

        state.End = state.Start + length - 1;

        //
        // Do any preprocessing that is required
        //

        status = Arbiter->PreprocessEntry(Arbiter,&state);

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        //
        // If we had a requirement for length 0 then don't attemp to add the
        // range - it will fail!
        //

        if (length != 0) {

            Arbiter->AddAllocation(Arbiter, &state);

        }
    }

    return status;

cleanup:

    RtlFreeRangeList(Arbiter->PossibleAllocation);
    return status;
}

NTSTATUS
ArbBootAllocation(
    IN PARBITER_INSTANCE Arbiter,
    IN OUT PLIST_ENTRY ArbitrationList
    )
/*++

Routine Description:

    This provides the default implementation of the BootAllocation action.
    It walks the arbitration list and updates the allocation to reflect the fact
    that the allocation entries in the list are in use.

Parameters:

    Arbiter - The arbiter instance data for the arbiter being called.

    ArbitrationList - A list of ARBITER_LIST_ENTRY entries which contain the
        requirements and associated devices.  Each device should have one and
        only one requirement reflecting the resources it is currently consuming.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{

    NTSTATUS status;
    PARBITER_LIST_ENTRY current;
    PRTL_RANGE_LIST temp;
    ARBITER_ALLOCATION_STATE state;
    ARBITER_ALTERNATIVE alternative;

    PAGED_CODE();

    //
    // Initialize the state
    //

    RtlZeroMemory(&state, sizeof(ARBITER_ALLOCATION_STATE));
    RtlZeroMemory(&alternative, sizeof(ARBITER_ALTERNATIVE));
    state.AlternativeCount = 1;
    state.Alternatives = &alternative;
    state.CurrentAlternative = &alternative;
    state.Flags = ARBITER_STATE_FLAG_BOOT;
    state.RangeAttributes = ARBITER_RANGE_BOOT_ALLOCATED;

    //
    // Work on the possible allocation list
    //

    status = RtlCopyRangeList(Arbiter->PossibleAllocation, Arbiter->Allocation);

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        ASSERT(current->AlternativeCount == 1);
        ASSERT(current->PhysicalDeviceObject);

        //
        // Build an alternative and state structure for this allocation and
        // add it to the range list
        //

        state.Entry = current;

        //
        // Initialize the alternative
        //

        status = ArbpBuildAlternative(Arbiter,
                                    &current->Alternatives[0],
                                    &alternative
                                    );

        ASSERT(NT_SUCCESS(status));
        ASSERT(alternative.Flags &
               (ARBITER_ALTERNATIVE_FLAG_FIXED | ARBITER_ALTERNATIVE_FLAG_INVALID)
               );

        state.Start = alternative.Minimum;
        state.End = alternative.Maximum;

        //
        // Blow away the old workspace and masks
        //

        state.WorkSpace = 0;
        state.RangeAvailableAttributes = 0;

        //
        // Validate the requirement
        //

        if (alternative.Length == 0
        || alternative.Alignment == 0
        || state.End < state.Start
        || state.Start % alternative.Alignment != 0
        || LENGTH_OF(state.Start, state.End) != alternative.Length) {

            ARB_PRINT(1,
                        ("Skipping invalid boot allocation 0x%I64x-0x%I64x L 0x%x A 0x%x for 0x%08x\n",
                         state.Start,
                         state.End,
                         alternative.Length,
                         alternative.Alignment,
                         current->PhysicalDeviceObject
                         ));

            continue;
        }

#if PLUG_FEST_HACKS

        if (alternative.Flags & ARBITER_ALTERNATIVE_FLAG_SHARED) {

            ARB_PRINT(1,
                         ("Skipping shared boot allocation 0x%I64x-0x%I64x L 0x%x A 0x%x for 0x%08x\n",
                          state.Start,
                          state.End,
                          alternative.Length,
                          alternative.Alignment,
                          current->PhysicalDeviceObject
                          ));

            continue;
        }
#endif


        //
        // Do any preprocessing that is required
        //

        status = Arbiter->PreprocessEntry(Arbiter,&state);

        if (!NT_SUCCESS(status)) {
            goto cleanup;;
        }

        Arbiter->AddAllocation(Arbiter, &state);

    }

    //
    // Everything went OK so make this our allocated range
    //

    RtlFreeRangeList(Arbiter->Allocation);
    temp = Arbiter->Allocation;
    Arbiter->Allocation = Arbiter->PossibleAllocation;
    Arbiter->PossibleAllocation = temp;

    return STATUS_SUCCESS;

cleanup:

    RtlFreeRangeList(Arbiter->PossibleAllocation);
    return status;

}


NTSTATUS
ArbArbiterHandler(
    IN PVOID Context,
    IN ARBITER_ACTION Action,
    IN OUT PARBITER_PARAMETERS Params
    )

/*++

Routine Description:

    This provides the default entry point to an arbiter.

Parameters:

    Context - The context provided in the interface where this function was
        called from.  This is converted to an ARBITER_INSTANCE using the
        ARBITER_CONTEXT_TO_INSTANCE macro which should be defined.

    Action - The action the arbiter should perform.

    Params - The parameters for the action.

Return Value:

    Status code that indicates whether or not the function was successful.

Note:

    The routines which implement each action are determined from the dispatch
    table in the arbiter instance.

--*/

{

    NTSTATUS status;
    PARBITER_INSTANCE arbiter = Context;

    PAGED_CODE();
    ASSERT(Context);
    ASSERT(Action >= 0 && Action <= ArbiterActionBootAllocation);
    ASSERT(arbiter->Signature == ARBITER_INSTANCE_SIGNATURE);

    //
    // Acquire the state lock
    //

    ArbAcquireArbiterLock(arbiter);

    //
    // Announce ourselves
    //

    ARB_PRINT(2,
                ("%s %S\n",
                ArbpActionStrings[Action],
                arbiter->Name
                ));

    //
    // Check the transaction flag
    //

    if (Action == ArbiterActionTestAllocation
    ||  Action == ArbiterActionRetestAllocation
    ||  Action == ArbiterActionBootAllocation) {

        ASSERT(!arbiter->TransactionInProgress);

    } else if (Action == ArbiterActionCommitAllocation
           ||  Action == ArbiterActionRollbackAllocation) {

        ASSERT(arbiter->TransactionInProgress);
    }

#if ARB_DBG

replay:

#endif

    //
    // Do the appropriate thing
    //

    switch (Action) {

    case ArbiterActionTestAllocation:

        //
        // NTRAID #95564-2000/02/31-andrewth
        // Until we support rebalance we don't deal with AllocateFrom
        //

        ASSERT(Params->Parameters.TestAllocation.AllocateFromCount == 0);
        ASSERT(Params->Parameters.TestAllocation.AllocateFrom == NULL);

        status = arbiter->TestAllocation(
                     arbiter,
                     Params->Parameters.TestAllocation.ArbitrationList
                     );
        break;

    case ArbiterActionRetestAllocation:

        ASSERT(Params->Parameters.TestAllocation.AllocateFromCount == 0);
        ASSERT(Params->Parameters.TestAllocation.AllocateFrom == NULL);

        status = arbiter->RetestAllocation(
                     arbiter,
                     Params->Parameters.TestAllocation.ArbitrationList
                     );
        break;

    case ArbiterActionCommitAllocation:

        status = arbiter->CommitAllocation(arbiter);

        break;

    case ArbiterActionRollbackAllocation:

        status = arbiter->RollbackAllocation(arbiter);

        break;

    case ArbiterActionBootAllocation:

        status = arbiter->BootAllocation(
                    arbiter,
                    Params->Parameters.BootAllocation.ArbitrationList
                    );
        break;

    case ArbiterActionQueryConflict:

        status = arbiter->QueryConflict(
                    arbiter,
                    Params->Parameters.QueryConflict.PhysicalDeviceObject,
                    Params->Parameters.QueryConflict.ConflictingResource,
                    Params->Parameters.QueryConflict.ConflictCount,
                    Params->Parameters.QueryConflict.Conflicts
                    );
        break;

    case ArbiterActionQueryArbitrate:
    case ArbiterActionQueryAllocatedResources:
    case ArbiterActionWriteReservedResources:
    case ArbiterActionAddReserved:

        status = STATUS_NOT_IMPLEMENTED;
        break;

    default:
        status = STATUS_INVALID_PARAMETER;
        break;
    }

#if ARB_DBG

    //
    // Check if we failed and want to stop or replay on errors
    //

    if (!NT_SUCCESS(status)) {

        ARB_PRINT(1,
                 ("*** %s for %S FAILED status = %08x\n",
                  ArbpActionStrings[Action],
                  arbiter->Name,
                  status
                 ));

        if (ArbStopOnError) {
            DbgBreakPoint();
        }

        if (ArbReplayOnError) {
            goto replay;
        }
    }

#endif // ARB_DBG

    if (NT_SUCCESS(status)) {

        if (Action == ArbiterActionTestAllocation
        ||  Action == ArbiterActionRetestAllocation) {

            arbiter->TransactionInProgress = TRUE;

        } else if (Action == ArbiterActionCommitAllocation
               ||  Action == ArbiterActionRollbackAllocation) {

            arbiter->TransactionInProgress = FALSE;
        }
    }

    ArbReleaseArbiterLock(arbiter);

    return status;

}

NTSTATUS
ArbBuildAssignmentOrdering(
    IN OUT PARBITER_INSTANCE Arbiter,
    IN PWSTR AllocationOrderName,
    IN PWSTR ReservedResourcesName,
    IN PARBITER_TRANSLATE_ALLOCATION_ORDER Translate OPTIONAL
    )

/*++

Routine Description:

    This is called as part of arbiter initialization and extracts the allocation
    ordering and reserved information from the registry and combines them into
    an ordering list.  The reserved ranges are put in Arbiter->ReservedList
    and the initial ordering in Arbiter->OrderingList.

Parameters:

    Arbiter - The instance data of the arbiter to be initialized.

    AllocationOrderName - The name of the key under HKLM\System\
        CurrentControlSet\Control\Arbiters\AllocationOrder the ordering
        information should be taken from.

    ReservedResourcesName - The name of the key under HKLM\System\
        CurrentControlSet\Control\Arbiters\ReservedResources the reserved ranges
        information should be taken from.

    Translate - A function to be called for each range that will perform system
        dependant translations required for this system.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    NTSTATUS status;
    HANDLE arbitersHandle = NULL, tempHandle = NULL;
    UNICODE_STRING unicodeString;
    PKEY_VALUE_FULL_INFORMATION info = NULL;
    ULONG dummy;
    PIO_RESOURCE_LIST resourceList;
    PIO_RESOURCE_DESCRIPTOR current;
    ULONGLONG start, end;
    OBJECT_ATTRIBUTES attributes;
    IO_RESOURCE_DESCRIPTOR translated;

    PAGED_CODE();

    ArbAcquireArbiterLock(Arbiter);

    //
    // If we are reinitializing the orderings free the old ones
    //

    ArbFreeOrderingList(&Arbiter->OrderingList);
    ArbFreeOrderingList(&Arbiter->ReservedList);

    //
    // Initialize the orderings
    //

    status = ArbInitializeOrderingList(&Arbiter->OrderingList);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    status = ArbInitializeOrderingList(&Arbiter->ReservedList);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Open HKLM\System\CurrentControlSet\Control\Arbiters
    //

    ArbpWstrToUnicodeString(&unicodeString, PATH_ARBITERS);
    InitializeObjectAttributes(&attributes,
                               &unicodeString,
                               OBJ_CASE_INSENSITIVE,
                               NULL,
                               (PSECURITY_DESCRIPTOR) NULL
                               );


    status = ZwOpenKey(&arbitersHandle,
                       KEY_READ,
                       &attributes
                       );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Open AllocationOrder
    //

    ArbpWstrToUnicodeString(&unicodeString, KEY_ALLOCATIONORDER);
    InitializeObjectAttributes(&attributes,
                               &unicodeString,
                               OBJ_CASE_INSENSITIVE,
                               arbitersHandle,
                               (PSECURITY_DESCRIPTOR) NULL
                               );


    status = ZwOpenKey(&tempHandle,
                       KEY_READ,
                       &attributes
                       );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Extract the value the user asked for
    //

    status = ArbpGetRegistryValue(tempHandle,
                                  AllocationOrderName,
                                  &info
                                  );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Check if the value we retrieved was a string and if so then it was a
    // short cut to a value of that name - open it.
    //

    if (info->Type == REG_SZ) {

        PKEY_VALUE_FULL_INFORMATION tempInfo;
        PWSTR shortcut = (PWSTR) FULL_INFO_DATA(info);

        //
        // Check its NUL terminated
        // 
        
        if (shortcut[(info->DataLength/sizeof(WCHAR))-1] != UNICODE_NULL) {
            status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }
                
        status = ArbpGetRegistryValue(tempHandle,
                                      shortcut,
                                      &tempInfo
                                      );

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        ExFreePool(info);
        info = tempInfo;

    }

    ZwClose(tempHandle);

    //
    // We only support one level of short cuts so this should be a
    // REG_RESOURCE_REQUIREMENTS_LIST
    //

    if (info->Type != REG_RESOURCE_REQUIREMENTS_LIST) {
        status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Extract the resource list
    //

    ASSERT(((PIO_RESOURCE_REQUIREMENTS_LIST) FULL_INFO_DATA(info))
             ->AlternativeLists == 1);

    resourceList = (PIO_RESOURCE_LIST) &((PIO_RESOURCE_REQUIREMENTS_LIST)
                       FULL_INFO_DATA(info))->List[0];

    //
    // Convert the resource list into an ordering list
    //

    FOR_ALL_IN_ARRAY(resourceList->Descriptors,
                     resourceList->Count,
                     current) {

        //
        // Perform any translation that is necessary on the resources
        //

        if (ARGUMENT_PRESENT(Translate)) {

            status = (Translate)(&translated, current);

            if (!NT_SUCCESS(status)) {
                goto cleanup;
            }
        } else {
            translated = *current;
        }

        if (translated.Type == Arbiter->ResourceType) {

            status = Arbiter->UnpackRequirement(&translated,
                                                &start,
                                                &end,
                                                &dummy,  //length
                                                &dummy   //alignment
                                               );

            if (!NT_SUCCESS(status)) {
                goto cleanup;
            }

            status = ArbAddOrdering(&Arbiter->OrderingList,
                                    start,
                                    end
                                    );

            if (!NT_SUCCESS(status)) {
                    goto cleanup;
            }
        }
    }

    //
    // We're finished with info...
    //

    ExFreePool(info);
    info = NULL;

    //
    // Open ReservedResources
    //

    ArbpWstrToUnicodeString(&unicodeString, KEY_RESERVEDRESOURCES);
    InitializeObjectAttributes(&attributes,
                               &unicodeString,
                               OBJ_CASE_INSENSITIVE,
                               arbitersHandle,
                               (PSECURITY_DESCRIPTOR) NULL
                               );


    status = ZwCreateKey(&tempHandle,
                         KEY_READ,
                         &attributes,
                         0,
                         (PUNICODE_STRING) NULL,
                         REG_OPTION_NON_VOLATILE,
                         NULL
                         );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Extract the arbiter's reserved resources
    //

    status = ArbpGetRegistryValue(tempHandle,
                                  ReservedResourcesName,
                                  &info
                                  );

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Check if the value we retrieved was a string and if so then it was a
    // short cut to a value of that name - open it.
    //

    if (info->Type == REG_SZ) {

        PKEY_VALUE_FULL_INFORMATION tempInfo;
        PWSTR shortcut = (PWSTR) FULL_INFO_DATA(info);

        //
        // Check its NUL terminated
        // 
        
        if (shortcut[(info->DataLength/sizeof(WCHAR))-1] != UNICODE_NULL) {
            status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }
                
        status = ArbpGetRegistryValue(tempHandle,
                                      shortcut,
                                      &tempInfo
                                      );

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        ExFreePool(info);
        info = tempInfo;

    }

    ZwClose(tempHandle);

    if (NT_SUCCESS(status)) {

        ASSERT(((PIO_RESOURCE_REQUIREMENTS_LIST) FULL_INFO_DATA(info))
             ->AlternativeLists == 1);

        resourceList = (PIO_RESOURCE_LIST) &((PIO_RESOURCE_REQUIREMENTS_LIST)
                       FULL_INFO_DATA(info))->List[0];

        //
        // Apply the reserved ranges to the ordering
        //

        FOR_ALL_IN_ARRAY(resourceList->Descriptors,
                         resourceList->Count,
                         current) {

            //
            // Perform any translation that is necessary on the resources
            //

            if (ARGUMENT_PRESENT(Translate)) {

                status = (Translate)(&translated, current);

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }
            } else {
                translated = *current;
            }

            if (translated.Type == Arbiter->ResourceType) {

                status = Arbiter->UnpackRequirement(&translated,
                                                    &start,
                                                    &end,
                                                    &dummy,  //length
                                                    &dummy   //alignment
                                                   );

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }

                //
                // Add the reserved range to the reserved ordering
                //

                status = ArbAddOrdering(&Arbiter->ReservedList, start, end);

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }

                //
                // Prune the reserved range from the current ordering
                //

                status = ArbPruneOrdering(&Arbiter->OrderingList, start, end);

                if (!NT_SUCCESS(status)) {
                    goto cleanup;
                }

            }
        }

        ExFreePool(info);
    }

    //
    // All done!
    //

    ZwClose(arbitersHandle);

#if ARB_DBG

    {
        PARBITER_ORDERING current;

        FOR_ALL_IN_ARRAY(Arbiter->OrderingList.Orderings,
                         Arbiter->OrderingList.Count,
                         current) {
            ARB_PRINT(2,
                        ("Ordering: 0x%I64x-0x%I64x\n",
                         current->Start,
                         current->End
                        ));
        }

        ARB_PRINT(2, ("\n"));

        FOR_ALL_IN_ARRAY(Arbiter->ReservedList.Orderings,
                     Arbiter->ReservedList.Count,
                     current) {
            ARB_PRINT(2,
                        ("Reserved: 0x%I64x-0x%I64x\n",
                         current->Start,
                         current->End
                        ));
        }

    }

#endif

    ArbReleaseArbiterLock(Arbiter);

    return STATUS_SUCCESS;

cleanup:

    if (arbitersHandle) {
        ZwClose(arbitersHandle);
    }

    if (tempHandle) {
        ZwClose(tempHandle);
    }

    if (info) {
        ExFreePool(info);
    }

    if (Arbiter->OrderingList.Orderings) {
        ExFreePool(Arbiter->OrderingList.Orderings);
        Arbiter->OrderingList.Count = 0;
        Arbiter->OrderingList.Maximum = 0;
    }

    if (Arbiter->ReservedList.Orderings) {
        ExFreePool(Arbiter->ReservedList.Orderings);
        Arbiter->ReservedList.Count = 0;
        Arbiter->ReservedList.Maximum = 0;
    }

    ArbReleaseArbiterLock(Arbiter);

    return status;
}

BOOLEAN
ArbFindSuitableRange(
    PARBITER_INSTANCE Arbiter,
    PARBITER_ALLOCATION_STATE State
    )

/*++

Routine Description:

    This routine is called from AllocateEntry once we have decided where we want
    to allocate from.  It tries to find a free range that matches the
    requirements in State while restricting its possible solutions to the range
    State->CurrentMinimum to State->CurrentMaximum.  On success State->Start and
    State->End represent this range.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    TRUE if we found a range, FALSE otherwise.

--*/

{

    NTSTATUS status;
    ULONG findRangeFlags = 0;

    PAGED_CODE();

    ASSERT(State->CurrentAlternative);

    //
    // Catch the case where we backtrack and advance past the maximum
    //

    if (State->CurrentMinimum > State->CurrentMaximum) {
        return FALSE;
    }

    //
    // If we are asking for zero ports then trivially succeed with the minimum
    // value and remember that backtracking this is a recipe for infinite loops
    //

    if (State->CurrentAlternative->Length == 0) {
        State->End = State->Start = State->CurrentMinimum;
        return TRUE;
    }

    //
    // For legacy requests from IoAssignResources (directly or by way of
    // HalAssignSlotResources) or IoReportResourceUsage we consider preallocated
    // resources to be available for backward compatibility reasons.
    //
    // If we are allocating a devices boot config then we consider all other
    // boot configs to be available.
    //

    if (State->Entry->RequestSource == ArbiterRequestLegacyReported
        || State->Entry->RequestSource == ArbiterRequestLegacyAssigned) {

        State->RangeAvailableAttributes |= ARBITER_RANGE_BOOT_ALLOCATED;
    }

    //
    // Check if null conflicts are OK...
    //

    if (State->Flags & ARBITER_STATE_FLAG_NULL_CONFLICT_OK) {
        findRangeFlags |= RTL_RANGE_LIST_NULL_CONFLICT_OK;
    }

    //
    // ...or we are shareable...
    //

    if (State->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED) {
        findRangeFlags |= RTL_RANGE_LIST_SHARED_OK;
    }

    //
    // Select the first free alternative from the current alternative
    //

    status = RtlFindRange(
                 Arbiter->PossibleAllocation,
                 State->CurrentMinimum,
                 State->CurrentMaximum,
                 State->CurrentAlternative->Length,
                 State->CurrentAlternative->Alignment,
                 findRangeFlags,
                 State->RangeAvailableAttributes,
                 Arbiter->ConflictCallbackContext,
                 Arbiter->ConflictCallback,
                 &State->Start
                 );


    if (NT_SUCCESS(status)) {

        //
        // We found a suitable range
        //
        State->End = State->Start + State->CurrentAlternative->Length - 1;

        return TRUE;

    } else {

        if (ArbShareDriverExclusive(Arbiter, State) == FALSE) {

            //
            // We couldn't find any range so check if we will allow this conflict
            // - if so don'd fail!
            //

            return Arbiter->OverrideConflict(Arbiter, State);
        }
        return TRUE;
    }
}

VOID
ArbAddAllocation(
     IN PARBITER_INSTANCE Arbiter,
     IN PARBITER_ALLOCATION_STATE State
     )

/*++

Routine Description:

    This routine is called from AllocateEntry once we have found a possible
    solution (State->Start - State->End).  It adds the ranges that will not be
    available if we commit to this solution to Arbiter->PossibleAllocation.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    None.

--*/

{

    NTSTATUS status;

    PAGED_CODE();

    status = RtlAddRange(
                 Arbiter->PossibleAllocation,
                 State->Start,
                 State->End,
                 State->RangeAttributes,
                 RTL_RANGE_LIST_ADD_IF_CONFLICT +
                    (State->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED
                        ? RTL_RANGE_LIST_ADD_SHARED : 0),
                 NULL,
                 State->Entry->PhysicalDeviceObject
                 );

    ASSERT(NT_SUCCESS(status));

}


VOID
ArbBacktrackAllocation(
     IN PARBITER_INSTANCE Arbiter,
     IN PARBITER_ALLOCATION_STATE State
     )

/*++

Routine Description:

    This routine is called from AllocateEntry if the possible solution
    (State->Start - State->End) does not allow us to allocate resources to
    the rest of the devices being considered.  It deletes the ranges that were
    added to Arbiter->PossibleAllocation by AddAllocation.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    None.

--*/


{
    NTSTATUS status;

    PAGED_CODE();

    //
    // We couldn't allocate for the rest of the ranges then
    // backtrack
    //

    status = RtlDeleteRange(
                 Arbiter->PossibleAllocation,
                 State->Start,
                 State->End,
                 State->Entry->PhysicalDeviceObject
                 );

    ASSERT(NT_SUCCESS(status));

    ARB_PRINT(2,
                ("\t\tBacktracking on 0x%I64x-0x%I64x for %p\n",
                State->Start,
                State->End,
                State->Entry->PhysicalDeviceObject
                ));

}


NTSTATUS
ArbPreprocessEntry(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    )
/*++

Routine Description:

    This routine is called from AllocateEntry to allow preprocessing of
    entries

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    None.

--*/
{

    PAGED_CODE();

    UNREFERENCED_PARAMETER (Arbiter);
    UNREFERENCED_PARAMETER (State);

    return STATUS_SUCCESS;
}

NTSTATUS
ArbAllocateEntry(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    )
/*++

Routine Description:

    This is the core arbitration routine and is called from TestAllocation
    to allocate resources for all of the entries in the allocation stack.
    It calls off to various helper routines (described above) to perform this
    task.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    None.

--*/



{

    NTSTATUS status;
    PARBITER_ALLOCATION_STATE currentState = State;
    BOOLEAN backtracking = FALSE;

    PAGED_CODE();

    //
    // Have we reached the end of the list?  If so then we have a working
    // allocation.
    //

tryAllocation:

    while(currentState >= State && currentState->Entry != NULL) {

        //
        // Do any preprocessing that is required
        //

        status = Arbiter->PreprocessEntry(Arbiter,currentState);

        if (!NT_SUCCESS(status)) {
            return status;
        }

        //
        // If we need to backtrack do so!
        //

        if (backtracking) {

            ULONGLONG possibleCurrentMinimum;

            backtracking = FALSE;

            //
            // Clear the CurrentAlternative of the *next* alternative - this will
            // cause the priorities to be recalculated next time through so we
            // will attempt to explore the search space again
            //
            // The currentState+1 is guaranteed to be safe because the only way
            // we can get here is from where we currentState-- below.
            //

            (currentState + 1)->CurrentAlternative = NULL;

            //
            // We can't backtrack length 0 requests because there is nothing to
            // backtrack so we would get stuck in an inifinite loop...
            //

            if (currentState->CurrentAlternative->Length == 0) {
                goto failAllocation;
            }

            //
            // Backtrack
            //

            Arbiter->BacktrackAllocation(Arbiter, currentState);

            //
            // Reduce allocation window to not include the range we backtracked
            // and check that that doesn't underflow the minimum or wrap
            //

            possibleCurrentMinimum = currentState->Start - 1;

            if (possibleCurrentMinimum > currentState->CurrentMinimum // wrapped
            ||  possibleCurrentMinimum < currentState->CurrentAlternative->Minimum) {

                //
                // We have run out space in this alternative move on to the next
                //

                goto continueWithNextAllocationRange;

            } else {

                currentState->CurrentMaximum = possibleCurrentMinimum;

                //
                // Get back into arbitrating at the right point
                //

                goto continueWithNextSuitableRange;
            }
        }

        //
        // Try to allocate for this entry
        //

continueWithNextAllocationRange:

        while (Arbiter->GetNextAllocationRange(Arbiter, currentState)) {

            ARB_INDENT(2, (ULONG)(currentState - State));

            ARB_PRINT(2,
                        ("Testing 0x%I64x-0x%I64x %s\n",
                        currentState->CurrentMinimum,
                        currentState->CurrentMaximum,
                        currentState->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED ?
                            "shared" : "non-shared"
                        ));

continueWithNextSuitableRange:

            while (Arbiter->FindSuitableRange(Arbiter, currentState)) {

                //
                // We found a possible solution
                //

                ARB_INDENT(2, (ULONG)(currentState - State));

                if (currentState->CurrentAlternative->Length != 0) {

                    ARB_PRINT(2,
                        ("Possible solution for %p = 0x%I64x-0x%I64x, %s\n",
                        currentState->Entry->PhysicalDeviceObject,
                        currentState->Start,
                        currentState->End,
                        currentState->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED ?
                            "shared" : "non-shared"
                        ));

                    //
                    // Update the arbiter with the possible allocation
                    //

                    Arbiter->AddAllocation(Arbiter, currentState);

                } else {

                    ARB_PRINT(2,
                        ("Zero length solution solution for %p = 0x%I64x-0x%I64x, %s\n",
                        currentState->Entry->PhysicalDeviceObject,
                        currentState->Start,
                        currentState->End,
                        currentState->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_SHARED ?
                            "shared" : "non-shared"
                        ));

                    //
                    // Set the result in the arbiter appropriatley so that we
                    // don't try and translate this zero requirement - it won't!
                    //

                    currentState->Entry->Result = ArbiterResultNullRequest;
                }

                //
                // Move on to the next entry
                //

                currentState++;
                goto tryAllocation;
            }
        }

failAllocation:

        //
        // We couldn't allocate for this device
        //

        if (currentState == State) {

            //
            // We are at the top of the allocation stack to we can't backtrack -
            // *** GAME OVER ***
            //

            return STATUS_UNSUCCESSFUL;

        } else {

            //
            // Backtrack and try again
            //

            ARB_INDENT(2, (ULONG)(currentState - State));

            ARB_PRINT(2,
                ("Allocation failed for %p - backtracking\n",
                currentState->Entry->PhysicalDeviceObject
                ));

            backtracking = TRUE;

            //
            // Pop the last state off the stack and try a different path
            //

            currentState--;
            goto tryAllocation;
        }
    }

    //
    // We have successfully allocated for all ranges so fill in the allocation
    //

    currentState = State;

    while (currentState->Entry != NULL) {

        status = Arbiter->PackResource(
                    currentState->CurrentAlternative->Descriptor,
                    currentState->Start,
                    currentState->Entry->Assignment
                    );

        ASSERT(NT_SUCCESS(status));

        //
        // Remember the alternative we chose from so we can retrieve it during retest
        //

        currentState->Entry->SelectedAlternative
            = currentState->CurrentAlternative->Descriptor;

        ARB_PRINT(2,
                    ("Assigned - 0x%I64x-0x%I64x\n",
                    currentState->Start,
                    currentState->End
                    ));

        currentState++;
    }

    return STATUS_SUCCESS;

}

BOOLEAN
ArbGetNextAllocationRange(
    IN PARBITER_INSTANCE Arbiter,
    IN OUT PARBITER_ALLOCATION_STATE State
    )

/*++

Routine Description:

    This routine attempts to find the next range where allocation should be
    tried.  It updates State->CurrentMinimum, State->CurrentMaximum and
    State->CurrentAlternative to indicate this range.

Arguments:

    Arbiter - The instance data of the arbiter

    State - The state of the current arbitration

Return Value:

    TRUE if a range to attemp allocation in is found, FALSE otherwise

--*/

{

    PARBITER_ALTERNATIVE current, lowestAlternative;
    ULONGLONG min, max;
    PARBITER_ORDERING ordering;


    for (;;) {

        if (State->CurrentAlternative) {

            //
            // Update the priority of the alternative we selected last time
            //

            ArbpUpdatePriority(Arbiter, State->CurrentAlternative);

        } else {

            //
            // This is the first time we are looking at this alternative or a
            // backtrack - either way we need to update all the priorities
            //

            FOR_ALL_IN_ARRAY(State->Alternatives,
                             State->AlternativeCount,
                             current) {

                current->Priority = ARBITER_PRIORITY_NULL;
                ArbpUpdatePriority(Arbiter, current);

            }
        }

        //
        // Find the lowest priority of the alternatives
        //

        lowestAlternative = State->Alternatives;

        FOR_ALL_IN_ARRAY(State->Alternatives + 1,
                         State->AlternativeCount - 1,
                         current) {

            if (current->Priority < lowestAlternative->Priority) {
                lowestAlternative = current;
            }
        }

        ARB_INDENT(2, (ULONG)(State - Arbiter->AllocationStack));

        //
        // Check if we have run out of allocation ranges
        //

        if (lowestAlternative->Priority == ARBITER_PRIORITY_EXHAUSTED) {

            if (lowestAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_FIXED) {

                ARB_PRINT(2,("Fixed alternative exhausted\n"));

            } else {

                ARB_PRINT(2,("Alternative exhausted\n"));
            }

            return FALSE;

        } else {

            ARB_PRINT(2,(
                "LowestAlternative: [%i] 0x%I64x-0x%I64x L=0x%08x A=0x%08x\n",
                lowestAlternative->Priority,
                lowestAlternative->Minimum,
                lowestAlternative->Maximum,
                lowestAlternative->Length,
                lowestAlternative->Alignment
                ));

        }

        //
        // Check if we are now allowing reserved ranges
        //

        if (lowestAlternative->Priority == ARBITER_PRIORITY_RESERVED
        ||  lowestAlternative->Priority == ARBITER_PRIORITY_PREFERRED_RESERVED) {

            //
            // Set min and max to be the Minimum and Maximum that the descriptor
            // specified ignoring any reservations or orderings - this is our
            // last chance
            //

            min = lowestAlternative->Minimum;
            max = lowestAlternative->Maximum;

            ARB_INDENT(2, (ULONG)(State - Arbiter->AllocationStack));

            ARB_PRINT(2,("Allowing reserved ranges\n"));

        } else {

            ASSERT(ORDERING_INDEX_FROM_PRIORITY(lowestAlternative->Priority) <
                     Arbiter->OrderingList.Count);

            //
            // Locate the ordering we match
            //

            ordering = &Arbiter->OrderingList.Orderings
                [ORDERING_INDEX_FROM_PRIORITY(lowestAlternative->Priority)];

            //
            // Make sure they overlap and are big enough - this is just paranoia
            //

            ASSERT(INTERSECT(lowestAlternative->Minimum,
                             lowestAlternative->Maximum,
                             ordering->Start,
                             ordering->End)
                && INTERSECT_SIZE(lowestAlternative->Minimum,
                                  lowestAlternative->Maximum,
                                  ordering->Start,
                                  ordering->End) >= lowestAlternative->Length);

            //
            // Calculate the allocation range
            //

            min = __max(lowestAlternative->Minimum, ordering->Start);

            max = __min(lowestAlternative->Maximum, ordering->End);

        }

        //
        // If this is a length 0 requirement then succeed now and avoid much
        // trauma later
        //

        if (lowestAlternative->Length == 0) {

            min = lowestAlternative->Minimum;
            max = lowestAlternative->Maximum;

        } else {

            //
            // Trim range to match alignment.
            //

            min += lowestAlternative->Alignment - 1;
            min -= min % lowestAlternative->Alignment;

            if ((lowestAlternative->Length - 1) > (max - min)) {

                ARB_INDENT(3, (ULONG)(State - Arbiter->AllocationStack));
                ARB_PRINT(3, ("Range cannot be aligned ... Skipping\n"));

                //
                // Set CurrentAlternative so we will update the priority of this
                // alternative
                //

                State->CurrentAlternative = lowestAlternative;
                continue;
            }

            max -= lowestAlternative->Length - 1;
            max -= max % lowestAlternative->Alignment;
            max += lowestAlternative->Length - 1;

        }

        //
        // Check if we handed back the same range last time, for the same
        // alternative, if so try to find another range
        //

        if (min == State->CurrentMinimum
        && max == State->CurrentMaximum
        && State->CurrentAlternative == lowestAlternative) {

            ARB_INDENT(2, (ULONG)(State - Arbiter->AllocationStack));

            ARB_PRINT(2,
                  ("Skipping identical allocation range\n"
            ));

            continue;
        }

        State->CurrentMinimum = min;
        State->CurrentMaximum = max;
        State->CurrentAlternative = lowestAlternative;

        ARB_INDENT(2, (ULONG)(State - Arbiter->AllocationStack));
        ARB_PRINT(1, ("AllocationRange: 0x%I64x-0x%I64x\n", min, max));

        return TRUE;

    }
}

NTSTATUS
ArbpGetRegistryValue(
    IN HANDLE KeyHandle,
    IN PWSTR  ValueName,
    OUT PKEY_VALUE_FULL_INFORMATION *Information
    )

/*++

Routine Description:

    This routine is invoked to retrieve the data for a registry key's value.
    This is done by querying the value of the key with a zero-length buffer
    to determine the size of the value, and then allocating a buffer and
    actually querying the value into the buffer.

    It is the responsibility of the caller to free the buffer.

Arguments:

    KeyHandle - Supplies the key handle whose value is to be queried

    ValueName - Supplies the null-terminated Unicode name of the value.

    Information - Returns a pointer to the allocated data buffer.

Return Value:

    The function value is the final status of the query operation.

Note:

    The same as IopGetRegistryValue - it allows us to share the arbiter
    code with pci.sys

--*/

{
    UNICODE_STRING unicodeString;
    NTSTATUS status;
    PKEY_VALUE_FULL_INFORMATION infoBuffer;
    ULONG keyValueLength;

    PAGED_CODE();

    RtlInitUnicodeString( &unicodeString, ValueName );

    //
    // Figure out how big the data value is so that a buffer of the
    // appropriate size can be allocated.
    //

    status = ZwQueryValueKey( KeyHandle,
                              &unicodeString,
                              KeyValueFullInformationAlign64,
                              (PVOID) NULL,
                              0,
                              &keyValueLength );
    if (status != STATUS_BUFFER_OVERFLOW &&
        status != STATUS_BUFFER_TOO_SMALL) {
        return status;
    }

    //
    // Allocate a buffer large enough to contain the entire key data value.
    //

    infoBuffer = ExAllocatePoolWithTag( PagedPool,
                                        keyValueLength,
                                        ARBITER_MISC_TAG
                                        );

    if (!infoBuffer) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // Query the data for the key value.
    //

    status = ZwQueryValueKey( KeyHandle,
                              &unicodeString,
                              KeyValueFullInformationAlign64,
                              infoBuffer,
                              keyValueLength,
                              &keyValueLength );
    if (!NT_SUCCESS( status )) {
        ExFreePool( infoBuffer );
        return status;
    }

    //
    // Everything worked, so simply return the address of the allocated
    // buffer to the caller, who is now responsible for freeing it.
    //

    *Information = infoBuffer;
    return STATUS_SUCCESS;
}


#define ARBITER_ORDERING_LIST_INITIAL_SIZE      16

NTSTATUS
ArbInitializeOrderingList(
    IN OUT PARBITER_ORDERING_LIST List
    )

/*++

Routine Description:

    This routine inititialize an arbiter ordering list.

Arguments:

    List - The list to be initialized

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    PAGED_CODE();

    ASSERT(List);

    List->Orderings = ExAllocatePoolWithTag(PagedPool,
                                            ARBITER_ORDERING_LIST_INITIAL_SIZE *
                                                sizeof(ARBITER_ORDERING),
                                            ARBITER_ORDERING_LIST_TAG
                                            );

    if (!List->Orderings) {
        List->Maximum = 0;
        List->Count = 0;
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    List->Count = 0;
    List->Maximum = ARBITER_ORDERING_LIST_INITIAL_SIZE;

    return STATUS_SUCCESS;
}

NTSTATUS
ArbCopyOrderingList(
    OUT PARBITER_ORDERING_LIST Destination,
    IN PARBITER_ORDERING_LIST Source
    )

/*++

Routine Description:

    This routine copies an arbiter ordering list.

Arguments:

    Destination - An uninitialized arbiter ordering list where the data
        should be copied from

    Source - Arbiter ordering list to be copied
Return Value:

    Status code that indicates whether or not the function was successful.

--*/


{

    PAGED_CODE()

    ASSERT(Source->Count <= Source->Maximum);
    ASSERT(Source->Maximum > 0);

    Destination->Orderings =
        ExAllocatePoolWithTag(PagedPool,
                              Source->Maximum * sizeof(ARBITER_ORDERING),
                              ARBITER_ORDERING_LIST_TAG
                              );

    if (Destination->Orderings == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    Destination->Count = Source->Count;
    Destination->Maximum = Source->Maximum;

    if (Source->Count > 0) {

        RtlCopyMemory(Destination->Orderings,
                      Source->Orderings,
                      Source->Count * sizeof(ARBITER_ORDERING)
                      );
    }

    return STATUS_SUCCESS;
}


NTSTATUS
ArbAddOrdering(
    OUT PARBITER_ORDERING_LIST List,
    IN ULONGLONG Start,
    IN ULONGLONG End
    )

/*++

Routine Description:

    This routine adds the range Start-End to the end of the ordering list.  No
    checking for overlaps or pruning is done (see ArbpPruneOrdering)

Arguments:

    OrderingList - The list where the range should be added.

    Start - The start of the range to be added.

    End - The end of the range to be added.

Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{

    PAGED_CODE()

    //
    // Validate parameters
    //

    if (End < Start) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Check if the buffer is full
    //

    if (List->Count == List->Maximum) {

        PARBITER_ORDERING temp;

        //
        // Out of space - grow the buffer
        //

        temp = ExAllocatePoolWithTag(PagedPool,
                              (List->Count + ARBITER_ORDERING_GROW_SIZE) *
                                  sizeof(ARBITER_ORDERING),
                              ARBITER_ORDERING_LIST_TAG
                              );

        if (!temp) {
            return STATUS_INSUFFICIENT_RESOURCES;
        }

        //
        // If we had any orderings copy them
        //

        if (List->Orderings) {

            RtlCopyMemory(temp,
                          List->Orderings,
                          List->Count * sizeof(ARBITER_ORDERING)
                          );

            ExFreePool(List->Orderings);
        }

        List->Maximum += ARBITER_ORDERING_GROW_SIZE;
        List->Orderings = temp;

    }

    //
    // Add the entry to the list
    //

    List->Orderings[List->Count].Start = Start;
    List->Orderings[List->Count].End = End;
    List->Count++;

    ASSERT(List->Count <= List->Maximum);

    return STATUS_SUCCESS;
}

NTSTATUS
ArbPruneOrdering(
    IN OUT PARBITER_ORDERING_LIST OrderingList,
    IN ULONGLONG Start,
    IN ULONGLONG End
    )

/*++

Routine Description:

    This routine removes the range Start-End from all entries in the ordering
    list, splitting ranges into two or deleting them as necessary.

Arguments:

    OrderingList - The list to be pruned.

    Start - The start of the range to be deleted.

    End - The end of the range to be deleted.

Return Value:

    Status code that indicates whether or not the function was successful.

Note:

    In the comments below *** represents the range Start - End and --- the range
    current->Start - current->End.

--*/

{

    NTSTATUS status;
    PARBITER_ORDERING current, currentInsert, newOrdering = NULL, temp = NULL;
    USHORT count;

    PAGED_CODE()

    ASSERT(OrderingList);
    ASSERT(OrderingList->Orderings);

    //
    // Validate parameters
    //

    if (End < Start) {
        status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Allocate a buffer big enough for all eventualities
    //

    newOrdering = ExAllocatePoolWithTag(PagedPool,
                                        (OrderingList->Count * 2 + 1) *
                                            sizeof(ARBITER_ORDERING),
                                        ARBITER_ORDERING_LIST_TAG
                                        );

    if (!newOrdering) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    currentInsert = newOrdering;

    //
    // Do we have a current ordering?
    //

    if (OrderingList->Count > 0) {

        //
        // Iterate through the current ordering and prune accordingly
        //

        FOR_ALL_IN_ARRAY(OrderingList->Orderings, OrderingList->Count, current) {

            if (End < current->Start || Start > current->End) {

                //
                // ****      or      ****
                //      ----    ----
                //
                // We don't overlap so copy the range unchanged
                //

                *currentInsert++ = *current;

            } else if (Start > current->Start) {

                if (End < current->End) {

                    //
                    //   ****
                    // --------
                    //
                    // Split the range into two
                    //

                    currentInsert->Start = End + 1;
                    currentInsert->End = current->End;
                    currentInsert++;

                    currentInsert->Start = current->Start;
                    currentInsert->End = Start - 1;
                    currentInsert++;


                } else {

                    //
                    //       **** or     ****
                    // --------      --------
                    //
                    // Prune the end of the range
                    //

                    ASSERT(End >= current->End);

                    currentInsert->Start = current->Start;
                    currentInsert->End = Start - 1;
                    currentInsert++;
                }
            } else {

                ASSERT(Start <= current->Start);

                if (End < current->End) {

                    //
                    // ****       or ****
                    //   --------    --------
                    //
                    // Prune the start of the range
                    //

                    currentInsert->Start = End + 1;
                    currentInsert->End = current->End;
                    currentInsert++;

                } else {

                    ASSERT(End >= current->End);

                    //
                    // ******** or ********
                    //   ----      --------
                    //
                    // Don't copy the range (ie. Delete it)
                    //

                }
            }
        }
    }


    ASSERT(currentInsert - newOrdering >= 0);

    count = (USHORT)(currentInsert - newOrdering);

    //
    // Check if we have any orderings left
    //

    if (count > 0) {

        if (count > OrderingList->Maximum) {

            //
            // There isn't enough space so allocate a new buffer
            //

            temp =
                ExAllocatePoolWithTag(PagedPool,
                                      count * sizeof(ARBITER_ORDERING),
                                      ARBITER_ORDERING_LIST_TAG
                                      );

            if (!temp) {
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto cleanup;
            }

            if (OrderingList->Orderings) {
                ExFreePool(OrderingList->Orderings);
            }

            OrderingList->Orderings = temp;
            OrderingList->Maximum = count;

        }


        //
        // Copy the new ordering
        //

        RtlCopyMemory(OrderingList->Orderings,
                      newOrdering,
                      count * sizeof(ARBITER_ORDERING)
                      );
    }

    //
    // Free our temporary buffer
    //

    ExFreePool(newOrdering);

    OrderingList->Count = count;

    return STATUS_SUCCESS;

cleanup:

    if (newOrdering) {
        ExFreePool(newOrdering);
    }

    if (temp) {
        ExFreePool(temp);
    }

    return status;

}
VOID
ArbFreeOrderingList(
    IN PARBITER_ORDERING_LIST List
    )
/*++

Routine Description:

    Frees storage associated with an ordering list.
    Reverses ArbInitializeOrderingList.

Arguments:

    List - The list to be fred

Return Value:

    None
--*/

{
    PAGED_CODE();

    if (List->Orderings) {
        ASSERT(List->Maximum);
        ExFreePool(List->Orderings);
    }

    List->Count = 0;
    List->Maximum = 0;
    List->Orderings = NULL;
}



BOOLEAN
ArbOverrideConflict(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    )

/*++

Routine Description:

    This is the default implementation of override conflict which

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    TRUE if the conflict is allowable, false otherwise

--*/

{

    PRTL_RANGE current;
    RTL_RANGE_LIST_ITERATOR iterator;
    BOOLEAN ok = FALSE;

    PAGED_CODE();

    if (!(State->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_FIXED)) {
        return FALSE;
    }

    FOR_ALL_RANGES(Arbiter->PossibleAllocation, &iterator, current) {

        //
        // Only test the overlapping ones
        //

        if (INTERSECT(current->Start, current->End, State->CurrentMinimum, State->CurrentMaximum)) {


            //
            // Check if we should ignore the range because of its attributes
            //

            if (current->Attributes & State->RangeAvailableAttributes) {

                //
                // We DON'T set ok to true because we are just ignoring the range,
                // as RtlFindRange would have and thus it can't be the cause of
                // RtlFindRange failing, so ignoring it can't fix the conflict.
                //

                continue;
            }

            //
            // Check if we are conflicting with ourselves AND the conflicting range
            // is a fixed requirement
            //

            if (current->Owner == State->Entry->PhysicalDeviceObject
            && State->CurrentAlternative->Flags & ARBITER_ALTERNATIVE_FLAG_FIXED) {

                State->Start=State->CurrentMinimum;
                State->End=State->CurrentMaximum;

                ok = TRUE;
                continue;
            }

            //
            // The conflict is still valid
            //

            return FALSE;
        }
    }
    return ok;
}

VOID
ArbpUpdatePriority(
    PARBITER_INSTANCE Arbiter,
    PARBITER_ALTERNATIVE Alternative
    )

/*++

Routine Description:

    This routine updates the priority of an arbiter alternative.

Arguments:

    Arbiter - The arbiter we are operating on

    Alternative - The alternative currently being considered

Return Value:

    Status code that indicates whether or not the function was successful.

Note:

    The priorities are a LONG values organised as:

    <------Preferred priorities-----> <-----Ordinary Priorities----->

    MINLONG--------------------------0-----------------------------MAXLONG
                                     ^                               ^ ^ ^
                                     |                               | | |
                                    NULL            PREFERRED_RESERVED | |
                                                                RESERVED |
                                                                     EXHAUSTED

    An ordinary priority is calculated the (index + 1) of the next ordering it
    intersects with (and has enough space for an allocation).

    A preferred priority is the ordinary priority * - 1

    In this way by examining each of the alternatives in priority order (lowest
    first) we achieve the desired allocation order of:

    (1) Preferred alternative with non-reserved resources
    (2) Alternatives with non-reserved resources
    (3) Preferred reserved resources
    (4) Reserved Resources

    MAXLONG the worst priority indicates that there are no more allocation ranges
    left.

--*/

{

    PARBITER_ORDERING ordering;
    BOOLEAN preferred;
    LONG priority;

    PAGED_CODE();

    priority = Alternative->Priority;

    //
    // If we have already tried the reserved resources then we are out of luck!
    //

    if (priority == ARBITER_PRIORITY_RESERVED
    ||  priority == ARBITER_PRIORITY_PREFERRED_RESERVED) {

        Alternative->Priority = ARBITER_PRIORITY_EXHAUSTED;
        return;
    }

    //
    // Check if this is a preferred value - we treat them specially
    //

    preferred = Alternative->Descriptor->Option & IO_RESOURCE_PREFERRED;

    //
    // If priority is NULL then we haven't started calculating one so we
    // should start the search from the initial ordering
    //

    if (priority == ARBITER_PRIORITY_NULL) {

        ordering = Arbiter->OrderingList.Orderings;

    } else {

        //
        // If we are a fixed resource then there is no point
        // in trying to find another range - it will be the
        // same and thus still conflict.  Mark this alternative as
        // exhausted
        //

        if (Alternative->Flags & ARBITER_ALTERNATIVE_FLAG_FIXED) {

            Alternative->Priority = ARBITER_PRIORITY_EXHAUSTED;

            return;
        }

        ASSERT(ORDERING_INDEX_FROM_PRIORITY(Alternative->Priority) <
                 Arbiter->OrderingList.Count);

        ordering = &Arbiter->OrderingList.Orderings
            [ORDERING_INDEX_FROM_PRIORITY(Alternative->Priority) + 1];

    }

    //
    // Now find the first member of the assignent ordering for this arbiter
    // where we have an overlap big enough
    //

    FOR_REST_IN_ARRAY(Arbiter->OrderingList.Orderings,
                      Arbiter->OrderingList.Count,
                      ordering) {

        //
        // Is the ordering applicable?
        //

        if (INTERSECT(Alternative->Minimum, Alternative->Maximum,
                      ordering->Start, ordering->End)
        && INTERSECT_SIZE(Alternative->Minimum, Alternative->Maximum,
                          ordering->Start,ordering->End) >= Alternative->Length) {

            //
            // This is out guy, calculate his priority
            //

            Alternative->Priority = (LONG)(ordering - Arbiter->OrderingList.Orderings + 1);

            //
            // Preferred priorities are -ve
            //

            if (preferred) {
                Alternative->Priority *= -1;
            }

            return;
        }
    }

    //
    // We have runout of non-reserved resources so try the reserved ones
    //

    if (preferred) {
        Alternative->Priority = ARBITER_PRIORITY_PREFERRED_RESERVED;
    } else {
        Alternative->Priority = ARBITER_PRIORITY_RESERVED;
    }

}

NTSTATUS
ArbAddReserved(
    IN PARBITER_INSTANCE Arbiter,
    IN PIO_RESOURCE_DESCRIPTOR Requirement      OPTIONAL,
    IN PCM_PARTIAL_RESOURCE_DESCRIPTOR Resource OPTIONAL
    )
{
    PAGED_CODE();

    UNREFERENCED_PARAMETER (Arbiter);
    UNREFERENCED_PARAMETER (Requirement);
    UNREFERENCED_PARAMETER (Resource);

    return STATUS_NOT_SUPPORTED;
}

BOOLEAN
ArbpQueryConflictCallback(
    IN PVOID Context,
    IN PRTL_RANGE Range
    )

/*++

Routine Description:

    This call back is called from FindSuitableRange (via RtlFindRange) when we
    encounter an conflicting range.

Arguments:

    Context - Actually a PRTL_RANGE * where we store the range we conflicted
        with.

    Range - The range we conflict with.

Return Value:

    FALSE

--*/

{
    PRTL_RANGE *conflictingRange = (PRTL_RANGE*)Context;

    PAGED_CODE();

    ARB_PRINT(2,("Possible conflict: (%p) 0x%I64x-0x%I64x Owner: %p",
                   Range,
                   Range->Start,
                   Range->End,
                   Range->Owner
                ));

    //
    // Remember the conflicting range
    //

    *conflictingRange = Range;

    //
    // We want to allow the rest of FindSuitableRange to determine if this really
    // is a conflict.
    //

    return FALSE;
}


NTSTATUS
ArbQueryConflict(
    IN PARBITER_INSTANCE Arbiter,
    IN PDEVICE_OBJECT PhysicalDeviceObject,
    IN PIO_RESOURCE_DESCRIPTOR ConflictingResource,
    OUT PULONG ConflictCount,
    OUT PARBITER_CONFLICT_INFO *Conflicts
    )

/*++

Routine Description:

    This routine examines the arbiter state and returns a list of devices that
    conflict with ConflictingResource

Arguments:

    Arbiter - The arbiter to examine conflicts in

    ConflictingResource - The resource we want to know the conflicts with

    ConflictCount - On success contains the number of conflicts detected

    ConflictList - On success contains a pointer to an array of conflicting
        devices

Return Value:

    Status code that indicates whether or not the function was successful.

--*/
{
    //
    // NTRAID #98568 - 2000/03/31 - andrewth
    // ArbQueryConflict needs to be redesigned
    //
    
    NTSTATUS status;
    RTL_RANGE_LIST backupAllocation;
    BOOLEAN backedUp = FALSE;
    ARBITER_LIST_ENTRY entry;
    ARBITER_ALLOCATION_STATE state;
    ARBITER_ALTERNATIVE alternative;
    ULONG count = 0, size = 10;
    PRTL_RANGE conflictingRange;
    PARBITER_CONFLICT_INFO conflictInfo = NULL;
    PVOID savedContext;
    PRTL_CONFLICT_RANGE_CALLBACK savedCallback;
    ULONG sz;

    PAGED_CODE();

    ASSERT(PhysicalDeviceObject);
    ASSERT(ConflictingResource);
    ASSERT(ConflictCount);
    ASSERT(Conflicts);
    //
    // Set up our conflict callback
    //
    savedCallback = Arbiter->ConflictCallback;
    savedContext = Arbiter->ConflictCallbackContext;
    Arbiter->ConflictCallback = ArbpQueryConflictCallback;
    Arbiter->ConflictCallbackContext = &conflictingRange;

    //
    // If there is a transaction in progress then we need to backup the
    // the possible allocation so we can restore it when we are done.
    //

    if (Arbiter->TransactionInProgress) {

        RtlInitializeRangeList(&backupAllocation);

        status = RtlCopyRangeList(&backupAllocation, Arbiter->PossibleAllocation);

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        RtlFreeRangeList(Arbiter->PossibleAllocation);

        backedUp = TRUE;
    }

    //
    // Fake up the allocation state
    //


    status = RtlCopyRangeList(Arbiter->PossibleAllocation, Arbiter->Allocation);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    status = ArbpBuildAlternative(Arbiter, ConflictingResource, &alternative);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    RtlZeroMemory(&state, sizeof(ARBITER_ALLOCATION_STATE));

    state.Start = alternative.Minimum;
    state.End = alternative.Maximum;
    state.CurrentMinimum = state.Start;
    state.CurrentMaximum = state.End;
    state.CurrentAlternative = &alternative;
    state.AlternativeCount = 1;
    state.Alternatives = &alternative;
    state.Flags = ARBITER_STATE_FLAG_CONFLICT;
    state.Entry = &entry;

    RtlZeroMemory(&entry, sizeof(ARBITER_LIST_ENTRY));
    entry.RequestSource = ArbiterRequestPnpEnumerated;
    entry.PhysicalDeviceObject = PhysicalDeviceObject;
    
    if (!NT_SUCCESS(IoGetDeviceProperty(PhysicalDeviceObject,DevicePropertyLegacyBusType,sizeof(entry.InterfaceType),&entry.InterfaceType,&sz))) {
        entry.InterfaceType = Isa; // not what I want to do! However this has the right effect - good enough for conflict detection
    }
    if (!NT_SUCCESS(IoGetDeviceProperty(PhysicalDeviceObject,DevicePropertyBusNumber,sizeof(entry.InterfaceType),&entry.BusNumber,&sz))) {
        entry.BusNumber = 0; // not what I want to do! However this has the right effect - good enough for conflict detection
    }

    //
    // Initialize the return buffers
    //

    conflictInfo = ExAllocatePoolWithTag(PagedPool,
                                         size * sizeof(ARBITER_CONFLICT_INFO),
                                         ARBITER_CONFLICT_INFO_TAG
                                         );

    if (!conflictInfo) {
        status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Perform any necessary preprocessing
    //

    status = Arbiter->PreprocessEntry(Arbiter, &state);

    if (!NT_SUCCESS(status)) {
        goto cleanup;
    }

    //
    // Remove self from list of possible allocations
    // status may be set, but can be ignored
    // we take ourself out of test completely, so that a user can
    // pick new values in context of rest of the world
    // if we decide to use RtlDeleteRange instead
    // make sure we do it for every alias formed in PreprocessEntry
    //

    status = RtlDeleteOwnersRanges(Arbiter->PossibleAllocation,
                            state.Entry->PhysicalDeviceObject
                            );

    //
    // Keep trying to find a suitable range and each time we fail remember why.
    //
    conflictingRange = NULL;
    state.CurrentMinimum = state.Start;
    state.CurrentMaximum = state.End;

    while (!Arbiter->FindSuitableRange(Arbiter, &state)) {

        if (count == size) {

            //
            // We need to resize the return buffer
            //

            PARBITER_CONFLICT_INFO temp = conflictInfo;

            size += 5;

            conflictInfo =
                ExAllocatePoolWithTag(PagedPool,
                                      size * sizeof(ARBITER_CONFLICT_INFO),
                                      ARBITER_CONFLICT_INFO_TAG
                                      );

            if (!conflictInfo) {
                status = STATUS_INSUFFICIENT_RESOURCES;
                conflictInfo = temp;
                goto cleanup;
            }

            RtlCopyMemory(conflictInfo,
                          temp,
                          count * sizeof(ARBITER_CONFLICT_INFO)
                          );

            ExFreePool(temp);

        }

        if (conflictingRange != NULL) {
            conflictInfo[count].OwningObject = conflictingRange->Owner;
            conflictInfo[count].Start = conflictingRange->Start;
            conflictInfo[count].End = conflictingRange->End;
            count++;

            //
            // Delete the range we conflicted with so we don't loop forever
            //
#if 0
            status = RtlDeleteRange(Arbiter->PossibleAllocation,
                                    conflictingRange->Start,
                                    conflictingRange->End,
                                    conflictingRange->Owner
                                    );
#endif
            status = RtlDeleteOwnersRanges(Arbiter->PossibleAllocation,
                                    conflictingRange->Owner
                                    );

            if (!NT_SUCCESS(status)) {
                goto cleanup;
            }

        } else {
            //
            // someone isn't playing by the rules (such as ACPI!)
            //
            ARB_PRINT(0,("Conflict detected - but someone hasn't set conflicting info\n"));

            conflictInfo[count].OwningObject = NULL;
            conflictInfo[count].Start = (ULONGLONG)0;
            conflictInfo[count].End = (ULONGLONG)(-1);
            count++;

            //
            // we daren't continue at risk of looping forever
            //
            break;
        }

        //
        // reset for next round
        //
        conflictingRange = NULL;
        state.CurrentMinimum = state.Start;
        state.CurrentMaximum = state.End;
    }

    RtlFreeRangeList(Arbiter->PossibleAllocation);

    if (Arbiter->TransactionInProgress) {

        status = RtlCopyRangeList(Arbiter->PossibleAllocation, &backupAllocation);

        if (!NT_SUCCESS(status)) {
            goto cleanup;
        }

        RtlFreeRangeList(&backupAllocation);
    }

    Arbiter->ConflictCallback = savedCallback;
    Arbiter->ConflictCallbackContext = savedContext;

    *Conflicts = conflictInfo;
    *ConflictCount = count;

    return STATUS_SUCCESS;

cleanup:

    if (conflictInfo) {
        ExFreePool(conflictInfo);
    }

    RtlFreeRangeList(Arbiter->PossibleAllocation);

    if (Arbiter->TransactionInProgress && backedUp) {
        status = RtlCopyRangeList(Arbiter->PossibleAllocation, &backupAllocation);
        RtlFreeRangeList(&backupAllocation);
    }

    Arbiter->ConflictCallback = savedCallback;
    Arbiter->ConflictCallbackContext = savedContext;

    *Conflicts = NULL;

    return status;
}


NTSTATUS
ArbStartArbiter(
    IN PARBITER_INSTANCE Arbiter,
    IN PCM_RESOURCE_LIST StartResources
    )

/*++

Routine Description:

    This function is called by the driver that implements the arbiter once
    it has been started and knowns what resources it can allocate to its
    children.

    It will eventually initialize the range lists correctly but for
    now it is just an overloadable place holder as that work is done elsewhere.

Parameters:

    Arbiter - The instance of the arbiter being called.


Return Value:

    Status code that indicates whether or not the function was successful.

--*/

{
    PAGED_CODE();

    UNREFERENCED_PARAMETER (Arbiter);
    UNREFERENCED_PARAMETER (StartResources);

    return STATUS_SUCCESS;
}

BOOLEAN
ArbShareDriverExclusive(
    IN PARBITER_INSTANCE Arbiter,
    IN PARBITER_ALLOCATION_STATE State
    )

/*++

Routine Description:

    This routine implements support for CmResourceShareDriverExclusive disposition
    by overriding conflict if the owner and request share at least one common
    driver.

Arguments:

    Arbiter - The instance data of the arbiter who was called.

    State - The state of the current arbitration.

Return Value:

    TRUE if the conflict is allowable, false otherwise

--*/

{

    PRTL_RANGE current;
    RTL_RANGE_LIST_ITERATOR iterator;
    PDEVICE_OBJECT owner, other;
    ULONG enumeratorNameLength;
    WCHAR enumeratorName[sizeof(REGSTR_KEY_ROOTENUM) / sizeof(WCHAR)];
    NTSTATUS status;
    BOOLEAN isRootEnumerated;

    PAGED_CODE();

    owner = NULL;
    isRootEnumerated = FALSE;
    status = IoGetDeviceProperty(
        State->Entry->PhysicalDeviceObject, 
        DevicePropertyEnumeratorName,
        sizeof(enumeratorName),
        enumeratorName,
        &enumeratorNameLength);
    if (NT_SUCCESS(status)) {

        if (_wcsicmp(enumeratorName, REGSTR_KEY_ROOTENUM) == 0) {

            isRootEnumerated = TRUE;
        }                
    }
    FOR_ALL_RANGES(Arbiter->PossibleAllocation, &iterator, current) {
        //
        // Only test the overlapping ones
        //
        if (INTERSECT(current->Start, current->End, State->CurrentMinimum, State->CurrentMaximum)) {
            //
            // Check if we should ignore the range because of its attributes
            //
            if (current->Attributes & State->RangeAvailableAttributes) {
                //
                // We DON'T set ok to true because we are just ignoring the range,
                // as RtlFindRange would have and thus it can't be the cause of
                // RtlFindRange failing, so ignoring it can't fix the conflict.
                //
                continue;
            }
            if (State->CurrentAlternative->Descriptor->ShareDisposition != CmResourceShareDriverExclusive &&
                !(current->Attributes & ARBITER_RANGE_SHARE_DRIVER_EXCLUSIVE)) {

                continue;
            }
            if (!current->Owner) {

                continue;
            }
            //
            // Special case ROOT enumerated devices.
            //
            if (isRootEnumerated) {

                status = IoGetDeviceProperty(
                    current->Owner, 
                    DevicePropertyEnumeratorName,
                    sizeof(enumeratorName),
                    enumeratorName,
                    &enumeratorNameLength);
                if (NT_SUCCESS(status)) {

                    if (_wcsicmp(enumeratorName, REGSTR_KEY_ROOTENUM) != 0) {

                        isRootEnumerated = FALSE;
                    }                
                }
            }
            //
            // If both devices are ROOT enumerated, override the conflict.
            //
            if (isRootEnumerated) {

                if (owner != NULL) {
                    ARB_PRINT(2,
                            ("Overriding conflict on IRQ %04x for driver %wZ\n",
                            (ULONG)State->Start,
                            &owner->DriverObject->DriverName
                            ));
                }
                State->Start=State->CurrentMinimum;
                State->End=State->CurrentMaximum;
                if (State->CurrentAlternative->Descriptor->ShareDisposition == CmResourceShareDriverExclusive) {

                    State->RangeAttributes |= ARBITER_RANGE_SHARE_DRIVER_EXCLUSIVE;
                }
                return TRUE;
            }
            //
            // Check if there is a common driver in the two stacks ignoring the 
            // one for the PDO.
            //
            owner = ((PDEVICE_OBJECT)(current->Owner))->AttachedDevice;
            while (owner) {

                other = (PDEVICE_OBJECT)(State->Entry->PhysicalDeviceObject)->AttachedDevice;
                while (other) {

                    if (owner->DriverObject == other->DriverObject) {

                        ARB_PRINT(2,
                                    ("Overriding conflict on IRQ %04x for driver %wZ\n",
                                    (ULONG)State->Start,
                                    &owner->DriverObject->DriverName
                                    ));
                        State->Start=State->CurrentMinimum;
                        State->End=State->CurrentMaximum;
                        if (State->CurrentAlternative->Descriptor->ShareDisposition == CmResourceShareDriverExclusive) {

                            State->RangeAttributes |= ARBITER_RANGE_SHARE_DRIVER_EXCLUSIVE;
                        }
                        return TRUE;
                    }
                    other = other->AttachedDevice;
                }
                owner = owner->AttachedDevice;
            }
        }
    }
    //
    // The conflict is still valid
    //
    return FALSE;
}

#if DBG
VOID
ArbpIndent(
    IN ULONG Count
    )
{
    UCHAR spaces[80];

    ASSERT(Count <= 80);

    RtlFillMemory(spaces, Count, '*');

    spaces[Count] = 0;

    DbgPrint("%s", spaces);

}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\cachedat.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    cachedat.c

Abstract:

    This module implements the Memory Management based cache management
    routines for the common Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  Global SharedCacheMap lists and resource to synchronize access to it.
//
//

// extern KSPIN_LOCK CcMasterSpinLock;
LIST_ENTRY CcCleanSharedCacheMapList;
SHARED_CACHE_MAP_LIST_CURSOR CcDirtySharedCacheMapList;
SHARED_CACHE_MAP_LIST_CURSOR CcLazyWriterCursor;

//
//  Worker thread structures:
//
//      A spinlock to synchronize all three lists.
//      A count of the number of worker threads Cc will use
//      A count of the number of worker threads Cc in use
//      A listhead for preinitialized executive work items for Cc use.
//      A listhead for an express queue of WORK_QUEUE_ENTRYs
//      A listhead for a regular queue of WORK_QUEUE_ENTRYs
//      A listhead for a post-tick queue of WORK_QUEUE_ENTRYs
//
//      A flag indicating if we are throttling the queue to a single thread
//

// extern KSPIN_LOCK CcWorkQueueSpinLock;
ULONG CcNumberWorkerThreads = 0;
ULONG CcNumberActiveWorkerThreads = 0;
LIST_ENTRY CcIdleWorkerThreadList;
LIST_ENTRY CcExpressWorkQueue;
LIST_ENTRY CcRegularWorkQueue;
LIST_ENTRY CcPostTickWorkQueue;

BOOLEAN CcQueueThrottle = FALSE;

//
//  Store the current idle delay and target time to clean all.  We must calculate
//  the idle delay in terms of clock ticks for the lazy writer timeout.
//

ULONG CcIdleDelayTick;
LARGE_INTEGER CcNoDelay;
LARGE_INTEGER CcFirstDelay = {(ULONG)-(3*LAZY_WRITER_IDLE_DELAY), -1};
LARGE_INTEGER CcIdleDelay = {(ULONG)-LAZY_WRITER_IDLE_DELAY, -1};
LARGE_INTEGER CcCollisionDelay = {(ULONG)-LAZY_WRITER_COLLISION_DELAY, -1};
LARGE_INTEGER CcTargetCleanDelay = {(ULONG)-(LONG)(LAZY_WRITER_IDLE_DELAY * (LAZY_WRITER_MAX_AGE_TARGET + 1)), -1};

//
//  Spinlock for controlling access to Vacb and related global structures,
//  and a counter indicating how many Vcbs are active.
//

// extern KSPIN_LOCK CcVacbSpinLock;
ULONG_PTR CcNumberVacbs;

//
//  Pointer to the global Vacb vector.
//

PVACB CcVacbs;
PVACB CcBeyondVacbs;
LIST_ENTRY CcVacbLru;
LIST_ENTRY CcVacbFreeList;
ULONG CcMaxVacbLevelsSeen = 1;
ULONG CcVacbLevelEntries = 0;
PVACB *CcVacbLevelFreeList = NULL;
ULONG CcVacbLevelWithBcbsEntries = 0;
PVACB *CcVacbLevelWithBcbsFreeList = NULL;

//
//  Deferred write list and respective Thresholds
//

extern KSPIN_LOCK CcDeferredWriteSpinLock;
LIST_ENTRY CcDeferredWrites;
ULONG CcDirtyPageThreshold;
ULONG CcDirtyPageTarget;
ULONG CcPagesYetToWrite;
ULONG CcPagesWrittenLastTime = 0;
ULONG CcDirtyPagesLastScan = 0;
ULONG CcAvailablePagesThreshold = 100;
ULONG CcTotalDirtyPages = 0;

//
//  Captured system size
//

MM_SYSTEMSIZE CcCapturedSystemSize;

//
//  Number of outstanding aggresive zeroers in the system.  Used
//  to throttle the activity.
//

LONG CcAggressiveZeroCount;
LONG CcAggressiveZeroThreshold;

//
//  Tuning options du Jour
//

ULONG CcTune = 0;

//
//  Global structure controlling lazy writer algorithms
//

LAZY_WRITER LazyWriter;

GENERAL_LOOKASIDE CcTwilightLookasideList;

#ifdef CCDBG

LONG CcDebugTraceLevel = 0;
LONG CcDebugTraceIndent = 0;

#ifdef CCDBG_LOCK
extern KSPIN_LOCK CcDebugTraceLock;
#endif //  def CCDBG_LOCK

#endif

//
//  Global list of pinned Bcbs which may be examined for debug purposes
//

#if DBG

ULONG CcBcbCount;
LIST_ENTRY CcBcbList;

#endif

//
//  Throw away miss counter.
//

ULONG CcThrowAway;

//
//  Performance Counters
//

ULONG CcFastReadNoWait;
ULONG CcFastReadWait;
ULONG CcFastReadResourceMiss;
ULONG CcFastReadNotPossible;

ULONG CcFastMdlReadNoWait;
ULONG CcFastMdlReadWait;
ULONG CcFastMdlReadResourceMiss;
ULONG CcFastMdlReadNotPossible;

ULONG CcMapDataNoWait;
ULONG CcMapDataWait;
ULONG CcMapDataNoWaitMiss;
ULONG CcMapDataWaitMiss;

ULONG CcPinMappedDataCount;

ULONG CcPinReadNoWait;
ULONG CcPinReadWait;
ULONG CcPinReadNoWaitMiss;
ULONG CcPinReadWaitMiss;

ULONG CcCopyReadNoWait;
ULONG CcCopyReadWait;
ULONG CcCopyReadNoWaitMiss;
ULONG CcCopyReadWaitMiss;

ULONG CcMdlReadNoWait;
ULONG CcMdlReadWait;
ULONG CcMdlReadNoWaitMiss;
ULONG CcMdlReadWaitMiss;

ULONG CcReadAheadIos;

ULONG CcLazyWriteHotSpots;
ULONG CcLazyWriteIos;
ULONG CcLazyWritePages;
ULONG CcDataFlushes;
ULONG CcDataPages;

ULONG CcLostDelayedWrites;

PULONG CcMissCounter = &CcThrowAway;
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\arb\debug.c ===
/*++

Copyright (c) 1997  Microsoft Corporation

Module Name:

    debug.c

Abstract:

    This module contains support routines for the Pnp resource arbiters.

Author:

    Andrew Thornton (andrewth) 19-June-1998


Environment:

    Kernel mode

Revision History:

--*/

#include "arbp.h"


//
// Debugging support
//

//
// Debug print level:
//    -1 = no messages
//     0 = vital messages only
//     1 = call trace
//     2 = verbose messages
//

//Present in retail builds
LONG ArbDebugLevel = -1;

#if ARB_DBG

//
// ArbStopOnError works just like a debug level variable except
// instead of controlling whether a message is printed, it controls
// whether we breakpoint on an error or not.  Likewise ArbReplayOnError
// controls if we replay fail arbitrations so we can debug them.
//

ULONG ArbStopOnError;
ULONG ArbReplayOnError;

const CHAR* ArbpActionStrings[] = {
    "ArbiterActionTestAllocation",
    "ArbiterActionRetestAllocation",
    "ArbiterActionCommitAllocation",
    "ArbiterActionRollbackAllocation",
    "ArbiterActionQueryAllocatedResources",
    "ArbiterActionWriteReservedResources",
    "ArbiterActionQueryConflict",
    "ArbiterActionQueryArbitrate",
    "ArbiterActionAddReserved",
    "ArbiterActionBootAllocation"
};

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, ArbDumpArbiterRange)
#pragma alloc_text(PAGE, ArbDumpArbiterInstance)
#pragma alloc_text(PAGE, ArbDumpArbitrationList)
#endif

VOID
ArbDumpArbiterRange(
    LONG Level,
    PRTL_RANGE_LIST List,
    PCHAR RangeText
    )

/*++

Routine Description:

    This dumps the contents of a range list to the debugger.

Parameters:

    Level     - The debug level at or above which the data should be displayed.
    List      - The range list to be displayed.
    RangeText - Informative text to go with the display.

Return Value:

    None

--*/

{
    PRTL_RANGE current;
    RTL_RANGE_LIST_ITERATOR iterator;
    BOOLEAN headerDisplayed = FALSE;

    PAGED_CODE();

    FOR_ALL_RANGES(List, &iterator, current) {

        if (headerDisplayed == FALSE) {
            headerDisplayed = TRUE;
            ARB_PRINT(Level, ("  %s:\n", RangeText));
        }

        ARB_PRINT(Level,
                    ("    %I64x-%I64x %s%s O=0x%08x U=0x%08x\n",
                    current->Start,
                    current->End,
                    current->Flags & RTL_RANGE_SHARED ? "S" : " ",
                    current->Flags & RTL_RANGE_CONFLICT ? "C" : " ",
                    current->Owner,
                    current->UserData
                   ));
    }
    if (headerDisplayed == FALSE) {
        ARB_PRINT(Level, ("  %s: <None>\n", RangeText));
    }
}

VOID
ArbDumpArbiterInstance(
    LONG Level,
    PARBITER_INSTANCE Arbiter
    )

/*++

Routine Description:

    This dumps the state of the arbiter to the debugger.

Parameters:

    Level - The debug level at or above which the data should be displayed.

    Arbiter - The arbiter instance to display

Return Value:

    None

--*/

{

    PAGED_CODE();

    ARB_PRINT(Level,
                ("---%S Arbiter State---\n",
                Arbiter->Name
                ));

    ArbDumpArbiterRange(
        Level,
        Arbiter->Allocation,
        "Allocation"
        );

    ArbDumpArbiterRange(
        Level,
        Arbiter->PossibleAllocation,
        "PossibleAllocation"
        );
}

VOID
ArbDumpArbitrationList(
    LONG Level,
    PLIST_ENTRY ArbitrationList
    )

/*++

Routine Description:

    Display the contents of an arbitration list.  That is, the
    set of resources (possibilities) we are trying to get.

Parameters:

    Level           - The debug level at or above which the data
                      should be displayed.
    ArbitrationList - The arbitration list to be displayed.

Return Value:

    None

--*/

{
    PARBITER_LIST_ENTRY current;
    PIO_RESOURCE_DESCRIPTOR alternative;
    PDEVICE_OBJECT previousOwner = NULL;
    UCHAR andOr = ' ';

    PAGED_CODE();

    ARB_PRINT(Level, ("Arbitration List\n"));

    FOR_ALL_IN_LIST(ARBITER_LIST_ENTRY, ArbitrationList, current) {

        if (previousOwner != current->PhysicalDeviceObject) {

            previousOwner = current->PhysicalDeviceObject;

            ARB_PRINT(
                Level,
                ("  Owning object 0x%08x\n",
                current->PhysicalDeviceObject
                ));
            ARB_PRINT(
                Level,
                ("    Length  Alignment   Minimum Address - Maximum Address\n"
                ));

        }

        FOR_ALL_IN_ARRAY(current->Alternatives,
                         current->AlternativeCount,
                         alternative) {

            ARB_PRINT(
                Level,
                ("%c %8x   %8x  %08x%08x - %08x%08x  %s\n",
                andOr,
                alternative->u.Generic.Length,
                alternative->u.Generic.Alignment,
                alternative->u.Generic.MinimumAddress.HighPart,
                alternative->u.Generic.MinimumAddress.LowPart,
                alternative->u.Generic.MaximumAddress.HighPart,
                alternative->u.Generic.MaximumAddress.LowPart,
                alternative->Type == CmResourceTypeMemory ?
                  "Memory"
                : "Port"
                ));
            andOr = '|';
        }
        andOr = '&';
    }
}

#endif // ARB_DBG
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\cc.h ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    cc.h

Abstract:

    This module is a header file for the Memory Management based cache
    management routines for the common Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#ifndef _CCh_
#define _CCh_

#pragma warning(disable:4214)   // bit field types other than int
#pragma warning(disable:4201)   // nameless struct/union
#pragma warning(disable:4127)   // condition expression is constant
#pragma warning(disable:4115)   // named type definition in parentheses

#include <ntos.h>
#include <NtIoLogc.h>

#ifdef MEMPRINT
#include <memprint.h>
#endif

//
// Define macros to acquire and release cache manager locks.
//

#define CcAcquireMasterLock( OldIrql ) \
    *( OldIrql ) = KeAcquireQueuedSpinLock( LockQueueMasterLock )

#define CcReleaseMasterLock( OldIrql ) \
    KeReleaseQueuedSpinLock( LockQueueMasterLock, OldIrql )

#define CcAcquireMasterLockAtDpcLevel() \
    KeAcquireQueuedSpinLockAtDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueMasterLock] )

#define CcReleaseMasterLockFromDpcLevel() \
    KeReleaseQueuedSpinLockFromDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueMasterLock] )

#define CcAcquireVacbLock( OldIrql ) \
    *( OldIrql ) = KeAcquireQueuedSpinLock( LockQueueVacbLock )

#define CcReleaseVacbLock( OldIrql ) \
    KeReleaseQueuedSpinLock( LockQueueVacbLock, OldIrql )

#define CcAcquireVacbLockAtDpcLevel() \
    KeAcquireQueuedSpinLockAtDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueVacbLock] )

#define CcReleaseVacbLockFromDpcLevel() \
    KeReleaseQueuedSpinLockFromDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueVacbLock] )

#define CcAcquireWorkQueueLock( OldIrql ) \
    *( OldIrql ) = KeAcquireQueuedSpinLock( LockQueueWorkQueueLock )

#define CcReleaseWorkQueueLock( OldIrql ) \
    KeReleaseQueuedSpinLock( LockQueueWorkQueueLock, OldIrql )

#define CcAcquireWorkQueueLockAtDpcLevel() \
    KeAcquireQueuedSpinLockAtDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueWorkQueueLock] )

#define CcReleaseWorkQueueLockFromDpcLevel() \
    KeReleaseQueuedSpinLockFromDpcLevel( &KeGetCurrentPrcb()->LockQueue[LockQueueWorkQueueLock] )

//
//  This turns on the Bcb list debugging in a debug system.  Set value
//  to 0 to turn off.
//
//  ****    Note it must currently be turned off because the routines in
//          pinsup.c that manipulate this list need to be changed to do the
//          right thing for Obcbs.  Right now they get messed up by inserting Obcbs
//          (which may not be large enough among other things) into the global
//          list.  Ideally each place gets some code to insert the underlying
//          Bcbs into the list if they are not already there.
//

#if DBG
#define LIST_DBG 0
#endif

#include <FsRtl.h>

//
//  Peek at number of available pages.
//

extern PFN_NUMBER MmAvailablePages;

//
//  Define our node type codes.
//

#define CACHE_NTC_SHARED_CACHE_MAP       (0x2FF)
#define CACHE_NTC_PRIVATE_CACHE_MAP      (0x2FE)
#define CACHE_NTC_BCB                    (0x2FD)
#define CACHE_NTC_DEFERRED_WRITE         (0x2FC)
#define CACHE_NTC_MBCB                   (0x2FB)
#define CACHE_NTC_OBCB                   (0x2FA)
#define CACHE_NTC_MBCB_GRANDE            (0x2F9)

//
//  The following definitions are used to generate meaningful blue bugcheck
//  screens.  On a bugcheck the file system can output 4 ulongs of useful
//  information.  The first ulong will have encoded in it a source file id
//  (in the high word) and the line number of the bugcheck (in the low word).
//  The other values can be whatever the caller of the bugcheck routine deems
//  necessary.
//
//  Each individual file that calls bugcheck needs to have defined at the
//  start of the file a constant called BugCheckFileId with one of the
//  CACHE_BUG_CHECK_ values defined below and then use CcBugCheck to bugcheck
//  the system.
//

#define CACHE_BUG_CHECK_CACHEDAT           (0x00010000)
#define CACHE_BUG_CHECK_CACHESUB           (0x00020000)
#define CACHE_BUG_CHECK_COPYSUP            (0x00030000)
#define CACHE_BUG_CHECK_FSSUP              (0x00040000)
#define CACHE_BUG_CHECK_LAZYRITE           (0x00050000)
#define CACHE_BUG_CHECK_LOGSUP             (0x00060000)
#define CACHE_BUG_CHECK_MDLSUP             (0x00070000)
#define CACHE_BUG_CHECK_PINSUP             (0x00080000)
#define CACHE_BUG_CHECK_VACBSUP            (0x00090000)

#define CcBugCheck(A,B,C) { KeBugCheckEx(CACHE_MANAGER, BugCheckFileId | __LINE__, A, B, C ); }

//
//  Define maximum View Size (These constants are currently so chosen so
//  as to be exactly a page worth of PTEs.
//

#define DEFAULT_CREATE_MODULO            ((ULONG)(0x00100000))
#define DEFAULT_EXTEND_MODULO            ((ULONG)(0x00100000))

//
//  For non FO_RANDOM_ACCESS files, define how far we go before umapping
//  views.
//

#define SEQUENTIAL_MAP_LIMIT        ((ULONG)(0x00080000))

//
//  Define some constants to drive read ahead and write behind
//

//
//  Set max read ahead.  Even though some drivers, such as AT, break up transfers >= 128kb,
//  we need to permit enough readahead to satisfy plausible cached read operation while
//  preventing denial of service attacks.
//
//  This value used to be set to 64k.  When doing cached reads in larger units (128k), we
//  would never be bringing in enough data to keep the user from blocking. 8mb is
//  arbitrarily chosen to be greater than plausible RAID bandwidth and user operation size
//  by a factor of 3-4.
//

#define MAX_READ_AHEAD                   (8 * 1024 * 1024)

//
//  Set maximum write behind / lazy write (most drivers break up transfers >= 64kb)
//

#define MAX_WRITE_BEHIND                 (MM_MAXIMUM_DISK_IO_SIZE)

//
//  Set a throttle for charging a given write against the total number of dirty
//  pages in the system, for the purpose of seeing when we should invoke write
//  throttling.
//
//  This must be the same as the throttle used for seeing when we must flush
//  temporary files in the lazy writer.  On the back of the envelope, here
//  is why:
//
//      RDP = Regular File Dirty Pages
//      TDP = Temporary File Dirty Pages
//      CWT = Charged Write Throttle
//          -> the maximum we will charge a user with when we see if
//              he should be throttled
//      TWT = Temporary Write Throttle
//          -> if we can't write this many pages, we must write temp data
//      DPT = Dirty Page Threshold
//          -> the limit when write throttling kicks in
//
//      PTD = Pages To Dirty
//      CDP = Charged Dirty Pages
//
//      Now, CDP = Min( PTD, CWT).
//
//      Excluding other effects, we throttle when:
//          #0  (RDP + TDP) + CPD >= DPT
//
//      To write temporary data, we must cause:
//          #1  (RDP + TDP) + TWT >= DPT
//
//      To release the throttle, we must eventually cause:
//          #2  (RDP + TDP) + CDP < DPT
//
//      Now, imagine TDP >> RDP (perhaps RDP == 0) and CDP == CWT for a particular
//      throttled write.
//
//      If CWT > TWT, as we drive RDP to zero (we never defer writing regular
//      data except for hotspots or other very temporary conditions), it is clear
//      that we may never trigger the writing of temporary data (#1) but also
//      never release the throttle (#2).  Simply, we would be willing to charge
//      for more dirty pages than we would be willing to guarantee are available
//      to dirty.  Hence, potential deadlock.
//
//      CWT < TWT I leave aside for the moment.  This would mean we try not to
//      allow temporary data to accumulate to the point that writes throttle as
//      a result.  Perhaps this would even be better than CWT == TWT.
//
//  It is legitimate to ask if throttling temporary data writes should be relaxed
//  if we see a large amount of dirty temp data accumulate (and it would be very
//  easy to keep track of this).  I don't claim to know the best answer to this,
//  but for now the attempt to avoid temporary data writes at all costs still
//  fits the reasonable operation mix, and we will only penalize the outside
//  oddcase with a little more throttle/release.
//

#define WRITE_CHARGE_THRESHOLD          (64 * PAGE_SIZE)

//
//  Define constants to control zeroing of file data: one constant to control
//  how much data we will actually zero ahead in the cache, and another to
//  control what the maximum transfer size is that we will use to write zeros.
//

#define MAX_ZERO_TRANSFER               (PAGE_SIZE * 128)
#define MIN_ZERO_TRANSFER               (0x10000)
#define MAX_ZEROS_IN_CACHE              (0x10000)

//
//  Definitions for multi-level Vacb structure.  The primary definition is the
//  VACB_LEVEL_SHIFT.  In a multi-level Vacb structure, level in the tree of
//  pointers has 2 ** VACB_LEVEL_SHIFT pointers.
//
//  For test, this value may be set as low as 4 (no lower), a value of 10 corresponds
//  to a convenient block size of 4KB.  (If set to 2, CcExtendVacbArray will try to
//  "push" the Vacb array allocated within the SharedCacheMap, and later someone will
//  try to deallocate the middle of the SharedCacheMap.  At 3, the MBCB_BITMAP_BLOCK_SIZE
//  is larger than MBCB_BITMAP_BLOCK_SIZE)
//
//  There is a bit of a trick as we make the jump to the multilevel structure in that
//  we need a real fixed reference count.
//

#define VACB_LEVEL_SHIFT                  (7)

//
//  This is how many bytes of pointers are at each level.  This is the size for both
//  the Vacb array and (optional) Bcb listheads.  It does not include the reference
//  block.
//

#define VACB_LEVEL_BLOCK_SIZE             ((1 << VACB_LEVEL_SHIFT) * sizeof(PVOID))

//
//  This is the last index for a level.
//

#define VACB_LAST_INDEX_FOR_LEVEL         ((1 << VACB_LEVEL_SHIFT) - 1)

//
//  This is the size of file which can be handled in a single level.
//

#define VACB_SIZE_OF_FIRST_LEVEL         (1 << (VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT))

//
//  This is the maximum number of levels it takes to support 63-bits.  It is
//  used for routines that must remember a path.
//

#define VACB_NUMBER_OF_LEVELS            (((63 - VACB_OFFSET_SHIFT)/VACB_LEVEL_SHIFT) + 1)

//
//  Define the reference structure for multilevel Vacb trees.
//

typedef struct _VACB_LEVEL_REFERENCE {

    LONG Reference;
    LONG SpecialReference;

} VACB_LEVEL_REFERENCE, *PVACB_LEVEL_REFERENCE;

//
//  Define the size of a bitmap allocated for a bitmap range, in bytes.
//

#define MBCB_BITMAP_BLOCK_SIZE           (VACB_LEVEL_BLOCK_SIZE)

//
//  Define how many bytes of a file are covered by an Mbcb bitmap range,
//  at a bit for each page.
//

#define MBCB_BITMAP_RANGE                (MBCB_BITMAP_BLOCK_SIZE * 8 * PAGE_SIZE)

//
//  Define the initial size of the Mbcb bitmap that is self-contained in the Mbcb.
//

#define MBCB_BITMAP_INITIAL_SIZE         (2 * sizeof(BITMAP_RANGE))

//
//  Define constants controlling when the Bcb list is broken into a
//  pendaflex-style array of listheads, and how the correct listhead
//  is found.  Begin when file size exceeds 2MB, and cover 512KB per
//  listhead.  At 512KB per listhead, the BcbListArray is the same
//  size as the Vacb array, i.e., it doubles the size.
//
//  The code handling these Bcb lists in the Vacb package contains
//  assumptions that the size is the same as that of the Vacb pointers.
//  Future work could undo this, but until then the size and shift
//  below cannot change.  There really isn't a good reason to want to
//  anyway.
//
//  Note that by definition a flat vacb array cannot fail to find an
//  exact match when searching for the listhead - this is only a
//  complication of the sparse structure.
//


#define BEGIN_BCB_LIST_ARRAY             (0x200000)
#define SIZE_PER_BCB_LIST                (VACB_MAPPING_GRANULARITY * 2)
#define BCB_LIST_SHIFT                   (VACB_OFFSET_SHIFT + 1)

#define GetBcbListHead(SCM,OFF,FAILSUCC) (                                                         \
  (((SCM)->SectionSize.QuadPart > BEGIN_BCB_LIST_ARRAY) &&                                         \
   FlagOn((SCM)->Flags, MODIFIED_WRITE_DISABLED)) ?                                                \
   (((SCM)->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) ?                                     \
    CcGetBcbListHeadLargeOffset((SCM),(OFF),(FAILSUCC)) :                                          \
    (((OFF) >= (SCM)->SectionSize.QuadPart) ? &(SCM)->BcbList :                                    \
     ((PLIST_ENTRY)((SCM)->Vacbs) + (((SCM)->SectionSize.QuadPart + (OFF)) >> BCB_LIST_SHIFT)))) : \
   &(SCM)->BcbList                                                                                 \
)

//
//  Macros to lock/unlock a Vacb level as Bcbs are inserted/deleted
//

#define CcLockVacbLevel(SCM,OFF) {                                                               \
    if (((SCM)->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) &&                              \
        FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {                                \
    CcAdjustVacbLevelLockCount((SCM),(OFF), +1);}                                                \
}

#define CcUnlockVacbLevel(SCM,OFF) {                                                             \
    if (((SCM)->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) &&                              \
        FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {                                \
    CcAdjustVacbLevelLockCount((SCM),(OFF), -1);}                                                \
}

//
//  NOISE_BITS defines how many bits are masked off when testing for
//  sequential reads.  This allows the reader to skip up to 7 bytes
//  for alignment purposes, and we still consider the next read to be
//  sequential.  Starting and ending addresses are masked by this pattern
//  before comparison.
//

#define NOISE_BITS                       (0x7)

//
//  Define some constants to drive the Lazy Writer
//

#define LAZY_WRITER_IDLE_DELAY           ((LONG)(10000000))
#define LAZY_WRITER_COLLISION_DELAY      ((LONG)(1000000))

//
// the wait is in 100 nanosecond units to 10,000,000 = 1 second
//

#define NANO_FULL_SECOND ((LONGLONG)10000000)

//
//  The following target should best be a power of 2
//

#define LAZY_WRITER_MAX_AGE_TARGET       ((ULONG)(8))

//
//  Requeue information hint for the lazy writer.
//

#define CC_REQUEUE                       35422

//
//  The global Cache Manager debug level variable, its values are:
//
//      0x00000000      Always gets printed (used when about to bug check)
//
//      0x00000001      FsSup
//      0x00000002      CacheSub
//      0x00000004      CopySup
//      0x00000008      PinSup
//
//      0x00000010      MdlSup
//      0x00000020      LazyRite
//      0x00000040
//      0x00000080
//
//      0x00000100      Trace all Mm calls
//

#define mm (0x100)

//
//  Miscellaneous support macros.
//
//      ULONG
//      FlagOn (
//          IN ULONG Flags,
//          IN ULONG SingleFlag
//          );
//
//      BOOLEAN
//      BooleanFlagOn (
//          IN ULONG Flags,
//          IN ULONG SingleFlag
//          );
//
//      VOID
//      SetFlag (
//          IN ULONG Flags,
//          IN ULONG SingleFlag
//          );
//
//      VOID
//      ClearFlag (
//          IN ULONG Flags,
//          IN ULONG SingleFlag
//          );
//
//      ULONG
//      QuadAlign (
//          IN ULONG Pointer
//          );
//

#define FlagOn(F,SF) ( \
    (((F) & (SF)))     \
)

#define BooleanFlagOn(F,SF) (    \
    (BOOLEAN)(((F) & (SF)) != 0) \
)

#define SetFlag(F,SF) { \
    (F) |= (SF);        \
}

#define ClearFlag(F,SF) { \
    (F) &= ~(SF);         \
}

#define QuadAlign(P) (             \
    ((((P)) + 7) & (-8)) \
)

//
//  Turn on pseudo-asserts if CC_FREE_ASSERTS is defined.
//

#if (!DBG && defined( CC_FREE_ASSERTS ))
#undef ASSERT
#undef ASSERTMSG
#define ASSERT(exp)                                             \
    ((exp) ? TRUE :                                             \
             (DbgPrint( "%s:%d %s\n",__FILE__,__LINE__,#exp ),  \
              DbgBreakPoint(),                                  \
              TRUE))
#define ASSERTMSG(msg,exp)                                              \
    ((exp) ? TRUE :                                                     \
             (DbgPrint( "%s:%d %s %s\n",__FILE__,__LINE__,msg,#exp ),   \
              DbgBreakPoint(),                                          \
              TRUE))
#endif


//
//  Define the Virtual Address Control Block, which controls all mapping
//  performed by the Cache Manager.
//

//
//  First some constants
//

#define PREALLOCATED_VACBS               (4)

//
//  Virtual Address Control Block
//

typedef struct _VACB {

    //
    //  Base Address for this control block.
    //

    PVOID BaseAddress;

    //
    //  Pointer to the Shared Cache Map using this Vacb.
    //

    struct _SHARED_CACHE_MAP *SharedCacheMap;

    //
    //  Overlay for remembering mapped offset within the Shared Cache Map,
    //  and the count of the number of times this Vacb is in use.
    //

    union {

        //
        //  File Offset within Shared Cache Map
        //

        LARGE_INTEGER FileOffset;

        //
        //  Count of number of times this Vacb is in use.  The size of this
        //  count is calculated to be adequate, while never large enough to
        //  overwrite nonzero bits of the FileOffset, which is a multiple
        //  of VACB_MAPPING_GRANULARITY.
        //

        USHORT ActiveCount;

    } Overlay;

    //
    //  Entry for the VACB reuse list
    //

    LIST_ENTRY LruList;

} VACB, *PVACB;

//
//  These define special flag values that are overloaded as PVACB.  They cause
//  certain special behavior, currently only in the case of multilevel structures.
//

#define VACB_SPECIAL_REFERENCE           ((PVACB) ~0)
#define VACB_SPECIAL_DEREFERENCE         ((PVACB) ~1)

#define VACB_SPECIAL_FIRST_VALID         VACB_SPECIAL_DEREFERENCE



#define PRIVATE_CACHE_MAP_READ_AHEAD_ACTIVE     0x10000
#define PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED    0x20000

typedef struct _PRIVATE_CACHE_MAP_FLAGS {
    ULONG DontUse : 16;                     // Overlaid with NodeTypeCode

    //
    //  This flag says read ahead is currently active, which means either
    //  a file system call to CcReadAhead is still determining if the
    //  desired data is already resident, or else a request to do read ahead
    //  has been queued to a worker thread.
    //

    ULONG ReadAheadActive : 1;

    //
    //  Flag to say whether read ahead is currently enabled for this
    //  FileObject/PrivateCacheMap.  On read misses it is enabled on
    //  read ahead hits it will be disabled.  Initially disabled.
    //

    ULONG ReadAheadEnabled : 1;

    ULONG Available : 14;
} PRIVATE_CACHE_MAP_FLAGS;

#define CC_SET_PRIVATE_CACHE_MAP(PrivateCacheMap, Flags) \
    RtlInterlockedSetBitsDiscardReturn (&PrivateCacheMap->UlongFlags, Flags);

#define CC_CLEAR_PRIVATE_CACHE_MAP(PrivateCacheMap, Feature) \
    RtlInterlockedAndBitsDiscardReturn (&PrivateCacheMap->UlongFlags, (ULONG)~Feature);

//
//  The Private Cache Map is a structure pointed to by the File Object, whenever
//  a file is opened with caching enabled (default).
//

typedef struct _PRIVATE_CACHE_MAP {

    //
    //  Type and size of this record
    //

    union {
        CSHORT NodeTypeCode;
        PRIVATE_CACHE_MAP_FLAGS Flags;
        ULONG UlongFlags;
    };

    //
    //  Read Ahead mask formed from Read Ahead granularity - 1.
    //  Private Cache Map ReadAheadSpinLock controls access to this field.
    //

    ULONG ReadAheadMask;

    //
    //  Pointer to FileObject for this PrivateCacheMap.
    //

    PFILE_OBJECT FileObject;

    //
    //  READ AHEAD CONTROL
    //
    //  Read ahead history for determining when read ahead might be
    //  beneficial.
    //

    LARGE_INTEGER FileOffset1;
    LARGE_INTEGER BeyondLastByte1;

    LARGE_INTEGER FileOffset2;
    LARGE_INTEGER BeyondLastByte2;

    //
    //  Current read ahead requirements.
    //
    //  Array element 0 is optionally used for recording remaining bytes
    //  required for satisfying a large Mdl read.
    //
    //  Array element 1 is used for predicted read ahead.
    //

    LARGE_INTEGER ReadAheadOffset[2];
    ULONG ReadAheadLength[2];

    //
    //  SpinLock controlling access to following fields
    //

    KSPIN_LOCK ReadAheadSpinLock;

    //
    // Links for list of all PrivateCacheMaps linked to the same
    // SharedCacheMap.
    //

    LIST_ENTRY PrivateLinks;

} PRIVATE_CACHE_MAP;

typedef PRIVATE_CACHE_MAP *PPRIVATE_CACHE_MAP;


//
//  The Shared Cache Map is a per-file structure pointed to indirectly by
//  each File Object.  The File Object points to a pointer in a single
//  FS-private structure for the file (Fcb).  The SharedCacheMap maps the
//  first part of the file for common access by all callers.
//

//
//  OpenCount log Reasons/Actions
//

#if OPEN_COUNT_LOG
typedef struct _CC_OPEN_COUNT_LOG_ENTRY {
    ULONG Action;
    ULONG Reason;
} CC_OPEN_COUNT_LOG_ENTRY;

typedef struct _CC_OPEN_COUNT_LOG {
    USHORT Next;
    USHORT Size;
    CC_OPEN_COUNT_LOG_ENTRY Log[48];
} CC_OPEN_COUNT_LOG;

#define CcAddOpenToLog( LOG, ACTION, REASON ) {             \
    (LOG)->Log[(LOG)->Next].Action = (ACTION);              \
    (LOG)->Log[(LOG)->Next].Reason = (REASON);              \
    (LOG)->Next += 1;                                       \
    if ((LOG)->Next == (LOG)->Size) {                       \
        (LOG)->Next = 0;                                    \
    }                                                       \
}
#else  // OPEN_COUNT_LOG
#define CcAddOpenToLog( LOG, ACTION, REASON )
#endif // OPEN_COUNT_LOG

#define CcIncrementOpenCount( SCM, REASON ) {               \
    (SCM)->OpenCount += 1;                                  \
    if (REASON != 0) {                                      \
        CcAddOpenToLog( &(SCM)->OpenCountLog, REASON, 1 );  \
    }                                                       \
}

#define CcDecrementOpenCount( SCM, REASON ) {               \
    (SCM)->OpenCount -= 1;                                  \
    if (REASON != 0) {                                      \
        CcAddOpenToLog( &(SCM)->OpenCountLog, REASON, -1 ); \
    }                                                       \
}

typedef struct _SHARED_CACHE_MAP {

    //
    //  Type and size of this record
    //

    CSHORT NodeTypeCode;
    CSHORT NodeByteSize;

    //
    //  Number of times this file has been opened cached.
    //

    ULONG OpenCount;

    //
    //  Actual size of file, primarily for restricting Read Ahead.  Initialized
    //  on creation and maintained by extend and truncate operations.
    //
    //  NOTE:   This field may never be moved, thanks to the late DavidGoe,
    //          who should have written this comment himself :-(   cache.h
    //          exports a macro which "knows" that FileSize is the second
    //          longword in the Cache Map!
    //

    LARGE_INTEGER FileSize;

    //
    //  Bcb Listhead.  The BcbList is ordered by descending
    //  FileOffsets, to optimize misses in the sequential I/O case.
    //  Synchronized by the BcbSpinLock.
    //

    LIST_ENTRY BcbList;

    //
    //  Size of section created.
    //

    LARGE_INTEGER SectionSize;

    //
    //  ValidDataLength for file, as currently stored by the file system.
    //  Synchronized by the BcbSpinLock or exclusive access by FileSystem.
    //

    LARGE_INTEGER ValidDataLength;

    //
    //  Goal for ValidDataLength, when current dirty data is written.
    //  Synchronized by the BcbSpinLock or exclusive access by FileSystem.
    //

    LARGE_INTEGER ValidDataGoal;

    //
    //  Pointer to a contiguous array of Vacb pointers which control mapping
    //  to this file, along with Vacbs (currently) for a 1MB file.
    //  Synchronized by CcVacbSpinLock.
    //

    PVACB InitialVacbs[PREALLOCATED_VACBS];
    PVACB * Vacbs;

    //
    //  Referenced pointer to original File Object on which the SharedCacheMap
    //  was created.
    //

    PFILE_OBJECT FileObject;

    //
    //  Describe Active Vacb and Page for copysup optimizations.
    //

    volatile PVACB ActiveVacb;

    //
    //  Virtual address needing zero to end of page
    //

    volatile PVOID NeedToZero;

    ULONG ActivePage;
    ULONG NeedToZeroPage;

    //
    //  Fields for synchronizing on active requests.
    //

    KSPIN_LOCK ActiveVacbSpinLock;
    ULONG VacbActiveCount;

    //
    //  Number of dirty pages in this SharedCacheMap.  Used to trigger
    //  write behind.  Synchronized by CcMasterSpinLock.
    //

    ULONG DirtyPages;

    //
    //  THE NEXT TWO FIELDS MUST BE ADJACENT, TO SUPPORT
    //  SHARED_CACHE_MAP_LIST_CURSOR!
    //
    //  Links for Global SharedCacheMap List
    //

    LIST_ENTRY SharedCacheMapLinks;

    //
    //  Shared Cache Map flags (defined below)
    //

    ULONG Flags;

    //
    //  Status variable set by creator of SharedCacheMap
    //

    NTSTATUS Status;

    //
    //  Mask Bcb for this SharedCacheMap, if there is one.
    //  Synchronized by the BcbSpinLock.
    //

    struct _MBCB *Mbcb;

    //
    //  Pointer to the common Section Object used by the file system.
    //

    PVOID Section;

    //
    //  This event pointer is used to handle creation collisions.
    //  If a second thread tries to call CcInitializeCacheMap for the
    //  same file, while BeingCreated (below) is TRUE, then that thread
    //  will allocate an event store it here (if not already allocated),
    //  and wait on it.  The first creator will set this event when it
    //  is done.  The event is not deleted until CcUninitializedCacheMap
    //  is called, to avoid possible race conditions.  (Note that normally
    //  the event never has to be allocated.
    //

    PKEVENT CreateEvent;

    //
    //  This points to an event used to wait for active count to go to zero
    //

    PKEVENT WaitOnActiveCount;

    //
    //  These two fields control the writing of large metadata
    //  streams.  The first field gives a target for the current
    //  flush interval, and the second field stores the end of
    //  the last flush that occurred on this file.
    //

    ULONG PagesToWrite;
    LONGLONG BeyondLastFlush;

    //
    //  Pointer to structure of routines used by the Lazy Writer to Acquire
    //  and Release the file for Lazy Write and Close, to avoid deadlocks,
    //  and the context to call them with.
    //

    PCACHE_MANAGER_CALLBACKS Callbacks;

    PVOID LazyWriteContext;

    //
    //  Listhead of all PrivateCacheMaps linked to this SharedCacheMap.
    //

    LIST_ENTRY PrivateList;

    //
    //  Log handle specified for this shared cache map, for support of routines
    //  in logsup.c
    //

    PVOID LogHandle;

    //
    //  Callback routine specified for flushing to Lsn.
    //

    PFLUSH_TO_LSN FlushToLsnRoutine;

    //
    //  Dirty Page Threshold for this stream
    //

    ULONG DirtyPageThreshold;

    //
    //  Lazy Writer pass count.  Used by the Lazy Writer for
    //  no modified write streams, which are not serviced on
    //  every pass in order to avoid contention with foreground
    //  activity.
    //

    ULONG LazyWritePassCount;

    //
    //  This event pointer is used to allow a file system to be notified when
    //  the deletion of a shared cache map.
    //
    //  This has to be provided here because the cache manager may decide to
    //  "Lazy Delete" the shared cache map, and some network file systems
    //  will want to know when the lazy delete completes.
    //

    PCACHE_UNINITIALIZE_EVENT UninitializeEvent;

    //
    //  This Vacb pointer is needed for keeping the NeedToZero virtual address
    //  valid.
    //

    PVACB NeedToZeroVacb;

    //
    //  Spinlock for synchronizing the Mbcb and Bcb lists - must be acquired
    //  before CcMasterSpinLock.  This spinlock also synchronizes ValidDataGoal
    //  and ValidDataLength, as described above.
    //

    KSPIN_LOCK BcbSpinLock;

    PVOID Reserved;

    //
    //  This is an event which may be used for the WaitOnActiveCount event.  We
    //  avoid overhead by only "activating" it when it is needed.
    //

    KEVENT Event;

    EX_PUSH_LOCK VacbPushLock;
    
    //
    //  Preallocate one PrivateCacheMap to reduce pool allocations.
    //

    PRIVATE_CACHE_MAP PrivateCacheMap;

#if OPEN_COUNT_LOG

    //
    //  Instrument reasons for OpenCount
    //

    CC_OPEN_COUNT_LOG OpenCountLog;

#endif

} SHARED_CACHE_MAP;

typedef SHARED_CACHE_MAP *PSHARED_CACHE_MAP;

//
//  Shared Cache Map Flags
//

//
//  Read ahead has been disabled on this file.
//

#define DISABLE_READ_AHEAD               0x0001

//
//  Write behind has been disabled on this file.
//

#define DISABLE_WRITE_BEHIND             0x0002

//
//  This flag indicates whether CcInitializeCacheMap was called with
//  PinAccess = TRUE.
//

#define PIN_ACCESS                       0x0004

//
//  This flag indicates that a truncate is required when OpenCount
//  goes to 0.
//

#define TRUNCATE_REQUIRED                0x0010

//
//  This flag indicates that a LazyWrite request is queued.
//

#define WRITE_QUEUED                     0x0020

//
//  This flag indicates that we have never seen anyone cache
//  the file except for with FO_SEQUENTIAL_ONLY, so we should
//  tell MM to quickly dump pages when we unmap.
//

#define ONLY_SEQUENTIAL_ONLY_SEEN        0x0040

//
//  Active Page is locked
//

#define ACTIVE_PAGE_IS_DIRTY             0x0080

//
//  Flag to say that a create is in progress.
//

#define BEING_CREATED                    0x0100

//
//  Flag to say that modified write was disabled on the section.
//

#define MODIFIED_WRITE_DISABLED          0x0200

//
//  Flag that indicates if a lazy write ever occurred on this file.
//

#define LAZY_WRITE_OCCURRED              0x0400

//
//  Flag that indicates this structure is only a cursor, only the
//  SharedCacheMapLinks and Flags are valid!
//

#define IS_CURSOR                        0x0800

//
//  Flag that indicates that we have seen someone cache this file
//  and specify FO_RANDOM_ACCESS.  This will deactivate our cache
//  working set trim assist.
//

#define RANDOM_ACCESS_SEEN               0x1000

//
//  Flag indicating that the stream is private write.  This disables
//  non-aware flush/purge.
//

#define PRIVATE_WRITE                    0x2000

//
//  This flag indicates that a LazyWrite request is queued.
//

#define READ_AHEAD_QUEUED                0x4000

//
//  This flag indicates that CcMapAndCopy() forced a remote write
//  to be write through while writes were throttled.  This tells
//  CcUninitializeCacheMap() to force a lazy close of the file
//  and CcWriteBehind() to force an update of the valid data
//  length.
//

#define FORCED_WRITE_THROUGH             0x8000

//
//  This flag indicates that Mm is waiting for the data section being used
//  by Cc at this time to go away so that the file can be opened as an image
//  section.  If this flag is set during CcWriteBehind, we will flush the
//  entire file and try to tear down the shared cache map.
//

#define WAITING_FOR_TEARDOWN             0x10000

//
//  Cursor structure for traversing the SharedCacheMap lists.  Anyone
//  scanning these lists must verify that the IS_CURSOR flag is clear
//  before looking at other SharedCacheMap fields.
//


typedef struct _SHARED_CACHE_MAP_LIST_CURSOR {

    //
    //  Links for Global SharedCacheMap List
    //

    LIST_ENTRY SharedCacheMapLinks;

    //
    //  Shared Cache Map flags, IS_CURSOR must be set.
    //

    ULONG Flags;

} SHARED_CACHE_MAP_LIST_CURSOR, *PSHARED_CACHE_MAP_LIST_CURSOR;



#ifndef KDEXT
//
//  Bitmap Range structure.  For small files there is just one embedded in the
//  Mbcb.  For large files there may be many of these linked to the Mbcb.
//

typedef struct _BITMAP_RANGE {

    //
    //  Links for the list of bitmap ranges off the Mbcb.
    //

    LIST_ENTRY Links;

    //
    //  Base page (FileOffset / PAGE_SIZE) represented by this range.
    //  (Size is a fixed maximum.)
    //

    LONGLONG BasePage;

    //
    //  First and Last dirty pages relative to the BasePage.
    //

    ULONG FirstDirtyPage;
    ULONG LastDirtyPage;

    //
    //  Number of dirty pages in this range.
    //

    ULONG DirtyPages;

    //
    //  Pointer to the bitmap for this range.
    //

    PULONG Bitmap;

} BITMAP_RANGE, *PBITMAP_RANGE;
#endif

//
//  This structure is a "mask" Bcb.  For fast simple write operations,
//  a mask Bcb is used so that we basically only have to set bits to remember
//  where the dirty data is.
//

typedef struct _MBCB {

    //
    //  Type and size of this record
    //

    CSHORT NodeTypeCode;
    CSHORT NodeIsInZone;

    //
    //  This field is used as a scratch area for the Lazy Writer to
    //  guide how much he will write each time he wakes up.
    //

    ULONG PagesToWrite;

    //
    //  Number of dirty pages (set bits) in the bitmap below.
    //

    ULONG DirtyPages;

    //
    //  Reserved for alignment.
    //

    ULONG Reserved;

    //
    //  ListHead of Bitmap ranges.
    //

    LIST_ENTRY BitmapRanges;

    //
    //  This is a hint on where to resume writing, since we will not
    //  always write all of the dirty data at once.
    //

    LONGLONG ResumeWritePage;

    //
    //  Initial three embedded Bitmap ranges.  For a file up to 2MB, only the
    //  first range is used, and the rest of the Mbcb contains bits for 2MB of
    //  dirty pages (4MB on Alpha).  For larger files, all three ranges may
    //  be used to describe external bitmaps.
    //

    BITMAP_RANGE BitmapRange1;
    BITMAP_RANGE BitmapRange2;
    BITMAP_RANGE BitmapRange3;

} MBCB;

typedef MBCB *PMBCB;


//
//  This is the Buffer Control Block structure for representing data which
//  is "pinned" in memory by one or more active requests and/or dirty.  This
//  structure is created the first time that a call to CcPinFileData specifies
//  a particular integral range of pages.  It is deallocated whenever the Pin
//  Count reaches 0 and the Bcb is not Dirty.
//
//  NOTE: The first four fields must be the same as the PUBLIC_BCB.
//

typedef struct _BCB {

    union {

        //
        // To ensure QuadAlign (sizeof (BCB)) >= QuadAlign (sizeof (MBCB))
        // so that they can share the same pool blocks.
        //

        MBCB Dummy;

        struct {

            //
            //  Type and size of this record
            //

            CSHORT NodeTypeCode;

            //
            //  Flags
            //

            BOOLEAN Dirty;
            BOOLEAN Reserved;

            //
            //  Byte FileOffset and and length of entire buffer
            //

            ULONG  ByteLength;
            LARGE_INTEGER FileOffset;

            //
            //  Links for BcbList in SharedCacheMap
            //

            LIST_ENTRY BcbLinks;

            //
            //  Byte FileOffset of last byte in buffer (used for searching)
            //

            LARGE_INTEGER BeyondLastByte;

            //
            //  Oldest Lsn (if specified) when this buffer was set dirty.
            //

            LARGE_INTEGER OldestLsn;

            //
            //  Most recent Lsn specified when this buffer was set dirty.
            //  The FlushToLsnRoutine is called with this Lsn.
            //

            LARGE_INTEGER NewestLsn;

            //
            //  Pointer to Vacb via which this Bcb is mapped.
            //

            PVACB Vacb;

#if LIST_DBG
            //
            //  Links and caller addresses for the global Bcb list (for debug only)
            //

            LIST_ENTRY CcBcbLinks;
            PVOID CallerAddress;
            PVOID CallersCallerAddress;
#endif

            //
            //  Count of threads actively using this Bcb to process a request.
            //  This must be manipulated under protection of the BcbListSpinLock
            //  in the SharedCacheMap.
            //

            ULONG PinCount;

            //
            //  Resource to synchronize buffer access.  Pinning Readers and all Writers
            //  of the described buffer take out shared access (synchronization of
            //  buffer modifications is strictly up to the caller).  Note that pinning
            //  readers do not declare if they are going to modify the buffer or not.
            //  Anyone writing to disk takes out exclusive access, to prevent the buffer
            //  from changing while it is being written out.
            //

            ERESOURCE Resource;

            //
            //  Pointer to SharedCacheMap for this Bcb.
            //

            PSHARED_CACHE_MAP SharedCacheMap;

            //
            //  This is the Base Address at which the buffer can be seen in
            //  system space.  All access to buffer data should go through this
            //  address.
            //

            PVOID BaseAddress;
        };
    };

} BCB;

#ifndef KDEXT
typedef BCB *PBCB;
#endif

//
//  This is the Overlap Buffer Control Block structure for representing data which
//  is "pinned" in memory and must be represented by multiple Bcbs due to overlaps.
//
//  NOTE: The first four fields must be the same as the PUBLIC_BCB.
//

typedef struct _OBCB {

    //
    //  Type and size of this record
    //

    CSHORT NodeTypeCode;
    CSHORT NodeByteSize;

    //
    //  Byte FileOffset and and length of entire buffer
    //

    ULONG  ByteLength;
    LARGE_INTEGER FileOffset;

    //
    //  Vector of Bcb pointers.
    //

    PBCB Bcbs[ANYSIZE_ARRAY];

} OBCB;

typedef OBCB *POBCB;


//
//  Struct for remembering deferred writes for later posting.
//

typedef struct _DEFERRED_WRITE {

    //
    //  Type and size of this record
    //

    CSHORT NodeTypeCode;
    CSHORT NodeByteSize;

    //
    //  The file to be written.
    //

    PFILE_OBJECT FileObject;

    //
    //  Number of bytes the caller intends to write
    //

    ULONG BytesToWrite;

    //
    //  Links for the deferred write queue.
    //

    LIST_ENTRY DeferredWriteLinks;

    //
    //  If this event pointer is not NULL, then this event will
    //  be signalled when the write is ok, rather than calling
    //  the PostRoutine below.
    //

    PKEVENT Event;

    //
    //  The posting routine and its parameters
    //

    PCC_POST_DEFERRED_WRITE PostRoutine;
    PVOID Context1;
    PVOID Context2;

    BOOLEAN LimitModifiedPages;

} DEFERRED_WRITE, *PDEFERRED_WRITE;


//
//  Struct controlling the Lazy Writer algorithms
//

typedef struct _LAZY_WRITER {

    //
    //  Work queue.
    //

    LIST_ENTRY WorkQueue;

    //
    //  Dpc and Timer Structures used for activating periodic scan when active.
    //

    KDPC ScanDpc;
    KTIMER ScanTimer;

    //
    //  Boolean to say whether Lazy Writer scan is active or not.
    //

    BOOLEAN ScanActive;

    //
    //  Boolean indicating if there is any other reason for Lazy Writer to
    //  wake up.
    //

    BOOLEAN OtherWork;

} LAZY_WRITER;


#ifndef KDEXT
//
//  Work queue entry for the worker threads, with an enumerated
//  function code.
//

typedef enum _WORKER_FUNCTION {
    Noop = 0,
    ReadAhead,
    WriteBehind,
    LazyWriteScan,
    EventSet
} WORKER_FUNCTION;
#endif

typedef struct _WORK_QUEUE_ENTRY {

    //
    //  List entry for our work queues.
    //

    LIST_ENTRY WorkQueueLinks;

    //
    //  Define a union to contain function-specific parameters.
    //

    union {

        //
        //  Read parameters (for read ahead)
        //

        struct {
            PFILE_OBJECT FileObject;
        } Read;

        //
        //  Write parameters (for write behind)
        //

        struct {
            PSHARED_CACHE_MAP SharedCacheMap;
        } Write;

        //
        //  Set event parameters (for queue checks)
        //

        struct {
            PKEVENT Event;
        } Event;

    } Parameters;

    //
    //  Function code for this entry:
    //

    UCHAR Function;

} WORK_QUEUE_ENTRY, *PWORK_QUEUE_ENTRY;

//
//  This is a structure apended to the end of an MDL
//

typedef struct _MDL_WRITE {

    //
    //  This field is for the use of the Server to stash anything interesting
    //

    PVOID ServerContext;

    //
    //  This is the resource to release when the write is complete.
    //

    PERESOURCE Resource;

    //
    //  This is thread caller's thread, and the thread that must release
    //  the resource.
    //

    ERESOURCE_THREAD Thread;

    //
    //  This links all the pending MDLs through the shared cache map.
    //

    LIST_ENTRY MdlLinks;

} MDL_WRITE, *PMDL_WRITE;


//
//  Common Private routine definitions for the Cache Manager
//

VOID
CcGetActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    OUT PVACB *Vacb,
    OUT PULONG Page,
    OUT PULONG Dirty
    );

VOID
CcSetActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN OUT PVACB *Vacb,
    IN ULONG Page,
    IN ULONG Dirty
    );

//
//  We trim out the previous macro-forms of Get/Set (nondpc) so that we can page
//  more cache manager code that otherwise does not acquire spinlocks.
//

#define GetActiveVacb(SCM,IRQ,V,P,D)     CcGetActiveVacb((SCM),&(V),&(P),&(D))
#define SetActiveVacb(SCM,IRQ,V,P,D)     CcSetActiveVacb((SCM),&(V),(P),(D))

#define GetActiveVacbAtDpcLevel(SCM,V,P,D) {                            \
    ExAcquireSpinLockAtDpcLevel(&(SCM)->ActiveVacbSpinLock);            \
    (V) = (SCM)->ActiveVacb;                                            \
    if ((V) != NULL) {                                                  \
        (P) = (SCM)->ActivePage;                                        \
        (SCM)->ActiveVacb = NULL;                                       \
        (D) = (SCM)->Flags & ACTIVE_PAGE_IS_DIRTY;                      \
    }                                                                   \
    ExReleaseSpinLockFromDpcLevel(&(SCM)->ActiveVacbSpinLock);          \
}

//
//  Gather the common work of charging and deducting dirty page counts.  When
//  write hysteresis was being considered during Windows XP, this also helped
//  gather up the activation of that throttle.
//

#define CcDeductDirtyPages( S, P )                                      \
        CcTotalDirtyPages -= (P);                                       \
        (S)->DirtyPages -= (P);
        
#define CcChargeMaskDirtyPages( S, M, B, P )                            \
        CcTotalDirtyPages += (P);                                       \
        (M)->DirtyPages += (P);                                         \
        (B)->DirtyPages += (P);                                         \
        (S)->DirtyPages += (P);

#define CcChargePinDirtyPages( S, P )                                   \
        CcTotalDirtyPages += (P);                                       \
        (S)->DirtyPages += (P);

VOID
CcPostDeferredWrites (
    );

BOOLEAN
CcPinFileData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN ReadOnly,
    IN BOOLEAN WriteOnly,
    IN ULONG Flags,
    OUT PBCB *Bcb,
    OUT PVOID *BaseAddress,
    OUT PLARGE_INTEGER BeyondLastByte
    );

typedef enum {
    UNPIN,
    UNREF,
    SET_CLEAN
} UNMAP_ACTIONS;

VOID
FASTCALL
CcUnpinFileData (
    IN OUT PBCB Bcb,
    IN BOOLEAN ReadOnly,
    IN UNMAP_ACTIONS UnmapAction
    );

VOID
FASTCALL
CcDeallocateBcb (
    IN PBCB Bcb
    );

VOID
FASTCALL
CcPerformReadAhead (
    IN PFILE_OBJECT FileObject
    );

VOID
CcSetDirtyInMask (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length
    );

VOID
FASTCALL
CcWriteBehind (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PIO_STATUS_BLOCK IoStatus
    );

#define ZERO_FIRST_PAGE                  1
#define ZERO_MIDDLE_PAGES                2
#define ZERO_LAST_PAGE                   4

BOOLEAN
CcMapAndRead(
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG ZeroFlags,
    IN BOOLEAN Wait,
    IN PVOID BaseAddress
    );

VOID
CcFreeActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB ActiveVacb OPTIONAL,
    IN ULONG ActivePage,
    IN ULONG PageIsDirty
    );

VOID
CcMapAndCopy(
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVOID UserBuffer,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG ZeroFlags,
    IN PFILE_OBJECT FileObject
    );

VOID
CcScanDpc (
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    );

VOID
CcScheduleLazyWriteScan (
    IN BOOLEAN FastScan
    );

VOID
CcStartLazyWriter (
    IN PVOID NotUsed
    );

#define CcAllocateWorkQueueEntry() \
    (PWORK_QUEUE_ENTRY)ExAllocateFromPPLookasideList(LookasideTwilightList)

#define CcFreeWorkQueueEntry(_entry_)         \
    ExFreeToPPLookasideList(LookasideTwilightList, (_entry_))

VOID
FASTCALL
CcPostWorkQueue (
    IN PWORK_QUEUE_ENTRY WorkQueueEntry,
    IN PLIST_ENTRY WorkQueue
    );

VOID
CcWorkerThread (
    PVOID ExWorkQueueItem
    );

VOID
FASTCALL
CcDeleteSharedCacheMap (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN KIRQL ListIrql,
    IN ULONG ReleaseFile
    );

//
//  This exception filter handles STATUS_IN_PAGE_ERROR correctly
//

LONG
CcCopyReadExceptionFilter(
    IN PEXCEPTION_POINTERS ExceptionPointer,
    IN PNTSTATUS ExceptionCode
    );

//
//  Exception filter for Worker Threads in lazyrite.c
//

LONG
CcExceptionFilter (
    IN NTSTATUS ExceptionCode
    );

#ifdef CCDBG
VOID
CcDump (
    IN PVOID Ptr
    );
#endif

//
//  Vacb routines
//

VOID
CcInitializeVacbs(
    );

PVOID
CcGetVirtualAddressIfMapped (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    OUT PVACB *Vacb,
    OUT PULONG ReceivedLength
    );

PVOID
CcGetVirtualAddress (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset,
    OUT PVACB *Vacb,
    OUT PULONG ReceivedLength
    );

VOID
FASTCALL
CcFreeVirtualAddress (
    IN PVACB Vacb
    );

VOID
CcReferenceFileOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset
    );

VOID
CcDereferenceFileOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset
    );

VOID
CcWaitOnActiveCount (
    IN PSHARED_CACHE_MAP SharedCacheMap
    );

NTSTATUS
FASTCALL
CcCreateVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER NewSectionSize
    );

NTSTATUS
CcExtendVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER NewSectionSize
    );

BOOLEAN
FASTCALL
CcUnmapVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset OPTIONAL,
    IN ULONG Length,
    IN BOOLEAN UnmapBehind
    );

VOID
CcAdjustVacbLevelLockCount (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN LONG Adjustment
    );

PLIST_ENTRY
CcGetBcbListHeadLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN BOOLEAN FailToSuccessor
    );

ULONG
CcPrefillVacbLevelZone (
    IN ULONG NumberNeeded,
    OUT PKIRQL OldIrql,
    IN ULONG NeedBcbListHeads
    );

VOID
CcDrainVacbLevelZone (
    );

//
//  Define references to global data
//

extern KSPIN_LOCK CcBcbSpinLock;
extern LIST_ENTRY CcCleanSharedCacheMapList;
extern SHARED_CACHE_MAP_LIST_CURSOR CcDirtySharedCacheMapList;
extern SHARED_CACHE_MAP_LIST_CURSOR CcLazyWriterCursor;
extern GENERAL_LOOKASIDE CcTwilightLookasideList;
extern ULONG CcNumberWorkerThreads;
extern ULONG CcNumberActiveWorkerThreads;
extern LIST_ENTRY CcIdleWorkerThreadList;
extern LIST_ENTRY CcExpressWorkQueue;
extern LIST_ENTRY CcRegularWorkQueue;
extern LIST_ENTRY CcPostTickWorkQueue;
extern BOOLEAN CcQueueThrottle;
extern ULONG CcIdleDelayTick;
extern LARGE_INTEGER CcNoDelay;
extern LARGE_INTEGER CcFirstDelay;
extern LARGE_INTEGER CcIdleDelay;
extern LARGE_INTEGER CcCollisionDelay;
extern LARGE_INTEGER CcTargetCleanDelay;
extern LAZY_WRITER LazyWriter;
extern ULONG_PTR CcNumberVacbs;
extern PVACB CcVacbs;
extern PVACB CcBeyondVacbs;
extern LIST_ENTRY CcVacbLru;
extern LIST_ENTRY CcVacbFreeList;
extern KSPIN_LOCK CcDeferredWriteSpinLock;
extern LIST_ENTRY CcDeferredWrites;
extern ULONG CcDirtyPageThreshold;
extern ULONG CcDirtyPageTarget;
extern ULONG CcDirtyPagesLastScan;
extern ULONG CcPagesYetToWrite;
extern ULONG CcPagesWrittenLastTime;
extern ULONG CcThrottleLastTime;
extern ULONG CcDirtyPageHysteresisThreshold;
extern PSHARED_CACHE_MAP CcSingleDirtySourceDominant;
extern ULONG CcAvailablePagesThreshold;
extern ULONG CcTotalDirtyPages;
extern ULONG CcTune;
extern LONG CcAggressiveZeroCount;
extern LONG CcAggressiveZeroThreshold;
extern ULONG CcLazyWriteHotSpots;
extern MM_SYSTEMSIZE CcCapturedSystemSize;
extern ULONG CcMaxVacbLevelsSeen;
extern ULONG CcVacbLevelEntries;
extern PVACB *CcVacbLevelFreeList;
extern ULONG CcVacbLevelWithBcbsEntries;
extern PVACB *CcVacbLevelWithBcbsFreeList;

//
//  Macros for allocating and deallocating Vacb levels - CcVacbSpinLock must
//  be acquired.
//

_inline PVACB *CcAllocateVacbLevel (
    IN LOGICAL AllocatingBcbListHeads
    )

{
    PVACB *ReturnEntry;

    if (AllocatingBcbListHeads) {
        ReturnEntry = CcVacbLevelWithBcbsFreeList;
        CcVacbLevelWithBcbsFreeList = (PVACB *)*ReturnEntry;
        CcVacbLevelWithBcbsEntries -= 1;
    } else {
        ReturnEntry = CcVacbLevelFreeList;
        CcVacbLevelFreeList = (PVACB *)*ReturnEntry;
        CcVacbLevelEntries -= 1;
    }
    *ReturnEntry = NULL;
    ASSERT(RtlCompareMemory(ReturnEntry, ReturnEntry + 1, VACB_LEVEL_BLOCK_SIZE - sizeof(PVACB)) ==
                                                          (VACB_LEVEL_BLOCK_SIZE - sizeof(PVACB)));
    return ReturnEntry;
}

_inline VOID CcDeallocateVacbLevel (
    IN PVACB *Entry,
    IN LOGICAL DeallocatingBcbListHeads
    )

{
    if (DeallocatingBcbListHeads) {
        *Entry = (PVACB)CcVacbLevelWithBcbsFreeList;
        CcVacbLevelWithBcbsFreeList = Entry;
        CcVacbLevelWithBcbsEntries += 1;
    } else {
        *Entry = (PVACB)CcVacbLevelFreeList;
        CcVacbLevelFreeList = Entry;
        CcVacbLevelEntries += 1;
    }
}

//
//  Export the macros for inspecting the reference counts for
//  the multilevel Vacb array.
//

_inline
PVACB_LEVEL_REFERENCE
VacbLevelReference (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level
    )
{
    return (PVACB_LEVEL_REFERENCE)
           ((PCHAR)VacbArray +
            VACB_LEVEL_BLOCK_SIZE +
            (Level != 0?
             0 : (FlagOn( SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED )?
                  VACB_LEVEL_BLOCK_SIZE : 0)));
}

_inline
ULONG
IsVacbLevelReferenced (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level
    )
{
    PVACB_LEVEL_REFERENCE VacbReference = VacbLevelReference( SharedCacheMap, VacbArray, Level );

    return VacbReference->Reference | VacbReference->SpecialReference;
}


//
//  Here is a page of macros stolen directly from Pinball...
//

//
//  The following macros are used to establish the semantics needed
//  to do a return from within a try-finally clause.  As a rule every
//  try clause must end with a label call try_exit.  For example,
//
//      try {
//              :
//              :
//
//      try_exit: NOTHING;
//      } finally {
//
//              :
//              :
//      }
//
//  Every return statement executed inside of a try clause should use the
//  try_return macro.  If the compiler fully supports the try-finally construct
//  then the macro should be
//
//      #define try_return(S)  { return(S); }
//
//  If the compiler does not support the try-finally construct then the macro
//  should be
//
//      #define try_return(S)  { S; goto try_exit; }
//

#define try_return(S) { S; goto try_exit; }

#ifdef CCDBG

extern LONG CcDebugTraceLevel;
extern LONG CcDebugTraceIndent;

#ifndef CCDBG_LOCK

#define DebugTrace(INDENT,LEVEL,X,Y) {                     \
    LONG _i;                                               \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        DbgPrint("%08lx:",_i);                             \
        if ((INDENT) < 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        if (CcDebugTraceIndent < 0) {                      \
            CcDebugTraceIndent = 0;                        \
        }                                                  \
        for (_i=0; _i<CcDebugTraceIndent; _i+=1) {         \
            DbgPrint(" ");                                 \
        }                                                  \
        DbgPrint(X,Y);                                     \
        if ((INDENT) > 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
    }                                                      \
}

#define DebugTrace2(INDENT,LEVEL,X,Y,Z) {                  \
    LONG _i;                                               \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        DbgPrint("%08lx:",_i);                             \
        if ((INDENT) < 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        if (CcDebugTraceIndent < 0) {                      \
            CcDebugTraceIndent = 0;                        \
        }                                                  \
        for (_i=0; _i<CcDebugTraceIndent; _i+=1) {         \
            DbgPrint(" ");                                 \
        }                                                  \
        DbgPrint(X,Y,Z);                                   \
        if ((INDENT) > 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
    }                                                      \
}

#define DebugDump(STR,LEVEL,PTR) {                         \
    LONG _i;                                               \
    VOID CcDump();                                         \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        DbgPrint("%08lx:",_i);                             \
        DbgPrint(STR);                                     \
        if (PTR != NULL) {CcDump(PTR);}                    \
        DbgBreakPoint();                                   \
    }                                                      \
}

#else //  ndef CCDBG_LOCK

extern KSPIN_LOCK CcDebugTraceLock;

#define DebugTrace(INDENT,LEVEL,X,Y) {                     \
    LONG _i;                                               \
    KIRQL _oldIrql;                                        \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        ExAcquireSpinLock( &CcDebugTraceLock, &_oldIrql ); \
        DbgPrint("%08lx:",_i);                             \
        if ((INDENT) < 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        if (CcDebugTraceIndent < 0) {                      \
            CcDebugTraceIndent = 0;                        \
        }                                                  \
        for (_i=0; _i<CcDebugTraceIndent; _i+=1) {         \
            DbgPrint(" ");                                 \
        }                                                  \
        DbgPrint(X,Y);                                     \
        if ((INDENT) > 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        ExReleaseSpinLock( &CcDebugTraceLock, _oldIrql );  \
    }                                                      \
}

#define DebugTrace2(INDENT,LEVEL,X,Y,Z) {                  \
    LONG _i;                                               \
    KIRQL _oldIrql;                                        \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
        ExAcquireSpinLock( &CcDebugTraceLock, &_oldIrql ); \
        DbgPrint("%08lx:",_i);                             \
        if ((INDENT) < 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
        if (CcDebugTraceIndent < 0) {                      \
            CcDebugTraceIndent = 0;                        \
        }                                                  \
        for (_i=0; _i<CcDebugTraceIndent; _i+=1) {         \
            DbgPrint(" ");                                 \
        }                                                  \
        DbgPrint(X,Y,Z);                                   \
        if ((INDENT) > 0) {                                \
            CcDebugTraceIndent += (INDENT);                \
        }                                                  \
      ExReleaseSpinLock( &CcDebugTraceLock, _oldIrql );  \
    }                                                      \
}

#define DebugDump(STR,LEVEL,PTR) {                         \
    LONG _i;                                               \
    KIRQL _oldIrql;                                        \
    VOID CcDump();                                         \
    if (((LEVEL) == 0) || (CcDebugTraceLevel & (LEVEL))) { \
        _i = (ULONG)PsGetCurrentThread();                  \
      ExAcquireSpinLock( &CcDebugTraceLock, &_oldIrql ); \
        DbgPrint("%08lx:",_i);                             \
        DbgPrint(STR);                                     \
        if (PTR != NULL) {CcDump(PTR);}                    \
        DbgBreakPoint();                                   \
      ExReleaseSpinLock( &CcDebugTraceLock, _oldIrql );  \
    }                                                      \
}

#endif //  else ndef CCDBG_LOCK

#else

#undef CCDBG_LOCK

#define DebugTrace(INDENT,LEVEL,X,Y) {NOTHING;}

#define DebugTrace2(INDENT,LEVEL,X,Y,Z) {NOTHING;}

#define DebugDump(STR,LEVEL,PTR) {NOTHING;}

#endif //  CCDBG

//
//  Global list of pinned Bcbs which may be examined for debug purposes
//

#if DBG

extern ULONG CcBcbCount;
extern LIST_ENTRY CcBcbList;

#endif

FORCEINLINE
VOID
CcInsertIntoCleanSharedCacheMapList (
    IN PSHARED_CACHE_MAP SharedCacheMap
    )
{
    if (KdDebuggerEnabled && 
        (KdDebuggerNotPresent == FALSE) &&
        SharedCacheMap->OpenCount == 0 &&
        SharedCacheMap->DirtyPages == 0) {

        DbgPrint( "CC: SharedCacheMap->OpenCount == 0 && DirtyPages == 0 && going onto CleanList!\n" );
        DbgBreakPoint();
    }

    InsertTailList( &CcCleanSharedCacheMapList,
                    &SharedCacheMap->SharedCacheMapLinks );
}

#endif  //  _CCh_
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\copysup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    copysup.c

Abstract:

    This module implements the copy support routines for the Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  Define our debug constant
//

#define me 0x00000004

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CcCopyRead)
#pragma alloc_text(PAGE,CcFastCopyRead)
#endif


BOOLEAN
CcCopyRead (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN Wait,
    OUT PVOID Buffer,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine attempts to copy the specified file data from the cache
    into the output buffer, and deliver the correct I/O status.  It is *not*
    safe to call this routine from Dpc level.

    If the caller does not want to block (such as for disk I/O), then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to supply all of the requested data without
    blocking, then this routine will return FALSE.  However, if the
    data is immediately accessible in the cache and no blocking is
    required, this routine copies the data and returns TRUE.

    If the caller supplies Wait as TRUE, then this routine is guaranteed
    to copy the data and return TRUE.  If the data is immediately
    accessible in the cache, then no blocking will occur.  Otherwise,
    the the data transfer from the file into the cache will be initiated,
    and the caller will be blocked until the data can be returned.

    File system Fsd's should typically supply Wait = TRUE if they are
    processing a synchronous I/O requests, or Wait = FALSE if they are
    processing an asynchronous request.

    File system or Server Fsp threads should supply Wait = TRUE.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Wait - FALSE if caller may not block, TRUE otherwise (see description
           above)

    Buffer - Pointer to output buffer to which data should be copied.

    IoStatus - Pointer to standard I/O status block to receive the status
               for the transfer.  (STATUS_SUCCESS guaranteed for cache
               hits, otherwise the actual I/O status is returned.)

               Note that even if FALSE is returned, the IoStatus.Information
               field will return the count of any bytes successfully
               transferred before a blocking condition occured.  The caller
               may either choose to ignore this information, or resume
               the copy later accounting for bytes transferred.

Return Value:

    FALSE - if Wait was supplied as FALSE and the data was not delivered

    TRUE - if the data is being delivered

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PVACB Vacb;
    PBCB Bcb;
    PVACB ActiveVacb;
    ULONG ActivePage;
    ULONG PageIsDirty;
    ULONG SavedState;
    ULONG PagesToGo;
    ULONG MoveLength;
    ULONG LengthToGo;
    NTSTATUS Status;
    ULONG OriginalLength = Length;
    PETHREAD Thread = PsGetCurrentThread();
    ULONG GotAMiss = 0;

    DebugTrace(+1, me, "CcCopyRead\n", 0 );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  Get pointer to shared and private cache maps
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    PrivateCacheMap = FileObject->PrivateCacheMap;

    //
    //  Check for read past file size, the caller must filter this case out.
    //

    ASSERT( ( FileOffset->QuadPart + (LONGLONG)Length) <= SharedCacheMap->FileSize.QuadPart );

    //
    //  If read ahead is enabled, then do the read ahead here so it
    //  overlaps with the copy (otherwise we will do it below).
    //  Note that we are assuming that we will not get ahead of our
    //  current transfer - if read ahead is working it should either
    //  already be in memory or else underway.
    //

    if (PrivateCacheMap->Flags.ReadAheadEnabled && (PrivateCacheMap->ReadAheadLength[1] == 0)) {
        CcScheduleReadAhead( FileObject, FileOffset, Length );
    }

    FOffset = *FileOffset;

    //
    //  Increment performance counters
    //

    if (Wait) {
        HOT_STATISTIC(CcCopyReadWait) += 1;

        //
        //  This is not an exact solution, but when IoPageRead gets a miss,
        //  it cannot tell whether it was CcCopyRead or CcMdlRead, but since
        //  the miss should occur very soon, by loading the pointer here
        //  probably the right counter will get incremented, and in any case,
        //  we hope the errrors average out!
        //

        CcMissCounter = &CcCopyReadWaitMiss;

    } else {
        HOT_STATISTIC(CcCopyReadNoWait) += 1;
    }

    //
    //  See if we have an active Vacb, that we can just copy to.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    if (ActiveVacb != NULL) {

        if ((ULONG)(FOffset.QuadPart >> VACB_OFFSET_SHIFT) == (ActivePage >> (VACB_OFFSET_SHIFT - PAGE_SHIFT))) {

            ULONG LengthToCopy = VACB_MAPPING_GRANULARITY - (FOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1));

            if (SharedCacheMap->NeedToZero != NULL) {
                CcFreeActiveVacb( SharedCacheMap, NULL, 0, FALSE );
            }

            //
            //  Get the starting point in the view.
            //

            CacheBuffer = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                          (FOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1)));

            //
            //  Reduce LengthToCopy if it is greater than our caller's length.
            //

            if (LengthToCopy > Length) {
                LengthToCopy = Length;
            }

            //
            //  Like the logic for the normal case below, we want to spin around
            //  making sure Mm only reads the pages we will need.
            //
            
            PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                               LengthToCopy ) - 1;

            //
            //  Copy the data to the user buffer.
            //

            try {

                if (PagesToGo != 0) {
    
                    LengthToGo = LengthToCopy;
    
                    while (LengthToGo != 0) {
    
                        MoveLength = (ULONG)((PCHAR)(ROUND_TO_PAGES(((PCHAR)CacheBuffer + 1))) -
                                     (PCHAR)CacheBuffer);
    
                        if (MoveLength > LengthToGo) {
                            MoveLength = LengthToGo;
                        }
    
                        //
                        //  Here's hoping that it is cheaper to call Mm to see if
                        //  the page is valid.  If not let Mm know how many pages
                        //  we are after before doing the move.
                        //
    
                        MmSetPageFaultReadAhead( Thread, PagesToGo );
                        GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );
    
                        RtlCopyBytes( Buffer, CacheBuffer, MoveLength );
    
                        PagesToGo -= 1;
    
                        LengthToGo -= MoveLength;
                        Buffer = (PCHAR)Buffer + MoveLength;
                        CacheBuffer = (PCHAR)CacheBuffer + MoveLength;
                    }
    
                //
                //  Handle the read here that stays on a single page.
                //
    
                } else {
    
                    //
                    //  Here's hoping that it is cheaper to call Mm to see if
                    //  the page is valid.  If not let Mm know how many pages
                    //  we are after before doing the move.
                    //
    
                    MmSetPageFaultReadAhead( Thread, 0 );
                    GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );
    
                    RtlCopyBytes( Buffer, CacheBuffer, LengthToCopy );
    
                    Buffer = (PCHAR)Buffer + LengthToCopy;
                }
                
            } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                 &Status ) ) {

                MmResetPageFaultReadAhead( Thread, SavedState );

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

                //
                //  If we got an access violation, then the user buffer went
                //  away.  Otherwise we must have gotten an I/O error trying
                //  to bring the data in.
                //

                if (Status == STATUS_ACCESS_VIOLATION) {
                    ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                }
                else {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }
            }

            //
            //  Now adjust FOffset and Length by what we copied.
            //

            FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)LengthToCopy;
            Length -= LengthToCopy;

        }

        //
        //  If that was all the data, then remember the Vacb
        //

        if (Length == 0) {

            SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

        //
        //  Otherwise we must free it because we will map other vacbs below.
        //

        } else {

            CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
        }
    }

    //
    //  Not all of the transfer will come back at once, so we have to loop
    //  until the entire transfer is complete.
    //

    while (Length != 0) {

        ULONG ReceivedLength;
        LARGE_INTEGER BeyondLastByte;

        //
        //  Call local routine to Map or Access the file data, then move the data,
        //  then call another local routine to free the data.  If we cannot map
        //  the data because of a Wait condition, return FALSE.
        //
        //  Note that this call may result in an exception, however, if it
        //  does no Bcb is returned and this routine has absolutely no
        //  cleanup to perform.  Therefore, we do not have a try-finally
        //  and we allow the possibility that we will simply be unwound
        //  without notice.
        //

        if (Wait) {

            CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                               FOffset,
                                               &Vacb,
                                               &ReceivedLength );

            BeyondLastByte.QuadPart = FOffset.QuadPart + (LONGLONG)ReceivedLength;

        } else if (!CcPinFileData( FileObject,
                                   &FOffset,
                                   Length,
                                   TRUE,
                                   FALSE,
                                   FALSE,
                                   &Bcb,
                                   &CacheBuffer,
                                   &BeyondLastByte )) {

            DebugTrace(-1, me, "CcCopyRead -> FALSE\n", 0 );

            HOT_STATISTIC(CcCopyReadNoWaitMiss) += 1;

            //
            //  Enable ReadAhead if we missed.
            //

            if (!FlagOn( FileObject->Flags, FO_RANDOM_ACCESS ) &&
                !PrivateCacheMap->Flags.ReadAheadEnabled) {
                
                CC_SET_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);
            }

            return FALSE;

        } else {

            //
            //  Calculate how much data is described by Bcb starting at our desired
            //  file offset.
            //

            ReceivedLength = (ULONG)(BeyondLastByte.QuadPart - FOffset.QuadPart);
        }

        //
        //  If we got more than we need, make sure to only transfer
        //  the right amount.
        //

        if (ReceivedLength > Length) {
            ReceivedLength = Length;
        }

        //
        //  It is possible for the user buffer to become no longer accessible
        //  since it was last checked by the I/O system.  If we fail to access
        //  the buffer we must raise a status that the caller's exception
        //  filter considers as "expected".  Also we unmap the Bcb here, since
        //  we otherwise would have no other reason to put a try-finally around
        //  this loop.
        //

        try {

            PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                               ReceivedLength ) - 1;

            //
            //  We know exactly how much we want to read here, and we do not
            //  want to read any more in case the caller is doing random access.
            //  Our read ahead logic takes care of detecting sequential reads,
            //  and tends to do large asynchronous read aheads.  So far we have
            //  only mapped the data and we have not forced any in.  What we
            //  do now is get into a loop where we copy a page at a time and
            //  just prior to each move, we tell MM how many additional pages
            //  we would like to have read in, in the event that we take a
            //  fault.  With this strategy, for cache hits we never make a single
            //  expensive call to MM to guarantee that the data is in, yet if we
            //  do take a fault, we are guaranteed to only take one fault because
            //  we will read all of the data in for the rest of the transfer.
            //
            //  We test first for the multiple page case, to keep the small
            //  reads faster.
            //

            if (PagesToGo != 0) {

                LengthToGo = ReceivedLength;

                while (LengthToGo != 0) {

                    MoveLength = (ULONG)((PCHAR)(ROUND_TO_PAGES(((PCHAR)CacheBuffer + 1))) -
                                 (PCHAR)CacheBuffer);

                    if (MoveLength > LengthToGo) {
                        MoveLength = LengthToGo;
                    }

                    //
                    //  Here's hoping that it is cheaper to call Mm to see if
                    //  the page is valid.  If not let Mm know how many pages
                    //  we are after before doing the move.
                    //

                    MmSetPageFaultReadAhead( Thread, PagesToGo );
                    GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );

                    RtlCopyBytes( Buffer, CacheBuffer, MoveLength );

                    PagesToGo -= 1;

                    LengthToGo -= MoveLength;
                    Buffer = (PCHAR)Buffer + MoveLength;
                    CacheBuffer = (PCHAR)CacheBuffer + MoveLength;
                }

            //
            //  Handle the read here that stays on a single page.
            //

            } else {

                //
                //  Here's hoping that it is cheaper to call Mm to see if
                //  the page is valid.  If not let Mm know how many pages
                //  we are after before doing the move.
                //

                MmSetPageFaultReadAhead( Thread, 0 );
                GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );

                RtlCopyBytes( Buffer, CacheBuffer, ReceivedLength );

                Buffer = (PCHAR)Buffer + ReceivedLength;
            }

        }
        except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                           &Status ) ) {

            CcMissCounter = &CcThrowAway;

            //
            //  If we get an exception, then we have to renable page fault
            //  clustering and unmap on the way out.
            //

            MmResetPageFaultReadAhead( Thread, SavedState );


            if (Wait) {
                CcFreeVirtualAddress( Vacb );
            } else {
                CcUnpinFileData( Bcb, TRUE, UNPIN );
            }

            //
            //  If we got an access violation, then the user buffer went
            //  away.  Otherwise we must have gotten an I/O error trying
            //  to bring the data in.
            //

            if (Status == STATUS_ACCESS_VIOLATION) {
                ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
            }
            else {
                ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                       STATUS_UNEXPECTED_IO_ERROR ));
            }
        }

        //
        //  Update number of bytes transferred.
        //

        Length -= ReceivedLength;

        //
        //  Unmap the data now, and calculate length left to transfer.
        //

        if (Wait) {

            //
            //  If there is more to go, just free this vacb.
            //

            if (Length != 0) {

                CcFreeVirtualAddress( Vacb );

            //
            //  Otherwise save it for the next time through.
            //

            } else {

                SetActiveVacb( SharedCacheMap, OldIrql, Vacb, (ULONG)(FOffset.QuadPart >> PAGE_SHIFT), 0 );
                break;
            }

        } else {
            CcUnpinFileData( Bcb, TRUE, UNPIN );
        }

        //
        //  Assume we did not get all the data we wanted, and set FOffset
        //  to the end of the returned data.
        //

        FOffset = BeyondLastByte;
    }

    MmResetPageFaultReadAhead( Thread, SavedState );

    CcMissCounter = &CcThrowAway;

    //
    //  Now enable read ahead if it looks like we got any misses, and do
    //  the first one.
    //

    if (GotAMiss &&
        !FlagOn( FileObject->Flags, FO_RANDOM_ACCESS ) &&
        !PrivateCacheMap->Flags.ReadAheadEnabled) {

        CC_SET_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);
        CcScheduleReadAhead( FileObject, FileOffset, OriginalLength );
    }

    //
    //  Now that we have described our desired read ahead, let's
    //  shift the read history down.
    //

    PrivateCacheMap->FileOffset1 = PrivateCacheMap->FileOffset2;
    PrivateCacheMap->BeyondLastByte1 = PrivateCacheMap->BeyondLastByte2;
    PrivateCacheMap->FileOffset2 = *FileOffset;
    PrivateCacheMap->BeyondLastByte2.QuadPart =
                                FileOffset->QuadPart + (LONGLONG)OriginalLength;

    IoStatus->Status = STATUS_SUCCESS;
    IoStatus->Information = OriginalLength;

    DebugTrace(-1, me, "CcCopyRead -> TRUE\n", 0 );

    return TRUE;
}


VOID
CcFastCopyRead (
    IN PFILE_OBJECT FileObject,
    IN ULONG FileOffset,
    IN ULONG Length,
    IN ULONG PageCount,
    OUT PVOID Buffer,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine attempts to copy the specified file data from the cache
    into the output buffer, and deliver the correct I/O status.

    This is a faster version of CcCopyRead which only supports 32-bit file
    offsets and synchronicity (Wait = TRUE).

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    PageCount - Number of pages spanned by the read.

    Buffer - Pointer to output buffer to which data should be copied.

    IoStatus - Pointer to standard I/O status block to receive the status
               for the transfer.  (STATUS_SUCCESS guaranteed for cache
               hits, otherwise the actual I/O status is returned.)

               Note that even if FALSE is returned, the IoStatus.Information
               field will return the count of any bytes successfully
               transferred before a blocking condition occured.  The caller
               may either choose to ignore this information, or resume
               the copy later accounting for bytes transferred.

Return Value:

    None

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PVACB Vacb;
    PVACB ActiveVacb;
    ULONG ActivePage;
    ULONG PageIsDirty;
    ULONG SavedState;
    ULONG PagesToGo;
    ULONG MoveLength;
    ULONG LengthToGo;
    NTSTATUS Status;
    LARGE_INTEGER OriginalOffset;
    ULONG OriginalLength = Length;
    PETHREAD Thread = PsGetCurrentThread();
    ULONG GotAMiss = 0;

    UNREFERENCED_PARAMETER (PageCount);

    DebugTrace(+1, me, "CcFastCopyRead\n", 0 );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  Get pointer to shared and private cache maps
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    PrivateCacheMap = FileObject->PrivateCacheMap;

    //
    //  Check for read past file size, the caller must filter this case out.
    //

    ASSERT( (FileOffset + Length) <= SharedCacheMap->FileSize.LowPart );

    //
    //  If read ahead is enabled, then do the read ahead here so it
    //  overlaps with the copy (otherwise we will do it below).
    //  Note that we are assuming that we will not get ahead of our
    //  current transfer - if read ahead is working it should either
    //  already be in memory or else underway.
    //

    OriginalOffset.LowPart = FileOffset;
    OriginalOffset.HighPart = 0;

    if (PrivateCacheMap->Flags.ReadAheadEnabled && (PrivateCacheMap->ReadAheadLength[1] == 0)) {
        CcScheduleReadAhead( FileObject, &OriginalOffset, Length );
    }

    //
    //  This is not an exact solution, but when IoPageRead gets a miss,
    //  it cannot tell whether it was CcCopyRead or CcMdlRead, but since
    //  the miss should occur very soon, by loading the pointer here
    //  probably the right counter will get incremented, and in any case,
    //  we hope the errrors average out!
    //

    CcMissCounter = &CcCopyReadWaitMiss;

    //
    //  Increment performance counters
    //

    HOT_STATISTIC(CcCopyReadWait) += 1;

    //
    //  See if we have an active Vacb, that we can just copy to.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    if (ActiveVacb != NULL) {

        if ((FileOffset >> VACB_OFFSET_SHIFT) == (ActivePage >> (VACB_OFFSET_SHIFT - PAGE_SHIFT))) {

            ULONG LengthToCopy = VACB_MAPPING_GRANULARITY - (FileOffset & (VACB_MAPPING_GRANULARITY - 1));

            if (SharedCacheMap->NeedToZero != NULL) {
                CcFreeActiveVacb( SharedCacheMap, NULL, 0, FALSE );
            }

            //
            //  Get the starting point in the view.
            //

            CacheBuffer = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                          (FileOffset & (VACB_MAPPING_GRANULARITY - 1)));

            //
            //  Reduce LengthToCopy if it is greater than our caller's length.
            //

            if (LengthToCopy > Length) {
                LengthToCopy = Length;
            }

            //
            //  Like the logic for the normal case below, we want to spin around
            //  making sure Mm only reads the pages we will need.
            //
            
            PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                               LengthToCopy ) - 1;

            //
            //  Copy the data to the user buffer.
            //

            try {

                if (PagesToGo != 0) {
    
                    LengthToGo = LengthToCopy;
    
                    while (LengthToGo != 0) {
    
                        MoveLength = (ULONG)((PCHAR)(ROUND_TO_PAGES(((PCHAR)CacheBuffer + 1))) -
                                     (PCHAR)CacheBuffer);
    
                        if (MoveLength > LengthToGo) {
                            MoveLength = LengthToGo;
                        }
    
                        //
                        //  Here's hoping that it is cheaper to call Mm to see if
                        //  the page is valid.  If not let Mm know how many pages
                        //  we are after before doing the move.
                        //
    
                        MmSetPageFaultReadAhead( Thread, PagesToGo );
                        GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );
    
                        RtlCopyBytes( Buffer, CacheBuffer, MoveLength );
    
                        PagesToGo -= 1;
    
                        LengthToGo -= MoveLength;
                        Buffer = (PCHAR)Buffer + MoveLength;
                        CacheBuffer = (PCHAR)CacheBuffer + MoveLength;
                    }
    
                //
                //  Handle the read here that stays on a single page.
                //
    
                } else {
    
                    //
                    //  Here's hoping that it is cheaper to call Mm to see if
                    //  the page is valid.  If not let Mm know how many pages
                    //  we are after before doing the move.
                    //
    
                    MmSetPageFaultReadAhead( Thread, 0 );
                    GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );
    
                    RtlCopyBytes( Buffer, CacheBuffer, LengthToCopy );
    
                    Buffer = (PCHAR)Buffer + LengthToCopy;
                }
                
            } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                 &Status ) ) {

                MmResetPageFaultReadAhead( Thread, SavedState );


                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

                //
                //  If we got an access violation, then the user buffer went
                //  away.  Otherwise we must have gotten an I/O error trying
                //  to bring the data in.
                //

                if (Status == STATUS_ACCESS_VIOLATION) {
                    ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                }
                else {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }
            }

            //
            //  Now adjust FileOffset and Length by what we copied.
            //

            FileOffset += LengthToCopy;
            Length -= LengthToCopy;
        }

        //
        //  If that was all the data, then remember the Vacb
        //

        if (Length == 0) {

            SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

        //
        //  Otherwise we must free it because we will map other vacbs below.
        //

        } else {

            CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
        }
    }

    //
    //  Not all of the transfer will come back at once, so we have to loop
    //  until the entire transfer is complete.
    //

    FOffset.HighPart = 0;
    FOffset.LowPart = FileOffset;

    while (Length != 0) {

        ULONG ReceivedLength;
        ULONG BeyondLastByte;

        //
        //  Call local routine to Map or Access the file data, then move the data,
        //  then call another local routine to free the data.  If we cannot map
        //  the data because of a Wait condition, return FALSE.
        //
        //  Note that this call may result in an exception, however, if it
        //  does no Bcb is returned and this routine has absolutely no
        //  cleanup to perform.  Therefore, we do not have a try-finally
        //  and we allow the possibility that we will simply be unwound
        //  without notice.
        //

        CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                           FOffset,
                                           &Vacb,
                                           &ReceivedLength );

        BeyondLastByte = FOffset.LowPart + ReceivedLength;

        //
        //  If we got more than we need, make sure to only transfer
        //  the right amount.
        //

        if (ReceivedLength > Length) {
            ReceivedLength = Length;
        }

        //
        //  It is possible for the user buffer to become no longer accessible
        //  since it was last checked by the I/O system.  If we fail to access
        //  the buffer we must raise a status that the caller's exception
        //  filter considers as "expected".  Also we unmap the Bcb here, since
        //  we otherwise would have no other reason to put a try-finally around
        //  this loop.
        //

        try {

            PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                               ReceivedLength ) - 1;

            //
            //  We know exactly how much we want to read here, and we do not
            //  want to read any more in case the caller is doing random access.
            //  Our read ahead logic takes care of detecting sequential reads,
            //  and tends to do large asynchronous read aheads.  So far we have
            //  only mapped the data and we have not forced any in.  What we
            //  do now is get into a loop where we copy a page at a time and
            //  just prior to each move, we tell MM how many additional pages
            //  we would like to have read in, in the event that we take a
            //  fault.  With this strategy, for cache hits we never make a single
            //  expensive call to MM to guarantee that the data is in, yet if we
            //  do take a fault, we are guaranteed to only take one fault because
            //  we will read all of the data in for the rest of the transfer.
            //
            //  We test first for the multiple page case, to keep the small
            //  reads faster.
            //

            if (PagesToGo != 0) {

                LengthToGo = ReceivedLength;

                while (LengthToGo != 0) {

                    MoveLength = (ULONG)((PCHAR)(ROUND_TO_PAGES(((PCHAR)CacheBuffer + 1))) -
                                 (PCHAR)CacheBuffer);

                    if (MoveLength > LengthToGo) {
                        MoveLength = LengthToGo;
                    }

                    //
                    //  Here's hoping that it is cheaper to call Mm to see if
                    //  the page is valid.  If not let Mm know how many pages
                    //  we are after before doing the move.
                    //

                    MmSetPageFaultReadAhead( Thread, PagesToGo );
                    GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );

                    RtlCopyBytes( Buffer, CacheBuffer, MoveLength );

                    PagesToGo -= 1;

                    LengthToGo -= MoveLength;
                    Buffer = (PCHAR)Buffer + MoveLength;
                    CacheBuffer = (PCHAR)CacheBuffer + MoveLength;
                }

            //
            //  Handle the read here that stays on a single page.
            //

            } else {

                //
                //  Here's hoping that it is cheaper to call Mm to see if
                //  the page is valid.  If not let Mm know how many pages
                //  we are after before doing the move.
                //

                MmSetPageFaultReadAhead( Thread, 0 );
                GotAMiss |= !MmCheckCachedPageState( CacheBuffer, FALSE );

                RtlCopyBytes( Buffer, CacheBuffer, ReceivedLength );

                Buffer = (PCHAR)Buffer + ReceivedLength;
            }
        }
        except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                           &Status ) ) {

            CcMissCounter = &CcThrowAway;

            //
            //  If we get an exception, then we have to renable page fault
            //  clustering and unmap on the way out.
            //

            MmResetPageFaultReadAhead( Thread, SavedState );


            CcFreeVirtualAddress( Vacb );

            //
            //  If we got an access violation, then the user buffer went
            //  away.  Otherwise we must have gotten an I/O error trying
            //  to bring the data in.
            //

            if (Status == STATUS_ACCESS_VIOLATION) {
                ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
            }
            else {
                ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                       STATUS_UNEXPECTED_IO_ERROR ));
            }
        }

        //
        //  Update number of bytes transferred.
        //

        Length -= ReceivedLength;

        //
        //  Unmap the data now, and calculate length left to transfer.
        //

        if (Length != 0) {

            //
            //  If there is more to go, just free this vacb.
            //

            CcFreeVirtualAddress( Vacb );

        } else {

            //
            //  Otherwise save it for the next time through.
            //

            SetActiveVacb( SharedCacheMap, OldIrql, Vacb, (FOffset.LowPart >> PAGE_SHIFT), 0 );
            break;
        }

        //
        //  Assume we did not get all the data we wanted, and set FOffset
        //  to the end of the returned data.
        //

        FOffset.LowPart = BeyondLastByte;
    }

    MmResetPageFaultReadAhead( Thread, SavedState );

    CcMissCounter = &CcThrowAway;

    //
    //  Now enable read ahead if it looks like we got any misses, and do
    //  the first one.
    //

    if (GotAMiss &&
        !FlagOn( FileObject->Flags, FO_RANDOM_ACCESS ) &&
        !PrivateCacheMap->Flags.ReadAheadEnabled) {

        CC_SET_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);
        CcScheduleReadAhead( FileObject, &OriginalOffset, OriginalLength );
    }

    //
    //  Now that we have described our desired read ahead, let's
    //  shift the read history down.
    //

    PrivateCacheMap->FileOffset1.LowPart = PrivateCacheMap->FileOffset2.LowPart;
    PrivateCacheMap->BeyondLastByte1.LowPart = PrivateCacheMap->BeyondLastByte2.LowPart;
    PrivateCacheMap->FileOffset2.LowPart = OriginalOffset.LowPart;
    PrivateCacheMap->BeyondLastByte2.LowPart = OriginalOffset.LowPart + OriginalLength;

    IoStatus->Status = STATUS_SUCCESS;
    IoStatus->Information = OriginalLength;

    DebugTrace(-1, me, "CcFastCopyRead -> VOID\n", 0 );
}


BOOLEAN
CcCopyWrite (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN Wait,
    IN PVOID Buffer
    )

/*++

Routine Description:

    This routine attempts to copy the specified file data from the specified
    buffer into the Cache, and deliver the correct I/O status.  It is *not*
    safe to call this routine from Dpc level.

    If the caller does not want to block (such as for disk I/O), then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to receive all of the requested data without
    blocking, then this routine will return FALSE.  However, if the
    correct space is immediately accessible in the cache and no blocking is
    required, this routine copies the data and returns TRUE.

    If the caller supplies Wait as TRUE, then this routine is guaranteed
    to copy the data and return TRUE.  If the correct space is immediately
    accessible in the cache, then no blocking will occur.  Otherwise,
    the necessary work will be initiated to read and/or free cache data,
    and the caller will be blocked until the data can be received.

    File system Fsd's should typically supply Wait = TRUE if they are
    processing a synchronous I/O requests, or Wait = FALSE if they are
    processing an asynchronous request.

    File system or Server Fsp threads should supply Wait = TRUE.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file to receive the data.

    Length - Length of data in bytes.

    Wait - FALSE if caller may not block, TRUE otherwise (see description
           above)

    Buffer - Pointer to input buffer from which data should be copied.

Return Value:

    FALSE - if Wait was supplied as FALSE and the data was not copied.

    TRUE - if the data has been copied.

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.
        This can only occur if Wait was specified as TRUE.  (If Wait is
        specified as FALSE, and an allocation failure occurs, this
        routine simply returns FALSE.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PFSRTL_ADVANCED_FCB_HEADER FcbHeader;
    PVACB ActiveVacb;
    ULONG ActivePage;
    PVOID ActiveAddress;
    ULONG PageIsDirty;
    KIRQL OldIrql;
    NTSTATUS Status;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PBCB Bcb;
    ULONG ZeroFlags;
    LARGE_INTEGER Temp;

    DebugTrace(+1, me, "CcCopyWrite\n", 0 );

    //
    //  If the caller specified Wait == FALSE, but the FileObject is WriteThrough,
    //  then we need to just get out.
    //

    if ((FileObject->Flags & FO_WRITE_THROUGH) && !Wait) {

        DebugTrace(-1, me, "CcCopyWrite->FALSE (WriteThrough && !Wait)\n", 0 );

        return FALSE;
    }

    //
    //  Get pointer to shared cache map
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    FOffset = *FileOffset;

    //
    //  See if we have an active Vacb, that we can just copy to.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    if (ActiveVacb != NULL) {

        //
        //  See if the request starts in the ActivePage.  WriteThrough requests must
        //  go the longer route through CcMapAndCopy, where WriteThrough flushes are
        //  implemented.
        //

        if (((ULONG)(FOffset.QuadPart >> PAGE_SHIFT) == ActivePage) && (Length != 0) &&
            !FlagOn( FileObject->Flags, FO_WRITE_THROUGH )) {

            ULONG LengthToCopy = PAGE_SIZE - (FOffset.LowPart & (PAGE_SIZE - 1));

            //
            //  Reduce LengthToCopy if it is greater than our caller's length.
            //

            if (LengthToCopy > Length) {
                LengthToCopy = Length;
            }

            //
            //  Copy the data to the user buffer.
            //

            try {

                //
                //  If we are copying to a page that is locked down, then
                //  we have to do it under our spinlock, and update the
                //  NeedToZero field.
                //

                OldIrql = 0xFF;

                CacheBuffer = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                      (FOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1)));

                if (SharedCacheMap->NeedToZero != NULL) {

                    //
                    //  The FastLock may not write our "flag".
                    //

                    OldIrql = 0;

                    ExAcquireFastLock( &SharedCacheMap->ActiveVacbSpinLock, &OldIrql );

                    //
                    //  Note that the NeedToZero could be cleared, since we
                    //  tested it without the spinlock.
                    //

                    ActiveAddress = SharedCacheMap->NeedToZero;
                    if ((ActiveAddress != NULL) &&
                        (ActiveVacb == SharedCacheMap->NeedToZeroVacb) &&
                        (((PCHAR)CacheBuffer + LengthToCopy) > (PCHAR)ActiveAddress)) {

                        //
                        //  If we are skipping some bytes in the page, then we need
                        //  to zero them.
                        //

                        if ((PCHAR)CacheBuffer > (PCHAR)ActiveAddress) {

                            RtlZeroMemory( ActiveAddress, (PCHAR)CacheBuffer - (PCHAR)ActiveAddress );
                        }
                        SharedCacheMap->NeedToZero = (PVOID)((PCHAR)CacheBuffer + LengthToCopy);
                    }

                    ExReleaseFastLock( &SharedCacheMap->ActiveVacbSpinLock, OldIrql );
                }

                RtlCopyBytes( CacheBuffer, Buffer, LengthToCopy );

            } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                 &Status ) ) {

                //
                //  If we failed to overwrite the uninitialized data,
                //  zero it now (we cannot safely restore NeedToZero).
                //

                if (OldIrql != 0xFF) {
                    RtlZeroBytes( CacheBuffer, LengthToCopy );
                }

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, ACTIVE_PAGE_IS_DIRTY );

                //
                //  If we got an access violation, then the user buffer went
                //  away.  Otherwise we must have gotten an I/O error trying
                //  to bring the data in.
                //

                if (Status == STATUS_ACCESS_VIOLATION) {
                    ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                }
                else {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }
            }

            //
            //  Now adjust FOffset and Length by what we copied.
            //

            Buffer = (PVOID)((PCHAR)Buffer + LengthToCopy);
            FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)LengthToCopy;
            Length -= LengthToCopy;

            //
            //  If that was all the data, then get outski...
            //

            if (Length == 0) {

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, ACTIVE_PAGE_IS_DIRTY );
                return TRUE;
            }

            //
            //  Remember that the page is dirty now.
            //

            PageIsDirty |= ACTIVE_PAGE_IS_DIRTY;
        }

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

    //
    //  Else someone else could have the active page, and may want to zero
    //  the range we plan to write!
    //

    } else if (SharedCacheMap->NeedToZero != NULL) {

        CcFreeActiveVacb( SharedCacheMap, NULL, 0, FALSE );
    }

    //
    //  At this point we can calculate the ZeroFlags.
    //

    //
    //  We can always zero middle pages, if any.
    //

    ZeroFlags = ZERO_MIDDLE_PAGES;

    if (((FOffset.LowPart & (PAGE_SIZE - 1)) == 0) &&
        (Length >= PAGE_SIZE)) {
        ZeroFlags |= ZERO_FIRST_PAGE;
    }

    if (((FOffset.LowPart + Length) & (PAGE_SIZE - 1)) == 0) {
        ZeroFlags |= ZERO_LAST_PAGE;
    }

    Temp = FOffset;
    Temp.LowPart &= ~(PAGE_SIZE -1);

    //
    //  If there is an advanced header, then we can acquire the FastMutex to
    //  make capturing ValidDataLength atomic.  Currently our other file systems
    //  are either RO or do not really support 64-bits.
    //

    FcbHeader = (PFSRTL_ADVANCED_FCB_HEADER)FileObject->FsContext;
    if (FlagOn(FcbHeader->Flags, FSRTL_FLAG_ADVANCED_HEADER)) {
        ExAcquireFastMutex( FcbHeader->FastMutex );
        Temp.QuadPart = ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->ValidDataLength.QuadPart -
                        Temp.QuadPart;
        ExReleaseFastMutex( FcbHeader->FastMutex );
    } else {
        Temp.QuadPart = ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->ValidDataLength.QuadPart -
                        Temp.QuadPart;
    }

    if (Temp.QuadPart <= 0) {
        ZeroFlags |= ZERO_FIRST_PAGE | ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
    } else if ((Temp.HighPart == 0) && (Temp.LowPart <= PAGE_SIZE)) {
        ZeroFlags |= ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
    }

    //
    //  Call a routine to map and copy the data in Mm and get out.
    //

    if (Wait) {

        CcMapAndCopy( SharedCacheMap,
                      Buffer,
                      &FOffset,
                      Length,
                      ZeroFlags,
                      FileObject );

        return TRUE;
    }

    //
    //  The rest of this routine is the Wait == FALSE case.
    //
    //  Not all of the transfer will come back at once, so we have to loop
    //  until the entire transfer is complete.
    //

    while (Length != 0) {

        ULONG ReceivedLength;
        LARGE_INTEGER BeyondLastByte;

        if (!CcPinFileData( FileObject,
                            &FOffset,
                            Length,
                            FALSE,
                            TRUE,
                            FALSE,
                            &Bcb,
                            &CacheBuffer,
                            &BeyondLastByte )) {

            DebugTrace(-1, me, "CcCopyWrite -> FALSE\n", 0 );

            return FALSE;

        } else {

            //
            //  Calculate how much data is described by Bcb starting at our desired
            //  file offset.
            //

            ReceivedLength = (ULONG)(BeyondLastByte.QuadPart - FOffset.QuadPart);

            //
            //  If we got more than we need, make sure to only transfer
            //  the right amount.
            //

            if (ReceivedLength > Length) {
                ReceivedLength = Length;
            }
        }

        //
        //  It is possible for the user buffer to become no longer accessible
        //  since it was last checked by the I/O system.  If we fail to access
        //  the buffer we must raise a status that the caller's exception
        //  filter considers as "expected".  Also we unmap the Bcb here, since
        //  we otherwise would have no other reason to put a try-finally around
        //  this loop.
        //

        try {

            RtlCopyBytes( CacheBuffer, Buffer, ReceivedLength );

            CcSetDirtyPinnedData( Bcb, NULL );
            CcUnpinFileData( Bcb, FALSE, UNPIN );
        }
        except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                           &Status ) ) {

            CcUnpinFileData( Bcb, TRUE, UNPIN );

            //
            //  If we got an access violation, then the user buffer went
            //  away.  Otherwise we must have gotten an I/O error trying
            //  to bring the data in.
            //

            if (Status == STATUS_ACCESS_VIOLATION) {
                ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
            }
            else {

                ExRaiseStatus(FsRtlNormalizeNtstatus( Status, STATUS_UNEXPECTED_IO_ERROR ));
            }
        }

        //
        //  Assume we did not get all the data we wanted, and set FOffset
        //  to the end of the returned data and adjust the Buffer and Length.
        //

        FOffset = BeyondLastByte;
        Buffer = (PCHAR)Buffer + ReceivedLength;
        Length -= ReceivedLength;
    }

    DebugTrace(-1, me, "CcCopyWrite -> TRUE\n", 0 );

    return TRUE;
}


VOID
CcFastCopyWrite (
    IN PFILE_OBJECT FileObject,
    IN ULONG FileOffset,
    IN ULONG Length,
    IN PVOID Buffer
    )

/*++

Routine Description:

    This routine attempts to copy the specified file data from the specified
    buffer into the Cache, and deliver the correct I/O status.

    This is a faster version of CcCopyWrite which only supports 32-bit file
    offsets and synchronicity (Wait = TRUE) and no Write Through.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file to receive the data.

    Length - Length of data in bytes.

    Buffer - Pointer to input buffer from which data should be copied.

Return Value:

    None

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.
        This can only occur if Wait was specified as TRUE.  (If Wait is
        specified as FALSE, and an allocation failure occurs, this
        routine simply returns FALSE.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID CacheBuffer;
    PVACB ActiveVacb;
    ULONG ActivePage;
    PVOID ActiveAddress;
    ULONG PageIsDirty;
    KIRQL OldIrql;
    NTSTATUS Status;
    ULONG ZeroFlags;
    ULONG ValidDataLength;
    LARGE_INTEGER FOffset;

    DebugTrace(+1, me, "CcFastCopyWrite\n", 0 );

    //
    //  Get pointer to shared cache map and a copy of valid data length
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  See if we have an active Vacb, that we can just copy to.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    if (ActiveVacb != NULL) {

        //
        //  See if the request starts in the ActivePage.  WriteThrough requests must
        //  go the longer route through CcMapAndCopy, where WriteThrough flushes are
        //  implemented.
        //

        if (((FileOffset >> PAGE_SHIFT) == ActivePage) && (Length != 0) &&
            !FlagOn( FileObject->Flags, FO_WRITE_THROUGH )) {

            ULONG LengthToCopy = PAGE_SIZE - (FileOffset & (PAGE_SIZE - 1));

            //
            //  Reduce LengthToCopy if it is greater than our caller's length.
            //

            if (LengthToCopy > Length) {
                LengthToCopy = Length;
            }

            //
            //  Copy the data to the user buffer.
            //

            try {

                //
                //  If we are copying to a page that is locked down, then
                //  we have to do it under our spinlock, and update the
                //  NeedToZero field.
                //

                OldIrql = 0xFF;

                CacheBuffer = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                      (FileOffset & (VACB_MAPPING_GRANULARITY - 1)));

                if (SharedCacheMap->NeedToZero != NULL) {

                    //
                    //  The FastLock may not write our "flag".
                    //

                    OldIrql = 0;

                    ExAcquireFastLock( &SharedCacheMap->ActiveVacbSpinLock, &OldIrql );

                    //
                    //  Note that the NeedToZero could be cleared, since we
                    //  tested it without the spinlock.
                    //

                    ActiveAddress = SharedCacheMap->NeedToZero;
                    if ((ActiveAddress != NULL) &&
                        (ActiveVacb == SharedCacheMap->NeedToZeroVacb) &&
                        (((PCHAR)CacheBuffer + LengthToCopy) > (PCHAR)ActiveAddress)) {

                        //
                        //  If we are skipping some bytes in the page, then we need
                        //  to zero them.
                        //

                        if ((PCHAR)CacheBuffer > (PCHAR)ActiveAddress) {

                            RtlZeroMemory( ActiveAddress, (PCHAR)CacheBuffer - (PCHAR)ActiveAddress );
                        }
                        SharedCacheMap->NeedToZero = (PVOID)((PCHAR)CacheBuffer + LengthToCopy);
                    }

                    ExReleaseFastLock( &SharedCacheMap->ActiveVacbSpinLock, OldIrql );
                }

                RtlCopyBytes( CacheBuffer, Buffer, LengthToCopy );

            } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                 &Status ) ) {

                //
                //  If we failed to overwrite the uninitialized data,
                //  zero it now (we cannot safely restore NeedToZero).
                //

                if (OldIrql != 0xFF) {
                    RtlZeroBytes( CacheBuffer, LengthToCopy );
                }

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, ACTIVE_PAGE_IS_DIRTY );

                //
                //  If we got an access violation, then the user buffer went
                //  away.  Otherwise we must have gotten an I/O error trying
                //  to bring the data in.
                //

                if (Status == STATUS_ACCESS_VIOLATION) {
                    ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                }
                else {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }
            }

            //
            //  Now adjust FileOffset and Length by what we copied.
            //

            Buffer = (PVOID)((PCHAR)Buffer + LengthToCopy);
            FileOffset += LengthToCopy;
            Length -= LengthToCopy;

            //
            //  If that was all the data, then get outski...
            //

            if (Length == 0) {

                SetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, ACTIVE_PAGE_IS_DIRTY );
                return;
            }

            //
            //  Remember that the page is dirty now.
            //

            PageIsDirty |= ACTIVE_PAGE_IS_DIRTY;
        }

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

    //
    //  Else someone else could have the active page, and may want to zero
    //  the range we plan to write!
    //

    } else if (SharedCacheMap->NeedToZero != NULL) {

        CcFreeActiveVacb( SharedCacheMap, NULL, 0, FALSE );
    }

    //
    //  Set up for call to CcMapAndCopy
    //

    FOffset.LowPart = FileOffset;
    FOffset.HighPart = 0;

    ValidDataLength = ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->ValidDataLength.LowPart;

    ASSERT((ValidDataLength == MAXULONG) ||
           (((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->ValidDataLength.HighPart == 0));

    //
    //  At this point we can calculate the ReadOnly flag for
    //  the purposes of whether to use the Bcb resource, and
    //  we can calculate the ZeroFlags.
    //

    //
    //  We can always zero middle pages, if any.
    //

    ZeroFlags = ZERO_MIDDLE_PAGES;

    if (((FileOffset & (PAGE_SIZE - 1)) == 0) &&
        (Length >= PAGE_SIZE)) {
        ZeroFlags |= ZERO_FIRST_PAGE;
    }

    if (((FileOffset + Length) & (PAGE_SIZE - 1)) == 0) {
        ZeroFlags |= ZERO_LAST_PAGE;
    }

    if ((FileOffset & ~(PAGE_SIZE - 1)) >= ValidDataLength) {
        ZeroFlags |= ZERO_FIRST_PAGE | ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
    } else if (((FileOffset & ~(PAGE_SIZE - 1)) + PAGE_SIZE) >= ValidDataLength) {
        ZeroFlags |= ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
    }

    //
    //  Call a routine to map and copy the data in Mm and get out.
    //

    CcMapAndCopy( SharedCacheMap,
                  Buffer,
                  &FOffset,
                  Length,
                  ZeroFlags,
                  FileObject );

    DebugTrace(-1, me, "CcFastCopyWrite -> VOID\n", 0 );
}


LONG
CcCopyReadExceptionFilter(
    IN PEXCEPTION_POINTERS ExceptionPointer,
    IN PNTSTATUS ExceptionCode
    )

/*++

Routine Description:

    This routine serves as a exception filter and has the special job of
    extracting the "real" I/O error when Mm raises STATUS_IN_PAGE_ERROR
    beneath us.

Arguments:

    ExceptionPointer - A pointer to the exception record that contains
                       the real Io Status.

    ExceptionCode - A pointer to an NTSTATUS that is to receive the real
                    status.

Return Value:

    EXCEPTION_EXECUTE_HANDLER

--*/

{
    *ExceptionCode = ExceptionPointer->ExceptionRecord->ExceptionCode;

    if ( (*ExceptionCode == STATUS_IN_PAGE_ERROR) &&
         (ExceptionPointer->ExceptionRecord->NumberParameters >= 3) ) {

        *ExceptionCode = (NTSTATUS) ExceptionPointer->ExceptionRecord->ExceptionInformation[2];
    }

    ASSERT( !NT_SUCCESS(*ExceptionCode) );

    return EXCEPTION_EXECUTE_HANDLER;
}


BOOLEAN
CcCanIWrite (
    IN PFILE_OBJECT FileObject,
    IN ULONG BytesToWrite,
    IN BOOLEAN Wait,
    IN UCHAR Retrying
    )

/*++

Routine Description:

    This routine tests whether it is ok to do a write to the cache
    or not, according to the Thresholds of dirty bytes and available
    pages.  The first time this routine is called for a request (Retrying
    FALSE), we automatically make the new request queue if there are other
    requests in the queue.

    Note that the ListEmpty test is important to prevent small requests from sneaking
    in and starving large requests.

Arguments:

    FileObject - for the file to be written

    BytesToWrite - Number of bytes caller wishes to write to the Cache.

    Wait - TRUE if the caller owns no resources, and can block inside this routine
           until it is ok to write.

    Retrying - Specified as FALSE when the request is first received, and
               otherwise specified as TRUE if this write has already entered
               the queue.  Special non-zero value of MAXUCHAR indicates that
               we were called within the cache manager with a MasterSpinLock held,
               so do not attempt to acquire it here.  MAXUCHAR - 1 means we
               were called within the Cache Manager with some other spinlock
               held.  MAXUCHAR - 2 means we want to enforce throttling, even if
               the file object is flagged as being of remote origin.  For either
               of the first two special values, we do not touch the FsRtl header.

Return Value:

    TRUE if it is ok to write.
    FALSE if the caller should defer the write via a call to CcDeferWrite.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    KEVENT Event;
    KIRQL OldIrql;
    ULONG PagesToWrite;
    BOOLEAN ExceededPerFileThreshold;
    DEFERRED_WRITE DeferredWrite;
    PSECTION_OBJECT_POINTERS SectionObjectPointers;

    //
    //  If this file is writethrough or of remote origin, exempt it from throttling
    //  and let it write.  We do this under the assumption that it has been throttled
    //  at the remote location and we do not want to block it here.  If we were called
    //  with Retrying set to MAXUCHAR - 2, enforce the throttle regardless of the
    //  file object origin (see above).
    //

    if (BooleanFlagOn( FileObject->Flags, FO_WRITE_THROUGH)) {

        return TRUE;
    } 
    
    //
    //  Do a special test here for file objects that keep track of dirty
    //  pages on a per-file basis.  This is used mainly for slow links.
    //

    ExceededPerFileThreshold = FALSE;

    PagesToWrite = ((BytesToWrite < WRITE_CHARGE_THRESHOLD ?
                     BytesToWrite : WRITE_CHARGE_THRESHOLD) + (PAGE_SIZE - 1)) / PAGE_SIZE;

    //
    //  Don't dereference the FsContext field if we were called while holding
    //  a spinlock.
    //

    if ((Retrying >= MAXUCHAR - 1) ||

        FlagOn(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
               FSRTL_FLAG_LIMIT_MODIFIED_PAGES)) {

        if (Retrying != MAXUCHAR) {
            CcAcquireMasterLock( &OldIrql );
        }

        if (((SectionObjectPointers = FileObject->SectionObjectPointer) != NULL) &&
            ((SharedCacheMap = SectionObjectPointers->SharedCacheMap) != NULL) &&
            (SharedCacheMap->DirtyPageThreshold != 0) &&
            (SharedCacheMap->DirtyPages != 0) &&
            ((PagesToWrite + SharedCacheMap->DirtyPages) >
              SharedCacheMap->DirtyPageThreshold)) {

            ExceededPerFileThreshold = TRUE;
        }

        if (Retrying != MAXUCHAR) {
            CcReleaseMasterLock( OldIrql );
        }
    }

    //
    //  See if it is ok to do the write right now
    //

    if ((Retrying || IsListEmpty(&CcDeferredWrites))

                &&

        (CcTotalDirtyPages + PagesToWrite < CcDirtyPageThreshold)

                &&

        MmEnoughMemoryForWrite()

                &&

        !ExceededPerFileThreshold) {

        return TRUE;
    }

    //
    //  Otherwise, if our caller is synchronous, we will just wait here.
    //

    if (Wait) {

        if (IsListEmpty(&CcDeferredWrites) ) {

            //
            // Get a write scan to occur NOW
            //

            CcAcquireMasterLock( &OldIrql );
            CcScheduleLazyWriteScan( TRUE );
            CcReleaseMasterLock( OldIrql );
        }
    
        KeInitializeEvent( &Event, NotificationEvent, FALSE );

        //
        //  Fill in the block.  Note that we can access the Fsrtl Common Header
        //  even if it's paged because Wait will be FALSE if called from
        //  within the cache.
        //

        DeferredWrite.NodeTypeCode = CACHE_NTC_DEFERRED_WRITE;
        DeferredWrite.NodeByteSize = sizeof(DEFERRED_WRITE);
        DeferredWrite.FileObject = FileObject;
        DeferredWrite.BytesToWrite = BytesToWrite;
        DeferredWrite.Event = &Event;
        DeferredWrite.LimitModifiedPages = BooleanFlagOn(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
                                                         FSRTL_FLAG_LIMIT_MODIFIED_PAGES);

        //
        //  Now insert at the appropriate end of the list
        //

        if (Retrying) {
            ExInterlockedInsertHeadList( &CcDeferredWrites,
                                         &DeferredWrite.DeferredWriteLinks,
                                         &CcDeferredWriteSpinLock );
        } else {
            ExInterlockedInsertTailList( &CcDeferredWrites,
                                         &DeferredWrite.DeferredWriteLinks,
                                         &CcDeferredWriteSpinLock );
        }

        while (TRUE) {

            //
            //  Now since we really didn't synchronize anything but the insertion,
            //  we call the post routine to make sure that in some wierd case we
            //  do not leave anyone hanging with no dirty bytes for the Lazy Writer.
            //

            CcPostDeferredWrites();

            //
            //  Finally wait until the event is signalled and we can write
            //  and return to tell the guy he can write.
            //

            if (KeWaitForSingleObject( &Event,
                                       Executive,
                                       KernelMode,
                                       FALSE,
                                       &CcIdleDelay ) == STATUS_SUCCESS) {


                return TRUE;
            }
        }

    } else {
        return FALSE;
    }
}


VOID
CcDeferWrite (
    IN PFILE_OBJECT FileObject,
    IN PCC_POST_DEFERRED_WRITE PostRoutine,
    IN PVOID Context1,
    IN PVOID Context2,
    IN ULONG BytesToWrite,
    IN BOOLEAN Retrying
    )

/*++

Routine Description:

    This routine may be called to have the Cache Manager defer posting
    of a write until the Lazy Writer makes some progress writing, or
    there are more available pages.  A file system would normally call
    this routine after receiving FALSE from CcCanIWrite, and preparing
    the request to be posted.

Arguments:

    FileObject - for the file to be written

    PostRoutine - Address of the PostRoutine that the Cache Manager can
                  call to post the request when conditions are right.  Note
                  that it is possible that this routine will be called
                  immediately from this routine.

    Context1 - First context parameter for the post routine.

    Context2 - Secont parameter for the post routine.

    BytesToWrite - Number of bytes that the request is trying to write
                   to the cache.

    Retrying - Supplied as FALSE if the request is being posted for the
               first time, TRUE otherwise.

Return Value:

    None

--*/

{
    PDEFERRED_WRITE DeferredWrite;
    KIRQL OldIrql;

    //
    //  Attempt to allocate a deferred write block, and if we do not get
    //  one, just post it immediately rather than gobbling up must succeed
    //  pool.
    //

    DeferredWrite = ExAllocatePoolWithTag( NonPagedPool, sizeof(DEFERRED_WRITE), 'wDcC' );

    if (DeferredWrite == NULL) {
        (*PostRoutine)( Context1, Context2 );
        return;
    }

    //
    //  Fill in the block.
    //

    DeferredWrite->NodeTypeCode = CACHE_NTC_DEFERRED_WRITE;
    DeferredWrite->NodeByteSize = sizeof(DEFERRED_WRITE);
    DeferredWrite->FileObject = FileObject;
    DeferredWrite->BytesToWrite = BytesToWrite;
    DeferredWrite->Event = NULL;
    DeferredWrite->PostRoutine = PostRoutine;
    DeferredWrite->Context1 = Context1;
    DeferredWrite->Context2 = Context2;
    DeferredWrite->LimitModifiedPages = BooleanFlagOn(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
                                                      FSRTL_FLAG_LIMIT_MODIFIED_PAGES);

    //
    //  Now insert at the appropriate end of the list
    //

    if (Retrying) {
        ExInterlockedInsertHeadList( &CcDeferredWrites,
                                     &DeferredWrite->DeferredWriteLinks,
                                     &CcDeferredWriteSpinLock );
    } else {
        ExInterlockedInsertTailList( &CcDeferredWrites,
                                     &DeferredWrite->DeferredWriteLinks,
                                     &CcDeferredWriteSpinLock );
    }

    //
    //  Now since we really didn't synchronize anything but the insertion,
    //  we call the post routine to make sure that in some wierd case we
    //  do not leave anyone hanging with no dirty bytes for the Lazy Writer.
    //

    CcPostDeferredWrites();

    //
    //  Schedule the lazy writer in case the reason we're blocking
    //  is that we're waiting for Mm (or some other external flag)
    //  to lower and let this write happen.  He will be the one to
    //  keep coming back and checking if this can proceed, even if
    //  there are no cache manager pages to write.
    //
            
    CcAcquireMasterLock( &OldIrql);
            
    if (!LazyWriter.ScanActive) {
        CcScheduleLazyWriteScan( FALSE );
    }

    CcReleaseMasterLock( OldIrql);
}


VOID
CcPostDeferredWrites (
    )

/*++

Routine Description:

    This routine may be called to see if any deferred writes should be posted
    now, and to post them.  It should be called any time the status of the
    queue may have changed, such as when a new entry has been added, or the
    Lazy Writer has finished writing out buffers and set them clean.

Arguments:

    None

Return Value:

    None

--*/

{
    PDEFERRED_WRITE DeferredWrite;
    ULONG TotalBytesLetLoose = 0;
    KIRQL OldIrql;

    do {

        //
        //  Initially clear the deferred write structure pointer
        //  and syncrhronize.
        //

        DeferredWrite = NULL;

        ExAcquireSpinLock( &CcDeferredWriteSpinLock, &OldIrql );

        //
        //  If the list is empty we are done.
        //

        if (!IsListEmpty(&CcDeferredWrites)) {

            PLIST_ENTRY Entry;

            Entry = CcDeferredWrites.Flink;

            while (Entry != &CcDeferredWrites) {

                DeferredWrite = CONTAINING_RECORD( Entry,
                                                   DEFERRED_WRITE,
                                                   DeferredWriteLinks );

                //
                //  Check for a paranoid case here that TotalBytesLetLoose
                //  wraps.  We stop processing the list at this time.
                //

                TotalBytesLetLoose += DeferredWrite->BytesToWrite;

                if (TotalBytesLetLoose < DeferredWrite->BytesToWrite) {

                    DeferredWrite = NULL;
                    break;
                }

                //
                //  If it is now ok to post this write, remove him from
                //  the list.
                //

                if (CcCanIWrite( DeferredWrite->FileObject,
                                 TotalBytesLetLoose,
                                 FALSE,
                                 MAXUCHAR - 1 )) {

                    RemoveEntryList( &DeferredWrite->DeferredWriteLinks );
                    break;

                //
                //  Otherwise, it is time to stop processing the list, so
                //  we clear the pointer again unless we throttled this item
                //  because of a private dirty page limit.
                //

                } else {

                    //
                    //  If this was a private throttle, skip over it and
                    //  remove its byte count from the running total.
                    //

                    if (DeferredWrite->LimitModifiedPages) {

                        Entry = Entry->Flink;
                        TotalBytesLetLoose -= DeferredWrite->BytesToWrite;
                        DeferredWrite = NULL;
                        continue;

                    } else {

                        DeferredWrite = NULL;

                        break;
                    }
                }
            }
        }

        ExReleaseSpinLock( &CcDeferredWriteSpinLock, OldIrql );

        //
        //  If we got something, set the event or call the post routine
        //  and deallocate the structure.
        //

        if (DeferredWrite != NULL) {

            if (DeferredWrite->Event != NULL) {

                KeSetEvent( DeferredWrite->Event, 0, FALSE );

            } else {

                (*DeferredWrite->PostRoutine)( DeferredWrite->Context1,
                                               DeferredWrite->Context2 );
                ExFreePool( DeferredWrite );
            }
        }

    //
    //  Loop until we find no more work to do.
    //

    } while (DeferredWrite != NULL);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\fssup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    fssup.c

Abstract:

    This module implements the File System support routines for the
    Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  The Bug check file id for this module
//

#define BugCheckFileId                   (CACHE_BUG_CHECK_FSSUP)

//
//  Define our debug constant
//

#define me 0x00000001

//
//  For your debugging pleasure, if the flag doesn't move!  (Currently not used)
//

#define IsSyscacheFile(FO) (((FO) != NULL) &&                                               \
                            (*(PUSHORT)(FO)->FsContext == 0X705) &&                         \
                            FlagOn(*(PULONG)((PCHAR)(FO)->FsContext + 0x48), 0x80000000))

extern POBJECT_TYPE IoFileObjectType;
extern ULONG MmLargeSystemCache;

VOID
CcUnmapAndPurge(
    IN PSHARED_CACHE_MAP SharedCacheMap
    );

VOID
CcDeleteMbcb(
    IN PSHARED_CACHE_MAP SharedCacheMap
    );

VOID
CcDeleteBcbs (
    IN PSHARED_CACHE_MAP SharedCacheMap
    );

VOID
CcPurgeAndClearCacheSection (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CcInitializeCacheManager)
#pragma alloc_text(PAGE,CcZeroData)
#endif


BOOLEAN
CcInitializeCacheManager (
    )

/*++

Routine Description:

    This routine must be called during system initialization before the
    first call to any file system, to allow the Cache Manager to initialize
    its global data structures.  This routine has no dependencies on other
    system components being initialized.

Arguments:

    None

Return Value:

    TRUE if initialization was successful

--*/

{
    CLONG i;
    ULONG Index;
    PGENERAL_LOOKASIDE Lookaside;
    USHORT NumberOfItems;
    PKPRCB Prcb;
    PWORK_QUEUE_ITEM WorkItem;

#ifdef CCDBG_LOCK
    KeInitializeSpinLock( &CcDebugTraceLock );
#endif

#if DBG
    CcBcbCount = 0;
    InitializeListHead( &CcBcbList );
#endif

    //
    //  Figure out the timeout clock tick for the lazy writer.
    //

    CcIdleDelayTick = LAZY_WRITER_IDLE_DELAY / KeQueryTimeIncrement();

    //
    //  Initialize shared cache map list structures
    //

    InitializeListHead( &CcCleanSharedCacheMapList );
    InitializeListHead( &CcDirtySharedCacheMapList.SharedCacheMapLinks );
    CcDirtySharedCacheMapList.Flags = IS_CURSOR;
    InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                    &CcLazyWriterCursor.SharedCacheMapLinks );
    CcLazyWriterCursor.Flags = IS_CURSOR;

    //
    //  Initialize worker thread structures
    //

    InitializeListHead( &CcIdleWorkerThreadList );
    InitializeListHead( &CcExpressWorkQueue );
    InitializeListHead( &CcRegularWorkQueue );
    InitializeListHead( &CcPostTickWorkQueue );

    //
    //  Set the number of worker threads based on the system size.
    //

    CcCapturedSystemSize = MmQuerySystemSize();
    if (CcNumberWorkerThreads == 0) {

        switch (CcCapturedSystemSize) {
        case MmSmallSystem:
            CcNumberWorkerThreads = ExCriticalWorkerThreads - 1;
            CcDirtyPageThreshold = MmNumberOfPhysicalPages / 8;
            CcAggressiveZeroThreshold = 1;
            break;

        case MmMediumSystem:
            CcNumberWorkerThreads = ExCriticalWorkerThreads - 1;
            CcDirtyPageThreshold = MmNumberOfPhysicalPages / 4;
            CcAggressiveZeroThreshold = 2;
            break;

        case MmLargeSystem:
            CcNumberWorkerThreads = ExCriticalWorkerThreads - 2;
            CcDirtyPageThreshold = MmNumberOfPhysicalPages / 4 +
                                    MmNumberOfPhysicalPages / 8;
            CcAggressiveZeroThreshold = 4;
            break;

        default:
            CcNumberWorkerThreads = 1;
            CcDirtyPageThreshold = MmNumberOfPhysicalPages / 8;
        }

        if (MmSystemCacheWs.MaximumWorkingSetSize > ((4*1024*1024)/PAGE_SIZE)) {
            CcDirtyPageThreshold = (ULONG)(MmSystemCacheWs.MaximumWorkingSetSize -
                                                    ((2*1024*1024)/PAGE_SIZE));
        }

        CcDirtyPageTarget = CcDirtyPageThreshold / 2 +
                            CcDirtyPageThreshold / 4;
    }

    CcAggressiveZeroCount = 0;

    //
    //  Now allocate and initialize the above number of worker thread
    //  items.
    //

    for (i = 0; i < CcNumberWorkerThreads; i++) {

        WorkItem = ExAllocatePoolWithTag( NonPagedPool, sizeof(WORK_QUEUE_ITEM), 'qWcC' );

        if (WorkItem == NULL) {

            CcBugCheck( 0, 0, 0 );
        }

        //
        //  Initialize the work queue item and insert in our queue
        //  of potential worker threads.
        //

        ExInitializeWorkItem( WorkItem, CcWorkerThread, WorkItem );
        InsertTailList( &CcIdleWorkerThreadList, &WorkItem->List );
    }

    //
    //  Initialize the Lazy Writer thread structure, and start him up.
    //

    RtlZeroMemory( &LazyWriter, sizeof(LAZY_WRITER) );

    InitializeListHead( &LazyWriter.WorkQueue );

    //
    //  Initialize the Scan Dpc and Timer.
    //

    KeInitializeDpc( &LazyWriter.ScanDpc, &CcScanDpc, NULL );
    KeInitializeTimer( &LazyWriter.ScanTimer );

    //
    //  Now initialize the lookaside list for allocating Work Queue entries.
    //

    switch ( CcCapturedSystemSize ) {

        //
        // ~512 bytes
        //

    case MmSmallSystem :
        NumberOfItems = 32;
        break;

        //
        // ~1k bytes
        //

    case MmMediumSystem :
        NumberOfItems = 64;
        break;

        //
        // ~2k bytes
        //

    case MmLargeSystem :
        NumberOfItems = 128;
        if (MmIsThisAnNtAsSystem()) {
            NumberOfItems += 128;
        }

        break;
    }

    ExInitializeSystemLookasideList( &CcTwilightLookasideList,
                                     NonPagedPool,
                                     sizeof( WORK_QUEUE_ENTRY ),
                                     'kWcC',
                                     NumberOfItems,
                                     &ExSystemLookasideListHead );

    //
    // Initialize the per processor nonpaged lookaside lists and descriptors.
    //

    for (Index = 0; Index < (ULONG)KeNumberProcessors; Index += 1) {
        Prcb = KiProcessorBlock[Index];

        //
        // Initialize the large IRP per processor lookaside pointers.
        //

        Prcb->PPLookasideList[LookasideTwilightList].L = &CcTwilightLookasideList;
        Lookaside = ExAllocatePoolWithTag( NonPagedPool,
                                           sizeof(GENERAL_LOOKASIDE),
                                           'KWcC');

        if (Lookaside != NULL) {
            ExInitializeSystemLookasideList( Lookaside,
                                             NonPagedPool,
                                             sizeof( WORK_QUEUE_ENTRY ),
                                             'KWcC',
                                             NumberOfItems,
                                             &ExSystemLookasideListHead );

        } else {
            Lookaside = &CcTwilightLookasideList;
        }

        Prcb->PPLookasideList[LookasideTwilightList].P = Lookaside;
    }

    //
    //  Initialize the Deferred Write List.
    //

    KeInitializeSpinLock( &CcDeferredWriteSpinLock );
    InitializeListHead( &CcDeferredWrites );

    //
    //  Initialize the Vacbs.
    //

    CcInitializeVacbs();

    return TRUE;
}


VOID
CcInitializeCacheMap (
    IN PFILE_OBJECT FileObject,
    IN PCC_FILE_SIZES FileSizes,
    IN BOOLEAN PinAccess,
    IN PCACHE_MANAGER_CALLBACKS Callbacks,
    IN PVOID LazyWriteContext
    )

/*++

Routine Description:

    This routine is intended to be called by File Systems only.  It
    initializes the cache maps for data caching.  It should be called
    every time a file is opened or created, and NO_INTERMEDIATE_BUFFERING
    was specified as FALSE.

Arguments:

    FileObject - A pointer to the newly-created file object.

    FileSizes - A pointer to AllocationSize, FileSize and ValidDataLength
                for the file.  ValidDataLength should contain MAXLONGLONG if
                valid data length tracking and callbacks are not desired.

    PinAccess - FALSE if file will be used exclusively for Copy and Mdl
                access, or TRUE if file will be used for Pin access.
                (Files for Pin access are not limited in size as the caller
                must access multiple areas of the file at once.)

    Callbacks - Structure of callbacks used by the Lazy Writer

    LazyWriteContext - Parameter to be passed in to above routine.

Return Value:

    None.  If an error occurs, this routine will Raise the status.

--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID CacheMapToFree = NULL;
    CC_FILE_SIZES LocalSizes;
    LOGICAL WeSetBeingCreated = FALSE;
    LOGICAL SharedListOwned = FALSE;
    LOGICAL MustUninitialize = FALSE;
    LOGICAL WeCreated = FALSE;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    NTSTATUS Status = STATUS_SUCCESS;

    DebugTrace(+1, me, "CcInitializeCacheMap:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    FileSizes = %08lx\n", FileSizes );

    //
    //  Make a local copy of the passed in file sizes before acquiring
    //  the spin lock.
    //

    LocalSizes = *FileSizes;

    //
    //  If no FileSize was given, set to one byte before maximizing below.
    //

    if (LocalSizes.AllocationSize.QuadPart == 0) {
        LocalSizes.AllocationSize.LowPart += 1;
    }

    //
    //  If caller has Write access or will allow write, then round
    //  size to next create modulo.  (***Temp*** there may be too many
    //  apps that end up allowing shared write, thanks to our Dos heritage,
    //  to keep that part of the check in.)
    //

    if (FileObject->WriteAccess /*|| FileObject->SharedWrite */) {

        LocalSizes.AllocationSize.QuadPart = LocalSizes.AllocationSize.QuadPart + (LONGLONG)(DEFAULT_CREATE_MODULO - 1);
        LocalSizes.AllocationSize.LowPart &= ~(DEFAULT_CREATE_MODULO - 1);

    } else {

        LocalSizes.AllocationSize.QuadPart = LocalSizes.AllocationSize.QuadPart + (LONGLONG)(VACB_MAPPING_GRANULARITY - 1);
        LocalSizes.AllocationSize.LowPart &= ~(VACB_MAPPING_GRANULARITY - 1);
    }

    //
    //  Do the allocate of the SharedCacheMap, based on an unsafe test,
    //  while not holding a spinlock.  If the allocation fails, it's ok
    //  to fail the request even though the test was unsafe.
    //

    if (FileObject->SectionObjectPointer->SharedCacheMap == NULL) {

restart:

        ASSERT (CacheMapToFree == NULL);

        SharedCacheMap = ExAllocatePoolWithTag( NonPagedPool, sizeof(SHARED_CACHE_MAP), 'cScC' );

        if (SharedCacheMap == NULL) {
            DebugTrace( 0, 0, "Failed to allocate SharedCacheMap\n", 0 );
            ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
        }

        //
        //  Stash a copy of it so we can free it in the error path below.
        //

        CacheMapToFree = SharedCacheMap;

        //
        //  Zero the SharedCacheMap and fill in the nonzero portions later.
        //

        RtlZeroMemory( SharedCacheMap, sizeof(SHARED_CACHE_MAP) );

#if OPEN_COUNT_LOG
        SharedCacheMap->OpenCountLog.Size = sizeof(SharedCacheMap->OpenCountLog.Log)/sizeof(CC_OPEN_COUNT_LOG_ENTRY);
#endif

        //
        //  Now initialize the Shared Cache Map.
        //

        SharedCacheMap->NodeTypeCode = CACHE_NTC_SHARED_CACHE_MAP;
        SharedCacheMap->NodeByteSize = sizeof(SHARED_CACHE_MAP);
        SharedCacheMap->FileObject = FileObject;
        SharedCacheMap->FileSize = LocalSizes.FileSize;
        SharedCacheMap->ValidDataLength = LocalSizes.ValidDataLength;
        SharedCacheMap->ValidDataGoal = LocalSizes.ValidDataLength;
        //  SharedCacheMap->Section set below

        //
        //  Initialize the spin locks.
        //

        KeInitializeSpinLock( &SharedCacheMap->ActiveVacbSpinLock );
        KeInitializeSpinLock( &SharedCacheMap->BcbSpinLock );

        ExInitializePushLock( &SharedCacheMap->VacbPushLock );

        if (PinAccess) {
            SetFlag(SharedCacheMap->Flags, PIN_ACCESS);
        }

        //
        //  If this file has FO_SEQUENTIAL_ONLY set, then remember that
        //  in the SharedCacheMap.
        //

        if (FlagOn(FileObject->Flags, FO_SEQUENTIAL_ONLY)) {
            SetFlag(SharedCacheMap->Flags, ONLY_SEQUENTIAL_ONLY_SEEN);
        }

        //
        //  Do the round-robin allocation of the spinlock for the shared
        //  cache map.  Note the manipulation of the next
        //  counter is safe, since we have the CcMasterSpinLock
        //  exclusive.
        //

        InitializeListHead( &SharedCacheMap->BcbList );
        SharedCacheMap->Callbacks = Callbacks;
        SharedCacheMap->LazyWriteContext = LazyWriteContext;

        //
        //  Initialize listhead for all PrivateCacheMaps
        //

        InitializeListHead( &SharedCacheMap->PrivateList );
    }

    //
    //  Serialize Creation/Deletion of all Shared CacheMaps
    //

    SharedListOwned = TRUE;

    CcAcquireMasterLock( &OldIrql );

    //
    //  Check for second initialization of same file object
    //

    if (FileObject->PrivateCacheMap != NULL) {

        DebugTrace( 0, 0, "CacheMap already initialized\n", 0 );
        CcReleaseMasterLock( OldIrql );
        if (CacheMapToFree != NULL) {
            ExFreePool(CacheMapToFree);
        }
        DebugTrace(-1, me, "CcInitializeCacheMap -> VOID\n", 0 );
        return;
    }

    //
    //  Get current Shared Cache Map pointer indirectly off of the file object.
    //  (The actual pointer is typically in a file system data structure, such
    //  as an Fcb.)
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  If there is no SharedCacheMap, then we must create a section and
    //  the SharedCacheMap structure.
    //

    if (SharedCacheMap == NULL) {

        //
        //  Insert the new SharedCacheMap.
        //

        if (CacheMapToFree == NULL) {
            CcReleaseMasterLock( OldIrql );
            SharedListOwned = FALSE;
            goto restart;
        }

        SharedCacheMap = CacheMapToFree;
        CacheMapToFree = NULL;

        //
        //  Insert the new Shared Cache Map in the global list
        //

        //
        //  Note: We do NOT use the common CcInsertIntoCleanSharedCacheMapList
        //  routine here because this shared cache map does not meet the
        //  validation conditions we check for in that routine since it is 
        //  not finished being initialized.
        //

        InsertTailList( &CcCleanSharedCacheMapList,
                        &SharedCacheMap->SharedCacheMapLinks );

        WeCreated = TRUE;

        //
        //  Finally, store the pointer to the Shared Cache Map back
        //  via the indirect pointer in the File Object.
        //

        FileObject->SectionObjectPointer->SharedCacheMap = SharedCacheMap;

        //
        //  We must reference this file object so that it cannot go away
        //  until we do CcUninitializeCacheMap below.  Note we cannot
        //  find or rely on the FileObject that Memory Management has,
        //  although normally it will be this same one anyway.
        //

        ObReferenceObject ( FileObject );

    } else {

        //
        //  If this file has FO_SEQUENTIAL_ONLY clear, then remember that
        //  in the SharedCacheMap.
        //

        if (!FlagOn(FileObject->Flags, FO_SEQUENTIAL_ONLY)) {
            ClearFlag(SharedCacheMap->Flags, ONLY_SEQUENTIAL_ONLY_SEEN);
        }
    }

    //
    //  If this file is opened for random access, remember this in
    //  the SharedCacheMap.
    //

    if (FlagOn(FileObject->Flags, FO_RANDOM_ACCESS)) {
        SetFlag(SharedCacheMap->Flags, RANDOM_ACCESS_SEEN);
    }

    //
    //  Make sure that no one is trying to lazy delete it in the case
    //  that the Cache Map was already there.
    //

    ClearFlag(SharedCacheMap->Flags, TRUNCATE_REQUIRED);

    //
    //  In case there has been a CcUnmapAndPurge call, we check here if we
    //  if we need to recreate the section and map it.
    //

    if ((SharedCacheMap->Vacbs == NULL) &&
        !FlagOn(SharedCacheMap->Flags, BEING_CREATED)) {

        //
        //  Increment the OpenCount on the CacheMap.
        //

        CcIncrementOpenCount( SharedCacheMap, 'onnI' );

        //
        //  We still want anyone else to wait.
        //

        SetFlag(SharedCacheMap->Flags, BEING_CREATED);

        //
        //  If there is a create event, then this must be the path where we
        //  we were only unmapped.  We will just clear it here again in case
        //  someone needs to wait again this time too.
        //

        if (SharedCacheMap->CreateEvent != NULL) {

            KeInitializeEvent( SharedCacheMap->CreateEvent,
                               NotificationEvent,
                               FALSE );
        }

        //
        //  Release global resource
        //

        CcReleaseMasterLock( OldIrql );
        SharedListOwned = FALSE;

        //
        //  Signify we have incremented the open count.
        //

        MustUninitialize = TRUE;

        //
        //  Signify we have marked BEING_CREATED in the CacheMap flags.
        //

        WeSetBeingCreated = TRUE;

        //
        //  We have to test this, because the section may only be unmapped.
        //

        if (SharedCacheMap->Section == NULL) {

            //
            //  Call MM to create a section for this file, for the calculated
            //  section size.  Note that we have the choice in this service to
            //  pass in a FileHandle or a FileObject pointer, but not both.
            //  Use the pointer as it results in much faster performance.
            //

            DebugTrace( 0, mm, "MmCreateSection:\n", 0 );
            DebugTrace2(0, mm, "    MaximumSize = %08lx, %08lx\n",
                        LocalSizes.AllocationSize.LowPart,
                        LocalSizes.AllocationSize.HighPart );
            DebugTrace( 0, mm, "    FileObject = %08lx\n", FileObject );

            SharedCacheMap->Status = MmCreateSection( &SharedCacheMap->Section,
                                                      SECTION_MAP_READ
                                                        | SECTION_MAP_WRITE
                                                        | SECTION_QUERY,
                                                      NULL,
                                                      &LocalSizes.AllocationSize,
                                                      PAGE_READWRITE,
                                                      SEC_COMMIT,
                                                      NULL,
                                                      FileObject );

            DebugTrace( 0, mm, "    <Section = %08lx\n", SharedCacheMap->Section );

            if (!NT_SUCCESS( SharedCacheMap->Status )){
                DebugTrace( 0, 0, "Error from MmCreateSection = %08lx\n",
                            SharedCacheMap->Status );

                SharedCacheMap->Section = NULL;
                Status = FsRtlNormalizeNtstatus( SharedCacheMap->Status,
                                                 STATUS_UNEXPECTED_MM_CREATE_ERR );
                goto exitfinally;
            }

            ObDeleteCapturedInsertInfo(SharedCacheMap->Section);

            //
            //  If this is a stream file object, then no user can map it,
            //  and we should keep the modified page writer out of it.
            //

            if (!FlagOn(((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags2,
                        FSRTL_FLAG2_DO_MODIFIED_WRITE) &&
                (FileObject->FsContext2 == NULL)) {

                MmDisableModifiedWriteOfSection( FileObject->SectionObjectPointer );
                CcAcquireMasterLock( &OldIrql );
                SetFlag(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED);
                CcReleaseMasterLock( OldIrql );
            }

            //
            //  Create the Vacb array.
            //

            Status = CcCreateVacbArray( SharedCacheMap, LocalSizes.AllocationSize );
            if (!NT_SUCCESS(Status)) {
                goto exitfinally;
            }
        }

        //
        //  If the section already exists, we still have to call MM to
        //  extend, in case it is not large enough.
        //

        else {

            if ( LocalSizes.AllocationSize.QuadPart > SharedCacheMap->SectionSize.QuadPart ) {

                DebugTrace( 0, mm, "MmExtendSection:\n", 0 );
                DebugTrace( 0, mm, "    Section = %08lx\n", SharedCacheMap->Section );
                DebugTrace2(0, mm, "    Size = %08lx, %08lx\n",
                            LocalSizes.AllocationSize.LowPart,
                            LocalSizes.AllocationSize.HighPart );

                Status = MmExtendSection( SharedCacheMap->Section,
                                          &LocalSizes.AllocationSize,
                                          TRUE );

                if (!NT_SUCCESS(Status)) {

                    DebugTrace( 0, 0, "Error from MmExtendSection, Status = %08lx\n",
                                Status );

                    Status = FsRtlNormalizeNtstatus( Status,
                                                     STATUS_UNEXPECTED_MM_EXTEND_ERR );
                    goto exitfinally;
                }
            }

            //
            //  Extend the Vacb array.
            //

            Status = CcExtendVacbArray( SharedCacheMap, LocalSizes.AllocationSize );
            if (!NT_SUCCESS(Status)) {
                goto exitfinally;
            }
        }

        //
        //  Now show that we are all done and resume any waiters.
        //

        CcAcquireMasterLock( &OldIrql );
        ClearFlag(SharedCacheMap->Flags, BEING_CREATED);
        if (SharedCacheMap->CreateEvent != NULL) {
            KeSetEvent( SharedCacheMap->CreateEvent, 0, FALSE );
        }
        CcReleaseMasterLock( OldIrql );
        WeSetBeingCreated = FALSE;
    }

    //
    //  Else if the section is already there, we make sure it is large
    //  enough by calling CcExtendCacheSection.
    //

    else {

        //
        //  If the SharedCacheMap is currently being created we have
        //  to optionally create and wait on an event for it.  Note that
        //  the only safe time to delete the event is in
        //  CcUninitializeCacheMap, because we otherwise have no way of
        //  knowing when everyone has reached the KeWaitForSingleObject.
        //

        if (FlagOn(SharedCacheMap->Flags, BEING_CREATED)) {

            if (SharedCacheMap->CreateEvent == NULL) {

                SharedCacheMap->CreateEvent = (PKEVENT)ExAllocatePoolWithTag( NonPagedPool,
                                                                              sizeof(KEVENT),
                                                                              'vEcC' );

                if (SharedCacheMap->CreateEvent == NULL) {
                    DebugTrace( 0, 0, "Failed to allocate CreateEvent\n", 0 );

                    CcReleaseMasterLock( OldIrql );
                    SharedListOwned = FALSE;

                    Status = STATUS_INSUFFICIENT_RESOURCES;
                    goto exitfinally;
                }

                KeInitializeEvent( SharedCacheMap->CreateEvent,
                                   NotificationEvent,
                                   FALSE );
            }

            //
            //  Increment the OpenCount on the CacheMap.
            //

            CcIncrementOpenCount( SharedCacheMap, 'ecnI' );

            //
            //  Release global resource before waiting
            //

            CcReleaseMasterLock( OldIrql );
            SharedListOwned = FALSE;

            MustUninitialize = TRUE;

            DebugTrace( 0, 0, "Waiting on CreateEvent\n", 0 );

            KeWaitForSingleObject( SharedCacheMap->CreateEvent,
                                   Executive,
                                   KernelMode,
                                   FALSE,
                                   (PLARGE_INTEGER)NULL);

            //
            //  If the real creator got an error, then we must bomb
            //  out too.
            //

            if (!NT_SUCCESS(SharedCacheMap->Status)) {
                Status = FsRtlNormalizeNtstatus( SharedCacheMap->Status,
                                                 STATUS_UNEXPECTED_MM_CREATE_ERR );
                goto exitfinally;
            }
        }
        else {

            //
            //  Increment the OpenCount on the CacheMap.
            //

            CcIncrementOpenCount( SharedCacheMap, 'esnI' );

            //
            //  Release global resource
            //

            CcReleaseMasterLock( OldIrql );
            SharedListOwned = FALSE;
            MustUninitialize = TRUE;
        }
    }

    if (CacheMapToFree != NULL) {
        ExFreePool( CacheMapToFree );
        CacheMapToFree = NULL;
    }

    //
    //  Now allocate (if local one already in use) and initialize
    //  the Private Cache Map.
    //

    PrivateCacheMap = &SharedCacheMap->PrivateCacheMap;

    //
    //  See if we should allocate a PrivateCacheMap while not holding
    //  a spinlock.
    //

    if (PrivateCacheMap->NodeTypeCode != 0) {

restart2:

        CacheMapToFree = ExAllocatePoolWithTag( NonPagedPool, sizeof(PRIVATE_CACHE_MAP), 'cPcC' );

        if (CacheMapToFree == NULL) {
            DebugTrace( 0, 0, "Failed to allocate PrivateCacheMap\n", 0 );

            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto exitfinally;
        }

    }

    //
    //  Insert the new PrivateCacheMap in the list off the SharedCacheMap.
    //

    SharedListOwned = TRUE;
    CcAcquireMasterLock( &OldIrql );

    //
    //  Now make sure there is still no PrivateCacheMap, and if so just get out.
    //

    if (FileObject->PrivateCacheMap == NULL) {

        //
        //  Is the local one already in use?
        //

        if (PrivateCacheMap->NodeTypeCode != 0) {

            //
            //  Use the one allocated above, if there is one, else go to pool now.
            //

            if (CacheMapToFree == NULL) {
                CcReleaseMasterLock( OldIrql );
                SharedListOwned = FALSE;

                goto restart2;
            }

            PrivateCacheMap = CacheMapToFree;
            CacheMapToFree = NULL;
        }

        RtlZeroMemory( PrivateCacheMap, sizeof(PRIVATE_CACHE_MAP) );

        PrivateCacheMap->NodeTypeCode = CACHE_NTC_PRIVATE_CACHE_MAP;
        PrivateCacheMap->FileObject = FileObject;
        PrivateCacheMap->ReadAheadMask = PAGE_SIZE - 1;

        //
        //  Initialize the spin lock.
        //

        KeInitializeSpinLock( &PrivateCacheMap->ReadAheadSpinLock );

        InsertTailList( &SharedCacheMap->PrivateList, &PrivateCacheMap->PrivateLinks );

        FileObject->PrivateCacheMap = PrivateCacheMap;

    } else {

        //
        //  We raced with another initializer for the same fileobject and must
        //  drop our (to this point speculative) opencount.
        //

        ASSERT( SharedCacheMap->OpenCount > 1 );

        CcDecrementOpenCount( SharedCacheMap, 'rpnI' );
        SharedCacheMap = NULL;
    }

    MustUninitialize = FALSE;

exitfinally:

    //
    //  See if we got an error and must uninitialize the SharedCacheMap
    //

    if (MustUninitialize) {

        if (!SharedListOwned) {
            CcAcquireMasterLock( &OldIrql );
        }
        if (WeSetBeingCreated) {
            if (SharedCacheMap->CreateEvent != NULL) {
                KeSetEvent( SharedCacheMap->CreateEvent, 0, FALSE );
            }
            ClearFlag(SharedCacheMap->Flags, BEING_CREATED);
        }

        //
        //  Now release our open count.
        //

        CcDecrementOpenCount( SharedCacheMap, 'umnI' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  It is neccesary to eliminate the structure now.  We should
            //  be guaranteed that our dereference will not result in close
            //  due to the caller's reference on the fileobject, unlike the
            //  comment in the original code, below, would indicate.
            //
            //  Not removing this structure can result in problems if the file
            //  is also mapped and the mapped page writer extends VDL. An FS
            //  will use CcSetFileSizes and cause us to issue a recursive flush
            //  of the same range, resulting in a self-colliding page flush and
            //  a deadlock.
            //
            //  We also think that file extension/truncation in the interim
            //  (if the section create failed) would result in an inconsistent
            //  "resurrected" cache map if we managed to use the one we have
            //  now.  Note CcSetFileSizes aborts if the section is NULL.
            //

            CcDeleteSharedCacheMap( SharedCacheMap, OldIrql, FALSE );

#if 0                
            //
            //  On PinAccess it is safe and necessary to eliminate
            //  the structure immediately.
            //

            if (PinAccess) {

                CcDeleteSharedCacheMap( SharedCacheMap, OldIrql, FALSE );

            //
            //  If it is not PinAccess, we must lazy delete, because
            //  we could get into a deadlock trying to acquire the
            //  stream exclusive when we dereference the file object.
            //

            } else {

                //
                //  Move it to the dirty list so the lazy write scan will
                //  see it.
                //

                RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
                InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                                &SharedCacheMap->SharedCacheMapLinks );

                //
                //  Make sure the Lazy Writer will wake up, because we
                //  want him to delete this SharedCacheMap.
                //

                LazyWriter.OtherWork = TRUE;
                if (!LazyWriter.ScanActive) {
                    CcScheduleLazyWriteScan( FALSE );
                }

                CcReleaseMasterLock( OldIrql );
            }
#endif

        } else {

            CcReleaseMasterLock( OldIrql );
        }

        SharedListOwned = FALSE;

    } else if (SharedCacheMap != NULL) {

        PCACHE_UNINITIALIZE_EVENT CUEvent, EventNext;

        //
        //  If we did not create this SharedCacheMap, then there is a
        //  possibility that it is in the dirty list.  Once we are sure
        //  we have the spinlock, just make sure it is in the clean list
        //  if there are no dirty bytes and the open count is nonzero.
        //  (The latter test is almost guaranteed, of course, but we check
        //  it to be safe.)
        //

        if (!SharedListOwned) {

            CcAcquireMasterLock( &OldIrql );
            SharedListOwned = TRUE;
        }

        if (!WeCreated                        &&
            (SharedCacheMap->DirtyPages == 0) &&
            (SharedCacheMap->OpenCount != 0)) {

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            CcInsertIntoCleanSharedCacheMapList( SharedCacheMap );
        }

        //
        //  If there is a process waiting on an uninitialize on this
        //  cache map to complete, let the thread that is waiting go,
        //  since the uninitialize is now complete.
        //
        
        CUEvent = SharedCacheMap->UninitializeEvent;

        while (CUEvent != NULL) {
            EventNext = CUEvent->Next;
            KeSetEvent(&CUEvent->Event, 0, FALSE);
            CUEvent = EventNext;
        }

        SharedCacheMap->UninitializeEvent = NULL;
        ClearFlag( SharedCacheMap->Flags, WAITING_FOR_TEARDOWN );
    }

    //
    //  Release global resource
    //

    if (SharedListOwned) {
        CcReleaseMasterLock( OldIrql );
    }

    if (CacheMapToFree != NULL) {
        ExFreePool(CacheMapToFree);
    }

    if (!NT_SUCCESS(Status)) {
        DebugTrace(-1, me, "CcInitializeCacheMap -> RAISING EXCEPTION\n", 0 );
        ExRaiseStatus(Status);
    }

    DebugTrace(-1, me, "CcInitializeCacheMap -> VOID\n", 0 );

    return;
}


BOOLEAN
CcUninitializeCacheMap (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER TruncateSize OPTIONAL,
    IN PCACHE_UNINITIALIZE_EVENT UninitializeEvent OPTIONAL
    )

/*++

Routine Description:

    This routine uninitializes the previously initialized Shared and Private
    Cache Maps.  This routine is only intended to be called by File Systems.
    It should be called when the File System receives a cleanup call on the
    File Object.

    A File System which supports data caching must always call this routine
    whenever it closes a file, whether the caller opened the file with
    NO_INTERMEDIATE_BUFFERING as FALSE or not.  This is because the final
    cleanup of a file related to truncation or deletion of the file, can
    only occur on the last close, whether the last closer cached the file
    or not.  When CcUnitializeCacheMap is called on a file object for which
    CcInitializeCacheMap was never called, the call has a benign effect
    iff no one has truncated or deleted the file; otherwise the necessary
    cleanup relating to the truncate or close is performed.

    In summary, CcUnitializeCacheMap does the following:

        If the caller had Write or Delete access, the cache is flushed.
        (This could change with lazy writing.)

        If a Cache Map was initialized on this File Object, it is
        unitialized (unmap any views, delete section, and delete
        Cache Map structures).

        On the last Cleanup, if the file has been deleted, the
        Section is forced closed.  If the file has been truncated, then
        the truncated pages are purged from the cache.

Arguments:

    FileObject - File Object which was previously supplied to
                 CcInitializeCacheMap.

    TruncateSize - If specified, the file was truncated to the specified
                   size, and the cache should be purged accordingly.

    UninitializeEvent - If specified, then the provided event will be set
                        to the signalled state when the actual flush is
                        completed.  This is only of interest to file systems
                        that require that they be notified when a cache flush
                        operation has completed.  Due to network protocol
                        restrictions, it is critical that network file
                        systems know exactly when a cache flush operation
                        completes, by specifying this event, they can be
                        notified when the cache section is finally purged
                        if the section is "lazy-deleted".

ReturnValue:

    FALSE if Section was not closed.
    TRUE if Section was closed.

--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB ActiveVacb = NULL;
    BOOLEAN SectionClosed = FALSE;
    PPRIVATE_CACHE_MAP PrivateCacheMap;

    DebugTrace(+1, me, "CcUninitializeCacheMap:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    &TruncateSize = %08lx\n", TruncateSize );

    //
    //  Serialize Creation/Deletion of all Shared CacheMaps
    //

    CcAcquireMasterLock( &OldIrql );

    //
    //  Get pointer to SharedCacheMap via File Object.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    PrivateCacheMap = FileObject->PrivateCacheMap;

    //
    //  Decrement Open Count on SharedCacheMap, if we did a cached open.
    //  Also unmap PrivateCacheMap if it is mapped and deallocate it.
    //

    if (PrivateCacheMap != NULL) {

        ASSERT( PrivateCacheMap->FileObject == FileObject );

        CcDecrementOpenCount( SharedCacheMap, 'ninU' );

        //
        //  Remove PrivateCacheMap from list in SharedCacheMap.
        //

        RemoveEntryList( &PrivateCacheMap->PrivateLinks );

        //
        //  Free local or allocated PrivateCacheMap
        //

        if (PrivateCacheMap == &SharedCacheMap->PrivateCacheMap) {
            PrivateCacheMap->NodeTypeCode = 0;
            PrivateCacheMap = NULL;
        }

        FileObject->PrivateCacheMap = (PPRIVATE_CACHE_MAP)NULL;
    }

    //
    //  Now if we have a SharedCacheMap whose Open Count went to 0, we
    //  have some additional cleanup.
    //

    if (SharedCacheMap != NULL) {

        //
        //  If a Truncate Size was specified, then remember that we want to
        //  truncate the FileSize and purge the unneeded pages when OpenCount
        //  goes to 0.
        //

        if (ARGUMENT_PRESENT(TruncateSize)) {

            if ( (TruncateSize->QuadPart == 0) && (SharedCacheMap->FileSize.QuadPart != 0) ) {

                SetFlag(SharedCacheMap->Flags, TRUNCATE_REQUIRED);

            } else if (IsListEmpty(&SharedCacheMap->PrivateList)) {

                //
                //  If this is the last guy, I can drop the file size down
                //  now.
                //

                SharedCacheMap->FileSize = *TruncateSize;
            }
        }

        //
        //  If other file objects are still using this SharedCacheMap,
        //  then we are done now.
        //

        if (SharedCacheMap->OpenCount != 0) {

            DebugTrace(-1, me, "SharedCacheMap OpenCount != 0\n", 0);

            //
            //  If the caller specified an event to be set when
            //  the cache uninitialize is completed, set the event
            //  now, because the uninitialize is complete for this file.
            //  (Note, we make him wait if he is the last guy.)
            //

            if (ARGUMENT_PRESENT(UninitializeEvent)) {

                if (!IsListEmpty(&SharedCacheMap->PrivateList)) {
                    KeSetEvent(&UninitializeEvent->Event, 0, FALSE);
                } else {
                    UninitializeEvent->Next = SharedCacheMap->UninitializeEvent;
                    SharedCacheMap->UninitializeEvent = UninitializeEvent;
                }
            }

            CcReleaseMasterLock( OldIrql );

            //
            //  Free PrivateCacheMap now that we no longer have the spinlock.
            //

            if (PrivateCacheMap != NULL) {
                ExFreePool( PrivateCacheMap );
            }

            DebugTrace(-1, me, "CcUnitializeCacheMap -> %02lx\n", FALSE );
            return FALSE;
        }

        //
        //  Remove the private write flag synchronously.  Even though a
        //  private writer is also opening the file exclusively, the
        //  shared cache map is not going away synchronously and we
        //  cannot let a non private writer re-reference the scm in
        //  this state. Their data will never be written!
        //

        if (FlagOn(SharedCacheMap->Flags, PRIVATE_WRITE)) {

            ClearFlag(SharedCacheMap->Flags, PRIVATE_WRITE | DISABLE_WRITE_BEHIND);
            MmEnableModifiedWriteOfSection( FileObject->SectionObjectPointer );
        }

        //
        //  The private cache map list better be empty!
        //

        ASSERT(IsListEmpty(&SharedCacheMap->PrivateList));

        //
        //  Set the "uninitialize complete" in the shared cache map
        //  so that CcDeleteSharedCacheMap will delete it.
        //

        if (ARGUMENT_PRESENT(UninitializeEvent)) {
            UninitializeEvent->Next = SharedCacheMap->UninitializeEvent;
            SharedCacheMap->UninitializeEvent = UninitializeEvent;
        }

        //
        //  We are in the process of deleting this cache map.  If the
        //  Lazy Writer is active or the Bcb list is not empty or the Lazy
        //  Writer will hit this SharedCacheMap because we are purging
        //  the file to 0, then get out and let the Lazy Writer clean
        //  up.  If a write through, was forced queue a lazy write to
        //  update the file sizes.
        //

        if ((!FlagOn(SharedCacheMap->Flags, PIN_ACCESS) &&
             !ARGUMENT_PRESENT(UninitializeEvent))

                ||

            FlagOn(SharedCacheMap->Flags, WRITE_QUEUED)

                ||

            (SharedCacheMap->DirtyPages != 0)

                ||

            FlagOn(SharedCacheMap->Flags, FORCED_WRITE_THROUGH)) {

            //
            //  Move it to the dirty list so the lazy write scan will
            //  see it.
            //

            if (!FlagOn(SharedCacheMap->Flags, WRITE_QUEUED)) {
                RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
                InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                                &SharedCacheMap->SharedCacheMapLinks );
            }

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }

            //
            //  Get the active Vacb if we are going to lazy delete, to
            //  free it for someone who can use it.
            //

            GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

            DebugTrace(-1, me, "SharedCacheMap has Bcbs and not purging to 0\n", 0);

            CcReleaseMasterLock( OldIrql );
            ASSERT (SectionClosed == FALSE);
        }
        else {

            //
            //  Now we can delete the SharedCacheMap.  If there are any Bcbs,
            //  then we must be truncating to 0, and they will also be deleted.
            //  On return the Shared Cache Map List Spinlock will be released.
            //

            CcDeleteSharedCacheMap( SharedCacheMap, OldIrql, FALSE );

            SectionClosed = TRUE;
        }
    }

    //
    //  No Shared Cache Map.  To make the file go away, we still need to
    //  purge the section, if one exists.  (And we still need to release
    //  our global list first to avoid deadlocks.)
    //

    else {
        if (ARGUMENT_PRESENT(TruncateSize) &&
            ( TruncateSize->QuadPart == 0 ) &&
            (*(PCHAR *)FileObject->SectionObjectPointer != NULL)) {

            CcReleaseMasterLock( OldIrql );

            DebugTrace( 0, mm, "MmPurgeSection:\n", 0 );
            DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n",
                        FileObject->SectionObjectPointer );
            DebugTrace2(0, mm, "    Offset = %08lx\n",
                        TruncateSize->LowPart,
                        TruncateSize->HighPart );

            //
            //  0 Length means to purge from the TruncateSize on.
            //

            CcPurgeCacheSection( FileObject->SectionObjectPointer,
                                 TruncateSize,
                                 0,
                                 FALSE );
        }
        else {
            CcReleaseMasterLock( OldIrql );
        }

        //
        //  If the caller specified an event to be set when
        //  the cache uninitialize is completed, set the event
        //  now, because the uninitialize is complete for this file.
        //

        if (ARGUMENT_PRESENT(UninitializeEvent)) {
            KeSetEvent(&UninitializeEvent->Event, 0, FALSE);
        }
    }

    //
    //  Free the active vacb, if we found one.
    //

    if (ActiveVacb != NULL) {

        CcFreeActiveVacb( ActiveVacb->SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }

    //
    //  Free PrivateCacheMap now that we no longer have the spinlock.
    //

    if (PrivateCacheMap != NULL) {
        ExFreePool( PrivateCacheMap );
    }

    DebugTrace(-1, me, "CcUnitializeCacheMap -> %02lx\n", SectionClosed );

    return SectionClosed;
}

VOID
CcWaitForUninitializeCacheMap (
    IN PFILE_OBJECT FileObject
    )

/*++

Routine Description:

    This routine is called to wait for the uninitialization of this FileObject's
    SharedCacheMap to complete.  If we are in the process of tearing down the
    SharedCacheMap, this routine will wait for that work to complete.  If this
    SharedCacheMap is referenced by another file object initiating caching of
    this stream, the wait will end.

    This routine will wait for residual references to a data section
    caused by a SharedCacheMap to go away.  If this SharedCacheMap still needs
    to reference the data section, then the SharedCacheMap reference on the
    section will remain when this call returns.
    
Arguments:

    FileObject - The file of interest for which the caller wants to ensure any
        residual references on the sections backing this file due to the 
        Cache Manager are released.

Return Value:

    None.

--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    CACHE_UNINITIALIZE_EVENT UninitializeEvent;
    BOOLEAN ShouldWait = FALSE;
    LARGE_INTEGER Timeout;
    NTSTATUS Status;

    DebugTrace(+1, me, "CcWaitForUninitializeCacheMap:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );

    //
    //  First, do an unprotected check to see if a SharedCacheMap exists
    //  for this file.  If not, we've got no more work to do and avoid
    //  acquiring the master lock.
    //

    if (FileObject->SectionObjectPointer->SharedCacheMap == NULL) {

        return;
    }

    //
    //  Initialize event that we may have to wait on if we are in the process
    //  of uninitializing the SharedCacheMap.
    //
    
    KeInitializeEvent( &UninitializeEvent.Event,
                       NotificationEvent,
                       FALSE );

    //
    //  Serialize Creation/Deletion of all Shared CacheMaps
    //

    CcAcquireMasterLock( &OldIrql );

    //
    //  Get pointer to SharedCacheMap via File Object.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  If we have a SharedCacheMap, we will check to OpenCount to see if 
    //  we are in the process of uninitializing the SharedCacheMap and 
    //  should therefore wait for that work to complete.
    //

    if (SharedCacheMap != NULL) {

        //
        //  If the OpenCount on the SharedCacheMap is zero or the list
        //  of private cache maps is empty, we are in the process of 
        //  uninitializing this SharedCacheMap.  Link our event into the 
        //  SharedCacheMap's UninitializeEvent list so that we will be signaled
        //  when the work is completed or the SharedCacheMap is referenced by
        //  another file before it is torn down.
        //

        if (SharedCacheMap->OpenCount == 0 ||
            IsListEmpty( &SharedCacheMap->PrivateList )) {

            DebugTrace(-1, me, "SharedCacheMap OpenCount == 0 or PrivateList is empty\n", 0);

            ShouldWait = TRUE; 
            SetFlag( SharedCacheMap->Flags, WAITING_FOR_TEARDOWN );

            UninitializeEvent.Next = SharedCacheMap->UninitializeEvent;
            SharedCacheMap->UninitializeEvent = &UninitializeEvent;

            //
            //  Give the lazy write scan a kick to get it to start doing its
            //  scan right now.
            //
            
            CcScheduleLazyWriteScan( TRUE );
        } 
    }

    //
    //  Release the lock because we are finished with the SharedCacheMap.
    //

    CcReleaseMasterLock( OldIrql );

    if (!ShouldWait) {

        //
        //  We shouldn't wait or try to force this teardown sooner, so just
        //  return now.
        
        goto exit;
    }

    //
    //  We will now wait for the event to get signaled.  We've given the lazy
    //  write scan a kick so it should process this right away ahead of any
    //  other outstanding work.  We should get signaled as soon as the flush
    //  has been completed.
    //

    Timeout.QuadPart = (LONGLONG)-(10 * 60 * NANO_FULL_SECOND);

    Status = KeWaitForSingleObject( &UninitializeEvent.Event, 
                                    Executive,
                                    KernelMode,
                                    FALSE,
                                    &Timeout );

    if (Status == STATUS_TIMEOUT) {

        PCACHE_UNINITIALIZE_EVENT CUEvent;

        //
        //  We weren't signaled, so grab the master spin lock and remove
        //  this event from the shared cache map if it is still around.
        //

        CcAcquireMasterLock( &OldIrql );

        SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

        if (SharedCacheMap != NULL) {

            //
            //  We've got a shared cache map, so take our UninitializeEvent
            //  out of the list.  Since this is a singlely-linked list, we've
            //  got to search, but the list shouldn't be long.
            //               

            CUEvent = CONTAINING_RECORD( &SharedCacheMap->UninitializeEvent,
                                         CACHE_UNINITIALIZE_EVENT,
                                         Next );

            while (CUEvent->Next != NULL) {

                if (CUEvent->Next == &UninitializeEvent) {

                    CUEvent->Next = UninitializeEvent.Next;
                    break;
                }

                CUEvent = CUEvent->Next;
            }

            ClearFlag( SharedCacheMap->Flags, WAITING_FOR_TEARDOWN );
            
            //
            //  All done, so release the master lock.
            //
            
            CcReleaseMasterLock( OldIrql );

        } else {

            //
            //  Release the master lock and wait again on the event.  If the
            //  shared cache map is no longer around, another thread is
            //  in CcDeleteSharedCacheMap and will be walking the event list
            //  to signal this event very soon.  
            //
            
            CcReleaseMasterLock( OldIrql );

            KeWaitForSingleObject( &UninitializeEvent.Event, 
                                    Executive,
                                    KernelMode,
                                    FALSE,
                                    NULL );
        }
    }
    
exit:
    
    DebugTrace(-1, me, "CcWaitForUninitializeCacheMap\n", 0 );
    return;
}


//
//  Internal support routine.
//

VOID
CcDeleteBcbs (
    IN PSHARED_CACHE_MAP SharedCacheMap
    )

/*++

Routine Description:

    This routine may be called to delete all Bcbs for a stream.
    
    External synchronization must be acquired to guarantee no
    active pin on any bcb.

Arguments:

    SharedCacheMap - Pointer to SharedCacheMap.

Return Value:

    None.

--*/

{
    KIRQL OldIrql;
    PLIST_ENTRY NextEntry;
    PBCB Bcb;

    //
    //  If there are Bcbs, then empty the list. None of them can be pinned now!
    //  Either the file is being truncated, in which case synchronization with
    //  the lazy writer must have been externally acheived, or the file is being
    //  closed down and nothing should be able to get a fresh reference on this
    //  shared cache map.
    //

    NextEntry = SharedCacheMap->BcbList.Flink;
    while (NextEntry != &SharedCacheMap->BcbList) {

        Bcb = (PBCB)CONTAINING_RECORD( NextEntry,
                                       BCB,
                                       BcbLinks );
        NextEntry = Bcb->BcbLinks.Flink;

        //
        //  Skip over the pendaflex entries, only removing true Bcbs
        //  so that level teardown doesn't need to special case unhooking
        //  the pendaflex.  This has the side benefit of dramatically
        //  reducing write traffic to memory on teardown of large files.
        //

        if (Bcb->NodeTypeCode == CACHE_NTC_BCB) {

            ASSERT( Bcb->PinCount == 0 );

            RemoveEntryList( &Bcb->BcbLinks );

            //
            //  For large metadata streams we unlock the Vacb level when
            //  removing.  We do not need spinlocks since no other thread
            //  can be accessing this list when we are deleting the
            //  SharedCacheMap.
            //

            CcUnlockVacbLevel( SharedCacheMap, Bcb->FileOffset.QuadPart );

            //
            //  There is a small window where the data could still be mapped
            //  if (for example) the Lazy Writer collides with a CcCopyWrite
            //  in the foreground, and then someone calls CcUninitializeCacheMap
            //  while the Lazy Writer is active.  This is because the Lazy
            //  Writer biases the pin count.  Deal with that here.
            //

            if (Bcb->BaseAddress != NULL) {
                CcFreeVirtualAddress( Bcb->Vacb );
            }

#if LIST_DBG
            //
            //  Debug routines used to remove Bcbs from the global list
            //

            OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

            if (Bcb->CcBcbLinks.Flink != NULL) {

                RemoveEntryList( &Bcb->CcBcbLinks );
                CcBcbCount -= 1;
            }

            KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
#endif

            //
            //  If the Bcb is dirty, we have to synchronize with the Lazy Writer
            //  and reduce the total number of dirty.
            //

            CcAcquireMasterLock( &OldIrql );
            if (Bcb->Dirty) {
                CcDeductDirtyPages( SharedCacheMap,  Bcb->ByteLength >> PAGE_SHIFT );
            }
            CcReleaseMasterLock( OldIrql );

            CcDeallocateBcb( Bcb );
        }
    }
}


//
//  Internal support routine.
//

VOID
FASTCALL
CcDeleteSharedCacheMap (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN KIRQL ListIrql,
    IN ULONG ReleaseFile
    )

/*++

Routine Description:

    The specified SharedCacheMap is removed from the global list of
    SharedCacheMap's and deleted with all of its related structures.
    Other objects which were referenced in CcInitializeCacheMap are
    dereferenced here.

    NOTE:   The CcMasterSpinLock must already be acquired
            on entry.  It is released on return.

Arguments:

    SharedCacheMap - Pointer to Cache Map to delete

    ListIrql - priority to restore to when releasing shared cache map list

    ReleaseFile - Supplied as nonzero if file was acquired exclusive and
                  should be released.

ReturnValue:

    None.

--*/

{
    LIST_ENTRY LocalList;
    PFILE_OBJECT FileObject;
    PVACB ActiveVacb;
    ULONG ActivePage;
    ULONG PageIsDirty;

    DebugTrace(+1, me, "CcDeleteSharedCacheMap:\n", 0 );
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap );

    //
    //  Remove it from the global list and clear the pointer to it via
    //  the File Object.
    //

    RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );

    //
    //  Zero pointer to SharedCacheMap.  Once we have cleared the pointer,
    //  we can/must release the global list to avoid deadlocks.
    //

    FileObject = SharedCacheMap->FileObject;

    FileObject->SectionObjectPointer->SharedCacheMap = (PSHARED_CACHE_MAP)NULL;
    SetFlag( SharedCacheMap->Flags, WRITE_QUEUED );

    //
    //  The OpenCount is 0, but we still need to flush out any dangling
    //  cache read or writes.
    //

    if ((SharedCacheMap->VacbActiveCount != 0) || (SharedCacheMap->NeedToZero != NULL)) {

        //
        //  We will put it in a local list and set a flag
        //  to keep the Lazy Writer away from it, so that we can rip it out
        //  below if someone manages to sneak in and set something dirty, etc.
        //  If the file system does not synchronize cleanup calls with an
        //  exclusive on the stream, then this case is possible.
        //

        InitializeListHead( &LocalList );
        InsertTailList( &LocalList, &SharedCacheMap->SharedCacheMapLinks );

        //
        //  If there is an active Vacb, then nuke it now (before waiting!).
        //

        GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

        CcReleaseMasterLock( ListIrql );

        //
        //  No point in saying the page is dirty (which can cause an allocation
        //  failure), since we are deleting this SharedCacheMap anyway.
        //

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, FALSE );

        while (SharedCacheMap->VacbActiveCount != 0) {
            CcWaitOnActiveCount( SharedCacheMap );
        }

        //
        //  Now in case we hit the rare path where someone moved the
        //  SharedCacheMap again, do a remove again now.  It may be
        //  from our local list or it may be from the dirty list,
        //  but who cares?  The important thing is to remove it in
        //  the case it was the dirty list, since we will delete it
        //  below.
        //

        CcAcquireMasterLock( &ListIrql );
        RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
    }

    CcReleaseMasterLock( ListIrql );

    //
    //  If there are Bcbs, then empty the list.
    //
    //  I really wonder how often we have Bcbs at teardown.  This is
    //  a lot of work that could be avoided otherwise.
    //

    if (!IsListEmpty( &SharedCacheMap->BcbList )) {
        CcDeleteBcbs( SharedCacheMap );
    }

    //
    //  Call local routine to unmap, and purge if necessary.
    //

    CcUnmapAndPurge( SharedCacheMap );

    //
    //  Now release the file now that the purge is done.
    //

    if (ReleaseFile) {
        FsRtlReleaseFile( SharedCacheMap->FileObject );
    }

    //
    //  Dereference our pointer to the Section and FileObject
    //  (We have to test the Section pointer since CcInitializeCacheMap
    //  calls this routine for error recovery.  Release our global
    //  resource before dereferencing the FileObject to avoid deadlocks.
    //

    if (SharedCacheMap->Section != NULL) {
        ObDereferenceObject( SharedCacheMap->Section );
    }
    ObDereferenceObject( FileObject );

    //
    //  If there is an Mbcb, deduct any dirty pages and deallocate.
    //

    if (SharedCacheMap->Mbcb != NULL) {
        CcDeleteMbcb( SharedCacheMap );
    }

    //
    //  If there was an uninitialize event specified for this shared cache
    //  map, then set it to the signalled state, indicating that we are
    //  removing the section and deleting the shared cache map.
    //

    if (SharedCacheMap->UninitializeEvent != NULL) {
        PCACHE_UNINITIALIZE_EVENT CUEvent, EventNext;

        CUEvent = SharedCacheMap->UninitializeEvent;
        while (CUEvent != NULL) {
            EventNext = CUEvent->Next;
            KeSetEvent(&CUEvent->Event, 0, FALSE);
            CUEvent = EventNext;
        }
    }

    //
    //  Now delete the Vacb vector.
    //

    if ((SharedCacheMap->Vacbs != &SharedCacheMap->InitialVacbs[0])

            &&

        (SharedCacheMap->Vacbs != NULL)) {

        //
        //  If there are Vacb levels, then the Vacb Array better be in an empty state.
        //

        ASSERT((SharedCacheMap->SectionSize.QuadPart <= VACB_SIZE_OF_FIRST_LEVEL) ||
               !IsVacbLevelReferenced( SharedCacheMap, SharedCacheMap->Vacbs, 1 ));

        ExFreePool( SharedCacheMap->Vacbs );
    }

    //
    //  If an event had to be allocated for this SharedCacheMap,
    //  deallocate it.
    //

    if ((SharedCacheMap->CreateEvent != NULL) && (SharedCacheMap->CreateEvent != &SharedCacheMap->Event)) {
        ExFreePool( SharedCacheMap->CreateEvent );
    }

    if ((SharedCacheMap->WaitOnActiveCount != NULL) && (SharedCacheMap->WaitOnActiveCount != &SharedCacheMap->Event)) {
        ExFreePool( SharedCacheMap->WaitOnActiveCount );
    }

    //
    //  Deallocate the storeage for the SharedCacheMap.
    //

    ExFreePool( SharedCacheMap );

    DebugTrace(-1, me, "CcDeleteSharedCacheMap -> VOID\n", 0 );

    return;

}


VOID
CcSetFileSizes (
    IN PFILE_OBJECT FileObject,
    IN PCC_FILE_SIZES FileSizes
    )

/*++

Routine Description:

    This routine must be called whenever a file has been extended to reflect
    this extension in the cache maps and underlying section.  Calling this
    routine has a benign effect if the current size of the section is
    already greater than or equal to the new AllocationSize.

    This routine must also be called whenever the FileSize for a file changes
    to reflect these changes in the Cache Manager.

    This routine seems rather large, but in the normal case it only acquires
    a spinlock, updates some fields, and exits.  Less often it will either
    extend the section, or truncate/purge the file, but it would be unexpected
    to do both.  On the other hand, the idea of this routine is that it does
    "everything" required when AllocationSize or FileSize change.

Arguments:

    FileObject - A file object for which CcInitializeCacheMap has been
                 previously called.

    FileSizes - A pointer to AllocationSize, FileSize and ValidDataLength
                for the file.  AllocationSize is ignored if it is not larger
                than the current section size (i.e., it is ignored unless it
                has grown).  ValidDataLength is not used.


Return Value:

    None

--*/

{
    LARGE_INTEGER NewSectionSize;
    LARGE_INTEGER NewFileSize;
    LARGE_INTEGER NewValidDataLength;
    IO_STATUS_BLOCK IoStatus;
    PSHARED_CACHE_MAP SharedCacheMap;
    NTSTATUS Status;
    KIRQL OldIrql;
    PVACB ActiveVacb;
    ULONG ActivePage;
    ULONG PageIsDirty;

    DebugTrace(+1, me, "CcSetFileSizes:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    FileSizes = %08lx\n", FileSizes );

    //
    //  Make a local copy of the new file size and section size.
    //

    NewSectionSize = FileSizes->AllocationSize;
    NewFileSize = FileSizes->FileSize;
    NewValidDataLength = FileSizes->ValidDataLength;

    //
    //  Serialize Creation/Deletion of all Shared CacheMaps
    //

    CcAcquireMasterLock( &OldIrql );

    //
    //  Get pointer to SharedCacheMap via File Object.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  If the file is not cached, just get out.
    //

    if ((SharedCacheMap == NULL) || (SharedCacheMap->Section == NULL)) {

        CcReleaseMasterLock( OldIrql );

        //
        //  Let's try to purge the file incase this is a truncate.  In the
        //  vast majority of cases when there is no shared cache map, there
        //  is no data section either, so this call will eventually be
        //  no-oped in Mm.
        //
        //  First flush the first page we are keeping, if it has data, before
        //  we throw it away.
        //

        if (NewFileSize.LowPart & (PAGE_SIZE - 1)) {
            MmFlushSection( FileObject->SectionObjectPointer, &NewFileSize, 1, &IoStatus, FALSE );
        }

        CcPurgeCacheSection( FileObject->SectionObjectPointer,
                             &NewFileSize,
                             0,
                             FALSE );

        DebugTrace(-1, me, "CcSetFileSizes -> VOID\n", 0 );

        return;
    }

    //
    //  Make call a Noop if file is not mapped, or section already big enough.
    //

    if ( NewSectionSize.QuadPart > SharedCacheMap->SectionSize.QuadPart ) {

        //
        //  Increment open count to make sure the SharedCacheMap stays around,
        //  then release the spinlock so that we can call Mm.
        //

        CcIncrementOpenCount( SharedCacheMap, '1fSS' );
        CcReleaseMasterLock( OldIrql );

        //
        //  Round new section size to pages.
        //

        NewSectionSize.QuadPart = NewSectionSize.QuadPart + (LONGLONG)(DEFAULT_EXTEND_MODULO - 1);
        NewSectionSize.LowPart &= ~(DEFAULT_EXTEND_MODULO - 1);

        //
        //  Call MM to extend the section.
        //

        DebugTrace( 0, mm, "MmExtendSection:\n", 0 );
        DebugTrace( 0, mm, "    Section = %08lx\n", SharedCacheMap->Section );
        DebugTrace2(0, mm, "    Size = %08lx, %08lx\n",
                    NewSectionSize.LowPart, NewSectionSize.HighPart );

        Status = MmExtendSection( SharedCacheMap->Section, &NewSectionSize, TRUE );

        if (NT_SUCCESS(Status)) {

            //
            //  Extend the Vacb array.
            //

            Status = CcExtendVacbArray( SharedCacheMap, NewSectionSize );
        }
        else {

            DebugTrace( 0, 0, "Error from MmExtendSection, Status = %08lx\n",
                        Status );

            Status = FsRtlNormalizeNtstatus( Status,
                                             STATUS_UNEXPECTED_MM_EXTEND_ERR );
        }

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, '1fSF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        //
        //  If section or VACB extension failed, raise an
        //  exception to our caller.
        //

        if (!NT_SUCCESS(Status)) {
            CcReleaseMasterLock( OldIrql );
            ExRaiseStatus( Status );
        }

        //
        //  It is now very unlikely that we have any more work to do, but since
        //  the spinlock is already held, check again if we are cached.
        //

        //
        //  Get pointer to SharedCacheMap via File Object.
        //

        SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

        //
        //  If the file is not cached, just get out.
        //

        if (SharedCacheMap == NULL) {

            CcReleaseMasterLock( OldIrql );

            DebugTrace(-1, me, "CcSetFileSizes -> VOID\n", 0 );

            return;
        }
    }

    //
    //  If we are shrinking either of these two sizes, then we must free the
    //  active page, since it may be locked.
    //

    CcIncrementOpenCount( SharedCacheMap, '2fSS' );

    if ( ( NewFileSize.QuadPart < SharedCacheMap->ValidDataGoal.QuadPart ) ||
         ( NewFileSize.QuadPart < SharedCacheMap->FileSize.QuadPart )) {

        GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

        if ((ActiveVacb != NULL) || (SharedCacheMap->NeedToZero != NULL)) {

            CcReleaseMasterLock( OldIrql );

            CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

            //
            //  Serialize again to reduce ValidDataLength.  It cannot change
            //  because the caller must have the file exclusive.
            //

            CcAcquireMasterLock( &OldIrql );
        }
    }

    //
    //  If the section did not grow, see if the file system supports
    //  ValidDataLength, then update the valid data length in the file system.
    //

    if ( SharedCacheMap->ValidDataLength.QuadPart != MAXLONGLONG ) {

        if ( NewFileSize.QuadPart < SharedCacheMap->ValidDataLength.QuadPart ) {
            SharedCacheMap->ValidDataLength = NewFileSize;
        }

        //
        //  Update our notion of ValidDataGoal (how far the file has been
        //  written in the cache) with caller's ValidDataLength.  (Our
        //  ValidDataLength controls when we issue ValidDataLength callbacks.)
        //

        SharedCacheMap->ValidDataGoal = NewValidDataLength;
    }

    //
    //  On truncate, be nice guys and actually purge away user data from
    //  the cache.  However, the PinAccess check is important to avoid deadlocks
    //  in Ntfs.
    //
    //  It is also important to check the Vacb Active count.  The caller
    //  must have the file exclusive, therefore, no one else can be actively
    //  doing anything in the file.  Normally the Active count will be zero
    //  (like in a normal call from Set File Info), and we can go ahead and
    //  truncate.  However, if the active count is nonzero, chances are this
    //  very thread has something pinned or mapped, and we will deadlock if
    //  we try to purge and wait for the count to go zero.  A rare case of
    //  this which deadlocked DaveC on Christmas Day of 1992, is where Ntfs
    //  was trying to convert an attribute from resident to nonresident - which
    //  is a good example of a case where the purge was not needed.
    //

    if ( (NewFileSize.QuadPart < SharedCacheMap->FileSize.QuadPart ) &&
        !FlagOn(SharedCacheMap->Flags, PIN_ACCESS) &&
        (SharedCacheMap->VacbActiveCount == 0)) {

        //
        //  Release the spinlock so that we can call Mm.
        //

        CcReleaseMasterLock( OldIrql );

        //
        //  If we are actually truncating to zero (a size which has particular
        //  meaning to the Lazy Writer scan!) then we must reset the Mbcb/Bcbs,
        //  if there are any, so that we do not keep dirty pages around forever.
        //

        if (NewFileSize.QuadPart == 0) {
            if (SharedCacheMap->Mbcb != NULL) {
                CcDeleteMbcb( SharedCacheMap );
            }
            if (!IsListEmpty( &SharedCacheMap->BcbList )) {
                CcDeleteBcbs( SharedCacheMap );
            }
        }

        CcPurgeAndClearCacheSection( SharedCacheMap, &NewFileSize );

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );
    }

    CcDecrementOpenCount( SharedCacheMap, '2fSF' );

    SharedCacheMap->FileSize = NewFileSize;

    if ((SharedCacheMap->OpenCount == 0) &&
        !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
        (SharedCacheMap->DirtyPages == 0)) {

        //
        //  Move to the dirty list.
        //

        RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
        InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                        &SharedCacheMap->SharedCacheMapLinks );

        //
        //  Make sure the Lazy Writer will wake up, because we
        //  want him to delete this SharedCacheMap.
        //

        LazyWriter.OtherWork = TRUE;
        if (!LazyWriter.ScanActive) {
            CcScheduleLazyWriteScan( FALSE );
        }
    }

    CcReleaseMasterLock( OldIrql );

    DebugTrace(-1, me, "CcSetFileSizes -> VOID\n", 0 );

    return;
}


VOID
CcPurgeAndClearCacheSection (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset
    )

/*++

Routine Description:

    This routine calls CcPurgeCacheSection after zeroing the end any
    partial page at the start of the range.  If the file is not cached
    it flushes this page before the purge.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

    FileOffset - Offset from which file should be purged - rounded down
               to page boundary.  If NULL, purge the entire file.

ReturnValue:

    FALSE - if the section was not successfully purged
    TRUE - if the section was successfully purged

--*/

{
    ULONG TempLength, Length;
    LARGE_INTEGER LocalFileOffset;
    IO_STATUS_BLOCK IoStatus;
    PVOID TempVa;
    PVACB Vacb;
    LOGICAL ZeroSucceeded = TRUE;

    //
    //  Awareness is indicated by the lowbit of the fileoffset pointer.
    //  Non-awareness of a private write stream results in a no-op.
    //

    if (FlagOn( SharedCacheMap->Flags, PRIVATE_WRITE )) {

        if (((ULONG_PTR)FileOffset & 1) == 0) {
            return;
        }

        FileOffset = (PLARGE_INTEGER)((ULONG_PTR)FileOffset ^ 1);
    }

    //
    //  If a range was specified, then we have to see if we need to
    //  save any user data before purging.
    //

    if ((FileOffset->LowPart & (PAGE_SIZE - 1)) != 0) {

        //
        //  Switch to LocalFileOffset.  We do it this way because we
        //  still pass it on as an optional parameter.
        //

        LocalFileOffset = *FileOffset;
        FileOffset = &LocalFileOffset;

        //
        //  If the file is cached, then we can actually zero the data to
        //  be purged in memory, and not purge those pages.  This is a huge
        //  savings, because sometimes the flushes in the other case cause
        //  us to kill lots of stack, time and I/O doing CcZeroData in especially
        //  large user-mapped files.
        //

        if ((SharedCacheMap->Section != NULL) &&
            (SharedCacheMap->Vacbs != NULL)) {

            //
            //  First zero the first page we are keeping, if it has data, and
            //  adjust FileOffset and Length to allow it to stay.
            //

            TempLength = PAGE_SIZE - (FileOffset->LowPart & (PAGE_SIZE - 1));

            TempVa = CcGetVirtualAddress( SharedCacheMap, *FileOffset, &Vacb, &Length );

            try {

                //
                //  Do not map and zero the page if we are not reducing our notion
                //  of Valid Data, because that does two bad things.  First
                //  CcSetDirtyInMask will arbitrarily smash up ValidDataGoal
                //  (causing a potential invalid CcSetValidData call).  Secondly,
                //  if the Lazy Writer writes the last page ahead of another flush
                //  through MM, then the file system will never see a write from
                //  MM, and will not include the last page in ValidDataLength on
                //  disk.
                //

                RtlZeroMemory( TempVa, TempLength );

            } except (EXCEPTION_EXECUTE_HANDLER) {

                //
                //  If we get an exception here, it means TempVa was not valid
                //  and we got an error trying to page that data in from the
                //  backing file.  If that is the case, then we don't need zero
                //  the end of this file because the file system will take
                //  care of that.  We will just swallow the exception here
                //  and continue.  If we couldn't zero this range, we don't
                //  want to mark that we made data dirty, so remember that
                //  this operation failed.
                //
                
                ZeroSucceeded = FALSE;
            }

            if (ZeroSucceeded) {
                
                if (FileOffset->QuadPart <= SharedCacheMap->ValidDataGoal.QuadPart) {

                    //
                    //  Make sure the Lazy Writer writes it.
                    //

                    CcSetDirtyInMask( SharedCacheMap, FileOffset, TempLength );

                //
                //  Otherwise, we are mapped, so make sure at least that Mm
                //  knows the page is dirty since we zeroed it.
                //

                } else {

                    MmSetAddressRangeModified( TempVa, 1 );
                }

                FileOffset->QuadPart += (LONGLONG)TempLength;
            }

            //
            //  If we get any kind of error, like failing to read the page from
            //  the network, just charge on.  Note that we only read it in order
            //  to zero it and avoid the flush below, so if we cannot read it
            //  there is really no stale data problem.
            //

            CcFreeVirtualAddress( Vacb );

        } else {

            //
            //  First flush the first page we are keeping, if it has data, before
            //  we throw it away.
            //

            MmFlushSection( SharedCacheMap->FileObject->SectionObjectPointer, FileOffset, 1, &IoStatus, FALSE );
        }
    }

    CcPurgeCacheSection( SharedCacheMap->FileObject->SectionObjectPointer,
                         FileOffset,
                         0,
                         FALSE );
}


BOOLEAN
CcPurgeCacheSection (
    IN PSECTION_OBJECT_POINTERS SectionObjectPointer,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN UninitializeCacheMaps
    )

/*++

Routine Description:

    This routine may be called to force a purge of the cache section,
    even if it is cached.  Note, if a user has the file mapped, then the purge
    will *not* take effect, and this must be considered part of normal application
    interaction.  The purpose of purge is to throw away potentially nonzero
    data, so that it will be read in again and presumably zeroed.  This is
    not really a security issue, but rather an effort to not confuse the
    application when it sees nonzero data.  We cannot help the fact that
    a user-mapped view forces us to hang on to stale data.

    This routine is intended to be called whenever previously written
    data is being truncated from the file, and the file is not being
    deleted.

    The file must be acquired exclusive in order to call this routine.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

    FileOffset - Offset from which file should be purged - rounded down
               to page boundary.  If NULL, purge the entire file.

    Length - Defines the length of the byte range to purge, starting at
             FileOffset.  This parameter is ignored if FileOffset is
             specified as NULL.  If FileOffset is specified and Length
             is 0, then purge from FileOffset to the end of the file.

    UninitializeCacheMaps - If TRUE, we should uninitialize all the private
                            cache maps before purging the data.

ReturnValue:

    FALSE - if the section was not successfully purged
    TRUE - if the section was successfully purged

--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    ULONG ActivePage;
    ULONG PageIsDirty;
    BOOLEAN PurgeWorked = TRUE;
    PVACB Vacb = NULL;

    DebugTrace(+1, me, "CcPurgeCacheSection:\n", 0 );
    DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n", SectionObjectPointer );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n",
                            ARGUMENT_PRESENT(FileOffset) ? FileOffset->LowPart
                                                         : 0,
                            ARGUMENT_PRESENT(FileOffset) ? FileOffset->HighPart
                                                         : 0 );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );


    //
    //  If you want us to uninitialize cache maps, the RtlZeroMemory paths
    //  below depend on actually having to purge something after zeroing.
    //

    ASSERT(!UninitializeCacheMaps || (Length == 0) || (Length >= PAGE_SIZE * 2));

    //
    //  Serialize Creation/Deletion of all Shared CacheMaps
    //

    CcAcquireMasterLock( &OldIrql );

    //
    //  Get pointer to SharedCacheMap via File Object.
    //

    SharedCacheMap = SectionObjectPointer->SharedCacheMap;

    //
    //  Increment open count to make sure the SharedCacheMap stays around,
    //  then release the spinlock so that we can call Mm.
    //

    if (SharedCacheMap != NULL) {

        //
        //  Awareness is indicated by the lowbit of the fileoffset pointer.
        //  Non-awareness of a private write stream results in a no-op.
        //

        if (FlagOn( SharedCacheMap->Flags, PRIVATE_WRITE )) {

            if (((ULONG_PTR)FileOffset & 1) == 0) {

                CcReleaseMasterLock( OldIrql );
                return TRUE;
            }

            FileOffset = (PLARGE_INTEGER)((ULONG_PTR)FileOffset ^ 1);
        }

        CcIncrementOpenCount( SharedCacheMap, 'scPS' );

        //
        //  If there is an active Vacb, then nuke it now (before waiting!).
        //

        GetActiveVacbAtDpcLevel( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
    }

    CcReleaseMasterLock( OldIrql );

    if (Vacb != NULL) {

        CcFreeActiveVacb( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
    }

    //
    //  Increment open count to make sure the SharedCacheMap stays around,
    //  then release the spinlock so that we can call Mm.
    //

    if (SharedCacheMap != NULL) {

        //
        // Now loop to make sure that no one is currently caching the file.
        //

        if (UninitializeCacheMaps) {

            while (!IsListEmpty( &SharedCacheMap->PrivateList )) {

                PrivateCacheMap = CONTAINING_RECORD( SharedCacheMap->PrivateList.Flink,
                                                     PRIVATE_CACHE_MAP,
                                                     PrivateLinks );

                CcUninitializeCacheMap( PrivateCacheMap->FileObject, NULL, NULL );
            }
        }

        //
        //  Now, let's unmap and purge here.
        //
        //  We still need to wait for any dangling cache read or writes.
        //
        //  In fact we have to loop and wait because the lazy writer can
        //  sneak in and do an CcGetVirtualAddressIfMapped, and we are not
        //  synchronized.
        //

        while ((SharedCacheMap->Vacbs != NULL) &&
               !CcUnmapVacbArray( SharedCacheMap, FileOffset, Length, FALSE )) {

            CcWaitOnActiveCount( SharedCacheMap );
        }
    }

    //
    //  Purge failures are extremely rare if there are no user mapped sections.
    //  However, it is possible that we will get one from our own mapping, if
    //  the file is being lazy deleted from a previous open.  For that case
    //  we wait here until the purge succeeds, so that we are not left with
    //  old user file data.  Although Length is actually invariant in this loop,
    //  we do need to keep checking that we are allowed to truncate in case a
    //  user maps the file during a delay.
    //

    while (!(PurgeWorked = MmPurgeSection(SectionObjectPointer,
                                          FileOffset,
                                          Length,
                                          (BOOLEAN)((SharedCacheMap !=NULL) &&
                                                    ARGUMENT_PRESENT(FileOffset)))) &&
           (Length == 0) &&
           MmCanFileBeTruncated(SectionObjectPointer, FileOffset)) {

        (VOID)KeDelayExecutionThread( KernelMode, FALSE, &CcCollisionDelay );
    }

    //
    //  Reduce the open count on the SharedCacheMap if there was one.
    //

    if (SharedCacheMap != NULL) {

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'scPF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }

    DebugTrace(-1, me, "CcPurgeCacheSection -> %02lx\n", PurgeWorked );

    return PurgeWorked;
}


//
//  Internal support routine.
//

VOID
CcUnmapAndPurge(
    IN PSHARED_CACHE_MAP SharedCacheMap
    )

/*++

Routine Description:

    This routine may be called to unmap and purge a section, causing Memory
    Management to throw the pages out and reset his notion of file size.

Arguments:

    SharedCacheMap - Pointer to SharedCacheMap of section to purge.

Return Value:

    None.

--*/

{
    PFILE_OBJECT FileObject;

    FileObject = SharedCacheMap->FileObject;

    //
    //  Unmap all Vacbs
    //

    if (SharedCacheMap->Vacbs != NULL) {
        (VOID)CcUnmapVacbArray( SharedCacheMap, NULL, 0, FALSE );
    }

    //
    //  Now that the file is unmapped, we can purge the truncated
    //  pages from memory, if TRUNCATE_REQUIRED.  Note that since the
    //  entire section is being purged (FileSize == NULL), the purge
    //  and subsequent delete  of the SharedCacheMap should drop
    //  all references on the section and file object clearing the
    //  way for the Close Call and actual file delete to occur
    //  immediately.
    //

    if (FlagOn(SharedCacheMap->Flags, TRUNCATE_REQUIRED)) {

        DebugTrace( 0, mm, "MmPurgeSection:\n", 0 );
        DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n",
                    FileObject->SectionObjectPointer );
        DebugTrace2(0, mm, "    Offset = %08lx\n",
                    SharedCacheMap->FileSize.LowPart,
                    SharedCacheMap->FileSize.HighPart );

        CcPurgeCacheSection( FileObject->SectionObjectPointer,
                             NULL,
                             0,
                             FALSE );
    }
}


VOID
CcDeleteMbcb(
    IN PSHARED_CACHE_MAP SharedCacheMap
    )

/*++

Routine Description:

    This routine may be called to reset the Mbcb for a stream to say
    there are no dirty pages, and free all auxillary allocation.

Arguments:

    SharedCacheMap - Pointer to SharedCacheMap.

Return Value:

    None.

--*/

{
    PMBCB Mbcb;
    PBITMAP_RANGE BitmapRange;
    KLOCK_QUEUE_HANDLE LockHandle;
    ULONG DoDrain = FALSE;
    PLIST_ENTRY NextEntry;
    LIST_ENTRY BitmapRangesToFree;

    InitializeListHead( &BitmapRangesToFree );

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    Mbcb = SharedCacheMap->Mbcb;

    //
    //  Is there an Mbcb?
    //

    if (Mbcb != NULL) {

        //
        //  First deduct the dirty pages we are getting rid of.
        //

        CcAcquireMasterLockAtDpcLevel();
        CcDeductDirtyPages( SharedCacheMap, Mbcb->DirtyPages );
        CcReleaseMasterLockFromDpcLevel();

        //
        //  Now loop through all of the ranges.
        //

        while (!IsListEmpty(&Mbcb->BitmapRanges)) {

            //
            //  Get next range and remove it from the list.
            //

            BitmapRange = (PBITMAP_RANGE)CONTAINING_RECORD( Mbcb->BitmapRanges.Flink,
                                                            BITMAP_RANGE,
                                                            Links );

            RemoveEntryList( &BitmapRange->Links );

            //
            //  If there is a bitmap, and it is not the initial embedded one, then
            //  delete it.
            //

            if ((BitmapRange->Bitmap != NULL) &&
                (BitmapRange->Bitmap != (PULONG)&Mbcb->BitmapRange2)) {

                DoDrain = TRUE;

                //
                //  Usually the bitmap is all zeros at this point, but it may not be.
                //

                if (BitmapRange->DirtyPages != 0) {
                    RtlZeroMemory( BitmapRange->Bitmap, MBCB_BITMAP_BLOCK_SIZE );
                }
                CcAcquireVacbLockAtDpcLevel();
                CcDeallocateVacbLevel( (PVACB *)BitmapRange->Bitmap, FALSE );
                CcReleaseVacbLockFromDpcLevel();
            }

            //
            //  If the range is not one of the initial embedded ranges, then delete it.
            //

            if ((BitmapRange < (PBITMAP_RANGE)Mbcb) ||
                (BitmapRange >= (PBITMAP_RANGE)((PCHAR)Mbcb + sizeof(MBCB)))) {

                InsertTailList( &BitmapRangesToFree, &BitmapRange->Links );
            }
        }

        //
        //  Zero the pointer and get out.
        //

        SharedCacheMap->Mbcb = NULL;

        KeReleaseInStackQueuedSpinLock( &LockHandle );

        //
        // Free all the pool now that no locks are held.
        //

        while (!IsListEmpty(&BitmapRangesToFree)) {
            NextEntry = RemoveHeadList( &BitmapRangesToFree );

            BitmapRange = CONTAINING_RECORD ( NextEntry,
                                              BITMAP_RANGE,
                                              Links );

            ExFreePool( BitmapRange );
        }

        //
        //  Now delete the Mbcb.
        //

        CcDeallocateBcb( (PBCB)Mbcb );

    } else {

        KeReleaseInStackQueuedSpinLock( &LockHandle );
    }

    if (DoDrain) {
        CcDrainVacbLevelZone();
    }
}


VOID
CcSetDirtyPageThreshold (
    IN PFILE_OBJECT FileObject,
    IN ULONG DirtyPageThreshold
    )

/*++

Routine Description:

    This routine may be called to set a dirty page threshold for this
    stream.  The write throttling will kick in whenever the file system
    attempts to exceed the dirty page threshold for this file.

Arguments:

    FileObject - Supplies file object for the stream

    DirtyPageThreshold - Supplies the dirty page threshold for this stream,
                         or 0 for no threshold.

Return Value:

    None

Environment:

    The caller must guarantee exclusive access to the FsRtl header flags,
    for example, by calling this routine once during create of the structure
    containing the header.  Then it would call the routine again when actually
    caching the stream.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    if (SharedCacheMap != NULL) {

        SharedCacheMap->DirtyPageThreshold = DirtyPageThreshold;
    }

    //
    //  Test the flag before setting, in case the caller is no longer properly
    //  synchronized.
    //

    if (!FlagOn(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
                FSRTL_FLAG_LIMIT_MODIFIED_PAGES)) {

        SetFlag(((PFSRTL_COMMON_FCB_HEADER)(FileObject->FsContext))->Flags,
                FSRTL_FLAG_LIMIT_MODIFIED_PAGES);
    }
}


VOID
CcZeroEndOfLastPage (
    IN PFILE_OBJECT FileObject
    )

/*++

Routine Description:

    This routine is only called by Mm before mapping a user view to
    a section.  If there is an uninitialized page at the end of the
    file, we zero it by freeing that page.

Parameters:

    FileObject - File object for section to be mapped

Return Value:

    None
--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    ULONG ActivePage;
    ULONG PageIsDirty;
    KIRQL OldIrql;
    PVOID NeedToZero = NULL;
    PVACB ActiveVacb = NULL;
    IO_STATUS_BLOCK Iosb;
    BOOLEAN PurgeResult;
    BOOLEAN ReferencedCacheMap = FALSE;
    
    //
    //  See if we have an active Vacb, that we need to free.
    //

    FsRtlAcquireFileExclusive( FileObject );
    CcAcquireMasterLock( &OldIrql );
    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    if (SharedCacheMap != NULL) {

        //
        //  See if there is an active vacb.
        //

        if ((SharedCacheMap->ActiveVacb != NULL) || ((NeedToZero = SharedCacheMap->NeedToZero) != NULL)) {

            CcIncrementOpenCount( SharedCacheMap, 'peZS' );
            ReferencedCacheMap = TRUE;
            GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
        }
    }

    CcReleaseMasterLock( OldIrql );

    //
    //  Remember in FsRtl header there is a user section.
    //  If this is an advanced header then also acquire the mutex to access
    //  this field.
    //

    if (FlagOn( ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags,
                FSRTL_FLAG_ADVANCED_HEADER )) {

        ExAcquireFastMutex( ((PFSRTL_ADVANCED_FCB_HEADER)FileObject->FsContext)->FastMutex );

        SetFlag( ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags,
                 FSRTL_FLAG_USER_MAPPED_FILE );

        ExReleaseFastMutex( ((PFSRTL_ADVANCED_FCB_HEADER)FileObject->FsContext)->FastMutex );

    } else {

        SetFlag( ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags,
                 FSRTL_FLAG_USER_MAPPED_FILE );
    }

    //
    //  Free the active vacb now so we don't deadlock if we have to purge
    //


    if ((ActiveVacb != NULL) || (NeedToZero != NULL)) {
        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }


    if (FlagOn( ((PFSRTL_COMMON_FCB_HEADER)FileObject->FsContext)->Flags2, FSRTL_FLAG2_PURGE_WHEN_MAPPED )) {

        if (FileObject->SectionObjectPointer->SharedCacheMap) {
            ASSERT( ((PSHARED_CACHE_MAP)(FileObject->SectionObjectPointer->SharedCacheMap))->VacbActiveCount == 0 );
        }

        CcFlushCache( FileObject->SectionObjectPointer, NULL, 0, &Iosb );

        //
        //  Only purge if the flush was successful so we don't lose user data
        //  

        if (Iosb.Status == STATUS_SUCCESS) {
            PurgeResult = CcPurgeCacheSection( FileObject->SectionObjectPointer, NULL, 0, FALSE );
        }

        if (FileObject->SectionObjectPointer->SharedCacheMap) {
            ASSERT( ((PSHARED_CACHE_MAP)(FileObject->SectionObjectPointer->SharedCacheMap))->VacbActiveCount == 0 );
        }
    }


    FsRtlReleaseFile( FileObject );

    //
    //  If the file is cached and we have a Vacb to free, we need to
    //  use the lazy writer callback to synchronize so no one will be
    //  extending valid data.
    //

    if (ReferencedCacheMap) {

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'peZF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }
}


BOOLEAN
CcZeroData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER StartOffset,
    IN PLARGE_INTEGER EndOffset,
    IN BOOLEAN Wait
    )

/*++

Routine Description:

    This routine attempts to zero the specified file data and deliver the
    correct I/O status.

    If the caller does not want to block (such as for disk I/O), then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to zero all of the requested data without
    blocking, then this routine will return FALSE.  However, if the
    required space is immediately accessible in the cache and no blocking is
    required, this routine zeros the data and returns TRUE.

    If the caller supplies Wait as TRUE, then this routine is guaranteed
    to zero the data and return TRUE.  If the correct space is immediately
    accessible in the cache, then no blocking will occur.  Otherwise,
    the necessary work will be initiated to read and/or free cache data,
    and the caller will be blocked until the data can be received.

    File system Fsd's should typically supply Wait = TRUE if they are
    processing a synchronous I/O requests, or Wait = FALSE if they are
    processing an asynchronous request.

    File system threads should supply Wait = TRUE.

    IMPORTANT NOTE: File systems which call this routine must be prepared
    to handle a special form of a write call where the Mdl is already
    supplied.  Namely, if Irp->MdlAddress is supplied, the file system
    must check the low order bit of Irp->MdlAddress->ByteOffset.  If it
    is set, that means that the Irp was generated in this routine and
    the file system must do two things:

        Decrement Irp->MdlAddress->ByteOffset and Irp->UserBuffer

        Clear Irp->MdlAddress immediately prior to completing the
        request, as this routine expects to reuse the Mdl and
        ultimately deallocate the Mdl itself.

Arguments:

    FileObject - pointer to the FileObject for which a range of bytes
                 is to be zeroed.  This FileObject may either be for
                 a cached file or a noncached file.  If the file is
                 not cached, then WriteThrough must be TRUE and
                 StartOffset and EndOffset must be on sector boundaries.

    StartOffset - Start offset in file to be zeroed.

    EndOffset - End offset in file to be zeroed.

    Wait - FALSE if caller may not block, TRUE otherwise (see description
           above)

Return Value:

    FALSE - if Wait was supplied as FALSE and the data was not zeroed.

    TRUE - if the data has been zeroed.

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.
        This can only occur if Wait was specified as TRUE.  (If Wait is
        specified as FALSE, and an allocation failure occurs, this
        routine simply returns FALSE.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    LARGE_INTEGER ToGo;
    ULONG ZeroBytes, ZeroTransfer;
    ULONG SectorMask;
    ULONG i;
    BOOLEAN WriteThrough;
    BOOLEAN AggressiveZero = FALSE;
    ULONG SavedState = 0;
    ULONG MaxZerosInCache = MAX_ZEROS_IN_CACHE;
    ULONG NumberOfColors = 1;

    PBCB Bcb = NULL;
    PCHAR Zeros = NULL;
    PMDL ZeroMdl = NULL;
    ULONG MaxBytesMappedInMdl = 0;
    BOOLEAN Result = TRUE;

    PPFN_NUMBER Page;
    ULONG SavedByteCount;
    LARGE_INTEGER SizeLeft;

    DebugTrace(+1, me, "CcZeroData\n", 0 );

    WriteThrough = (BOOLEAN)(((FileObject->Flags & FO_WRITE_THROUGH) != 0) ||
                   (FileObject->PrivateCacheMap == NULL));

    //
    //  If the caller specified Wait, but the FileObject is WriteThrough,
    //  then we need to just get out.
    //

    if (WriteThrough && !Wait) {

        DebugTrace(-1, me, "CcZeroData->FALSE (WriteThrough && !Wait)\n", 0 );

        return FALSE;
    }

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    SectorMask = IoGetRelatedDeviceObject(FileObject)->SectorSize - 1;

    FOffset = *StartOffset;

    //
    //  Calculate how much to zero this time.
    //

    ToGo.QuadPart = EndOffset->QuadPart - FOffset.QuadPart;

    //
    //  This magic number is what the fastpaths throttle on, and they will present
    //  non-sector aligned zeroing requests. As long as we will always handle them
    //  on the cached path, we are OK.
    //
    //  If we will not make the cached path, the request must be aligned.
    //

    ASSERT( ToGo.QuadPart <= 0x2000 ||
            ((ToGo.LowPart & SectorMask) == 0  &&
             (FOffset.LowPart & SectorMask) == 0));

    //
    //  We will only do zeroing in the cache if the caller is using a
    //  cached file object, and did not specify WriteThrough.  We are
    //  willing to zero some data in the cache if our total is not too
    //  much, or there is sufficient available pages.
    //

    if (((ToGo.QuadPart <= 0x2000) ||
         (MmAvailablePages >= ((MAX_ZEROS_IN_CACHE / PAGE_SIZE) * 4))) && !WriteThrough) {

        try {

            while (MaxZerosInCache != 0) {

                ULONG ReceivedLength;
                LARGE_INTEGER BeyondLastByte;

                if ( ToGo.QuadPart > (LONGLONG)MaxZerosInCache ) {

                    //
                    //  If Wait == FALSE, then there is no point in getting started,
                    //  because we would have to start all over again zeroing with
                    //  Wait == TRUE, since we would fall out of this loop and
                    //  start synchronously writing pages to disk.
                    //

                    if (!Wait) {

                        DebugTrace(-1, me, "CcZeroData -> FALSE\n", 0 );

                        try_return( Result = FALSE );
                    }
                }
                else {
                    MaxZerosInCache = ToGo.LowPart;
                }

                //
                //  Call local routine to Map or Access the file data, then zero the data,
                //  then call another local routine to free the data.  If we cannot map
                //  the data because of a Wait condition, return FALSE.
                //
                //  Note that this call may result in an exception, however, if it
                //  does no Bcb is returned and this routine has absolutely no
                //  cleanup to perform.  Therefore, we do not have a try-finally
                //  and we allow the possibility that we will simply be unwound
                //  without notice.
                //

                if (!CcPinFileData( FileObject,
                                    &FOffset,
                                    MaxZerosInCache,
                                    FALSE,
                                    TRUE,
                                    Wait,
                                    &Bcb,
                                    &CacheBuffer,
                                    &BeyondLastByte )) {

                    DebugTrace(-1, me, "CcZeroData -> FALSE\n", 0 );

                    try_return( Result = FALSE );
                }

                //
                //  Calculate how much data is described by Bcb starting at our desired
                //  file offset.  If it is more than we need, we will zero the whole thing
                //  anyway.
                //

                ReceivedLength = (ULONG)(BeyondLastByte.QuadPart - FOffset.QuadPart );

                //
                //  Now attempt to allocate an Mdl to describe the mapped data.
                //

                ZeroMdl = IoAllocateMdl( CacheBuffer,
                                         ReceivedLength,
                                         FALSE,
                                         FALSE,
                                         NULL );

                if (ZeroMdl == NULL) {

                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }

                //
                //  It is necessary to probe and lock the pages, or else
                //  the pages may not still be in memory when we do the
                //  MmSetAddressRangeModified for the dirty Bcb.
                //

                MmDisablePageFaultClustering(&SavedState);
                MmProbeAndLockPages( ZeroMdl, KernelMode, IoReadAccess );
                MmEnablePageFaultClustering(SavedState);
                SavedState = 0;

                //
                //  Assume we did not get all the data we wanted, and set FOffset
                //  to the end of the returned data, and advance buffer pointer.
                //

                FOffset = BeyondLastByte;

                //
                //  Figure out how many bytes we are allowed to zero in the cache.
                //  Note it is possible we have zeroed a little more than our maximum,
                //  because we hit an existing Bcb that extended beyond the range.
                //

                if (MaxZerosInCache <= ReceivedLength) {
                    MaxZerosInCache = 0;
                }
                else {
                    MaxZerosInCache -= ReceivedLength;
                }

                //
                //  Now set the Bcb dirty.  We have to explicitly set the address
                //  range modified here, because that work otherwise gets deferred
                //  to the Lazy Writer.
                //

                MmSetAddressRangeModified( CacheBuffer, ReceivedLength );
                CcSetDirtyPinnedData( Bcb, NULL );

                //
                //  Unmap the data now
                //

                CcUnpinFileData( Bcb, FALSE, UNPIN );
                Bcb = NULL;

                //
                //  Unlock and free the Mdl (we only loop back if we crossed
                //  a 256KB boundary.
                //

                MmUnlockPages( ZeroMdl );
                IoFreeMdl( ZeroMdl );
                ZeroMdl = NULL;
            }

        try_exit: NOTHING;
        } finally {

            if (SavedState != 0) {
                MmEnablePageFaultClustering(SavedState);
            }

            //
            //  Clean up only necessary in abnormal termination.
            //

            if (Bcb != NULL) {

                CcUnpinFileData( Bcb, FALSE, UNPIN );
            }

            //
            //  Since the last thing in the above loop which can
            //  fail is the MmProbeAndLockPages, we only need to
            //  free the Mdl here.
            //

            if (ZeroMdl != NULL) {

                IoFreeMdl( ZeroMdl );
            }
        }

        //
        //  If hit a wait condition above, return it now.
        //

        if (!Result) {
            return FALSE;
        }

        //
        //  If we finished, get out nbow.
        //

        if ( FOffset.QuadPart >= EndOffset->QuadPart ) {
            return TRUE;
        }
    }

    //
    //  We either get here because we decided above not to zero anything in
    //  the cache directly, or else we zeroed up to our maximum and still
    //  have some left to zero direct to the file on disk.  In either case,
    //  we will now zero from FOffset to *EndOffset, and then flush this
    //  range in case the file is cached/mapped, and there are modified
    //  changes in memory.
    //

    //
    //  Round FOffset and EndOffset up to sector boundaries, since
    //  we will be doing disk I/O, and calculate size left.
    //

    ASSERT( (FOffset.LowPart & SectorMask) == 0 );

    FOffset.QuadPart += (LONGLONG)SectorMask;
    FOffset.LowPart &= ~SectorMask;
    SizeLeft.QuadPart = EndOffset->QuadPart + (LONGLONG)SectorMask;
    SizeLeft.LowPart &= ~SectorMask;
    SizeLeft.QuadPart -= FOffset.QuadPart;

    ASSERT( (FOffset.LowPart & SectorMask) == 0 );
    ASSERT( (SizeLeft.LowPart & SectorMask) == 0 );

    if (SizeLeft.QuadPart == 0) {
        return TRUE;
    }

    //
    //  try-finally to guarantee cleanup.
    //

    try {

        //
        //  Allocate a page to hold the zeros we will write, and
        //  zero it.
        //

        ZeroBytes = NumberOfColors * PAGE_SIZE;

        if (SizeLeft.HighPart == 0 && SizeLeft.LowPart < ZeroBytes) {
            ZeroBytes = SizeLeft.LowPart;
        }

        Zeros = (PCHAR)ExAllocatePoolWithTag( NonPagedPoolCacheAligned, ZeroBytes, 'eZcC' );

        if (Zeros != NULL) {

            //
            //  Allocate and initialize an Mdl to describe the zeros
            //  we need to transfer.  Allocate to cover the maximum
            //  size required, and we will use and reuse it in the
            //  loop below, initialized correctly.
            //

            if (SizeLeft.HighPart == 0 && SizeLeft.LowPart < MAX_ZERO_TRANSFER) {

                ZeroTransfer = SizeLeft.LowPart;

            } else {

                //
                //  See how aggressive we can afford to be.
                //

                if (InterlockedIncrement( &CcAggressiveZeroCount ) <= CcAggressiveZeroThreshold) {
                    AggressiveZero = TRUE;
                    ZeroTransfer = MAX_ZERO_TRANSFER;
                } else {
                    InterlockedDecrement( &CcAggressiveZeroCount );
                    ZeroTransfer = MIN_ZERO_TRANSFER;
                }
            }

            //
            //  Since the maximum zero may start at a very aggresive level, fall back
            //  until we really have to give up.  Since filter drivers, filesystems and
            //  even storage drivers may need to map this Mdl, we have to pre-map it
            //  into system space so that we know enough PTEs are available.  We also
            //  need to throttle our consumption of virtual addresses based on the size
            //  of the system and the number of parallel instances of this work outstanding.
            //  This may be a bit of overkill, but since running out of PTEs is a fatal
            //  event for the rest of the system, try to help out while still being fast.
            //

            while (TRUE) {

                //
                //  Spin down trying to get an MDL which can describe our operation.
                //
                
                while (TRUE) {

                    ZeroMdl = IoAllocateMdl( Zeros, ZeroTransfer, FALSE, FALSE, NULL );
                
                    //
                    //  Throttle ourselves to what we've physically allocated.  Note that
                    //  we could have started with an odd multiple of this number.  If we
                    //  tried for exactly that size and failed, we're toast.
                    //

                    if (ZeroMdl || ZeroTransfer == ZeroBytes) {

                        break;
                    }
                
                    Fall_Back:
                
                    //
                    //  Fallback by half and round down to a sector multiple.
                    //
                        
                    ZeroTransfer /= 2;
                    ZeroTransfer &= ~SectorMask;
                    if (ZeroTransfer < ZeroBytes) {
                        ZeroTransfer = ZeroBytes;
                    }

                    ASSERT( (ZeroTransfer & SectorMask) == 0 && ZeroTransfer != 0);
                }

                if (ZeroMdl == NULL) {

                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }

                //
                //  If we have throttled all the way down, stop and just build a
                //  simple MDL describing our previous allocation.
                //

                if (ZeroTransfer == ZeroBytes) {

                    MmBuildMdlForNonPagedPool( ZeroMdl );
                    break;
                }

                //
                //  Now we will temporarily lock the allocated pages
                //  only, and then replicate the page frame numbers through
                //  the entire Mdl to keep writing the same pages of zeros.
                //
                //  It would be nice if Mm exported a way for us to not have
                //  to pull the Mdl apart and rebuild it ourselves, but this
                //  is so bizzare a purpose as to be tolerable.
                //

                SavedByteCount = ZeroMdl->ByteCount;
                ZeroMdl->ByteCount = ZeroBytes;
                MmBuildMdlForNonPagedPool( ZeroMdl );

                ZeroMdl->MdlFlags &= ~MDL_SOURCE_IS_NONPAGED_POOL;
                ZeroMdl->MdlFlags |= MDL_PAGES_LOCKED;
                ZeroMdl->MappedSystemVa = NULL;
                ZeroMdl->ByteCount = SavedByteCount;
                Page = MmGetMdlPfnArray( ZeroMdl );
                for (i = NumberOfColors;
                     i < (ADDRESS_AND_SIZE_TO_SPAN_PAGES( 0, SavedByteCount ));
                     i++) {

                    *(Page + i) = *(Page + i - NumberOfColors);
                }

                if (MmGetSystemAddressForMdlSafe( ZeroMdl, LowPagePriority ) == NULL) {

                    //
                    //  Blow away this Mdl and trim for the retry.  Since it didn't
                    //  get mapped, there is nothing fancy to do.
                    //

                    IoFreeMdl( ZeroMdl );
                    goto Fall_Back;
                }

                break;
            }

        //
        //  We failed to allocate the space we wanted, so we will go to
        //  half of a page and limp along.
        //

        } else {

            //
            //  Of course, if we have a device which has large sectors, that defines
            //  the lower limit of our attempt.
            //

            if (IoGetRelatedDeviceObject(FileObject)->SectorSize < PAGE_SIZE / 2) {
                
                ZeroBytes = PAGE_SIZE / 2;
                Zeros = (PCHAR)ExAllocatePoolWithTag( NonPagedPoolCacheAligned, ZeroBytes, 'eZcC' );
            }

            //
            //  If we cannot get even that much, then let's write a sector at a time.
            //

            if (Zeros == NULL) {

                ZeroBytes = IoGetRelatedDeviceObject(FileObject)->SectorSize;
                Zeros = (PCHAR)ExAllocatePoolWithTag( NonPagedPoolCacheAligned, ZeroBytes, 'eZcC' );

                //
                //  If we cannot get even the minimum, we have to give up.
                //

                if (Zeros == NULL) {
                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }
            }

            //
            //  Allocate and initialize an Mdl to describe the zeros
            //  we need to transfer.  Allocate to cover the maximum
            //  size required, and we will use and reuse it in the
            //  loop below, initialized correctly.
            //

            ZeroTransfer = ZeroBytes;
            ZeroMdl = IoAllocateMdl( Zeros, ZeroBytes, FALSE, FALSE, NULL );

            ASSERT( (ZeroTransfer & SectorMask) == 0 );

            if (ZeroMdl == NULL) {
                ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
            }

            //
            //  Now we will lock and map the allocated pages.
            //

            MmBuildMdlForNonPagedPool( ZeroMdl );

            ASSERT( ZeroMdl->MappedSystemVa == Zeros );
        }

        //
        //  Zero the buffer now.
        //

        RtlZeroMemory( Zeros, ZeroBytes );

        //
        //  We have a mapped and zeroed range back by an MDL to use.  Note the
        //  size we have for cleanup, since we will possibly wind this down
        //  over the operation.
        //

        ASSERT( MmGetSystemAddressForMdl(ZeroMdl) );
        MaxBytesMappedInMdl = ZeroMdl->ByteCount;

        //
        //  Now loop to write buffers full of zeros through to the file
        //  until we reach the starting Vbn for the transfer.
        //

        ASSERT( ZeroTransfer != 0 &&
                (ZeroTransfer & SectorMask) == 0 &&
                (SizeLeft.LowPart & SectorMask) == 0 );

        while ( SizeLeft.QuadPart != 0 ) {

            IO_STATUS_BLOCK IoStatus;
            NTSTATUS Status;
            KEVENT Event;

            //
            //  See if we really need to write that many zeros, and
            //  trim the size back if not.
            //

            if ( (LONGLONG)ZeroTransfer > SizeLeft.QuadPart ) {

                ZeroTransfer = SizeLeft.LowPart;
            }

            //
            //  (Re)initialize the kernel event to FALSE.
            //

            KeInitializeEvent( &Event, NotificationEvent, FALSE );

            //
            //  Initiate and wait for the synchronous transfer.
            //

            ZeroMdl->ByteCount = ZeroTransfer;

            Status = IoSynchronousPageWrite( FileObject,
                                             ZeroMdl,
                                             &FOffset,
                                             &Event,
                                             &IoStatus );

            //
            //  If pending is returned (which is a successful status),
            //  we must wait for the request to complete.
            //

            if (Status == STATUS_PENDING) {
                KeWaitForSingleObject( &Event,
                                       Executive,
                                       KernelMode,
                                       FALSE,
                                       (PLARGE_INTEGER)NULL);
            }


            //
            //  If we got an error back in Status, then the Iosb
            //  was not written, so we will just copy the status
            //  there, then test the final status after that.
            //

            if (!NT_SUCCESS(Status)) {
                ExRaiseStatus( Status );
            }

            if (!NT_SUCCESS(IoStatus.Status)) {
                ExRaiseStatus( IoStatus.Status );
            }

            //
            //  If we succeeded, then update where we are at by how much
            //  we wrote, and loop back to see if there is more.
            //

            FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)ZeroTransfer;
            SizeLeft.QuadPart = SizeLeft.QuadPart - (LONGLONG)ZeroTransfer;
        }
    }
    finally{

        //
        //  Clean up anything from zeroing pages on a noncached
        //  write.
        //

        if (ZeroMdl != NULL) {

            if ((MaxBytesMappedInMdl != 0) &&
                !FlagOn(ZeroMdl->MdlFlags, MDL_SOURCE_IS_NONPAGED_POOL)) {
                ZeroMdl->ByteCount = MaxBytesMappedInMdl;
                MmUnmapLockedPages (ZeroMdl->MappedSystemVa, ZeroMdl);
            }

            IoFreeMdl( ZeroMdl );
        }

        if (AggressiveZero) {
            InterlockedDecrement( &CcAggressiveZeroCount );
        }

        if (Zeros != NULL) {
            ExFreePool( Zeros );
        }

        DebugTrace(-1, me, "CcZeroData -> TRUE\n", 0 );
    }

    return TRUE;
}


PFILE_OBJECT
CcGetFileObjectFromSectionPtrs (
    IN PSECTION_OBJECT_POINTERS SectionObjectPointer
    )

/*++

This routine may be used to retrieve a pointer to the FileObject that the
Cache Manager is using for a given file from the Section Object Pointers
in the nonpaged File System structure Fcb.  The use of this function is
intended for exceptional use unrelated to the processing of user requests,
when the File System would otherwise not have a FileObject at its disposal.
An example is for mount verification.

Note that the File System is responsible for insuring that the File
Object does not go away while in use.  It is impossible for the Cache
Manager to guarantee this.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

Return Value:

    Pointer to the File Object, or NULL if the file is not cached or no
    longer cached

--*/

{
    KIRQL OldIrql;
    PFILE_OBJECT FileObject = NULL;

    //
    //  Serialize with Creation/Deletion of all Shared CacheMaps
    //

    CcAcquireMasterLock( &OldIrql );

    if (SectionObjectPointer->SharedCacheMap != NULL) {

        FileObject = ((PSHARED_CACHE_MAP)SectionObjectPointer->SharedCacheMap)->FileObject;
    }

    CcReleaseMasterLock( OldIrql );

    return FileObject;
}


PFILE_OBJECT
CcGetFileObjectFromBcb (
    IN PVOID Bcb
    )

/*++

This routine may be used to retrieve a pointer to the FileObject that the
Cache Manager is using for a given file from a Bcb of that file.

Note that the File System is responsible for insuring that the File
Object does not go away while in use.  It is impossible for the Cache
Manager to guarantee this.

Arguments:

    Bcb - A pointer to the pinned Bcb.

Return Value:

    Pointer to the File Object, or NULL if the file is not cached or no
    longer cached

--*/

{
    return ((PBCB)Bcb)->SharedCacheMap->FileObject;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\ccperf.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

   CcPerf.c

Abstract:

    This module contains the perf trace routines in Cc Component

Author:

    Stephen Hsiao (shsiao) 2-Feb-2001

Revision History:

--*/

#include "cc.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGEWMI, CcPerfFileRunDown)
#endif //ALLOC_PRAGMA

VOID
CcPerfFileRunDown(
    PPERFINFO_ENTRY_TABLE HashTable
    )
/*++

Routine Description:

    This routine walks the following lists:

    1. CcDirtySharedCacheMapList
    2. CcCleanSharedCacheMapList
    
    and returns a pointer to a pool allocation
    containing the referenced file object pointers.

Arguments:
 
    None.
 
Return Value:
 
    Returns a pointer to a NULL terminated pool allocation 
    containing the file object pointers from the two lists, 
    NULL if the memory could not be allocated.
     
    It is also the responsibility of the caller to dereference each
    file object in the list and then free the returned pool.

Environment:

    PASSIVE_LEVEL, arbitrary thread context.
--*/
{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;

    ASSERT (KeGetCurrentIrql () == PASSIVE_LEVEL);

    CcAcquireMasterLock( &OldIrql );

    //
    // Walk through CcDirtySharedCacheMapList
    //
    
    SharedCacheMap = CONTAINING_RECORD( CcDirtySharedCacheMapList.SharedCacheMapLinks.Flink,
                                        SHARED_CACHE_MAP,
                                        SharedCacheMapLinks );
    
    while (&SharedCacheMap->SharedCacheMapLinks != &CcDirtySharedCacheMapList.SharedCacheMapLinks) {
        //
        //  Skip over cursors
        //
        if (!FlagOn(SharedCacheMap->Flags, IS_CURSOR)) {
            PerfInfoAddToFileHash(HashTable, SharedCacheMap->FileObject);
        }
        SharedCacheMap = CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                                            SHARED_CACHE_MAP,
                                            SharedCacheMapLinks );
    }                   

    //
    // CcCleanSharedCacheMapList
    //
    SharedCacheMap = CONTAINING_RECORD( CcCleanSharedCacheMapList.Flink,
                                        SHARED_CACHE_MAP,
                                        SharedCacheMapLinks );

    while (&SharedCacheMap->SharedCacheMapLinks != &CcCleanSharedCacheMapList) {
        PerfInfoAddToFileHash(HashTable, SharedCacheMap->FileObject);

        SharedCacheMap = CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                                            SHARED_CACHE_MAP,
                                            SharedCacheMapLinks );

    }

    CcReleaseMasterLock( OldIrql );
    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\cachesub.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    cachesub.c

Abstract:

    This module implements the common subroutines for the Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  The Bug check file id for this module
//

#define BugCheckFileId                   (CACHE_BUG_CHECK_CACHESUB)

//
//  Define our debug constant
//

#define me 0x00000002

//
//  Define those errors which should be retried
//

#define RetryError(STS) (((STS) == STATUS_VERIFY_REQUIRED) || ((STS) == STATUS_FILE_LOCK_CONFLICT))

ULONG CcMaxDirtyWrite = 0x10000;

//
//  Local support routines
//

BOOLEAN
CcFindBcb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN OUT PLARGE_INTEGER BeyondLastByte,
    OUT PBCB *Bcb
    );

PBCB
CcAllocateInitializeBcb (
    IN OUT PSHARED_CACHE_MAP SharedCacheMap OPTIONAL,
    IN OUT PBCB AfterBcb,
    IN PLARGE_INTEGER FileOffset,
    IN PLARGE_INTEGER Length
    );

NTSTATUS
CcSetValidData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER ValidDataLength
    );

BOOLEAN
CcAcquireByteRangeForWrite (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER TargetOffset OPTIONAL,
    IN ULONG TargetLength,
    OUT PLARGE_INTEGER FileOffset,
    OUT PULONG Length,
    OUT PBCB *FirstBcb
    );

VOID
CcReleaseByteRangeFromWrite (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN PBCB FirstBcb,
    IN BOOLEAN VerifyRequired
    );

PBITMAP_RANGE
CcFindBitmapRangeToDirty (
    IN PMBCB Mbcb,
    IN LONGLONG Page,
    IN PULONG *FreePageForSetting
    );

PBITMAP_RANGE
CcFindBitmapRangeToClean (
    IN PMBCB Mbcb,
    IN LONGLONG Page
    );

BOOLEAN
CcLogError(
    IN PFILE_OBJECT FileObject,
    IN PUNICODE_STRING FileName,
    IN NTSTATUS Error,
    IN NTSTATUS DeviceError,
    IN UCHAR IrpMajorCode
    );



//
//  Internal support routine
//

BOOLEAN
CcPinFileData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN ReadOnly,
    IN BOOLEAN WriteOnly,
    IN ULONG Flags,
    OUT PBCB *Bcb,
    OUT PVOID *BaseAddress,
    OUT PLARGE_INTEGER BeyondLastByte
    )

/*++

Routine Description:

    This routine locks the specified range of file data into memory.

    Note that the data desired by the caller (or the first part of it)
    may be in one of three states:

        No Bcb exists which describes the data

        A Bcb exists describing the data, but it is not mapped
        (BcbOut->BaseAddress == NULL)

        A Bcb exists describing the data, and it is mapped

    Given the above three states, and given that the caller may call
    with either Wait == FALSE or Wait == TRUE, this routine has basically
    six cases.  What has to be done, and the order in which things must be
    done varies quite a bit with each of these six cases.  The most
    straight-forward implementation of this routine, with the least amount
    of branching, is achieved by determining which of the six cases applies,
    and dispatching fairly directly to that case.  The handling of the
    cases is summarized in the following table:

                Wait == TRUE                Wait == FALSE
                ------------                -------------

    no Bcb      Case 1:                     Case 2:

                CcAllocateInitializeBcb     CcMapAndRead (exit if FALSE)
                Acquire Bcb Exclusive       CcAllocateInitializeBcb
                Release BcbList SpinLock    Acquire Bcb Shared if not ReadOnly
                CcMapAndRead w/ Wait        Release BcbList SpinLock
                Convert/Release Bcb Resource

    Bcb not     Case 3:                     Case 4:
    mapped
                Increment PinCount          Acquire Bcb Exclusive (exit if FALSE)
                Release BcbList SpinLock    CcMapAndRead (exit if FALSE)
                Acquire Bcb Excl. w/ Wait   Increment PinCount
                if still not mapped         Convert/Release Bcb Resource
                    CcMapAndRead w/ Wait    Release BcbList SpinLock
                Convert/Release Bcb Resource

    Bcb mapped  Case 5:                     Case 6:

                Increment PinCount          if not ReadOnly
                Release BcbList SpinLock        Acquire Bcb shared (exit if FALSE)
                if not ReadOnly             Increment PinCount
                    Acquire Bcb Shared      Release BcbList SpinLock

    It is important to note that most changes to this routine will affect
    multiple cases from above.

Arguments:

    FileObject - Pointer to File Object for file

    FileOffset - Offset in file at which map should begin

    Length - Length of desired map in bytes

    ReadOnly - Supplies TRUE if caller will only read the mapped data (i.e.,
               TRUE for CcCopyRead, CcMapData and CcMdlRead and FALSE for
               everyone else)

    WriteOnly - The specified range of bytes will only be written.

    Flags - (PIN_WAIT, PIN_EXCLUSIVE, PIN_NO_READ, etc. as defined in cache.h)

    Bcb - Returns a pointer to the Bcb representing the pinned data.

    BaseAddress - Returns base address of desired data

    BeyondLastByte - Returns the File Offset of the first byte beyond the
                     last accessible byte.

Return Value:

    FALSE - if PIN_WAIT was set, and it was impossible to lock all
            of the data without blocking
    TRUE - if the desired data, is being returned

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.
        This can only occur if Wait was specified as TRUE.  (If Wait is
        specified as FALSE, and an allocation failure occurs, this
        routine simply returns FALSE.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    LARGE_INTEGER TrialBound;
    KLOCK_QUEUE_HANDLE LockHandle;
    PBCB BcbOut = NULL;
    ULONG ZeroFlags = 0;
    LOGICAL SpinLockAcquired = FALSE;
    BOOLEAN Result = FALSE;

    ULONG ReceivedLength;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB Vacb = NULL;

    DebugTrace(+1, me, "CcPinFileData:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );
    DebugTrace( 0, me, "    Flags = %02lx\n", Flags );

    //
    //  Get pointer to SharedCacheMap via File Object.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  See if we have an active Vacb, that we need to free.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, Vacb, ActivePage, PageIsDirty );

    //
    //  If there is an end of a page to be zeroed, then free that page now,
    //  so it does not cause our data to get zeroed.  If there is an active
    //  page, free it so we have the correct ValidDataGoal.
    //

    if ((Vacb != NULL) || (SharedCacheMap->NeedToZero != NULL)) {

        CcFreeActiveVacb( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
        Vacb = NULL;
    }

    //
    //  Make sure the calling file system is not asking to map beyond the
    //  end of the section, for example, that it did not forget to do
    //  CcExtendCacheSection.
    //

    ASSERT( ( FileOffset->QuadPart + (LONGLONG)Length ) <=
                     SharedCacheMap->SectionSize.QuadPart );

    //
    //  Initially clear output
    //

    *Bcb = NULL;
    *BaseAddress = NULL;

    if (!FlagOn(Flags, PIN_NO_READ)) {

        *BaseAddress = CcGetVirtualAddress( SharedCacheMap,
                                            *FileOffset,
                                            &Vacb,
                                            &ReceivedLength );

    } else {

        //
        //  In the PIN_NO_READ case, we simply need to make sure that the
        //  sparse structure containing the Bcb listheads is expanded in the
        //  region of the file we are interested in.
        //
        //  Fake a ReceivedLength that matches the remaining bytes in the view.
        //

        ReceivedLength = VACB_MAPPING_GRANULARITY -
                         (ULONG)(FileOffset->QuadPart & (VACB_MAPPING_GRANULARITY - 1));

        //
        //  Now simply cause a reference that will expand a multilevel Vacb.
        //

        CcReferenceFileOffset( SharedCacheMap, *FileOffset );
    }

    //
    //  Acquire Bcb List Exclusive to look for Bcb
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
    SpinLockAcquired = TRUE;

    //
    //  Use try to guarantee cleanup on the way out.
    //

    try {

        LOGICAL Found;
        LARGE_INTEGER FOffset;
        LARGE_INTEGER TLength;

        //
        //  Search for Bcb describing the largest matching "prefix" byte range,
        //  or where to insert it.
        //

        TrialBound.QuadPart = FileOffset->QuadPart + (LONGLONG)Length;
        Found = CcFindBcb( SharedCacheMap, FileOffset, &TrialBound, &BcbOut );


        //
        //  Cases 1 and 2 - Bcb was not found.
        //
        //  First caculate data to pin down.
        //

        if (!Found) {

            //
            //  Get out if the user specified PIN_IF_BCB.
            //

            if (FlagOn(Flags, PIN_IF_BCB)) {

                //
                //  We need to zap BcbOut since this is a hint to the cleanup code
                //  to remove the Bcb if we are returning FALSE.
                //

                BcbOut = NULL;
                try_return( Result = FALSE );
            }

            //
            //  Not found, calculate data to pin down.
            //
            //  Round local copy of FileOffset down to page boundary, and
            //  round copies of size and minimum size up.  Also make sure that
            //  we keep the length from crossing the end of the SharedCacheMap.
            //

            FOffset = *FileOffset;
            TLength.QuadPart = TrialBound.QuadPart - FOffset.QuadPart;

            TLength.LowPart += FOffset.LowPart & (PAGE_SIZE - 1);
            ReceivedLength += FOffset.LowPart & (PAGE_SIZE - 1);

            //
            //  At this point we can calculate the ReadOnly flag for
            //  the purposes of whether to use the Bcb resource, and
            //  we can calculate the ZeroFlags.
            //

            if ((!ReadOnly  && !FlagOn(SharedCacheMap->Flags, PIN_ACCESS)) || WriteOnly) {

                //
                //  We can always zero middle pages, if any.
                //

                ZeroFlags = ZERO_MIDDLE_PAGES;

                if (((FOffset.LowPart & (PAGE_SIZE - 1)) == 0) &&
                    (Length >= PAGE_SIZE)) {
                    ZeroFlags |= ZERO_FIRST_PAGE;
                }

                if ((TLength.LowPart & (PAGE_SIZE - 1)) == 0) {
                    ZeroFlags |= ZERO_LAST_PAGE;
                }
            }

            //
            //  We treat Bcbs as ReadOnly (do not acquire resource) if they
            //  are in sections for which we have not disabled modified writing.
            //

            if (!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {
                ReadOnly = TRUE;
            }

            TLength.LowPart = (ULONG) ROUND_TO_PAGES( TLength.LowPart );

            //
            //  Round BaseAddress and FOffset down to the bottom of a page.
            //

            *BaseAddress = ((PCHAR)*BaseAddress - (FileOffset->LowPart & (PAGE_SIZE - 1)));
            FOffset.LowPart &= ~(PAGE_SIZE - 1);

            //
            //  Even if we are readonly, we can still zero pages entirely
            //  beyond valid data length.
            //

            if (FOffset.QuadPart >= SharedCacheMap->ValidDataGoal.QuadPart) {

                ZeroFlags |= ZERO_FIRST_PAGE | ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;

            } else if ((FOffset.QuadPart + (LONGLONG)PAGE_SIZE) >=
                                SharedCacheMap->ValidDataGoal.QuadPart) {

                ZeroFlags |= ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
            }

            //
            //  We will get into trouble if we try to read more than we
            //  can map by one Vacb.  So make sure that our lengths stay
            //  within a Vacb.
            //

            if (TLength.LowPart > ReceivedLength) {
                TLength.LowPart = ReceivedLength;
            }


            //
            //  Case 1 - Bcb was not found and Wait is TRUE.
            //
            //  Note that it is important to minimize the time that the Bcb
            //  List spin lock is held, as well as guarantee we do not take
            //  any faults while holding this lock.
            //
            //  If we can (and perhaps will) wait, then it is important to
            //  allocate the Bcb acquire it exclusive and free the Bcb List.
            //  We then procede to read in the data, and anyone else finding
            //  our Bcb will have to wait shared to insure that the data is
            //  in.
            //

            if (FlagOn(Flags, PIN_WAIT)) {

                BcbOut = CcAllocateInitializeBcb( SharedCacheMap,
                                                  BcbOut,
                                                  &FOffset,
                                                  &TLength );

                if (BcbOut == NULL) {
                    DebugTrace( 0, 0, "Bcb allocation failure\n", 0 );
                    KeReleaseInStackQueuedSpinLock( &LockHandle );
                    SpinLockAcquired = FALSE;
                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }

                //
                //  Now just acquire the newly-allocated Bcb shared, and
                //  release the spin lock.
                //

                if (!ReadOnly) {
                    if (FlagOn(Flags, PIN_EXCLUSIVE)) {
                        (VOID)ExAcquireResourceExclusiveLite( &BcbOut->Resource, TRUE );
                    } else {
                        (VOID)ExAcquireSharedStarveExclusive( &BcbOut->Resource, TRUE );
                    }
                }
                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;

                //
                //  Now read in the data.
                //

                if (!FlagOn(Flags, PIN_NO_READ)) {

                    (VOID)CcMapAndRead( SharedCacheMap,
                                        &FOffset,
                                        TLength.LowPart,
                                        ZeroFlags,
                                        TRUE,
                                        *BaseAddress );

                    //
                    //  Now we have to reacquire the Bcb List spinlock to load
                    //  up the mapping if we are the first one, else we collided
                    //  with someone else who loaded the mapping first, and we
                    //  will just free our mapping.  It is guaranteed that the
                    //  data will be mapped to the same place.
                    //

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                    if (BcbOut->BaseAddress == NULL) {

                        BcbOut->BaseAddress = *BaseAddress;
                        BcbOut->Vacb = Vacb;
                        Vacb = NULL;
                    }

                    KeReleaseInStackQueuedSpinLock( &LockHandle );

                    //
                    //  Calculate Base Address of the data we want.
                    //

                    *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                                   (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );
                }

                //
                //  Success!
                //

                try_return( Result = TRUE );
            }


            //
            //  Case 2 - Bcb was not found and Wait is FALSE
            //
            //  If we cannot wait, then we go immediately see if the data is
            //  there (CcMapAndRead), and then only set up the Bcb and release
            //  the spin lock if the data is there.  Note here we call
            //  CcMapAndRead while holding the spin lock, because we know we
            //  will not fault and not block before returning.
            //

            else {

                //
                //  Now try to allocate and initialize the Bcb.  If we
                //  fail to allocate one, then return FALSE, since we know that
                //  Wait = FALSE.  The caller may get lucky if he calls
                //  us back with Wait = TRUE.
                //

                BcbOut = CcAllocateInitializeBcb( SharedCacheMap,
                                                  BcbOut,
                                                  &FOffset,
                                                  &TLength );

                if (BcbOut == NULL) {

                    try_return( Result = FALSE );
                }

                //
                //  If we are not ReadOnly, we must acquire the newly-allocated
                //  resource shared, and then we can free the spin lock.
                //

                if (!ReadOnly) {
                    ExAcquireSharedStarveExclusive( &BcbOut->Resource, TRUE );
                }
                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;

                //
                //  Note that since this call has Wait = FALSE, it cannot
                //  get an exception (see procedure header).
                //

                ASSERT( !FlagOn(Flags, PIN_NO_READ) );
                if (!CcMapAndRead( SharedCacheMap,
                                   &FOffset,
                                   TLength.LowPart,
                                   ZeroFlags,
                                   FALSE,
                                   *BaseAddress )) {

                    try_return( Result = FALSE );
                }

                //
                //  Now we have to reacquire the Bcb List spinlock to load
                //  up the mapping if we are the first one, else we collided
                //  with someone else who loaded the mapping first, and we
                //  will just free our mapping.  It is guaranteed that the
                //  data will be mapped to the same place.
                //

                KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                if (BcbOut->BaseAddress == NULL) {

                    BcbOut->BaseAddress = *BaseAddress;
                    BcbOut->Vacb = Vacb;
                    Vacb = NULL;
                }

                KeReleaseInStackQueuedSpinLock( &LockHandle );

                //
                //  Calculate Base Address of the data we want.
                //

                *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                               (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );

                //
                //  Success!
                //

                try_return( Result = TRUE );
            }

        } else {

            //
            //  We treat Bcbs as ReadOnly (do not acquire resource) if they
            //  are in sections for which we have not disabled modified writing.
            //

            if (!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {
                ReadOnly = TRUE;
            }
        }


        //
        //  Cases 3 and 4 - Bcb is there but not mapped
        //

        if (BcbOut->BaseAddress == NULL) {

            //
            //  It is too complicated to attempt to calculate any ZeroFlags in this
            //  case, because we have to not only do the tests above, but also
            //  compare to the byte range in the Bcb since we will be passing
            //  those parameters to CcMapAndRead.  Also, the probability of hitting
            //  some window where zeroing is of any advantage is quite small.
            //

            //
            //  Set up to just reread the Bcb exactly as the data in it is
            //  described.
            //

            *BaseAddress = ((PCHAR)*BaseAddress - (FileOffset->LowPart - BcbOut->FileOffset.LowPart));
            FOffset = BcbOut->FileOffset;
            TLength.QuadPart = (LONGLONG)BcbOut->ByteLength;

            //
            //  Case 3 - Bcb is there but not mapped and Wait is TRUE
            //
            //  Increment the PinCount, and then release the BcbList
            //  SpinLock so that we can wait to acquire the Bcb exclusive.
            //  Once we have the Bcb exclusive, map and read it in if no
            //  one beats us to it.  Someone may have beat us to it since
            //  we had to release the SpinLock above.
            //

            if (FlagOn(Flags, PIN_WAIT)) {

                BcbOut->PinCount += 1;

                //
                //  Now we have to release the BcbList SpinLock in order to
                //  acquire the Bcb shared.
                //

                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;
                if (!ReadOnly) {
                    if (FlagOn(Flags, PIN_EXCLUSIVE)) {
                        (VOID)ExAcquireResourceExclusiveLite( &BcbOut->Resource, TRUE );
                    } else {
                        (VOID)ExAcquireSharedStarveExclusive( &BcbOut->Resource, TRUE );
                    }
                }

                //
                //  Now procede to map and read the data in.
                //
                //  Now read in the data.
                //

                if (!FlagOn(Flags, PIN_NO_READ)) {

                    (VOID)CcMapAndRead( SharedCacheMap,
                                        &FOffset,
                                        TLength.LowPart,
                                        ZeroFlags,
                                        TRUE,
                                        *BaseAddress );

                    //
                    //  Now we have to reacquire the Bcb List spinlock to load
                    //  up the mapping if we are the first one, else we collided
                    //  with someone else who loaded the mapping first, and we
                    //  will just free our mapping.  It is guaranteed that the
                    //  data will be mapped to the same place.
                    //

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                    if (BcbOut->BaseAddress == NULL) {

                        BcbOut->BaseAddress = *BaseAddress;
                        BcbOut->Vacb = Vacb;
                        Vacb = NULL;
                    }

                    KeReleaseInStackQueuedSpinLock( &LockHandle );

                    //
                    //
                    //  Calculate Base Address of the data we want.
                    //

                    *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                                   (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );
                }

                //
                //  Success!
                //

                try_return( Result = TRUE );
            }


            //
            //  Case 4 - Bcb is there but not mapped, and Wait is FALSE
            //
            //  Since we cannot wait, we go immediately see if the data is
            //  there (CcMapAndRead), and then only set up the Bcb and release
            //  the spin lock if the data is there.  Note here we call
            //  CcMapAndRead while holding the spin lock, because we know we
            //  will not fault and not block before returning.
            //

            else {

                if (!ReadOnly && !ExAcquireSharedStarveExclusive( &BcbOut->Resource, FALSE )) {

                    //
                    //  If we cannot get the resource and have not incremented PinCount, then
                    //  suppress the unpin on cleanup.
                    //

                    BcbOut = NULL;
                    try_return( Result = FALSE );
                }

                BcbOut->PinCount += 1;

                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;

                //
                //  Note that since this call has Wait = FALSE, it cannot
                //  get an exception (see procedure header).
                //

                ASSERT( !FlagOn(Flags, PIN_NO_READ) );
                if (!CcMapAndRead( SharedCacheMap,
                                   &BcbOut->FileOffset,
                                   BcbOut->ByteLength,
                                   ZeroFlags,
                                   FALSE,
                                   *BaseAddress )) {

                    try_return( Result = FALSE );
                }

                //
                //  Now we have to reacquire the Bcb List spinlock to load
                //  up the mapping if we are the first one, else we collided
                //  with someone else who loaded the mapping first, and we
                //  will just free our mapping.  It is guaranteed that the
                //  data will be mapped to the same place.
                //

                KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                if (BcbOut->BaseAddress == NULL) {

                    BcbOut->BaseAddress = *BaseAddress;
                    BcbOut->Vacb = Vacb;
                    Vacb = NULL;
                }

                KeReleaseInStackQueuedSpinLock( &LockHandle );

                //
                //  Calculate Base Address of the data we want.
                //

                *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                               (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );

                //
                //  Success!
                //

                try_return( Result = TRUE );
            }
        }


        //
        //  Cases 5 and 6 - Bcb is there and it is mapped
        //

        else {

            //
            //  Case 5 - Bcb is there and mapped, and Wait is TRUE
            //
            //  We can just increment the PinCount, release the SpinLock
            //  and then acquire the Bcb Shared if we are not ReadOnly.
            //

            if (FlagOn(Flags, PIN_WAIT)) {

                BcbOut->PinCount += 1;
                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;

                //
                //  Acquire Bcb Resource shared to insure that it is in memory.
                //

                if (!ReadOnly) {
                    if (FlagOn(Flags, PIN_EXCLUSIVE)) {
                        (VOID)ExAcquireResourceExclusiveLite( &BcbOut->Resource, TRUE );
                    } else {
                        (VOID)ExAcquireSharedStarveExclusive( &BcbOut->Resource, TRUE );
                    }
                }
            }

            //
            //  Case 6 - Bcb is there and mapped, and Wait is FALSE
            //
            //  If we are not ReadOnly, we have to first see if we can
            //  acquire the Bcb shared before incrmenting the PinCount,
            //  since we will have to return FALSE if we cannot acquire the
            //  resource.
            //

            else {

                //
                //  Acquire Bcb Resource shared to insure that it is in memory.
                //

                if (!ReadOnly && !ExAcquireSharedStarveExclusive( &BcbOut->Resource, FALSE )) {

                    //
                    //  If we cannot get the resource and have not incremented PinCount, then
                    //  suppress the unpin on cleanup.
                    //

                    BcbOut = NULL;
                    try_return( Result = FALSE );
                }

                BcbOut->PinCount += 1;
                KeReleaseInStackQueuedSpinLock( &LockHandle );
                SpinLockAcquired = FALSE;
            }

            //
            //  Calculate Base Address of the data we want.
            //

            *BaseAddress = (PCHAR)BcbOut->BaseAddress +
                           (ULONG)( FileOffset->QuadPart - BcbOut->FileOffset.QuadPart );

            //
            //  Success!
            //

            try_return( Result = TRUE );
        }


    try_exit: NOTHING;

        if (FlagOn(Flags, PIN_NO_READ) &&
            FlagOn(Flags, PIN_EXCLUSIVE) &&
            (BcbOut != NULL) &&
            (BcbOut->BaseAddress != NULL)) {

            //
            //  Unmap the Vacb and free the resource if the Bcb is still
            //  dirty.  We have to free the resource before dropping the
            //  spinlock, and we want to hold the resource until the
            //  virtual address is freed.
            //

            CcFreeVirtualAddress( BcbOut->Vacb );

            BcbOut->BaseAddress = NULL;
            BcbOut->Vacb = NULL;
        }

    } finally {

        //
        //  Release the spinlock if it is acquired.
        //

        if (SpinLockAcquired) {
            KeReleaseInStackQueuedSpinLock( &LockHandle );
        }

        //
        //  If the Vacb was not used for any reason (error or not needed), then free it here.
        //

        if (Vacb != NULL) {
            CcFreeVirtualAddress( Vacb );
        }

        //
        //  If we referenced a piece of a multilevel structure, release here.
        //

        if (FlagOn(Flags, PIN_NO_READ)) {

            CcDereferenceFileOffset( SharedCacheMap, *FileOffset );
        }

        if (Result) {

            *Bcb = BcbOut;
            *BeyondLastByte = BcbOut->BeyondLastByte;

        //
        //  An abnormal termination can occur on an allocation failure,
        //  or on a failure to map and read the buffer.
        //

        } else {

            *BaseAddress = NULL;
            if (BcbOut != NULL) {
                CcUnpinFileData( BcbOut, ReadOnly, UNPIN );
            }
        }

        DebugTrace( 0, me, "    <Bcb = %08lx\n", *Bcb );
        DebugTrace( 0, me, "    <BaseAddress = %08lx\n", *BaseAddress );
        DebugTrace(-1, me, "CcPinFileData -> %02lx\n", Result );
    }

    return Result;
}


//
//  Internal Support Routine
//

VOID
FASTCALL
CcUnpinFileData (
    IN OUT PBCB Bcb,
    IN BOOLEAN ReadOnly,
    IN UNMAP_ACTIONS UnmapAction
    )

/*++

Routine Description:

    This routine umaps and unlocks the specified buffer, which was previously
    locked and mapped by calling CcPinFileData.

Arguments:

    Bcb - Pointer previously returned from CcPinFileData.  As may be
          seen above, this pointer may be either a Bcb or a Vacb.

    ReadOnly - must specify same value as when data was mapped

    UnmapAction - UNPIN or SET_CLEAN

Return Value:

    None

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    PSHARED_CACHE_MAP SharedCacheMap;

    DebugTrace(+1, me, "CcUnpinFileData >Bcb = %08lx\n", Bcb );

    //
    //  Note, since we have to allocate so many Vacbs, we do not use
    //  a node type code.  However, the Vacb starts with a BaseAddress,
    //  so we assume that the low byte of the Bcb node type code has
    //  some bits set, which a page-aligned Base Address cannot.
    //

    ASSERT( (CACHE_NTC_BCB & 0xFF) != 0 );

    if (Bcb->NodeTypeCode != CACHE_NTC_BCB) {

        ASSERT(((PVACB)Bcb >= CcVacbs) && ((PVACB)Bcb < CcBeyondVacbs));
        ASSERT(((PVACB)Bcb)->SharedCacheMap->NodeTypeCode == CACHE_NTC_SHARED_CACHE_MAP);

        CcFreeVirtualAddress( (PVACB)Bcb );

        DebugTrace(-1, me, "CcUnpinFileData -> VOID (simple release)\n", 0 );

        return;
    }

    SharedCacheMap = Bcb->SharedCacheMap;

    //
    //  We treat Bcbs as ReadOnly (do not acquire resource) if they
    //  are in sections for which we have not disabled modified writing, or
    //  in this special case if this action is a dereferencing of the BCB.
    //

    if (!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) ||
        UnmapAction == UNREF) {
        ReadOnly = TRUE;
    }

    //
    //  Synchronize
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    switch (UnmapAction) {

    case UNPIN:
    case UNREF:

        ASSERT( Bcb->PinCount > 0 );

        Bcb->PinCount -= 1;
        break;

    case SET_CLEAN:

        if (Bcb->Dirty) {

            ULONG Pages = Bcb->ByteLength >> PAGE_SHIFT;

            //
            //  Reverse the rest of the actions taken when the Bcb was set dirty.
            //

            Bcb->Dirty = FALSE;

            //
            //  Clear any Lsn that was assigned to this Bcb.
            //

            Bcb->OldestLsn.QuadPart = 0;
            Bcb->NewestLsn.QuadPart = 0;

            CcAcquireMasterLockAtDpcLevel();
            CcDeductDirtyPages( SharedCacheMap, Pages );
            
            //
            //  Normally we need to reduce CcPagesYetToWrite appropriately.
            //

            if (CcPagesYetToWrite > Pages) {
                CcPagesYetToWrite -= Pages;
            } else {
                CcPagesYetToWrite = 0;
            }

            //
            //  Remove SharedCacheMap from dirty list if nothing more dirty,
            //  and someone still has the cache map opened.
            //

            if ((SharedCacheMap->DirtyPages == 0) &&
                (SharedCacheMap->OpenCount != 0)) {

                RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
                CcInsertIntoCleanSharedCacheMapList( SharedCacheMap );
            }

            CcReleaseMasterLockFromDpcLevel();
        }

        break;

    default:
        CcBugCheck( UnmapAction, 0, 0 );
    }

    //
    //  If we brought it to 0, then we have to kill it.
    //

    if (Bcb->PinCount == 0) {

        //
        //  If the Bcb is Dirty, we only release the resource and unmap now.
        //

        if (Bcb->Dirty) {

            if (Bcb->BaseAddress != NULL) {

                //
                //  Unmap the Vacb and free the resource if the Bcb is still
                //  dirty.  We have to free the resource before dropping the
                //  spinlock, and we want to hold the resource until the
                //  virtual address is freed.
                //

                CcFreeVirtualAddress( Bcb->Vacb );

                Bcb->BaseAddress = NULL;
                Bcb->Vacb = NULL;
            }

            if (!ReadOnly) {
                ExReleaseResourceLite( &Bcb->Resource );
            }

            KeReleaseInStackQueuedSpinLock( &LockHandle );
        }

        //
        //  Otherwise, we also delete the Bcb.
        //

        else {

            //
            //  Since CcCalculateVacbLockCount has to be able to walk
            //  the BcbList with only the VacbSpinLock, we take that one
            //  out to change the list and decrement the level.
            //

            CcAcquireVacbLockAtDpcLevel();
            RemoveEntryList( &Bcb->BcbLinks );

            //
            //  For large metadata streams we unlock the Vacb level.
            //

            CcUnlockVacbLevel( SharedCacheMap, Bcb->FileOffset.QuadPart );
            CcReleaseVacbLockFromDpcLevel();

            //
            //  Debug routines used to remove Bcbs from the global list
            //

#if LIST_DBG

            KeAcquireQueuedSpinLockAtDpcLevel( KeQueuedSpinLockContext(LockQueueBcbLock) );

            if (Bcb->CcBcbLinks.Flink != NULL) {

                RemoveEntryList( &Bcb->CcBcbLinks );
                CcBcbCount -= 1;
            }

            KeReleaseQueuedSpinLockFromDpcLevel( KeQueuedSpinLockContext(LockQueueBcbLock) );

#endif

            if (Bcb->BaseAddress != NULL) {

                CcFreeVirtualAddress( Bcb->Vacb );
            }
#if DBG
            if (!ReadOnly) {
                ExReleaseResourceLite( &Bcb->Resource );
            }

            //
            //  ASSERT that the resource is unowned.
            //

            ASSERT( Bcb->Resource.ActiveCount == 0 );
#endif
            KeReleaseInStackQueuedSpinLock( &LockHandle );
            CcDeallocateBcb( Bcb );
        }
    }

    //
    //  Else we just have to release our Shared access, if we are not
    //  readonly.  We don't need to do this above, since we deallocate
    //  the entire Bcb there.
    //

    else {

        if (!ReadOnly) {
            ExReleaseResourceLite( &Bcb->Resource );
        }

        KeReleaseInStackQueuedSpinLock( &LockHandle );
    }

    DebugTrace(-1, me, "CcUnpinFileData -> VOID\n", 0 );

    return;
}


VOID
CcSetReadAheadGranularity (
    IN PFILE_OBJECT FileObject,
    IN ULONG Granularity
    )

/*++

Routine Description:

    This routine may be called to set the read ahead granularity used by
    the Cache Manager.  The default is PAGE_SIZE.  The number is decremented
    and stored as a mask.

Arguments:

    FileObject - File Object for which granularity shall be set

    Granularity - new granularity, which must be an even power of 2 and
                  >= PAGE_SIZE

Return Value:

    None
--*/

{
    ((PPRIVATE_CACHE_MAP)FileObject->PrivateCacheMap)->ReadAheadMask = Granularity - 1;
}


VOID
CcScheduleReadAhead (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length
    )

/*++

Routine Description:

    This routine is called by Copy Read and Mdl Read file system routines to
    perform common Read Ahead processing.  The input parameters describe
    the current read which has just been completed, or perhaps only started
    in the case of Mdl Reads.  Based on these parameters, an
    assessment is made on how much data should be read ahead, and whether
    that data has already been read ahead.

    The processing is divided into two parts:

        CALCULATE READ AHEAD REQUIREMENTS   (CcScheduleReadAhead)

        PERFORM READ AHEAD                  (CcPerformReadAhead)

    File systems should always call CcReadAhead, which will conditionally
    call CcScheduleReadAhead (if the read is large enough).  If such a call
    determines that there is read ahead work to do, and no read ahead is
    currently active, then it will set ReadAheadActive and schedule read
    ahead to be peformed by the Lazy Writer, who will call CcPeformReadAhead.

Arguments:

    FileObject - supplies pointer to FileObject on which readahead should be
                 considered.

    FileOffset - supplies the FileOffset at which the last read just occurred.

    Length - supplies the length of the last read.

Return Value:

    None
--*/

{
    LARGE_INTEGER NewOffset;
    LARGE_INTEGER NewBeyond;
    LARGE_INTEGER FileOffset1, FileOffset2;
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    PWORK_QUEUE_ENTRY WorkQueueEntry;
    ULONG ReadAheadSize;
    LOGICAL Changed = FALSE;

    DebugTrace(+1, me, "CcScheduleReadAhead:\n", 0 );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    PrivateCacheMap = FileObject->PrivateCacheMap;

    if ((PrivateCacheMap == NULL) ||
        (SharedCacheMap == NULL) ||
        FlagOn(SharedCacheMap->Flags, DISABLE_READ_AHEAD)) {

        DebugTrace(-1, me, "CcScheduleReadAhead -> VOID (Nooped)\n", 0 );

        return;
    }

    //
    //  Round boundaries of transfer up to some greater granularity, so that
    //  sequential reads will be recognized even if a few bytes are skipped
    //  between records.
    //

    NewOffset = *FileOffset;
    NewBeyond.QuadPart = FileOffset->QuadPart + (LONGLONG)Length;

    //
    //  Find the next read ahead boundary beyond the current read.
    //

    ReadAheadSize = (Length + PrivateCacheMap->ReadAheadMask) & ~PrivateCacheMap->ReadAheadMask;
    FileOffset2.QuadPart = NewBeyond.QuadPart + (LONGLONG)ReadAheadSize;
    FileOffset2.LowPart &= ~PrivateCacheMap->ReadAheadMask;

    //
    //  CALCULATE READ AHEAD REQUIREMENTS
    //

    //
    //  Take out the ReadAhead spinlock to synchronize our read ahead decision.
    //

    ExAcquireSpinLock( &PrivateCacheMap->ReadAheadSpinLock, &OldIrql );

    //
    //  Read Ahead Case 0.
    //
    //  Sequential-only hint in the file object.  For this case we will
    //  try and always keep two read ahead granularities read ahead from
    //  and including the end of the current transfer.  This case has the
    //  lowest overhead, and the code is completely immune to how the
    //  caller skips around.  Sequential files use ReadAheadOffset[1] in
    //  the PrivateCacheMap as their "high water mark".
    //

    if (FlagOn(FileObject->Flags, FO_SEQUENTIAL_ONLY)) {

        //
        //  If the next boundary is greater than or equal to the high-water mark,
        //  then read ahead.
        //

        if (FileOffset2.QuadPart >= PrivateCacheMap->ReadAheadOffset[1].QuadPart) {

            //
            //  On the first read if we are using a large read ahead granularity,
            //  and the read did not get it all, we will just get the rest of the
            //  first data we want.
            //

            if ((FileOffset->QuadPart == 0)

                    &&

                (PrivateCacheMap->ReadAheadMask > (PAGE_SIZE - 1))

                    &&

                ((Length + PAGE_SIZE - 1) <= PrivateCacheMap->ReadAheadMask)) {

                FileOffset1.QuadPart = (LONGLONG)( ROUND_TO_PAGES(Length) );
                PrivateCacheMap->ReadAheadLength[0] = ReadAheadSize - FileOffset1.LowPart;
                FileOffset2.QuadPart = (LONGLONG)ReadAheadSize;

            //
            //  Calculate the next read ahead boundary.
            //

            } else {

                FileOffset1.QuadPart = PrivateCacheMap->ReadAheadOffset[1].QuadPart +
                                       (LONGLONG)ReadAheadSize;

                //
                //  If the end of the current read is actually beyond where we would
                //  normally do our read ahead, then we have fallen behind, and we must
                //  advance to that spot.
                //

                if (FileOffset2.QuadPart > FileOffset1.QuadPart) {
                    FileOffset1 = FileOffset2;
                }
                PrivateCacheMap->ReadAheadLength[0] = ReadAheadSize;
                FileOffset2.QuadPart = FileOffset1.QuadPart + (LONGLONG)ReadAheadSize;
            }

            //
            //  Now issue the next two read aheads.
            //

            PrivateCacheMap->ReadAheadOffset[0] = FileOffset1;

            PrivateCacheMap->ReadAheadOffset[1] = FileOffset2;
            PrivateCacheMap->ReadAheadLength[1] = ReadAheadSize;

            Changed = TRUE;
        }

    //
    //  Read Ahead Case 1.
    //
    //  If this is the third of three sequential reads, then we will see if
    //  we can read ahead.  Note that if the first read to a file is to
    //  offset 0, it passes this test.
    //

    } else if ((NewOffset.HighPart == PrivateCacheMap->BeyondLastByte2.HighPart)

            &&

        ((NewOffset.LowPart & ~NOISE_BITS)
           == (PrivateCacheMap->BeyondLastByte2.LowPart & ~NOISE_BITS))

            &&

        (PrivateCacheMap->FileOffset2.HighPart
           == PrivateCacheMap->BeyondLastByte1.HighPart)

            &&

        ((PrivateCacheMap->FileOffset2.LowPart & ~NOISE_BITS)
           == (PrivateCacheMap->BeyondLastByte1.LowPart & ~NOISE_BITS))) {

        //
        //  On the first read if we are using a large read ahead granularity,
        //  and the read did not get it all, we will just get the rest of the
        //  first data we want.
        //

        if ((FileOffset->QuadPart == 0)

                &&

            (PrivateCacheMap->ReadAheadMask > (PAGE_SIZE - 1))

                &&

            ((Length + PAGE_SIZE - 1) <= PrivateCacheMap->ReadAheadMask)) {

            FileOffset2.QuadPart = (LONGLONG)( ROUND_TO_PAGES(Length) );
        }

        //
        //  Round read offset to next read ahead boundary.
        //

        else {
            FileOffset2.QuadPart = NewBeyond.QuadPart + (LONGLONG)ReadAheadSize;

            FileOffset2.LowPart &= ~PrivateCacheMap->ReadAheadMask;
        }

        //
        //  Set read ahead length to be the same as for the most recent read,
        //  up to our max.
        //

        if (FileOffset2.QuadPart != PrivateCacheMap->ReadAheadOffset[1].QuadPart) {

            ASSERT( FileOffset2.HighPart >= 0 );

            Changed = TRUE;
            PrivateCacheMap->ReadAheadOffset[1] = FileOffset2;
            PrivateCacheMap->ReadAheadLength[1] = ReadAheadSize;
        }
    }

    //
    //  Read Ahead Case 2.
    //
    //  If this is the third read following a particular stride, then we
    //  will see if we can read ahead.  One example of an application that
    //  might do this is a spreadsheet.  Note that this code even works
    //  for negative strides.
    //

    else if ( ( NewOffset.QuadPart -
                PrivateCacheMap->FileOffset2.QuadPart ) ==
              ( PrivateCacheMap->FileOffset2.QuadPart -
                PrivateCacheMap->FileOffset1.QuadPart )) {

        //
        //  According to the current stride, the next offset will be:
        //
        //      NewOffset + (NewOffset - FileOffset2)
        //
        //  which is the same as:
        //
        //      (NewOffset * 2) - FileOffset2
        //

        FileOffset2.QuadPart = ( NewOffset.QuadPart << 1 ) - PrivateCacheMap->FileOffset2.QuadPart;

        //
        //  If our stride is going backwards through the file, we
        //  have to detect the case where the next step would wrap.
        //

        if (FileOffset2.HighPart >= 0) {

            //
            //  The read ahead length must be extended by the same amount that
            //  we will round the PrivateCacheMap->ReadAheadOffset down.
            //

            Length += FileOffset2.LowPart & (PAGE_SIZE - 1);

            //
            //  Now round the PrivateCacheMap->ReadAheadOffset down.
            //

            FileOffset2.LowPart &= ~(PAGE_SIZE - 1);
            PrivateCacheMap->ReadAheadOffset[1] = FileOffset2;

            //
            //  Round to page boundary.
            //

            PrivateCacheMap->ReadAheadLength[1] = (ULONG) ROUND_TO_PAGES(Length);
            Changed = TRUE;
        }
    }

    //
    //  Get out if the ReadAhead requirements did not change.
    //

    if (!Changed || PrivateCacheMap->Flags.ReadAheadActive) {

        DebugTrace( 0, me, "Read ahead already in progress or no change\n", 0 );

        ExReleaseSpinLock( &PrivateCacheMap->ReadAheadSpinLock, OldIrql );
        return;
    }

    //
    //  Otherwise, we will proceed and try to schedule the read ahead
    //  ourselves.
    //

    CC_SET_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ACTIVE);

    //
    //  Release spin lock on way out
    //

    ExReleaseSpinLock( &PrivateCacheMap->ReadAheadSpinLock, OldIrql );

    //
    //  Queue the read ahead request to the Lazy Writer's work queue.
    //

    DebugTrace( 0, me, "Queueing read ahead to worker thread\n", 0 );

    WorkQueueEntry = CcAllocateWorkQueueEntry();

    //
    //  If we failed to allocate a work queue entry, then, we will
    //  quietly bag it.  Read ahead is only an optimization, and
    //  no one ever requires that it occur.
    //

    if (WorkQueueEntry != NULL) {

        //
        //  We must reference this file object so that it cannot go away
        //  until we finish Read Ahead processing in the Worker Thread.
        //

        ObReferenceObject ( FileObject );

        //
        //  Increment open count to make sure the SharedCacheMap stays around.
        //

        CcAcquireMasterLock( &OldIrql );
        CcIncrementOpenCount( SharedCacheMap, 'adRQ' );
        SetFlag(SharedCacheMap->Flags, READ_AHEAD_QUEUED);
        CcReleaseMasterLock( OldIrql );

        WorkQueueEntry->Function = (UCHAR)ReadAhead;
        WorkQueueEntry->Parameters.Read.FileObject = FileObject;

        CcPostWorkQueue( WorkQueueEntry, &CcExpressWorkQueue );
    }

    //
    //  If we failed to allocate a Work Queue Entry, or all of the pages
    //  are resident we must set the active flag false.
    //

    else {

        ExAcquireFastLock( &PrivateCacheMap->ReadAheadSpinLock, &OldIrql );
        CC_CLEAR_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ACTIVE);
        ExReleaseFastLock( &PrivateCacheMap->ReadAheadSpinLock, OldIrql );
    }

    DebugTrace(-1, me, "CcScheduleReadAhead -> VOID\n", 0 );

    return;
}


VOID
FASTCALL
CcPerformReadAhead (
    IN PFILE_OBJECT FileObject
    )

/*++

Routine Description:

    This routine is called by the Lazy Writer to perform read ahead which
    has been scheduled for this file by CcScheduleReadAhead.

Arguments:

    FileObject - supplies pointer to FileObject on which readahead should be
                 considered.

Return Value:

    None
--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    ULONG i;
    LARGE_INTEGER ReadAheadOffset[2];
    ULONG ReadAheadLength[2];
    PCACHE_MANAGER_CALLBACKS Callbacks;
    PVOID Context;
    ULONG SavedState;
    LOGICAL Done;
    LOGICAL HitEof = FALSE;
    LOGICAL ReadAheadPerformed = FALSE;
    ULONG FaultOccurred = 0;
    PETHREAD Thread = PsGetCurrentThread();
    PVACB Vacb = NULL;

    LOGICAL ResourceHeld = FALSE;

    DebugTrace(+1, me, "CcPerformReadAhead:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    try {

        //
        //  Since we have the open count biased, we can safely access the
        //  SharedCacheMap.
        //

        SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

        Callbacks = SharedCacheMap->Callbacks;
        Context = SharedCacheMap->LazyWriteContext;

        //
        //  After the first time, keep looping as long as there are new
        //  read ahead requirements.  (We will skip out below.)
        //

        while (TRUE) {

            //
            //  Get SharedCacheMap and PrivateCacheMap.  If either are now NULL, get
            //  out.
            //

            CcAcquireMasterLock( &OldIrql );

            PrivateCacheMap = FileObject->PrivateCacheMap;

            //
            //  Now capture the information that we need, so that we can drop the
            //  SharedList Resource.  This information is advisory only anyway, and
            //  the caller must guarantee that the FileObject is referenced.
            //

            if (PrivateCacheMap != NULL) {

                ExAcquireSpinLockAtDpcLevel( &PrivateCacheMap->ReadAheadSpinLock );

                //
                //  We are done when the lengths are 0
                //

                Done = ((PrivateCacheMap->ReadAheadLength[0] |
                         PrivateCacheMap->ReadAheadLength[1]) == 0);

                ReadAheadOffset[0] = PrivateCacheMap->ReadAheadOffset[0];
                ReadAheadOffset[1] = PrivateCacheMap->ReadAheadOffset[1];
                ReadAheadLength[0] = PrivateCacheMap->ReadAheadLength[0];
                ReadAheadLength[1] = PrivateCacheMap->ReadAheadLength[1];
                PrivateCacheMap->ReadAheadLength[0] = 0;
                PrivateCacheMap->ReadAheadLength[1] = 0;

                ExReleaseSpinLockFromDpcLevel( &PrivateCacheMap->ReadAheadSpinLock );
            }

            CcReleaseMasterLock( OldIrql );

            //
            //  Acquire the file shared.
            //

            ResourceHeld = (*Callbacks->AcquireForReadAhead)( Context, TRUE );

            if ((PrivateCacheMap == NULL) || Done || !ResourceHeld) {

                try_return( NOTHING );
            }

            //
            //  PERFORM READ AHEAD
            //
            //
            //  Now loop until everything is read in.  The Read ahead is accomplished
            //  by touching the pages with an appropriate ReadAhead parameter in MM.
            //

            i = 0;

            do {

                LARGE_INTEGER Offset, SavedOffset;
                ULONG Length, SavedLength;

                Offset = ReadAheadOffset[i];
                Length = ReadAheadLength[i];
                SavedOffset = Offset;
                SavedLength = Length;

                if ((Length != 0)

                        &&

                    ( Offset.QuadPart <= SharedCacheMap->FileSize.QuadPart )) {

                    ReadAheadPerformed = TRUE;

                    //
                    //  Keep length within file and MAX_READ_AHEAD
                    //

                    if ( ( Offset.QuadPart + (LONGLONG)Length ) >= SharedCacheMap->FileSize.QuadPart ) {

                        Length = (ULONG)( SharedCacheMap->FileSize.QuadPart - Offset.QuadPart );
                        HitEof = TRUE;

                    }
                    if (Length > MAX_READ_AHEAD) {
                        Length = MAX_READ_AHEAD;
                    }

                    //
                    //  Now loop to read all of the desired data in.  This loop
                    //  is more or less like the same loop to read data in
                    //  CcCopyRead, except that we do not copy anything, just
                    //  unmap as soon as it is in.
                    //

                    while (Length != 0) {

                        ULONG ReceivedLength;
                        PVOID CacheBuffer;
                        ULONG PagesToGo;

                        //
                        //  Call local routine to Map or Access the file data.
                        //  If we cannot map the data because of a Wait condition,
                        //  return FALSE.
                        //
                        //  Since this routine is intended to be called from
                        //  the finally handler from file system read modules,
                        //  it is imperative that it not raise any exceptions.
                        //  Therefore, if any expected exception is raised, we
                        //  will simply get out.
                        //

                        CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                                           Offset,
                                                           &Vacb,
                                                           &ReceivedLength );

                        //
                        //  If we got more than we need, make sure to only transfer
                        //  the right amount.
                        //

                        if (ReceivedLength > Length) {
                            ReceivedLength = Length;
                        }

                        //
                        //  Now loop to touch all of the pages, calling MM to insure
                        //  that if we fault, we take in exactly the number of pages
                        //  we need.
                        //

                        PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer,
                                                           ReceivedLength );

                        CcMissCounter = &CcReadAheadIos;

                        while (PagesToGo) {

                            MmSetPageFaultReadAhead( Thread, (PagesToGo - 1) );
                            FaultOccurred |= !MmCheckCachedPageState(CacheBuffer, FALSE);

                            CacheBuffer = (PCHAR)CacheBuffer + PAGE_SIZE;
                            PagesToGo -= 1;
                        }
                        CcMissCounter = &CcThrowAway;

                        //
                        //  Calculate how much data we have left to go.
                        //

                        Length -= ReceivedLength;

                        //
                        //  Assume we did not get all the data we wanted, and set
                        //  Offset to the end of the returned data.
                        //

                        Offset.QuadPart = Offset.QuadPart + (LONGLONG)ReceivedLength;

                        //
                        //  It was only a page, so we can just leave this loop
                        //  After freeing the address.
                        //

                        CcFreeVirtualAddress( Vacb );
                        Vacb = NULL;
                    }
                }
                i += 1;
            } while (i <= 1);

            //
            //  Release the file
            //

            (*Callbacks->ReleaseFromReadAhead)( Context );
            ResourceHeld = FALSE;
        }

    try_exit: NOTHING;
    }
    finally {

        MmResetPageFaultReadAhead(Thread, SavedState);
        CcMissCounter = &CcThrowAway;

        //
        //  If we got an error faulting a single page in, release the Vacb
        //  here.  It is important to free any mapping before dropping the
        //  resource to prevent purge problems.
        //

        if (Vacb != NULL) {
            CcFreeVirtualAddress( Vacb );
        }

        //
        //  Release the file
        //

        if (ResourceHeld) {
            (*Callbacks->ReleaseFromReadAhead)( Context );
        }

        //
        //  To show we are done, we must make sure the PrivateCacheMap is
        //  still there.
        //

        CcAcquireMasterLock( &OldIrql );

        PrivateCacheMap = FileObject->PrivateCacheMap;

        //
        //  Show readahead is going inactive.
        //

        if (PrivateCacheMap != NULL) {

            ExAcquireSpinLockAtDpcLevel( &PrivateCacheMap->ReadAheadSpinLock );
            CC_CLEAR_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ACTIVE);

            //
            //  If he said sequential only and we smashed into Eof, then
            //  let's reset the highwater mark in case he wants to read the
            //  file sequentially again.
            //

            if (HitEof && FlagOn(FileObject->Flags, FO_SEQUENTIAL_ONLY)) {
                PrivateCacheMap->ReadAheadOffset[1].LowPart =
                PrivateCacheMap->ReadAheadOffset[1].HighPart = 0;
            }

            //
            //  If no faults occurred, turn read ahead off.
            //

            if (ReadAheadPerformed && !FaultOccurred) {
                CC_CLEAR_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);
            }

            ExReleaseSpinLockFromDpcLevel( &PrivateCacheMap->ReadAheadSpinLock );
        }

        //
        //  Free SharedCacheMap list
        //

        CcReleaseMasterLock( OldIrql );

        ObDereferenceObject( FileObject );

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'adRP' );

        ClearFlag(SharedCacheMap->Flags, READ_AHEAD_QUEUED);

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }

    DebugTrace(-1, me, "CcPerformReadAhead -> VOID\n", 0 );

    return;
}


PBITMAP_RANGE
CcFindBitmapRangeToDirty (
    IN PMBCB Mbcb,
    IN LONGLONG Page,
    IN PULONG *FreePageForSetting
    )

/*++

Routine Description:

    This routine looks for the bitmap range containing the specified page.
    If it is found it is returned so the caller can set some dirty bits.
    If it is not found, then an attempt is made to come up with a free range
    and set it up to describe the desired range.  To come up with a free range,
    first we attempt to recycle the lowest range that does not currently contain
    any dirty pages.  If there is no such range, then we allocate one.

Arguments:

    Mbcb - Supplies the Mbcb in which to find the range.

    Page - Supplies the page number for the first page to be set dirty.

    FreePageForSetting - Supplies a free bitmap page of zeros from the zone; the
                         caller's pointer is cleared on return if this page is used.

Return Value:

    The desired bitmap range, or NULL if one could not be allocated.

Environment:

    The BcbSpinLock must be held on entry.

--*/

{
    PBITMAP_RANGE BitmapRange, FreeRange;
    PLIST_ENTRY InsertPoint;
    LONGLONG BasePage;

    //
    //  Initialize FreeRange and InsertPoint for the case we have
    //  to initialize a range.
    //

    FreeRange = NULL;
    InsertPoint = &Mbcb->BitmapRanges;

    //
    //  Point to the first bitmap range.
    //

    BitmapRange = (PBITMAP_RANGE)InsertPoint->Flink;

    //
    //  Calculate the desired BasePage from the caller's page.
    //

    BasePage = (Page & ~(LONGLONG)((MBCB_BITMAP_BLOCK_SIZE * 8) - 1));

    //
    //  Loop through the list until we find the range or we have a free range
    //  and correct insertion point.
    //

    do {

        //
        //  If we get an exact match, then we must have hit a fully-initialized
        //  range which we can return.
        //

        if (BasePage == BitmapRange->BasePage) {
            return BitmapRange;

        //
        //  Otherwise, see if the range is free and we have not captured a
        //  free range yet.
        //

        } else if ((BitmapRange->DirtyPages == 0) && (FreeRange == NULL)) {
            FreeRange = BitmapRange;

        //
        //  If we did not capture a free range, see if we need to update our
        //  insertion point.
        //

        } else if (BasePage > BitmapRange->BasePage) {
            InsertPoint = &BitmapRange->Links;
        }

        //
        //  Advance to the next range (or possibly back to the listhead).
        //

        BitmapRange = (PBITMAP_RANGE)BitmapRange->Links.Flink;

    //
    //  Loop until we hit the end, or we know we are done updating both InsertPoint
    //  and FreeRange.
    //

    } while ((BitmapRange != (PBITMAP_RANGE)&Mbcb->BitmapRanges) &&
             ((BasePage >= BitmapRange->BasePage) ||
              (FreeRange == NULL)));

    //
    //  If we found a FreeRange we can use, then remove it from the list.
    //

    if (FreeRange != NULL) {
        RemoveEntryList( &FreeRange->Links );

    //
    //  Otherwise we have to allocate the small bitmap range structure.  We usually
    //  try to avoid calling the pool package while owning a spin lock, but note the
    //  following things which must be true if we hit this point:
    //
    //      The file is larger than 3 bitmap ranges (normally 384MB on Intel).
    //      Three ranges plus all previously allocated ranges are simultaneously dirty.
    //
    //  The second point is fairly unlikely, especially for a sequential writer.  It
    //  can occur for a random writer in a large file, but eventually we will allocate
    //  enough ranges to always describe how many ranges he can keep dirty at once!
    //

    } else {
        FreeRange = ExAllocatePoolWithTag( NonPagedPool, sizeof(BITMAP_RANGE), 'rBcC' );
        if (FreeRange == NULL) {
            return NULL;
        }
        RtlZeroMemory( FreeRange, sizeof(BITMAP_RANGE) );
    }

    //
    //  Insert and initialize.
    //

    InsertHeadList( InsertPoint, &FreeRange->Links );
    FreeRange->BasePage = BasePage;
    FreeRange->FirstDirtyPage = MAXULONG;
    FreeRange->LastDirtyPage = 0;

    //
    //  If the range does not have a bitmap yet, then consume the one we were passed
    //  in.
    //

    if (FreeRange->Bitmap == NULL) {
        ASSERT(*FreePageForSetting != NULL);
        FreeRange->Bitmap = *FreePageForSetting;
        *FreePageForSetting = NULL;
    }

    return FreeRange;
}


PBITMAP_RANGE
CcFindBitmapRangeToClean (
    IN PMBCB Mbcb,
    IN LONGLONG Page
    )

/*++

Routine Description:

    This routine starts from the specified page, and looks for a range with dirty
    pages.  The caller must guarantee that some range exists with dirty pages.  If
    the end of the ranges is hit before finding any dirty ranges, then this routine
    loops back to the start of the range list.

Arguments:

    Mbcb - Supplies the Mbcb in which to find the range.

    Page - Supplies the page number for the first page to scan from.

Return Value:

    The desired bitmap range with dirty pages.

Environment:

    The BcbSpinLock must be held on entry.

--*/

{
    PBITMAP_RANGE BitmapRange;

    //
    //  Point to the first bitmap range.
    //

    BitmapRange = (PBITMAP_RANGE)Mbcb->BitmapRanges.Flink;

    //
    //  Loop through the list until we find the range to return.
    //

    do {

        //
        //  If we hit the listhead, then wrap to find the first dirty range.
        //

        if (BitmapRange == (PBITMAP_RANGE)&Mbcb->BitmapRanges) {

            //
            //  If Page is already 0, we are in an infinite loop.
            //

            ASSERT(Page != 0);

            //
            //  Clear Page and fall through to advance to first range.
            //

            Page = 0;


        //
        //  Otherwise, if we are in range, return the first range
        //  with dirty pages.
        //

        } else if ((Page <= (BitmapRange->BasePage + BitmapRange->LastDirtyPage)) &&
            (BitmapRange->DirtyPages != 0)) {
            return BitmapRange;
        }

        //
        //  Advance to the next range (or possibly back to the listhead).
        //

        BitmapRange = (PBITMAP_RANGE)BitmapRange->Links.Flink;

    } while (TRUE);
}


VOID
CcSetDirtyInMask (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length
    )

/*++

Routine Description:

    This routine may be called to set a range of pages dirty in a user data
    file, by just setting the corresponding bits in the mask bcb.

    IMPORTANT NOTE:

        If this routine fails to set any bits due to an allocation failure,
        it just returns quietly without informing the caller.  (Note that this
        routine is never called for no modified write sections.)  The reason
        for this behavior is that this routine is sometimes called as part of
        error recovery (CcFreeActiveVacb, CcMdlWriteComplete, etc.) when it is
        essential to just keep on moving.  Note that if an allocation failure does
        occur, this only means that MM will have to flush the modified page in
        time, since the Lazy Writer will not do it.

Arguments:

    SharedCacheMap - SharedCacheMap where the pages are to be set dirty.

    FileOffset - FileOffset of first page to set dirty

    Length - Used in conjunction with FileOffset to determine how many pages
             to set dirty.

Return Value:

    None

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    PMBCB Mbcb;
    PBITMAP_RANGE BitmapRange;
    LONGLONG FirstPage;
    LONGLONG LastPage;
    PULONG MaskPtr;
    ULONG Mask = 0;
    PULONG Bitmap = NULL;

    //
    //  We assume no caller can cross a bitmap range boundary (currently not even
    //  a view boundary!), so we do not want to loop through bitmap ranges.
    //

    ASSERT((FileOffset->QuadPart / MBCB_BITMAP_RANGE) ==
           ((FileOffset->QuadPart + Length - 1) / MBCB_BITMAP_RANGE));

    //
    //  Initialize our locals.
    //

    FirstPage = FileOffset->QuadPart >> PAGE_SHIFT;
    LastPage = ((FileOffset->QuadPart + Length - 1) >> PAGE_SHIFT);

    //
    //  PREfix correctly notes that Mbcb grande promotion test and the one
    //  that decides to preallocate the bitmap buffer ever disagree, we will
    //  be able to have a NULL Bitmap and die.  This will not happen since we
    //  guarantee that section size >= filesize.  Assert this case, and we will
    //  also assert that Bitmap is never NULL when needed - this should convince
    //  PREfix we're OK.
    //

    ASSERT( (SharedCacheMap->SectionSize.QuadPart / PAGE_SIZE) > LastPage );

    //
    //  If we have to convert to an Mbcb grande, we will loop back here to
    //  preallocate another buffer.
    //

    do {

        //
        //  For large streams, we need to preallocate a block we use for
        //  we use for bitmaps.  We allocate one, then loop back in the rare
        //  case where we will need another.  We free it at the bottom if we
        //  don't need one.
        //

        if (SharedCacheMap->SectionSize.QuadPart > (MBCB_BITMAP_INITIAL_SIZE * 8 * PAGE_SIZE)) {

            //
            //  If we could not preallocate, break out into common cleanup code and
            //  return quietly.
            //

            if (!CcPrefillVacbLevelZone( 1, &LockHandle.OldIrql, FALSE )) {
                return;
            }

            Bitmap = (PULONG)CcAllocateVacbLevel( FALSE );
            CcReleaseVacbLock( LockHandle.OldIrql );
        }

        //
        //  Acquire the Mbcb spinlock.
        //

        KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

        //
        //  If there is no Mbcb, we will have to allocate one.
        //

        Mbcb = SharedCacheMap->Mbcb;
        if (Mbcb == NULL) {

            //
            //  Since we use the Bcb zone, we must assume that Bcbs are big enough.
            //

            ASSERT(QuadAlign(sizeof(MBCB)) <= QuadAlign(sizeof(BCB)));

            //
            //  Allocate the Mbcb from the Bcb zone.
            //

            Mbcb = (PMBCB)CcAllocateInitializeBcb( NULL, NULL, NULL, NULL );

            //
            //  If we could not allocate an Mbcb, break out to clean up and return
            //

            if (Mbcb == NULL) {
                break;
            }

            //
            //  Set in the node type, and initialize the listhead of ranges.
            //

            Mbcb->NodeTypeCode = CACHE_NTC_MBCB;
            InitializeListHead( &Mbcb->BitmapRanges );

            //
            //  Insert and initialize the first range.
            //

            InsertTailList( &Mbcb->BitmapRanges, &Mbcb->BitmapRange1.Links );
            Mbcb->BitmapRange1.FirstDirtyPage = MAXULONG;

            //
            //  Use the rest of the Mbcb as the initial bitmap.
            //

            Mbcb->BitmapRange1.Bitmap = (PULONG)&Mbcb->BitmapRange2;

            //
            //  Now set to use our new Mbcb.
            //

            SharedCacheMap->Mbcb = Mbcb;
        }

        //
        //  Now see if we need to switch to the Mbcb grande format.
        //

        if ((LastPage >= (MBCB_BITMAP_INITIAL_SIZE * 8)) &&
            (Mbcb->NodeTypeCode != CACHE_NTC_MBCB_GRANDE)) {

            ASSERT( Bitmap != NULL );

            //
            //  If there are any dirty pages, copy the initial bitmap over, and zero
            //  out the original end of the Mbcb for reuse.
            //

            if (Mbcb->BitmapRange1.DirtyPages != 0) {
                RtlCopyMemory( Bitmap, Mbcb->BitmapRange1.Bitmap, MBCB_BITMAP_INITIAL_SIZE );
                RtlZeroMemory( Mbcb->BitmapRange1.Bitmap, MBCB_BITMAP_INITIAL_SIZE );
            }

            //
            //  Store the new bitmap pointer and show we have consumed this one.
            //

            Mbcb->BitmapRange1.Bitmap = Bitmap;
            Bitmap = NULL;

            //
            //  Insert and initialize the first range.
            //

            InsertTailList( &Mbcb->BitmapRanges, &Mbcb->BitmapRange2.Links );
            Mbcb->BitmapRange2.BasePage = MAXLONGLONG;
            Mbcb->BitmapRange2.FirstDirtyPage = MAXULONG;
            InsertTailList( &Mbcb->BitmapRanges, &Mbcb->BitmapRange3.Links );
            Mbcb->BitmapRange3.BasePage = MAXLONGLONG;
            Mbcb->BitmapRange3.FirstDirtyPage = MAXULONG;
            Mbcb->NodeTypeCode = CACHE_NTC_MBCB_GRANDE;

            //
            //  This is a one-time event - converting to the large Mbcb.  Continue back
            //  to preallocate another buffer for CcFindBitmapRangeToDirty.
            //

            KeReleaseInStackQueuedSpinLock( &LockHandle );
            continue;
        }

        //
        //  Now find the Bitmap range we are setting bits in.
        //

        BitmapRange = CcFindBitmapRangeToDirty( Mbcb, FirstPage, &Bitmap );

        //
        //  If we could not allocate this dinky structure, break out quietly.
        //

        if (BitmapRange == NULL) {
            break;
        }

        //
        //  Now update the first and last dirty page indices and the bitmap.
        //

        if (FirstPage < (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)) {
            BitmapRange->FirstDirtyPage = (ULONG)(FirstPage - BitmapRange->BasePage);
        }

        if (LastPage > (BitmapRange->BasePage + BitmapRange->LastDirtyPage)) {
            BitmapRange->LastDirtyPage = (ULONG)(LastPage - BitmapRange->BasePage);
        }

        //
        //  We have to acquire the shared cache map list, because we
        //  may be changing lists.
        //

        CcAcquireMasterLockAtDpcLevel();

        //
        //  If this is the first dirty page for this cache map, there is some work
        //  to do.
        //

        if (SharedCacheMap->DirtyPages == 0) {

            //
            //  If the lazy write scan is not active, then start it.
            //

            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            Mbcb->ResumeWritePage = FirstPage;
        }

        MaskPtr = &BitmapRange->Bitmap[(ULONG)(FirstPage - BitmapRange->BasePage) / 32];
        Mask = 1 << ((ULONG)FirstPage % 32);

        //
        //  Loop to set all of the bits and adjust the DirtyPage totals.
        //

        for ( ; FirstPage <= LastPage; FirstPage++) {

            if ((*MaskPtr & Mask) == 0) {
                CcChargeMaskDirtyPages( SharedCacheMap, Mbcb, BitmapRange, 1 );
                *MaskPtr |= Mask;
            }

            Mask <<= 1;

            if (Mask == 0) {

                MaskPtr += 1;
                Mask = 1;
            }
        }

        //
        //  See if we need to advance our goal for ValidDataLength.
        //

        LastPage = FileOffset->QuadPart + Length;

        if (LastPage > SharedCacheMap->ValidDataGoal.QuadPart) {
            SharedCacheMap->ValidDataGoal.QuadPart = (LONGLONG)LastPage;
        }

        CcReleaseMasterLockFromDpcLevel();

    //
    //  Continue until we have actually set the bits (there is a continue
    //  which just wants to loop back and allocate another buffer).
    //

    } while (Mask == 0);

    //
    //  Now if we preallocated a bitmap buffer, free it on the way out.
    //

    if (Bitmap != NULL) {
        CcAcquireVacbLockAtDpcLevel();
        CcDeallocateVacbLevel( (PVACB *)Bitmap, FALSE );
        CcReleaseVacbLockFromDpcLevel();
    }
    KeReleaseInStackQueuedSpinLock( &LockHandle );
}


VOID
CcSetDirtyPinnedData (
    IN PVOID BcbVoid,
    IN PLARGE_INTEGER Lsn OPTIONAL
    )

/*++

Routine Description:

    This routine may be called to set a Bcb (returned by CcPinFileData)
    dirty, and a candidate for the Lazy Writer.  All Bcbs should be set
    dirty by calling this routine, even if they are to be flushed
    another way.

Arguments:

    Bcb - Supplies a pointer to a pinned (by CcPinFileData) Bcb, to
          be set dirty.

    Lsn - Lsn to be remembered with page.

Return Value:

    None

--*/

{
    PBCB Bcbs[2];
    PBCB *BcbPtrPtr;
    KLOCK_QUEUE_HANDLE LockHandle;
    PSHARED_CACHE_MAP SharedCacheMap;

    DebugTrace(+1, me, "CcSetDirtyPinnedData: Bcb = %08lx\n", BcbVoid );

    //
    //  Assume this is a normal Bcb, and set up for loop below.
    //

    Bcbs[0] = (PBCB)BcbVoid;
    Bcbs[1] = NULL;
    BcbPtrPtr = &Bcbs[0];

    //
    //  If it is an overlap Bcb, then point into the Bcb vector
    //  for the loop.
    //

    if (Bcbs[0]->NodeTypeCode == CACHE_NTC_OBCB) {
        BcbPtrPtr = &((POBCB)Bcbs[0])->Bcbs[0];
    }

    //
    //  Loop to set all Bcbs dirty
    //

    while (*BcbPtrPtr != NULL) {

        Bcbs[0] = *(BcbPtrPtr++);

        //
        //  Should be no ReadOnly Bcbs
        //

        ASSERT(((ULONG_PTR)Bcbs[0] & 1) != 1);

        SharedCacheMap = Bcbs[0]->SharedCacheMap;

        //
        //  We have to acquire the shared cache map list, because we
        //  may be changing lists.
        //

        KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

        if (!Bcbs[0]->Dirty) {

            ULONG Pages = Bcbs[0]->ByteLength >> PAGE_SHIFT;

            //
            //  Set dirty to keep the Bcb from going away until
            //  it is set Undirty, and assign the next modification time stamp.
            //

            Bcbs[0]->Dirty = TRUE;

            //
            //  Initialize the OldestLsn field.
            //

            if (ARGUMENT_PRESENT(Lsn)) {
                Bcbs[0]->OldestLsn = *Lsn;
                Bcbs[0]->NewestLsn = *Lsn;
            }

            //
            //  Move it to the dirty list if these are the first dirty pages,
            //  and this is not disabled for write behind.
            //
            //  Increase the count of dirty bytes in the shared cache map.
            //

            CcAcquireMasterLockAtDpcLevel();
            if ((SharedCacheMap->DirtyPages == 0) &&
                !FlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND)) {

                //
                //  If the lazy write scan is not active, then start it.
                //

                if (!LazyWriter.ScanActive) {
                    CcScheduleLazyWriteScan( FALSE );
                }

                RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
                InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                                &SharedCacheMap->SharedCacheMapLinks );
            }
            
            CcChargePinDirtyPages( SharedCacheMap, Pages );
            CcReleaseMasterLockFromDpcLevel();
        }

        //
        //  If this Lsn happens to be older/newer than the ones we have stored, then
        //  change it.
        //

        if (ARGUMENT_PRESENT(Lsn)) {

            if ((Bcbs[0]->OldestLsn.QuadPart == 0) || (Lsn->QuadPart < Bcbs[0]->OldestLsn.QuadPart)) {
                Bcbs[0]->OldestLsn = *Lsn;
            }

            if (Lsn->QuadPart > Bcbs[0]->NewestLsn.QuadPart) {
                Bcbs[0]->NewestLsn = *Lsn;
            }
        }

        //
        //  See if we need to advance our goal for ValidDataLength.
        //

        if ( Bcbs[0]->BeyondLastByte.QuadPart > SharedCacheMap->ValidDataGoal.QuadPart ) {

            SharedCacheMap->ValidDataGoal = Bcbs[0]->BeyondLastByte;
        }

        KeReleaseInStackQueuedSpinLock( &LockHandle );
    }

    DebugTrace(-1, me, "CcSetDirtyPinnedData -> VOID\n", 0 );
}


NTSTATUS
CcSetValidData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER ValidDataLength
    )

/*++

Routine Description:

    This routine is used to call the File System to update ValidDataLength
    for a file.

Arguments:

    FileObject - A pointer to a referenced file object describing which file
        the read should be performed from.

    ValidDataLength - Pointer to new ValidDataLength.

Return Value:

    Status of operation.

--*/

{
    PIO_STACK_LOCATION IrpSp;
    PDEVICE_OBJECT DeviceObject;
    NTSTATUS Status;
    FILE_END_OF_FILE_INFORMATION Buffer;
    IO_STATUS_BLOCK IoStatus;
    KEVENT Event;
    PIRP Irp;

    DebugTrace(+1, me, "CcSetValidData:\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace2(0, me, "    ValidDataLength = %08lx, %08lx\n",
                ValidDataLength->LowPart, ValidDataLength->HighPart );

    //
    //  Copy ValidDataLength to our buffer.
    //

    Buffer.EndOfFile = *ValidDataLength;

    //
    //  Initialize the event.
    //

    KeInitializeEvent( &Event, NotificationEvent, FALSE );

    //
    //  Begin by getting a pointer to the device object that the file resides
    //  on.
    //

    DeviceObject = IoGetRelatedDeviceObject( FileObject );

    //
    //  Allocate an I/O Request Packet (IRP) for this in-page operation.
    //

    Irp = IoAllocateIrp( DeviceObject->StackSize, FALSE );
    if (Irp == NULL) {

        DebugTrace(-1, me, "CcSetValidData-> STATUS_INSUFFICIENT_RESOURCES\n", 0 );

        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    //  Get a pointer to the first stack location in the packet.  This location
    //  will be used to pass the function codes and parameters to the first
    //  driver.
    //

    IrpSp = IoGetNextIrpStackLocation( Irp );

    //
    //  Fill in the IRP according to this request, setting the flags to
    //  just cause IO to set the event and deallocate the Irp.
    //

    Irp->Flags = IRP_PAGING_IO | IRP_SYNCHRONOUS_PAGING_IO;
    Irp->RequestorMode = KernelMode;
    Irp->UserIosb = &IoStatus;
    Irp->UserEvent = &Event;
    Irp->Tail.Overlay.OriginalFileObject = FileObject;
    Irp->Tail.Overlay.Thread = PsGetCurrentThread();
    Irp->AssociatedIrp.SystemBuffer = &Buffer;

    //
    //  Fill in the normal read parameters.
    //

    IrpSp->MajorFunction = IRP_MJ_SET_INFORMATION;
    IrpSp->FileObject = FileObject;
    IrpSp->DeviceObject = DeviceObject;
    IrpSp->Parameters.SetFile.Length = sizeof(FILE_END_OF_FILE_INFORMATION);
    IrpSp->Parameters.SetFile.FileInformationClass = FileEndOfFileInformation;
    IrpSp->Parameters.SetFile.FileObject = NULL;
    IrpSp->Parameters.SetFile.AdvanceOnly = TRUE;

    //
    //  Queue the packet to the appropriate driver based on whether or not there
    //  is a VPB associated with the device.  This routine should not raise.
    //

    Status = IoCallDriver( DeviceObject, Irp );

    //
    //  If pending is returned (which is a successful status),
    //  we must wait for the request to complete.
    //

    if (Status == STATUS_PENDING) {
        KeWaitForSingleObject( &Event,
                               Executive,
                               KernelMode,
                               FALSE,
                               (PLARGE_INTEGER)NULL);
    }

    //
    //  If we got an error back in Status, then the Iosb
    //  was not written, so we will just copy the status
    //  there, then test the final status after that.
    //

    if (!NT_SUCCESS(Status)) {
        IoStatus.Status = Status;
    }

    DebugTrace(-1, me, "CcSetValidData-> %08lx\n", IoStatus.Status );

    return IoStatus.Status;
}


//
//  Internal Support Routine
//

BOOLEAN
CcAcquireByteRangeForWrite (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER TargetOffset OPTIONAL,
    IN ULONG TargetLength,
    OUT PLARGE_INTEGER FileOffset,
    OUT PULONG Length,
    OUT PBCB *FirstBcb
    )

/*++

Routine Description:

    This routine is called by the Lazy Writer to try to find a contiguous
    range of bytes from the specified SharedCacheMap that are dirty and
    should be flushed.  After flushing, these bytes should be released
    by calling CcReleaseByteRangeFromWrite.

    Dirty ranges are returned in strictly increasing order.

Arguments:

    SharedCacheMap - for the file for which the dirty byte range is sought

    TargetOffset - If specified, then only the specified range is
                   to be flushed.

    TargetLength - If target offset specified, this completes the range.
                   In any case, this field is zero for the Lazy Writer,
                   and nonzero for explicit flush calls.

    FileOffset - Returns the offset for the beginning of the dirty byte
                 range to flush

    Length - Returns the length of bytes in the range.

    FirstBcb - Returns the first Bcb in the list for the range, to be used
               when calling CcReleaseByteRangeFromWrite, or NULL if dirty
               pages were found in the mask Bcb.

Return Value:

    FALSE - if no dirty byte range could be found to match the necessary
            criteria.

    TRUE - if a dirty byte range is being returned.

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    PMBCB Mbcb;
    PBCB Bcb;
    LARGE_INTEGER LsnToFlushTo = {0, 0};

    LOGICAL BcbLookasideCheck = FALSE;

    PBITMAP_RANGE BitmapRange;
    PULONG EndPtr;
    PULONG MaskPtr;
    ULONG Mask;
    LONGLONG FirstDirtyPage;
    ULONG OriginalFirstDirtyPage;
    LONGLONG LastDirtyPage = MAXLONGLONG;

    DebugTrace(+1, me, "CcAcquireByteRangeForWrite:\n", 0);
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap);

    //
    //  Initially clear outputs.
    //

    FileOffset->QuadPart = 0;
    *Length = 0;

    //
    //  We must acquire the SharedCacheMap->BcbSpinLock.
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    //
    //  See if there is a simple Mask Bcb, and if there is anything dirty in
    //  it.  If so we will simply handle that case here by processing the bitmap.
    //

    Mbcb = SharedCacheMap->Mbcb;

    if ((Mbcb != NULL) &&
        (Mbcb->DirtyPages != 0) &&
        ((Mbcb->PagesToWrite != 0) || (TargetLength != 0))) {

        //
        //  If a target range was specified (outside call to CcFlush for a range),
        //  then calculate FirstPage and EndPtr based on these inputs.
        //

        if (ARGUMENT_PRESENT(TargetOffset)) {

            FirstDirtyPage = TargetOffset->QuadPart >> PAGE_SHIFT;
            LastDirtyPage = (TargetOffset->QuadPart + TargetLength - 1) >> PAGE_SHIFT;

            //
            //  Find the bitmap range containing the first dirty page.
            //

            BitmapRange = CcFindBitmapRangeToClean( Mbcb, FirstDirtyPage );

            //
            //  If the target range is not dirty, get out.  We may have even
            //  gotten back a nonoverlapping bitmap range.
            //

            if ((LastDirtyPage < (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)) ||
                (FirstDirtyPage > (BitmapRange->BasePage + BitmapRange->LastDirtyPage))) {

                goto Scan_Bcbs;
            }

            if (LastDirtyPage < (BitmapRange->BasePage + BitmapRange->LastDirtyPage)) {
                EndPtr = &BitmapRange->Bitmap[(ULONG)(LastDirtyPage - BitmapRange->BasePage) / 32];
            } else {
                EndPtr = &BitmapRange->Bitmap[BitmapRange->LastDirtyPage / 32];
            }


        //
        //  Otherwise, for the Lazy Writer pick up where we left off.
        //

        } else {

            //
            //  If a length was specified, then it is an explicit flush, and
            //  we want to start with the first dirty page, else the Lazy Writer
            //  starts from the ResumeWritePage.
            //

            FirstDirtyPage = 0;
            if (TargetLength == 0) {
                FirstDirtyPage = Mbcb->ResumeWritePage;
            }

            //
            //  Now find the next (cyclic) dirty page from this point.
            //

            BitmapRange = CcFindBitmapRangeToClean( Mbcb, FirstDirtyPage );

            //
            //  If the page we thought we were looking for is beyond the last dirty page
            //  of this range, then CcFindBitmapRangeToClean must have wrapped back to
            //  the start of the file, and we should resume on the first dirty page of
            //  this range.
            //

            if (FirstDirtyPage > (BitmapRange->BasePage + BitmapRange->LastDirtyPage)) {
                FirstDirtyPage = BitmapRange->BasePage + BitmapRange->FirstDirtyPage;
            }

            EndPtr = &BitmapRange->Bitmap[BitmapRange->LastDirtyPage / 32];
        }

        //
        //  Now we can skip over any clean pages.
        //

        if (FirstDirtyPage < (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)) {
            FirstDirtyPage = BitmapRange->BasePage + BitmapRange->FirstDirtyPage;
        }

        //
        //  Form a few other inputs for our dirty page scan.
        //

        MaskPtr = &BitmapRange->Bitmap[(ULONG)(FirstDirtyPage - BitmapRange->BasePage) / 32];
        Mask = (ULONG)(-1 << (FirstDirtyPage % 32));
        OriginalFirstDirtyPage = (ULONG)(FirstDirtyPage - BitmapRange->BasePage);

        //
        //  Because of the possibility of getting stuck on a "hot spot" which gets
        //  modified over and over, we want to be very careful to resume exactly
        //  at the recorded resume point.  If there is nothing there, then we
        //  fall into the loop below to scan for nozero long words in the bitmap,
        //  starting at the next longword.
        //

        if ((*MaskPtr & Mask) == 0) {

            //
            //  Before entering loop, set all mask bits and insure we increment from
            //  an even Ulong boundary.
            //

            Mask = MAXULONG;
            FirstDirtyPage &= ~31;

            //
            //  To scan the bitmap faster, we scan for entire long words which are
            //  nonzero.
            //

            do {

                MaskPtr += 1;
                FirstDirtyPage += 32;

                //
                //  If we go beyond the end, then we must wrap back to the first
                //  dirty page.  We will just go back to the start of the first
                //  longword.
                //

                if (MaskPtr > EndPtr) {

                    //
                    //  We can backup the last dirty page hint to where we
                    //  started scanning, if we are the lazy writer.
                    //

                    if (TargetLength == 0) {
                        ASSERT(OriginalFirstDirtyPage >= BitmapRange->FirstDirtyPage);
                        BitmapRange->LastDirtyPage = OriginalFirstDirtyPage - 1;
                    }

                    //
                    //  We hit the end of our scan.  Let's assume we are supposed
                    //  to move on to the next range with dirty pages.
                    //

                    do {

                        //
                        //  Go to the next range.
                        //

                        BitmapRange = (PBITMAP_RANGE)BitmapRange->Links.Flink;

                        //
                        //  Did we hit the listhead?
                        //

                        if (BitmapRange == (PBITMAP_RANGE)&Mbcb->BitmapRanges) {

                            //
                            //  If this is an explicit flush, then it is time to
                            //  get out.
                            //

                            if (TargetLength != 0) {
                                goto Scan_Bcbs;
                            }

                            //
                            //  Otherwise, we must wrap back to the first range in the
                            //  Lazy Writer Scan.
                            //

                            BitmapRange = (PBITMAP_RANGE)BitmapRange->Links.Flink;
                        }

                    } while (BitmapRange->DirtyPages == 0);

                    //
                    //  Now we have a new range with dirty pages, but if this is
                    //  an explicit flush of a specified range, we may be done.
                    //

                    if ((LastDirtyPage < (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)) ||
                        (FirstDirtyPage > (BitmapRange->BasePage + BitmapRange->LastDirtyPage))) {

                        goto Scan_Bcbs;
                    }

                    //
                    //  Otherwise, we need to set up our context to resume scanning in this
                    //  range.
                    //

                    MaskPtr = &BitmapRange->Bitmap[BitmapRange->FirstDirtyPage / 32];
                    EndPtr = &BitmapRange->Bitmap[BitmapRange->LastDirtyPage / 32];
                    FirstDirtyPage = BitmapRange->BasePage + (BitmapRange->FirstDirtyPage & ~31);
                    OriginalFirstDirtyPage = BitmapRange->FirstDirtyPage;
                }
            } while (*MaskPtr == 0);
        }

        //
        //  Calculate the first set bit in the mask that we hit on.
        //

        Mask = ~Mask + 1;

        //
        //  Now loop to find the first set bit.
        //

        while ((*MaskPtr & Mask) == 0) {

            Mask <<= 1;
            FirstDirtyPage += 1;
        }

        //
        //  If a TargetOffset was specified, then make sure we do not start
        //  beyond the specified range or a dirty Bcb in the range.
        //

        if (ARGUMENT_PRESENT(TargetOffset)) {

            if (FirstDirtyPage >= ((TargetOffset->QuadPart + TargetLength + PAGE_SIZE - 1) >> PAGE_SHIFT)) {

                goto Scan_Bcbs;
            }

            //
            //  If Bcbs are present on this file, we must go scan to see if they
            //  describe a range that must be written first.  If this is not the
            //  case, we'll hop back and continue building the range from the mask Bcb.
            //
            //  Note that this case will be very rare.  Bcbs are introduced into user
            //  files in limited situations (CcZero) and the reverse is never allowed
            //  to happen.
            //

            if (!IsListEmpty(&SharedCacheMap->BcbList)) {

                BcbLookasideCheck = TRUE;
                goto Scan_Bcbs;
            }
        }

Accept_Page:

        //
        //  Now loop to count the set bits at that point, clearing them as we
        //  go because we plan to write the corresponding pages.  Stop as soon
        //  as we find a clean page, or we reach our maximum write size.  Of
        //  course we want to ignore long word boundaries and keep trying to
        //  extend the write.  We do not check for wrapping around the end of
        //  the bitmap here, because we guarantee some zero bits at the end
        //  in CcSetDirtyInMask.
        //

        while (((*MaskPtr & Mask) != 0) && (*Length < (MAX_WRITE_BEHIND / PAGE_SIZE)) &&
               (!ARGUMENT_PRESENT(TargetOffset) || ((FirstDirtyPage + *Length) <
                                                    (ULONG)((TargetOffset->QuadPart + TargetLength + PAGE_SIZE - 1) >> PAGE_SHIFT)))) {

            ASSERT(MaskPtr <= (&BitmapRange->Bitmap[BitmapRange->LastDirtyPage / 32]));

            *MaskPtr -= Mask;
            *Length += 1;
            Mask <<= 1;

            if (Mask == 0) {

                MaskPtr += 1;
                Mask = 1;

                if (MaskPtr > EndPtr) {
                    break;
                }
            }
        }

        //
        //  Now reduce the count of pages we were supposed to write this time,
        //  possibly clearing this count.
        //

        if (*Length < Mbcb->PagesToWrite) {

            Mbcb->PagesToWrite -= *Length;

        } else {

            Mbcb->PagesToWrite = 0;
        }

        //
        //  Reduce the dirty page counts by the number of pages we just cleared.
        //

        ASSERT(Mbcb->DirtyPages >= *Length);
        Mbcb->DirtyPages -= *Length;
        BitmapRange->DirtyPages -= *Length;

        CcAcquireMasterLockAtDpcLevel();
        CcDeductDirtyPages( SharedCacheMap, *Length );

        //
        //  Normally we need to reduce CcPagesYetToWrite appropriately.
        //

        if (CcPagesYetToWrite > *Length) {
            CcPagesYetToWrite -= *Length;
        } else {
            CcPagesYetToWrite = 0;
        }

        //
        //  If we took out the last dirty page, then move the SharedCacheMap
        //  back to the clean list.
        //

        if (SharedCacheMap->DirtyPages == 0) {

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            CcInsertIntoCleanSharedCacheMapList( SharedCacheMap );
        }
        CcReleaseMasterLockFromDpcLevel();

        //
        //  If the number of dirty pages for the Mbcb went to zero, we can reset
        //  our hint fields now.
        //

        if (BitmapRange->DirtyPages == 0) {

            BitmapRange->FirstDirtyPage = MAXULONG;
            BitmapRange->LastDirtyPage = 0;

            //
            //  Assume this is a large file and that the resume point should
            //  be at the beginning of the next range.  In all cases if the resume
            //  point is set too high, the next resume will just wrap back to 0 anyway.
            //

            Mbcb->ResumeWritePage = BitmapRange->BasePage + (MBCB_BITMAP_BLOCK_SIZE * 8);

        //
        //  Otherwise we have to update the hint fields.
        //

        } else {

            //
            //  Advance the first dirty page hint if we can.
            //

            if (BitmapRange->FirstDirtyPage == OriginalFirstDirtyPage) {

                BitmapRange->FirstDirtyPage = (ULONG)(FirstDirtyPage - BitmapRange->BasePage) + *Length;
            }

            //
            //  Set to resume the next scan at the next bit for
            //  the Lazy Writer.
            //

            if (TargetLength == 0) {

                Mbcb->ResumeWritePage = FirstDirtyPage + *Length;
            }
        }

        //
        //  We can save a callback by letting our caller know when
        //  we have no more pages to write.
        //

        if (IsListEmpty(&SharedCacheMap->BcbList)) {
            SharedCacheMap->PagesToWrite = Mbcb->PagesToWrite;
        }

        KeReleaseInStackQueuedSpinLock( &LockHandle );

        //
        //  Now form all of our outputs.  We calculated *Length as a page count,
        //  but our caller wants it in bytes.
        //

        *Length <<= PAGE_SHIFT;
        FileOffset->QuadPart = (LONGLONG)FirstDirtyPage << PAGE_SHIFT;
        *FirstBcb = NULL;

        DebugTrace2(0, me, "    <FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                               FileOffset->HighPart );
        DebugTrace( 0, me, "    <Length = %08lx\n", *Length );
        DebugTrace(-1, me, "CcAcquireByteRangeForWrite -> TRUE\n", 0 );

        return TRUE;
    }

    //
    //  We get here if there is no Mbcb or no dirty pages in it.  Note that we
    //  wouldn't even be here if there were no dirty pages in this SharedCacheMap.
    //

    //
    //  Now point to last Bcb in List, and loop until we hit one of the
    //  breaks below or the beginning of the list.
    //

Scan_Bcbs:

    //
    //  Use while TRUE to handle case where the current target range wraps
    //  (escape is at the bottom).
    //

    while (TRUE) {

        Bcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Blink, BCB, BcbLinks );

        //
        //  If we are to resume from a nonzero FileOffset, call CcFindBcb
        //  to get a quicker start.  This is only useful on files that make
        //  use of significant pinned access, of course.
        //

        if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {

            PLARGE_INTEGER StartingOffset;

            if (ARGUMENT_PRESENT(TargetOffset)) {
                StartingOffset = TargetOffset;
            } else {
                StartingOffset = (PLARGE_INTEGER)&SharedCacheMap->BeyondLastFlush;
            }

            if (StartingOffset->QuadPart != 0) {

                LARGE_INTEGER StartingOffsetBias;

                StartingOffsetBias.QuadPart = StartingOffset->QuadPart + PAGE_SIZE;

                //
                //  Position ourselves.  If we did not find a Bcb for the page, then
                //  a lower FileOffset was returned, so we want to move forward one.
                //

                if (!CcFindBcb( SharedCacheMap,
                                StartingOffset,
                                &StartingOffsetBias,
                                &Bcb )) {
                    Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Blink, BCB, BcbLinks );
                }
            }
        }

        while (&Bcb->BcbLinks != &SharedCacheMap->BcbList) {

            //
            //  Skip over this item if it is a listhead.
            //

            if (Bcb->NodeTypeCode != CACHE_NTC_BCB) {

                Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Blink, BCB, BcbLinks );
                continue;
            }

            //
            //  If we are doing a specified range, then get out if we hit a
            //  higher Bcb.
            //

            if (ARGUMENT_PRESENT(TargetOffset) &&
                ((TargetOffset->QuadPart + TargetLength) <= Bcb->FileOffset.QuadPart)) {

                break;
            }

            //
            //  If we have not started a run, then see if this Bcb is a candidate
            //  to start one.
            //

            if (*Length == 0) {

                //
                //  Else see if the Bcb is dirty, and is in our specified range, if
                //  there is one.
                //

                if (!Bcb->Dirty ||
                    (ARGUMENT_PRESENT(TargetOffset) && (TargetOffset->QuadPart >= Bcb->BeyondLastByte.QuadPart)) ||
                    (!ARGUMENT_PRESENT(TargetOffset) && (Bcb->FileOffset.QuadPart < SharedCacheMap->BeyondLastFlush))) {

                    Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Blink, BCB, BcbLinks );
                    continue;

                }

                //
                //  If we have a candidate dirty page from the mask Bcb, see
                //  if it describes a prior range.  We must decide to return
                //  the first dirty range.
                //

                if (BcbLookasideCheck && FirstDirtyPage <= (ULONG)(Bcb->FileOffset.QuadPart >> PAGE_SHIFT)) {
                    goto Accept_Page;
                }
            }

            //
            //  Else, if we have started a run, then if this guy cannot be
            //  appended to the run, then break.  Note that we ignore the
            //  Bcb's modification time stamp here to simplify the test.
            //
            //  If the Bcb is currently pinned, then there is no sense in causing
            //  contention, so we will skip over this guy as well.
            //
            //  Finally, if the new Bcb is in the next Vacb level, we will skip it
            //  to avoid problems with Bcb listheads going away in the middle of
            //  CcReleaseByteRangeFromWrite.
            //

            else {
                if (!Bcb->Dirty || ( Bcb->FileOffset.QuadPart != ( FileOffset->QuadPart + (LONGLONG)*Length)) ||
                    (*Length + Bcb->ByteLength > MAX_WRITE_BEHIND) ||
                    (Bcb->PinCount != 0) ||
                    ((Bcb->FileOffset.QuadPart & (VACB_SIZE_OF_FIRST_LEVEL - 1)) == 0)) {

                    break;
                }
            }

            //
            //  Increment PinCount to prevent Bcb from going away once the
            //  SpinLock is released, or we set it clean for the case where
            //  modified write is allowed.
            //

            Bcb->PinCount += 1;

            //
            //  Release the SpinLock before waiting on the resource.
            //

            KeReleaseInStackQueuedSpinLock( &LockHandle );

            if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) &&
                !FlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND)) {

                //
                //  Now acquire the Bcb exclusive, so that we know that nobody
                //  has it pinned and thus no one can be modifying the described
                //  buffer.  To acquire the first Bcb in a run, we can afford
                //  to wait, because we are not holding any resources.  However
                //  if we already have a Bcb, then we better not wait, because
                //  someone could have this Bcb pinned, and then wait for the
                //  Bcb we already have exclusive.
                //
                //  For streams for which we have not disabled modified page
                //  writing, we do not need to acquire this resource, and the
                //  foreground processing will not be acquiring the Bcb either.
                //

                if (!ExAcquireResourceExclusiveLite( &Bcb->Resource,
                                                 (BOOLEAN)(*Length == 0) )) {

                    DebugTrace( 0, me, "Could not acquire 2nd Bcb\n", 0 );

                    //
                    //  Release the Bcb count we took out above.  We say
                    //  ReadOnly = TRUE since we do not own the resource,
                    //  and SetClean = FALSE because we just want to decement
                    //  the count.
                    //

                    CcUnpinFileData( Bcb, TRUE, UNPIN );

                    //
                    //  When we leave the loop, we have to have the spin lock
                    //

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
                    break;
                }

                KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                //
                //  If someone has the file open WriteThrough, then the Bcb may no
                //  longer be dirty.  If so, call CcUnpinFileData to decrement the
                //  PinCount we incremented and free the resource.
                //

                if (!Bcb->Dirty) {

                    //
                    //  Release the spinlock so that we can call CcUnpinFileData
                    //

                    KeReleaseInStackQueuedSpinLock( &LockHandle );

                    CcUnpinFileData( Bcb, FALSE, UNPIN );

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                    //
                    //  Now if we already have some data we can just break to return
                    //  it, otherwise we have to restart the scan, since our Bcb
                    //  may have gone away.
                    //

                    if (*Length != 0) {
                        break;
                    }
                    else {

                        Bcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Blink, BCB, BcbLinks );
                        continue;
                    }
                }

            //
            //  If we are not in the disable modified write mode (normal user data)
            //  then we must set the buffer clean before doing the write, since we
            //  are unsynchronized with anyone producing dirty data.  That way if we,
            //  for example, are writing data out while it is actively being changed,
            //  at least the changer will mark the buffer dirty afterwards and cause
            //  us to write it again later.
            //

            } else {

                CcUnpinFileData( Bcb, TRUE, SET_CLEAN );

               KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
            }

            DebugTrace( 0, me, "Adding Bcb = %08lx to run\n", Bcb );

            //
            //  No matter what, once we've reached this point we are returning
            //  a range from the Bcbs.
            //

            BcbLookasideCheck = FALSE;

            //
            //  Update all of our return values.  Note that FirstBcb refers to the
            //  FirstBcb in terms of how the Bcb list is ordered.  Since the Bcb list
            //  is ordered by descending file offsets, FirstBcb will actually return
            //  the Bcb with the highest FileOffset.
            //

            if (*Length == 0) {
                *FileOffset = Bcb->FileOffset;
            }
            *FirstBcb = Bcb;
            *Length += Bcb->ByteLength;

            //
            //  If there is a log file flush callback for this stream, then we must
            //  remember the largest Lsn we are about to flush.
            //

            if ((SharedCacheMap->FlushToLsnRoutine != NULL) &&
                (Bcb->NewestLsn.QuadPart > LsnToFlushTo.QuadPart)) {

                LsnToFlushTo = Bcb->NewestLsn;
            }

            Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Blink, BCB, BcbLinks );
        }

        //
        //  If we have a candidate dirty page from the mask Bcb, accept it
        //  since no Bcb has been found.
        //

        if (BcbLookasideCheck) {

            ASSERT( *Length == 0 );
            goto Accept_Page;
        }

        //
        //  If we found something, update our last flush range and reduce
        //  PagesToWrite.
        //

        if (*Length != 0) {

            //
            //  If this is the Lazy Writer, then update BeyondLastFlush and
            //  the PagesToWrite target.
            //

            if (!ARGUMENT_PRESENT(TargetOffset)) {

                SharedCacheMap->BeyondLastFlush = FileOffset->QuadPart + *Length;

                if (SharedCacheMap->PagesToWrite > (*Length >> PAGE_SHIFT)) {
                    SharedCacheMap->PagesToWrite -= (*Length >> PAGE_SHIFT);
                } else {
                    SharedCacheMap->PagesToWrite = 0;
                }
            }

            break;

        //
        //  Else, if we scanned the entire file, get out - nothing to write now.
        //

        } else if ((SharedCacheMap->BeyondLastFlush == 0) || ARGUMENT_PRESENT(TargetOffset)) {
            break;
        }

        //
        //  Otherwise, we may have not found anything because there is nothing
        //  beyond the last flush.  In that case it is time to wrap back to 0
        //  and keep scanning.
        //

        SharedCacheMap->BeyondLastFlush = 0;
    }

    //
    //  Now release the spinlock file while we go off and do the I/O
    //

    KeReleaseInStackQueuedSpinLock( &LockHandle );

    //
    //  If we need to flush to some Lsn, this is the time to do it now
    //  that we have found the largest Lsn and freed the spin lock.
    //

    if (LsnToFlushTo.QuadPart != 0) {

        try {

            (*SharedCacheMap->FlushToLsnRoutine) ( SharedCacheMap->LogHandle,
                                                   LsnToFlushTo );
        } except( CcExceptionFilter( GetExceptionCode() )) {

            //
            //  If there was an error, it will be raised.  We cannot
            //  write anything until we successfully flush the log
            //  file, so we will release everything here and just
            //  return with 0 bytes.
            //

            LARGE_INTEGER LastOffset;
            PBCB NextBcb;

            //
            //  Now loop to free up all of the Bcbs.  Set the time
            //  stamps to 0, so that we are guaranteed to try to
            //  flush them again on the next sweep.
            //

            do {
                NextBcb = CONTAINING_RECORD( (*FirstBcb)->BcbLinks.Flink, BCB, BcbLinks );

                //
                //  Skip over any listheads.
                //

                if ((*FirstBcb)->NodeTypeCode == CACHE_NTC_BCB) {

                    LastOffset = (*FirstBcb)->FileOffset;

                    CcUnpinFileData( *FirstBcb,
                                     BooleanFlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND),
                                     UNPIN );
                }

                *FirstBcb = NextBcb;
            } while (FileOffset->QuadPart != LastOffset.QuadPart);

            //
            //  Show we did not acquire anything.
            //

            *Length = 0;
        }
    }

    //
    //  If we got anything, return TRUE.
    //

    DebugTrace2(0, me, "    <FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                           FileOffset->HighPart );
    DebugTrace( 0, me, "    <Length = %08lx\n", *Length );
    DebugTrace(-1, me, "CcAcquireByteRangeForWrite -> %02lx\n", *Length != 0 );

    return ((BOOLEAN)(*Length != 0));
}


//
//  Internal Support Routine
//

VOID
CcReleaseByteRangeFromWrite (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN PBCB FirstBcb,
    IN BOOLEAN VerifyRequired
    )

/*++

Routine Description:

    This routine is called by the Lazy Writer to free a range of bytes and
    clear all dirty bits, for a byte range returned by CcAcquireByteRangeForWrite.

Arguments:

    SharedCacheMap - As supplied to CcAcquireByteRangeForWrite

    FileOffset - As returned from CcAcquireByteRangeForWrite

    Length - As returned from CcAcquirebyteRangeForWrite

    FirstBcb - As returned from CcAcquireByteRangeForWrite

    VerifyRequired - supplied as TRUE if a verify required error was received.
                     In this case we must mark/leave the data dirty so that
                     we will try to write it again.

Return Value:

    None

--*/

{
    LARGE_INTEGER LastOffset;
    PBCB NextBcb;

    DebugTrace(+1, me, "CcReleaseByteRangeFromWrite:\n", 0);
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );

    //
    //  If it is a mask Mbcb we are getting, then we only have to check
    //  for VerifyRequired.
    //

    if (FirstBcb == NULL) {

        ASSERT(Length != 0);

        if (VerifyRequired) {
            CcSetDirtyInMask( SharedCacheMap, FileOffset, Length );
        }

        DebugTrace(-1, me, "CcReleaseByteRangeFromWrite -> VOID\n", 0);

        return;
    }

    //
    //  PREfix correctly notes that if the caller gives us a listhead to start with,
    //  we will not have filled in LastOffset by the time we do our first loop test.
    //  For PREfix's benefit (and ours), assert we really are starting with a Bcb.
    //

    ASSERT( FirstBcb->NodeTypeCode == CACHE_NTC_BCB );

    //
    //  Now loop to free up all of the Bcbs.  If modified writing is disabled
    //  for each Bcb, then we are to set it clean here, since we are synchronized
    //  with callers who set the data dirty.  Otherwise we only have the Bcb pinned
    //  so it will not go away, and we only unpin it here.
    //

    do {
        NextBcb = CONTAINING_RECORD( FirstBcb->BcbLinks.Flink, BCB, BcbLinks );

        //
        //  Skip over any listheads.
        //

        if (FirstBcb->NodeTypeCode == CACHE_NTC_BCB) {

            LastOffset = FirstBcb->FileOffset;

            //
            //  If this is file system metadata (we disabled modified writing),
            //  then this is the time to mark the buffer clean, so long as we
            //  did not get verify required.
            //

            if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {

                CcUnpinFileData( FirstBcb,
                                 BooleanFlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND),
                                 SET_CLEAN );
            }

            //
            //  If we got verify required, we have to mark the buffer dirty again
            //  so we will try again later.  Note we have to make this call again
            //  to make sure the right thing happens with time stamps.
            //

            if (VerifyRequired) {
                CcSetDirtyPinnedData( FirstBcb, NULL );
            }

            //
            //  Finally remove a pin count left over from CcAcquireByteRangeForWrite.
            //

            CcUnpinFileData( FirstBcb, TRUE, UNPIN );
        }

        FirstBcb = NextBcb;
    } while (FileOffset->QuadPart != LastOffset.QuadPart);

    DebugTrace(-1, me, "CcReleaseByteRangeFromWrite -> VOID\n", 0);
}


//
//  Internal Support Routine
//

VOID
FASTCALL
CcWriteBehind (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine may be called with Wait = FALSE to see if write behind
    is required, or with Wait = TRUE to perform write behind as required.

    The code is very similar to the the code that the Lazy Writer performs
    for each SharedCacheMap.  The main difference is in the call to
    CcAcquireByteRangeForWrite.  Write Behind does not care about time
    stamps (passing ULONG to accept all time stamps), but it will never
    dump the first (highest byte offset) buffer in the list if the last
    byte of that buffer is not yet written.  The Lazy Writer does exactly
    the opposite, in the sense that it is totally time-driven, and will
    even dump a partially modified buffer if it sits around long enough.

Arguments:

    SharedCacheMap - Pointer to SharedCacheMap to be written

Return Value:

    FALSE - if write behind is required, but the caller supplied
            Wait = FALSE

    TRUE - if write behind is complete or not required

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PMBCB Mbcb;
    NTSTATUS Status;
    PVACB ActiveVacb = NULL;

    DebugTrace(+1, me, "CcWriteBehind\n", 0 );
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap );

    //
    //  First we have to acquire the file for LazyWrite, to avoid
    //  deadlocking with writers to the file.  We do this via the
    //  CallBack procedure specified to CcInitializeCacheMap.
    //

    if (!(*SharedCacheMap->Callbacks->AcquireForLazyWrite)
                            ( SharedCacheMap->LazyWriteContext, TRUE )) {

        //
        //  The filesystem is hinting that it doesn't think that it can
        //  service the write without significant delay so we will defer
        //  and come back later.  Simply drop the queued flag ... note that
        //  we do not modify CcPagesYetToWrite, in the hope that we can make
        //  up the difference in some other cache map on this pass.
        //

        CcAcquireMasterLock( &LockHandle.OldIrql );
        ClearFlag(SharedCacheMap->Flags, WRITE_QUEUED);
        CcReleaseMasterLock( LockHandle.OldIrql );

        IoStatus->Status = STATUS_FILE_LOCK_CONFLICT;
        return;
    }

    //
    //  See if there is a previous active page to clean up, but only
    //  do so now if it is the last dirty page or no users have the
    //  file open.  We will free it below after dropping the spinlock.
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
    CcAcquireMasterLockAtDpcLevel();

    if ((SharedCacheMap->DirtyPages <= 1) || (SharedCacheMap->OpenCount == 0)) {
        GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }

    //
    //  Increment open count so that our caller's views stay available
    //  for CcGetVacbMiss.  We could be tying up all of the views, and
    //  still need to write file sizes.
    //

    CcIncrementOpenCount( SharedCacheMap, 'brWS' );

    //
    //  If there is a mask bcb, then we need to establish a target for
    //  it to flush.
    //

    if ((Mbcb = SharedCacheMap->Mbcb) != 0) {

        //
        //  Set a target of pages to write, assuming that any Active
        //  Vacb will increase the number.
        //

        Mbcb->PagesToWrite = Mbcb->DirtyPages + ((ActiveVacb != NULL) ? 1 : 0);

        if (Mbcb->PagesToWrite > CcPagesYetToWrite) {

            Mbcb->PagesToWrite = CcPagesYetToWrite;
        }
    }

    CcReleaseMasterLockFromDpcLevel();
    KeReleaseInStackQueuedSpinLock( &LockHandle );

    //
    //  Now free the active Vacb, if we found one.
    //

    if (ActiveVacb != NULL) {

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }

    //
    //  Now perform the lazy writing for this file via a special call
    //  to CcFlushCache.  He recognizes us by the &CcNoDelay input to
    //  FileOffset, which signifies a Lazy Write, but is subsequently
    //  ignored.
    //

    CcFlushCache( SharedCacheMap->FileObject->SectionObjectPointer,
                  &CcNoDelay,
                  1,
                  IoStatus );

    //
    //  No need for the Lazy Write resource now.
    //

    (*SharedCacheMap->Callbacks->ReleaseFromLazyWrite)
                        ( SharedCacheMap->LazyWriteContext );

    //
    //  Check if we need to put up a popup.
    //

    if (!NT_SUCCESS(IoStatus->Status) && !RetryError(IoStatus->Status)) {

        //
        //  We lost writebehind data.  Bemoan our fate into the system event
        //  log and throw a popup with a meaningful name to the desktop.
        //

        POBJECT_NAME_INFORMATION FileNameInfo = NULL;
        NTSTATUS Status;

        //
        //  Increment the count of how many of these we've had.  This counter
        //  is useful in attempting to discriminate some corruption cases under
        //  test.
        //

        CcLostDelayedWrites += 1;
        
        Status = IoQueryFileDosDeviceName( SharedCacheMap->FileObject, &FileNameInfo );

        if ( Status == STATUS_SUCCESS ) {
            IoRaiseInformationalHardError( STATUS_LOST_WRITEBEHIND_DATA, &FileNameInfo->Name, NULL );

        } else {
            if ( SharedCacheMap->FileObject->FileName.Length &&
                 SharedCacheMap->FileObject->FileName.MaximumLength &&
                 SharedCacheMap->FileObject->FileName.Buffer ) {

                IoRaiseInformationalHardError( STATUS_LOST_WRITEBEHIND_DATA, &SharedCacheMap->FileObject->FileName, NULL );
            }
        }

        CcLogError( SharedCacheMap->FileObject,
                    ( Status == STATUS_SUCCESS ?
                      &FileNameInfo->Name :
                      &SharedCacheMap->FileObject->FileName ),
                    IO_LOST_DELAYED_WRITE,
                    IoStatus->Status,
                    IRP_MJ_WRITE );

        if (FileNameInfo) {
            ExFreePool(FileNameInfo);
        }

    //
    //  See if there is any deferred writes we can post.
    //

    } else if (!IsListEmpty(&CcDeferredWrites)) {
        CcPostDeferredWrites();
    }

    //
    //  Now acquire BcbSpinLock again to check for ValidData updates.
    //

    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    //
    //  If the the current ValidDataGoal is greater (or equal) than ValidDataLength,
    //  then we must see if we have advanced beyond the current ValidDataLength.
    //
    //  If we have NEVER written anything out from this shared cache map, then
    //  there is no need to check anything associtated with valid data length
    //  here.  We will come by here again when, and if, anybody actually
    //  modifies the file and we lazy write some data.
    //

    Status = STATUS_SUCCESS;
    if (FlagOn(SharedCacheMap->Flags, (LAZY_WRITE_OCCURRED | FORCED_WRITE_THROUGH)) &&
        (SharedCacheMap->ValidDataGoal.QuadPart >= SharedCacheMap->ValidDataLength.QuadPart) &&
        (SharedCacheMap->ValidDataLength.QuadPart != MAXLONGLONG) &&
        (SharedCacheMap->FileSize.QuadPart != 0)) {

        LARGE_INTEGER NewValidDataLength;

        NewValidDataLength = CcGetFlushedValidData( SharedCacheMap->FileObject->SectionObjectPointer,
                                                    TRUE );

        //
        //  If New ValidDataLength has been written, then we have to
        //  call the file system back to update it.  We must temporarily
        //  drop our global list while we do this, which is safe to do since
        //  we have not cleared WRITE_QUEUED.
        //
        //  Note we keep calling any time we wrote the last page of the file,
        //  to solve the "famous" AFS Server problem.  The file system will
        //  truncate our valid data call to whatever is currently valid.  But
        //  then if he writes a little more, we do not want to stop calling
        //  back.
        //

        if ( NewValidDataLength.QuadPart >= SharedCacheMap->ValidDataLength.QuadPart ) {

            KeReleaseInStackQueuedSpinLock( &LockHandle );

            //
            //  Call file system to set new valid data.  We have no
            //  one to tell if this doesn't work.
            //

            Status = CcSetValidData( SharedCacheMap->FileObject,
                                     &NewValidDataLength );

            KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
            if (NT_SUCCESS(Status)) {
                SharedCacheMap->ValidDataLength = NewValidDataLength;
#ifdef TOMM
            } else if ((Status != STATUS_INSUFFICIENT_RESOURCES) && !RetryError(Status)) {
                DbgPrint("Unexpected status from CcSetValidData: %08lx, FileObject: %08lx\n",
                         Status,
                         SharedCacheMap->FileObject);
                DbgBreakPoint();
#endif TOMM
            }
        }
    }

    KeReleaseInStackQueuedSpinLock( &LockHandle );

    //
    //  Show we are done.
    //

    CcAcquireMasterLock( &LockHandle.OldIrql );
    CcDecrementOpenCount( SharedCacheMap, 'brWF' );

    //
    //  Make an approximate guess about whether we will call CcDeleteSharedCacheMap or not
    //  to truncate the file.
    //
    //  Also do not delete the SharedCacheMap if we got an error on the ValidDataLength
    //  callback.  If we get a resource allocation failure or a retryable error (due to
    //  log file full?), we have no one to tell, so we must just loop back and try again.
    //  Of course all I/O errors are just too bad.
    //

    if (SharedCacheMap->OpenCount == 0) {


        if (NT_SUCCESS(Status) || 
            ((Status != STATUS_INSUFFICIENT_RESOURCES) && !RetryError(Status))) {

            CcReleaseMasterLock( LockHandle.OldIrql );
            FsRtlAcquireFileExclusive( SharedCacheMap->FileObject );
            CcAcquireMasterLock( &LockHandle.OldIrql );

            //
            //  Now really see if we are to delete this SharedCacheMap. By having released
            //  first we avoid a deadlock with the file system when the FileObject is
            //  dereferenced.  Note that CcDeleteSharedCacheMap requires that the
            //  CcMasterSpinLock already be acquired, and it releases it.
            //
            //  Note that we must retest since we dropped and reacquired the master
            //  lock.
            //

            if ((SharedCacheMap->OpenCount == 0)

                    &&

                ( (SharedCacheMap->DirtyPages == 0) 
                    
                            || 
                            
                  ( (SharedCacheMap->FileSize.QuadPart == 0) && 
                    !FlagOn(SharedCacheMap->Flags, PIN_ACCESS) ) )
                ) {

                //
                //  Make sure to drop the requeue flag in case the write hit the timeout at
                //  the same time it finished everything up.
                //

                CcDeleteSharedCacheMap( SharedCacheMap, LockHandle.OldIrql, TRUE );
                IoStatus->Information = 0;
                SharedCacheMap = NULL;

            } else {

                CcReleaseMasterLock( LockHandle.OldIrql );
                FsRtlReleaseFile( SharedCacheMap->FileObject );
                CcAcquireMasterLock( &LockHandle.OldIrql );
            }
            
        } else {

            //
            //  We got an error where we should retry our operation.  Move this
            //  shared cache map back to the dirty list if it is not already
            //  there.
            //

            if (SharedCacheMap->DirtyPages == 0) {

                RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
                InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                                &SharedCacheMap->SharedCacheMapLinks );

                //
                //  Make sure the Lazy Writer will wake up, because we
                //  want him to delete this SharedCacheMap.
                //

                LazyWriter.OtherWork = TRUE;
                if (!LazyWriter.ScanActive) {
                    CcScheduleLazyWriteScan( FALSE );
                }
            }
        }
    }

    //
    //  In the normal case, we just clear the flag on the way out if
    //  we will not requeue the workitem.
    //

    if (SharedCacheMap != NULL) {

        if (IoStatus->Information != CC_REQUEUE) {
            ClearFlag(SharedCacheMap->Flags, WRITE_QUEUED);
        }
        CcReleaseMasterLock( LockHandle.OldIrql );
    }

    DebugTrace(-1, me, "CcWriteBehind->VOID\n", 0 );

    return;
}


LARGE_INTEGER
CcGetFlushedValidData (
    IN PSECTION_OBJECT_POINTERS SectionObjectPointer,
    IN BOOLEAN CcInternalCaller
    )

/*++

Routine Description:

    This routine may be called by a file system to find out how far the Cache Manager
    has flushed in the stream.  More accurately, this routine returns either the FileOffset
    of the lowest dirty page currently in the file.

    NOTE that even though the routine takes SectionObjectPointer, the caller must insure
    that the stream is cached and stays cached for the duration of this routine, much like
    for the copy routines, etc.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

    CcInternalCaller - must be TRUE if the caller is coming from Cc, FALSE otherwise.
        TRUE imples the need for self-synchronization.

Return Value:

    The derived number for flushed ValidData, or MAXLONGLONG in the quad part if
    the Section is not cached.  (Naturally the caller can guarantee that this case
    does not occur, and internal callers do.)

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    KLOCK_QUEUE_HANDLE LockHandle;
    LARGE_INTEGER NewValidDataLength;

    //
    //  External callers may be unsynchronized with this shared cache map
    //  perhaps going away underneath this call.  NTFS and his
    //  pair of streams for compression-on-the-wire is a good example of
    //  someone who may be synchronized in one stream but needs to peek at
    //  the other.
    //

    if (!CcInternalCaller) {

        CcAcquireMasterLock( &LockHandle.OldIrql );

        SharedCacheMap = SectionObjectPointer->SharedCacheMap;

        if (SharedCacheMap == NULL) {
            CcReleaseMasterLock( LockHandle.OldIrql );
            NewValidDataLength.QuadPart = MAXLONGLONG;
            return NewValidDataLength;
        }

        CcIncrementOpenCount( SharedCacheMap, 'dfGS' );
        CcReleaseMasterLock( LockHandle.OldIrql );
        KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

    } else {

        SharedCacheMap = SectionObjectPointer->SharedCacheMap;
    }

    ASSERT( SharedCacheMap != NULL );

    //
    //  If the file is entirely clean, then we wish to return
    //  the new ValidDataLength as equal to ValidDataGoal.
    //

    NewValidDataLength = SharedCacheMap->ValidDataGoal;

    //
    //  If there may be dirty pages we will look at the last Bcb in the
    //  descending-order Bcb list, and see if it describes data beyond
    //  ValidDataGoal.
    //
    //  It is important to note that since we use DirtyPages as a faux
    //  reference count over some short windows (+1, -1) the simple
    //  fact it is nonzero does *not* mean the file is dirty.
    //
    //  (This test is logically too conservative.  For example, the last Bcb
    //  may not even be dirty (in which case we should look at its
    //  predecessor), or we may have earlier written valid data to this
    //  byte range (which also means if we knew this we could look at
    //  the predessor).  This simply means that the Lazy Writer may not
    //  successfully get ValidDataLength updated in a file being randomly
    //  accessed until the level of file access dies down, or at the latest
    //  until the file is closed.  However, security will never be
    //  compromised.)
    //

    if (SharedCacheMap->DirtyPages) {

        PBITMAP_RANGE BitmapRange;
        PBCB LastBcb;
        PMBCB Mbcb = SharedCacheMap->Mbcb;

        if ((Mbcb != NULL) && (Mbcb->DirtyPages != 0)) {

            BitmapRange = CcFindBitmapRangeToClean( Mbcb, 0 );

            ASSERT(BitmapRange->FirstDirtyPage != MAXULONG);

            NewValidDataLength.QuadPart = (BitmapRange->BasePage + BitmapRange->FirstDirtyPage)
                                            << PAGE_SHIFT;
        }

        LastBcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Flink,
                                     BCB,
                                     BcbLinks );

        while (&LastBcb->BcbLinks != &SharedCacheMap->BcbList) {

            if ((LastBcb->NodeTypeCode == CACHE_NTC_BCB) && LastBcb->Dirty) {
                break;
            }

            LastBcb = CONTAINING_RECORD( LastBcb->BcbLinks.Flink,
                                         BCB,
                                         BcbLinks );
        }

        //
        //  Check the Base of the last entry.
        //

        if ((&LastBcb->BcbLinks != &SharedCacheMap->BcbList) &&
            (LastBcb->FileOffset.QuadPart < NewValidDataLength.QuadPart )) {

            NewValidDataLength = LastBcb->FileOffset;
        }
    }

    if (!CcInternalCaller) {

        //
        //  Remove our reference.
        //

        CcAcquireMasterLockAtDpcLevel();
        CcDecrementOpenCount( SharedCacheMap, 'dfGF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                        &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        KeReleaseInStackQueuedSpinLockFromDpcLevel( &LockHandle );
        CcReleaseMasterLock( LockHandle.OldIrql );
    }

    return NewValidDataLength;
}


VOID
CcFlushCache (
    IN PSECTION_OBJECT_POINTERS SectionObjectPointer,
    IN PLARGE_INTEGER FileOffset OPTIONAL,
    IN ULONG Length,
    OUT PIO_STATUS_BLOCK IoStatus OPTIONAL
    )

/*++

Routine Description:

    This routine may be called to flush dirty data from the cache to the
    cached file on disk.  Any byte range within the file may be flushed,
    or the entire file may be flushed by omitting the FileOffset parameter.

    This routine does not take a Wait parameter; the caller should assume
    that it will always block.

Arguments:

    SectionObjectPointer - A pointer to the Section Object Pointers
                           structure in the nonpaged Fcb.

    FileOffset - If this parameter is supplied (not NULL), then only the
                 byte range specified by FileOffset and Length are flushed.
                 If &CcNoDelay is specified, then this signifies the call
                 from the Lazy Writer, and the lazy write scan should resume
                 as normal from the last spot where it left off in the file.

    Length - Defines the length of the byte range to flush, starting at
             FileOffset.  This parameter is ignored if FileOffset is
             specified as NULL.

    IoStatus - The I/O status resulting from the flush operation.

Return Value:

    None.

--*/

{
    LARGE_INTEGER NextFileOffset, TargetOffset;
    ULONG NextLength;
    PBCB FirstBcb;
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap;
    IO_STATUS_BLOCK TrashStatus;
    PVOID TempVa;
    ULONG RemainingLength, TempLength;
    NTSTATUS PopupStatus;
    LOGICAL HotSpot;
    ULONG BytesWritten = 0;
    LOGICAL PopupRequired = FALSE;
    LOGICAL VerifyRequired = FALSE;
    LOGICAL IsLazyWriter = FALSE;
    LOGICAL FastLazyWrite = FALSE;
    LOGICAL FreeActiveVacb = FALSE;
    PVACB ActiveVacb = NULL;
    NTSTATUS Status = STATUS_SUCCESS;
    LARGE_INTEGER EndTick, CurrentTick;

    DebugTrace(+1, me, "CcFlushCache:\n", 0 );
    DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n", SectionObjectPointer );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n",
                            ARGUMENT_PRESENT(FileOffset) ? FileOffset->LowPart
                                                         : 0,
                            ARGUMENT_PRESENT(FileOffset) ? FileOffset->HighPart
                                                         : 0 );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    //
    //  If IoStatus passed a Null pointer, set up to through status away.
    //

    if (!ARGUMENT_PRESENT(IoStatus)) {
        IoStatus = &TrashStatus;
    }
    IoStatus->Status = STATUS_SUCCESS;
    IoStatus->Information = 0;

    //
    //  See if this is the Lazy Writer.  Since he wants to use this common
    //  routine, which is also a public routine callable by file systems,
    //  the Lazy Writer shows his call by specifying CcNoDelay as the file offset!
    //
    //  Also, in case we do not write anything because we see only HotSpot(s),
    //  initialize the Status to indicate a retryable error, so CcWorkerThread
    //  knows we did not make any progress.  Of course any actual flush will
    //  overwrite this code.
    //

    if (FileOffset == &CcNoDelay) {
        IoStatus->Status = STATUS_VERIFY_REQUIRED;
        IsLazyWriter = TRUE;
        FileOffset = NULL;
    }

    CcAcquireMasterLock( &OldIrql );

    SharedCacheMap = SectionObjectPointer->SharedCacheMap;

    //
    //  Awareness is indicated by the lowbit of the FileOffset pointer.
    //  Non-awareness of a private write stream results in a no-op.
    //

    if (SharedCacheMap != NULL) {

        if (IsLazyWriter && FlagOn( SharedCacheMap->Flags, WAITING_FOR_TEARDOWN )) {

            //
            //  If the WAITING_FOR_TEARDOWN flag is set, Mm is waiting for Cc
            //  to flush this file and teardown the shared cache map so that
            //  the file can be remapped as a section image.  In this case,
            //  we want the lazy writer to flush all dirty data for this file
            //  to disk now, not just a fraction of the dirty pages to keep 
            //  within the lazy write threshold.
            //
            
            FastLazyWrite = TRUE;
        }

        if (FlagOn( SharedCacheMap->Flags, PRIVATE_WRITE )) {
            
            if (((ULONG_PTR)FileOffset & 1) == 0) {

                CcReleaseMasterLock( OldIrql );
                return;

            }

            FileOffset = (PLARGE_INTEGER)((ULONG_PTR)FileOffset ^ 1);
        }
    }

    //
    //  If there is nothing to do, return here.
    //

    if (ARGUMENT_PRESENT(FileOffset) && (Length == 0)) {

        CcReleaseMasterLock( OldIrql );
        DebugTrace(-1, me, "CcFlushCache -> VOID\n", 0 );
        return;
    }

    //
    //  See if the file is cached.
    //

    if (SharedCacheMap != NULL) {

        //
        //  Increment the open count to keep it from going away.
        //

        CcIncrementOpenCount( SharedCacheMap, 'fcCS' );

        if ((SharedCacheMap->NeedToZero != NULL) || (SharedCacheMap->ActiveVacb != NULL)) {

            ULONG FirstPage = 0;
            ULONG LastPage = MAXULONG;

            if (ARGUMENT_PRESENT(FileOffset)) {

                FirstPage = (ULONG)(FileOffset->QuadPart >> PAGE_SHIFT);
                LastPage = (ULONG)((FileOffset->QuadPart + Length - 1) >> PAGE_SHIFT);
            }

            //
            //  Make sure we do not flush the active page without zeroing any
            //  uninitialized data.  Also, it is very important to free the active
            //  page if it is the one to be flushed, so that we get the dirty
            //  bit out to the Pfn.
            //

            if (((((LONGLONG)LastPage + 1) << PAGE_SHIFT) > SharedCacheMap->ValidDataGoal.QuadPart) ||

                ((SharedCacheMap->NeedToZero != NULL) &&
                 (FirstPage <= SharedCacheMap->NeedToZeroPage) &&
                 (LastPage >= SharedCacheMap->NeedToZeroPage)) ||

                ((SharedCacheMap->ActiveVacb != NULL) &&
                 (FirstPage <= SharedCacheMap->ActivePage) &&
                 (LastPage >= SharedCacheMap->ActivePage))) {

                GetActiveVacbAtDpcLevel( SharedCacheMap, ActiveVacb, RemainingLength, TempLength );
                FreeActiveVacb = TRUE;
            }
        }
    }

    CcReleaseMasterLock( OldIrql );

    if (FreeActiveVacb) {
        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, RemainingLength, TempLength );
    }

    //
    //  If there is a user-mapped file, then we perform the "service" of
    //  flushing even data not written via the file system.  Note that this
    //  is pretty important for folks provoking the flush/purge of a coherency
    //  operation.
    //
    //  It is critical this happen before we examine our own hints.  In the course
    //  of this flush it is possible valid data length will be advanced by the
    //  underlying filesystem, with CcZero'ing behind - which will cause us to
    //  make some dirty zeroes in the cache.  Syscache bug!  Note how coherency
    //  flushing works ...
    //

    if ((SharedCacheMap == NULL)

            ||

        FlagOn(((PFSRTL_COMMON_FCB_HEADER)(SharedCacheMap->FileObject->FsContext))->Flags,
               FSRTL_FLAG_USER_MAPPED_FILE) && !IsLazyWriter) {

        //
        //  Call MM to flush the section through our view.
        //

        DebugTrace( 0, mm, "MmFlushSection:\n", 0 );
        DebugTrace( 0, mm, "    SectionObjectPointer = %08lx\n", SectionObjectPointer );
        DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n",
                                ARGUMENT_PRESENT(FileOffset) ? FileOffset->LowPart
                                                             : 0,
                                ARGUMENT_PRESENT(FileOffset) ? FileOffset->HighPart
                                                             : 0 );
        DebugTrace( 0, mm, "    RegionSize = %08lx\n", Length );

        Status = MmFlushSection( SectionObjectPointer,
                                 FileOffset,
                                 Length,
                                 IoStatus,
                                 TRUE );

        if ((!NT_SUCCESS(IoStatus->Status)) && !RetryError(IoStatus->Status)) {

            PopupRequired = TRUE;
            PopupStatus = IoStatus->Status;
        }

        DebugTrace2(0, mm, "    <IoStatus = %08lx, %08lx\n",
                    IoStatus->Status, IoStatus->Information );
    }

    //
    //  Scan for dirty pages if there is a shared cache map.
    //

    if (SharedCacheMap != NULL) {

        //
        //  If FileOffset was not specified then set to flush entire region
        //  and set valid data length to the goal so that we will not get
        //  any more call backs.  We will also flush the entire region if
        //  we are trying to do a fast lazy write to flush the entire file to
        //  disk now.
        //

        if (!(IsLazyWriter && !FastLazyWrite) && !ARGUMENT_PRESENT(FileOffset)) {

            SharedCacheMap->ValidDataLength = SharedCacheMap->ValidDataGoal;
        }

        //
        //  If this is an explicit flush, initialize our offset to scan for.
        //

        if (ARGUMENT_PRESENT(FileOffset)) {
            TargetOffset = *FileOffset;
        }

        //
        //  Assume we want to pass the explicit flush flag in Length.
        //  But overwrite it if a length really was specified.  On
        //  subsequent loops, NextLength will have some nonzero value.
        //

        NextLength = 1;
        if (Length != 0) {
            NextLength = Length;
        }

        //
        //  Now calculate the tick that will signal the expiration of a
        //  lazy writer tick interval.
        //

        if (IsLazyWriter) {

            KeQueryTickCount( &EndTick );
            EndTick.QuadPart += CcIdleDelayTick;
        }

        //
        //  Loop as long as we find buffers to flush for this
        //  SharedCacheMap, and we are not trying to delete the guy.
        //

        while (((SharedCacheMap->PagesToWrite != 0) || !(IsLazyWriter && !FastLazyWrite))

                    &&
               ((SharedCacheMap->FileSize.QuadPart != 0) ||
                FlagOn(SharedCacheMap->Flags, PIN_ACCESS))

                    &&

               !VerifyRequired

                    &&

               CcAcquireByteRangeForWrite ( SharedCacheMap,
                                            (IsLazyWriter && !FastLazyWrite ) ? NULL : (ARGUMENT_PRESENT(FileOffset) ?
                                                                                       &TargetOffset : NULL),
                                            (IsLazyWriter && !FastLazyWrite ) ? 0: NextLength,
                                            &NextFileOffset,
                                            &NextLength,
                                            &FirstBcb )) {

            //
            //  Assume this range is not a hot spot.
            //

            HotSpot = FALSE;

            //
            //  We defer calling Mm to set address range modified until here, to take
            //  overhead out of the main line path, and to reduce the number of TBIS
            //  on a multiprocessor.
            //

            RemainingLength = NextLength;

            do {

                //
                //  See if the next file offset is mapped.  (If not, the dirty bit
                //  was propagated on the unmap.)
                //

                if ((TempVa = CcGetVirtualAddressIfMapped( SharedCacheMap,
                                                           NextFileOffset.QuadPart + NextLength - RemainingLength,
                                                           &ActiveVacb,
                                                           &TempLength)) != NULL) {

                    //
                    //  Reduce TempLength to RemainingLength if necessary, and
                    //  call MM.
                    //

                    if (TempLength > RemainingLength) {
                        TempLength = RemainingLength;
                    }

                    //
                    //  Clear the Dirty bit (if set) in the PTE and set the
                    //  Pfn modified.  Assume if the Pte was dirty, that this may
                    //  be a hot spot.  Do not do hot spots for metadata, and unless
                    //  they are within ValidDataLength as reported to the file system
                    //  via CcSetValidData.
                    //

                    HotSpot = (BOOLEAN)(((MmSetAddressRangeModified(TempVa, TempLength) || HotSpot) &&
                                         ((NextFileOffset.QuadPart + NextLength) <
                                          (SharedCacheMap->ValidDataLength.QuadPart)) &&
                                         ((SharedCacheMap->LazyWritePassCount & 0xF) != 0) &&
                                         (IsLazyWriter && !FastLazyWrite)) &&
                                        !FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED));

                    CcFreeVirtualAddress( ActiveVacb );

                } else {

                    //
                    //  Reduce TempLength to RemainingLength if necessary.
                    //

                    if (TempLength > RemainingLength) {
                        TempLength = RemainingLength;
                    }
                }

                //
                //  Reduce RemainingLength by what we processed.
                //

                RemainingLength -= TempLength;

            //
            //  Loop until done.
            //

            } while (RemainingLength != 0);

            CcLazyWriteHotSpots += HotSpot;

            //
            //  Now flush, now flush if we do not think it is a hot spot.
            //

            if (!HotSpot) {

                MmFlushSection( SharedCacheMap->FileObject->SectionObjectPointer,
                                &NextFileOffset,
                                NextLength,
                                IoStatus,
                                !IsLazyWriter );

                if (NT_SUCCESS(IoStatus->Status)) {

                    if (!FlagOn(SharedCacheMap->Flags, LAZY_WRITE_OCCURRED)) {

                        CcAcquireMasterLock( &OldIrql );
                        SetFlag(SharedCacheMap->Flags, LAZY_WRITE_OCCURRED);
                        CcReleaseMasterLock( OldIrql );
                    }

                    //
                    //  Increment performance counters
                    //

                    if (IsLazyWriter) {

                        CcLazyWriteIos += 1;
                        CcLazyWritePages += (NextLength + PAGE_SIZE - 1) >> PAGE_SHIFT;
                    }

                } else {

                    LARGE_INTEGER Offset = NextFileOffset;
                    ULONG RetryLength = NextLength;

                    DebugTrace2( 0, 0, "I/O Error on Cache Flush: %08lx, %08lx\n",
                                 IoStatus->Status, IoStatus->Information );

                    if (RetryError(IoStatus->Status)) {

                        VerifyRequired = TRUE;

                    //
                    //  Loop to write each page individually, starting with one
                    //  more try on the page that got the error, in case that page
                    //  or any page beyond it can be successfully written
                    //  individually.  Note that Offset and RetryLength are
                    //  guaranteed to be in integral pages, but the Information
                    //  field from the failed request is not.
                    //
                    //  We ignore errors now, and give it one last shot, before
                    //  setting the pages clean (see below).
                    //

                    } else {

                        do {

                            DebugTrace2( 0, 0, "Trying page at offset %08lx, %08lx\n",
                                         Offset.LowPart, Offset.HighPart );

                            MmFlushSection ( SharedCacheMap->FileObject->SectionObjectPointer,
                                             &Offset,
                                             PAGE_SIZE,
                                             IoStatus,
                                             !IsLazyWriter );

                            DebugTrace2( 0, 0, "I/O status = %08lx, %08lx\n",
                                         IoStatus->Status, IoStatus->Information );

                            if (NT_SUCCESS(IoStatus->Status)) {
                                CcAcquireMasterLock( &OldIrql );
                                SetFlag(SharedCacheMap->Flags, LAZY_WRITE_OCCURRED);
                                CcReleaseMasterLock( OldIrql );
                            }

                            if ((!NT_SUCCESS(IoStatus->Status)) && !RetryError(IoStatus->Status)) {

                                PopupRequired = TRUE;
                                PopupStatus = IoStatus->Status;
                            }

                            VerifyRequired = VerifyRequired || RetryError(IoStatus->Status);

                            Offset.QuadPart = Offset.QuadPart + (LONGLONG)PAGE_SIZE;
                            RetryLength -= PAGE_SIZE;

                        } while(RetryLength > 0);
                    }
                }
            }

            //
            //  Now release the Bcb resources and set them clean.  Note we do not check
            //  here for errors, and just returned in the I/O status.  Errors on writes
            //  are rare to begin with.  Nonetheless, our strategy is to rely on
            //  one or more of the following (depending on the file system) to prevent
            //  errors from getting to us.
            //
            //      - Retries and/or other forms of error recovery in the disk driver
            //      - Mirroring driver
            //      - Hot fixing in the noncached path of the file system
            //
            //  In the unexpected case that a write error does get through, we
            //  *currently* just set the Bcbs clean anyway, rather than let
            //  Bcbs and pages accumulate which cannot be written.  Note we did
            //  a popup above to at least notify the guy.
            //
            //  Set the pages dirty again if we either saw a HotSpot or got
            //  verify required.
            //

            CcReleaseByteRangeFromWrite ( SharedCacheMap,
                                          &NextFileOffset,
                                          NextLength,
                                          FirstBcb,
                                          (BOOLEAN)(HotSpot || VerifyRequired) );

            //
            //  See if there is any deferred writes we should post.
            //

            BytesWritten += NextLength;
            if ((BytesWritten >= 0x40000) && !IsListEmpty(&CcDeferredWrites)) {
                CcPostDeferredWrites();
                BytesWritten = 0;
            }

            //
            //  If we're the lazy writer and have spent more than the active tick
            //  length in this loop, break out for a requeue so we share the
            //  file resources.
            //

            if (IsLazyWriter) {

                KeQueryTickCount( &CurrentTick );

                if (CurrentTick.QuadPart > EndTick.QuadPart) {
                    IoStatus->Information = CC_REQUEUE;
                    break;
                }
            }

            //
            //  Now for explicit flushes, we should advance our range.
            //

            if (ARGUMENT_PRESENT(FileOffset)) {

                NextFileOffset.QuadPart += NextLength;

                //
                //  Done yet?
                //

                if ((FileOffset->QuadPart + Length) <= NextFileOffset.QuadPart) {
                    break;
                }

                //
                //  Calculate new target range
                //

                NextLength = (ULONG)((FileOffset->QuadPart + Length) - NextFileOffset.QuadPart);
                TargetOffset = NextFileOffset;
            }
        }
    }

    //
    //  See if there are any deferred writes we should post if
    //  we escaped the loop without checking after a series of
    //  flushes.
    //

    if (BytesWritten != 0 && !IsListEmpty(&CcDeferredWrites)) {

        CcPostDeferredWrites();
    }

    //
    //  Now we can get rid of the open count, and clean up as required.
    //

    if (SharedCacheMap != NULL) {

        //
        //  Serialize again to decrement the open count.
        //

        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'fcCF' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }

    //
    //  Make sure and return the first error to our caller.  In the
    //  case of the Lazy Writer, a popup will be issued.
    //

    if (PopupRequired) {
        IoStatus->Status = PopupStatus;
    }

    DebugTrace(-1, me, "CcFlushCache -> VOID\n", 0 );

    return;
}


PVOID
CcRemapBcb (
    IN PVOID Bcb
    )

/*++

Routine Description:

    This routine may be called by a file system to map a Bcb an additional
    time in order to preserve it through several calls that perform additional
    maps and unpins.


Arguments:

    Bcb - Supplies a pointer to a previously returned Bcb.

Return Value:

    Bcb with read-only indicator.

--*/

{
    KIRQL OldIrql;
    PVACB Vacb;

    //
    //  Remove read-only bit
    //

    Bcb = (PVOID) ((ULONG_PTR)Bcb & ~1);

    if (((PBCB)Bcb)->NodeTypeCode == CACHE_NTC_OBCB) {

        //
        //  If this is an overlapped BCB, use the first Vacb in the
        //  array
        //

        Vacb = ((POBCB)Bcb)->Bcbs[0]->Vacb;

    } else if (((PBCB)Bcb)->NodeTypeCode == CACHE_NTC_BCB) {

        //
        //  If this is a BCB, extract the Vcb from it
        //

        Vacb = ((PBCB)Bcb)->Vacb;

    } else {

        //
        //  Otherwise, there is no signature to match. Assume
        //  it is a Vacb.
        //

        Vacb = (PVACB) Bcb;
    }

    ASSERT((Vacb >= CcVacbs) && (Vacb < CcBeyondVacbs));

    //
    //  Safely bump the active count
    //

    CcAcquireVacbLock( &OldIrql );

    Vacb->Overlay.ActiveCount += 1;

    CcReleaseVacbLock( OldIrql );

    return (PVOID) ((ULONG_PTR)Vacb | 1);
}


VOID
CcRepinBcb (
    IN PVOID Bcb
    )

/*++

Routine Description:

    This routine may be called by a file system to pin a Bcb an additional
    time in order to reserve it for Write Through or error recovery.
    Typically the file system would do this the first time that it sets a
    pinned buffer dirty while processing a WriteThrough request, or any
    time that it determines that a buffer will be required for WriteThrough.

    The call to this routine must be followed by a call to CcUnpinRepinnedBcb.
    CcUnpinRepinnedBcb should normally be called during request completion
    after all other resources have been released.  CcUnpinRepinnedBcb
    synchronously writes the buffer (for WriteThrough requests) and performs
    the matching unpin for this call.

Arguments:

    Bcb - Supplies a pointer to a previously pinned Bcb

Return Value:

    None.

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;

    KeAcquireInStackQueuedSpinLock( &((PBCB)Bcb)->SharedCacheMap->BcbSpinLock, &LockHandle );

    ((PBCB)Bcb)->PinCount += 1;

    KeReleaseInStackQueuedSpinLock( &LockHandle );
}


VOID
CcUnpinRepinnedBcb (
    IN PVOID Bcb,
    IN BOOLEAN WriteThrough,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine may be called to Write a previously pinned buffer
    through to the file.  It must have been preceded by a call to
    CcRepinBcb.  As this routine must acquire the Bcb
    resource exclusive, the caller must be extremely careful to avoid
    deadlocks.  Ideally the caller owns no resources at all when it
    calls this routine, or else the caller should guarantee that it
    has nothing else pinned in this same file.  (The latter rule is
    the one used to avoid deadlocks in calls from CcCopyWrite and
    CcMdlWrite.)

Arguments:

    Bcb - Pointer to a Bcb which was previously specified in a call
          to CcRepinBcb.

    WriteThrough - TRUE if the Bcb should be written through.

    IoStatus - Returns the I/O status for the operation.

Return Value:

    None.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap = ((PBCB)Bcb)->SharedCacheMap;

    DebugTrace(+1, me, "CcUnpinRepinnedBcb\n", 0 );
    DebugTrace( 0, me, "    Bcb = %08lx\n", Bcb );
    DebugTrace( 0, me, "    WriteThrough = %02lx\n", WriteThrough );

    //
    //  Set status to success for non write through case.
    //

    IoStatus->Status = STATUS_SUCCESS;

    if (WriteThrough) {

        //
        //  Acquire Bcb exclusive to eliminate possible modifiers of the buffer,
        //  since we are about to write its buffer.
        //

        if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {
            ExAcquireResourceExclusiveLite( &((PBCB)Bcb)->Resource, TRUE );
        }

        //
        //  Now, there is a chance that the LazyWriter has already written
        //  it, since the resource was free.  We will only write it if it
        //  is still dirty.
        //

        if (((PBCB)Bcb)->Dirty) {

            //
            //  First we make sure that the dirty bit in the PFN database is set.
            //

            ASSERT( ((PBCB)Bcb)->BaseAddress != NULL );
            MmSetAddressRangeModified( ((PBCB)Bcb)->BaseAddress,
                                       ((PBCB)Bcb)->ByteLength );

            //
            //  Now release the Bcb resource and set it clean.  Note we do not check
            //  here for errors, and just return the I/O status.  Errors on writes
            //  are rare to begin with.  Nonetheless, our strategy is to rely on
            //  one or more of the following (depending on the file system) to prevent
            //  errors from getting to us.
            //
            //      - Retries and/or other forms of error recovery in the disk driver
            //      - Mirroring driver
            //      - Hot fixing in the noncached path of the file system
            //
            //  In the unexpected case that a write error does get through, we
            //  report it to our caller, but go ahead and set the Bcb clean.  There
            //  seems to be no point in letting Bcbs (and pages in physical memory)
            //  accumulate which can never go away because we get an unrecoverable I/O
            //  error.
            //

            //
            //  We specify TRUE here for ReadOnly so that we will keep the
            //  resource during the flush.
            //

            CcUnpinFileData( (PBCB)Bcb, TRUE, SET_CLEAN );

            //
            //  Write it out.
            //

            MmFlushSection( ((PBCB)Bcb)->SharedCacheMap->FileObject->SectionObjectPointer,
                            &((PBCB)Bcb)->FileOffset,
                            ((PBCB)Bcb)->ByteLength,
                            IoStatus,
                            TRUE );

            //
            //  If we got verify required, we have to mark the buffer dirty again
            //  so we will try again later.
            //

            if (RetryError(IoStatus->Status)) {
                CcSetDirtyPinnedData( (PBCB)Bcb, NULL );
            }

            //
            //  Now remove the final pin count now that we have set it clean.
            //

            CcUnpinFileData( (PBCB)Bcb, FALSE, UNPIN );

            //
            //  See if there is any deferred writes we can post.
            //

            if (!IsListEmpty(&CcDeferredWrites)) {
                CcPostDeferredWrites();
            }
        }
        else {

            //
            //  Lazy Writer got there first, just free the resource and unpin.
            //

            CcUnpinFileData( (PBCB)Bcb, FALSE, UNPIN );

        }

        DebugTrace2(0, me, "    <IoStatus = %08lx, %08lx\n", IoStatus->Status,
                                                             IoStatus->Information );
    }

    //
    //  Non-WriteThrough case
    //

    else {

        CcUnpinFileData( (PBCB)Bcb, TRUE, UNPIN );

        //
        //  Set status to success for non write through case.
        //

        IoStatus->Status = STATUS_SUCCESS;
    }

    DebugTrace(-1, me, "CcUnpinRepinnedBcb -> VOID\n", 0 );
}


//
//  Internal Support Routine
//

BOOLEAN
CcFindBcb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN OUT PLARGE_INTEGER BeyondLastByte,
    OUT PBCB *Bcb
    )

/*++

Routine Description:

    This routine is called to find a Bcb describing the specified byte range
    of a file.  It returns TRUE if it could at least find a Bcb which describes
    the beginning of the specified byte range, or else FALSE if the first
    part of the byte range is not present.  In the latter case, the requested
    byte range (TrialLength) is truncated if there is currently a Bcb which
    describes bytes beyond the beginning of the byte range.

    The caller may see if the entire byte range is being returned by examining
    the Bcb, and the caller (or caller's caller) may then make subsequent
    calls if the data is not all returned.

    The BcbSpinLock must be currently acquired.

Arguments:

    SharedCacheMap - Supplies a pointer to the SharedCacheMap for the file
                     in which the byte range is desired.

    FileOffset - Supplies the file offset for the beginning of the desired
                 byte range.

    BeyondLastByte - Supplies the file offset of the ending of the desired
                  byte range + 1.  Note that this offset will be truncated
                  on return if the Bcb was not found, but bytes beyond the
                  beginning of the Bcb are contained in another Bcb.

    Bcb - returns a Bcb describing the beginning of the byte range if also
          returning TRUE, or else the point in the Bcb list to insert after.

Return Value:

    FALSE - if no Bcb describes the beginning of the desired byte range

    TRUE - if a Bcb is being returned describing at least an initial
           part of the byte range.

--*/

{
    PLIST_ENTRY BcbList;
    PBCB Bcbt;
    BOOLEAN Found = FALSE;

    DebugTrace(+1, me, "CcFindBcb:\n", 0 );
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace2(0, me, "    TrialLength = %08lx, %08lx\n", TrialLength->LowPart,
                                                           TrialLength->HighPart );

    //
    //  We want to terminate scans by testing the NodeTypeCode field from the
    //  BcbLinks, so we want to see the SharedCacheMap signature from the same
    //  offset.
    //

    ASSERT(FIELD_OFFSET(SHARED_CACHE_MAP, BcbList) == FIELD_OFFSET(BCB, BcbLinks));

    //
    //  Similarly, when we hit one of the BcbListHeads in the array, small negative
    //  offsets are all structure pointers, so we are counting on the Bcb signature
    //  to have some non-Ulong address bits set.
    //

    ASSERT((CACHE_NTC_BCB & 3) != 0);

    //
    //  Get address of Bcb listhead that is *after* the Bcb we are looking for,
    //  for backwards scan.  It is important that we fail in the forward
    //  direction so that we are looking in the right segment of the Bcb list.
    //

    BcbList = GetBcbListHead( SharedCacheMap, FileOffset->QuadPart + SIZE_PER_BCB_LIST, TRUE );

    //
    //  Search for an entry that overlaps the specified range, or until we hit
    //  a listhead.
    //

    Bcbt = CONTAINING_RECORD(BcbList->Flink, BCB, BcbLinks);

    //
    //  First see if we really have to do Large arithmetic or not, and
    //  then use either a 32-bit loop or a 64-bit loop to search for
    //  the Bcb.
    //

    if (FileOffset->HighPart == 0 &&
        Bcbt->NodeTypeCode == CACHE_NTC_BCB &&
        Bcbt->BeyondLastByte.HighPart == 0) {

        //
        //  32-bit - loop until we get back to a listhead.
        //

        while (Bcbt->NodeTypeCode == CACHE_NTC_BCB) {

            //
            //  Since the Bcb list is in descending order, we first check
            //  if we are completely beyond the current entry, and if so
            //  get out.
            //

            if (FileOffset->LowPart >= Bcbt->BeyondLastByte.LowPart) {
                break;
            }

            //
            //  Next check if the first byte we are looking for is
            //  contained in the current Bcb.  If so, we either have
            //  a partial hit and must truncate to the exact amount
            //  we have found, or we may have a complete hit.  In
            //  either case we break with Found == TRUE.
            //

            if (FileOffset->LowPart >= Bcbt->FileOffset.LowPart) {
                Found = TRUE;
                break;
            }

            //
            //  Now we know we must loop back and keep looking, but we
            //  still must check for the case where the tail end of the
            //  bytes we are looking for are described by the current
            //  Bcb.  If so we must truncate what we are looking for,
            //  because this routine is only supposed to return bytes
            //  from the start of the desired range.
            //

            if (BeyondLastByte->LowPart >= Bcbt->FileOffset.LowPart) {
                BeyondLastByte->LowPart = Bcbt->FileOffset.LowPart;
            }

            //
            //  Advance to next entry in list (which is possibly back to
            //  the listhead) and loop back.
            //

            Bcbt = CONTAINING_RECORD( Bcbt->BcbLinks.Flink,
                                      BCB,
                                      BcbLinks );

        }

    } else {

        //
        //  64-bit - Loop until we get back to a listhead.
        //

        while (Bcbt->NodeTypeCode == CACHE_NTC_BCB) {

            //
            //  Since the Bcb list is in descending order, we first check
            //  if we are completely beyond the current entry, and if so
            //  get out.
            //

            if (FileOffset->QuadPart >= Bcbt->BeyondLastByte.QuadPart) {
                break;
            }

            //
            //  Next check if the first byte we are looking for is
            //  contained in the current Bcb.  If so, we either have
            //  a partial hit and must truncate to the exact amount
            //  we have found, or we may have a complete hit.  In
            //  either case we break with Found == TRUE.
            //

            if (FileOffset->QuadPart >= Bcbt->FileOffset.QuadPart) {
                Found = TRUE;
                break;
            }

            //
            //  Now we know we must loop back and keep looking, but we
            //  still must check for the case where the tail end of the
            //  bytes we are looking for are described by the current
            //  Bcb.  If so we must truncate what we are looking for,
            //  because this routine is only supposed to return bytes
            //  from the start of the desired range.
            //

            if (BeyondLastByte->QuadPart >= Bcbt->FileOffset.QuadPart) {
                BeyondLastByte->QuadPart = Bcbt->FileOffset.QuadPart;
            }

            //
            //  Advance to next entry in list (which is possibly back to
            //  the listhead) and loop back.
            //

            Bcbt = CONTAINING_RECORD( Bcbt->BcbLinks.Flink,
                                      BCB,
                                      BcbLinks );

        }
    }

    *Bcb = Bcbt;

    DebugTrace2(0, me, "    <TrialLength = %08lx, %08lx\n", TrialLength->LowPart,
                                                            TrialLength->HighPart );
    DebugTrace( 0, me, "    <Bcb = %08lx\n", *Bcb );
    DebugTrace(-1, me, "CcFindBcb -> %02lx\n", Found );

    return Found;
}


//
//  Internal Support Routine
//

PBCB
CcAllocateInitializeBcb (
    IN OUT PSHARED_CACHE_MAP SharedCacheMap OPTIONAL,
    IN OUT PBCB AfterBcb,
    IN PLARGE_INTEGER FileOffset,
    IN PLARGE_INTEGER TrialLength
    )

/*++

Routine Description:

    This routine allocates and initializes a Bcb to describe the specified
    byte range, and inserts it into the Bcb List of the specified Shared
    Cache Map.  The Bcb List spin lock must currently be acquired.

    BcbSpinLock must be acquired on entry.

Arguments:

    SharedCacheMap - Supplies the SharedCacheMap for the new Bcb.

    AfterBcb - Supplies where in the descending-order BcbList the new Bcb
               should be inserted: either the ListHead (masquerading as
               a Bcb) or a Bcb.

    FileOffset - Supplies File Offset for the desired data.

    TrialLength - Supplies length of desired data.

Return Value:

    Address of the allocated and initialized Bcb

--*/

{
    PBCB Bcb;
    ULONG RoundedBcbSize = (sizeof(BCB) + 7) & ~7;

    if ((Bcb = ExAllocatePoolWithTag( NonPagedPool, sizeof(BCB), 'cBcC')) == NULL) {
        
        return NULL;
    }

    //
    //  Initialize the newly allocated Bcb.  First zero it, then fill in
    //  nonzero fields.
    //

    RtlZeroMemory( Bcb, RoundedBcbSize );

    //
    //  For Mbcb's, SharedCacheMap is NULL, and the rest of this initialization
    //  is not desired.
    //

    if (SharedCacheMap != NULL) {

        Bcb->NodeTypeCode = CACHE_NTC_BCB;
        Bcb->FileOffset = *FileOffset;
        Bcb->ByteLength = TrialLength->LowPart;
        Bcb->BeyondLastByte.QuadPart = FileOffset->QuadPart + TrialLength->QuadPart;
        Bcb->PinCount += 1;
        ExInitializeResourceLite( &Bcb->Resource );
        Bcb->SharedCacheMap = SharedCacheMap;

        //
        //  Since CcCalculateVacbLockCount has to be able to walk
        //  the BcbList with only the VacbSpinLock, we take that one
        //  out to change the list and set the count.
        //

        CcAcquireVacbLockAtDpcLevel();
        InsertTailList( &AfterBcb->BcbLinks, &Bcb->BcbLinks );

        ASSERT( (SharedCacheMap->SectionSize.QuadPart < VACB_SIZE_OF_FIRST_LEVEL) ||
                (CcFindBcb(SharedCacheMap, FileOffset, &Bcb->BeyondLastByte, &AfterBcb) &&
                 (Bcb == AfterBcb)) );

        //
        //  Now for large metadata streams we lock the Vacb level.
        //

        CcLockVacbLevel( SharedCacheMap, FileOffset->QuadPart );
        CcReleaseVacbLockFromDpcLevel();

        //
        //  If this resource was no write behind, let Ex know that the
        //  resource will never be acquired exclusive.  Also disable
        //  boost (I know this is useless, but KenR said I had to do it).
        //

        if (SharedCacheMap &&
            FlagOn(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND)) {
#if DBG
            SetFlag(Bcb->Resource.Flag, ResourceNeverExclusive);
#endif
            ExDisableResourceBoost( &Bcb->Resource );
        }
    }

    return Bcb;
}


//
//  Internal support routine
//

VOID
FASTCALL
CcDeallocateBcb (
    IN PBCB Bcb
    )

/*++

Routine Description:

    This routine deallocates a Bcb to the BcbZone.  It must
    already be removed from the BcbList.

Arguments:

    Bcb - the Bcb to deallocate

Return Value:

    None

--*/

{
    //
    //  Deallocate Resource structures
    //

    if (Bcb->NodeTypeCode == CACHE_NTC_BCB) {

        ExDeleteResourceLite( &Bcb->Resource );
    }

    ExFreePool(Bcb);
    return;
}


//
//  Internal Support Routine
//

BOOLEAN
CcMapAndRead(
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG ZeroFlags,
    IN BOOLEAN Wait,
    IN PVOID BaseAddress
    )

/*++

Routine Description:

    This routine may be called to insure that the specified data is mapped,
    read into memory and locked.  If TRUE is returned, then the
    correct I/O status for the transfer is also returned, along with
    a system-space address for the data.

Arguments:

    SharedCacheMap - Supplies the address of the SharedCacheMap for the
                     data.

    FileOffset - Supplies the file offset of the desired data.

    Length - Supplies the total amount of data desired.

    ZeroFlags - Defines which pages may be zeroed if not resident.

    Wait - Supplies FALSE if the caller is not willing to block for the
           data, or TRUE if the caller is willing to block.

    BaseAddress - Supplies the system base address at which the data may
                  be accessed.

Return Value:

    FALSE - if the caller supplied Wait = FALSE and the data could not
            be returned without blocking.

    TRUE - if the data is being returned.

    Note: this routine may raise an exception due to a map or read failure,
          however, this can only happen if Wait was specified as TRUE, since
          mapping and reading will not be performed if the caller cannot wait.

--*/

{
    ULONG ZeroCase;
    ULONG SavedState;
    BOOLEAN Result = FALSE;
    PETHREAD Thread = PsGetCurrentThread();

    UNREFERENCED_PARAMETER (SharedCacheMap);
    UNREFERENCED_PARAMETER (FileOffset);

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  try around everything for cleanup.
    //

    try {

        ULONG PagesToGo;

        //
        //  Now loop to touch all of the pages, calling MM to insure
        //  that if we fault, we take in exactly the number of pages
        //  we need.
        //

        PagesToGo = ADDRESS_AND_SIZE_TO_SPAN_PAGES( BaseAddress, Length );

        //
        //  Loop to touch or zero the pages.
        //

        ZeroCase = ZERO_FIRST_PAGE;

        while (PagesToGo) {

            //
            //  If we cannot zero this page, or Mm failed to return
            //  a zeroed page, then just fault it in.
            //

            MmSetPageFaultReadAhead( Thread, (PagesToGo - 1) );

            if (!FlagOn(ZeroFlags, ZeroCase) ||
                !MmCheckCachedPageState(BaseAddress, TRUE)) {

                //
                //  If we get here, it is almost certainly due to the fact
                //  that we can not take a zero page.  MmCheckCachedPageState
                //  will so rarely return FALSE, that we will not worry
                //  about it.  We will only check if the page is there if
                //  Wait is FALSE, so that we can do the right thing.
                //

                if (!MmCheckCachedPageState(BaseAddress, FALSE) && !Wait) {
                    try_return( Result = FALSE );
                }
            }

            BaseAddress = (PCHAR)BaseAddress + PAGE_SIZE;
            PagesToGo -= 1;

            if (PagesToGo == 1) {
                ZeroCase = ZERO_LAST_PAGE;
            } else {
                ZeroCase = ZERO_MIDDLE_PAGES;
            }
        }

        try_return( Result = TRUE );

    try_exit: NOTHING;
    }

    //
    //  Cleanup on the way out.
    //

    finally {

        MmResetPageFaultReadAhead(Thread, SavedState);
    }

    return Result;
}


//
//  Internal Support Routine
//

VOID
CcFreeActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB ActiveVacb OPTIONAL,
    IN ULONG ActivePage,
    IN ULONG PageIsDirty
    )

/*++

Routine Description:

    This routine may be called to zero the end of a locked page or
    free the ActiveVacb for a Shared Cache Map, if there is one.
    Note that some callers are not synchronized with foreground
    activity, and may therefore not have an ActiveVacb.  Examples
    of unsynchronized callers are CcZeroEndOfLastPage (which is
    called by MM) and any flushing done by CcWriteBehind.

Arguments:

    SharedCacheMap - SharedCacheMap to examine for page to be zeroed.

    ActiveVacb - Vacb to free

    ActivePage - Page that was used

    PageIsDirty - ACTIVE_PAGE_IS_DIRTY if the active page is dirty

Return Value:

    None

--*/

{
    LARGE_INTEGER ActiveOffset;
    PVOID ActiveAddress;
    ULONG BytesLeftInPage;
    KIRQL OldIrql;

    //
    //  If the page was locked, then unlock it.
    //

    if (SharedCacheMap->NeedToZero != NULL) {

        PVACB NeedToZeroVacb;

        //
        //  Zero the rest of the page under spinlock control,
        //  and then clear the address field.  This field makes
        //  zero->nonzero transitions only when the file is exclusive,
        //  but it can make nonzero->zero transitions any time the
        //  spinlock is not held.
        //

        ExAcquireFastLock( &SharedCacheMap->ActiveVacbSpinLock, &OldIrql );

        //
        //  The address could already be gone.
        //

        ActiveAddress = SharedCacheMap->NeedToZero;
        if (ActiveAddress != NULL) {

            BytesLeftInPage = PAGE_SIZE - ((((ULONG)((ULONG_PTR)ActiveAddress) - 1) & (PAGE_SIZE - 1)) + 1);

            RtlZeroBytes( ActiveAddress, BytesLeftInPage );
            NeedToZeroVacb = SharedCacheMap->NeedToZeroVacb;
            ASSERT( NeedToZeroVacb != NULL );
            SharedCacheMap->NeedToZero = NULL;

        }
        ExReleaseFastLock( &SharedCacheMap->ActiveVacbSpinLock, OldIrql );

        //
        //  Now call MM to unlock the address.  Note we will never store the
        //  address at the start of the page, but we can sometimes store
        //  the start of the next page when we have exactly filled the page.
        //

        if (ActiveAddress != NULL) {
            MmUnlockCachedPage( (PVOID)((PCHAR)ActiveAddress - 1) );
            CcFreeVirtualAddress( NeedToZeroVacb );
        }
    }

    //
    //  See if caller actually has an ActiveVacb
    //

    if (ActiveVacb != NULL) {

        //
        //  See if the page is dirty
        //

        if (PageIsDirty) {

            ActiveOffset.QuadPart = (LONGLONG)ActivePage << PAGE_SHIFT;
            ActiveAddress = (PVOID)((PCHAR)ActiveVacb->BaseAddress +
                                    (ActiveOffset.LowPart  & (VACB_MAPPING_GRANULARITY - 1)));

            //
            //  Tell the Lazy Writer to write the page.
            //

            CcSetDirtyInMask( SharedCacheMap, &ActiveOffset, PAGE_SIZE );

            //
            //  Now we need to clear the flag and decrement some counts if there is
            //  no other active Vacb which snuck in.
            //

            CcAcquireMasterLock( &OldIrql );
            ExAcquireSpinLockAtDpcLevel( &SharedCacheMap->ActiveVacbSpinLock );
            if ((SharedCacheMap->ActiveVacb == NULL) &&
                FlagOn(SharedCacheMap->Flags, ACTIVE_PAGE_IS_DIRTY)) {

                ClearFlag(SharedCacheMap->Flags, ACTIVE_PAGE_IS_DIRTY);
                CcDeductDirtyPages( SharedCacheMap, 1);
            }
            ExReleaseSpinLockFromDpcLevel( &SharedCacheMap->ActiveVacbSpinLock );
            CcReleaseMasterLock( OldIrql );
        }

        //
        //  Now free the Vacb.
        //

        CcFreeVirtualAddress( ActiveVacb );
    }
}


//
//  Internal Support Routine
//

VOID
CcMapAndCopy(
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVOID UserBuffer,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG ZeroFlags,
    IN PFILE_OBJECT FileObject
    )

/*++

Routine Description:

    This routine may be called to copy the specified user data to the
    cache via a special Mm routine which copies the data to uninitialized
    pages and returns.

Arguments:

    SharedCacheMap - Supplies the address of the SharedCacheMap for the
                     data.

    UserBuffer - unsafe buffer supplying the user's data to be written

    FileOffset - Supplies the file offset to be modified

    Length - Supplies the total amount of data

    ZeroFlags - Defines which pages may be zeroed if not resident.

    WriteThrough - Supplies the file object being written to

Return Value:

    None

--*/

{
    ULONG ReceivedLength;
    ULONG ZeroCase;
    PVOID CacheBuffer;
    PVOID SavedMappedBuffer;
    ULONG SavedMappedLength;
    ULONG ActivePage;
    KIRQL OldIrql;
    LARGE_INTEGER PFileOffset;
    IO_STATUS_BLOCK IoStatus;
    NTSTATUS Status;
    ULONG SavedState;
    LOGICAL MorePages;
    BOOLEAN WriteThrough = BooleanFlagOn( FileObject->Flags, FO_WRITE_THROUGH );
    ULONG SavedTotalLength = Length;
    LARGE_INTEGER LocalOffset;
    ULONG PageOffset = FileOffset->LowPart & (PAGE_SIZE - 1);
    PVACB Vacb = NULL;
    PETHREAD Thread = PsGetCurrentThread();
    BOOLEAN CopySuccessful;

    //
    //  Initialize SavePage to TRUE to skip the finally clause on zero-length
    //  writes.
    //

    BOOLEAN SavePage = TRUE;

    //
    //  PREfix needs to see this explicitly, as opposed to a structure copy.
    //

    LocalOffset.QuadPart = FileOffset->QuadPart;

    DebugTrace(+1, me, "CcMapAndCopy:\n", 0 );
    DebugTrace( 0, me, "    SharedCacheMap = %08lx\n", SharedCacheMap );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  See if we need to force write through.  If the file object is of remote origin,
    //  it has been exempted from throttling.  As a result, it is possible that too
    //  many pages will get dirty.  In order to prevent this, we force write through
    //  on these file objects if we would have throttled them in the first place.
    //

    if (!WriteThrough && IoIsFileOriginRemote(FileObject)

                &&

        !CcCanIWrite( FileObject,
                      Length,
                      FALSE,
                      MAXUCHAR - 2 )) {

        WriteThrough = TRUE;

        if (!FlagOn(SharedCacheMap->Flags, FORCED_WRITE_THROUGH)) {

            CcAcquireMasterLock( &OldIrql );
            SetFlag(SharedCacheMap->Flags, FORCED_WRITE_THROUGH);
            CcReleaseMasterLock( OldIrql );
        }
    }

    //
    //  try around everything for cleanup.
    //

    try {

        while (Length != 0) {

            CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                               LocalOffset,
                                               &Vacb,
                                               &ReceivedLength );

            //
            //  PREfix wants to know this cannot be NULL, otherwise it
            //  will complain.
            //

            ASSERT( CacheBuffer != NULL );

            //
            //  If we got more than we need, make sure to only use
            //  the right amount.
            //

            if (ReceivedLength > Length) {
                ReceivedLength = Length;
            }
            SavedMappedBuffer = CacheBuffer;
            SavedMappedLength = ReceivedLength;
            Length -= ReceivedLength;

            //
            //  Now loop to touch all of the pages, calling MM to insure
            //  that if we fault, we take in exactly the number of pages
            //  we need.
            //

            CacheBuffer = (PVOID)((PCHAR)CacheBuffer - PageOffset);
            ReceivedLength += PageOffset;

            //
            //  Loop to touch or zero the pages.
            //

            ZeroCase = ZERO_FIRST_PAGE;

            //
            //  Set up offset to page for use below.
            //

            PFileOffset = LocalOffset;
            PFileOffset.LowPart -= PageOffset;

            while (TRUE) {

                //
                //  Calculate whether we wish to save an active page
                //  or not.
                //

                SavePage = (BOOLEAN) ((Length == 0) &&
                            (ReceivedLength < PAGE_SIZE) &&
                            (SavedTotalLength <= (PAGE_SIZE / 2)) &&
                            !WriteThrough);

                MorePages = (ReceivedLength > PAGE_SIZE);

                //
                //  Copy the data to the user buffer.
                //

                try {

                    //
                    //  It is possible that there is a locked page
                    //  hanging around, and so we need to nuke it here.
                    //

                    if (SharedCacheMap->NeedToZero != NULL) {
                        CcFreeActiveVacb( SharedCacheMap, NULL, 0, 0 );
                    }

                    Status = STATUS_SUCCESS;
                    if (FlagOn(ZeroFlags, ZeroCase)) {

                        Status = MmCopyToCachedPage( CacheBuffer,
                                                     UserBuffer,
                                                     PageOffset,
                                                     MorePages ?
                                                       (PAGE_SIZE - PageOffset) :
                                                       (ReceivedLength - PageOffset),
                                                     SavePage );

                        if (Status == STATUS_INSUFFICIENT_RESOURCES) {

                            //
                            //  Couldn't take the optimization path, so we
                            //  we set CopySuccessful appropriately so we will
                            //  just do the copy of the data ourselves.
                            //

                            CopySuccessful = FALSE;

                        } else if (NT_SUCCESS(Status)) {

                            //
                            //  Mm successfully copied the data for us
                            //

                            CopySuccessful = TRUE;

                        } else {

                            //
                            //  We got some other error -- this indicates that
                            //  the user buffer was invalid, so we will raise 
                            //  here.
                            //

                            ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                                   STATUS_INVALID_USER_BUFFER ));
                        }
                        
                    } else {

                        CopySuccessful = FALSE;
                    }

                    if (!CopySuccessful) {

                        //
                        //  We have to actually copy the data ourselves because
                        //  either:
                        //  * This isn't a case where we can do the 
                        //    MmCopyToCachedPage optimization  - or -
                        //  * We got INSUFFICIENT_RESOURCES returned from
                        //    MmCopyToCachedPage, so we should just do this copy
                        //    ourselves.
                        //

                        MmSetPageFaultReadAhead( Thread,
                                                 (MorePages && FlagOn(ZeroFlags, ZERO_LAST_PAGE)) ? 1 : 0);

                        RtlCopyBytes( (PVOID)((PCHAR)CacheBuffer + PageOffset),
                                      UserBuffer,
                                      MorePages ?
                                        (PAGE_SIZE - PageOffset) :
                                        (ReceivedLength - PageOffset) );

                        MmResetPageFaultReadAhead( Thread, SavedState );

                    }

                } except( CcCopyReadExceptionFilter( GetExceptionInformation(),
                                                     &Status ) ) {

                    //
                    //  If we got an access violation, then the user buffer went
                    //  away.  Otherwise we must have gotten an I/O error trying
                    //  to bring the data in.
                    //

                    if (Status == STATUS_ACCESS_VIOLATION) {
                        ExRaiseStatus( STATUS_INVALID_USER_BUFFER );
                    }
                    else {
                        ExRaiseStatus( FsRtlNormalizeNtstatus( Status,
                                                               STATUS_UNEXPECTED_IO_ERROR ));
                    }
                }

                //
                //  Now get out quickly if it is a small write and we want
                //  to save the page.
                //

                if (SavePage) {

                    ActivePage = (ULONG)( Vacb->Overlay.FileOffset.QuadPart >> PAGE_SHIFT ) +
                                 (ULONG)(((PCHAR)CacheBuffer - (PCHAR)Vacb->BaseAddress) >>
                                   PAGE_SHIFT);

                    PFileOffset.LowPart += ReceivedLength;

                    //
                    //  If the cache page was not locked, then clear the address
                    //  to zero from.
                    //

                    if (Status == STATUS_CACHE_PAGE_LOCKED) {

                        //
                        //  We need to guarantee this Vacb for zeroing and calling
                        //  MmUnlockCachedPage, so we increment the active count here
                        //  and remember it for CcFreeActiveVacb.
                        //

                        CcAcquireVacbLock( &OldIrql );
                        Vacb->Overlay.ActiveCount += 1;

                        ExAcquireSpinLockAtDpcLevel( &SharedCacheMap->ActiveVacbSpinLock );

                        ASSERT(SharedCacheMap->NeedToZero == NULL);

                        SharedCacheMap->NeedToZero = (PVOID)((PCHAR)CacheBuffer +
                                                             (PFileOffset.LowPart & (PAGE_SIZE - 1)));
                        SharedCacheMap->NeedToZeroPage = ActivePage;
                        SharedCacheMap->NeedToZeroVacb = Vacb;

                        ExReleaseSpinLockFromDpcLevel( &SharedCacheMap->ActiveVacbSpinLock );
                        CcReleaseVacbLock( OldIrql );

                    }

                    SetActiveVacb( SharedCacheMap,
                                   OldIrql,
                                   Vacb,
                                   ActivePage,
                                   ACTIVE_PAGE_IS_DIRTY );

                    try_return( NOTHING );
                }

                //
                //  If it looks like we may save a page and exit on the next loop,
                //  then we must make sure to mark the current page dirty.  Note
                //  that Cc[Fast]CopyWrite will finish the last part of any page
                //  before allowing us to free the Active Vacb above, therefore
                //  this case only occurs for a small random write.
                //

                if ((SavedTotalLength <= (PAGE_SIZE / 2)) && !WriteThrough) {

                    CcSetDirtyInMask( SharedCacheMap, &PFileOffset, ReceivedLength );
                }

                UserBuffer = (PVOID)((PCHAR)UserBuffer + (PAGE_SIZE - PageOffset));
                PageOffset = 0;

                //
                //  If there is more than a page to go (including what we just
                //  copied), then adjust our buffer pointer and counts, and
                //  determine if we are to the last page yet.
                //

                if (MorePages) {

                    CacheBuffer = (PCHAR)CacheBuffer + PAGE_SIZE;
                    ReceivedLength -= PAGE_SIZE;

                    //
                    //  Update our offset to the page.  Note that 32-bit
                    //  add is ok since we cannot cross a Vacb boundary
                    //  and we reinitialize this offset before entering
                    //  this loop again.
                    //

                    PFileOffset.LowPart += PAGE_SIZE;

                    if (ReceivedLength > PAGE_SIZE) {
                        ZeroCase = ZERO_MIDDLE_PAGES;
                    } else {
                        ZeroCase = ZERO_LAST_PAGE;
                    }

                } else {

                    break;
                }
            }

            //
            //  If there is still more to write (ie. we are going to step
            //  onto the next vacb) AND we just dirtied more than 64K, then
            //  do a vicarious MmFlushSection here.  This prevents us from
            //  creating unlimited dirty pages while holding the file
            //  resource exclusive.  We also do not need to set the pages
            //  dirty in the mask in this case.
            //

            if (Length > CcMaxDirtyWrite) {

                MmSetAddressRangeModified( SavedMappedBuffer, SavedMappedLength );
                MmFlushSection( SharedCacheMap->FileObject->SectionObjectPointer,
                                &LocalOffset,
                                SavedMappedLength,
                                &IoStatus,
                                TRUE );

                if (!NT_SUCCESS(IoStatus.Status)) {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( IoStatus.Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }

            //
            //  For write through files, call Mm to propagate the dirty bits
            //  here while we have the view mapped, so we know the flush will
            //  work below.  Again - do not set dirty in the mask.
            //

            } else if (WriteThrough) {

                MmSetAddressRangeModified( SavedMappedBuffer, SavedMappedLength );

            //
            //  For the normal case, just set the pages dirty for the Lazy Writer
            //  now.
            //

            } else {

                CcSetDirtyInMask( SharedCacheMap, &LocalOffset, SavedMappedLength );
            }

            CcFreeVirtualAddress( Vacb );
            Vacb = NULL;

            //
            //  If we have to loop back to get at least a page, it will be ok to
            //  zero the first page.  If we are not getting at least a page, we
            //  must make sure we clear the ZeroFlags if we cannot zero the last
            //  page.
            //

            if (Length >= PAGE_SIZE) {
                ZeroFlags |= ZERO_FIRST_PAGE;
            } else if ((ZeroFlags & ZERO_LAST_PAGE) == 0) {
                ZeroFlags = 0;
            }

            //
            //  Note that if ReceivedLength (and therefore SavedMappedLength)
            //  was truncated to the transfer size then the new LocalOffset
            //  computed below is not correct.  This is not an issue since
            //  in that case (Length == 0) and we would never get here.
            //

            LocalOffset.QuadPart = LocalOffset.QuadPart + (LONGLONG)SavedMappedLength;
        }
    try_exit: NOTHING;
    }

    //
    //  Cleanup on the way out.
    //

    finally {

        MmResetPageFaultReadAhead( Thread, SavedState );

        //
        //  We have no work to do if we have squirreled away the Vacb.
        //

        if (!SavePage || AbnormalTermination()) {

            //
            //  Make sure we do not leave anything mapped or dirty in the PTE
            //  on the way out.
            //

            if (Vacb != NULL) {

                CcFreeVirtualAddress( Vacb );
            }

            //
            //  Either flush the whole range because of write through, or
            //  mark it dirty for the lazy writer.
            //

            if (WriteThrough) {

                MmFlushSection ( SharedCacheMap->FileObject->SectionObjectPointer,
                                 FileOffset,
                                 SavedTotalLength,
                                 &IoStatus,
                                 TRUE );

                if (!NT_SUCCESS(IoStatus.Status)) {
                    ExRaiseStatus( FsRtlNormalizeNtstatus( IoStatus.Status,
                                                           STATUS_UNEXPECTED_IO_ERROR ));
                }

                //
                //  Advance ValidDataGoal
                //

                LocalOffset.QuadPart = FileOffset->QuadPart + (LONGLONG)SavedTotalLength;
                if (LocalOffset.QuadPart > SharedCacheMap->ValidDataGoal.QuadPart) {
                    SharedCacheMap->ValidDataGoal = LocalOffset;
                }
            }
        }
    }

    DebugTrace(-1, me, "CcMapAndCopy -> %02lx\n", Result );

    return;
}


BOOLEAN
CcLogError(
    IN PFILE_OBJECT FileObject,
    IN PUNICODE_STRING FileName,
    IN NTSTATUS Error,
    IN NTSTATUS DeviceError,
    IN UCHAR IrpMajorCode
    )

/*++

Routine Description:

    This routine writes an eventlog entry to the eventlog.

Arguments:

    FileObject - The fileobject in whose context the error occured.

    FileName - The filename to use in logging the error (usually the DOS-side name)

    Error - The error to log in the eventlog record

    DeviceError - The actual error that occured in the device - will be logged
                  as user data

Return Value:

    True if successful, false if internal memory allocation failed

--*/

{
    UCHAR ErrorPacketLength;
    UCHAR BasePacketLength;
    ULONG StringLength;
    PIO_ERROR_LOG_PACKET ErrorLogEntry = NULL;
    BOOLEAN Result = FALSE;
    PWCHAR String;

    PAGED_CODE();

    //
    //  Get our error packet, holding the string and status code.  Note we log against the
    //  true filesystem if this is available.
    //
    //  The sizing of the packet is a bit slimy since the dumpdata is already grown by a
    //  ULONG onto the end of the packet.  Since NTSTATUS is ULONG, well, we just work in
    //  place.
    //

    BasePacketLength = sizeof(IO_ERROR_LOG_PACKET);
    if ((BasePacketLength + FileName->Length + sizeof(WCHAR)) <= ERROR_LOG_MAXIMUM_SIZE) {
        ErrorPacketLength = (UCHAR)(BasePacketLength + FileName->Length + sizeof(WCHAR));
    } else {
        ErrorPacketLength = ERROR_LOG_MAXIMUM_SIZE;
    }

    ErrorLogEntry = (PIO_ERROR_LOG_PACKET) IoAllocateErrorLogEntry( (FileObject->Vpb ?
                                                                     FileObject->Vpb->DeviceObject :
                                                                     FileObject->DeviceObject),
                                                                    ErrorPacketLength );
    if (ErrorLogEntry) {

        //
        //  Fill in the nonzero members of the packet.
        //

        ErrorLogEntry->MajorFunctionCode = IrpMajorCode;
        ErrorLogEntry->ErrorCode = Error;
        ErrorLogEntry->FinalStatus = DeviceError;

        ErrorLogEntry->DumpDataSize = sizeof(NTSTATUS);
        RtlCopyMemory( &ErrorLogEntry->DumpData, &DeviceError, sizeof(NTSTATUS) );

        //
        //  The filename string is appended to the end of the error log entry. We may
        //  have to smash the middle to fit it in the limited space.
        //

        StringLength = ErrorPacketLength - BasePacketLength - sizeof(WCHAR);

        ASSERT(!(StringLength % sizeof(WCHAR)));

        String = (PWCHAR) ((PUCHAR)ErrorLogEntry + BasePacketLength);
        ErrorLogEntry->NumberOfStrings = 1;
        ErrorLogEntry->StringOffset = BasePacketLength;

        //
        //  If the name does not fit in the packet, divide the name equally to the
        //  prefix and suffix, with an ellipsis " .. " (4 wide characters) to indicate
        //  the loss.
        //

        if (StringLength < FileName->Length) {

            //
            //  Remember, prefix + " .. " + suffix is the length.  Calculate by figuring
            //  the prefix and then get the suffix by whacking the ellipsis and prefix off
            //  the total.
            //
            
            ULONG NamePrefixSegmentLength = ((StringLength/sizeof(WCHAR))/2 - 2)*sizeof(WCHAR);
            ULONG NameSuffixSegmentLength = StringLength - 4*sizeof(WCHAR) - NamePrefixSegmentLength;

            ASSERT(!(NamePrefixSegmentLength % sizeof(WCHAR)));
            ASSERT(!(NameSuffixSegmentLength % sizeof(WCHAR)));

            RtlCopyMemory( String,
                           FileName->Buffer,
                           NamePrefixSegmentLength );
            String = (PWCHAR)((PCHAR)String + NamePrefixSegmentLength);

            RtlCopyMemory( String,
                           L" .. ",
                           4*sizeof(WCHAR) );
            String += 4;

            RtlCopyMemory( String,
                           (PUCHAR)FileName->Buffer +
                           FileName->Length - NameSuffixSegmentLength,
                           NameSuffixSegmentLength );
            String = (PWCHAR)((PCHAR)String + NameSuffixSegmentLength);

        } else {
            
            RtlCopyMemory( String,
                           FileName->Buffer,
                           FileName->Length );
            String += FileName->Length/sizeof(WCHAR);
        }

        //
        //  Null terminate the string and send the packet.
        //

        *String = L'\0';

        IoWriteErrorLogEntry( ErrorLogEntry );
        Result = TRUE;
    }

    return Result;
}


LOGICAL
CcHasInactiveViews (
    VOID
    )

/*++

Routine Description:

    This routine is called by Memory Management only to query if the system
    cache has any inactive views.  If so, Memory Management may issue a
    subsequent call to CcUnmapInactiveViews to discard these views in an
    attempt to reclaim the prototype PTE pool (and other resources tied to
    the section).

Arguments:

    None.

Return Value:

    TRUE if Cc has any views it can discard, FALSE if not.

Environment:

    Arbitrary thread context, generally APC_LEVEL or DISPATCH_LEVEL.  Various
    mutexes and/or spinlocks may be held by the caller.

--*/

{
    return FALSE;       // BUGBUG - add code to flesh out.
}


LOGICAL
CcUnmapInactiveViews (
    IN ULONG NumberOfViewsToUnmap
    )

/*++

Routine Description:

    This routine is called by Memory Management to request that the cache
    manager unmap a number of inactive views.  This call is generally made
    because the system is low on pool (paged or nonpaged).

    Discarding these views is done in an attempt to reclaim the prototype
    PTE pool (and other resources tied to the section).

Arguments:

    NumberOfViewsToUnmap - Supplies the desired number of views to unmap.

Return Value:

    TRUE if Cc discarded *ANY* views, FALSE if not.

Environment:

    Dereference segment thread context at PASSIVE_LEVEL.

--*/

{
    UNREFERENCED_PARAMETER (NumberOfViewsToUnmap);

    return FALSE;       // BUGBUG - add code to flesh out.
}

#ifdef CCDBG
VOID
CcDump (
    IN PVOID Ptr
    )

{
    PVOID Junk = Ptr;
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\lazyrite.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    lazyrite.c

Abstract:

    This module implements the lazy writer for the Cache subsystem.

Author:

    Tom Miller      [TomM]      22-July-1990

Revision History:

--*/

#include "cc.h"

//
//  The Bug check file id for this module
//

#define BugCheckFileId                   (CACHE_BUG_CHECK_LAZYRITE)

//
//  Define our debug constant
//

#define me 0x00000020

//
//  Local support routines
//

PWORK_QUEUE_ENTRY
CcReadWorkQueue (
    );

VOID
CcLazyWriteScan (
    );


VOID
CcScheduleLazyWriteScan (
    IN BOOLEAN FastScan
    )

/*++

Routine Description:

    This routine may be called to schedule the next lazy writer scan,
    during which lazy write and lazy close activity is posted to other
    worker threads.  Callers should acquire the lazy writer spin lock
    to see if the scan is currently active, and then call this routine
    still holding the spin lock if not.  One special call is used at
    the end of the lazy write scan to propagate lazy write active once
    we go active.  This call is "the" scan thread, and it can therefore
    safely schedule the next scan without taking out the spin lock.

Arguments:

    FastScan - if set, make the scan happen immediately

Return Value:

    None.

--*/

{
    //
    //  It is important to set the active flag TRUE first for the propagate
    //  case, because it is conceivable that once the timer is set, another
    //  thread could actually run and make the scan go idle before we then
    //  jam the flag TRUE.
    //
    //  When going from idle to active, we delay a little longer to let the
    //  app finish saving its file.
    //

    if (FastScan) {
        
        LazyWriter.ScanActive = TRUE;
        KeSetTimer( &LazyWriter.ScanTimer, CcNoDelay, &LazyWriter.ScanDpc );

    } else if (LazyWriter.ScanActive) {

        KeSetTimer( &LazyWriter.ScanTimer, CcIdleDelay, &LazyWriter.ScanDpc );
    
    } else {

        LazyWriter.ScanActive = TRUE;
        KeSetTimer( &LazyWriter.ScanTimer, CcFirstDelay, &LazyWriter.ScanDpc );
    }
}


VOID
CcScanDpc (
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    )

/*++

Routine Description:

    This is the Dpc routine which runs when the scan timer goes off.  It
    simply posts an element for an Ex Worker thread to do the scan.

Arguments:

    (All are ignored)

Return Value:

    None.

--*/

{
    PWORK_QUEUE_ENTRY WorkQueueEntry;

    UNREFERENCED_PARAMETER(Dpc);
    UNREFERENCED_PARAMETER(DeferredContext);
    UNREFERENCED_PARAMETER(SystemArgument1);
    UNREFERENCED_PARAMETER(SystemArgument2);

    WorkQueueEntry = CcAllocateWorkQueueEntry();

    //
    //  If we failed to allocate a WorkQueueEntry, things must
    //  be in pretty bad shape.  However, all we have to do is
    //  say we are not active, and wait for another event to
    //  wake things up again.
    //

    if (WorkQueueEntry == NULL) {

        LazyWriter.ScanActive = FALSE;

    } else {

        //
        //  Otherwise post a work queue entry to do the scan.
        //

        WorkQueueEntry->Function = (UCHAR)LazyWriteScan;

        CcPostWorkQueue( WorkQueueEntry, &CcRegularWorkQueue );
    }
}


NTSTATUS
CcWaitForCurrentLazyWriterActivity (
    )

/*++

Routine Description:

    This routine allows a thread to receive notification when the current tick
    of lazy writer work has completed.  It must not be called within a lazy
    writer workitem!  The caller must not be holding synchronization that could
    block a Cc workitem!

    In particular, this lets a caller insure that all available lazy closes at
    the time of the call have completed.

Arguments:

    None.

Return Value:

    Final result of the wait.

--*/

{
    KIRQL OldIrql;
    KEVENT Event;
    PWORK_QUEUE_ENTRY WorkQueueEntry;

    WorkQueueEntry = CcAllocateWorkQueueEntry();

    if (WorkQueueEntry == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    WorkQueueEntry->Function = (UCHAR)EventSet;
    KeInitializeEvent( &Event, NotificationEvent, FALSE );
    WorkQueueEntry->Parameters.Event.Event = &Event;

    //
    //  Add this to the post-tick work queue and wake the lazy writer for it.
    //  The lazy writer will add this to the end of the next batch of work
    //  he issues.
    //

    CcAcquireMasterLock( &OldIrql );

    InsertTailList( &CcPostTickWorkQueue, &WorkQueueEntry->WorkQueueLinks );

    LazyWriter.OtherWork = TRUE;
    if (!LazyWriter.ScanActive) {
        CcScheduleLazyWriteScan( TRUE );
    }

    CcReleaseMasterLock( OldIrql );

    return KeWaitForSingleObject( &Event, Executive, KernelMode, FALSE, NULL );
}



VOID
CcLazyWriteScan (
    )

/*++

Routine Description:

    This routine implements the Lazy Writer scan for dirty data to flush
    or any other work to do (lazy close).  This routine is scheduled by
    calling CcScheduleLazyWriteScan.

Arguments:

    None.

Return Value:

    None.

--*/

{
    ULONG PagesToWrite, ForegroundRate, EstimatedDirtyNextInterval;
    PSHARED_CACHE_MAP SharedCacheMap, FirstVisited, NextSharedCacheMap;
    KIRQL OldIrql;
    ULONG LoopsWithLockHeld = 0;
    BOOLEAN AlreadyMoved = FALSE;
    BOOLEAN MoveBehindCursor = FALSE;

    LIST_ENTRY PostTickWorkQueue;

    //
    //  Top of Lazy Writer scan.
    //

    try {

        //
        //  If there is no work to do, then we will go inactive, and return.
        //

        CcAcquireMasterLock( &OldIrql );

        if ((CcTotalDirtyPages == 0) && !LazyWriter.OtherWork) {

            //
            //  Sleep if there are no deferred writes.  It is important to check
            //  proactively because writes may be blocked for reasons external
            //  to the cache manager.  The lazy writer must keep poking since it
            //  may have no bytes to write itself.
            //

#if DBG
            //
            //  In DBG builds, make sure that the CcDirtySharedCacheMapList
            //  is really empty (except for the cursor) if we are going to sleep
            //  because we think there is no more work to do.
            //
            
            {
                PLIST_ENTRY CurrentEntry = CcDirtySharedCacheMapList.SharedCacheMapLinks.Flink;
                PSHARED_CACHE_MAP CurrentScm;
                ULONG Count = 0;
                
                while( CurrentEntry != &CcDirtySharedCacheMapList.SharedCacheMapLinks ) {

                    CurrentScm = CONTAINING_RECORD( CurrentEntry,
                                                    SHARED_CACHE_MAP,
                                                    SharedCacheMapLinks );

                    if (FlagOn(CurrentScm->Flags, WAITING_FOR_TEARDOWN)) {
                        Count++;
                    }
                    CurrentEntry = CurrentEntry->Flink;
                }

                ASSERTMSG( "CcLazyWriteScan stopped scan while SCM with the flag WAITING_FOR_TEARDOWN are still in the dirty list!\n",
                           Count == 0 );
            }
#endif

            if (IsListEmpty(&CcDeferredWrites)) {

                LazyWriter.ScanActive = FALSE;
                CcReleaseMasterLock( OldIrql );

            } else {

                CcReleaseMasterLock( OldIrql );

                //
                //  Check for writes and schedule the next scan.
                //

                CcPostDeferredWrites();
                CcScheduleLazyWriteScan( FALSE );
            }

            return;
        }

        //
        //  Pull out the post tick workitems for this pass.  It is important that
        //  we are doing this at the top since more could be queued as we rummage
        //  for work to do.  Post tick workitems are guaranteed to occur after all
        //  work generated in a complete scan.
        //

        InitializeListHead( &PostTickWorkQueue );
        while (!IsListEmpty( &CcPostTickWorkQueue )) {

            PLIST_ENTRY Entry = RemoveHeadList( &CcPostTickWorkQueue );
            InsertTailList( &PostTickWorkQueue, Entry );
        }

        //
        //  Calculate the next sweep time stamp, then update all relevant fields for
        //  the next time around.  Also we can clear the OtherWork flag.
        //

        LazyWriter.OtherWork = FALSE;

        //
        //  Assume we will write our usual fraction of dirty pages.  Do not do the
        //  divide if there is not enough dirty pages, or else we will never write
        //  the last few pages.
        //

        PagesToWrite = CcTotalDirtyPages;
        if (PagesToWrite > LAZY_WRITER_MAX_AGE_TARGET) {
            PagesToWrite /= LAZY_WRITER_MAX_AGE_TARGET;
        }

        //
        //  Estimate the rate of dirty pages being produced in the foreground.
        //  This is the total number of dirty pages now plus the number of dirty
        //  pages we scheduled to write last time, minus the number of dirty
        //  pages we have now.  Throw out any cases which would not produce a
        //  positive rate.
        //

        ForegroundRate = 0;

        if ((CcTotalDirtyPages + CcPagesWrittenLastTime) > CcDirtyPagesLastScan) {
            ForegroundRate = (CcTotalDirtyPages + CcPagesWrittenLastTime) -
                             CcDirtyPagesLastScan;
        }

        //
        //  If we estimate that we will exceed our dirty page target by the end
        //  of this interval, then we must write more.  Try to arrive on target.
        //

        EstimatedDirtyNextInterval = CcTotalDirtyPages - PagesToWrite + ForegroundRate;

        if (EstimatedDirtyNextInterval > CcDirtyPageTarget) {

            PagesToWrite += EstimatedDirtyNextInterval - CcDirtyPageTarget;
        }

        //
        //  Now save away the number of dirty pages and the number of pages we
        //  just calculated to write.
        //

        CcDirtyPagesLastScan = CcTotalDirtyPages;
        CcPagesYetToWrite = CcPagesWrittenLastTime = PagesToWrite;

        //
        //  Loop to flush enough Shared Cache Maps to write the number of pages
        //  we just calculated.
        //

        SharedCacheMap = CONTAINING_RECORD( CcLazyWriterCursor.SharedCacheMapLinks.Flink,
                                            SHARED_CACHE_MAP,
                                            SharedCacheMapLinks );

        DebugTrace( 0, me, "Start of Lazy Writer Scan\n", 0 );

        //
        //  Normally we would just like to visit every Cache Map once on each scan,
        //  so the scan will terminate normally when we return to FirstVisited.  But
        //  in the off chance that FirstVisited gets deleted, we are guaranteed to stop
        //  when we get back to our own listhead.
        //

        FirstVisited = NULL;
        while ((SharedCacheMap != FirstVisited) &&
               (&SharedCacheMap->SharedCacheMapLinks != &CcLazyWriterCursor.SharedCacheMapLinks)) {

            if (FirstVisited == NULL) {
                FirstVisited = SharedCacheMap;
            }

            //
            //  Skip the SharedCacheMap if a write behind request is
            //  already queued, write behind has been disabled, or
            //  if there is no work to do (either dirty data to be written
            //  or a delete is required).
            //
            //  Note that for streams where modified writing is disabled, we
            //  need to take out Bcbs exclusive, which serializes with foreground
            //  activity.  Therefore we use a special counter in the SharedCacheMap
            //  to only service these once every n intervals.
            //
            //  Skip temporary files unless we currently could not write as many
            //  bytes as we might charge some hapless thread for throttling, unless
            //  it has been closed.  We assume that the "tick" of the lazy writer,
            //  delayed temporarily by the passcount check, will permit the common
            //  open/write/close/delete action on temporary files to sneak in and
            //  truncate the file before we really write the data, if the file was
            //  not opened delete-on-close to begin with.
            //
            //  Since we will write closed files with dirty pages as part of the
            //  regular pass (even temporary ones), only do lazy close on files
            //  with no dirty pages.
            //

            if (!FlagOn(SharedCacheMap->Flags, WRITE_QUEUED | IS_CURSOR)

                    &&

                (((SharedCacheMap->DirtyPages != 0) 
                           &&
                   (FlagOn(SharedCacheMap->Flags, WAITING_FOR_TEARDOWN)
                                ||
                    ((PagesToWrite != 0)
                                        && 
                     (((++SharedCacheMap->LazyWritePassCount & 0xF) == 0) ||
                      !FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) ||
                      (CcCapturedSystemSize == MmSmallSystem) ||
                      (SharedCacheMap->DirtyPages >= (4 * (MAX_WRITE_BEHIND / PAGE_SIZE))))
                                        &&
                     (!FlagOn(SharedCacheMap->FileObject->Flags, FO_TEMPORARY_FILE) ||
                      (SharedCacheMap->OpenCount == 0) ||
                      !CcCanIWrite(SharedCacheMap->FileObject, WRITE_CHARGE_THRESHOLD, FALSE, MAXUCHAR)))))

                    ||

                 ((SharedCacheMap->OpenCount == 0) &&
                  (SharedCacheMap->DirtyPages == 0) ||
                  (SharedCacheMap->FileSize.QuadPart == 0)))) {

                PWORK_QUEUE_ENTRY WorkQueueEntry;

                //
                //  If this is a metadata stream with at least 4 times
                //  the maximum write behind I/O size, then let's tell
                //  this guy to write 1/8 of his dirty data on this pass
                //  so it doesn't build up.
                //
                //  Else assume we can write everything (PagesToWrite only affects
                //  metadata streams - otherwise writing is controlled by the Mbcb -
                //  this throttle is engaged in CcWriteBehind).
                //

                SharedCacheMap->PagesToWrite = SharedCacheMap->DirtyPages;

                if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) &&
                    (SharedCacheMap->PagesToWrite >= (4 * (MAX_WRITE_BEHIND / PAGE_SIZE))) &&
                    (CcCapturedSystemSize != MmSmallSystem)) {

                    SharedCacheMap->PagesToWrite /= 8;
                }

                //
                //  If still searching for pages to write, adjust our targets.
                //

                if (!AlreadyMoved) {

                    //
                    //  See if he exhausts the number of pages to write.  (We
                    //  keep going in case there are any closes to do.)
                    //

                    if (SharedCacheMap->PagesToWrite >= PagesToWrite) {

                        //
                        //  Here is where we should move the cursor to.  Figure
                        //  out if we should resume on this stream or the next one.
                        //

                        //
                        //  For Metadata streams, set up to resume on the next stream on the
                        //  next scan.  Also force a push forward every n intervals if all of
                        //  the pages came from this stream, so we don't get preoccupied with
                        //  one stream at the expense of others (which may be waiting for a
                        //  lazy close).  Normally we would like to avoid seek overhead and
                        //  take the common case of a large sequential series of writes.
                        //
                        //  This is similar to hotspot detection.
                        //
                        //  Note, to ensure that we iterate through the entire
                        //  CcDirtySharedCacheMap list, we cannot move this shared
                        //  cache map behind the cursor now.  We will just 
                        //  remember that we want to move this to the end of the 
                        //  list and do the actual move when we are ready to read
                        //  the next entry.
                        //

                        if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) ||
                            ((FirstVisited == SharedCacheMap) &&
                             ((SharedCacheMap->LazyWritePassCount & 0xF) == 0))) {

                            MoveBehindCursor = TRUE;

                        //
                        //  For other streams, set up to resume on the same stream on the
                        //  next scan.
                        //

                        } else {

                            RemoveEntryList( &CcLazyWriterCursor.SharedCacheMapLinks );
                            InsertTailList( &SharedCacheMap->SharedCacheMapLinks, &CcLazyWriterCursor.SharedCacheMapLinks );
                        }

                        PagesToWrite = 0;
                        AlreadyMoved = TRUE;

                    } else {

                        PagesToWrite -= SharedCacheMap->PagesToWrite;
                    }
                }

                //
                //  Otherwise show we are actively writing, and keep it in the dirty
                //  list.
                //

                SetFlag(SharedCacheMap->Flags, WRITE_QUEUED);
                SharedCacheMap->DirtyPages += 1;

                CcReleaseMasterLock( OldIrql );

                //
                //  Queue the request to do the work to a worker thread.
                //

                WorkQueueEntry = CcAllocateWorkQueueEntry();

                //
                //  If we failed to allocate a WorkQueueEntry, things must
                //  be in pretty bad shape.  However, all we have to do is
                //  break out of our current loop, and try to go back and
                //  delay a while.  Even if the current guy should have gone
                //  away when we clear WRITE_QUEUED, we will find him again
                //  in the LW scan.
                //

                if (WorkQueueEntry == NULL) {

                    CcAcquireMasterLock( &OldIrql );
                    ClearFlag(SharedCacheMap->Flags, WRITE_QUEUED);
                    SharedCacheMap->DirtyPages -= 1;
                    break;
                }

                WorkQueueEntry->Function = (UCHAR)WriteBehind;
                WorkQueueEntry->Parameters.Write.SharedCacheMap = SharedCacheMap;

                //
                //  Post it to the regular work queue.
                //

                CcAcquireMasterLock( &OldIrql );
                SharedCacheMap->DirtyPages -= 1;

                if (FlagOn( SharedCacheMap->Flags, WAITING_FOR_TEARDOWN )) {

                    //
                    //  If we are waiting for this shared cache map to be torn
                    //  down, put it at the head of the express work queue so
                    //  that it gets processed right away.
                    //
                    
                    CcPostWorkQueue( WorkQueueEntry, &CcExpressWorkQueue );

                } else {

                    //
                    //  We aren't anxiously awaiting for this shared cached map
                    //  to go away, so just process this work item via the 
                    //  regular work queue.
                    //

                    CcPostWorkQueue( WorkQueueEntry, &CcRegularWorkQueue );
                }

                LoopsWithLockHeld = 0;

            //
            //  Make sure we occasionally drop the lock.  Set WRITE_QUEUED
            //  to keep the guy from going away.
            //

            } else if ((++LoopsWithLockHeld >= 20) &&
                       !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED | IS_CURSOR)) {

                SetFlag(SharedCacheMap->Flags, WRITE_QUEUED);
                SharedCacheMap->DirtyPages += 1;
                CcReleaseMasterLock( OldIrql );
                LoopsWithLockHeld = 0;
                CcAcquireMasterLock( &OldIrql );
                ClearFlag(SharedCacheMap->Flags, WRITE_QUEUED);
                SharedCacheMap->DirtyPages -= 1;
            }

            //
            //  Now loop back.
            //
            //  If we want to put this shared cache map at the end of the 
            //  dirty list, we will do it AFTER we determine the next shared
            //  cache map to go to.  This ensures that we loop through the entire
            //  list during this scan tick.
            //

            NextSharedCacheMap =
                CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                                   SHARED_CACHE_MAP,
                                   SharedCacheMapLinks );

            if (MoveBehindCursor) {

                RemoveEntryList( &CcLazyWriterCursor.SharedCacheMapLinks );
                InsertHeadList( &SharedCacheMap->SharedCacheMapLinks, &CcLazyWriterCursor.SharedCacheMapLinks );
                MoveBehindCursor = FALSE;
            }

            SharedCacheMap = NextSharedCacheMap;
        }

        DebugTrace( 0, me, "End of Lazy Writer Scan\n", 0 );

        //
        //  Queue up our  post tick workitems for this pass.
        //

        while (!IsListEmpty( &PostTickWorkQueue )) {

            PLIST_ENTRY Entry = RemoveHeadList( &PostTickWorkQueue );
            CcPostWorkQueue( CONTAINING_RECORD( Entry, WORK_QUEUE_ENTRY, WorkQueueLinks ),
                             &CcRegularWorkQueue );
        }

        //
        //  Now we can release the global list and loop back, per chance to sleep.
        //

        CcReleaseMasterLock( OldIrql );

        //
        //  Once again we need to give the deferred writes a poke.  We can have all dirty
        //  pages on disable_write_behind files but also have an external condition that
        //  caused the cached IO to be deferred. If so, this serves as our only chance to
        //  issue it when the condition clears.
        //
        //  Case hit on ForrestF's 5gb Alpha, 1/12/99.
        //

        if (!IsListEmpty(&CcDeferredWrites)) {

            CcPostDeferredWrites();
        }

        //
        //  Now go ahead and schedule the next scan.
        //

        CcScheduleLazyWriteScan( FALSE );

    //
    //  Basically, the Lazy Writer thread should never get an exception,
    //  so we put a try-except around it that bug checks one way or the other.
    //  Better we bug check here than worry about what happens if we let one
    //  get by.
    //

    } except( CcExceptionFilter( GetExceptionCode() )) {

        CcBugCheck( GetExceptionCode(), 0, 0 );
    }
}


//
//  Internal support routine
//

LONG
CcExceptionFilter (
    IN NTSTATUS ExceptionCode
    )

/*++

Routine Description:

    This is the standard exception filter for worker threads which simply
    calls an FsRtl routine to see if an expected status is being raised.
    If so, the exception is handled, else we bug check.

Arguments:

    ExceptionCode - the exception code which was raised.

Return Value:

    EXCEPTION_EXECUTE_HANDLER if expected, else a Bug Check occurs.

--*/

{
    DebugTrace(0, 0, "CcExceptionFilter %08lx\n", ExceptionCode);

    if (FsRtlIsNtstatusExpected( ExceptionCode )) {

        return EXCEPTION_EXECUTE_HANDLER;

    } else {

        return EXCEPTION_CONTINUE_SEARCH;
    }
}



//
//  Internal support routine
//

VOID
FASTCALL
CcPostWorkQueue (
    IN PWORK_QUEUE_ENTRY WorkQueueEntry,
    IN PLIST_ENTRY WorkQueue
    )

/*++

Routine Description:

    This routine queues a WorkQueueEntry, which has been allocated and
    initialized by the caller, to the WorkQueue for FIFO processing by
    the work threads.

Arguments:

    WorkQueueEntry - supplies a pointer to the entry to queue

Return Value:

    None

--*/

{
    KIRQL OldIrql;
    PLIST_ENTRY WorkerThreadEntry = NULL;

    ASSERT(FIELD_OFFSET(WORK_QUEUE_ITEM, List) == 0);

    DebugTrace(+1, me, "CcPostWorkQueue:\n", 0 );
    DebugTrace( 0, me, "    WorkQueueEntry = %08lx\n", WorkQueueEntry );

    //
    //  Queue the entry to the respective work queue.
    //

    CcAcquireWorkQueueLock( &OldIrql );
    InsertTailList( WorkQueue, &WorkQueueEntry->WorkQueueLinks );

    //
    //  Now, if we aren't throttled and have any more idle threads we can
    //  use, activate one.
    //

    if (!CcQueueThrottle && !IsListEmpty(&CcIdleWorkerThreadList)) {
        WorkerThreadEntry = RemoveHeadList( &CcIdleWorkerThreadList );
        CcNumberActiveWorkerThreads += 1;
    }
    CcReleaseWorkQueueLock( OldIrql );

    if (WorkerThreadEntry != NULL) {

        //
        //  I had to peak in the sources to verify that this routine
        //  is a noop if the Flink is not NULL.  Sheeeeit!
        //

        ((PWORK_QUEUE_ITEM)WorkerThreadEntry)->List.Flink = NULL;
        ExQueueWorkItem( (PWORK_QUEUE_ITEM)WorkerThreadEntry, CriticalWorkQueue );
    }

    //
    //  And return to our caller
    //

    DebugTrace(-1, me, "CcPostWorkQueue -> VOID\n", 0 );

    return;
}


//
//  Internal support routine
//

VOID
CcWorkerThread (
    PVOID ExWorkQueueItem
    )

/*++

Routine Description:

    This is worker thread routine for processing cache manager work queue
    entries.

Arguments:

    ExWorkQueueItem - The work item used for this thread

Return Value:

    None

--*/

{
    KIRQL OldIrql;
    PLIST_ENTRY WorkQueue;
    PWORK_QUEUE_ENTRY WorkQueueEntry;
    BOOLEAN RescanOk = FALSE;
    BOOLEAN DropThrottle = FALSE;
    IO_STATUS_BLOCK IoStatus;

    IoStatus.Status = STATUS_SUCCESS;
    IoStatus.Information = 0;

    ASSERT(FIELD_OFFSET(WORK_QUEUE_ENTRY, WorkQueueLinks) == 0);

    while (TRUE) {

        CcAcquireWorkQueueLock( &OldIrql );

        //
        //  If we just processed a throttled operation, drop the flag.
        //

        if (DropThrottle) {

            DropThrottle = CcQueueThrottle = FALSE;
        }

        //
        //  On requeue, push at end of the source queue and clear hint.
        //

        if (IoStatus.Information == CC_REQUEUE) {

            InsertTailList( WorkQueue, &WorkQueueEntry->WorkQueueLinks );
            IoStatus.Information = 0;
        }

        //
        //  First see if there is something in the express queue.
        //

        if (!IsListEmpty(&CcExpressWorkQueue)) {
            WorkQueue = &CcExpressWorkQueue;

        //
        //  If there was nothing there, then try the regular queue.
        //

        } else if (!IsListEmpty(&CcRegularWorkQueue)) {
            WorkQueue = &CcRegularWorkQueue;

        //
        //  Else we can break and go idle.
        //

        } else {

            break;
        }

        WorkQueueEntry = CONTAINING_RECORD( WorkQueue->Flink, WORK_QUEUE_ENTRY, WorkQueueLinks );

        //
        //  If this is an EventSet, throttle down to a single thread to be sure
        //  that this event fires after all preceeding workitems have completed.
        //

        if (WorkQueueEntry->Function == EventSet && CcNumberActiveWorkerThreads > 1) {

            CcQueueThrottle = TRUE;
            break;
        }

        //
        //  Pop the workitem off: we will execute it now.
        //

        RemoveHeadList( WorkQueue );

        CcReleaseWorkQueueLock( OldIrql );

        //
        //  Process the entry within a try-except clause, so that any errors
        //  will cause us to continue after the called routine has unwound.
        //

        try {

            switch (WorkQueueEntry->Function) {

            //
            //  Perform read ahead
            //

            case ReadAhead:

                DebugTrace( 0, me, "CcWorkerThread Read Ahead FileObject = %08lx\n",
                            WorkQueueEntry->Parameters.Read.FileObject );

                CcPerformReadAhead( WorkQueueEntry->Parameters.Read.FileObject );

                break;

            //
            //  Perform write behind
            //

            case WriteBehind:

                DebugTrace( 0, me, "CcWorkerThread WriteBehind SharedCacheMap = %08lx\n",
                            WorkQueueEntry->Parameters.Write.SharedCacheMap );

                //
                //  While CcWriteBehind is running, we mark this thread as a
                //  MemoryMaker so that Mm will allow pool allocations to 
                //  succeed when we are getting into low-resource situations.
                //  This helps avoid loss delayed write error in low-resource
                //  scenarios.
                //

                PsGetCurrentThread()->MemoryMaker = 1;

                CcWriteBehind( WorkQueueEntry->Parameters.Write.SharedCacheMap, &IoStatus );
                RescanOk = (BOOLEAN)NT_SUCCESS(IoStatus.Status);

                PsGetCurrentThread()->MemoryMaker = 0;
                break;


            //
            //  Perform set event
            //
        
            case EventSet:

                DebugTrace( 0, me, "CcWorkerThread SetEvent Event = %08lx\n",
                            WorkQueueEntry->Parameters.Event.Event );

                KeSetEvent( WorkQueueEntry->Parameters.Event.Event, 0, FALSE );
                DropThrottle = TRUE;
                break;

            //
            //  Perform Lazy Write Scan
            //

            case LazyWriteScan:

                DebugTrace( 0, me, "CcWorkerThread Lazy Write Scan\n", 0 );

                CcLazyWriteScan();
                break;
            }

        }
        except( CcExceptionFilter( GetExceptionCode() )) {

            //
            //  If we hit an exception in this thread, we need to make sure
            //  that if we had made this thread a memory maker that flag is
            //  cleared in the thread structure because this thread will be
            //  reused by arbitrary system worker threads that should not have
            //  this designation.
            //
            
            if (WorkQueueEntry->Function == WriteBehind) {
                
                PsGetCurrentThread()->MemoryMaker = 0;
            }
        }

        //
        //  If not a requeue request, free the workitem.
        //

        if (IoStatus.Information != CC_REQUEUE) {

            CcFreeWorkQueueEntry( WorkQueueEntry );
        }
    }

    //
    //  No more work.  Requeue our worker thread entry and get out.
    //

    InsertTailList( &CcIdleWorkerThreadList,
                    &((PWORK_QUEUE_ITEM)ExWorkQueueItem)->List );
    CcNumberActiveWorkerThreads -= 1;

    CcReleaseWorkQueueLock( OldIrql );

    if (!IsListEmpty(&CcDeferredWrites) && (CcTotalDirtyPages >= 20) && RescanOk) {
        CcLazyWriteScan();
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\pinsup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    pinsup.c

Abstract:

    This module implements the pointer-based Pin support routines for the
    Cache subsystem.

Author:

    Tom Miller      [TomM]      4-June-1990

Revision History:

--*/

#include "cc.h"

//
//  Define our debug constant
//

#define me 0x00000008

#if LIST_DBG

#define SetCallersAddress(BCB) {                            \
    RtlGetCallersAddress( &(BCB)->CallerAddress,            \
                          &(BCB)->CallersCallerAddress );   \
}

#endif

//
//  Internal routines
//

POBCB
CcAllocateObcb (
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN PBCB FirstBcb
    );

#ifdef ALLOC_PRAGMA
#if !LIST_DBG
#pragma alloc_text(PAGE,CcMapData)
#pragma alloc_text(PAGE,CcPinMappedData)
#pragma alloc_text(PAGE,CcPinRead)
#pragma alloc_text(PAGE,CcPreparePinWrite)
#endif
#pragma alloc_text(PAGE,CcUnpinData)
#pragma alloc_text(PAGE,CcSetBcbOwnerPointer)
#pragma alloc_text(PAGE,CcUnpinDataForThread)
#pragma alloc_text(PAGE,CcAllocateObcb)
#endif



BOOLEAN
CcMapData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG Flags,
    OUT PVOID *Bcb,
    OUT PVOID *Buffer
    )

/*++

Routine Description:

    This routine attempts to map the specified file data in the cache.
    A pointer is returned to the desired data in the cache.

    If the caller does not want to block on this call, then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to supply the requested data without
    blocking, then this routine will return FALSE.  However, if the
    data is immediately accessible in the cache and no blocking is
    required, this routine returns TRUE with a pointer to the data.

    Note that a call to this routine with Wait supplied as TRUE is
    considerably faster than a call with Wait supplies as FALSE, because
    in the Wait TRUE case we only have to make sure the data is mapped
    in order to return.

    It is illegal to modify data that is only mapped, and can in fact lead
    to serious problems.  It is impossible to check for this in all cases,
    however CcSetDirtyPinnedData may implement some Assertions to check for
    this.  If the caller wishes to modify data that it has only mapped, then
    it must *first* call CcPinMappedData.

    In any case, the caller MUST subsequently call CcUnpinData.
    Naturally if CcPinRead or CcPreparePinWrite were called multiple
    times for the same data, CcUnpinData must be called the same number
    of times.

    The returned Buffer pointer is valid until the data is unpinned, at
    which point it is invalid to use the pointer further.  This buffer pointer
    will remain valid if CcPinMappedData is called.

    Note that under some circumstances (like Wait supplied as FALSE or more
    than a page is requested), this routine may actually pin the data, however
    it is not necessary, and in fact not correct, for the caller to be concerned
    about this.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Wait - FALSE if caller may not block, TRUE otherwise (see description
           above)

    Bcb - On the first call this returns a pointer to a Bcb
          parameter which must be supplied as input on all subsequent
          calls, for this buffer

    Buffer - Returns pointer to desired data, valid until the buffer is
             unpinned or freed.  This pointer will remain valid if CcPinMappedData
             is called.

Return Value:

    FALSE - if Wait was supplied as FALSE and the data was not delivered

    TRUE - if the data is being delivered

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    LARGE_INTEGER BeyondLastByte;
    ULONG ReceivedLength;
    ULONG SavedState;
    volatile UCHAR ch;
    PVOID TempBcb;
    ULONG PageCount = ADDRESS_AND_SIZE_TO_SPAN_PAGES((ULongToPtr(FileOffset->LowPart)), Length);
    PETHREAD Thread = PsGetCurrentThread();

    DebugTrace(+1, me, "CcMapData\n", 0 );

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  Increment performance counters
    //

    if (FlagOn(Flags, MAP_WAIT)) {

        CcMapDataWait += 1;

        //
        //  Initialize the indirect pointer to our miss counter.
        //

        CcMissCounter = &CcMapDataWaitMiss;

    } else {
        CcMapDataNoWait += 1;
    }

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  Call local routine to Map or Access the file data.  If we cannot map
    //  the data because of a Wait condition, return FALSE.
    //

    if (FlagOn(Flags, MAP_WAIT)) {

        *Buffer = CcGetVirtualAddress( SharedCacheMap,
                                       *FileOffset,
                                       (PVACB *)&TempBcb,
                                       &ReceivedLength );

        ASSERT( ReceivedLength >= Length );

    } else if (!CcPinFileData( FileObject,
                               FileOffset,
                               Length,
                               TRUE,
                               FALSE,
                               Flags,
                               (PBCB *)&TempBcb,
                               Buffer,
                               &BeyondLastByte )) {

        DebugTrace(-1, me, "CcMapData -> FALSE\n", 0 );

        CcMapDataNoWaitMiss += 1;

        return FALSE;

    } else {

        ASSERT( (BeyondLastByte.QuadPart - FileOffset->QuadPart) >= Length );

#if LIST_DBG
        {
            KIRQL OldIrql;
            PBCB BcbTemp = (PBCB)*Bcb;

            OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

            if (BcbTemp->CcBcbLinks.Flink == NULL) {

                InsertTailList( &CcBcbList, &BcbTemp->CcBcbLinks );
                CcBcbCount += 1;
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                SetCallersAddress( BcbTemp );

            } else {
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
            }

        }
#endif

    }

    //
    //  Caller specifically requested he doesn't want data to be faulted in.
    //

    if (!FlagOn( Flags, MAP_NO_READ )) {

        //
        //  Now let's just sit here and take the miss(es) like a man (and count them).
        //

        try {

            //
            //  Loop to touch each page
            //

            BeyondLastByte.LowPart = 0;

            while (PageCount != 0) {

                MmSetPageFaultReadAhead( Thread, PageCount - 1 );

                ch = *((volatile UCHAR *)(*Buffer) + BeyondLastByte.LowPart);

                BeyondLastByte.LowPart += PAGE_SIZE;
                PageCount -= 1;
            }

        } finally {

            MmResetPageFaultReadAhead( Thread, SavedState );

            if (AbnormalTermination() && (TempBcb != NULL)) {
                CcUnpinFileData( (PBCB)TempBcb, TRUE, UNPIN );
            }
        }
    }

    CcMissCounter = &CcThrowAway;

    //
    //  Increment the pointer as a reminder that it is read only, and
    //  return it.  We pend this until now to avoid raising with a valid
    //  Bcb into caller's contexts.
    //

    *(PCHAR *)&TempBcb += 1;
    *Bcb = TempBcb;

    DebugTrace(-1, me, "CcMapData -> TRUE\n", 0 );

    return TRUE;
}


BOOLEAN
CcPinMappedData (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG Flags,
    IN OUT PVOID *Bcb
    )

/*++

Routine Description:

    This routine attempts to pin data that was previously only mapped.
    If the routine determines that in fact it was necessary to actually
    pin the data when CcMapData was called, then this routine does not
    have to do anything.

    If the caller does not want to block on this call, then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to supply the requested data without
    blocking, then this routine will return FALSE.  However, if the
    data is immediately accessible in the cache and no blocking is
    required, this routine returns TRUE with a pointer to the data.

    If the data is not returned in the first call, the caller
    may request the data later with Wait = TRUE.  It is not required
    that the caller request the data later.

    If the caller subsequently modifies the data, it should call
    CcSetDirtyPinnedData.

    In any case, the caller MUST subsequently call CcUnpinData.
    Naturally if CcPinRead or CcPreparePinWrite were called multiple
    times for the same data, CcUnpinData must be called the same number
    of times.

    Note there are no performance counters in this routine, as the misses
    will almost always occur on the map above, and there will seldom be a
    miss on this conversion.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Flags - (PIN_WAIT, PIN_EXCLUSIVE, PIN_NO_READ, etc. as defined in cache.h)
            If the caller specifies PIN_NO_READ and PIN_EXCLUSIVE, then he must
            guarantee that no one else will be attempting to map the view, if he
            wants to guarantee that the Bcb is not mapped (view may be purged).
            If the caller specifies PIN_NO_READ without PIN_EXCLUSIVE, the data
            may or may not be mapped in the return Bcb.

    Bcb - On the first call this returns a pointer to a Bcb
          parameter which must be supplied as input on all subsequent
          calls, for this buffer

Return Value:

    FALSE - if Wait was not set and the data was not delivered

    TRUE - if the data is being delivered

--*/

{
    PVOID Buffer;
    LARGE_INTEGER BeyondLastByte;
    PSHARED_CACHE_MAP SharedCacheMap;
    LARGE_INTEGER LocalFileOffset = *FileOffset;
    POBCB MyBcb = NULL;
    PBCB *CurrentBcbPtr = (PBCB *)&MyBcb;
    BOOLEAN Result = FALSE;

    DebugTrace(+1, me, "CcPinMappedData\n", 0 );

    //
    // If the Bcb is no longer ReadOnly, then just return.
    //

    if ((*(PULONG)Bcb & 1) == 0) {
        return TRUE;
    }

    //
    // Remove the Read Only flag
    //

    *(PCHAR *)Bcb -= 1;

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  We only count the calls to this routine, since they are almost guaranteed
    //  to be hits.
    //

    CcPinMappedDataCount += 1;

    //
    //  Guarantee we will put the flag back if required.
    //

    try {

        if (((PBCB)*Bcb)->NodeTypeCode != CACHE_NTC_BCB) {

            //
            //  Form loop to handle occasional overlapped Bcb case.
            //

            do {

                //
                //  If we have already been through the loop, then adjust
                //  our file offset and length from the last time.
                //

                if (MyBcb != NULL) {

                    //
                    //  If this is the second time through the loop, then it is time
                    //  to handle the overlap case and allocate an OBCB.
                    //

                    if (CurrentBcbPtr == (PBCB *)&MyBcb) {

                        MyBcb = CcAllocateObcb( FileOffset, Length, (PBCB)MyBcb );

                        //
                        //  Set CurrentBcbPtr to point at the first entry in
                        //  the vector (which is already filled in), before
                        //  advancing it below.
                        //

                        CurrentBcbPtr = &MyBcb->Bcbs[0];
                    }

                    Length -= (ULONG)(BeyondLastByte.QuadPart - LocalFileOffset.QuadPart);
                    LocalFileOffset.QuadPart = BeyondLastByte.QuadPart;
                    CurrentBcbPtr += 1;
                }

                //
                //  Call local routine to Map or Access the file data.  If we cannot map
                //  the data because of a Wait condition, return FALSE.
                //

                if (!CcPinFileData( FileObject,
                                    &LocalFileOffset,
                                    Length,
                                    (BOOLEAN)!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED),
                                    FALSE,
                                    Flags,
                                    CurrentBcbPtr,
                                    &Buffer,
                                    &BeyondLastByte )) {

                    try_return( Result = FALSE );
                }

            //
            //  Continue looping if we did not get everything.
            //

            } while((BeyondLastByte.QuadPart - LocalFileOffset.QuadPart) < Length);

            //
            //  Free the Vacb before going on.
            //

            CcFreeVirtualAddress( (PVACB)*Bcb );

            *Bcb = MyBcb;

            //
            //  Debug routines used to insert and remove Bcbs from the global list
            //

#if LIST_DBG
            {
                KIRQL OldIrql;
                PBCB BcbTemp = (PBCB)*Bcb;

                OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

                if (BcbTemp->CcBcbLinks.Flink == NULL) {

                    InsertTailList( &CcBcbList, &BcbTemp->CcBcbLinks );
                    CcBcbCount += 1;
                    KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                    SetCallersAddress( BcbTemp );

                } else {
                    KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                }

            }
#endif
        }

        //
        //  If he really has a Bcb, all we have to do is acquire it shared since he is
        //  no longer ReadOnly.
        //

        else {

            if (!ExAcquireSharedStarveExclusive( &((PBCB)*Bcb)->Resource, BooleanFlagOn(Flags, PIN_WAIT))) {

                try_return( Result = FALSE );
            }
        }

        Result = TRUE;

    try_exit: NOTHING;
    }
    finally {

        if (!Result) {

            //
            //  Put the Read Only flag back
            //

            *(PCHAR *)Bcb += 1;

            //
            //  We may have gotten partway through
            //

            if (MyBcb != NULL) {
                CcUnpinData( MyBcb );
            }
        }

        DebugTrace(-1, me, "CcPinMappedData -> %02lx\n", Result );
    }
    return Result;
}


BOOLEAN
CcPinRead (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN ULONG Flags,
    OUT PVOID *Bcb,
    OUT PVOID *Buffer
    )

/*++

Routine Description:

    This routine attempts to pin the specified file data in the cache.
    A pointer is returned to the desired data in the cache.  This routine
    is intended for File System support and is not intended to be called
    from Dpc level.

    If the caller does not want to block on this call, then
    Wait should be supplied as FALSE.  If Wait was supplied as FALSE and
    it is currently impossible to supply the requested data without
    blocking, then this routine will return FALSE.  However, if the
    data is immediately accessible in the cache and no blocking is
    required, this routine returns TRUE with a pointer to the data.

    If the data is not returned in the first call, the caller
    may request the data later with Wait = TRUE.  It is not required
    that the caller request the data later.

    If the caller subsequently modifies the data, it should call
    CcSetDirtyPinnedData.

    In any case, the caller MUST subsequently call CcUnpinData.
    Naturally if CcPinRead or CcPreparePinWrite were called multiple
    times for the same data, CcUnpinData must be called the same number
    of times.

    The returned Buffer pointer is valid until the data is unpinned, at
    which point it is invalid to use the pointer further.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Flags - (PIN_WAIT, PIN_EXCLUSIVE, PIN_NO_READ, etc. as defined in cache.h)
            If the caller specifies PIN_NO_READ and PIN_EXCLUSIVE, then he must
            guarantee that no one else will be attempting to map the view, if he
            wants to guarantee that the Bcb is not mapped (view may be purged).
            If the caller specifies PIN_NO_READ without PIN_EXCLUSIVE, the data
            may or may not be mapped in the return Bcb.

    Bcb - On the first call this returns a pointer to a Bcb
          parameter which must be supplied as input on all subsequent
          calls, for this buffer

    Buffer - Returns pointer to desired data, valid until the buffer is
             unpinned or freed.

Return Value:

    FALSE - if Wait was not set and the data was not delivered

    TRUE - if the data is being delivered

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID LocalBuffer;
    LARGE_INTEGER BeyondLastByte;
    LARGE_INTEGER LocalFileOffset = *FileOffset;
    POBCB MyBcb = NULL;
    PBCB *CurrentBcbPtr = (PBCB *)&MyBcb;
    BOOLEAN Result = FALSE;

    DebugTrace(+1, me, "CcPinRead\n", 0 );

    //
    //  Increment performance counters
    //

    if (FlagOn(Flags, PIN_WAIT)) {

        CcPinReadWait += 1;

        //
        //  Initialize the indirect pointer to our miss counter.
        //

        CcMissCounter = &CcPinReadWaitMiss;

    } else {
        CcPinReadNoWait += 1;
    }

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    try {

        //
        //  Form loop to handle occasional overlapped Bcb case.
        //

        do {

            //
            //  If we have already been through the loop, then adjust
            //  our file offset and length from the last time.
            //

            if (MyBcb != NULL) {

                //
                //  If this is the second time through the loop, then it is time
                //  to handle the overlap case and allocate an OBCB.
                //

                if (CurrentBcbPtr == (PBCB *)&MyBcb) {

                    MyBcb = CcAllocateObcb( FileOffset, Length, (PBCB)MyBcb );

                    //
                    //  Set CurrentBcbPtr to point at the first entry in
                    //  the vector (which is already filled in), before
                    //  advancing it below.
                    //

                    CurrentBcbPtr = &MyBcb->Bcbs[0];

                    //
                    //  Also on second time through, return starting Buffer
                    //

                    *Buffer = LocalBuffer;
                }

                Length -= (ULONG)(BeyondLastByte.QuadPart - LocalFileOffset.QuadPart);
                LocalFileOffset.QuadPart = BeyondLastByte.QuadPart;
                CurrentBcbPtr += 1;
            }

            //
            //  Call local routine to Map or Access the file data.  If we cannot map
            //  the data because of a Wait condition, return FALSE.
            //

            if (!CcPinFileData( FileObject,
                                &LocalFileOffset,
                                Length,
                                (BOOLEAN)!FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED),
                                FALSE,
                                Flags,
                                CurrentBcbPtr,
                                &LocalBuffer,
                                &BeyondLastByte )) {

                CcPinReadNoWaitMiss += 1;

                try_return( Result = FALSE );
            }

        //
        //  Continue looping if we did not get everything.
        //

        } while((BeyondLastByte.QuadPart - LocalFileOffset.QuadPart) < Length);

        *Bcb = MyBcb;

        //
        //  Debug routines used to insert and remove Bcbs from the global list
        //

#if LIST_DBG

        {
            KIRQL OldIrql;
            PBCB BcbTemp = (PBCB)*Bcb;

            OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

            if (BcbTemp->CcBcbLinks.Flink == NULL) {

                InsertTailList( &CcBcbList, &BcbTemp->CcBcbLinks );
                CcBcbCount += 1;
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                SetCallersAddress( BcbTemp );

            } else {
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
            }

        }

#endif

        //
        //  In the normal (nonoverlapping) case we return the
        //  correct buffer address here.
        //

        if (CurrentBcbPtr == (PBCB *)&MyBcb) {
            *Buffer = LocalBuffer;
        }

        Result = TRUE;

    try_exit: NOTHING;
    }
    finally {

        CcMissCounter = &CcThrowAway;

        if (!Result) {

            //
            //  We may have gotten partway through
            //

            if (MyBcb != NULL) {
                CcUnpinData( MyBcb );
            }
        }

        DebugTrace(-1, me, "CcPinRead -> %02lx\n", Result );
    }

    return Result;
}


BOOLEAN
CcPreparePinWrite (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN BOOLEAN Zero,
    IN ULONG Flags,
    OUT PVOID *Bcb,
    OUT PVOID *Buffer
    )

/*++

Routine Description:

    This routine attempts to lock the specified file data in the cache
    and return a pointer to it along with the correct
    I/O status.  Pages to be completely overwritten may be satisfied
    with emtpy pages.

    If not all of the pages can be prepared, and Wait was supplied as
    FALSE, then this routine will return FALSE, and its outputs will
    be meaningless.  The caller may request the data later with
    Wait = TRUE.  However, it is not required that the caller request
    the data later.

    If Wait is supplied as TRUE, and all of the pages can be prepared
    without blocking, this call will return TRUE immediately.  Otherwise,
    this call will block until all of the pages can be prepared, and
    then return TRUE.

    When this call returns with TRUE, the caller may immediately begin
    to transfer data into the buffers via the Buffer pointer.  The
    buffer will already be marked dirty.

    The caller MUST subsequently call CcUnpinData.
    Naturally if CcPinRead or CcPreparePinWrite were called multiple
    times for the same data, CcUnpinData must be called the same number
    of times.

    The returned Buffer pointer is valid until the data is unpinned, at
    which point it is invalid to use the pointer further.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    Zero - If supplied as TRUE, the buffer will be zeroed on return.

    Flags - (PIN_WAIT, PIN_EXCLUSIVE, PIN_NO_READ, etc. as defined in cache.h)
            If the caller specifies PIN_NO_READ and PIN_EXCLUSIVE, then he must
            guarantee that no one else will be attempting to map the view, if he
            wants to guarantee that the Bcb is not mapped (view may be purged).
            If the caller specifies PIN_NO_READ without PIN_EXCLUSIVE, the data
            may or may not be mapped in the return Bcb.

    Bcb - This returns a pointer to a Bcb parameter which must be
          supplied as input to CcPinWriteComplete.

    Buffer - Returns pointer to desired data, valid until the buffer is
             unpinned or freed.

Return Value:

    FALSE - if Wait was not set and the data was not delivered

    TRUE - if the pages are being delivered

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID LocalBuffer;
    LARGE_INTEGER BeyondLastByte;
    LARGE_INTEGER LocalFileOffset = *FileOffset;
    POBCB MyBcb = NULL;
    PBCB *CurrentBcbPtr = (PBCB *)&MyBcb;
    ULONG OriginalLength = Length;
    BOOLEAN Result = FALSE;

    DebugTrace(+1, me, "CcPreparePinWrite\n", 0 );

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    try {

        //
        //  Form loop to handle occasional overlapped Bcb case.
        //

        do {

            //
            //  If we have already been through the loop, then adjust
            //  our file offset and length from the last time.
            //

            if (MyBcb != NULL) {

                //
                //  If this is the second time through the loop, then it is time
                //  to handle the overlap case and allocate an OBCB.
                //

                if (CurrentBcbPtr == (PBCB *)&MyBcb) {

                    MyBcb = CcAllocateObcb( FileOffset, Length, (PBCB)MyBcb );

                    //
                    //  Set CurrentBcbPtr to point at the first entry in
                    //  the vector (which is already filled in), before
                    //  advancing it below.
                    //

                    CurrentBcbPtr = &MyBcb->Bcbs[0];

                    //
                    //  Also on second time through, return starting Buffer
                    //

                    *Buffer = LocalBuffer;
                }

                Length -= (ULONG)(BeyondLastByte.QuadPart - LocalFileOffset.QuadPart);
                LocalFileOffset.QuadPart = BeyondLastByte.QuadPart;
                CurrentBcbPtr += 1;
            }

            //
            //  Call local routine to Map or Access the file data.  If we cannot map
            //  the data because of a Wait condition, return FALSE.
            //

            if (!CcPinFileData( FileObject,
                                &LocalFileOffset,
                                Length,
                                FALSE,
                                TRUE,
                                Flags,
                                CurrentBcbPtr,
                                &LocalBuffer,
                                &BeyondLastByte )) {

                try_return( Result = FALSE );
            }

        //
        //  Continue looping if we did not get everything.
        //

        } while((BeyondLastByte.QuadPart - LocalFileOffset.QuadPart) < Length);

        //
        //  Debug routines used to insert and remove Bcbs from the global list
        //

#if LIST_DBG

        {
            KIRQL OldIrql;
            PBCB BcbTemp = (PBCB)*Bcb;

            OldIrql = KeAcquireQueuedSpinLock( LockQueueBcbLock );

            if (BcbTemp->CcBcbLinks.Flink == NULL) {

                InsertTailList( &CcBcbList, &BcbTemp->CcBcbLinks );
                CcBcbCount += 1;
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
                SetCallersAddress( BcbTemp );

            } else {
                KeReleaseQueuedSpinLock( LockQueueBcbLock, OldIrql );
            }

        }

#endif

        //
        //  In the normal (nonoverlapping) case we return the
        //  correct buffer address here.
        //

        if (CurrentBcbPtr == (PBCB *)&MyBcb) {
            *Buffer = LocalBuffer;
        }

        if (Zero) {
            RtlZeroMemory( *Buffer, OriginalLength );
        }

        CcSetDirtyPinnedData( MyBcb, NULL );

        //
        //  Fill in the return argument.
        //

        *Bcb = MyBcb;
        
        Result = TRUE;

    try_exit: NOTHING;
    }
    finally {

        CcMissCounter = &CcThrowAway;

        if (!Result) {

            //
            //  We may have gotten partway through
            //

            if (MyBcb != NULL) {
                CcUnpinData( MyBcb );
            }
        }

        DebugTrace(-1, me, "CcPreparePinWrite -> %02lx\n", Result );
    }

    return Result;
}


VOID
CcUnpinData (
    IN PVOID Bcb
    )

/*++

Routine Description:

    This routine must be called at IPL0, some time after calling CcPinRead
    or CcPreparePinWrite.  It performs any cleanup that is necessary.

Arguments:

    Bcb - Bcb parameter returned from the last call to CcPinRead.

Return Value:

    None.

--*/

{
    DebugTrace(+1, me, "CcUnpinData:\n", 0 );
    DebugTrace( 0, me, "    >Bcb = %08lx\n", Bcb );

    //
    //  Test for ReadOnly and unpin accordingly.
    //

    if (((ULONG_PTR)Bcb & 1) != 0) {

        //
        //  Remove the Read Only flag
        //

        Bcb = (PVOID) ((ULONG_PTR)Bcb & ~1);

        CcUnpinFileData( (PBCB)Bcb, TRUE, UNPIN );

    } else {

        //
        //  Handle the overlapped Bcb case.
        //

        if (((POBCB)Bcb)->NodeTypeCode == CACHE_NTC_OBCB) {

            PBCB *BcbPtrPtr = &((POBCB)Bcb)->Bcbs[0];

            //
            //  Loop to free all Bcbs with recursive calls
            //  (rather than dealing with RO for this uncommon case).
            //

            while (*BcbPtrPtr != NULL) {
                CcUnpinData(*(BcbPtrPtr++));
            }

            //
            //  Then free the pool for the Obcb
            //

            ExFreePool( Bcb );

        //
        //  Otherwise, it is a normal Bcb
        //

        } else {
            CcUnpinFileData( (PBCB)Bcb, FALSE, UNPIN );
        }
    }

    DebugTrace(-1, me, "CcUnPinData -> VOID\n", 0 );
}


VOID
CcSetBcbOwnerPointer (
    IN PVOID Bcb,
    IN PVOID OwnerPointer
    )

/*++

Routine Description:

    This routine may be called to set the resource owner for the Bcb resource,
    for cases where another thread will do the unpin *and* the current thread
    may exit.

Arguments:

    Bcb - Bcb parameter returned from the last call to CcPinRead.

    OwnerPointer - A valid resource owner pointer, which means a pointer to
                   an allocated system address, with the low-order two bits
                   set.  The address may not be deallocated until after the
                   unpin call.

Return Value:

    None.

--*/

{
    ASSERT(((ULONG_PTR)Bcb & 1) == 0);

    //
    //  Handle the overlapped Bcb case.
    //

    if (((POBCB)Bcb)->NodeTypeCode == CACHE_NTC_OBCB) {

        PBCB *BcbPtrPtr = &((POBCB)Bcb)->Bcbs[0];

        //
        //  Loop to set owner for all Bcbs.
        //

        while (*BcbPtrPtr != NULL) {
            ExSetResourceOwnerPointer( &(*BcbPtrPtr)->Resource, OwnerPointer );
            BcbPtrPtr++;
        }

    //
    //  Otherwise, it is a normal Bcb
    //

    } else {

        //
        //  Handle normal case.
        //

        ExSetResourceOwnerPointer( &((PBCB)Bcb)->Resource, OwnerPointer );
    }
}


VOID
CcUnpinDataForThread (
    IN PVOID Bcb,
    IN ERESOURCE_THREAD ResourceThreadId
    )

/*++

Routine Description:

    This routine must be called at IPL0, some time after calling CcPinRead
    or CcPreparePinWrite.  It performs any cleanup that is necessary,
    releasing the Bcb resource for the given thread.

Arguments:

    Bcb - Bcb parameter returned from the last call to CcPinRead.

Return Value:

    None.

--*/

{
    DebugTrace(+1, me, "CcUnpinDataForThread:\n", 0 );
    DebugTrace( 0, me, "    >Bcb = %08lx\n", Bcb );
    DebugTrace( 0, me, "    >ResoureceThreadId = %08lx\n", ResoureceThreadId );

    //
    //  Test for ReadOnly and unpin accordingly.
    //

    if (((ULONG_PTR)Bcb & 1) != 0) {

        //
        //  Remove the Read Only flag
        //

        Bcb = (PVOID) ((ULONG_PTR)Bcb & ~1);

        CcUnpinFileData( (PBCB)Bcb, TRUE, UNPIN );

    } else {

        //
        //  Handle the overlapped Bcb case.
        //

        if (((POBCB)Bcb)->NodeTypeCode == CACHE_NTC_OBCB) {

            PBCB *BcbPtrPtr = &((POBCB)Bcb)->Bcbs[0];

            //
            //  Loop to free all Bcbs with recursive calls
            //  (rather than dealing with RO for this uncommon case).
            //

            while (*BcbPtrPtr != NULL) {
                CcUnpinDataForThread( *(BcbPtrPtr++), ResourceThreadId );
            }

            //
            //  Then free the pool for the Obcb
            //

            ExFreePool( Bcb );

        //
        //  Otherwise, it is a normal Bcb
        //

        } else {

            //
            //  If not readonly, we can release the resource for the thread first,
            //  and then call CcUnpinFileData.  Release resource first in case
            //  Bcb gets deallocated.
            //

            ExReleaseResourceForThreadLite( &((PBCB)Bcb)->Resource, ResourceThreadId );
            CcUnpinFileData( (PBCB)Bcb, TRUE, UNPIN );
        }
    }
    DebugTrace(-1, me, "CcUnpinDataForThread -> VOID\n", 0 );
}


POBCB
CcAllocateObcb (
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    IN PBCB FirstBcb
    )

/*++

Routine Description:

    This routine is called by the various pinning routines to allocate and
    initialize an overlap Bcb.

Arguments:

    FileOffset - Starting file offset for the Obcb (An Obcb starts with a
                 public structure, which someone could use)

    Length - Length of the range covered by the Obcb

    FirstBcb - First Bcb already created, which only covers the start of
               the desired range (low order bit may be set to indicate ReadOnly)

Return Value:

    Pointer to the allocated Obcb

--*/

{
    ULONG LengthToAllocate;
    POBCB Obcb;
    PBCB Bcb = (PBCB)((ULONG_PTR)FirstBcb & ~1);

    //
    //  Allocate according to the worst case, assuming that we
    //  will need as many additional Bcbs as there are pages
    //  remaining. Also throw in one more pointer to guarantee
    //  users of the OBCB can always terminate on NULL.
    //
    //  We remove fron consideration the range described by the
    //  first Bcb (note that the range of the Obcb is not strictly
    //  starting at the first Bcb) and add in locations for the first
    //  bcb and the null.
    //

    LengthToAllocate = FIELD_OFFSET(OBCB, Bcbs) + (2 * sizeof(PBCB)) +
                       ((Length -
                         (Bcb->ByteLength -
                          (FileOffset->HighPart?
                           (ULONG)(FileOffset->QuadPart - Bcb->FileOffset.QuadPart) :
                           FileOffset->LowPart - Bcb->FileOffset.LowPart)) +
                         PAGE_SIZE - 1) / PAGE_SIZE) * sizeof(PBCB);

    Obcb = ExAllocatePoolWithTag( NonPagedPool, LengthToAllocate, 'bOcC' );
    if (Obcb == NULL) {
        ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
    }

    RtlZeroMemory( Obcb, LengthToAllocate );
    Obcb->NodeTypeCode = CACHE_NTC_OBCB;
    Obcb->NodeByteSize = (USHORT)LengthToAllocate;
    Obcb->ByteLength = Length;
    Obcb->FileOffset = *FileOffset;
    Obcb->Bcbs[0] = FirstBcb;

    return Obcb;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\prefboot.c ===
/*++

Copyright (c) 1999 Microsoft Corporation

Module Name:

    prefboot.c

Abstract:

    This module contains the code for boot prefetching.

Author:

    Cenk Ergan (cenke)          15-Mar-2000

Revision History:

--*/

#include "cc.h"
#include "zwapi.h"
#include "prefetch.h"
#include "preftchp.h"
#include "stdio.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, CcPfBeginBootPhase)
#pragma alloc_text(PAGE, CcPfBootWorker)
#pragma alloc_text(PAGE, CcPfBootQueueEndTraceTimer)
#endif // ALLOC_PRAGMA

//
// Globals:
//

//
// Whether the system is currently prefetching for boot.
//

LOGICAL CcPfPrefetchingForBoot = FALSE;

//
// Current boot phase, only updated in begin boot phase routine.
//

PF_BOOT_PHASE_ID CcPfBootPhase = 0;

//
// Prefetcher globals.
//

extern CCPF_PREFETCHER_GLOBALS CcPfGlobals;

//
// Routines for boot prefetching.
//

NTSTATUS
CcPfBeginBootPhase(
    PF_BOOT_PHASE_ID Phase
    )

/*++

Routine Description:

    This routine is the control center for the boot prefetcher. 
    It is called to notify boot prefetcher of boot progress. 

Arguments:

    Phase - Boot phase the system is entering.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    LARGE_INTEGER VideoInitEndTime;
    LARGE_INTEGER MaxWaitTime;
    LONGLONG VideoInitTimeIn100ns;
    HANDLE ThreadHandle;
    PETHREAD Thread;
    PERFINFO_BOOT_PHASE_START LogEntry;
    PF_BOOT_PHASE_ID OriginalPhase;
    PF_BOOT_PHASE_ID NewPhase;   
    ULONG VideoInitTime;
    NTSTATUS Status;

    //
    // This is the boot prefetcher. It is allocated and free'd in this routine.
    // It is passed to the spawned boot worker if boot prefetching is enabled.
    //

    static PCCPF_BOOT_PREFETCHER BootPrefetcher = NULL;

    //
    // This is the system time when we started initializing the video.
    //

    static LARGE_INTEGER VideoInitStartTime;

    DBGPR((CCPFID,PFTRC,"CCPF: BeginBootPhase(%d)\n", (ULONG)Phase));

    //
    // Make sure phase is valid.
    //

    if (Phase >= PfMaxBootPhaseId) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    } 

    //
    // Log phase to trace buffer.
    //

    if (PERFINFO_IS_GROUP_ON(PERF_LOADER)) {

        LogEntry.Phase = Phase;
        
        PerfInfoLogBytes(PERFINFO_LOG_TYPE_BOOT_PHASE_START,
                         &LogEntry,
                         sizeof(LogEntry));
    }

    //
    // Update the global current boot phase.
    //

    for (;;) {
    
        OriginalPhase = CcPfBootPhase;

        if (Phase <= OriginalPhase) {
            Status = STATUS_TOO_LATE;
            goto cleanup;
        }

        //
        // If CcPfBootPhase is still OriginalPhase, set it to Phase.
        //

        NewPhase = InterlockedCompareExchange(&(LONG)CcPfBootPhase, Phase, OriginalPhase);

        if (NewPhase == OriginalPhase) {

            //
            // CcPfBootPhase was still OriginalPhase, so now it is set to
            // Phase. We are done.
            //

            break;
        }
    }

    Status = STATUS_SUCCESS;

    //
    // Perform the work we have to do for this boot phase.
    //

    switch (Phase) {

    case PfSystemDriverInitPhase:

        //
        // Update whether prefetcher is enabled or not.
        //

        CcPfDetermineEnablePrefetcher();

        //
        // If boot prefetching is not enabled, we are done.
        //

        if (!CCPF_IS_PREFETCHER_ENABLED() ||
            CcPfGlobals.Parameters.Parameters.EnableStatus[PfSystemBootScenarioType] != PfSvEnabled) {
            Status = STATUS_NOT_SUPPORTED;
            break;
        }

        //
        // Allocate and initialize boot prefetcher.
        //

        BootPrefetcher = ExAllocatePoolWithTag(NonPagedPool,
                                               sizeof(*BootPrefetcher),
                                               CCPF_ALLOC_BOOTWRKR_TAG);

        if (!BootPrefetcher) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            break;
        }

        KeInitializeEvent(&BootPrefetcher->SystemDriversPrefetchingDone,
                          NotificationEvent,
                          FALSE);
        KeInitializeEvent(&BootPrefetcher->PreSmssPrefetchingDone,
                          NotificationEvent,
                          FALSE);
        KeInitializeEvent(&BootPrefetcher->VideoInitPrefetchingDone,
                          NotificationEvent,
                          FALSE);
        KeInitializeEvent(&BootPrefetcher->VideoInitStarted,
                          NotificationEvent,
                          FALSE);

        //
        // Kick off the boot worker in paralel.
        //
            
        Status = PsCreateSystemThread(&ThreadHandle,
                                      THREAD_ALL_ACCESS,
                                      NULL,
                                      NULL,
                                      NULL,
                                      CcPfBootWorker,
                                      BootPrefetcher);
            
        if (NT_SUCCESS(Status)) {

            //
            // Give boot worker some head start by bumping its
            // priority. This helps to make sure pages we will
            // prefetch are put into transition before boot gets
            // ahead of the prefetcher.
            //

            Status = ObReferenceObjectByHandle(ThreadHandle,
                                               THREAD_SET_INFORMATION,
                                               PsThreadType,
                                               KernelMode,
                                               &Thread,
                                               NULL);

            if (NT_SUCCESS(Status)) {
                KeSetPriorityThread(&Thread->Tcb, HIGH_PRIORITY - 1);
                ObDereferenceObject(Thread);
            }

            ZwClose(ThreadHandle);               

            //
            // Before returning to initialize system drivers, wait
            // for boot worker to make progress.
            //
                
            KeWaitForSingleObject(&BootPrefetcher->SystemDriversPrefetchingDone, 
                                  Executive, 
                                  KernelMode, 
                                  FALSE, 
                                  NULL);

        } else {

            //
            // Free the allocated boot prefetcher.
            //

            ExFreePool(BootPrefetcher);
            BootPrefetcher = NULL;
        }

        break;

    case PfSessionManagerInitPhase:

        //
        // Wait for boot worker to make enough progress before launching
        // session manager.
        //

        if (BootPrefetcher) {
            KeWaitForSingleObject(&BootPrefetcher->PreSmssPrefetchingDone, 
                                  Executive, 
                                  KernelMode, 
                                  FALSE, 
                                  NULL);
        }

        break;

    case PfVideoInitPhase:

        //
        // Note when video initialization started.
        //

        KeQuerySystemTime(&VideoInitStartTime);

        //
        // Signal boot prefetcher to start prefetching in parallel to video 
        // initialization.
        //

        if (BootPrefetcher) {
            KeSetEvent(&BootPrefetcher->VideoInitStarted, 
                       IO_NO_INCREMENT,
                       FALSE);
        }

        break;

    case PfPostVideoInitPhase:

        //
        // Note when we complete video initialization. Save how long video  
        // initialization took in the registry in milliseconds.
        //

        KeQuerySystemTime(&VideoInitEndTime);

        VideoInitTimeIn100ns = VideoInitEndTime.QuadPart - VideoInitStartTime.QuadPart;
        VideoInitTime = (ULONG) (VideoInitTimeIn100ns / (1i64 * 10 * 1000));

        KeEnterCriticalRegionThread(KeGetCurrentThread());
        ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

        Status = CcPfSetParameter(CcPfGlobals.Parameters.ParametersKey,
                                  CCPF_VIDEO_INIT_TIME_VALUE_NAME,
                                  REG_DWORD,
                                  &VideoInitTime,
                                  sizeof(VideoInitTime));

        ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
        KeLeaveCriticalRegionThread(KeGetCurrentThread());

        //
        // Wait for prefetching parallel to video initialization to complete.
        //

        if (BootPrefetcher) {

            //
            // Make sure video init was signaled if it was skipped somehow.
            //

            KeSetEvent(&BootPrefetcher->VideoInitStarted, IO_NO_INCREMENT, FALSE);

            KeWaitForSingleObject(&BootPrefetcher->VideoInitPrefetchingDone, 
                                  Executive, 
                                  KernelMode, 
                                  FALSE, 
                                  NULL);
        }

        break;

    case PfBootAcceptedRegistryInitPhase:

        //
        // Service Controller has accepted this boot as a valid boot.
        // Boot & system services have initialized successfully.
        //

        //
        // We are done with boot prefetching. No one else could be accessing
        // BootPrefetcher structure at this point. 
        //

        if (BootPrefetcher) {

            //
            // Cleanup the allocated boot prefetcher.
            //

            ExFreePool(BootPrefetcher);
            BootPrefetcher = NULL;

            //
            // Determine if the prefetcher is enabled now that boot
            // is over.
            //

            CcPfDetermineEnablePrefetcher();
        }

        //
        // The user may not log in after booting. 
        // Queue a timer to end boot trace.
        //

        MaxWaitTime.QuadPart =  -1i64 * 60 * 1000 * 1000 * 10; // 60 seconds.

        CcPfBootQueueEndTraceTimer(&MaxWaitTime);

        break;
        
    case PfUserShellReadyPhase:
        
        //
        // Explorer has started, but start menu items may still be launching.
        // Queue a timer to end boot trace.
        //

        MaxWaitTime.QuadPart =  -1i64 * 30 * 1000 * 1000 * 10; // 30 seconds.

        CcPfBootQueueEndTraceTimer(&MaxWaitTime);

        break;

    default:
        
        //
        // Ignored for now.
        //

        Status = STATUS_SUCCESS;
        
    }

    //
    // Fall through with status from switch statement.
    //
    
 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: BeginBootPhase(%d)=%x\n", (ULONG)Phase, Status));

    return Status;
}

VOID
CcPfBootWorker(
    PCCPF_BOOT_PREFETCHER BootPrefetcher
    )

/*++

Routine Description:

    This routine is queued to prefetch and start tracing boot in parallel.

Arguments:

    BootPrefetcher - Pointer to boot prefetcher context.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PF_SCENARIO_ID BootScenarioId;
    CCPF_PREFETCH_HEADER PrefetchHeader;
    CCPF_BASIC_SCENARIO_INFORMATION ScenarioInfo;
    CCPF_BOOT_SCENARIO_INFORMATION BootScenarioInfo;
    PERFINFO_BOOT_PREFETCH_INFORMATION LogEntry;
    ULONG NumPages;
    ULONG RequiredSize;
    PFN_NUMBER NumPagesPrefetched;
    PFN_NUMBER TotalPagesPrefetched;
    ULONG BootPrefetchAdjustment;
    PFN_NUMBER AvailablePages;
    PFN_NUMBER NumPagesToPrefetch;
    ULONG TotalPagesToPrefetch;
    ULONG RemainingDataPages;
    ULONG RemainingImagePages;
    ULONG VideoInitTime;
    ULONG VideoInitPagesPerSecond;
    ULONG VideoInitMaxPages;
    ULONG RemainingVideoInitPages;
    ULONG VideoInitDataPages;
    ULONG VideoInitImagePages;
    ULONG PrefetchPhaseIdx;
    ULONG LastPrefetchPhaseIdx;
    ULONG SystemDriverPrefetchingPhaseIdx;
    ULONG PreSmssPrefetchingPhaseIdx;
    ULONG VideoInitPrefetchingPhaseIdx;
    ULONG ValueSize;
    CCPF_BOOT_SCENARIO_PHASE BootPhaseIdx;
    NTSTATUS Status;
    BOOLEAN OutOfAvailablePages;
    BOOLEAN BootPrefetcherGone;

    //
    // First we will prefetch data pages, then image pages.
    //

    enum {
        DataCursor = 0,
        ImageCursor,
        MaxCursor
    } CursorIdx;

    CCPF_BOOT_PREFETCH_CURSOR Cursors[MaxCursor];
    PCCPF_BOOT_PREFETCH_CURSOR Cursor;

    //
    // Initialize locals.
    //

    BootPrefetcherGone = FALSE;
    CcPfInitializePrefetchHeader(&PrefetchHeader);
    TotalPagesPrefetched = 0;
    OutOfAvailablePages = FALSE;

    DBGPR((CCPFID,PFTRC,"CCPF: BootWorker()\n"));

    //
    // Initialize boot scenario ID.
    //

    wcsncpy(BootScenarioId.ScenName, 
            PF_BOOT_SCENARIO_NAME, 
            PF_SCEN_ID_MAX_CHARS);

    BootScenarioId.ScenName[PF_SCEN_ID_MAX_CHARS] = 0;
    BootScenarioId.HashId = PF_BOOT_SCENARIO_HASHID;

    //
    // Start boot prefetch tracing.
    //

    CcPfBeginTrace(&BootScenarioId, PfSystemBootScenarioType, PsInitialSystemProcess);

    //
    // If we try to prefetch more pages then what we have available, we will 
    // end up cannibalizing the pages we prefetched into the standby list.
    // To avoid cannibalizing, we check MmAvailablePages but leave some 
    // breathing room for metadata pages, allocations from the driver 
    // initialization phase etc.
    //

    BootPrefetchAdjustment = 512;

    //
    // We also know that right after we prefetch for boot, in smss when 
    // initializing the registry we'll use up 8-10MB of prefetched pages if we 
    // don't have anything left in the free list. So we leave some room for 
    // that too.
    //

    BootPrefetchAdjustment += 8 * 1024 * 1024 / PAGE_SIZE; 

    //
    // Get prefetch instructions.
    //
    
    Status = CcPfGetPrefetchInstructions(&BootScenarioId,
                                         PfSystemBootScenarioType,
                                         &PrefetchHeader.Scenario);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }     
    
    //
    // Query the total number of pages to be prefetched. 
    //

    Status = CcPfQueryScenarioInformation(PrefetchHeader.Scenario,
                                          CcPfBasicScenarioInformation,
                                          &ScenarioInfo,
                                          sizeof(ScenarioInfo),
                                          &RequiredSize);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }
    
    //
    // Query the number of pages we have to prefetch for boot phases.
    //


    Status = CcPfQueryScenarioInformation(PrefetchHeader.Scenario,
                                          CcPfBootScenarioInformation,
                                          &BootScenarioInfo,
                                          sizeof(BootScenarioInfo),
                                          &RequiredSize);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }                                                            

    //
    // Read how long it took to initialize video in the last boot.
    //

    KeEnterCriticalRegionThread(KeGetCurrentThread());
    ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

    ValueSize = sizeof(VideoInitTime);
    Status = CcPfGetParameter(CcPfGlobals.Parameters.ParametersKey,
                              CCPF_VIDEO_INIT_TIME_VALUE_NAME,
                              REG_DWORD,
                              &VideoInitTime,
                              &ValueSize);

    ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
    KeLeaveCriticalRegionThread(KeGetCurrentThread());

    if (!NT_SUCCESS(Status)) {

        //
        // Reset video init time, so we don't attempt to prefetch
        // in parallel to it.
        //

        VideoInitTime = 0;

    } else {

        //
        // Verify the value we read from registry.
        //

        if (VideoInitTime > CCPF_MAX_VIDEO_INIT_TIME) {
            VideoInitTime = 0;
        }
    }

    //
    // Read how many pages per second we should be trying to prefetching 
    // in parallel to video initialization.
    //

    KeEnterCriticalRegionThread(KeGetCurrentThread());
    ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

    ValueSize = sizeof(VideoInitPagesPerSecond);
    Status = CcPfGetParameter(CcPfGlobals.Parameters.ParametersKey,
                              CCPF_VIDEO_INIT_PAGES_PER_SECOND_VALUE_NAME,
                              REG_DWORD,
                              &VideoInitPagesPerSecond,
                              &ValueSize);

    ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
    KeLeaveCriticalRegionThread(KeGetCurrentThread());

    if (!NT_SUCCESS(Status)) {

        //
        // There was no valid value in the registry. Use the default.
        //

        VideoInitPagesPerSecond = CCPF_VIDEO_INIT_DEFAULT_PAGES_PER_SECOND;

    } else {

        //
        // Verify the value we read from registry.
        //

        if (VideoInitPagesPerSecond > CCPF_VIDEO_INIT_MAX_PAGES_PER_SECOND) {
            VideoInitPagesPerSecond = CCPF_VIDEO_INIT_MAX_PAGES_PER_SECOND;
        }
    }

    //
    // Determine how many pages max we can prefetch in parallel to video
    // initialization.
    //

    VideoInitMaxPages = VideoInitTime * VideoInitPagesPerSecond / 1000;

    //
    // We can only prefetch pages used after winlogon in parallel to video
    // initialization. Determine exactly how many pages we will prefetch
    // starting from the last boot phase.
    //

    RemainingVideoInitPages = VideoInitMaxPages;
    VideoInitDataPages = 0;
    VideoInitImagePages = 0;

    for (BootPhaseIdx = CcPfBootScenMaxPhase - 1;
         RemainingVideoInitPages && (BootPhaseIdx >= CcPfBootScenSystemProcInitPhase);
         BootPhaseIdx--) {

        NumPages = CCPF_MIN(RemainingVideoInitPages, BootScenarioInfo.NumDataPages[BootPhaseIdx]);
        VideoInitDataPages += NumPages;
        RemainingVideoInitPages -= NumPages;

        if (RemainingVideoInitPages) {
            NumPages = CCPF_MIN(RemainingVideoInitPages, BootScenarioInfo.NumImagePages[BootPhaseIdx]);
            VideoInitImagePages += NumPages;
            RemainingVideoInitPages -= NumPages;
        }
    }  

    //
    // Let MM know that we have started prefetching for boot.
    //

    CcPfPrefetchingForBoot = TRUE;

    //
    // Log that we are starting prefetch disk I/Os.
    //

    if (PERFINFO_IS_GROUP_ON(PERF_DISK_IO)) {

        LogEntry.Action = 0;
        LogEntry.Status = 0;
        LogEntry.Pages = ScenarioInfo.NumDataPages + ScenarioInfo.NumImagePages;
        
        PerfInfoLogBytes(PERFINFO_LOG_TYPE_BOOT_PREFETCH_INFORMATION,
                         &LogEntry,
                         sizeof(LogEntry));
    }

    //
    // Verify & open the volumes that we will prefetch from.
    //

    Status = CcPfOpenVolumesForPrefetch(&PrefetchHeader);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Prefetch the metadata.
    //
     
    CcPfPrefetchMetadata(&PrefetchHeader);  

    //
    // Initialize the boot prefetch cursors for data and image.
    //

    RtlZeroMemory(Cursors, sizeof(Cursors));

    Cursors[DataCursor].PrefetchType = CcPfPrefetchPartOfDataPages;
    Cursors[ImageCursor].PrefetchType = CcPfPrefetchPartOfImagePages;

    PrefetchPhaseIdx = 0;
    RemainingDataPages = ScenarioInfo.NumDataPages;
    RemainingImagePages = ScenarioInfo.NumImagePages;

    //
    // Setup the cursors for phases in which we will prefetch for boot.
    // First we will prefetch for system drivers.
    //

    NumPages = BootScenarioInfo.NumDataPages[CcPfBootScenDriverInitPhase];
    Cursors[DataCursor].NumPagesForPhase[PrefetchPhaseIdx] = NumPages;
    RemainingDataPages -= NumPages;

    NumPages = BootScenarioInfo.NumImagePages[CcPfBootScenDriverInitPhase];
    Cursors[ImageCursor].NumPagesForPhase[PrefetchPhaseIdx] = NumPages;
    RemainingImagePages -= NumPages;

    SystemDriverPrefetchingPhaseIdx = PrefetchPhaseIdx;

    PrefetchPhaseIdx++;

    //
    // Account for the video init pages we will prefetch last.
    //

    RemainingDataPages -= VideoInitDataPages;
    RemainingImagePages -= VideoInitImagePages;

    //
    // If we have plenty of available memory, prefetch the rest of the pages
    // (i.e. left over after driver init pages) in one pass.
    //

    TotalPagesToPrefetch = ScenarioInfo.NumDataPages + ScenarioInfo.NumImagePages;

    if (MmAvailablePages > BootPrefetchAdjustment + TotalPagesToPrefetch) {
       
        Cursors[DataCursor].NumPagesForPhase[PrefetchPhaseIdx] = RemainingDataPages;
        RemainingDataPages = 0;
        
        Cursors[ImageCursor].NumPagesForPhase[PrefetchPhaseIdx] = RemainingImagePages;
        RemainingImagePages = 0;

        PrefetchPhaseIdx++;

    } else {

        //
        // We will be short on memory. Try to prefetch for as many phases of
        // boot as we can in parallel. Prefetching data & image pages per boot
        // phase, so we don't end up with data pages for all phase but no image
        // pages so we have to go to the disk in each phase. Prefetching in 
        // chunks also help that all the pages we need for the initial phases
        // of boot ending up at the end of the standby list, since when 
        // CcPfPrefetchingForBoot is set, prefetched pages will be inserted 
        // from the front of the standby list.
        //

        for (BootPhaseIdx = CcPfBootScenDriverInitPhase + 1; 
             BootPhaseIdx < CcPfBootScenMaxPhase; 
             BootPhaseIdx++) {

            //
            // If we don't have any type of pages left to prefetch, we are done.
            //

            if (!RemainingDataPages && !RemainingImagePages) {
                break;
            }

            NumPages = CCPF_MIN(RemainingDataPages, BootScenarioInfo.NumDataPages[BootPhaseIdx]);
            RemainingDataPages -= NumPages;
            Cursors[DataCursor].NumPagesForPhase[PrefetchPhaseIdx] = NumPages;

            NumPages = CCPF_MIN(RemainingImagePages, BootScenarioInfo.NumImagePages[BootPhaseIdx]);
            RemainingImagePages -= NumPages;
            Cursors[ImageCursor].NumPagesForPhase[PrefetchPhaseIdx] = NumPages;

            PrefetchPhaseIdx++;
        }
    }

    PreSmssPrefetchingPhaseIdx = PrefetchPhaseIdx - 1;

    //
    // If we'll be prefetching pages in parallel to video initialization, now
    // add the phase for it.
    //

    if (VideoInitDataPages || VideoInitImagePages) {

        Cursors[DataCursor].NumPagesForPhase[PrefetchPhaseIdx] = VideoInitDataPages;
        Cursors[ImageCursor].NumPagesForPhase[PrefetchPhaseIdx] = VideoInitImagePages;

        VideoInitPrefetchingPhaseIdx = PrefetchPhaseIdx;

        PrefetchPhaseIdx++;

    } else {

        //
        // We won't have a prefetching phase parallel to video initialization.
        //

        VideoInitPrefetchingPhaseIdx = CCPF_MAX_BOOT_PREFETCH_PHASES;
    }

    //
    // We should not end up with more prefetch phases than we have room for.
    //

    CCPF_ASSERT(PrefetchPhaseIdx <= CCPF_MAX_BOOT_PREFETCH_PHASES);

    LastPrefetchPhaseIdx = PrefetchPhaseIdx;

    //
    // Prefetch the data and image pages for each boot prefetching phase,
    // waiting for & signaling the events matching those phases so boot
    // is synchronized with prefetching. (I.e. we prefetch pages for a boot
    // phase before we start that boot phase.)
    //

    for (PrefetchPhaseIdx = 0; PrefetchPhaseIdx < LastPrefetchPhaseIdx; PrefetchPhaseIdx++) {

        //
        // If this is the video init prefetching phase, wait for video 
        // initialization to begin.
        //

        if (PrefetchPhaseIdx == VideoInitPrefetchingPhaseIdx) {
            KeWaitForSingleObject(&BootPrefetcher->VideoInitStarted, 
                                  Executive, 
                                  KernelMode, 
                                  FALSE, 
                                  NULL);
        }

        for (CursorIdx = 0; CursorIdx < MaxCursor; CursorIdx++) {

            Cursor = &Cursors[CursorIdx];

            NumPagesToPrefetch = Cursor->NumPagesForPhase[PrefetchPhaseIdx];

            //
            // For prefetch phases before SMSS is launched keep an eye on
            // how much memory is still available to prefetch into so we
            // don't cannibalize ourselves. After SMSS our heuristics on
            // standby-list composition do not make sense.
            //

            if (PrefetchPhaseIdx <= PreSmssPrefetchingPhaseIdx) {          

                //
                // Check if we have available memory to prefetch more.
                //

                if (TotalPagesPrefetched + BootPrefetchAdjustment >= MmAvailablePages) {

                    OutOfAvailablePages = TRUE;

                    NumPagesToPrefetch = 0;

                } else {

                    //
                    // Check if we have to adjust NumPagesToPrefetch and prefetch
                    // one last chunk.
                    //

                    AvailablePages = MmAvailablePages;
                    AvailablePages -= (TotalPagesPrefetched + BootPrefetchAdjustment);

                    if (AvailablePages < NumPagesToPrefetch) {
                        OutOfAvailablePages = TRUE;
                        NumPagesToPrefetch = AvailablePages;
                    }
                }
            }

            if (NumPagesToPrefetch) {

                Status = CcPfPrefetchSections(&PrefetchHeader, 
                                              Cursor->PrefetchType,  
                                              &Cursor->StartCursor,
                                              NumPagesToPrefetch,
                                              &NumPagesPrefetched,
                                              &Cursor->EndCursor);

                if (!NT_SUCCESS(Status)) {
                    goto cleanup;
                }

            } else {

                NumPagesPrefetched = 0;
            }

            //
            // Update our position.
            //
            
            Cursor->StartCursor = Cursor->EndCursor;

            TotalPagesPrefetched += NumPagesPrefetched;

        }

        //
        // Note that we are done with this prefetching phase and
        // system boot can continue.
        //

        if (PrefetchPhaseIdx == SystemDriverPrefetchingPhaseIdx) {
            KeSetEvent(&BootPrefetcher->SystemDriversPrefetchingDone,
                       IO_NO_INCREMENT,
                       FALSE);
        }

        if (PrefetchPhaseIdx == PreSmssPrefetchingPhaseIdx) {
            KeSetEvent(&BootPrefetcher->PreSmssPrefetchingDone,
                       IO_NO_INCREMENT,
                       FALSE);
        }

        if (PrefetchPhaseIdx == VideoInitPrefetchingPhaseIdx) {
            KeSetEvent(&BootPrefetcher->VideoInitPrefetchingDone,
                       IO_NO_INCREMENT,
                       FALSE);

            //
            // After we signal this event the BootPrefetcher structure may
            // get freed, so don't touch it.
            //

            BootPrefetcherGone = TRUE;
        }
    }

    Status = STATUS_SUCCESS;

 cleanup:

    //
    // Log that we are done with boot prefetch disk I/Os.
    //

    if (PERFINFO_IS_GROUP_ON(PERF_DISK_IO)) {

        LogEntry.Action = 1;
        LogEntry.Status = Status;
        LogEntry.Pages = (ULONG) TotalPagesPrefetched;
        
        PerfInfoLogBytes(PERFINFO_LOG_TYPE_BOOT_PREFETCH_INFORMATION,
                         &LogEntry,
                         sizeof(LogEntry));
    }

    //
    // Make sure all the events system may wait for before proceeding with
    // boot are signaled.
    //

    if (!BootPrefetcherGone) {

        //
        // Don't access the BootPrefetcher structure after the video-init-done
        // event is signaled: it may get freed from beneath us.
        //   

        KeSetEvent(&BootPrefetcher->SystemDriversPrefetchingDone,
                   IO_NO_INCREMENT,
                   FALSE);

        KeSetEvent(&BootPrefetcher->PreSmssPrefetchingDone,
                   IO_NO_INCREMENT,
                   FALSE);

        KeSetEvent(&BootPrefetcher->VideoInitPrefetchingDone,
                   IO_NO_INCREMENT,
                   FALSE);

        BootPrefetcherGone = TRUE;
    }
    
    //
    // Let MM know that we are done prefetching for boot.
    //

    CcPfPrefetchingForBoot = FALSE;

    //
    // Cleanup prefetching context.
    //

    CcPfCleanupPrefetchHeader(&PrefetchHeader);

    if (PrefetchHeader.Scenario) {
        ExFreePool(PrefetchHeader.Scenario);
    }

    DBGPR((CCPFID,PFTRC,"CCPF: BootWorker()=%x,%d\n",Status,(ULONG)OutOfAvailablePages));
}

NTSTATUS
CcPfBootQueueEndTraceTimer (
    PLARGE_INTEGER Timeout
    )

/*++

Routine Description:

    This routine allocates and queues a timer that will attempt to end
    the boot trace when it fires.

Arguments:

    Timeout - Timeout for the timer.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL <= PASSIVE_LEVEL.

--*/

{
    PVOID Allocation;
    PKTIMER Timer;
    PKDPC Dpc;
    ULONG AllocationSize;
    NTSTATUS Status;
    BOOLEAN TimerAlreadyQueued;

    //
    // Initialize locals.
    //

    Allocation = NULL;

    //
    // Make a single allocation for the timer and dpc.
    //

    AllocationSize = sizeof(KTIMER);
    AllocationSize += sizeof(KDPC);

    Allocation = ExAllocatePoolWithTag(NonPagedPool,
                                       AllocationSize,
                                       CCPF_ALLOC_BOOTWRKR_TAG);

    if (!Allocation) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    Timer = Allocation;
    Dpc = (PKDPC)(Timer + 1);

    //
    // Initialize the timer and DPC. We'll be passing the allocation to the 
    // queued DPC so it can be freed.
    //

    KeInitializeTimer(Timer);
    KeInitializeDpc(Dpc, CcPfEndBootTimerRoutine, Allocation);

    //
    // Queue the timer.
    //

    TimerAlreadyQueued = KeSetTimer(Timer, *Timeout, Dpc);

    CCPF_ASSERT(!TimerAlreadyQueued);

    Status = STATUS_SUCCESS;
    
  cleanup:

    if (!NT_SUCCESS(Status)) {
        if (Allocation) {
            ExFreePool(Allocation);
        }
    }

    return Status;
}

VOID
CcPfEndBootTimerRoutine(
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    )

/*++

Routine Description:

    This routine is invoked as the DPC handler for a timer queued to
    mark the end of boot and end the boot trace if one is active.

Arguments:

    DeferredContext - Allocated memory for the timer & dpc that need
      to be freed.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == DISPATCH_LEVEL.

--*/

    
{
    PCCPF_TRACE_HEADER BootTrace;
    PERFINFO_BOOT_PHASE_START LogEntry;

    UNREFERENCED_PARAMETER (Dpc);
    UNREFERENCED_PARAMETER (SystemArgument1);
    UNREFERENCED_PARAMETER (SystemArgument2);

    //
    // Initialize locals.
    //

    BootTrace = NULL;

    //
    // Is the boot trace still active?
    //

    BootTrace = CcPfReferenceProcessTrace(PsInitialSystemProcess);

    if (BootTrace && BootTrace->ScenarioType == PfSystemBootScenarioType) {

        //
        // Is somebody already ending the boot trace?
        //

        if (!InterlockedCompareExchange(&BootTrace->EndTraceCalled, 1, 0)) {
        
            //
            // We set EndTraceCalled from 0 to 1. Queue the
            // workitem to end the trace.
            //
            
            ExQueueWorkItem(&BootTrace->EndTraceWorkItem, DelayedWorkQueue);

            //
            // Log that we are ending the boot trace.
            //

            if (PERFINFO_IS_GROUP_ON(PERF_LOADER)) {

                LogEntry.Phase = PfMaxBootPhaseId;
                
                PerfInfoLogBytes(PERFINFO_LOG_TYPE_BOOT_PHASE_START,
                                 &LogEntry,
                                 sizeof(LogEntry));
            }
        }
    }

    //
    // Free the memory allocated for the timer and dpc.
    //

    CCPF_ASSERT(DeferredContext);   
    ExFreePool(DeferredContext);

    if (BootTrace) {
        CcPfDecRef(&BootTrace->RefCount);
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\logsup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    logsup.c

Abstract:

    This module implements the special cache manager support for logging
    file systems.

Author:

    Tom Miller      [TomM]      30-Jul-1991

Revision History:

--*/

#include "cc.h"

//
//  Define our debug constant
//

#define me 0x0000040

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CcSetLogHandleForFile)
#endif


VOID
CcSetAdditionalCacheAttributes (
    IN PFILE_OBJECT FileObject,
    IN BOOLEAN DisableReadAhead,
    IN BOOLEAN DisableWriteBehind
    )

/*++

Routine Description:

    This routine supports the setting of disable read ahead or disable write
    behind flags to control Cache Manager operation.  This routine may be
    called any time after calling CcInitializeCacheMap.  Initially both
    read ahead and write behind are enabled.  Note that the state of both
    of these flags must be specified on each call to this routine.

Arguments:

    FileObject - File object for which the respective flags are to be set.

    DisableReadAhead - FALSE to enable read ahead, TRUE to disable it.

    DisableWriteBehind - FALSE to enable write behind, TRUE to disable it.

Return Value:

    None.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    KIRQL OldIrql;

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  Now set the flags and return.
    //

    CcAcquireMasterLock( &OldIrql );
    if (DisableReadAhead) {
        SetFlag(SharedCacheMap->Flags, DISABLE_READ_AHEAD);
    } else {
        ClearFlag(SharedCacheMap->Flags, DISABLE_READ_AHEAD);
    }
    if (DisableWriteBehind) {
        SetFlag(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND | MODIFIED_WRITE_DISABLED);
    } else {
        ClearFlag(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND);
    }
    CcReleaseMasterLock( OldIrql );
}


NTKERNELAPI
BOOLEAN
CcSetPrivateWriteFile(
    PFILE_OBJECT FileObject
    )

/*++

Routine Description:

    This routine will instruct the cache manager to treat the file as
    a private-write stream, so that a caller can implement a private
    logging mechanism for it.  We will turn on both Mm's modify-no-write
    and our disable-write-behind, and disallow non-aware flush/purge for
    the file.

    Caching must already be initiated on the file.

    This routine is only exported to the kernel.

Arguments:

    FileObject - File to make private-write.

Return Value:

    None.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    BOOLEAN Disabled;
    KIRQL OldIrql;
    PVACB Vacb;
    ULONG ActivePage;
    ULONG PageIsDirty;

    //
    //  Pick up the file exclusive to synchronize against readahead and
    //  other purge/map activity.
    //

    FsRtlAcquireFileExclusive( FileObject );

    //
    //  Get a pointer to the SharedCacheMap. Be sure to release the FileObject
    //  in case an error condition forces a premature exit.
    //
    
    if ((FileObject->SectionObjectPointer == NULL) ||
    	((SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap) == NULL)){
    	 FsRtlReleaseFile( FileObject );
        return FALSE;
    }
    
    //
    //  Unmap all the views in preparation for making the disable mw call.
    //

    //
    //  We still need to wait for any dangling cache read or writes.
    //
    //  In fact we have to loop and wait because the lazy writer can
    //  sneak in and do an CcGetVirtualAddressIfMapped, and we are not
    //  synchronized.
    //
    //  This is the same bit of code that our purge will do.  We assume
    //  that a private writer has succesfully blocked out other activity.
    //

    //
    //  If there is an active Vacb, then nuke it now (before waiting!).
    //

    CcAcquireMasterLock( &OldIrql );
    GetActiveVacbAtDpcLevel( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
    CcReleaseMasterLock( OldIrql );
    
    if (Vacb != NULL) {

        CcFreeActiveVacb( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
    }

    while ((SharedCacheMap->Vacbs != NULL) &&
           !CcUnmapVacbArray( SharedCacheMap, NULL, 0, FALSE )) {

        CcWaitOnActiveCount( SharedCacheMap );
    }

    //
    //  Knock the file down.
    // 

    CcFlushCache( FileObject->SectionObjectPointer, NULL, 0, NULL );

    //
    //  Now the file is clean and unmapped. We can still have a racing
    //  lazy writer, though.
    //
    //  We just wait for the lazy writer queue to drain before disabling
    //  modified write.  There may be a better way to do this by having
    //  an event for the WRITE_QUEUED flag. ?  This would also let us
    //  dispense with the pagingio pick/drop in the FS cache coherency
    //  paths, but there could be reasons why CcFlushCache shouldn't
    //  always do such a block.  Investigate this.
    //
    //  This wait takes on the order of ~.5s avg. case.
    //

    CcAcquireMasterLock( &OldIrql );
    
    if (FlagOn( SharedCacheMap->Flags, WRITE_QUEUED ) ||
        FlagOn( SharedCacheMap->Flags, READ_AHEAD_QUEUED )) {
        
        CcReleaseMasterLock( OldIrql );
        FsRtlReleaseFile( FileObject );
        CcWaitForCurrentLazyWriterActivity();
        FsRtlAcquireFileExclusive( FileObject );

    } else {

        CcReleaseMasterLock( OldIrql );
    }

    //
    //  Now set the flags and return.  We do not set our MODIFIED_WRITE_DISABLED
    //  since we don't want to fully promote this cache map.  Future?
    //

    Disabled = MmDisableModifiedWriteOfSection( FileObject->SectionObjectPointer );

    if (Disabled) {
        CcAcquireMasterLock( &OldIrql );
        SetFlag(SharedCacheMap->Flags, DISABLE_WRITE_BEHIND | PRIVATE_WRITE);
        CcReleaseMasterLock( OldIrql );
    }

    //
    //  Now release the file for regular operation.
    //

    FsRtlReleaseFile( FileObject );

    return Disabled;
}


VOID
CcSetLogHandleForFile (
    IN PFILE_OBJECT FileObject,
    IN PVOID LogHandle,
    IN PFLUSH_TO_LSN FlushToLsnRoutine
    )

/*++

Routine Description:

    This routine may be called to instruct the Cache Manager to store the
    specified log handle with the shared cache map for a file, to support
    subsequent calls to the other routines in this module which effectively
    perform an associative search for files by log handle.

Arguments:

    FileObject - File for which the log handle should be stored.

    LogHandle - Log Handle to store.

    FlushToLsnRoutine - A routine to call before flushing buffers for this
                        file, to insure a log file is flushed to the most
                        recent Lsn for any Bcb being flushed.

Return Value:

    None.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  Now set the log file handle and flush routine
    //

    SharedCacheMap->LogHandle = LogHandle;
    SharedCacheMap->FlushToLsnRoutine = FlushToLsnRoutine;
}


LARGE_INTEGER
CcGetDirtyPages (
    IN PVOID LogHandle,
    IN PDIRTY_PAGE_ROUTINE DirtyPageRoutine,
    IN PVOID Context1,
    IN PVOID Context2
    )

/*++

Routine Description:

    This routine may be called to return all of the dirty pages in all files
    for a given log handle.  Each page is returned by an individual call to
    the Dirty Page Routine.  The Dirty Page Routine is defined by a prototype
    in ntos\inc\cache.h.

Arguments:

    LogHandle - Log Handle which must match the log handle previously stored
                for all files which are to be returned.

    DirtyPageRoutine -- The routine to call as each dirty page for this log
                        handle is found.

    Context1 - First context parameter to be passed to the Dirty Page Routine.

    Context2 - First context parameter to be passed to the Dirty Page Routine.

Return Value:

    LARGE_INTEGER - Oldest Lsn found of all the dirty pages, or 0 if no dirty pages

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PBCB Bcb, BcbToUnpin = NULL;
    KLOCK_QUEUE_HANDLE LockHandle;
    LARGE_INTEGER SavedFileOffset, SavedOldestLsn, SavedNewestLsn;
    ULONG SavedByteLength;
    LARGE_INTEGER OldestLsn = {0,0};

    //
    //  Synchronize with changes to the SharedCacheMap list.
    //

    CcAcquireMasterLock( &LockHandle.OldIrql );

    SharedCacheMap = CONTAINING_RECORD( CcDirtySharedCacheMapList.SharedCacheMapLinks.Flink,
                                        SHARED_CACHE_MAP,
                                        SharedCacheMapLinks );

    //
    //  Use try/finally for cleanup.  The only spot where we can raise is out of the
    //  filesystem callback, but we have the exception handler out here so we aren't
    //  constantly setting/unsetting it.
    //

    try {

        while (&SharedCacheMap->SharedCacheMapLinks != &CcDirtySharedCacheMapList.SharedCacheMapLinks) {

            //
            //  Skip over cursors, SharedCacheMaps for other LogHandles, and ones with
            //  no dirty pages
            //

            if (!FlagOn(SharedCacheMap->Flags, IS_CURSOR) && (SharedCacheMap->LogHandle == LogHandle) &&
                (SharedCacheMap->DirtyPages != 0)) {

                //
                //  This SharedCacheMap should stick around for a while in the dirty list.
                //

                CcIncrementOpenCount( SharedCacheMap, 'pdGS' );
                SharedCacheMap->DirtyPages += 1;
                CcReleaseMasterLock( LockHandle.OldIrql );

                //
                //  Set our initial resume point and point to first Bcb in List.
                //

                KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
                Bcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Flink, BCB, BcbLinks );

                //
                //  Scan to the end of the Bcb list.
                //

                while (&Bcb->BcbLinks != &SharedCacheMap->BcbList) {

                    //
                    //  If the Bcb is dirty, then capture the inputs for the
                    //  callback routine so we can call without holding a spinlock.
                    //

                    if ((Bcb->NodeTypeCode == CACHE_NTC_BCB) && Bcb->Dirty) {

                        SavedFileOffset = Bcb->FileOffset;
                        SavedByteLength = Bcb->ByteLength;
                        SavedOldestLsn = Bcb->OldestLsn;
                        SavedNewestLsn = Bcb->NewestLsn;

                        //
                        //  Increment PinCount so the Bcb sticks around
                        //

                        Bcb->PinCount += 1;

                        KeReleaseInStackQueuedSpinLock( &LockHandle );

                        //
                        //  Any Bcb to unref from a previous loop?
                        //

                        if (BcbToUnpin != NULL) {
                            CcUnpinFileData( BcbToUnpin, TRUE, UNREF );
                            BcbToUnpin = NULL;
                        }

                        //
                        //  Call the file system.  This callback may raise status.
                        //

                        (*DirtyPageRoutine)( SharedCacheMap->FileObject,
                                             &SavedFileOffset,
                                             SavedByteLength,
                                             &SavedOldestLsn,
                                             &SavedNewestLsn,
                                             Context1,
                                             Context2 );

                        //
                        //  Possibly update OldestLsn
                        //

                        if ((SavedOldestLsn.QuadPart != 0) &&
                            ((OldestLsn.QuadPart == 0) || (SavedOldestLsn.QuadPart < OldestLsn.QuadPart ))) {
                            OldestLsn = SavedOldestLsn;
                        }

                        //
                        //  Now reacquire the spinlock and scan from the resume point
                        //  point to the next Bcb to return in the descending list.
                        //

                        KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );

                        //
                        //  Normally the Bcb can stay around a while, but if not,
                        //  we will just remember it for the next time we do not
                        //  have the spin lock.  We cannot unpin it now, because
                        //  we would lose our place in the list.
                        //
                        //  This is cheating, but it works and is sane since we're
                        //  already traversing the bcb list - dropping the bcb count
                        //  is OK, as long as we don't hit zero.  Zero requires a 
                        //  slight bit more attention that shouldn't be replicated.
                        //  (unmapping the view)
                        //

                        if (Bcb->PinCount > 1) {
                            Bcb->PinCount -= 1;
                        } else {
                            BcbToUnpin = Bcb;
                        }
                    }

                    Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Flink, BCB, BcbLinks );
                }
                KeReleaseInStackQueuedSpinLock( &LockHandle );

                //
                //  We need to unref any Bcb we are holding before moving on to
                //  the next SharedCacheMap, or else CcDeleteSharedCacheMap will
                //  also delete this Bcb.
                //

                if (BcbToUnpin != NULL) {

                    CcUnpinFileData( BcbToUnpin, TRUE, UNREF );
                    BcbToUnpin = NULL;
                }

                CcAcquireMasterLock( &LockHandle.OldIrql );

                //
                //  Now release the SharedCacheMap, leaving it in the dirty list.
                //

                CcDecrementOpenCount( SharedCacheMap, 'pdGF' );
                SharedCacheMap->DirtyPages -= 1;
            }

            //
            //  Now loop back for the next cache map.
            //

            SharedCacheMap =
                CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                                   SHARED_CACHE_MAP,
                                   SharedCacheMapLinks );
        }

        CcReleaseMasterLock( LockHandle.OldIrql );

    } finally {

        //
        //  Drop the Bcb if we are being ejected.  We are guaranteed that the
        //  only raise is from the callback, at which point we have an incremented
        //  pincount.
        //

        if (AbnormalTermination()) {

            CcUnpinFileData( Bcb, TRUE, UNPIN );
        }
    }

    return OldestLsn;
}


BOOLEAN
CcIsThereDirtyData (
    IN PVPB Vpb
    )

/*++

Routine Description:

    This routine returns TRUE if the specified Vcb has any unwritten dirty
    data in the cache.

Arguments:

    Vpb - specifies Vpb to check for

Return Value:

    FALSE - if the Vpb has no dirty data
    TRUE - if the Vpb has dirty data

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    KIRQL OldIrql;
    ULONG LoopsWithLockHeld = 0;

    //
    //  Synchronize with changes to the SharedCacheMap list.
    //

    CcAcquireMasterLock( &OldIrql );

    SharedCacheMap = CONTAINING_RECORD( CcDirtySharedCacheMapList.SharedCacheMapLinks.Flink,
                                        SHARED_CACHE_MAP,
                                        SharedCacheMapLinks );

    while (&SharedCacheMap->SharedCacheMapLinks != &CcDirtySharedCacheMapList.SharedCacheMapLinks) {

        //
        //  Look at this one if the Vpb matches and if there is dirty data.
        //  For what it's worth, don't worry about dirty data in temporary files,
        //  as that should not concern the caller if it wants to dismount.
        //

        if (!FlagOn(SharedCacheMap->Flags, IS_CURSOR) &&
            (SharedCacheMap->FileObject->Vpb == Vpb) &&
            (SharedCacheMap->DirtyPages != 0) &&
            !FlagOn(SharedCacheMap->FileObject->Flags, FO_TEMPORARY_FILE)) {

            CcReleaseMasterLock( OldIrql );
            return TRUE;
        }

        //
        //  Make sure we occasionally drop the lock.  Set WRITE_QUEUED
        //  to keep the guy from going away, and increment DirtyPages to
        //  keep it in this list.
        //

        if ((++LoopsWithLockHeld >= 20) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED | IS_CURSOR)) {

            SetFlag( *((ULONG volatile *)&SharedCacheMap->Flags), WRITE_QUEUED);
            *((ULONG volatile *)&SharedCacheMap->DirtyPages) += 1;
            CcReleaseMasterLock( OldIrql );
            LoopsWithLockHeld = 0;
            CcAcquireMasterLock( &OldIrql );
            ClearFlag( *((ULONG volatile *)&SharedCacheMap->Flags), WRITE_QUEUED);
            *((ULONG volatile *)&SharedCacheMap->DirtyPages) -= 1;
        }

        //
        //  Now loop back for the next cache map.
        //

        SharedCacheMap =
            CONTAINING_RECORD( SharedCacheMap->SharedCacheMapLinks.Flink,
                               SHARED_CACHE_MAP,
                               SharedCacheMapLinks );
    }

    CcReleaseMasterLock( OldIrql );

    return FALSE;
}

LARGE_INTEGER
CcGetLsnForFileObject(
    IN PFILE_OBJECT FileObject,
    OUT PLARGE_INTEGER OldestLsn OPTIONAL
    )

/*++

Routine Description:

    This routine returns the  oldest and newest LSNs for a file object.

Arguments:

    FileObject - File for which the log handle should be stored.

    OldestLsn - pointer to location to store oldest LSN for file object.

Return Value:

    The newest LSN for the file object.

--*/

{
    PBCB Bcb;
    KLOCK_QUEUE_HANDLE LockHandle;
    LARGE_INTEGER Oldest, Newest;
    PSHARED_CACHE_MAP SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    // initialize lsn variables
    //

    Oldest.LowPart = 0;
    Oldest.HighPart = 0;
    Newest.LowPart = 0;
    Newest.HighPart = 0;

    if(SharedCacheMap == NULL) {
        return Oldest;
    }

    KeAcquireInStackQueuedSpinLock(&SharedCacheMap->BcbSpinLock, &LockHandle);

    //
    //  Now point to first Bcb in List, and loop through it.
    //

    Bcb = CONTAINING_RECORD( SharedCacheMap->BcbList.Flink, BCB, BcbLinks );

    while (&Bcb->BcbLinks != &SharedCacheMap->BcbList) {

        //
        //  If the Bcb is dirty then capture the oldest and newest lsn
        //


        if ((Bcb->NodeTypeCode == CACHE_NTC_BCB) && Bcb->Dirty) {

            LARGE_INTEGER BcbLsn, BcbNewest;

            BcbLsn = Bcb->OldestLsn;
            BcbNewest = Bcb->NewestLsn;

            if ((BcbLsn.QuadPart != 0) &&
                ((Oldest.QuadPart == 0) ||
                 (BcbLsn.QuadPart < Oldest.QuadPart))) {

                 Oldest = BcbLsn;
            }

            if ((BcbLsn.QuadPart != 0) && (BcbNewest.QuadPart > Newest.QuadPart)) {

                Newest = BcbNewest;
            }
        }


        Bcb = CONTAINING_RECORD( Bcb->BcbLinks.Flink, BCB, BcbLinks );
    }

    //
    //  Now release the spin lock for this Bcb list and generate a callback
    //  if we got something.
    //

    KeReleaseInStackQueuedSpinLock( &LockHandle );

    if (ARGUMENT_PRESENT(OldestLsn)) {

        *OldestLsn = Oldest;
    }

    return Newest;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\mdlsup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    mdlsup.c

Abstract:

    This module implements the Mdl support routines for the Cache subsystem.

Author:

    Tom Miller      [TomM]      4-May-1990

Revision History:

--*/

#include "cc.h"

//
//  Debug Trace Level
//

#define me                               (0x00000010)

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CcMdlRead)
#pragma alloc_text(PAGE,CcMdlReadComplete)
#pragma alloc_text(PAGE,CcMdlReadComplete2)
#pragma alloc_text(PAGE,CcMdlWriteComplete)
#endif


VOID
CcMdlRead (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    OUT PMDL *MdlChain,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine attempts to lock the specified file data in the cache
    and return a description of it in an Mdl along with the correct
    I/O status.  It is *not* safe to call this routine from Dpc level.

    This routine is synchronous, and raises on errors.

    As each call returns, the pages described by the Mdl are
    locked in memory, but not mapped in system space.  If the caller
    needs the pages mapped in system space, then it must map them.

    Note that each call is a "single shot" which should be followed by
    a call to CcMdlReadComplete.  To resume an Mdl-based transfer, the
    caller must form one or more subsequent calls to CcMdlRead with
    appropriately adjusted parameters.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    MdlChain - On output it returns a pointer to an Mdl chain describing
               the desired data.  Note that even if FALSE is returned,
               one or more Mdls may have been allocated, as may be ascertained
               by the IoStatus.Information field (see below).

    IoStatus - Pointer to standard I/O status block to receive the status
               for the transfer.  (STATUS_SUCCESS guaranteed for cache
               hits, otherwise the actual I/O status is returned.)  The
               I/O Information Field indicates how many bytes have been
               successfully locked down in the Mdl Chain.

Return Value:

    None

Raises:

    STATUS_INSUFFICIENT_RESOURCES - If a pool allocation failure occurs.

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PPRIVATE_CACHE_MAP PrivateCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PMDL Mdl = NULL;
    PMDL MdlTemp;
    PETHREAD Thread = PsGetCurrentThread();
    ULONG SavedState = 0;
    ULONG OriginalLength = Length;
    ULONG Information = 0;
    PVACB Vacb = NULL;
    ULONG SavedMissCounter = 0;

    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB ActiveVacb = NULL;

    DebugTrace(+1, me, "CcMdlRead\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    //
    //  Save the current readahead hints.
    //

    MmSavePageFaultReadAhead( Thread, &SavedState );

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;
    PrivateCacheMap = FileObject->PrivateCacheMap;

    //
    //  See if we have an active Vacb, that we need to free.
    //

    GetActiveVacb( SharedCacheMap, OldIrql, ActiveVacb, ActivePage, PageIsDirty );

    //
    //  If there is an end of a page to be zeroed, then free that page now,
    //  so we don't send Greg the uninitialized data...
    //

    if ((ActiveVacb != NULL) || (SharedCacheMap->NeedToZero != NULL)) {

        CcFreeActiveVacb( SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
    }

    //
    //  If read ahead is enabled, then do the read ahead here so it
    //  overlaps with the copy (otherwise we will do it below).
    //  Note that we are assuming that we will not get ahead of our
    //  current transfer - if read ahead is working it should either
    //  already be in memory or else underway.
    //

    if (PrivateCacheMap->Flags.ReadAheadEnabled && (PrivateCacheMap->ReadAheadLength[1] == 0)) {
        CcScheduleReadAhead( FileObject, FileOffset, Length );
    }

    //
    //  Increment performance counters
    //

    CcMdlReadWait += 1;

    //
    //  This is not an exact solution, but when IoPageRead gets a miss,
    //  it cannot tell whether it was CcCopyRead or CcMdlRead, but since
    //  the miss should occur very soon, by loading the pointer here
    //  probably the right counter will get incremented, and in any case,
    //  we hope the errrors average out!
    //

    CcMissCounter = &CcMdlReadWaitMiss;

    FOffset = *FileOffset;

    //
    //  Check for read past file size, the caller must filter this case out.
    //

    ASSERT( ( FOffset.QuadPart + (LONGLONG)Length ) <= SharedCacheMap->FileSize.QuadPart );

    //
    //  Put try-finally around the loop to deal with any exceptions
    //

    try {

        //
        //  Not all of the transfer will come back at once, so we have to loop
        //  until the entire transfer is complete.
        //

        while (Length != 0) {

            ULONG ReceivedLength;
            LARGE_INTEGER BeyondLastByte;

            //
            //  Map the data and read it in (if necessary) with the
            //  MmProbeAndLockPages call below.
            //

            CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                               FOffset,
                                               &Vacb,
                                               &ReceivedLength );

            if (ReceivedLength > Length) {
                ReceivedLength = Length;
            }

            BeyondLastByte.QuadPart = FOffset.QuadPart + (LONGLONG)ReceivedLength;

            //
            //  Now attempt to allocate an Mdl to describe the mapped data.
            //

            DebugTrace( 0, mm, "IoAllocateMdl:\n", 0 );
            DebugTrace( 0, mm, "    BaseAddress = %08lx\n", CacheBuffer );
            DebugTrace( 0, mm, "    Length = %08lx\n", ReceivedLength );

            Mdl = IoAllocateMdl( CacheBuffer,
                                 ReceivedLength,
                                 FALSE,
                                 FALSE,
                                 NULL );

            DebugTrace( 0, mm, "    <Mdl = %08lx\n", Mdl );

            if (Mdl == NULL) {
                DebugTrace( 0, 0, "Failed to allocate Mdl\n", 0 );

                ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
            }

            DebugTrace( 0, mm, "MmProbeAndLockPages:\n", 0 );
            DebugTrace( 0, mm, "    Mdl = %08lx\n", Mdl );

            //
            //  Set to see if the miss counter changes in order to
            //  detect when we should turn on read ahead.
            //

            SavedMissCounter += CcMdlReadWaitMiss;

            MmSetPageFaultReadAhead( Thread, ADDRESS_AND_SIZE_TO_SPAN_PAGES( CacheBuffer, ReceivedLength ) - 1);
            MmProbeAndLockPages( Mdl, KernelMode, IoReadAccess );

            SavedMissCounter -= CcMdlReadWaitMiss;

            //
            //  Unmap the data now, now that the pages are locked down.
            //

            CcFreeVirtualAddress( Vacb );
            Vacb = NULL;

            //
            //  Now link the Mdl into the caller's chain
            //

            if ( *MdlChain == NULL ) {
                *MdlChain = Mdl;
            } else {
                MdlTemp = CONTAINING_RECORD( *MdlChain, MDL, Next );
                while (MdlTemp->Next != NULL) {
                    MdlTemp = MdlTemp->Next;
                }
                MdlTemp->Next = Mdl;
            }
            Mdl = NULL;

            //
            //  Assume we did not get all the data we wanted, and set FOffset
            //  to the end of the returned data.
            //

            FOffset = BeyondLastByte;

            //
            //  Update number of bytes transferred.
            //

            Information += ReceivedLength;

            //
            //  Calculate length left to transfer.
            //

            Length -= ReceivedLength;
        }
    }
    finally {

        CcMissCounter = &CcThrowAway;

        //
        //  Restore the readahead hints.
        //

        MmResetPageFaultReadAhead( Thread, SavedState );

        if (AbnormalTermination()) {

            //
            //  We may have failed to allocate an Mdl while still having
            //  data mapped.
            //

            if (Vacb != NULL) {
                CcFreeVirtualAddress( Vacb );
            }

            if (Mdl != NULL) {
                IoFreeMdl( Mdl );
            }

            //
            //  Otherwise loop to deallocate the Mdls
            //

            while (*MdlChain != NULL) {
                MdlTemp = (*MdlChain)->Next;

                DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
                DebugTrace( 0, mm, "    Mdl = %08lx\n", *MdlChain );

                MmUnlockPages( *MdlChain );
                IoFreeMdl( *MdlChain );

                *MdlChain = MdlTemp;
            }

            DebugTrace(-1, me, "CcMdlRead -> Unwinding\n", 0 );

        }
        else {

            //
            //  Now enable read ahead if it looks like we got any misses, and do
            //  the first one.
            //

            if (!FlagOn( FileObject->Flags, FO_RANDOM_ACCESS ) &&
                !PrivateCacheMap->Flags.ReadAheadEnabled &&
                (SavedMissCounter != 0)) {

                CC_SET_PRIVATE_CACHE_MAP (PrivateCacheMap, PRIVATE_CACHE_MAP_READ_AHEAD_ENABLED);
                CcScheduleReadAhead( FileObject, FileOffset, OriginalLength );
            }

            //
            //  Now that we have described our desired read ahead, let's
            //  shift the read history down.
            //

            PrivateCacheMap->FileOffset1 = PrivateCacheMap->FileOffset2;
            PrivateCacheMap->BeyondLastByte1 = PrivateCacheMap->BeyondLastByte2;
            PrivateCacheMap->FileOffset2 = *FileOffset;
            PrivateCacheMap->BeyondLastByte2.QuadPart =
                                FileOffset->QuadPart + (LONGLONG)OriginalLength;

            IoStatus->Status = STATUS_SUCCESS;
            IoStatus->Information = Information;
        }
    }


    DebugTrace( 0, me, "    <MdlChain = %08lx\n", *MdlChain );
    DebugTrace2(0, me, "    <IoStatus = %08lx, %08lx\n", IoStatus->Status,
                                                         IoStatus->Information );
    DebugTrace(-1, me, "CcMdlRead -> VOID\n", 0 );

    return;
}


//
//  First we have the old routine which checks for an entry in the FastIo vector.
//  This routine becomes obsolete for every component that compiles with the new
//  definition of FsRtlMdlReadComplete in fsrtl.h.
//

VOID
CcMdlReadComplete (
    IN PFILE_OBJECT FileObject,
    IN PMDL MdlChain
    )

{
    PDEVICE_OBJECT DeviceObject;
    PFAST_IO_DISPATCH FastIoDispatch;

    DeviceObject = IoGetRelatedDeviceObject( FileObject );
    FastIoDispatch = DeviceObject->DriverObject->FastIoDispatch;

    if ((FastIoDispatch != NULL) &&
        (FastIoDispatch->SizeOfFastIoDispatch > FIELD_OFFSET(FAST_IO_DISPATCH, MdlWriteComplete)) &&
        (FastIoDispatch->MdlReadComplete != NULL) &&
        FastIoDispatch->MdlReadComplete( FileObject, MdlChain, DeviceObject )) {

        NOTHING;

    } else {
        CcMdlReadComplete2( FileObject, MdlChain );
    }
}

VOID
CcMdlReadComplete2 (
    IN PFILE_OBJECT FileObject,
    IN PMDL MdlChain
    )

/*++

Routine Description:

    This routine must be called at IPL0 after a call to CcMdlRead.  The
    caller must simply supply the address of the MdlChain returned in
    CcMdlRead.

    This call does the following:

        Deletes the MdlChain

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    MdlChain - same as returned from corresponding call to CcMdlRead.

Return Value:

    None.
--*/

{
    PMDL MdlNext;

    UNREFERENCED_PARAMETER (FileObject);

    DebugTrace(+1, me, "CcMdlReadComplete\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    MdlChain = %08lx\n", MdlChain );

    //
    //  Deallocate the Mdls
    //

    while (MdlChain != NULL) {

        MdlNext = MdlChain->Next;

        DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
        DebugTrace( 0, mm, "    Mdl = %08lx\n", MdlChain );

        MmUnlockPages( MdlChain );

        IoFreeMdl( MdlChain );

        MdlChain = MdlNext;
    }

    DebugTrace(-1, me, "CcMdlReadComplete -> VOID\n", 0 );
}


VOID
CcPrepareMdlWrite (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN ULONG Length,
    OUT PMDL *MdlChain,
    OUT PIO_STATUS_BLOCK IoStatus
    )

/*++

Routine Description:

    This routine attempts to lock the specified file data in the cache
    and return a description of it in an Mdl along with the correct
    I/O status.  Pages to be completely overwritten may be satisfied
    with emtpy pages.  It is *not* safe to call this routine from Dpc level.

    This call is synchronous and raises on error.

    When this call returns, the caller may immediately begin
    to transfer data into the buffers via the Mdl.

    When the call returns with TRUE, the pages described by the Mdl are
    locked in memory, but not mapped in system space.  If the caller
    needs the pages mapped in system space, then it must map them.
    On the subsequent call to CcMdlWriteComplete the pages will be
    unmapped if they were mapped, and in any case unlocked and the Mdl
    deallocated.

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Byte offset in file for desired data.

    Length - Length of desired data in bytes.

    MdlChain - On output it returns a pointer to an Mdl chain describing
               the desired data.  Note that even if FALSE is returned,
               one or more Mdls may have been allocated, as may be ascertained
               by the IoStatus.Information field (see below).

    IoStatus - Pointer to standard I/O status block to receive the status
               for the in-transfer of the data.  (STATUS_SUCCESS guaranteed
               for cache hits, otherwise the actual I/O status is returned.)
               The I/O Information Field indicates how many bytes have been
               successfully locked down in the Mdl Chain.

Return Value:

    None

--*/

{
    PSHARED_CACHE_MAP SharedCacheMap;
    PVOID CacheBuffer;
    LARGE_INTEGER FOffset;
    PMDL Mdl = NULL;
    PMDL MdlTemp;
    LARGE_INTEGER Temp;
    ULONG SavedState = 0;
    ULONG ZeroFlags = 0;
    ULONG Information = 0;

    KLOCK_QUEUE_HANDLE LockHandle;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB Vacb = NULL;

    DebugTrace(+1, me, "CcPrepareMdlWrite\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace2(0, me, "    FileOffset = %08lx, %08lx\n", FileOffset->LowPart,
                                                          FileOffset->HighPart );
    DebugTrace( 0, me, "    Length = %08lx\n", Length );

    //
    //  Get pointer to SharedCacheMap.
    //

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  See if we have an active Vacb, that we need to free.
    //

    GetActiveVacb( SharedCacheMap, LockHandle.OldIrql, Vacb, ActivePage, PageIsDirty );

    //
    //  If there is an end of a page to be zeroed, then free that page now,
    //  so it does not cause our data to get zeroed.  If there is an active
    //  page, free it so we have the correct ValidDataGoal.
    //

    if ((Vacb != NULL) || (SharedCacheMap->NeedToZero != NULL)) {

        CcFreeActiveVacb( SharedCacheMap, Vacb, ActivePage, PageIsDirty );
        Vacb = NULL;
    }

    FOffset = *FileOffset;

    //
    //  Put try-finally around the loop to deal with exceptions
    //

    try {

        //
        //  Not all of the transfer will come back at once, so we have to loop
        //  until the entire transfer is complete.
        //

        while (Length != 0) {

            ULONG ReceivedLength;
            LARGE_INTEGER BeyondLastByte;

            //
            //  Map and see how much we could potentially access at this
            //  FileOffset, then cut it down if it is more than we need.
            //

            CacheBuffer = CcGetVirtualAddress( SharedCacheMap,
                                               FOffset,
                                               &Vacb,
                                               &ReceivedLength );

            if (ReceivedLength > Length) {
                ReceivedLength = Length;
            }

            BeyondLastByte.QuadPart = FOffset.QuadPart + (LONGLONG)ReceivedLength;

            //
            //  At this point we can calculate the ZeroFlags.
            //

            //
            //  We can always zero middle pages, if any.
            //

            ZeroFlags = ZERO_MIDDLE_PAGES;

            //
            //  See if we are completely overwriting the first or last page.
            //

            if (((FOffset.LowPart & (PAGE_SIZE - 1)) == 0) &&
                (ReceivedLength >= PAGE_SIZE)) {
                ZeroFlags |= ZERO_FIRST_PAGE;
            }

            if ((BeyondLastByte.LowPart & (PAGE_SIZE - 1)) == 0) {
                ZeroFlags |= ZERO_LAST_PAGE;
            }

            //
            //  See if the entire transfer is beyond valid data length,
            //  or at least starting from the second page.
            //

            Temp = FOffset;
            Temp.LowPart &= ~(PAGE_SIZE -1);
            KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
            Temp.QuadPart = SharedCacheMap->ValidDataGoal.QuadPart - Temp.QuadPart;
            KeReleaseInStackQueuedSpinLock( &LockHandle );

            if (Temp.QuadPart <= 0) {
                ZeroFlags |= ZERO_FIRST_PAGE | ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
            } else if ((Temp.HighPart == 0) && (Temp.LowPart <= PAGE_SIZE)) {
                ZeroFlags |= ZERO_MIDDLE_PAGES | ZERO_LAST_PAGE;
            }

            (VOID)CcMapAndRead( SharedCacheMap,
                                &FOffset,
                                ReceivedLength,
                                ZeroFlags,
                                TRUE,
                                CacheBuffer );

            //
            //  Now attempt to allocate an Mdl to describe the mapped data.
            //

            DebugTrace( 0, mm, "IoAllocateMdl:\n", 0 );
            DebugTrace( 0, mm, "    BaseAddress = %08lx\n", CacheBuffer );
            DebugTrace( 0, mm, "    Length = %08lx\n", ReceivedLength );

            Mdl = IoAllocateMdl( CacheBuffer,
                                 ReceivedLength,
                                 FALSE,
                                 FALSE,
                                 NULL );

            DebugTrace( 0, mm, "    <Mdl = %08lx\n", Mdl );

            if (Mdl == NULL) {
                DebugTrace( 0, 0, "Failed to allocate Mdl\n", 0 );

                ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
            }

            DebugTrace( 0, mm, "MmProbeAndLockPages:\n", 0 );
            DebugTrace( 0, mm, "    Mdl = %08lx\n", Mdl );

            MmDisablePageFaultClustering(&SavedState);
            MmProbeAndLockPages( Mdl, KernelMode, IoWriteAccess );
            MmEnablePageFaultClustering(SavedState);
            SavedState = 0;

            //
            //  Now that some data (maybe zeros) is locked in memory and
            //  set dirty, it is safe, and necessary for us to advance
            //  valid data goal, so that we will not subsequently ask
            //  for a zero page.  Note if we are extending valid data,
            //  our caller has the file exclusive.
            //

            KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
            if (BeyondLastByte.QuadPart > SharedCacheMap->ValidDataGoal.QuadPart) {
                SharedCacheMap->ValidDataGoal = BeyondLastByte;
            }
            KeReleaseInStackQueuedSpinLock( &LockHandle );

            //
            //  Unmap the data now, now that the pages are locked down.
            //

            CcFreeVirtualAddress( Vacb );
            Vacb = NULL;

            //
            //  Now link the Mdl into the caller's chain
            //

            if ( *MdlChain == NULL ) {
                *MdlChain = Mdl;
            } else {
                MdlTemp = CONTAINING_RECORD( *MdlChain, MDL, Next );
                while (MdlTemp->Next != NULL) {
                    MdlTemp = MdlTemp->Next;
                }
                MdlTemp->Next = Mdl;
            }
            Mdl = NULL;

            //
            //  Assume we did not get all the data we wanted, and set FOffset
            //  to the end of the returned data.
            //

            FOffset = BeyondLastByte;

            //
            //  Update number of bytes transferred.
            //

            Information += ReceivedLength;

            //
            //  Calculate length left to transfer.
            //

            Length -= ReceivedLength;
        }
    }
    finally {

        if (AbnormalTermination()) {

            if (SavedState != 0) {
                MmEnablePageFaultClustering(SavedState);
            }

            if (Vacb != NULL) {
                CcFreeVirtualAddress( Vacb );
            }

            if (Mdl != NULL) {
                IoFreeMdl( Mdl );
            }

            //
            //  Otherwise loop to deallocate the Mdls
            //

            FOffset = *FileOffset;
            while (*MdlChain != NULL) {
                MdlTemp = (*MdlChain)->Next;

                DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
                DebugTrace( 0, mm, "    Mdl = %08lx\n", *MdlChain );

                MmUnlockPages( *MdlChain );

                //
                //  Extract the File Offset for this part of the transfer, and
                //  tell the lazy writer to write these pages, since we have
                //  marked them dirty.  Ignore the only exception (allocation
                //  error), and console ourselves for having tried.
                //

                CcSetDirtyInMask( SharedCacheMap, &FOffset, (*MdlChain)->ByteCount );

                FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)((*MdlChain)->ByteCount);

                IoFreeMdl( *MdlChain );

                *MdlChain = MdlTemp;
            }

            DebugTrace(-1, me, "CcPrepareMdlWrite -> Unwinding\n", 0 );
        }
        else {

            IoStatus->Status = STATUS_SUCCESS;
            IoStatus->Information = Information;

            //
            //  Make sure the SharedCacheMap does not go away while
            //  the Mdl write is in progress.  We decrment below.
            //

            CcAcquireMasterLock( &LockHandle.OldIrql );
            CcIncrementOpenCount( SharedCacheMap, 'ldmP' );
            CcReleaseMasterLock( LockHandle.OldIrql );
        }
    }

    DebugTrace( 0, me, "    <MdlChain = %08lx\n", *MdlChain );
    DebugTrace(-1, me, "CcPrepareMdlWrite -> VOID\n", 0 );

    return;
}


//
//  First we have the old routine which checks for an entry in the FastIo vector.
//  This routine becomes obsolete for every component that compiles with the new
//  definition of FsRtlMdlWriteComplete in fsrtl.h.
//

VOID
CcMdlWriteComplete (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN PMDL MdlChain
    )

{
    PDEVICE_OBJECT DeviceObject;
    PFAST_IO_DISPATCH FastIoDispatch;

    DeviceObject = IoGetRelatedDeviceObject( FileObject );
    FastIoDispatch = DeviceObject->DriverObject->FastIoDispatch;

    if ((FastIoDispatch != NULL) &&
        (FastIoDispatch->SizeOfFastIoDispatch > FIELD_OFFSET(FAST_IO_DISPATCH, MdlWriteComplete)) &&
        (FastIoDispatch->MdlWriteComplete != NULL) &&
        FastIoDispatch->MdlWriteComplete( FileObject, FileOffset, MdlChain, DeviceObject )) {

        NOTHING;

    } else {
        CcMdlWriteComplete2( FileObject, FileOffset, MdlChain );
    }
}

VOID
CcMdlWriteComplete2 (
    IN PFILE_OBJECT FileObject,
    IN PLARGE_INTEGER FileOffset,
    IN PMDL MdlChain
    )

/*++

Routine Description:

    This routine must be called at IPL0 after a call to CcPrepareMdlWrite.
    The caller supplies the ActualLength of data that it actually wrote
    into the buffer, which may be less than or equal to the Length specified
    in CcPrepareMdlWrite.

    This call does the following:

        Makes sure the data up to ActualLength eventually gets written.
        If WriteThrough is FALSE, the data will not be written immediately.
        If WriteThrough is TRUE, then the data is written synchronously.

        Unmaps the pages (if mapped), unlocks them and deletes the MdlChain

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    FileOffset - Original file offset read above.

    MdlChain - same as returned from corresponding call to CcPrepareMdlWrite.

Return Value:

    None

--*/

{
    PMDL MdlNext;
    PMDL Mdl;
    PSHARED_CACHE_MAP SharedCacheMap;
    LARGE_INTEGER FOffset;
    IO_STATUS_BLOCK IoStatus;
    KIRQL OldIrql;
    NTSTATUS StatusToRaise = STATUS_SUCCESS;
    BOOLEAN First = FALSE;

    DebugTrace(+1, me, "CcMdlWriteComplete\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    MdlChain = %08lx\n", MdlChain );

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  Deallocate the Mdls
    //

    FOffset.QuadPart = *(LONGLONG UNALIGNED *)FileOffset;
    Mdl = MdlChain;

    //
    //  If the MDL is unlocked, this is a retry.
    //
    
    if (FlagOn( MdlChain->MdlFlags, MDL_PAGES_LOCKED )) {
        First = TRUE;
    }
    
    while (Mdl != NULL) {

        MdlNext = Mdl->Next;

        DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
        DebugTrace( 0, mm, "    Mdl = %08lx\n", Mdl );

        //
        //  Now clear the dirty bits in the Pte and set them in the
        //  Pfn.  The Mdls will not be locked on repeated completion
        //  attempts.
        //

        if (First) {
            MmUnlockPages( Mdl );
        }

        //
        //  Extract the File Offset for this part of the transfer.
        //

        if (FlagOn(FileObject->Flags, FO_WRITE_THROUGH)) {

            MmFlushSection ( FileObject->SectionObjectPointer,
                             &FOffset,
                             Mdl->ByteCount,
                             &IoStatus,
                             TRUE );

            //
            //  If we got an I/O error, remember it.
            //

            if (!NT_SUCCESS(IoStatus.Status)) {
                StatusToRaise = IoStatus.Status;
            }

        } else {

            //
            //  Ignore the only exception (allocation error), and console
            //  ourselves for having tried.
            //

            CcSetDirtyInMask( SharedCacheMap, &FOffset, Mdl->ByteCount );
        }

        FOffset.QuadPart = FOffset.QuadPart + (LONGLONG)(Mdl->ByteCount);

        Mdl = MdlNext;
    }

    //
    //  Remove our open count and check to see if this makes the shared cache
    //  map eligible for lazy close.
    //
    //  We do this now so, on failure, old filesystems which did not expect
    //  writethrough to raise continue to work.  They will be within exception
    //  handling with the Mdl still in the IRP.
    //
    //  Note that non-writethrough is the only one that needs the cache map,
    //  and it'll always work.  Removing the open count for writethrough
    //  could be a minor win.
    //
    
    if (First) {
        
        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'ldmC' );

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }
    
    //
    //  If we got an I/O error, raise it now.  Note that we have not free'd the Mdl
    //  yet so the owning filesystem can retry the completion.
    //

    if (!NT_SUCCESS(StatusToRaise)) {
        ExRaiseStatus( FsRtlNormalizeNtstatus( StatusToRaise,
                                               STATUS_UNEXPECTED_IO_ERROR ));
    }

    //
    //  Otherwise, free the Mdl chain and clean everything up.
    //
    
    Mdl = MdlChain;
    while (Mdl != NULL) {

        MdlNext = Mdl->Next;
        IoFreeMdl( Mdl );
        Mdl = MdlNext;
    }

    DebugTrace(-1, me, "CcMdlWriteComplete -> TRUE\n", 0 );

    return;
}

VOID
CcMdlWriteAbort (
    IN PFILE_OBJECT FileObject,
    IN PMDL MdlChain
    )

/*++

Routine Description:

    This routine must be called at IPL0 after a call to CcPrepareMdlWrite.

    This call does the following:

        Unmaps the pages (if mapped), unlocks them and deletes the MdlChain
        unlike the CcMdlWriteComplete this is only used to do teardown in a non
        success case where we didn't actually write anything

Arguments:

    FileObject - Pointer to the file object for a file which was
                 opened with NO_INTERMEDIATE_BUFFERING clear, i.e., for
                 which CcInitializeCacheMap was called by the file system.

    MdlChain - same as returned from corresponding call to CcPrepareMdlWrite.

Return Value:

    None

--*/

{
    PMDL MdlNext;
    PSHARED_CACHE_MAP SharedCacheMap;
    KIRQL OldIrql;
    BOOLEAN First = FALSE;

    DebugTrace(+1, me, "CcMdlWriteAbort\n", 0 );
    DebugTrace( 0, me, "    FileObject = %08lx\n", FileObject );
    DebugTrace( 0, me, "    MdlChain = %08lx\n", MdlChain );

    SharedCacheMap = FileObject->SectionObjectPointer->SharedCacheMap;

    //
    //  If the MDL is unlocked, we went through completion.
    //
    
    if (FlagOn( MdlChain->MdlFlags, MDL_PAGES_LOCKED )) {
        First = TRUE;
    }
    
    //
    //  Deallocate the Mdls
    //

    while (MdlChain != NULL) {

        MdlNext = MdlChain->Next;

        DebugTrace( 0, mm, "MmUnlockPages/IoFreeMdl:\n", 0 );
        DebugTrace( 0, mm, "    Mdl = %08lx\n", MdlChain );

        if (First) {
            MmUnlockPages( MdlChain );
        }
        IoFreeMdl( MdlChain );
        MdlChain = MdlNext;
    }

    //
    //  Now release our open count.  If this already went through completion,
    //  the opencount is already dropped.
    //

    if (First) {
        
        CcAcquireMasterLock( &OldIrql );

        CcDecrementOpenCount( SharedCacheMap, 'AdmC' );

        //
        //  Check for a possible deletion, this Mdl write may have been the last
        //  reference.
        //

        if ((SharedCacheMap->OpenCount == 0) &&
            !FlagOn(SharedCacheMap->Flags, WRITE_QUEUED) &&
            (SharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &SharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &SharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( OldIrql );
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\prefetch.c ===
/*++

Copyright (c) 1999 Microsoft Corporation

Module Name:

    prefetch.c

Abstract:

    This module contains the prefetcher for optimizing demand
    paging. Page faults for a scenario are logged and the next time
    scenario starts, these pages are prefetched efficiently via
    asynchronous paging I/O.

Author:

    Arthur Zwiegincew (arthurz) 13-May-1999
    Stuart Sechrest (stuartse)  15-Jul-1999
    Chuck Lenzmeier (chuckl)    15-Mar-2000
    Cenk Ergan (cenke)          15-Mar-2000

Revision History:

--*/

#include "cc.h"
#include "zwapi.h"
#include "prefetch.h"
#include "preftchp.h"
#include "stdio.h"
#include "stdlib.h"

//
// Mark pagable routines to save footprint.
//

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT, CcPfInitializePrefetcher)
#pragma alloc_text(PAGE, CcPfBeginAppLaunch)
#pragma alloc_text(PAGE, CcPfBeginTrace)
#pragma alloc_text(PAGE, CcPfGetPrefetchInstructions)
#pragma alloc_text(PAGE, CcPfQueryScenarioInformation)
#pragma alloc_text(PAGE, CcPfPrefetchFileMetadata)
#pragma alloc_text(PAGE, CcPfPrefetchDirectoryContents)
#pragma alloc_text(PAGE, CcPfPrefetchMetadata)
#pragma alloc_text(PAGE, CcPfPrefetchScenario)
#pragma alloc_text(PAGE, CcPfPrefetchSections)
#pragma alloc_text(PAGE, CcPfOpenVolumesForPrefetch)
#pragma alloc_text(PAGE, CcPfFindPrefetchVolumeInfoInList)
#pragma alloc_text(PAGE, CcPfUpdateVolumeList)
#pragma alloc_text(PAGE, CcPfFindString)
#pragma alloc_text(PAGE, CcPfIsVolumeMounted)
#pragma alloc_text(PAGE, CcPfQueryVolumeInfo)
#pragma alloc_text(PAGE, CcPfEndTrace)
#pragma alloc_text(PAGE, CcPfBuildDumpFromTrace)
#pragma alloc_text(PAGE, CcPfCleanupTrace)
#pragma alloc_text(PAGE, CcPfInitializePrefetchHeader)
#pragma alloc_text(PAGE, CcPfCleanupPrefetchHeader)
#pragma alloc_text(PAGE, CcPfEndTraceWorkerThreadRoutine)
#pragma alloc_text(PAGE, CcPfInitializeRefCount)
#pragma alloc_text(PAGE, CcPfAcquireExclusiveRef)
#pragma alloc_text(PAGE, CcPfGetSectionObject)
#pragma alloc_text(PAGE, CcPfScanCommandLine)
#pragma alloc_text(PAGE, CcPfGetCompletedTrace)
#pragma alloc_text(PAGE, CcPfGetFileNamesWorkerRoutine)
#pragma alloc_text(PAGE, CcPfSetPrefetcherInformation)
#pragma alloc_text(PAGE, CcPfQueryPrefetcherInformation)
#pragma alloc_text(PAGE, CcPfProcessExitNotification)
#pragma alloc_text(PAGE, PfWithinBounds)
#pragma alloc_text(PAGE, PfVerifyScenarioId)
#pragma alloc_text(PAGE, PfVerifyScenarioBuffer)
#pragma alloc_text(PAGE, PfVerifyTraceBuffer)
#endif

//
// Globals:
//

//
// Whether prefetching is enabled.
//

LOGICAL CcPfEnablePrefetcher = 0;

//
// Number of active prefetcher traces.
//

LONG CcPfNumActiveTraces = 0;

//
// This structure contains prefetcher globals except the ones above
// that are accessed by other kernel components. It is important that
// this structure is initialized to zeros.
//

CCPF_PREFETCHER_GLOBALS CcPfGlobals = {0};

//
// Routines exported to other kernel components:
//
 
NTSTATUS
CcPfInitializePrefetcher(
    VOID
    )

/*++

Routine Description:

    This routine is called to initialize the prefetcher. 

Arguments:

    None.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

Notes:

    The code & local constants for this function gets discarded after system boots.   

--*/

{   
    DBGPR((CCPFID,PFTRC,"CCPF: InitializePrefetcher()\n"));

    //
    // Since CcPfGlobals is zeroed in its global definition e.g. CcPfGlobals = {0};
    // we don't have to initialize:
    //
    // NumCompletedTraces
    // CompletedTracesEvent
    //

    //
    // Initialize the active traces list and lock.
    //

    InitializeListHead(&CcPfGlobals.ActiveTraces);
    KeInitializeSpinLock(&CcPfGlobals.ActiveTracesLock);

    //
    // Initialize list of saved completed prefetch traces and its lock.
    //

    InitializeListHead(&CcPfGlobals.CompletedTraces);
    ExInitializeFastMutex(&CcPfGlobals.CompletedTracesLock);

    //
    // Initialize prefetcher parameters.
    //

    CcPfParametersInitialize(&CcPfGlobals.Parameters);
    
    //
    // Determine from the global parameters if the prefetcher is
    // enabled and update the global enable status.
    //

    CcPfDetermineEnablePrefetcher();

    //
    // Fall through with status.
    //

    return STATUS_SUCCESS;
}

NTSTATUS
CcPfBeginAppLaunch(
    PEPROCESS Process,
    PVOID Section
    )

/*++

Routine Description:

    This routine is called when the first user thread is starting up
    in the process. It may attempt to access the PEB for the command 
    line parameters.

Arguments:

    Process - Pointer to new process created for the application.

    Section - Pointer to section mapped to newly created process.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    LARGE_INTEGER CurrentTime;
    LARGE_INTEGER TimeSinceLastLaunch;
    PPF_SCENARIO_HEADER Scenario;
    NTSTATUS Status;
    PF_SCENARIO_ID ScenarioId;
    ULONG NameNumChars;
    ULONG PathNumChars;
    WCHAR *CurCharPtr;
    WCHAR *FileNamePtr;
    PULONG CommandLineHashId;
    ULONG NumCharsToCopy;
    ULONG CharIdx;
    STRING AnsiFilePath;
    UNICODE_STRING FilePath;
    ULONG HashId;
    ULONG PrefetchHint;
    BOOLEAN AllocatedUnicodePath;
    BOOLEAN ShouldTraceScenario;
    BOOLEAN IsHostingApplication;

    DBGPR((CCPFID,PFTRC,"CCPF: BeginAppLaunch()\n"));
    
    //
    // Initialize locals.
    //

    AllocatedUnicodePath = FALSE;
    Scenario = NULL;

    //
    // Check to see if the prefetcher is enabled.
    //

    if (!CCPF_IS_PREFETCHER_ENABLED()) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }
    
    //
    // Check if prefetching is enabled for application launches.
    //

    if (CcPfGlobals.Parameters.Parameters.EnableStatus[PfApplicationLaunchScenarioType] != PfSvEnabled) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Don't prefetch or start tracing if there is an active system-wide trace.
    //

    if (CcPfGlobals.SystemWideTrace != NULL) {
        Status = STATUS_USER_EXISTS;
        goto cleanup;
    }

    //
    // Query name from the section. Unfortunately this returns us an
    // ANSI string which we then have to convert back to UNICODE. We
    // have to it this way for now because we could not add an API to
    // Mm.
    //

    Status = MmGetFileNameForSection(Section, &AnsiFilePath);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Convert ANSI path to UNICODE path.
    //
    
    Status = RtlAnsiStringToUnicodeString(&FilePath, &AnsiFilePath, TRUE);
    
    //
    // Don't leak the ANSI buffer...
    //

    ExFreePool (AnsiFilePath.Buffer);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    AllocatedUnicodePath = TRUE;

    //
    // Scenario Id requires us to be case insensitive.
    //
       
    RtlUpcaseUnicodeString(&FilePath, &FilePath, FALSE);
    
    //
    // We need to copy just the real file name into the scenario
    // name. Make a first pass to calculate the size of real file
    // name.
    //

    NameNumChars = 0;
    PathNumChars = FilePath.Length / sizeof(WCHAR);
    
    for (CurCharPtr = &FilePath.Buffer[PathNumChars - 1];
         CurCharPtr >= FilePath.Buffer;
         CurCharPtr--) {

        if (*CurCharPtr == L'\\') {
            break;
        }

        NameNumChars++;
    }

    //
    // Check if we got a name.
    //

    if (NameNumChars == 0) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Set pointer to where file name begins.
    //

    FileNamePtr = &FilePath.Buffer[PathNumChars - NameNumChars];

    //
    // Copy up to PF_SCEN_ID_MAX_CHARS characters into the scenario
    // name buffer.
    //

    NumCharsToCopy = CCPF_MIN(PF_SCEN_ID_MAX_CHARS, NameNumChars);

    for (CharIdx = 0; CharIdx < NumCharsToCopy; CharIdx++) {
        
        ScenarioId.ScenName[CharIdx] = FileNamePtr[CharIdx];
    }

    //
    // Make sure scenario name is NUL terminated.
    //

    ScenarioId.ScenName[NumCharsToCopy] = 0;

    //
    // Calculate scenario hash id from the full path name.
    //

    ScenarioId.HashId = CcPfHashValue(FilePath.Buffer,
                                      FilePath.Length);


    //
    // If this is a "hosting" application (e.g. dllhost, rundll32, mmc)
    // we want to have unique scenarios based on the command line, so 
    // we update the hash id.
    //

    IsHostingApplication = CcPfIsHostingApplication(ScenarioId.ScenName);

    if (IsHostingApplication) {
        CommandLineHashId = &HashId;
    } else {
        CommandLineHashId = NULL;
    }

    //
    // Scan the command line for this process, calculating a hash if
    // requested and checking for a prefetch hint.
    //

    Status = CcPfScanCommandLine(&PrefetchHint, CommandLineHashId);

    if (!NT_SUCCESS(Status)) {

        //
        // If we failed to access the PEB to get the command line,
        // the process may be exiting etc. Do not continue.
        //

        goto cleanup;
    }

    if (IsHostingApplication) {

        //
        // Update the hash ID calculated from full path name.
        //

        ScenarioId.HashId += HashId;
    }

    //
    // If there is a specific hint in the command line add it to the 
    // hash id to make it a unique scenario.
    //
        
    ScenarioId.HashId += PrefetchHint;

    //
    // Get prefetch instructions for this scenario. If there are
    // instructions we will use them to determine whether we should
    // prefetch and/or trace this scenario. By default we will trace
    // the scenario even if there are no instructions.
    //

    ShouldTraceScenario = TRUE;

    Status = CcPfGetPrefetchInstructions(&ScenarioId,
                                         PfApplicationLaunchScenarioType,
                                         &Scenario);

    if (NT_SUCCESS(Status)) {

        CCPF_ASSERT(Scenario);

        //
        // Determine how much time has passed since the last launch
        // for which instructions were updated. Note that the way
        // checks are done below we will recover after a while if the
        // user changes the system time.
        //
        
        KeQuerySystemTime(&CurrentTime);
        TimeSinceLastLaunch.QuadPart = CurrentTime.QuadPart - Scenario->LastLaunchTime.QuadPart;

        if (TimeSinceLastLaunch.QuadPart >= Scenario->MinRePrefetchTime.QuadPart) {
            Status = CcPfPrefetchScenario(Scenario);
        } else {
            DBGPR((CCPFID,PFPREF,"CCPF: BeginAppLaunch-NotRePrefetching\n"));
        }

        if (TimeSinceLastLaunch.QuadPart < Scenario->MinReTraceTime.QuadPart) {
            DBGPR((CCPFID,PFPREF,"CCPF: BeginAppLaunch-NotReTracing\n"));
            ShouldTraceScenario = FALSE;
        }
    }

    if (ShouldTraceScenario) {

        //
        // Start tracing the application launch. Fall through with status.
        // The trace will end when we time out or when the process
        // terminates.
        //
    
        Status = CcPfBeginTrace(&ScenarioId, 
                                PfApplicationLaunchScenarioType,
                                Process);
    }

    //
    // We will fall through with either the status from
    // CcPfGetPrefetchInstructions, CcPfPrefetchScenario or
    // CcPfBeginTrace.
    //

 cleanup:

    if (AllocatedUnicodePath) {
        RtlFreeUnicodeString(&FilePath);
    }

    if (Scenario) {
        ExFreePool(Scenario);
    }

    DBGPR((CCPFID,PFTRC,"CCPF: BeginAppLaunch()=%x\n", Status));

    return Status;
}

NTSTATUS
CcPfProcessExitNotification(
    PEPROCESS Process
    )

/*++

Routine Description:

    This routine gets called when a process is exiting while there are
    active prefetch traces. It checks for active traces that are
    associated with this process, and makes sure they don't stay
    around much longer.

Arguments:

    Process - Process that is terminating.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_HEADER Trace;
   
    DBGPR((CCPFID,PFTRC,"CCPF: ProcessExit(%p)\n", Process));

    //
    // Validate parameters. We should have been called with a valid
    // process.
    //

    CCPF_ASSERT(Process);

    //
    // Get the trace associated with this process if any.
    //

    Trace = CcPfReferenceProcessTrace(Process);

    if (Trace) {

        if (!InterlockedCompareExchange(&Trace->EndTraceCalled, 1, 0)) {
        
            //
            // We set EndTraceCalled from 0 to 1. Queue the
            // workitem to end the trace.
            //
            
            ExQueueWorkItem(&Trace->EndTraceWorkItem, DelayedWorkQueue);
        }

        CcPfDecRef(&Trace->RefCount);
    }

    //
    // We are done.
    //
    
    return STATUS_SUCCESS;
}

VOID
CcPfLogPageFault(
    IN PFILE_OBJECT FileObject,
    IN ULONGLONG FileOffset,
    IN ULONG Flags
    )

/*++

Routine Description:

    This routine logs the specified page fault in appropriate prefetch
    traces.

Arguments:

    FileObject - Supplies the file object for the faulting address.

    FileOffset - Supplies the file offset for the faulting address.

    Flags - Supplies various bits indicating attributes of the fault.

Return Value:

    None.

Environment:

    Kernel mode. IRQL <= DISPATCH_LEVEL. 
    Uses interlocked slist operation.
    Acquires spinlock.

--*/

{
    PCCPF_TRACE_HEADER Trace;
    NTSTATUS Status;
    KIRQL OrigIrql;
    PSECTION_OBJECT_POINTERS SectionObjectPointer;
    LONG FoundIndex;
    LONG AvailIndex;
    PCCPF_SECTION_INFO SectionInfo;
    BOOLEAN IncrementedNumSections;
    LONG NewNumSections;
    LONG NewNumFaults;
    LONG NewNumEntries;
    ULONG NumHashLookups;
    PCCPF_LOG_ENTRIES TraceBuffer;
    PCCPF_LOG_ENTRIES NewTraceBuffer;
    PCCPF_LOG_ENTRY LogEntry;
    LONG MaxEntries;   
    PVPB Vpb;

    DBGPR((CCPFID,PFTRAC,"CCPF: LogPageFault(%p,%I64x,%x)\n", 
           FileObject, FileOffset, Flags));

    //
    // Get the trace associated with this process.
    //

    Trace = CcPfReferenceProcessTrace(PsGetCurrentProcess());

    //
    // If there is no trace associated with this process, see if there is
    // a system-wide trace.
    //

    if (Trace == NULL) {

        if (CcPfGlobals.SystemWideTrace) {

            Trace = CcPfReferenceProcessTrace(PsInitialSystemProcess);

            if (Trace) {

                CCPF_ASSERT(Trace == CcPfGlobals.SystemWideTrace);

            } else {

                Status = STATUS_NO_SUCH_MEMBER;
                goto cleanup;
            }

        } else {

            Status = STATUS_NO_SUCH_MEMBER;
            goto cleanup;
        }
    }

    //
    // Make sure the trace is really a trace.
    //

    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    //
    // Don't prefetch ROM-backed pages.
    //

    if (Flags & CCPF_TYPE_ROM) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Check file offset for this page fault. We don't support files >
    // 4GB for the prefetcher.
    //
       
    if (((PLARGE_INTEGER) &FileOffset)->HighPart != 0) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // If the volume this file object is on is not mounted, this is probably 
    // an internal file system file object we don't want to reference.
    // Remote file systems may have file objects for which the device object
    // does not have a VPB. We don't support prefetching on remote file
    // systems.
    //

    Vpb = FileObject->Vpb;

    if (!Vpb) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    if (!(Vpb->Flags & VPB_MOUNTED)) {
        Status = STATUS_DEVICE_NOT_READY;
        goto cleanup;
    }

    //
    // Check if the section in which we hit this pagefault is in the
    // hash for this trace [so we will have a file name for it]. If
    // not we will have to add it.
    //

    SectionObjectPointer = FileObject->SectionObjectPointer;

    NumHashLookups = 0;
    IncrementedNumSections = FALSE;

    do {
        
        FoundIndex = CcPfLookUpSection(Trace->SectionInfoTable,
                                       Trace->SectionTableSize,
                                       SectionObjectPointer,
                                       &AvailIndex);

        if (FoundIndex != CCPF_INVALID_TABLE_INDEX) {
            
            //
            // We found the section.
            //
            
            break;
        }

        if (AvailIndex == CCPF_INVALID_TABLE_INDEX) {

            //
            // We don't have room in the table for anything else. The
            // table is allocated so that SectionTableSize >
            // MaxSections. This should not be the case.
            //

            CCPF_ASSERT(FALSE);
            
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto cleanup;
        }

        //
        // We have to add the section. Before we compete for the
        // available index, check if we are allowed to have another
        // section.
        //

        if (!IncrementedNumSections) {

            NewNumSections = InterlockedIncrement(&Trace->NumSections);
            
            if (NewNumSections > Trace->MaxSections) {

                //
                // We cannot add any more sections to this trace. So
                // we cannot log this page fault.
                //

                InterlockedDecrement(&Trace->NumSections);

                Status = STATUS_INSUFFICIENT_RESOURCES;
                goto cleanup;
            }
            
            IncrementedNumSections = TRUE;
        }

        //
        // Try to get the available spot for ourselves.
        //
        
        SectionInfo = &Trace->SectionInfoTable[AvailIndex];

        if (!InterlockedCompareExchange(&SectionInfo->EntryValid, 1, 0)) {
            
            //
            // We have to be careful with how we are initializing the
            // new entry here. Don't forget, there are no locks.
            //

            //
            // EntryValid was 0 and we set it to 1. It is ours now.
            //

            //
            // First save the other fields of SectionObjectPointers. We check the
            // SectionObjectPointer first to find an entry in the hash.
            // 

            SectionInfo->DataSectionObject = SectionObjectPointer->DataSectionObject;
            SectionInfo->ImageSectionObject = SectionObjectPointer->ImageSectionObject;

            SectionInfo->SectionObjectPointer = SectionObjectPointer;

            //
            // In case we have to queue a worker to get the name for
            // this section, try to get another reference to the trace
            // up front. We already hold a reference so we don't have
            // to acquire any locks.
            //

            Status = CcPfAddRef(&Trace->RefCount);

            if (NT_SUCCESS(Status)) {

                //
                // Reference the file object, so it does not go away until
                // we get a name for it.
                //
                
                ObReferenceObject(FileObject);
                SectionInfo->ReferencedFileObject = FileObject;
                        
                //
                // Push this section into the list for which the worker
                // will get file names. Do this before checking to see if
                // a worker needs to be queued.
                //
                
                InterlockedPushEntrySList(&Trace->SectionsWithoutNamesList,
                                          &SectionInfo->GetNameLink);
                
                //
                // If there is not already a worker queued to get
                // names, queue one.
                // 
                
                if (!InterlockedCompareExchange(&Trace->GetFileNameWorkItemQueued, 
                                                1, 
                                                0)) {
                    
                    //
                    // Queue the worker.
                    //
                    
                    ExQueueWorkItem(&Trace->GetFileNameWorkItem, DelayedWorkQueue);
                    
                } else {

                    //
                    // Notify the event that an existing worker may be
                    // waiting on for new sections.
                    //
                    
                    KeSetEvent(&Trace->GetFileNameWorkerEvent,
                               IO_NO_INCREMENT,
                               FALSE);

                    //
                    // We don't need the reference since we did not
                    // queue a worker.
                    //

                    CcPfDecRef(&Trace->RefCount);
                }

            } else {

                //
                // We added the section but the trace has already
                // ended. We will not be able to get a file name for
                // this section. Fall through to log the entry. The
                // entry will be ignored though because its section
                // won't have a file name.
                //

            }

            //
            // Break out of the loop.
            //
            
            FoundIndex = AvailIndex;
            
            break;
        }

        //
        // We could not have filled up the table, because the table is
        // bigger than the maximum allowed size [MaxSections]
        //

        //
        // Please note that this assert is overactive.
        // Due to multiple InterlockedIncrements that haven't yet detected
        // the "num sections too big" condition, it is possible -- albeit
        // extremely unlikely -- that this assert could fire prematurely.
        // So if it fires, it is rather likely because something is wrong.
        //

        CCPF_ASSERT((ULONG) Trace->NumSections < Trace->SectionTableSize);
        
        //
        // Updated number of times we've looped. We should not have to
        // loop more than SectionTableSize. If there is a free entry,
        // we should have found it after that many lookups.
        //
            
        NumHashLookups++;

    } while (NumHashLookups < Trace->SectionTableSize);

    //
    // FoundIndex is set to the index of the section in the table.
    //

    if (FoundIndex == CCPF_INVALID_TABLE_INDEX) {
        CCPF_ASSERT(FoundIndex != CCPF_INVALID_TABLE_INDEX);
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // If the section is a metafile (e.g. directory) section, don't need to 
    // log more faults for it. We just need to know that we accessed it since
    // we can only prefetch all or nothing from metafile. Note that by the 
    // time we come here, the get-names worker may not have yet determined if 
    // this section is for a metafile. This is OK, because metafile sections
    // are not expected to have page faults logged for them, and if they have
    // that is handled too.
    //

    if (Trace->SectionInfoTable[FoundIndex].Metafile) {
        Status = STATUS_SUCCESS;
        goto cleanup;
    }

    //
    // See if we've already logged too many faults.
    //

    NewNumFaults = InterlockedIncrement(&Trace->NumFaults);

    //
    // If we are beyond bounds we cannot log anymore.
    //

    if (NewNumFaults > Trace->MaxFaults) {

        InterlockedDecrement(&Trace->NumFaults);

        //
        // Try to queue the end of trace workitem.
        //
        
        if (!Trace->EndTraceCalled &&
            !InterlockedCompareExchange(&Trace->EndTraceCalled, 1, 0)) {
            
            //
            // We set EndTraceCalled from 0 to 1. We can queue the
            // workitem now.
            //

            ExQueueWorkItem(&Trace->EndTraceWorkItem, DelayedWorkQueue);
        }

        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Get space for the entry we are going to log.
    //

    do {

        TraceBuffer = Trace->CurrentTraceBuffer;

        NewNumEntries = InterlockedIncrement(&TraceBuffer->NumEntries);
    
        //
        // If we are beyond bounds, try to allocate a new buffer.
        //
    
        if (NewNumEntries > TraceBuffer->MaxEntries) {

            InterlockedDecrement(&TraceBuffer->NumEntries);

            //
            // Allocate a new trace buffer.
            //

            MaxEntries = CCPF_TRACE_BUFFER_MAX_ENTRIES;
            NewTraceBuffer = ExAllocatePoolWithTag(NonPagedPool,
                                                   CCPF_TRACE_BUFFER_SIZE,
                                                   CCPF_ALLOC_TRCBUF_TAG);
            
            if (NewTraceBuffer == NULL) {

                //
                // Couldn't allocate a new buffer. Decrement the count
                // of logged faults and go away.
                //

                InterlockedDecrement(&Trace->NumFaults);
                Status = STATUS_INSUFFICIENT_RESOURCES;
                break;
            }

            //
            // Acquire the right to make trace buffer changes.
            //

            KeAcquireSpinLock(&Trace->TraceBufferSpinLock, &OrigIrql);

            //
            // If the trace buffer has already been changed, start over.
            //

            if (Trace->CurrentTraceBuffer != TraceBuffer) {
                KeReleaseSpinLock(&Trace->TraceBufferSpinLock, OrigIrql);
                ExFreePool(NewTraceBuffer);
                continue;
            }

            //
            // Number of entries field of the full trace buffer should
            // be equal to or greater than max entries, because
            // somebody may have bumped it just to see it can't log
            // its entry here. It should not be less than, however.
            //

            CCPF_ASSERT(TraceBuffer->NumEntries >= TraceBuffer->MaxEntries);

            //
            // Initialize the new trace buffer.
            //

            NewTraceBuffer->NumEntries = 0;
            NewTraceBuffer->MaxEntries = MaxEntries;

            //
            // Insert it at the end of buffers list.
            //

            InsertTailList(&Trace->TraceBuffersList,
                           &NewTraceBuffer->TraceBuffersLink);

            Trace->NumTraceBuffers++;

            //
            // Make it the current buffer.
            //

            Trace->CurrentTraceBuffer = NewTraceBuffer;

            //
            // Release the spinlock and start over.
            //

            KeReleaseSpinLock(&Trace->TraceBufferSpinLock, OrigIrql);
            continue;
        }

        LogEntry = &TraceBuffer->Entries[NewNumEntries - 1];
    
        LogEntry->FileOffset = (ULONG) FileOffset;
        LogEntry->SectionId = (USHORT) FoundIndex;
        LogEntry->IsImage = (Flags & CCPF_TYPE_IMAGE)? TRUE : FALSE;

        break;

    } while (TRUE);

    Status = STATUS_SUCCESS;

cleanup:

    if (Trace != NULL) {
        CcPfDecRef(&Trace->RefCount);
    }

    DBGPR((CCPFID,PFTRAC,"CCPF: LogPageFault()=%x\n", Status)); 

    return;
}

NTSTATUS
CcPfQueryPrefetcherInformation (
    IN SYSTEM_INFORMATION_CLASS SystemInformationClass,
    IN PVOID SystemInformation,
    IN ULONG SystemInformationLength,
    IN KPROCESSOR_MODE PreviousMode,
    OUT PULONG Length
    )

/*++

Routine Description:

    This routine gets called from NtQuerySystemInformation for
    prefetcher related queries.

Arguments:

    SystemInformationClass - The system information class about which
      to retrieve information.

    SystemInformation - A pointer to a buffer which receives the specified
      information.

    SystemInformationLength - Specifies the length in bytes of the system
      information buffer.    

    PreviousMode - Previous processor mode.

    Length - Size of data put into the embedded structure in 
      PrefetcherInformation.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PPREFETCHER_INFORMATION PrefetcherInformation;
    NTSTATUS Status;
    PF_SYSTEM_PREFETCH_PARAMETERS Temp;
    PKTHREAD CurrentThread;

    UNREFERENCED_PARAMETER (SystemInformationClass);

    DBGPR((CCPFID,PFTRC,"CCPF: QueryPrefetcherInformation()\n"));

    //
    // Check permissions.
    //

    if (!SeSinglePrivilegeCheck(SeProfileSingleProcessPrivilege,PreviousMode)) {
        Status = STATUS_ACCESS_DENIED;
        goto cleanup;
    }

    //
    // Check parameters.
    //

    if (SystemInformationLength != sizeof(PREFETCHER_INFORMATION)) {
        Status = STATUS_INFO_LENGTH_MISMATCH;
        goto cleanup;
    }

    PrefetcherInformation = SystemInformation;

    //
    // Verify version and magic.
    //

    if (PrefetcherInformation->Version != PF_CURRENT_VERSION ||
        PrefetcherInformation->Magic != PF_SYSINFO_MAGIC_NUMBER) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Process requested information class.
    //
        
    switch (PrefetcherInformation->PrefetcherInformationClass) {
    
    case PrefetcherRetrieveTrace:
        Status = CcPfGetCompletedTrace(PrefetcherInformation->PrefetcherInformation,
                                       PrefetcherInformation->PrefetcherInformationLength,
                                       Length);
        break;

    case PrefetcherSystemParameters:
        
        //
        // Make sure input buffer is big enough.
        //

        if (PrefetcherInformation->PrefetcherInformationLength != 
            sizeof(PF_SYSTEM_PREFETCH_PARAMETERS)) {
            Status = STATUS_BUFFER_TOO_SMALL;
            break;
        }

        //
        // Acquire parameters lock and copy current parameters into
        // user's buffer.
        //
        
        Status = STATUS_SUCCESS;

        CurrentThread = KeGetCurrentThread ();
        KeEnterCriticalRegionThread(CurrentThread);
        ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

        RtlCopyMemory(&Temp,
                      &CcPfGlobals.Parameters.Parameters,
                      sizeof(PF_SYSTEM_PREFETCH_PARAMETERS));            

        ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);

        try {

            //
            // If called from user-mode, probe whether it is safe to write 
            // to the pointer passed in.
            //
            
            if (PreviousMode != KernelMode) {
                ProbeForWriteSmallStructure(PrefetcherInformation->PrefetcherInformation, 
                                            sizeof(PF_SYSTEM_PREFETCH_PARAMETERS), 
                                            _alignof(PF_SYSTEM_PREFETCH_PARAMETERS));
            }

            RtlCopyMemory(PrefetcherInformation->PrefetcherInformation,
                          &Temp,
                          sizeof(PF_SYSTEM_PREFETCH_PARAMETERS));
            
        } except (EXCEPTION_EXECUTE_HANDLER) {

            Status = GetExceptionCode();
        }


        //
        // Set returned number of bytes.
        //

        if (NT_SUCCESS(Status)) {
            if (Length) {
                *Length = sizeof(PF_SYSTEM_PREFETCH_PARAMETERS);
            }
        }

        break;

    default:

        Status = STATUS_INVALID_INFO_CLASS;
    }

    //
    // Fall through with status from switch statement.
    //

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: QueryPrefetcherInformation()=%x\n", Status));

    return Status;
}

NTSTATUS
CcPfSetPrefetcherInformation (
    IN SYSTEM_INFORMATION_CLASS SystemInformationClass,
    IN PVOID SystemInformation,
    IN ULONG SystemInformationLength,
    IN KPROCESSOR_MODE PreviousMode
    )

/*++

Routine Description:

    This routine gets called from NtSetSystemInformation for
    prefetcher related settings.

Arguments:

    SystemInformationClass - The system information which is to be 
      modified.

    SystemInformation - A pointer to a buffer which contains the specified
      information.

    SystemInformationLength - Specifies the length in bytes of the system
      information buffer.    

    PreviousMode - Previous processor mode.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PPREFETCHER_INFORMATION PrefetcherInformation;
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters;
    PF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    NTSTATUS Status;
    PF_BOOT_PHASE_ID NewPhaseId;
    PKTHREAD CurrentThread;

    UNREFERENCED_PARAMETER (SystemInformationClass);

    DBGPR((CCPFID,PFTRC,"CCPF: SetPrefetcherInformation()\n"));

    //
    // Check permissions.
    //

    if (!SeSinglePrivilegeCheck(SeProfileSingleProcessPrivilege,PreviousMode)) {
        Status = STATUS_ACCESS_DENIED;
        goto cleanup;
    }

    //
    // Check parameters.
    //

    if (SystemInformationLength != sizeof(PREFETCHER_INFORMATION)) {
        Status = STATUS_INFO_LENGTH_MISMATCH;
        goto cleanup;
    }

    PrefetcherInformation = SystemInformation;

    //
    // Verify version and magic.
    //

    if (PrefetcherInformation->Version != PF_CURRENT_VERSION ||
        PrefetcherInformation->Magic != PF_SYSINFO_MAGIC_NUMBER) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Process requested information class.
    //

    switch (PrefetcherInformation->PrefetcherInformationClass) {
    
    case PrefetcherRetrieveTrace:
        Status = STATUS_INVALID_INFO_CLASS;
        break;

    case PrefetcherSystemParameters:
        
        //
        // Make sure input buffer is the right size.
        //

        if (PrefetcherInformation->PrefetcherInformationLength != 
            sizeof(PF_SYSTEM_PREFETCH_PARAMETERS)) {
            Status = STATUS_BUFFER_TOO_SMALL;
            break;
        }

        //
        // *Copy* the parameters, in case the caller changes them
        // beneath our feet to break us.
        //

        Status = STATUS_SUCCESS;

        try {

            //
            // If called from user-mode, probe whether it is safe to read
            // from the pointer passed in.
            //

            if (PreviousMode != KernelMode) {
                ProbeForReadSmallStructure(PrefetcherInformation->PrefetcherInformation,
                                           sizeof(PF_SYSTEM_PREFETCH_PARAMETERS),
                                           _alignof(PF_SYSTEM_PREFETCH_PARAMETERS));
            }

            RtlCopyMemory(&Parameters,
                          PrefetcherInformation->PrefetcherInformation,
                          sizeof(PF_SYSTEM_PREFETCH_PARAMETERS));

        } except (EXCEPTION_EXECUTE_HANDLER) {

            Status = GetExceptionCode();
        }

        if (!NT_SUCCESS(Status)) {
            break;
        }

        //
        // Verify new parameters.
        //
        
        Status = CcPfParametersVerify(&Parameters);

        if (!NT_SUCCESS(Status)) {
            break;
        }

        //
        // Acquire the parameters lock exclusive.
        //

        PrefetcherParameters = &CcPfGlobals.Parameters;

        CurrentThread = KeGetCurrentThread ();
        KeEnterCriticalRegionThread(CurrentThread);
        ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);
           
        //
        // Copy them over to our globals.
        //
        
        PrefetcherParameters->Parameters = Parameters;
        PrefetcherParameters->ParametersVersion++;

        //
        // Release the exclusive hold on parameters lock.
        //

        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
        
        //
        // Determine if prefetching is still enabled.
        //

        CcPfDetermineEnablePrefetcher();

        //
        // Set the event so the service queries for the latest
        // parameters.
        //
        
        CcPfParametersSetChangedEvent(PrefetcherParameters);
        
        //
        // If the parameters update was successful, update the registry.
        //
        
        Status = CcPfParametersSave(PrefetcherParameters);

        break;
    
    case PrefetcherBootPhase:
        
        //
        // This is called to notify the prefetcher that a new boot
        // phase has started. The new phase id is at PrefetcherInformation.
        //

        //
        // Check length of PrefetcherInformation.
        //

        if (PrefetcherInformation->PrefetcherInformationLength != sizeof(PF_BOOT_PHASE_ID)) {
            Status = STATUS_BUFFER_TOO_SMALL;
            break;
        }

        //
        // Get new phase id.
        //
        
        Status = STATUS_SUCCESS;
        
        try {

            //
            // If called from user-mode, probe whether it is safe to read
            // from the pointer passed in.
            //

            if (PreviousMode != KernelMode) {
                ProbeForReadSmallStructure(PrefetcherInformation->PrefetcherInformation,
                                           sizeof(PF_BOOT_PHASE_ID),
                                           _alignof(PF_BOOT_PHASE_ID));
            }

            NewPhaseId = *((PPF_BOOT_PHASE_ID)(PrefetcherInformation->PrefetcherInformation));

        } except (EXCEPTION_EXECUTE_HANDLER) {

            Status = GetExceptionCode();
        }

        if (NT_SUCCESS(Status)) {
            
            //
            // Call the function to note the new boot phase.
            //

            Status = CcPfBeginBootPhase(NewPhaseId);
        }

        break;

    default:

        Status = STATUS_INVALID_INFO_CLASS;
    }

    //
    // Fall through with status from the switch statement.
    //

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: SetPrefetcherInformation()=%x\n", Status));

    return Status;
}

//
// Internal prefetcher routines:
//

//
// Routines used in prefetch tracing.
//

NTSTATUS
CcPfBeginTrace(
    IN PF_SCENARIO_ID *ScenarioId,
    IN PF_SCENARIO_TYPE ScenarioType,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function is called to begin tracing for a prefetch scenario.

Arguments:

    ScenarioId - Identifier for the scenario.

    ScenarioType - Type of scenario.

    Process - The process new scenario is associated with.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_HEADER Trace;
    PPF_TRACE_LIMITS TraceLimits; 
    NTSTATUS Status;
    ULONG AllocationSize;
    ULONG SectionTableSize;
    LONG MaxEntries;
    
    //
    // Initialize locals.
    //
    
    Trace = NULL;

    DBGPR((CCPFID,PFTRC,"CCPF: BeginTrace()-%d-%d\n", 
           CcPfNumActiveTraces, CcPfGlobals.NumCompletedTraces));

    //
    // Check if prefetching is enabled.
    //
    
    if (!CCPF_IS_PREFETCHER_ENABLED()) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Make sure the scenario type is valid.
    // 

    if (ScenarioType < 0 || ScenarioType >= PfMaxScenarioType) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }
    
    //
    // Check if prefetching is enabled for the specified scenario type.
    //

    if (CcPfGlobals.Parameters.Parameters.EnableStatus[ScenarioType] != PfSvEnabled) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Check if a system-wide trace is active. If so only it can be active.
    //

    if (CcPfGlobals.SystemWideTrace) {
        Status = STATUS_USER_EXISTS;
        goto cleanup;
    }

    //
    // Make a quick check to see if we already have too many outstanding 
    // traces. Since we don't make this check under a lock, the limit is
    // not enforced exactly.
    //  

    if ((ULONG)CcPfNumActiveTraces >= CcPfGlobals.Parameters.Parameters.MaxNumActiveTraces) {
        Status = STATUS_TOO_MANY_SESSIONS;
        goto cleanup;
    }   

    //
    // Make a quick check to see if we already have too many completed 
    // traces that the service has not picked up.
    //   
    
    if ((ULONG)CcPfGlobals.NumCompletedTraces >= CcPfGlobals.Parameters.Parameters.MaxNumSavedTraces) {
        Status = STATUS_TOO_MANY_SESSIONS;
        goto cleanup;
    }
    
    //
    // If a process was not specified we cannot start a trace.
    //

    if (!Process) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    } 

    //
    // Allocate and initialize trace structure.
    //

    Trace = ExAllocatePoolWithTag(NonPagedPool,
                                  sizeof(CCPF_TRACE_HEADER),
                                  CCPF_ALLOC_TRACE_TAG);
    
    if (!Trace) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Zero the whole structure so that we don't have to write zeroes
    // one field at a time to initialize it. Note that most fields
    // really have to be initialized to 0's.
    //

    RtlZeroMemory(Trace, sizeof(CCPF_TRACE_HEADER));
    
    //
    // Initialize other trace fields so we know what to cleanup.
    //

    Trace->Magic = PF_TRACE_MAGIC_NUMBER;
    KeInitializeTimer(&Trace->TraceTimer);
    InitializeListHead(&Trace->TraceBuffersList);
    KeInitializeSpinLock(&Trace->TraceBufferSpinLock);
    InitializeListHead(&Trace->VolumeList);
    Trace->TraceDumpStatus = STATUS_NOT_COMMITTED;
    KeQuerySystemTime(&Trace->LaunchTime);

    //
    // Initialize the spinlock and DPC for the trace timer.
    //

    KeInitializeSpinLock(&Trace->TraceTimerSpinLock);

    KeInitializeDpc(&Trace->TraceTimerDpc, 
                    CcPfTraceTimerRoutine, 
                    Trace);
                                                  
    //
    // Initialize reference count structure. A reference to a trace
    // can only be acquired while holding the active traces spinlock.
    //

    CcPfInitializeRefCount(&Trace->RefCount);
    
    //
    // Get reference to associated process so it does
    // not go away while our timer routines etc. are running.
    //

    ObReferenceObject(Process);
    Trace->Process = Process;

    //
    // Initialize the workitem that may be queued to call end trace
    // function and the field that has to be InterlockedCompareExchange'd 
    // to 1 before anybody queues the workitem or makes the call.
    //

    ExInitializeWorkItem(&Trace->EndTraceWorkItem,
                         CcPfEndTraceWorkerThreadRoutine,
                         Trace);

    Trace->EndTraceCalled = 0;

    //
    // Initialize the workitem queued to get names for file objects.
    //

    ExInitializeWorkItem(&Trace->GetFileNameWorkItem,
                         CcPfGetFileNamesWorkerRoutine,
                         Trace);

    Trace->GetFileNameWorkItemQueued = 0;

    KeInitializeEvent(&Trace->GetFileNameWorkerEvent,
                      SynchronizationEvent,
                      FALSE);

    //
    // Initialize the list where we put sections we have to get names
    // for.
    //

    InitializeSListHead(&Trace->SectionsWithoutNamesList);

    //
    // Initialize scenario id and type fields.
    //

    Trace->ScenarioId = *ScenarioId;
    Trace->ScenarioType = ScenarioType;

    //
    // Determine trace limits and timer period from scenario type.
    // We have already checked that ScenarioType is within limits.
    //
    
    TraceLimits = &CcPfGlobals.Parameters.Parameters.TraceLimits[Trace->ScenarioType];

    Trace->MaxFaults = TraceLimits->MaxNumPages;
    Trace->MaxSections = TraceLimits->MaxNumSections;
    Trace->TraceTimerPeriod.QuadPart = TraceLimits->TimerPeriod;

    //
    // Make sure the sizes are within sanity limits.
    //

    if ((Trace->MaxFaults == 0) || (Trace->MaxSections == 0)) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    if (Trace->MaxFaults > PF_MAXIMUM_LOG_ENTRIES) {
        Trace->MaxFaults = PF_MAXIMUM_LOG_ENTRIES;
    }
    
    if (Trace->MaxSections > PF_MAXIMUM_SECTIONS) {
        Trace->MaxSections = PF_MAXIMUM_SECTIONS;
    }

    //
    // Allocate a trace buffer and section info table.
    //

    MaxEntries = CCPF_TRACE_BUFFER_MAX_ENTRIES;
    Trace->CurrentTraceBuffer = ExAllocatePoolWithTag(NonPagedPool,
                                                      CCPF_TRACE_BUFFER_SIZE,
                                                      CCPF_ALLOC_TRCBUF_TAG);
    
    if (Trace->CurrentTraceBuffer == NULL) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    Trace->CurrentTraceBuffer->NumEntries = 0;
    Trace->CurrentTraceBuffer->MaxEntries = MaxEntries;

    //
    // Insert the current trace buffer to the trace buffers list.
    //

    InsertTailList(&Trace->TraceBuffersList, 
                   &Trace->CurrentTraceBuffer->TraceBuffersLink);

    Trace->NumTraceBuffers = 1;

    //
    // SectionInfoTable is a hash. To give it enough room and avoid
    // too many hash conflicts, allocate it to be bigger.
    //

    SectionTableSize = Trace->MaxSections + (Trace->MaxSections / 2);
    AllocationSize = SectionTableSize * sizeof(CCPF_SECTION_INFO);
    Trace->SectionInfoTable = ExAllocatePoolWithTag(NonPagedPool,
                                                    AllocationSize,
                                                    CCPF_ALLOC_SECTTBL_TAG);
    
    if (!Trace->SectionInfoTable) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }  

    Trace->SectionTableSize = SectionTableSize;

    //
    // Initialize entries in the section table. We want the whole table
    // to contain zeroes, so just use RtlZeroMemory. 
    //
    // EntryValid is the crucial field in section info entries allowing
    // us not to have any locks. The first to (interlocked) set it
    // to 1 gets the entry in the table. In case someone tries to
    // access the entry right afterwards we initialize the other
    // fields to sensible values upfront.
    //
    // It is important to set SectionObjectPointer to NULL. When EntryValid is
    // InterlockedCompareExchange'd into 1, we don't want anybody
    // to match before we set it up.
    //

    RtlZeroMemory(Trace->SectionInfoTable, AllocationSize);
  
    //
    // Add this trace to active traces list. 
    // Set the trace on process header.
    // Start the trace timer.
    // We'll start logging page faults, processing process delete notificatios etc.
    //

    CcPfActivateTrace(Trace);

    //
    // NOTE: FROM THIS POINT ON WE SHOULD NOT FAIL. 
    // CcPfEndTrace has to be called to stop & cleanup the trace.
    //

    Status = STATUS_SUCCESS;

 cleanup:

    if (!NT_SUCCESS(Status)) {       
        if (Trace) {
            CcPfCleanupTrace(Trace);
            ExFreePool(Trace);
        }
    }

    DBGPR((CCPFID,PFTRC,"CCPF: BeginTrace(%p)=%x\n", Trace, Status));

    return Status;
}

NTSTATUS
CcPfActivateTrace(
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This routine adds the specified trace to the list of active
    traces.

Arguments:

    Trace - Pointer to trace header.

Return Value:

    STATUS_SUCCESS.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL. Acquires spinlock.

--*/

{
    KIRQL OrigIrql;
    NTSTATUS Status;
    BOOLEAN TimerAlreadyQueued;

    DBGPR((CCPFID,PFTRC,"CCPF: ActivateTrace(%p)\n", Trace));

    //
    // Get a reference to the trace for the timer.
    //

    Status = CcPfAddRef(&Trace->RefCount);
    CCPF_ASSERT(NT_SUCCESS(Status));

    //
    // Insert to active traces list.
    //
    
    KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OrigIrql);
    
    InsertTailList(&CcPfGlobals.ActiveTraces, &Trace->ActiveTracesLink);
    CcPfNumActiveTraces++;

    //
    // Start the timer.
    //

    TimerAlreadyQueued = KeSetTimer(&Trace->TraceTimer,
                                    Trace->TraceTimerPeriod,
                                    &Trace->TraceTimerDpc);

    //
    // We just initialized the timer. It could not have been already queued.
    //

    CCPF_ASSERT(!TimerAlreadyQueued);

    //
    // Set up the trace pointer on the process with fast ref. Since we are 
    // already holding a reference, this operation should not fail.
    //

    Status = CcPfAddProcessTrace(Trace->Process, Trace);
    CCPF_ASSERT(NT_SUCCESS(Status));

    //
    // Do we trace system-wide for this scenario type?
    //

    if (CCPF_IS_SYSTEM_WIDE_SCENARIO_TYPE(Trace->ScenarioType)) {

        CcPfGlobals.SystemWideTrace = Trace;

    } else {

        //
        // If we are the only active trace, place ourselves on the system
        // process as well so we can trace ReadFile & metafile access.
        //

        if (CcPfNumActiveTraces == 1 && 
            Trace->Process != PsInitialSystemProcess) {

            CCPF_ASSERT(NULL == ExFastRefGetObject(PsInitialSystemProcess->PrefetchTrace));
            Status = CcPfAddProcessTrace(PsInitialSystemProcess, Trace);
            CCPF_ASSERT(NT_SUCCESS(Status));
        }
    }

    //
    // NOTE: AddProcessTrace and KeSetTimer(TraceTimer) has to be done 
    // inside the spinlock so DeactivateTrace can know activation has been
    // fully completed by acquiring and releasing the spinlock.
    //

    KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OrigIrql);
    
    return STATUS_SUCCESS;
}

NTSTATUS
CcPfDeactivateTrace(
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This routine waits for all references to the trace to go away, and
    removes it from the active traces list. This function should only
    be called after CcPfActivateTrace has been called on the trace.

Arguments:

    Trace - Pointer to trace header.

Return Value:

    STATUS_SUCCESS.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL. Acquires spinlock.

--*/

{
    PCCPF_TRACE_HEADER RemovedTrace;
    PCCPF_TRACE_HEADER ReferencedTrace;
    KIRQL OrigIrql;
    NTSTATUS Status;  

    DBGPR((CCPFID,PFTRC,"CCPF: DeactivateTrace(%p)\n", Trace));

    //
    // Acquire and release the active traces spinlock. This makes sure we
    // don't try to deactivate before activation (which also holds this lock) 
    // has fully completed.
    //

#if !defined (NT_UP)
    KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OrigIrql);   
    KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OrigIrql);
#endif // NT_UP

    //
    // Remove the trace from process header and release the fast refs.
    //

    RemovedTrace = CcPfRemoveProcessTrace(Trace->Process);
    CCPF_ASSERT(RemovedTrace == Trace);

    //
    // Release the reference associated with the fast ref itself.
    //

    CcPfDecRef(&Trace->RefCount);

    //
    // If we were placed on the system process as well, remove that.
    //

    ReferencedTrace = CcPfReferenceProcessTrace(PsInitialSystemProcess);

    if (ReferencedTrace) {

        if (Trace == ReferencedTrace) {

            //
            // Remove ourselves from the system process header.
            //

            RemovedTrace = CcPfRemoveProcessTrace(PsInitialSystemProcess);
            CCPF_ASSERT(RemovedTrace == Trace);

            //
            // Release the reference associated with the fast ref itself.
            //

            CcPfDecRef(&Trace->RefCount);           
        }

        //
        // Release the reference we just got.
        //

        CcPfDecRef(&ReferencedTrace->RefCount);
    }
    
    //
    // Cancel the timer.
    //

    CcPfCancelTraceTimer(Trace);

    //
    // Signal the trace's get-file-name worker to return [in case it
    // is active] and release its reference. Give it a priority bump
    // so it releases its reference before we begin waiting for it.
    //

    KeSetEvent(&Trace->GetFileNameWorkerEvent,
               EVENT_INCREMENT,
               FALSE);


    //
    // Wait for all references to go away.
    //
    
    Status = CcPfAcquireExclusiveRef(&Trace->RefCount);

    DBGPR((CCPFID,PFTRAC,"CCPF: DeactivateTrace-Exclusive=%x\n", Status));

    //
    // We should have been able to acquire the trace exclusively.
    // Otherwise this trace may have already been deactivated.
    //

    CCPF_ASSERT(NT_SUCCESS(Status));

    //
    // Get the active traces lock.
    //
     
    KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OrigIrql);

    //
    // Remove us from the active trace list.
    //
    
    RemoveEntryList(&Trace->ActiveTracesLink);
    CcPfNumActiveTraces--;
    
    //
    // If this was a system-wide trace, it is over now.
    //

    if (CCPF_IS_SYSTEM_WIDE_SCENARIO_TYPE(Trace->ScenarioType)) {
        CCPF_ASSERT(CcPfGlobals.SystemWideTrace == Trace);
        CcPfGlobals.SystemWideTrace = NULL;
    }

    //
    // Release active traces lock.
    //

    KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OrigIrql);

    return STATUS_SUCCESS;
}

NTSTATUS
CcPfEndTrace(
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This function is called to end a prefetch trace. In order to
    ensure this function gets called only once, EndTraceCalled field
    of the trace has to be InterlockedCompareExchange'd from 0 to
    1. All intermediate references and allocations are freed. The
    trace is saved until the service queries for it and the service
    event is signaled.

Arguments:

    Trace - Pointer to trace header.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_DUMP TraceDump;
    PCCPF_TRACE_DUMP RemovedTraceDump;
    PLIST_ENTRY ListHead;
    OBJECT_ATTRIBUTES EventObjAttr;
    UNICODE_STRING EventName;
    HANDLE EventHandle;
    NTSTATUS Status;
    LONG FaultsLoggedAfterTimeout;

    DBGPR((CCPFID,PFTRC,"CCPF: EndTrace(%p)\n", Trace));

    //
    // Make sure the trace we are called on is valid.
    //

    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    //
    // Before anyone called us, they should have
    // InterlockedCompareExchange'd this to 1 to ensure this function
    // gets called only once for this trace.
    //

    CCPF_ASSERT(Trace->EndTraceCalled == 1);

    //
    // Deactivate the trace, if necessary waiting for all the references to 
    // it to go away.
    // This function makes sure activation fully finished before deactivating.
    // This needs to be done before we do anything else with the trace.
    //
                
    CcPfDeactivateTrace(Trace);   

    //
    // If we did not timeout, save the number of pagefaults logged
    // since the last period into the next period.
    //

    if (Trace->CurPeriod < PF_MAX_NUM_TRACE_PERIODS) {

        //
        // Number of log entries could only have increased since the
        // last time we saved them.
        //
     
        CCPF_ASSERT(Trace->NumFaults >= Trace->LastNumFaults);
   
        Trace->FaultsPerPeriod[Trace->CurPeriod] = 
            Trace->NumFaults - Trace->LastNumFaults;
    
        Trace->LastNumFaults = Trace->NumFaults;
        
        Trace->CurPeriod++;

    } else {

        //
        // Verify that CurPeriod is within bounds.
        //

        if (Trace->CurPeriod > PF_MAX_NUM_TRACE_PERIODS) {    
            CCPF_ASSERT(Trace->CurPeriod <= PF_MAX_NUM_TRACE_PERIODS);
            Trace->CurPeriod = PF_MAX_NUM_TRACE_PERIODS;
        }

        //
        // If we did time out, we may have logged more faults since we
        // saved the number of faults, until the end trace function
        // got run. Update the number faults in the last period.
        //
        
        if (Trace->LastNumFaults != Trace->NumFaults) {
            
            //
            // What we saved as LastNumFaults in the timer routine
            // cannot be greater than what we really logged.
            //
            
            CCPF_ASSERT(Trace->LastNumFaults < Trace->NumFaults);
            
            FaultsLoggedAfterTimeout = Trace->NumFaults - Trace->LastNumFaults;
            
            Trace->FaultsPerPeriod[Trace->CurPeriod - 1] += FaultsLoggedAfterTimeout;
        }
    }

    //
    // Convert the trace into a paged, single buffer dump that we can
    // give to the user mode service.
    //

    Status = CcPfBuildDumpFromTrace(&TraceDump, Trace);

    Trace->TraceDumpStatus = Status;
    Trace->TraceDump = TraceDump;

    //
    // Cleanup and deallocate the trace structure.
    //

    CcPfCleanupTrace(Trace);
    ExFreePool(Trace);

    //
    // If we could not create a dump from the trace we acquired, we
    // are done.
    //

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Put the dump on the saved traces list. If we have too many,
    // trim in a round robin fashion. First get the lock.
    //

    ExAcquireFastMutex(&CcPfGlobals.CompletedTracesLock);
    
    InsertTailList(&CcPfGlobals.CompletedTraces, &TraceDump->CompletedTracesLink);
    CcPfGlobals.NumCompletedTraces++;

    while ((ULONG) CcPfGlobals.NumCompletedTraces > 
           CcPfGlobals.Parameters.Parameters.MaxNumSavedTraces) {

        //
        // While NumCompletedTraces > MaxNumSavedTraces we should have at
        // least a completed trace in the list.
        //
        
        if (IsListEmpty(&CcPfGlobals.CompletedTraces)) {
            CCPF_ASSERT(FALSE);
            break;
        }

        ListHead = RemoveHeadList(&CcPfGlobals.CompletedTraces);
        
        RemovedTraceDump = CONTAINING_RECORD(ListHead,
                                             CCPF_TRACE_DUMP,
                                             CompletedTracesLink);
       
        //
        // Free the tracedump structure.
        //
    
        CCPF_ASSERT(RemovedTraceDump->Trace.MagicNumber == PF_TRACE_MAGIC_NUMBER);
        ExFreePool(RemovedTraceDump);

        CcPfGlobals.NumCompletedTraces--;
    }
    
    ExReleaseFastMutex(&CcPfGlobals.CompletedTracesLock);   

    //
    // Signal the event service is waiting on for new traces. If we
    // have not opened it yet, first we have to open it.
    //

    if (CcPfGlobals.CompletedTracesEvent) {

        ZwSetEvent(CcPfGlobals.CompletedTracesEvent, NULL);

    } else {

        //
        // Try to open the event. We don't open this at initialization
        // because our service may not have started to create this
        // event yet. If csrss.exe has not initialized, we may not
        // even have the BaseNamedObjects object directory created, in
        // which Win32 events reside.
        //

        RtlInitUnicodeString(&EventName, PF_COMPLETED_TRACES_EVENT_NAME);

        InitializeObjectAttributes(&EventObjAttr,
                                   &EventName,
                                   OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                                   NULL,
                                   NULL);
        
        Status = ZwOpenEvent(&EventHandle,
                             EVENT_ALL_ACCESS,
                             &EventObjAttr);
        
        if (NT_SUCCESS(Status)) {

            //
            // Acquire the lock and set the global handle.
            //

            ExAcquireFastMutex(&CcPfGlobals.CompletedTracesLock);

            if (!CcPfGlobals.CompletedTracesEvent) {

                //
                // Set the global handle.
                //

                CcPfGlobals.CompletedTracesEvent = EventHandle;
                CCPF_ASSERT(EventHandle);

            } else {

                //
                // Somebody already initialized the global handle
                // before us. Close our handle and use the one they
                // initialized.
                //

                ZwClose(EventHandle);
            }

            ExReleaseFastMutex(&CcPfGlobals.CompletedTracesLock);

            //
            // We have an event now. Signal it.
            //
            
            ZwSetEvent(CcPfGlobals.CompletedTracesEvent, NULL);
        }
    }

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: EndTrace(%p)=%x\n", Trace, Status));

    return Status;
}

NTSTATUS
CcPfBuildDumpFromTrace(
    OUT PCCPF_TRACE_DUMP *TraceDump, 
    IN PCCPF_TRACE_HEADER RuntimeTrace
    )

/*++

Routine Description:

    This routine allocates (from paged pool) and prepares a TraceDump
    structure from a run-time trace that can be saved on a list. It
    tries to get file names for all sections in the passed in run-time
    trace structure. The file names that are obtained are allocated
    from paged pool and put on the run-time trace's section info table
    and are cleaned up when that is cleaned up. The trace dump
    structure contains a pointer to an allocated (from paged pool)
    trace buffer that was built from the run-time trace, that can be
    passed to the user mode service. The caller is responsible for
    freeing both the TraceDump structure and the prepared trace.

Arguments:

    TraceDump - Where pointer to the allocated trace buffer is put if
      success is returned. If failure is returned, this is undefined.
    
    RuntimeTrace - Run-time trace structure to put into dump format.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    ULONG SectionIdx;
    PCCPF_SECTION_INFO SectionInfo;
    ULONG FileNameLength;
    ULONG TraceSize;
    PPF_TRACE_HEADER Trace;
    ULONG FileNameDataNumChars;
    PSHORT SectIdTranslationTable;
    ULONG TranslationTableSize;
    PPF_SECTION_INFO TargetSectionInfo;
    LONG EntryIdx;
    LONG NumEntries;
    PCCPF_LOG_ENTRY LogEntry;
    PPF_LOG_ENTRY TargetLogEntry;
    ULONG NumEntriesCopied;
    ULONG NumSectionsCopied;
    PCHAR DestPtr;
    SHORT NewSectionId;
    PPF_LOG_ENTRY NewTraceEntries;
    ULONG SectionInfoSize;
    PCCPF_LOG_ENTRIES TraceBuffer;
    PLIST_ENTRY HeadEntry;
    PLIST_ENTRY NextEntry;
    LONG CurrentFaultIdx;
    LONG CurrentPeriodIdx;
    LONG CurrentPeriodEndFaultIdx;
    ULONG_PTR AlignmentOffset;
    ULONG AllocationSize;
    ULONG NumVolumes;
    ULONG TotalVolumeInfoSize;
    ULONG VolumeInfoSize;
    PCCPF_VOLUME_INFO VolumeInfo;
    PPF_VOLUME_INFO TargetVolumeInfo;
    ULONG FailedCheck;

    //
    // Initialize locals.
    //

    SectIdTranslationTable = NULL;
    Trace = NULL;
    *TraceDump = NULL;
    NumEntriesCopied = 0;

    DBGPR((CCPFID,PFTRC,"CCPF: DumpTrace(%p)\n", RuntimeTrace));

    //
    // If the acquired trace is too small, don't bother.
    //
      
    if (RuntimeTrace->NumFaults < PF_MIN_SCENARIO_PAGES) {
        Status = STATUS_BUFFER_TOO_SMALL;
        goto cleanup;
    }

    //
    // If the acquired trace does not contain any sections or volumes
    // it is useless.
    //

    if (!RuntimeTrace->NumSections || !RuntimeTrace->NumVolumes) {
        Status = STATUS_BUFFER_TOO_SMALL;
        goto cleanup;
    }

    //
    // Calculate the maximum size of trace we will build.
    //
    
    TraceSize = sizeof(PF_TRACE_HEADER);
    TraceSize += RuntimeTrace->NumFaults * sizeof(PF_LOG_ENTRY);
    TraceSize += RuntimeTrace->NumSections * sizeof(PF_SECTION_INFO);

    //
    // Add up file name data size.
    //

    FileNameDataNumChars = 0;
    
    for (SectionIdx = 0; 
         SectionIdx < RuntimeTrace->SectionTableSize; 
         SectionIdx++) {

        SectionInfo = &RuntimeTrace->SectionInfoTable[SectionIdx];
        
        if (SectionInfo->EntryValid && SectionInfo->FileName) {
            
            //
            // We would add space for terminating NUL but the space
            // for one character in section info accounts for that.
            //

            FileNameDataNumChars += wcslen(SectionInfo->FileName);
        }
    }

    TraceSize += FileNameDataNumChars * sizeof(WCHAR);

    //
    // We may have to align LogEntries coming after section infos that
    // contain WCHAR strings.
    //

    TraceSize += _alignof(PF_LOG_ENTRY);
    
    //
    // Add space for the volume info nodes.
    //

    HeadEntry = &RuntimeTrace->VolumeList;
    NextEntry = HeadEntry->Flink;

    NumVolumes = 0;
    TotalVolumeInfoSize = 0;
    
    while (NextEntry != HeadEntry) {
        
        VolumeInfo = CONTAINING_RECORD(NextEntry,
                                       CCPF_VOLUME_INFO,
                                       VolumeLink);
        
        NextEntry = NextEntry->Flink;

        //
        // Keep track of number of volumes on the list so we can
        // verify it.
        //

        NumVolumes++;

        //
        // Calculate size of this volume info in the dumped
        // trace. Note that PF_VOLUME_INFO contains space for the
        // terminating NUL.
        //

        VolumeInfoSize = sizeof(PF_VOLUME_INFO);
        VolumeInfoSize += VolumeInfo->VolumePathLength * sizeof(WCHAR);

        //
        // Update size for the volume info block. Add space for
        // aligning a volume info node if necessary.
        //
        
        TotalVolumeInfoSize += VolumeInfoSize;
        TotalVolumeInfoSize += _alignof(PF_VOLUME_INFO);        
    }

    CCPF_ASSERT(NumVolumes == RuntimeTrace->NumVolumes);

    TraceSize += TotalVolumeInfoSize;

    //
    // Allocate the trace dump structure we are going to
    // return. Subtract sizeof(PF_TRACE_HEADER) since both
    // CCPF_TRACE_DUMP and TraceSize include this.
    //

    AllocationSize = sizeof(CCPF_TRACE_DUMP);
    AllocationSize += TraceSize - sizeof(PF_TRACE_HEADER);

    *TraceDump = ExAllocatePoolWithTag(PagedPool,
                                       AllocationSize,
                                       CCPF_ALLOC_TRCDMP_TAG);

    if ((*TraceDump) == NULL) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Get pointer to the trace structure.
    //
    
    Trace = &(*TraceDump)->Trace;
    
    //
    // Setup trace header.
    //

    Trace->Version = PF_CURRENT_VERSION;
    Trace->MagicNumber = PF_TRACE_MAGIC_NUMBER;
    Trace->ScenarioId = RuntimeTrace->ScenarioId;
    Trace->ScenarioType = RuntimeTrace->ScenarioType;
    Trace->LaunchTime = RuntimeTrace->LaunchTime;
    Trace->PeriodLength = RuntimeTrace->TraceTimerPeriod.QuadPart;

    //
    // Initialize faults per period to 0's. We will update these as we
    // copy valid entries from the runtime trace.
    //

    RtlZeroMemory(Trace->FaultsPerPeriod, sizeof(Trace->FaultsPerPeriod));

    DestPtr = (PCHAR) Trace + sizeof(PF_TRACE_HEADER);

    //
    // Copy over sections for which we have names. Since their indices
    // in the new table will be different, build a translation table
    // that we will use to translate the section id's of log
    // entries. First allocate this table.
    //

    TranslationTableSize = RuntimeTrace->SectionTableSize * sizeof(USHORT);

    SectIdTranslationTable = ExAllocatePoolWithTag(PagedPool,
                                                   TranslationTableSize,
                                                   CCPF_ALLOC_TRCDMP_TAG);
    
    if (!SectIdTranslationTable) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }
       
    //
    // Copy section information to the trace buffer while setting up
    // the translation table.
    //

    Trace->SectionInfoOffset = (ULONG) (DestPtr - (PCHAR) Trace);
    
    NumSectionsCopied = 0;
                                        
    for (SectionIdx = 0;
         SectionIdx < RuntimeTrace->SectionTableSize; 
         SectionIdx++) {
        
        SectionInfo = &RuntimeTrace->SectionInfoTable[SectionIdx];

        if (SectionInfo->EntryValid && 
            SectionInfo->FileName &&
            (FileNameLength = wcslen(SectionInfo->FileName)) > 0) {
            
            TargetSectionInfo = (PPF_SECTION_INFO) DestPtr;

            SectionInfoSize = sizeof(PF_SECTION_INFO);
            SectionInfoSize += FileNameLength * sizeof(WCHAR);

            //
            // Make sure we are not going off bounds.
            //
            
            if (DestPtr + SectionInfoSize > (PCHAR) Trace + TraceSize) {
                SectIdTranslationTable[SectionIdx] = CCPF_INVALID_TABLE_INDEX;
                CCPF_ASSERT(FALSE);
                continue;
            }

            TargetSectionInfo->FileNameLength = (USHORT) FileNameLength;

            TargetSectionInfo->Metafile = (USHORT) SectionInfo->Metafile;
            
            //
            // Copy the file name including the terminating NUL.
            //

            RtlCopyMemory(TargetSectionInfo->FileName,
                          SectionInfo->FileName,
                          (FileNameLength + 1) * sizeof(WCHAR));

            //
            // Update our position in the destination buffer.
            //
            
            DestPtr += SectionInfoSize;

            //
            // Update the translation table:
            //

            SectIdTranslationTable[SectionIdx] = (USHORT) NumSectionsCopied;

            NumSectionsCopied++;

        } else {

            SectIdTranslationTable[SectionIdx] = CCPF_INVALID_TABLE_INDEX;
        }
    }

    Trace->NumSections = NumSectionsCopied;
    CCPF_ASSERT(Trace->NumSections <= (ULONG) RuntimeTrace->NumSections);

    //
    // Make sure DestPtr is aligned for Log Entries coming next. We
    // had reserved max space we'd need for this adjustment upfront.
    //

    AlignmentOffset = ((ULONG_PTR) DestPtr) % _alignof(PF_LOG_ENTRY);
    
    if (AlignmentOffset) {
        DestPtr += (_alignof(PF_LOG_ENTRY) - AlignmentOffset);
    }

    //
    // Copy the log entries.
    //

    Trace->TraceBufferOffset = (ULONG) (DestPtr - (PCHAR) Trace);
    NewTraceEntries = (PPF_LOG_ENTRY) DestPtr;

    //
    // Initialize index of the current log entry in the whole runtime
    // trace, which period it was logged in, and what the index of the
    // first fault logged after this period was.
    //

    CurrentFaultIdx = 0;
    CurrentPeriodIdx = 0;
    CurrentPeriodEndFaultIdx = RuntimeTrace->FaultsPerPeriod[0];

    //
    // Walk through the trace buffers list and copy over
    // entries. NumEntriesCopied is initialized to 0 at the top.
    //

    HeadEntry = &RuntimeTrace->TraceBuffersList;
    NextEntry = HeadEntry->Flink;

    while (NextEntry != HeadEntry) {

        TraceBuffer = CONTAINING_RECORD(NextEntry,
                                        CCPF_LOG_ENTRIES,
                                        TraceBuffersLink);
        
        NumEntries = TraceBuffer->NumEntries;

        NextEntry = NextEntry->Flink;

        for (EntryIdx = 0, LogEntry = TraceBuffer->Entries;
             EntryIdx < NumEntries;
             EntryIdx++, LogEntry++, CurrentFaultIdx++) {    

            //
            // Current fault index should not be greater than the
            // total number of faults we logged in the trace.
            //

            if (CurrentFaultIdx >= RuntimeTrace->NumFaults) {
                CCPF_ASSERT(FALSE);
                Status = STATUS_INVALID_PARAMETER;
                goto cleanup;
            }

            //
            // Update the period this fault was logged in
            //

            while (CurrentFaultIdx >= CurrentPeriodEndFaultIdx) {
                
                CurrentPeriodIdx++;

                //
                // Check bounds on period.
                //

                if (CurrentPeriodIdx >= PF_MAX_NUM_TRACE_PERIODS) {
                    CCPF_ASSERT(FALSE);
                    Status = STATUS_INVALID_PARAMETER;
                    goto cleanup;
                }

                //
                // Update the end for this period. It is beyond the
                // current end by the number of entries logged in the
                // period.
                //
                
                CurrentPeriodEndFaultIdx += RuntimeTrace->FaultsPerPeriod[CurrentPeriodIdx];

                //
                // This end fault index should not be greater than the
                // total number of faults we logged.
                //

                if (CurrentPeriodEndFaultIdx > RuntimeTrace->NumFaults) {
                    CCPF_ASSERT(FALSE);
                    Status = STATUS_INVALID_PARAMETER;
                    goto cleanup;
                }
            }

            //
            // Make sure log entry's section id is within bounds.
            //

            if (LogEntry->SectionId >= RuntimeTrace->SectionTableSize) {
                CCPF_ASSERT(FALSE);
                continue;
            }

            NewSectionId = SectIdTranslationTable[LogEntry->SectionId];

            //
            // Copy only those entries for which we have a valid file
            // name.
            //
   
            if (NewSectionId != CCPF_INVALID_TABLE_INDEX) {

                //
                // New section id should be within the number of sections in
                // the final trace.
                //
            
                if ((USHORT) NewSectionId >= Trace->NumSections) {
                    CCPF_ASSERT(FALSE);
                    continue;
                }

                TargetLogEntry = &NewTraceEntries[NumEntriesCopied];

                //
                // Don't ever go beyond the buffer we had allocated.
                //

                if ((PCHAR) (TargetLogEntry + 1) > (PCHAR) Trace + TraceSize) {
                    CCPF_ASSERT(FALSE);
                    continue;
                }
            
                TargetLogEntry->FileOffset = LogEntry->FileOffset;
                TargetLogEntry->SectionId = NewSectionId;
                TargetLogEntry->IsImage = LogEntry->IsImage;

                //
                // Update number of entries copied for this period. 
                //

                Trace->FaultsPerPeriod[CurrentPeriodIdx]++;

                //
                // Update the total number of entries copied.
                //

                NumEntriesCopied++;
            }
        }
    }

    Trace->NumEntries = NumEntriesCopied;
    CCPF_ASSERT(Trace->NumEntries <= (ULONG) RuntimeTrace->NumFaults);

    //
    // Update destination pointer.
    //
    
    DestPtr += NumEntriesCopied * sizeof(PF_LOG_ENTRY);

    //
    // Add volume info structures. Clear the VolumeInfoOffset, so it
    // will get set appropriately when we add the first volume.
    //

    Trace->VolumeInfoOffset = 0;
    Trace->NumVolumes = 0;
    Trace->VolumeInfoSize = 0;   

    HeadEntry = &RuntimeTrace->VolumeList;
    NextEntry = HeadEntry->Flink;
    
    while (NextEntry != HeadEntry) {
        
        VolumeInfo = CONTAINING_RECORD(NextEntry,
                                       CCPF_VOLUME_INFO,
                                       VolumeLink);
        
        NextEntry = NextEntry->Flink;

        //
        // Align the DestPtr for the VolumeInfo structure.
        //

        DestPtr = PF_ALIGN_UP(DestPtr, _alignof(PF_VOLUME_INFO));

        //
        // If this is the first VolumeInfo, update the offset in the
        // trace header.
        //

        if (!Trace->VolumeInfoOffset) {
            Trace->VolumeInfoOffset = (ULONG) (DestPtr - (PCHAR) Trace);
        }

        //
        // Calculate size of this volume info in the dumped
        // trace. Note that PF_VOLUME_INFO contains space for the
        // terminating NUL.
        //

        VolumeInfoSize = sizeof(PF_VOLUME_INFO);
        VolumeInfoSize += VolumeInfo->VolumePathLength * sizeof(WCHAR);

        //
        // Make sure we have space for this entry.
        //
        
        if (DestPtr + VolumeInfoSize  > (PCHAR) Trace + TraceSize) {
            CCPF_ASSERT(FALSE);
            Status = STATUS_BUFFER_TOO_SMALL;
            goto cleanup;
        }

        //
        // Copy the data over.
        //

        TargetVolumeInfo = (PPF_VOLUME_INFO) DestPtr;
        
        TargetVolumeInfo->CreationTime = VolumeInfo->CreationTime;
        TargetVolumeInfo->SerialNumber = VolumeInfo->SerialNumber;
        
        RtlCopyMemory(TargetVolumeInfo->VolumePath,
                      VolumeInfo->VolumePath,
                      (VolumeInfo->VolumePathLength + 1) * sizeof(WCHAR));
        
        TargetVolumeInfo->VolumePathLength = VolumeInfo->VolumePathLength;

        //
        // Update DestPtr and the Trace header.
        //

        Trace->NumVolumes++;
        DestPtr = DestPtr + VolumeInfoSize;
    }    
    
    //
    // Update VolumeInfoSize on the trace header.
    //

    Trace->VolumeInfoSize = (ULONG) (DestPtr - (PCHAR) Trace) - Trace->VolumeInfoOffset;

    //
    // Update trace header. We should not have copied more than what
    // we allocated for.
    //

    Trace->Size = (ULONG) (DestPtr - (PCHAR) Trace);
    CCPF_ASSERT(Trace->Size <= TraceSize);

    //
    // Make sure the trace we built passes the tests.
    //

    if (!PfVerifyTraceBuffer(Trace, Trace->Size, &FailedCheck)) {
        CCPF_ASSERT(FALSE);
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }
    
    Status = STATUS_SUCCESS;

 cleanup:

    if (SectIdTranslationTable) {
        ExFreePool(SectIdTranslationTable);
    }

    if (!NT_SUCCESS(Status)) {
        
        if (*TraceDump) {
            ExFreePool(*TraceDump);
            *TraceDump = NULL;
        }
    }

    DBGPR((CCPFID,PFTRC,"CCPF: DumpTrace(%p)=%x [%d,%d]\n", 
           RuntimeTrace, Status, NumEntriesCopied, RuntimeTrace->NumFaults));

    return Status;
}

VOID
CcPfCleanupTrace (
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This routine cleans up allocated fields of a trace header, and
    releases references. It does not free the trace structure
    itself.

Arguments:

    Trace - Trace to cleanup.

Return Value:

    None.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    ULONG SectionIdx;
    PCCPF_SECTION_INFO SectionInfo;
    PCCPF_LOG_ENTRIES TraceBufferToFree;
    PLIST_ENTRY ListHead;
    PCCPF_VOLUME_INFO VolumeInfo;

    DBGPR((CCPFID,PFTRC,"CCPF: CleanupTrace(%p)\n", Trace));

    //
    // Validate parameters.
    //

    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    //
    // We should not have any sections we are still trying to get
    // names for: we would have acquired a trace reference and cleanup
    // functions would not get called with pending references.
    //

    CCPF_ASSERT(ExQueryDepthSList(&Trace->SectionsWithoutNamesList) == 0);

    //
    // Free the trace buffers. 
    //

    while (!IsListEmpty(&Trace->TraceBuffersList)) {
        
        ListHead = RemoveHeadList(&Trace->TraceBuffersList);
        
        CCPF_ASSERT(Trace->NumTraceBuffers);
        Trace->NumTraceBuffers--;

        TraceBufferToFree = CONTAINING_RECORD(ListHead,
                                              CCPF_LOG_ENTRIES,
                                              TraceBuffersLink);
        
        ExFreePool(TraceBufferToFree);
    }
    
    //
    // Go through the section info hash. Free the file names and make
    // sure we don't have any file objects referenced anymore.
    //
    
    if (Trace->SectionInfoTable) {

        for (SectionIdx = 0; SectionIdx < Trace->SectionTableSize; SectionIdx++) {
            
            SectionInfo = &Trace->SectionInfoTable[SectionIdx];
            
            if (SectionInfo->EntryValid) {
                
                if (SectionInfo->FileName) {
                    ExFreePool(SectionInfo->FileName);
                }
                
                if (SectionInfo->ReferencedFileObject) {
                    ObDereferenceObject(SectionInfo->ReferencedFileObject);
                }
            }
        }

        ExFreePool(Trace->SectionInfoTable);
    }

    //
    // If there was a process we were associated with, release the
    // reference we got on it.
    //

    if (Trace->Process) {
        ObDereferenceObject(Trace->Process);
    }

    //
    // Free the volume info nodes.
    //

    while (!IsListEmpty(&Trace->VolumeList)) {
        
        CCPF_ASSERT(Trace->NumVolumes);
        
        Trace->NumVolumes--;

        ListHead = RemoveHeadList(&Trace->VolumeList);
        
        VolumeInfo = CONTAINING_RECORD(ListHead,
                                       CCPF_VOLUME_INFO,
                                       VolumeLink);
        
        ExFreePool(VolumeInfo);
    }   
}

VOID
CcPfTraceTimerRoutine(
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    )

/*++

Routine Description:

    This routine is invoked as the DPC handler for the trace timer to
    keep track of page faults per period as well as trace timeout.

    Note that the timer may fire before the trace has been activated.

    There is always a trace reference associated with the timer queued,
    If the timer fires, this reference must be freed before this routine 
    returns. If the timer is canceled while in the queue, this reference
    must be freed by who has canceled it.

Arguments:

    DeferredContext - Pointer to the trace header.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == DISPATCH_LEVEL.

--*/

{
    PCCPF_TRACE_HEADER Trace;
    NTSTATUS Status;
    LONG NumFaults;
    
    UNREFERENCED_PARAMETER (Dpc);
    UNREFERENCED_PARAMETER (SystemArgument1);
    UNREFERENCED_PARAMETER (SystemArgument2);

    //
    // Initialize locals.
    //

    Trace = DeferredContext;

    DBGPR((CCPFID,PFTMR,"CCPF: TraceTimer(%p)\n", Trace));

    //
    // We already got a reference to our trace when the timer was queued.
    // The fields we access / update in this routine are only accessed by
    // the timer routine. There should be a single instance of this 
    // routine running on this trace.
    //

    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    //
    // If the trace is going away don't do anything.
    //

    if (Trace->EndTraceCalled) {
        Status = STATUS_TOO_LATE;
        goto cleanup;
    }

    //
    // Update number of faults for this period.
    //

    NumFaults = Trace->NumFaults;

    //
    // Don't let NumFaults be bigger than MaxFaults. We may interlocked increment
    // then decrement Trace->NumFaults if it goes over MaxFaults.
    //

    if (NumFaults > Trace->MaxFaults) {
        NumFaults = Trace->MaxFaults;
    }
        
    Trace->FaultsPerPeriod[Trace->CurPeriod] = NumFaults - Trace->LastNumFaults;
    
    Trace->LastNumFaults = NumFaults;

    //
    // Update current period.
    //
    
    Trace->CurPeriod++;

    //
    // If current period is past max number of periods, try to queue
    // end of trace work item.
    //

    if (Trace->CurPeriod >= PF_MAX_NUM_TRACE_PERIODS) {
        
        //
        // We should have caught CurPeriod before it goes above max.
        //

        CCPF_ASSERT(Trace->CurPeriod == PF_MAX_NUM_TRACE_PERIODS);

        if (!InterlockedCompareExchange(&Trace->EndTraceCalled, 1, 0)) {
            
            //
            // We set EndTraceCalled from 0 to 1. We can queue the
            // workitem now.
            //

            ExQueueWorkItem(&Trace->EndTraceWorkItem, DelayedWorkQueue);
        }

    } else {

        //
        // Queue ourselves for the next period.
        //

        KeAcquireSpinLockAtDpcLevel(&Trace->TraceTimerSpinLock);       

        if (!Trace->EndTraceCalled) {

            //
            // Requeue the timer only if the trace is not being ended.
            //

            Status = CcPfAddRef(&Trace->RefCount);

            if (NT_SUCCESS(Status)) {
        
                KeSetTimer(&Trace->TraceTimer,
                           Trace->TraceTimerPeriod,
                           &Trace->TraceTimerDpc);
            }
        }

        KeReleaseSpinLockFromDpcLevel(&Trace->TraceTimerSpinLock);

        //
        // We should not touch any fields of the Trace beyond this point
        // except releasing our reference count.
        //
    }

    Status = STATUS_SUCCESS;

 cleanup:

    //
    // Release the trace reference acquired when this timer was queued.
    //

    CcPfDecRef(&Trace->RefCount);

    DBGPR((CCPFID,PFTMR,"CCPF: TraceTimer(%p)=%x\n", Trace, Status));

    return;
}

NTSTATUS
CcPfCancelTraceTimer(
    IN PCCPF_TRACE_HEADER Trace
    )

/*++

Routine Description:

    This function is called from CcPfEndTrace to cancel the timer and
    release its refcount if it was in the queue. 

    It is a seperate function because it needs to acquire a spinlock and
    CcPfEndTrace can remain pagable.
    
Arguments:

    Trace - Pointer to trace header.

Return Value:

    STATUS_SUCCESS.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL. Acquires spinlock.


--*/

{
    KIRQL OrigIrql;

    KeAcquireSpinLock(&Trace->TraceTimerSpinLock, &OrigIrql);

    //
    // We know that no new timers can be queued from here on because EndTraceCalled
    // has been set and we have acquired the trace's timer lock. Running timer 
    // routines will release their references as they return. 
    //

    if (KeCancelTimer(&Trace->TraceTimer)) {

        //
        // If we canceled a timer that was in the queue, then there was a reference 
        // associated with it. It is our responsibility to release it.
        // 

        CcPfDecRef(&Trace->RefCount);
    }

    KeReleaseSpinLock(&Trace->TraceTimerSpinLock, OrigIrql);

    return STATUS_SUCCESS;
}

VOID
CcPfEndTraceWorkerThreadRoutine(
    PVOID Parameter
    )

/*++

Routine Description:

    This routine is queued to call end of trace function for the
    specified trace.

Arguments:

    Parameter - Pointer to trace to end.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_HEADER Trace;

    //
    // Initialize locals.
    //

    Trace = Parameter;

    DBGPR((CCPFID,PFTRC,"CCPF: EndTraceWorker(%p)\n", Trace));

    //
    // Call the real end of trace routine.
    //

    CcPfEndTrace(Trace);

    return;
}

VOID
CcPfGetFileNamesWorkerRoutine(
    PVOID Parameter
    )

/*++

Routine Description:

    This routine is queued to get file names for sections we have
    logged page faults to. GetFileNameWorkItemQueued on the trace
    header should have been InterlockedCompareExchange'd from 0 to 1
    and a reference to the trace should have been acquired before
    this is queued. There are no locks protecting the trace's
    SectionInfoTable, and this is how we make sure there is only one
    routine trying to get filenames and update the table.

    Note: This whole function is in a way a cleanup clause. We will
    empty the SectionsWithoutNamesList queue, we get names or not. So
    do not just put a return anywhere in the function without really
    understanding the flow and making sure the list is cleaned up, so
    all the file object references are deref'ed.

Arguments:

    Parameter - Pointer to trace header.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL. Uses interlocked slist operation.

--*/

{
    PCCPF_TRACE_HEADER Trace;
    PDEVICE_OBJECT DeviceObject;
    POBJECT_NAME_INFORMATION FileNameInfo;
    PFSRTL_COMMON_FCB_HEADER FcbHeader;
    PWCHAR Suffix;
    PWCHAR MFTFileSuffix;
    ULONG QueryBufferSize;
    ULONG ReturnedLength;
    ULONG FileNameLength;
    PCCPF_SECTION_INFO SectionInfo;
    PSLIST_ENTRY SectionLink;
    ULONG NumNamesAcquired;
    ULONG NumSectionsWithoutNames;
    LONG NumPasses;
    NTSTATUS Status;
    LARGE_INTEGER WaitTimeout;
    ULONG MFTFileSuffixLength;
    LONG NumSleeps;
    CSHORT NodeTypeCode;
    BOOLEAN SectionForMetafile;

    //
    // Initialize locals and validate parameters.
    //

    Trace = Parameter;
    CCPF_ASSERT(Trace && Trace->Magic == PF_TRACE_MAGIC_NUMBER);

    FileNameInfo = NULL;
    NumNamesAcquired = 0;
    NumSectionsWithoutNames = 0;
    MFTFileSuffix = L"\\$Mft";
    MFTFileSuffixLength = wcslen(MFTFileSuffix);

    // FUTURE-2002/02/21-ScottMa -- Calculating the above string length at
    //   runtime is not necessary, since the string is a constant.

    DBGPR((CCPFID,PFNAME,"CCPF: GetNames(%p)\n", Trace)); 

    //
    // Allocate a file name query buffer.
    //

    QueryBufferSize = sizeof(OBJECT_NAME_INFORMATION);
    QueryBufferSize += PF_MAXIMUM_SECTION_FILE_NAME_LENGTH * sizeof(WCHAR);

    FileNameInfo = ExAllocatePoolWithTag (PagedPool | POOL_COLD_ALLOCATION, 
                                          QueryBufferSize, 
                                          CCPF_ALLOC_QUERY_TAG);

    if (!FileNameInfo) {

        //
        // We could not allocate a file name query buffer. Bummer, we
        // still have to empty the queue, although we can't be getting
        // any file names.
        //

        QueryBufferSize = 0;

        DBGPR((CCPFID,PFWARN,"CCPF: GetNames-FailedQueryAlloc\n")); 
    }   

    NumPasses = 0;
    NumSleeps = 0;

    do {

        //
        // We may come back here if after saying that we (the get-name
        // worker) are no longer active, and we see that there are
        // still sections to get names for, and we reactivate
        // ourselves. This covers the case when somebody decides not
        // to start us because we are active, just as we are
        // deactivating ourselves.
        //

        //
        // While there are sections we have to get names for...
        //
        
        while (SectionLink = InterlockedPopEntrySList(&Trace->SectionsWithoutNamesList)) {

            SectionInfo = CONTAINING_RECORD(SectionLink,
                                            CCPF_SECTION_INFO,
                                            GetNameLink);
            
            NumSectionsWithoutNames++;

            //
            // We are getting names for sections. Clear the event that
            // may have been signalled to tell us to do so.
            //

            KeClearEvent(&Trace->GetFileNameWorkerEvent);

            //
            // We should not have already gotten a file name for this
            // valid section entry. We should have a referenced file
            // object from which we can safely get a name, i.e. not a
            // special file system object.
            //

            CCPF_ASSERT(SectionInfo->EntryValid);
            CCPF_ASSERT(!SectionInfo->FileName);
            CCPF_ASSERT(SectionInfo->ReferencedFileObject);

            //
            // If we could not allocate a file name query buffer, just skip this
            // section. Note that we still had to dequeue it however.
            //

            if (!FileNameInfo) {
                goto NextQueuedSection;
            }

            //
            // Check if this pagefault is for a file that's on a fixed disk.
            //

            DeviceObject = IoGetRelatedDeviceObject(SectionInfo->ReferencedFileObject);
            
            if ((DeviceObject == NULL) ||
                (DeviceObject->DeviceType != FILE_DEVICE_DISK_FILE_SYSTEM) ||
                (DeviceObject->Characteristics & (FILE_REMOVABLE_MEDIA | FILE_REMOTE_DEVICE))) {

                //
                // We will not get a section name for this section. This results 
                // in this section being ignored when preparing a trace dump.               
                //

                goto NextQueuedSection;
            }

            //
            // If this is a metafile section (e.g. for a directory) see if 
            // it is on a filesystem that supports metafile prefetching. 
            // A section is for internal file system metafile if its FsContext2 
            // is NULL. 
            //

            SectionForMetafile = FALSE;

            if (SectionInfo->ReferencedFileObject->FsContext2 == 0) {

                FcbHeader = SectionInfo->ReferencedFileObject->FsContext;

                if (FcbHeader) {

                    //
                    // Currently only NTFS supports metafile prefetching. FAT hits 
                    // a race condition  if we ask names for metafile sections. 
                    // To determine if it is for NTFS, we check the NodeType range  
                    // on FsContext. 0x07xx is reserved for NTFS and 0x05xx 
                    // is reserved for FAT.

                    NodeTypeCode = FcbHeader->NodeTypeCode;

                    if ((NodeTypeCode >> 8) != 0x07) {

                        //
                        // Skip this section.
                        //

                        goto NextQueuedSection;
                    }

                    //
                    // Note that this section is for metafile.
                    //

                    SectionForMetafile = TRUE;

                } else {

                    //
                    // We will not get a section name for this metafile section. This 
                    // results in this section being ignored when preparing a trace dump.
                    //

                    goto NextQueuedSection;
                }
            }

            //
            // Try to get the name for the file object. This will most
            // likely fail if we could not allocate a FileNameInfo
            // buffer.
            //
                
            Status = ObQueryNameString(SectionInfo->ReferencedFileObject,
                                       FileNameInfo,
                                       QueryBufferSize,
                                       &ReturnedLength);

            
            if (!NT_SUCCESS(Status)) {
                goto NextQueuedSection;
            }

            //
            // Allocate a file name buffer and copy into
            // it. The file names will be NUL terminated.
            // Allocate extra for that.
            //
                
            FileNameLength = FileNameInfo->Name.Length / sizeof(WCHAR);
                
            SectionInfo->FileName = ExAllocatePoolWithTag(PagedPool | POOL_COLD_ALLOCATION,
                                                          (FileNameLength + 1) * sizeof(WCHAR),
                                                          CCPF_ALLOC_FILENAME_TAG);
                
            if (SectionInfo->FileName) {
                    
                RtlCopyMemory(SectionInfo->FileName,
                              FileNameInfo->Name.Buffer,
                              FileNameLength * sizeof(WCHAR));
                    
                //
                // Make sure it is NUL terminated.
                //

                SectionInfo->FileName[FileNameLength] = 0;

                //
                // If the section is for a metafile check if it is for Mft. 
                // Unlike other metafile, we are interested in faults from
                // Mft in addition to knowing that we accessed it at all.
                //

                if (SectionForMetafile) {

                    if (FileNameLength >= MFTFileSuffixLength) {

                        Suffix = SectionInfo->FileName + FileNameLength;
                        Suffix -= MFTFileSuffixLength;

                        //
                        // Note that we can avoid expensive case insensitive
                        // comparison because NTFS returns the name for Mft
                        // as always $Mft.
                        //

                        if (wcscmp(Suffix, MFTFileSuffix) == 0) {

                            //
                            // Clear the "Metafile" bit of MFT so we keep
                            // track of faults from it.
                            //

                            SectionForMetafile = FALSE;
                        }
                    }
                }

                //
                // Update the section structure.
                //

                if (SectionForMetafile) {
                    SectionInfo->Metafile = 1;
                } else {
                    SectionInfo->Metafile = 0;
                }

                //
                // Update the volume list with the volume this
                // section is on. We reuse the existing query
                // buffer to get volume's name since we've already
                // copied the file's name to another buffer. The
                // device object for the file should be for the
                // volume.
                //

                Status = ObQueryNameString(SectionInfo->ReferencedFileObject->DeviceObject,
                                           FileNameInfo,
                                           QueryBufferSize,
                                           &ReturnedLength);
                
                if (NT_SUCCESS(Status)) {                 

                    RtlUpcaseUnicodeString(&FileNameInfo->Name, &FileNameInfo->Name, FALSE);

                    Status = CcPfUpdateVolumeList(Trace,
                                                  FileNameInfo->Name.Buffer,
                                                  FileNameInfo->Name.Length / sizeof(WCHAR));
                }

                if (!NT_SUCCESS(Status)) {

                    //
                    // If we could not update the volume list as
                    // necessary for this section, we have to
                    // cleanup and ignore this section.
                    //
                    
                    ExFreePool(SectionInfo->FileName);
                    SectionInfo->FileName = NULL;
                    
                } else {
                    
                    NumNamesAcquired++;
                }

            }

          NextQueuedSection:
          
            //
            // Dereference the file object, and clear it on the section
            // entry.
            //

            ObDereferenceObject(SectionInfo->ReferencedFileObject);
            SectionInfo->ReferencedFileObject = NULL;

            //
            // If we could not get a name because the query failed or
            // we could not allocate a name buffer, too bad. For this
            // run, pagefaults for this section will be ignored. Over
            // time it will straighten itself out.
            //
        }

        //
        // We don't seem to have any more queued section
        // entries. Before marking ourself inactive, wait a
        // little. Maybe someone will want us to get name for another
        // section. Then we'll save the overhead of queuing another
        // workitem. Set a limit on how long we'll wait though
        // [negative because it is relative, in 100ns].
        //

        //
        // Note that we are sleeping while holding a trace
        // reference. If end trace gets called, it also signals the
        // event to make us release that reference quicker.
        //

        //
        // If we could not even allocate a query buffer,
        // no reason to wait for more misery.
        //

        if (FileNameInfo) {

            WaitTimeout.QuadPart = - 200 * 1000 * 10; // 200 ms.

            DBGPR((CCPFID,PFNAMS,"CCPF: GetNames-Sleeping:%p\n", Trace)); 

            NumSleeps++;

            Status = KeWaitForSingleObject(&Trace->GetFileNameWorkerEvent,
                                           Executive,
                                           KernelMode,
                                           FALSE,
                                           &WaitTimeout);

            DBGPR((CCPFID,PFNAMS,"CCPF: GetNames-WokeUp:%x\n", Status)); 
        }
        
        //
        // If there are no new sections to get names for, go ahead and
        // mark ourselves inactive, otherwise we will loop to get more
        // names.
        //

        if (!ExQueryDepthSList(&Trace->SectionsWithoutNamesList)) {

            //
            // We went through all the queued section entries. Note that
            // we are no longer active.
            //

            InterlockedExchange(&Trace->GetFileNameWorkItemQueued, 0);

            //
            // Check to see if there are new sections to get file
            // names for since we last checked and marked ourselves
            // inactive.
            //
        
            if (ExQueryDepthSList(&Trace->SectionsWithoutNamesList)) {

                //
                // Somebody may have inserted a section to get name for,
                // but seeing us active may not have queued another work
                // item. If it is so and we don't get name for that
                // section, we may keep the file object referenced for
                // longer than we'd like to. Try to mark ourselves active
                // again.
                //

                if (!InterlockedCompareExchange(&Trace->GetFileNameWorkItemQueued, 
                                                1, 
                                                0)) {

                    //
                    // We marked ourselves active. They really may not
                    // have queued another worker. Loop and check for
                    // more work.
                    //

                } else {
                
                    //
                    // It seems another worker was queued. Any items
                    // on the work list are that guy's problem
                    // now. Break out and cleanup.
                    //

                    break;
                }

            } else {

                //
                // No more work items on the list. We are really
                // done. Just break out and cleanup.
                //

                break;
            }
        }

        //
        // Bump number of passes we've made over the sections-without-
        // names-list. We should not have to make more passes than the
        // max number of section info entries we can have. This is an
        // infinite loop protection and should not happen. If it does,
        // however, in the worst case we will keep a reference to a
        // file object longer than we'd like to, and we may not get a
        // file name for it.
        //

        NumPasses++;
        if (NumPasses > Trace->MaxSections) {    
            CCPF_ASSERT(FALSE);
            break;
        }
       
    } while (TRUE);

    //
    // Clean up:
    //

    if (FileNameInfo) {
        ExFreePool(FileNameInfo);
    }

    //
    // Release reference on the trace as the very last thing. Don't
    // touch anything from the trace after this.
    //

    CcPfDecRef(&Trace->RefCount);

    DBGPR((CCPFID,PFNAME,"CCPF: GetNames(%p)=%d-%d,[%d-%d]\n", 
           Trace, NumSectionsWithoutNames, NumNamesAcquired,
           NumPasses, NumSleeps)); 

    return;
}

LONG
CcPfLookUpSection(
    PCCPF_SECTION_INFO Table,
    ULONG TableSize,
    PSECTION_OBJECT_POINTERS SectionObjectPointer,
    PLONG AvailablePosition
    )

/*++

Routine Description:

    This routine is called to look up a section in the specified
    section table hash. If the section is found its index is
    returned. Otherwise index to where the section should go in the
    table is put into AvailablePosition, if the table is not
    full.

Arguments:

    Table - An array of section info entries used as a hash table.

    TableSize - Maximum size of the table.

    SectionObjectPointer - This is used as a key to identify a mapping.

    AvailablePosition - If section is not found and there is room in
      the table, index of where the section should go is put here.

Return Value:

    Index into the table where the section is found or CCPF_INVALID_TABLE_INDEX

Environment:

    Kernel mode, IRQL <= DISPATCH_LEVEL if Table is NonPaged.

--*/

{
    PCCPF_SECTION_INFO Entry;
    ULONG StartIdx;
    ULONG EndIdx;
    ULONG EntryIdx;
    ULONG HashIndex;
    ULONG NumPasses;

    //
    // Get the hashed index into the table where the entry ideally
    // should be at.
    //

    HashIndex = CcPfHashValue((PVOID)&SectionObjectPointer, 
                              sizeof(SectionObjectPointer)) % TableSize;

    //
    // We will make two runs through the table looking for the
    // entry. First starting from the hashed position up to the end of
    // the table. Next from the beginning of the table up to the
    // hashed position.
    //

    NumPasses = 0;

    do {

        //
        // Setup start and end indices accordingly.
        //

        if (NumPasses == 0) {
            StartIdx = HashIndex;
            EndIdx = TableSize;
        } else {
            StartIdx = 0;
            EndIdx = HashIndex;
        }
    
        for (EntryIdx = StartIdx; EntryIdx < EndIdx; EntryIdx++) {
            
            Entry = &Table[EntryIdx];
            
            if (Entry->EntryValid) {
                
                if (Entry->SectionObjectPointer == SectionObjectPointer) {

                    //
                    // Check if other saved fields match the fields of
                    // the SectionObjectPointer we are trying to find.
                    // Please see the comments in CCPF_SECTION_INFO
                    // definition.
                    //
                    
                    if (Entry->DataSectionObject == SectionObjectPointer->DataSectionObject &&
                        Entry->ImageSectionObject == SectionObjectPointer->ImageSectionObject) {
                    
                        //
                        // We found the entry.
                        //
                        
                        *AvailablePosition = CCPF_INVALID_TABLE_INDEX;
                    
                        return EntryIdx;

                    } else if (Entry->DataSectionObject == SectionObjectPointer->DataSectionObject ||
                               Entry->ImageSectionObject == SectionObjectPointer->ImageSectionObject) {
                        
                        //
                        // If one of them matches, check to see if the
                        // one that does not match is NULL on the
                        // Entry. We don't want to create two entries
                        // for the same file when it is first opened
                        // as data and then as image or vice
                        // versa. Note that if later image or data
                        // segment gets deleted, we may end up
                        // creating a new entry. We are optimizing
                        // only for the case that we think is likely
                        // to happen often.
                        //
                        
                        if (Entry->DataSectionObject == NULL &&
                            SectionObjectPointer->DataSectionObject != NULL) {

                            DBGPR((CCPFID,PFLKUP,"CCPF: LookupSect-DataSectUpt(%p)\n", SectionObjectPointer)); 

                            //
                            // Try to update the entry. If our update
                            // was succesful, return found entry.
                            //

                            InterlockedCompareExchangePointer(&Entry->DataSectionObject,
                                                              SectionObjectPointer->DataSectionObject,
                                                              NULL);

                            if (Entry->DataSectionObject == SectionObjectPointer->DataSectionObject) {
                                 *AvailablePosition = CCPF_INVALID_TABLE_INDEX;
                                 return EntryIdx;
                            }
                        }
                        
                        if (Entry->ImageSectionObject == NULL &&
                            SectionObjectPointer->ImageSectionObject != NULL) {

                            DBGPR((CCPFID,PFLKUP,"CCPF: LookupSect-ImgSectUpt(%p)\n", SectionObjectPointer)); 

                            //
                            // Try to update the entry. If our update
                            // was succesful, return found entry.
                            //
                            
                            InterlockedCompareExchangePointer(&Entry->ImageSectionObject,
                                                              SectionObjectPointer->ImageSectionObject,
                                                              NULL);

                            if (Entry->ImageSectionObject == SectionObjectPointer->ImageSectionObject) {
                                 *AvailablePosition = CCPF_INVALID_TABLE_INDEX;
                                 return EntryIdx;
                            }
                        }

                        //
                        // Most likely, the field that matched was
                        // NULL, signifying nothing. Fall through to
                        // continue with the lookup.
                        //
                    }

                    //
                    // Although the SectionObjectPointer matches the
                    // other fields don't match. The old file may be
                    // gone and this may be a new file that somehow
                    // ended up with the same SectionObjectPointer.
                    // Continue the lookup.
                    //

                }
                
            } else {
                
                //
                // This is an available position. The fact that the entry
                // is not here means the entry is not in the table.
                //
                
                *AvailablePosition = EntryIdx;
                
                return CCPF_INVALID_TABLE_INDEX;
            }

        }

        NumPasses++;

    } while (NumPasses < 2);

    //
    // We could not find the entry or an available position.
    //

    *AvailablePosition = CCPF_INVALID_TABLE_INDEX;

    return CCPF_INVALID_TABLE_INDEX;
}

NTSTATUS
CcPfGetCompletedTrace (
    PVOID Buffer,
    ULONG BufferSize,
    PULONG ReturnSize
    )

/*++

Routine Description:

    If there is a completed scenario trace on the completed traces
    list, this routine tries to copy it into the supplied buffer and
    remove it. If BufferSize is too small, nothing is copied or
    removed from the list, but ReturnSize is set to how big a buffer
    is needed to get the first trace on the list. If BufferSize is
    large enough, the number of bytes copied into the buffer is set on
    the ReturnSize.

Arguments:

    Buffer - Caller supplied buffer to copy a completed trace into.

    BufferSize - Size of the caller supplied buffer in bytes.

    ReturnSize - If BufferSize is big enough for the completed trace
      number of bytes copied is put here. If BufferSize is not big
      enough for the trace, the required size is put here. If there
      are no more entries, this variable undefined.

Return Value:

    STATUS_BUFFER_TOO_SMALL - BufferSize is not big enough for the
      first completed trace on the list.

    STATUS_NO_MORE_ENTRIES - There are no more completed traces on the
      list.

    STATUS_SUCCESS - A trace was removed from the list and copied into
      the buffer.

    or other status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_TRACE_DUMP TraceDump;
    NTSTATUS Status;
    KPROCESSOR_MODE PreviousMode;
    BOOLEAN HoldingCompletedTracesLock;

    //
    // Initialize locals.
    //

    HoldingCompletedTracesLock = FALSE;

    DBGPR((CCPFID,PFTRC,"CCPF: GetCompletedTrace()\n"));

    //
    // Get the completed traces lock. 
    //

    ExAcquireFastMutex(&CcPfGlobals.CompletedTracesLock);

    HoldingCompletedTracesLock = TRUE;

    //
    // If the list is empty, there are no more completed trace entries.
    //
    
    if (IsListEmpty(&CcPfGlobals.CompletedTraces)) {
        Status = STATUS_NO_MORE_ENTRIES;
        goto cleanup;
    }

    //
    // Peek at the trace to see if it will fit into the supplied
    // buffer.
    //

    TraceDump = CONTAINING_RECORD(CcPfGlobals.CompletedTraces.Flink,
                                  CCPF_TRACE_DUMP,
                                  CompletedTracesLink);
    
    if (TraceDump->Trace.Size > BufferSize) {
        *ReturnSize = TraceDump->Trace.Size;
        Status = STATUS_BUFFER_TOO_SMALL;
        goto cleanup;
    }

    //
    // The trace will fit in the user supplied buffer. Remove it from
    // the list, release the lock and copy it.
    //
    
    RemoveHeadList(&CcPfGlobals.CompletedTraces);
    CcPfGlobals.NumCompletedTraces--;
    
    ExReleaseFastMutex(&CcPfGlobals.CompletedTracesLock);

    HoldingCompletedTracesLock = FALSE;
    
    //
    // Copy the completed trace buffer.
    //

    Status = STATUS_SUCCESS;

    try {

        //
        // If called from user-mode, probe whether it is safe to write 
        // to the pointer passed in.
        //

        PreviousMode = KeGetPreviousMode();

        if (PreviousMode != KernelMode) {
            ProbeForWrite(Buffer, BufferSize, _alignof(PF_TRACE_HEADER));
        }

        //
        // Copy into the probed user buffer.
        //

        RtlCopyMemory(Buffer,
                      &TraceDump->Trace,
                      TraceDump->Trace.Size);

    } except (EXCEPTION_EXECUTE_HANDLER) {

        Status = GetExceptionCode();
    }

    if (!NT_SUCCESS(Status)) {

        //
        // The copy failed. Requeue the trace for the next query.
        // Note that we might end up with one too many traces in
        // the list because of this, but that's OK.
        //

        ExAcquireFastMutex(&CcPfGlobals.CompletedTracesLock);
        HoldingCompletedTracesLock = TRUE;
        InsertHeadList(&CcPfGlobals.CompletedTraces,&TraceDump->CompletedTracesLink);
        CcPfGlobals.NumCompletedTraces++;

    } else {
    
        //
        // Set number of bytes copied.
        //

        *ReturnSize = TraceDump->Trace.Size;
    
        //
        // Free the trace dump entry.
        //
    
        ExFreePool(TraceDump);

        //
        // We are done.
        //

        Status = STATUS_SUCCESS;
    }

 cleanup:

    if (HoldingCompletedTracesLock) {
        ExReleaseFastMutex(&CcPfGlobals.CompletedTracesLock);
    }

    DBGPR((CCPFID,PFTRC,"CCPF: GetCompletedTrace()=%x\n", Status));

    return Status;
}


NTSTATUS
CcPfUpdateVolumeList(
    PCCPF_TRACE_HEADER Trace,
    WCHAR *VolumePath,
    ULONG VolumePathLength
    )

/*++

Routine Description:

    If the specified volume is not in the volume list of Trace, its
    information is acquired and added to the list.

    This routine does not use any synchronization when accessing and
    updating the volume list on the trace.
    
Arguments:

    Trace - Pointer to trace.
    
    VolumePath - Pointer to UPCASED volume path. Does NOT need to be NUL
      terminated.
    
    VolumePathLength - Length of VolumePath in characters excluding
      NUL.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    PLIST_ENTRY NextEntry;
    PLIST_ENTRY FoundPosition;
    PLIST_ENTRY HeadEntry;
    PCCPF_VOLUME_INFO CurrentVolumeInfo;
    PCCPF_VOLUME_INFO NewVolumeInfo;
    LONG ComparisonResult;
    ULONG AllocationSize;
    BOOLEAN InsertedNewVolume;

    //
    // Define an enumeration for the passes we make over the volume
    // list.
    //

    enum {
        LookingForVolume,
        AddingNewVolume,
        MaxLoopIdx
    } LoopIdx;

    //
    // Initialize locals.
    //
    
    NewVolumeInfo = NULL;
    InsertedNewVolume = FALSE;

    //
    // We should be called with a valid volume name.
    //
    
    if (!VolumePathLength) {
        CCPF_ASSERT(VolumePathLength != 0);
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    // FUTURE-2002/02/20-ScottMa -- There is no need for an additional 
    // pass.

    //
    // Walk the volume list. We will make two passes. First we will 
    // check to see if the volume already exists in the list. If it 
    // does not, we'll build a new volume node and make a second 
    // pass to insert it. If we need to protect this list with a lock
    // we could release the lock while building the new volume node
    // and reacquire it for the second pass.
    //
    
    for (LoopIdx = LookingForVolume; LoopIdx < MaxLoopIdx; LoopIdx++) {

        //
        // Determine what to do based on which pass we are in.
        //

        if (LoopIdx == LookingForVolume) {
            
            CCPF_ASSERT(!InsertedNewVolume);
            CCPF_ASSERT(!NewVolumeInfo);

        } else if (LoopIdx == AddingNewVolume) {
            
            CCPF_ASSERT(!InsertedNewVolume);
            CCPF_ASSERT(NewVolumeInfo);    

        } else {

            //
            // We should only loop two times.
            //

            CCPF_ASSERT(FALSE);

            Status = STATUS_UNSUCCESSFUL;
            goto cleanup;
        }

        HeadEntry = &Trace->VolumeList;
        NextEntry = HeadEntry->Flink;
        FoundPosition = NULL;
        
        while (NextEntry != HeadEntry) {
        
            CurrentVolumeInfo = CONTAINING_RECORD(NextEntry,
                                                  CCPF_VOLUME_INFO,
                                                  VolumeLink);

            NextEntry = NextEntry->Flink;

            ComparisonResult = wcsncmp(VolumePath, 
                                       CurrentVolumeInfo->VolumePath, 
                                       VolumePathLength);
        
            if (ComparisonResult == 0) {

                //
                // Make sure VolumePathLength's are equal
                //
            
                if (CurrentVolumeInfo->VolumePathLength != VolumePathLength) {
                
                    //
                    // Continue searching.
                    //
                
                    continue;
                }
            
                //
                // The volume already exists in the list.
                //
            
                Status = STATUS_SUCCESS;
                goto cleanup;

            } else if (ComparisonResult < 0) {
            
                //
                // The volume paths are sorted lexically. The file
                // path would be less than other volumes too. We'd
                // insert the new node before this entry.
                //

                FoundPosition = &CurrentVolumeInfo->VolumeLink;

                break;
            }

            //
            // Continue looking...
            //
        
        }

        //
        // If we could not find an entry to insert the new node
        // before, it goes before the list head.
        //

        if (!FoundPosition) {
            FoundPosition = HeadEntry;
        }

        //
        // If we come here, we could not find the volume in the list.
        //

        //
        // If this is the first pass over the list (we were checking
        // if the volume already exists), release the lock and build a
        // volume node.
        //

        if (LoopIdx == LookingForVolume) {

            // 
            // Build a new node. Note that CCPF_VOLUME_INFO already
            // has space for the terminating NUL character.
            //

            AllocationSize = sizeof(CCPF_VOLUME_INFO);
            AllocationSize += VolumePathLength * sizeof(WCHAR);

            NewVolumeInfo = ExAllocatePoolWithTag(PagedPool | POOL_COLD_ALLOCATION,
                                                  AllocationSize,
                                                  CCPF_ALLOC_VOLUME_TAG);
    
            if (!NewVolumeInfo) {
                Status = STATUS_INSUFFICIENT_RESOURCES;
                goto cleanup;
            }

            //
            // Copy the volume name and terminate it.
            //
    
            RtlCopyMemory(NewVolumeInfo->VolumePath,
                          VolumePath,
                          VolumePathLength * sizeof(WCHAR));
    
            NewVolumeInfo->VolumePath[VolumePathLength] = 0;
            NewVolumeInfo->VolumePathLength = VolumePathLength;

            //
            // Query the signature and creation time.
            //

            Status = CcPfQueryVolumeInfo(NewVolumeInfo->VolumePath,
                                         NULL,
                                         &NewVolumeInfo->CreationTime,
                                         &NewVolumeInfo->SerialNumber);

            if (!NT_SUCCESS(Status)) {
                goto cleanup;
            }

            //
            // The new volume is ready to be inserted into the list,
            // if somebody has not acted before us. Loop and go
            // through the volume list again.
            //

        } else if (LoopIdx == AddingNewVolume) {
    
            //
            // Insert the volume node before the found position.
            //
            
            InsertTailList(FoundPosition, &NewVolumeInfo->VolumeLink);
            Trace->NumVolumes++;
            InsertedNewVolume = TRUE;

            Status = STATUS_SUCCESS;
            goto cleanup;

        } else {

            //
            // We should only loop two times.
            //

            CCPF_ASSERT(FALSE);

            Status = STATUS_UNSUCCESSFUL;
            goto cleanup;   
        }
    }

    //
    // We should not come here.
    //
    
    CCPF_ASSERT(FALSE);

    Status = STATUS_UNSUCCESSFUL;

 cleanup:

    if (!NT_SUCCESS(Status)) {
        if (NewVolumeInfo) {
            ExFreePool(NewVolumeInfo);
        }
    } else {
        if (!InsertedNewVolume && NewVolumeInfo) {
            ExFreePool(NewVolumeInfo);
        }
    }

    return Status;
}

//
// Routines used for prefetching and dealing with prefetch instructions.
//

NTSTATUS
CcPfPrefetchScenario (
    PPF_SCENARIO_HEADER Scenario
    )

/*++

Routine Description:

    This routine checks for prefetch instructions for the specified
    scenario and asks Mm to prefetch those pages. 

Arguments:

    Scenario - Prefetch instructions for the scenario.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    CCPF_PREFETCH_HEADER PrefetchHeader;

    //
    // Initialize locals & prefetch context.
    //
    
    CcPfInitializePrefetchHeader(&PrefetchHeader);

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchScenario(%p)\n", Scenario)); 

    //
    // Scenario instructions should be passed in.
    //
    
    if (!Scenario) {
        CCPF_ASSERT(Scenario);
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Check if prefetching is enabled.
    //
    
    if (!CCPF_IS_PREFETCHER_ENABLED()) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }
    
    //
    // Check if prefetching is enabled for the specified scenario type.
    //

    if (CcPfGlobals.Parameters.Parameters.EnableStatus[Scenario->ScenarioType] != PfSvEnabled) {
        Status = STATUS_NOT_SUPPORTED;
        goto cleanup;
    }

    //
    // Save prefetch instructions pointer on the header.
    //

    PrefetchHeader.Scenario = Scenario;

    //
    // Try to make sure we have enough available memory to prefetch
    // what we want to prefetch.
    //

    if (!MmIsMemoryAvailable((PFN_NUMBER)PrefetchHeader.Scenario->NumPages)) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        DBGPR((CCPFID,PFPREF,"CCPF: PrefetchScenario-MemNotAvailable\n")); 
        goto cleanup;
    }

    //
    // Open the volumes we will prefetch on, making sure they are 
    // already mounted and the serials match etc.
    //

    Status = CcPfOpenVolumesForPrefetch(&PrefetchHeader);
    
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Prefetch the filesystem metadata we will need, so metadata I/Os
    // do not get in the way of efficient prefetch I/O. Since this is
    // not critical, ignore return value.
    //

    CcPfPrefetchMetadata(&PrefetchHeader);

    //
    // Prefetch the pages accessed through data mappings. This will
    // also bring in the header pages for image mappings.
    //

    Status = CcPfPrefetchSections(&PrefetchHeader, 
                                  CcPfPrefetchAllDataPages,  
                                  NULL,
                                  0,
                                  NULL,
                                  NULL);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Prefetch the pages accessed through image mappings.
    //

    Status = CcPfPrefetchSections(&PrefetchHeader, 
                                  CcPfPrefetchAllImagePages,
                                  NULL,
                                  0,
                                  NULL,
                                  NULL);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    Status = STATUS_SUCCESS;

 cleanup:

    CcPfCleanupPrefetchHeader(&PrefetchHeader);

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchScenario(%ws)=%x\n", Scenario->ScenarioId.ScenName, Status)); 

    return Status;
}

NTSTATUS
CcPfPrefetchSections(
    IN PCCPF_PREFETCH_HEADER PrefetchHeader,
    IN CCPF_PREFETCH_TYPE PrefetchType,
    OPTIONAL IN PCCPF_PREFETCH_CURSOR StartCursor,
    OPTIONAL PFN_NUMBER TotalPagesToPrefetch,
    OPTIONAL OUT PPFN_NUMBER NumPagesPrefetched,
    OPTIONAL OUT PCCPF_PREFETCH_CURSOR EndCursor
    )

/*++

Routine Description:

    This routine prepares read lists for the specified pages in the
    scenario and calls Mm to prefetch them. This function is usually
    called first to prefetch data pages then image pages. When
    prefetching data pages, header pages for any image mappings are
    also prefetched, which would otherwise hurt efficiency when
    prefetching image pages.   

Arguments:

    PrefetchHeader - Pointer to the prefetch header.

    PrefetchType - What/How to prefetch.

    StartCursor - If prefetching only part of the scenario, where to
      start prefetching from.

    TotalPagesToPrefetch - If prefetching only part of the scenario, how
      many pages to prefetch. This function may prefetch more or less pages
      as it sees fit.

    NumPagesPrefetched - If prefetching only part of the scenario,
      this is the number of pages we asked Mm to prefetch.

    EndCursor - If prefetching only part of the scenario, this is
      updated to the position NumPages pages after the StartCursor.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PWCHAR FilePath;
    PCCPF_PREFETCH_VOLUME_INFO VolumeNode;
    PREAD_LIST *ReadLists;
    PREAD_LIST ReadList;
    HANDLE *FileHandleTable;
    HANDLE FileHandle;
    PFILE_OBJECT *FileObjectTable;
    PFILE_OBJECT FileObject;
    PSECTION *SectionObjectTable;
    PSECTION SectionObject;
    PPF_SECTION_RECORD SectionRecord;
    PPF_SECTION_RECORD SectionRecords;
    PCHAR FileNameData;
    UNICODE_STRING SectionName;
    PPF_PAGE_RECORD PageRecord;
    PPF_PAGE_RECORD PageRecords;
    ULONG SectionIdx;
    ULONG ReadListIdx;
    LONG PageIdx;
    ULONG NumReadLists;
    ULONG AllocationSize;
    NTSTATUS Status;
    LOGICAL PrefetchingImagePages;
    BOOLEAN AddedHeaderPage;
    BOOLEAN PrefetchingPartOfScenario;
    ULONGLONG LastOffset;
    ULONG NumberOfSections;
    ULONG NumPagesToPrefetch;
    ULONG NumSectionPages;
    PUCHAR Tables;
    PUCHAR CurrentPosition;
    PPF_SCENARIO_HEADER Scenario;
    ULONG StartSectionNumber;
    ULONG StartPageNumber;

    //
    // Initialize locals so we know what to cleanup.
    //

    Scenario = PrefetchHeader->Scenario;
    Tables = NULL;
    ReadList = NULL;
    ReadLists = NULL;
    FileHandle = NULL;
    FileHandleTable = NULL;
    FileObject = NULL;
    FileObjectTable = NULL;
    SectionObject = NULL;
    SectionObjectTable = NULL;
    NumReadLists = 0;
    NumberOfSections = Scenario->NumSections;
    NumPagesToPrefetch = 0;
    NumSectionPages = 0;
    PageIdx = 0;

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchSections(%p,%d,%d,%d)\n", 
           PrefetchHeader, PrefetchType,
           (StartCursor)?StartCursor->SectionIdx:0,
           (StartCursor)?StartCursor->PageIdx:0)); 

    //
    // Validate parameters.
    //

    if (PrefetchType < 0 || PrefetchType >= CcPfMaxPrefetchType) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Determine whether we are prefetching data or image pages and
    // other parameters based on prefetch type.
    //

    switch (PrefetchType) {

    case CcPfPrefetchAllDataPages:
        StartSectionNumber = 0;
        StartPageNumber = 0;
        PrefetchingImagePages = FALSE;
        PrefetchingPartOfScenario = FALSE;
        break;

    case CcPfPrefetchAllImagePages:
        StartSectionNumber = 0;
        StartPageNumber = 0;
        PrefetchingImagePages = TRUE;
        PrefetchingPartOfScenario = FALSE;
        break;

    case CcPfPrefetchPartOfDataPages:

        if (!StartCursor) {
            CCPF_ASSERT(StartCursor);
            Status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }

        StartSectionNumber = StartCursor->SectionIdx;
        StartPageNumber = StartCursor->PageIdx;
        PrefetchingImagePages = FALSE;
        PrefetchingPartOfScenario = TRUE;
        break;

    case CcPfPrefetchPartOfImagePages:

        if (!StartCursor) {
            CCPF_ASSERT(StartCursor);
            Status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }

        StartSectionNumber = StartCursor->SectionIdx;
        StartPageNumber = StartCursor->PageIdx;
        PrefetchingImagePages = TRUE;
        PrefetchingPartOfScenario = TRUE;
        break;

    default:
        
        //
        // We should be handling all types above.
        //
        
        CCPF_ASSERT(FALSE);

        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Allocate and initialize intermediate tables. We will make a
    // single allocation for all the tables.
    //

    AllocationSize = sizeof(PREAD_LIST) * NumberOfSections;
    AllocationSize += sizeof(HANDLE) * NumberOfSections;
    AllocationSize += sizeof(PFILE_OBJECT) * NumberOfSections;
    AllocationSize += sizeof(PSECTION) * NumberOfSections;

    Tables = ExAllocatePoolWithTag(PagedPool,
                                   AllocationSize,
                                   CCPF_ALLOC_INTRTABL_TAG);

    if (!Tables) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Zero out the whole buffer. This initializes all elements of the
    // tables to NULL.
    //

    RtlZeroMemory(Tables, AllocationSize);
    
    //
    // Determine where each table goes in the buffer.
    //

    CurrentPosition = Tables;

    ReadLists = (PREAD_LIST *) CurrentPosition;
    CurrentPosition += sizeof(PREAD_LIST) * NumberOfSections;
    FileHandleTable = (HANDLE *) CurrentPosition;
    CurrentPosition += sizeof(HANDLE) * NumberOfSections;
    FileObjectTable = (PFILE_OBJECT *) CurrentPosition;
    CurrentPosition += sizeof(PFILE_OBJECT) * NumberOfSections;
    SectionObjectTable = (PSECTION *) CurrentPosition;
    CurrentPosition += sizeof(PSECTION) * NumberOfSections;

    //
    // We should have allocated the right size buffer.
    //

    CCPF_ASSERT(CurrentPosition == Tables + AllocationSize);

    //
    // Go through the sections and prepare read lists. We may not have
    // a read list for every section in the scenario so keep another
    // counter, NumReadLists, to keep our read list array compact.
    //

    SectionRecords = (PPF_SECTION_RECORD) 
        ((PCHAR) Scenario + Scenario->SectionInfoOffset);

    PageRecords = (PPF_PAGE_RECORD) 
        ((PCHAR) Scenario + Scenario->PageInfoOffset);

    FileNameData = (PCHAR) Scenario + Scenario->FileNameInfoOffset;
    
    for (SectionIdx = StartSectionNumber; 
         SectionIdx < NumberOfSections; 
         SectionIdx ++) {

        SectionRecord = &SectionRecords[SectionIdx];

        //
        // Skip this section if it was marked ignore for some reason.
        //

        if (SectionRecord->IsIgnore) {
            continue;
        }

        //
        // If this section is on a bad volume (e.g. one that was not
        // mounted or whose serial / creation time did not match the
        // volume we had traced), we cannot prefetch this section.
        //

        FilePath = (WCHAR *) (FileNameData + SectionRecord->FileNameOffset);
        
        VolumeNode = CcPfFindPrefetchVolumeInfoInList(FilePath,
                                                      &PrefetchHeader->BadVolumeList);

        if (VolumeNode) {
            continue;
        }

        //
        // The section info should either be for an image or data
        // mapping or both.
        //

        CCPF_ASSERT(SectionRecord->IsImage || SectionRecord->IsData);

        //
        // If we are prefetching image pages and this section does not 
        // have image pages skip it. Note that the reverse is not
        // true. We prefetch headers for an image section when
        // prefetching data pages.
        //

        if (PrefetchingImagePages && !SectionRecord->IsImage) {
            continue;
        }

        //
        // Allocate a read list. Note that READ_LIST has storage for a
        // FILE_SEGMENT_ELEMENT. We allocate space for one extra page
        // in case we have to also bring in a header page for image
        // mapping.
        //

        AllocationSize = sizeof(READ_LIST) + 
            (SectionRecord->NumPages * sizeof(FILE_SEGMENT_ELEMENT));

        ReadList = ExAllocatePoolWithTag(NonPagedPool,
                                         AllocationSize,
                                         CCPF_ALLOC_READLIST_TAG);

        if (ReadList == NULL) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto cleanup;
        }
        
        //
        // Initialize header fields of the read list.
        //

        ReadList->FileObject = 0;
        ReadList->IsImage = PrefetchingImagePages;
        ReadList->NumberOfEntries = 0;
        
        //
        // If we are prefetching data pages and this section was
        // mapped as an image, add the header page to the readlist.
        // This way when creating the image mapping to prefetch image
        // pages we don't have to read it from the disk inefficiently.
        //

        AddedHeaderPage = FALSE;

        if((PrefetchingImagePages == FALSE) && SectionRecord->IsImage) {

            //
            // Don't add the header page if we are prefetching only
            // part of the section and we are past the first page.
            //

            BOOLEAN PrefetchHeaderPage = FALSE;

            if (!PrefetchingPartOfScenario) {
                PrefetchHeaderPage = TRUE;
            } else {

                //
                // We are prefetching part of the scenario. Are we past the 
                // first section?
                //

                if (SectionIdx > StartSectionNumber) {
                    PrefetchHeaderPage = TRUE;
                } else {

                    //
                    // This is the first section in the prefetch cursor.
                    // If we prefetched part of this section last time, we
                    // prefetched the header page then and we don't need to
                    // prefetch it again. However, if the cursor is at the 
                    // start of this section, we have not prefetched the 
                    // header page yet and we need to.
                    //

                    if (StartPageNumber == 0) {
                        PrefetchHeaderPage = TRUE;
                    }
                }
            }

            if (PrefetchHeaderPage) {

                //
                // Header page starts at offset 0.
                //
                
                ReadList->List[ReadList->NumberOfEntries].Alignment = 0;
                
                ReadList->NumberOfEntries++;
                
                NumPagesToPrefetch++;
                
                //
                // Note that if we are prefetching only part of the
                // scenario, we do not check to see if we've
                // prefetched enough pages here. This is to avoid
                // having to prefetch the header page twice in case it
                // maxes the number of pages to prefetch and
                // PrefetchSections is called again.
                //

                AddedHeaderPage = TRUE;
            }
        }

        //
        // Go through all the pages in the section and put offsets for
        // pages to prefetch into the readlist.
        //

        PageIdx = SectionRecord->FirstPageIdx;
        NumSectionPages = 0;

        while (PageIdx != PF_INVALID_PAGE_IDX) {

            PageRecord = &PageRecords[PageIdx];

            //
            // Update the number of pages we've seen on the list so
            // far. If it is greater than what there should be on the
            // list we have a problem. We may have even hit a loop. We
            // should have caught this when we verified the scenario.
            //

            NumSectionPages++;
            if (NumSectionPages > SectionRecord->NumPages) {
                DBGPR((CCPFID,PFWARN,"CCPF: PrefetchSections-Corrupt0\n"));
                Status = STATUS_INVALID_PARAMETER;
                CCPF_ASSERT(FALSE);
                goto cleanup;
            }

            //
            // Get the index for the next page in the list.
            //
            
            PageIdx = PageRecord->NextPageIdx;

            //
            // If we are prefetching parts of the scenario and this is
            // the first section, skip the pages up to the start
            // cursor. Note that NumSectionPages has already been
            // incremented above.
            //

            if (PrefetchingPartOfScenario &&
                StartSectionNumber == SectionIdx &&
                NumSectionPages <= StartPageNumber) {
                continue;
            }

            //
            // Skip pages we have marked "ignore" for some reason.
            //

            if (PageRecord->IsIgnore) {
                continue;
            }

            //
            // Except for the header page, we should not have put
            // more entries into the read list then the number of
            // pages for the section in the scenario file.
            //
           
            if (ReadList->NumberOfEntries >= SectionRecord->NumPages + 1) {
                DBGPR((CCPFID,PFWARN,"CCPF: PrefetchSections-Corrupt1\n"));
                Status = STATUS_INVALID_PARAMETER;
                CCPF_ASSERT(FALSE);
                goto cleanup;
            }
            
            //
            // Add this page to the list only if it's type (image
            // or data) matches the type of pages we are prefetching.
            //
            
            if (((PrefetchingImagePages == FALSE) && !PageRecord->IsData) ||
                ((PrefetchingImagePages == TRUE) && !PageRecord->IsImage)) {
                continue;
            }

            //
            // If we already added the header page to the list,
            // don't add another entry for the same offset.
            //
            
            if (AddedHeaderPage && (PageRecord->FileOffset == 0)) {
                continue;
            }

            //
            // Check to see if this page comes after the last page
            // we put in the read list. Perform this check as the
            // very last check before adding the page to the
            // readlist.
            //

            if (ReadList->NumberOfEntries) {
                
                LastOffset = ReadList->List[ReadList->NumberOfEntries - 1].Alignment;
                    
                if (PageRecord->FileOffset <= (ULONG) LastOffset) {
                    DBGPR((CCPFID,PFWARN,"CCPF: PrefetchSections-Corrupt2\n"));
                    Status = STATUS_INVALID_PARAMETER;
                    CCPF_ASSERT(FALSE);
                    goto cleanup;
                }
            }
      
            //
            // Add this page to the readlist for this section.
            //
            
            ReadList->List[ReadList->NumberOfEntries].Alignment = PageRecord->FileOffset;
            ReadList->NumberOfEntries++;
            
            //
            // Update number of pages we are asking mm to bring for us.
            //
            
            NumPagesToPrefetch++;

            //
            // Break out if we are prefetching requested number of
            // pages.
            //

            if (PrefetchingPartOfScenario && 
                NumPagesToPrefetch >= TotalPagesToPrefetch) {
                break;
            }
        }

        if (ReadList->NumberOfEntries) {

            //
            // Get the section object.
            //
            
            RtlInitUnicodeString(&SectionName, FilePath);
            
            Status = CcPfGetSectionObject(&SectionName,
                                          PrefetchingImagePages,
                                          &SectionObject,
                                          &FileObject,
                                          &FileHandle);
            
            if (!NT_SUCCESS(Status)) {
                
                if (Status == STATUS_SHARING_VIOLATION) {
                    
                    //
                    // We cannot open registry files due to sharing
                    // violation. Pass the file name and readlist to
                    // registry in case this is a registry file.
                    //

                    CmPrefetchHivePages(&SectionName, ReadList);
                }

                //
                // Free the built read list.
                //

                ExFreePool(ReadList);
                ReadList = NULL;

                continue;
            }

            //
            // We should have got a file object and a section object
            // pointer if we created the section successfully.
            //
            
            CCPF_ASSERT(FileObject != NULL && SectionObject != NULL);
            
            ReadList->FileObject = FileObject;

            //
            // Put data into the tables, so we know what to cleanup.
            //
            
            ReadLists[NumReadLists] = ReadList;
            FileHandleTable[NumReadLists] = FileHandle;
            FileObjectTable[NumReadLists] = FileObject;  
            SectionObjectTable[NumReadLists] = SectionObject;
            
            NumReadLists++;

        } else {
            
            //
            // We won't be prefetching anything for this section.
            //
            
            ExFreePool(ReadList);
        }

        //
        // Reset these so we know what to cleanup.
        //

        ReadList = NULL;
        FileHandle = NULL;
        FileObject = NULL;
        SectionObject = NULL;

        //
        // Break out if we are prefetching requested number of
        // pages.
        //
        
        if (PrefetchingPartOfScenario && 
            NumPagesToPrefetch >= TotalPagesToPrefetch) {
            break;
        }
    }

    //
    // If prefetching only part of the the scenario, update return
    // values.
    //

    if (PrefetchingPartOfScenario) {

        if (NumPagesPrefetched) {
            *NumPagesPrefetched = NumPagesToPrefetch;
        }

        if (EndCursor) {

            //
            // If we did the last page of the current section, then
            // start from the next section. Otherwise start from the
            // next page in this section.
            //

            if (PageIdx == PF_INVALID_PAGE_IDX) {
                EndCursor->SectionIdx = SectionIdx + 1;  
                EndCursor->PageIdx = 0;
            } else {
                EndCursor->SectionIdx = SectionIdx;  
                EndCursor->PageIdx = NumSectionPages;
            }
            
            // ISSUE-2002/02/21-ScottMa -- Why do we artificially boost the
            //   end positions here?  Should this be an assert?

            //
            // Make sure the end position is equal to or greater than
            // start position.
            //
            
            if (EndCursor->SectionIdx < StartSectionNumber) {
                EndCursor->SectionIdx = StartSectionNumber;
            }
            
            if (EndCursor->SectionIdx == StartSectionNumber) {
                if (EndCursor->PageIdx < StartPageNumber) {
                    EndCursor->PageIdx = StartPageNumber;
                }
            }
        }
    }

    //
    // Ask Mm to process the readlists only if we actually have pages
    // to ask for.
    //

    if (NumReadLists) {

        if (NumPagesToPrefetch) {

            DBGPR((CCPFID,PFPRFD,"CCPF: Prefetching %d sections %d pages\n", 
                   NumReadLists, NumPagesToPrefetch)); 

            Status = MmPrefetchPages(NumReadLists, ReadLists);

        } else {

            Status = STATUS_UNSUCCESSFUL;
            
            //
            // We cannot have any read lists if we don't have any
            // pages to prefetch.
            //

            CCPF_ASSERT(!NumReadLists);
        }

    } else {

        Status = STATUS_SUCCESS;

    }

cleanup:

    if (Tables) {

        for (ReadListIdx = 0; ReadListIdx < NumReadLists; ReadListIdx++) {
            
            if (ReadLists[ReadListIdx]) {
                ExFreePool(ReadLists[ReadListIdx]);
            }
            
            if (FileHandleTable[ReadListIdx]) {
                ZwClose(FileHandleTable[ReadListIdx]);
            }
            
            if (FileObjectTable[ReadListIdx]) {
                ObDereferenceObject(FileObjectTable[ReadListIdx]);
            }
            
            if (SectionObjectTable[ReadListIdx]) {
                ObDereferenceObject(SectionObjectTable[ReadListIdx]);
            }
        }

        ExFreePool(Tables);
    }

    if (ReadList) {
        ExFreePool(ReadList);
    }
    
    if (FileHandle) {
        ZwClose(FileHandle);
    }
    
    if (FileObject) {
        ObDereferenceObject(FileObject);
    }
    
    if (SectionObject) {
        ObDereferenceObject(SectionObject);
    }

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchSections(%p)=%x,%d,%d\n", 
           PrefetchHeader, Status, NumReadLists, NumPagesToPrefetch)); 

    return Status;
}

NTSTATUS
CcPfPrefetchMetadata(
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    )

/*++

Routine Description:

    This routine tries to prefetch the filesystem metadata that will
    be needed to prefetch pages for the scenario, so metadata I/Os do
    not get in the way of efficient page prefetch I/O.

    This function should be called only after the prefetch header has
    been initialized and the routine to open the volumes for prefetch
    has been called.

Arguments:

    PrefetchHeader - Pointer to prefetch header.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCHAR MetadataInfoBase;
    PPF_METADATA_RECORD MetadataRecordTable;
    PPF_METADATA_RECORD MetadataRecord;
    PWCHAR VolumePath;
    PFILE_PREFETCH FilePrefetchInfo;
    PPF_SCENARIO_HEADER Scenario;
    PPF_COUNTED_STRING DirectoryPath;
    PCCPF_PREFETCH_VOLUME_INFO VolumeNode;
    ULONG MetadataRecordIdx;
    ULONG DirectoryIdx;
    NTSTATUS Status;

    //
    // Initialize locals.
    //

    Scenario = PrefetchHeader->Scenario;

    if (Scenario == NULL) {
        CCPF_ASSERT(Scenario);
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }
    
    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchMetadata(%p)\n",PrefetchHeader)); 

    //
    // Get pointer to metadata prefetch information.
    //

    MetadataInfoBase = (PCHAR)Scenario + Scenario->MetadataInfoOffset;
    MetadataRecordTable = (PPF_METADATA_RECORD) MetadataInfoBase;

    //
    // Go through and prefetch requested metadata from volumes.
    //

    for (MetadataRecordIdx = 0;
         MetadataRecordIdx < Scenario->NumMetadataRecords;
         MetadataRecordIdx++) {

        MetadataRecord = &MetadataRecordTable[MetadataRecordIdx];

        VolumePath = (PWCHAR)
            (MetadataInfoBase + MetadataRecord->VolumeNameOffset);  

        //
        // Find the volume node for this volume containing opened handle.
        //

        VolumeNode = CcPfFindPrefetchVolumeInfoInList(VolumePath,
                                                      &PrefetchHeader->OpenedVolumeList);

        if (!VolumeNode) {

            //
            // If it is not in the opened volume list, it should be in the
            // bad volume list (because it was not mounted, or its serial 
            // did not match etc.)
            //

            CCPF_ASSERT(CcPfFindPrefetchVolumeInfoInList(VolumePath, &PrefetchHeader->BadVolumeList));

            //
            // We cannot prefetch metadata on this volume.
            //

            continue;

        } else {

            //
            // We should have already opened a handle to this volume.
            //

            CCPF_ASSERT(VolumeNode->VolumeHandle);
        }

        //
        // Prefetch MFT entries and such for the files and directories
        // we will access.
        //
        
        FilePrefetchInfo = (PFILE_PREFETCH) 
            (MetadataInfoBase + MetadataRecord->FilePrefetchInfoOffset);       

        //
        // Some file systems may not support prefetching file metadata.
        // So ignore any errors returned here and still prefetch directories.
        //

        Status = CcPfPrefetchFileMetadata(VolumeNode->VolumeHandle, FilePrefetchInfo);

        //
        // Walk through the contents of the directories sequentially
        // so we don't jump around when opening the files. The
        // directory list is sorted, so we will prefetch the parent
        // directories before children.
        //

        DirectoryPath = (PPF_COUNTED_STRING)
            (MetadataInfoBase + MetadataRecord->DirectoryPathsOffset);
        
        for (DirectoryIdx = 0;
             DirectoryIdx < MetadataRecord->NumDirectories;
             DirectoryIdx++) {

            Status = CcPfPrefetchDirectoryContents(DirectoryPath->String,
                                                   DirectoryPath->Length);

            if (Status == STATUS_UNRECOGNIZED_VOLUME ||
                Status == STATUS_INVALID_PARAMETER) {

                //
                // This volume may not have been mounted or got dismounted.
                //

                break;
            }
            
            //
            // Get next directory.
            //

            DirectoryPath = (PPF_COUNTED_STRING) 
                (&DirectoryPath->String[DirectoryPath->Length + 1]);
        }
    }

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFPREF,"CCPF: PrefetchMetadata(%p)=%x\n",PrefetchHeader,Status)); 

    return Status;
}

NTSTATUS
CcPfPrefetchFileMetadata(
    HANDLE VolumeHandle,
    PFILE_PREFETCH FilePrefetch
    )

/*++

Routine Description:

    This routine issues the specified metadata prefetch request to the
    file system.

Arguments:

    VolumeHandle - Volume this request should be issued to.

    FilePrefetch - POinter to prefetch request.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PFILE_PREFETCH SplitFilePrefetch;
    IO_STATUS_BLOCK IoStatusBlock;
    ULONG FilePrefetchSize;
    ULONG CurrentFileMetadataIdx;
    ULONG NumFileMetadataToPrefetch;
    ULONG RemainingFileMetadata;
    ULONG CopySize;
    NTSTATUS Status;
    
    //
    // Initialize locals.
    //

    SplitFilePrefetch = NULL;
    Status = STATUS_SUCCESS;

    DBGPR((CCPFID,PFPRFD,"CCPF: PrefetchFileMetadata(%p)\n", FilePrefetch)); 
    
    //
    // If the number of file prefetch entries are small, simply pass the
    // buffer in the scenario instructions to the file system.
    //

    if (FilePrefetch->Count < CCPF_MAX_FILE_METADATA_PREFETCH_COUNT) {

        FilePrefetchSize = sizeof(FILE_PREFETCH);
        if (FilePrefetch->Count) {
            FilePrefetchSize += (FilePrefetch->Count - 1) * sizeof(ULONGLONG);
        }
        
        Status = ZwFsControlFile(VolumeHandle,
                                 NULL,
                                 NULL,
                                 NULL,
                                 &IoStatusBlock,
                                 FSCTL_FILE_PREFETCH,
                                 FilePrefetch,
                                 FilePrefetchSize,
                                 NULL,
                                 0);

    } else {

        //
        // We need to allocate an intermediary buffer and split up the 
        // requests.
        //

        FilePrefetchSize = sizeof(FILE_PREFETCH);
        FilePrefetchSize += (CCPF_MAX_FILE_METADATA_PREFETCH_COUNT - 1) * sizeof(ULONGLONG);

        SplitFilePrefetch = ExAllocatePoolWithTag(PagedPool,
                                                  FilePrefetchSize,
                                                  CCPF_ALLOC_METADATA_TAG);
        
        if (!SplitFilePrefetch) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto cleanup;
        }

        //
        // Copy header.
        //

        *SplitFilePrefetch = *FilePrefetch;

        for (CurrentFileMetadataIdx = 0;
             CurrentFileMetadataIdx < FilePrefetch->Count;
             CurrentFileMetadataIdx += NumFileMetadataToPrefetch) {

            //
            // Calculate how many more file metadata entries we have to prefetch.
            // Adjust it so we don't go beyond FilePrefetch->Count.
            //

            NumFileMetadataToPrefetch = CCPF_MAX_FILE_METADATA_PREFETCH_COUNT;

            RemainingFileMetadata = FilePrefetch->Count - CurrentFileMetadataIdx;

            if (NumFileMetadataToPrefetch > RemainingFileMetadata) {
                NumFileMetadataToPrefetch = RemainingFileMetadata;
            }

            //
            // Update the count on header.
            //

            SplitFilePrefetch->Count = NumFileMetadataToPrefetch;

            //
            // Copy over the file metadata indices.
            //

            CopySize = NumFileMetadataToPrefetch * sizeof(ULONGLONG);

            RtlCopyMemory(SplitFilePrefetch->Prefetch, 
                          &FilePrefetch->Prefetch[CurrentFileMetadataIdx],
                          CopySize);

            //
            // Calculate the request size.
            //

            CCPF_ASSERT(SplitFilePrefetch->Count);
            CCPF_ASSERT(SplitFilePrefetch->Count <= CCPF_MAX_FILE_METADATA_PREFETCH_COUNT);

            FilePrefetchSize = sizeof(FILE_PREFETCH);
            FilePrefetchSize +=  (SplitFilePrefetch->Count - 1) * sizeof(ULONGLONG);

            //
            // Issue the request.
            //

            Status = ZwFsControlFile(VolumeHandle,
                                     NULL,
                                     NULL,
                                     NULL,
                                     &IoStatusBlock,
                                     FSCTL_FILE_PREFETCH,
                                     SplitFilePrefetch,
                                     FilePrefetchSize,
                                     NULL,
                                     0);

            if (NT_ERROR(Status)) {
                goto cleanup;
            }
        }
    }
    
    //
    // Fall through with status.
    //

 cleanup:

    if (SplitFilePrefetch) {
        ExFreePool(SplitFilePrefetch);
    }

    DBGPR((CCPFID,PFPRFD,"CCPF: PrefetchFileMetadata()=%x\n", Status)); 

    return Status;
}

NTSTATUS
CcPfPrefetchDirectoryContents(
    WCHAR *DirectoryPath,
    WCHAR DirectoryPathlength
    )

/*++

Routine Description:

    This routine attempts to prefetch the contents of a directory.

Arguments:

    DirectoryPath - NUL terminated path.
    
    DirectoryPathLength - Number of characters exclusing terminating NUL.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    HANDLE DirectoryHandle;
    UNICODE_STRING DirectoryPathU;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatusBlock;
    BOOLEAN OpenedDirectory;
    PVOID QueryBuffer;
    ULONG QueryBufferSize;
    ULONG QueryIdx;
    BOOLEAN RestartScan;

    UNREFERENCED_PARAMETER (DirectoryPathlength);

    //
    // Initialize locals.
    //

    OpenedDirectory = FALSE;
    QueryBuffer = NULL;

    DBGPR((CCPFID,PFPRFD,"CCPF: PrefetchDirectory(%ws)\n",DirectoryPath)); 

    //
    // Open the directory.
    //

    RtlInitUnicodeString(&DirectoryPathU, DirectoryPath);
    
    InitializeObjectAttributes(&ObjectAttributes,
                               &DirectoryPathU,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);
    
    Status = ZwCreateFile(&DirectoryHandle,
                          FILE_LIST_DIRECTORY | SYNCHRONIZE,
                          &ObjectAttributes,
                          &IoStatusBlock,
                          0,
                          0,
                          FILE_SHARE_READ |
                            FILE_SHARE_WRITE |
                            FILE_SHARE_DELETE,
                          FILE_OPEN,
                          FILE_DIRECTORY_FILE | 
                            FILE_SYNCHRONOUS_IO_NONALERT | 
                            FILE_OPEN_FOR_BACKUP_INTENT,
                          NULL,
                          0);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    OpenedDirectory = TRUE;

    //
    // Allocate a big query buffer so we have to make only a small
    // number of calls to cause the file system to walk through the
    // contents of the directory.
    //

    // FUTURE-2002/02/21-ScottMa -- We should consider allocating this buffer
    //   once and using it for all calls, since the buffer contents are
    //   ignored anyways.


    QueryBufferSize = 4 * PAGE_SIZE;
    QueryBuffer = ExAllocatePoolWithTag(PagedPool | POOL_COLD_ALLOCATION,
                                        QueryBufferSize,
                                        CCPF_ALLOC_QUERY_TAG);

    if (!QueryBuffer) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Query names of files in the directory hopefully causing the
    // file system to touch the directory contents sequentially. If
    // the directory is really big, we don't want to attempt to bring
    // it all in, so we limit the number of times we query. 
    //
    // Assuming filenames are 16 characters long on average, we can
    // fit 32 filenames in 1KB, 128 on an x86 page. A 4 page query
    // buffer holds 512 file names. If we do it 10 times, we end up
    // prefetching data for about 5000 files.
    //
    
    RestartScan = TRUE;

    for (QueryIdx = 0; QueryIdx < 10; QueryIdx++) {
        
        Status = ZwQueryDirectoryFile(DirectoryHandle,
                                      NULL,
                                      NULL,
                                      NULL,
                                      &IoStatusBlock,
                                      QueryBuffer,
                                      QueryBufferSize,
                                      FileNamesInformation,
                                      FALSE,
                                      NULL,
                                      RestartScan);
        
        RestartScan = FALSE;

        if (!NT_SUCCESS(Status)) {
            
            //
            // If the status is that we got all the files, we are done.
            //

            if (Status == STATUS_NO_MORE_FILES) {
                break;
            }

            goto cleanup;
        }
    }

    Status = STATUS_SUCCESS;

 cleanup:

    if (QueryBuffer) {
        ExFreePool(QueryBuffer);
    }
    
    if (OpenedDirectory) {
        ZwClose(DirectoryHandle);
    }

    DBGPR((CCPFID,PFPRFD,"CCPF: PrefetchDirectory(%ws)=%x\n",DirectoryPath, Status)); 

    return Status;
}

VOID
CcPfInitializePrefetchHeader (
    OUT PCCPF_PREFETCH_HEADER PrefetchHeader
)

/*++

Routine Description:

    This routine initalizes the prefetch header fields.

Arguments:

    PrefetchHeader - Pointer to prefetch header.

Return Value:

    None.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{

    //
    // Zero out the structure. This initializes the following:
    //
    // Scenario
    // VolumeNodes
    //

    RtlZeroMemory(PrefetchHeader, sizeof(CCPF_PREFETCH_HEADER));

    //
    // Initialize the volume lists.
    //

    InitializeListHead(&PrefetchHeader->BadVolumeList);
    InitializeListHead(&PrefetchHeader->OpenedVolumeList);
    
}

VOID
CcPfCleanupPrefetchHeader (
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    )

/*++

Routine Description:

    This routine cleans up allocations / references in the
    PrefetchHeader. It does not free the structure itself. 

Arguments:

    PrefetchHeader - Prefetch header to cleanup.

Return Value:

    None.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_PREFETCH_VOLUME_INFO VolumeNode;
    PLIST_ENTRY RemovedEntry;
    
    DBGPR((CCPFID,PFTRC,"CCPF: CleanupPrefetchHeader(%p)\n", PrefetchHeader));

    //
    // Walk the opened volumes list and close the handles.
    //

    while (!IsListEmpty(&PrefetchHeader->OpenedVolumeList)) {

        RemovedEntry = RemoveHeadList(&PrefetchHeader->OpenedVolumeList);

        VolumeNode = CONTAINING_RECORD(RemovedEntry,
                                       CCPF_PREFETCH_VOLUME_INFO,
                                       VolumeLink);

        CCPF_ASSERT(VolumeNode->VolumeHandle);

        ZwClose(VolumeNode->VolumeHandle);
    }
    
    //
    // Free allocated volume nodes.
    //

    if (PrefetchHeader->VolumeNodes) {
        ExFreePool(PrefetchHeader->VolumeNodes);
    }

}

NTSTATUS
CcPfGetPrefetchInstructions(
    IN PPF_SCENARIO_ID ScenarioId,
    IN PF_SCENARIO_TYPE ScenarioType,
    OUT PPF_SCENARIO_HEADER *ScenarioHeader
    )

/*++

Routine Description:

    This routine checks for prefetch instructions for the specified
    scenario, verifies them and returns them in an allocated buffer
    from paged pool the caller should free.

Arguments:

    ScenarioId - Scenario identifier.

    ScenarioType - Scenario type.

    Scenario - Where pointer to allocated buffer should be put.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;  
    PWSTR SystemRootPath = L"\\SystemRoot";
    PWSTR FilePath;
    UNICODE_STRING ScenarioFilePath;
    ULONG FilePathSize;
    HANDLE ScenarioFile;
    PPF_SCENARIO_HEADER Scenario;
    ULONG ScenarioSize;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatus;
    FILE_STANDARD_INFORMATION StandardInfo;
    ULONG FailedCheck;
    BOOLEAN OpenedScenarioFile;
    PKTHREAD CurrentThread;

    //
    // Initialize locals.
    //

    FilePath = NULL;
    Scenario = NULL;
    OpenedScenarioFile = FALSE;

    DBGPR((CCPFID,PFPREF,"CCPF: GetInstructions(%ws)\n", ScenarioId->ScenName)); 

    //
    // Hold the parameters lock while building path to instructions so
    // RootDirPath does not change beneath our feet.
    //

    CurrentThread = KeGetCurrentThread ();
    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceSharedLite(&CcPfGlobals.Parameters.ParametersLock, TRUE);

    //
    // Build file path for prefetch instructions for this scenario
    // id. +1 to wcslen(SystemRootPath) is for the "\" after it. The last
    // sizeof(WCHAR) is added for the terminating NUL.
    //

    FilePathSize = (wcslen(SystemRootPath) + 1) * sizeof(WCHAR);
    FilePathSize += wcslen(CcPfGlobals.Parameters.Parameters.RootDirPath) * sizeof(WCHAR);
    FilePathSize += sizeof(WCHAR); // for "\" after RootDirPath.
    FilePathSize += PF_MAX_SCENARIO_FILE_NAME * sizeof(WCHAR);
    FilePathSize += sizeof(WCHAR);
    
    FilePath = ExAllocatePoolWithTag(PagedPool | POOL_COLD_ALLOCATION,
                                     FilePathSize,
                                     CCPF_ALLOC_FILENAME_TAG);

    if (!FilePath) {
        ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    swprintf(FilePath,
             L"%s\\%s\\" PF_SCEN_FILE_NAME_FORMAT, 
             SystemRootPath,
             CcPfGlobals.Parameters.Parameters.RootDirPath,
             ScenarioId->ScenName,
             ScenarioId->HashId,
             PF_PREFETCH_FILE_EXTENSION);

    //
    // Release the parameters lock.
    //

    ExReleaseResourceLite(&CcPfGlobals.Parameters.ParametersLock);
    KeLeaveCriticalRegionThread(CurrentThread);

    //
    // Open the scenario file. We open the file exlusive so we do not
    // end up with half a file when the service is updating it etc.
    //

    DBGPR((CCPFID,PFPRFD,"CCPF: GetInstructions-[%ws]\n", FilePath)); 

    RtlInitUnicodeString(&ScenarioFilePath, FilePath);
    
    InitializeObjectAttributes(&ObjectAttributes,
                               &ScenarioFilePath,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);
                                        
    Status = ZwOpenFile(&ScenarioFile,
                        GENERIC_READ | SYNCHRONIZE,
                        &ObjectAttributes,
                        &IoStatus,
                        0,
                        FILE_SYNCHRONOUS_IO_NONALERT);

    if (!NT_SUCCESS(Status)) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FailedOpenFile\n")); 
        goto cleanup;
    }

    OpenedScenarioFile = TRUE;

    //
    // Get file size. If it is too big or too small, give up.
    //

    Status = ZwQueryInformationFile(ScenarioFile,
                                    &IoStatus,
                                    &StandardInfo,
                                    sizeof(StandardInfo),
                                    FileStandardInformation);

    if (!NT_SUCCESS(Status)) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FailedGetInfo\n")); 
        goto cleanup;
    }

    ScenarioSize = StandardInfo.EndOfFile.LowPart;

    if (ScenarioSize > PF_MAXIMUM_SCENARIO_SIZE ||
        ScenarioSize == 0 ||
        StandardInfo.EndOfFile.HighPart) {

        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FileTooBig\n")); 
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }

    //
    // Allocate scenario buffer.
    //

    Scenario = ExAllocatePoolWithTag(PagedPool,
                                     ScenarioSize,
                                     CCPF_ALLOC_PREFSCEN_TAG);

    if (!Scenario) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Read the scenario file.
    //

    Status = ZwReadFile(ScenarioFile,
                        0,
                        0,
                        0,
                        &IoStatus,
                        Scenario,
                        ScenarioSize,
                        0,
                        0);
    
    if (!NT_SUCCESS(Status)) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FailedRead\n")); 
        goto cleanup;
    }

    //
    // Verify the scenario file.
    //

    if (!PfVerifyScenarioBuffer(Scenario, ScenarioSize, &FailedCheck)) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-FailedVerify\n")); 
        Status = STATUS_INVALID_IMAGE_FORMAT;
        goto cleanup;
    }

    //
    // Verify that the scenario type matches.
    //

    if (Scenario->ScenarioType != ScenarioType) {
        DBGPR((CCPFID,PFWARN,"CCPF: GetInstructions-ScenTypeMismatch\n")); 
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }

    //
    // Setup return pointer.
    //
    
    *ScenarioHeader = Scenario;

    Status = STATUS_SUCCESS;

 cleanup:

    if (OpenedScenarioFile) {
        ZwClose(ScenarioFile);
    }

    if (FilePath) {
        ExFreePool(FilePath);
    }

    if (!NT_SUCCESS(Status)) {
        if (Scenario) {
            ExFreePool(Scenario);
        }
    }

    DBGPR((CCPFID,PFPREF,"CCPF: GetInstructions(%ws)=%x,%p\n", ScenarioId->ScenName, Status, Scenario)); 

    return Status;
}

NTSTATUS
CcPfQueryScenarioInformation(
    IN PPF_SCENARIO_HEADER Scenario,
    IN CCPF_SCENARIO_INFORMATION_TYPE InformationType,
    OUT PVOID Buffer,
    IN ULONG BufferSize,
    OUT PULONG RequiredSize
    )

/*++

Routine Description:

    This routine gathers requested information from the scenario structure.

Arguments:

    Scenario - Pointer to scenario.

    InformationType - Type of information requested.

    Buffer - Where requested information will be put.

    BufferSize - Max size of buffer in bytes.

    RequiredSize - How big the buffer should be if it is too small.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    PPF_SECTION_RECORD SectionRecord;
    PPF_SECTION_RECORD SectionRecords;
    ULONG SectionIdx;
    PPF_PAGE_RECORD PageRecord;
    PPF_PAGE_RECORD PageRecords;
    PCHAR FileNameData;
    LONG PageIdx;
    PCCPF_BASIC_SCENARIO_INFORMATION BasicInfo;
    PCCPF_BOOT_SCENARIO_INFORMATION BootInfo;
    BOOLEAN AddedHeaderPage;
    ULONG NumDataPages;
    ULONG NumImagePages;
    WCHAR *SectionName;
    WCHAR *SectionNameSuffix;
    WCHAR *SmssSuffix;
    WCHAR *WinlogonSuffix;
    WCHAR *SvchostSuffix;
    WCHAR *UserinitSuffix;
    ULONG SmssSuffixLength;
    ULONG WinlogonSuffixLength;
    ULONG SvchostSuffixLength;
    ULONG UserinitSuffixLength;
    CCPF_BOOT_SCENARIO_PHASE BootPhaseIdx;

    //
    // Initialize locals.
    //

    // FUTURE-2002/02/21-ScottMa -- Calculating the four string lengths below
    //   at runtime is not necessary, since the string is a constant.

    BootPhaseIdx = 0;
    SmssSuffix = L"\\SYSTEM32\\SMSS.EXE";
    SmssSuffixLength = wcslen(SmssSuffix);
    WinlogonSuffix = L"\\SYSTEM32\\WINLOGON.EXE";
    WinlogonSuffixLength = wcslen(WinlogonSuffix);
    SvchostSuffix = L"\\SYSTEM32\\SVCHOST.EXE";
    SvchostSuffixLength = wcslen(SvchostSuffix);
    UserinitSuffix = L"\\SYSTEM32\\USERINIT.EXE";
    UserinitSuffixLength = wcslen(UserinitSuffix);

    DBGPR((CCPFID,PFTRC,"CCPF: QueryScenario(%p,%x,%p)\n",Scenario,InformationType,Buffer));

    //
    // Check requested information type.
    //

    if (InformationType < 0 || InformationType >= CcPfMaxScenarioInformationType) {
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Initialize pointers to data in the scenario.
    //
    
    SectionRecords = (PPF_SECTION_RECORD) 
        ((PCHAR) Scenario + Scenario->SectionInfoOffset);
    
    PageRecords = (PPF_PAGE_RECORD) 
        ((PCHAR) Scenario + Scenario->PageInfoOffset);

    FileNameData = (PCHAR) Scenario + Scenario->FileNameInfoOffset;
    
    //
    // Collect requested information.
    //

    switch(InformationType) {

    case CcPfBasicScenarioInformation:

        //
        // Check buffer size.
        //

        if (BufferSize < sizeof(CCPF_BASIC_SCENARIO_INFORMATION)) {
            *RequiredSize = sizeof(CCPF_BASIC_SCENARIO_INFORMATION);
            Status = STATUS_BUFFER_TOO_SMALL;
            goto cleanup;
        }
        
        //
        // Initialize return buffer.
        //

        BasicInfo = Buffer;
        RtlZeroMemory(BasicInfo, sizeof(CCPF_BASIC_SCENARIO_INFORMATION));

        //
        // Go through the scenario's sections.
        //

        for (SectionIdx = 0; SectionIdx < Scenario->NumSections; SectionIdx ++) {
            
            SectionRecord = &SectionRecords[SectionIdx];
              
            //
            // Skip this section if it was marked ignore for some reason.
            //
            
            if (SectionRecord->IsIgnore) {
                BasicInfo->NumIgnoredSections++;
                continue;
            }
            
            //
            // Initialize loop locals.
            //

            AddedHeaderPage = FALSE;
            NumDataPages = 0;
            NumImagePages = 0;

            //
            // Note that we will prefetch the header page as a data
            // page if this section will be prefetched as image.
            //
            
            if (SectionRecord->IsImage) {
                NumDataPages++;
                AddedHeaderPage = TRUE;
            }

            //
            // Go through the section's pages.
            //

            PageIdx = SectionRecord->FirstPageIdx;
            while (PageIdx != PF_INVALID_PAGE_IDX) {
                
                PageRecord = &PageRecords[PageIdx];

                //
                // Get the index for the next page in the list.
                //
                
                PageIdx = PageRecord->NextPageIdx;
            
                //
                // Skip pages we have marked "ignore" for some reason.
                //
                
                if (PageRecord->IsIgnore) {
                    BasicInfo->NumIgnoredPages++;
                    continue;
                }

                if (PageRecord->IsData) {

                    //
                    // If this page is the first page, count it only
                    // if we have not already counted the header page
                    // for image mapping.
                    //

                    if (PageRecord->FileOffset != 0 ||
                        AddedHeaderPage == FALSE) {
                        NumDataPages++;
                    }
                }

                if (PageRecord->IsImage) {
                    NumImagePages++;
                }
            }
            
            //
            // Update the information structure.
            //

            BasicInfo->NumDataPages += NumDataPages;
            BasicInfo->NumImagePages += NumImagePages;

            if (!NumImagePages && NumDataPages) {
                BasicInfo->NumDataOnlySections++;
            }

            if (NumImagePages && (NumDataPages == 1)) {
                BasicInfo->NumImageOnlySections++;
            }
        }

        Status = STATUS_SUCCESS;

        break;

    case CcPfBootScenarioInformation:

        //
        // Check buffer size.
        //

        if (BufferSize < sizeof(CCPF_BOOT_SCENARIO_INFORMATION)) {
            *RequiredSize = sizeof(CCPF_BOOT_SCENARIO_INFORMATION);
            Status = STATUS_BUFFER_TOO_SMALL;
            goto cleanup;
        }
        
        //
        // Initialize return buffer.
        //

        BootInfo = Buffer;
        RtlZeroMemory(BootInfo, sizeof(CCPF_BOOT_SCENARIO_INFORMATION));

        //
        // Verify that this is a boot scenario.
        //

        if (Scenario->ScenarioType != PfSystemBootScenarioType) {
            Status = STATUS_INVALID_PARAMETER;
            goto cleanup;
        }

        //
        // Go through the scenario's sections.
        //

        for (SectionIdx = 0; SectionIdx < Scenario->NumSections; SectionIdx ++) {
            
            SectionRecord = &SectionRecords[SectionIdx];
        
            SectionName = (WCHAR *) (FileNameData + SectionRecord->FileNameOffset);

            //
            // Update boot phase based on section name.
            //
            
            if (SectionRecord->FileNameLength > SmssSuffixLength) {               
                SectionNameSuffix = SectionName + (SectionRecord->FileNameLength - SmssSuffixLength);               
                if (!wcscmp(SectionNameSuffix, SmssSuffix)) {                   
                    BootPhaseIdx = CcPfBootScenSubsystemInitPhase;
                }
            }

            if (SectionRecord->FileNameLength > WinlogonSuffixLength) {               
                SectionNameSuffix = SectionName + (SectionRecord->FileNameLength - WinlogonSuffixLength);               
                if (!wcscmp(SectionNameSuffix, WinlogonSuffix)) {                   
                    BootPhaseIdx = CcPfBootScenSystemProcInitPhase;
                }
            }

            if (SectionRecord->FileNameLength > SvchostSuffixLength) {               
                SectionNameSuffix = SectionName + (SectionRecord->FileNameLength - SvchostSuffixLength);               
                if (!wcscmp(SectionNameSuffix, SvchostSuffix)) {                   
                    BootPhaseIdx = CcPfBootScenServicesInitPhase;
                }
            }

            if (SectionRecord->FileNameLength > UserinitSuffixLength) {               
                SectionNameSuffix = SectionName + (SectionRecord->FileNameLength - UserinitSuffixLength);               
                if (!wcscmp(SectionNameSuffix, UserinitSuffix)) {                   
                    BootPhaseIdx = CcPfBootScenUserInitPhase;
                }
            }

            CCPF_ASSERT(BootPhaseIdx < CcPfBootScenMaxPhase);
              
            //
            // Skip this section if it was marked ignore for some reason.
            //
            
            if (SectionRecord->IsIgnore) {
                continue;
            }
            
            //
            // Note that we will prefetch the header page as a data
            // page if this section will be prefetched as image.
            //
            
            if (SectionRecord->IsImage) {
                BootInfo->NumDataPages[BootPhaseIdx]++;
                AddedHeaderPage = TRUE;
            } else {
                AddedHeaderPage = FALSE;
            }

            //
            // Go through the section's pages.
            //

            PageIdx = SectionRecord->FirstPageIdx;
            while (PageIdx != PF_INVALID_PAGE_IDX) {
                
                PageRecord = &PageRecords[PageIdx];

                //
                // Get the index for the next page in the list.
                //
                
                PageIdx = PageRecord->NextPageIdx;
            
                //
                // Skip pages we have marked "ignore" for some reason.
                //
                
                if (PageRecord->IsIgnore) {
                    continue;
                }

                if (PageRecord->IsData) {

                    //
                    // If this page is the first page, count it only
                    // if we have not already counted the header page
                    // for image mapping.
                    //

                    if (PageRecord->FileOffset != 0 ||
                        AddedHeaderPage == FALSE) {
                        BootInfo->NumDataPages[BootPhaseIdx]++;
                    }
                }

                if (PageRecord->IsImage) {
                    BootInfo->NumImagePages[BootPhaseIdx]++;
                }
            }
        }
        
        Status = STATUS_SUCCESS;

        break;

    default:

        Status = STATUS_NOT_SUPPORTED;
    }

    //
    // Fall through with status from the switch statement.
    //
        
 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: QueryScenario(%p,%x)=%x\n",Scenario,InformationType,Status));

    return Status;
}

NTSTATUS
CcPfOpenVolumesForPrefetch (
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    )

/*++

Routine Description:

    This routine is called on an initialized PrefetchHeader with the scenario
    field specified. It opens the volumes specified in the scenario updating
    VolumeNodes and the list of volumes we can't prefetch from and the list 
    of volumes we have successfully opened and saved a handle for.

Arguments:

    PrefetchHeader - Pointer to prefetch header that contains the
      prefetch instructions.

Return Value:

    Status.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    LARGE_INTEGER CreationTime;
    PCHAR MetadataInfoBase;
    PPF_METADATA_RECORD MetadataRecordTable;
    PPF_METADATA_RECORD MetadataRecord;
    PWCHAR VolumePath;
    PPF_SCENARIO_HEADER Scenario;
    PCCPF_PREFETCH_VOLUME_INFO VolumeNode;
    HANDLE VolumeHandle;
    ULONG SerialNumber;
    ULONG MetadataRecordIdx;
    ULONG AllocationSize;
    NTSTATUS Status;
    BOOLEAN VolumeMounted;

    //
    // Initialize locals.
    //

    Scenario = PrefetchHeader->Scenario;

    DBGPR((CCPFID,PFPREF,"CCPF: OpenVolumesForPrefetch(%p)\n",PrefetchHeader)); 

    //
    // Verify parameters.
    //

    if (Scenario == NULL) {
        CCPF_ASSERT(Scenario);
        Status = STATUS_INVALID_PARAMETER;
        goto cleanup;
    }

    //
    // Allocate volume nodes.
    //

    AllocationSize = Scenario->NumMetadataRecords * sizeof(CCPF_PREFETCH_VOLUME_INFO);

    PrefetchHeader->VolumeNodes = ExAllocatePoolWithTag(PagedPool, 
                                                        AllocationSize,
                                                        CCPF_ALLOC_VOLUME_TAG);

    if (!PrefetchHeader->VolumeNodes) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto cleanup;
    }

    //
    // Get pointer to metadata prefetch information.
    //

    MetadataInfoBase = (PCHAR)Scenario + Scenario->MetadataInfoOffset;
    MetadataRecordTable = (PPF_METADATA_RECORD) MetadataInfoBase;

    //
    // Go through metadata records and build the volume nodes for prefetching.
    //

    for (MetadataRecordIdx = 0;
         MetadataRecordIdx < Scenario->NumMetadataRecords;
         MetadataRecordIdx++) {

        //
        // Initialize loop locals.
        //
        
        MetadataRecord = &MetadataRecordTable[MetadataRecordIdx];
        VolumeHandle = NULL;
        
        VolumePath = (PWCHAR)
            (MetadataInfoBase + MetadataRecord->VolumeNameOffset);  

        //
        // Is the volume mounted?
        //

        Status = CcPfIsVolumeMounted(VolumePath, &VolumeMounted);

        if (!NT_SUCCESS(Status)) {

            //
            // Since we could not tell for sure, treat this volume as 
            // if it were not mounted.
            //

            VolumeMounted = FALSE;
        }

        //
        // If the volume is not mounted we don't want to cause it to be
        // mounted. This creates a problem especially during boot for 
        // clustering where a single physical disk is shared by many 
        // computers.
        //

        if (!VolumeMounted) {
            Status = STATUS_VOLUME_DISMOUNTED;
            goto NextVolume;
        }

        //
        // Open the volume and get relevant information.
        //

        Status = CcPfQueryVolumeInfo(VolumePath,
                                     &VolumeHandle,
                                     &CreationTime,
                                     &SerialNumber);
        
        if (!NT_SUCCESS(Status)) {
            goto NextVolume;
        }

        //
        // For simplicity we save NT paths for the files to prefetch
        // from. If volumes are mounted in a different order, or new ones
        // are created these paths would not work:
        // (e.g. \Device\HarddiskVolume2 should be \Device\HarddiskVolume3 etc.)
        // Verify that such a change has not taken place.
        //
        
        if (SerialNumber != MetadataRecord->SerialNumber ||
            CreationTime.QuadPart != MetadataRecord->CreationTime.QuadPart) {

            Status = STATUS_REVISION_MISMATCH;
            goto NextVolume;
        }

        Status = STATUS_SUCCESS;

      NextVolume:

        //
        // Update the volume node we'll keep around for prefetching.
        //
    
        VolumeNode = &PrefetchHeader->VolumeNodes[MetadataRecordIdx];

        VolumeNode->VolumePath = VolumePath;
        VolumeNode->VolumePathLength = MetadataRecord->VolumeNameLength;

        //
        // If we failed to open the volume, or if it was not mounted or if
        // its SerialNumber / CreationTime has changed put it in the list of
        // volumes we won't prefetch from. Otherwise put it in the list of 
        // opened volumes so we don't have to open it again.
        //

        if (NT_SUCCESS(Status) && VolumeHandle) {
            VolumeNode->VolumeHandle = VolumeHandle;
            VolumeHandle = NULL;
            InsertTailList(&PrefetchHeader->OpenedVolumeList, &VolumeNode->VolumeLink);
        } else {
            VolumeNode->VolumeHandle = NULL;
            InsertTailList(&PrefetchHeader->BadVolumeList, &VolumeNode->VolumeLink);
        }

        if (VolumeHandle) {
            ZwClose(VolumeHandle);
            VolumeHandle = NULL;
        }
    }

    //
    // We've dealt with all the volumes in the prefetch instructions.
    //

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFPREF,"CCPF: OpenVolumesForPrefetch(%p)=%x\n",PrefetchHeader,Status)); 
    
    return Status;
}

PCCPF_PREFETCH_VOLUME_INFO 
CcPfFindPrefetchVolumeInfoInList(
    WCHAR *Path,
    PLIST_ENTRY List
    )

/*++

Routine Description:

    This routine looks for the volume on which "Path" would be in the list of 
    volumes and returns it.

Arguments:

    Path - NUL terminated path of the volume or a file/directory on the volume.

    List - List of volumes to search.

Return Value:

    Found volume or NULL.

Environment:

    Kernel mode, IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_PREFETCH_VOLUME_INFO FoundVolume;
    PCCPF_PREFETCH_VOLUME_INFO VolumeInfo;
    PLIST_ENTRY NextEntry;

    //
    // Initialize locals.
    //

    FoundVolume = NULL;

    //
    // Walk the list.
    //

    for (NextEntry = List->Flink;
         NextEntry != List;
         NextEntry = NextEntry->Flink) {

        VolumeInfo = CONTAINING_RECORD(NextEntry,
                                       CCPF_PREFETCH_VOLUME_INFO,
                                       VolumeLink);

        if (!wcsncmp(Path, VolumeInfo->VolumePath, VolumeInfo->VolumePathLength)) {
            FoundVolume = VolumeInfo;
            break;
        }
    }

    return FoundVolume;
}

// FUTURE-2002/02/21-ScottMa -- The style of the CcPfGetSectionObject function
//   isn't consistent with the others, with regard to error handling.
//   Consider reworking the error path like the other functions.

NTSTATUS
CcPfGetSectionObject(
    IN PUNICODE_STRING FilePath,
    IN LOGICAL ImageSection,
    OUT PVOID* SectionObject,
    OUT PFILE_OBJECT* FileObject,
    OUT HANDLE* FileHandle
    )

/*++

Routine Description:

    This routine ensures that a section for the specified file exists.

Arguments:

    FilePath - Path to file to get section object for.
    
    ImageSection - TRUE if we want to map as image
    
    SectionObject - Receives the section object if successful (addref'd).
    
    FileObject - Receives the file object if successful (addref'd).
    
    FileHandle - Receives the file handle. We need to keep the file handle,
                 because otherwise non-paging I/O would stop working.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    HANDLE SectionHandle;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatus;
    NTSTATUS status;
    ULONG SectionFlags;
    ULONG SectionAccess;
    ULONG FileAccess;
    extern POBJECT_TYPE IoFileObjectType;

    DBGPR((CCPFID,PFPRFD,"CCPF: GetSection(%wZ,%d)\n", FilePath, ImageSection)); 
 
    //
    // Reset parameters.
    //

    *SectionObject = NULL;
    *FileObject = NULL;
    *FileHandle = NULL;

    if (!ImageSection) {
        // ISSUE-2002/02/21-ScottMa -- Is SEC_RESERVE the correct flag to use
        //   for data sections?  Should we be committing the pages?

        SectionFlags = SEC_RESERVE;
        FileAccess =  FILE_READ_DATA | FILE_READ_ATTRIBUTES;
        SectionAccess = PAGE_READWRITE;
    } else {
        SectionFlags = SEC_IMAGE;
        FileAccess = FILE_EXECUTE;
        SectionAccess = PAGE_EXECUTE;
    }

    //
    // To ensure that the section exists and is addref'd, we simply
    // open the file and create a section. This way we let Io and Mm
    // handle all the details.
    //

    InitializeObjectAttributes(&ObjectAttributes,
                               FilePath,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);

    // ISSUE-2002/02/21-ScottMa -- IoCreateFile is used here, but other areas
    //   use ZwCreateFile...  Why?

    status = IoCreateFile(FileHandle,
                          (ACCESS_MASK) FileAccess,
                          &ObjectAttributes,
                          &IoStatus,
                          NULL,
                          FILE_ATTRIBUTE_NORMAL,
                          FILE_SHARE_READ | FILE_SHARE_WRITE | FILE_SHARE_DELETE,
                          FILE_OPEN,
                          FILE_NON_DIRECTORY_FILE,
                          NULL,
                          0,
                          CreateFileTypeNone,
                          (PVOID)NULL,
                          IO_FORCE_ACCESS_CHECK |
                            IO_NO_PARAMETER_CHECKING |
                            IO_CHECK_CREATE_PARAMETERS);

    if (!NT_SUCCESS(status)) {
        goto _return;
    }

    //
    // Create section.
    //

    InitializeObjectAttributes(&ObjectAttributes,
                               NULL,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);

    status = ZwCreateSection(&SectionHandle,
                             SECTION_MAP_READ | SECTION_MAP_EXECUTE | SECTION_QUERY,
                             &ObjectAttributes,
                             NULL,
                             SectionAccess,
                             SectionFlags,
                             *FileHandle);

    if (!NT_SUCCESS(status)) {
        ZwClose(*FileHandle);
        *FileHandle = NULL;
        goto _return;
    }

    //
    // Get section object pointer.
    //

    status = ObReferenceObjectByHandle(
        SectionHandle,
        SECTION_MAP_READ | SECTION_MAP_EXECUTE | SECTION_QUERY,
        MmSectionObjectType,
        KernelMode,
        SectionObject,
        NULL
        );

    ZwClose(SectionHandle);

    if (!NT_SUCCESS(status)) {
        *SectionObject = NULL;
        ZwClose(*FileHandle);
        *FileHandle = NULL;
        goto _return;
    }

    //
    // Get file object pointer.
    //

    status = ObReferenceObjectByHandle(*FileHandle,
                                       FileAccess,
                                       IoFileObjectType,
                                       KernelMode,
                                       (PVOID*)FileObject,
                                       NULL);

    if (!NT_SUCCESS(status)) {
        ObDereferenceObject(*SectionObject);
        *SectionObject = NULL;
        *FileObject = NULL;
        ZwClose(*FileHandle);
        *FileHandle = NULL;
        goto _return;
    }

 _return:

    DBGPR((CCPFID,PFPRFD,"CCPF: GetSection(%wZ)=%x\n", FilePath, status)); 

    return status;
}

//
// Routines used for application launch prefetching.
//

NTSTATUS
CcPfScanCommandLine(
    OUT PULONG PrefetchHint,
    OPTIONAL OUT PULONG HashId
    )

/*++

Routine Description:

    Scan the command line (in the PEB) for the current process.

    Checks for /prefetch:XXX in the command line. This is specified by 
    applications to distinguish different ways they are launched in so
    we can customize application launch prefetching for them (e.g. have
    different prefetch instructions for Windows Media player that is 
    launched to play a CD than one that is launched to browse the web.

    If HashId is requested, calculates a hash ID from the full command line.

Arguments:

    PrefetchHint - Hint specified in the command line. If no hint is 
      specified, 0 will be returned.
      
    HashId - Calculated hash id is returned here.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PEPROCESS CurrentProcess;
    PPEB Peb;
    PRTL_USER_PROCESS_PARAMETERS ProcessParameters;
    PWCHAR FoundPosition;
    PWCHAR Source;
    PWCHAR SourceEnd;
    PWCHAR Destination;
    PWCHAR DestinationEnd;
    UNICODE_STRING CommandLine;
    UNICODE_STRING PrefetchParameterName;
    NTSTATUS Status;
    ULONG PrefetchHintStringMaxChars;
    WCHAR PrefetchHintString[15];
    
    //
    // Initialize locals.
    //

    RtlInitUnicodeString(&PrefetchParameterName, L"/prefetch:");
    PrefetchHintStringMaxChars = sizeof(PrefetchHintString) / sizeof(PrefetchHintString[0]);
    CurrentProcess = PsGetCurrentProcess();
    Peb = CurrentProcess->Peb;

    //
    // Initialize output parameters.
    //

    *PrefetchHint = 0;

    //
    // Make sure the user mode process environment block is not gone.
    //

    if (!Peb) {
        Status = STATUS_TOO_LATE;
        goto cleanup;
    }

    try {

        //
        // Make sure we can access the process parameters structure.
        //

        ProcessParameters = Peb->ProcessParameters;
        ProbeForReadSmallStructure(ProcessParameters,
                                   sizeof(*ProcessParameters),
                                   _alignof(RTL_USER_PROCESS_PARAMETERS));

        //
        // Copy CommandLine UNICODE_STRING structure to a local.
        //

        CommandLine = ProcessParameters->CommandLine;

        //
        // Is there a command line?
        //

        if (!CommandLine.Buffer) {
            Status = STATUS_NOT_FOUND;
            goto cleanup;
        }

        //
        // If ProcessParameters has been de-normalized, normalize CommandLine.
        //

        if ((ProcessParameters->Flags & RTL_USER_PROC_PARAMS_NORMALIZED) == 0) {
            CommandLine.Buffer = (PWSTR)((PCHAR)ProcessParameters + (ULONG_PTR) CommandLine.Buffer);
        }

        //
        // Probe the command line string.
        //

        ProbeForRead(CommandLine.Buffer, CommandLine.Length, _alignof(WCHAR));

        //
        // Look for the prefetch hint parameter.
        //

        FoundPosition = CcPfFindString(&CommandLine, &PrefetchParameterName);

        if (FoundPosition) {

            //
            // Copy the decimal number following the prefetch hint switch into
            // our local buffer and NUL terminate it.
            //

            Source = FoundPosition + (PrefetchParameterName.Length / sizeof(WCHAR));
            SourceEnd = CommandLine.Buffer + (CommandLine.Length / sizeof(WCHAR));

            Destination = PrefetchHintString;
            DestinationEnd = PrefetchHintString + PrefetchHintStringMaxChars - 1;

            //
            // Copy while we don't hit the end of the command line string and the
            // end of our local buffer (we left room for a terminating NUL), and
            // we don't hit a space (' ') that would mark the end of the prefetch
            // hint command line parameter.
            //

            while ((Source < SourceEnd) && 
                   (Destination < DestinationEnd) && 
                   (*Source != L' ')) {

                *Destination = *Source;

                Source++;
                Destination++;
            }

            //
            // Terminate prefetch hint string. DestinationEnd is the last 
            // character within the PrefetchHintString bounds. Destination
            // can only be <= DestinationEnd.
            //

            CCPF_ASSERT(Destination <= DestinationEnd);

            *Destination = 0;

            //
            // Convert prefetch hint to a number.
            //

            *PrefetchHint = _wtol(PrefetchHintString);

        }

        //
        // Calculate hash id.
        //

        if (HashId) {
            *HashId = CcPfHashValue(CommandLine.Buffer, CommandLine.Length);
        }

        //
        // We are done.
        //

        Status = STATUS_SUCCESS;

    } except (EXCEPTION_EXECUTE_HANDLER) {

        Status = GetExceptionCode();
    }

    //
    // Fall through with the status.
    //

cleanup:

    return Status;    
}

//
// Reference count implementation:
//

VOID
CcPfInitializeRefCount(
    PCCPF_REFCOUNT RefCount
    )

/*++

Routine Description:

    This routine initializes a reference count structure.

Arguments:

    RefCount - Pointer to reference count structure.
    
Return Value:

    None.

Environment:

    Kernel Mode, IRQL == PASSIVE_LEVEL.

--*/   

{
    //
    // Start reference count from 1. When somebody wants to gain
    // exclusive access they decrement it one extra so it may become
    // 0.
    //
    
    RefCount->RefCount = 1;

    //
    // Nobody has exclusive access to start with. 
    //

    RefCount->Exclusive = 0;
}

NTSTATUS
FASTCALL
CcPfAddRef(
    PCCPF_REFCOUNT RefCount
    )

/*++

Routine Description:

    This routine tries to bump the reference count if it has not been
    acquired exclusive.

Arguments:

    RefCount - Pointer to reference count structure.
    
Return Value:

    Status.

Environment:

    Kernel Mode, IRQL <= DISPATCH_LEVEL if RefCount is non-paged.

--*/   

{
    LONG NewValue;

    //
    // Do a fast check if the lock was acquire exclusive. If so just
    // return.
    //
    
    if (RefCount->Exclusive) {
        return STATUS_UNSUCCESSFUL;
    }

    //
    // Bump the reference count.
    //

    InterlockedIncrement(&RefCount->RefCount);
    
    //
    // If it was acquired exclusive, pull back.
    //

    if (RefCount->Exclusive) {
        
        NewValue = InterlockedDecrement(&RefCount->RefCount);

        //
        // Reference count should never go negative.
        //
        
        CCPF_ASSERT(NewValue >= 0);
                
        return STATUS_UNSUCCESSFUL;

    } else {

        //
        // We got our reference.
        //

        return STATUS_SUCCESS;
    }  
}

VOID
FASTCALL
CcPfDecRef(
    PCCPF_REFCOUNT RefCount
    )

/*++

Routine Description:

    This routine decrements the reference count. 

Arguments:

    RefCount - Pointer to reference count structure.
    
Return Value:

    None.

Environment:

    Kernel Mode, IRQL <= DISPATCH_LEVEL if RefCount is non-paged.

--*/   

{
    LONG NewValue;

    //
    // Decrement the reference count.
    //

    NewValue = InterlockedDecrement(&RefCount->RefCount);   

    //
    // Reference count should never go negative.
    //

    CCPF_ASSERT(NewValue >= 0);
}

NTSTATUS
FASTCALL
CcPfAddRefEx(
    PCCPF_REFCOUNT RefCount,
    ULONG Count
    )

/*++

Routine Description:

    This routine tries to bump the reference count if it has not been
    acquired exclusive.

Arguments:

    RefCount - Pointer to reference count structure.
    Count    - Amount to bump the reference count by
    
Return Value:

    Status.

Environment:

    Kernel Mode, IRQL <= DISPATCH_LEVEL if RefCount is non-paged.

--*/   

{
    LONG NewValue;

    //
    // Do a fast check if the lock was acquire exclusive. If so just
    // return.
    //
    
    if (RefCount->Exclusive) {
        return STATUS_UNSUCCESSFUL;
    }

    //
    // Bump the reference count.
    //

    InterlockedExchangeAdd(&RefCount->RefCount, Count);
    
    //
    // If it was acquired exclusive, pull back.
    //

    if (RefCount->Exclusive) {
        
        NewValue = InterlockedExchangeAdd(&RefCount->RefCount, -(LONG) Count);

        //
        // Reference count should never go negative.
        //
        
        CCPF_ASSERT(NewValue >= 0);
                
        return STATUS_UNSUCCESSFUL;

    } else {

        //
        // We got our reference.
        //

        return STATUS_SUCCESS;
    }  
}

VOID
FASTCALL
CcPfDecRefEx(
    PCCPF_REFCOUNT RefCount,
    ULONG Count
    )

/*++

Routine Description:

    This routine decrements the reference count. 

Arguments:

    RefCount - Pointer to reference count structure.
    Count    - Count of how far to decrement the reference count by
    
Return Value:

    None.

Environment:

    Kernel Mode, IRQL <= DISPATCH_LEVEL if RefCount is non-paged.

--*/   

{
    LONG NewValue;

    //
    // Decrement the reference count.
    //

    NewValue = InterlockedExchangeAdd(&RefCount->RefCount, -(LONG) Count);   

    //
    // Reference count should never go negative.
    //

    CCPF_ASSERT(NewValue >= 0);
}

NTSTATUS
CcPfAcquireExclusiveRef(
    PCCPF_REFCOUNT RefCount
    )

/*++

Routine Description:

    This routine attempts to get exclusive reference. If there is
    already an exclusive reference, it fails. Othwerwise it waits for
    all normal references to go away.

Arguments:

    RefCount - Pointer to reference count structure.
    
Return Value:

    Status.

Environment:

    Kernel Mode, IRQL == PASSIVE_LEVEL.

--*/   

{
    LONG OldValue;
    LARGE_INTEGER SleepTime;

    //
    // Try to get exclusive access by setting Exclusive from 0 to 1.
    //

    OldValue = InterlockedCompareExchange(&RefCount->Exclusive, 1, 0);

    if (OldValue != 0) {

        //
        // Somebody already had the lock.
        //
        
        return STATUS_UNSUCCESSFUL;
    }

    //
    // Decrement the reference count once so it may become 0.
    //

    InterlockedDecrement(&RefCount->RefCount);

    //
    // No new references will be given away. We poll until existing
    // references are released.
    //

    do {

        if (RefCount->RefCount == 0) {

            break;

        } else {

            //
            // Sleep for a while [in 100ns, negative so it is relative
            // to current system time].
            //

            SleepTime.QuadPart = - 10 * 1000 * 10; // 10 ms.

            KeDelayExecutionThread(KernelMode, FALSE, &SleepTime);
        }

    } while(TRUE);

    return STATUS_SUCCESS;
}

PCCPF_TRACE_HEADER
CcPfReferenceProcessTrace(
    PEPROCESS Process
    )
/*++

Routine Description:

    This routine references the trace associated with the specified process
    if possible. It uses fast references to avoid taking the trace lock
    to improve performance.

Arguments:

    Process - The process whose trace should be referenced

Return Value:

    The referenced trace buffer or NULL if it could not be referenced

--*/
{
    EX_FAST_REF OldRef;
    PCCPF_TRACE_HEADER Trace;
    ULONG RefsToAdd, Unused;
    NTSTATUS Status;
    KIRQL OldIrql;

    //
    // Attempt the fast reference
    //
    
    OldRef = ExFastReference (&Process->PrefetchTrace);

    Trace = ExFastRefGetObject (OldRef);

    //
    // Optimize the common path where there won't be a trace on the
    // process header (since traces are just for the application launch.)
    //

    if (Trace == NULL) {
        return 0;
    }
    
    Unused = ExFastRefGetUnusedReferences (OldRef);

    if (Unused <= 1) {
        //
        // If there are no references left then we have to do this under the lock
        //
        if (Unused == 0) {
            Status = STATUS_SUCCESS;
            KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OldIrql);                    

            Trace = ExFastRefGetObject (Process->PrefetchTrace);
            if (Trace != NULL) {
                Status = CcPfAddRef(&Trace->RefCount);
            }
            KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OldIrql);

            if (!NT_SUCCESS (Status)) {
                Trace = NULL;
            }
            return Trace;
        }

        //
        // If we took the counter to zero then attempt to make life easier for
        // the next referencer by resetting the counter to its max. Since we now
        // have a reference to the object we can do this.
        //
        
        RefsToAdd = ExFastRefGetAdditionalReferenceCount ();
        Status = CcPfAddRefEx (&Trace->RefCount, RefsToAdd);

        //
        // If we failed to obtain additional references then just ignore the fixup.
        //
        
        if (NT_SUCCESS (Status)) {

            //
            // If we fail to add them to the fast reference structure then
            // give them back to the trace and forget about fixup.
            //
            
            if (!ExFastRefAddAdditionalReferenceCounts (&Process->PrefetchTrace, Trace, RefsToAdd)) {
                CcPfDecRefEx (&Trace->RefCount, RefsToAdd);
            }
        }

    }
    return Trace;
}

PCCPF_TRACE_HEADER
CcPfRemoveProcessTrace(
    PEPROCESS Process
    )
/*++

Routine Description:

    This routine removes the trace associated with the specified process.

    It returns the trace with the original reference acquired by AddProcessTrace.

Arguments:

    Process - The process whose trace should be removed

Return Value:

    The removed trace buffer.

--*/
{
    EX_FAST_REF OldRef;
    PCCPF_TRACE_HEADER Trace;
    ULONG RefsToReturn;
    KIRQL OldIrql;

    //
    // Do the swap.
    //

    OldRef = ExFastRefSwapObject (&Process->PrefetchTrace, NULL);
    Trace = ExFastRefGetObject (OldRef);

    //
    // We should have a trace on the process if we are trying to remove it.
    //

    CCPF_ASSERT(Trace);

    //
    // Work out how many cached references there were (if any) and 
    // return them.
    //

    RefsToReturn = ExFastRefGetUnusedReferences (OldRef);

    if (RefsToReturn > 0) {
        CcPfDecRefEx (&Trace->RefCount, RefsToReturn);
    }

    //
    // Force any slow path references out of that path now before we return 
    // the trace.
    //

#if !defined (NT_UP)
    KeAcquireSpinLock(&CcPfGlobals.ActiveTracesLock, &OldIrql);                    
    KeReleaseSpinLock(&CcPfGlobals.ActiveTracesLock, OldIrql);
#endif // NT_UP

    //
    // We are returning the trace with the extra reference we had acquired in
    // AddProcessTrace.
    //

    return Trace;

}

NTSTATUS
CcPfAddProcessTrace(
    PEPROCESS Process,
    PCCPF_TRACE_HEADER Trace
    )
/*++

Routine Description:

    This routine adds the trace associated with the specified process
    if possible.

Arguments:

    Process - The process whose trace should be removed
    Trace - The trace to associate with the process

Return Value:

    Status.

--*/
{
    NTSTATUS Status;

    //
    // Bias the trace reference by the cache size + an additional reference to
    // be associated with the fast reference as a whole (allowing the slow
    // path to access the trace.)
    //
    
    Status = CcPfAddRefEx (&Trace->RefCount, ExFastRefGetAdditionalReferenceCount () + 1);
    if (NT_SUCCESS (Status)) {
        ExFastRefInitialize (&Process->PrefetchTrace, Trace);
    }
    
    return Status;
}

//
// Utility routines.
//

PWCHAR
CcPfFindString (
    PUNICODE_STRING SearchIn,
    PUNICODE_STRING SearchFor
    )

/*++

Routine Description:

    Finds SearchFor string in SearchIn string and returns pointer to the 
    beginning of the match in SearchIn.

Arguments:

    SearchIn - Pointer to string to search in.

    SearchFor - Pointer to string to search for.

Return Value:

    Pointer to beginning of match in SearchIn, or NULL if not found.

Environment:

    Kernel mode, IRQL <= DISPATCH_LEVEL if *Key is NonPaged.

--*/

{
    PWCHAR SearchInPosition;
    PWCHAR SearchInEnd;
    PWCHAR SearchInMatchPosition;
    PWCHAR SearchForPosition;
    PWCHAR SearchForEnd;

    SearchInPosition = SearchIn->Buffer;
    SearchInEnd = SearchIn->Buffer + (SearchIn->Length / sizeof(WCHAR));

    SearchForEnd = SearchFor->Buffer + (SearchFor->Length / sizeof(WCHAR));

    while (SearchInPosition < SearchInEnd) {

        //
        // Try to match the SearchFor string starting at SearchInPosition.
        //

        SearchInMatchPosition = SearchInPosition;
        SearchForPosition = SearchFor->Buffer;
        
        while ((SearchInMatchPosition < SearchInEnd) &&
               (SearchForPosition < SearchForEnd) &&
               (*SearchInMatchPosition == *SearchForPosition)) {

            SearchInMatchPosition++;
            SearchForPosition++;
        }

        //
        // We should not go beyond bounds.
        //

        CCPF_ASSERT(SearchInMatchPosition <= SearchInEnd);
        CCPF_ASSERT(SearchForPosition <= SearchForEnd);
               
        //
        // If we matched up to the end of SearchFor string, we found it.
        //

        if (SearchForPosition == SearchForEnd) {
            return SearchInPosition;
        }

        //
        // Look for a match starting at the next character in the SearchIn string.
        //

        SearchInPosition++;
    }

    //
    // We could not find the SearchFor string in SearchIn string.
    //

    return NULL;
}

ULONG
CcPfHashValue(
    PVOID key,
    ULONG len
    )

/*++

Routine Description:

    Generic hash routine.

Arguments:

    Key - Pointer to data to calculate a hash value for.

    Len - Number of bytes pointed to by key.

Return Value:

    Hash value.

Environment:

    Kernel mode, IRQL <= DISPATCH_LEVEL if *Key is NonPaged.

--*/

{
    char *cp = key;
    ULONG i, convkey=0;
    for(i = 0; i < len; i++)
    {
        convkey = 37 * convkey + (unsigned int) *cp;
        cp++;
    }

    #define CCPF_RNDM_CONSTANT   314159269
    #define CCPF_RNDM_PRIME     1000000007

    return (abs(CCPF_RNDM_CONSTANT * convkey) % CCPF_RNDM_PRIME);
}

NTSTATUS 
CcPfIsVolumeMounted (
    IN WCHAR *VolumePath,
    OUT BOOLEAN *VolumeMounted
    )

/*++

Routine Description:

    Determines if the volume is mounted without causing it to be
    mounted..

Arguments:

    VolumePath - Pointer to NUL terminated volume path.

    VolumeMounted - Whether the volume mounted is returned here.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    HANDLE VolumeHandle;
    FILE_FS_DEVICE_INFORMATION DeviceInfo;
    UNICODE_STRING VolumePathU;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatusBlock;
    NTSTATUS Status;
    BOOLEAN OpenedVolume;

    //
    // Initialize locals.
    //
      
    OpenedVolume = FALSE;

    //
    // Open the device so we can query if a volume is mounted without
    // causing it to be mounted.
    //

    RtlInitUnicodeString(&VolumePathU, VolumePath);  

    InitializeObjectAttributes(&ObjectAttributes,
                               &VolumePathU,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);
   
    
    Status = ZwCreateFile(&VolumeHandle,
                          FILE_READ_ATTRIBUTES | SYNCHRONIZE,
                          &ObjectAttributes,
                          &IoStatusBlock,
                          0,
                          0,
                          FILE_SHARE_READ|FILE_SHARE_WRITE|FILE_SHARE_DELETE,
                          FILE_OPEN,
                          FILE_SYNCHRONOUS_IO_NONALERT,
                          NULL,
                          0);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    OpenedVolume = TRUE;

    //
    // Make the device info query.
    //

    Status = ZwQueryVolumeInformationFile(VolumeHandle,
                                          &IoStatusBlock,
                                          &DeviceInfo,
                                          sizeof(DeviceInfo),
                                          FileFsDeviceInformation);
    
    if (NT_ERROR(Status)) {
        goto cleanup;
    }

    //
    // Is a volume mounted on this device?
    //

    *VolumeMounted = (DeviceInfo.Characteristics & FILE_DEVICE_IS_MOUNTED) ? TRUE : FALSE;

    Status = STATUS_SUCCESS;

cleanup:

    if (OpenedVolume) {
        ZwClose(VolumeHandle);
    }

    return Status;

}

NTSTATUS
CcPfQueryVolumeInfo (
    IN WCHAR *VolumePath,
    OPTIONAL OUT HANDLE *VolumeHandleOut,
    OUT PLARGE_INTEGER CreationTime,
    OUT PULONG SerialNumber
    )

/*++

Routine Description:

    Queries volume information for the specified volume.

Arguments:

    VolumePath - Pointer to NUL terminated volume path.

    VolumeHandleOut - If specified, the volume handle is returned here. 
       The caller has to close the volume when done with it.
    
    CreationTime - Pointer to where creation time of the volume will
      be put. 

    SerialNumber - Pointer to where serial number of the volume will be put.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    HANDLE VolumeHandle;
    FILE_FS_VOLUME_INFORMATION VolumeInfo;
    UNICODE_STRING VolumePathU;
    OBJECT_ATTRIBUTES ObjectAttributes;
    IO_STATUS_BLOCK IoStatusBlock;
    NTSTATUS Status;
    BOOLEAN OpenedVolume;
        
    //
    // Initialize locals.
    //
      
    OpenedVolume = FALSE;

    //
    // Open the volume so we can make queries to the file system
    // mounted on it. This will cause a mount if the volume has not been
    // mounted.
    //

    RtlInitUnicodeString(&VolumePathU, VolumePath);  

    InitializeObjectAttributes(&ObjectAttributes,
                               &VolumePathU,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);
   
    
    Status = ZwCreateFile(&VolumeHandle,
                          FILE_WRITE_ATTRIBUTES | FILE_READ_ATTRIBUTES | SYNCHRONIZE,
                          &ObjectAttributes,
                          &IoStatusBlock,
                          0,
                          0,
                          FILE_SHARE_READ|FILE_SHARE_WRITE|FILE_SHARE_DELETE,
                          FILE_OPEN,
                          FILE_SYNCHRONOUS_IO_NONALERT,
                          NULL,
                          0);

    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }
    
    OpenedVolume = TRUE;

    //
    // Query volume information. We won't have space for the full
    // volume label in our buffer but we don't really need it. The
    // file systems seem to fill in the SerialNo/CreationTime fields
    // and return a STATUS_MORE_DATA warning status.
    //

    Status = ZwQueryVolumeInformationFile(VolumeHandle,
                                          &IoStatusBlock,
                                          &VolumeInfo,
                                          sizeof(VolumeInfo),
                                          FileFsVolumeInformation);
    
    if (NT_ERROR(Status)) {
        goto cleanup;
    }

    *CreationTime = VolumeInfo.VolumeCreationTime;
    *SerialNumber = VolumeInfo.VolumeSerialNumber;

    Status = STATUS_SUCCESS;

 cleanup:

    if (NT_SUCCESS(Status)) {

        //
        // If the caller wants the volume handle, hand it over to them.
        // It is their responsibility to close the handle.
        //

        if (VolumeHandleOut) {
            *VolumeHandleOut = VolumeHandle;
            OpenedVolume = FALSE;
        }
    }
   
    if (OpenedVolume) {
        ZwClose(VolumeHandle);
    }

    return Status;
}

//
// Verification code shared between the kernel and user mode
// components. This code should be kept in sync with a simple copy &
// paste, so don't add any kernel/user specific code/macros. Note that
// the prefix on the function names are Pf, just like it is with
// shared structures / constants.
//

BOOLEAN
__forceinline
PfWithinBounds(
    PVOID Pointer,
    PVOID Base,
    ULONG Length
    )

/*++

Routine Description:

    Check whether the pointer is within Length bytes from the base.

Arguments:

    Pointer - Pointer to check.

    Base - Pointer to base of mapping/array etc.

    Length - Number of bytes that are valid starting from Base.

Return Value:

    TRUE - Pointer is within bounds.
    
    FALSE - Pointer is not within bounds.

--*/

{
    if (((PCHAR)Pointer < (PCHAR)Base) ||
        ((PCHAR)Pointer >= ((PCHAR)Base + Length))) {

        return FALSE;
    } else {

        return TRUE;
    }
}

BOOLEAN
PfVerifyScenarioId (
    PPF_SCENARIO_ID ScenarioId
    )

/*++

Routine Description:

    Verify that the scenario id is sensible.

Arguments:

    ScenarioId - Scenario Id to verify.

Return Value:

    TRUE - ScenarioId is fine.
    FALSE - ScenarioId is corrupt.

--*/
    
{
    LONG CurCharIdx;

    //
    // Make sure the scenario name is NUL terminated.
    //

    for (CurCharIdx = PF_SCEN_ID_MAX_CHARS; CurCharIdx >= 0; CurCharIdx--) {

        if (ScenarioId->ScenName[CurCharIdx] == 0) {
            break;
        }
    }

    if (ScenarioId->ScenName[CurCharIdx] != 0) {
        return FALSE;
    }

    //
    // Make sure there is a scenario name.
    //

    if (CurCharIdx == 0) {
        return FALSE;
    }

    //
    // Checks passed.
    //
    
    return TRUE;
}

BOOLEAN
PfVerifyScenarioBuffer(
    PPF_SCENARIO_HEADER Scenario,
    ULONG BufferSize,
    PULONG FailedCheck
    )

/*++

Routine Description:

    Verify offset and indices in a scenario file are not beyond
    bounds. This code is shared between the user mode service and
    kernel mode component. If you update this function, update it in
    both.

Arguments:

    Scenario - Base of mapped view of the whole file.

    BufferSize - Size of the scenario buffer.

    FailedCheck - If verify failed, Id for the check that was failed.

Return Value:

    TRUE - Scenario is fine.
    FALSE - Scenario is corrupt.

--*/

{
    PPF_SECTION_RECORD Sections;
    PPF_SECTION_RECORD pSection;
    ULONG SectionIdx;
    PPF_PAGE_RECORD Pages;
    PPF_PAGE_RECORD pPage;
    LONG PageIdx;   
    PCHAR FileNames;
    PCHAR pFileNameStart;
    PCHAR pFileNameEnd;
    PWCHAR pwFileName;
    LONG FailedCheckId;
    ULONG NumRemainingPages;
    ULONG NumPages;
    LONG PreviousPageIdx;
    ULONG FileNameSize;
    BOOLEAN ScenarioVerified;
    PCHAR MetadataInfoBase;
    PPF_METADATA_RECORD MetadataRecordTable;
    PPF_METADATA_RECORD MetadataRecord;
    ULONG MetadataRecordIdx;
    PWCHAR VolumePath;
    PFILE_PREFETCH FilePrefetchInfo;
    ULONG FilePrefetchInfoSize;
    PPF_COUNTED_STRING DirectoryPath;
    ULONG DirectoryIdx;

    //
    // Initialize locals.
    //

    FailedCheckId = 0;
        
    //
    // Initialize return value to FALSE. It will be set to TRUE only
    // after all the checks pass.
    //
    
    ScenarioVerified = FALSE;

    //
    // The buffer should at least contain the scenario header.
    //

    if (BufferSize < sizeof(PF_SCENARIO_HEADER)) {       
        FailedCheckId = 10;
        goto cleanup;
    }

    if ((ULONG_PTR)Scenario & (_alignof(PF_SCENARIO_HEADER) - 1)) {
        FailedCheckId = 15;
        goto cleanup;
    }

    //
    // Check version and magic on the header.
    //

    if (Scenario->Version != PF_CURRENT_VERSION ||
        Scenario->MagicNumber != PF_SCENARIO_MAGIC_NUMBER) { 

        FailedCheckId = 20;
        goto cleanup;
    }

    //
    // The buffer should not be greater than max allowed size.
    //

    if (BufferSize > PF_MAXIMUM_SCENARIO_SIZE) {
        
        FailedCheckId = 25;
        goto cleanup;
    }

    if (BufferSize != Scenario->Size) {
        FailedCheckId = 26;
        goto cleanup;
    }
        
    //
    // Check for legal scenario type.
    //

    if (Scenario->ScenarioType < 0 || Scenario->ScenarioType >= PfMaxScenarioType) {
        FailedCheckId = 27;
        goto cleanup;
    }

    //
    // Check limits on number of pages, sections etc.
    //

    if (Scenario->NumSections > PF_MAXIMUM_SECTIONS ||
        Scenario->NumMetadataRecords > PF_MAXIMUM_SECTIONS ||
        Scenario->NumPages > PF_MAXIMUM_PAGES ||
        Scenario->FileNameInfoSize > PF_MAXIMUM_FILE_NAME_DATA_SIZE) {
        
        FailedCheckId = 30;
        goto cleanup;
    }

    if (Scenario->NumSections == 0 ||
        Scenario->NumPages == 0 ||
        Scenario->FileNameInfoSize == 0) {
        
        FailedCheckId = 33;
        goto cleanup;
    }
    
    //
    // Check limit on sensitivity.
    //

    if (Scenario->Sensitivity < PF_MIN_SENSITIVITY ||
        Scenario->Sensitivity > PF_MAX_SENSITIVITY) {
        
        FailedCheckId = 35;
        goto cleanup;
    }

    //
    // Make sure the scenario id is valid.
    //

    if (!PfVerifyScenarioId(&Scenario->ScenarioId)) {
        
        FailedCheckId = 37;
        goto cleanup;
    }

    //
    // Initialize pointers to tables.
    //

    Sections = (PPF_SECTION_RECORD) ((PCHAR)Scenario + Scenario->SectionInfoOffset);

    if ((ULONG_PTR)Sections & (_alignof(PF_SECTION_RECORD) - 1)) {
        FailedCheckId = 38;
        goto cleanup;
    }
       
    if (!PfWithinBounds(Sections, Scenario, BufferSize)) {
        FailedCheckId = 40;
        goto cleanup;
    }

    if (!PfWithinBounds((PCHAR) &Sections[Scenario->NumSections] - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 45;
        goto cleanup;
    }   

    Pages = (PPF_PAGE_RECORD) ((PCHAR)Scenario + Scenario->PageInfoOffset);

    if ((ULONG_PTR)Pages & (_alignof(PF_PAGE_RECORD) - 1)) {
        FailedCheckId = 47;
        goto cleanup;
    }
       
    if (!PfWithinBounds(Pages, Scenario, BufferSize)) {
        FailedCheckId = 50;
        goto cleanup;
    }

    if (!PfWithinBounds((PCHAR) &Pages[Scenario->NumPages] - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 55;
        goto cleanup;
    }

    FileNames = (PCHAR)Scenario + Scenario->FileNameInfoOffset;

    if ((ULONG_PTR)FileNames & (_alignof(WCHAR) - 1)) {
        FailedCheckId = 57;
        goto cleanup;
    }
      
    if (!PfWithinBounds(FileNames, Scenario, BufferSize)) {
        FailedCheckId = 60;
        goto cleanup;
    }

    if (!PfWithinBounds(FileNames + Scenario->FileNameInfoSize - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 70;
        goto cleanup;
    }

    MetadataInfoBase = (PCHAR)Scenario + Scenario->MetadataInfoOffset;
    MetadataRecordTable = (PPF_METADATA_RECORD) MetadataInfoBase;

    if ((ULONG_PTR)MetadataRecordTable & (_alignof(PF_METADATA_RECORD) - 1)) {
        FailedCheckId = 72;
        goto cleanup;
    }

    if (!PfWithinBounds(MetadataInfoBase, Scenario, BufferSize)) {
        FailedCheckId = 73;
        goto cleanup;
    }

    if (!PfWithinBounds(MetadataInfoBase + Scenario->MetadataInfoSize - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 74;
        goto cleanup;
    }   

    if (!PfWithinBounds(((PCHAR) &MetadataRecordTable[Scenario->NumMetadataRecords]) - 1, 
                        Scenario, 
                        BufferSize)) {
        FailedCheckId = 75;
        goto cleanup;
    }   
    
    //
    // Verify that sections contain valid information.
    //

    NumRemainingPages = Scenario->NumPages;

    for (SectionIdx = 0; SectionIdx < Scenario->NumSections; SectionIdx++) {
        
        pSection = &Sections[SectionIdx];

        //
        // Check if file name is within bounds. 
        //

        pFileNameStart = FileNames + pSection->FileNameOffset;

        if ((ULONG_PTR)pFileNameStart & (_alignof(WCHAR) - 1)) {
            FailedCheckId = 77;
            goto cleanup;
        }


        if (!PfWithinBounds(pFileNameStart, Scenario, BufferSize)) {
            FailedCheckId = 80;
            goto cleanup;
        }

        //
        // Make sure there is a valid sized file name. 
        //

        if (pSection->FileNameLength == 0) {
            FailedCheckId = 90;
            goto cleanup;    
        }

        //
        // Check file name max length.
        //

        if (pSection->FileNameLength > PF_MAXIMUM_SECTION_FILE_NAME_LENGTH) {
            FailedCheckId = 100;
            goto cleanup;    
        }

        //
        // Note that pFileNameEnd gets a -1 so it is the address of
        // the last byte.
        //

        FileNameSize = (pSection->FileNameLength + 1) * sizeof(WCHAR);
        pFileNameEnd = pFileNameStart + FileNameSize - 1;

        if (!PfWithinBounds(pFileNameEnd, Scenario, BufferSize)) {
            FailedCheckId = 110;
            goto cleanup;
        }

        //
        // Check if the file name is NUL terminated.
        //
        
        pwFileName = (PWCHAR) pFileNameStart;
        
        if (pwFileName[pSection->FileNameLength] != 0) {
            FailedCheckId = 120;
            goto cleanup;
        }

        //
        // Check max number of pages in a section.
        //

        if (pSection->NumPages > PF_MAXIMUM_SECTION_PAGES) {
            FailedCheckId = 140;
            goto cleanup;    
        }

        //
        // Make sure NumPages for the section is at least less
        // than the remaining pages in the scenario. Then update the
        // remaining pages.
        //

        if (pSection->NumPages > NumRemainingPages) {
            FailedCheckId = 150;
            goto cleanup;
        }

        NumRemainingPages -= pSection->NumPages;

        //
        // Verify that there are NumPages pages in our page list and
        // they are sorted by file offset.
        //

        PageIdx = pSection->FirstPageIdx;
        NumPages = 0;
        PreviousPageIdx = PF_INVALID_PAGE_IDX;

        while (PageIdx != PF_INVALID_PAGE_IDX) {
            
            //
            // Check that page idx is within range.
            //
            
            if (PageIdx < 0 || (ULONG) PageIdx >= Scenario->NumPages) {
                FailedCheckId = 160;
                goto cleanup;
            }

            //
            // If this is not the first page record, make sure it
            // comes after the previous one. We also check for
            // duplicate offset here.
            //

            if (PreviousPageIdx != PF_INVALID_PAGE_IDX) {
                if (Pages[PageIdx].FileOffset <= 
                    Pages[PreviousPageIdx].FileOffset) {

                    FailedCheckId = 165;
                    goto cleanup;
                }
            }

            //
            // Update the last page index.
            //

            PreviousPageIdx = PageIdx;

            //
            // Get the next page index.
            //

            pPage = &Pages[PageIdx];
            PageIdx = pPage->NextPageIdx;
            
            //
            // Update the number of pages we've seen on the list so
            // far. If it is greater than what there should be on the
            // list we have a problem. We may have even hit a list.
            //

            NumPages++;
            if (NumPages > pSection->NumPages) {
                FailedCheckId = 170;
                goto cleanup;
            }
        }
        
        //
        // Make sure the section has exactly the number of pages it
        // says it does.
        //

        if (NumPages != pSection->NumPages) {
            FailedCheckId = 180;
            goto cleanup;
        }
    }

    //
    // We should have accounted for all pages in the scenario.
    //

    if (NumRemainingPages) {
        FailedCheckId = 190;
        goto cleanup;
    }

    //
    // Make sure metadata prefetch records make sense.
    //

    for (MetadataRecordIdx = 0;
         MetadataRecordIdx < Scenario->NumMetadataRecords;
         MetadataRecordIdx++) {

        MetadataRecord = &MetadataRecordTable[MetadataRecordIdx];
        
        //
        // Make sure that the volume path is within bounds and NUL
        // terminated.
        //

        VolumePath = (PWCHAR)(MetadataInfoBase + MetadataRecord->VolumeNameOffset);  

        if ((ULONG_PTR)VolumePath & (_alignof(WCHAR) - 1)) {
            FailedCheckId = 195;
            goto cleanup;
        }
       
        if (!PfWithinBounds(VolumePath, Scenario, BufferSize)) {
            FailedCheckId = 200;
            goto cleanup;
        }

        if (!PfWithinBounds(((PCHAR)(VolumePath + MetadataRecord->VolumeNameLength + 1)) - 1, 
                            Scenario, 
                            BufferSize)) {
            FailedCheckId = 210;
            goto cleanup;
        }

        if (VolumePath[MetadataRecord->VolumeNameLength] != 0) {
            FailedCheckId = 220;
            goto cleanup;           
        }

        //
        // Make sure that FilePrefetchInformation is within bounds.
        //

        FilePrefetchInfo = (PFILE_PREFETCH) 
            (MetadataInfoBase + MetadataRecord->FilePrefetchInfoOffset);

        if ((ULONG_PTR)FilePrefetchInfo & (_alignof(FILE_PREFETCH) - 1)) {
            FailedCheckId = 225;
            goto cleanup;
        }
        
        if (!PfWithinBounds(FilePrefetchInfo, Scenario, BufferSize)) {
            FailedCheckId = 230;
            goto cleanup;
        }

        //
        // Its size should be greater than size of a FILE_PREFETCH
        // structure (so we can safely access the fields).
        //

        if (MetadataRecord->FilePrefetchInfoSize < sizeof(FILE_PREFETCH)) {
            FailedCheckId = 240;
            goto cleanup;
        }

        if (!PfWithinBounds((PCHAR)FilePrefetchInfo + MetadataRecord->FilePrefetchInfoSize - 1, 
                            Scenario, 
                            BufferSize)) {
            FailedCheckId = 245;
            goto cleanup;
        }
       
        //
        // It should be for prefetching file creates.
        //

        if (FilePrefetchInfo->Type != FILE_PREFETCH_TYPE_FOR_CREATE) {
            FailedCheckId = 250;
            goto cleanup;
        }

        //
        // There should not be more entries then are files and
        // directories. The number of inidividual directories may be
        // more than what we allow for, but it would be highly rare to
        // be suspicious and thus ignored.
        //

        if (FilePrefetchInfo->Count > PF_MAXIMUM_DIRECTORIES + PF_MAXIMUM_SECTIONS) {
            FailedCheckId = 260;
            goto cleanup;
        }

        //
        // Its size should match the size calculated by number of file
        // index numbers specified in the header.
        //

        FilePrefetchInfoSize = sizeof(FILE_PREFETCH);
        if (FilePrefetchInfo->Count) {
            FilePrefetchInfoSize += (FilePrefetchInfo->Count - 1) * sizeof(ULONGLONG);
        }

        if (FilePrefetchInfoSize != MetadataRecord->FilePrefetchInfoSize) {
            FailedCheckId = 270;
            goto cleanup;
        }

        //
        // Make sure that the directory paths for this volume make
        // sense.
        //

        if (MetadataRecord->NumDirectories > PF_MAXIMUM_DIRECTORIES) {
            FailedCheckId = 280;
            goto cleanup;
        }

        DirectoryPath = (PPF_COUNTED_STRING) 
            (MetadataInfoBase + MetadataRecord->DirectoryPathsOffset);

        if ((ULONG_PTR)DirectoryPath & (_alignof(PF_COUNTED_STRING) - 1)) {
            FailedCheckId = 283;
            goto cleanup;
        }
        
        for (DirectoryIdx = 0;
             DirectoryIdx < MetadataRecord->NumDirectories;
             DirectoryIdx ++) {
            
            //
            // Make sure head of the structure is within bounds.
            //

            if (!PfWithinBounds(DirectoryPath, Scenario, BufferSize)) {
                FailedCheckId = 285;
                goto cleanup;
            }
        
            if (!PfWithinBounds((PCHAR)DirectoryPath + sizeof(PF_COUNTED_STRING) - 1, 
                                Scenario, 
                                BufferSize)) {
                FailedCheckId = 290;
                goto cleanup;
            }
                
            //
            // Check the length of the string.
            //
            
            if (DirectoryPath->Length >= PF_MAXIMUM_SECTION_FILE_NAME_LENGTH) {
                FailedCheckId = 300;
                goto cleanup;
            }

            //
            // Make sure end of the string is within bounds.
            //
            
            if (!PfWithinBounds((PCHAR)(&DirectoryPath->String[DirectoryPath->Length + 1]) - 1,
                                Scenario, 
                                BufferSize)) {
                FailedCheckId = 310;
                goto cleanup;
            }
            
            //
            // Make sure the string is NUL terminated.
            //
            
            if (DirectoryPath->String[DirectoryPath->Length] != 0) {
                FailedCheckId = 320;
                goto cleanup;   
            }
            
            //
            // Set pointer to next DirectoryPath.
            //
            
            DirectoryPath = (PPF_COUNTED_STRING) 
                (&DirectoryPath->String[DirectoryPath->Length + 1]);
        }            
    }

    //
    // We've passed all the checks.
    //

    ScenarioVerified = TRUE;

 cleanup:

    *FailedCheck = FailedCheckId;

    return ScenarioVerified;
}

BOOLEAN
PfVerifyTraceBuffer(
    PPF_TRACE_HEADER Trace,
    ULONG BufferSize,
    PULONG FailedCheck
    )

/*++

Routine Description:

    Verify offset and indices in a trace buffer are not beyond
    bounds. This code is shared between the user mode service and
    kernel mode component. If you update this function, update it in
    both.

Arguments:

    Trace - Base of Trace buffer.

    BufferSize - Size of the scenario file / mapping.

    FailedCheck - If verify failed, Id for the check that was failed.

Return Value:

    TRUE - Trace is fine.
    FALSE - Trace is corrupt;

--*/

{
    LONG FailedCheckId;
    PPF_LOG_ENTRY LogEntries;
    PPF_SECTION_INFO Section;
    PPF_VOLUME_INFO VolumeInfo;
    ULONG SectionLength;
    ULONG EntryIdx;
    ULONG SectionIdx;
    ULONG TotalFaults;
    ULONG PeriodIdx;
    ULONG VolumeIdx;
    BOOLEAN TraceVerified;
    ULONG VolumeInfoSize;

    //
    // Initialize locals:
    //

    FailedCheckId = 0;

    //
    // Initialize return value to FALSE. It will be set to TRUE only
    // after all the checks pass.
    //

    TraceVerified = FALSE;

    //
    // The buffer should at least contain the scenario header.
    //

    if (BufferSize < sizeof(PF_TRACE_HEADER)) {
        FailedCheckId = 10;
        goto cleanup;
    }

    //
    // Check trace header alignment.
    //

    if ((ULONG_PTR)Trace & (_alignof(PF_TRACE_HEADER) - 1)) {
        FailedCheckId = 15;
        goto cleanup;
    }

    //
    // Check version and magic on the header.
    //

    if (Trace->Version != PF_CURRENT_VERSION ||
        Trace->MagicNumber != PF_TRACE_MAGIC_NUMBER) {
        FailedCheckId = 20;
        goto cleanup;
    }

    //
    // The buffer should not be greater than max allowed size.
    //

    if (BufferSize > PF_MAXIMUM_TRACE_SIZE) {
        FailedCheckId = 23;
        goto cleanup;
    }

    //
    // Check for legal scenario type.
    //

    if (Trace->ScenarioType < 0 || Trace->ScenarioType >= PfMaxScenarioType) {
        FailedCheckId = 25;
        goto cleanup;
    }

    //
    // Check limits on number of pages, sections etc.
    //

    if (Trace->NumSections > PF_MAXIMUM_SECTIONS ||
        Trace->NumEntries > PF_MAXIMUM_LOG_ENTRIES ||
        Trace->NumVolumes > PF_MAXIMUM_SECTIONS) {
        FailedCheckId = 30;
        goto cleanup;
    }

    //
    // Check buffer size and the size of the trace.
    //

    if (Trace->Size != BufferSize) {
        FailedCheckId = 35;
        goto cleanup;
    }

    //
    // Make sure the scenario id is valid.
    //

    if (!PfVerifyScenarioId(&Trace->ScenarioId)) {
        
        FailedCheckId = 37;
        goto cleanup;
    }

    //
    // Check Bounds of Trace Buffer
    //

    LogEntries = (PPF_LOG_ENTRY) ((PCHAR)Trace + Trace->TraceBufferOffset);

    if ((ULONG_PTR)LogEntries & (_alignof(PF_LOG_ENTRY) - 1)) {
        FailedCheckId = 38;
        goto cleanup;
    }

    if (!PfWithinBounds(LogEntries, Trace, BufferSize)) {
        FailedCheckId = 40;
        goto cleanup;
    }

    if (!PfWithinBounds((PCHAR)&LogEntries[Trace->NumEntries] - 1, 
                        Trace, 
                        BufferSize)) {
        FailedCheckId = 50;
        goto cleanup;
    }

    //
    // Verify pages contain valid information.
    //

    for (EntryIdx = 0; EntryIdx < Trace->NumEntries; EntryIdx++) {

        //
        // Make sure sequence number is within bounds.
        //

        if (LogEntries[EntryIdx].SectionId >= Trace->NumSections) {
            FailedCheckId = 60;
            goto cleanup;
        }
    }

    //
    // Verify section info entries are valid.
    //

    Section = (PPF_SECTION_INFO) ((PCHAR)Trace + Trace->SectionInfoOffset);

    if ((ULONG_PTR)Section & (_alignof(PF_SECTION_INFO) - 1)) {
        FailedCheckId = 65;
        goto cleanup;
    }

    for (SectionIdx = 0; SectionIdx < Trace->NumSections; SectionIdx++) {

        //
        // Make sure the section is within bounds.
        //

        if (!PfWithinBounds(Section, Trace, BufferSize)) {
            FailedCheckId = 70;
            goto cleanup;
        }

        if (!PfWithinBounds((PCHAR)Section + sizeof(PF_SECTION_INFO) - 1, 
                            Trace, 
                            BufferSize)) {
            FailedCheckId = 75;
            goto cleanup;
        }

        //
        // Make sure the file name is not too big.
        //

        if(Section->FileNameLength > PF_MAXIMUM_SECTION_FILE_NAME_LENGTH) {
            FailedCheckId = 80;
            goto cleanup;
        }
        
        //
        // Calculate size of this section entry.
        //

        SectionLength = sizeof(PF_SECTION_INFO) +
            (Section->FileNameLength) * sizeof(WCHAR);

        //
        // Make sure all of the data in the section info is within
        // bounds.
        //

        if (!PfWithinBounds((PUCHAR)Section + SectionLength - 1, 
                            Trace, 
                            BufferSize)) {

            FailedCheckId = 90;
            goto cleanup;
        }

        //
        // Make sure the file name is NUL terminated.
        //
        
        if (Section->FileName[Section->FileNameLength] != 0) {
            FailedCheckId = 100;
            goto cleanup;
        }

        //
        // Set pointer to next section.
        //

        Section = (PPF_SECTION_INFO) ((PUCHAR) Section + SectionLength);
    }

    //
    // Check FaultsPerPeriod information.
    //

    TotalFaults = 0;

    for (PeriodIdx = 0; PeriodIdx < PF_MAX_NUM_TRACE_PERIODS; PeriodIdx++) {
        TotalFaults += Trace->FaultsPerPeriod[PeriodIdx];
    }

    if (TotalFaults != Trace->NumEntries) {
        FailedCheckId = 120;
        goto cleanup;
    }

    //
    // Verify the volume information block.
    //

    VolumeInfo = (PPF_VOLUME_INFO) ((PCHAR)Trace + Trace->VolumeInfoOffset);

    if ((ULONG_PTR)VolumeInfo & (_alignof(PF_VOLUME_INFO) - 1)) {
        FailedCheckId = 125;
        goto cleanup;
    }

    if (!PfWithinBounds(VolumeInfo, Trace, BufferSize)) {
        FailedCheckId = 130;
        goto cleanup;
    }

    if (!PfWithinBounds((PCHAR)VolumeInfo + Trace->VolumeInfoSize - 1, 
                        Trace, 
                        BufferSize)) {
        FailedCheckId = 140;
        goto cleanup;
    }
    
    //
    // If there are sections, we should have at least one volume.
    //

    if (Trace->NumSections && !Trace->NumVolumes) {
        FailedCheckId = 150;
        goto cleanup;
    }

    //
    // Verify the volume info structures per volume.
    //

    for (VolumeIdx = 0; VolumeIdx < Trace->NumVolumes; VolumeIdx++) {
        
        //
        // Make sure the whole volume structure is within bounds. Note
        // that VolumeInfo structure contains space for the
        // terminating NUL.
        //

        if (!PfWithinBounds(VolumeInfo, Trace, BufferSize)) {
            FailedCheckId = 155;
            goto cleanup;
        }

        if (!PfWithinBounds((PCHAR) VolumeInfo + sizeof(PF_VOLUME_INFO) - 1,
                            Trace,
                            BufferSize)) {
            FailedCheckId = 160;
            goto cleanup;
        }
        
        VolumeInfoSize = sizeof(PF_VOLUME_INFO);
        VolumeInfoSize += VolumeInfo->VolumePathLength * sizeof(WCHAR);
        
        if (!PfWithinBounds((PCHAR) VolumeInfo + VolumeInfoSize - 1,
                            Trace,
                            BufferSize)) {
            FailedCheckId = 165;
            goto cleanup;
        }
        
        //
        // Verify that the volume path string is terminated.
        //

        if (VolumeInfo->VolumePath[VolumeInfo->VolumePathLength] != 0) {
            FailedCheckId = 170;
            goto cleanup;
        }
        
        //
        // Get the next volume.
        //

        VolumeInfo = (PPF_VOLUME_INFO) ((PCHAR) VolumeInfo + VolumeInfoSize);
        
        //
        // Make sure VolumeInfo is aligned.
        //

        VolumeInfo = PF_ALIGN_UP(VolumeInfo, _alignof(PF_VOLUME_INFO));
    }

    //
    // We've passed all the checks.
    //
    
    TraceVerified = TRUE;
    
 cleanup:

    *FailedCheck = FailedCheckId;

    return TraceVerified;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\sources.inc ===
MAJORCOMP=ntos
MINORCOMP=cache

TARGETNAME=cache
TARGETTYPE=LIBRARY
TARGETPATH=obj

BUILD_PRODUCES=ntoscache$(NT_UP)

INCLUDES=..;..\..\inc

SOURCES=..\cachedat.c   \
        ..\cachesub.c   \
        ..\copysup.c    \
        ..\fssup.c      \
        ..\lazyrite.c   \
        ..\logsup.c     \
        ..\mdlsup.c     \
        ..\pinsup.c     \
        ..\prefboot.c   \
        ..\prefetch.c   \
        ..\prefparm.c   \
        ..\ccperf.c     \
        ..\vacbsup.c

PRECOMPILED_INCLUDE=..\cc.h
PRECOMPILED_PCH=cc.pch
PRECOMPILED_OBJ=cc.obj

SOURCES_USED=..\sources.inc
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\preftchp.h ===
/*++

Copyright (c 1999 Microsoft Corporation

Module Name:

    preftchp.h

Abstract:

    This module contains the private definitions for the kernel mode
    prefetcher for optimizing demand paging. Page faults for a
    scenario are logged and the next time scenario starts, these pages
    are prefetched efficiently via asynchronous paging I/O.

Author:

    Stuart Sechrest (stuartse)
    Chuck Lenzmeier (chuckl)
    Cenk Ergan (cenke)

Revision History:

--*/

#ifndef _PREFTCHP_H
#define _PREFTCHP_H

//
// Define tags used in prefetcher routines.
//

#define CCPF_PREFETCHER_TAG         'fPcC'

#define CCPF_ALLOC_SCENARIO_TAG     'SPcC'
#define CCPF_ALLOC_TRACE_TAG        'TPcC'
#define CCPF_ALLOC_TRCBUF_TAG       'BPcC'
#define CCPF_ALLOC_SECTTBL_TAG      'sPcC'
#define CCPF_ALLOC_TRCDMP_TAG       'DPcC'
#define CCPF_ALLOC_QUERY_TAG        'qPcC'
#define CCPF_ALLOC_FILENAME_TAG     'FPcC'
#define CCPF_ALLOC_CONTEXT_TAG      'CPcC'
#define CCPF_ALLOC_INTRTABL_TAG     'IPcC'
#define CCPF_ALLOC_PREFSCEN_TAG     'pPcC'
#define CCPF_ALLOC_BOOTWRKR_TAG     'wPcC'
#define CCPF_ALLOC_VOLUME_TAG       'vPcC'
#define CCPF_ALLOC_READLIST_TAG     'LPcC'
#define CCPF_ALLOC_METADATA_TAG     'MPcC'

//
// Whether the scenario type is for a system-wide scenario, meaning that 
// only it can be active while running.
//

#define CCPF_IS_SYSTEM_WIDE_SCENARIO_TYPE(ScenarioType) \
    ((ScenarioType) == PfSystemBootScenarioType)

//
// In the kernel, we have to look for named objects under this
// directory for them to visible to Win32 prefetcher service.
//

#define CCPF_BASE_NAMED_OBJ_ROOT_DIR L"\\BaseNamedObjects"

//
// This is the invalid index value used with section tables.
//

#define CCPF_INVALID_TABLE_INDEX     (-1)

//
// This is the max number of file metadata that NTFS can prefetch
// at a time.
//

#define CCPF_MAX_FILE_METADATA_PREFETCH_COUNT 0x300

//
// Define structure to hold prefetcher parameters state.
//

typedef struct _CCPF_PREFETCHER_PARAMETERS {

    //
    // This is the named event that is used to signal the service that
    // parameters have been updated.
    //

    HANDLE ParametersChangedEvent;

    //
    // This is the registry key containing prefetch parameters.
    //
    
    HANDLE ParametersKey;

    //
    // Fields used in registering for change notify on parameters
    // registry key.
    //

    IO_STATUS_BLOCK RegistryWatchIosb;
    WORK_QUEUE_ITEM RegistryWatchWorkItem;
    ULONG RegistryWatchBuffer;

    //
    // System wide prefetching parameters. When using any parameters
    // whose update may cause problems [e.g. strings], get the
    // ParametersLock shared. When you need to update Parameters,
    // after getting the ParametersLock exclusive, bump
    // ParametersVersion before updating parameters.
    //

    PF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    ERESOURCE ParametersLock;
    LONG ParametersVersion;

    //
    // Prefixes to registry values for different scenario types.
    //

    WCHAR *ScenarioTypePrefixes[PfMaxScenarioType];

    //
    // This is set to InitSafeBootMode during initialization.
    //
    
    ULONG SafeBootMode;

} CCPF_PREFETCHER_PARAMETERS, *PCCPF_PREFETCHER_PARAMETERS;

//
// Define structure to hold prefetcher's global state.
//

typedef struct _CCPF_PREFETCHER_GLOBALS {

    //
    // List of active traces and the lock to protect it. The number
    // of items on this list is a global, since it is used by other
    // kernel components to make a fast check.
    //

    LIST_ENTRY ActiveTraces;
    KSPIN_LOCK ActiveTracesLock;

    //
    // Pointer to the global trace if one is active. While there is a
    // global trace active we don't trace & prefetch other scenarios.
    // Boot tracing is an example of global trace.
    //

    struct _CCPF_TRACE_HEADER *SystemWideTrace;

    //
    // List and number of saved completed prefetch traces and lock to
    // protect it.
    //

    LIST_ENTRY CompletedTraces; 
    FAST_MUTEX CompletedTracesLock;
    LONG NumCompletedTraces;

    //
    // This is the named event that is used to signal the service that
    // there are traces ready for it to get.
    //

    HANDLE CompletedTracesEvent;

    //
    // Prefetcher parameters.
    //

    CCPF_PREFETCHER_PARAMETERS Parameters;

} CCPF_PREFETCHER_GLOBALS, *PCCPF_PREFETCHER_GLOBALS;

//
// Reference count structure.
//

typedef struct _CCPF_REFCOUNT {

    //
    // When initialized or reset, this reference count starts from
    // 1. When exclusive access is granted it stays at 0: even if it
    // may get bumped by an AddRef by mistake, it will return to 0.
    //

    LONG RefCount;

    //
    // This is set when somebody wants to gain exclusive access to the
    // protected structure.
    //

    LONG Exclusive;   

} CCPF_REFCOUNT, *PCCPF_REFCOUNT;

//
// Define structures used for logging pagefaults:
//

//
// One of these is logged for every page fault.
//

typedef struct _CCPF_LOG_ENTRY {

    //
    // File offset of the page that was faulted.
    //
    
    ULONG FileOffset;

    //
    // Index into the section table in the trace header that helps us
    // identify the file.
    //

    USHORT SectionId;

    //
    // Whether this page was faulted as an image page or data page.
    //

    BOOLEAN IsImage;

} CCPF_LOG_ENTRY, *PCCPF_LOG_ENTRY;

//
// CCPF_LOG_ENTRIES is a buffer of log entries with a small header containing
// an index to the highest used entry. This is used so that a trace can consist
// of several smaller trace buffers instead of one large, fixed-size buffer.
// The current index must be contained in the buffer in order to allow entries
// to be added without acquiring a spin lock.
//

typedef struct _CCPF_LOG_ENTRIES {

    //
    // Link used to put this buffer in the traces's buffer list.
    //

    LIST_ENTRY TraceBuffersLink;

    //
    // NumEntries is the current number of entries in the buffer. MaxEntries
    // is the maximum number of entries that can be placed in the buffer.
    // (Currently MaxEntries always equals CCPF_TRACE_BUFFER_MAX_ENTRIES.)
    //

    LONG NumEntries;
    LONG MaxEntries;

    //
    // The logged entries start here.
    //

    CCPF_LOG_ENTRY Entries[1];

} CCPF_LOG_ENTRIES, *PCCPF_LOG_ENTRIES;

//
// CCPF_TRACE_BUFFER_SIZE is the size of an allocated CCPF_LOG_ENTRIES structure
// (including the header). This should be a multiple of the page size.
//

#define CCPF_TRACE_BUFFER_SIZE 8192

//
// CCPF_TRACE_BUFFER_MAX_ENTRIES is the number of log entries that will fit in
// a trace buffer of size CCPF_TRACE_BUFFER_SIZE.
//

#define CCPF_TRACE_BUFFER_MAX_ENTRIES (((CCPF_TRACE_BUFFER_SIZE - sizeof(CCPF_LOG_ENTRIES)) / sizeof(CCPF_LOG_ENTRY)) + 1)

//
// This structure associates a SectionObjectPointer with a file name
// in the runtime trace buffer. There is a table of these in the trace
// header and every page fault has an index into this table denoting
// which file it is to.
//

typedef struct DECLSPEC_ALIGN(MEMORY_ALLOCATION_ALIGNMENT) _CCPF_SECTION_INFO {

    //
    // Section info entries are kept in a hash. This field is
    // InterlockedCompareExchange'd to denote that it is in use.
    //

    LONG EntryValid;

    //
    // Whether this section is used for file systems to map metafile.
    //

    ULONG Metafile:1;
    ULONG Unused:31;

    //
    // SectionObjectPointer used as a unique identifier to a file
    // mapping. The same file may be mapped using a number of file
    // objects, but the SectionObjectPointer fields of all those file
    // objects will be the same.
    //

    PSECTION_OBJECT_POINTERS SectionObjectPointer;

    //
    // All references to all file objects for a file may be released,
    // and a new file may be opened using the same memory block for
    // its FCB at which point the SectionObjectPointer would no longer
    // be unique. This would result in pagefaults getting logged under
    // the entry for the file that was closed. The consequences would
    // be misprefetching wrong pages from a couple of sections until
    // the scenario corrects itself by looking at new traces. By
    // keeping track of these two fields of the SectionObjectPointers
    // to check for uniqueness we make this case very unlikely to
    // happen. The other solutions we thought of to solve this issue
    // 100% were too costly in terms of complication or efficiency.
    //

    //
    // In order to avoid adding two entries to the table for the
    // section when it is used as data first then image (or vice
    // versa) it is assumed that it is still the same section if the
    // current entry's Data/ImageSectionObject is NULL but the
    // Data/ImageSectionObject of the section we are logging a new
    // pagefault to is not. Then we try to update the NULL pointer
    // with the new value using InterlockedCompareExchangePointer.
    //

    PVOID DataSectionObject;
    PVOID ImageSectionObject;

    //
    // This may point to a file object that we have referenced to
    // ensure the section object stays around until we can get a name.
    //

    PFILE_OBJECT ReferencedFileObject;

    //
    // The name is set as soon as we can get a file name. We cannot
    // access the file name while running at a high IRQL.
    //

    WCHAR *FileName;

    //
    // We queue a section to the get-file-name list using this field.
    //

    SLIST_ENTRY GetNameLink;

} CCPF_SECTION_INFO, *PCCPF_SECTION_INFO;

//
// This structure contains information on a volume on which sections
// in the trace are located on.
//

typedef struct _CCPF_VOLUME_INFO {
    
    //
    // Link in the trace's volume list.
    //

    LIST_ENTRY VolumeLink;

    //
    // Volume creation time and serial number used to identify the
    // volume in case its NT/device path e.g. \Device\HarddiskVolume1
    // changes.
    //

    LARGE_INTEGER CreationTime;
    ULONG SerialNumber;

    //
    // Current NT/device path for the volume and its length in
    // characters excluding terminating NUL.
    //

    ULONG VolumePathLength;
    WCHAR VolumePath[1];

} CCPF_VOLUME_INFO, *PCCPF_VOLUME_INFO;

//
// This is the runtime trace header for a scenario.
//

typedef struct _CCPF_TRACE_HEADER {

    //
    // Magic number identifying this structure as a trace.
    //

    ULONG Magic;

    //
    // Link in the active traces list.
    //

    LIST_ENTRY ActiveTracesLink;

    //
    // Scenario id for which we are acquiring this trace.
    //

    PF_SCENARIO_ID ScenarioId;

    //
    // Type of this scenario.
    //

    PF_SCENARIO_TYPE ScenarioType;

    //
    // CurrentTraceBuffer is the active trace buffer. 
    //
    
    PCCPF_LOG_ENTRIES CurrentTraceBuffer;

    //
    // This is the list of trace buffers for this trace.
    // CurrentTraceBuffer is the last element. Both this list and
    // CurrentTraceBuffer are protected by TraceBufferSpinLock.
    //

    LIST_ENTRY TraceBuffersList;
    ULONG NumTraceBuffers;
    KSPIN_LOCK TraceBufferSpinLock;

    //
    // This is the table for section info.
    //
    
    PCCPF_SECTION_INFO SectionInfoTable;
    LONG NumSections;
    LONG MaxSections;
    ULONG SectionTableSize;

    //
    // We don't log timestamps with page faults but it helps to know
    // how many we are logging per given time. This information can be
    // used to mark the end of a scenario.
    //

    KTIMER TraceTimer;
    LARGE_INTEGER TraceTimerPeriod;
    KDPC TraceTimerDpc;
    KSPIN_LOCK TraceTimerSpinLock;
    
    //
    // This array contains the number of page faults logged per trace
    // period.
    //

    ULONG FaultsPerPeriod[PF_MAX_NUM_TRACE_PERIODS];
    LONG LastNumFaults;
    LONG CurPeriod;
    
    //
    // NumFaults is the number of faults that have been logged so far, in all
    // trace buffers. MaxFaults is the maximum number of page faults we will
    // log, in all trace buffers.
    //

    LONG NumFaults;
    LONG MaxFaults;

    //
    // This workitem is queued to get names for file objects we are
    // logging page faults to. First GetFileNameWorkItemQueued should
    // be InterlockedCompareExchange'd from 0 to 1 and a reference
    // should be acquired on the scenario. The workitem will free this
    // reference just before it completes.
    //

    WORK_QUEUE_ITEM GetFileNameWorkItem;
    LONG GetFileNameWorkItemQueued;

    //
    // Sections for which we have to get names are pushed and popped
    // to/from this slist.
    //

    SLIST_HEADER SectionsWithoutNamesList;

    //
    // Because we don't want to incur the cost of queuing a work item
    // to get file names for every one or two sections, the worker we
    // queue will wait on this event before returning. The event can
    // be signaled when a new section comes, or when the scenario is
    // ending.
    //

    KEVENT GetFileNameWorkerEvent;

    //
    // This is the process we are associated with.
    //

    PEPROCESS Process;

    //
    // This is the removal reference count protecting us.
    //

    CCPF_REFCOUNT RefCount;

    //
    // This work item can be queued to call the end trace function if
    // the trace times out or we log to many entries etc. First
    // EndTraceCalled should be InterlockedCompareExchange'd from 0 to
    // 1.
    //

    WORK_QUEUE_ITEM EndTraceWorkItem;

    //
    // Before anybody calls end trace function, they have to
    // InterlockedCompareExchange this from 0 to 1 to ensure this
    // function gets called only once.
    //

    LONG EndTraceCalled;

    //
    // This is the list of volumes the sections we are tracing are
    // located on. It is sorted lexically by the volume NT/device path.
    //

    LIST_ENTRY VolumeList;
    ULONG NumVolumes;

    //
    // This is the pointer to the built trace dump from this runtime
    // trace structure and the status with which dumping failed if it
    // did. These are useful for debugging on retail builds.
    //

    struct _CCPF_TRACE_DUMP *TraceDump;
    NTSTATUS TraceDumpStatus;

    //
    // System time when we started tracing.
    //
    
    LARGE_INTEGER LaunchTime;

} CCPF_TRACE_HEADER, *PCCPF_TRACE_HEADER;

//
// This structure is used to save completed traces in a list. The
// trace extends beyond this structure as necessary.
//

typedef struct _CCPF_TRACE_DUMP {
    
    //
    // Link in the completed traces list.
    //

    LIST_ENTRY CompletedTracesLink;
    
    //
    // Completed trace.
    //

    PF_TRACE_HEADER Trace;

} CCPF_TRACE_DUMP, *PCCPF_TRACE_DUMP;

//
// This structure contains information for a volume used during prefetching.
//

typedef struct _CCPF_PREFETCH_VOLUME_INFO {

    //
    // Link in the lists this volume gets put on.
    //

    LIST_ENTRY VolumeLink;

    //
    // Volume path.
    //

    WCHAR *VolumePath;
    ULONG VolumePathLength;

    //
    // Handle to the opened volume.
    //

    HANDLE VolumeHandle;

} CCPF_PREFETCH_VOLUME_INFO, *PCCPF_PREFETCH_VOLUME_INFO;

//
// This structure is used to keep track of prefetched pages & context.
//

//
// Note: This structure is used as a stack variable. Don't add events
// etc, without changing that.
//

typedef struct _CCPF_PREFETCH_HEADER {

    //
    // Pointer to prefetch instructions. The instructions should not
    // be removed / freed until the prefetch header is cleaned up.
    // E.g. VolumeNodes may point to volume paths in the scenario.
    //

    PPF_SCENARIO_HEADER Scenario;

    //
    // Nodes for the volumes we are going to prefetch from.
    //

    PCCPF_PREFETCH_VOLUME_INFO VolumeNodes;

    //
    // List of volumes we won't prefetch on.
    //

    LIST_ENTRY BadVolumeList;

    //
    // List of volumes we have opened. They are opened with the following 
    // flags: FILE_READ_ATTRIBUTES | FILE_WRITE_ATTRIBUTES | SYNCHRONIZE
    //

    LIST_ENTRY OpenedVolumeList;

} CCPF_PREFETCH_HEADER, *PCCPF_PREFETCH_HEADER;

//
// Define types of prefetching CcPfPrefetchSections can be called to
// perform.
//

typedef enum _CCPF_PREFETCH_TYPE {
    CcPfPrefetchAllDataPages,
    CcPfPrefetchAllImagePages,
    CcPfPrefetchPartOfDataPages,
    CcPfPrefetchPartOfImagePages,
    CcPfMaxPrefetchType
} CCPF_PREFETCH_TYPE, *PCCPF_PREFETCH_TYPE;

//
// This structure stands for the position in the prefetch
// instructions. It is used and updated by CcPfPrefetchSections when
// prefetching parts of a scenario at a time.
//

typedef struct _CCPF_PREFETCH_CURSOR {
    
    //
    // Index of the current section and the page in that section.
    //

    ULONG SectionIdx;
    ULONG PageIdx;
    
} CCPF_PREFETCH_CURSOR, *PCCPF_PREFETCH_CURSOR;

//
// This type is used in CcPfPrefetchSections.
//

typedef struct _SECTION *PSECTION;

//
// Define types of information CcPfQueryScenarioInformation can be
// asked to return.
//

typedef enum _CCPF_SCENARIO_INFORMATION_TYPE {
    CcPfBasicScenarioInformation,
    CcPfBootScenarioInformation,
    CcPfMaxScenarioInformationType
} CCPF_SCENARIO_INFORMATION_TYPE, *PCCPF_SCENARIO_INFORMATION_TYPE;

//
// This structure contains basic scenario information.
//

typedef struct _CCPF_BASIC_SCENARIO_INFORMATION {
    
    //
    // Number of pages that will be prefetched as data pages.
    //
    
    ULONG NumDataPages;

    //
    // Number of pages that will be prefetched as image pages.
    //

    ULONG NumImagePages;

    //
    // Number of sections for which only data pages will be
    // prefetched.
    //

    ULONG NumDataOnlySections;

    //
    // Number of sections for which only image pages will be
    // prefetched excluding the header page.
    //

    ULONG NumImageOnlySections;

    //
    // Number of ignored pages.
    //
    
    ULONG NumIgnoredPages;

    //
    // Number of ignored sections.
    //

    ULONG NumIgnoredSections;

} CCPF_BASIC_SCENARIO_INFORMATION, *PCCPF_BASIC_SCENARIO_INFORMATION;

//
// Routines used in the core prefetcher.
//

//
// Routines used in prefetch tracing.
//

NTSTATUS
CcPfBeginTrace(
    IN PF_SCENARIO_ID *ScenarioId,
    IN PF_SCENARIO_TYPE ScenarioType,
    IN PEPROCESS Process
    );

NTSTATUS
CcPfActivateTrace(
    IN PCCPF_TRACE_HEADER Scenario
    );

NTSTATUS
CcPfDeactivateTrace(
    IN PCCPF_TRACE_HEADER Scenario
    );

NTSTATUS
CcPfEndTrace(
    IN PCCPF_TRACE_HEADER Trace
    );

NTSTATUS
CcPfBuildDumpFromTrace(
    OUT PCCPF_TRACE_DUMP *TraceDump, 
    IN PCCPF_TRACE_HEADER RuntimeTrace
    );

VOID
CcPfCleanupTrace(
    IN PCCPF_TRACE_HEADER Trace
    );

VOID
CcPfTraceTimerRoutine(
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    );

NTSTATUS
CcPfCancelTraceTimer(
    IN PCCPF_TRACE_HEADER Trace
    );

VOID
CcPfEndTraceWorkerThreadRoutine(
    PVOID Parameter
    );

VOID
CcPfGetFileNamesWorkerRoutine(
    PVOID Parameter
    );

LONG
CcPfLookUpSection(
    PCCPF_SECTION_INFO Table,
    ULONG TableSize,
    PSECTION_OBJECT_POINTERS SectionObjectPointer,
    PLONG AvailablePosition
    );

NTSTATUS
CcPfGetCompletedTrace (
    PVOID Buffer,
    ULONG BufferSize,
    PULONG ReturnSize
    );               

NTSTATUS
CcPfUpdateVolumeList(
    PCCPF_TRACE_HEADER Trace,
    WCHAR *VolumePath,
    ULONG VolumePathLength
    );
    
//
// Routines used for prefetching and dealing with prefetch instructions.
//

NTSTATUS
CcPfPrefetchScenario (
    PPF_SCENARIO_HEADER Scenario
    );

NTSTATUS
CcPfPrefetchSections(
    IN PCCPF_PREFETCH_HEADER PrefetchHeader,
    IN CCPF_PREFETCH_TYPE PrefetchType,
    OPTIONAL IN PCCPF_PREFETCH_CURSOR StartCursor,
    OPTIONAL PFN_NUMBER TotalPagesToPrefetch,
    OPTIONAL OUT PPFN_NUMBER NumPagesPrefetched,
    OPTIONAL OUT PCCPF_PREFETCH_CURSOR EndCursor
    );

NTSTATUS
CcPfPrefetchMetadata(
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    );

NTSTATUS
CcPfPrefetchDirectoryContents(
    WCHAR *DirectoryPath,
    WCHAR DirectoryPathlength
    );

NTSTATUS
CcPfPrefetchFileMetadata(
    HANDLE VolumeHandle,
    PFILE_PREFETCH FilePrefetch
    );

VOID
CcPfInitializePrefetchHeader (
    OUT PCCPF_PREFETCH_HEADER PrefetchHeader
);

VOID
CcPfCleanupPrefetchHeader (
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    );

NTSTATUS
CcPfGetPrefetchInstructions(
    IN PPF_SCENARIO_ID ScenarioId,
    IN PF_SCENARIO_TYPE ScenarioType,
    OUT PPF_SCENARIO_HEADER *ScenarioHeader
    );

NTSTATUS
CcPfQueryScenarioInformation(
    IN PPF_SCENARIO_HEADER Scenario,
    IN CCPF_SCENARIO_INFORMATION_TYPE InformationType,
    OUT PVOID Buffer,
    IN ULONG BufferSize,
    OUT PULONG RequiredSize
    );

NTSTATUS
CcPfOpenVolumesForPrefetch (
    IN PCCPF_PREFETCH_HEADER PrefetchHeader
    );

PCCPF_PREFETCH_VOLUME_INFO 
CcPfFindPrefetchVolumeInfoInList(
    WCHAR *Path,
    PLIST_ENTRY List
    );
    
NTSTATUS
CcPfGetSectionObject(
    IN PUNICODE_STRING FileName,
    IN LOGICAL ImageSection,
    OUT PVOID* SectionObject,
    OUT PFILE_OBJECT* FileObject,
    OUT HANDLE* FileHandle
    );

//
// Routines used for application launch prefetching.
//

BOOLEAN
CcPfIsHostingApplication(
    IN PWCHAR ExecutableName
    );

NTSTATUS
CcPfScanCommandLine(
    OUT PULONG PrefetchHint,
    OPTIONAL OUT PULONG HashId
    );

//
// Reference count functions:
//

VOID
CcPfInitializeRefCount(
    PCCPF_REFCOUNT RefCount
    );

NTSTATUS
FASTCALL
CcPfAddRef(
    PCCPF_REFCOUNT RefCount
    );

VOID
FASTCALL
CcPfDecRef(
    PCCPF_REFCOUNT RefCount
    );

NTSTATUS
FASTCALL
CcPfAddRefEx(
    PCCPF_REFCOUNT RefCount,
    ULONG Count
    );

VOID
FASTCALL
CcPfDecRefEx(
    PCCPF_REFCOUNT RefCount,
    ULONG Count
    );

NTSTATUS
CcPfAcquireExclusiveRef(
    PCCPF_REFCOUNT RefCount
    );

PCCPF_TRACE_HEADER
CcPfReferenceProcessTrace(
    PEPROCESS Process
    );

PCCPF_TRACE_HEADER
CcPfRemoveProcessTrace(
    PEPROCESS Process
    );

NTSTATUS
CcPfAddProcessTrace(
    PEPROCESS Process,
    PCCPF_TRACE_HEADER Trace
    );

//
// Utility routines.
//

PWCHAR
CcPfFindString (
    PUNICODE_STRING SearchIn,
    PUNICODE_STRING SearchFor
    );
    
ULONG
CcPfHashValue(
    PVOID Key,
    ULONG Len
    );

NTSTATUS 
CcPfIsVolumeMounted (
    IN WCHAR *VolumePath,
    OUT BOOLEAN *VolumeMounted
    );
    
NTSTATUS
CcPfQueryVolumeInfo (
    IN WCHAR *VolumePath,
    OPTIONAL OUT HANDLE *VolumeHandleOut,
    OUT PLARGE_INTEGER CreationTime,
    OUT PULONG SerialNumber
    );
    
//
// Declarations and definitions for prefetcher parameters.
//

//
// Define location of registry key for prefetch parameters.
//

#define CCPF_PARAMETERS_KEY L"\\Registry\\Machine\\System\\CurrentControlSet\\Control\\Session Manager\\Memory Management\\PrefetchParameters"

//
// Maximum characters in registry value names for prefetch parameters.
//

#define CCPF_MAX_PARAMETER_NAME_LENGTH  80

//
// Maximum bytes needed to query a prefetch parameter from the
// registry. Currently our largest parameter would be the hosting
// application list.
//

#define CCPF_MAX_PARAMETER_VALUE_BUFFER ((PF_HOSTING_APP_LIST_MAX_CHARS * sizeof(WCHAR)) + sizeof(KEY_VALUE_PARTIAL_INFORMATION))

NTSTATUS
CcPfParametersInitialize (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );
    
VOID
CcPfParametersSetDefaults (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );
    
NTSTATUS
CcPfParametersRead (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );
 
NTSTATUS
CcPfParametersSave (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );

NTSTATUS
CcPfParametersVerify (
    PPF_SYSTEM_PREFETCH_PARAMETERS Parameters
    );

VOID
CcPfParametersWatcher (
    IN PVOID Context
    );

NTSTATUS
CcPfParametersSetChangedEvent (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    );

NTSTATUS
CcPfGetParameter (
    HANDLE ParametersKey,
    WCHAR *ValueNameBuffer,
    ULONG ValueType,
    PVOID Value,
    ULONG *ValueSize
    );

NTSTATUS
CcPfSetParameter (
    HANDLE ParametersKey,
    WCHAR *ValueNameBuffer,
    ULONG ValueType,
    PVOID Value,
    ULONG ValueSize
    );

LOGICAL
CcPfDetermineEnablePrefetcher(
    VOID
    );

//
// Declarations and definitions for boot prefetching.
//

//
// Value name under prefetcher parameters key where we store how long
// video initialization took during boot.
//

#define CCPF_VIDEO_INIT_TIME_VALUE_NAME      L"VideoInitTime"

//
// How long (in milliseconds) video initialization could take max. This value 
// is used to sanity check the value read from the registry.
//

#define CCPF_MAX_VIDEO_INIT_TIME             (10 * 1000) // 10 seconds

//
// Value name under prefetcher parameters key where we store how many
// pages we should try to prefetch per second of video initialization.
//

#define CCPF_VIDEO_INIT_PAGES_PER_SECOND_VALUE_NAME L"VideoInitPagesPerSecond"

//
// Sanity check maximum value for video init pages per second.
//

#define CCPF_VIDEO_INIT_MAX_PAGES_PER_SECOND        128000

//
// How many pages will we try to prefetch in parallel to video initialization
// per second of it.
//

#define CCPF_VIDEO_INIT_DEFAULT_PAGES_PER_SECOND    1500

//
// Maximum number of chunks in which we will prefetch for boot.
//

#define CCPF_MAX_BOOT_PREFETCH_PHASES        16

//
// Different phases of boot we return page counts for in
// CCPF_BOOT_SCENARIO_INFORMATION.
//

typedef enum _CCPF_BOOT_SCENARIO_PHASE {

    CcPfBootScenDriverInitPhase,
    CcPfBootScenSubsystemInitPhase,
    CcPfBootScenSystemProcInitPhase,
    CcPfBootScenServicesInitPhase,
    CcPfBootScenUserInitPhase,
    CcPfBootScenMaxPhase

} CCPF_BOOT_SCENARIO_PHASE, *PCCPF_BOOT_SCENARIO_PHASE;

//
// Define structure to hold boot prefetching state.
//

typedef struct _CCPF_BOOT_PREFETCHER {

    //
    // These events are signaled by the boot prefetch worker when 
    // it has completed prefetching for the specified phase. 
    //

    KEVENT SystemDriversPrefetchingDone;
    KEVENT PreSmssPrefetchingDone;
    KEVENT VideoInitPrefetchingDone;

    //
    // This event will be signaled when we start initializing video
    // on the console. Boot prefetcher waits on this event to perform
    // prefetching parallel to video initialization.
    //
    
    KEVENT VideoInitStarted;

} CCPF_BOOT_PREFETCHER, *PCCPF_BOOT_PREFETCHER;

//
// This structure contains boot scenario information.
//

typedef struct _CCPF_BOOT_SCENARIO_INFORMATION {

    //
    // These are the number of data/image pages to prefetch for the
    // different phase of boot.
    //

    ULONG NumDataPages[CcPfBootScenMaxPhase];
    ULONG NumImagePages[CcPfBootScenMaxPhase];
    
} CCPF_BOOT_SCENARIO_INFORMATION, *PCCPF_BOOT_SCENARIO_INFORMATION;

//
// We will be prefetching data and image pages for boot in parts. Since the
// code is mostly same to prefetch the data and image pages, we keep track
// of where we left off and what to prefetch next in a common boot prefetch 
// cursor structure and make two passes (first for data, then for image).
//

typedef struct _CCPF_BOOT_PREFETCH_CURSOR {

    //
    // Start & end cursors passed to prefetch sections function.
    //

    CCPF_PREFETCH_CURSOR StartCursor;
    CCPF_PREFETCH_CURSOR EndCursor;

    //
    // How to prefetch (e.g. part of data pages or part of image pages).
    //

    CCPF_PREFETCH_TYPE PrefetchType; 

    //
    // How many pages to prefetch per phase.
    //

    ULONG NumPagesForPhase[CCPF_MAX_BOOT_PREFETCH_PHASES];
   
} CCPF_BOOT_PREFETCH_CURSOR, *PCCPF_BOOT_PREFETCH_CURSOR;

//
// Boot prefetching routines.
//

VOID
CcPfBootWorker(
    PCCPF_BOOT_PREFETCHER BootPrefetcher
    );

NTSTATUS
CcPfBootQueueEndTraceTimer (
    PLARGE_INTEGER Timeout
    );    

VOID
CcPfEndBootTimerRoutine(
    IN PKDPC Dpc,
    IN PVOID DeferredContext,
    IN PVOID SystemArgument1,
    IN PVOID SystemArgument2
    );

//
// Debug routines.
//

#if CCPF_DBG

NTSTATUS
CcPfWriteToFile(
    IN PVOID pData,
    IN ULONG Size,
    IN WCHAR *pFileName
    );

#endif // CCPF_DBG

//
// Define useful macros. As with all macros, must be careful of
// parameter reevalation. Don't use expressions as macro parameters.
//

#define CCPF_MAX(A,B) (((A) >= (B)) ? (A) : (B))
#define CCPF_MIN(A,B) (((A) <= (B)) ? (A) : (B))
        
//
// Define debugging macros:
//

//
// Define the component ID we use.
//

#define CCPFID     DPFLTR_PREFETCHER_ID

//
// Define DbgPrintEx levels.
//

#define PFERR      DPFLTR_ERROR_LEVEL
#define PFWARN     DPFLTR_WARNING_LEVEL
#define PFTRC      DPFLTR_TRACE_LEVEL
#define PFINFO     DPFLTR_INFO_LEVEL
#define PFPREF     4
#define PFPRFD     5
#define PFPRFF     6
#define PFPRFZ     7
#define PFTRAC     8
#define PFTMR      9
#define PFNAME     10
#define PFNAMS     11
#define PFLKUP     12
#define PFBOOT     13

//
// DbgPrintEx levels 20 - 31 are reserved for the service.
//

//
//  This may help you determine what to set the DbgPrintEx mask.
//
//  3 3 2 2  2 2 2 2  2 2 2 2  1 1 1 1   1 1 1 1  1 1 0 0  0 0 0 0  0 0 0 0
//  1 0 9 8  7 6 5 4  3 2 1 0  9 8 7 6   5 4 3 2  1 0 9 8  7 6 5 4  3 2 1 0
//  _ _ _ _  _ _ _ _  _ _ _ _  _ _ _ _   _ _ _ _  _ _ _ _  _ _ _ _  _ _ _ _
//

//
// CCPF_DBG can be defined if you want to turn on asserts and debug
// prints in prefetcher code but you do not want to have a checked
// kernel. Defining CCPF_DBG overrides defining DBG.
//

#if CCPF_DBG

NTSYSAPI
VOID
NTAPI
RtlAssert(
    PVOID FailedAssertion,
    PVOID FileName,
    ULONG LineNumber,
    PCHAR Message
    );

#define DBGPR(x) DbgPrintEx x
#define CCPF_ASSERT(x) if (!(x)) RtlAssert(#x, __FILE__, __LINE__, NULL )

#else  // CCPF_DBG

//
// If CCPF_DBG is not defined, build with debug prints and asserts
// only on checked build.
//

#if DBG

#define DBGPR(x) DbgPrintEx x
#define CCPF_ASSERT(x) ASSERT(x)

#else // DBG

//
// On a free build we don't compile with debug prints or asserts.
//

#define DBGPR(x)
#define CCPF_ASSERT(x)

#endif // DBG

#endif // CCPF_DBG

#endif // _PREFTCHP_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\prefparm.c ===
/*++

Copyright (c) 1999 Microsoft Corporation

Module Name:

    prefparm.c

Abstract:

    This module contains the code for prefetcher parameter handling.

Author:

    Cenk Ergan (cenke)          15-Mar-2000

Revision History:

--*/

#include "cc.h"
#include "zwapi.h"
#include "prefetch.h"
#include "preftchp.h"
#include "stdio.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT, CcPfParametersInitialize)
#pragma alloc_text(INIT, CcPfParametersSetDefaults)
#pragma alloc_text(PAGE, CcPfParametersRead)
#pragma alloc_text(PAGE, CcPfParametersSave)
#pragma alloc_text(PAGE, CcPfParametersVerify)
#pragma alloc_text(PAGE, CcPfParametersWatcher)
#pragma alloc_text(PAGE, CcPfParametersSetChangedEvent)
#pragma alloc_text(PAGE, CcPfGetParameter)
#pragma alloc_text(PAGE, CcPfSetParameter)
#pragma alloc_text(PAGE, CcPfDetermineEnablePrefetcher)
#pragma alloc_text(PAGE, CcPfIsHostingApplication)
#endif // ALLOC_PRAGMA

//
// Globals:
//

extern CCPF_PREFETCHER_GLOBALS CcPfGlobals;

//
// Constants:
//

//
// The following are used as prefixs for the value names for registry
// parameters that are per scenario type.
//

WCHAR *CcPfAppLaunchScenarioTypePrefix = L"AppLaunch";
WCHAR *CcPfBootScenarioTypePrefix = L"Boot";
WCHAR *CcPfInvalidScenarioTypePrefix = L"Invalid";

//
// Routines for prefetcher parameter handling.
//

NTSTATUS
CcPfParametersInitialize (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    Initializes specified prefetcher parameters structure.

Arguments:

    PrefetcherParameters - Pointer to structure to initialize.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

Notes:

    The code & local constants for this function gets discarded after system boots.   

--*/

{   
    OBJECT_ATTRIBUTES ObjectAttributes;
    UNICODE_STRING KeyName;
    NTSTATUS Status;

    //
    // Zero out the structure. This initializes:
    // ParametersVersion
    //

    RtlZeroMemory(PrefetcherParameters, sizeof(*PrefetcherParameters));

    //
    // Initialize the lock protecting the parameters and parameters
    // version. Each time parameters are updated, the version is
    // bumped.
    //

    ExInitializeResourceLite(&PrefetcherParameters->ParametersLock);
    
    //
    // Initialize the workitem used for registry notifications on the
    // parameters key.
    //

    ExInitializeWorkItem(&PrefetcherParameters->RegistryWatchWorkItem, 
                         CcPfParametersWatcher, 
                         PrefetcherParameters);

    //
    // Set default parameters.
    //

    CcPfParametersSetDefaults(PrefetcherParameters);

    //
    // Create / Open the registry key that contains our parameters.
    //

    RtlInitUnicodeString(&KeyName, CCPF_PARAMETERS_KEY);

    InitializeObjectAttributes(&ObjectAttributes,
                               &KeyName,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               NULL);

    Status = ZwCreateKey(&PrefetcherParameters->ParametersKey,
                         KEY_ALL_ACCESS,
                         &ObjectAttributes,
                         0,
                         NULL,
                         REG_OPTION_NON_VOLATILE,
                         0);

    if (NT_SUCCESS(Status)) {      

        //
        // Update the default parameters with those in the registry.
        //
    
        Status = CcPfParametersRead(PrefetcherParameters); 
    
        if (!NT_SUCCESS(Status)) {
            DBGPR((CCPFID,PFERR,"CCPF: Init-FailedReadParams=%x\n",Status));
        }

        //
        // Request notification when something changes in the
        // prefetcher parameters key.
        //
    
        Status = ZwNotifyChangeKey(PrefetcherParameters->ParametersKey,
                                   NULL,
                                   (PIO_APC_ROUTINE)&PrefetcherParameters->RegistryWatchWorkItem,
                                   (PVOID)(UINT_PTR)(unsigned int)DelayedWorkQueue,
                                   &PrefetcherParameters->RegistryWatchIosb,
                                   REG_LEGAL_CHANGE_FILTER,
                                   FALSE,
                                   &PrefetcherParameters->RegistryWatchBuffer,
                                   sizeof(PrefetcherParameters->RegistryWatchBuffer),
                                   TRUE);
    
        if (!NT_SUCCESS(Status)) {

            //
            // Although we could not register a notification, this
            // is not a fatal error.
            //

            DBGPR((CCPFID,PFERR,"CCPF: Init-FailedSetParamNotify=%x\n",Status));
        }

    } else {

        DBGPR((CCPFID,PFERR,"CCPF: Init-FailedCreateParamKey=%x\n",Status));

        //
        // Make sure parameters key handle is invalid.
        //
        
        PrefetcherParameters->ParametersKey = NULL;
    }

    return Status;
}

VOID
CcPfParametersSetDefaults (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    Initializes specified parameters structure to default values.

Arguments:

    Parameters - Pointer to structure to initialize.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

Notes:

    The code & local constants for this function gets discarded after system boots.   

--*/

{
    PPF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    PPF_TRACE_LIMITS TraceLimits;
    PF_SCENARIO_TYPE ScenarioType;

    //
    // Initialize locals.
    //

    Parameters = &PrefetcherParameters->Parameters;

    for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {

        //
        // PfSvNotSpecified is currently treated as disabled.
        //

        Parameters->EnableStatus[ScenarioType] = PfSvNotSpecified;

        //
        // Trace limits are determined based on scenario type.
        //

        TraceLimits = &Parameters->TraceLimits[ScenarioType];

        switch(ScenarioType) {

        case PfApplicationLaunchScenarioType:

            TraceLimits->MaxNumPages =    4000;
            TraceLimits->MaxNumSections = 170;
            TraceLimits->TimerPeriod =    (-1 * 1000 * 1000 * 10);

            PrefetcherParameters->ScenarioTypePrefixes[ScenarioType] = 
                CcPfAppLaunchScenarioTypePrefix;

            break;

        case PfSystemBootScenarioType:

            TraceLimits->MaxNumPages =    128000;
            TraceLimits->MaxNumSections = 4080;
            TraceLimits->TimerPeriod =    (-1 * 12000 * 1000 * 10);

            PrefetcherParameters->ScenarioTypePrefixes[ScenarioType] = 
                CcPfBootScenarioTypePrefix;

            break;
        
        default:
        
            //
            // We should be handling all scenario types above.
            //

            CCPF_ASSERT(FALSE);

            TraceLimits->MaxNumPages =    PF_MAXIMUM_PAGES;
            TraceLimits->MaxNumSections = PF_MAXIMUM_SECTIONS;
            TraceLimits->TimerPeriod =    (-1 * 1000 * 1000 * 10);

            PrefetcherParameters->ScenarioTypePrefixes[ScenarioType] = 
                CcPfInvalidScenarioTypePrefix;
        }
    }

    //
    // These limits ensure that we don't monopolize system resources
    // for prefetching.
    //

    Parameters->MaxNumActiveTraces = 8;
    Parameters->MaxNumSavedTraces = 8;

    //
    // This is the default directory under SystemRoot where we
    // find prefetch instructions for scenarios. During upgrades
    // we remove the contents of this directory, so "Prefetch" is
    // hardcoded in txtsetup.inx.
    //

    wcsncpy(Parameters->RootDirPath, 
            L"Prefetch",
            PF_MAX_PREFETCH_ROOT_PATH);

    Parameters->RootDirPath[PF_MAX_PREFETCH_ROOT_PATH - 1] = 0;

    //
    // This is the default list of known hosting applications.
    //

    wcsncpy(Parameters->HostingApplicationList,
            L"DLLHOST.EXE,MMC.EXE,RUNDLL32.EXE",
            PF_HOSTING_APP_LIST_MAX_CHARS);

    Parameters->HostingApplicationList[PF_HOSTING_APP_LIST_MAX_CHARS - 1] = 0;

    //
    // Make sure the default parameters make sense.
    //

    CCPF_ASSERT(NT_SUCCESS(CcPfParametersVerify(Parameters)));

}

NTSTATUS
CcPfParametersRead (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    This routine updates the parameters structure with the
    parameters in the registry.

    Keep the value names that are used in sync with the function to
    save the parameters.

Arguments:

    PrefetcherParameters - Pointer to parameters.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    PF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    PPF_TRACE_LIMITS TraceLimits;
    PF_SCENARIO_TYPE ScenarioType;
    WCHAR ValueName[CCPF_MAX_PARAMETER_NAME_LENGTH];
    WCHAR *ValueNamePrefix;
    HANDLE ParametersKey;
    BOOLEAN EnableStatusSpecified;
    ULONG EnablePrefetcher;
    BOOLEAN AcquiredParametersLock;
    ULONG Length;
    LONG CurrentVersion;
    ULONG RetryCount;
    PKTHREAD CurrentThread;

    //
    // Initialize locals.
    //

    CurrentThread = KeGetCurrentThread ();
    AcquiredParametersLock = FALSE;
    RetryCount = 0;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersRead()\n"));

    do {

        //
        // Get the parameters lock shared. 
        // 
        
        KeEnterCriticalRegionThread(CurrentThread);
        ExAcquireResourceSharedLite(&PrefetcherParameters->ParametersLock, TRUE);
        AcquiredParametersLock = TRUE;

        //
        // If we could not initialize the parameters key, we would fail
        // all the following ops miserably.
        //

        if (!PrefetcherParameters->ParametersKey) {
            Status = STATUS_REINITIALIZATION_NEEDED;
            goto cleanup;
        }

        ParametersKey = PrefetcherParameters->ParametersKey;

        //
        // Save current version of parameters. Each time parameters gets
        // updated, the version is bumped.
        //
        
        CurrentVersion = PrefetcherParameters->ParametersVersion;

        //
        // Copy over existing parameters to the parameters structure we
        // are building. This way, if we cannot get a value from the
        // registry we'll keep the value we already have.
        //

        Parameters = PrefetcherParameters->Parameters;

        //
        // Read the prefetcher enable value. Depending on whether it is
        // specified and if so its value we will set enable status for
        // prefetch scenario types.
        //

        Length = sizeof(EnablePrefetcher);
        Status = CcPfGetParameter(ParametersKey,
                                  L"EnablePrefetcher",
                                  REG_DWORD,
                                  &EnablePrefetcher,
                                  &Length);

        if (!NT_SUCCESS(Status)) {
        
            //
            // Enable status is not specified or we cannot access it.
            //

            EnableStatusSpecified = FALSE;

        } else {
        
            EnableStatusSpecified = TRUE;
        }

        //
        // Get per scenario parameters.
        //

        for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {

            ValueNamePrefix = PrefetcherParameters->ScenarioTypePrefixes[ScenarioType];

            //
            // Determine enable status. If EnableStatusSpecified, whether
            // prefeching for this scenario type is on or off is
            // determined by the ScenarioType'th bit in EnablePrefetcher.
            //
        
            if (EnableStatusSpecified) {
                if (EnablePrefetcher & (1 << ScenarioType)) {
                    Parameters.EnableStatus[ScenarioType] = PfSvEnabled;
                } else {
                    Parameters.EnableStatus[ScenarioType] = PfSvDisabled;
                }
            } else {
                Parameters.EnableStatus[ScenarioType] = PfSvNotSpecified;
            }

            //
            // Update trace limits for this scenario type. Ignore return
            // value from GetParameter since the value may not be
            // specified in the registry. If so the current value is kept
            // intact.
            //

            TraceLimits = &Parameters.TraceLimits[ScenarioType];
            
            wcscpy(ValueName, ValueNamePrefix);       
            wcscat(ValueName, L"MaxNumPages");
            Length = sizeof(TraceLimits->MaxNumPages);
            CcPfGetParameter(ParametersKey,
                             ValueName,
                             REG_DWORD,
                             &TraceLimits->MaxNumPages,
                             &Length);

            wcscpy(ValueName, ValueNamePrefix);       
            wcscat(ValueName, L"MaxNumSections");
            Length = sizeof(TraceLimits->MaxNumSections);
            CcPfGetParameter(ParametersKey,
                             ValueName,
                             REG_DWORD,
                             &TraceLimits->MaxNumSections,
                             &Length);

            wcscpy(ValueName, ValueNamePrefix);       
            wcscat(ValueName, L"TimerPeriod");
            Length = sizeof(TraceLimits->TimerPeriod);
            CcPfGetParameter(ParametersKey,
                             ValueName,
                             REG_BINARY,
                             &TraceLimits->TimerPeriod,
                             &Length);
        }

        //
        // Update maximum number of active traces. 
        //

        Length = sizeof(Parameters.MaxNumActiveTraces);
        CcPfGetParameter(ParametersKey,
                         L"MaxNumActiveTraces",
                         REG_DWORD,
                         &Parameters.MaxNumActiveTraces,
                         &Length);
    
        //
        // Update maximum number of saved traces. 
        //

        Length = sizeof(Parameters.MaxNumSavedTraces);
        CcPfGetParameter(ParametersKey,
                         L"MaxNumSavedTraces",
                         REG_DWORD,
                         &Parameters.MaxNumSavedTraces,
                         &Length);
    
        //
        // Update the root directory path.
        //
    
        Length = sizeof(Parameters.RootDirPath);
        CcPfGetParameter(ParametersKey,
                         L"RootDirPath",
                         REG_SZ,
                         Parameters.RootDirPath,
                         &Length);

        Parameters.RootDirPath[PF_MAX_PREFETCH_ROOT_PATH - 1] = 0;

        //
        // Update list of known hosting applications.
        //

        Length = sizeof(Parameters.HostingApplicationList);
        CcPfGetParameter(ParametersKey,
                         L"HostingAppList",
                         REG_SZ,
                         Parameters.HostingApplicationList,
                         &Length);
        
        Parameters.HostingApplicationList[PF_HOSTING_APP_LIST_MAX_CHARS - 1] = 0;
        _wcsupr(Parameters.HostingApplicationList);
         
        //
        // Verify the parameters updated from the registry.
        //

        Status = CcPfParametersVerify(&Parameters);
    
        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }
        
        //
        // Release the shared lock and acquire it exclusive.
        //

        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);

        KeEnterCriticalRegionThread(CurrentThread);
        ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);
        
        //
        // Check if somebody already updated the parameters before us.
        //
        
        if (CurrentVersion != PrefetcherParameters->ParametersVersion) {

            //
            // Bummer. Somebody updated parameters when we released
            // our shared lock to acquire it exclusive. We have to try
            // again. The default values we used for parameters that
            // were not in the registry may have been changed.
            //

            ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
            KeLeaveCriticalRegionThread(CurrentThread);
            AcquiredParametersLock = FALSE;

            RetryCount++;
            continue;
        }
        
        //
        // We are updating the parameters, bump the version.
        //

        PrefetcherParameters->ParametersVersion++;
        
        PrefetcherParameters->Parameters = Parameters;

        //
        // Release the exclusive lock and break out.
        //
        
        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
        AcquiredParametersLock = FALSE;
        
        break;

    } while (RetryCount < 10);

    //
    // See if we looped too many times and could not achive updating
    // the parameters.
    //

    if (RetryCount >= 10) {
        Status = STATUS_RETRY;
        goto cleanup;
    }

    //
    // Otherwise we were successful.
    //

    Status = STATUS_SUCCESS;

 cleanup:

    if (AcquiredParametersLock) {
        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
    }

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersRead()=%x\n", Status));

    return Status;
}

NTSTATUS
CcPfParametersSave (
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    This routine updates the registry with the specified prefetch
    parameters.

Arguments:

    PrefetcherParameters - Pointer to parameters structure.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    PPF_TRACE_LIMITS TraceLimits;
    PF_SCENARIO_TYPE ScenarioType;
    WCHAR ValueName[CCPF_MAX_PARAMETER_NAME_LENGTH];
    WCHAR *ValueNamePrefix;
    HANDLE ParametersKey;
    BOOLEAN EnableStatusSpecified;
    ULONG EnablePrefetcher;
    BOOLEAN AcquiredParametersLock;
    ULONG Length;
    PPF_SYSTEM_PREFETCH_PARAMETERS Parameters;
    PKTHREAD CurrentThread;

    //
    // Initialize locals.
    //

    CurrentThread = KeGetCurrentThread ();
    Parameters = &PrefetcherParameters->Parameters;
    AcquiredParametersLock = FALSE;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersSave()\n"));

    //
    // Get the parameters lock shared. 
    // 
    
    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceSharedLite(&PrefetcherParameters->ParametersLock, TRUE);
    AcquiredParametersLock = TRUE;

    //
    // If we could not initialize the parameters key, we would fail
    // all the following ops miserably.
    //

    if (!PrefetcherParameters->ParametersKey) {
        Status = STATUS_REINITIALIZATION_NEEDED;
        goto cleanup;
    }

    ParametersKey = PrefetcherParameters->ParametersKey;

    //
    // Build up the prefetcher enable value.
    //
    
    EnableStatusSpecified = FALSE;
    EnablePrefetcher = 0;

    for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {

        //
        // By default prefetching for all scenario types will be
        // disabled, except it is explicitly enabled.
        //

        if (Parameters->EnableStatus[ScenarioType] == PfSvEnabled) {
            EnablePrefetcher |= (1 << ScenarioType);
        }       
        
        //
        // Even if enable status for one scenario type is specified,
        // we have to save the enable prefetcher key. 
        //

        if (Parameters->EnableStatus[ScenarioType] != PfSvNotSpecified) {
            EnableStatusSpecified = TRUE;
        }
    }

    if (EnableStatusSpecified) {

        //
        // Save the prefetcher enable key.
        //

        Length = sizeof(EnablePrefetcher);

        Status = CcPfSetParameter(ParametersKey,
                                  L"EnablePrefetcher",
                                  REG_DWORD,
                                  &EnablePrefetcher,
                                  Length);

        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }
    }

    //
    // Save per scenario parameters.
    //

    for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {
        
        ValueNamePrefix = PrefetcherParameters->ScenarioTypePrefixes[ScenarioType];
        
        //
        // Update trace limits for this scenario type.
        //

        TraceLimits = &Parameters->TraceLimits[ScenarioType];
        
        wcscpy(ValueName, ValueNamePrefix);       
        wcscat(ValueName, L"MaxNumPages");
        Length = sizeof(TraceLimits->MaxNumPages);
        Status = CcPfSetParameter(ParametersKey,
                                  ValueName,
                                  REG_DWORD,
                                  &TraceLimits->MaxNumPages,
                                  Length);
        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }
        
        wcscpy(ValueName, ValueNamePrefix);       
        wcscat(ValueName, L"MaxNumSections");
        Length = sizeof(TraceLimits->MaxNumSections);
        Status = CcPfSetParameter(ParametersKey,
                         ValueName,
                         REG_DWORD,
                         &TraceLimits->MaxNumSections,
                         Length);
        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }

        wcscpy(ValueName, ValueNamePrefix);       
        wcscat(ValueName, L"TimerPeriod");
        Length = sizeof(TraceLimits->TimerPeriod);
        Status = CcPfSetParameter(ParametersKey,
                                  ValueName,
                                  REG_BINARY,
                                  &TraceLimits->TimerPeriod,
                                  Length);
        if (!NT_SUCCESS(Status)) {
            goto cleanup;
        }
    }
    
    //
    // Update maximum number of active traces. 
    //
    
    Length = sizeof(Parameters->MaxNumActiveTraces);
    Status = CcPfSetParameter(ParametersKey,
                              L"MaxNumActiveTraces",
                              REG_DWORD,
                              &Parameters->MaxNumActiveTraces,
                              Length);
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }
    
    //
    // Update maximum number of saved traces. 
    //

    Length = sizeof(Parameters->MaxNumSavedTraces);
    Status = CcPfSetParameter(ParametersKey,
                              L"MaxNumSavedTraces",
                              REG_DWORD,
                              &Parameters->MaxNumSavedTraces,
                              Length);
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Update the root directory path.
    //
    
    Length = (wcslen(Parameters->RootDirPath) + 1) * sizeof(WCHAR);
    Status = CcPfSetParameter(ParametersKey,
                              L"RootDirPath",
                              REG_SZ,
                              Parameters->RootDirPath,
                              Length);
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Update the hosting application list path.
    //
    
    Length = (wcslen(Parameters->HostingApplicationList) + 1) * sizeof(WCHAR);
    Status = CcPfSetParameter(ParametersKey,
                              L"HostingAppList",
                              REG_SZ,
                              Parameters->HostingApplicationList,
                              Length);
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    Status = STATUS_SUCCESS;

 cleanup:

    if (AcquiredParametersLock) {
        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
    }
    
    DBGPR((CCPFID,PFTRC,"CCPF: ParametersSave()=%x\n", Status));

    return Status;
}

NTSTATUS
CcPfParametersVerify (
    PPF_SYSTEM_PREFETCH_PARAMETERS Parameters
    )

/*++

Routine Description:

    This routine verifies that the specified parameters structure is
    valid and within sanity limits.

Arguments:

    Parameters - Pointer to parameters structure.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    ULONG FailedCheckId;
    ULONG CharIdx;
    BOOLEAN FoundNUL;
    PF_SCENARIO_TYPE ScenarioType;
    PPF_TRACE_LIMITS TraceLimits;

    //
    // Initialize locals.
    //

    Status = STATUS_INVALID_PARAMETER;
    FailedCheckId = 0;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersVerify\n"));

    //
    // Make sure RootDirPath is NUL terminated.
    //
    
    FoundNUL = FALSE;

    for (CharIdx = 0; CharIdx < PF_MAX_PREFETCH_ROOT_PATH; CharIdx++) {
        if (Parameters->RootDirPath[CharIdx] == 0) {
            FoundNUL = TRUE;
            break;
        }
    }

    if (FoundNUL == FALSE) {
        FailedCheckId = 10;
        goto cleanup;
    }

    //
    // Make sure HostingApplicationList is NUL terminated.
    //

    FoundNUL = FALSE;

    for (CharIdx = 0; CharIdx < PF_HOSTING_APP_LIST_MAX_CHARS; CharIdx++) {
        if (Parameters->HostingApplicationList[CharIdx] == 0) {
            FoundNUL = TRUE;
            break;
        }

        //
        // Make sure the list is upper case.
        //

        if (towupper(Parameters->HostingApplicationList[CharIdx]) !=
            Parameters->HostingApplicationList[CharIdx]) {

            FailedCheckId = 13;
            goto cleanup;
        }
    }

    if (FoundNUL == FALSE) {
        FailedCheckId = 15;
        goto cleanup;
    }

    //
    // Make sure all per scenario type parameters types are within
    // sanity limits.
    //

    for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {

        if (Parameters->EnableStatus[ScenarioType] < 0 ||
            Parameters->EnableStatus[ScenarioType] >= PfSvMaxEnableStatus) {
            FailedCheckId = 20;
            goto cleanup;
        }

        //
        // Check trace limits.
        //
        
        TraceLimits = &Parameters->TraceLimits[ScenarioType];
        
        if (TraceLimits->MaxNumPages > PF_MAXIMUM_PAGES) {
            FailedCheckId = 30;
            goto cleanup;
        }
        
        if (TraceLimits->MaxNumSections > PF_MAXIMUM_SECTIONS) {
            FailedCheckId = 40;
            goto cleanup;
        }

        if ((TraceLimits->TimerPeriod < PF_MAXIMUM_TIMER_PERIOD) ||
            (TraceLimits->TimerPeriod >= 0)) {
            FailedCheckId = 50;
            goto cleanup;
        }
    }

    //
    // Check limits on active/saved traces.
    //

    if (Parameters->MaxNumActiveTraces > PF_MAXIMUM_ACTIVE_TRACES) {
        FailedCheckId = 60;
        goto cleanup;
    }

    if (Parameters->MaxNumSavedTraces > PF_MAXIMUM_SAVED_TRACES) {
        FailedCheckId = 70;
        goto cleanup;
    }

    //
    // We passed all the checks.
    //

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersVerify()=%x,%d\n", Status, FailedCheckId));

    return Status;
}

VOID
CcPfParametersWatcher(
    IN PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    This routine gets called when our parameters in the registry change.

Arguments:

    PrefetcherParameters - Pointer to parameters structure.

Return Value:

    None.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    UNICODE_STRING KeyName;
    OBJECT_ATTRIBUTES ObjectAttributes;
    HANDLE ParametersKey;
    PKTHREAD CurrentThread;
    HANDLE TempHandle;
    BOOLEAN HoldingParametersLock;

    //
    // Initialize locals.
    //

    HoldingParametersLock = FALSE;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersWatcher()\n"));
    
    //
    // Our change notify triggered. Request further notification. But
    // first wait until we can get the parameters lock exclusive, so
    // while we are saving parameters to the registry we don't kick
    // off a notification for each key.
    //

    CurrentThread = KeGetCurrentThread ();
    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);
    ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
    KeLeaveCriticalRegionThread(CurrentThread);

    //
    // Hold the parameters lock shared since we are using ParametersKey.
    //

    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceSharedLite(&PrefetcherParameters->ParametersLock, TRUE);
    HoldingParametersLock = TRUE;

    //
    // Make sure we still have a parameters key.
    //

    if (!PrefetcherParameters->ParametersKey) {

        //
        // In order to have setup a registry watch, we should have
        // initialized the parameters key successfully.
        //

        CCPF_ASSERT(PrefetcherParameters->ParametersKey);
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }

    Status = ZwNotifyChangeKey(PrefetcherParameters->ParametersKey,
                               NULL,
                               (PIO_APC_ROUTINE)&PrefetcherParameters->RegistryWatchWorkItem,
                               (PVOID)(UINT_PTR)(unsigned int)DelayedWorkQueue,
                               &PrefetcherParameters->RegistryWatchIosb,
                               REG_LEGAL_CHANGE_FILTER,
                               FALSE,
                               &PrefetcherParameters->RegistryWatchBuffer,
                               sizeof(PrefetcherParameters->RegistryWatchBuffer),
                               TRUE);

    if (!NT_SUCCESS(Status)) {

        //
        // Somebody may have deleted the key. We have to recreate it then.
        //

        if (Status == STATUS_KEY_DELETED) {

            RtlInitUnicodeString(&KeyName, CCPF_PARAMETERS_KEY);
            
            InitializeObjectAttributes(&ObjectAttributes,
                                       &KeyName,
                                       OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                                       NULL,
                                       NULL);
           
            Status = ZwCreateKey(&ParametersKey,
                                 KEY_ALL_ACCESS,
                                 &ObjectAttributes,
                                 0,
                                 NULL,
                                 REG_OPTION_NON_VOLATILE,
                                 0);

            if (!NT_SUCCESS(Status)) {
                DBGPR((CCPFID,PFERR,"CCPF: ParametersWatcher-FailedRecreate=%x\n",Status));
                goto cleanup;
            }

            //
            // Update global key handle. To do this release the shared lock
            // and get it exclusive.
            //

            CCPF_ASSERT(HoldingParametersLock);
            ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);                       
            ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);

            TempHandle = PrefetcherParameters->ParametersKey;
            PrefetcherParameters->ParametersKey = ParametersKey;
            
            ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
            ExAcquireResourceSharedLite(&PrefetcherParameters->ParametersLock, TRUE);

            //
            // Close the old handle.
            //

            if (TempHandle) {
                ZwClose(TempHandle);
            }

            //
            // Did someone steal the parameters key from beneath us?
            //

            if (!PrefetcherParameters->ParametersKey) {
                Status = STATUS_UNSUCCESSFUL;
                goto cleanup;
            }

            //
            // Retry setting a notification again.
            //

            Status = ZwNotifyChangeKey(PrefetcherParameters->ParametersKey,
                                       NULL,
                                       (PIO_APC_ROUTINE)&PrefetcherParameters->RegistryWatchWorkItem,
                                       (PVOID)(UINT_PTR)(unsigned int)DelayedWorkQueue,
                                       &PrefetcherParameters->RegistryWatchIosb,
                                       REG_LEGAL_CHANGE_FILTER,
                                       FALSE,
                                       &PrefetcherParameters->RegistryWatchBuffer,
                                       sizeof(PrefetcherParameters->RegistryWatchBuffer),
                                       TRUE);

            if (!NT_SUCCESS(Status)) {
                DBGPR((CCPFID,PFERR,"CCPF: ParametersWatcher-FailedReSetNotify=%x\n",Status));
                goto cleanup;
            }
            
        } else {
            DBGPR((CCPFID,PFERR,"CCPF: ParametersWatcher-FailedSetNotify=%x\n",Status));
            goto cleanup;
        }
    }

    //
    // Release the parameters lock as we'll need it when re-reading the 
    // parameters.
    //

    if (HoldingParametersLock) {
        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
        HoldingParametersLock = FALSE;
    }

    //
    // Update the global parameters.
    //

    Status = CcPfParametersRead(PrefetcherParameters);

    if (NT_SUCCESS(Status)) {

        //
        // Determine if prefetching is enabled.
        //
        
        CcPfDetermineEnablePrefetcher();
        
        //
        // Set the event so the service queries for the latest parameters.
        //
        
        CcPfParametersSetChangedEvent(PrefetcherParameters);
    }

  cleanup:

    if (HoldingParametersLock) {
        ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
        KeLeaveCriticalRegionThread(CurrentThread);
        HoldingParametersLock = FALSE;
    }

    return;
}

NTSTATUS
CcPfParametersSetChangedEvent(
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters
    )

/*++

Routine Description:

    This routine tries to open and set the event that tells the
    service system prefetch parameters have changed.

Arguments:

    None.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    NTSTATUS Status;
    UNICODE_STRING EventName;
    OBJECT_ATTRIBUTES EventObjAttr;
    HANDLE EventHandle;
    PKTHREAD CurrentThread;

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersSetChangedEvent()\n"));

    //
    // If we have already opened the event, just signal it.
    //

    if (PrefetcherParameters->ParametersChangedEvent) {

        ZwSetEvent(PrefetcherParameters->ParametersChangedEvent, NULL);

        Status = STATUS_SUCCESS;

    } else {

        //
        // Try to open the event. We don't open this at initialization
        // because our service may not have started to create this
        // event yet. If csrss.exe has not initialized, we may not
        // even have the BaseNamedObjects object directory created, in
        // which Win32 events reside.
        //

        RtlInitUnicodeString(&EventName, PF_PARAMETERS_CHANGED_EVENT_NAME);

        InitializeObjectAttributes(&EventObjAttr,
                                   &EventName,
                                   OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                                   NULL,
                                   NULL);
        
        Status = ZwOpenEvent(&EventHandle,
                             EVENT_ALL_ACCESS,
                             &EventObjAttr);
        
        if (NT_SUCCESS(Status)) {

            //
            // Acquire the lock and set the global handle.
            //
            CurrentThread = KeGetCurrentThread ();

            KeEnterCriticalRegionThread(CurrentThread);
            ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);

            if (!PrefetcherParameters->ParametersChangedEvent) {

                //
                // Set the global handle.
                //

                PrefetcherParameters->ParametersChangedEvent = EventHandle;
                CCPF_ASSERT(EventHandle);

                EventHandle = NULL;
            }

            ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
            KeLeaveCriticalRegionThread(CurrentThread);

            if (EventHandle != NULL) {
                //
                // Somebody already initialized the global handle
                // before us. Close our handle and use the one they
                // initialized.
                //

                ZwClose(EventHandle);
            }

            
            //
            // We have an event now. Signal it.
            //
            
            ZwSetEvent(PrefetcherParameters->ParametersChangedEvent, NULL);
        }
    }

    DBGPR((CCPFID,PFTRC,"CCPF: ParametersSetChangedEvent()=%x\n", Status));
 
    return Status;
}
                 
NTSTATUS
CcPfGetParameter (
    HANDLE ParametersKey,
    WCHAR *ValueNameBuffer,
    ULONG ValueType,
    PVOID Value,
    ULONG *ValueSize
    )

/*++

Routine Description:

    This routine queries a value under the specified registry into the
    specified buffer. Contents of Value and ValueSize are not changed
    if returning failure.

Arguments:

    ParametersKey - Handle to key to query value under.

    ValueNameBuffer - Name of the value.
    
    ValueType - What the type of that value should be. (e.g. REG_DWORD).

    Value - Queried value data gets put here.

    ValueSize - Size of Value buffer in bytes. On successful return
      this is set to number of bytes copied into Value.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    UNICODE_STRING ValueName;    
    CHAR Buffer[CCPF_MAX_PARAMETER_VALUE_BUFFER];
    PKEY_VALUE_PARTIAL_INFORMATION ValueBuffer;
    ULONG Length;
    NTSTATUS Status;

    //
    // Initialize locals.
    //

    ValueBuffer = (PKEY_VALUE_PARTIAL_INFORMATION) Buffer;
    Length = CCPF_MAX_PARAMETER_VALUE_BUFFER;
    RtlInitUnicodeString(&ValueName, ValueNameBuffer);

    DBGPR((CCPFID,PFTRC,"CCPF: GetParameter(%ws,%x)\n", ValueNameBuffer, ValueType));

    //
    // Verify parameters.
    //

    if (!ParametersKey) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Query value.
    //

    Status = ZwQueryValueKey(ParametersKey,
                             &ValueName,
                             KeyValuePartialInformation,
                             ValueBuffer,
                             Length,
                             &Length);
    
    if (!NT_SUCCESS(Status)) {
        goto cleanup;
    }

    //
    // Make sure ZwQueryValue returns valid information.
    //
    
    if (Length < sizeof(KEY_VALUE_PARTIAL_INFORMATION)) {
        CCPF_ASSERT(Length >= sizeof(KEY_VALUE_PARTIAL_INFORMATION));
        Status = STATUS_UNSUCCESSFUL;
        goto cleanup;
    }
    
    //
    // Check value type.
    //

    if (ValueBuffer->Type != ValueType) {
        Status = STATUS_OBJECT_TYPE_MISMATCH;
        goto cleanup;
    }

    //
    // Check if data will fit into the buffer caller passed in.
    //

    if (ValueBuffer->DataLength > *ValueSize) {
        Status = STATUS_BUFFER_TOO_SMALL;
        goto cleanup;
    }

    //
    // Copy data into user's buffer.
    //

    RtlCopyMemory(Value, ValueBuffer->Data, ValueBuffer->DataLength);

    //
    // Set copied number of bytes.
    //

    *ValueSize = ValueBuffer->DataLength;

    Status = STATUS_SUCCESS;

 cleanup:

    DBGPR((CCPFID,PFTRC,"CCPF: GetParameter(%ws)=%x\n", ValueNameBuffer, Status));

    return Status;
}  
                 
NTSTATUS
CcPfSetParameter (
    HANDLE ParametersKey,
    WCHAR *ValueNameBuffer,
    ULONG ValueType,
    PVOID Value,
    ULONG ValueSize
    )

/*++

Routine Description:

    This routine sets a parameter under the specified registry.

Arguments:

    ParametersKey - Handle to key to query value under.

    ValueNameBuffer - Name of the value.
    
    ValueType - What the type of that value should be. (e.g. REG_DWORD).

    Value - Data to save.

    ValueSize - Size of Value buffer in bytes.

Return Value:

    Status.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    UNICODE_STRING ValueName;    
    NTSTATUS Status;

    //
    // Initialize locals.
    //

    RtlInitUnicodeString(&ValueName, ValueNameBuffer);

    DBGPR((CCPFID,PFTRC,"CCPF: SetParameter(%ws,%x)\n", ValueNameBuffer, ValueType));

    //
    // Verify parameters.
    //

    if (!ParametersKey) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Save the value.
    //

    Status = ZwSetValueKey(ParametersKey,
                           &ValueName,
                           0,
                           ValueType,
                           Value,
                           ValueSize);
    
    //
    // Return the status.
    //

    DBGPR((CCPFID,PFTRC,"CCPF: SetParameter(%ws)=%x\n", ValueNameBuffer, Status));

    return Status;
}  

LOGICAL
CcPfDetermineEnablePrefetcher(
    VOID
    )

/*++

Routine Description:

    This routine sets the global CcPfEnablePrefetcher based on the
    EnableStatus'es for all scenario types in global parameters as
    well as other factors, such as whether we have booted safe mode.

    Note: Acquires Parameters lock exclusive.

Arguments:

    None.

Return Value:

    New value of CcPfEnablePrefetcher.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PF_SCENARIO_TYPE ScenarioType;
    LOGICAL EnablePrefetcher;
    PKTHREAD CurrentThread;
    BOOLEAN IgnoreBootScenarioType;
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters;

    extern PF_BOOT_PHASE_ID CcPfBootPhase;

    //
    // Initialize locals.
    //

    EnablePrefetcher = FALSE;
    PrefetcherParameters = &CcPfGlobals.Parameters;
    CurrentThread = KeGetCurrentThread ();

    //
    // Ignore whether prefetching is enabled for boot, if we've
    // already past the point in boot where this matters.
    //
    
    IgnoreBootScenarioType = (CcPfBootPhase >= PfSessionManagerInitPhase) ? TRUE : FALSE;

    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceExclusiveLite(&PrefetcherParameters->ParametersLock, TRUE);

    //
    // If we have booted to safe mode, the prefetcher will be disabled.
    //

    if (InitSafeBootMode) {

        EnablePrefetcher = FALSE;

    } else {
        
        //
        // By default prefetching is disabled. If prefetching is
        // enabled for any scenario type, then the prefetcher is
        // enabled.
        //
    
        for (ScenarioType = 0; ScenarioType < PfMaxScenarioType; ScenarioType++) {
            
            //
            // Skip enable status for the boot scenario if requested.
            //
            
            if (IgnoreBootScenarioType) {
                if (ScenarioType == PfSystemBootScenarioType) {
                    continue;
                }
            }
            
            if (PrefetcherParameters->Parameters.EnableStatus[ScenarioType] == PfSvEnabled) {
                EnablePrefetcher = TRUE;
                break;
            }
        }
    }

    //
    // Update global enable status.
    //

    CcPfEnablePrefetcher = EnablePrefetcher;

    ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
    KeLeaveCriticalRegionThread(CurrentThread);

    return CcPfEnablePrefetcher;
}

BOOLEAN
CcPfIsHostingApplication(
    IN PWCHAR ExecutableName
    )

/*++

Routine Description:

    This routine determines whether the specified executable is in the
    list of known hosting applications, e.g. rundll32, dllhost etc.

Arguments:

    ExecutableName - NUL terminated UPCASED executable name, e.g. "MMC.EXE"

Return Value:

    TRUE - Executable is for a known hosting application.

    FALSE - It is not.

Environment:

    Kernel mode. IRQL == PASSIVE_LEVEL.

--*/

{
    PCCPF_PREFETCHER_PARAMETERS PrefetcherParameters;
    PKTHREAD CurrentThread;
    PWCHAR CurrentPosition;
    PWCHAR ListStart;
    PWCHAR ListEnd;
    ULONG ExecutableNameLength;
    BOOLEAN FoundInList;
    
    //
    // Initialize locals.
    //

    PrefetcherParameters = &CcPfGlobals.Parameters;
    CurrentThread = KeGetCurrentThread();
    ExecutableNameLength = wcslen(ExecutableName);
    FoundInList = FALSE;

    //
    // Get the parameters lock for read.
    //

    KeEnterCriticalRegionThread(CurrentThread);
    ExAcquireResourceSharedLite(&PrefetcherParameters->ParametersLock, TRUE);

    //
    // Search for executable in hosting application list.
    //

    ListStart = PrefetcherParameters->Parameters.HostingApplicationList;
    ListEnd = ListStart + wcslen(PrefetcherParameters->Parameters.HostingApplicationList);

    for (CurrentPosition = wcsstr(ListStart, ExecutableName);
         CurrentPosition != NULL;
         CurrentPosition = wcsstr(CurrentPosition + 1, ExecutableName)) {

        //
        // We should not go beyond the limits.
        //

        if (CurrentPosition < ListStart || CurrentPosition >= ListEnd) {
            CCPF_ASSERT(CurrentPosition >= ListStart);
            CCPF_ASSERT(CurrentPosition < ListEnd);
            break;
        }

        //
        // It should be the first item in the list or be preceded by a comma.
        //

        if (CurrentPosition != ListStart && *(CurrentPosition - 1) != L',') {
            continue;
        }

        //
        // It should be the last item in the list or be followed by a comma.
        //

        if (CurrentPosition + ExecutableNameLength != ListEnd &&
            CurrentPosition[ExecutableNameLength] != L',') {
            continue;
        }

        //
        // We found it in the list.
        //

        FoundInList = TRUE;
        break;

    }

    //
    // Release the parameters lock.
    //

    ExReleaseResourceLite(&PrefetcherParameters->ParametersLock);
    KeLeaveCriticalRegionThread(CurrentThread);

    //
    // Return whether the executable was found in the list.
    //

    return FoundInList;    
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmapi2.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmapi2.c

Abstract:

    This module contains CM level entry points for the registry,
    particularly those which we don't want to link into tools,
    setup, the boot loader, etc.

Author:

    Bryan M. Willman (bryanwi) 26-Jan-1993

Revision History:

--*/

#include "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmDeleteKey)
#endif


NTSTATUS
CmDeleteKey(
    IN PCM_KEY_BODY KeyBody
    )
/*++

Routine Description:

    Delete a registry key, clean up Notify block.

Arguments:

    KeyBody - pointer to key handle object

Return Value:

    NTSTATUS

--*/
{
    NTSTATUS                status;
    PCM_KEY_NODE            ptarget;
    PHHIVE                  Hive;
    HCELL_INDEX             Cell;
    HCELL_INDEX             Parent;
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock;
    LARGE_INTEGER           TimeStamp;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmDeleteKey\n"));

    CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    //
    // If already marked for deletion, storage is gone, so
    // do nothing and return success.
    //
    KeyControlBlock = KeyBody->KeyControlBlock;

    PERFINFO_REG_DELETE_KEY(KeyControlBlock);

    if (KeyControlBlock->Delete == TRUE) {
        status = STATUS_SUCCESS;
        goto Exit;
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    ptarget = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
    if( ptarget == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        status = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit;
    }

    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);

    ASSERT( ptarget->Flags == KeyControlBlock->Flags );

    if ( ((ptarget->SubKeyCounts[Stable] + ptarget->SubKeyCounts[Volatile]) == 0) &&
         ((ptarget->Flags & KEY_NO_DELETE) == 0))
    {
        //
        // Cell is NOT marked NO_DELETE and does NOT have children
        // Send Notification while key still present, if delete fails,
        //   we'll have sent a spurious notify, that doesn't matter
        // Delete the actual storage
        //
        Hive = KeyControlBlock->KeyHive;
        Cell = KeyControlBlock->KeyCell;
        Parent = ptarget->Parent;

        CmpReportNotify(
            KeyControlBlock,
            Hive,
            Cell,
            REG_NOTIFY_CHANGE_NAME
            );

        status = CmpFreeKeyByCell(Hive, Cell, TRUE);

        if (NT_SUCCESS(status)) {
            //
            // post any waiting notifies
            //
            CmpFlushNotifiesOnKeyBodyList(KeyControlBlock);

            //
            // Remove kcb out of cache, but do NOT
            // free its storage, CmDelete will do that when
            // the RefCount becomes zero.
            //
            // There are two things that can hold the RefCount non-zero.
            //
            // 1. open handles for this key
            // 2. Fake subKeys that are still in DelayClose.
            //
            // At this point, we have no way of deleting the fake subkeys from cache
            // unless we do a search for the whole cache, which is too expensive.
            // Thus, we decide to either let the fake keys age out of cache or when 
            // someone is doing the lookup for the fake key, then we delete it at that point.
            // See routine CmpCacheLookup in cmparse.c for more details.
            //
            // If the parent has the subkey info or hint cached, free it.
            // Again, registry is locked exclusively, no need to lock KCB.
            //
            ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
            CmpCleanUpSubKeyInfo(KeyControlBlock->ParentKcb);
            ptarget = (PCM_KEY_NODE)HvGetCell(Hive, Parent);
            if( ptarget != NULL ) {
                // release the cell right here, as the registry is locked exclusively, so we don't care
                HvReleaseCell(Hive, Parent);

                //
                // this should always be true as CmpFreeKeyByCell always marks the parent dirty on success
                //
                KeyControlBlock->ParentKcb->KcbMaxNameLen = (USHORT)ptarget->MaxNameLen;
                // sanity
                ASSERT_CELL_DIRTY(Hive,Parent);
                //
                // update the LastWriteTime on parent and kcb too
                //
                KeQuerySystemTime(&TimeStamp);
                ptarget->LastWriteTime = TimeStamp;
                KeyBody->KeyControlBlock->ParentKcb->KcbLastWriteTime = TimeStamp;

            }

            KeyControlBlock->Delete = TRUE;
            CmpRemoveKeyControlBlock(KeyControlBlock);
            KeyControlBlock->KeyCell = HCELL_NIL;
        }

    } else {

        status = STATUS_CANNOT_DELETE;

    }

Exit:

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    CmpUnlockRegistry();

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    return status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmchek.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmchek.c

Abstract:

    This module implements consistency checking for the registry.
    This module can be linked standalone, cmchek2.c cannot.

Author:

    Bryan M. Willman (bryanwi) 27-Jan-92

Environment:


Revision History:

--*/

#include    "cmp.h"

#define     REG_MAX_PLAUSIBLE_KEY_SIZE \
                ((FIELD_OFFSET(CM_KEY_NODE, Name)) + \
                 (sizeof(WCHAR) * REG_MAX_KEY_NAME_LENGTH) + 16)

extern PCMHIVE CmpMasterHive;

//
// Private prototypes
//

ULONG
CmpCheckRegistry2(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    );

ULONG
CmpCheckKey(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    );

ULONG
CmpCheckValueList(
    PHHIVE      Hive,
    PCELL_DATA  List,
    ULONG       Count,
    HCELL_INDEX KeyCell
    );

BOOLEAN
CmpCheckLexicographicalOrder (  IN PHHIVE       HiveToCheck,
                                IN HCELL_INDEX  PriorSibling,
                                IN HCELL_INDEX  Current 
                                );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmCheckRegistry)
#pragma alloc_text(PAGE,CmpCheckRegistry2)
#pragma alloc_text(PAGE,CmpCheckKey)
#pragma alloc_text(PAGE,CmpCheckValueList)
#pragma alloc_text(PAGE,CmpCheckLexicographicalOrder)

#ifdef CHECK_REGISTRY_USECOUNT
#pragma alloc_text(PAGE,CmpCheckRegistryUseCount)
#endif

#endif

//
// debug structures
//

extern struct {
    PHHIVE      Hive;
    ULONG       Status;
} CmCheckRegistryDebug;

extern struct {
    PHHIVE      Hive;
    ULONG       Status;
} CmpCheckRegistry2Debug;

extern struct {
    PHHIVE      Hive;
    ULONG       Status;
    HCELL_INDEX Cell;
    PCELL_DATA  CellPoint;
    PVOID       RootPoint;
    ULONG       Index;
} CmpCheckKeyDebug;

extern struct {
    PHHIVE      Hive;
    ULONG       Status;
    PCELL_DATA  List;
    ULONG       Index;
    HCELL_INDEX Cell;
    PCELL_DATA  CellPoint;
} CmpCheckValueListDebug;


ULONG
CmCheckRegistry(
    PCMHIVE CmHive,
    ULONG   Flags
    )
/*++

Routine Description:

    Check consistency of the registry within a given hive.  Start from
    root, and check that:
        .   Each child key points back to its parent.
        .   All allocated cells are refered to exactly once
            (requires looking inside the hive structure...)
            [This also detects space leaks.]
        .   All allocated cells are reachable from the root.

    NOTE:   Exactly 1 ref rule may change with security.

Arguments:

    CmHive - supplies a pointer to the CM hive control structure for the
            hive of interest.

    Clean   - if TRUE, references to volatile cells will be zapped
              (done at startup only to avoid groveling hives twice.)
              if FALSE, nothing will be changed.
    
    HiveCheck - If TRUE, performs hive consistency check too (i.e. checks
                the bins)

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  3000 - 3999

--*/
{
    PHHIVE                  Hive;
    ULONG                   rc = 0;
    ULONG                   Storage;
    PRELEASE_CELL_ROUTINE   ReleaseCellRoutine;
    BOOLEAN                 ResetSD = FALSE;

    if (CmHive == CmpMasterHive) {
        return(0);
    }

    CmCheckRegistryDebug.Hive = (PHHIVE)CmHive;
    CmCheckRegistryDebug.Status = 0;


    //
    // check the underlying hive and get storage use
    //
    Hive = &CmHive->Hive;

    if( Flags & CM_CHECK_REGISTRY_HIVE_CHECK ) {
        rc = HvCheckHive(Hive, &Storage);
        if (rc != 0) {
            CmCheckRegistryDebug.Status = rc;
            return rc;
        }
    }

    //
    // Store the release cell procedure so we can restore at the end;
    // Set it to NULL so we don't count : this saves us some pain during the check
    //
    ReleaseCellRoutine = Hive->ReleaseCellRoutine;
    Hive->ReleaseCellRoutine = NULL;

    //
    // Validate all the security descriptors in the hive
    //
    if (!CmpValidateHiveSecurityDescriptors(Hive,&ResetSD)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmCheckRegistry:"));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL," CmpValidateHiveSecurityDescriptors failed\n"));
        rc = 3040;
        CmCheckRegistryDebug.Status = rc;
        Hive->ReleaseCellRoutine = ReleaseCellRoutine;
        return rc;
    }

    rc = CmpCheckRegistry2((PHHIVE)CmHive,Flags,Hive->BaseBlock->RootCell, HCELL_NIL,ResetSD);

    //
    // Print a bit of a summary (make sure this data avail in all error cases)
    //
    if (rc > 0) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmCheckRegistry Failed (%d): CmHive:%p\n", rc, CmHive));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL," Hive:%p Root:%08lx\n", Hive, Hive->BaseBlock->RootCell));
    }

    //
    // restore the release cell routine
    // this saves us some pain during the check
    //
    Hive->ReleaseCellRoutine = ReleaseCellRoutine;

    return rc;
}

#ifndef _CM_LDR_

ULONG
CmpCheckRegistry2(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    )
/*++

Routine Description:

    Check consistency of the registry, from a particular cell on down.

        .   Check that the cell's value list, child key list, class,
            security are OK.
        .   Check that each value entry IN the list is OK.
        .   Apply self to each child key list.

    
    This version uses a stack in order to parse the tree "in-depth", 
    but not to touch any key_node.

Arguments:

    Cell - HCELL_INDEX of subkey to work on.

    ParentCell - expected value of parent cell for Cell, unless
                 HCELL_NIL, in which case ignore.

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  4000 - 4999

--*/
{
    PCMP_CHECK_REGISTRY_STACK_ENTRY     CheckStack;
    LONG                                StackIndex;
    PCM_KEY_NODE                        Node;
    ULONG                               rc = 0;
    HCELL_INDEX                         SubKey;


    CmpCheckRegistry2Debug.Hive = HiveToCheck;
    CmpCheckRegistry2Debug.Status = 0;
    
    ASSERT( HiveToCheck->ReleaseCellRoutine == NULL );

    //
    // Initialize the stack to simulate recursion here
    //

    CmRetryExAllocatePoolWithTag(PagedPool,sizeof(CMP_CHECK_REGISTRY_STACK_ENTRY)*CMP_MAX_REGISTRY_DEPTH,CM_POOL_TAG|PROTECTED_POOL,CheckStack);
    if (CheckStack == NULL) {
        CmpCheckRegistry2Debug.Status = 4099;
        return 4099;
    }

Restart:

    CheckStack[0].Cell = Cell;
    CheckStack[0].ParentCell = ParentCell;
    CheckStack[0].PriorSibling = HCELL_NIL;
    CheckStack[0].ChildIndex = 0;
    CheckStack[0].CellChecked = FALSE;
    StackIndex = 0;


    while(StackIndex >=0) {
        //
        // first check the current cell
        //
        if( CheckStack[StackIndex].CellChecked == FALSE ) {
            CheckStack[StackIndex].CellChecked = TRUE;

            rc = CmpCheckKey(HiveToCheck,CheckFlags,CheckStack[StackIndex].Cell, CheckStack[StackIndex].ParentCell,ResetSD);
            if (rc != 0) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tChild is list entry #%08lx\n", CheckStack[StackIndex].ChildIndex));
                CmpCheckRegistry2Debug.Status = rc;
YankKey:
                if( CmDoSelfHeal() && StackIndex ) { // root cell damage is fatal.
                    //
                    // delete this key from the parent's list and restart the whole iteration (not best performance, but safest).
                    //
                    if( !CmpRemoveSubKeyCellNoCellRef(HiveToCheck,CheckStack[StackIndex].ParentCell,CheckStack[StackIndex].Cell) ) {
                        //
                        // unable to delete subkey; punt.
                        //
                        break;
                    }
                    CmMarkSelfHeal(HiveToCheck);
                    rc = 0;
                    goto Restart;
                } else {
                    // bail out
                    break;
                }
            } else if( StackIndex > 0 ) {
                //
                // key is OK, check lexicographical order with PriorSibling
                //
                if( CheckStack[StackIndex-1].PriorSibling != HCELL_NIL ) {
                
                    ASSERT( CheckStack[StackIndex-1].Cell == CheckStack[StackIndex].ParentCell );
                    
                    if( !CmpCheckLexicographicalOrder(HiveToCheck,CheckStack[StackIndex-1].PriorSibling,CheckStack[StackIndex].Cell) ) {
                        //
                        // invalid order
                        //
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\t Invalid subkey ordering key #%08lx\n", CheckStack[StackIndex].Cell));
                        CmpCheckRegistry2Debug.Status = 4091;
                        rc = 4091;
                        // attempt to yank the key
                        goto YankKey;
                    }
                }   
                CheckStack[StackIndex-1].PriorSibling = CheckStack[StackIndex].Cell;
            }
        }

        Node = (PCM_KEY_NODE)HvGetCell(HiveToCheck, CheckStack[StackIndex].Cell);
        if( Node == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", CheckStack[StackIndex].Cell));
            CmpCheckRegistry2Debug.Status = 4098;
            rc = 4098;
            // bail out
            break;
        }

        if( CheckStack[StackIndex].ChildIndex < Node->SubKeyCounts[Stable] ) {
            //
            // we still have childs to check; add another entry for them and advance the 
            // StackIndex
            //
            SubKey = CmpFindSubKeyByNumber(HiveToCheck,
                                           Node,
                                           CheckStack[StackIndex].ChildIndex);
            if( SubKey == HCELL_NIL ) {
                //
                // we couldn't map cell;bail out
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", CheckStack[StackIndex].Cell));
                CmpCheckRegistry2Debug.Status = 4097;
                rc = 4097;
                break;
            }
            //
            // next iteration will check the next child
            //
            CheckStack[StackIndex].ChildIndex++;

            StackIndex++;
            if( StackIndex == CMP_MAX_REGISTRY_DEPTH ) {
                //
                // we've run out of stack; registry tree has too many levels
                //
                CmpCheckRegistry2Debug.Status = 4096;
                rc = 4096;
                // bail out
                break;
            }
            CheckStack[StackIndex].Cell = SubKey;
            CheckStack[StackIndex].ParentCell = CheckStack[StackIndex-1].Cell;
            CheckStack[StackIndex].PriorSibling = HCELL_NIL;
            CheckStack[StackIndex].ChildIndex = 0;
            CheckStack[StackIndex].CellChecked = FALSE;

        } else {
            //
            // we have checked all childs for this node; go back
            //
            StackIndex--;

        }

    }

    ExFreePoolWithTag(CheckStack, CM_POOL_TAG|PROTECTED_POOL);
    return rc;
}

#else 

ULONG
CmpCheckRegistry2(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    )
/*++

Routine Description:

    Check consistency of the registry, from a particular cell on down.

        .   Check that the cell's value list, child key list, class,
            security are OK.
        .   Check that each value entry IN the list is OK.
        .   Apply self to each child key list.

Arguments:

    Cell - HCELL_INDEX of subkey to work on.

    ParentCell - expected value of parent cell for Cell, unless
                 HCELL_NIL, in which case ignore.

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  4000 - 4999

--*/
{
    ULONG           Index;
    HCELL_INDEX     StartCell;
    HCELL_INDEX     SubKey;
    ULONG           rc = 0;
    PCELL_DATA      pcell;
    PCM_KEY_NODE    Node;
    HCELL_INDEX     EnterParent = ParentCell;
    HCELL_INDEX     EnterCell = Cell;


    CmpCheckRegistry2Debug.Hive = HiveToCheck;
    CmpCheckRegistry2Debug.Status = 0;
    
    ASSERT( HiveToCheck->ReleaseCellRoutine == NULL );

Restart:
    Cell = EnterCell;
    ParentCell = EnterParent;
    StartCell = EnterCell;
    Index = 0;
    //
    // A jump to NewKey amounts to a virtual call to check the
    // next child cell. (a descent into the tree)
    //
    // Cell, ParentCell, Index, and globals are defined
    //
    NewKey:
        rc = CmpCheckKey(HiveToCheck,CheckFlags,Cell, ParentCell,ResetSD);
        if (rc != 0) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tChild is list entry #%08lx\n", Index));
            CmpCheckRegistry2Debug.Status = rc;
            if( CmDoSelfHeal() && (Cell != EnterCell)) { // root cell damage is fatal.
                //
                // delete this key from the parent's list and restart the whole iteration (not best performance, but safest).
                //
                if( !CmpRemoveSubKeyCellNoCellRef(HiveToCheck,ParentCell,Cell) ) {
                    //
                    // unable to delete subkey; punt.
                    //
                    return rc;
                }
                CmMarkSelfHeal(HiveToCheck);
                rc = 0;
                goto Restart;
            } else {
                // bail out
                return rc;
            }
        }

        //
        // save Index and check out children
        //
        pcell = HvGetCell(HiveToCheck, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
            CmpCheckRegistry2Debug.Status = 4099;
            return 4099;
        }
        pcell->u.KeyNode.WorkVar = Index;

        for (Index = 0; Index<pcell->u.KeyNode.SubKeyCounts[Stable]; Index++) {

            Node = (PCM_KEY_NODE)HvGetCell(HiveToCheck,Cell);
            if( Node == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
                CmpCheckRegistry2Debug.Status = 4098;
                return 4098;
            }
            SubKey = CmpFindSubKeyByNumber(HiveToCheck,
                                           Node,
                                           Index);
            if( SubKey == HCELL_NIL ) {
                //
                // we couldn't map cell;bail out
                //
                return 0;
            }

            //
            // "recurse" onto child
            //
            ParentCell = Cell;
            Cell = SubKey;
            goto NewKey;

            ResumeKey:;                 // A jump here is a virtual return
                                        // Cell, ParentCell and Index
                                        // must be defined
        }

        //
        // since we're here, we've checked out all the children
        // of the current cell.
        //
        if (Cell == StartCell) {

            //
            // we are done
            //
            return 0;
        }

        //
        // "return" to "parent instance"
        //
        pcell = HvGetCell(HiveToCheck, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
            CmpCheckRegistry2Debug.Status = 4097;
            return 4097;
        }

        Index = pcell->u.KeyNode.WorkVar;

        Cell = ParentCell;

        pcell = HvGetCell(HiveToCheck, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
            CmpCheckRegistry2Debug.Status = 4096;
            return 4096;
        }
        ParentCell = pcell->u.KeyNode.Parent;

        goto ResumeKey;
}

#endif //_CM_LDR_

#if DBG

#define VOLATILE_KEY_NAME_LENGTH        PAGE_SIZE

HCELL_INDEX     CmpKeyCellDebug = 0;
WCHAR           CmpVolatileKeyNameBuffer[VOLATILE_KEY_NAME_LENGTH/2];
#endif //DBG

ULONG
CmpCheckKey(
    PHHIVE      HiveToCheck,
    ULONG       CheckFlags,
    HCELL_INDEX Cell,
    HCELL_INDEX ParentCell,
    BOOLEAN     ResetSD
    )
/*++

Routine Description:

    Check consistency of the registry, for a particular cell

        .   Check that the cell's value list, child key list, class,
            security are OK.
        .   Check that each value entry IN the list is OK.

Arguments:

    Cell - HCELL_INDEX of subkey to work on.

    ParentCell - expected value of parent cell for Cell, unless
                 HCELL_NIL, in which case ignore.

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  4000 - 4999

--*/
{
    PCELL_DATA      pcell;
    ULONG           size;
    ULONG           usedlen;
    ULONG           ClassLength;
    HCELL_INDEX     Class;
    ULONG           ValueCount;
    HCELL_INDEX     ValueList;
    HCELL_INDEX     Security;
    ULONG           rc = 0;
    ULONG           nrc = 0;
    ULONG           i;
    PCM_KEY_INDEX   Root;
    PCM_KEY_INDEX   Leaf;
    ULONG           SubCount;

    CmpCheckKeyDebug.Hive = HiveToCheck;
    CmpCheckKeyDebug.Status = 0;
    CmpCheckKeyDebug.Cell = Cell;
    CmpCheckKeyDebug.CellPoint = NULL;
    CmpCheckKeyDebug.RootPoint = NULL;
    CmpCheckKeyDebug.Index = (ULONG)-1;

#if DBG
    if(CmpKeyCellDebug == Cell) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Hive = %p :: Cell to debug = %lx\n",HiveToCheck,(ULONG)Cell));
        DbgBreakPoint();
    }
#endif //DBG

    //
    // Check key itself
    //
    if (! HvIsCellAllocated(HiveToCheck, Cell)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tNot allocated\n"));
        rc = 4010;
        CmpCheckKeyDebug.Status = rc;
        return rc;
    }
    pcell = HvGetCell(HiveToCheck, Cell);
    if( pcell == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
        CmpCheckKeyDebug.Status = 4095;
        return 4095;
    }

    CmpCheckKeyDebug.CellPoint = pcell;

    size = HvGetCellSize(HiveToCheck, pcell);
    if (size > REG_MAX_PLAUSIBLE_KEY_SIZE) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tImplausible size %lx\n", size));
        rc = 4020;
        CmpCheckKeyDebug.Status = rc;
        return rc;
    }
    usedlen = FIELD_OFFSET(CM_KEY_NODE, Name) + pcell->u.KeyNode.NameLength;
    if( (!pcell->u.KeyNode.NameLength) || (usedlen > size)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tKey is bigger than containing cell.\n"));
        rc = 4030;
        CmpCheckKeyDebug.Status = rc;
        return rc;
    }
    if (pcell->u.KeyNode.Signature != CM_KEY_NODE_SIGNATURE) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tNo key signature\n"));
        rc = 4040;
        CmpCheckKeyDebug.Status = rc;
        if( CmDoSelfHeal() ) {
            //
            // this could be only signature corruption; fix it;
            //
            if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                pcell->u.KeyNode.Signature = CM_KEY_NODE_SIGNATURE;
                rc = 0;
                CmMarkSelfHeal(HiveToCheck);
            } else {
                return rc;
            }
        } else {
            return rc;
        }
    }
    if (ParentCell != HCELL_NIL) {
        if (pcell->u.KeyNode.Parent != ParentCell) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tWrong parent value.\n"));
            rc = 4045;
            CmpCheckKeyDebug.Status = rc;
            if( CmDoSelfHeal() ) {
                //
                // this could isolated corruption; fix it;
                //
                if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                    pcell->u.KeyNode.Parent = ParentCell;
                    CmMarkSelfHeal(HiveToCheck);
                    rc = 0;
                } else {
                    return rc;
                }
            } else {
                return rc;
            }
        }
    }
    ClassLength = pcell->u.KeyNode.ClassLength;
    Class = pcell->u.KeyNode.Class;
    ValueCount = pcell->u.KeyNode.ValueList.Count;
    ValueList = pcell->u.KeyNode.ValueList.List;
    Security = pcell->u.KeyNode.Security;

    //
    // Check simple non-empty cases
    //
    if (ClassLength > 0) {
        if( Class == HCELL_NIL ) {
            pcell->u.KeyNode.ClassLength = 0;
            HvMarkCellDirty(HiveToCheck, Cell);
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx has ClassLength = %lu and Class == HCELL_NIL\n", HiveToCheck, Cell,ClassLength));
        } else {
            if (HvIsCellAllocated(HiveToCheck, Class) == FALSE) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tClass:%08lx - unallocated class\n", Class));
                    rc = 4080;
                    CmpCheckKeyDebug.Status = rc;
                    if( CmDoSelfHeal() ) {
                        //
                        // yank the class
                        //
                        if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                            pcell->u.KeyNode.Class = HCELL_NIL;
                            pcell->u.KeyNode.ClassLength = 0;
                            CmMarkSelfHeal(HiveToCheck);
                            rc = 0;
                        } else {
                            return rc;
                        }
                    } else {
                        return rc;
                    }
            } 
        }
    }

    if (Security != HCELL_NIL) {
        if ((HvIsCellAllocated(HiveToCheck, Security) == FALSE) || 
            ((ParentCell != HCELL_NIL) && CmDoSelfHeal() && ResetSD) ) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tSecurity:%08lx - unallocated security\n", Security));
            rc = 4090;
            CmpCheckKeyDebug.Status = rc;
            goto SetParentSecurity;
        } 
        //
        // Else CmpValidateHiveSecurityDescriptors must do computation
        //
    } else {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"SecurityCell is HCELL_NIL for (%p,%08lx) !!!\n", HiveToCheck, Cell));
        rc = 4130;
        CmpCheckKeyDebug.Status = rc;
SetParentSecurity:
        if( CmDoSelfHeal() ) {
            //
            // attempt to set the same security as it's parent
            //
            PCM_KEY_NODE ParentNode = NULL;
            PCM_KEY_SECURITY SecurityNode = NULL;

            if( ParentCell != HCELL_NIL ) {
                ParentNode = (PCM_KEY_NODE )HvGetCell(HiveToCheck, ParentCell);
                SecurityNode = (PCM_KEY_SECURITY)HvGetCell(HiveToCheck, ParentNode->Security);
            }

            if( ParentNode == NULL || SecurityNode == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                return rc;
            }

            if( HvMarkCellDirty(HiveToCheck, Cell) &&  HvMarkCellDirty(HiveToCheck, ParentNode->Security) ) {
                pcell->u.KeyNode.Security = ParentNode->Security;
                SecurityNode->ReferenceCount++;
                rc = 0;
                CmMarkSelfHeal(HiveToCheck);
            } else {
                return rc;
            }
        } else {
            return rc;
        }
        
    }

    //
    // Check value list case
    //
    if (ValueCount > 0) {
        if (HvIsCellAllocated(HiveToCheck, ValueList) == FALSE) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tValueList:%08lx - unallocated valuelist\n", ValueList));
            rc = 4100;
            CmpCheckKeyDebug.Status = rc;
            goto YankValueList;
        } else {
            pcell = HvGetCell(HiveToCheck, ValueList);
            if( pcell == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", ValueList));
                CmpCheckKeyDebug.Status = 4094;
                return 4094;
            }
            if( ValueCount * sizeof(HCELL_INDEX) > (ULONG)HvGetCellSize(HiveToCheck,pcell) ) {
                //
                // implausible value count.
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tValueList:%08lx - Implausible ValueCount = %08lx\n", ValueList,ValueCount));
                rc = 4095;
                CmpCheckKeyDebug.Status = rc;
                goto YankValueList;
            }

            nrc = CmpCheckValueList(HiveToCheck, pcell, ValueCount,Cell);
            if (nrc != 0) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"List was for HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                rc = nrc;
                CmpCheckKeyDebug.CellPoint = pcell;
                CmpCheckKeyDebug.Status = rc;
YankValueList:
                if( CmDoSelfHeal() ) {
                    PCM_KEY_NODE KeyNode;
                    //
                    // make the key valueless
                    //
                    if( HvMarkCellDirty(HiveToCheck, Cell) && (KeyNode = (PCM_KEY_NODE)HvGetCell(HiveToCheck, Cell) ) ) {
                        KeyNode->ValueList.Count = 0;
                        KeyNode->ValueList.List = HCELL_NIL;
                        CmMarkSelfHeal(HiveToCheck);
                        rc = 0;
                    } else {
                        return rc;
                    }
                } else {
                    return rc;
                }
            }
        }
    }


    //
    // Check subkey list case
    //

    pcell = HvGetCell(HiveToCheck, Cell);
    if( pcell == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
        CmpCheckKeyDebug.Status = 4093;
        return 4093;
    }
    CmpCheckKeyDebug.CellPoint = pcell;
    if ((HvGetCellType(Cell) == Volatile) &&
        (pcell->u.KeyNode.SubKeyCounts[Stable] != 0))
    {
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tVolatile Cell has Stable children\n"));
        rc = 4108;
        CmpCheckKeyDebug.Status = rc;
        return rc;
    } else if (pcell->u.KeyNode.SubKeyCounts[Stable] > 0) {
        if (! HvIsCellAllocated(HiveToCheck, pcell->u.KeyNode.SubKeyLists[Stable])) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tStableKeyList:%08lx - unallocated\n", pcell->u.KeyNode.SubKeyLists[Stable]));
            rc = 4110;
            CmpCheckKeyDebug.Status = rc;
            goto YankStableSubkeys;
        } else {
            //
            // Prove that the index is OK
            //
            Root = (PCM_KEY_INDEX)HvGetCell(
                                    HiveToCheck,
                                    pcell->u.KeyNode.SubKeyLists[Stable]
                                    );
            if( Root == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", pcell->u.KeyNode.SubKeyLists[Stable]));
                CmpCheckKeyDebug.Status = 4093;
                return 4093;
            }
            CmpCheckKeyDebug.RootPoint = Root;
            if ((Root->Signature == CM_KEY_INDEX_LEAF) ||
                (Root->Signature == CM_KEY_FAST_LEAF)  ||
                (Root->Signature == CM_KEY_HASH_LEAF) ) {
                if ((ULONG)Root->Count != pcell->u.KeyNode.SubKeyCounts[Stable]) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad Index count @%08lx\n", Root));
                    rc = 4120;
                    CmpCheckKeyDebug.Status = rc;
                    if( CmDoSelfHeal() ) {
                        //
                        // fix the subkeycount
                        //
                        if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                            pcell->u.KeyNode.SubKeyCounts[Stable] = (ULONG)Root->Count;
                            CmMarkSelfHeal(HiveToCheck);
                            rc = 0;
                        } else {
                            return rc;
                        }
                    } else {
                        return rc;
                    } 
                }
            } else if (Root->Signature == CM_KEY_INDEX_ROOT) {
                SubCount = 0;
                for (i = 0; i < Root->Count; i++) {
                    CmpCheckKeyDebug.Index = i;
                    if (! HvIsCellAllocated(HiveToCheck, Root->List[i])) {
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: Hive:%p Cell:%08lx\n", HiveToCheck, Cell));
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad Leaf Cell %08lx Root@%08lx\n", Root->List[i], Root));
                        rc = 4130;
                        CmpCheckKeyDebug.Status = rc;
                        goto YankStableSubkeys;
                    }
                    Leaf = (PCM_KEY_INDEX)HvGetCell(HiveToCheck,
                                                    Root->List[i]);
                    if( Leaf == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Root->List[i]));
                        CmpCheckKeyDebug.Status = 4092;
                        return 4092;
                    }

                    if ((Leaf->Signature != CM_KEY_INDEX_LEAF) &&
                        (Leaf->Signature != CM_KEY_FAST_LEAF)  &&
                        (Leaf->Signature != CM_KEY_HASH_LEAF) ) {
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad Leaf Index @%08lx Root@%08lx\n", Leaf, Root));
                        rc = 4140;
                        CmpCheckKeyDebug.Status = rc;
                        goto YankStableSubkeys;
                    }
                    SubCount += Leaf->Count;
                }
                if (pcell->u.KeyNode.SubKeyCounts[Stable] != SubCount) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad count in index, SubCount=%08lx\n", SubCount));
                    rc = 4150;
                    CmpCheckKeyDebug.Status = rc;
                    if( CmDoSelfHeal() ) {
                        //
                        // fix the subkeycount
                        //
                        if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                            pcell->u.KeyNode.SubKeyCounts[Stable] = SubCount;
                            CmMarkSelfHeal(HiveToCheck);
                            rc = 0;
                        } else {
                            return rc;
                        }
                    } else {
                        return rc;
                    } 
                }
            } else {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckKey: HiveToCheck:%p Cell:%08lx\n", HiveToCheck, Cell));
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tBad Root index signature @%08lx\n", Root));
                rc = 4120;
                CmpCheckKeyDebug.Status = rc;
                goto YankStableSubkeys;
            }
        }
    }
    if( FALSE ) {
YankStableSubkeys:
        if( CmDoSelfHeal() ) {
            //
            // mark the key as no subkeys
            //
            if( HvMarkCellDirty(HiveToCheck, Cell) ) {
                pcell->u.KeyNode.SubKeyCounts[Stable] = 0;
                pcell->u.KeyNode.SubKeyLists[Stable] = HCELL_NIL;
                CmMarkSelfHeal(HiveToCheck);
                rc = 0;
            } else {
                return rc;
            }
        } else {
            return rc;
        } 
    }
    //
    // force volatiles to be empty, if this is a load operation
    //
    if ( (CheckFlags & CM_CHECK_REGISTRY_FORCE_CLEAN) || // force clear out volatile info 
         ( 
             ( CheckFlags & (CM_CHECK_REGISTRY_CHECK_CLEAN | CM_CHECK_REGISTRY_LOADER_CLEAN) ) &&  // if asked to clear volatile info
             ( pcell->u.KeyNode.SubKeyCounts[Volatile] != 0 )                               // there is some volatile info saved from a previous version
         )                                             ||
         (
             ( CheckFlags & CM_CHECK_REGISTRY_SYSTEM_CLEAN ) &&         // system hive special case; the loader has cleaned only subkeycount
             (( pcell->u.KeyNode.SubKeyLists[Volatile] != HCELL_NIL ) ||    // now it is our job to clear Subkeylist, too
             (HiveToCheck->Version < HSYS_WHISTLER_BETA1) )
         ) 
        
        ) {
        //
        // go ahead and clear the volatile info for this key
        //
        if( CheckFlags & CM_CHECK_REGISTRY_SYSTEM_CLEAN ) {
            //
            // the loader must've left this on the previous value and cleared only the count
            //
            ASSERT( pcell->u.KeyNode.SubKeyLists[Volatile] == 0xBAADF00D || HiveToCheck->Version < HSYS_WHISTLER_BETA1 );
            ASSERT( pcell->u.KeyNode.SubKeyCounts[Volatile] == 0 );
#if DBG
#ifndef _CM_LDR_
            //
            // see who those volatile keys are
            //
            {
                ULONG           TotalLength = 0;
                HCELL_INDEX     CurrCell = Cell;
                PCM_KEY_NODE    CurrNode;
                PUCHAR          Dest;
                ULONG           k;

                Dest = ((PUCHAR)CmpVolatileKeyNameBuffer) + VOLATILE_KEY_NAME_LENGTH - 2;
                while(TRUE) {
                    CurrNode = (PCM_KEY_NODE)HvGetCell(HiveToCheck,CurrCell);
                    Dest -= CurrNode->NameLength;
                    TotalLength += CurrNode->NameLength;
                    if (CurrNode->Flags & KEY_COMP_NAME) {
                        Dest -= CurrNode->NameLength;
                        for (k=0;k<CurrNode->NameLength;k++) {
                            ((PWCHAR)Dest)[k] = (WCHAR)(((PUCHAR)CurrNode->Name)[k]);
                        }
                    } else {
                        RtlCopyMemory(
                            Dest,
                            CurrNode->Name,
                            CurrNode->NameLength
                            );
                    }
                    Dest -= 2;
                    TotalLength += (CurrNode->NameLength +2);
                    ((PWCHAR)Dest)[0] = (WCHAR)'\\';
                    if( CurrCell == HiveToCheck->BaseBlock->RootCell ) {
                        break;
                    }
                    CurrCell = CurrNode->Parent;
                }  
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"%.*S\n",TotalLength/2,Dest));
                
            }
#endif
#endif

        }

        HvMarkCellDirty(HiveToCheck, Cell);
        //CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Clear Volatile Info for Hive = %p Cell = %lx\n", HiveToCheck, Cell));
        pcell->u.KeyNode.SubKeyCounts[Volatile] = 0;
        if( (CheckFlags & CM_CHECK_REGISTRY_LOADER_CLEAN) &&
            (HiveToCheck->Version >= HSYS_WHISTLER_BETA1)
            ) {
            //
            // mark this as bad food
            //
            pcell->u.KeyNode.SubKeyLists[Volatile] = 0xBAADF00D;
        } else {
            //
            // clean it up 
            //
            pcell->u.KeyNode.SubKeyLists[Volatile] = HCELL_NIL;
        }
    }

    return rc;
}

ULONG
CmpCheckValueList(
    PHHIVE      Hive,
    PCELL_DATA  List,
    ULONG       Count,
    HCELL_INDEX KeyCell
    )
/*++

Routine Description:

    Check consistency of a value list.
        .   Each element allocated?
        .   Each element have valid signature?
        .   Data properly allocated?

Arguments:

    Hive - containing Hive.

    List - pointer to an array of HCELL_INDEX entries.

    Count - number of entries in list.

Return Value:

    0 if Hive is OK.  Error return indicator if not.

    RANGE:  5000 - 5999

--*/
{
    ULONG           i = 0,j;
    HCELL_INDEX     Cell;
    PCELL_DATA      pcell;
    ULONG           size;
    ULONG           usedlen;
    ULONG           DataLength;
    HCELL_INDEX     Data;
    ULONG           rc = 0;

    CmpCheckValueListDebug.Hive = Hive;
    CmpCheckValueListDebug.Status = 0;
    CmpCheckValueListDebug.List = List;
    CmpCheckValueListDebug.Index = (ULONG)-1;
    CmpCheckValueListDebug.Cell = 0;   // NOT HCELL_NIL
    CmpCheckValueListDebug.CellPoint = NULL;

    if( FALSE ) {
RemoveThisValue:
        if( CmDoSelfHeal() ) {
            //
            // remove value at index i
            //
            PCM_KEY_NODE    Node;
            Node = (PCM_KEY_NODE)HvGetCell(Hive,KeyCell);
            if( Node == NULL ) {
                return rc;
            }
            HvReleaseCell(Hive,KeyCell);

            if( HvMarkCellDirty(Hive, KeyCell) &&
                HvMarkCellDirty(Hive, Node->ValueList.List)) {
                Node->ValueList.Count--;
                Count--;
                RtlMoveMemory(&(List->u.KeyList[i]),&(List->u.KeyList[i+1]),(Count - i)*sizeof(HCELL_INDEX));
                rc = 0;
                CmMarkSelfHeal(Hive);
            } else {
                return rc;
            }
        } else {
            return rc;
        } 
    }

    for (; i < Count; i++) {

        //
        // Check out value entry's refs.
        //
        Cell = List->u.KeyList[i];
        if (Cell == HCELL_NIL) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tEntry is null\n"));
            rc = 5010;
            CmpCheckValueListDebug.Status = rc;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            goto RemoveThisValue;
        }
        if (HvIsCellAllocated(Hive, Cell) == FALSE) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tEntry is not allocated\n"));
            rc = 5020;
            CmpCheckValueListDebug.Status = rc;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            goto RemoveThisValue;
        } 

        //
        // Check out the value entry itself
        //
        pcell = HvGetCell(Hive, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Cell));
            CmpCheckValueListDebug.Status = 5099;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            rc = 5099;
            goto Exit;
        }
        size = HvGetCellSize(Hive, pcell);
        if (pcell->u.KeyValue.Signature != CM_KEY_VALUE_SIGNATURE) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx - invalid value signature\n", Cell));
            rc = 5030;
            CmpCheckValueListDebug.Status = rc;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            CmpCheckValueListDebug.CellPoint = pcell;
            goto RemoveThisValue;
        }
        usedlen = FIELD_OFFSET(CM_KEY_VALUE, Name) + pcell->u.KeyValue.NameLength;
        if (usedlen > size) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx - value bigger than containing cell\n", Cell));
            rc = 5040;
            CmpCheckValueListDebug.Status = rc;
            CmpCheckValueListDebug.Index = i;
            CmpCheckValueListDebug.Cell = Cell;
            CmpCheckValueListDebug.CellPoint = pcell;
            goto RemoveThisValue;
        }

        //
        // Check out value entry's data
        //
        DataLength = pcell->u.KeyValue.DataLength;
        if (DataLength < CM_KEY_VALUE_SPECIAL_SIZE) {
            Data = pcell->u.KeyValue.Data;
            if ((DataLength == 0) && (Data != HCELL_NIL)) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx Data:%08lx - data not null\n", Cell, Data));
                rc = 5050;
                CmpCheckValueListDebug.Status = rc;
                CmpCheckValueListDebug.Index = i;
                CmpCheckValueListDebug.Cell = Cell;
                CmpCheckValueListDebug.CellPoint = pcell;
                goto RemoveThisValue;
            }
            if (DataLength > 0) {
                if (HvIsCellAllocated(Hive, Data) == FALSE) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx Data:%08lx - unallocated\n", Cell, Data));
                    rc = 5060;
                    CmpCheckValueListDebug.Status = rc;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = Cell;
                    CmpCheckValueListDebug.CellPoint = pcell;
                    goto RemoveThisValue;
                }
            }
            if( CmpIsHKeyValueBig(Hive,DataLength) == TRUE ) {
                PCM_BIG_DATA    BigData;
                PHCELL_INDEX    Plist;

                BigData = (PCM_BIG_DATA)HvGetCell(Hive, Data);
                if( BigData == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", Data));
                    CmpCheckValueListDebug.Status = 5098;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = Data;
                    rc = 5098;
                    goto Exit;
                }
                
                if( (BigData->Signature != CM_BIG_DATA_SIGNATURE) ||
                    (BigData->Count == 0 ) ||
                    (BigData->List == HCELL_NIL) 
                    ) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tinvalid big data cell #%08lx\n", Data));
                    CmpCheckValueListDebug.Status = 5097;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = Data;
                    rc = 5097;
                    goto RemoveThisValue;
                }
                
                if (HvIsCellAllocated(Hive, BigData->List) == FALSE) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p i:%08lx\n", List, i));
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx DataList:%08lx - unallocated\n", Cell, BigData->List));
                    rc = 5096;
                    CmpCheckValueListDebug.Status = rc;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = BigData->List;
                    CmpCheckValueListDebug.CellPoint = (PCELL_DATA)BigData;
                    goto RemoveThisValue;
                }

                Plist = (PHCELL_INDEX)HvGetCell(Hive,BigData->List);
                if( Plist == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCould not map cell #%08lx\n", BigData->List));
                    CmpCheckValueListDebug.Status = 5098;
                    CmpCheckValueListDebug.Index = i;
                    CmpCheckValueListDebug.Cell = BigData->List;
                    rc = 5095;
                    goto Exit;
                }

                //
                // check each and every big data cell to see if it is allocated.
                // 
                for(j=0;j<BigData->Count;j++) {
                    if (HvIsCellAllocated(Hive, Plist[j]) == FALSE) {
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"CmpCheckValueList: List:%p j:%08lx\n", BigData->List, j));
                        CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"\tCell:%08lx BigData:%08lx - unallocated\n", Plist[j], BigData->List));
                        rc = 5094;
                        CmpCheckValueListDebug.Status = rc;
                        CmpCheckValueListDebug.Index = j;
                        CmpCheckValueListDebug.Cell = Plist[j];
                        CmpCheckValueListDebug.CellPoint = (PCELL_DATA)BigData;
                        goto RemoveThisValue;
                    }
                }
            }

        }
    }

Exit:
    // cleanup
        
    return rc;
}

#ifdef CHECK_REGISTRY_USECOUNT

extern LIST_ENTRY CmpHiveListHead;

VOID
CmpCheckRegistryUseCount( ) 
{
    PLIST_ENTRY p;
    PCMHIVE     CmHive;

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    
    LOCK_HIVE_LIST();
    p = CmpHiveListHead.Flink;
    while(p != &CmpHiveListHead) {
        CmHive = CONTAINING_RECORD(p, CMHIVE, HiveList);
        
        if( CmHive->UseCount != 0 ){
            DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_ERROR_LEVEL,"Hive (%p) is supposed to have USECount == 0 at this point; instead UseCount = %lu\n",CmHive,CmHive->UseCount);  
            DbgBreakPoint();
        }

        p=p->Flink;
    }
    UNLOCK_HIVE_LIST();

}
#endif

BOOLEAN
CmpCheckLexicographicalOrder (  IN PHHIVE       HiveToCheck,
                                IN HCELL_INDEX  PriorSibling,
                                IN HCELL_INDEX  Current 
                                )
{
    PCM_KEY_NODE    CurrentNode;
    PCM_KEY_NODE    PriorNode;
    UNICODE_STRING  PriorKeyName;
    UNICODE_STRING  CurrentKeyName;

#ifndef _CM_LDR_
    PAGED_CODE();
#endif //_CM_LDR_


    CurrentNode = (PCM_KEY_NODE)HvGetCell(HiveToCheck, Current);
    PriorNode = (PCM_KEY_NODE)HvGetCell(HiveToCheck, PriorSibling);
    if( (CurrentNode == NULL) || (PriorNode == NULL ) ) {
        return FALSE;
    }
    if(CurrentNode->Flags & KEY_COMP_NAME) { 
        if(PriorNode->Flags & KEY_COMP_NAME) {
            //
            // most usual case
            //
            if( CmpCompareTwoCompressedNames(   PriorNode->Name,
                                                PriorNode->NameLength,
                                                CurrentNode->Name,
                                                CurrentNode->NameLength ) >=0 ) {
                return FALSE;
            }
        } else {
            PriorKeyName.Buffer = &(PriorNode->Name[0]);
            PriorKeyName.Length = PriorNode->NameLength;
            PriorKeyName.MaximumLength = PriorKeyName.Length;
            if( CmpCompareCompressedName(&PriorKeyName,
                                        CurrentNode->Name,
                                        CurrentNode->NameLength,
                                        0) >= 0 ) {
                return FALSE;            
            }

        }
    } else {
        if(PriorNode->Flags & KEY_COMP_NAME) {
            CurrentKeyName.Buffer = &(CurrentNode->Name[0]);
            CurrentKeyName.Length = CurrentNode->NameLength;
            CurrentKeyName.MaximumLength = CurrentKeyName.Length;
            if( CmpCompareCompressedName(&CurrentKeyName,
                                        PriorNode->Name,
                                        PriorNode->NameLength,
                                        0) <= 0 ) {
                return FALSE;            
            }
        } else {
            //
            // worst case: two unicode strings
            //
            PriorKeyName.Buffer = &(PriorNode->Name[0]);
            PriorKeyName.Length = PriorNode->NameLength;
            PriorKeyName.MaximumLength = PriorKeyName.Length;
            CurrentKeyName.Buffer = &(CurrentNode->Name[0]);
            CurrentKeyName.Length = CurrentNode->NameLength;
            CurrentKeyName.MaximumLength = CurrentKeyName.Length;
            if( RtlCompareUnicodeString(&PriorKeyName,
                                        &CurrentKeyName,
                                        TRUE) >= 0 ) {
                return FALSE;
            }

        }
    }
    
    return TRUE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\cache\vacbsup.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    vacbsup.c

Abstract:

    This module implements the support routines for the Virtual Address
    Control Block support for the Cache Manager.  These routines are used
    to manage a large number of relatively small address windows to map
    file data for all forms of cache access.

Author:

    Tom Miller      [TomM]      8-Feb-1992

Revision History:

--*/

#include "cc.h"
#include "ex.h"

//
//  Define our debug constant
//

#define me 0x000000040

//
//  Internal Support Routines.
//

VOID
CcUnmapVacb (
    IN PVACB Vacb,
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN BOOLEAN UnmapBehind
    );

PVACB
CcGetVacbMiss (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset,
    IN OUT PKIRQL OldIrql
    );

VOID
CcCalculateVacbLevelLockCount (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level
    );

PVACB
CcGetVacbLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset
    );

VOID
CcSetVacbLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN PVACB Vacb
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT, CcInitializeVacbs)
#endif

//
//  Define a few macros for manipulating the Vacb array.
//

#define GetVacb(SCM,OFF) (                                                                \
    ((SCM)->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) ?                            \
    CcGetVacbLargeOffset((SCM),(OFF).QuadPart) :                                          \
    (SCM)->Vacbs[(OFF).LowPart >> VACB_OFFSET_SHIFT]                                      \
)

_inline
VOID
SetVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER Offset,
    IN PVACB Vacb
    )
{
    if (SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) {
        CcSetVacbLargeOffset(SharedCacheMap, Offset.QuadPart, Vacb);
#ifdef VACB_DBG
        ASSERT(Vacb >= VACB_SPECIAL_FIRST_VALID || CcGetVacbLargeOffset(SharedCacheMap, Offset.QuadPart) == Vacb);
#endif // VACB_DBG
    } else if (Vacb < VACB_SPECIAL_FIRST_VALID) {
        SharedCacheMap->Vacbs[Offset.LowPart >> VACB_OFFSET_SHIFT] = Vacb;
    }
#ifdef VACB_DBG
    //
    //  Note, we need a new field if we turn this check on again - ReservedForAlignment
    //  has been stolen for other purposes.
    //

    if (Vacb < VACB_SPECIAL_FIRST_VALID) {
        if (Vacb != NULL) {
            SharedCacheMap->ReservedForAlignment++;
        } else {
            SharedCacheMap->ReservedForAlignment--;
        }
    }
    ASSERT((SharedCacheMap->SectionSize.QuadPart <= VACB_SIZE_OF_FIRST_LEVEL) ||
           (SharedCacheMap->ReservedForAlignment == 0) ||
           IsVacbLevelReferenced( SharedCacheMap, SharedCacheMap->Vacbs, 1 ));
#endif // VACB_DBG
}

//
//  Define the macro for referencing the multilevel Vacb array.
//

_inline
VOID
ReferenceVacbLevel (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level,
    IN LONG Amount,
    IN LOGICAL Special
    )
{
    PVACB_LEVEL_REFERENCE VacbReference = VacbLevelReference( SharedCacheMap, VacbArray, Level );

    ASSERT( Amount > 0 ||
            (!Special && VacbReference->Reference >= (0 - Amount)) ||
            ( Special && VacbReference->SpecialReference >= (0 - Amount)));

    if (Special) {
        VacbReference->SpecialReference += Amount;
    } else {
        VacbReference->Reference += Amount;
    }

#ifdef VACB_DBG
    //
    //  For debugging purposes, we can assert that the regular reference count
    //  corresponds to the population of the level.
    //

    {
        LONG Current = VacbReference->Reference;
        CcCalculateVacbLevelLockCount( SharedCacheMap, VacbArray, Level );
        ASSERT( Current == VacbReference->Reference );
    }
#endif // VACB_DBG
}

//
//  Define the macros for moving the VACBs on the LRU list
//

#define CcMoveVacbToReuseFree(V)        RemoveEntryList( &(V)->LruList );                 \
                                        InsertHeadList( &CcVacbFreeList, &(V)->LruList );

#define CcMoveVacbToReuseTail(V)        RemoveEntryList( &(V)->LruList );                 \
                                        InsertTailList( &CcVacbLru, &(V)->LruList );

//
//  If the HighPart is nonzero, then we will go to a multi-level structure anyway, which is
//  most easily triggered by returning MAXULONG.
//

#define SizeOfVacbArray(LSZ) (                                                            \
    ((LSZ).HighPart != 0) ? MAXULONG :                                                    \
    ((LSZ).LowPart > (PREALLOCATED_VACBS * VACB_MAPPING_GRANULARITY) ?                    \
     (((LSZ).LowPart >> VACB_OFFSET_SHIFT) * sizeof(PVACB)) :                             \
     (PREALLOCATED_VACBS * sizeof(PVACB)))                                                \
)

#define CheckedDec(N) {  \
    ASSERT((N) != 0);    \
    (N) -= 1;            \
}

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CcInitializeVacbs)
#pragma alloc_text(PAGE,CcCreateVacbArray)
#pragma alloc_text(PAGE,CcUnmapVacb)
#endif


VOID
CcInitializeVacbs(
)

/*++

Routine Description:

    This routine must be called during Cache Manager initialization to
    initialize the Virtual Address Control Block structures.

Arguments:

    None.

Return Value:

    None.

--*/

{
    SIZE_T VacbBytes;
    PVACB NextVacb;

    CcNumberVacbs = (MmSizeOfSystemCacheInPages >> (VACB_OFFSET_SHIFT - PAGE_SHIFT)) - 2;
    VacbBytes = CcNumberVacbs * sizeof(VACB);

    CcVacbs = (PVACB) ExAllocatePoolWithTag( NonPagedPool, VacbBytes, 'aVcC' );

    if (CcVacbs != NULL) {
        CcBeyondVacbs = (PVACB)((PCHAR)CcVacbs + VacbBytes);
        RtlZeroMemory( CcVacbs, VacbBytes );

        InitializeListHead( &CcVacbLru );
        InitializeListHead( &CcVacbFreeList );

        for (NextVacb = CcVacbs; NextVacb < CcBeyondVacbs; NextVacb++) {

            InsertTailList( &CcVacbFreeList, &NextVacb->LruList );
        }
    }
}


PVOID
CcGetVirtualAddressIfMapped (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    OUT PVACB *Vacb,
    OUT PULONG ReceivedLength
    )

/*++

Routine Description:

    This routine returns a virtual address for the specified FileOffset,
    iff it is mapped.  Otherwise, it informs the caller that the specified
    virtual address was not mapped.  In the latter case, it still returns
    a ReceivedLength, which may be used to advance to the next view boundary.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

    Vach - Returns a Vacb pointer which must be supplied later to free
           this virtual address, or NULL if not mapped.

    ReceivedLength - Returns the number of bytes to the next view boundary,
                     whether the desired file offset is mapped or not.

Return Value:

    The virtual address at which the desired data is mapped, or NULL if it
    is not mapped.

--*/

{
    KIRQL OldIrql;
    ULONG VacbOffset = (ULONG)FileOffset & (VACB_MAPPING_GRANULARITY - 1);
    PVOID Value = NULL;

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  Generate ReceivedLength return right away.
    //

    *ReceivedLength = VACB_MAPPING_GRANULARITY - VacbOffset;

    //
    //  Modifiers of VacbArray hold the VacbLock to synchronize access.  The
    //  VacbLock must be released during the call to CcUnmapVacb() because it
    //  contains a call to MmUnmapViewInSystemCache().  It is this MM call that
    //  is responsible for copying the dirty bit from the PTEs back to the PFN.
    //
    //  During this time the worker thread may call CcFlushCache() on the
    //  Vacb being unmapped.  CcGetVirtualAddressIfMapped() is used to determine
    //  if the Vacb's memory is mapped and will correctly report that the address
    //  is not mapped so CcFlushCache() will proceed to call MmFlushSection().
    //
    //  This is where we have synchronization problems.  If MmUnmapViewInSystemCache()
    //  is not finished propogating the dirty PTE information back to the
    //  PFN when MmFlushSection() is run the MM doesn't thing there is anything
    //  to flush.
    //
    //  Later this results in noncached I/O returning different page data than
    //  cached I/O.
    //
    //  The solution to this problem is to use a multiple reader/single writer
    //  EX to delay CcGetVirtualAddressIfMapped() until any existing calls to
    //  MmUnmapViewInSystemCache() via CcUnmapVacb() complete.
    //

    ExAcquirePushLockExclusive( &SharedCacheMap->VacbPushLock );

    //
    //  Acquire the Vacb lock to see if the desired offset is already mapped.
    //

    CcAcquireVacbLock( &OldIrql );

    ASSERT( FileOffset <= SharedCacheMap->SectionSize.QuadPart );

    if ((*Vacb = GetVacb( SharedCacheMap, *(PLARGE_INTEGER)&FileOffset )) != NULL) {

        if ((*Vacb)->Overlay.ActiveCount == 0) {
            SharedCacheMap->VacbActiveCount += 1;
        }

        (*Vacb)->Overlay.ActiveCount += 1;

        //
        //  Move this range away from the front to avoid wasting cycles
        //  looking at it for reuse.
        //

        CcMoveVacbToReuseTail( *Vacb );

        Value = (PVOID)((PCHAR)(*Vacb)->BaseAddress + VacbOffset);
    }

    CcReleaseVacbLock( OldIrql );
    
    ExReleasePushLockExclusive( &SharedCacheMap->VacbPushLock );
    
    return Value;
}


PVOID
CcGetVirtualAddress (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset,
    OUT PVACB *Vacb,
    IN OUT PULONG ReceivedLength
    )

/*++

Routine Description:

    This is the main routine for Vacb management.  It may be called to acquire
    a virtual address for a given file offset.  If the desired file offset is
    already mapped, this routine does very little work before returning with
    the desired virtual address and Vacb pointer (which must be supplied to
    free the mapping).

    If the desired virtual address is not currently mapped, then this routine
    claims a Vacb from the tail of the Vacb LRU to reuse its mapping.  This Vacb
    is then unmapped if necessary (normally not required), and mapped to the
    desired address.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

    Vacb - Returns a Vacb pointer which must be supplied later to free
           this virtual address.

    ReceivedLength - Returns the number of bytes which are contiguously
                     mapped starting at the virtual address returned.

Return Value:

    The virtual address at which the desired data is mapped.

--*/

{
    KIRQL OldIrql;
    PVACB TempVacb;
    ULONG VacbOffset = FileOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1);

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  Acquire the shared lock on the VacbArray because CcGetVacbMiss()
    //  might unmap a Vacb.  See CcGetVirtualAddressIfMapped() for more
    //  details.
    //
            
    ExAcquirePushLockShared( &SharedCacheMap->VacbPushLock );

    //
    //  Acquire the Vacb lock to see if the desired offset is already mapped.
    //

    CcAcquireVacbLock( &OldIrql );

    ASSERT( FileOffset.QuadPart <= SharedCacheMap->SectionSize.QuadPart );

    if ((TempVacb = GetVacb( SharedCacheMap, FileOffset )) == NULL) {

        TempVacb = CcGetVacbMiss( SharedCacheMap, FileOffset, &OldIrql );

    } else {

        if (TempVacb->Overlay.ActiveCount == 0) {
            SharedCacheMap->VacbActiveCount += 1;
        }

        TempVacb->Overlay.ActiveCount += 1;
    }

    //
    //  Move this range away from the front to avoid wasting cycles
    //  looking at it for reuse.
    //

    CcMoveVacbToReuseTail( TempVacb );

    CcReleaseVacbLock( OldIrql );

    ExReleasePushLockShared( &SharedCacheMap->VacbPushLock );
    
    //
    //  Now form all outputs.
    //

    *Vacb = TempVacb;
    *ReceivedLength = VACB_MAPPING_GRANULARITY - VacbOffset;

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  PREfix wants to know this cannot be NULL, otherwise it will complain
    //  about users of this function.
    //

    ASSERT( TempVacb->BaseAddress != NULL );

    return (PVOID)((PCHAR)TempVacb->BaseAddress + VacbOffset);
}


PVACB
CcGetVacbMiss (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset,
    IN OUT PKIRQL OldIrql
    )

/*++

Routine Description:

    This is the main routine for Vacb management.  It may be called to acquire
    a virtual address for a given file offset.  If the desired file offset is
    already mapped, this routine does very little work before returning with
    the desired virtual address and Vacb pointer (which must be supplied to
    free the mapping).

    If the desired virtual address is not currently mapped, then this routine
    claims a Vacb from the tail of the Vacb LRU to reuse its mapping.  This Vacb
    is then unmapped if necessary (normally not required), and mapped to the
    desired address.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

    OldIrql - Pointer to the OldIrql variable in the caller

Return Value:

    The Vacb.

--*/

{
    PSHARED_CACHE_MAP OldSharedCacheMap;
    PVACB Vacb, TempVacb;
    LARGE_INTEGER MappedLength;
    LARGE_INTEGER NormalOffset;
    NTSTATUS Status;
    ULONG ActivePage;
    ULONG PageIsDirty;
    PVACB ActiveVacb = NULL;
    ULONG VacbOffset = FileOffset.LowPart & (VACB_MAPPING_GRANULARITY - 1);

    NormalOffset = FileOffset;
    NormalOffset.LowPart -= VacbOffset;

    //
    //  For files that are not open for random access, we assume sequential
    //  access and periodically unmap unused views behind us as we go, to
    //  keep from hogging memory.
    //
    //  We used to only do this for pure FO_SEQUENTIAL_ONLY access.  The
    //  sequential flags still has an effect (to put the pages at the front
    //  of the standby lists) but we intend for the majority of the file
    //  cache to live on the standby and are willing to take transition
    //  faults to bring it back.  Granted, this exacerbates the problem that
    //  it is hard to figure out how big the filecache really is since even
    //  less of it is going to be mapped at any given time.  It may also
    //  promote the synchronization bottlenecks in view mapping (MmPfnLock)
    //  to the forefront when significant view thrashing occurs.
    //
    //  This isn't as bad as it seems.  When we see access take a view miss,
    //  it is really likely that it is a result of sequential access.  As long
    //  as the pages go onto the back of the standby, they'll live for a while.
    //  The problem we're dealing with here is that the cache can be filled at
    //  high speed, but the working set manager can't possibly trim it as fast,
    //  intelligently, while we have a pretty good guess where the candidate
    //  pages should come from.  We can't let the filecache size make large
    //  excursions, or we'll kick out a lot of valuable pages in the process.
    //

    if (!FlagOn(SharedCacheMap->Flags, RANDOM_ACCESS_SEEN) &&
        ((NormalOffset.LowPart & (SEQUENTIAL_MAP_LIMIT - 1)) == 0) &&
        (NormalOffset.QuadPart >= (SEQUENTIAL_MAP_LIMIT * 2))) {

        //
        //  Use MappedLength as a scratch variable to form the offset
        //  to start unmapping.  We are not synchronized with these past
        //  views, so it is possible that CcUnmapVacbArray will kick out
        //  early when it sees an active view.  That is why we go back
        //  twice the distance, and effectively try to unmap everything
        //  twice.  The second time should normally do it.  If the file
        //  is truly sequential only, then the only collision expected
        //  might be the previous view if we are being called from readahead,
        //  or there is a small chance that we can collide with the
        //  Lazy Writer during the small window where he briefly maps
        //  the file to push out the dirty bits.
        //

        CcReleaseVacbLock( *OldIrql );
        MappedLength.QuadPart = NormalOffset.QuadPart - (SEQUENTIAL_MAP_LIMIT * 2);
        CcUnmapVacbArray( SharedCacheMap, &MappedLength, (SEQUENTIAL_MAP_LIMIT * 2), TRUE );
        CcAcquireVacbLock( OldIrql );
    }

    //
    //  If there is a free view, move it to the LRU and we're done.
    //

    if (!IsListEmpty(&CcVacbFreeList)) {
    
        Vacb = CONTAINING_RECORD( CcVacbFreeList.Flink, VACB, LruList );
        CcMoveVacbToReuseTail( Vacb );

    } else {

        //
        //  Scan from the front of the lru for the next victim Vacb
        //

        Vacb = CONTAINING_RECORD( CcVacbLru.Flink, VACB, LruList );

        while (TRUE) {

            //
            //  If this guy is not active, break out and use him.  Also, if
            //  it is an Active Vacb, nuke it now, because the reader may be idle and we
            //  want to clean up.
            //

            OldSharedCacheMap = Vacb->SharedCacheMap;
            if ((Vacb->Overlay.ActiveCount == 0) ||
                ((ActiveVacb == NULL) &&
                 (OldSharedCacheMap != NULL) &&
                 (OldSharedCacheMap->ActiveVacb == Vacb))) {

                //
                //  The normal case is that the Vacb is no longer mapped
                //  and we can just get out and use it, however, here we
                //  handle the case where it is mapped.
                //

                if (Vacb->BaseAddress != NULL) {


                    //
                    //  If this Vacb is active, it must be the ActiveVacb.
                    //

                    if (Vacb->Overlay.ActiveCount != 0) {

                        //
                        //  Get the active Vacb.
                        //

                        GetActiveVacbAtDpcLevel( Vacb->SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );

                    //
                    //  Otherwise we will break out and use this Vacb.  If it
                    //  is still mapped we can now safely increment the open
                    //  count.
                    //

                    } else {

                        //
                        //  Note that if the SharedCacheMap is currently
                        //  being deleted, we need to skip over
                        //  it, otherwise we will become the second
                        //  deleter.  CcDeleteSharedCacheMap clears the
                        //  pointer in the SectionObjectPointer.
                        //

                        CcAcquireMasterLockAtDpcLevel();
                        if (Vacb->SharedCacheMap->FileObject->SectionObjectPointer->SharedCacheMap ==
                            Vacb->SharedCacheMap) {

                            CcIncrementOpenCount( Vacb->SharedCacheMap, 'mvGS' );
                            CcReleaseMasterLockFromDpcLevel();
                            break;
                        }
                        CcReleaseMasterLockFromDpcLevel();
                    }
                } else {
                    break;
                }
            }

            //
            //  Advance to the next guy if we haven't scanned
            //  the entire list.
            //

            if (Vacb->LruList.Flink != &CcVacbLru) {

                Vacb = CONTAINING_RECORD( Vacb->LruList.Flink, VACB, LruList );

            } else {

                CcReleaseVacbLock( *OldIrql );

                //
                //  If we found an active vacb, then free it and go back and
                //  try again.  Else it's time to bail.
                //

                if (ActiveVacb != NULL) {
                    CcFreeActiveVacb( ActiveVacb->SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
                    ActiveVacb = NULL;

                    //
                    //  Reacquire spinlocks to loop back and position ourselves at the head
                    //  of the LRU for the next pass.
                    //

                    CcAcquireVacbLock( OldIrql );

                    Vacb = CONTAINING_RECORD( CcVacbLru.Flink, VACB, LruList );

                } else {

                    ExReleasePushLockShared( &SharedCacheMap->VacbPushLock );

                    ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
                }
            }
        }
    }

    //
    //  Unlink it from the other SharedCacheMap, so the other
    //  guy will not try to use it when we free the spin lock.
    //

    if (Vacb->SharedCacheMap != NULL) {

        OldSharedCacheMap = Vacb->SharedCacheMap;
        SetVacb( OldSharedCacheMap, Vacb->Overlay.FileOffset, NULL );
        Vacb->SharedCacheMap = NULL;
    }

    //
    //  Mark it in use so no one else will muck with it after
    //  we release the spin lock.
    //

    Vacb->Overlay.ActiveCount = 1;
    SharedCacheMap->VacbActiveCount += 1;

    CcReleaseVacbLock( *OldIrql );

    //
    //  If the Vacb is already mapped, then unmap it.
    //

    if (Vacb->BaseAddress != NULL) {

        //
        //  Check to see if we need to drain the zone.
        //

        CcDrainVacbLevelZone();

        CcUnmapVacb( Vacb, OldSharedCacheMap, FALSE );

        //
        //  Now we can decrement the open count as we normally
        //  do, possibly deleting the guy.
        //

        CcAcquireMasterLock( OldIrql );

        //
        //  Now release our open count.
        //

        CcDecrementOpenCount( OldSharedCacheMap, 'mvGF' );

        if ((OldSharedCacheMap->OpenCount == 0) &&
            !FlagOn(OldSharedCacheMap->Flags, WRITE_QUEUED) &&
            (OldSharedCacheMap->DirtyPages == 0)) {

            //
            //  Move to the dirty list.
            //

            RemoveEntryList( &OldSharedCacheMap->SharedCacheMapLinks );
            InsertTailList( &CcDirtySharedCacheMapList.SharedCacheMapLinks,
                            &OldSharedCacheMap->SharedCacheMapLinks );

            //
            //  Make sure the Lazy Writer will wake up, because we
            //  want him to delete this SharedCacheMap.
            //

            LazyWriter.OtherWork = TRUE;
            if (!LazyWriter.ScanActive) {
                CcScheduleLazyWriteScan( FALSE );
            }
        }

        CcReleaseMasterLock( *OldIrql );
    }

    //
    //  Assume we are mapping to the end of the section, but
    //  reduce to our normal mapping granularity if the section
    //  is too large.
    //

    MappedLength.QuadPart = SharedCacheMap->SectionSize.QuadPart - NormalOffset.QuadPart;

    if ((MappedLength.HighPart != 0) ||
        (MappedLength.LowPart > VACB_MAPPING_GRANULARITY)) {

        MappedLength.LowPart = VACB_MAPPING_GRANULARITY;
    }

    try {

        //
        //  Now map this one in the system cache.
        //

        DebugTrace( 0, mm, "MmMapViewInSystemCache:\n", 0 );
        DebugTrace( 0, mm, "    Section = %08lx\n", SharedCacheMap->Section );
        DebugTrace2(0, mm, "    Offset = %08lx, %08lx\n",
                                NormalOffset.LowPart,
                                NormalOffset.HighPart );
        DebugTrace( 0, mm, "    ViewSize = %08lx\n", MappedLength.LowPart );

        Status = MmMapViewInSystemCache (SharedCacheMap->Section,
                                         &Vacb->BaseAddress,
                                         &NormalOffset,
                                         &MappedLength.LowPart);
     
        //
        //  Take this opportunity to free the active vacb.
        //

        if (ActiveVacb != NULL) {

            CcFreeActiveVacb( ActiveVacb->SharedCacheMap, ActiveVacb, ActivePage, PageIsDirty );
        }

        if (!NT_SUCCESS (Status)) {
            
            DebugTrace (0, 0, "Error from Map, Status = %08lx\n", Status);

            //
            //  We should make sure this is NULL since the mapping failed.  Our
            //  Vacb->Overlay.ActiveCount == 1 ensures that we are the only
            //  folks accessing this Vacb right now as we set it up so we can
            //  make this assignment without the VacbLock held.
            //
            
            Vacb->BaseAddress = NULL;

            ExRaiseStatus (FsRtlNormalizeNtstatus (Status,
                                                   STATUS_UNEXPECTED_MM_MAP_ERROR));
        }

        DebugTrace( 0, mm, "    <BaseAddress = %p\n", Vacb->BaseAddress );
        DebugTrace( 0, mm, "    <ViewSize = %08lx\n", MappedLength.LowPart );

        //
        //  Make sure the zone contains the worst case number of entries.
        //

        if (SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) {

            //
            //  Raise if we cannot preallocate enough buffers.
            //

            if (!CcPrefillVacbLevelZone( CcMaxVacbLevelsSeen - 1,
                                         OldIrql,
                                         FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) )) {

                //
                //  We can't setup the Vacb levels, so we will raise the error
                //  here and the finally clause will do the proper cleanup.
                //

                //
                //  Since the Vacb->BaseAddress is non-NULL we will do the 
                //  proper unmapping work in the finally.
                //
                
                ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
            }

            //
            //  CcPrefillVacbLevelZone returns with the VacbLock acquired.
            //

        } else {

            CcAcquireVacbLock( OldIrql );
        }

    } finally {

        if (AbnormalTermination()) {

            if (Vacb->BaseAddress != NULL) {

                CcUnmapVacb( Vacb, SharedCacheMap, FALSE );
            }

            ExReleasePushLockShared( &SharedCacheMap->VacbPushLock );

            CcAcquireVacbLock( OldIrql );
            
            CheckedDec(Vacb->Overlay.ActiveCount);
            CheckedDec(SharedCacheMap->VacbActiveCount);

            //
            //  If there is someone waiting for this count to go to zero,
            //  wake them here.
            //

            if (SharedCacheMap->WaitOnActiveCount != NULL) {
                KeSetEvent( SharedCacheMap->WaitOnActiveCount, 0, FALSE );
            }

            ASSERT( Vacb->SharedCacheMap == NULL );

            CcMoveVacbToReuseFree( Vacb );

            CcReleaseVacbLock( *OldIrql );
        }
    }

    //
    //  Finish filling in the Vacb, and store its address in the array in
    //  the Shared Cache Map.  (We have to rewrite the ActiveCount
    //  since it is overlaid.)  To do this we must reacquire the
    //  spin lock one more time.  Note we have to check for the unusual
    //  case that someone beat us to mapping this view, since we had to
    //  drop the spin lock.
    //

    if ((TempVacb = GetVacb( SharedCacheMap, NormalOffset )) == NULL) {

        Vacb->SharedCacheMap = SharedCacheMap;
        Vacb->Overlay.FileOffset = NormalOffset;
        Vacb->Overlay.ActiveCount = 1;

        SetVacb( SharedCacheMap, NormalOffset, Vacb );

    //
    //  This is the unlucky case where we collided with someone else
    //  trying to map the same view.  He can get in because we dropped
    //  the spin lock above.  Rather than allocating events and making
    //  someone wait, considering this case is fairly unlikely, we just
    //  dump this one at the head of the LRU and use the one from the
    //  guy who beat us.
    //

    } else {

        //
        //  Now we have to increment all of the counts for the one that
        //  was already there, then ditch the one we had.
        //

        if (TempVacb->Overlay.ActiveCount == 0) {
            SharedCacheMap->VacbActiveCount += 1;
        }

        TempVacb->Overlay.ActiveCount += 1;

        //
        //  Now unmap the one we mapped and proceed with the other Vacb.
        //  On this path we have to release the spinlock to do the unmap,
        //  and then reacquire the spinlock before cleaning up.
        //

        CcReleaseVacbLock( *OldIrql );

        CcUnmapVacb( Vacb, SharedCacheMap, FALSE );

        CcAcquireVacbLock( OldIrql );
        CheckedDec(Vacb->Overlay.ActiveCount);
        CheckedDec(SharedCacheMap->VacbActiveCount);
        Vacb->SharedCacheMap = NULL;

        CcMoveVacbToReuseFree( Vacb );

        Vacb = TempVacb;
    }

    return Vacb;
}


VOID
FASTCALL
CcFreeVirtualAddress (
    IN PVACB Vacb
    )

/*++

Routine Description:

    This routine must be called once for each call to CcGetVirtualAddress
    to free that virtual address.

Arguments:

    Vacb - Supplies the Vacb which was returned from CcGetVirtualAddress.

Return Value:

    None.

--*/

{
    KIRQL OldIrql;
    PSHARED_CACHE_MAP SharedCacheMap = Vacb->SharedCacheMap;

    CcAcquireVacbLock( &OldIrql );

    CheckedDec(Vacb->Overlay.ActiveCount);

    //
    //  If the count goes to zero, then we want to decrement the global
    //  Active count.
    //

    if (Vacb->Overlay.ActiveCount == 0) {

        //
        //  If the SharedCacheMap address is not NULL, then this one is
        //  in use by a shared cache map, and we have to decrement his
        //  count and see if anyone is waiting.
        //

        if (SharedCacheMap != NULL) {

            CheckedDec(SharedCacheMap->VacbActiveCount);

            //
            //  If there is someone waiting for this count to go to zero,
            //  wake them here.
            //

            if (SharedCacheMap->WaitOnActiveCount != NULL) {
                KeSetEvent( SharedCacheMap->WaitOnActiveCount, 0, FALSE );
            }

            //
            //  Go to the back of the LRU to save this range for a bit
            //

            CcMoveVacbToReuseTail( Vacb );

        } else {

            //
            //  This range is no longer referenced, so make it available
            //

            ASSERT( Vacb->BaseAddress == NULL );

            CcMoveVacbToReuseFree( Vacb );
        }

    } else {

        //
        //  This range is still in use, so move it away from the front
        //  so that it doesn't consume cycles being checked.
        //

        CcMoveVacbToReuseTail( Vacb );
    }

    CcReleaseVacbLock( OldIrql );
}


VOID
CcReferenceFileOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset
    )

/*++

Routine Description:

    This is a special form of reference that insures that the multi-level
    Vacb structures are expanded to cover a given file offset.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

Return Value:

    None

--*/

{
    KIRQL OldIrql;

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  This operation only has meaning if the Vacbs are in the multilevel form.
    //

    if (SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) {

        //
        //  Prefill the level zone so that we can expand the tree if required.
        //

        if (!CcPrefillVacbLevelZone( CcMaxVacbLevelsSeen - 1,
                                     &OldIrql,
                                     FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) )) {

            ExRaiseStatus( STATUS_INSUFFICIENT_RESOURCES );
        }

        ASSERT( FileOffset.QuadPart <= SharedCacheMap->SectionSize.QuadPart );

        SetVacb( SharedCacheMap, FileOffset, VACB_SPECIAL_REFERENCE );

        CcReleaseVacbLock( OldIrql );
    }

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    return;
}


VOID
CcDereferenceFileOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER FileOffset
    )

/*++

Routine Description:

    This routine must be called once for each call to CcReferenceFileOffset
    to remove the reference.

Arguments:

    SharedCacheMap - Supplies a pointer to the Shared Cache Map for the file.

    FileOffset - Supplies the desired FileOffset within the file.

Return Value:

    None

--*/

{
    KIRQL OldIrql;

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    //
    //  This operation only has meaning if the Vacbs are in the multilevel form.
    //

    if (SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL) {

        //
        //  Acquire the Vacb lock to synchronize the dereference.
        //

        CcAcquireVacbLock( &OldIrql );

        ASSERT( FileOffset.QuadPart <= SharedCacheMap->SectionSize.QuadPart );

        SetVacb( SharedCacheMap, FileOffset, VACB_SPECIAL_DEREFERENCE );

        CcReleaseVacbLock( OldIrql );
    }

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);

    return;
}


VOID
CcWaitOnActiveCount (
    IN PSHARED_CACHE_MAP SharedCacheMap
    )

/*++

Routine Description:

    This routine may be called to wait for outstanding mappings for
    a given SharedCacheMap to go inactive.  It is intended to be called
    from CcUninitializeCacheMap, which is called by the file systems
    during cleanup processing.  In that case this routine only has to
    wait if the user closed a handle without waiting for all I/Os on the
    handle to complete.

    This routine returns each time the active count is decremented.  The
    caller must recheck his wait conditions on return, either waiting for
    the ActiveCount to go to 0, or for specific views to go inactive
    (CcPurgeCacheSection case).

Arguments:

    SharedCacheMap - Supplies the Shared Cache Map on whose VacbActiveCount
                     we wish to wait.

Return Value:

    None.

--*/

{
    KIRQL OldIrql;
    PKEVENT Event;

    //
    //  In the unusual case that we get a cleanup while I/O is still going
    //  on, we can wait here.  The caller must test the count for nonzero
    //  before calling this routine.
    //
    //  Since we are being called from cleanup, we cannot afford to
    //  fail here.
    //

    CcAcquireVacbLock( &OldIrql );

    //
    //  It is possible that the count went to zero before we acquired the
    //  spinlock, so we must handle two cases here.
    //

    if (SharedCacheMap->VacbActiveCount != 0) {

        Event = SharedCacheMap->WaitOnActiveCount;

        if (Event == NULL) {

            //
            //  Take the event.  We avoid dispatcher lock overhead for
            //  every single zero transition by only picking up the event
            //  when we actually need it.
            //

            Event = &SharedCacheMap->Event;

            KeInitializeEvent( Event,
                               NotificationEvent,
                               FALSE );

            SharedCacheMap->WaitOnActiveCount = Event;
        }
        else {
            KeClearEvent( Event );
        }

        CcReleaseVacbLock( OldIrql );

        KeWaitForSingleObject( Event,
                               Executive,
                               KernelMode,
                               FALSE,
                               (PLARGE_INTEGER)NULL);
    } else {

        CcReleaseVacbLock( OldIrql );
    }
}


//
//  Internal Support Routine.
//

VOID
CcUnmapVacb (
    IN PVACB Vacb,
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN BOOLEAN UnmapBehind
    )

/*++

Routine Description:

    This routine may be called to unmap a previously mapped Vacb, and
    clear its BaseAddress field.

Arguments:

    Vacb - Supplies the Vacb which was returned from CcGetVirtualAddress.

    UnmapBehind - If this is a result of our unmap behind logic (the
        only case in which we pay attention to sequential hints)

Return Value:

    None.

--*/

{
    //
    //  Make sure it is mapped.
    //

    ASSERT(SharedCacheMap != NULL);
    ASSERT(Vacb->BaseAddress != NULL);

    //
    //  Call MM to unmap it.
    //

    DebugTrace( 0, mm, "MmUnmapViewInSystemCache:\n", 0 );
    DebugTrace( 0, mm, "    BaseAddress = %08lx\n", Vacb->BaseAddress );

    MmUnmapViewInSystemCache( Vacb->BaseAddress,
                              SharedCacheMap->Section,
                              UnmapBehind &&
                              FlagOn(SharedCacheMap->Flags, ONLY_SEQUENTIAL_ONLY_SEEN) );

    Vacb->BaseAddress = NULL;
}


NTSTATUS
FASTCALL
CcCreateVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER NewSectionSize
    )

/*++

Routine Description:

    This routine must be called when a SharedCacheMap is created to create
    and initialize the initial Vacb array.

Arguments:

    SharedCacheMap - Supplies the shared cache map for which the array is
                     to be created.

    NewSectionSize - Supplies the current size of the section which must be
                     covered by the Vacb array.

Return Value:

    NTSTATUS.

--*/

{
    PVACB *NewAddresses;
    ULONG NewSize, SizeToAllocate;
    PLIST_ENTRY BcbListHead;
    LOGICAL CreateBcbListHeads = FALSE, CreateReference = FALSE;

    NewSize = SizeToAllocate = SizeOfVacbArray(NewSectionSize);

    //
    //  The following limit is greater than the MM limit
    //  (i.e., MM actually only supports even smaller sections).
    //  We have to reject the sign bit, and testing the high byte
    //  for nonzero will surely only catch errors.
    //

    if (NewSectionSize.HighPart & ~(PAGE_SIZE - 1)) {
        return STATUS_SECTION_TOO_BIG;
    }

    //
    //  See if we can use the array inside the shared cache map.
    //

    if (NewSize == (PREALLOCATED_VACBS * sizeof(PVACB))) {

        NewAddresses = &SharedCacheMap->InitialVacbs[0];

    //
    //  Else allocate the array.
    //

    } else {

        //
        //  For large metadata streams, double the size to allocate
        //  an array of Bcb listheads.  Each two Vacb pointers also
        //  gets its own Bcb listhead, thus requiring double the size.
        //

        ASSERT(SIZE_PER_BCB_LIST == (VACB_MAPPING_GRANULARITY * 2));

        //
        //  If this stream is larger than the size for multi-level Vacbs,
        //  then fix the size to allocate the root.
        //

        if (NewSize > VACB_LEVEL_BLOCK_SIZE) {

            ULONG Level = 0;
            ULONG Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;

            NewSize = SizeToAllocate = VACB_LEVEL_BLOCK_SIZE;
            SizeToAllocate += sizeof(VACB_LEVEL_REFERENCE);
            CreateReference = TRUE;

            //
            //  Loop to calculate how many levels we have and how much we have to
            //  shift to index into the first level.
            //

            do {

                Level += 1;
                Shift += VACB_LEVEL_SHIFT;

            } while ((NewSectionSize.QuadPart > ((LONGLONG)1 << Shift)) != 0);

            //
            //  Remember the maximum level ever seen (which is actually Level + 1).
            //

            if (Level >= CcMaxVacbLevelsSeen) {
                ASSERT(Level <= VACB_NUMBER_OF_LEVELS);
                CcMaxVacbLevelsSeen = Level + 1;
            }

        } else {

            //
            //  Does this stream get a Bcb Listhead array?
            //

            if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) &&
                (NewSectionSize.QuadPart > BEGIN_BCB_LIST_ARRAY)) {

                SizeToAllocate *= 2;
                CreateBcbListHeads = TRUE;
            }

            //
            //  Handle the boundary case by giving the proto-level a
            //  reference count.  This will allow us to simply push it
            //  in the expansion case.  In practice, due to pool granularity
            //  this will not change the amount of space allocated
            //

            if (NewSize == VACB_LEVEL_BLOCK_SIZE) {

                SizeToAllocate += sizeof(VACB_LEVEL_REFERENCE);
                CreateReference = TRUE;
            }
        }

        NewAddresses = ExAllocatePoolWithTag( NonPagedPool, SizeToAllocate, 'pVcC' );
        if (NewAddresses == NULL) {
            SharedCacheMap->Status = STATUS_INSUFFICIENT_RESOURCES;
            return STATUS_INSUFFICIENT_RESOURCES;
        }
    }

    //
    //  Zero out the Vacb array and the trailing reference counts.
    //

    RtlZeroMemory( (PCHAR)NewAddresses, NewSize );

    if (CreateReference) {

        SizeToAllocate -= sizeof(VACB_LEVEL_REFERENCE);
        RtlZeroMemory( (PCHAR)NewAddresses + SizeToAllocate, sizeof(VACB_LEVEL_REFERENCE) );
    }

    //
    //  Loop to insert the Bcb listheads (if any) in the *descending* order
    //  Bcb list.
    //

    if (CreateBcbListHeads) {

        for (BcbListHead = (PLIST_ENTRY)((PCHAR)NewAddresses + NewSize);
             BcbListHead < (PLIST_ENTRY)((PCHAR)NewAddresses + SizeToAllocate);
             BcbListHead++) {

            InsertHeadList( &SharedCacheMap->BcbList, BcbListHead );
        }
    }

    SharedCacheMap->Vacbs = NewAddresses;
    SharedCacheMap->SectionSize = NewSectionSize;

    return STATUS_SUCCESS;
}


NTSTATUS
CcExtendVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LARGE_INTEGER NewSectionSize
    )

/*++

Routine Description:

    This routine must be called any time the section for a shared cache
    map is extended, in order to extend the Vacb array (if necessary).

Arguments:

    SharedCacheMap - Supplies the shared cache map for which the array is
                     to be created.

    NewSectionSize - Supplies the new size of the section which must be
                     covered by the Vacb array.

Return Value:

    NTSTATUS.

--*/

{
    KLOCK_QUEUE_HANDLE LockHandle;
    PVACB *OldAddresses;
    PVACB *NewAddresses;
    ULONG OldSize;
    ULONG NewSize, SizeToAllocate;
    LARGE_INTEGER NextLevelSize;
    LOGICAL GrowingBcbListHeads = FALSE, CreateReference = FALSE;

    //
    //  The following limit is greater than the MM limit
    //  (i.e., MM actually only supports even smaller sections).
    //  We have to reject the sign bit, and testing the high byte
    //  for nonzero will surely only catch errors.
    //

    if (NewSectionSize.HighPart & ~(PAGE_SIZE - 1)) {
        return STATUS_SECTION_TOO_BIG;
    }

    //
    //  See if we will be growing the Bcb ListHeads, so we can take out the
    //  master lock if so.
    //

    if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) &&
        (NewSectionSize.QuadPart > BEGIN_BCB_LIST_ARRAY)) {

        GrowingBcbListHeads = TRUE;
    }

    //
    //  Is there any work to do?
    //

    if (NewSectionSize.QuadPart > SharedCacheMap->SectionSize.QuadPart) {

        //
        //  Handle the growth of the first level here.
        //

        if (SharedCacheMap->SectionSize.QuadPart < VACB_SIZE_OF_FIRST_LEVEL) {

            NextLevelSize = NewSectionSize;

            //
            //  Limit the growth of this level
            //

            if (NextLevelSize.QuadPart >= VACB_SIZE_OF_FIRST_LEVEL) {
                NextLevelSize.QuadPart = VACB_SIZE_OF_FIRST_LEVEL;
                CreateReference = TRUE;
            }

            //
            //  N.B.: SizeOfVacbArray only calculates the size of the VACB
            //  pointer block.  We must adjust for Bcb listheads and the
            //  multilevel reference count.
            //

            NewSize = SizeToAllocate = SizeOfVacbArray(NextLevelSize);
            OldSize = SizeOfVacbArray(SharedCacheMap->SectionSize);

            //
            //  Only do something if the size is growing.
            //

            if (NewSize > OldSize) {

                //
                //  Does this stream get a Bcb Listhead array?
                //

                if (GrowingBcbListHeads) {
                    SizeToAllocate *= 2;
                }

                //
                //  Do we need space for the reference count?
                //

                if (CreateReference) {
                    SizeToAllocate += sizeof(VACB_LEVEL_REFERENCE);
                }

                NewAddresses = ExAllocatePoolWithTag( NonPagedPool, SizeToAllocate, 'pVcC' );
                if (NewAddresses == NULL) {
                    return STATUS_INSUFFICIENT_RESOURCES;
                }

                //
                //  See if we will be growing the Bcb ListHeads, so we can take out the
                //  master lock if so.
                //

                if (GrowingBcbListHeads) {

                    KeAcquireInStackQueuedSpinLock( &SharedCacheMap->BcbSpinLock, &LockHandle );
                    CcAcquireVacbLockAtDpcLevel();

                } else {

                    //
                    //  Acquire the spin lock to serialize with anyone who might like
                    //  to "steal" one of the mappings we are going to move.
                    //

                    CcAcquireVacbLock( &LockHandle.OldIrql );
                }

                OldAddresses = SharedCacheMap->Vacbs;
                if (OldAddresses != NULL) {
                    RtlCopyMemory( NewAddresses, OldAddresses, OldSize );
                } else {
                    OldSize = 0;
                }

                RtlZeroMemory( (PCHAR)NewAddresses + OldSize, NewSize - OldSize );

                if (CreateReference) {

                    SizeToAllocate -= sizeof(VACB_LEVEL_REFERENCE);
                    RtlZeroMemory( (PCHAR)NewAddresses + SizeToAllocate, sizeof(VACB_LEVEL_REFERENCE) );
                }

                //
                //  See if we have to initialize Bcb Listheads.
                //

                if (GrowingBcbListHeads) {

                    LARGE_INTEGER Offset;
                    PLIST_ENTRY BcbListHeadNew, TempEntry;

                    Offset.QuadPart = 0;
                    BcbListHeadNew = (PLIST_ENTRY)((PCHAR)NewAddresses + NewSize );

                    //
                    //  Handle case where the old array had Bcb Listheads.
                    //

                    if ((SharedCacheMap->SectionSize.QuadPart > BEGIN_BCB_LIST_ARRAY) &&
                        (OldAddresses != NULL)) {

                        PLIST_ENTRY BcbListHeadOld;

                        BcbListHeadOld = (PLIST_ENTRY)((PCHAR)OldAddresses + OldSize);

                        //
                        //  Loop to remove each old listhead and insert the new one
                        //  in its place.
                        //

                        do {
                            TempEntry = BcbListHeadOld->Flink;
                            RemoveEntryList( BcbListHeadOld );
                            InsertTailList( TempEntry, BcbListHeadNew );
                            Offset.QuadPart += SIZE_PER_BCB_LIST;
                            BcbListHeadOld += 1;
                            BcbListHeadNew += 1;
                        } while (Offset.QuadPart < SharedCacheMap->SectionSize.QuadPart);

                    //
                    //  Otherwise, handle the case where we are adding Bcb
                    //  Listheads.
                    //

                    } else {

                        TempEntry = SharedCacheMap->BcbList.Blink;

                        //
                        //  Loop through any/all Bcbs to insert the new listheads.
                        //

                        while (TempEntry != &SharedCacheMap->BcbList) {

                            //
                            //  Sit on this Bcb until we have inserted all listheads
                            //  that go before it.
                            //

                            while (Offset.QuadPart <= ((PBCB)CONTAINING_RECORD(TempEntry, BCB, BcbLinks))->FileOffset.QuadPart) {

                                InsertHeadList(TempEntry, BcbListHeadNew);
                                Offset.QuadPart += SIZE_PER_BCB_LIST;
                                BcbListHeadNew += 1;
                            }
                            TempEntry = TempEntry->Blink;
                        }
                    }

                    //
                    //  Now insert the rest of the new listhead entries that were
                    //  not finished in either loop above.
                    //

                    while (Offset.QuadPart < NextLevelSize.QuadPart) {

                        InsertHeadList(&SharedCacheMap->BcbList, BcbListHeadNew);
                        Offset.QuadPart += SIZE_PER_BCB_LIST;
                        BcbListHeadNew += 1;
                    }
                }

                //
                //  These two fields must be changed while still holding the spinlock.
                //

                SharedCacheMap->Vacbs = NewAddresses;
                SharedCacheMap->SectionSize = NextLevelSize;

                //
                //  Now we can free the spinlocks ahead of freeing pool.
                //

                if (GrowingBcbListHeads) {
                    CcReleaseVacbLockFromDpcLevel();
                    KeReleaseInStackQueuedSpinLock( &LockHandle );
                } else {
                    CcReleaseVacbLock( LockHandle.OldIrql );
                }

                if ((OldAddresses != &SharedCacheMap->InitialVacbs[0]) &&
                    (OldAddresses != NULL)) {
                    ExFreePool( OldAddresses );
                }
            }

            //
            //  Make sure SectionSize gets updated.  It is ok to fall through here
            //  without a spinlock, so long as either Vacbs was not changed, or it
            //  was changed together with SectionSize under the spinlock(s) above.
            //

            SharedCacheMap->SectionSize = NextLevelSize;
        }

        //
        //  Handle extends up to and within multi-level Vacb arrays here.  This is fairly simple.
        //  If no additional Vacb levels are required, then there is no work to do, otherwise
        //  we just have to push the root one or more levels linked through the first pointer
        //  in the new root(s).
        //

        if (NewSectionSize.QuadPart > SharedCacheMap->SectionSize.QuadPart) {

            PVACB *NextVacbArray;
            ULONG NewLevel;
            ULONG Level = 1;
            ULONG Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;

            //
            //  Loop to calculate how many levels we currently have.
            //

            while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift)) {

                Level += 1;
                Shift += VACB_LEVEL_SHIFT;
            }

            NewLevel = Level;

            //
            //  Loop to calculate how many levels we need.
            //

            while (((NewSectionSize.QuadPart - 1) >> Shift) != 0) {

                NewLevel += 1;
                Shift += VACB_LEVEL_SHIFT;
            }

            //
            //  Now see if we have any work to do.
            //

            if (NewLevel > Level) {

                //
                //  Remember the maximum level ever seen (which is actually NewLevel + 1).
                //

                if (NewLevel >= CcMaxVacbLevelsSeen) {
                    ASSERT(NewLevel <= VACB_NUMBER_OF_LEVELS);
                    CcMaxVacbLevelsSeen = NewLevel + 1;
                }

                //
                //  Raise if we cannot preallocate enough buffers.
                //

                if (!CcPrefillVacbLevelZone( NewLevel - Level, &LockHandle.OldIrql, FALSE )) {

                    return STATUS_INSUFFICIENT_RESOURCES;
                }

                //
                //  Now if the current Level of the file is 1, we have not been maintaining
                //  a reference count, so we have to calculate it before pushing.  In the
                //  boundary case we have made sure that the reference space is available.
                //

                if (Level == 1) {

                    //
                    //  We know this is always a leaf-like level right now.
                    //

                    CcCalculateVacbLevelLockCount( SharedCacheMap, SharedCacheMap->Vacbs, 0 );
                }

                //
                //  Finally, if there are any active pointers in the first level, then we
                //  have to create new levels by adding a new root enough times to create
                //  additional levels.  On the other hand, if the pointer count in the top
                //  level is zero, then we must not do any pushes, because we never allow
                //  empty leaves!
                //

                if (IsVacbLevelReferenced( SharedCacheMap, SharedCacheMap->Vacbs, Level - 1 )) {

                    while (NewLevel > Level++) {

                        ASSERT(CcVacbLevelEntries != 0);
                        NextVacbArray = CcAllocateVacbLevel(FALSE);

                        NextVacbArray[0] = (PVACB)SharedCacheMap->Vacbs;
                        ReferenceVacbLevel( SharedCacheMap, NextVacbArray, Level, 1, FALSE );

                        SharedCacheMap->Vacbs = NextVacbArray;
                    }

                } else {

                    //
                    //  We are now possesed of the additional problem that this level has no
                    //  references but may have Bcb listheads due to the boundary case where
                    //  we have expanded up to the multilevel Vacbs above.  This level can't
                    //  remain at the root and needs to be destroyed.  What we need to do is
                    //  replace it with one of our prefilled (non Bcb) levels and unlink the
                    //  Bcb listheads in the old one.
                    //

                    if (Level == 1 && FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {

                        PLIST_ENTRY PredecessorListHead, SuccessorListHead;

                        NextVacbArray = SharedCacheMap->Vacbs;
                        SharedCacheMap->Vacbs = CcAllocateVacbLevel(FALSE);

                        PredecessorListHead = ((PLIST_ENTRY)((PCHAR)NextVacbArray + VACB_LEVEL_BLOCK_SIZE))->Flink;
                        SuccessorListHead = ((PLIST_ENTRY)((PCHAR)NextVacbArray + (VACB_LEVEL_BLOCK_SIZE * 2) - sizeof(LIST_ENTRY)))->Blink;
                        PredecessorListHead->Blink = SuccessorListHead;
                        SuccessorListHead->Flink = PredecessorListHead;

                        CcDeallocateVacbLevel( NextVacbArray, TRUE );
                    }
                }

                //
                //  These two fields (Vacbs and SectionSize) must be changed while still
                //  holding the spinlock.
                //

                SharedCacheMap->SectionSize = NewSectionSize;
                CcReleaseVacbLock( LockHandle.OldIrql );
            }

            //
            //  Make sure SectionSize gets updated.  It is ok to fall through here
            //  without a spinlock, so long as either Vacbs was not changed, or it
            //  was changed together with SectionSize under the spinlock(s) above.
            //

            SharedCacheMap->SectionSize = NewSectionSize;
        }
    }
    return STATUS_SUCCESS;
}


BOOLEAN
FASTCALL
CcUnmapVacbArray (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PLARGE_INTEGER FileOffset OPTIONAL,
    IN ULONG Length,
    IN BOOLEAN UnmapBehind
    )

/*++

Routine Description:

    This routine must be called to do any unmapping and associated
    cleanup for a shared cache map, just before it is deleted.

Arguments:

    SharedCacheMap - Supplies a pointer to the shared cache map
                     which is about to be deleted.

    FileOffset - If supplied, only unmap the specified offset and length

    Length - Completes range to unmap if FileOffset specified.  If FileOffset
             is specified, Length of 0 means unmap to the end of the section.

    UnmapBehind - If this is a result of our unmap behind logic

Return Value:

    FALSE -- if an the unmap was not done due to an active vacb
    TRUE -- if the unmap was done

--*/

{
    PVACB Vacb;
    KIRQL OldIrql;
    LARGE_INTEGER StartingFileOffset = {0,0};
    LARGE_INTEGER EndingFileOffset = SharedCacheMap->SectionSize;

    //
    //  We could be just cleaning up for error recovery.
    //

    if (SharedCacheMap->Vacbs == NULL) {
        return TRUE;
    }

    //
    //  See if a range was specified. Align it to the VACB boundaries so it
    //  works in the loop below
    //

    if (ARGUMENT_PRESENT(FileOffset)) {
        StartingFileOffset.QuadPart = ((FileOffset->QuadPart) & (~((LONGLONG)VACB_MAPPING_GRANULARITY - 1)));
        if (Length != 0) {

            EndingFileOffset.QuadPart = FileOffset->QuadPart + Length;

        }
    }

    //
    //  Acquire the spin lock to
    //

    CcAcquireVacbLock( &OldIrql );

    while (StartingFileOffset.QuadPart < EndingFileOffset.QuadPart) {

        //
        //  Note that the caller with an explicit range may be off the
        //  end of the section (example CcPurgeCacheSection for cache
        //  coherency).  That is the reason for the first part of the
        //  test below.
        //
        //  Check the next cell once without the spin lock, it probably will
        //  not change, but we will handle it if it does not.
        //

        if ((StartingFileOffset.QuadPart < SharedCacheMap->SectionSize.QuadPart) &&
            ((Vacb = GetVacb( SharedCacheMap, StartingFileOffset )) != NULL)) {

            //
            //  Return here if we are unlucky and see an active
            //  Vacb.  It could be Purge calling, and the Lazy Writer
            //  may have done a CcGetVirtualAddressIfMapped!
            //

            if (Vacb->Overlay.ActiveCount != 0) {

                CcReleaseVacbLock( OldIrql );
                return FALSE;
            }

            //
            //  Unlink it from the other SharedCacheMap, so the other
            //  guy will not try to use it when we free the spin lock.
            //

            SetVacb( SharedCacheMap, StartingFileOffset, NULL );
            Vacb->SharedCacheMap = NULL;

            //
            //  Increment the open count so that no one else will
            //  try to unmap or reuse until we are done.
            //

            Vacb->Overlay.ActiveCount += 1;

            //
            //  Release the spin lock.
            //

            CcReleaseVacbLock( OldIrql );

            //
            //  Unmap and free it if we really got it above.
            //

            CcUnmapVacb( Vacb, SharedCacheMap, UnmapBehind );

            //
            //  Reacquire the spin lock so that we can decrment the count.
            //

            CcAcquireVacbLock( &OldIrql );
            Vacb->Overlay.ActiveCount -= 1;

            //
            //  Place this VACB at the head of the LRU
            //

            CcMoveVacbToReuseFree( Vacb );
        }

        StartingFileOffset.QuadPart = StartingFileOffset.QuadPart + VACB_MAPPING_GRANULARITY;
    }

    CcReleaseVacbLock( OldIrql );

    CcDrainVacbLevelZone();

    return TRUE;
}


ULONG
CcPrefillVacbLevelZone (
    IN ULONG NumberNeeded,
    OUT PKIRQL OldIrql,
    IN ULONG NeedBcbListHeads
    )

/*++

Routine Description:

    This routine may be called to prefill the VacbLevelZone with the number of
    entries required, and return with CcVacbSpinLock acquired.  This approach is
    taken so that the pool allocations and RtlZeroMemory calls can occur without
    holding any spinlock, yet the caller may proceed to peform a single indivisible
    operation without error handling, since there is a guaranteed minimum number of
    entries in the zone.

Arguments:

    NumberNeeded - Number of VacbLevel entries needed, not counting the possible
                   one with Bcb listheads.

    OldIrql = supplies a pointer to where OldIrql should be returned upon acquiring
              the spinlock.

    NeedBcbListHeads - Supplies true if a level is also needed which contains listheads.

Return Value:

    FALSE if the buffers could not be preallocated, TRUE otherwise.

Environment:

    No spinlocks should be held upon entry.

--*/

{
    PVACB *NextVacbArray;

    CcAcquireVacbLock( OldIrql );

    //
    //  Loop until there is enough entries, else return failure...
    //

    while ((NumberNeeded > CcVacbLevelEntries) ||
           (NeedBcbListHeads && (CcVacbLevelWithBcbsFreeList == NULL))) {


        //
        //  Else release the spinlock so we can do the allocate/zero.
        //

        CcReleaseVacbLock( *OldIrql );

        //
        //  First handle the case where we need a VacbListHead with Bcb Listheads.
        //  The pointer test is unsafe but see below.
        //

        if (NeedBcbListHeads && (CcVacbLevelWithBcbsFreeList == NULL)) {

            //
            //  Allocate and initialize the Vacb block for this level, and store its pointer
            //  back into our parent.  We do not zero the listhead area.
            //

            NextVacbArray =
            (PVACB *)ExAllocatePoolWithTag( NonPagedPool, (VACB_LEVEL_BLOCK_SIZE * 2) + sizeof(VACB_LEVEL_REFERENCE), 'lVcC' );

            if (NextVacbArray == NULL) {
                return FALSE;
            }

            RtlZeroMemory( (PCHAR)NextVacbArray, VACB_LEVEL_BLOCK_SIZE );
            RtlZeroMemory( (PCHAR)NextVacbArray + (VACB_LEVEL_BLOCK_SIZE * 2), sizeof(VACB_LEVEL_REFERENCE) );

            CcAcquireVacbLock( OldIrql );

            NextVacbArray[0] = (PVACB)CcVacbLevelWithBcbsFreeList;
            CcVacbLevelWithBcbsFreeList = NextVacbArray;
            CcVacbLevelWithBcbsEntries += 1;

        } else {

            //
            //  Allocate and initialize the Vacb block for this level, and store its pointer
            //  back into our parent.
            //

            NextVacbArray =
            (PVACB *)ExAllocatePoolWithTag( NonPagedPool, VACB_LEVEL_BLOCK_SIZE + sizeof(VACB_LEVEL_REFERENCE), 'lVcC' );

            if (NextVacbArray == NULL) {
                return FALSE;
            }

            RtlZeroMemory( (PCHAR)NextVacbArray, VACB_LEVEL_BLOCK_SIZE + sizeof(VACB_LEVEL_REFERENCE) );

            CcAcquireVacbLock( OldIrql );

            NextVacbArray[0] = (PVACB)CcVacbLevelFreeList;
            CcVacbLevelFreeList = NextVacbArray;
            CcVacbLevelEntries += 1;
        }
    }

    return TRUE;
}


VOID
CcDrainVacbLevelZone (
    )

/*++

Routine Description:

    This routine should be called any time some entries have been deallocated to
    the VacbLevel zone, and we want to insure the zone is returned to a normal level.

Arguments:

Return Value:

    None.

Environment:

    No spinlocks should be held upon entry.

--*/

{
    KIRQL OldIrql;
    PVACB *NextVacbArray;

    //
    //  This is an unsafe loop to see if it looks like there is stuff to
    //  clean up.
    //

    while ((CcVacbLevelEntries > (CcMaxVacbLevelsSeen * 4)) ||
           (CcVacbLevelWithBcbsEntries > 2)) {

        //
        //  Now go in and try to pick up one entry to free under a FastLock.
        //

        NextVacbArray = NULL;
        CcAcquireVacbLock( &OldIrql );
        if (CcVacbLevelEntries > (CcMaxVacbLevelsSeen * 4)) {
            NextVacbArray = CcVacbLevelFreeList;
            CcVacbLevelFreeList = (PVACB *)NextVacbArray[0];
            CcVacbLevelEntries -= 1;
        } else if (CcVacbLevelWithBcbsEntries > 2) {
            NextVacbArray = CcVacbLevelWithBcbsFreeList;
            CcVacbLevelWithBcbsFreeList = (PVACB *)NextVacbArray[0];
            CcVacbLevelWithBcbsEntries -= 1;
        }
        CcReleaseVacbLock( OldIrql );

        //
        //  Since the loop is unsafe, we may not have gotten anything.
        //

        if (NextVacbArray != NULL) {
            ExFreePool(NextVacbArray);
        }
    }
}


PLIST_ENTRY
CcGetBcbListHeadLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN BOOLEAN FailToSuccessor
    )

/*++

Routine Description:

    This routine may be called to return the Bcb listhead for the specified FileOffset.
    It should only be called if the SectionSize is greater than VACB_SIZE_OF_FIRST_LEVEL.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the listhead
                     is desired.

    FileOffset - Supplies the fileOffset corresponding to the desired listhead.

    FailToSuccessor - Instructs whether not finding the exact listhead should cause us to
        return the predecessor or successor Bcb listhead.

Return Value:

    Returns the desired Listhead pointer.  If the desired listhead does not actually exist
    yet, then it returns the appropriate listhead.

Environment:

    The BcbSpinlock should be held on entry.

--*/

{
    ULONG Level, Shift;
    PVACB *VacbArray, *NextVacbArray;
    ULONG Index;
    ULONG SavedIndexes[VACB_NUMBER_OF_LEVELS];
    PVACB *SavedVacbArrays[VACB_NUMBER_OF_LEVELS];
    ULONG SavedLevels = 0;

    //
    //  Initialize variables controlling our descent into the hierarchy.
    //

    Level = 0;
    Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;
    VacbArray = SharedCacheMap->Vacbs;

    //
    //  Caller must have verified that we have a hierarchy, otherwise this routine
    //  would fail.
    //

    ASSERT(SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL);

    //
    //  Loop to calculate how many levels we have and how much we have to
    //  shift to index into the first level.
    //

    do {

        Level += 1;
        Shift += VACB_LEVEL_SHIFT;

    } while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift));

    //
    //  Our caller could be asking for an offset off the end of section size, so if he
    //  is actually off the size of the level, then return the main listhead.
    //

    if (FileOffset >= ((LONGLONG)1 << Shift)) {
        return &SharedCacheMap->BcbList;
    }

    //
    //  Now descend the tree to the bottom level to get the caller's Bcb ListHead.
    //

    Shift -= VACB_LEVEL_SHIFT;
    do {

        //
        //  Decrement back to the level that describes the size we are within.
        //

        Level -= 1;

        //
        //  Calculate the index into the Vacb block for this level.
        //

        Index = (ULONG)(FileOffset >> Shift);
        ASSERT(Index <= VACB_LAST_INDEX_FOR_LEVEL);

        //
        //  Get block address for next level.
        //

        NextVacbArray = (PVACB *)VacbArray[Index];

        //
        //  If it is NULL then we have to go find the highest Bcb or listhead which
        //  comes before the guy we are looking for, i.e., its predecessor.
        //

        if (NextVacbArray == NULL) {

            //
            //  Back up to look for the highest guy earlier in this tree, i.e., the
            //  predecessor listhead.
            //

            while (TRUE) {

                //
                //  Scan, if we can, in the current array for a non-null index.
                //

                if (FailToSuccessor) {

                    if (Index != VACB_LAST_INDEX_FOR_LEVEL) {

                        while ((Index != VACB_LAST_INDEX_FOR_LEVEL) && (VacbArray[++Index] == NULL)) {
                            continue;
                        }

                        //
                        //  If we found a non-null index, get out and try to return the
                        //  listhead.
                        //

                        if ((NextVacbArray = (PVACB *)VacbArray[Index]) != NULL) {
                            break;
                        }
                    }

                } else {

                    if (Index != 0) {

                        while ((Index != 0) && (VacbArray[--Index] == NULL)) {
                            continue;
                        }

                        //
                        //  If we found a non-null index, get out and try to return the
                        //  listhead.
                        //

                        if ((NextVacbArray = (PVACB *)VacbArray[Index]) != NULL) {
                            break;
                        }
                    }
                }

                //
                //  If there are no saved levels yet, then there is no predecessor or
                //  successor - it is the main listhead.
                //

                if (SavedLevels == 0) {
                    return &SharedCacheMap->BcbList;
                }

                //
                //  Otherwise, we can pop up a level in the tree and start scanning
                //  from that guy for a path to the right listhead.
                //

                Level += 1;
                Index = SavedIndexes[--SavedLevels];
                VacbArray = SavedVacbArrays[SavedLevels];
            }

            //
            //  We have backed up in the hierarchy, so now we are just looking for the
            //  highest/lowest guy in the level we want, i.e., the level-linking listhead.
            //  So smash FileOffset accordingly (we mask the high bits out anyway).
            //

            if (FailToSuccessor) {
                FileOffset = 0;
            } else {
                FileOffset = MAXLONGLONG;
            }
        }

        //
        //  We save Index and VacbArray at each level, for the case that we
        //  have to walk back up the tree to find a predecessor.
        //

        SavedIndexes[SavedLevels] = Index;
        SavedVacbArrays[SavedLevels] = VacbArray;
        SavedLevels += 1;

        //
        //  Now make this one our current pointer, and mask away the extraneous high-order
        //  FileOffset bits for this level.
        //

        VacbArray = NextVacbArray;
        FileOffset &= ((LONGLONG)1 << Shift) - 1;
        Shift -= VACB_LEVEL_SHIFT;

    //
    //  Loop until we hit the bottom level.
    //

    } while (Level != 0);

    //
    //  Now calculate the index for the bottom level and return the appropriate listhead.
    //  (The normal Vacb index indexes to a pointer to a Vacb for a .25MB view, so dropping
    //  the low bit gets you to the even-indexed Vacb pointer which is one block size below
    //  the two-pointer listhead for the Bcbs for that .5MB range...)
    //

    Index = (ULONG)(FileOffset >> Shift);
    return (PLIST_ENTRY)((PCHAR)&VacbArray[Index & ~1] + VACB_LEVEL_BLOCK_SIZE);
}


VOID
CcAdjustVacbLevelLockCount (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN LONG Adjustment
    )

/*++

Routine Description:

    This routine may be called to adjust the lock count of the bottom Vacb level when
    Bcbs are inserted or deleted.  If the count goes to zero, the level will be
    eliminated.  The bottom level must exist, or we crash!

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the Vacb
                     is desired.

    FileOffset - Supplies the fileOffset corresponding to the desired Vacb.

    Adjustment - Generally -1 or +1.

Return Value:

    None.

Environment:

    CcVacbSpinLock should be held on entry.

--*/

{
    ULONG Level, Shift;
    PVACB *VacbArray;
    LONGLONG OriginalFileOffset = FileOffset;

    //
    //  Initialize variables controlling our descent into the hierarchy.
    //

    Level = 0;
    Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;

    VacbArray = SharedCacheMap->Vacbs;

    //
    //  Caller must have verified that we have a hierarchy, otherwise this routine
    //  would fail.
    //

    ASSERT(SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL);

    //
    //  Loop to calculate how many levels we have and how much we have to
    //  shift to index into the first level.
    //

    do {

        Level += 1;
        Shift += VACB_LEVEL_SHIFT;

    } while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift));

    //
    //  Now descend the tree to the bottom level to get the caller's Vacb.
    //

    Shift -= VACB_LEVEL_SHIFT;
    do {

        VacbArray = (PVACB *)VacbArray[(ULONG)(FileOffset >> Shift)];

        Level -= 1;

        FileOffset &= ((LONGLONG)1 << Shift) - 1;

        Shift -= VACB_LEVEL_SHIFT;

    } while (Level != 0);

    //
    //  Now we have reached the final level, do the adjustment.
    //

    ReferenceVacbLevel( SharedCacheMap, VacbArray, Level, Adjustment, FALSE );

    //
    //  Now, if we decremented the count to 0, then force the collapse to happen by
    //  upping count and resetting to NULL.  Then smash OriginalFileOffset to be
    //  the first entry so we do not recalculate!
    //

    if (!IsVacbLevelReferenced( SharedCacheMap, VacbArray, Level )) {
        ReferenceVacbLevel( SharedCacheMap, VacbArray, Level, 1, TRUE );
        OriginalFileOffset &= ~(VACB_SIZE_OF_FIRST_LEVEL - 1);
        CcSetVacbLargeOffset( SharedCacheMap, OriginalFileOffset, VACB_SPECIAL_DEREFERENCE );
    }
}


VOID
CcCalculateVacbLevelLockCount (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN PVACB *VacbArray,
    IN ULONG Level
    )

/*++

Routine Description:

    This routine may be called to calculate or recalculate the lock count on a
    given Vacb level array.  It is called, for example, when we are extending a
    section up to the point where we activate multilevel logic and want to start
    keeping the count.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the Vacb
                     is desired.

    VacbArray - The Vacb Level array to recalculate

    Level - Supplies 0 for the bottom level, nonzero otherwise.

Return Value:

    None.

Environment:

    CcVacbSpinLock should be held on entry.

--*/

{
    PBCB Bcb;
    ULONG Index;
    LONG Count = 0;
    PVACB *VacbTemp = VacbArray;
    PVACB_LEVEL_REFERENCE VacbReference;

    //
    //  First loop through to count how many Vacb pointers are in use.
    //

    for (Index = 0; Index <= VACB_LAST_INDEX_FOR_LEVEL; Index++) {
        if (*(VacbTemp++) != NULL) {
            Count += 1;
        }
    }

    //
    //  If this is a metadata stream, we also have to count the Bcbs in the
    //  corresponding listheads.
    //

    if (FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) && (Level == 0)) {

        //
        //  Pick up the Blink of the first listhead, casting it to a Bcb.
        //

        Bcb = (PBCB)CONTAINING_RECORD(((PLIST_ENTRY)VacbTemp)->Blink, BCB, BcbLinks);
        Index = 0;

        //
        //  Now loop through the list.  For each Bcb we see, increment the count,
        //  and for each listhead, increment Index.  We are done when we hit the
        //  last listhead, which is actually the next listhead past the ones in this
        //  block.
        //

        do {

            if (Bcb->NodeTypeCode == CACHE_NTC_BCB) {
                Count += 1;
            } else {
                Index += 1;
            }

            Bcb = (PBCB)CONTAINING_RECORD(Bcb->BcbLinks.Blink, BCB, BcbLinks);

        } while (Index <= (VACB_LAST_INDEX_FOR_LEVEL / 2));
    }

    //
    //  Store the count and get out... (by hand, don't touch the special count)
    //

    VacbReference = VacbLevelReference( SharedCacheMap, VacbArray, Level );
    VacbReference->Reference = Count;
}


PVACB
CcGetVacbLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset
    )

/*++

Routine Description:

    This routine may be called to return the Vacb for the specified FileOffset.
    It should only be called if the SectionSize is greater than VACB_SIZE_OF_FIRST_LEVEL.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the Vacb
                     is desired.

    FileOffset - Supplies the fileOffset corresponding to the desired Vacb.

Return Value:

    Returns the desired Vacb pointer or NULL if there is none.

Environment:

    CcVacbSpinLock should be held on entry.

--*/

{
    ULONG Level, Shift;
    PVACB *VacbArray;
    PVACB Vacb;

    //
    //  Initialize variables controlling our descent into the hierarchy.
    //

    Level = 0;
    Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;
    VacbArray = SharedCacheMap->Vacbs;

    //
    //  Caller must have verified that we have a hierarchy, otherwise this routine
    //  would fail.
    //

    ASSERT(SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL);

    //
    //  Loop to calculate how many levels we have and how much we have to
    //  shift to index into the first level.
    //

    do {

        Level += 1;
        Shift += VACB_LEVEL_SHIFT;

    } while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift));

    //
    //  Now descend the tree to the bottom level to get the caller's Vacb.
    //

    Shift -= VACB_LEVEL_SHIFT;
    while (((Vacb = (PVACB)VacbArray[FileOffset >> Shift]) != NULL) && (Level != 0)) {

        Level -= 1;

        VacbArray = (PVACB *)Vacb;
        FileOffset &= ((LONGLONG)1 << Shift) - 1;

        Shift -= VACB_LEVEL_SHIFT;
    }

    //
    //  If the Vacb we exited with is not NULL, we want to make sure it looks OK.
    //

    ASSERT(Vacb == NULL || ((Vacb >= CcVacbs) && (Vacb < CcBeyondVacbs)));

    return Vacb;
}


VOID
CcSetVacbLargeOffset (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN LONGLONG FileOffset,
    IN PVACB Vacb
    )

/*++

Routine Description:

    This routine may be called to set the specified Vacb pointer for the specified FileOffset.
    It should only be called if the SectionSize is greater than VACB_SIZE_OF_FIRST_LEVEL.

    For non-null Vacb, intermediate Vacb levels will be added as necessary, and if the lowest
    level has Bcb listheads, these will also be added.  For this case the caller must acquire
    the spinlock by calling CcPrefillVacbLevelZone specifying the worst-case number of levels
    required.

    For a null Vacb pointer, the tree is pruned of all Vacb levels that go empty.  If the lowest
    level has Bcb listheads, then they are removed.  The caller should subsequently call
    CcDrainVacbLevelZone once the spinlock is release to actually free some of this zone to the
    pool.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the Vacb
                     is desired.

    FileOffset - Supplies the fileOffset corresponding to the desired Vacb.

Return Value:

    Returns the desired Vacb pointer or NULL if there is none.

Environment:

    CcVacbSpinLock should be held on entry.

--*/

{
    ULONG Level, Shift;
    PVACB *VacbArray, *NextVacbArray;
    ULONG Index;
    ULONG SavedIndexes[VACB_NUMBER_OF_LEVELS];
    PVACB *SavedVacbArrays[VACB_NUMBER_OF_LEVELS];
    PLIST_ENTRY PredecessorListHead, SuccessorListHead, CurrentListHead;
    LOGICAL AllocatingBcbListHeads, Special = FALSE;
    LONGLONG OriginalFileOffset = FileOffset;
    ULONG SavedLevels = 0;

    //
    //  Initialize variables controlling our descent into the hierarchy.
    //

    Level = 0;
    Shift = VACB_OFFSET_SHIFT + VACB_LEVEL_SHIFT;
    VacbArray = SharedCacheMap->Vacbs;

    //
    //  Caller must have verified that we have a hierarchy, otherwise this routine
    //  would fail.
    //

    ASSERT(SharedCacheMap->SectionSize.QuadPart > VACB_SIZE_OF_FIRST_LEVEL);

    //
    //  Loop to calculate how many levels we have and how much we have to
    //  shift to index into the first level.
    //

    do {

        Level += 1;
        Shift += VACB_LEVEL_SHIFT;

    } while (SharedCacheMap->SectionSize.QuadPart > ((LONGLONG)1 << Shift));

    //
    //  Now descend the tree to the bottom level to set the caller's Vacb.
    //

    Shift -= VACB_LEVEL_SHIFT;
    do {

        //
        //  Decrement back to the level that describes the size we are within.
        //

        Level -= 1;

        //
        //  Calculate the index into the Vacb block for this level.
        //

        Index = (ULONG)(FileOffset >> Shift);
        ASSERT(Index <= VACB_LAST_INDEX_FOR_LEVEL);

        //
        //  We save Index and VacbArray at each level, for the case that we
        //  are collapsing and deallocating blocks below.
        //

        SavedIndexes[SavedLevels] = Index;
        SavedVacbArrays[SavedLevels] = VacbArray;
        SavedLevels += 1;

        //
        //  Get block address for next level.
        //

        NextVacbArray = (PVACB *)VacbArray[Index];

        //
        //  If it is NULL then we have to allocate the next level to fill it in.
        //

        if (NextVacbArray == NULL) {

            //
            //  We better not be thinking we're dereferencing a level if the level
            //  doesn't currently exist.
            //

            ASSERT( Vacb != VACB_SPECIAL_DEREFERENCE );

            AllocatingBcbListHeads = FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED) && (Level == 0);

            //
            //  This is only valid if we are setting a nonzero pointer!
            //

            ASSERT(Vacb != NULL);

            NextVacbArray = CcAllocateVacbLevel(AllocatingBcbListHeads);

            //
            //  If we allocated Bcb Listheads, we must link them in.
            //

            if (AllocatingBcbListHeads) {

                ULONG i;

                //
                //  Find our predecessor.
                //

                PredecessorListHead = CcGetBcbListHeadLargeOffset( SharedCacheMap, OriginalFileOffset, FALSE );

                //
                //  If he is followed by any Bcbs, they "belong" to him, and we have to
                //  skip over them.
                //

                while (((PBCB)CONTAINING_RECORD(PredecessorListHead->Blink, BCB, BcbLinks))->NodeTypeCode ==
                       CACHE_NTC_BCB) {
                    PredecessorListHead = (PLIST_ENTRY)PredecessorListHead->Blink;
                }

                //
                //  Point to the first newly allocated listhead.
                //

                CurrentListHead = (PLIST_ENTRY)((PCHAR)NextVacbArray + VACB_LEVEL_BLOCK_SIZE);

                //
                //  Link first new listhead to predecessor.
                //

                SuccessorListHead = PredecessorListHead->Blink;
                PredecessorListHead->Blink = CurrentListHead;
                CurrentListHead->Flink = PredecessorListHead;

                //
                //  Now loop to link all of the new listheads together.
                //

                for (i = 0; i < ((VACB_LEVEL_BLOCK_SIZE / sizeof(LIST_ENTRY) - 1)); i++) {

                    CurrentListHead->Blink = CurrentListHead + 1;
                    CurrentListHead += 1;
                    CurrentListHead->Flink = CurrentListHead - 1;
                }

                //
                //  Finally link the last new listhead to the successor.
                //

                CurrentListHead->Blink = SuccessorListHead;
                SuccessorListHead->Flink = CurrentListHead;
            }

            VacbArray[Index] = (PVACB)NextVacbArray;

            //
            //  Increment the reference count.  Note that Level right now properly indicates
            //  what level NextVacbArray is at, not VacbArray.
            //

            ReferenceVacbLevel( SharedCacheMap, VacbArray, Level + 1, 1, FALSE );
        }

        //
        //  Now make this one our current pointer, and mask away the extraneous high-order
        //  FileOffset bits for this level and reduce the shift count.
        //

        VacbArray = NextVacbArray;
        FileOffset &= ((LONGLONG)1 << Shift) - 1;
        Shift -= VACB_LEVEL_SHIFT;

    //
    //  Loop until we hit the bottom level.
    //

    } while (Level != 0);

    if (Vacb < VACB_SPECIAL_FIRST_VALID) {

        //
        //  Now calculate the index for the bottom level and store the caller's Vacb pointer.
        //

        Index = (ULONG)(FileOffset >> Shift);
        VacbArray[Index] = Vacb;

    //
    //  Handle the special actions.
    //

    } else {

        Special = TRUE;

        //
        //  Induce the dereference.
        //

        if (Vacb == VACB_SPECIAL_DEREFERENCE) {

            Vacb = NULL;
        }
    }

    //
    //  If he is storing a nonzero pointer, just reference the level.
    //

    if (Vacb != NULL) {

        ASSERT( !(Special && Level != 0) );

        ReferenceVacbLevel( SharedCacheMap, VacbArray, Level, 1, Special );

    //
    //  Otherwise we are storing a NULL pointer, and we have to see if we can collapse
    //  the tree by deallocating empty blocks of pointers.
    //

    } else {

        //
        //  Loop until doing all possible collapse except for the top level.
        //

        while (TRUE) {

            ReferenceVacbLevel( SharedCacheMap, VacbArray, Level, -1, Special );

            //
            //  If this was a special dereference, then recognize that this was
            //  the only one.  The rest, as we tear up the tree, are regular
            //  (calculable) references.
            //

            Special = FALSE;

            //
            //  Now, if we have an empty block (other than the top one), then we should free the
            //  block and keep looping.
            //

            if (!IsVacbLevelReferenced( SharedCacheMap, VacbArray, Level ) && (SavedLevels != 0)) {

                SavedLevels -= 1;

                //
                //  First see if we have Bcb Listheads to delete and if so, we have to unlink
                //  the whole block first.
                //

                AllocatingBcbListHeads = FALSE;
                if ((Level++ == 0) && FlagOn(SharedCacheMap->Flags, MODIFIED_WRITE_DISABLED)) {

                    AllocatingBcbListHeads = TRUE;
                    PredecessorListHead = ((PLIST_ENTRY)((PCHAR)VacbArray + VACB_LEVEL_BLOCK_SIZE))->Flink;
                    SuccessorListHead = ((PLIST_ENTRY)((PCHAR)VacbArray + (VACB_LEVEL_BLOCK_SIZE * 2) - sizeof(LIST_ENTRY)))->Blink;
                    PredecessorListHead->Blink = SuccessorListHead;
                    SuccessorListHead->Flink = PredecessorListHead;
                }

                //
                //  Free the unused block and then pick up the saved parent pointer array and
                //  index and erase the pointer to this block.
                //

                CcDeallocateVacbLevel( VacbArray, AllocatingBcbListHeads );
                Index = SavedIndexes[SavedLevels];
                VacbArray = SavedVacbArrays[SavedLevels];
                VacbArray[Index] = NULL;

            //
            //  No more collapsing if we hit a block that still has pointers, or we hit the root.
            //

            } else {
                break;
            }
        }
    }
}


VOID
CcGetActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    OUT PVACB *Vacb,
    OUT PULONG Page,
    OUT PULONG Dirty
    )

/*++

Routine Description:

    This routine retrieves and clears the active page hint from a shared cache map.

    Originally, this routine is a macro.  To reduce the nonpaged footprint of the
    system we want to page as much as possible, and it turns out this was the only
    reason a substantial part of the cache manager wasn't.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the active
                Vacb is desired.

    Vacb - Receives the active Vacb

    Page - Receives the active Page #

    Dirty - Receives ACTIVE_PAGE_IS_DIRTY if the page has dirty data

Return Value:

    None.

Environment:

    Passive.

--*/

{
    KIRQL Irql;

    ExAcquireFastLock(&SharedCacheMap->ActiveVacbSpinLock, &Irql);
    *Vacb = SharedCacheMap->ActiveVacb;
    if (*Vacb != NULL) {
        *Page = SharedCacheMap->ActivePage;
        SharedCacheMap->ActiveVacb = NULL;
        *Dirty = SharedCacheMap->Flags & ACTIVE_PAGE_IS_DIRTY;
    }
    ExReleaseFastLock(&SharedCacheMap->ActiveVacbSpinLock, Irql);
}


VOID
CcSetActiveVacb (
    IN PSHARED_CACHE_MAP SharedCacheMap,
    IN OUT PVACB *Vacb,
    IN ULONG Page,
    IN ULONG Dirty
    )

/*++

Routine Description:

    This routine sets the active page hint for a shared cache map.

    Originally, this routine is a macro.  To reduce the nonpaged footprint of the
    system we want to page as much as possible, and it turns out this was the only
    reason a substantial part of the cache manager wasn't.

Arguments:

    SharedCacheMap - Supplies the pointer to the SharedCacheMap for which the active
                Vacb is desired.

    Vacb - Supplies the new active Vacb

    Page - Supplies the new active Page #

    Dirty - Supplies ACTIVE_PAGE_IS_DIRTY if the page has dirty data

Return Value:

    None.

Environment:

    Passive.

--*/

{
    KIRQL Irql;

    //
    //  When setting dirty, when we set ACTIVE_PAGE_IS_DIRTY the first time,
    //  we increment the dirty counts, and they never get decremented until
    //  CcFreeActiveVacb.  If we are trying to set and there is already an
    //  active Vacb *or* we are trying to set a clean one and the flag above
    //  is set, we do not allow it, and we just free the vacb (we only want
    //  to handle the clean transition in one place).
    //
    //  MP & UP cases are separately defined, because I do not trust the compiler
    //  to otherwise generate the optimal UP code.
    //

    //
    //  In the MP case, we test if we are setting the page dirty, because then
    //  we must acquire CcMasterSpinLock to diddle CcDirtyPages.
    //

    //
    //  In the UP case, any FastLock will do, so we just use the ActiveVacb lock, and do not
    //  explicitly acquire CcMasterSpinLock.
    //

#if !defined(NT_UP)
    if (Dirty) {
        CcAcquireMasterLock(&Irql);
        ExAcquireSpinLockAtDpcLevel(&SharedCacheMap->ActiveVacbSpinLock);
    } else {
        ExAcquireSpinLock(&SharedCacheMap->ActiveVacbSpinLock, &Irql);
    }
#else
    ExAcquireFastLock(&SharedCacheMap->ActiveVacbSpinLock, &Irql);
#endif

    do {
        if (SharedCacheMap->ActiveVacb == NULL) {
            if ((SharedCacheMap->Flags & ACTIVE_PAGE_IS_DIRTY) != Dirty) {
                if (Dirty) {
                    SharedCacheMap->ActiveVacb = *Vacb;
                    SharedCacheMap->ActivePage = Page;
                    *Vacb = NULL;
                    SetFlag(SharedCacheMap->Flags, ACTIVE_PAGE_IS_DIRTY);
                    CcTotalDirtyPages += 1;
                    SharedCacheMap->DirtyPages += 1;
                    if (SharedCacheMap->DirtyPages == 1) {
                        PLIST_ENTRY Blink;
                        PLIST_ENTRY Entry;
                        PLIST_ENTRY Flink;
                        PLIST_ENTRY Head;
                        Entry = &SharedCacheMap->SharedCacheMapLinks;
                        Blink = Entry->Blink;
                        Flink = Entry->Flink;
                        Blink->Flink = Flink;
                        Flink->Blink = Blink;
                        Head = &CcDirtySharedCacheMapList.SharedCacheMapLinks;
                        Blink = Head->Blink;
                        Entry->Flink = Head;
                        Entry->Blink = Blink;
                        Blink->Flink = Entry;
                        Head->Blink = Entry;
                        if (!LazyWriter.ScanActive) {
                            LazyWriter.ScanActive = TRUE;
#if !defined(NT_UP)
                            ExReleaseSpinLockFromDpcLevel(&SharedCacheMap->ActiveVacbSpinLock);
                            CcReleaseMasterLock(Irql);
#else
                            ExReleaseFastLock(&SharedCacheMap->ActiveVacbSpinLock, Irql);
#endif
                            KeSetTimer( &LazyWriter.ScanTimer,
                                        CcFirstDelay,
                                        &LazyWriter.ScanDpc );
                            break;
                        }
                    }
                }
            } else {
                SharedCacheMap->ActiveVacb = *Vacb;
                SharedCacheMap->ActivePage = Page;
                *Vacb = NULL;
            }
        }
#if !defined(NT_UP)
        if (Dirty) {
            ExReleaseSpinLockFromDpcLevel(&SharedCacheMap->ActiveVacbSpinLock);
            CcReleaseMasterLock(Irql);
        } else {
            ExReleaseSpinLock(&SharedCacheMap->ActiveVacbSpinLock, Irql);
        }
#else
        ExReleaseFastLock(&SharedCacheMap->ActiveVacbSpinLock, Irql);
#endif
        if (*Vacb != NULL) {
            CcFreeActiveVacb( SharedCacheMap, *Vacb, Page, Dirty);
        }
    } while (FALSE);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmchek2.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmchek2.c

Abstract:

    This module implements consistency checking for the registry.


Author:

    Bryan M. Willman (bryanwi) 27-Jan-92

Environment:


Revision History:

--*/

#include    "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpValidateHiveSecurityDescriptors)
#endif

extern ULONG   CmpUsedStorage;

#ifdef HIVE_SECURITY_STATS
ULONG
CmpCheckForSecurityDuplicates(
    IN OUT PCMHIVE      CmHive
                              );
#endif

BOOLEAN
CmpValidateHiveSecurityDescriptors(
    IN PHHIVE       Hive,
    OUT PBOOLEAN    ResetSD
    )
/*++

Routine Description:

    Walks the list of security descriptors present in the hive and passes
    each security descriptor to RtlValidSecurityDescriptor.

    Only applies to descriptors in Stable store.  Those in Volatile store
    cannot have come from disk and therefore do not need this treatment
    anyway.

Arguments:

    Hive - Supplies pointer to the hive control structure

Return Value:

    TRUE  - All security descriptors are valid
    FALSE - At least one security descriptor is invalid

--*/

{
    PCM_KEY_NODE        RootNode;
    PCM_KEY_SECURITY    SecurityCell;
    HCELL_INDEX         ListAnchor;
    HCELL_INDEX         NextCell;
    HCELL_INDEX         LastCell;
    BOOLEAN             BuildSecurityCache;

#ifdef HIVE_SECURITY_STATS
    UNICODE_STRING      HiveName;
    ULONG               NoOfCells = 0;
    ULONG               SmallestSize = 0;
    ULONG               BiggestSize = 0;
    ULONG               TotalSecuritySize = 0;

    RtlInitUnicodeString(&HiveName, (PCWSTR)Hive->BaseBlock->FileName);
#ifndef _CM_LDR_
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Security stats for hive (%lx) (%.*S):\n",Hive,HiveName.Length / sizeof(WCHAR),HiveName.Buffer);
#endif //_CM_LDR_

#endif

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"CmpValidateHiveSecurityDescriptor: Hive = %p\n",(ULONG_PTR)Hive));

    ASSERT( Hive->ReleaseCellRoutine == NULL );

    *ResetSD = FALSE;

    if( ((PCMHIVE)Hive)->SecurityCount == 0 ) {
        BuildSecurityCache = TRUE;
    } else {
        BuildSecurityCache = FALSE;
    }
    if (!HvIsCellAllocated(Hive,Hive->BaseBlock->RootCell)) {
        //
        // root cell HCELL_INDEX is bogus
        //
        return(FALSE);
    }
    RootNode = (PCM_KEY_NODE) HvGetCell(Hive, Hive->BaseBlock->RootCell);
    if( RootNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return FALSE;
    }
    
    if( FALSE ) {
YankSD:
        if( CmDoSelfHeal() ) {
            //
            // reset all security for the entire hive to the root security. There is no reliable way to 
            // patch the security list
            //
            SecurityCell = (PCM_KEY_SECURITY) HvGetCell(Hive, RootNode->Security);
            if( SecurityCell == NULL ) {
                return FALSE;
            }

            if( HvMarkCellDirty(Hive, RootNode->Security) ) {
                SecurityCell->Flink = SecurityCell->Blink = RootNode->Security;
            } else {
                return FALSE;
            }
            //
            // destroy existing cache and set up an empty one
            //
            CmpDestroySecurityCache((PCMHIVE)Hive);
            CmpInitSecurityCache((PCMHIVE)Hive);
            CmMarkSelfHeal(Hive);
            *ResetSD = TRUE;

#if 0
            //
            // remove this security cell from the list and restart iteration
            //
            if(HvIsCellAllocated(Hive, NextCell)) {
                //
                // we come this path when the SD is invalid; we need to free the cell so 
                // cmpcheckregistry2 detects and fixes it
                //
                if( HvMarkCellDirty(Hive, NextCell) ) {
                    HvFreeCell(Hive, NextCell);
                } else {
                    return FALSE;
                }
            }
            LastCell = SecurityCell->Blink;
            NextCell = SecurityCell->Flink;
            SecurityCell = (PCM_KEY_SECURITY) HvGetCell(Hive, LastCell);
            if( SecurityCell == NULL ) {
                return FALSE;
            }
            if( HvMarkCellDirty(Hive, LastCell) ) {
                SecurityCell->Flink = NextCell;
            } else {
                return FALSE;
            }

            SecurityCell = (PCM_KEY_SECURITY) HvGetCell(Hive, NextCell);
            if( SecurityCell == NULL ) {
                return FALSE;
            }
            if( HvMarkCellDirty(Hive, NextCell) ) {
                SecurityCell->Blink = LastCell;
            } else {
                return FALSE;
            }
            CmMarkSelfHeal(Hive);
#endif
        } else {
            return FALSE;
        }

    }

    LastCell = 0;
    ListAnchor = NextCell = RootNode->Security;

    do {
        if (!HvIsCellAllocated(Hive, NextCell)) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"CM: CmpValidateHiveSecurityDescriptors\n"));
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"    NextCell: %08lx is invalid HCELL_INDEX\n",NextCell));
            goto YankSD;
        }
        SecurityCell = (PCM_KEY_SECURITY) HvGetCell(Hive, NextCell);
        if( SecurityCell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            return FALSE;
        }
#ifdef HIVE_SECURITY_STATS
        NoOfCells++;
        if( (SmallestSize == 0) || ((SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor)) < SmallestSize) ) {
            SmallestSize = SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor);
        }
        if( (BiggestSize == 0) || ((SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor)) > BiggestSize) ) {
            BiggestSize = SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor);
        }
        TotalSecuritySize += (SecurityCell->DescriptorLength + FIELD_OFFSET(CM_KEY_SECURITY, Descriptor));

#endif

        if (NextCell != ListAnchor) {
            //
            // Check to make sure that our Blink points to where we just
            // came from.
            //
            if (SecurityCell->Blink != LastCell) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"  Invalid Blink (%08lx) on security cell %08lx\n",SecurityCell->Blink, NextCell));
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"  should point to %08lx\n", LastCell));
                return(FALSE);
            }
        }

        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_SEC,"CmpValidSD:  SD shared by %d nodes\n",SecurityCell->ReferenceCount));
        if (!SeValidSecurityDescriptor(SecurityCell->DescriptorLength, &SecurityCell->Descriptor)) {
#if DBG
            CmpDumpSecurityDescriptor(&SecurityCell->Descriptor,"INVALID DESCRIPTOR");
#endif
            goto YankSD;
        }
        //
        // cache this security cell; now that we know it is valid
        //
        if( BuildSecurityCache == TRUE ) {
            if( !NT_SUCCESS(CmpAddSecurityCellToCache ( (PCMHIVE)Hive,NextCell,TRUE,NULL) ) ) {
                return FALSE;
            }
        } else {
            //
            // just check this cell is there
            //
            ULONG Index;
            if( CmpFindSecurityCellCacheIndex ((PCMHIVE)Hive,NextCell,&Index) == FALSE ) {
                //
                // bad things happened; maybe an error in our caching code?
                //
                return FALSE;
            }

        }

        LastCell = NextCell;
        NextCell = SecurityCell->Flink;
    } while ( NextCell != ListAnchor );
#ifdef HIVE_SECURITY_STATS

#ifndef _CM_LDR_
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t NumberOfCells    \t = %20lu (%8lx) \n",NoOfCells,NoOfCells);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t SmallestCellSize \t = %20lu (%8lx) \n",SmallestSize,SmallestSize);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t BiggestCellSize  \t = %20lu (%8lx) \n",BiggestSize,BiggestSize);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t TotalSecuritySize\t = %20lu (%8lx) \n",TotalSecuritySize,TotalSecuritySize);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\t HiveLength       \t = %20lu (%8lx) \n",Hive->BaseBlock->Length,Hive->BaseBlock->Length);
    DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"\n");
#endif //_CM_LDR_

#endif

    if( BuildSecurityCache == TRUE ) {
        //
        // adjust the size of the cache in case we allocated too much
        //
        CmpAdjustSecurityCacheSize ( (PCMHIVE)Hive );
#ifdef HIVE_SECURITY_STATS
        {
            ULONG Duplicates;
            
            Duplicates = CmpCheckForSecurityDuplicates((PCMHIVE)Hive);
            if( Duplicates ) {
#ifndef _CM_LDR_
                DbgPrintEx(DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"Hive %p %lu security cells duplicated !!!\n",Hive,Duplicates);
#endif //_CM_LDR_
            }
        }
#endif
    }

    return(TRUE);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmclose.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmclose.c

Abstract:

    This module contains the close object method.

Author:

    Bryan M. Willman (bryanwi) 07-Jan-92

Revision History:

--*/

#include    "cmp.h"

VOID
CmpDelayedDerefKeys(
                    PLIST_ENTRY DelayedDeref
                    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpCloseKeyObject)
#endif

VOID
CmpCloseKeyObject(
    IN PEPROCESS Process OPTIONAL,
    IN PVOID Object,
    IN ACCESS_MASK GrantedAccess,
    IN ULONG_PTR ProcessHandleCount,
    IN ULONG_PTR SystemHandleCount
    )
/*++

Routine Description:

    This routine interfaces to the NT Object Manager.  It is invoked when
    a Key object (or Key Root object) is closed.

    It's function is to do cleanup processing by waking up any notifies
    pending on the handle.  This keeps the key object from hanging around
    forever because a synchronous notify is stuck on it somewhere.

    All other cleanup, in particular, the freeing of storage, will be
    done in CmpDeleteKeyObject.

Arguments:

    Process - ignored

    Object - supplies a pointer to a KeyRoot or Key, thus -> KEY_BODY.

    GrantedAccess, ProcessHandleCount, SystemHandleCount - ignored

Return Value:

    NONE.

--*/
{
    PCM_KEY_BODY        KeyBody;
    PCM_NOTIFY_BLOCK    NotifyBlock;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (Process);
    UNREFERENCED_PARAMETER (GrantedAccess);
    UNREFERENCED_PARAMETER (ProcessHandleCount);

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_POOL,"CmpCloseKeyObject: Object = %p\n", Object));

    if( SystemHandleCount > 1 ) {
        //
        // There are still has open handles on this key. Do nothing
        //
        return;
    }

    CmpLockRegistry();

    KeyBody = (PCM_KEY_BODY)Object;

    //
    // Check the type, it will be something else if we are closing a predefined
    // handle key
    //
    if (KeyBody->Type == KEY_BODY_TYPE) {
        //
        // Clean up any outstanding notifies attached to the KeyBody
        //
        if (KeyBody->NotifyBlock != NULL) {
            //
            // Post all PostBlocks waiting on the NotifyBlock
            //
            NotifyBlock = KeyBody->NotifyBlock;
            if (IsListEmpty(&(NotifyBlock->PostList)) == FALSE) {
                LIST_ENTRY          DelayedDeref;
                //
                // we need to follow the rule here the hive lock
                // otherwise we could deadlock down in CmDeleteKeyObject. We don't acquire the kcb lock, 
                // but we make sure that in subsequent places where we get the hive lock we get it before 
                // the kcb lock, ie. we follow the precedence rule below. 
                //
                // NB: the order of these locks is First the hive lock, then the kcb lock
                //
                InitializeListHead(&DelayedDeref);
                CmLockHive((PCMHIVE)(KeyBody->KeyControlBlock->KeyHive));
                CmpPostNotify(NotifyBlock,
                              NULL,
                              0,
                              STATUS_NOTIFY_CLEANUP,
                              &DelayedDeref
#ifdef CM_NOTIFY_CHANGED_KCB_FULLPATH  
                              ,
                              NULL
#endif //CM_NOTIFY_CHANGED_KCB_FULLPATH  
                              );
                CmUnlockHive((PCMHIVE)(KeyBody->KeyControlBlock->KeyHive));
                //
                // finish the job started in CmpPostNotify (i.e. dereference the keybodies
                // we prevented. this may cause some notifyblocks to be freed
                //
                CmpDelayedDerefKeys(&DelayedDeref);
            }
        }
    }

    CmpUnlockRegistry();
    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmalloc.c ===
/*++

Copyright (c) 20001 Microsoft Corporation

Module Name:

    cmalloc.c

Abstract:

    Provides routines for implementing the registry's own pool allocator.

Author:

    Dragos C. Sambotin (DragosS) 07-Feb-2001

Revision History:


--*/
#include "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmpInitCmPrivateAlloc)
#pragma alloc_text(PAGE,CmpDestroyCmPrivateAlloc)
#pragma alloc_text(PAGE,CmpAllocateKeyControlBlock)
#pragma alloc_text(PAGE,CmpFreeKeyControlBlock)
#endif

typedef struct _CM_ALLOC_PAGE {
    ULONG       FreeCount;		// number of free kcbs
    ULONG       Reserved;		// alignment
#if DBG
	LIST_ENTRY	CmPageListEntry;// debug only to track pages we are using
#endif
    PVOID       AllocPage;      // crud allocations - this member is NOT USED
} CM_ALLOC_PAGE, *PCM_ALLOC_PAGE;

#define CM_KCB_ENTRY_SIZE   sizeof( CM_KEY_CONTROL_BLOCK )
#define CM_ALLOC_PAGES      (PAGE_SIZE / sizeof(CM_ALLOC_ENTRY))
#define CM_KCBS_PER_PAGE    ((PAGE_SIZE - FIELD_OFFSET(CM_ALLOC_PAGE,AllocPage)) / CM_KCB_ENTRY_SIZE)

#define KCB_TO_PAGE_ADDRESS( kcb ) (PVOID)(((ULONG_PTR)(kcb)) & ~(PAGE_SIZE - 1))
#define KCB_TO_ALLOC_PAGE( kcb ) ((PCM_ALLOC_PAGE)KCB_TO_PAGE_ADDRESS(kcb))

LIST_ENTRY          CmpFreeKCBListHead;   // list of free kcbs
BOOLEAN				CmpAllocInited = FALSE;

#if DBG
ULONG               CmpTotalKcbUsed   = 0;
ULONG               CmpTotalKcbFree   = 0;
LIST_ENTRY			CmPageListHead;
#endif

FAST_MUTEX			CmpAllocBucketLock;                // used to protect the bucket

#define LOCK_ALLOC_BUCKET() ExAcquireFastMutexUnsafe(&CmpAllocBucketLock)
#define UNLOCK_ALLOC_BUCKET() ExReleaseFastMutexUnsafe(&CmpAllocBucketLock)

VOID
CmpInitCmPrivateAlloc( )

/*++

Routine Description:

    Initialize the CmPrivate pool allocation module

Arguments:


Return Value:


--*/

{
    if( CmpAllocInited ) {
        //
        // already inited
        //
        return;
    }
    
    
#if DBG
    InitializeListHead(&(CmPageListHead));   
#endif //DBG

    InitializeListHead(&(CmpFreeKCBListHead));   

    //
	// init the bucket lock
	//
	ExInitializeFastMutex(&CmpAllocBucketLock);
	
	CmpAllocInited = TRUE;
}

VOID
CmpDestroyCmPrivateAlloc( )

/*++

Routine Description:

    Frees memory used byt the CmPrivate pool allocation module

Arguments:


Return Value:


--*/

{
    PAGED_CODE();
    
    if( !CmpAllocInited ) {
        return;
    }
    
#if DBG
	//
	// sanity
	//
	ASSERT( CmpTotalKcbUsed == 0 );
	ASSERT( CmpTotalKcbUsed == 0 );
	ASSERT( IsListEmpty(&(CmPageListHead)) == TRUE );
#endif

}


PCM_KEY_CONTROL_BLOCK
CmpAllocateKeyControlBlock( )

/*++

Routine Description:

    Allocates a kcb; first try from our own allocator.
    If it doesn't work (we have maxed out our number of allocs
    or private allocator is not inited)
    try from paged pool

Arguments:


Return Value:

    The  new kcb

--*/

{
    USHORT                  j;
    PCM_KEY_CONTROL_BLOCK   kcb = NULL;
	PCM_ALLOC_PAGE			AllocPage;

    PAGED_CODE();
    
    if( !CmpAllocInited ) {
        //
        // not inited
        //
        goto AllocFromPool;
    }
    
	LOCK_ALLOC_BUCKET();

SearchFreeKcb:
    //
    // try to find a free one
    //
    if( IsListEmpty(&CmpFreeKCBListHead) == FALSE ) {
        //
        // found one
        //
        kcb = (PCM_KEY_CONTROL_BLOCK)RemoveHeadList(&CmpFreeKCBListHead);
        kcb = CONTAINING_RECORD(kcb,
                                CM_KEY_CONTROL_BLOCK,
                                FreeListEntry);

		AllocPage = (PCM_ALLOC_PAGE)KCB_TO_ALLOC_PAGE( kcb );

        ASSERT( AllocPage->FreeCount != 0 );

        AllocPage->FreeCount--;
        
		//
		// set when page was allocated
		//
		ASSERT( kcb->PrivateAlloc == 1);

#if DBG
        CmpTotalKcbUsed++;
        CmpTotalKcbFree--;
#endif //DBG
		
		UNLOCK_ALLOC_BUCKET();
        return kcb;
    }

    ASSERT( IsListEmpty(&CmpFreeKCBListHead) == TRUE );
    ASSERT( CmpTotalKcbFree == 0 );

    //
    // we need to allocate a new page as we ran out of free kcbs
    //
            
    //
    // allocate a new page and insert all kcbs in the freelist
    //
    AllocPage = (PCM_ALLOC_PAGE)ExAllocatePoolWithTag(PagedPool, PAGE_SIZE, CM_ALLOCATE_TAG|PROTECTED_POOL);
    if( AllocPage == NULL ) {
        //
        // we might be low on pool; maybe small pool chunks will work
        //
		UNLOCK_ALLOC_BUCKET();
        goto AllocFromPool;
    }

	//
	// set up the page
	//
    AllocPage->FreeCount = CM_KCBS_PER_PAGE;

#if DBG
    AllocPage->Reserved = 0;
    InsertTailList(
        &CmPageListHead,
        &(AllocPage->CmPageListEntry)
        );
#endif //DBG


    //
    // now the dirty job; insert all kcbs inside the page in the free list
    //
    for(j=0;j<CM_KCBS_PER_PAGE;j++) {
        kcb = (PCM_KEY_CONTROL_BLOCK)((PUCHAR)AllocPage + FIELD_OFFSET(CM_ALLOC_PAGE,AllocPage) + j*CM_KCB_ENTRY_SIZE);

		//
		// set it here; only once
		//
		kcb->PrivateAlloc = 1;
        
        InsertTailList(
            &CmpFreeKCBListHead,
            &(kcb->FreeListEntry)
            );
    }
            
#if DBG
	CmpTotalKcbFree += CM_KCBS_PER_PAGE;
#endif //DBG

    //
    // this time will find one for sure
    //
    goto SearchFreeKcb;

AllocFromPool:
    kcb = ExAllocatePoolWithTag(PagedPool,
                                sizeof(CM_KEY_CONTROL_BLOCK),
                                CM_KCB_TAG | PROTECTED_POOL);

    if( kcb != NULL ) {
        //
        // clear the private alloc flag
        //
        kcb->PrivateAlloc = 0;
    }

    return kcb;
}


VOID
CmpFreeKeyControlBlock( PCM_KEY_CONTROL_BLOCK kcb )

/*++

Routine Description:

    Frees a kcb; if it's allocated from our own pool put it back in the free list.
    If it's allocated from general pool, just free it.

Arguments:

    kcb to free

Return Value:


--*/
{
    USHORT			j;
	PCM_ALLOC_PAGE	AllocPage;

    PAGED_CODE();

    ASSERT_KEYBODY_LIST_EMPTY(kcb);

    if( !kcb->PrivateAlloc ) {
        //
        // just free it and be done with it
        //
        ExFreePoolWithTag(kcb, CM_KCB_TAG | PROTECTED_POOL);
        return;
    }

	LOCK_ALLOC_BUCKET();

#if DBG
    CmpTotalKcbFree ++;
    CmpTotalKcbUsed --;
#endif

    //
    // add kcb to freelist
    //
    InsertTailList(
        &CmpFreeKCBListHead,
        &(kcb->FreeListEntry)
        );

	//
	// get the page
	//
	AllocPage = (PCM_ALLOC_PAGE)KCB_TO_ALLOC_PAGE( kcb );

    //
	// not all are free
	//
	ASSERT( AllocPage->FreeCount != CM_KCBS_PER_PAGE);

	AllocPage->FreeCount++;

    if( AllocPage->FreeCount == CM_KCBS_PER_PAGE ) {
        //
        // entire page is free; let it go
        //
        //
        // first; iterate through the free kcb list and remove all kcbs inside this page
        //
        for(j=0;j<CM_KCBS_PER_PAGE;j++) {
            kcb = (PCM_KEY_CONTROL_BLOCK)((PUCHAR)AllocPage + FIELD_OFFSET(CM_ALLOC_PAGE,AllocPage) + j*CM_KCB_ENTRY_SIZE);
        
            RemoveEntryList(&(kcb->FreeListEntry));
        }
#if DBG
        CmpTotalKcbFree -= CM_KCBS_PER_PAGE;
		RemoveEntryList(&(AllocPage->CmPageListEntry));
#endif
        ExFreePoolWithTag(AllocPage, CM_ALLOCATE_TAG|PROTECTED_POOL);
    }

	UNLOCK_ALLOC_BUCKET();

}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmapi.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmapi.c

Abstract:

    This module contains CM level entry points for the registry.

Author:

    Bryan M. Willman (bryanwi) 30-Aug-1991

Revision History:

--*/

#include "cmp.h"



extern  BOOLEAN     CmpNoWrite;

extern  LIST_ENTRY  CmpHiveListHead;

extern  BOOLEAN CmpProfileLoaded;
extern  BOOLEAN CmpWasSetupBoot;

extern  UNICODE_STRING CmSymbolicLinkValueName;

extern ULONG   CmpGlobalQuotaAllowed;
extern ULONG   CmpGlobalQuotaWarning;
extern PCMHIVE CmpMasterHive;
extern HIVE_LIST_ENTRY CmpMachineHiveList[];

VOID
CmpDereferenceNameControlBlockWithLock(
    PCM_NAME_CONTROL_BLOCK   Ncb
    );

//
// procedures private to this file
//
NTSTATUS
CmpSetValueKeyExisting(
    IN PHHIVE  Hive,
    IN HCELL_INDEX OldChild,
    IN PCM_KEY_VALUE Value,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize,
    IN ULONG StorageType,
    IN ULONG TempData
    );


NTSTATUS
CmpSetValueKeyNew(
    IN PHHIVE  Hive,
    IN PCM_KEY_NODE Parent,
    IN PUNICODE_STRING ValueName,
    IN ULONG Index,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize,
    IN ULONG StorageType,
    IN ULONG TempData
    );

VOID
CmpRemoveKeyHash(
    IN PCM_KEY_HASH KeyHash
    );

PCM_KEY_CONTROL_BLOCK
CmpInsertKeyHash(
    IN PCM_KEY_HASH KeyHash,
    IN BOOLEAN      FakeKey
    );

#if DBG
ULONG
CmpUnloadKeyWorker(
    PCM_KEY_CONTROL_BLOCK Current,
    PVOID                 Context1,
    PVOID                 Context2
    );
#endif

ULONG
CmpCompressKeyWorker(
    PCM_KEY_CONTROL_BLOCK Current,
    PVOID                 Context1,
    PVOID                 Context2
    );

NTSTATUS
CmpDuplicateKey(
    PHHIVE          Hive,
    HCELL_INDEX     OldKeyCell,
    PHCELL_INDEX    NewKeyCell
    );


VOID
CmpDestroyTemporaryHive(
    PCMHIVE CmHive
    );

BOOLEAN
CmpCompareNewValueDataAgainstKCBCache(  PCM_KEY_CONTROL_BLOCK KeyControlBlock,
                                        PUNICODE_STRING ValueName,
                                        ULONG Type,
                                        PVOID Data,
                                        ULONG DataSize
                                        );
BOOLEAN
CmpGetValueDataFromCache(
    IN PHHIVE               Hive,
    IN PPCM_CACHED_VALUE    ContainingList,
    IN PCELL_DATA           ValueKey,
    IN BOOLEAN              ValueCached,
    OUT PUCHAR              *DataPointer,
    OUT PBOOLEAN            Allocated,
    OUT PHCELL_INDEX        CellToRelease
);

BOOLEAN
CmpCompareNewValueDataAgainstKCBCache(  PCM_KEY_CONTROL_BLOCK KeyControlBlock,
                                        PUNICODE_STRING ValueName,
                                        ULONG Type,
                                        PVOID Data,
                                        ULONG DataSize
                                        );
BOOLEAN
CmpGetValueDataFromCache(
    IN PHHIVE               Hive,
    IN PPCM_CACHED_VALUE    ContainingList,
    IN PCELL_DATA           ValueKey,
    IN BOOLEAN              ValueCached,
    OUT PUCHAR              *DataPointer,
    OUT PBOOLEAN            Allocated,
    OUT PHCELL_INDEX        CellToRelease
);

BOOLEAN
CmpIsHiveAlreadyLoaded( IN HANDLE KeyHandle,
                        IN POBJECT_ATTRIBUTES SourceFile,
                        OUT PCMHIVE *CmHive
                        );

NTSTATUS
static
__forceinline
CmpCheckReplaceHive(    IN PHHIVE           Hive,
                        OUT PHCELL_INDEX    Key
                    );

BOOLEAN
CmpDoFlushNextHive(
    BOOLEAN     ForceFlush,
    PBOOLEAN    PostWarning,
    PULONG      DirtyCount
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmDeleteValueKey)
#pragma alloc_text(PAGE,CmEnumerateKey)
#pragma alloc_text(PAGE,CmEnumerateValueKey)
#pragma alloc_text(PAGE,CmFlushKey)
#pragma alloc_text(PAGE,CmQueryKey)
#pragma alloc_text(PAGE,CmQueryValueKey)
#pragma alloc_text(PAGE,CmQueryMultipleValueKey)
#pragma alloc_text(PAGE,CmSetValueKey)
#pragma alloc_text(PAGE,CmpSetValueKeyExisting)
#pragma alloc_text(PAGE,CmpSetValueKeyNew)
#pragma alloc_text(PAGE,CmSetLastWriteTimeKey)
#pragma alloc_text(PAGE,CmSetKeyUserFlags)
#pragma alloc_text(PAGE,CmLoadKey)
#pragma alloc_text(PAGE,CmUnloadKey)

#ifdef NT_UNLOAD_KEY_EX
#pragma alloc_text(PAGE,CmUnloadKeyEx)
#endif //NT_UNLOAD_KEY_EX

#pragma alloc_text(PAGE,CmpDoFlushAll)
#pragma alloc_text(PAGE,CmpDoFlushNextHive)
#pragma alloc_text(PAGE,CmReplaceKey)

#ifdef WRITE_PROTECTED_REGISTRY_POOL
#pragma alloc_text(PAGE,CmpMarkAllBinsReadOnly)
#endif //WRITE_PROTECTED_REGISTRY_POOL

#ifdef NT_RENAME_KEY
#pragma alloc_text(PAGE,CmRenameKey)
#endif //NT_RENAME_KEY

#pragma alloc_text(PAGE,CmLockKcbForWrite)

#if DBG
#pragma alloc_text(PAGE,CmpUnloadKeyWorker)
#endif

#pragma alloc_text(PAGE,CmMoveKey)
#pragma alloc_text(PAGE,CmpDuplicateKey)
#pragma alloc_text(PAGE,CmCompressKey)
#pragma alloc_text(PAGE,CmpCompressKeyWorker)
#pragma alloc_text(PAGE,CmpCompareNewValueDataAgainstKCBCache)
#pragma alloc_text(PAGE,CmpIsHiveAlreadyLoaded)
#pragma alloc_text(PAGE,CmpCheckReplaceHive)
#endif

NTSTATUS
CmDeleteValueKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN UNICODE_STRING           ValueName         // RAW
    )
/*++

Routine Description:

    One of the value entries of a registry key may be removed with this call.

    The value entry with ValueName matching ValueName is removed from the key.
    If no such entry exists, an error is returned.

Arguments:

    KeyControlBlock - pointer to kcb for key to operate on

    ValueName - The name of the value to be deleted.  NULL is a legal name.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS        status;
    PCM_KEY_NODE    pcell = NULL;
    PCHILD_LIST     plist;
    PCM_KEY_VALUE   Value = NULL;
    ULONG           targetindex;
    HCELL_INDEX     ChildCell;
    PHHIVE          Hive;
    HCELL_INDEX     Cell;
    LARGE_INTEGER   systemtime;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmDeleteValueKey\n"));

    status = STATUS_OBJECT_NAME_NOT_FOUND;

    ChildCell = HCELL_NIL;

    CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    PERFINFO_REG_DELETE_VALUE(KeyControlBlock, &ValueName);

    //
    // no edits, not even this one, on keys marked for deletion
    //
    if (KeyControlBlock->Delete) {

#ifdef CHECK_REGISTRY_USECOUNT
        CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

        CmpUnlockRegistry();

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        return STATUS_KEY_DELETED;
    }

    Hive = KeyControlBlock->KeyHive;
    Cell = KeyControlBlock->KeyCell;

    try {

        pcell = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
        if( pcell == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            status = STATUS_INSUFFICIENT_RESOURCES;
            leave;
        }

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        plist = &(pcell->ValueList);

        if (plist->Count != 0) {

            //
            // The parent has at least one value, map in the list of
            // values and call CmpFindChildInList
            //

            //
            // plist -> the CHILD_LIST structure
            // pchild -> the child node structure being examined
            //

            if( CmpFindNameInList(Hive,
                                  plist,
                                  &ValueName,
                                  &targetindex,
                                  &ChildCell) == FALSE ) {
            
                    // Mark the hive as read only
                    CmpMarkAllBinsReadOnly(Hive);

                    status = STATUS_INSUFFICIENT_RESOURCES;
                    leave;
            }

            if (ChildCell != HCELL_NIL) {

                //
                // 1. the desired target was found
                // 2. ChildCell is it's HCELL_INDEX
                // 3. targetaddress points to it
                // 4. targetindex is it's index
                //

                //
                // attempt to mark all relevent cells dirty
                //
                if (!(HvMarkCellDirty(Hive, Cell) &&
                      HvMarkCellDirty(Hive, pcell->ValueList.List) &&
                      HvMarkCellDirty(Hive, ChildCell)))

                {
                    // Mark the hive as read only
                    CmpMarkAllBinsReadOnly(Hive);

                    status = STATUS_NO_LOG_SPACE;
                    leave;
                }

                Value = (PCM_KEY_VALUE)HvGetCell(Hive,ChildCell);
                if( Value == NULL ) {
                    //
                    // could not map view inside
                    // this is impossible as we just dirtied the view
                    //
                    ASSERT( FALSE );
                    // Mark the hive as read only
                    CmpMarkAllBinsReadOnly(Hive);

                    status = STATUS_INSUFFICIENT_RESOURCES;
                    leave;
                }
                if( !CmpMarkValueDataDirty(Hive,Value) ) {
                    // Mark the hive as read only
                    CmpMarkAllBinsReadOnly(Hive);

                    status = STATUS_NO_LOG_SPACE;
                    leave;
                }

                // sanity
                ASSERT_CELL_DIRTY(Hive,pcell->ValueList.List);
                ASSERT_CELL_DIRTY(Hive,ChildCell);

                if( !NT_SUCCESS(CmpRemoveValueFromList(Hive,targetindex,plist)) ) {
                    //
                    // bail out !
                    //
                    status = STATUS_INSUFFICIENT_RESOURCES;
                    leave;
                }
                if( CmpFreeValue(Hive, ChildCell) == FALSE ) {
                    //
                    // we couldn't map a view inside above call
                    //
                    status = STATUS_INSUFFICIENT_RESOURCES;
                    leave;
                }

                KeQuerySystemTime(&systemtime);
                pcell->LastWriteTime = systemtime;
                // cache it in the kcb too.
                KeyControlBlock->KcbLastWriteTime = systemtime;
                
                // some sanity asserts
                ASSERT( pcell->MaxValueNameLen == KeyControlBlock->KcbMaxValueNameLen );
                ASSERT( pcell->MaxValueDataLen == KeyControlBlock->KcbMaxValueDataLen );
                ASSERT_CELL_DIRTY(Hive,Cell);

                if (pcell->ValueList.Count == 0) {
                    pcell->MaxValueNameLen = 0;
                    pcell->MaxValueDataLen = 0;
                    // update the kcb cache too
                    KeyControlBlock->KcbMaxValueNameLen = 0;
                    KeyControlBlock->KcbMaxValueDataLen = 0;
                }

                //
                // We are changing the KCB cache. Since the registry is locked exclusively,
                // we do not need a KCB lock.
                //
                ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

                //
                // Invalidate and rebuild the cache
                //
                CmpCleanUpKcbValueCache(KeyControlBlock);
                CmpSetUpKcbValueCache(KeyControlBlock,plist->Count,plist->List);
    
                CmpReportNotify(
                        KeyControlBlock,
                        KeyControlBlock->KeyHive,
                        KeyControlBlock->KeyCell,
                        REG_NOTIFY_CHANGE_LAST_SET
                        );
                status = STATUS_SUCCESS;
            } else {
                status = STATUS_OBJECT_NAME_NOT_FOUND;
            }
        }
    } finally {
        if(pcell != NULL){
            HvReleaseCell(Hive, Cell);
        }
        if(Value != NULL){
            ASSERT( ChildCell != HCELL_NIL );
            HvReleaseCell(Hive, ChildCell);
        }

#ifdef CHECK_REGISTRY_USECOUNT
        CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

        CmpUnlockRegistry();
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return status;
}


NTSTATUS
CmEnumerateKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN ULONG Index,
    IN KEY_INFORMATION_CLASS KeyInformationClass,
    IN PVOID KeyInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    )
/*++

Routine Description:

    Enumerate sub keys, return data on Index'th entry.

    CmEnumerateKey returns the name of the Index'th sub key of the open
    key specified.  The value STATUS_NO_MORE_ENTRIES will be
    returned if value of Index is larger than the number of sub keys.

    Note that Index is simply a way to select among child keys.  Two calls
    to CmEnumerateKey with the same Index are NOT guaranteed to return
    the same results.

    If KeyInformation is not long enough to hold all requested data,
    STATUS_BUFFER_OVERFLOW will be returned, and ResultLength will be
    set to the number of bytes actually required.

Arguments:

    KeyControlBlock - pointer to the KCB that describes the key

    Index - Specifies the (0-based) number of the sub key to be returned.

    KeyInformationClass - Specifies the type of information returned in
        Buffer.  One of the following types:

        KeyBasicInformation - return last write time, title index, and name.
            (see KEY_BASIC_INFORMATION structure)

        KeyNodeInformation - return last write time, title index, name, class.
            (see KEY_NODE_INFORMATION structure)

    KeyInformation -Supplies pointer to buffer to receive the data.

    Length - Length of KeyInformation in bytes.

    ResultLength - Number of bytes actually written into KeyInformation.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS        status;
    HCELL_INDEX     childcell;
    PHHIVE          Hive;
    HCELL_INDEX     Cell;
    PCM_KEY_NODE    Node;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmEnumerateKey\n"));


    CmpLockRegistry();

    PERFINFO_REG_ENUM_KEY(KeyControlBlock, Index);

    if (KeyControlBlock->Delete) {
        CmpUnlockRegistry();
        return STATUS_KEY_DELETED;
    }

    Hive = KeyControlBlock->KeyHive;
    Cell = KeyControlBlock->KeyCell;

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    //
    // fetch the child of interest
    //

    Node = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmpUnlockRegistry();
        CmpMarkAllBinsReadOnly(Hive);
        return STATUS_INSUFFICIENT_RESOURCES;

    }
    childcell = CmpFindSubKeyByNumber(Hive, Node, Index);
    
    // release this cell here as we don't need this Node anymore
    HvReleaseCell(Hive, Cell);

    if (childcell == HCELL_NIL) {
        //
        // no such child, clean up and return error
        //
        // we cannot return STATUS_INSUFFICIENT_RESOURCES because of Iop 
        // subsystem which treats INSUFFICIENT RESOURCES as no fatal error
        //
        CmpUnlockRegistry();

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        return STATUS_NO_MORE_ENTRIES;
    }

    Node = (PCM_KEY_NODE)HvGetCell(Hive,childcell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmpMarkAllBinsReadOnly(Hive);
        CmpUnlockRegistry();
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    try {

        //
        // call a worker to perform data transfer
        //

        status = CmpQueryKeyData(Hive,
                                 Node,
                                 KeyInformationClass,
                                 KeyInformation,
                                 Length,
                                 ResultLength
#if defined(CMP_STATS) || defined(CMP_KCB_CACHE_VALIDATION)
                                 ,
                                 NULL
#endif
                                 );

     } except (EXCEPTION_EXECUTE_HANDLER) {

        HvReleaseCell(Hive, childcell);

        CmpUnlockRegistry();
        status = GetExceptionCode();

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        return status;
    }

    HvReleaseCell(Hive, childcell);

    CmpUnlockRegistry();

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return status;
}



NTSTATUS
CmEnumerateValueKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN ULONG Index,
    IN KEY_VALUE_INFORMATION_CLASS KeyValueInformationClass,
    IN PVOID KeyValueInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    )
/*++

Routine Description:

    The value entries of an open key may be enumerated.

    CmEnumerateValueKey returns the name of the Index'th value
    entry of the open key specified by KeyHandle.  The value
    STATUS_NO_MORE_ENTRIES will be returned if value of Index is
    larger than the number of sub keys.

    Note that Index is simply a way to select among value
    entries.  Two calls to NtEnumerateValueKey with the same Index
    are NOT guaranteed to return the same results.

    If KeyValueInformation is not long enough to hold all requested data,
    STATUS_BUFFER_OVERFLOW will be returned, and ResultLength will be
    set to the number of bytes actually required.

Arguments:

    KeyControlBlock - pointer to the KCB that describes the key

    Index - Specifies the (0-based) number of the sub key to be returned.

    KeyValueInformationClass - Specifies the type of information returned
    in Buffer. One of the following types:

        KeyValueBasicInformation - return time of last write,
            title index, and name.  (See KEY_VALUE_BASIC_INFORMATION)

        KeyValueFullInformation - return time of last write,
            title index, name, class.  (See KEY_VALUE_FULL_INFORMATION)

    KeyValueInformation -Supplies pointer to buffer to receive the data.

    Length - Length of KeyValueInformation in bytes.

    ResultLength - Number of bytes actually written into KeyValueInformation.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS            status;
    PHHIVE              Hive;
    PCM_KEY_NODE        Node;
    PCELL_DATA          ChildList;
    PCM_KEY_VALUE       ValueData = NULL;
    BOOLEAN             IndexCached;
    BOOLEAN             ValueCached = FALSE;
    PPCM_CACHED_VALUE   ContainingList = NULL;
    HCELL_INDEX         ValueDataCellToRelease = HCELL_NIL;
    HCELL_INDEX         ValueListToRelease = HCELL_NIL;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmEnumerateValueKey\n"));


    //
    // lock the parent cell
    //

    CmpLockRegistry();

    PERFINFO_REG_ENUM_VALUE(KeyControlBlock, Index);

    if (KeyControlBlock->Delete) {
        CmpUnlockRegistry();
        return STATUS_KEY_DELETED;
    }
    Hive = KeyControlBlock->KeyHive;
    Node = (PCM_KEY_NODE)HvGetCell(Hive, KeyControlBlock->KeyCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmpUnlockRegistry();
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // fetch the child of interest
    //
    //
    // Do it using the cache
    //
    if (Index >= KeyControlBlock->ValueCache.Count) {
        //
        // No such child, clean up and return error.
        //
        HvReleaseCell(Hive, KeyControlBlock->KeyCell);
        CmpUnlockRegistry();
        return(STATUS_NO_MORE_ENTRIES);
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    BEGIN_KCB_LOCK_GUARD;
    CmpLockKCBTreeExclusive();

    if (KeyControlBlock->ExtFlags & CM_KCB_SYM_LINK_FOUND) {
        //
        // The value list is now set to the KCB for symbolic link,
        // Clean it up and set the value right before we do the query.
        //
        CmpCleanUpKcbValueCache(KeyControlBlock);
        CmpSetUpKcbValueCache(KeyControlBlock,Node->ValueList.Count,Node->ValueList.List);
    }

    ChildList = CmpGetValueListFromCache(Hive, &(KeyControlBlock->ValueCache), &IndexCached, &ValueListToRelease);
    if( ChildList == NULL ) {
        //
        // couldn't map view; treat it as insufficient resources
        //

        if( ValueListToRelease != HCELL_NIL ) {
            HvReleaseCell(Hive,ValueListToRelease);
        }
        HvReleaseCell(Hive, KeyControlBlock->KeyCell);

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        CmpUnlockKCBTree();
        CmpUnlockRegistry();
        return(STATUS_INSUFFICIENT_RESOURCES);

    }
    ValueData = CmpGetValueKeyFromCache(Hive, ChildList, Index, &ContainingList, IndexCached, &ValueCached,&ValueDataCellToRelease);    
    if( ValueData == NULL ) {
        //
        // couldn't map view; treat it as insufficient resources
        //

        if( ValueListToRelease != HCELL_NIL ) {
            HvReleaseCell(Hive,ValueListToRelease);
        }
        HvReleaseCell(Hive, KeyControlBlock->KeyCell);
        if( ValueDataCellToRelease != HCELL_NIL ) {
            HvReleaseCell(Hive,ValueDataCellToRelease);
        }

        // Mark the hive as read only
        CmpMarkAllBinsReadOnly(Hive);

        CmpUnlockKCBTree();
        CmpUnlockRegistry();
        return(STATUS_INSUFFICIENT_RESOURCES);
    }

    END_KCB_LOCK_GUARD;


    // Trying to catch the BAD guy who writes over our pool.
    CmpMakeValueCacheReadWrite(ValueCached,CMP_GET_CACHED_ADDRESS(KeyControlBlock->ValueCache.ValueList));

    try {

        //
        // call a worker to perform data transfer; we are touching user-mode address; do it in a try/except
        //
        status = CmpQueryKeyValueData(Hive,
                                  ContainingList,
                                  ValueData,
                                  ValueCached,
                                  KeyValueInformationClass,
                                  KeyValueInformation,
                                  Length,
                                  ResultLength);

    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"CmEnumerateValueKey: code:%08lx\n", GetExceptionCode()));
        status = GetExceptionCode();
    }

     // Trying to catch the BAD guy who writes over our pool.
    CmpMakeValueCacheReadOnly(ValueCached,CMP_GET_CACHED_ADDRESS(KeyControlBlock->ValueCache.ValueList));

    if( ValueListToRelease != HCELL_NIL ) {
        HvReleaseCell(Hive,ValueListToRelease);
    }

    HvReleaseCell(Hive, KeyControlBlock->KeyCell);

    if( ValueDataCellToRelease != HCELL_NIL ) {
        HvReleaseCell(Hive,ValueDataCellToRelease);
    }

    CmpUnlockKCBTree();
    CmpUnlockRegistry();

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return status;
}



NTSTATUS
CmFlushKey(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell
    )
/*++

Routine Description:

    Forces changes made to a key to disk.

    CmFlushKey will not return to its caller until any changed data
    associated with the key has been written out.

    WARNING: CmFlushKey will flush the entire registry tree, and thus will
    burn cycles and I/O.

Arguments:

    Hive - supplies a pointer to the hive control structure for the hive

    Cell - supplies index of node to whose sub keys are to be found

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    PCMHIVE CmHive;
    NTSTATUS    status = STATUS_SUCCESS;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmFlushKey\n"));

    UNREFERENCED_PARAMETER (Cell);

    //
    // If writes are not working, lie and say we succeeded, will
    // clean up in a short time.  Only early system init code
    // will ever know the difference.
    //
    if (CmpNoWrite) {
        return STATUS_SUCCESS;
    }


    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    CmHive = CONTAINING_RECORD(Hive, CMHIVE, Hive);

    //
    // Don't flush the master hive.  If somebody asks for a flushkey on
    // the master hive, do a CmpDoFlushAll instead.  CmpDoFlushAll flushes
    // every hive except the master hive, which is what they REALLY want.
    //
    if (CmHive == CmpMasterHive) {
        CmpDoFlushAll(FALSE);
    } else {
        DCmCheckRegistry(CONTAINING_RECORD(Hive, CMHIVE, Hive));

        CmLockHive (CmHive);
        CmLockHiveViews (CmHive);

        if( HvHiveWillShrink( &(CmHive->Hive) ) ) {
            //
            // we may end up here is when the hive shrinks and we need
            // exclusive access over the registry, as we are going to CcPurge !
            //
            CmUnlockHiveViews (CmHive);
            CmUnlockHive (CmHive);
            CmpUnlockRegistry();
            CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
            CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

            CmLockHive (CmHive);

            if( CmHive->UseCount != 0) {
                ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
                CmpFixHiveUsageCount(CmHive);
                ASSERT( CmHive->UseCount == 0 );
            }
        } else {
            //
            // release the views
            //
            CmUnlockHiveViews (CmHive);
        }

        if (! HvSyncHive(Hive)) {

            status = STATUS_REGISTRY_IO_FAILED;

            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmFlushKey: HvSyncHive failed\n"));
        }

        CmUnlockHive (CmHive);
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return  status;
}


NTSTATUS
CmQueryKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN KEY_INFORMATION_CLASS    KeyInformationClass,
    IN PVOID                    KeyInformation,
    IN ULONG                    Length,
    IN PULONG                   ResultLength
    )
/*++

Routine Description:

    Data about the class of a key, and the numbers and sizes of its
    children and value entries may be queried with CmQueryKey.

    NOTE: The returned lengths are guaranteed to be at least as
          long as the described values, but may be longer in
          some circumstances.

Arguments:

    KeyControlBlock - pointer to the KCB that describes the key

    KeyInformationClass - Specifies the type of information
        returned in Buffer.  One of the following types:

        KeyBasicInformation - return last write time, title index, and name.
            (See KEY_BASIC_INFORMATION)

        KeyNodeInformation - return last write time, title index, name, class.
            (See KEY_NODE_INFORMATION)

        KeyFullInformation - return all data except for name and security.
            (See KEY_FULL_INFORMATION)

    KeyInformation -Supplies pointer to buffer to receive the data.

    Length - Length of KeyInformation in bytes.

    ResultLength - Number of bytes actually written into KeyInformation.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS        status = STATUS_UNSUCCESSFUL;
    PCM_KEY_NODE    Node = NULL;
    PUNICODE_STRING Name = NULL;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmQueryKey\n"));

    CmpLockRegistry();

    PERFINFO_REG_QUERY_KEY(KeyControlBlock);

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    try {

        //
        // request for the FULL path of the key
        //
        if( KeyInformationClass == KeyNameInformation ) {
            if (KeyControlBlock->Delete ) {
                //
                // special case: return key deleted status, but still fill the full name of the key.
                //
                status = STATUS_KEY_DELETED;
            } else {
                status = STATUS_SUCCESS;
            }
            
            if( KeyControlBlock->NameBlock ) {

                Name = CmpConstructName(KeyControlBlock);
                if (Name == NULL) {
                    status = STATUS_INSUFFICIENT_RESOURCES;
                } else {
                    ULONG       requiredlength;
                    ULONG       minimumlength;
                    USHORT      NameLength;
                    LONG        leftlength;
                    PKEY_INFORMATION pbuffer = (PKEY_INFORMATION)KeyInformation;

                    NameLength = Name->Length;

                    requiredlength = FIELD_OFFSET(KEY_NAME_INFORMATION, Name) + NameLength;
                    
                    minimumlength = FIELD_OFFSET(KEY_NAME_INFORMATION, Name);

                    *ResultLength = requiredlength;
                    if (Length < minimumlength) {

                        status = STATUS_BUFFER_TOO_SMALL;

                    } else {
                        //
                        // Fill in the length of the name
                        //
                        pbuffer->KeyNameInformation.NameLength = NameLength;
                        
                        //
                        // Now copy the full name into the user buffer, if enough space
                        //
                        leftlength = Length - minimumlength;
                        requiredlength = NameLength;
                        if (leftlength < (LONG)requiredlength) {
                            requiredlength = leftlength;
                            status = STATUS_BUFFER_OVERFLOW;
                        }

                        //
                        // If not enough space, copy how much we can and return overflow
                        //
                        RtlCopyMemory(
                            &(pbuffer->KeyNameInformation.Name[0]),
                            Name->Buffer,
                            requiredlength
                            );
                    }
                }
            }
        } else if(KeyControlBlock->Delete ) {
            // 
            // key already deleted
            //
            status = STATUS_KEY_DELETED;
        } else if( KeyInformationClass == KeyFlagsInformation ) {
            //
            // we only want to get the user defined flags;
            //
            PKEY_INFORMATION    pbuffer = (PKEY_INFORMATION)KeyInformation;
            ULONG               requiredlength;

            requiredlength = sizeof(KEY_FLAGS_INFORMATION);

            *ResultLength = requiredlength;

            if (Length < requiredlength) {
                status = STATUS_BUFFER_TOO_SMALL;
            } else {
                pbuffer->KeyFlagsInformation.UserFlags = (ULONG)((USHORT)KeyControlBlock->Flags >> KEY_USER_FLAGS_SHIFT);
                status = STATUS_SUCCESS;
            }
        } else {
            //
            // call a worker to perform data transfer
            //

            if( KeyInformationClass == KeyCachedInformation ) {
                //
                // call the fast version
                //
                status = CmpQueryKeyDataFromCache(  KeyControlBlock,
                                                    KeyInformationClass,
                                                    KeyInformation,
                                                    Length,
                                                    ResultLength );
            } else {
                //
                // old'n plain slow version
                //
                Node = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
                if( Node == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    status = STATUS_INSUFFICIENT_RESOURCES;
                } else {
                    status = CmpQueryKeyData(KeyControlBlock->KeyHive,
                                             Node,
                                             KeyInformationClass,
                                             KeyInformation,
                                             Length,
                                             ResultLength 
#if defined(CMP_STATS) || defined(CMP_KCB_CACHE_VALIDATION)
                                 ,
                                 KeyControlBlock
#endif
                                             );
                }
            }
        }

    } finally {
        if( Node != NULL ) {
            HvReleaseCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
        }

        if( Name != NULL ) {
            ExFreePoolWithTag(Name, CM_NAME_TAG | PROTECTED_POOL);
        }
        CmpUnlockRegistry();
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    return status;
}


NTSTATUS
CmQueryValueKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN UNICODE_STRING ValueName,
    IN KEY_VALUE_INFORMATION_CLASS KeyValueInformationClass,
    IN PVOID KeyValueInformation,
    IN ULONG Length,
    IN PULONG ResultLength
    )
/*++

Routine Description:

    The ValueName, TitleIndex, Type, and Data for any one of a key's
    value entries may be queried with CmQueryValueKey.

    If KeyValueInformation is not long enough to hold all requested data,
    STATUS_BUFFER_OVERFLOW will be returned, and ResultLength will be
    set to the number of bytes actually required.

Arguments:

    KeyControlBlock - pointer to the KCB that describes the key

    ValueName  - The name of the value entry to return data for.

    KeyValueInformationClass - Specifies the type of information
        returned in KeyValueInformation.  One of the following types:

        KeyValueBasicInformation - return time of last write, title
            index, and name.  (See KEY_VALUE_BASIC_INFORMATION)

        KeyValueFullInformation - return time of last write, title
            index, name, class.  (See KEY_VALUE_FULL_INFORMATION)

    KeyValueInformation -Supplies pointer to buffer to receive the data.

    Length - Length of KeyValueInformation in bytes.

    ResultLength - Number of bytes actually written into KeyValueInformation.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS            status;
    PCM_KEY_VALUE       ValueData = NULL;
    ULONG               Index;
    BOOLEAN             ValueCached = FALSE;
    PPCM_CACHED_VALUE   ContainingList = NULL;
    HCELL_INDEX         ValueDataCellToRelease = HCELL_NIL;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmQueryValueKey\n"));

    CmpLockRegistry();

    PERFINFO_REG_QUERY_VALUE(KeyControlBlock, &ValueName);

    if (KeyControlBlock->Delete) {

        CmpUnlockRegistry();
        return STATUS_KEY_DELETED;
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    BEGIN_KCB_LOCK_GUARD;
    // try shared first
    CmpLockKCBTree();

    if (KeyControlBlock->ExtFlags & CM_KCB_SYM_LINK_FOUND) {

        // upgrade lock to exclusive (referenced so can't be deleted)
        CmpUnlockKCBTree();
        CmpLockKCBTreeExclusive();

        if (KeyControlBlock->ExtFlags & CM_KCB_SYM_LINK_FOUND) {
            //
            // The value list is now set to the KCB for symbolic link,
            // Clean it up and set the value right before we do the query.
            //
            CmpCleanUpKcbValueCache(KeyControlBlock);

            {
                PCM_KEY_NODE Node = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
                if( Node == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //

                    CmpUnlockKCBTree();
                    CmpUnlockRegistry();
                    // Mark the hive as read only
                    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

                    return STATUS_INSUFFICIENT_RESOURCES;

                }

                CmpSetUpKcbValueCache(KeyControlBlock,Node->ValueList.Count,Node->ValueList.List);

                HvReleaseCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
            }
        }
    }
    CmpLockKCB(KeyControlBlock);
    //
    // Find the data
    //

    ValueData = CmpFindValueByNameFromCache(KeyControlBlock->KeyHive,
                                            &(KeyControlBlock->ValueCache),
                                            &ValueName,
                                            &ContainingList,
                                            &Index,
                                            &ValueCached,
                                            &ValueDataCellToRelease
                                            );

    END_KCB_LOCK_GUARD;

    if (ValueData) {

        // Trying to catch the BAD guy who writes over our pool.
        CmpMakeValueCacheReadWrite(ValueCached,CMP_GET_CACHED_ADDRESS(KeyControlBlock->ValueCache.ValueList));

        try {

            //
            // call a worker to perform data transfer; we are touching user-mode address; do it in a try/except
            //

            status = CmpQueryKeyValueData(KeyControlBlock->KeyHive,
                                          ContainingList,
                                          ValueData,
                                          ValueCached,
                                          KeyValueInformationClass,
                                          KeyValueInformation,
                                          Length,
                                          ResultLength);


        } except (EXCEPTION_EXECUTE_HANDLER) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"CmQueryValueKey: code:%08lx\n", GetExceptionCode()));
            status = GetExceptionCode();
        }

        // Trying to catch the BAD guy who writes over our pool.
        CmpMakeValueCacheReadOnly(ValueCached,CMP_GET_CACHED_ADDRESS(KeyControlBlock->ValueCache.ValueList));
    } else {
        status = STATUS_OBJECT_NAME_NOT_FOUND;
    }


    if(ValueDataCellToRelease != HCELL_NIL) {
        HvReleaseCell(KeyControlBlock->KeyHive,ValueDataCellToRelease);
    }
    CmpUnlockKCB(KeyControlBlock);
    CmpUnlockKCBTree();
    CmpUnlockRegistry();

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    return status;
}


NTSTATUS
CmQueryMultipleValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PKEY_VALUE_ENTRY ValueEntries,
    IN ULONG EntryCount,
    IN PVOID ValueBuffer,
    IN OUT PULONG BufferLength,
    IN OPTIONAL PULONG ResultLength
    )
/*++

Routine Description:

    Multiple values of any key may be queried atomically with
    this api.

Arguments:

    KeyControlBlock - Supplies the key to be queried.

    ValueEntries - Returns an array of KEY_VALUE_ENTRY structures, one for each value.

    EntryCount - Supplies the number of entries in the ValueNames and ValueEntries arrays

    ValueBuffer - Returns the value data for each value.

    BufferLength - Supplies the length of the ValueBuffer array in bytes.
                   Returns the length of the ValueBuffer array that was filled in.

    ResultLength - if present, Returns the length in bytes of the ValueBuffer
                    array required to return the requested values of this key.

Return Value:

    NTSTATUS

--*/

{
    PHHIVE          Hive;
    NTSTATUS        Status;
    ULONG           i;
    UNICODE_STRING  CurrentName;
    HCELL_INDEX     ValueCell = HCELL_NIL;
    PCM_KEY_VALUE   ValueNode;
    ULONG           RequiredLength = 0;
    ULONG           UsedLength = 0;
    ULONG           DataLength;
    BOOLEAN         BufferFull = FALSE;
    BOOLEAN         Small;
    KPROCESSOR_MODE PreviousMode;
    PCM_KEY_NODE    Node;

    PAGED_CODE();
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmQueryMultipleValueKey\n"));


    CmpLockRegistry();

    if (KeyControlBlock->Delete) {
        CmpUnlockRegistry();
        return STATUS_KEY_DELETED;
    }
    Hive = KeyControlBlock->KeyHive;
    Status = STATUS_SUCCESS;

    Node = (PCM_KEY_NODE)HvGetCell(Hive, KeyControlBlock->KeyCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        CmpUnlockRegistry();
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    PreviousMode = KeGetPreviousMode();
    try {
        for (i=0; i < EntryCount; i++) {
            //
            // find the data
            //
            if (PreviousMode == UserMode) {
                CurrentName = ProbeAndReadUnicodeString(ValueEntries[i].ValueName);
                ProbeForRead(CurrentName.Buffer,CurrentName.Length,sizeof(WCHAR));
            } else {
                CurrentName = *(ValueEntries[i].ValueName);
            }

            PERFINFO_REG_QUERY_MULTIVALUE(KeyControlBlock, &CurrentName); 

            ValueCell = CmpFindValueByName(Hive,
                                           Node,
                                           &CurrentName);
            if (ValueCell != HCELL_NIL) {

                ValueNode = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
                if( ValueNode == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    ValueCell = HCELL_NIL;
                    Status = STATUS_INSUFFICIENT_RESOURCES;
                    break;
                }
                Small = CmpIsHKeyValueSmall(DataLength, ValueNode->DataLength);

                //
                // Round up UsedLength and RequiredLength to a ULONG boundary
                //
                UsedLength = (UsedLength + sizeof(ULONG)-1) & ~(sizeof(ULONG)-1);
                RequiredLength = (RequiredLength + sizeof(ULONG)-1) & ~(sizeof(ULONG)-1);

                //
                // If there is enough room for this data value in the buffer,
                // fill it in now. Otherwise, mark the buffer as full. We must
                // keep iterating through the values in order to determine the
                // RequiredLength.
                //
                if ((UsedLength + DataLength <= *BufferLength) &&
                    (!BufferFull)) {
                    PCELL_DATA  Buffer;
                    BOOLEAN     BufferAllocated;
                    HCELL_INDEX CellToRelease;
                    //
                    // get the data from source, regardless of the size
                    //
                    if( CmpGetValueData(Hive,ValueNode,&DataLength,&Buffer,&BufferAllocated,&CellToRelease) == FALSE ) {
                        //
                        // insufficient resources; return NULL
                        //
                        ASSERT( BufferAllocated == FALSE );
                        ASSERT( Buffer == NULL );
                        Status = STATUS_INSUFFICIENT_RESOURCES;
                        break;
                    }

                    RtlCopyMemory((PUCHAR)ValueBuffer + UsedLength,
                                  Buffer,
                                  DataLength);
                    //
                    // cleanup the temporary buffer
                    //
                    if( BufferAllocated == TRUE ) {
                        ExFreePool( Buffer );
                    }
                    //
                    // release the buffer in case we are using hive storage
                    //
                    if( CellToRelease != HCELL_NIL ) {
                        HvReleaseCell(Hive,CellToRelease);
                    }

                    ValueEntries[i].Type = ValueNode->Type;
                    ValueEntries[i].DataLength = DataLength;
                    ValueEntries[i].DataOffset = UsedLength;
                    UsedLength += DataLength;
                } else {
                    BufferFull = TRUE;
                    Status = STATUS_BUFFER_OVERFLOW;
                }
                RequiredLength += DataLength;
                HvReleaseCell(Hive, ValueCell);
                ValueCell = HCELL_NIL;
            } else {
                Status = STATUS_OBJECT_NAME_NOT_FOUND;
                break;
            }
        }

        if (NT_SUCCESS(Status) ||
            (Status == STATUS_BUFFER_OVERFLOW)) {
            *BufferLength = UsedLength;
            if (ARGUMENT_PRESENT(ResultLength)) {
                *ResultLength = RequiredLength;
            }
        }

    } finally {
        if( ValueCell != HCELL_NIL) {
            HvReleaseCell(Hive, ValueCell);
        }
        HvReleaseCell(Hive, KeyControlBlock->KeyCell);
        
        CmpUnlockRegistry();
    }

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(Hive);

    return Status;
}

NTSTATUS
CmSetValueKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PUNICODE_STRING ValueName,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize
    )
/*++

Routine Description:

    A value entry may be created or replaced with CmSetValueKey.

    If a value entry with a Value ID (i.e. name) matching the
    one specified by ValueName exists, it is deleted and replaced
    with the one specified.  If no such value entry exists, a new
    one is created.  NULL is a legal Value ID.  While Value IDs must
    be unique within any given key, the same Value ID may appear
    in many different keys.

Arguments:

    KeyControlBlock - pointer to kcb for the key to operate on

    ValueName - The unique (relative to the containing key) name
        of the value entry.  May be NULL.

    Type - The integer type number of the value entry.

    Data - Pointer to buffer with actual data for the value entry.

    DataSize - Size of Data buffer.


Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS        status;
    PCM_KEY_NODE    parent = NULL;
    HCELL_INDEX     oldchild = 0;
    ULONG           count;
    PHHIVE          Hive = NULL;
    HCELL_INDEX     Cell;
    ULONG           StorageType;
    ULONG           TempData;
    BOOLEAN         found;
    PCM_KEY_VALUE   Value = NULL;
    LARGE_INTEGER   systemtime;
    ULONG           mustChange=FALSE;
    ULONG           ChildIndex;
    HCELL_INDEX     ParentToRelease = HCELL_NIL;
    HCELL_INDEX     ChildToRelease = HCELL_NIL;

    PERFINFO_REG_SET_VALUE_DECL();

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmSetValueKey\n"));

    CmpLockRegistry();

    ASSERT(sizeof(ULONG) == CM_KEY_VALUE_SMALL);

    PERFINFO_REG_SET_VALUE(KeyControlBlock);

    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    while (TRUE) {
        //
        // Check that we are not being asked to add a value to a key
        // that has been deleted
        //
        if (KeyControlBlock->Delete == TRUE) {
            status = STATUS_KEY_DELETED;
            goto Exit;
        }

        //
        // Check to see if this is a symbolic link node.  If so caller
        // is only allowed to create/change the SymbolicLinkValue
        // value name
        //

#ifdef CMP_KCB_CACHE_VALIDATION
        {
            PCM_KEY_NODE    Node;
            Node = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
            if( Node == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
        
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto Exit;
            }
            ASSERT( Node->Flags == KeyControlBlock->Flags );
            HvReleaseCell(KeyControlBlock->KeyHive, KeyControlBlock->KeyCell);
        }
#endif
        if (KeyControlBlock->Flags & KEY_SYM_LINK &&
            (( (Type != REG_LINK) 
#ifdef CM_DYN_SYM_LINK
            && (Type != REG_DYN_LINK)
#endif //CM_DYN_SYM_LINK
            ) ||
             ValueName == NULL ||
             !RtlEqualUnicodeString(&CmSymbolicLinkValueName, ValueName, TRUE)))
        {
            //
            // Disallow attempts to manipulate any value names under a symbolic link
            // except for the "SymbolicLinkValue" value name or type other than REG_LINK
            //

            // Mark the hive as read only
            CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

            status = STATUS_ACCESS_DENIED;
            goto Exit;
        }

        if( mustChange == FALSE ) {
            //
            // first iteration; look inside the kcb cache
            //
            
            if( CmpCompareNewValueDataAgainstKCBCache(KeyControlBlock,ValueName,Type,Data,DataSize) == TRUE ) {
                //
                // the value is in the cache and is the same; make this call a noop
                //
                status = STATUS_SUCCESS;
                goto Exit;
            }
            //
            // To Get here, we must either be changing a value, or setting a new one
            //
            mustChange=TRUE;
        } else {
            //
            // second iteration; look inside the hive
            //

            
            //
            // get reference to parent key,
            //
            Hive = KeyControlBlock->KeyHive;
            Cell = KeyControlBlock->KeyCell;
            if( ParentToRelease != HCELL_NIL ) {
                HvReleaseCell(Hive,ParentToRelease);
                ParentToRelease = HCELL_NIL;
            }
            parent = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
            if( parent == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
        
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto Exit;
            }
            ParentToRelease = Cell;
            //
            // try to find an existing value entry by the same name
            //
            count = parent->ValueList.Count;
            found = FALSE;

            if (count > 0) {
                if( CmpFindNameInList(Hive,
                                     &parent->ValueList,
                                     ValueName,
                                     &ChildIndex,
                                     &oldchild) == FALSE ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
        
                    status = STATUS_INSUFFICIENT_RESOURCES;
                    goto Exit;
                }

                if (oldchild != HCELL_NIL) {
                    if( ChildToRelease != HCELL_NIL ) {
                        HvReleaseCell(Hive,ChildToRelease);
                        ChildToRelease = HCELL_NIL;
                    }
                    Value = (PCM_KEY_VALUE)HvGetCell(Hive,oldchild);
                    if( Value == NULL ) {
                        //
                        // could no map view
                        //
                        status = STATUS_INSUFFICIENT_RESOURCES;
                        goto Exit;
                    }
                    ChildToRelease = oldchild;
                    found = TRUE;
                }
            } else {
                //
                // empty list; add it first
                //
                ChildIndex = 0;
            }

            //
            // Performance Hack:
            // If a Set is asking us to set a key to the current value (IE does this a lot)
            // drop it (and, therefore, the last modified time) on the floor, but return success
            // this stops the page from being dirtied, and us having to flush the registry.
            //
            //
            break;
        }

        //
        // We're going through these gyrations so that if someone does come in and try and delete the
        // key we're setting we're safe. Once we know we have to change the key, take the
        // Exclusive (write) lock then restart
        //
        //
        CmpUnlockRegistry();
        CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    }// while

    ASSERT( mustChange == TRUE );

    // It's a different or new value, mark it dirty, since we'll
    // at least set its time stamp

    if (! HvMarkCellDirty(Hive, Cell)) {
        status = STATUS_NO_LOG_SPACE;
        goto Exit;
    }

    StorageType = HvGetCellType(Cell);

    //
    // stash small data if relevent
    //
    TempData = 0;
    if ((DataSize <= CM_KEY_VALUE_SMALL) &&
        (DataSize > 0))
    {
        try {
            RtlCopyMemory(          // yes, move memory, could be 1 byte
                &TempData,          // at the end of a page.
                Data,
                DataSize
                );
         } except (EXCEPTION_EXECUTE_HANDLER) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmSetValueKey: code:%08lx\n", GetExceptionCode()));
            status = GetExceptionCode();
            goto Exit;
        }
    }

    if (found) {

        //
        // ----- Existing Value Entry Path -----
        //

        //
        // An existing value entry of the specified name exists,
        // set our data into it.
        //
        status = CmpSetValueKeyExisting(Hive,
                                        oldchild,
                                        Value,
                                        Type,
                                        Data,
                                        DataSize,
                                        StorageType,
                                        TempData);

        PERFINFO_REG_SET_VALUE_EXIST();
    } else {

        //
        // ----- New Value Entry Path -----
        //

        //
        // Either there are no existing value entries, or the one
        // specified is not in the list.  In either case, create and
        // fill a new one, and add it to the list
        //
        status = CmpSetValueKeyNew(Hive,
                                   parent,
                                   ValueName,
                                   ChildIndex,
                                   Type,
                                   Data,
                                   DataSize,
                                   StorageType,
                                   TempData);
        PERFINFO_REG_SET_VALUE_NEW();
    }

    if (NT_SUCCESS(status)) {

        // sanity assert
        ASSERT( parent->MaxValueNameLen == KeyControlBlock->KcbMaxValueNameLen );
        if (parent->MaxValueNameLen < ValueName->Length) {
            parent->MaxValueNameLen = ValueName->Length;
            // update the kcb cache too
            KeyControlBlock->KcbMaxValueNameLen = ValueName->Length;
        }

        //sanity assert
        ASSERT( parent->MaxValueDataLen == KeyControlBlock->KcbMaxValueDataLen );
        if (parent->MaxValueDataLen < DataSize) {
            parent->MaxValueDataLen = DataSize;
            // update the kcb cache too
            KeyControlBlock->KcbMaxValueDataLen = parent->MaxValueDataLen;
        }

        KeQuerySystemTime(&systemtime);
        parent->LastWriteTime = systemtime;
        // update the kcb cache too.
        KeyControlBlock->KcbLastWriteTime = systemtime;
    
        //
        // Update the cache, no need for KCB lock as the registry is locked exclusively.
        //
        ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

        if( found && (CMP_IS_CELL_CACHED(KeyControlBlock->ValueCache.ValueList)) ) {
            //
            // invalidate only the entry we changed.
            //
            PULONG_PTR CachedList = (PULONG_PTR) CMP_GET_CACHED_CELLDATA(KeyControlBlock->ValueCache.ValueList);
            if (CMP_IS_CELL_CACHED(CachedList[ChildIndex])) {

                ExFreePool((PVOID) CMP_GET_CACHED_ADDRESS(CachedList[ChildIndex]));
            }
            CachedList[ChildIndex] = oldchild;

        } else {
            //
            // rebuild ALL KCB cache
            // 
            CmpCleanUpKcbValueCache(KeyControlBlock);
            CmpSetUpKcbValueCache(KeyControlBlock,parent->ValueList.Count,parent->ValueList.List);
        }
        CmpReportNotify(KeyControlBlock,
                        KeyControlBlock->KeyHive,
                        KeyControlBlock->KeyCell,
                        REG_NOTIFY_CHANGE_LAST_SET);
    }

Exit:
    PERFINFO_REG_SET_VALUE_DONE(ValueName);

    if( ParentToRelease != HCELL_NIL && Hive != NULL) {
        HvReleaseCell(Hive,ParentToRelease);
    }
    if( ChildToRelease != HCELL_NIL && Hive != NULL) {
        HvReleaseCell(Hive,ChildToRelease);
    }

    CmpUnlockRegistry();
  
    // Mark the hive as read only
    CmpMarkAllBinsReadOnly(KeyControlBlock->KeyHive);

    return status;
}


NTSTATUS
CmpSetValueKeyExisting(
    IN PHHIVE  Hive,
    IN HCELL_INDEX OldChild,
    IN PCM_KEY_VALUE Value,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize,
    IN ULONG StorageType,
    IN ULONG TempData
    )
/*++

Routine Description:

    Helper for CmSetValueKey, implements the case where the value entry
    being set already exists.

Arguments:

    Hive - hive of interest

    OldChild - hcell_index of the value entry body to which we are to
                    set new data

    Type - The integer type number of the value entry.

    Data - Pointer to buffer with actual data for the value entry.

    DataSize - Size of Data buffer.

    StorageType - stable or volatile

    TempData - small values are passed here

Return Value:

    STATUS_SUCCESS if it worked, appropriate status code if it did not

Note: 
    
    For new hives format, we have the following cases:

    New Data                Old Data
    --------                --------

1.  small                   small
2.  small                   normal
3.  small                   bigdata
4.  normal                  small
5.  normal                  normal
6.  normal                  bigdata
7.  bigdata                 small
8.  bigdata                 normal
9.  bigdata                 bigdata  



--*/
{
    HCELL_INDEX     DataCell;
    HCELL_INDEX     OldDataCell;
    PCELL_DATA      pdata;
    HCELL_INDEX     NewCell;
    ULONG           OldRealSize;
    USHORT          OldSizeType;    // 0 - small
    USHORT          NewSizeType;    // 1 - normal
                                    // 2 - bigdata
    HANDLE          hSecure = 0;
    NTSTATUS        status = STATUS_SUCCESS;

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();


    //
    // value entry by the specified name already exists
    // oldchild is hcell_index of its value entry body
    //  which we will always edit, so mark it dirty
    //
    if (! HvMarkCellDirty(Hive, OldChild)) {
        return STATUS_NO_LOG_SPACE;
    }

    if(CmpIsHKeyValueSmall(OldRealSize, Value->DataLength) == TRUE ) {
        //
        // old data was small
        //
        OldSizeType = 0;
    } else if( CmpIsHKeyValueBig(Hive,OldRealSize) == TRUE ) {
        //
        // old data was big
        //
        OldSizeType = 2;
    } else {
        //
        // old data was normal
        //
        OldSizeType = 1;
    }

    if( DataSize <= CM_KEY_VALUE_SMALL ) {
        //
        // new data is small
        //
        NewSizeType = 0;
    } else if( CmpIsHKeyValueBig(Hive,DataSize) == TRUE ) {
        //
        // new data is big
        //
        NewSizeType = 2;
    } else {
        //
        // new data is normal
        //
        NewSizeType = 1;
    }


    //
    // this will handle all cases and will make sure data is marked dirty 
    //
    if( !CmpMarkValueDataDirty(Hive,Value) ) {
        return STATUS_NO_LOG_SPACE;
    }

    //
    // cases 1,2,3
    //
    if( NewSizeType == 0 ) {
        if( ((OldSizeType == 1) && (OldRealSize > 0) ) ||
            (OldSizeType == 2) 
            ) {
            CmpFreeValueData(Hive,Value->Data,OldRealSize);
        }
        
        //
        // write our new small data into value entry body
        //
        Value->DataLength = DataSize + CM_KEY_VALUE_SPECIAL_SIZE;
        Value->Data = TempData;
        Value->Type = Type;

        return STATUS_SUCCESS;
    }
    
    //
    // secure the user buffer so we don't get inconsistencies.
    // ONLY if we are called with a user mode buffer !!!
    //

    if ( (ULONG_PTR)Data <= (ULONG_PTR)MM_HIGHEST_USER_ADDRESS ) {
        hSecure = MmSecureVirtualMemory(Data,DataSize, PAGE_READONLY);
        if (hSecure == 0) {
            return STATUS_INVALID_PARAMETER;
        }
    }
    
    //
    // store it to be freed if the allocation succeeds
    //
    OldDataCell = Value->Data;

    //
    // cases 4,5,6
    //
    if( NewSizeType == 1 ){

        if( (OldSizeType == 1) && (OldRealSize > 0)) { 
            //
            // we already have a cell; see if we can reuse it !
            //
            DataCell = Value->Data;
            ASSERT(DataCell != HCELL_NIL);
            pdata = HvGetCell(Hive, DataCell);
            if( pdata == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto Exit;
            }
            // release it right here, as the registry is locked exclusively, so we don't care
            HvReleaseCell(Hive, DataCell);

            ASSERT(HvGetCellSize(Hive, pdata) > 0);

            if (DataSize <= (ULONG)(HvGetCellSize(Hive, pdata))) {

                //
                // The existing data cell is big enough to hold the new data.  
                //

                //
                // we'll keep this cell
                //
                NewCell = DataCell;

            } else {
                //
                // grow the existing cell
                //
                NewCell = HvReallocateCell(Hive,DataCell,DataSize);
                if (NewCell == HCELL_NIL) {
                    status = STATUS_INSUFFICIENT_RESOURCES;
                    goto Exit;
                }
            }

        } else {
            //
            // allocate a new cell 
            //
            NewCell = HvAllocateCell(Hive, DataSize, StorageType,(HvGetCellType(OldChild)==StorageType)?OldChild:HCELL_NIL);

            if (NewCell == HCELL_NIL) {
                status = STATUS_INSUFFICIENT_RESOURCES;
                goto Exit;
            }
        }
     
        //
        // now we have a cell that can accomodate the data
        //
        pdata = HvGetCell(Hive, NewCell);
        if( pdata == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            // this shouldn't happen as we just allocated/ reallocated/ marked dirty this cell
            //
            ASSERT( FALSE );
            status = STATUS_INSUFFICIENT_RESOURCES;
            goto Exit;
        }
        // release it right here, as the registry is locked exclusively, so we don't care
        HvReleaseCell(Hive, NewCell);

        //
        // copy the actual data
        //
        RtlCopyMemory(pdata,Data,DataSize);
        Value->Data = NewCell;
        Value->DataLength = DataSize;
        Value->Type = Type;
        
        // sanity
        ASSERT_CELL_DIRTY(Hive,NewCell);

        if( OldSizeType == 2 ) {
            //
            // old data was big; free it
            //
            ASSERT( OldDataCell != NewCell );
            CmpFreeValueData(Hive,OldDataCell,OldRealSize);
        }

        status = STATUS_SUCCESS;
        goto Exit;
    }
    
    //
    // cases 7,8,9
    //
    if( NewSizeType == 2 ) {

        if( OldSizeType == 2 ) { 
            //
            // data was previously big; grow it!
            //
            
            status =CmpSetValueDataExisting(Hive,Data,DataSize,StorageType,OldDataCell);
            if( !NT_SUCCESS(status) ) {
                goto Exit;
            }
            NewCell = OldDataCell;
            
        } else {
            //
            // data was small or normal. 
            // allocate and copy to a new big data cell; 
            // then free the old cell
            //
            status = CmpSetValueDataNew(Hive,Data,DataSize,StorageType,OldChild,&NewCell);
            if( !NT_SUCCESS(status) ) {
                //
                // We have bombed out loading user data, clean up and exit.
                //
                goto Exit;
            }
            
            if( (OldSizeType != 0) && (OldRealSize != 0) ) {
                //
                // there is something to free
                //
                HvFreeCell(Hive, Value->Data);
            }
        }

        Value->DataLength = DataSize;
        Value->Data = NewCell;
        Value->Type = Type;

        // sanity
        ASSERT_CELL_DIRTY(Hive,NewCell);

        status = STATUS_SUCCESS;
        goto Exit;

    }

    //
    // we shouldn't get here
    //
    ASSERT( FALSE );

Exit:
    if( hSecure) {
        MmUnsecureVirtualMemory(hSecure);
    }
    return status;
}

NTSTATUS
CmpSetValueKeyNew(
    IN PHHIVE  Hive,
    IN PCM_KEY_NODE Parent,
    IN PUNICODE_STRING ValueName,
    IN ULONG Index,
    IN ULONG Type,
    IN PVOID Data,
    IN ULONG DataSize,
    IN ULONG StorageType,
    IN ULONG TempData
    )
/*++

Routine Description:

    Helper for CmSetValueKey, implements the case where the value entry
    being set does not exist.  Will create new value entry and data,
    place in list (which may be created)

Arguments:

    Hive - hive of interest

    Parent - pointer to key node value entry is for

    ValueName - The unique (relative to the containing key) name
        of the value entry.  May be NULL.

    Index - where in the list should this value be inserted

    Type - The integer type number of the value entry.

    Data - Pointer to buffer with actual data for the value entry.

    DataSize - Size of Data buffer.

    StorageType - stable or volatile

    TempData - small data values passed here


Return Value:

    STATUS_SUCCESS if it worked, appropriate status code if it did not

--*/
{
    PCELL_DATA  pvalue;
    HCELL_INDEX ValueCell;
    NTSTATUS    Status;

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    //
    // Either Count == 0 (no list) or our entry is simply not in
    // the list.  Create a new value entry body, and data.  Add to list.
    // (May create the list.)
    //
    if (Parent->ValueList.Count != 0) {
        ASSERT(Parent->ValueList.List != HCELL_NIL);
        if (! HvMarkCellDirty(Hive, Parent->ValueList.List)) {
            return STATUS_NO_LOG_SPACE;
        }
    }

    //
    // allocate the body of the value entry, and the data
    //
    ValueCell = HvAllocateCell(
                    Hive,
                    CmpHKeyValueSize(Hive, ValueName),
                    StorageType,
                    HCELL_NIL
                    );

    if (ValueCell == HCELL_NIL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // map in the body, and fill in its fixed portion
    //
    pvalue = HvGetCell(Hive, ValueCell);
    if( pvalue == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        //
        // normally this shouldn't happen as we just allocated ValueCell
        // i.e. the bin containing ValueCell should be mapped in memory at this point.
        //
        ASSERT( FALSE );
        HvFreeCell(Hive, ValueCell);
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    // release it right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, ValueCell);

    // sanity
    ASSERT_CELL_DIRTY(Hive,ValueCell);

    pvalue->u.KeyValue.Signature = CM_KEY_VALUE_SIGNATURE;

    //
    // fill in the variable portions of the new value entry,  name and
    // and data are copied from caller space, could fault.
    //
    try {

        //
        // fill in the name
        //
        pvalue->u.KeyValue.NameLength = CmpCopyName(Hive,
                                                    pvalue->u.KeyValue.Name,
                                                    ValueName);
    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmSetValueKey: code:%08lx\n", GetExceptionCode()));

        //
        // We have bombed out loading user data, clean up and exit.
        //
        HvFreeCell(Hive, ValueCell);
        return GetExceptionCode();
    }

    if (pvalue->u.KeyValue.NameLength < ValueName->Length) {
        pvalue->u.KeyValue.Flags = VALUE_COMP_NAME;
    } else {
        pvalue->u.KeyValue.Flags = 0;
    }

    //
    // fill in the data
    //
    if (DataSize > CM_KEY_VALUE_SMALL) {
        Status = CmpSetValueDataNew(Hive,Data,DataSize,StorageType,ValueCell,&(pvalue->u.KeyValue.Data));
        if( !NT_SUCCESS(Status) ) {
            //
            // We have bombed out loading user data, clean up and exit.
            //
            HvFreeCell(Hive, ValueCell);
            return Status;
        }

        pvalue->u.KeyValue.DataLength = DataSize;
        // sanity
        ASSERT_CELL_DIRTY(Hive,pvalue->u.KeyValue.Data);

    } else {
        pvalue->u.KeyValue.DataLength = DataSize + CM_KEY_VALUE_SPECIAL_SIZE;
        pvalue->u.KeyValue.Data = TempData;
    }
    pvalue->u.KeyValue.Type = Type;

    if( !NT_SUCCESS(CmpAddValueToList(Hive,ValueCell,Index,StorageType,&(Parent->ValueList)) ) ) {
        // out of space, free all allocated stuff
        // this will free embeded cigdata cell info too (if any)
        CmpFreeValue(Hive,ValueCell);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    return STATUS_SUCCESS;
}

NTSTATUS
CmSetLastWriteTimeKey(
    IN PCM_KEY_CONTROL_BLOCK KeyControlBlock,
    IN PLARGE_INTEGER LastWriteTime
    )
/*++

Routine Description:

    The LastWriteTime associated with a key node can be set with
    CmSetLastWriteTimeKey

Arguments:

    KeyControlBlock - pointer to kcb for the key to operate on

    LastWriteTime - new time for key

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    PCM_KEY_NODE parent;
    PHHIVE      Hive;
    HCELL_INDEX Cell;
    NTSTATUS    status = STATUS_SUCCESS;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmSetLastWriteTimeKey\n"));

    CmpLockRegistryExclusive();

    //
    // Check that we are not being asked to modify a key
    // that has been deleted
    //
    if (KeyControlBlock->Delete == TRUE) {
        status = STATUS_KEY_DELETED;
        goto Exit;
    }

    Hive = KeyControlBlock->KeyHive;
    Cell = KeyControlBlock->KeyCell;
    parent = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
    if( parent == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        status = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit;
    }

    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, Cell);

    if (! HvMarkCellDirty(Hive, Cell)) {
        status = STATUS_NO_LOG_SPACE;
        goto Exit;
    }

    parent->LastWriteTime = *LastWriteTime;
    // update the kcb cache too.
    KeyControlBlock->KcbLastWriteTime = *LastWriteTime;

Exit:

    CmpUnlockRegistry();
    return status;
}

NTSTATUS
CmSetKeyUserFlags(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN ULONG                    UserFlags
    )
/*++

Routine Description:

    Sets the user defined flags for the key; At this point there are only 
    4 bits reserved for user defined flags. kcb and knode must be kept in 
    sync.

Arguments:

    KeyControlBlock - pointer to kcb for the key to operate on

    UserFlags - user defined flags to be set on this key.

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    PCM_KEY_NODE    Node;
    PHHIVE          Hive;
    HCELL_INDEX     Cell;
    LARGE_INTEGER   LastWriteTime;
    NTSTATUS        status = STATUS_SUCCESS;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmSetKeyUserFlags\n"));

    CmpLockRegistryExclusive();

    //
    // Check that we are not being asked to modify a key
    // that has been deleted
    //
    if (KeyControlBlock->Delete == TRUE) {
        status = STATUS_KEY_DELETED;
        goto Exit;
    }

    if( UserFlags & (~((ULONG)KEY_USER_FLAGS_VALID_MASK)) ) {
        //
        // number of user defined flags exceeded; punt
        //
        status = STATUS_INVALID_PARAMETER;
        goto Exit;

    }

    Hive = KeyControlBlock->KeyHive;
    Cell = KeyControlBlock->KeyCell;

    Node = (PCM_KEY_NODE)HvGetCell(Hive, Cell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        status = STATUS_INSUFFICIENT_RESOURCES;
        goto Exit;
    }

    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, Cell);

    if (! HvMarkCellDirty(Hive, Cell)) {
        status = STATUS_NO_LOG_SPACE;
        goto Exit;
    }
    
    //
    // shift/(pack) the user defined flags and
    // update knode and kcb cache
    //
    // first, erase the old flags
    Node->Flags &= KEY_USER_FLAGS_CLEAR_MASK;
    Node->Flags |= (USHORT)(UserFlags<<KEY_USER_FLAGS_SHIFT);
    // update the kcb cache
    KeyControlBlock->Flags = Node->Flags;

    //
    // we need to update the LstWriteTime as well
    //
    KeQuerySystemTime(&LastWriteTime);
    Node->LastWriteTime = LastWriteTime;
    // update the kcb cache too.
    KeyControlBlock->KcbLastWriteTime = LastWriteTime;

Exit:
    CmpUnlockRegistry();
    return status;
}

BOOLEAN
CmpIsHiveAlreadyLoaded( IN HANDLE KeyHandle,
                        IN POBJECT_ATTRIBUTES SourceFile,
                        OUT PCMHIVE *CmHive
                        )
/*++

Routine Description:

    Checks if the SourceFile is already loaded in the same spot as KeyHandle.

Arguments:

    KeyHandle - should be the root of a hive. We'll query the name of the primary file
                and compare it against the name of SourceFile

    SourceFile - specifies a file.  while file could be remote,
                that is strongly discouraged.

Return Value:

    TRUE/FALSE
--*/
{
    NTSTATUS                    status;
    PCM_KEY_BODY                KeyBody;
    BOOLEAN                     Result = FALSE; // pesimistic
    
    PAGED_CODE();

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    status = ObReferenceObjectByHandle(KeyHandle,
                                       0,
                                       CmpKeyObjectType,
                                       KernelMode,
                                       (PVOID *)(&KeyBody),
                                       NULL);
    if(!NT_SUCCESS(status)) {
        return FALSE;
    }

	if( KeyBody->KeyControlBlock->Delete ) {
		return FALSE;	
	}
    
    *CmHive = (PCMHIVE)CONTAINING_RECORD(KeyBody->KeyControlBlock->KeyHive, CMHIVE, Hive);

    //
    // should be the root of a hive
    // 
    if( !(KeyBody->KeyControlBlock->Flags & KEY_HIVE_ENTRY) || // not root of a hive
        ((*CmHive)->FileUserName.Buffer == NULL)// no name captured
        ) {
        goto ExitCleanup;
    }
    
    if( RtlCompareUnicodeString(&((*CmHive)->FileUserName),
                                SourceFile->ObjectName,
                                TRUE) == 0 ) {
        //
        // same file; same spot
        //
        Result = TRUE;
        //
        // unfreeze the hive;hive will become just a regular hive from now on
        // it is safe to do this because we hold an extra refcount on the root of the hive
        // as we have specifically opened the root to check if it's already loaded
        //
        if( IsHiveFrozen(*CmHive) ) {
            (*CmHive)->Frozen = FALSE;
            if( (*CmHive)->UnloadWorkItem != NULL ) {
                ExFreePool( (*CmHive)->UnloadWorkItem );
                (*CmHive)->UnloadWorkItem = NULL;
            }
            if( (*CmHive)->RootKcb ) {
                CmpDereferenceKeyControlBlockWithLock((*CmHive)->RootKcb);
                (*CmHive)->RootKcb = NULL;
            }

        }

    }
    
ExitCleanup:
    ObDereferenceObject((PVOID)KeyBody);
    return Result;
}


NTSTATUS
CmLoadKey(
    IN POBJECT_ATTRIBUTES   TargetKey,
    IN POBJECT_ATTRIBUTES   SourceFile,
    IN ULONG                Flags,
    IN PCM_KEY_BODY         KeyBody
    )

/*++

Routine Description:

    A hive (file in the format created by NtSaveKey) may be linked
    into the active registry with this call.  UNLIKE NtRestoreKey,
    the file specified to NtLoadKey will become the actual backing
    store of part of the registry (that is, it will NOT be copied.)

    The file may have an associated .log file.

    If the hive file is marked as needing a .log file, and one is
    not present, the call will fail.

    The name specified by SourceFile must be such that ".log" can
    be appended to it to generate the name of the log file.  Thus,
    on FAT file systems, the hive file may not have an extension.

    This call is used by logon to make the user's profile available
    in the registry.  It is not intended for use doing backup,
    restore, etc.  Use NtRestoreKey for that.

    N.B.  This routine assumes that the object attributes for the file
          to be opened have been captured into kernel space so that
          they can safely be passed to the worker thread to open the file
          and do the actual I/O.

Arguments:

    TargetKey - specifies the path to a key to link the hive to.
                path must be of the form "\registry\user\<username>"

    SourceFile - specifies a file.  while file could be remote,
                that is strongly discouraged.

    Flags - specifies any flags that should be used for the load operation.
            The only valid flag is REG_NO_LAZY_FLUSH.

Return Value:

    NTSTATUS - values TBS.

--*/
{
    PCMHIVE                     NewHive;
    NTSTATUS                    Status;
    BOOLEAN                     Allocate;
    BOOLEAN                     RegistryLockAquired;
    SECURITY_QUALITY_OF_SERVICE ServiceQos;
    SECURITY_CLIENT_CONTEXT     ClientSecurityContext;
    HANDLE                      KeyHandle;
    PCMHIVE                     OtherHive = NULL;
    CM_PARSE_CONTEXT            ParseContext;


    if( KeyBody != NULL ) {
        OtherHive = (PCMHIVE)CONTAINING_RECORD(KeyBody->KeyControlBlock->KeyHive, CMHIVE, Hive);
        if( ! (OtherHive->Flags & CM_CMHIVE_FLAG_UNTRUSTED) ) {
            //
            // deny attempts to join the TRUSTED class of trust
            //
            return STATUS_INVALID_PARAMETER;
        }
    }


    //
    // Obtain the security context here so we can use it
    // later to impersonate the user, which we will do
    // if we cannot access the file as SYSTEM.  This
    // usually occurs if the file is on a remote machine.
    //
    ServiceQos.Length = sizeof(SECURITY_QUALITY_OF_SERVICE);
    ServiceQos.ImpersonationLevel = SecurityImpersonation;
    ServiceQos.ContextTrackingMode = SECURITY_DYNAMIC_TRACKING;
    ServiceQos.EffectiveOnly = TRUE;
    Status = SeCreateClientSecurity(CONTAINING_RECORD(KeGetCurrentThread(),ETHREAD,Tcb),
                                    &ServiceQos,
                                    FALSE,
                                    &ClientSecurityContext);
    if (!NT_SUCCESS(Status)) {
        return(Status);
    }

    RtlZeroMemory(&ParseContext,sizeof(CM_PARSE_CONTEXT));
    ParseContext.CreateOperation = FALSE;
    //
    // we open the root of the hive here. if it already exists,this will prevent it from going
    // away from under us while we are doing the "already loaded" check (due to delay unload logic)
    //
    Status = ObOpenObjectByName(TargetKey,
                                CmpKeyObjectType,
                                KernelMode,
                                NULL,
                                KEY_READ,
                                (PVOID)&ParseContext,
                                &KeyHandle);
    if(!NT_SUCCESS(Status)) {
        KeyHandle = NULL;
    }

    //
    // Do not lock the registry; Instead set the RegistryLockAquired member 
    // of REGISTRY_COMMAND so CmpWorker can lock it after opening the hive files
    //
    //CmpLockRegistryExclusive();
    //

    RegistryLockAquired = FALSE;
    Allocate = TRUE;
    Status = CmpCmdHiveOpen(    SourceFile,             // FileAttributes
                                &ClientSecurityContext, // ImpersonationContext
                                &Allocate,              // Allocate
                                &RegistryLockAquired,   // RegistryLockAquired
                                &NewHive,               // NewHive
								CM_CHECK_REGISTRY_CHECK_CLEAN //CheckFlags
                            );

    SeDeleteClientSecurity( &ClientSecurityContext );


    if (!NT_SUCCESS(Status)) {
        if( KeyHandle != NULL ) {
            PCMHIVE LoadedHive = NULL;
            
            //
            // lock the registry exclusive while we are checking attempt to load same file into the same spot
            //
            if( !RegistryLockAquired ) {
                CmpLockRegistryExclusive();
                RegistryLockAquired = TRUE;
            }
            
            //
            // check if the same file is loaded in the same spot
            //
            if( CmpIsHiveAlreadyLoaded(KeyHandle,SourceFile,&LoadedHive) ) {
                ASSERT( LoadedHive );
                if( OtherHive != NULL ) {
                    //
                    // unjoin the existing class (if any) and join the new one
                    //
                    CmpUnJoinClassOfTrust(LoadedHive);
                    CmpJoinClassOfTrust(LoadedHive,OtherHive);
                    LoadedHive->Flags |= CM_CMHIVE_FLAG_UNTRUSTED;
                }
                Status = STATUS_SUCCESS;
            }
        }
        
        if( RegistryLockAquired ) {
            // if CmpWorker has locked the registry, unlock it now.
            CmpUnlockRegistry();
        }

        if( KeyHandle != NULL ) {
            ZwClose(KeyHandle);
        }
        return(Status);
    } else {
        //
        // if we got here, CmpWorker should have locked the registry exclusive.
        //
        ASSERT( RegistryLockAquired );
    }

    //
    // if this is a NO_LAZY_FLUSH hive, set the appropriate bit.
    //
    if (Flags & REG_NO_LAZY_FLUSH) {
        NewHive->Hive.HiveFlags |= HIVE_NOLAZYFLUSH;
    }
    //
    // mark the hive as untrusted
    //
    NewHive->Flags |= CM_CMHIVE_FLAG_UNTRUSTED;
    if( OtherHive != NULL ) {
        //
        // join the same class of trust with the otherhive
        //
        CmpJoinClassOfTrust(NewHive,OtherHive);
    }
    //
    // We now have a succesfully loaded and initialized CmHive, so we
    // just need to link that into the appropriate spot in the master hive.
    //
    Status = CmpLinkHiveToMaster(TargetKey->ObjectName,
                                 TargetKey->RootDirectory,
                                 NewHive,
                                 Allocate,
                                 TargetKey->SecurityDescriptor);

    if (NT_SUCCESS(Status)) {
        //
        // add new hive to hivelist
        //
        CmpAddToHiveFileList(NewHive);
        //
        // flush the hive right here if just created; this is to avoid situations where 
        // the lazy flusher doesn't get a chance to flush the hive, or it can't (because
        // the hive is a no_lazy_flush hive and it is never explicitly flushed)
        // 
        if( Allocate == TRUE ) {
            HvSyncHive(&(NewHive->Hive));
        }

    } else {
        LOCK_HIVE_LIST();
        CmpRemoveEntryList(&(NewHive->HiveList));
        UNLOCK_HIVE_LIST();

        CmpCheckForOrphanedKcbs((PHHIVE)NewHive);

        CmpDestroyHiveViewList(NewHive);
        CmpDestroySecurityCache (NewHive);
        CmpDropFileObjectForHive(NewHive);
        CmpUnJoinClassOfTrust(NewHive);

        HvFreeHive((PHHIVE)NewHive);

        //
        // Close the hive files
        //
        CmpCmdHiveClose(NewHive);

        //
        // free the cm level structure
        //
        ASSERT( NewHive->HiveLock );
        ExFreePool(NewHive->HiveLock);
        ASSERT( NewHive->ViewLock );
        ExFreePool(NewHive->ViewLock);
        CmpFree(NewHive, sizeof(CMHIVE));
    }

    //
    // We've given user chance to log on, so turn on quota
    //
    if ((CmpProfileLoaded == FALSE) &&
        (CmpWasSetupBoot == FALSE)) {
        CmpProfileLoaded = TRUE;
        CmpSetGlobalQuotaAllowed();
    }

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    CmpUnlockRegistry();

    if( KeyHandle != NULL ) {
        ZwClose(KeyHandle);
    }
    return(Status);
}

#if DBG
ULONG
CmpUnloadKeyWorker(
    PCM_KEY_CONTROL_BLOCK Current,
    PVOID                 Context1,
    PVOID                 Context2
    )
{
    PUNICODE_STRING ConstructedName;

    UNREFERENCED_PARAMETER (Context2);

    if (Current->KeyHive == Context1) {
        ConstructedName = CmpConstructName(Current);

        if (ConstructedName) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"%wZ\n", ConstructedName));
            ExFreePoolWithTag(ConstructedName, CM_NAME_TAG | PROTECTED_POOL);
        }
    }
    return KCB_WORKER_CONTINUE;   // always keep searching
}
#endif

NTSTATUS
CmUnloadKey(
    IN PHHIVE                   Hive,
    IN HCELL_INDEX              Cell,
    IN PCM_KEY_CONTROL_BLOCK    Kcb,
    IN ULONG                    Flags
    )

/*++

Routine Description:

    Unlinks a hive from its location in the registry, closes its file
    handles, and deallocates all its memory.

    There must be no key control blocks currently referencing the hive
    to be unloaded.

Arguments:

    Hive - Supplies a pointer to the hive control structure for the
           hive to be unloaded

    Cell - supplies the HCELL_INDEX for the root cell of the hive.

    Kcb - Supplies the key control block

    Flags - REG_FORCE_UNLOAD will first mark open handles as invalid 
            and then unload the hive.

Return Value:

    NTSTATUS

--*/

{
    PCMHIVE CmHive;
    LOGICAL Success;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmUnloadKey\n"));

    //
    // Make sure the cell passed in is the root cell of the hive.
    //
    if((Cell != Hive->BaseBlock->RootCell) || ((PCMHIVE)Hive == CmpMasterHive)) {
        return(STATUS_INVALID_PARAMETER);
    }

    //
    // Make sure there are no open references to key control blocks
    // for this hive.  If there are none, then we can unload the hive.
    //

    CmHive = CONTAINING_RECORD(Hive, CMHIVE, Hive);
    if(Kcb->RefCount != 1) {
        if( Flags == REG_FORCE_UNLOAD ) {
            //
            // this will mark open handles as invalid.
            //
            CmpSearchForOpenSubKeys(Kcb, SearchAndDeref,NULL);
        } else {
            Success = (CmpSearchForOpenSubKeys(Kcb,SearchIfExist,NULL) == 0);
            Success = Success && (Kcb->RefCount == 1);
        
            if( Success == FALSE) {
#if DBG
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"List of keys open against hive unload was attempted on:\n"));
                CmpSearchKeyControlBlockTree(
                    CmpUnloadKeyWorker,
                    Hive,
                    NULL
                    );
#endif
                return STATUS_CANNOT_DELETE;
            }
            ASSERT( Kcb->RefCount == 1 );
        }
    }

    //
    // Flush any dirty data to disk. If this fails, too bad.
    //
    CmFlushKey(Hive, Cell);

    //
    // Remove the hive from the HiveFileList
    //
    CmpRemoveFromHiveFileList((PCMHIVE)Hive);

    //
    // Unlink from master hive, remove from list
    //
    Success = CmpDestroyHive(Hive, Cell);

    if (Success) {
        //
        // signal the user event (if any), then do the cleanup (i.e. deref the event
        // and the artificial refcount we set on the root kcb)
        //
        if( CmHive->UnloadEvent != NULL ) {
            KeSetEvent(CmHive->UnloadEvent,0,FALSE);
            ObDereferenceObject(CmHive->UnloadEvent);
        }

        CmpDestroyHiveViewList(CmHive);
        CmpDestroySecurityCache (CmHive);
        CmpDropFileObjectForHive(CmHive);
        CmpUnJoinClassOfTrust(CmHive);

        HvFreeHive(Hive);

        //
        // Close the hive files
        //
        CmpCmdHiveClose(CmHive);

        //
        // free the cm level structure
        //
        ASSERT( CmHive->HiveLock );
        ExFreePool(CmHive->HiveLock);
        ASSERT( CmHive->ViewLock );
        ExFreePool(CmHive->ViewLock);
        CmpFree(CmHive, sizeof(CMHIVE));

        return(STATUS_SUCCESS);
    } else {
        return(STATUS_INSUFFICIENT_RESOURCES);
    }

}

#ifdef NT_UNLOAD_KEY_EX
NTSTATUS
CmUnloadKeyEx(
    IN PCM_KEY_CONTROL_BLOCK kcb,
    IN PKEVENT UserEvent
    )

/*++

Routine Description:

    First tries to unlink the hive, by calling the sync version
    
    If the hive cannot be unloaded (there are open handles inside it),
    reference the root of the hive (i.e. kcb) and freeze the hive.

Arguments:

    Kcb - Supplies the key control block

    UserEvent - the event to be signaled after the hive was unloaded
                (only if late - unload is needed)

Return Value:

    STATUS_PENDING - the hive was frozen and it'll be unloaded later

    STATUS_SUCCESS - the hive was successfully sync-unloaded (no need 
                to signal for UserEvent)

    <other> - an error occured, operation failed

--*/
{
    PCMHIVE         CmHive;
    HCELL_INDEX     Cell;    
    NTSTATUS        Status;

    PAGED_CODE();

    Cell = kcb->KeyCell;
    CmHive = (PCMHIVE)CONTAINING_RECORD(kcb->KeyHive, CMHIVE, Hive);

    if( IsHiveFrozen(CmHive) ) {
        //
        // don't let them hurt themselves by calling it twice
        //
        return STATUS_TOO_LATE;
    }
    //
    // first, try out he sync routine; this may or may not unload the hive,
    // but at least will kick kcbs with refcount = 0 out of cache
    //
    Status = CmUnloadKey(&(CmHive->Hive),Cell,kcb,0);
    if( Status != STATUS_CANNOT_DELETE ) {
        //
        // the hive was either unloaded, or some bad thing happened
        //
        return Status;
    }

    ASSERT( kcb->RefCount > 1 );
    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    //
    // Prepare for late-unloading:
    // 1. reference the kcb, to make sure it won't go away without us noticing
    //  (we have the registry locked in exclusive mode, so we don't need to lock the kcbtree
    //
    if (!CmpReferenceKeyControlBlock(kcb)) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

	//
	// parse the kcb tree and mark all open kcbs inside this hive and "no delay close"
	//
    CmpSearchForOpenSubKeys(kcb,SearchAndTagNoDelayClose,NULL);
	kcb->ExtFlags |= CM_KCB_NO_DELAY_CLOSE;

    //
    // 2. Freeze the hive
    //
    CmHive->RootKcb = kcb;
    CmHive->Frozen = TRUE;
    CmHive->UnloadEvent = UserEvent;

    return STATUS_PENDING;
}

#endif //NT_UNLOAD_KEY_EX

// define in cmworker.c
extern BOOLEAN CmpForceForceFlush;

BOOLEAN
CmpDoFlushAll(
    BOOLEAN ForceFlush
    )
/*++

Routine Description:

    Flush all hives.

    Runs down list of Hives and applies HvSyncHive to them.

    NOTE: Hives which are marked as HV_NOLAZYFLUSH are *NOT* flushed
          by this call.  You must call HvSyncHive explicitly to flush
          a hive marked as HV_NOLAZYFLUSH.

Arguments:

    ForceFlush - used as a contingency plan when a prior exception left 
                some hive in a used state. When set to TRUE, assumes the 
                registry is locked exclusive. It also repairs the broken 
                hives.

               - When FALSE saves only the hives with UseCount == 0.

Return Value:

    NONE

Notes:

    If any of the hives is about to shrink CmpForceForceFlush is set to TRUE, 
    otherwise, it is set to FALSE

--*/
{
    NTSTATUS    Status;
    PLIST_ENTRY p;
    PCMHIVE     h;
    BOOLEAN     Result = TRUE;    
/*
    ULONG rc;
*/
    extern PCMHIVE CmpMasterHive;

    //
    // If writes are not working, lie and say we succeeded, will
    // clean up in a short time.  Only early system init code
    // will ever know the difference.
    //
    if (CmpNoWrite) {
        return TRUE;
    }
    
    CmpForceForceFlush = FALSE;

    //
    // traverse list of hives, sync each one
    //
    LOCK_HIVE_LIST();
    p = CmpHiveListHead.Flink;
    while (p != &CmpHiveListHead) {

        h = CONTAINING_RECORD(p, CMHIVE, HiveList);

        if (!(h->Hive.HiveFlags & HIVE_NOLAZYFLUSH)) {

            //
            //Lock the hive before we flush it.
            //-- since we now allow multiple readers
            // during a flush (a flush is considered a read)
            // we have to force a serialization on the vector table
            //
            CmLockHive (h);
            
            if( (ForceFlush == TRUE) &&  (h->UseCount != 0) ) {
                //
                // hive was left in an instable state by a prior exception raised 
                // somewhere inside a CM function.
                //
                ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
                CmpFixHiveUsageCount(h);
                ASSERT( h->UseCount == 0 );
            }

            
            if( (ForceFlush == TRUE) || (!HvHiveWillShrink((PHHIVE)h)) ) {
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_IO,"CmpDoFlushAll hive = %p ForceFlush = %lu IsHiveShrinking = %lu BaseLength = %lx StableLength = %lx\n",
                    h,(ULONG)ForceFlush,(ULONG)HvHiveWillShrink((PHHIVE)h),((PHHIVE)h)->BaseBlock->Length,((PHHIVE)h)->Storage[Stable].Length));
                Status = HvSyncHive((PHHIVE)h);

                if( !NT_SUCCESS( Status ) ) {
                    Result = FALSE;
                }
            } else {
                CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpDoFlushAll: Fail to flush hive %p because is shrinking\n",h));
                Result = FALSE;
                //
                // another unsuccessful attempt to save this hive, because we needed the reglock exclusive
                //
                CmpForceForceFlush = TRUE;
            }

            CmUnlockHive (h);
            //
            // WARNNOTE - the above means that a lazy flush or
            //            or shutdown flush did not work.  we don't
            //            know why.  there is noone to report an error
            //            to, so continue on and hope for the best.
            //            (in theory, worst that can happen is user changes
            //             are lost.)
            //
        }


        p = p->Flink;
    }
    UNLOCK_HIVE_LIST();
    
    return Result;
}

extern ULONG    CmpLazyFlushCount;
extern ULONG    CmpLazyFlushHiveCount;

BOOLEAN
CmpDoFlushNextHive(
    BOOLEAN     ForceFlush,
    PBOOLEAN    PostWarning,
    PULONG      DirtyCount
    )
/*++

Routine Description:

    Flush next hive in list with FlushCount != CmpLazyFlushCount

    Runs in the context of the CmpWorkerThread.

    Runs down list of Hives until it finds the first one with that was not yet flushed
    by the lazy flusher (ie. has its flush count lesser than the lazy flusher count)

    NOTE: Hives which are marked as HV_NOLAZYFLUSH are *NOT* flushed
          by this call.  You must call HvSyncHive explicitly to flush
          a hive marked as HV_NOLAZYFLUSH.

Arguments:

    ForceFlush - used as a contingency plan when a prior exception left 
                some hive in a used state. When set to TRUE, assumes the 
                registry is locked exclusive. It also repairs the broken 
                hives.

               - When FALSE saves only the hives with UseCount == 0.

Return Value:

    TRUE - if there are more hives to flush
    FALSE - otherwise

Notes:

    If any of the hives is about to shrink CmpForceForceFlush is set to TRUE, 
    otherwise, it is set to FALSE

--*/
{
    NTSTATUS    Status;
    PLIST_ENTRY p;
    PCMHIVE     h;
    BOOLEAN     Result;    
    ULONG       HiveCount = CmpLazyFlushHiveCount;

    extern PCMHIVE CmpMasterHive;

    *PostWarning = FALSE;
    *DirtyCount = 0;
    //
    // If writes are not working, lie and say we succeeded, will
    // clean up in a short time.  Only early system init code
    // will ever know the difference.
    //
    if (CmpNoWrite) {
        return TRUE;
    }
    //
    // flush at least one hive
    //
    if( !HiveCount ) {
        HiveCount = 1;
    }

    CmpForceForceFlush = FALSE;

    //
    // traverse list of hives, sync each one
    //
    LOCK_HIVE_LIST();
    p = CmpHiveListHead.Flink;
    while (p != &CmpHiveListHead) {

        h = CONTAINING_RECORD(p, CMHIVE, HiveList);

        if (!(h->Hive.HiveFlags & HIVE_NOLAZYFLUSH) &&  // lazy flush is notspecifically disabled on this hive
            (h->FlushCount != CmpLazyFlushCount)        // and it was not already flushed during this iteration
            ) {

#if 0
    {
        UNICODE_STRING  HiveName;
        RtlInitUnicodeString(&HiveName, (PCWSTR)h->Hive.BaseBlock->FileName);
        DbgPrint("CmpDoFlushNextHive : Hive = (%32.*S); FC = %lx ...",HiveName.Length / sizeof(WCHAR),HiveName.Buffer,h->FlushCount);
    }
#endif
            Result = TRUE;    
            //
            //Lock the hive before we flush it.
            //-- since we now allow multiple readers
            // during a flush (a flush is considered a read)
            // we have to force a serialization on the vector table
            //
            CmLockHive (h);
            if( (h->Hive.DirtyCount == 0) || (h->Hive.HiveFlags & HIVE_VOLATILE) ) {
                //
                // if the hive is volatile or has no dirty data, just skip it.
                // silently update the flush count
                //
                h->FlushCount = CmpLazyFlushCount;
#if 0
                DbgPrint(" skipping it ...");
#endif
            } else {
                if( (ForceFlush == TRUE) &&  (h->UseCount != 0) ) {
                    //
                    // hive was left in an instable state by a prior exception raised 
                    // somewhere inside a CM function.
                    //
                    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
                    CmpFixHiveUsageCount(h);
                    ASSERT( h->UseCount == 0 );
                }

            
                if( (ForceFlush == TRUE) || (!HvHiveWillShrink((PHHIVE)h)) ) {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_IO,"CmpDoFlushAll hive = %p ForceFlush = %lu IsHiveShrinking = %lu BaseLength = %lx StableLength = %lx\n",
                        h,(ULONG)ForceFlush,(ULONG)HvHiveWillShrink((PHHIVE)h),((PHHIVE)h)->BaseBlock->Length,((PHHIVE)h)->Storage[Stable].Length));
                    Status = HvSyncHive((PHHIVE)h);

                    if( !NT_SUCCESS( Status ) ) {
                        *PostWarning = TRUE;
                        Result = FALSE;
                    }
                } else {
                    CmKdPrintEx((DPFLTR_CONFIG_ID,DPFLTR_TRACE_LEVEL,"CmpDoFlushAll: Fail to flush hive %p because is shrinking\n",h));
                    Result = FALSE;
                    //
                    // another unsuccessful attempt to save this hive, because we needed the reglock exclusive
                    //
                    CmpForceForceFlush = TRUE;
                }
                if( Result == TRUE ) {
#if 0
                    DbgPrint(" flushed sucessfuly");
                    DbgPrint(" \t GLFC = %lx\n",CmpLazyFlushCount);
#endif
                    //
                    // we have successfully flushed current hive hive
                    //
                    h->FlushCount = CmpLazyFlushCount;
                    HiveCount--;
                    if( !HiveCount) {
                        //
                        // skip to the next one and break out of the loop, so we can detect whether the last one was flushed out
                        //
                        CmUnlockHive (h);
                        p = p->Flink;
                        break;
                    }
                } else {
                    //
                    // do not update flush count for this one as we want to attempt to flush it at next iteration
                    //
#if 0
                    DbgPrint(" failed to flush ");
#endif
                }
            }
            CmUnlockHive (h);
#if 0
            DbgPrint(" \t GLFC = %lx\n",CmpLazyFlushCount);
#endif
        } else if(  (h->Hive.DirtyCount != 0) &&                // hive has dirty data
                    (!(h->Hive.HiveFlags & HIVE_VOLATILE)) &&   // is not volatile
                    (!(h->Hive.HiveFlags & HIVE_NOLAZYFLUSH))){  // and lazy flush is enabled
            //
            // count dirty count for this hive; we'll need to fire another lazy flusher
            // to take this into account, even if we made it to the end of the list
            //
            // sanity; this has already been flushed
            ASSERT( h->FlushCount == CmpLazyFlushCount );
            *DirtyCount += h->Hive.DirtyCount;
        }

        p = p->Flink;
    }
    if( p == &CmpHiveListHead ) {
        //
        // we have flushed out everything; caller must update globalflush count
        //
        Result = FALSE;
    } else {
        Result = TRUE;
    }
    UNLOCK_HIVE_LIST();

    return Result;
}


NTSTATUS
CmReplaceKey(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN PUNICODE_STRING NewHiveName,
    IN PUNICODE_STRING OldFileName
    )

/*++

Routine Description:

    Renames the hive file for a running system and replaces it with a new
    file.  The new file is not actually used until the next boot.

Arguments:

    Hive - Supplies a hive control structure for the hive to be replaced.

    Cell - Supplies the HCELL_INDEX of the root cell of the hive to be
           replaced.

    NewHiveName - Supplies the name of the file which is to be installed
            as the new hive.

    OldFileName - Supplies the name of the file which the existing hive
            file is to be renamed to.

Return Value:

    NTSTATUS

--*/

{
    CHAR                        ObjectInfoBuffer[512];
    NTSTATUS                    Status;
    NTSTATUS                    Status2;
    OBJECT_ATTRIBUTES           Attributes;
    PCMHIVE                     NewHive;
    PCMHIVE                     CmHive; 
    POBJECT_NAME_INFORMATION    NameInfo;
    ULONG                       OldQuotaAllowed;
    ULONG                       OldQuotaWarning;
    BOOLEAN                     Allocate;
    BOOLEAN                     RegistryLockAquired;

    UNREFERENCED_PARAMETER (Cell);
    CmpLockRegistryExclusive();

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    if (Hive->HiveFlags & HIVE_HAS_BEEN_REPLACED) {
        CmpUnlockRegistry();
        return STATUS_FILE_RENAMED;
    }

    //
    // temporarily disable registry quota as we will be giving this memory back immediately!
    //
    OldQuotaAllowed = CmpGlobalQuotaAllowed;
    OldQuotaWarning = CmpGlobalQuotaWarning;
    CmpGlobalQuotaAllowed = CM_WRAP_LIMIT;
    CmpGlobalQuotaWarning = CM_WRAP_LIMIT;

    //
    // First open the new hive file and check to make sure it is valid.
    //
    InitializeObjectAttributes(&Attributes,
                               NewHiveName,
                               OBJ_CASE_INSENSITIVE,
                               NULL,
                               NULL);

    Allocate = FALSE;
    RegistryLockAquired = TRUE;
    Status = CmpCmdHiveOpen(    &Attributes,            // FileAttributes
                                NULL,                   // ImpersonationContext
                                &Allocate,              // Allocate
                                &RegistryLockAquired,   // RegistryLockAquired
                                &NewHive,               // NewHive
								CM_CHECK_REGISTRY_CHECK_CLEAN // CheckFlags
                            );

    
    if (!NT_SUCCESS(Status)) {
        goto ErrorExit;
    }
    ASSERT(Allocate == FALSE);

    if( Hive == (PHHIVE)(CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive) ) {
        //
        // Somebody attempts to replace the system hive: do the WPA test
        //
        HCELL_INDEX Src,Dest;

        Status = CmpCheckReplaceHive(Hive,&Src);
        if( !NT_SUCCESS(Status) ) {
            goto ErrorCleanup;
        }
        Status = CmpCheckReplaceHive((PHHIVE)NewHive,&Dest);
        if( !NT_SUCCESS(Status) ) {
            goto ErrorCleanup;
        }

        ASSERT( Src != HCELL_NIL );
        ASSERT( Dest != HCELL_NIL );
        //
        // now stuff the current WPA subtree into the new hive
        //
        if( !CmpSyncTrees(Hive, Src, (PHHIVE)NewHive, Dest, FALSE ) ) {
            Status = STATUS_REGISTRY_CORRUPT;
            goto ErrorCleanup;
        }

        //
        // commit the changes we've made in the destination hive
        //
        if( !HvSyncHive((PHHIVE)NewHive) ) {
            Status = STATUS_REGISTRY_CORRUPT;
            goto ErrorCleanup;
        }
    }
    //
    // The new hive exists, and is consistent, and we have it open.
    // Now rename the current hive file.
    //
    CmHive = (PCMHIVE)CONTAINING_RECORD(Hive, CMHIVE, Hive);
    Status = CmpCmdRenameHive(  CmHive,                                     // CmHive
                                (POBJECT_NAME_INFORMATION)ObjectInfoBuffer, // OldName
                                OldFileName,                                // NewName
                                sizeof(ObjectInfoBuffer)                    // NameInfoLength
                                );

    if (!NT_SUCCESS(Status)) {
        //
        // rename failed, close the files associated with the new hive
        //
        goto ErrorCleanup;
    }

    //
    // The existing hive was successfully renamed, so try to rename the
    // new file to what the old hive file was named.  (which was returned
    // into ObjectInfoBuffer by the worker thread)
    //
    Hive->HiveFlags |= HIVE_HAS_BEEN_REPLACED;
    NameInfo = (POBJECT_NAME_INFORMATION)ObjectInfoBuffer;

    Status = CmpCmdRenameHive(  NewHive,        // CmHive
                                NULL,           // OldName
                                &NameInfo->Name,// NewName
                                0               // NameInfoLength
                            );
   
    if (!NT_SUCCESS(Status)) {

        //
        // We are in trouble now.  We have renamed the existing hive file,
        // but we couldn't rename the new hive file!  Try to rename the
        // existing hive file back to where it was.
        //

        CmHive = (PCMHIVE)CONTAINING_RECORD(Hive, CMHIVE, Hive);
        Status2 = CmpCmdRenameHive( CmHive,             // CmHive            
                                    NULL,               // OldName
                                    &NameInfo->Name,    // NewName
                                    0                   // NameInfoLength
                                );
        
        if (!NT_SUCCESS(Status2)) {

            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmReplaceKey: renamed existing hive file, but couldn't\n"));
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"              rename new hive file (%08lx) ",Status));
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK," or replace old hive file (%08lx)!\n",Status2));

            //
            // WARNNOTE:
            //      To get into this state, the user must have relevent
            //      privileges, deliberately mess with system in an attempt
            //      to defeat it, AND get it done in a narrow timing window.
            //
            //      Further, if it's a user profile, the system will
            //      still come up.
            //
            //      Therefore, return an error code and go on.
            //

            Status = STATUS_REGISTRY_CORRUPT;

        }
    } else {
        //
        // flush file buffers (we are particulary interested in ValidDataLength to be updated on-disk)
        //
        IO_STATUS_BLOCK IoStatus;
        Status = ZwFlushBuffersFile(NewHive->FileHandles[HFILE_TYPE_PRIMARY],&IoStatus);
        if (!NT_SUCCESS(Status)) {
            //
            // failed to set ValidDataLength, close the files associated with the new hive
            //

            //
            // We are in trouble now.  We have renamed the existing hive file,
            // but we couldn't rename the new hive file!  Try to rename the
            // existing hive file back to where it was.
            //

            CmHive = (PCMHIVE)CONTAINING_RECORD(Hive, CMHIVE, Hive);
            Status2 = CmpCmdRenameHive( CmHive,             // CmHive            
                                        NULL,               // OldName
                                        &NameInfo->Name,    // NewName
                                        0                   // NameInfoLength
                                    );
        
            if (!NT_SUCCESS(Status2)) {

                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmReplaceKey: renamed existing hive file, but couldn't\n"));
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"              rename new hive file (%08lx) ",Status));
                CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK," or replace old hive file (%08lx)!\n",Status2));

                //
                // WARNNOTE:
                //      To get into this state, the user must have relevent
                //      privileges, deliberately mess with system in an attempt
                //      to defeat it, AND get it done in a narrow timing window.
                //
                //      Further, if it's a user profile, the system will
                //      still come up.
                //
                //      Therefore, return an error code and go on.
                //

                Status = STATUS_REGISTRY_CORRUPT;

            }
        }
    }
    //
    // All of the renaming is done.  However, we are holding an in-memory
    // image of the new hive.  Release it, since it will not actually
    // be used until next boot.
    //
    // Do not close the open file handles to the new hive, we need to
    // keep it locked exclusively until the system is rebooted to prevent
    // people from mucking with it.
    //
ErrorCleanup:

    LOCK_HIVE_LIST();
    CmpRemoveEntryList(&(NewHive->HiveList));
    UNLOCK_HIVE_LIST();

    CmpDestroyHiveViewList(NewHive);
    CmpDestroySecurityCache(NewHive);
    CmpDropFileObjectForHive(NewHive);
    CmpUnJoinClassOfTrust(NewHive);

    HvFreeHive((PHHIVE)NewHive);

    //
    // only close handles on error
    //
    if( !NT_SUCCESS(Status) ) {
        CmpCmdHiveClose(NewHive);
    }

    ASSERT( NewHive->HiveLock );
    ExFreePool(NewHive->HiveLock);
    ASSERT( NewHive->ViewLock );
    ExFreePool(NewHive->ViewLock);
    CmpFree(NewHive, sizeof(CMHIVE));

ErrorExit:
    //
    // Set global quota back to what it was.
    //
    CmpGlobalQuotaAllowed = OldQuotaAllowed;
    CmpGlobalQuotaWarning = OldQuotaWarning;

#ifdef CHECK_REGISTRY_USECOUNT
    CmpCheckRegistryUseCount();
#endif //CHECK_REGISTRY_USECOUNT

    CmpUnlockRegistry();
    return(Status);
}

#ifdef NT_RENAME_KEY

ULONG
CmpComputeKcbConvKey(
    PCM_KEY_CONTROL_BLOCK   KeyControlBlock
    );

NTSTATUS
CmRenameKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock,
    IN UNICODE_STRING           NewKeyName         // RAW
    )
/*++

Routine Description:

    Changes the name of the key to the given one.

    What needs to be done:
    
    1. Allocate a cell big enough to accomodate new knode 
    2. make a duplicate of the index in subkeylist of kcb's parent
    3. replace parent's subkeylist with the duplicate
    4. add new subkey to parent
    5. remove old subkey
    6. free storage.

Arguments:

    KeyControlBlock - pointer to kcb for key to operate on

    NewKeyName - The new name to be given to this key

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

Comments:

    What do we do with symbolic links?
--*/
{
    NTSTATUS                Status;
    PHHIVE                  Hive;
    HCELL_INDEX             Cell;
    PCM_KEY_NODE            Node;
    PCM_KEY_NODE            ParentNode;
    ULONG                   NodeSize;
    HCELL_INDEX             NewKeyCell = HCELL_NIL;
    HSTORAGE_TYPE           StorageType;
    HCELL_INDEX             OldSubKeyList = HCELL_NIL;
    PCM_KEY_NODE            NewKeyNode;
    PCM_KEY_INDEX           Index;
    ULONG                   i;
    LARGE_INTEGER           TimeStamp;
    ULONG                   NameLength;
    PCM_NAME_CONTROL_BLOCK  OldNcb = NULL;
    ULONG                   ConvKey;
    WCHAR                   *Cp;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmRenameKey\n"));

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    //
    // validate new name
    //
    if( NewKeyName.Length > REG_MAX_KEY_NAME_LENGTH ) {
        return STATUS_INVALID_PARAMETER;
    }
    try {
        Cp = NewKeyName.Buffer;
        for (i=0; i<NewKeyName.Length; i += sizeof(WCHAR)) {
            if( *Cp == OBJ_NAME_PATH_SEPARATOR ) {
                return STATUS_INVALID_PARAMETER;
            }
            ++Cp;
        }
    } except (EXCEPTION_EXECUTE_HANDLER) {
        Status = GetExceptionCode();
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!NtRenameKey: code:%08lx\n", Status));
        return Status;
    }
    //
    // no edits, on keys marked for deletion
    //
    if (KeyControlBlock->Delete) {
        return STATUS_KEY_DELETED;
    }

    //
    // see if the newName is not already a subkey of parentKcb
    //
    Hive = KeyControlBlock->KeyHive;
    Cell = KeyControlBlock->KeyCell;
    StorageType = HvGetCellType(Cell);

    //
    // OBS. we could have worked with the kcb tree instead, but if this is not 
    // going to work, we are in trouble anyway, so it's better to find out soon
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Cell);
    if( Node == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, Cell);

    //
    // cannot rename the root of a hive; or anything in the master hive !!!
    //
    if((Hive == &CmpMasterHive->Hive) || (KeyControlBlock->ParentKcb == NULL) || (KeyControlBlock->ParentKcb->KeyHive == &CmpMasterHive->Hive) ) {
        return STATUS_ACCESS_DENIED;
    }

    ParentNode = (PCM_KEY_NODE)HvGetCell(Hive,Node->Parent);
    if( ParentNode == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    
    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, Node->Parent);

    try {
        if( CmpFindSubKeyByName(Hive,ParentNode,&NewKeyName) != HCELL_NIL ) {
            //
            // a subkey with this name already exists
            //
            return STATUS_CANNOT_DELETE;
        }

        //
        // since we are in try-except, compute the new node size
        //
        NodeSize = CmpHKeyNodeSize(Hive, &NewKeyName);

    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmRenameKey: code:%08lx\n", GetExceptionCode()));
        return GetExceptionCode();
    }    
    
    //
    // 1. Allocate the new knode cell and copy the data from the old one, updating 
    // the name. 
    
    //
    // mark the parent dirty, as we will modify its SubkeyLists
    //
    if(!HvMarkCellDirty(Hive, Node->Parent)) {
        return STATUS_NO_LOG_SPACE;
    }

    //
    // mark the index dirty as we are going to free it on success
    //
    if ( !CmpMarkIndexDirty(Hive, Node->Parent, Cell) ) {
        return STATUS_NO_LOG_SPACE;
    }
    //
    // mark key_node as dirty as we are going to free it if we succeed
    //
    if(!HvMarkCellDirty(Hive, Cell)) {
        return STATUS_NO_LOG_SPACE;
    }
   
    OldSubKeyList = ParentNode->SubKeyLists[StorageType];       
    if( (OldSubKeyList == HCELL_NIL) || (!HvMarkCellDirty(Hive, OldSubKeyList)) ) {
        return STATUS_NO_LOG_SPACE;
    }
    Index = (PCM_KEY_INDEX)HvGetCell(Hive,OldSubKeyList);
    if( Index == NULL ) {
        //
        // this is a bad joke; we just marked this dirty
        //
        ASSERT( FALSE );
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, OldSubKeyList);

    //
    // mark all the index cells dirty
    //
    if( Index->Signature == CM_KEY_INDEX_ROOT ) {
        //
        // it's a root
        //
        for(i=0;i<Index->Count;i++) {
            // common sense
            ASSERT( (Index->List[i] != 0) && (Index->List[i] != HCELL_NIL) );
            if(!HvMarkCellDirty(Hive, Index->List[i])) {
                return STATUS_NO_LOG_SPACE;
            }
        }

    } 


    NewKeyCell = HvAllocateCell(
                    Hive,
                    NodeSize,
                    StorageType,
                    Cell // in the same vicinity
                    );
    if( NewKeyCell == HCELL_NIL ) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    
    NewKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,NewKeyCell);
    if( NewKeyNode == NULL ) {
        //
        // cannot map view; this shouldn't happen as we just allocated 
        // this cell (i.e. it should be dirty/pinned into memory)
        //
        ASSERT( FALSE );
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }
    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, NewKeyCell);

    //
    // copy old keynode info onto the new cell and update the name
    //
    // first everything BUT the name
    RtlCopyMemory(NewKeyNode,Node,FIELD_OFFSET(CM_KEY_NODE, Name));
    // second, the new name
    try {
        NewKeyNode->NameLength = CmpCopyName(   Hive,
                                                NewKeyNode->Name,
                                                &NewKeyName);
        NameLength = NewKeyName.Length;

        if (NewKeyNode->NameLength < NameLength ) {
            NewKeyNode->Flags |= KEY_COMP_NAME;
        } else {
            NewKeyNode->Flags &= ~KEY_COMP_NAME;
        }
    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmRenameKey: code:%08lx\n", GetExceptionCode()));
        Status = GetExceptionCode();
        goto ErrorExit;
    }    
    // third, the timestamp
    KeQuerySystemTime(&TimeStamp);
    NewKeyNode->LastWriteTime = TimeStamp;
    
    //
    // at this point we have the new key_node all built up.
    //

    //
    // 2.3. Make a duplicate of the parent's subkeylist and replace the original
    //
    ParentNode->SubKeyLists[StorageType] = CmpDuplicateIndex(Hive,OldSubKeyList,StorageType);
    if( ParentNode->SubKeyLists[StorageType] == HCELL_NIL ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // 4. Add new subkey to the parent. This will take care of index 
    // grow and rebalance problems. 
    // Note: the index is at this point a duplicate, so if we fail, we still have the 
    // original one handy to recover
    //
    if( !CmpAddSubKey(Hive,Node->Parent,NewKeyCell) ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // 5. remove old subkey;
    //
    if( !CmpRemoveSubKey(Hive,Node->Parent,Cell) ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // 5'. update the parent on each and every son.
    //
    if( !CmpUpdateParentForEachSon(Hive,NewKeyCell) ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // update the NCB in the kcb; at the end of this function, the kcbs underneath this 
    // will eventually get rehashed
    //
    OldNcb = KeyControlBlock->NameBlock;
    try {
        KeyControlBlock->NameBlock = CmpGetNameControlBlock (&NewKeyName);
    } except (EXCEPTION_EXECUTE_HANDLER) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_EXCEPTION,"!!CmRenameKey: code:%08lx\n", GetExceptionCode()));
        Status = GetExceptionCode();
        goto ErrorExit;
    }    

    //
    // 6. At this point we have it all done. We just need to free the old index and key_cell
    //
    
    //
    // free old index
    //
    Index = (PCM_KEY_INDEX)HvGetCell(Hive,OldSubKeyList);
    if( Index == NULL ) {
        //
        // this is a bad joke; we just marked this dirty
        //
        ASSERT( FALSE );
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }
    // release the cell right here, as the registry is locked exclusively, so we don't care
    HvReleaseCell(Hive, OldSubKeyList);

    if( Index->Signature == CM_KEY_INDEX_ROOT ) {
        //
        // it's a root
        //
        for(i=0;i<Index->Count;i++) {
            // common sense
            ASSERT( (Index->List[i] != 0) && (Index->List[i] != HCELL_NIL) );
            HvFreeCell(Hive, Index->List[i]);
        }

    } else {
        //
        // should be a leaf 
        //
        ASSERT((Index->Signature == CM_KEY_INDEX_LEAF)  ||
               (Index->Signature == CM_KEY_FAST_LEAF)   ||
               (Index->Signature == CM_KEY_HASH_LEAF)
               );
        ASSERT(Index->Count != 0);
    }
    HvFreeCell(Hive, OldSubKeyList);
    
    //
    // free old cell
    //
    HvFreeCell(Hive,Cell);

    //
    // update the node KeyCell for this kcb and the timestamp on the kcb;
    //
    KeyControlBlock->KeyCell = NewKeyCell;
    KeyControlBlock->KcbLastWriteTime = TimeStamp;

    //
    // and one last "little" thing: update parent's maxnamelen and reset parents cache
    //
    CmpCleanUpSubKeyInfo (KeyControlBlock->ParentKcb);

    if (ParentNode->MaxNameLen < NameLength) {
        ParentNode->MaxNameLen = NameLength;
        KeyControlBlock->ParentKcb->KcbMaxNameLen = (USHORT)NameLength;
    }
    
    //
    // rehash this kcb
    //
    ConvKey = CmpComputeKcbConvKey(KeyControlBlock);
    if( ConvKey != KeyControlBlock->ConvKey ) {
        //
        // rehash the kcb by removing it from hash, and then inserting it
        // again with th new ConvKey
        //
        CmpRemoveKeyHash(&(KeyControlBlock->KeyHash));
        KeyControlBlock->ConvKey = ConvKey;
        CmpInsertKeyHash(&(KeyControlBlock->KeyHash),FALSE);
    }

    //
    // Aditional work: take care of the kcb subtree; this cannot fail, punt
    //
    CmpSearchForOpenSubKeys(KeyControlBlock,SearchAndRehash,NULL);

    //
    // last, dereference the OldNcb for this kcb
    //
    ASSERT( OldNcb != NULL );
    CmpDereferenceNameControlBlockWithLock(OldNcb);

    return STATUS_SUCCESS;

ErrorExit:
    if( OldSubKeyList != HCELL_NIL ) {
        //
        // we have attempted (maybe even succedded) to duplicate parent's index)
        //
        if( ParentNode->SubKeyLists[StorageType] != HCELL_NIL ) {
            //
            // we need to free this as it is a duplicate
            //
            Index = (PCM_KEY_INDEX)HvGetCell(Hive,ParentNode->SubKeyLists[StorageType]);
            if( Index == NULL ) {
                //
                // could not map view;this shouldn't happen as we just allocated this cell
                //
                ASSERT( FALSE );
            } else {
                // release the cell right here, as the registry is locked exclusively, so we don't care
                HvReleaseCell(Hive, ParentNode->SubKeyLists[StorageType]);

                if( Index->Signature == CM_KEY_INDEX_ROOT ) {
                    //
                    // it's a root
                    //
                    for(i=0;i<Index->Count;i++) {
                        // common sense
                        ASSERT( (Index->List[i] != 0) && (Index->List[i] != HCELL_NIL) );
                        HvFreeCell(Hive, Index->List[i]);
                    }

                } else {
                    //
                    // should be a leaf 
                    //
                    ASSERT((Index->Signature == CM_KEY_INDEX_LEAF)  ||
                           (Index->Signature == CM_KEY_FAST_LEAF)   ||
                           (Index->Signature == CM_KEY_HASH_LEAF)
                           );
                    ASSERT(Index->Count != 0);
                }
                HvFreeCell(Hive, ParentNode->SubKeyLists[StorageType]);
            }

        }
        //
        // restore the parent's index
        //
        ParentNode->SubKeyLists[StorageType] = OldSubKeyList;
    }
    ASSERT( NewKeyCell != HCELL_NIL );
    HvFreeCell(Hive,NewKeyCell);
    
    if( OldNcb != NULL ) {
        KeyControlBlock->NameBlock = OldNcb;
    }
    
    return Status;
}
#endif

NTSTATUS
CmMoveKey(
    IN PCM_KEY_CONTROL_BLOCK    KeyControlBlock
    )
/*++

Routine Description:

    Moves all the cells related to this kcb above the specified fileoffset.

    What needs to be done:
    
    1. mark all data that we are going to touch dirty
    2. Duplicate the key_node (and values and all cells involved)
    3. Update the parent for all children
    4. replace the new Key_cell in the parent's subkeylist
    5. Update the kcb and the kcb cache
    6. remove old subkey

WARNING:
    after 3 we cannot fail anymore. if we do, we'll leak cells.

Arguments:

    KeyControlBlock - pointer to kcb for key to operate on

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS                Status;
    PHHIVE                  Hive;
    HCELL_INDEX             OldKeyCell;
    HCELL_INDEX             NewKeyCell = HCELL_NIL;
    HCELL_INDEX             ParentKeyCell;
    HSTORAGE_TYPE           StorageType;
    PCM_KEY_NODE            OldKeyNode;
    PCM_KEY_NODE            ParentKeyNode;
    PCM_KEY_NODE            NewKeyNode;
    PCM_KEY_INDEX           ParentIndex;
    PCM_KEY_INDEX           OldIndex;
    ULONG                   i,j;
    HCELL_INDEX             LeafCell;
    PCM_KEY_INDEX           Leaf;
    PCM_KEY_FAST_INDEX      FastIndex;
    PHCELL_INDEX            ParentIndexLocation = NULL;

    PAGED_CODE();

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmMoveKey\n"));

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    //
    // no edits, on keys marked for deletion
    //
    if (KeyControlBlock->Delete) {
        return STATUS_KEY_DELETED;
    }

    //
    // see if the newName is not already a subkey of parentKcb
    //
    Hive = KeyControlBlock->KeyHive;
    OldKeyCell = KeyControlBlock->KeyCell;
    StorageType = HvGetCellType(OldKeyCell);

    if( StorageType != Stable ) {
        //
        // nop the volatiles
        //
        return STATUS_SUCCESS;
    }

    if( OldKeyCell ==  Hive->BaseBlock->RootCell ) {
        //
        // this works only for stable keys.
        //
        return STATUS_INVALID_PARAMETER;
    }

    //
    // 1. mark all data that we are going to touch dirty
    //
    // parent's index, as we will replace the key node cell in it
    // we only search in the Stable storage. It is supposed to be there
    //
    OldKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,OldKeyCell);
    if( OldKeyNode == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    if (! CmpMarkKeyDirty(Hive, OldKeyCell
#if DBG
		,FALSE
#endif //DBG
		)) {
        HvReleaseCell(Hive, OldKeyCell);
        return STATUS_NO_LOG_SPACE;
    }
    // release the cell right here, as the registry is locked exclusively, and the key_cell is marked as dirty
    HvReleaseCell(Hive, OldKeyCell);

	if( OldKeyNode->Flags & KEY_SYM_LINK ) {
		//
		// we do not compact links
		//
		return STATUS_INVALID_PARAMETER;
	}
	if( OldKeyNode->SubKeyLists[Stable] != HCELL_NIL ) {
		//
		// mark the index dirty
		//
		OldIndex = (PCM_KEY_INDEX)HvGetCell(Hive, OldKeyNode->SubKeyLists[Stable]);
		if( OldIndex == NULL ) {
			//
			// we couldn't map the bin containing this cell
			//
			return STATUS_INSUFFICIENT_RESOURCES;
		}
		HvReleaseCell(Hive, OldKeyNode->SubKeyLists[Stable]);
		if( !HvMarkCellDirty(Hive, OldKeyNode->SubKeyLists[Stable]) ) {
			return STATUS_NO_LOG_SPACE;
		}

		if(OldIndex->Signature == CM_KEY_INDEX_ROOT) {
			for (i = 0; i < OldIndex->Count; i++) {
				if( !HvMarkCellDirty(Hive, OldIndex->List[i]) ) {
					return STATUS_NO_LOG_SPACE;
				}
			}
		} 
	}

    ParentKeyCell = OldKeyNode->Parent;
    //
    // now in the parent's spot
    //
    ParentKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,ParentKeyCell);
    if( ParentKeyNode == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    if( !HvMarkCellDirty(Hive, ParentKeyCell) ) {
        HvReleaseCell(Hive, ParentKeyCell);
        return STATUS_NO_LOG_SPACE;
    }
    // release the cell right here, as the registry is locked exclusively, so we don't care
    // Key_cell is marked dirty to keep the parent knode mapped
    HvReleaseCell(Hive, ParentKeyCell);

    ParentIndex = (PCM_KEY_INDEX)HvGetCell(Hive, ParentKeyNode->SubKeyLists[Stable]);
    if( ParentIndex == NULL ) {
        //
        // we couldn't map the bin containing this cell
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }
    HvReleaseCell(Hive, ParentKeyNode->SubKeyLists[Stable]);

    if(ParentIndex->Signature == CM_KEY_INDEX_ROOT) {

        //
        // step through root, till we find the right leaf
        //
        for (i = 0; i < ParentIndex->Count; i++) {
            LeafCell = ParentIndex->List[i];
            Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
            if( Leaf == NULL ) {
                //
                // we couldn't map the bin containing this cell
                //
                return STATUS_INSUFFICIENT_RESOURCES;
            }
            HvReleaseCell(Hive, LeafCell);

            if ( (Leaf->Signature == CM_KEY_FAST_LEAF) ||
                 (Leaf->Signature == CM_KEY_HASH_LEAF)
                ) {
                FastIndex = (PCM_KEY_FAST_INDEX)Leaf;
                for(j=0;j<FastIndex->Count;j++) {
                    if( FastIndex->List[j].Cell == OldKeyCell ) {
                        //
                        // found it! remember the locations we want to update later and break the loop
                        //
                        if( !HvMarkCellDirty(Hive, LeafCell) ) {
					        return STATUS_NO_LOG_SPACE;
                        }
                        ParentIndexLocation = &(FastIndex->List[j].Cell);
                        break;
                    }
                }
                if( ParentIndexLocation != NULL ) {
                    break;
                }
            } else {
                for(j=0;j<Leaf->Count;j++) {
                    if( Leaf->List[j] == OldKeyCell ) {
                        //
                        // found it! remember the locations we want to update later and break the loop
                        //
                        if( !HvMarkCellDirty(Hive, LeafCell) ) {
					        return STATUS_NO_LOG_SPACE;
                        }
                        ParentIndexLocation = &(Leaf->List[j]);
                        break;
                    }
                }
                if( ParentIndexLocation != NULL ) {
                    break;
                }
            }
        }
    } else if ( (ParentIndex->Signature == CM_KEY_FAST_LEAF) ||
                (ParentIndex->Signature == CM_KEY_HASH_LEAF)
        ) {
        FastIndex = (PCM_KEY_FAST_INDEX)ParentIndex;
        for(j=0;j<FastIndex->Count;j++) {
            if( FastIndex->List[j].Cell == OldKeyCell ) {
                //
                // found it! remember the locations we want to update later and break the loop
                //
                if( !HvMarkCellDirty(Hive, ParentKeyNode->SubKeyLists[Stable]) ) {
			        return STATUS_NO_LOG_SPACE;
                }
                ParentIndexLocation = &(FastIndex->List[j].Cell);
                break;
            }
        }
    } else {
        for(j=0;j<ParentIndex->Count;j++) {
            if( ParentIndex->List[j] == OldKeyCell ) {
                //
                // found it! remember the locations we want to update later and break the loop
                //
                if( !HvMarkCellDirty(Hive, ParentKeyNode->SubKeyLists[Stable]) ) {
			        return STATUS_NO_LOG_SPACE;
                }
                ParentIndexLocation = &(ParentIndex->List[j]);
                break;
            }
        }
    }

    // we should've find it !!!
    ASSERT( ParentIndexLocation != NULL );

    // 
    // 2. Duplicate the key_node (and values and all cells involved)
    //
    Status = CmpDuplicateKey(Hive,OldKeyCell,&NewKeyCell);
    if( !NT_SUCCESS(Status) ) {
        return Status;
    }

    // sanity
    ASSERT( (NewKeyCell != HCELL_NIL) && (StorageType == (HSTORAGE_TYPE)HvGetCellType(NewKeyCell)));

    //
    // 3. update the parent on each and every son.
    //
    if( !CmpUpdateParentForEachSon(Hive,NewKeyCell) ) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto ErrorExit;
    }

    //
    // 4. replace the new Key_cell in the parent's subkeylist
    // From now on, WE CANNOT fails. we have everything marked dirty
    // we just update some fields. no resources required !
    // If we fail to free some cells, too bad, we'll leak some cells.
    //
    *ParentIndexLocation = NewKeyCell;

    //
    // 5. Update the kcb and the kcb cache
    //
    CmpCleanUpSubKeyInfo(KeyControlBlock->ParentKcb);
    KeyControlBlock->KeyCell = NewKeyCell;
    CmpRebuildKcbCache(KeyControlBlock);

    //
    // 6. remove old subkey
    //
    // First the Index; it's already marked dirty (i.e. PINNED)
    //
	if( OldKeyNode->SubKeyLists[Stable] != HCELL_NIL ) {
		OldIndex = (PCM_KEY_INDEX)HvGetCell(Hive, OldKeyNode->SubKeyLists[Stable]);
		ASSERT( OldIndex != NULL );
		HvReleaseCell(Hive, OldKeyNode->SubKeyLists[Stable]);
		if(OldIndex->Signature == CM_KEY_INDEX_ROOT) {
			for (i = 0; i < OldIndex->Count; i++) {
				HvFreeCell(Hive, OldIndex->List[i]);
			}
		} 
		HvFreeCell(Hive,OldKeyNode->SubKeyLists[Stable]);
	}

	OldKeyNode->SubKeyCounts[Stable] = 0;
    OldKeyNode->SubKeyCounts[Volatile] = 0;

    CmpFreeKeyByCell(Hive,OldKeyCell,FALSE);

    return STATUS_SUCCESS;

ErrorExit:
    //
    // we need to free the new knode allocated
    //
    NewKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,NewKeyCell);
    // must be dirty
    ASSERT( NewKeyNode != NULL );
	HvReleaseCell(Hive, NewKeyCell);
	if( NewKeyNode->SubKeyLists[Stable] != HCELL_NIL ) {
		OldIndex = (PCM_KEY_INDEX)HvGetCell(Hive, NewKeyNode->SubKeyLists[Stable]);
		ASSERT( OldIndex != NULL );
		HvReleaseCell(Hive, NewKeyNode->SubKeyLists[Stable]);
		if(OldIndex->Signature == CM_KEY_INDEX_ROOT) {
			for (i = 0; i < OldIndex->Count; i++) {
				HvFreeCell(Hive, OldIndex->List[i]);
			}
		} 
		HvFreeCell(Hive,NewKeyNode->SubKeyLists[Stable]);
	}
    NewKeyNode->SubKeyCounts[Stable] = 0;
    NewKeyNode->SubKeyCounts[Volatile] = 0;

    CmpFreeKeyByCell(Hive,NewKeyCell,FALSE);
    return Status;

}

NTSTATUS
CmpDuplicateKey(
    PHHIVE          Hive,
    HCELL_INDEX     OldKeyCell,
    PHCELL_INDEX    NewKeyCell
    )
/*++

Routine Description:

    Makes an exact clone of OldKeyCell key_node in the 
    space above AboveFileOffset.
    Operates on Stable storage ONLY!!!

Arguments:


Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    PCM_KEY_NODE			OldKeyNode;
    PCM_KEY_NODE			NewKeyNode;
    PRELEASE_CELL_ROUTINE   TargetReleaseCellRoutine;

    PAGED_CODE();

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    ASSERT( HvGetCellType(OldKeyCell) == Stable );
    
    OldKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,OldKeyCell);
    if( OldKeyNode == NULL ) {
        //
        // cannot map view
        //
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // since the registry is locked exclusively here, we don't need to lock/release cells 
    // while copying the trees; So, we just set the release routines to NULL and restore after
    // the copy is complete; this saves some pain
    //
    TargetReleaseCellRoutine = Hive->ReleaseCellRoutine;
    Hive->ReleaseCellRoutine = NULL;

    *NewKeyCell = CmpCopyKeyPartial(Hive,OldKeyCell,Hive,OldKeyNode->Parent,TRUE);
    Hive->ReleaseCellRoutine  = TargetReleaseCellRoutine;

    if( *NewKeyCell == HCELL_NIL ) {
	    HvReleaseCell(Hive, OldKeyCell);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    NewKeyNode = (PCM_KEY_NODE)HvGetCell(Hive,*NewKeyCell);
    if( NewKeyNode == NULL ) {
        //
        // cannot map view
        //
	    HvReleaseCell(Hive, OldKeyCell);
        CmpFreeKeyByCell(Hive,*NewKeyCell,FALSE);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // now we have the key_cell duplicated. Values and security has also been taken care of
    // Go ahead and duplicate the Index.
    //
    if( OldKeyNode->SubKeyLists[Stable] != HCELL_NIL ) {
		NewKeyNode->SubKeyLists[Stable] = CmpDuplicateIndex(Hive,OldKeyNode->SubKeyLists[Stable],Stable);
		if( NewKeyNode->SubKeyLists[Stable] == HCELL_NIL ) {
			HvReleaseCell(Hive, OldKeyCell);
			CmpFreeKeyByCell(Hive,*NewKeyCell,FALSE);
			HvReleaseCell(Hive, *NewKeyCell);
			return STATUS_INSUFFICIENT_RESOURCES;
		}
	} else {
		ASSERT( OldKeyNode->SubKeyCounts[Stable] == 0 );
		NewKeyNode->SubKeyLists[Stable] = HCELL_NIL;
	}
    NewKeyNode->SubKeyCounts[Stable] = OldKeyNode->SubKeyCounts[Stable];
    NewKeyNode->SubKeyLists[Volatile] = OldKeyNode->SubKeyLists[Volatile];
    NewKeyNode->SubKeyCounts[Volatile] = OldKeyNode->SubKeyCounts[Volatile];

	HvReleaseCell(Hive, *NewKeyCell);
    HvReleaseCell(Hive, OldKeyCell);
    return STATUS_SUCCESS;

}


#ifdef WRITE_PROTECTED_REGISTRY_POOL

VOID
CmpMarkAllBinsReadOnly(
    PHHIVE      Hive
    )
/*++

Routine Description:

    Marks the memory allocated for all the stable bins in this hive as read only.

Arguments:

    Hive - supplies a pointer to the hive control structure for the
            hive of interest

Return Value:

    NONE (It should work!)

--*/
{
    PHMAP_ENTRY t;
    PHBIN       Bin;
    HCELL_INDEX p;
    ULONG       Length;

    //
    // we are only interested in the stable storage
    //
    Length = Hive->Storage[Stable].Length;

    p = 0;

    //
    // for each bin in the space
    //
    while (p < Length) {
        t = HvpGetCellMap(Hive, p);
        VALIDATE_CELL_MAP(__LINE__,t,Hive,p);

        Bin = (PHBIN)HBIN_BASE(t->BinAddress);

        if (t->BinAddress & HMAP_NEWALLOC) {

            //
            // Mark it as read Only
            //
            HvpChangeBinAllocation(Bin,TRUE);
        }

        // next one, please
        p = (ULONG)p + Bin->Size;

    }

}

#endif //WRITE_PROTECTED_REGISTRY_POOL

ULONG
CmpCompressKeyWorker(
    PCM_KEY_CONTROL_BLOCK Current,
    PVOID                 Context1,
    PVOID                 Context2
    )
{
	PLIST_ENTRY				pListHead;
	PCM_KCB_REMAP_BLOCK		kcbRemapBlock;
	//PLIST_ENTRY             AnchorAddr;

    if (Current->KeyHive == Context1) {
		
		pListHead = (PLIST_ENTRY)Context2;
		ASSERT( pListHead );
/*
		//
		// check if we didn't already recorded this kcb
		//
		AnchorAddr = pListHead;
		kcbRemapBlock = (PCM_KCB_REMAP_BLOCK)(pListHead->Flink);

		while ( kcbRemapBlock != (PCM_KCB_REMAP_BLOCK)AnchorAddr ) {
			kcbRemapBlock = CONTAINING_RECORD(
							kcbRemapBlock,
							CM_KCB_REMAP_BLOCK,
							RemapList
							);
			if( kcbRemapBlock->KeyControlBlock == Current ) {
				//
				// we already have this kcb
				//
				return KCB_WORKER_CONTINUE;
			}
            //
            // skip to the next element
            //
            kcbRemapBlock = (PCM_KCB_REMAP_BLOCK)(kcbRemapBlock->RemapList.Flink);
		}
*/

		kcbRemapBlock = (PCM_KCB_REMAP_BLOCK)ExAllocatePool(PagedPool, sizeof(CM_KCB_REMAP_BLOCK));
		if( kcbRemapBlock == NULL ) {
			return KCB_WORKER_ERROR;
		}
		kcbRemapBlock->KeyControlBlock = Current;
		kcbRemapBlock->NewCellIndex = HCELL_NIL;
		kcbRemapBlock->OldCellIndex = Current->KeyCell;
		kcbRemapBlock->ValueCount = 0;
		kcbRemapBlock->ValueList = HCELL_NIL;
        InsertTailList(pListHead,&(kcbRemapBlock->RemapList));

    }
    return KCB_WORKER_CONTINUE;   // always keep searching
}

NTSTATUS
CmCompressKey(
    IN PHHIVE Hive
    )
/*++

Routine Description:

	Compresses the kcb, by means of simulating an "in-place" SaveKey

    What needs to be done:

	1. iterate through the kcb tree and make a list of all the kcbs 
	that need to be changed (their keycell will change during the process)
	2. iterate through the cache and compute an array of security cells.
	We'll need it to map security cells into the new hive.
	3. Save the hive into a temporary hive, preserving
	the volatile info in keynodes and updating the cell mappings.
	4. Update the cache by adding volatile security cells from the old hive.
	5. Dump temporary (compressed) hive over to the old file.
	6. Switch hive data from the compressed one to the existing one and update
	the kcb KeyCell and security mapping
	7. Invalidate the map and drop paged bins.
	8. Free storage for the new hive (OK if we fail)

Arguments:

    Hive - Hive to operate on

Return Value:

    NTSTATUS - Result code from call, among the following:

        <TBS>

--*/
{
    NTSTATUS                Status = STATUS_SUCCESS;
    HCELL_INDEX             KeyCell;
    PCMHIVE                 CmHive;
    PCM_KCB_REMAP_BLOCK     RemapBlock;
    PCMHIVE                 NewHive = NULL;
    HCELL_INDEX             LinkCell;
    PCM_KEY_NODE            LinkNode;
    PCM_KNODE_REMAP_BLOCK   KnodeRemapBlock;
    ULONG                   OldLength;

    
	PAGED_CODE();

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_CM,"CmCompressKey\n"));

    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();

    if( HvAutoCompressCheck(Hive) == FALSE ) {
        return STATUS_SUCCESS;
    }

    KeyCell = Hive->BaseBlock->RootCell;
    CmHive = CONTAINING_RECORD(Hive, CMHIVE, Hive);
    //
    // Make sure the cell passed in is the root cell of the hive.
    //
    if ( CmHive == CmpMasterHive ) {
        return STATUS_INVALID_PARAMETER;
    }

	//
	// 0. Get the cells we need to relink the compressed hive
	//
	LinkNode = (PCM_KEY_NODE)HvGetCell(Hive,KeyCell);
	if( LinkNode == NULL ) {
        return STATUS_INSUFFICIENT_RESOURCES;
	}
	LinkCell = LinkNode->Parent;
	HvReleaseCell(Hive,KeyCell);
	LinkNode = (PCM_KEY_NODE)HvGetCell((PHHIVE)CmpMasterHive,LinkCell);
	// master storage is paged pool
	ASSERT(LinkNode != NULL);
	HvReleaseCell((PHHIVE)CmpMasterHive,LinkCell);


    OldLength = Hive->BaseBlock->Length;
	//
	//	1. iterate through the kcb tree and make a list of all the kcbs 
	//	that need to be changed (their keycell will change during the process)
	//
	ASSERT( IsListEmpty(&(CmHive->KcbConvertListHead)) );
	//
	// this will kick all kcb with refcount == 0 out of cache, so we can use 
	// CmpSearchKeyControlBlockTree for recording referenced kcbs
	//
	CmpCleanUpKCBCacheTable();
	//CmpSearchForOpenSubKeys(KeyControlBlock,SearchIfExist);
    if( !CmpSearchKeyControlBlockTree(CmpCompressKeyWorker,(PVOID)Hive,(PVOID)(&(CmHive->KcbConvertListHead))) ) {
		Status = STATUS_INSUFFICIENT_RESOURCES;
		goto Exit;
	}

	//
	// 2. iterate through the cache and compute an array of security cells.
	// We'll need it to map security cells into the new hive.
	//
	if( !CmpBuildSecurityCellMappingArray(CmHive) ) {
		Status = STATUS_INSUFFICIENT_RESOURCES;
		goto Exit;
	}

	//
	// 3. Save the hive into a temporary hive , preserving
	// the volatile info in keynodes and updating the cell mappings.
	//
	Status = CmpShiftHiveFreeBins(CmHive,&NewHive);
	if( !NT_SUCCESS(Status) ) {
		goto Exit;
	}

	//
	// 5. Dump temporary (compressed) hive over to the old file.
	//
	Status = CmpOverwriteHive(CmHive,NewHive,LinkCell);
    if (!NT_SUCCESS(Status)) {
        goto Exit;
    }


	//
	// From this point on, we WILL NOT FAIL!
	//

	//
	// get the root node and link it into the master storage
	//
	LinkNode->ChildHiveReference.KeyCell = NewHive->Hive.BaseBlock->RootCell;

	//
	// 6. Switch hive data from the compressed one to the existing one and update
	// the kcb KeyCell and security mapping
	// This should better NOT fail!!! If it does, we are doomed, as we have partial
	// data => bugcheck
	//
	CmpSwitchStorageAndRebuildMappings(CmHive,NewHive);

	
	//
	// 7. Invalidate the map and drop paged bins. If system hive, check for the hysteresis callback.
	//
    HvpDropAllPagedBins(&(CmHive->Hive));
    if( OldLength < CmHive->Hive.BaseBlock->Length ) {
        CmpUpdateSystemHiveHysteresis(&(CmHive->Hive),CmHive->Hive.BaseBlock->Length,OldLength);
    }


Exit:

	//
	// 8. Free storage for the new hive (OK if we fail)
	//
	if( NewHive != NULL ) { 
		CmpDestroyTemporaryHive(NewHive);	
	}

	if( CmHive->CellRemapArray != NULL ) {
		ExFreePool(CmHive->CellRemapArray);
		CmHive->CellRemapArray = NULL;
	}
	//
	// remove all remap blocks and free them
	//
	while (IsListEmpty(&(CmHive->KcbConvertListHead)) == FALSE) {
        RemapBlock = (PCM_KCB_REMAP_BLOCK)RemoveHeadList(&(CmHive->KcbConvertListHead));
        RemapBlock = CONTAINING_RECORD(
                        RemapBlock,
                        CM_KCB_REMAP_BLOCK,
                        RemapList
                        );
		ExFreePool(RemapBlock);
	}
	while (IsListEmpty(&(CmHive->KnodeConvertListHead)) == FALSE) {
        KnodeRemapBlock = (PCM_KNODE_REMAP_BLOCK)RemoveHeadList(&(CmHive->KnodeConvertListHead));
        KnodeRemapBlock = CONTAINING_RECORD(
                            KnodeRemapBlock,
                            CM_KNODE_REMAP_BLOCK,
                            RemapList
                        );
		ExFreePool(KnodeRemapBlock);
	}

	return Status;
}

NTSTATUS
CmLockKcbForWrite(PCM_KEY_CONTROL_BLOCK KeyControlBlock)
/*++

Routine Description:

    Tags the kcb as being read-only and no-delay-close

Arguments:

    KeyControlBlock

Return Value:

    TBS

--*/
{
    PAGED_CODE();

    CmpLockKCBTreeExclusive();

    ASSERT_KCB(KeyControlBlock);
    if( KeyControlBlock->Delete ) {
        CmpUnlockKCBTree();
        return STATUS_KEY_DELETED;
    }
    //
    // sanity check in case we are called twice
    //
    ASSERT( ((KeyControlBlock->ExtFlags&CM_KCB_READ_ONLY_KEY) && (KeyControlBlock->ExtFlags&CM_KCB_NO_DELAY_CLOSE)) ||
            (!(KeyControlBlock->ExtFlags&CM_KCB_READ_ONLY_KEY))
        );

    //
    // tag the kcb as read-only; also make it no-delay close so it can revert to the normal state after all handles are closed.
    //
    KeyControlBlock->ExtFlags |= (CM_KCB_READ_ONLY_KEY|CM_KCB_NO_DELAY_CLOSE);

    //
    // add an artificial refcount on this kcb. This will keep the kcb (and the read only flag set in memory for as long as the system is up)
    //
    InterlockedIncrement( (PLONG)&KeyControlBlock->RefCount );

    CmpUnlockKCBTree();

    return STATUS_SUCCESS;
}


BOOLEAN
CmpCompareNewValueDataAgainstKCBCache(  PCM_KEY_CONTROL_BLOCK KeyControlBlock,
                                        PUNICODE_STRING ValueName,
                                        ULONG Type,
                                        PVOID Data,
                                        ULONG DataSize
                                        )

/*++

Routine Description:

    Most of the SetValue calls are noops (i.e. they are setting the same 
    value name to the same value data). By comparing against the data already 
    in the kcb cache (i.e. faulted in) we can save page faults.


Arguments:

    KeyControlBlock - pointer to kcb for the key to operate on

    ValueName - The unique (relative to the containing key) name
        of the value entry.  May be NULL.

    Type - The integer type number of the value entry.

    Data - Pointer to buffer with actual data for the value entry.

    DataSize - Size of Data buffer.


Return Value:

    TRUE - same value with the same data exist in the cache.

--*/
{
    PCM_KEY_VALUE       Value;
    ULONG               Index;
    BOOLEAN             ValueCached;
    PPCM_CACHED_VALUE   ContainingList;
    HCELL_INDEX         ValueDataCellToRelease = HCELL_NIL;
    BOOLEAN             Result = FALSE;
    PUCHAR              datapointer = NULL;
    BOOLEAN             BufferAllocated = FALSE;
    HCELL_INDEX         CellToRelease = HCELL_NIL;
    ULONG               compareSize;
    ULONG               realsize;
    BOOLEAN             small;

    PAGED_CODE();

    BEGIN_KCB_LOCK_GUARD;
    CmpLockKCBTreeExclusive();

    if( KeyControlBlock->Flags & KEY_SYM_LINK ) {
        //
        // need to rebuild the value cache, so we could runt the same code
        //
        PCM_KEY_NODE    Node = (PCM_KEY_NODE)HvGetCell(KeyControlBlock->KeyHive,KeyControlBlock->KeyCell);

        if( Node == NULL ) {
            //
            // we couldn't map the bin containing this cell
            //
            goto Exit;
        }

        CmpCleanUpKcbValueCache(KeyControlBlock);
        CmpSetUpKcbValueCache(KeyControlBlock,Node->ValueList.Count,Node->ValueList.List);

        HvReleaseCell(KeyControlBlock->KeyHive,KeyControlBlock->KeyCell);
    }

    Value = CmpFindValueByNameFromCache(KeyControlBlock->KeyHive,
                                        &(KeyControlBlock->ValueCache),
                                        ValueName,
                                        &ContainingList,
                                        &Index,
                                        &ValueCached,
                                        &ValueDataCellToRelease
                                        );

    if(Value) {
        if( (Type == Value->Type) && (DataSize == (Value->DataLength & ~CM_KEY_VALUE_SPECIAL_SIZE)) ) {
        
            small = CmpIsHKeyValueSmall(realsize, Value->DataLength);
            if (small == TRUE) {
                datapointer = (PUCHAR)(&(Value->Data));
            } else if( CmpGetValueDataFromCache(KeyControlBlock->KeyHive, ContainingList,(PCELL_DATA)Value, 
                                                ValueCached,&datapointer,&BufferAllocated,&CellToRelease) == FALSE ){
                //
                // we couldn't map view for cell; treat it as insufficient resources problem
                //
                ASSERT( datapointer == NULL );
                ASSERT( BufferAllocated == FALSE );
                goto Exit;
            } 
            //
            // compare data
            //
            if (DataSize > 0) {

                try {
                    compareSize = (ULONG)RtlCompareMemory ((PVOID)datapointer,Data,(DataSize & ~CM_KEY_VALUE_SPECIAL_SIZE));
                } except (EXCEPTION_EXECUTE_HANDLER) {
                    goto Exit;
                }

            } else {
                compareSize = 0;
            }

            if (compareSize == DataSize) {
                Result = TRUE;
            }

        }
    }

Exit:

    CmpUnlockKCBTree();
    END_KCB_LOCK_GUARD;

    if(ValueDataCellToRelease != HCELL_NIL) {
        HvReleaseCell(KeyControlBlock->KeyHive,ValueDataCellToRelease);
    }
    if( BufferAllocated == TRUE ) {
        ExFreePool(datapointer);
    }
    if(CellToRelease != HCELL_NIL) {
        HvReleaseCell(KeyControlBlock->KeyHive,CellToRelease);
    }
    
    return Result;
}


NTSTATUS
static
__forceinline
CmpCheckReplaceHive(    IN PHHIVE           Hive,
                        OUT PHCELL_INDEX    Key
                    )
{
    HCELL_INDEX             RootCell;
    UNICODE_STRING          Name;
    NTSTATUS                Status = STATUS_SUCCESS;
    PRELEASE_CELL_ROUTINE   TargetReleaseCellRoutine;
    WCHAR                   Buffer[4];

    PAGED_CODE();
    
    ASSERT_CM_LOCK_OWNED_EXCLUSIVE();
    //
    // disable refcounting
    //
    TargetReleaseCellRoutine = Hive->ReleaseCellRoutine;
    Hive->ReleaseCellRoutine = NULL;
    
    Buffer[3] = 0;
    *Key = HCELL_NIL;
    Buffer[1] = (WCHAR)'P';

    RootCell = Hive->BaseBlock->RootCell;
    Buffer[2] = (WCHAR)'A';

    if( RootCell == HCELL_NIL ) {
        //
        // could not find root cell. Bogus.
        //
        Status =  STATUS_REGISTRY_CORRUPT;
        goto Exit;
    }
    Buffer[0] = (WCHAR)'W';

    RtlInitUnicodeString(&Name, Buffer);
    RootCell = CmpFindSubKeyByName(Hive,
                                   (PCM_KEY_NODE)HvGetCell(Hive,RootCell),
                                   &Name);


    if( RootCell != HCELL_NIL ) {
        //
        // found it.
        //
        *Key = RootCell;
    } else {
        //
        // WPA key should be present; it's created by GUI mode.
        //
        Status =  STATUS_REGISTRY_CORRUPT;
        goto Exit;
    }

Exit:
    Hive->ReleaseCellRoutine = TargetReleaseCellRoutine;
    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmboot.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmboot.c

Abstract:

    This provides routines for determining driver load lists from the
    registry.  The relevant drivers are extracted from the registry,
    sorted by groups, and then dependencies are resolved.

    This module is used both by the OS Loader for determining the boot
    driver list (CmScanRegistry) and by IoInitSystem for determining
    the drivers to be loaded in Phase 1 Initialization
    (CmGetSystemDriverList)

Author:

    John Vert (jvert) 7-Apr-1992

Environment:

    OS Loader environment
        or
    kernel mode

Revision History:

--*/
#include "cmp.h"
#include <profiles.h>

#define LOAD_LAST 0xffffffff
#define LOAD_NEXT_TO_LAST (LOAD_LAST-1)

//
// Private function prototypes.
//
BOOLEAN
CmpAddDriverToList(
    IN PHHIVE Hive,
    IN HCELL_INDEX DriverCell,
    IN HCELL_INDEX GroupOrderCell,
    IN PUNICODE_STRING RegistryPath,
    IN PLIST_ENTRY BootDriverListHead
    );

BOOLEAN
CmpDoSort(
    IN PLIST_ENTRY DriverListHead,
    IN PUNICODE_STRING OrderList
    );

ULONG
CmpFindTagIndex(
    IN PHHIVE Hive,
    IN HCELL_INDEX TagCell,
    IN HCELL_INDEX GroupOrderCell,
    IN PUNICODE_STRING GroupName
    );

BOOLEAN
CmpIsLoadType(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN SERVICE_LOAD_TYPE LoadType
    );

BOOLEAN
CmpOrderGroup(
    IN PBOOT_DRIVER_NODE GroupStart,
    IN PBOOT_DRIVER_NODE GroupEnd
    );

VOID
BlPrint(
    PCHAR cp,
    ...
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmpFindNLSData)
#pragma alloc_text(INIT,CmpFindDrivers)
#pragma alloc_text(INIT,CmpIsLoadType)
#pragma alloc_text(INIT,CmpAddDriverToList)
#pragma alloc_text(INIT,CmpSortDriverList)
#pragma alloc_text(INIT,CmpDoSort)
#pragma alloc_text(INIT,CmpResolveDriverDependencies)
#pragma alloc_text(INIT,CmpSetCurrentProfile)
#pragma alloc_text(INIT,CmpOrderGroup)
#pragma alloc_text(PAGE,CmpFindControlSet)
#pragma alloc_text(INIT,CmpFindTagIndex)
#pragma alloc_text(INIT,CmpFindProfileOption)
#pragma alloc_text(INIT,CmpValidateSelect)
#ifdef _WANT_MACHINE_IDENTIFICATION
#pragma alloc_text(INIT,CmpGetBiosDateFromRegistry)
#endif
#endif


BOOLEAN
CmpFindNLSData(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PUNICODE_STRING AnsiFilename,
    OUT PUNICODE_STRING OemFilename,
    OUT PUNICODE_STRING CaseTableFilename,
    OUT PUNICODE_STRING OemHalFont
    )

/*++

Routine Description:

    Traverses a particular control set and determines the filenames for
    the NLS data files that need to be loaded.

Arguments:

    Hive - Supplies the hive control structure for the SYSTEM hive.

    ControlSet - Supplies the HCELL_INDEX of the root of the control set.

    AnsiFileName - Returns the name of the Ansi codepage file (c_1252.nls)

    OemFileName -  Returns the name of the OEM codepage file  (c_437.nls)

    CaseTableFileName - Returns the name of the Unicode upper/lowercase
            table for the language (l_intl.nls)

    OemHalfont - Returns the name of the font file to be used by the HAL.

Return Value:

    TRUE - filenames successfully determined

    FALSE - hive is corrupt

--*/

{
    UNICODE_STRING Name;
    HCELL_INDEX Control;
    HCELL_INDEX Nls;
    HCELL_INDEX CodePage;
    HCELL_INDEX Language;
    HCELL_INDEX ValueCell;
    PCM_KEY_VALUE Value;
    ULONG realsize;
    PCM_KEY_NODE Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Find CONTROL node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Control");
    Control = CmpFindSubKeyByName(Hive,
                                 Node,
                                 &Name);
    if (Control == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find NLS node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Control);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"NLS");
    Nls = CmpFindSubKeyByName(Hive,
                             Node,
                             &Name);
    if (Nls == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find CodePage node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Nls);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"CodePage");
    CodePage = CmpFindSubKeyByName(Hive,
                                  Node,
                                  &Name);
    if (CodePage == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find ACP value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"ACP");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Name.Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
    if( Name.Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    Name.MaximumLength=(USHORT)realsize;
    Name.Length = 0;
    while ((Name.Length<Name.MaximumLength) &&
           (Name.Buffer[Name.Length/sizeof(WCHAR)] != UNICODE_NULL)) {
        Name.Length += sizeof(WCHAR);
    }

    //
    // Find ACP filename
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    AnsiFilename->Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
    if( AnsiFilename->Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    AnsiFilename->Length = AnsiFilename->MaximumLength = (USHORT)realsize;

    //
    // Find OEMCP node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"OEMCP");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Name.Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
    if( Name.Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    Name.MaximumLength = (USHORT)realsize;
    Name.Length = 0;
    while ((Name.Length<Name.MaximumLength) &&
           (Name.Buffer[Name.Length/sizeof(WCHAR)] != UNICODE_NULL)) {
        Name.Length += sizeof(WCHAR);
    }

    //
    // Find OEMCP filename
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    OemFilename->Buffer = (PWSTR)CmpValueToData(Hive, Value,&realsize);
    if( OemFilename->Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    OemFilename->Length = OemFilename->MaximumLength = (USHORT)realsize;

    //
    // Find Language node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Nls);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Language");
    Language = CmpFindSubKeyByName(Hive,
                                   Node,
                                   &Name);
    if (Language == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find Default value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Language);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Default");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
            return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Name.Buffer = (PWSTR)CmpValueToData(Hive, Value,&realsize);
    if( Name.Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    Name.MaximumLength = (USHORT)realsize;
    Name.Length = 0;

    while ((Name.Length<Name.MaximumLength) &&
           (Name.Buffer[Name.Length/sizeof(WCHAR)] != UNICODE_NULL)) {
        Name.Length+=sizeof(WCHAR);
    }

    //
    // Find default filename
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Language);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    CaseTableFilename->Buffer = (PWSTR)CmpValueToData(Hive, Value,&realsize);
    if( CaseTableFilename->Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    CaseTableFilename->Length = CaseTableFilename->MaximumLength = (USHORT)realsize;

    //
    // Find OEMHAL filename
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,CodePage);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"OEMHAL");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
#ifdef i386
        OemHalFont->Buffer = NULL;
        OemHalFont->Length = 0;
        OemHalFont->MaximumLength = 0;
        return TRUE;
#else
        return(FALSE);
#endif
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    OemHalFont->Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
    if( OemHalFont->Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    OemHalFont->Length = (USHORT)realsize;
    OemHalFont->MaximumLength = (USHORT)realsize;

    return(TRUE);
}


BOOLEAN
CmpFindDrivers(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    IN SERVICE_LOAD_TYPE LoadType,
    IN PWSTR BootFileSystem OPTIONAL,
    IN PLIST_ENTRY DriverListHead
    )

/*++

Routine Description:

    Traverses a particular control set and creates a list of boot drivers
    to be loaded.  This list is unordered, but complete.

Arguments:

    Hive - Supplies the hive control structure for the SYSTEM hive.

    ControlSet - Supplies the HCELL_INDEX of the root of the control set.

    LoadType - Supplies the type of drivers to be loaded (BootLoad,
            SystemLoad, AutoLoad, etc)

    BootFileSystem - If present, supplies the base name of the boot
        filesystem, which is explicitly added to the driver list.

    DriverListHead - Supplies a pointer to the head of the (empty) list
            of boot drivers to load.

Return Value:

    TRUE - List successfully created.

    FALSE - Hive is corrupt.

--*/

{
    HCELL_INDEX Services;
    HCELL_INDEX Control;
    HCELL_INDEX GroupOrder;
    HCELL_INDEX DriverCell;
    UNICODE_STRING Name;
    int i;
    UNICODE_STRING UnicodeString;
    UNICODE_STRING BasePath;
    WCHAR BaseBuffer[128];
    PBOOT_DRIVER_NODE BootFileSystemNode;
    PCM_KEY_NODE ControlNode;
    PCM_KEY_NODE ServicesNode;
    PCM_KEY_NODE Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Find SERVICES node.
    //
    ControlNode = (PCM_KEY_NODE)HvGetCell(Hive,ControlSet);
    if( ControlNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Services");
    Services = CmpFindSubKeyByName(Hive,
                                   ControlNode,
                                   &Name);
    if (Services == HCELL_NIL) {
        return(FALSE);
    }
    ServicesNode = (PCM_KEY_NODE)HvGetCell(Hive,Services);
    if( ServicesNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }

    //
    // Find CONTROL node.
    //
    RtlInitUnicodeString(&Name, L"Control");
    Control = CmpFindSubKeyByName(Hive,
                                  ControlNode,
                                  &Name);
    if (Control == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find GroupOrderList node.
    //
    RtlInitUnicodeString(&Name, L"GroupOrderList");
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Control);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    GroupOrder = CmpFindSubKeyByName(Hive,
                                     Node,
                                     &Name);
    if (GroupOrder == HCELL_NIL) {
        return(FALSE);
    }

    BasePath.Length = 0;
    BasePath.MaximumLength = sizeof(BaseBuffer);
    BasePath.Buffer = BaseBuffer;
    RtlAppendUnicodeToString(&BasePath, L"\\Registry\\Machine\\System\\");
    RtlAppendUnicodeToString(&BasePath, L"CurrentControlSet\\Services\\");

    i=0;
    do {
        DriverCell = CmpFindSubKeyByNumber(Hive,ServicesNode,i++);
        if (DriverCell != HCELL_NIL) {
            if (CmpIsLoadType(Hive, DriverCell, LoadType)) {
                CmpAddDriverToList(Hive,
                                   DriverCell,
                                   GroupOrder,
                                   &BasePath,
                                   DriverListHead);

            }
        }
    } while ( DriverCell != HCELL_NIL );

    if (ARGUMENT_PRESENT(BootFileSystem)) {
        //
        // Add boot filesystem to boot driver list
        //

        RtlInitUnicodeString(&UnicodeString, BootFileSystem);
        DriverCell = CmpFindSubKeyByName(Hive,
                                         ServicesNode,
                                         &UnicodeString);
        if (DriverCell != HCELL_NIL) {
            CmpAddDriverToList(Hive,
                               DriverCell,
                               GroupOrder,
                               &BasePath,
                               DriverListHead);

            //
            // mark the Boot Filesystem critical
            //
            BootFileSystemNode = CONTAINING_RECORD(DriverListHead->Flink,
                                                   BOOT_DRIVER_NODE,
                                                   ListEntry.Link);
            BootFileSystemNode->ErrorControl = SERVICE_ERROR_CRITICAL;
        }
    }
    return(TRUE);

}


BOOLEAN
CmpIsLoadType(
    IN PHHIVE Hive,
    IN HCELL_INDEX Cell,
    IN SERVICE_LOAD_TYPE LoadType
    )

/*++

Routine Description:

    Determines if the driver is of a specified LoadType, based on its
    node values.

Arguments:

    Hive - Supplies a pointer to the hive control structure for the system
           hive.

    Cell - Supplies the cell index of the driver's node in the system hive.

    LoadType - Supplies the type of drivers to be loaded (BootLoad,
            SystemLoad, AutoLoad, etc)

Return Value:

    TRUE - Driver is the correct type and should be loaded.

    FALSE - Driver is not the correct type and should not be loaded.

--*/

{
    HCELL_INDEX ValueCell;
    PLONG Data;
    UNICODE_STRING Name;
    PCM_KEY_VALUE Value;
    ULONG realsize;
    PCM_KEY_NODE Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Must have a Start=BootLoad value in order to be a boot driver, so
    // look for that first.
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Cell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Start");
    ValueCell = CmpFindValueByName(Hive,
                                   Node,
                                   &Name);
    if (ValueCell == HCELL_NIL) {
        return(FALSE);
    }

    Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }

    Data = (PLONG)CmpValueToData(Hive,Value,&realsize);
    if( Data == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }

    if (*Data != LoadType) {
        return(FALSE);
    }

    return(TRUE);
}


BOOLEAN
CmpAddDriverToList(
    IN PHHIVE Hive,
    IN HCELL_INDEX DriverCell,
    IN HCELL_INDEX GroupOrderCell,
    IN PUNICODE_STRING RegistryPath,
    IN PLIST_ENTRY BootDriverListHead
    )

/*++

Routine Description:

    This routine allocates a list entry node for a particular driver.
    It initializes it with the registry path, filename, group name, and
    dependency list.  Finally, it inserts the new node into the boot
    driver list.

    Note that this routine allocates memory by calling the Hive's
    memory allocation procedure.

Arguments:

    Hive - Supplies a pointer to the hive control structure

    DriverCell - Supplies the HCELL_INDEX of the driver's node in the hive.

    GroupOrderCell - Supplies the HCELL_INDEX of the GroupOrderList key.
        ( \Registry\Machine\System\CurrentControlSet\Control\GroupOrderList )

    RegistryPath - Supplies the full registry path to the SERVICES node
            of the current control set.

    BootDriverListHead - Supplies the head of the boot driver list

Return Value:

    TRUE - Driver successfully added to boot driver list.

    FALSE - Could not add driver to boot driver list.

--*/

{
    PCM_KEY_NODE            Driver;
    USHORT                  DriverNameLength;
    PCM_KEY_VALUE           Value;
    PBOOT_DRIVER_NODE       DriverNode;
    PBOOT_DRIVER_LIST_ENTRY DriverEntry;
    HCELL_INDEX             ValueCell;
    HCELL_INDEX             Tag;
    UNICODE_STRING          UnicodeString;
    PUNICODE_STRING         FileName;
    ULONG                   Length;
    ULONG                   realsize;
    PULONG                  TempULong;
    PWSTR                   TempBuffer;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );

    Driver = (PCM_KEY_NODE)HvGetCell(Hive, DriverCell);
    if( Driver == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    DriverNode = (Hive->Allocate)(sizeof(BOOT_DRIVER_NODE),FALSE,CM_FIND_LEAK_TAG1);
    if (DriverNode == NULL) {
        return(FALSE);
    }
    DriverEntry = &DriverNode->ListEntry;

    DriverEntry->RegistryPath.Buffer = NULL;
    DriverEntry->FilePath.Buffer = NULL;

    if (Driver->Flags & KEY_COMP_NAME) {
        DriverNode->Name.Length = CmpCompressedNameSize(Driver->Name,Driver->NameLength);
        DriverNode->Name.Buffer = (Hive->Allocate)(DriverNode->Name.Length, FALSE,CM_FIND_LEAK_TAG2);
        if (DriverNode->Name.Buffer == NULL) {
            return(FALSE);
        }
        CmpCopyCompressedName(DriverNode->Name.Buffer,
                              DriverNode->Name.Length,
                              Driver->Name,
                              Driver->NameLength);

    } else {
        DriverNode->Name.Length = Driver->NameLength;
        DriverNode->Name.Buffer = (Hive->Allocate)(DriverNode->Name.Length, FALSE,CM_FIND_LEAK_TAG2);
        if (DriverNode->Name.Buffer == NULL) {
            return(FALSE);
        }
        RtlCopyMemory((PVOID)(DriverNode->Name.Buffer), (PVOID)(Driver->Name), Driver->NameLength);
    }
    DriverNode->Name.MaximumLength = DriverNode->Name.Length;
    DriverNameLength = DriverNode->Name.Length;

    //
    // Check for ImagePath value, which will override the default name
    // if it is present.
    //
    RtlInitUnicodeString(&UnicodeString, L"ImagePath");
    ValueCell = CmpFindValueByName(Hive,
                                   Driver,
                                   &UnicodeString);
    if (ValueCell == HCELL_NIL) {

        //
        // No ImagePath, so generate default filename.
        // Build up Unicode filename  ("system32\drivers\<nodename>.sys");
        //

        Length = sizeof(L"System32\\Drivers\\") +
                 DriverNameLength  +
                 sizeof(L".sys");

        FileName = &DriverEntry->FilePath;
        FileName->Length = 0;
        FileName->MaximumLength = (USHORT)Length;
        FileName->Buffer = (PWSTR)(Hive->Allocate)(Length, FALSE,CM_FIND_LEAK_TAG3);
        if (FileName->Buffer == NULL) {
            return(FALSE);
        }
        if (!NT_SUCCESS(RtlAppendUnicodeToString(FileName, L"System32\\"))) {
            return(FALSE);
        }
        if (!NT_SUCCESS(RtlAppendUnicodeToString(FileName, L"Drivers\\"))) {
            return(FALSE);
        }
        if (!NT_SUCCESS(
                RtlAppendUnicodeStringToString(FileName,
                                               &DriverNode->Name))) {
            return(FALSE);
        }
        if (!NT_SUCCESS(RtlAppendUnicodeToString(FileName, L".sys"))) {
            return(FALSE);
        }

    } else {
        Value = (PCM_KEY_VALUE)HvGetCell(Hive,ValueCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return FALSE;
        }
        FileName = &DriverEntry->FilePath;
        TempBuffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
        FileName->Buffer = (PWSTR)(Hive->Allocate)(realsize, FALSE,CM_FIND_LEAK_TAG3);
        if( (FileName->Buffer == NULL) || (TempBuffer == NULL) ) {
            //
            // HvGetCell inside CmpValueToData failed; bail out safely
            //
            return FALSE;
        }
        RtlCopyMemory((PVOID)(FileName->Buffer), (PVOID)(TempBuffer), realsize);
        FileName->MaximumLength = FileName->Length = (USHORT)realsize;
    }

    FileName = &DriverEntry->RegistryPath;
    FileName->Length = 0;
    FileName->MaximumLength = RegistryPath->Length + DriverNameLength;
    FileName->Buffer = (Hive->Allocate)(FileName->MaximumLength,FALSE,CM_FIND_LEAK_TAG4);
    if (FileName->Buffer == NULL) {
        return(FALSE);
    }
    RtlAppendUnicodeStringToString(FileName, RegistryPath);
    RtlAppendUnicodeStringToString(FileName, &DriverNode->Name);

    InsertHeadList(BootDriverListHead, &DriverEntry->Link);

    //
    // Find "ErrorControl" value
    //

    RtlInitUnicodeString(&UnicodeString, L"ErrorControl");
    ValueCell = CmpFindValueByName(Hive,
                                   Driver,
                                   &UnicodeString);
    if (ValueCell == HCELL_NIL) {
        DriverNode->ErrorControl = NormalError;
    } else {
        Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return FALSE;
        }

        TempULong = (PULONG)CmpValueToData(Hive,Value,&realsize);
        if( TempULong == NULL ) {
            //
            // HvGetCell inside CmpValueToData failed; bail out safely
            //
            return FALSE;
        }
        DriverNode->ErrorControl = *TempULong;
    }

    //
    // Find "Group" value
    //
    RtlInitUnicodeString(&UnicodeString, L"group");
    ValueCell = CmpFindValueByName(Hive,
                                   Driver,
                                   &UnicodeString);
    if (ValueCell == HCELL_NIL) {
        DriverNode->Group.Length = 0;
        DriverNode->Group.MaximumLength = 0;
        DriverNode->Group.Buffer = NULL;
    } else {
        Value = (PCM_KEY_VALUE)HvGetCell(Hive, ValueCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return FALSE;
        }

        DriverNode->Group.Buffer = (PWSTR)CmpValueToData(Hive,Value,&realsize);
        if( DriverNode->Group.Buffer == NULL ) {
            //
            // HvGetCell inside CmpValueToData failed; bail out safely
            //
            return FALSE;
        }
        DriverNode->Group.Length = (USHORT)realsize - sizeof(WCHAR);
        DriverNode->Group.MaximumLength = (USHORT)DriverNode->Group.Length;
    }

    //
    // Calculate the tag value for the driver.  If the driver has no tag,
    // this defaults to 0xffffffff, so the driver is loaded last in the
    // group.
    //
    RtlInitUnicodeString(&UnicodeString, L"Tag");
    Tag = CmpFindValueByName(Hive,
                             Driver,
                             &UnicodeString);
    if (Tag == HCELL_NIL) {
        DriverNode->Tag = LOAD_LAST;
    } else {
        //
        // Now we have to find this tag in the tag list for the group.
        // If the tag is not in the tag list, then it defaults to 0xfffffffe,
        // so it is loaded after all the drivers in the tag list, but before
        // all the drivers without tags at all.
        //

        DriverNode->Tag = CmpFindTagIndex(Hive,
                                          Tag,
                                          GroupOrderCell,
                                          &DriverNode->Group);
    }

    return(TRUE);

}


BOOLEAN
CmpSortDriverList(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    IN PLIST_ENTRY DriverListHead
    )

/*++

Routine Description:

    Sorts the list of boot drivers by their groups based on the group
    ordering in <control_set>\CONTROL\SERVICE_GROUP_ORDER:list

    Does NOT do dependency ordering.

Arguments:

    Hive - Supplies the hive control structure for the SYSTEM hive.

    ControlSet - Supplies the HCELL_INDEX of the root of the control set.

    DriverListHead - Supplies a pointer to the head of the list of
            boot drivers to be sorted.

Return Value:

    TRUE - List successfully sorted

    FALSE - List is inconsistent and could not be sorted.

--*/

{
    HCELL_INDEX Controls;
    HCELL_INDEX GroupOrder;
    HCELL_INDEX ListCell;
    UNICODE_STRING Name;
    UNICODE_STRING DependList;
    PCM_KEY_VALUE ListNode;
    ULONG realsize;
    PCM_KEY_NODE Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Find "CONTROL" node.
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"Control");
    Controls = CmpFindSubKeyByName(Hive,
                                   Node,
                                   &Name);
    if (Controls == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find "SERVICE_GROUP_ORDER" subkey
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,Controls);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"ServiceGroupOrder");
    GroupOrder = CmpFindSubKeyByName(Hive,
                                     Node,
                                     &Name);
    if (GroupOrder == HCELL_NIL) {
        return(FALSE);
    }

    //
    // Find "list" value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive,GroupOrder);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"list");
    ListCell = CmpFindValueByName(Hive,
                                  Node,
                                  &Name);
    if (ListCell == HCELL_NIL) {
        return(FALSE);
    }
    ListNode = (PCM_KEY_VALUE)HvGetCell(Hive, ListCell);
    if( ListNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    if (ListNode->Type != REG_MULTI_SZ) {
        return(FALSE);
    }

    DependList.Buffer = (PWSTR)CmpValueToData(Hive,ListNode,&realsize);
    if( DependList.Buffer == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return FALSE;
    }
    DependList.Length = DependList.MaximumLength = (USHORT)realsize - sizeof(WCHAR);

    //
    // Dependency list is now pointed to by DependList->Buffer.  We need
    // to sort the driver entry list.
    //

    return (CmpDoSort(DriverListHead, &DependList));

}

BOOLEAN
CmpDoSort(
    IN PLIST_ENTRY DriverListHead,
    IN PUNICODE_STRING OrderList
    )

/*++

Routine Description:

    Sorts the boot driver list based on the order list

    Start with the last entry in the group order list and work towards
    the beginning.  For each group entry, move all driver entries that
    are members of the group to the front of the list.  Driver entries
    with no groups, or with a group that does not match any in the
    group list will be shoved to the end of the list.

Arguments:

    DriverListHead - Supplies a pointer to the head of the list of
            boot drivers to be sorted.

    OrderList - Supplies pointer to the order list

Return Value:

    TRUE - List successfully ordered

    FALSE - List is inconsistent and could not be ordered.

--*/

{
    PWSTR Current;
    PWSTR End = NULL;
    PLIST_ENTRY Next;
    PBOOT_DRIVER_NODE CurrentNode;
    UNICODE_STRING CurrentGroup;


    Current = (PWSTR) ((PUCHAR)(OrderList->Buffer)+OrderList->Length);

    while (Current > OrderList->Buffer) {
        do {
            if (*Current == UNICODE_NULL) {
                End = Current;
            }
            --Current;
        } while ((*(Current-1) != UNICODE_NULL) &&
                 ( Current != OrderList->Buffer));

        ASSERT (End != NULL);
        //
        // Current now points to the beginning of the NULL-terminated
        // Unicode string.
        // End now points to the end of the string
        //
        CurrentGroup.Length = (USHORT) ((PCHAR)End - (PCHAR)Current);
        CurrentGroup.MaximumLength = CurrentGroup.Length;
        CurrentGroup.Buffer = Current;
        Next = DriverListHead->Flink;
        while (Next != DriverListHead) {
            CurrentNode = CONTAINING_RECORD(Next,
                                            BOOT_DRIVER_NODE,
                                            ListEntry.Link);
            Next = CurrentNode->ListEntry.Link.Flink;
            if (CurrentNode->Group.Buffer != NULL) {
                if (RtlEqualUnicodeString(&CurrentGroup, &CurrentNode->Group,TRUE)) {
                    RemoveEntryList(&CurrentNode->ListEntry.Link);
                    InsertHeadList(DriverListHead,
                                   &CurrentNode->ListEntry.Link);
                }
            }
        }
        --Current;

    }

    return(TRUE);

}


BOOLEAN
CmpResolveDriverDependencies(
    IN PLIST_ENTRY DriverListHead
    )

/*++

Routine Description:

    This routine orders driver nodes in a group based on their dependencies
    on one another.  It removes any drivers that have circular dependencies
    from the list.

Arguments:

    DriverListHead - Supplies a pointer to the head of the list of
            boot drivers to be sorted.

Return Value:

    TRUE - Dependencies successfully resolved

    FALSE - Corrupt hive.

--*/

{
    PLIST_ENTRY CurrentEntry;
    PBOOT_DRIVER_NODE GroupStart;
    PBOOT_DRIVER_NODE GroupEnd;
    PBOOT_DRIVER_NODE CurrentNode;

    CurrentEntry = DriverListHead->Flink;

    while (CurrentEntry != DriverListHead) {
        //
        // The list is already ordered by groups.  Find the first and
        // last entry in each group, and order each of these sub-lists
        // based on their dependencies.
        //

        GroupStart = CONTAINING_RECORD(CurrentEntry,
                                       BOOT_DRIVER_NODE,
                                       ListEntry.Link);
        do {
            GroupEnd = CONTAINING_RECORD(CurrentEntry,
                                         BOOT_DRIVER_NODE,
                                         ListEntry.Link);

            CurrentEntry = CurrentEntry->Flink;
            CurrentNode = CONTAINING_RECORD(CurrentEntry,
                                            BOOT_DRIVER_NODE,
                                            ListEntry.Link);

            if (CurrentEntry == DriverListHead) {
                break;
            }

            if (!RtlEqualUnicodeString(&GroupStart->Group,
                                       &CurrentNode->Group,
                                       TRUE)) {
                break;
            }

        } while ( CurrentEntry != DriverListHead );

        //
        // GroupStart now points to the first driver node in the group,
        // and GroupEnd points to the last driver node in the group.
        //
        CmpOrderGroup(GroupStart, GroupEnd);

    }
    return(TRUE);
}


BOOLEAN
CmpOrderGroup(
    IN PBOOT_DRIVER_NODE GroupStart,
    IN PBOOT_DRIVER_NODE GroupEnd
    )

/*++

Routine Description:

    Reorders the nodes in a driver group based on their tag values.

Arguments:

    GroupStart - Supplies the first node in the group.

    GroupEnd - Supplies the last node in the group.

Return Value:

    TRUE - Group successfully reordered

    FALSE - Circular dependencies detected.

--*/

{
    PBOOT_DRIVER_NODE Current;
    PBOOT_DRIVER_NODE Previous;
    PLIST_ENTRY ListEntry;

    if (GroupStart == GroupEnd) {
        return(TRUE);
    }

    Current = GroupStart;

    do {
        //
        // If the driver before the current one has a lower tag, then
        // we do not need to move it.  If not, then remove the driver
        // from the list and scan backwards until we find a driver with
        // a tag that is <= the current tag, or we reach the beginning
        // of the list.
        //
        Previous = Current;
        ListEntry = Current->ListEntry.Link.Flink;
        Current = CONTAINING_RECORD(ListEntry,
                                    BOOT_DRIVER_NODE,
                                    ListEntry.Link);

        if (Previous->Tag > Current->Tag) {
            //
            // Remove the Current driver from the list, and search
            // backwards until we find a tag that is <= the current
            // driver's tag.  Reinsert the current driver there.
            //
            if (Current == GroupEnd) {
                ListEntry = Current->ListEntry.Link.Blink;
                GroupEnd = CONTAINING_RECORD(ListEntry,
                                             BOOT_DRIVER_NODE,
                                             ListEntry.Link);
            }
            RemoveEntryList(&Current->ListEntry.Link);
            while ( (Previous->Tag > Current->Tag) &&
                    (Previous != GroupStart) ) {
                ListEntry = Previous->ListEntry.Link.Blink;
                Previous = CONTAINING_RECORD(ListEntry,
                                             BOOT_DRIVER_NODE,
                                             ListEntry.Link);
            }
            InsertTailList(&Previous->ListEntry.Link,
                           &Current->ListEntry.Link);
            if (Previous == GroupStart) {
                GroupStart = Current;
            }
        }

    } while ( Current != GroupEnd );

    return(TRUE);
}

BOOLEAN
CmpValidateSelect(
     IN PHHIVE SystemHive,
     IN HCELL_INDEX RootCell
     )
/*++

Routine Description:

    This routines parses the SYSTEM hive and "Select" node
    and verifies the following values:

    Current
    Default
    Failed
    LastKnownGood


    If any of these is missing the the loader will put the corrupt
    system hive message

    This routine is to be called by the loader just after it loads the
    system hive. It's purpose is to ensure a uniform and consistent way
    to treat missing values in this area.

Arguments:

    SystemHive - Supplies the hive control structure for the SYSTEM hive.

    RootCell - Supplies the HCELL_INDEX of the root cell of the hive.


Return Value:

    TRUE - all the values are here
    FALSE - some of them are missing

--*/
{
    HCELL_INDEX     Select;
    PCM_KEY_NODE    Node;
    UNICODE_STRING  Name;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );

    //
    // Find \SYSTEM\SELECT node.
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,RootCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&Name, L"select");
    Select = CmpFindSubKeyByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    //
    // Find AutoSelect value
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,Select);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }

    // search for current
    RtlInitUnicodeString(&Name, L"current");
    Select = CmpFindValueByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    // search for default
    RtlInitUnicodeString(&Name, L"default");
    Select = CmpFindValueByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    // search for failed
    RtlInitUnicodeString(&Name, L"failed");
    Select = CmpFindValueByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    // search for LKG
    RtlInitUnicodeString(&Name, L"LastKnownGood");
    Select = CmpFindValueByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return FALSE;
    }

    return TRUE;
}

HCELL_INDEX
CmpFindControlSet(
     IN PHHIVE SystemHive,
     IN HCELL_INDEX RootCell,
     IN PUNICODE_STRING SelectName,
     OUT PBOOLEAN AutoSelect
     )

/*++

Routine Description:

    This routines parses the SYSTEM hive and "Select" node
    to locate the control set to be used for booting.

    Note that this routines also updates the value of Current to reflect
    the control set that was just found.  This is what we want to do
    when this is called during boot.  During I/O initialization, this
    is irrelevant, since we're just changing it to what it already is.

Arguments:

    SystemHive - Supplies the hive control structure for the SYSTEM hive.

    RootCell - Supplies the HCELL_INDEX of the root cell of the hive.

    SelectName - Supplies the name of the Select value to be used in
            determining the control set.  This should be one of "Current"
            "Default" or "LastKnownGood"

    AutoSelect - Returns the value of the AutoSelect value under
            the Select node.

Return Value:

    != HCELL_NIL - Cell Index of the control set to be used for booting.
    == HCELL_NIL - Indicates the hive is corrupt or inconsistent

--*/

{
    HCELL_INDEX     Select;
    HCELL_INDEX     ValueCell;
    HCELL_INDEX     ControlSet;
    HCELL_INDEX     AutoSelectCell;
    NTSTATUS        Status;
    UNICODE_STRING  Name;
    ANSI_STRING     AnsiString;
    PCM_KEY_VALUE   Value;
    PULONG          ControlSetIndex;
    PULONG          CurrentControl;
    CHAR            AsciiBuffer[128];
    WCHAR           UnicodeBuffer[128];
    ULONG           realsize;
    PCM_KEY_NODE    Node;
    PBOOLEAN        TempBoolean;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );
    //
    // Find \SYSTEM\SELECT node.
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,RootCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    RtlInitUnicodeString(&Name, L"select");
    Select = CmpFindSubKeyByName(SystemHive,
                                Node,
                                &Name);
    if (Select == HCELL_NIL) {
        return(HCELL_NIL);
    }

    //
    // Find AutoSelect value
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,Select);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    RtlInitUnicodeString(&Name, L"AutoSelect");
    AutoSelectCell = CmpFindValueByName(SystemHive,
                                        Node,
                                        &Name);
    if (AutoSelectCell == HCELL_NIL) {
        //
        // It's not there, we don't care.  Set autoselect to TRUE
        //
        *AutoSelect = TRUE;
    } else {
        Value = (PCM_KEY_VALUE)HvGetCell(SystemHive, AutoSelectCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return HCELL_NIL;
        }

        TempBoolean = (PBOOLEAN)(CmpValueToData(SystemHive,Value,&realsize));
        if( TempBoolean == NULL ) {
            //
            // HvGetCell inside CmpValueToData failed; bail out safely
            //
            return HCELL_NIL;
        }

        *AutoSelect = *TempBoolean;
    }

    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,Select);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    ValueCell = CmpFindValueByName(SystemHive,
                                   Node,
                                   SelectName);
    if (ValueCell == HCELL_NIL) {
        return(HCELL_NIL);
    }
    Value = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
    if( Value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    if (Value->Type != REG_DWORD) {
        return(HCELL_NIL);
    }

    ControlSetIndex = (PULONG)CmpValueToData(SystemHive, Value,&realsize);
    if( ControlSetIndex == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return HCELL_NIL;
    }

    //
    // Find appropriate control set
    //

    sprintf(AsciiBuffer, "ControlSet%03d", *ControlSetIndex);
    AnsiString.Length = AnsiString.MaximumLength = (USHORT) strlen(&(AsciiBuffer[0]));
    AnsiString.Buffer = AsciiBuffer;
    Name.MaximumLength = 128*sizeof(WCHAR);
    Name.Buffer = UnicodeBuffer;
    Status = RtlAnsiStringToUnicodeString(&Name,
                                          &AnsiString,
                                          FALSE);
    if (!NT_SUCCESS(Status)) {
        return(HCELL_NIL);
    }

    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,RootCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    ControlSet = CmpFindSubKeyByName(SystemHive,
                                     Node,
                                     &Name);
    if (ControlSet == HCELL_NIL) {
        return(HCELL_NIL);
    }

    //
    // Control set was successfully found, so update the value in "Current"
    // to reflect the control set we are going to use.
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,Select);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    RtlInitUnicodeString(&Name, L"Current");
    ValueCell = CmpFindValueByName(SystemHive,
                                   Node,
                                   &Name);
    if (ValueCell != HCELL_NIL) {
        Value = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
        if( Value == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //

            return HCELL_NIL;
        }
        if (Value->Type == REG_DWORD) {
            CurrentControl = (PULONG)CmpValueToData(SystemHive, Value,&realsize);
            if( CurrentControl == NULL ) {
                //
                // HvGetCell inside CmpValueToData failed; bail out safely
                //
                return HCELL_NIL;
            }
            *CurrentControl = *ControlSetIndex;
        }
    }
    return(ControlSet);

}


VOID
CmpSetCurrentProfile(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    IN PCM_HARDWARE_PROFILE Profile
    )

/*++

Routine Description:

    Edits the in-memory copy of the registry to reflect the hardware
    profile that the system is booting from.

Arguments:

    Hive - Supplies a pointer to the hive control structure

    ControlSet - Supplies the HCELL_INDEX of the current control set.

    Profile - Supplies a pointer to the selected hardware profile

Return Value:

    None.

--*/

{
    HCELL_INDEX IDConfigDB;
    PCM_KEY_NODE IDConfigNode;
    HCELL_INDEX CurrentConfigCell;
    PCM_KEY_VALUE CurrentConfigValue;
    UNICODE_STRING Name;
    PULONG CurrentConfig;
    ULONG realsize;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );

    IDConfigDB = CmpFindProfileOption(Hive,
                                      ControlSet,
                                      NULL,
                                      NULL,
                                      NULL);
    if (IDConfigDB != HCELL_NIL) {
        IDConfigNode = (PCM_KEY_NODE)HvGetCell(Hive, IDConfigDB);
        if( IDConfigNode == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            return;
        }

        RtlInitUnicodeString(&Name, L"CurrentConfig");
        CurrentConfigCell = CmpFindValueByName(Hive,
                                               IDConfigNode,
                                               &Name);
        if (CurrentConfigCell != HCELL_NIL) {
            CurrentConfigValue = (PCM_KEY_VALUE)HvGetCell(Hive, CurrentConfigCell);
            if( CurrentConfigValue == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                return;
            }
            if (CurrentConfigValue->Type == REG_DWORD) {
                CurrentConfig = (PULONG)CmpValueToData(Hive,
                                                       CurrentConfigValue,
                                                       &realsize);
                if( CurrentConfig == NULL ) {
                    //
                    // HvGetCell inside CmpValueToData failed; bail out safely
                    //
                    return;
                }
                *CurrentConfig = Profile->Id;
            }
        }
    }


}


HCELL_INDEX
CmpFindProfileOption(
     IN PHHIVE SystemHive,
     IN HCELL_INDEX ControlSet,
     OUT OPTIONAL PCM_HARDWARE_PROFILE_LIST *ReturnedProfileList,
     OUT OPTIONAL PCM_HARDWARE_PROFILE_ALIAS_LIST *ReturnedAliasList,
     OUT OPTIONAL PULONG ProfileTimeout
     )

/*++

Routine Description:

    This routines parses the SYSTEM hive and locates the
    "CurrentControlSet\Control\IDConfigDB" node to determine the
    hardware profile configuration settings.

Arguments:

    SystemHive - Supplies the hive control structure for the SYSTEM hive.

    ControlSet - Supplies the HCELL_INDEX of the root cell of the hive.

    ProfileList - Returns the list of available hardware profiles sorted
                  by preference. Will be allocated by this routine if
                  NULL is passed in, or a pointer to a CM_HARDWARE_PROFILE_LIST
                  structure that is too small is passed in.

    ProfileTimeout - Returns the timeout value for the config menu.

Return Value:

    != HCELL_NIL - Cell Index of the IDConfigDB node.
    == HCELL_NIL - Indicates IDConfigDB does not exist

--*/
{
    HCELL_INDEX                     ControlCell;
    HCELL_INDEX                     IDConfigDB;
    HCELL_INDEX                     TimeoutCell;
    HCELL_INDEX                     ProfileCell;
    HCELL_INDEX                     AliasCell;
    HCELL_INDEX                     HWCell;
    PCM_KEY_NODE                    HWNode;
    PCM_KEY_NODE                    ProfileNode;
    PCM_KEY_NODE                    AliasNode;
    PCM_KEY_NODE                    ConfigDBNode;
    PCM_KEY_NODE                    Control;
    PCM_KEY_VALUE                   TimeoutValue;
    UNICODE_STRING                  Name;
    ULONG                           realsize;
    PCM_HARDWARE_PROFILE_LIST       ProfileList;
    PCM_HARDWARE_PROFILE_ALIAS_LIST AliasList;
    ULONG                           ProfileCount;
    ULONG                           AliasCount;
    ULONG                           i,j;
    WCHAR                           NameBuf[20];
    PCM_KEY_NODE                    Node;
    PULONG                          TempULong;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );
    //
    // Find Control node
    //
    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }
    RtlInitUnicodeString(&Name, L"Control");
    ControlCell = CmpFindSubKeyByName(SystemHive,
                                      Node,
                                      &Name);
    if (ControlCell == HCELL_NIL) {
        return(HCELL_NIL);
    }
    Control = (PCM_KEY_NODE)HvGetCell(SystemHive, ControlCell);
    if( Control == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }

    //
    // Find IDConfigDB node
    //
    RtlInitUnicodeString(&Name, L"IDConfigDB");
    IDConfigDB = CmpFindSubKeyByName(SystemHive,
                                     Control,
                                     &Name);
    if (IDConfigDB == HCELL_NIL) {
        return(HCELL_NIL);
    }
    ConfigDBNode = (PCM_KEY_NODE)HvGetCell(SystemHive, IDConfigDB);
    if( ConfigDBNode == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return HCELL_NIL;
    }

    if (ARGUMENT_PRESENT(ProfileTimeout)) {
        //
        // Find UserWaitInterval value. This is the timeout
        //
        RtlInitUnicodeString(&Name, L"UserWaitInterval");
        TimeoutCell = CmpFindValueByName(SystemHive,
                                         ConfigDBNode,
                                         &Name);
        if (TimeoutCell == HCELL_NIL) {
            *ProfileTimeout = 0;
        } else {
            TimeoutValue = (PCM_KEY_VALUE)HvGetCell(SystemHive, TimeoutCell);
            if( TimeoutValue == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //

                return HCELL_NIL;
            }
            if (TimeoutValue->Type != REG_DWORD) {
                *ProfileTimeout = 0;
            } else {
                TempULong = (PULONG)CmpValueToData(SystemHive, TimeoutValue, &realsize);
                if( TempULong == NULL ) {
                    //
                    // HvGetCell inside CmpValueToData failed; bail out safely
                    //
                    return HCELL_NIL;
                }
                *ProfileTimeout = *TempULong;
            }
        }
    }

    if (ARGUMENT_PRESENT(ReturnedProfileList)) {
        ProfileList = *ReturnedProfileList;
        //
        // Enumerate the keys under IDConfigDB\Hardware Profiles
        // and build the list of available hardware profiles.  The list
        // is built sorted by PreferenceOrder.  Therefore, when the
        // list is complete, the default hardware profile is at the
        // head of the list.
        //
        RtlInitUnicodeString(&Name, L"Hardware Profiles");
        ProfileCell = CmpFindSubKeyByName(SystemHive,
                                          ConfigDBNode,
                                          &Name);
        if (ProfileCell == HCELL_NIL) {
            ProfileCount = 0;
            if (ProfileList != NULL) {
                ProfileList->CurrentProfileCount = 0;
            }
        } else {
            ProfileNode = (PCM_KEY_NODE)HvGetCell(SystemHive, ProfileCell);
            if( ProfileNode == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //

                return HCELL_NIL;
            }
            ProfileCount = ProfileNode->SubKeyCounts[Stable];
            if ((ProfileList == NULL) || (ProfileList->MaxProfileCount < ProfileCount)) {
                //
                // Allocate a larger ProfileList
                //
                ProfileList = (SystemHive->Allocate)(sizeof(CM_HARDWARE_PROFILE_LIST)
                                                     + (ProfileCount-1) * sizeof(CM_HARDWARE_PROFILE),
                                                     FALSE
                                                     ,CM_FIND_LEAK_TAG5);
                if (ProfileList == NULL) {
                    return(HCELL_NIL);
                }
                ProfileList->MaxProfileCount = ProfileCount;
            }
            ProfileList->CurrentProfileCount = 0;

            //
            // Enumerate the keys and fill in the profile list.
            //
            for (i=0; i<ProfileCount; i++) {
                CM_HARDWARE_PROFILE TempProfile;
                HCELL_INDEX ValueCell;
                PCM_KEY_VALUE ValueNode;
                UNICODE_STRING KeyName;

                HWCell = CmpFindSubKeyByNumber(SystemHive, ProfileNode, i);
                if (HWCell == HCELL_NIL) {
                    //
                    // This should never happen.
                    //
                    ProfileList->CurrentProfileCount = i;
                    break;
                }
                HWNode = (PCM_KEY_NODE)HvGetCell(SystemHive, HWCell);
                if( HWNode == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //

                    return HCELL_NIL;
                }
                if (HWNode->Flags & KEY_COMP_NAME) {
                    KeyName.Length = CmpCompressedNameSize(HWNode->Name,
                                                           HWNode->NameLength);
                    KeyName.MaximumLength = sizeof(NameBuf);
                    if (KeyName.MaximumLength < KeyName.Length) {
                        KeyName.Length = KeyName.MaximumLength;
                    }
                    KeyName.Buffer = NameBuf;
                    CmpCopyCompressedName(KeyName.Buffer,
                                          KeyName.Length,
                                          HWNode->Name,
                                          HWNode->NameLength);
                } else {
                    KeyName.Length = KeyName.MaximumLength = HWNode->NameLength;
                    KeyName.Buffer = HWNode->Name;
                }

                //
                // Fill in the temporary profile structure with this
                // profile's data.
                //
                RtlUnicodeStringToInteger(&KeyName, 0, &TempProfile.Id);
                RtlInitUnicodeString(&Name, CM_HARDWARE_PROFILE_STR_PREFERENCE_ORDER);
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempProfile.PreferenceOrder = (ULONG)-1;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,
                                                      ValueNode,
                                                      &realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempProfile.PreferenceOrder = *TempULong;
                }
                RtlInitUnicodeString(&Name, CM_HARDWARE_PROFILE_STR_FRIENDLY_NAME);
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempProfile.FriendlyName = L"-------";
                    TempProfile.NameLength = (ULONG)(wcslen(TempProfile.FriendlyName) * sizeof(WCHAR));
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }
                    TempProfile.FriendlyName = (PWSTR)CmpValueToData(SystemHive,
                                                                     ValueNode,
                                                                     &realsize);
                    if( TempProfile.FriendlyName == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempProfile.NameLength = realsize - sizeof(WCHAR);
                }

                TempProfile.Flags = 0;

                RtlInitUnicodeString(&Name, CM_HARDWARE_PROFILE_STR_ALIASABLE);
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempProfile.Flags = CM_HP_FLAGS_ALIASABLE;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData (SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    if (*TempULong) {
                        TempProfile.Flags = CM_HP_FLAGS_ALIASABLE;
                        // NO other flags set.
                    }
                }

                RtlInitUnicodeString(&Name, CM_HARDWARE_PROFILE_STR_PRISTINE);
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell != HCELL_NIL) {

                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData (SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    if (*TempULong) {
                        TempProfile.Flags = CM_HP_FLAGS_PRISTINE;
                        // NO other flags set.
                    }
                }

                //
                // If we see a profile with the ID of zero (AKA an illegal)
                // ID for a hardware profile to possess, then we know that this
                // must be a pristine profile.
                //
                if (0 == TempProfile.Id) {
                    TempProfile.Flags = CM_HP_FLAGS_PRISTINE;
                    // NO other flags set.

                    TempProfile.PreferenceOrder = (ULONG)-1; // move to the end of the list.
                }


                //
                // Insert this new profile into the appropriate spot in the
                // profile array. Entries are sorted by preference order.
                //
                for (j=0; j<ProfileList->CurrentProfileCount; j++) {
                    if (ProfileList->Profile[j].PreferenceOrder >= TempProfile.PreferenceOrder) {
                        //
                        // Insert at position j.
                        //
                        RtlMoveMemory(&ProfileList->Profile[j+1],
                                      &ProfileList->Profile[j],
                                      sizeof(CM_HARDWARE_PROFILE)*(ProfileList->MaxProfileCount-j-1));
                        break;
                    }
                }
                ProfileList->Profile[j] = TempProfile;
                ++ProfileList->CurrentProfileCount;
            }
        }
        *ReturnedProfileList = ProfileList;
    }

    if (ARGUMENT_PRESENT(ReturnedAliasList)) {
        AliasList = *ReturnedAliasList;
        //
        // Enumerate the keys under IDConfigDB\Alias
        // and build the list of available hardware profiles aliases.
        // So that if we know our docking state we can find it in the alias
        // table.
        //
        RtlInitUnicodeString(&Name, L"Alias");
        AliasCell = CmpFindSubKeyByName(SystemHive,
                                        ConfigDBNode,
                                        &Name);
        if (AliasCell == HCELL_NIL) {
            AliasCount = 0;
            if (AliasList != NULL) {
                AliasList->CurrentAliasCount = 0;
            }
        } else {
            AliasNode = (PCM_KEY_NODE)HvGetCell(SystemHive, AliasCell);
            if( AliasNode == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //

                return HCELL_NIL;
            }
            AliasCount = AliasNode->SubKeyCounts[Stable];
            if ((AliasList == NULL) || (AliasList->MaxAliasCount < AliasCount)) {
                //
                // Allocate a larger AliasList
                //
                AliasList = (SystemHive->Allocate)(sizeof(CM_HARDWARE_PROFILE_LIST)
                                                   + (AliasCount-1) * sizeof(CM_HARDWARE_PROFILE),
                                                   FALSE
                                                   ,CM_FIND_LEAK_TAG6);
                if (AliasList == NULL) {
                    return(HCELL_NIL);
                }
                AliasList->MaxAliasCount = AliasCount;
            }
            AliasList->CurrentAliasCount = 0;

            //
            // Enumerate the keys and fill in the profile list.
            //
            for (i=0; i<AliasCount; i++) {
#define TempAlias AliasList->Alias[i]
                HCELL_INDEX ValueCell;
                PCM_KEY_VALUE ValueNode;
                UNICODE_STRING KeyName;

                HWCell = CmpFindSubKeyByNumber(SystemHive, AliasNode, i);
                if (HWCell == HCELL_NIL) {
                    //
                    // This should never happen.
                    //
                    AliasList->CurrentAliasCount = i;
                    break;
                }
                HWNode = (PCM_KEY_NODE)HvGetCell(SystemHive, HWCell);
                if( HWNode == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //

                    return HCELL_NIL;
                }
                if (HWNode->Flags & KEY_COMP_NAME) {
                    KeyName.Length = CmpCompressedNameSize(HWNode->Name,
                                                           HWNode->NameLength);
                    KeyName.MaximumLength = sizeof(NameBuf);
                    if (KeyName.MaximumLength < KeyName.Length) {
                        KeyName.Length = KeyName.MaximumLength;
                    }
                    KeyName.Buffer = NameBuf;
                    CmpCopyCompressedName(KeyName.Buffer,
                                          KeyName.Length,
                                          HWNode->Name,
                                          HWNode->NameLength);
                } else {
                    KeyName.Length = KeyName.MaximumLength = HWNode->NameLength;
                    KeyName.Buffer = HWNode->Name;
                }

                //
                // Fill in the temporary profile structure with this
                // profile's data.
                //
                RtlInitUnicodeString(&Name, L"ProfileNumber");
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempAlias.ProfileNumber = 0;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempAlias.ProfileNumber = *TempULong;
                }
                RtlInitUnicodeString(&Name, L"DockState");
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempAlias.DockState = 0;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempAlias.DockState = *TempULong;
                }
                RtlInitUnicodeString(&Name, L"DockID");
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempAlias.DockID = 0;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempAlias.DockID = *TempULong;
                }
                RtlInitUnicodeString(&Name, L"SerialNumber");
                ValueCell = CmpFindValueByName(SystemHive,
                                               HWNode,
                                               &Name);
                if (ValueCell == HCELL_NIL) {
                    TempAlias.SerialNumber = 0;
                } else {
                    ValueNode = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                    if( ValueNode == NULL ) {
                        //
                        // we couldn't map a view for the bin containing this cell
                        //

                        return HCELL_NIL;
                    }

                    TempULong = (PULONG)CmpValueToData(SystemHive,ValueNode,&realsize);
                    if( TempULong == NULL ) {
                        //
                        // HvGetCell inside CmpValueToData failed; bail out safely
                        //
                        return HCELL_NIL;
                    }
                    TempAlias.SerialNumber = *TempULong;
                }

                ++AliasList->CurrentAliasCount;
            }
        }
        *ReturnedAliasList = AliasList;
    }

    return(IDConfigDB);
}


ULONG
CmpFindTagIndex(
    IN PHHIVE Hive,
    IN HCELL_INDEX TagCell,
    IN HCELL_INDEX GroupOrderCell,
    IN PUNICODE_STRING GroupName
    )

/*++

Routine Description:

    Calculates the tag index for a driver based on its tag value and
    the GroupOrderList entry for its group.

Arguments:

    Hive - Supplies the hive control structure for the driver.

    TagCell - Supplies the cell index of the driver's tag value cell.

    GroupOrderCell - Supplies the cell index for the control set's
            GroupOrderList:

            \Registry\Machine\System\CurrentControlSet\Control\GroupOrderList

    GroupName - Supplies the name of the group the driver belongs to.
            Note that if a driver's group does not have an entry under
            GroupOrderList, its tags will be ignored.  Also note that if
            a driver belongs to no group (GroupName is NULL) its tags will
            be ignored.

Return Value:

    The index that the driver should be sorted by.

--*/

{
    PCM_KEY_VALUE TagValue;
    PCM_KEY_VALUE DriverTagValue;
    HCELL_INDEX OrderCell;
    PULONG OrderVector;
    PULONG DriverTag;
    ULONG CurrentTag;
    ULONG realsize;
    PCM_KEY_NODE Node;
    BOOLEAN     BufferAllocated;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );

    DriverTagValue = (PCM_KEY_VALUE)HvGetCell(Hive, TagCell);
    if( DriverTagValue == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return LOAD_NEXT_TO_LAST;
    }

    DriverTag = (PULONG)CmpValueToData(Hive, DriverTagValue, &realsize);
    if( DriverTag == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return LOAD_NEXT_TO_LAST;
    }

    Node = (PCM_KEY_NODE)HvGetCell(Hive,GroupOrderCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return LOAD_NEXT_TO_LAST;
    }
    OrderCell = CmpFindValueByName(Hive,
                                   Node,
                                   GroupName);
    if (OrderCell == HCELL_NIL) {
        return(LOAD_NEXT_TO_LAST);
    }

    TagValue = (PCM_KEY_VALUE)HvGetCell(Hive, OrderCell);
    if( TagValue == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return LOAD_NEXT_TO_LAST;
    }
    CmpGetValueData(Hive,TagValue,&realsize,&OrderVector,&BufferAllocated,&OrderCell);
    //OrderVector = (PULONG)CmpValueToData(Hive, TagValue,&realsize);
    if( OrderVector == NULL ) {
        //
        // HvGetCell inside CmpValueToData failed; bail out safely
        //
        return LOAD_NEXT_TO_LAST;
    }

    for (CurrentTag=1; CurrentTag <= OrderVector[0]; CurrentTag++) {
        if (OrderVector[CurrentTag] == *DriverTag) {
            //
            // We have found a matching tag in the OrderVector, so return
            // its index.
            //
#ifndef _CM_LDR_
            if( BufferAllocated ) {
                ExFreePool( OrderVector );
            }
#endif //_CM_LDR_
            return(CurrentTag);
        }
    }

#ifndef _CM_LDR_
    if( BufferAllocated ) {
        ExFreePool( OrderVector );
    }
#endif //_CM_LDR_
    //
    // There was no matching tag in the OrderVector.
    //
    return(LOAD_NEXT_TO_LAST);

}

#ifdef _WANT_MACHINE_IDENTIFICATION

BOOLEAN
CmpGetBiosDateFromRegistry(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PUNICODE_STRING Date
    )

/*++

Routine Description:

    Reads and returns the BIOS date from the registry.

Arguments:

    Hive - Supplies the hive control structure for the driver.

    ControlSet - Supplies the HCELL_INDEX of the root cell of the hive.

    Date - Receives the date string in the format "mm/dd/yy".

Return Value:

 	TRUE iff successful, else FALSE.
 	
--*/

{
    UNICODE_STRING  name;
    HCELL_INDEX     control;
    HCELL_INDEX     biosInfo;
    HCELL_INDEX     valueCell;
    PCM_KEY_VALUE   value;
    ULONG           realSize;
    PCM_KEY_NODE    Node;
    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );

    //
    // Find CONTROL node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"Control");
    control = CmpFindSubKeyByName(  Hive,
                                    Node,
                                    &name);
    if (control == HCELL_NIL) {

        return(FALSE);
    }

    //
    // Find BIOSINFO node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, control);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"BIOSINFO");
    biosInfo = CmpFindSubKeyByName( Hive,
                                    Node,
                                    &name);
    if (biosInfo == HCELL_NIL) {

        return(FALSE);
    }

    //
    // Find SystemBiosDate value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, biosInfo);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"SystemBiosDate");
    valueCell = CmpFindValueByName( Hive,
                                    Node,
                                    &name);
    if (valueCell == HCELL_NIL) {

        return(FALSE);
    }

    value = (PCM_KEY_VALUE)HvGetCell(Hive, valueCell);
    if( value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Date->Buffer = (PWSTR)CmpValueToData(Hive, value, &realSize);
    if( Date->Buffer == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    Date->MaximumLength=(USHORT)realSize;
    Date->Length = 0;
    while ( (Date->Length < Date->MaximumLength) &&
            (Date->Buffer[Date->Length/sizeof(WCHAR)] != UNICODE_NULL)) {

        Date->Length += sizeof(WCHAR);
    }

    return (TRUE);
}

BOOLEAN
CmpGetBiosinfoFileNameFromRegistry(
    IN PHHIVE Hive,
    IN HCELL_INDEX ControlSet,
    OUT PUNICODE_STRING InfName
    )
{
    UNICODE_STRING  name;
    HCELL_INDEX     control;
    HCELL_INDEX     biosInfo;
    HCELL_INDEX     valueCell;
    PCM_KEY_VALUE   value;
    ULONG           realSize;
    PCM_KEY_NODE    Node;

    //
    // no mapped hives at this point. don't bother releasing cells
    //
    ASSERT( Hive->ReleaseCellRoutine == NULL );
    //
    // Find CONTROL node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, ControlSet);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"Control");
    control = CmpFindSubKeyByName(  Hive,
                                    Node,
                                    &name);
    if (control == HCELL_NIL) {

        return(FALSE);
    }

    //
    // Find BIOSINFO node
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, control);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"BIOSINFO");
    biosInfo = CmpFindSubKeyByName( Hive,
                                    Node,
                                    &name);
    if (biosInfo == HCELL_NIL) {

        return(FALSE);
    }

    //
    // Find InfName value
    //
    Node = (PCM_KEY_NODE)HvGetCell(Hive, biosInfo);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    RtlInitUnicodeString(&name, L"InfName");
    valueCell = CmpFindValueByName( Hive,
                                    Node,
                                    &name);
    if (valueCell == HCELL_NIL) {

        return(FALSE);
    }

    value = (PCM_KEY_VALUE)HvGetCell(Hive, valueCell);
    if( value == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    InfName->Buffer = (PWSTR)CmpValueToData(Hive, value, &realSize);
    if( InfName->Buffer == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //

        return FALSE;
    }
    InfName->MaximumLength=(USHORT)realSize;
    InfName->Length = 0;
    while ( (InfName->Length < InfName->MaximumLength) &&
            (InfName->Buffer[InfName->Length/sizeof(WCHAR)] != UNICODE_NULL)) {

        InfName->Length += sizeof(WCHAR);
    }

    return (TRUE);
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmconfig.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

    cmconfig.c

Abstract:

    This module is responsible to build the hardware tree of the
    registry data base.

Author:

    Shie-Lin Tzong (shielint) 23-Jan-1992


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"

//
// Title Index - Never used for Product 1, set to 0 for now.
//

#define TITLE_INDEX_VALUE 0


extern ULONG CmpTypeCount[];


#define EISA_ADAPTER_INDEX EisaAdapter
#define TURBOCHANNEL_ADAPTER_INDEX TcAdapter

//
// The following variables are used to cross-reference multifunction
// adapters to their corresponding NT interface type.
//

extern struct {
    PUCHAR  AscString;
    USHORT  InterfaceType;
    USHORT  Count;
} CmpMultifunctionTypes[];

extern USHORT CmpUnknownBusCount;


//
// CmpConfigurationData - A pointer to the area reserved for the purpose
//     of reconstructing Configuration Data.
//
// CmpConfigurationAreaSize - Record the size of the Configuration Data
//     area.

extern ULONG CmpConfigurationAreaSize;
extern PCM_FULL_RESOURCE_DESCRIPTOR CmpConfigurationData;

//
// Function prototypes for internal erferences
//

NTSTATUS
CmpSetupConfigurationTree(
     IN PCONFIGURATION_COMPONENT_DATA CurrentEntry,
     IN HANDLE ParentHandle,
     IN INTERFACE_TYPE InterfaceType,
     IN ULONG BusNumber
     );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmpInitializeHardwareConfiguration)
#pragma alloc_text(INIT,CmpSetupConfigurationTree)
#pragma alloc_text(INIT,CmpInitializeRegistryNode)
#endif


NTSTATUS
CmpInitializeHardwareConfiguration(
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )
/*++

Routine Description:

    This routine creates \\Registry\Machine\Hardware node in
    the registry and calls SetupTree routine to put the hardware
    information to the registry.

Arguments:

    LoaderBlock - supplies a pointer to the LoaderBlock passed in from the
                  OS Loader.

Returns:

    NTSTATUS code for sucess or reason of failure.

--*/
{
    NTSTATUS Status;
    OBJECT_ATTRIBUTES ObjectAttributes;
    HANDLE BaseHandle;
    PCONFIGURATION_COMPONENT_DATA ConfigurationRoot;
    ULONG Disposition;

    ConfigurationRoot = (PCONFIGURATION_COMPONENT_DATA)LoaderBlock->ConfigurationRoot;

    //
    // Create \\Registry\Machine\Hardware\DeviceMap
    //

    InitializeObjectAttributes(
        &ObjectAttributes,
        &CmRegistryMachineHardwareDeviceMapName,
        0,
        (HANDLE)NULL,
        NULL
        );
    ObjectAttributes.Attributes |= OBJ_CASE_INSENSITIVE;

    Status = NtCreateKey(                   // Paht may already exist
                &BaseHandle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes,
                TITLE_INDEX_VALUE,
                NULL,
                0,
                &Disposition
                );

    if (!NT_SUCCESS(Status)) {
        return(Status);
    }

    NtClose(BaseHandle);

    ASSERT(Disposition == REG_CREATED_NEW_KEY);

    //
    // Create \\Registry\Machine\Hardware\Description and use the
    // returned handle as the BaseHandle to build the hardware tree.
    //

    InitializeObjectAttributes(
        &ObjectAttributes,
        &CmRegistryMachineHardwareDescriptionName,
        0,
        (HANDLE)NULL,
        NULL
        );
    ObjectAttributes.Attributes |= OBJ_CASE_INSENSITIVE;

    Status = NtCreateKey(                   // Path may already exist
                &BaseHandle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes,
                TITLE_INDEX_VALUE,
                NULL,
                0,
                &Disposition
                );

    if (!NT_SUCCESS(Status)) {
        return(Status);
    }

    ASSERT(Disposition == REG_CREATED_NEW_KEY);

    //
    // Allocate 16K bytes memory from paged pool for constructing
    // configuration data for controller component.
    // NOTE:  The configuration Data for controller component
    //    usually takes less than 100 bytes.  But on EISA machine, the
    //    EISA configuration information takes more than 10K and up to
    //    64K.  I believe 16K is the reasonable number to handler 99.9%
    //    of the machines.  Therefore, 16K is the initial value.
    //

    CmpConfigurationData = (PCM_FULL_RESOURCE_DESCRIPTOR)ExAllocatePool(
                                        PagedPool,
                                        CmpConfigurationAreaSize
                                        );

    if (CmpConfigurationData == NULL) {
        return(STATUS_INSUFFICIENT_RESOURCES);
    }

    //
    // Call SetupConfigurationTree routine to go over each component
    // of the tree and add component information to registry database.
    //

    if (ConfigurationRoot) {
        Status = CmpSetupConfigurationTree(ConfigurationRoot,
                                           BaseHandle,
                                           -1,
                                           (ULONG)-1);
    } else {
        Status = STATUS_SUCCESS;
    }

    ExFreePool((PVOID)CmpConfigurationData);
    NtClose(BaseHandle);
    return(Status);
}

NTSTATUS
CmpSetupConfigurationTree(
     IN PCONFIGURATION_COMPONENT_DATA CurrentEntry,
     IN HANDLE ParentHandle,
     IN INTERFACE_TYPE InterfaceType,
     IN ULONG BusNumber
     )
/*++

Routine Description:

    This routine traverses loader configuration tree and register
    the hardware information to the registry data base.

    Note to reduce the stack usage on machines with large number of PCI buses,
    we do not recursively process the sibling nodes.  We only recursively
    process the child trees.

Arguments:

    CurrentEntry - Supplies a pointer to a loader configuration
        tree or subtree.

    ParentHandle - Supplies the parent handle of CurrentEntry node.

    InterfaceType - Specify the Interface type of the bus that the
        CurrentEntry component resides.

    BusNumber - Specify the Bus Number of the bus that the CurrentEntry
        component resides.  If Bus number is -1, it means InterfaceType
        and BusNumber are meaningless for this component.

Returns:

    None.

--*/
{
    NTSTATUS Status;
    HANDLE NewHandle;
    USHORT i;
    CONFIGURATION_COMPONENT *Component;
    INTERFACE_TYPE LocalInterfaceType = InterfaceType;
    ULONG LocalBusNumber = BusNumber;
    USHORT DeviceIndexTable[NUMBER_TYPES];

    for (i = 0; i < NUMBER_TYPES; i++) {
        DeviceIndexTable[i] = 0;
    }

    //
    // Process current entry and its siblings
    //

    while (CurrentEntry) {

        //
        // Register current entry first before going down to its children
        //

        Component = &CurrentEntry->ComponentEntry;

        //
        // If the current component is a bus component, we will set up
        // its bus number and Interface type and use them to initialize
        // its subtree.
        //

        if (Component->Class == AdapterClass &&
            CurrentEntry->Parent->ComponentEntry.Class == SystemClass) {

            switch (Component->Type) {

            case EisaAdapter:
                LocalInterfaceType = Eisa;
                LocalBusNumber = CmpTypeCount[EISA_ADAPTER_INDEX]++;
                break;
            case TcAdapter:
                LocalInterfaceType = TurboChannel;
                LocalBusNumber = CmpTypeCount[TURBOCHANNEL_ADAPTER_INDEX]++;
                break;
            case MultiFunctionAdapter:

                //
                // Here we try to distinguish if the Multifunction adapter is
                // Isa, Mca, Internal bus and assign BusNumber based on
                // its interface type (bus type.)
                //

                if (Component->Identifier) {
                    for (i=0; CmpMultifunctionTypes[i].AscString; i++) {
                        if (_stricmp((PCHAR)CmpMultifunctionTypes[i].AscString,
                                    Component->Identifier) == 0) {
                                        break;
                        }
                    }

                    LocalInterfaceType = CmpMultifunctionTypes[i].InterfaceType;
                    LocalBusNumber = CmpMultifunctionTypes[i].Count++;
                }
                break;

            case ScsiAdapter:

                //
                // Set the bus type to internal.
                //

                LocalInterfaceType = Internal;
                LocalBusNumber = CmpTypeCount[ScsiAdapter]++;
                break;

            default:
                LocalInterfaceType = -1;
                LocalBusNumber = CmpUnknownBusCount++;
                break;
            }
        }

        //
        // Initialize and copy current component to hardware registry
        //

        Status = CmpInitializeRegistryNode(
                     CurrentEntry,
                     ParentHandle,
                     &NewHandle,
                     LocalInterfaceType,
                     LocalBusNumber,
                     DeviceIndexTable
                     );

        if (!NT_SUCCESS(Status)) {
            return(Status);
        }

        //
        // Once we are going one level down, we need to clear the TypeCount
        // table for everything under the current component class ...
        //

        if (CurrentEntry->Child) {

            //
            // Process the child entry of current entry
            //

            Status = CmpSetupConfigurationTree(CurrentEntry->Child,
                                               NewHandle,
                                               LocalInterfaceType,
                                               LocalBusNumber
                                               );
            if (!NT_SUCCESS(Status)) {
                NtClose(NewHandle);
                return(Status);
            }
        }
        NtClose(NewHandle);
        CurrentEntry = CurrentEntry->Sibling;
    }
    return(STATUS_SUCCESS);
}


NTSTATUS
CmpInitializeRegistryNode(
    IN PCONFIGURATION_COMPONENT_DATA CurrentEntry,
    IN HANDLE ParentHandle,
    OUT PHANDLE NewHandle,
    IN INTERFACE_TYPE InterfaceType,
    IN ULONG BusNumber,
    IN PUSHORT DeviceIndexTable
    )

/*++

Routine Description:

    This routine creates a node for the current firmware component
    and puts component data to the data part of the node.

Arguments:

    CurrentEntry - Supplies a pointer to a configuration component.

    Handle - Supplies the parent handle of CurrentEntry node.

    NewHandle - Suppiles a pointer to a HANDLE to receive the handle of
        the newly created node.

    InterfaceType - Specify the Interface type of the bus that the
        CurrentEntry component resides. (See BusNumber also)

    BusNumber - Specify the Bus Number of the bus that the CurrentEntry
        component resides on.  If Bus number is -1, it means InterfaceType
        and BusNumber are meaningless for this component.

Returns:

    None.

--*/
{

    NTSTATUS Status;
    OBJECT_ATTRIBUTES ObjectAttributes;
    UNICODE_STRING KeyName;
    UNICODE_STRING ValueName;
    UNICODE_STRING ValueData;
    HANDLE Handle;
    HANDLE OldHandle;
    ANSI_STRING AnsiString;
    CHAR Buffer[12];
    WCHAR UnicodeBuffer[12];
    CONFIGURATION_COMPONENT *Component;
    ULONG Disposition;
    ULONG ConfigurationDataLength = 0;
    PCM_FULL_RESOURCE_DESCRIPTOR NewArea;

    Component = &CurrentEntry->ComponentEntry;

    //
    // If the component class is SystemClass, we set its Type to be
    // ArcSystem.  The reason is because the detection code sets
    // its type to MaximumType to indicate it is NOT ARC compatible.
    // Here, we are only interested in building a System Node.  So we
    // change its Type to ArcSystem to ease the setup.
    //

    if (Component->Class == SystemClass) {
        Component->Type = ArcSystem;
    }

    //
    // Create a new key to describe the Component.
    //
    // The type of the component will be used as the keyname of the
    // registry node.  The class is the class of the component.
    //

    InitializeObjectAttributes(
        &ObjectAttributes,
        &(CmTypeName[Component->Type]),
        0,
        ParentHandle,
        NULL
        );
    ObjectAttributes.Attributes |= OBJ_CASE_INSENSITIVE;

    Status = NtCreateKey(                   // Paht may already exist
                &Handle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes,
                0,
                NULL,
                0,
                &Disposition
                );

    if (!NT_SUCCESS(Status)) {
        return(Status);
    }

    //
    // If this component is NOT a SystemClass component, we will
    // create a subkey to identify the component's ordering.
    //

    if (Component->Class != SystemClass) {

        RtlIntegerToChar(
            DeviceIndexTable[Component->Type]++,
            10,
            12,
            Buffer
            );

        RtlInitAnsiString(
            &AnsiString,
            Buffer
            );

        KeyName.Buffer = (PWSTR)UnicodeBuffer;
        KeyName.Length = 0;
        KeyName.MaximumLength = sizeof(UnicodeBuffer);

        RtlAnsiStringToUnicodeString(
            &KeyName,
            &AnsiString,
            FALSE
            );

        OldHandle = Handle;

        InitializeObjectAttributes(
            &ObjectAttributes,
            &KeyName,
            0,
            OldHandle,
            NULL
            );
        ObjectAttributes.Attributes |= OBJ_CASE_INSENSITIVE;

        Status = NtCreateKey(
                    &Handle,
                    KEY_READ | KEY_WRITE,
                    &ObjectAttributes,
                    0,
                    NULL,
                    0,
                    &Disposition
                    );

        NtClose(OldHandle);

        if (!NT_SUCCESS(Status)) {
            return(Status);
        }

        ASSERT(Disposition == REG_CREATED_NEW_KEY);
    }

    //
    // Create a value which describes the following component information:
    //     Flags, Cersion, Key, AffinityMask.
    //

    RtlInitUnicodeString(
        &ValueName,
        L"Component Information"
        );

    Status = NtSetValueKey(
                Handle,
                &ValueName,
                TITLE_INDEX_VALUE,
                REG_BINARY,
                &Component->Flags,
                FIELD_OFFSET(CONFIGURATION_COMPONENT, ConfigurationDataLength) -
                    FIELD_OFFSET(CONFIGURATION_COMPONENT, Flags)
                );

    if (!NT_SUCCESS(Status)) {
        NtClose(Handle);
        return(Status);
    }

    //
    // Create a value which describes the component identifier, if any.
    //

    if (Component->IdentifierLength) {

        RtlInitUnicodeString(
            &ValueName,
            L"Identifier"
            );

        RtlInitAnsiString(
            &AnsiString,
            Component->Identifier
            );

        Status = RtlAnsiStringToUnicodeString(
                    &ValueData,
                    &AnsiString,
                    TRUE
                    );

        if( NT_SUCCESS(Status) ) {
            Status = NtSetValueKey(
                        Handle,
                        &ValueName,
                        TITLE_INDEX_VALUE,
                        REG_SZ,
                        ValueData.Buffer,
                        ValueData.Length + sizeof( UNICODE_NULL )
                        );

            RtlFreeUnicodeString(&ValueData);
        }

        if (!NT_SUCCESS(Status)) {
            NtClose(Handle);
            return(Status);
        }
    }

    //
    // Create a value entry for component configuration data.
    //

    RtlInitUnicodeString(
        &ValueName,
        L"Configuration Data"
        );

    //
    // Create the configuration data based on CM_FULL_RESOURCE_DESCRIPTOR.
    //
    // Note the configuration data in firmware tree may be in the form of
    // CM_PARTIAL_RESOURCE_LIST or nothing.  In both cases, we need to
    // set up the registry configuration data to be in the form of
    // CM_FULL_RESOURCE_DESCRIPTOR.
    //

    if (CurrentEntry->ConfigurationData) {

        //
        // This component has configuration data, we copy the data
        // to our work area, add some more data items and copy the new
        // configuration data to the registry.
        //

        ConfigurationDataLength = Component->ConfigurationDataLength +
                      FIELD_OFFSET(CM_FULL_RESOURCE_DESCRIPTOR,
                      PartialResourceList);

        //
        // Make sure our reserved area is big enough to hold the data.
        //

        if (ConfigurationDataLength > CmpConfigurationAreaSize) {

            //
            // If reserved area is not big enough, we resize our reserved
            // area.  If, unfortunately, the reallocation fails, we simply
            // loss the configuration data of this particular component.
            //

            NewArea = (PCM_FULL_RESOURCE_DESCRIPTOR)ExAllocatePool(
                                            PagedPool,
                                            ConfigurationDataLength
                                            );

            if (NewArea) {
                CmpConfigurationAreaSize = ConfigurationDataLength;
                ExFreePool(CmpConfigurationData);
                CmpConfigurationData = NewArea;
                RtlCopyMemory(
                    (PUCHAR)&CmpConfigurationData->PartialResourceList.Version,
                    CurrentEntry->ConfigurationData,
                    Component->ConfigurationDataLength
                    );
            } else {
                Component->ConfigurationDataLength = 0;
                CurrentEntry->ConfigurationData = NULL;
            }
        } else {
            RtlCopyMemory(
                (PUCHAR)&CmpConfigurationData->PartialResourceList.Version,
                CurrentEntry->ConfigurationData,
                Component->ConfigurationDataLength
                );
        }

    }

    if (CurrentEntry->ConfigurationData == NULL) {

        //
        // This component has NO configuration data (or we can't resize
        // our reserved area to hold the data), we simple add whatever
        // is required to set up a CM_FULL_RESOURCE_LIST.
        //

        CmpConfigurationData->PartialResourceList.Version = 0;
        CmpConfigurationData->PartialResourceList.Revision = 0;
        CmpConfigurationData->PartialResourceList.Count = 0;
        ConfigurationDataLength = FIELD_OFFSET(CM_FULL_RESOURCE_DESCRIPTOR,
                                               PartialResourceList) +
                                  FIELD_OFFSET(CM_PARTIAL_RESOURCE_LIST,
                                               PartialDescriptors);
    }

    //
    // Set up InterfaceType and BusNumber for the component.
    //

    CmpConfigurationData->InterfaceType = InterfaceType;
    CmpConfigurationData->BusNumber = BusNumber;

    //
    // Write the newly constructed configuration data to the hardware registry
    //

    Status = NtSetValueKey(
                Handle,
                &ValueName,
                TITLE_INDEX_VALUE,
                REG_FULL_RESOURCE_DESCRIPTOR,
                CmpConfigurationData,
                ConfigurationDataLength
                );

    if (!NT_SUCCESS(Status)) {
        NtClose(Handle);
        return(Status);
    }

    *NewHandle = Handle;
    return(STATUS_SUCCESS);

}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmcontrl.c ===
/*++

Copyright (c) 1992  Microsoft Corporation

Module Name:

    cmcontrl.c

Abstract:

    The module contains CmGetSystemControlValues, see cmdat.c for data.

Author:

    Bryan M. Willman (bryanwi) 12-May-92

Revision History:

--*/

#include    "cmp.h"

extern WCHAR   CmDefaultLanguageId[];
extern ULONG   CmDefaultLanguageIdLength;
extern ULONG   CmDefaultLanguageIdType;

extern WCHAR   CmInstallUILanguageId[];
extern ULONG   CmInstallUILanguageIdLength;
extern ULONG   CmInstallUILanguageIdType;

HCELL_INDEX
CmpWalkPath(
    PHHIVE      SystemHive,
    HCELL_INDEX ParentCell,
    PWSTR       Path
    );

LANGID
CmpConvertLangId(
    PWSTR LangIdString,
    ULONG LangIdStringLength
);

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmGetSystemControlValues)
#pragma alloc_text(INIT,CmpWalkPath)
#pragma alloc_text(INIT,CmpConvertLangId)
#endif

VOID
CmGetSystemControlValues(
    PVOID                   SystemHiveBuffer,
    PCM_SYSTEM_CONTROL_VECTOR  ControlVector
    )
/*++

Routine Description:

    Look for registry values in current control set, as specified
    by entries in ControlVector.  Report data for value entries
    (if any) to variables ControlVector points to.

Arguments:

    SystemHiveBuffer - pointer to flat image of the system hive

    ControlVector - pointer to structure that describes what values
                    to pull out and store

Return Value:

    NONE.

--*/
{
    NTSTATUS        status;
    PHHIVE          SystemHive;
    CMHIVE          TempHive;
    HCELL_INDEX     RootCell;
    HCELL_INDEX     BaseCell;
    UNICODE_STRING  Name;
    HCELL_INDEX     KeyCell;
    HCELL_INDEX     ValueCell;
    PCM_KEY_VALUE   ValueBody;
    ULONG           Length;
    BOOLEAN         AutoSelect;
    BOOLEAN         small;
    ULONG           tmplength;
    PCM_KEY_NODE    Node;

    //
    // set up to read flat system hive image loader passes us
    //
    RtlZeroMemory((PVOID)&TempHive, sizeof(TempHive));
    SystemHive = &(TempHive.Hive);
    CmpInitHiveViewList((PCMHIVE)SystemHive);
    CmpInitSecurityCache((PCMHIVE)SystemHive);
    status = HvInitializeHive(
                SystemHive,
                HINIT_FLAT,
                HIVE_VOLATILE,
                HFILE_TYPE_PRIMARY,
                SystemHiveBuffer,
                NULL,
                NULL,
                NULL,
                NULL,
                NULL,
                NULL,
                1,
                NULL
                );
    if (!NT_SUCCESS(status)) {
         CM_BUGCHECK(BAD_SYSTEM_CONFIG_INFO,BAD_SYSTEM_CONTROL_VALUES,1,SystemHive,status);
    }

    //
    // don't bother locking/releasing cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );
    //
    // get hive.cell of root of current control set
    //
    RootCell = ((PHBASE_BLOCK)SystemHiveBuffer)->RootCell;
    RtlInitUnicodeString(&Name, L"current");
    BaseCell = CmpFindControlSet(
                    SystemHive,
                    RootCell,
                    &Name,
                    &AutoSelect
                    );
    if (BaseCell == HCELL_NIL) {
        CM_BUGCHECK(BAD_SYSTEM_CONFIG_INFO,BAD_SYSTEM_CONTROL_VALUES,2,SystemHive,&Name);
    }

    Node = (PCM_KEY_NODE)HvGetCell(SystemHive,BaseCell);
    if( Node == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return;
    }
    RtlInitUnicodeString(&Name, L"control");
    BaseCell = CmpFindSubKeyByName(SystemHive,
                                   Node,
                                   &Name);
    if (BaseCell == HCELL_NIL) {
        CM_BUGCHECK(BAD_SYSTEM_CONFIG_INFO,BAD_SYSTEM_CONTROL_VALUES,3,Node,&Name);
    }

    //
    // SystemHive.BaseCell = \registry\machine\system\currentcontrolset\control
    //

    //
    // step through vector, trying to fetch each value
    //
    while (ControlVector->KeyPath != NULL) {

        //
        //  Assume we will fail to find the key or value.
        //
        
        Length = (ULONG)-1;

        KeyCell = CmpWalkPath(SystemHive, BaseCell, ControlVector->KeyPath);

        if (KeyCell != HCELL_NIL) {

            //
            // found the key, look for the value entry
            //
            Node = (PCM_KEY_NODE)HvGetCell(SystemHive,KeyCell);
            if( Node == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                return;
            }
            RtlInitUnicodeString(&Name, ControlVector->ValueName);
            ValueCell = CmpFindValueByName(SystemHive,
                                           Node,
                                           &Name);
            if (ValueCell != HCELL_NIL) {

                //
                // SystemHive.ValueCell is value entry body
                //

                if (ControlVector->BufferLength == NULL) {
                    tmplength = sizeof(ULONG);
                } else {
                    tmplength = *(ControlVector->BufferLength);
                }

                ValueBody = (PCM_KEY_VALUE)HvGetCell(SystemHive, ValueCell);
                if( ValueBody == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    return;
                }

                small = CmpIsHKeyValueSmall(Length, ValueBody->DataLength);

                if (tmplength < Length) {
                    Length = tmplength;
                }

                if (Length > 0) {

                    PCELL_DATA  Buffer;
                    BOOLEAN     BufferAllocated;
                    ULONG       realsize;
                    HCELL_INDEX CellToRelease;

                    ASSERT((small ? (Length <= CM_KEY_VALUE_SMALL) : TRUE));
                    //
                    // get the data from source, regardless of the size
                    //
                    if( CmpGetValueData(SystemHive,ValueBody,&realsize,&Buffer,&BufferAllocated,&CellToRelease) == FALSE ) {
                        //
                        // insufficient resources; return NULL
                        //
                        ASSERT( BufferAllocated == FALSE );
                        ASSERT( Buffer == NULL );
                        return;
                    }

                    RtlCopyMemory(
                        ControlVector->Buffer,
                        Buffer,
                        Length
                        );

                    //
                    // cleanup the temporary buffer
                    //
                    if( BufferAllocated == TRUE ) {
                        ExFreePool( Buffer );
                    }
                    if( CellToRelease != HCELL_NIL ) {
                        HvReleaseCell(SystemHive,CellToRelease);
                    }
                }

                if (ControlVector->Type != NULL) {
                    *(ControlVector->Type) = ValueBody->Type;
                }
            }
        }

        //
        // Stash the length of result (-1 if nothing was found)
        //
        
        if (ControlVector->BufferLength != NULL) {
            *(ControlVector->BufferLength) = Length;
        }

        ControlVector++;
    }

    //
    // Get the default locale ID for the system from the registry.
    //

    if (CmDefaultLanguageIdType == REG_SZ) {
        PsDefaultSystemLocaleId = (LCID) CmpConvertLangId( 
                                                CmDefaultLanguageId,
                                                CmDefaultLanguageIdLength);
    } else {
        PsDefaultSystemLocaleId = 0x00000409;
    }

    //
    // Get the install (native UI) language ID for the system from the registry.
    //

    if (CmInstallUILanguageIdType == REG_SZ) {
        PsInstallUILanguageId =  CmpConvertLangId( 
                                                CmInstallUILanguageId,
                                                CmInstallUILanguageIdLength);
    } else {
        PsInstallUILanguageId = LANGIDFROMLCID(PsDefaultSystemLocaleId);
    }

    //
    // Set the default thread locale to the default system locale
    // for now.  This will get changed as soon as somebody logs in.
    // Use the install (native) language id as our default UI language id. 
    // This also will get changed as soon as somebody logs in.
    //

    PsDefaultThreadLocaleId = PsDefaultSystemLocaleId;
    PsDefaultUILanguageId = PsInstallUILanguageId;
}


HCELL_INDEX
CmpWalkPath(
    PHHIVE      SystemHive,
    HCELL_INDEX ParentCell,
    PWSTR       Path
    )
/*++

Routine Description:

    Walk the path.

Arguments:

    SystemHive - hive

    ParentCell - where to start

    Path - string to walk

Return Value:

    HCELL_INDEX of found key cell, or HCELL_NIL for error

--*/
{
    UNICODE_STRING  PathString;
    UNICODE_STRING  NextName;
    BOOLEAN         Last;
    HCELL_INDEX     KeyCell;
    PCM_KEY_NODE    Node;

    //
    // don't bother counting/releasing used cells
    //
    ASSERT( SystemHive->ReleaseCellRoutine == NULL );

    KeyCell = ParentCell;
    RtlInitUnicodeString(&PathString, Path);

    while (TRUE) {

        CmpGetNextName(&PathString, &NextName, &Last);

        if (NextName.Length == 0) {
            return KeyCell;
        }

        Node = (PCM_KEY_NODE)HvGetCell(SystemHive,KeyCell);
        if( Node == NULL ) {
            //
            // we couldn't map a view for the bin containing this cell
            //
            return HCELL_NIL;
        }
        KeyCell = CmpFindSubKeyByName(SystemHive,
                                      Node,
                                      &NextName);

        if (KeyCell == HCELL_NIL) {
            return HCELL_NIL;
        }
    }
}

LANGID
CmpConvertLangId(
    PWSTR LangIdString,
    ULONG LangIdStringLength
)
{


    USHORT i, Digit;
    WCHAR c;
    LANGID LangId;

    LangId = 0;
    LangIdStringLength = LangIdStringLength / sizeof( WCHAR );
    for (i=0; i < LangIdStringLength; i++) {
        c = LangIdString[ i ];

        if (c >= L'0' && c <= L'9') {
            Digit = c - L'0';

        } else if (c >= L'A' && c <= L'F') {
            Digit = c - L'A' + 10;

        } else if (c >= L'a' && c <= L'f') {
            Digit = c - L'a' + 10;

        } else {
            break;
        }

        if (Digit >= 16) {
            break;
        }

        LangId = (LangId << 4) | Digit;
    }

    return LangId;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmdat.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

    cmdat.c

Abstract:

    This module contains registry "static" data, except for data
    also used by setup, which is in cmdat2.c.

Author:

    Bryan Willman (bryanwi) 19-Oct-93


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"

//
// ***** INIT *****
//

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("INIT")
#pragma const_seg("INITCONST")
#endif

//
// ---------------------------
//


UNICODE_STRING  CmpLoadOptions = { 0 };        // sys options from FW or boot.ini


//
// CmpClassString - contains strings which are used as the class
//     strings in the keynode.
// The associated enumerated type is CONFIGURATION_CLASS in arc.h
//

UNICODE_STRING CmClassName[MaximumClass + 1] = { 0 };

const PWCHAR CmClassString[MaximumClass + 1] = {
    L"System",
    L"Processor",
    L"Cache",
    L"Adapter",
    L"Controller",
    L"Peripheral",
    L"MemoryClass",
    L"Undefined"
    };


struct {
    PCHAR  AscString;
    USHORT  InterfaceType;
    USHORT  Count;
} CmpMultifunctionTypes[] = {
    "ISA",      Isa,            0,
    "MCA",      MicroChannel,   0,
    "PCI",      PCIBus,         0,
    "VME",      VMEBus,         0,
    "PCMCIA",   PCMCIABus,      0,
    "CBUS",     CBus,           0,
    "MPIPI",    MPIBus,         0,
    "MPSA",     MPSABus,        0,
    NULL,       Internal,       0
};


USHORT CmpUnknownBusCount = 0;

ULONG CmpConfigurationAreaSize = 0x4000;        // Initialize size = 16K
PCM_FULL_RESOURCE_DESCRIPTOR CmpConfigurationData = { 0 };

//
// The following strings will be used as the keynames for registry
// nodes.
// The associated enumerated type is CONFIGURATION_TYPE in arc.h
//

UNICODE_STRING CmTypeName[MaximumType + 1] = { 0 };


//
// ***** PAGE *****
//

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("PAGEDATA")
#pragma const_seg("PAGECONST")
#endif

const PWCHAR CmTypeString[MaximumType + 1] = {
    L"System",
    L"CentralProcessor",
    L"FloatingPointProcessor",
    L"PrimaryICache",
    L"PrimaryDCache",
    L"SecondaryICache",
    L"SecondaryDCache",
    L"SecondaryCache",
    L"EisaAdapter",
    L"TcAdapter",
    L"ScsiAdapter",
    L"DtiAdapter",
    L"MultifunctionAdapter",
    L"DiskController",
    L"TapeController",
    L"CdRomController",
    L"WormController",
    L"SerialController",
    L"NetworkController",
    L"DisplayController",
    L"ParallelController",
    L"PointerController",
    L"KeyboardController",
    L"AudioController",
    L"OtherController",
    L"DiskPeripheral",
    L"FloppyDiskPeripheral",
    L"TapePeripheral",
    L"ModemPeripheral",
    L"MonitorPeripheral",
    L"PrinterPeripheral",
    L"PointerPeripheral",
    L"KeyboardPeripheral",
    L"TerminalPeripheral",
    L"OtherPeripheral",
    L"LinePeripheral",
    L"NetworkPeripheral",
    L"SystemMemory",
    L"DockingInformation",
    L"RealModeIrqRoutingTable",    
    L"RealModePCIEnumeration",    
    L"Undefined"
    };

//
// CmpTypeCount[] - For each 'type', a count is used to keep track how many
//     keys have been created.
//

ULONG CmpTypeCount[NUMBER_TYPES] = {
            0,                  // ArcSystem
            0,                  // CentralProcessor",
            0,                  // FloatingPointProcessor",
            0,                  // PrimaryICache",
            0,                  // PrimaryDCache",
            0,                  // SecondaryICache",
            0,                  // SecondaryDCache",
            0,                  // SecondaryCache",
            0,                  // EisaAdapter", (8)
            0,                  // TcAdapter",   (9)
            0,                  // ScsiAdapter",
            0,                  // DtiAdapter",
            0,                  // MultifunctionAdapter", (12)
            0,                  // DiskController", (13)
            0,                  // TapeController",
            0,                  // CdRomController",
            0,                  // WormController",
            0,                  // SerialController",
            0,                  // NetworkController",
            0,                  // DisplayController",
            0,                  // ParallelController",
            0,                  // PointerController",
            0,                  // KeyboardController",
            0,                  // AudioController",
            0,                  // OtherController",
            0,                  // DiskPeripheral",
            0,                  // FloppyDiskPeripheral",
            0,                  // TapePeripheral",
            0,                  // ModemPeripheral",
            0,                  // MonitorPeripheral",
            0,                  // PrinterPeripheral",
            0,                  // PointerPeripheral",
            0,                  // KeyboardPeripheral",
            0,                  // TerminalPeripheral",
            0,                  // OtherPeripheral",
            0,                  // LinePeripheral",
            0,                  // NetworkPeripheral",
            0,                  // SystemMemory",
            0,                  // DockingInformation,
            0,					// RealModeIrqRoutingTable
            0                   // Undefined"
            };

const UNICODE_STRING nullclass = { 0, 0, NULL };

//
// All names used by the registry
//


UNICODE_STRING CmRegistryRootName = { 0 };
UNICODE_STRING CmRegistryMachineName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareDescriptionName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareDescriptionSystemName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareDeviceMapName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareResourceMapName = { 0 };
UNICODE_STRING CmRegistryMachineHardwareOwnerMapName = { 0 };
UNICODE_STRING CmRegistryMachineSystemName = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSet = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetEnumName = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetEnumRootName = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetServices = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetHardwareProfilesCurrent = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlClass = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlSafeBoot = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagement = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlBootLog = { 0 };
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetServicesEventLog = { 0 };
UNICODE_STRING CmRegistryUserName = { 0 };
UNICODE_STRING CmRegistrySystemCloneName = { 0 };
UNICODE_STRING CmpSystemFileName = { 0 };
UNICODE_STRING CmSymbolicLinkValueName = { 0 };

#ifdef _WANT_MACHINE_IDENTIFICATION
UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlBiosInfo = { 0 };
#endif

const PWCHAR CmpRegistryRootString = L"\\REGISTRY";
const PWCHAR CmpRegistryMachineString = L"\\REGISTRY\\MACHINE";
const PWCHAR CmpRegistryMachineHardwareString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE";
const PWCHAR CmpRegistryMachineHardwareDescriptionString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\DESCRIPTION";
const PWCHAR CmpRegistryMachineHardwareDescriptionSystemString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\DESCRIPTION\\SYSTEM";
const PWCHAR CmpRegistryMachineHardwareDeviceMapString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\DEVICEMAP";
const PWCHAR CmpRegistryMachineHardwareResourceMapString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\RESOURCEMAP";
const PWCHAR CmpRegistryMachineHardwareOwnerMapString =
                    L"\\REGISTRY\\MACHINE\\HARDWARE\\OWNERMAP";
const PWCHAR CmpRegistryMachineSystemString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetEnumString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\ENUM";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetEnumRootString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\ENUM\\ROOT";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetServicesString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\SERVICES";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetHardwareProfilesCurrentString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\HARDWARE PROFILES\\CURRENT";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlClassString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\CLASS";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlSafeBootString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\SAFEBOOT";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagementString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\SESSION MANAGER\\MEMORY MANAGEMENT";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlBootLogString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\BOOTLOG";
const PWCHAR CmpRegistryMachineSystemCurrentControlSetServicesEventLogString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\SERVICES\\EVENTLOG";
const PWCHAR CmpRegistryUserString = L"\\REGISTRY\\USER";
const PWCHAR CmpRegistrySystemCloneString = L"\\REGISTRY\\MACHINE\\CLONE";
const PWCHAR CmpRegistrySystemFileNameString = L"SYSTEM";
const PWCHAR CmpRegistryPerflibString = L"\\REGISTRY\\MACHINE\\SOFTWARE\\MICROSOFT\\WINDOWS NT\\CURRENTVERSION\\PERFLIB";

const PWCHAR CmpProcessorControl = L"ProcessorControl";
const PWCHAR CmpControlSessionManager = L"Control\\Session Manager";
const PWCHAR CmpSymbolicLinkValueName = L"SymbolicLinkValue";

#ifdef _WANT_MACHINE_IDENTIFICATION
const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlBiosInfoString =
                    L"\\REGISTRY\\MACHINE\\SYSTEM\\CURRENTCONTROLSET\\CONTROL\\BIOSINFO";
#endif

//
// N.B. The CLONE hive is left out of the machine Hive list if 
//      we will not be using it to clone the current control set, 
//      since that is that Hive's only purpose.
//

HIVE_LIST_ENTRY CmpMachineHiveList[] = {
    { L"HARDWARE", L"MACHINE\\", NULL, HIVE_VOLATILE    , 0                         ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"SECURITY", L"MACHINE\\", NULL, 0                , 0                         ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"SOFTWARE", L"MACHINE\\", NULL, 0                , 0                         ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"SYSTEM",   L"MACHINE\\", NULL, 0                , 0                         ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"DEFAULT",  L"USER\\.DEFAULT", NULL, 0           , CM_CMHIVE_FLAG_UNTRUSTED  ,   NULL,   FALSE,  FALSE,  FALSE},
    { L"SAM",      L"MACHINE\\", NULL, HIVE_NOLAZYFLUSH , 0                         ,   NULL,   FALSE,  FALSE,  FALSE},

#if CLONE_CONTROL_SET
    { L"CLONE",    L"MACHINE\\", NULL, HIVE_VOLATILE    , 0                         ,   NULL,   FALSE,  FALSE,  FALSE},
#endif

//  { L"TEST",     L"MACHINE\\", NULL, HIVE_NOLAZYFLUSH , 0                         ,   NULL,   FALSE,  FALSE,  FALSE},
    { NULL,        NULL,         0, 0                   , 0                         ,   NULL,   FALSE,  FALSE,  FALSE}
    };


UCHAR           SystemHiveFullPathBuffer[MAX_NAME];
UNICODE_STRING  SystemHiveFullPathName;

//
// Master Hive
//
//  The KEY_NODEs for \REGISTRY, \REGISTRY\MACHINE, and \REGISTRY\USER
//  are stored in a small memory only hive called the Master Hive.
//  All other hives have link nodes in this hive which point to them.
//
PCMHIVE CmpMasterHive = { 0 };
BOOLEAN CmpNoMasterCreates = FALSE;     // Set TRUE after we're done to
                                        // prevent random creates in the
                                        // master hive, which is not backed
                                        // by a file.


LIST_ENTRY  CmpHiveListHead = { 0 };            // List of CMHIVEs
FAST_MUTEX  CmpHiveListHeadLock;                // used to protect the list above

//
// Addresses of object type descriptors:
//

POBJECT_TYPE CmpKeyObjectType = { 0 };

//
// Write-Control:
//  CmpNoWrite is initially true.  When set this way write and flush
//  do nothing, simply returning success.  When cleared to FALSE, I/O
//  is enabled.  This change is made after the I/O system is started
//  AND autocheck (chkdsk) has done its thing.
//

BOOLEAN CmpNoWrite = TRUE;


//
// NtInitializeRegistry global status flags
//

// 
// If CmFirstTime is TRUE, then NtInitializeRegistry has not yet been
// called to perform basic registry initialization
//

BOOLEAN CmFirstTime = TRUE;       

//
// trick to allow paralel threads to access the registry
//
BOOLEAN CmpSpecialBootCondition = FALSE;


//
// If CmBootAcceptFirstTime is TRUE, then NtInitializeRegistry has not 
// yet been called to accept the current Boot and save the boot
// control set as the LKG control set.
//

BOOLEAN CmBootAcceptFirstTime = TRUE;   

//
// CmpWasSetupBoot indicates whether or not the boot
// is into text mode setup.  If so, we do not turn
// on global quotas.
//
BOOLEAN CmpWasSetupBoot;

//
// Indicates whether the hives need to be loaded in memory
// and in scratch mode
//
BOOLEAN CmpMiniNTBoot = FALSE;

//
// Indicates whether the system hives need to be opened in a
// shared mode. Generally needed if we are booting WinPE (MiniNT)
// on network
//
BOOLEAN CmpShareSystemHives = FALSE;

//
// Where are we booting from
//
ULONG	CmpBootType;
//
// Self healing hives control switch
//
BOOLEAN CmpSelfHeal = TRUE;


#ifdef ALLOC_DATA_PRAGMA
#pragma  const_seg()
#pragma  data_seg()
#endif

//
// ***** FIXED *****
//
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmdelay.c ===
/*++

Copyright (c) 1999  Microsoft Corporation

Module Name:

    cmdelay.c

Abstract:

    This module implements the new algorithm (LRU style) for the 
    Delayed Close KCB table.

    Functions in this module are thread safe protected by the kcb lock.
    When kcb lock is converted to a resource, we should assert (enforce)
    exclusivity of that resource here !!!

Note:
    
    We might want to convert these functions to macros after enough testing
    provides that they work well

Author:

    Dragos C. Sambotin (dragoss) 09-Aug-1999

Revision History:

--*/

#include    "cmp.h"

ULONG                   CmpDelayedCloseSize = 2048; // !!!! Cannot be bigger that 4094 !!!!!
CM_DELAYED_CLOSE_ENTRY  *CmpDelayedCloseTable;
LIST_ENTRY              CmpDelayedLRUListHead;  // head of the LRU list of Delayed Close Table entries


ULONG
CmpGetDelayedCloseIndex( );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpInitializeDelayedCloseTable)
#pragma alloc_text(PAGE,CmpRemoveFromDelayedClose)
#pragma alloc_text(PAGE,CmpGetDelayedCloseIndex)
#pragma alloc_text(PAGE,CmpAddToDelayedClose)
#endif

VOID
CmpInitializeDelayedCloseTable()
/*++

Routine Description:

    Initialize delayed close table; allocation + LRU list initialization.

Arguments:


Return Value:

    NONE.

--*/
{
    ULONG i;

    PAGED_CODE();

    //
    // allocate the table from paged pool; it is important that the table 
    // is contiguous in memory as we compute the index based on this assumption
    //
    CmpDelayedCloseTable = ExAllocatePoolWithTag(PagedPool,
                                                 CmpDelayedCloseSize * sizeof(CM_DELAYED_CLOSE_ENTRY),
                                                 CM_DELAYCLOSE_TAG);
    if (CmpDelayedCloseTable == NULL) {
        CM_BUGCHECK(CONFIG_INITIALIZATION_FAILED,INIT_DELAYED_CLOSE_TABLE,1,0,0);
        return;
    }
    
    // 
    // Init LRUlist head.
    //
    InitializeListHead(&CmpDelayedLRUListHead);

    for (i=0; i<CmpDelayedCloseSize; i++) {
        //
        // mark it as available and add it to the end of the LRU list
        //
        CmpDelayedCloseTable[i].KeyControlBlock = NULL; 
        InsertTailList(
            &CmpDelayedLRUListHead,
            &(CmpDelayedCloseTable[i].DelayedLRUList)
            );
    }

}


VOID
CmpRemoveFromDelayedClose(
    IN PCM_KEY_CONTROL_BLOCK kcb
    )
/*++

Routine Description:

    Removes a KCB from the delayed close table;

Arguments:

    kcb - the kcb in question

Note: 
    
    kcb lock/resource should be aquired exclusively when this function is called

Return Value:

    NONE.

--*/
{
    ULONG i;

    PAGED_CODE();

    i = kcb->DelayedCloseIndex;

    // If not on delayed close, don't try to remove
    if (i == CmpDelayedCloseSize) {
        return;
    }

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"[CmpRemoveFromDelayedClose] : Removing kcb = %p from DelayedCloseTable; index = %lu\n",kcb,(ULONG)i));
    //
    // at this index should be the this kcb and the index should not be bigger 
    // than the size of the table
    //
    ASSERT(CmpDelayedCloseTable[i].KeyControlBlock == kcb);
    ASSERT( i < CmpDelayedCloseSize );

    //
    // nobody should hold references on this particular kcb
    //
    ASSERT_KCB_LOCK_OWNED_EXCLUSIVE();

    //
    // mark the entry as available and add it to the end of the LRU list
    //
    CmpDelayedCloseTable[i].KeyControlBlock = NULL;
    CmpRemoveEntryList(&(CmpDelayedCloseTable[i].DelayedLRUList));
    InsertTailList(
        &CmpDelayedLRUListHead,
        &(CmpDelayedCloseTable[i].DelayedLRUList)
        );

    kcb->DelayedCloseIndex = CmpDelayedCloseSize;
}


ULONG
CmpGetDelayedCloseIndex( )
/*++

Routine Description:

    Finds a free entry in the delayed close table and returns it.
    If the table is full, the kcb in the last entry (LRU-wise) is
    kicked out of the table and its entry is reused.

Arguments:


Note: 
    
    kcb lock/resource should be aquired exclusively when this function is called

Return Value:

    NONE.

--*/
{
    ULONG                   DelayedIndex;
    PCM_DELAYED_CLOSE_ENTRY DelayedEntry;

    PAGED_CODE();

    //
    // get the last entry in the Delayed LRU list
    //
    DelayedEntry = (PCM_DELAYED_CLOSE_ENTRY)CmpDelayedLRUListHead.Blink;

Retry:
    DelayedEntry = CONTAINING_RECORD(   DelayedEntry,
                                        CM_DELAYED_CLOSE_ENTRY,
                                        DelayedLRUList);
    
    if( DelayedEntry->KeyControlBlock != NULL ) {
        //
        // entry is not available; kick the kcb out of cache
        //
        ASSERT_KCB(DelayedEntry->KeyControlBlock);
        //ASSERT( DelayedEntry->KeyControlBlock->RefCount == 0 );

        //
        // lock should be held here !!!
        //
        if(DelayedEntry->KeyControlBlock->RefCount == 0) {
            CmpCleanUpKcbCacheWithLock(DelayedEntry->KeyControlBlock);
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"[CmpGetDelayedCloseIndex] : no index free; kicking kcb = %p index = %lu out of DelayedCloseTable\n",
                DelayedEntry->KeyControlBlock,(ULONG)(((PUCHAR)DelayedEntry - (PUCHAR)CmpDelayedCloseTable) / sizeof( CM_DELAYED_CLOSE_ENTRY ))));

        } else {
            //
            // somebody else is partying on this kcb; go to the next entry (in reverse order).
            //
            if( DelayedEntry->DelayedLRUList.Blink == CmpDelayedLRUListHead.Flink ) {
                //
                // we cannot go up anymore; we need to yank this one.
                //
                DelayedEntry->KeyControlBlock->DelayedCloseIndex = CmpDelayedCloseSize;
            } else {
                //
                // go back one spot and retry
                //
                DelayedEntry = (PCM_DELAYED_CLOSE_ENTRY)(DelayedEntry->DelayedLRUList.Blink);
                goto Retry;
            }

        }
       
        DelayedEntry->KeyControlBlock = NULL;
    }

    DelayedIndex = (ULONG) (((PUCHAR)DelayedEntry - (PUCHAR)CmpDelayedCloseTable) / sizeof( CM_DELAYED_CLOSE_ENTRY ));

    //
    // sanity check
    //
    ASSERT( DelayedIndex < CmpDelayedCloseSize );

#if defined(_WIN64)
    //
    // somehow DelayedIndex is ok here but it gets corupted upon return from this api
    //
    if( DelayedIndex >= CmpDelayedCloseSize ) {
        DbgPrint("CmpGetDelayedCloseIndex: Bogus index %lx; DelayedEntry = %p; sizeof( CM_DELAYED_CLOSE_ENTRY ) = %lx\n",
            DelayedIndex,DelayedEntry,sizeof( CM_DELAYED_CLOSE_ENTRY ) );
        DbgBreakPoint();
    }
#endif
    return DelayedIndex;
}



VOID
CmpAddToDelayedClose(
    IN PCM_KEY_CONTROL_BLOCK kcb
    )
/*++

Routine Description:

    Adds a kcb to the delayed close table

Arguments:

    kcb - the kcb in question

Note: 
    
    kcb lock/resource should be aquired exclusively when this function is called

Return Value:

    NONE.

--*/
{
    ULONG                   DelayedIndex;
    PCM_DELAYED_CLOSE_ENTRY DelayedEntry;

    PAGED_CODE();

    ASSERT_KCB( kcb);
    ASSERT( kcb->RefCount == 0 );
    ASSERT_KCB_LOCK_OWNED_EXCLUSIVE();

    // Already on delayed close, don't try to put on again
    if (kcb->DelayedCloseIndex != CmpDelayedCloseSize) {
        return;
    }

    //
    // get the delayed entry and attach the kcb to it
    //
    DelayedIndex = CmpGetDelayedCloseIndex();
#if defined(_WIN64)
    //
    // somehow DelayedIndex is corupted here, but it was ok prior to return from CmpGetDeleyedCloseIndex
    //
    if( DelayedIndex >= CmpDelayedCloseSize ) {
        DbgPrint("CmpAddToDelayedClose: Bogus index %lx; sizeof( CM_DELAYED_CLOSE_ENTRY ) = %lx\n",
            DelayedIndex,sizeof( CM_DELAYED_CLOSE_ENTRY ) );
        DbgBreakPoint();
    }
#endif
    DelayedEntry = &(CmpDelayedCloseTable[DelayedIndex]);
    ASSERT( DelayedEntry->KeyControlBlock == NULL );
    DelayedEntry->KeyControlBlock = kcb;
    kcb->DelayedCloseIndex = DelayedIndex;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_FLOW,"[CmpAddToDelayedClose] : Adding kcb = %p to DelayedCloseTable; index = %lu\n",
        kcb,DelayedIndex));
    //
    // move the entry on top of the LRU list
    //
    CmpRemoveEntryList(&(DelayedEntry->DelayedLRUList));
    InsertHeadList(
        &CmpDelayedLRUListHead,
        &(DelayedEntry->DelayedLRUList)
        );

}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmdat3.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

    cmdat3.c

Abstract:

    This module contains registry "static" data which we don't
    want pulled into the loader.

Author:

    Bryan Willman (bryanwi) 19-Oct-93


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"
#pragma hdrstop
#include "dpfiltercm.h"

//
// ***** INIT *****
//

//
// Data for CmGetSystemControlValues
//
//
// ----- CmControlVector -----
//
#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("INIT")
#endif

//
//  Local examples
//
WCHAR   CmDefaultLanguageId[ 12 ] = { 0 };
ULONG   CmDefaultLanguageIdLength = sizeof( CmDefaultLanguageId );
ULONG   CmDefaultLanguageIdType = REG_NONE;

WCHAR   CmInstallUILanguageId[ 12 ] = { 0 };
ULONG   CmInstallUILanguageIdLength = sizeof( CmInstallUILanguageId );
ULONG   CmInstallUILanguageIdType = REG_NONE;
//
// suite data
//
WCHAR   CmSuiteBuffer[128] = {0};
ULONG   CmSuiteBufferLength = sizeof(CmSuiteBuffer);
ULONG   CmSuiteBufferType = REG_NONE;

//
// Verify driver list data
//
extern LONG    CmRegistryLogSizeLimit;
extern WCHAR   MmLargePageDriverBuffer[];
extern ULONG   MmLargePageDriverBufferLength;
extern ULONG   MmLargePageDriverBufferType;
extern WCHAR   MmVerifyDriverBuffer[];
extern ULONG   MmVerifyDriverBufferLength;
extern ULONG   MmVerifyDriverBufferType;
extern ULONG   MmVerifyDriverLevel;

extern ULONG IopAutoReboot;
extern ULONG ObpProtectionMode;
extern ULONG ObpAuditBaseDirectories;
extern ULONG ObpAuditBaseObjects;
extern ULONG ObpObjectSecurityMode;
extern ACCESS_MASK SepProcessAccessesToAudit;
extern ULONG CmNtGlobalFlag;
extern ULONG CmpLazyFlushIntervalInSeconds;
extern ULONG CmpLazyFlushHiveCount;
extern SIZE_T PoolTrackTableSize;
extern SIZE_T PoolBigPageTableSize;
extern SIZE_T MmAllocationFragment;
extern SIZE_T MmSizeOfPagedPoolInBytes;
extern SIZE_T MmSizeOfNonPagedPoolInBytes;
extern ULONG MmMaximumNonPagedPoolPercent;
extern ULONG MmLargeSystemCache;
#if defined (_X86_)
extern ULONG MmLargeStackSize;
#endif
extern ULONG MmAllocationPreference;
extern ULONG MmNumberOfSystemPtes;
extern ULONG MmLowMemoryThreshold;
extern ULONG MmHighMemoryThreshold;
extern ULONG MmConsumedPoolPercentage;
extern ULONG MmSecondaryColors;
extern ULONG MmDisablePagingExecutive;
extern ULONG MmModifiedPageLifeInSeconds;
extern LOGICAL MmSpecialPoolCatchOverruns;
#if 0
extern ULONG MmCompressionThresholdRatio;
#endif
extern ULONG MmSpecialPoolTag;
extern ULONG MmDynamicPfn;
extern ULONG MmMirroring;
extern SIZE_T MmSystemViewSize;
extern SIZE_T MmSessionViewSize;
extern SIZE_T MmSessionPoolSize;
extern SIZE_T MmSessionImageSize;
extern ULONG MmEnforceWriteProtection;
extern ULONG MmLargePageMinimum;
extern LOGICAL MmSnapUnloads;
extern LOGICAL MmTrackLockedPages;
extern LOGICAL MmMakeLowMemory;
extern LOGICAL MmProtectFreedNonPagedPool;
extern ULONG MmTrackPtes;
extern ULONG CmRegistrySizeLimit;
extern ULONG CmRegistrySizeLimitLength;
extern ULONG CmRegistrySizeLimitType;
extern ULONG PspDefaultPagedLimit;
extern ULONG PspDefaultNonPagedLimit;
extern ULONG PspDefaultPagefileLimit;
extern ULONG ExResourceTimeoutCount;
extern ULONG ExResourceCheckFlags;
extern ULONG MmCritsectTimeoutSeconds;
extern SIZE_T MmHeapSegmentReserve;
extern SIZE_T MmHeapSegmentCommit;
extern SIZE_T MmHeapDeCommitTotalFreeThreshold;
extern SIZE_T MmHeapDeCommitFreeBlockThreshold;
extern ULONG ExpAdditionalCriticalWorkerThreads;
extern ULONG ExpAdditionalDelayedWorkerThreads;
extern ULONG MmProductType;
extern ULONG CmBrand;
extern ULONG ExpHydraEnabled;
extern ULONG ExpMultiUserTS;
extern LOGICAL IoCountOperations;
extern ULONG IopLargeIrpStackLocations;
extern ULONG IovpVerifierLevel; 
extern ULONG IopFailZeroAccessCreate;
extern ULONG MmZeroPageFile;
extern ULONG ExpNtExpirationData[3];
extern ULONG ExpNtExpirationDataLength;
extern ULONG ExpMaxTimeSeperationBeforeCorrect;
extern ULONG PopSimulate;
extern ULONG PopIdleDefaultMinThrottle;
extern ULONG PopIdleThrottleCheckRate;
extern ULONG PopIdleThrottleCheckTimeout;
extern ULONG PopIdleFrom0Delay;
extern ULONG PopIdleFrom0IdlePercent;
extern ULONG PopIdle0TimeCheck;
extern ULONG PopIdleTimeCheck;
extern ULONG PopIdleTo0Percent;
extern ULONG PopIdleDefaultDemotePercent;
extern ULONG PopIdleDefaultDemoteTime;
extern ULONG PopIdleDefaultPromotePercent;
extern ULONG PopIdleDefaultPromoteTime;
extern ULONG PopPerfTimeDelta;
extern ULONG PopPerfCriticalTimeDelta;
extern ULONG PopPerfCriticalFrequencyDelta;
extern ULONG PopPerfIncreasePercentModifier;
extern ULONG PopPerfIncreaseAbsoluteModifier;
extern ULONG PopPerfDecreasePercentModifier;
extern ULONG PopPerfDecreaseAbsoluteModifier;
extern ULONG PopPerfIncreaseTimeValue;
extern ULONG PopPerfIncreaseMinimumTime;
extern ULONG PopPerfDecreaseTimeValue;
extern ULONG PopPerfDecreaseMinimumTime;
extern ULONG PopPerfDegradeThrottleMinCapacity;
extern ULONG PopPerfDegradeThrottleMinFrequency;
extern ULONG PopPerfMaxC3Frequency;
extern ULONG KiEnableTimerWatchdog;
extern ULONG ObpTraceNoDeregister;
extern WCHAR ObpTracePoolTagsBuffer[];
extern ULONG ObpTracePoolTagsLength;
extern ULONG ObpCaseInsensitive;
extern WCHAR ObpUnsecureGlobalNamesBuffer[];
extern ULONG ObpUnsecureGlobalNamesLength;
extern ULONG ViSearchedNodesLimitFromRegistry;
extern ULONG ViRecursionDepthLimitFromRegistry;
extern ULONG MmMinimumStackCommitInBytes;
extern ULONG ObpLUIDDeviceMapsDisabled;

#if defined(_IA64_)
extern ULONG KiEnableAlignmentFaultExceptions;
#endif

extern ULONG KiMaximumDpcQueueDepth;
extern ULONG KiMinimumDpcRate;
extern ULONG KiAdjustDpcThreshold;
extern ULONG KiIdealDpcRate;
extern LARGE_INTEGER ExpLastShutDown;
ULONG shutdownlength = 0;

#if defined (_X86_)
extern ULONG KiFastSystemCallDisable;
extern ULONG KiXMMIZeroingEnable;
extern ULONG KiTimeLimitDpcMicroseconds;
extern ULONG KiTimeLimitIsrMicroseconds;
#endif

#if defined(_IA64_)
extern ULONG KiExceptionDeferralMode;
extern ULONG KiBackingStoreSecurityMode;
#endif

//Debugger Retries
extern KD_CONTEXT KdpContext;

//
// WMI Control Variables
extern ULONG WmipMaxKmWnodeEventSize;
#if defined (_IA64_)
extern ULONG WmipDisableMCAPopups;
extern ULONG WmipCoalesceCorrectedErrorInterval;
extern ULONG WmipSingleBitEccErrorThreshold;
extern ULONG WmipMaxCorrectedMCEOutstanding;
extern ULONG WmipCorrectedEventlogCounter;
#endif
extern ULONG WmiTraceAlignment;

// Initial user-mode process to start and arguments.
extern WCHAR NtInitialUserProcessBuffer[];
extern ULONG NtInitialUserProcessBufferLength;
extern ULONG NtInitialUserProcessBufferType;

//
// CmpUlongPtrLength is used for registry values that are 4-byte on 32-bit
// machines and can be 64-bit on 64-bit machines.
//
ULONG CmpUlongPtrLength = sizeof (ULONG_PTR);

//
//  Vector - see ntos\inc\cm.h for definition
//
CM_SYSTEM_CONTROL_VECTOR   CmControlVector[] = {

    { L"Session Manager",
      L"ProtectionMode",
      &ObpProtectionMode,
      NULL,
      NULL
    },
    
    { L"Session Manager",
      L"ObjectSecurityMode",
      &ObpObjectSecurityMode,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"LUIDDeviceMapsDisabled",
      &ObpLUIDDeviceMapsDisabled,
      NULL,
      NULL
    },


    { L"LSA",
      L"AuditBaseDirectories",
      &ObpAuditBaseDirectories,
      NULL,
      NULL
    },


    { L"LSA",
      L"AuditBaseObjects",
      &ObpAuditBaseObjects,
      NULL,
      NULL
    },


    { L"LSA\\audit",
      L"ProcessAccessesToAudit",
      &SepProcessAccessesToAudit,
      NULL,
      NULL
    },


    { L"TimeZoneInformation",
      L"ActiveTimeBias",
      &ExpLastTimeZoneBias,
      NULL,
      NULL
    },


    { L"TimeZoneInformation",
      L"Bias",
      &ExpAltTimeZoneBias,
      NULL,
      NULL
    },

    { L"TimeZoneInformation",
      L"RealTimeIsUniversal",
      &ExpRealTimeIsUniversal,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"GlobalFlag",
      &CmNtGlobalFlag,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PagedPoolQuota",
      &PspDefaultPagedLimit,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"NonPagedPoolQuota",
      &PspDefaultNonPagedLimit,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PagingFileQuota",
      &PspDefaultPagefileLimit,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"AllocationPreference",
      &MmAllocationPreference,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"DynamicMemory",
      &MmDynamicPfn,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"Mirroring",
      &MmMirroring,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SystemViewSize",
      &MmSystemViewSize,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SessionViewSize",
      &MmSessionViewSize,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SessionImageSize",
      &MmSessionImageSize,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SessionPoolSize",
      &MmSessionPoolSize,
      NULL,
      NULL
    },

#if 0
    { L"Session Manager\\Memory Management",
      L"CompressionThresholdPercentage",
      &MmCompressionThresholdRatio,
      NULL,
      NULL
    },
#endif

    { L"Session Manager\\Memory Management",
      L"PoolUsageMaximum",
      &MmConsumedPoolPercentage,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"MapAllocationFragment",
      &MmAllocationFragment,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PagedPoolSize",
      &MmSizeOfPagedPoolInBytes,
      &CmpUlongPtrLength,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"NonPagedPoolSize",
      &MmSizeOfNonPagedPoolInBytes,
      &CmpUlongPtrLength,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"NonPagedPoolMaximumPercent",
      &MmMaximumNonPagedPoolPercent,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"LargeSystemCache",
      &MmLargeSystemCache,
      NULL,
      NULL
    },

#if defined (_X86_)
    { L"Session Manager\\Memory Management",
      L"LargeStackSize",
      &MmLargeStackSize,
      NULL,
      NULL
    },
#endif

    { L"Session Manager\\Memory Management",
      L"SystemPages",
      &MmNumberOfSystemPtes,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"LargePageDrivers",
      MmLargePageDriverBuffer,
      &MmLargePageDriverBufferLength,
      &MmLargePageDriverBufferType
    },

    { L"Session Manager\\Memory Management",
      L"LowMemoryThreshold",
      &MmLowMemoryThreshold,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"HighMemoryThreshold",
      &MmHighMemoryThreshold,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"DisablePagingExecutive",
      &MmDisablePagingExecutive,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"ModifiedPageLife",
      &MmModifiedPageLifeInSeconds,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SecondLevelDataCache",
      &MmSecondaryColors,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"ClearPageFileAtShutdown",
      &MmZeroPageFile,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PoolTagSmallTableSize",
      &PoolTrackTableSize,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PoolTagBigTableSize",
      &PoolBigPageTableSize,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PoolTag",
      &MmSpecialPoolTag,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"PoolTagOverruns",
      &MmSpecialPoolCatchOverruns,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"SnapUnloads",
      &MmSnapUnloads,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"ProtectNonPagedPool",
      &MmProtectFreedNonPagedPool,
      NULL,
      NULL
    },


    { L"Session Manager\\Memory Management",
      L"TrackLockedPages",
      &MmTrackLockedPages,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"TrackPtes",
      &MmTrackPtes,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"VerifyDrivers",
      MmVerifyDriverBuffer,
      &MmVerifyDriverBufferLength,
      &MmVerifyDriverBufferType
    },

    { L"Session Manager\\Memory Management",
      L"VerifyDriverLevel",
      &MmVerifyDriverLevel,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"LargePageMinimum",
      &MmLargePageMinimum,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"EnforceWriteProtection",
      &MmEnforceWriteProtection,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"MakeLowMemory",
      &MmMakeLowMemory,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"DeadlockRecursionDepthLimit",
      &ViRecursionDepthLimitFromRegistry,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"DeadlockSearchNodesLimit",
      &ViSearchedNodesLimitFromRegistry,
      NULL,
      NULL
    },

    { L"Session Manager\\Memory Management",
      L"MinimumStackCommitInBytes",
      &MmMinimumStackCommitInBytes,
      NULL,
      NULL
    },

    { L"Session Manager\\Executive",
      L"AdditionalCriticalWorkerThreads",
      &ExpAdditionalCriticalWorkerThreads,
      NULL,
      NULL
    },


    { L"Session Manager\\Executive",
      L"AdditionalDelayedWorkerThreads",
      &ExpAdditionalDelayedWorkerThreads,
      NULL,
      NULL
    },

    { L"Session Manager\\Executive",
      L"PriorityQuantumMatrix",
      &ExpNtExpirationData,
      &ExpNtExpirationDataLength,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"DPCTimeout",
      &KiDPCTimeout,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"SpinlockTimeout",
      &KiSpinlockTimeout,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"ThreadDpcEnable",
      &KeThreadDpcEnable,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"DpcQueueDepth",
      &KiMaximumDpcQueueDepth,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"MinimumDpcRate",
      &KiMinimumDpcRate,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"AdjustDpcThreshold",
      &KiAdjustDpcThreshold,
      NULL,
      NULL
    },

#if defined(_IA64_)

    { L"Session Manager\\Kernel",
      L"ExceptionDeferralMode",
      &KiExceptionDeferralMode,
      NULL,
      NULL
    },


    { L"Session Manager\\Kernel",
      L"BackingStoreSecurityMode",
      &KiBackingStoreSecurityMode,
      NULL,
      NULL
    },

#endif

    { L"Session Manager\\Kernel",
      L"IdealDpcRate",
      &KiIdealDpcRate,
      NULL,
      NULL
    },

#if defined(_X86_)

    { L"Session Manager\\Kernel",
      L"FastSystemCallDisable",
      &KiFastSystemCallDisable,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"XMMIZeroingEnable",
      &KiXMMIZeroingEnable,
      NULL,
      NULL
    },

#endif

    { L"Session Manager\\Kernel",
      L"ObTracePoolTags",
      &ObpTracePoolTagsBuffer,
      &ObpTracePoolTagsLength,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"ObTraceNoDeregister",
      &ObpTraceNoDeregister,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"PoCleanShutdownFlags",
      &PopShutdownCleanly,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"ObUnsecureGlobalNames",
      &ObpUnsecureGlobalNamesBuffer,
      &ObpUnsecureGlobalNamesLength,
      NULL
    },

#if defined(_X86_)

    { L"Session Manager\\Kernel",
      L"TimeLimitDpcMicroseconds",
      &KiTimeLimitDpcMicroseconds,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"TimeLimitIsrMicroseconds",
      &KiTimeLimitIsrMicroseconds,
      NULL,
      NULL
    },

#endif

    { L"Session Manager\\Power",
      L"IdleDefaultMinThrottle",
      &PopIdleDefaultMinThrottle,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleThrottleCheckRate",
      &PopIdleThrottleCheckRate,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleThrottleCheckTimeout",
      &PopIdleThrottleCheckTimeout,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleFrom0Delay",
      &PopIdleFrom0Delay,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleFrom0IdlePercent",
      &PopIdleFrom0IdlePercent,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"Idle0TimeCheck",
      &PopIdle0TimeCheck,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleTimeCheck",
      &PopIdleTimeCheck,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleTo0Percent",
      &PopIdleTo0Percent,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleDefaultDemotePercent",
      &PopIdleDefaultDemotePercent,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleDefaultDemoteTime",
      &PopIdleDefaultDemoteTime,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleDefaultPromotePercent",
      &PopIdleDefaultPromotePercent,
      NULL,
      NULL
    },

    { L"Session Manager\\Power",
      L"IdleDefaultPromoteTime",
      &PopIdleDefaultPromoteTime,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfTimeDelta",
      &PopPerfTimeDelta,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfCriticalTimeDelta",
      &PopPerfCriticalTimeDelta,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfCriticalFrequencyDelta",
      &PopPerfCriticalFrequencyDelta,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfIncreasePercentModifier",
      &PopPerfIncreasePercentModifier,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfIncreaseAbsoluteModifier",
      &PopPerfIncreaseAbsoluteModifier,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDecreasePercentModifier",
      &PopPerfDecreasePercentModifier,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDecreaseAbsoluteModifier",
      &PopPerfDecreaseAbsoluteModifier,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfIncreaseTimeValue",
      &PopPerfIncreaseTimeValue,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfIncreaseMinimumTime",
      &PopPerfIncreaseMinimumTime,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDecreaseTimeValue",
      &PopPerfDecreaseTimeValue,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDecreaseMinimumTime",
      &PopPerfDecreaseMinimumTime,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDegradeThrottleMinCapacity",
      &PopPerfDegradeThrottleMinCapacity,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfDegradeThrottleMinFrequency",
      &PopPerfDegradeThrottleMinFrequency,
      NULL,
      NULL
    },

    { L"Session Manager\\Throttle",
      L"PerfMaxC3Frequency",
      &PopPerfMaxC3Frequency,
      NULL,
      NULL
    },

    { L"Session Manager\\Kernel",
      L"ObCaseInsensitive",
      &ObpCaseInsensitive,
      NULL,
      NULL
    },

    { L"Session Manager\\I/O System",
      L"CountOperations",
      &IoCountOperations,
      NULL,
      NULL
    },

    { L"Session Manager\\I/O System",
      L"LargeIrpStackLocations",
      &IopLargeIrpStackLocations,
      NULL,
      NULL
    },

    { L"Session Manager\\I/O System",
      L"IoVerifierLevel",
      &IovpVerifierLevel,
      NULL,
      NULL
    },

    { L"Session Manager\\I/O System",
      L"IoFailZeroAccessCreate",
      &IopFailZeroAccessCreate,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"ResourceTimeoutCount",
      &ExResourceTimeoutCount,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"ResourceCheckFlags",
      &ExResourceCheckFlags,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"CriticalSectionTimeout",
      &MmCritsectTimeoutSeconds,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"HeapSegmentReserve",
      &MmHeapSegmentReserve,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"HeapSegmentCommit",
      &MmHeapSegmentCommit,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"HeapDeCommitTotalFreeThreshold",
      &MmHeapDeCommitTotalFreeThreshold,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"HeapDeCommitFreeBlockThreshold",
      &MmHeapDeCommitFreeBlockThreshold,
      NULL,
      NULL
    },

#if defined(_IA64_)

    { L"Session Manager",
      L"EnableAlignmentFaultExceptions",
      &KiEnableAlignmentFaultExceptions,
      NULL,
      NULL
    },

#endif

    { L"ProductOptions",
      L"ProductType",
      &MmProductType,
      NULL,
      NULL
    },
    
    { L"ProductOptions",
      L"Brand",
      &CmBrand,
      NULL,
      NULL
    },

    { L"Terminal Server",
      L"TSEnabled",
      &ExpHydraEnabled,
      NULL,
      NULL
    },

    { L"Terminal Server",
      L"TSAppCompat",
      &ExpMultiUserTS,
      NULL,
      NULL
    },

    { L"ProductOptions",
      L"ProductSuite",
      CmSuiteBuffer,
      &CmSuiteBufferLength,
      &CmSuiteBufferType
    },

    { L"Windows",
      L"CSDVersion",
      &CmNtCSDVersion,
      NULL,
      NULL
    },

    { L"Nls\\Language",
      L"Default",
      CmDefaultLanguageId,
      &CmDefaultLanguageIdLength,
      &CmDefaultLanguageIdType
    },

    { L"Nls\\Language",
      L"InstallLanguage",
      CmInstallUILanguageId,
      &CmInstallUILanguageIdLength,
      &CmInstallUILanguageIdType
    },

    { L"\0\0",
      L"RegistrySizeLimit",
      &CmRegistrySizeLimit,
      &CmRegistrySizeLimitLength,
      &CmRegistrySizeLimitType
    },

    { L"Session Manager\\Configuration Manager",
      L"RegistryLogSizeLimit",
      &CmRegistryLogSizeLimit,
      NULL,
      NULL
    },

    { L"Session Manager\\Configuration Manager",
      L"RegistryLazyFlushInterval",
      &CmpLazyFlushIntervalInSeconds,
      NULL,
      NULL
    },

    { L"Session Manager\\Configuration Manager",
      L"RegistryLazyFlushHiveCount",
      &CmpLazyFlushHiveCount,
      NULL,
      NULL
    },

#if !defined(NT_UP)
    { L"Session Manager",
      L"RegisteredProcessors",
      &KeRegisteredProcessors,
      NULL,
      NULL
    },
    { L"Session Manager",
      L"LicensedProcessors",
      &KeLicensedProcessors,
      NULL,
      NULL
    },
#endif

    { L"Session Manager",
      L"PowerPolicySimulate",
      &PopSimulate,
      NULL,
      NULL
    },

    { L"Session Manager\\Executive",
      L"MaxTimeSeparationBeforeCorrect",
      &ExpMaxTimeSeperationBeforeCorrect,
      NULL,
      NULL
    },

    { L"Windows",
      L"ShutdownTime",
      &ExpLastShutDown,
      &shutdownlength,
      NULL
    },

    { L"PriorityControl",
      L"Win32PrioritySeparation",
      &PsRawPrioritySeparation,
      NULL,
      NULL
    },

#if defined(_X86_)
    { L"Session Manager",
      L"EnableTimerWatchdog",
      &KiEnableTimerWatchdog,
      NULL,
      NULL
    },
#endif

    { L"Session Manager",
      L"Debugger Retries",
      &KdpContext.KdpDefaultRetries,
      NULL,
      NULL
    },

    { L"Session Manager\\Debug Print Filter",
      L"WIN2000",
      &Kd_WIN2000_Mask,
      NULL,
      NULL
    },

#include "dpfiltercm.c"

    { L"WMI",
      L"MaxEventSize",
      &WmipMaxKmWnodeEventSize,
      NULL,
      NULL
    },

#if defined(_IA64_)	
    { L"WMI",
      L"DisableMCAPopups",
      &WmipDisableMCAPopups,
      NULL,
      NULL
    },

    { L"WMI",
      L"CoalesceCorrectedErrorInterval",
      &WmipCoalesceCorrectedErrorInterval,
      NULL,
      NULL
    },

    { L"WMI",
      L"SingleBitEccErrorThreshold",
      &WmipSingleBitEccErrorThreshold,
      NULL,
      NULL
    },

    { L"WMI",
      L"MaxCorrectedMCEOutstanding",
      &WmipMaxCorrectedMCEOutstanding,
      NULL,
      NULL
    },

    { L"WMI",
      L"MaxCorrectedEventlogs",
      &WmipCorrectedEventlogCounter,
      NULL,
      NULL
    },



	
#endif	

    { L"WMI\\Trace",
      L"UsePerformanceClock",
      &WmiUsePerfClock,
      NULL,
      NULL
    },

    { L"WMI\\Trace",
      L"TraceAlignment",
      &WmiTraceAlignment,
      NULL,
      NULL
    },

    { L"Session Manager",
      L"Initial Process",
      NtInitialUserProcessBuffer,
      &NtInitialUserProcessBufferLength,
      &NtInitialUserProcessBufferType
    },

    { L"EmbeddedNT\\Executive",
      L"KernelOnlyConfiguration",
      &PsEmbeddedNTMask,
      NULL,
      NULL
    },

    { L"CrashControl",
      L"AutoReboot",
      &IopAutoReboot,
      NULL,
      NULL
    },

    { NULL, NULL, NULL, NULL, NULL }    // end marker
    };

#ifdef ALLOC_DATA_PRAGMA
#pragma  data_seg()
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmdatini.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

   cmdatini.c

Abstract:

   contains code to init static STRING structures for registry name space.

Author:

    Andre Vachon (andreva) 08-Apr-1992


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,CmpInitializeRegistryNames)
#endif

extern UNICODE_STRING CmRegistryRootName;
extern UNICODE_STRING CmRegistryMachineName;
extern UNICODE_STRING CmRegistryMachineHardwareName;
extern UNICODE_STRING CmRegistryMachineHardwareDescriptionName;
extern UNICODE_STRING CmRegistryMachineHardwareDescriptionSystemName;
extern UNICODE_STRING CmRegistryMachineHardwareDeviceMapName;
extern UNICODE_STRING CmRegistryMachineHardwareResourceMapName;
extern UNICODE_STRING CmRegistryMachineHardwareOwnerMapName;
extern UNICODE_STRING CmRegistryMachineSystemName;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSet;
extern UNICODE_STRING CmRegistryUserName;
extern UNICODE_STRING CmRegistrySystemCloneName;
extern UNICODE_STRING CmpSystemFileName;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetEnumName;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetEnumRootName;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetServices;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetHardwareProfilesCurrent;
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlClass;
extern UNICODE_STRING CmSymbolicLinkValueName;

#ifdef _WANT_MACHINE_IDENTIFICATION
extern UNICODE_STRING CmRegistryMachineSystemCurrentControlSetControlBiosInfo;
#endif

extern const PWCHAR CmpRegistryRootString;
extern const PWCHAR CmpRegistryMachineString;
extern const PWCHAR CmpRegistryMachineHardwareString;
extern const PWCHAR CmpRegistryMachineHardwareDescriptionString;
extern const PWCHAR CmpRegistryMachineHardwareDescriptionSystemString;
extern const PWCHAR CmpRegistryMachineHardwareDeviceMapString;
extern const PWCHAR CmpRegistryMachineHardwareResourceMapString;
extern const PWCHAR CmpRegistryMachineHardwareOwnerMapString;
extern const PWCHAR CmpRegistryMachineSystemString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetString;
extern const PWCHAR CmpRegistryUserString;
extern const PWCHAR CmpRegistrySystemCloneString;
extern const PWCHAR CmpRegistrySystemFileNameString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetEnumString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetEnumRootString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetServicesString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetHardwareProfilesCurrentString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlClassString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlSafeBootString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagementString;

extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlBootLogString;
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetServicesEventLogString;
extern const PWCHAR CmpSymbolicLinkValueName;

#ifdef _WANT_MACHINE_IDENTIFICATION
extern const PWCHAR CmpRegistryMachineSystemCurrentControlSetControlBiosInfoString;
#endif



VOID
CmpInitializeRegistryNames(
VOID
)

/*++

Routine Description:

    This routine creates all the Unicode strings for the various names used
    in and by the registry

Arguments:

    None.

Returns:

    None.

--*/
{
    ULONG i;

    RtlInitUnicodeString( &CmRegistryRootName,
                          CmpRegistryRootString );

    RtlInitUnicodeString( &CmRegistryMachineName,
                          CmpRegistryMachineString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareName,
                          CmpRegistryMachineHardwareString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareDescriptionName,
                          CmpRegistryMachineHardwareDescriptionString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareDescriptionSystemName,
                          CmpRegistryMachineHardwareDescriptionSystemString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareDeviceMapName,
                          CmpRegistryMachineHardwareDeviceMapString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareResourceMapName,
                          CmpRegistryMachineHardwareResourceMapString );

    RtlInitUnicodeString( &CmRegistryMachineHardwareOwnerMapName,
                          CmpRegistryMachineHardwareOwnerMapString );

    RtlInitUnicodeString( &CmRegistryMachineSystemName,
                          CmpRegistryMachineSystemString );

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSet,
                          CmpRegistryMachineSystemCurrentControlSetString);

    RtlInitUnicodeString( &CmRegistryUserName,
                          CmpRegistryUserString );

    RtlInitUnicodeString( &CmRegistrySystemCloneName,
                          CmpRegistrySystemCloneString );

    RtlInitUnicodeString( &CmpSystemFileName,
                          CmpRegistrySystemFileNameString );

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetEnumName,
                          CmpRegistryMachineSystemCurrentControlSetEnumString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetEnumRootName,
                          CmpRegistryMachineSystemCurrentControlSetEnumRootString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetServices,
                          CmpRegistryMachineSystemCurrentControlSetServicesString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetHardwareProfilesCurrent,
                          CmpRegistryMachineSystemCurrentControlSetHardwareProfilesCurrentString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlClass,
                          CmpRegistryMachineSystemCurrentControlSetControlClassString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlSafeBoot,
                          CmpRegistryMachineSystemCurrentControlSetControlSafeBootString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagement,
                          CmpRegistryMachineSystemCurrentControlSetControlSessionManagerMemoryManagementString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlBootLog,
                          CmpRegistryMachineSystemCurrentControlSetControlBootLogString);

    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetServicesEventLog,
                          CmpRegistryMachineSystemCurrentControlSetServicesEventLogString);

    RtlInitUnicodeString( &CmSymbolicLinkValueName,
                          CmpSymbolicLinkValueName);

#ifdef _WANT_MACHINE_IDENTIFICATION
    RtlInitUnicodeString( &CmRegistryMachineSystemCurrentControlSetControlBiosInfo,
                          CmpRegistryMachineSystemCurrentControlSetControlBiosInfoString);
#endif

    //
    // Initialize the type names for the hardware tree.
    //

    for (i = 0; i <= MaximumType; i++) {

        RtlInitUnicodeString( &(CmTypeName[i]),
                              CmTypeString[i] );

    }

    //
    // Initialize the class names for the hardware tree.
    //

    for (i = 0; i <= MaximumClass; i++) {

        RtlInitUnicodeString( &(CmClassName[i]),
                              CmClassString[i] );

    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmdat2.c ===
/*++

Copyright (c) 1990, 1991  Microsoft Corporation


Module Name:

    cmdat2.c

Abstract:

    This module contains data strings that describes the registry space
    and that are exported to the rest of the system.

Author:

    Andre Vachon (andreva) 08-Apr-1992


Environment:

    Kernel mode.

Revision History:

--*/

#include "cmp.h"

//
// ***** PAGE *****
//

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("PAGEDATA")
#endif

//
// control values/overrides read from registry
//
ULONG CmRegistrySizeLimit = { 0 };
ULONG CmRegistrySizeLimitLength = 4;
ULONG CmRegistrySizeLimitType = { 0 };

//
// Maximum number of bytes of Global Quota the registry may use.
// Set to largest positive number for use in boot.  Will be set down
// based on pool and explicit registry values.
//
ULONG   CmpGlobalQuotaAllowed = CM_WRAP_LIMIT;
ULONG   CmpGlobalQuota = CM_WRAP_LIMIT;
ULONG   CmpGlobalQuotaWarning = CM_WRAP_LIMIT;
BOOLEAN CmpQuotaWarningPopupDisplayed = FALSE;
BOOLEAN CmpSystemQuotaWarningPopupDisplayed = FALSE;

//
// the "disk full" popup has already been displayed
//
BOOLEAN CmpDiskFullWorkerPopupDisplayed = FALSE;
BOOLEAN CmpCannotWriteConfiguration = FALSE;
//
// GQ actually in use
//
ULONG   CmpGlobalQuotaUsed = 0;

//
// State flag to remember when to turn it on
//
BOOLEAN CmpProfileLoaded = FALSE;

PUCHAR CmpStashBuffer = NULL;
ULONG  CmpStashBufferSize = 0;
FAST_MUTEX CmpStashBufferLock;

//
// Shutdown control
//
BOOLEAN HvShutdownComplete = FALSE;     // Set to true after shutdown
                                        // to disable any further I/O

PCM_KEY_CONTROL_BLOCK CmpKeyControlBlockRoot = NULL;

HANDLE CmpRegistryRootHandle = NULL;

struct {
    PHHIVE      Hive;
    ULONG       Status;
} CmCheckRegistryDebug = { 0 };

//
// The last I/O error status code
//
struct {
    ULONG       Action;
    HANDLE      Handle;
    NTSTATUS    Status;
} CmRegistryIODebug = { 0 };

//
// globals private to check code
//

struct {
    PHHIVE      Hive;
    ULONG       Status;
} CmpCheckRegistry2Debug = { 0 };

struct {
    PHHIVE      Hive;
    ULONG       Status;
    HCELL_INDEX Cell;
    PCELL_DATA  CellPoint;
    PVOID       RootPoint;
    ULONG       Index;
} CmpCheckKeyDebug = { 0 };

struct {
    PHHIVE      Hive;
    ULONG       Status;
    PCELL_DATA  List;
    ULONG       Index;
    HCELL_INDEX Cell;
    PCELL_DATA  CellPoint;
} CmpCheckValueListDebug = { 0 };

ULONG CmpUsedStorage = { 0 };

// hivechek.c
struct {
    PHHIVE      Hive;
    ULONG       Status;
    ULONG       Space;
    HCELL_INDEX MapPoint;
    PHBIN       BinPoint;
} HvCheckHiveDebug = { 0 };

struct {
    PHBIN       Bin;
    ULONG       Status;
    PHCELL      CellPoint;
} HvCheckBinDebug = { 0 };

struct {
    PHHIVE      Hive;
    ULONG       FileOffset;
    ULONG       FailPoint; // look in HvpRecoverData for exact point of failure
} HvRecoverDataDebug = { 0 };

//
// when a local hive cannot be loded, set this to it's index
// and the load hive worker thread responsible for it will be held of 
// until all the others finish; We can then debug the offending hive
//
ULONG   CmpCheckHiveIndex = CM_NUMBER_OF_MACHINE_HIVES;


#ifdef CMP_STATS

struct {
    ULONG       CmpMaxKcbNo;
    ULONG       CmpKcbNo;
    ULONG       CmpStatNo;
    ULONG       CmpNtCreateKeyNo;
    ULONG       CmpNtDeleteKeyNo;
    ULONG       CmpNtDeleteValueKeyNo;
    ULONG       CmpNtEnumerateKeyNo;
    ULONG       CmpNtEnumerateValueKeyNo;
    ULONG       CmpNtFlushKeyNo;
    ULONG       CmpNtInitializeRegistryNo;
    ULONG       CmpNtNotifyChangeMultipleKeysNo;
    ULONG       CmpNtOpenKeyNo;
    ULONG       CmpNtQueryKeyNo;
    ULONG       CmpNtQueryValueKeyNo;
    ULONG       CmpNtQueryMultipleValueKeyNo;
    ULONG       CmpNtRestoreKeyNo;
    ULONG       CmpNtSaveKeyNo;
    ULONG       CmpNtSaveMergedKeysNo;
    ULONG       CmpNtSetValueKeyNo;
    ULONG       CmpNtLoadKeyNo;
    ULONG       CmpNtUnloadKeyNo;
    ULONG       CmpNtSetInformationKeyNo;
    ULONG       CmpNtReplaceKeyNo;
    ULONG       CmpNtQueryOpenSubKeysNo;
} CmpStatsDebug = { 0 };

#endif

#ifdef ALLOC_DATA_PRAGMA
#pragma  data_seg()
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmgquota.c ===
/*++

Copyright (c) 1993  Microsoft Corporation

Module Name:

    cmgquota.c

Abstract:

    The module contains CM routines to support Global Quota

    Global Quota has little to do with NT's standard per-process/user
    quota system.  Global Quota is waying of controlling the aggregate
    resource usage of the entire registry.  It is used to manage space
    consumption by objects which user apps create, but which are persistent
    and therefore cannot be assigned to the quota of a user app.

    Global Quota prevents the registry from consuming all of paged
    pool, and indirectly controls how much disk it can consume.
    Like the release 1 file systems, a single app can fill all the
    space in the registry, but at least it cannot kill the system.

    Memory objects used for known short times and protected by
    serialization, or billable as quota objects, are not counted
    in the global quota.

Author:

    Bryan M. Willman (bryanwi) 13-Jan-1993

Revision History:

    Dragos C Sambotin (dragoss) 04-Nov-1999
    Charge quota only for bins in paged pool (volatile storage and bins crossing 
    the CM_VIEW_SIZE boundary).

--*/

#include "cmp.h"

VOID
CmpSystemHiveHysteresisWorker(
    IN PVOID WorkItem
    );

VOID
CmpRaiseSelfHealWarningWorker(
    IN PVOID Arg
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpClaimGlobalQuota)
#pragma alloc_text(PAGE,CmpReleaseGlobalQuota)
#pragma alloc_text(PAGE,CmpSetGlobalQuotaAllowed)
#pragma alloc_text(PAGE,CmpQuotaWarningWorker)
#pragma alloc_text(PAGE,CmQueryRegistryQuotaInformation)
#pragma alloc_text(PAGE,CmSetRegistryQuotaInformation)
#pragma alloc_text(PAGE,CmpCanGrowSystemHive)
#pragma alloc_text(PAGE,CmpSystemQuotaWarningWorker)
#pragma alloc_text(INIT,CmpComputeGlobalQuotaAllowed)
#pragma alloc_text(PAGE,CmpSystemHiveHysteresisWorker)
#pragma alloc_text(PAGE,CmpUpdateSystemHiveHysteresis)
#pragma alloc_text(PAGE,CmRegisterSystemHiveLimitCallback)
#pragma alloc_text(PAGE,CmpRaiseSelfHealWarning)
#pragma alloc_text(PAGE,CmpRaiseSelfHealWarningForSystemHives)
#pragma alloc_text(PAGE,CmpRaiseSelfHealWarningWorker)
#endif

//
// Registry control values
//
#define CM_DEFAULT_RATIO            (3)
#define CM_LIMIT_RATIO(x)           ((x / 10) * 8)
#define CM_MINIMUM_GLOBAL_QUOTA     (16 *1024 * 1024)

//
// Percent of used registry quota that triggers a hard error
// warning popup.
//
#define CM_REGISTRY_WARNING_LEVEL   (95)

//
// System hive hard quota limit
//
// For an x86 3GB system we set the limit at 12MB for now. Needs some MM changes before we 
// bump this up.
// For an x86 non-3GB system, we set the limit at 1/4 of physical memory
// For IA-64 we set the limit at 32MB
//

#define _200MB (200 *1024 * 1024) 

#if defined(_X86_)
#define CM_SYSTEM_HIVE_LIMIT_SIZE       (MmVirtualBias ? (12 * 1024 * 1024) : (min(MmNumberOfPhysicalPages / 4, _200MB >> PAGE_SHIFT) * PAGE_SIZE))
#else
#define CM_SYSTEM_HIVE_LIMIT_SIZE       (32 * 1024 * 1024)
#endif

#define CM_SYSTEM_HIVE_WARNING_SIZE     ((CM_SYSTEM_HIVE_LIMIT_SIZE*9)/10)


extern ULONG CmRegistrySizeLimit;
extern ULONG CmRegistrySizeLimitLength;
extern ULONG CmRegistrySizeLimitType;

extern ULONG MmSizeOfPagedPoolInBytes;

//
// Maximum number of bytes of Global Quota the registry may use.
// Set to largest positive number for use in boot.  Will be set down
// based on pool and explicit registry values.
//
extern ULONG   CmpGlobalQuota;
extern ULONG   CmpGlobalQuotaAllowed;

//
// Mark that will trigger the low-on-quota popup
//
extern ULONG   CmpGlobalQuotaWarning;

//
// Indicate whether the popup has been triggered yet or not.
//
extern BOOLEAN CmpQuotaWarningPopupDisplayed;

extern BOOLEAN CmpSystemQuotaWarningPopupDisplayed;

//
// GQ actually in use
//
extern ULONG   CmpGlobalQuotaUsed;

extern  HIVE_LIST_ENTRY CmpMachineHiveList[];

VOID
CmQueryRegistryQuotaInformation(
    IN PSYSTEM_REGISTRY_QUOTA_INFORMATION RegistryQuotaInformation
    )

/*++

Routine Description:

    Returns the registry quota information

Arguments:

    RegistryQuotaInformation - Supplies pointer to buffer that will return
        the registry quota information.

Return Value:

    None.

--*/

{
    RegistryQuotaInformation->RegistryQuotaAllowed  = CmpGlobalQuota;
    RegistryQuotaInformation->RegistryQuotaUsed     = CmpGlobalQuotaUsed;
    RegistryQuotaInformation->PagedPoolSize         = MmSizeOfPagedPoolInBytes;
}


VOID
CmSetRegistryQuotaInformation(
    IN PSYSTEM_REGISTRY_QUOTA_INFORMATION RegistryQuotaInformation
    )

/*++

Routine Description:

    Sets the registry quota information.  The caller is assumed to have
    completed the necessary security checks already.

Arguments:

    RegistryQuotaInformation - Supplies pointer to buffer that provides
        the new registry quota information.

Return Value:

    None.

--*/

{
    CmpGlobalQuota = RegistryQuotaInformation->RegistryQuotaAllowed;

    //
    // Sanity checks against insane values
    //
    if (CmpGlobalQuota > CM_WRAP_LIMIT) {
        CmpGlobalQuota = CM_WRAP_LIMIT;
    }
    if (CmpGlobalQuota < CM_MINIMUM_GLOBAL_QUOTA) {
        CmpGlobalQuota = CM_MINIMUM_GLOBAL_QUOTA;
    }

    //
    // Recompute the warning level
    //
    CmpGlobalQuotaWarning = CM_REGISTRY_WARNING_LEVEL * (CmpGlobalQuota / 100);

    CmpGlobalQuotaAllowed = CmpGlobalQuota;
}

VOID
CmpQuotaWarningWorker(
    IN PVOID WorkItem
    )

/*++

Routine Description:

    Displays hard error popup that indicates the registry quota is
    running out.

Arguments:

    WorkItem - Supplies pointer to the work item. This routine will
               free the work item.

Return Value:

    None.

--*/

{
    NTSTATUS Status;
    ULONG Response;

    ExFreePool(WorkItem);

    Status = ExRaiseHardError(STATUS_REGISTRY_QUOTA_LIMIT,
                              0,
                              0,
                              NULL,
                              OptionOk,
                              &Response);
}


BOOLEAN
CmpClaimGlobalQuota(
    IN ULONG    Size
    )
/*++

Routine Description:

    If CmpGlobalQuotaUsed + Size >= CmpGlobalQuotaAllowed, return
    false.  Otherwise, increment CmpGlobalQuotaUsed, in effect claiming
    the requested GlobalQuota.

Arguments:

    Size - number of bytes of GlobalQuota caller wants to claim

Return Value:

    TRUE - Claim succeeded, and has been counted in Used GQ

    FALSE - Claim failed, nothing counted in GQ.

--*/
{
#if 0
    //
    // We shouldn't come to this, unless we have leaks;
    // There is no quota anymore, remember?
    //
    LONG   available;
    PWORK_QUEUE_ITEM WorkItem;

    //
    // compute available space, then see if size <.  This prevents overflows.
    // Note that this must be signed. Since quota is not enforced until logon,
    // it is possible for the available bytes to be negative.
    //

    available = (LONG)CmpGlobalQuotaAllowed - (LONG)CmpGlobalQuotaUsed;

    if ((LONG)Size < available) {
        CmpGlobalQuotaUsed += Size;
        if ((CmpGlobalQuotaUsed > CmpGlobalQuotaWarning) &&
            (!CmpQuotaWarningPopupDisplayed) &&
            (ExReadyForErrors)) {


            //
            // Queue work item to display popup
            //
            WorkItem = ExAllocatePool(NonPagedPool, sizeof(WORK_QUEUE_ITEM));
            if (WorkItem != NULL) {

                CmpQuotaWarningPopupDisplayed = TRUE;
                ExInitializeWorkItem(WorkItem,
                                     CmpQuotaWarningWorker,
                                     WorkItem);
                ExQueueWorkItem(WorkItem, DelayedWorkQueue);
            }
        }
        return TRUE;
    } else {
        return FALSE;
    }
#endif //0

    CmpGlobalQuotaUsed += Size;

    return TRUE;
}


VOID
CmpReleaseGlobalQuota(
    IN ULONG    Size
    )
/*++

Routine Description:

    If Size <= CmpGlobalQuotaUsed, then decrement it.  Else BugCheck.

Arguments:

    Size - number of bytes of GlobalQuota caller wants to release

Return Value:

    NONE.

--*/
{
    if (Size > CmpGlobalQuotaUsed) {
        CM_BUGCHECK(REGISTRY_ERROR,QUOTA_ERROR,1,0,0);
    }

    CmpGlobalQuotaUsed -= Size;
}


VOID
CmpComputeGlobalQuotaAllowed(
    VOID
    )

/*++

Routine Description:

    Compute CmpGlobalQuota based on:
        (a) Size of paged pool
        (b) Explicit user registry commands to set registry GQ

Return Value:

    NONE.

--*/

{
    ULONG   PagedLimit;

    PagedLimit = CM_LIMIT_RATIO(MmSizeOfPagedPoolInBytes);

    if ((CmRegistrySizeLimitLength != 4) ||
        (CmRegistrySizeLimitType != REG_DWORD) ||
        (CmRegistrySizeLimit == 0))
    {
        //
        // If no value at all, or value of wrong type, or set to
        // zero, use internally computed default
        //
        CmpGlobalQuota = MmSizeOfPagedPoolInBytes / CM_DEFAULT_RATIO;

    } else if (CmRegistrySizeLimit >= PagedLimit) {
        //
        // If more than computed upper bound, use computed upper bound
        //
        CmpGlobalQuota = PagedLimit;

    } else {
        //
        // Use the set size
        //
        CmpGlobalQuota = CmRegistrySizeLimit;

    }

    if (CmpGlobalQuota > CM_WRAP_LIMIT) {
        CmpGlobalQuota = CM_WRAP_LIMIT;
    }
    if (CmpGlobalQuota < CM_MINIMUM_GLOBAL_QUOTA) {
        CmpGlobalQuota = CM_MINIMUM_GLOBAL_QUOTA;
    }

    CmpGlobalQuotaWarning = CM_REGISTRY_WARNING_LEVEL * (CmpGlobalQuota / 100);

    return;
}


VOID
CmpSetGlobalQuotaAllowed(
    VOID
    )
/*++

Routine Description:

    Enables registry quota

    NOTE:   Do NOT put this in init segment, we call it after
            that code has been freed!

Return Value:

    NONE.

--*/
{
     CmpGlobalQuotaAllowed = CmpGlobalQuota;
}


BOOLEAN
CmpCanGrowSystemHive(
                     IN PHHIVE  Hive,
                     IN ULONG   NewLength
                     )

/*++

Routine Description:

    Checks if the system hive is allowed to grow with the specified amount
    of data (using the hard quota limit on the system hive)

Return Value:

    NONE.

--*/
{
    PCMHIVE             CmHive;
    PWORK_QUEUE_ITEM    WorkItem;

    PAGED_CODE();

    CmHive = (PCMHIVE)CONTAINING_RECORD(Hive,CMHIVE,Hive);
    
    if( CmHive != CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive ) {
        //
        // not the system hive, bail out
        //
        return TRUE;
    }

    // account for the header.
    NewLength += HBLOCK_SIZE;
    if( NewLength > CM_SYSTEM_HIVE_LIMIT_SIZE ) {
        //
        // this is bad; we may not be able to boot next time !!!
        //
        return FALSE;
    }

    if( (NewLength > CM_SYSTEM_HIVE_WARNING_SIZE) && 
        (!CmpSystemQuotaWarningPopupDisplayed) &&
        (ExReadyForErrors)
      ) {
        //
        // we're above the warning level, queue work item to display popup
        //
        WorkItem = ExAllocatePool(NonPagedPool, sizeof(WORK_QUEUE_ITEM));
        if (WorkItem != NULL) {

            CmpSystemQuotaWarningPopupDisplayed = TRUE;
            ExInitializeWorkItem(WorkItem,
                                 CmpSystemQuotaWarningWorker,
                                 WorkItem);
            ExQueueWorkItem(WorkItem, DelayedWorkQueue);
        }

    }

    return TRUE;
}


VOID
CmpSystemQuotaWarningWorker(
    IN PVOID WorkItem
    )

/*++

Routine Description:

    Displays hard error popup that indicates the hard quota limit
    on the system hive is running out.

Arguments:

    WorkItem - Supplies pointer to the work item. This routine will
               free the work item.

Return Value:

    None.

--*/

{
    NTSTATUS Status;
    ULONG Response;

    ExFreePool(WorkItem);

    Status = ExRaiseHardError(STATUS_REGISTRY_QUOTA_LIMIT,
                              0,
                              0,
                              NULL,
                              OptionOk,
                              &Response);
}

//
// Pnp private API 
//
ULONG                       CmpSystemHiveHysteresisLow = 0;
ULONG                       CmpSystemHiveHysteresisHigh = 0;
PVOID                       CmpSystemHiveHysteresisContext = NULL;
PCM_HYSTERESIS_CALLBACK     CmpSystemHiveHysteresisCallback = NULL;
ULONG                       CmpSystemHiveHysteresisHitRatio = 0;
BOOLEAN                     CmpSystemHiveHysteresisLowSeen = FALSE;
BOOLEAN                     CmpSystemHiveHysteresisHighSeen = FALSE;

VOID
CmpSystemHiveHysteresisWorker(
    IN PVOID WorkItem
    )

/*++

Routine Description:

    Calls the hysteresis callback

Arguments:

    WorkItem - Supplies pointer to the work item. This routine will
               free the work item.

Return Value:

    None.

--*/

{
    PCM_HYSTERESIS_CALLBACK   Callback;

    ExFreePool(WorkItem);

    Callback = CmpSystemHiveHysteresisCallback;

    if( Callback ) {
        (*Callback)(CmpSystemHiveHysteresisContext,CmpSystemHiveHysteresisHitRatio);
    }
}


VOID
CmpUpdateSystemHiveHysteresis(  PHHIVE  Hive,
                                ULONG   NewLength,
                                ULONG   OldLength
                                )
{
    PCMHIVE             CmHive;
    PWORK_QUEUE_ITEM    WorkItem;
    ULONG               CurrentRatio;
    BOOLEAN             DoWorkItem = FALSE;

    PAGED_CODE();

    CmHive = (PCMHIVE)CONTAINING_RECORD(Hive,CMHIVE,Hive);
    
    if( (!CmpSystemHiveHysteresisCallback) || (CmHive != CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive) ) {
        //
        // not the system hive, bail out
        //
        return;
    }

    ASSERT( NewLength != OldLength );

    //
    // compute current ratio; acount for the header first
    //
    CurrentRatio = NewLength + HBLOCK_SIZE;
    CurrentRatio *= 100;
    CurrentRatio /= CM_SYSTEM_HIVE_LIMIT_SIZE;

    if( NewLength > OldLength ) {
        //
        // hive is growing
        //
        if( (CmpSystemHiveHysteresisHighSeen == FALSE) && (CurrentRatio > CmpSystemHiveHysteresisHigh) ) {
            //
            // we reached high; see if low has already been hit and queue work item
            //
            CmpSystemHiveHysteresisHighSeen = TRUE;
            if( TRUE == CmpSystemHiveHysteresisLowSeen ) {
                //
                // low to high; queue workitem
                //
                CmpSystemHiveHysteresisHitRatio = CurrentRatio;
                DoWorkItem = TRUE;
            }
        }
    } else {
        //
        // hive is shrinking
        //
        if( (FALSE == CmpSystemHiveHysteresisLowSeen) && (CurrentRatio < CmpSystemHiveHysteresisLow ) ) {
            //
            // we reached low; see if low has been hit and queue work item
            //
            CmpSystemHiveHysteresisLowSeen = TRUE;
            if( TRUE == CmpSystemHiveHysteresisHighSeen ) {
                //
                // high to low; queue workitem
                //
                CmpSystemHiveHysteresisHitRatio = CurrentRatio;
                DoWorkItem = TRUE;
            }
        }
    }

    if( DoWorkItem ) {
        ASSERT( CmpSystemHiveHysteresisLowSeen && CmpSystemHiveHysteresisHighSeen );

        WorkItem = ExAllocatePool(NonPagedPool, sizeof(WORK_QUEUE_ITEM));
        if (WorkItem != NULL) {

            ExInitializeWorkItem(WorkItem,
                                 CmpSystemHiveHysteresisWorker,
                                 WorkItem);
            ExQueueWorkItem(WorkItem, DelayedWorkQueue);
        }
        //
        // reset state so we can fire again later
        //
        CmpSystemHiveHysteresisLowSeen = FALSE;
        CmpSystemHiveHysteresisHighSeen = FALSE;
    }
}

ULONG
CmRegisterSystemHiveLimitCallback(
                                ULONG Low,
                                ULONG High,
                                PVOID Ref,
                                PCM_HYSTERESIS_CALLBACK Callback
                                )
/*++

Routine Description:

    This routine registers a hysteresis for the system hive limit ratio.
    We will call the callback :

    a. the system hive goes above High from below Low
    b. the system hive goes below Low from above High

Arguments:

    Low, High - specifies the hysteresis

    Ref - Context to give back to the callback

    Callback - callback routine.

Return Value:

    current ratio 0 - 100

--*/
{
    ULONG               Length;

    PAGED_CODE();

    if( CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive ) {
        Length = CmpMachineHiveList[SYSTEM_HIVE_INDEX].CmHive->Hive.BaseBlock->Length + HBLOCK_SIZE;

        Length *= 100;
        Length /= CM_SYSTEM_HIVE_LIMIT_SIZE;
    } else {
        Length = 0;
    }

    //
    // allow only one call per system uptime.
    //
    if( CmpSystemHiveHysteresisCallback == NULL ) {
        CmpSystemHiveHysteresisLow = Low;
        CmpSystemHiveHysteresisHigh = High;
        CmpSystemHiveHysteresisContext = Ref;
        CmpSystemHiveHysteresisCallback = Callback;
        //
        // set state vars
        //
        if( Length <= Low ) {
            CmpSystemHiveHysteresisLowSeen = TRUE;
        } else {
            CmpSystemHiveHysteresisLowSeen = FALSE;
        }
        if( Length >= High) {
            CmpSystemHiveHysteresisHighSeen = TRUE;
        } else {
            CmpSystemHiveHysteresisHighSeen = FALSE;
        }
    }
    return Length;
}


VOID 
CmpHysteresisTest(PVOID Ref, ULONG Level)
{
    UNREFERENCED_PARAMETER (Ref);

    DbgPrint("CmpHysteresisTest called with level = %lu \n",Level);
}

LIST_ENTRY	CmpSelfHealQueueListHead;
FAST_MUTEX	CmpSelfHealQueueLock;
BOOLEAN		CmpSelfHealWorkerActive = FALSE;

#define LOCK_SELF_HEAL_QUEUE() ExAcquireFastMutex(&CmpSelfHealQueueLock)
#define UNLOCK_SELF_HEAL_QUEUE() ExReleaseFastMutex(&CmpSelfHealQueueLock)

typedef struct {
    PWORK_QUEUE_ITEM    WorkItem;
	LIST_ENTRY			SelfHealQueueListEntry;
    UNICODE_STRING      HiveName;
    //
    // variable length; name goes here
    //
} CM_SELF_HEAL_WORK_ITEM_PARAMETER, *PCM_SELF_HEAL_WORK_ITEM_PARAMETER;

VOID
CmpRaiseSelfHealWarningWorker(
    IN PVOID Arg
    )
{
    PVOID                               ErrorParameters;
    ULONG                               ErrorResponse;
    PCM_SELF_HEAL_WORK_ITEM_PARAMETER   Param;

    Param = (PCM_SELF_HEAL_WORK_ITEM_PARAMETER)Arg;
    ErrorParameters = &(Param->HiveName);
    ExRaiseHardError(
        STATUS_REGISTRY_HIVE_RECOVERED,
        1,
        1,
        (PULONG_PTR)&ErrorParameters,
        OptionOk,
        &ErrorResponse
        );

    //
    // free what we have allocated
    //
    ExFreePool(Param->WorkItem);
    ExFreePool(Param);
	
	//
	// see if there are other self heal warnings to be posted.
	//
	LOCK_SELF_HEAL_QUEUE();
	CmpSelfHealWorkerActive = FALSE;
	if( IsListEmpty(&CmpSelfHealQueueListHead) == FALSE ) {
		//
		// remove head and queue it.
		//
        Param = (PCM_SELF_HEAL_WORK_ITEM_PARAMETER)RemoveHeadList(&CmpSelfHealQueueListHead);
        Param = CONTAINING_RECORD(
                        Param,
                        CM_SELF_HEAL_WORK_ITEM_PARAMETER,
                        SelfHealQueueListEntry
                        );
		ExQueueWorkItem(Param->WorkItem, DelayedWorkQueue);
		CmpSelfHealWorkerActive = TRUE;
	} 
	UNLOCK_SELF_HEAL_QUEUE();
}

VOID 
CmpRaiseSelfHealWarning( 
                        IN PUNICODE_STRING  HiveName
                        )
/*++

Routine Description:

    Raise a hard error informing the use the specified hive has been self healed and
    it might not be entirely consitent

Arguments:

    Parameter - the hive name.

Return Value:

    None.

--*/
{
    PCM_SELF_HEAL_WORK_ITEM_PARAMETER   Param;

    PAGED_CODE();

    //
    // we're above the warning level, queue work item to display popup
    //
    Param = ExAllocatePool(NonPagedPool, sizeof(CM_SELF_HEAL_WORK_ITEM_PARAMETER) + HiveName->Length);
    if( Param ) {
        Param->WorkItem = ExAllocatePool(NonPagedPool, sizeof(WORK_QUEUE_ITEM));
        if(Param->WorkItem != NULL) {
            Param->HiveName.Length = Param->HiveName.MaximumLength = HiveName->Length;
            Param->HiveName.Buffer = (PWSTR)(((PUCHAR)Param) + sizeof(CM_SELF_HEAL_WORK_ITEM_PARAMETER));
            RtlCopyMemory(Param->HiveName.Buffer,HiveName->Buffer,HiveName->Length);
            ExInitializeWorkItem(Param->WorkItem,
                                 CmpRaiseSelfHealWarningWorker,
                                 Param);
			LOCK_SELF_HEAL_QUEUE();
			if( !CmpSelfHealWorkerActive ) {
				//
				// no work item currently; ok to queue one.
				//
				ExQueueWorkItem(Param->WorkItem, DelayedWorkQueue);
				CmpSelfHealWorkerActive = TRUE;
			} else {
				//
				// add it to the end of the list. It'll be picked up when the current work item 
				// completes
				//
				InsertTailList(
					&CmpSelfHealQueueListHead,
					&(Param->SelfHealQueueListEntry)
					);
			}
			UNLOCK_SELF_HEAL_QUEUE();
        } else {
            ExFreePool(Param);
        }
    }
}

VOID 
CmpRaiseSelfHealWarningForSystemHives( )
/*++

Routine Description:

    Walks the system hivelist and raises a hard error in the event one of the hives has been self healed.

    Intended to be called after controlset has been saved, from inside NtInitializeRegistry
    (i.e. we have an UI available so it will not stop the machine).

Arguments:

Return Value:

    None.

--*/
{
    ULONG           i;
    UNICODE_STRING  Name;

    PAGED_CODE();

	for (i = 0; i < CM_NUMBER_OF_MACHINE_HIVES; i++) {
        if( !(CmpMachineHiveList[i].HHiveFlags & HIVE_VOLATILE) && (((PHHIVE)(CmpMachineHiveList[i].CmHive2))->BaseBlock->BootType & HBOOT_SELFHEAL) ) {
            RtlInitUnicodeString(
                &Name,
                CmpMachineHiveList[i].Name
                );
            CmpRaiseSelfHealWarning( &Name );
        }
    }

}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmhook.c ===
/*++

Copyright (c) 20001 Microsoft Corporation

Module Name:

    cmhook.c

Abstract:

    Provides routines for implementing callbacks into the registry code.
    Callbacks are to be used by the virus filter drivers and cluster 
    replication engine.

Author:

    Dragos C. Sambotin (DragosS) 20-Mar-2001

Revision History:


--*/
#include "cmp.h"

#define CM_MAX_CALLBACKS    100  //TBD

typedef struct _CM_CALLBACK_CONTEXT_BLOCK {
    LARGE_INTEGER               Cookie;             // to identify a specific callback for deregistration purposes
    LIST_ENTRY                  ThreadListHead;     // Active threads inside this callback
    FAST_MUTEX                  ThreadListLock;     // syncronize access to the above
    PVOID                       CallerContext;
} CM_CALLBACK_CONTEXT_BLOCK, *PCM_CALLBACK_CONTEXT_BLOCK;

typedef struct _CM_ACTIVE_NOTIFY_THREAD {
    LIST_ENTRY  ThreadList;
    PETHREAD    Thread;
} CM_ACTIVE_NOTIFY_THREAD, *PCM_ACTIVE_NOTIFY_THREAD;

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("PAGEDATA")
#endif

ULONG       CmpCallBackCount = 0;
EX_CALLBACK CmpCallBackVector[CM_MAX_CALLBACKS] = {0};

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg()
#endif

VOID
CmpInitCallback(VOID);

BOOLEAN
CmpCheckRecursionAndRecordThreadInfo(
                                     PCM_CALLBACK_CONTEXT_BLOCK         CallbackBlock,
                                     PCM_ACTIVE_NOTIFY_THREAD   ActiveThreadInfo
                                     );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmRegisterCallback)
#pragma alloc_text(PAGE,CmUnRegisterCallback)
#pragma alloc_text(PAGE,CmpInitCallback)
#pragma alloc_text(PAGE,CmpCallCallBacks)
#pragma alloc_text(PAGE,CmpCheckRecursionAndRecordThreadInfo)
#endif


NTSTATUS
CmRegisterCallback(IN PEX_CALLBACK_FUNCTION Function,
                   IN PVOID                 Context,
                   IN OUT PLARGE_INTEGER    Cookie
                    )
/*++

Routine Description:

    Registers a new callback.

Arguments:



Return Value:


--*/
{
    PEX_CALLBACK_ROUTINE_BLOCK  RoutineBlock;
    ULONG                       i;
    PCM_CALLBACK_CONTEXT_BLOCK  CmCallbackContext;

    PAGED_CODE();
    
    CmCallbackContext = (PCM_CALLBACK_CONTEXT_BLOCK)ExAllocatePoolWithTag (PagedPool,
                                                                    sizeof (CM_CALLBACK_CONTEXT_BLOCK),
                                                                    'bcMC');
    if( CmCallbackContext == NULL ) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RoutineBlock = ExAllocateCallBack (Function,CmCallbackContext);
    if( RoutineBlock == NULL ) {
        ExFreePool(CmCallbackContext);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // init the context
    //
    KeQuerySystemTime(&(CmCallbackContext->Cookie));
    *Cookie = CmCallbackContext->Cookie;
    InitializeListHead(&(CmCallbackContext->ThreadListHead));   
	ExInitializeFastMutex(&(CmCallbackContext->ThreadListLock));
    CmCallbackContext->CallerContext = Context;

    //
    // find a spot where we could add this callback
    //
    for( i=0;i<CM_MAX_CALLBACKS;i++) {
        if( ExCompareExchangeCallBack (&CmpCallBackVector[i],RoutineBlock,NULL) ) {
            InterlockedExchangeAdd ((PLONG) &CmpCallBackCount, 1);
            return STATUS_SUCCESS;
        }
    }
    
    //
    // no more callbacks
    //
    ExFreePool(CmCallbackContext);
    ExFreeCallBack(RoutineBlock);
    return STATUS_INSUFFICIENT_RESOURCES;
}


NTSTATUS
CmUnRegisterCallback(IN LARGE_INTEGER  Cookie)
/*++

Routine Description:

    Unregisters a callback.

Arguments:



Return Value:


--*/
{
    ULONG                       i;
    PCM_CALLBACK_CONTEXT_BLOCK  CmCallbackContext;
    PEX_CALLBACK_ROUTINE_BLOCK  RoutineBlock;

    PAGED_CODE();
    
    //
    // Search for this cookie
    //
    for( i=0;i<CM_MAX_CALLBACKS;i++) {
        RoutineBlock = ExReferenceCallBackBlock(&(CmpCallBackVector[i]) );
        if( RoutineBlock  ) {
            CmCallbackContext = (PCM_CALLBACK_CONTEXT_BLOCK)ExGetCallBackBlockContext(RoutineBlock);
            if( CmCallbackContext && (CmCallbackContext->Cookie.QuadPart  == Cookie.QuadPart) ) {
                //
                // found it
                //
                if( ExCompareExchangeCallBack (&CmpCallBackVector[i],NULL,RoutineBlock) ) {
                    InterlockedExchangeAdd ((PLONG) &CmpCallBackCount, -1);
    
                    ExDereferenceCallBackBlock (&(CmpCallBackVector[i]),RoutineBlock);
                    //
                    // wait for others to release their reference, then tear down the structure
                    //
                    ExWaitForCallBacks (RoutineBlock);

                    ExFreePool(CmCallbackContext);
                    ExFreeCallBack(RoutineBlock);
                    return STATUS_SUCCESS;
                }

            } else {
                ExDereferenceCallBackBlock (&(CmpCallBackVector[i]),RoutineBlock);
            }
        }
            
    }

    return STATUS_INVALID_PARAMETER;
}

NTSTATUS CmpTestCallback(
    IN PVOID CallbackContext,
    IN PVOID Argument1,
    IN PVOID Argument2
    );

//
// Cm internals
//
NTSTATUS
CmpCallCallBacks (
    IN REG_NOTIFY_CLASS Type,
    IN PVOID Argument
    )
/*++

Routine Description:

    This function calls the callback thats inside a callback structure

Arguments:

    Type - Nt call selector

    Argument - Caller provided argument to pass on (one of the REG_*_INFORMATION )

Return Value:

    NTSTATUS - STATUS_SUCCESS or error status returned by the first callback

--*/
{
    NTSTATUS                    Status = STATUS_SUCCESS;
    ULONG                       i;
    PEX_CALLBACK_ROUTINE_BLOCK  RoutineBlock;
    PCM_CALLBACK_CONTEXT_BLOCK  CmCallbackContext;

    PAGED_CODE();

    for(i=0;i<CM_MAX_CALLBACKS;i++) {
        RoutineBlock = ExReferenceCallBackBlock(&(CmpCallBackVector[i]) );
        if( RoutineBlock != NULL ) {
            //
            // we have a safe reference on this block.
            //
            //
            // record thread on a stack struct, so we don't need to allocate pool for it. We unlink
            // it from our lists prior to this function exit, so we are on the safe side.
            //
            CM_ACTIVE_NOTIFY_THREAD ActiveThreadInfo;
            
            //
            // get context info
            //
            CmCallbackContext = (PCM_CALLBACK_CONTEXT_BLOCK)ExGetCallBackBlockContext(RoutineBlock);
            ASSERT( CmCallbackContext != NULL );

            ActiveThreadInfo.Thread = PsGetCurrentThread();
#if DBG
            InitializeListHead(&(ActiveThreadInfo.ThreadList));   
#endif //DBG

            if( CmpCheckRecursionAndRecordThreadInfo(CmCallbackContext,&ActiveThreadInfo) ) {
                Status = ExGetCallBackBlockRoutine(RoutineBlock)(CmCallbackContext->CallerContext,(PVOID)(ULONG_PTR)Type,Argument);
                //
                // now that we're down, remove ourselves from the thread list
                //
                ExAcquireFastMutex(&(CmCallbackContext->ThreadListLock));
                RemoveEntryList(&(ActiveThreadInfo.ThreadList));
                ExReleaseFastMutex(&(CmCallbackContext->ThreadListLock));
            } else {
                ASSERT( IsListEmpty(&(ActiveThreadInfo.ThreadList)) );
            }

            ExDereferenceCallBackBlock (&(CmpCallBackVector[i]),RoutineBlock);

            if( !NT_SUCCESS(Status) ) {
                //
                // don't bother calling other callbacks if this one vetoed.
                //
                return Status;
            }
        }
    }
    return STATUS_SUCCESS;
}

VOID
CmpInitCallback(VOID)
/*++

Routine Description:

    Init the callback module

Arguments:



Return Value:


--*/
{
    ULONG   i;

    PAGED_CODE();
    
    CmpCallBackCount = 0;
    for( i=0;i<CM_MAX_CALLBACKS;i++) {
        ExInitializeCallBack (&(CmpCallBackVector[i]));
    }

/*
    {
        LARGE_INTEGER Cookie;
        if( NT_SUCCESS(CmRegisterCallback(CmpTestCallback,NULL,&Cookie) ) ) {
            DbgPrint("Test Hooks installed\n");
        }
    }
*/
}

BOOLEAN
CmpCheckRecursionAndRecordThreadInfo(
                                     PCM_CALLBACK_CONTEXT_BLOCK CallbackBlock,
                                     PCM_ACTIVE_NOTIFY_THREAD   ActiveThreadInfo
                                     )
/*++

Routine Description:

    Checks if current thread is already inside the callback (recursion avoidance)

Arguments:


Return Value:


--*/
{
    PLIST_ENTRY                 AnchorAddr;
    PCM_ACTIVE_NOTIFY_THREAD    CurrentThreadInfo;

    PAGED_CODE();

    ExAcquireFastMutex(&(CallbackBlock->ThreadListLock));

    //
	// walk the ActiveThreadList and see if we are already active
	//
	AnchorAddr = &(CallbackBlock->ThreadListHead);
	CurrentThreadInfo = (PCM_ACTIVE_NOTIFY_THREAD)(CallbackBlock->ThreadListHead.Flink);

	while ( CurrentThreadInfo != (PCM_ACTIVE_NOTIFY_THREAD)AnchorAddr ) {
		CurrentThreadInfo = CONTAINING_RECORD(
						                    CurrentThreadInfo,
						                    CM_ACTIVE_NOTIFY_THREAD,
						                    ThreadList
						                    );
		if( CurrentThreadInfo->Thread == ActiveThreadInfo->Thread ) {
			//
			// already there!
			//
            ExReleaseFastMutex(&(CallbackBlock->ThreadListLock));
            return FALSE;
		}
        //
        // skip to the next element
        //
        CurrentThreadInfo = (PCM_ACTIVE_NOTIFY_THREAD)(CurrentThreadInfo->ThreadList.Flink);
	}

    //
    // add this thread
    //
    InsertTailList(&(CallbackBlock->ThreadListHead), &(ActiveThreadInfo->ThreadList));
    ExReleaseFastMutex(&(CallbackBlock->ThreadListLock));
    return TRUE;
}

//
// test hook procedure
//

BOOLEAN CmpCallbackSpew = FALSE;

NTSTATUS CmpTestCallback(
    IN PVOID CallbackContext,
    IN PVOID Argument1,
    IN PVOID Argument2
    )
{
    REG_NOTIFY_CLASS Type;

    PAGED_CODE();
    
    UNREFERENCED_PARAMETER (CallbackContext);

    if( !CmpCallbackSpew ) return STATUS_SUCCESS;

    Type = (REG_NOTIFY_CLASS)(ULONG_PTR)Argument1;
    switch( Type ) {
    case RegNtPreDeleteKey:
        {
            PREG_DELETE_KEY_INFORMATION  pDelete = (PREG_DELETE_KEY_INFORMATION)Argument2;
            //
            // Code to handle NtDeleteKey
            //
            DbgPrint("Callback(NtDeleteKey) called, arg = %p\n",pDelete);
        }
        break;
    case RegNtPreSetValueKey:
        {
            PREG_SET_VALUE_KEY_INFORMATION  pSetValue = (PREG_SET_VALUE_KEY_INFORMATION)Argument2;
            //
            // Code to handle NtSetValueKey
            //
            DbgPrint("Callback(NtSetValueKey) called, arg = %p\n",pSetValue);
        }
        break;
    case RegNtPreDeleteValueKey:
        {
            PREG_DELETE_VALUE_KEY_INFORMATION  pDeteteValue = (PREG_DELETE_VALUE_KEY_INFORMATION)Argument2;
            //
            // Code to handle NtDeleteValueKey
            //
            DbgPrint("Callback(NtDeleteValueKey) called, arg = %p\n",pDeteteValue);
        }
        break;
    case RegNtPreSetInformationKey:
        {
            PREG_SET_INFORMATION_KEY_INFORMATION  pSetInfo = (PREG_SET_INFORMATION_KEY_INFORMATION)Argument2;
            //
            // Code to handle NtSetInformationKey
            //
            DbgPrint("Callback(NtSetInformationKey) called, arg = %p\n",pSetInfo);
        }
        break;
    default:
        DbgPrint("Callback(%lx) called, arg = %p - We don't handle this call\n",(ULONG)Type,Argument2);
        break;
    }
    
    return STATUS_SUCCESS;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmhvlist.c ===
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmhvlist.c

Abstract:

    Code to maintain registry node that lists where the roots of
    hives are and what files they map to.

Author:

    Bryan M. Willman (bryanwi) 14-May-1992

Revision History:

--*/

#include "cmp.h"

#define HIVE_LIST L"\\registry\\machine\\system\\currentcontrolset\\control\\hivelist"

extern PCMHIVE CmpMasterHive;

BOOLEAN
CmpGetHiveName(
    PCMHIVE         CmHive,
    PUNICODE_STRING HiveName
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpAddToHiveFileList)
#pragma alloc_text(PAGE,CmpRemoveFromHiveFileList)
#pragma alloc_text(PAGE,CmpGetHiveName)
#endif


NTSTATUS
CmpAddToHiveFileList(
    PCMHIVE CmHive
    )
/*++

Routine Description:

    Add Hive to list of hives and their files in
    \registry\machine\system\currentcontrolset\control\hivelist

Arguments:

    HivePath - path to root of hive (e.g. \registry\machine\system)

    CmHive - pointer to CM_HIVE structure for hive.

Return Value:

    ntstatus

--*/
{
//
//  PERFNOTE - allocate small instead of large buffers after
//           NtQueryObject is fixec - bryanwi 15may92
//
#define NAME_BUFFER_SIZE    512
    OBJECT_ATTRIBUTES   ObjectAttributes;
    HANDLE              KeyHandle;
    NTSTATUS            Status;
    PUCHAR              Buffer;
    ULONG               Length;
    PWSTR               FilePath;
    WCHAR               UnicodeNull=UNICODE_NULL;
    UNICODE_STRING      TempName;
    UNICODE_STRING      HivePath;

    //
    // create/open the hive list key
    //
    RtlInitUnicodeString(
        &TempName,
        HIVE_LIST
        );

    InitializeObjectAttributes(
        &ObjectAttributes,
        &TempName,
        OBJ_CASE_INSENSITIVE,
        (HANDLE)NULL,
        NULL
        );

    Status = ZwCreateKey(
                &KeyHandle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes,
                0,
                NULL,
                REG_OPTION_VOLATILE,
                NULL
                );

    if (!NT_SUCCESS(Status)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmpAddToHiveFileList: "));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"Create/Open of Hive list failed status = %08lx\n", Status));
        return Status;
    }

    //
    // allocate work buffers
    //
    Buffer = ExAllocatePool(PagedPool, NAME_BUFFER_SIZE + sizeof(WCHAR));
    if (Buffer == NULL) {
        NtClose(KeyHandle);
        return STATUS_NO_MEMORY;
    }

    //
    // compute name of hive
    //
    if (! CmpGetHiveName(CmHive, &HivePath)) {
        NtClose(KeyHandle);
        ExFreePool(Buffer);
        return STATUS_NO_MEMORY;
    }


    //
    // get name of file
    //
    if (!(CmHive->Hive.HiveFlags & HIVE_VOLATILE)) {
        Status = ZwQueryObject(
                    CmHive->FileHandles[HFILE_TYPE_PRIMARY],
                    ObjectNameInformation,
                    (PVOID)Buffer,
                    NAME_BUFFER_SIZE,
                    &Length
                    );
        Length -= sizeof(UNICODE_STRING);
        if (!NT_SUCCESS(Status)) {
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmpAddToHiveFileList: "));
            CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"Query of name2 failed status = %08lx\n", Status));
            NtClose(KeyHandle);
            ExFreePool(HivePath.Buffer);
            ExFreePool(Buffer);
            return  Status;
        }
        FilePath = ((POBJECT_NAME_INFORMATION)Buffer)->Name.Buffer;
        FilePath[Length/sizeof(WCHAR)] = UNICODE_NULL;
        Length+=sizeof(WCHAR);
    } else {
        FilePath = &UnicodeNull;
        Length = sizeof(UnicodeNull);
    }

    //
    // set entry in list
    //
    Status = ZwSetValueKey(
                KeyHandle,
                &HivePath,
                0,
                REG_SZ,
                FilePath,
                Length
                );
    if (!NT_SUCCESS(Status)) {
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"CmpAddToHiveFileList: "));
        CmKdPrintEx((DPFLTR_CONFIG_ID,CML_BUGCHECK,"Set of entry in Hive list failed status = %08lx\n", Status));
    }

    NtClose(KeyHandle);
    ExFreePool(HivePath.Buffer);
    ExFreePool(Buffer);
    return  Status;
}


VOID
CmpRemoveFromHiveFileList(
    PCMHIVE         CmHive
    )
/*++

Routine Description:

    Remove hive name from hive file list key

Arguments:

    CmHive - pointer to CM_HIVE structure for hive.

Return Value:

    ntstatus

--*/
{
    NTSTATUS        Status;
    UNICODE_STRING  EntryName;
    UNICODE_STRING  TempName;
    OBJECT_ATTRIBUTES   ObjectAttributes;
    HANDLE          KeyHandle;

    //
    // open the hive list key
    //
    RtlInitUnicodeString(
        &TempName,
        HIVE_LIST
        );

    InitializeObjectAttributes(
        &ObjectAttributes,
        &TempName,
        OBJ_CASE_INSENSITIVE,
        (HANDLE)NULL,
        NULL
        );

    Status = ZwOpenKey(
                &KeyHandle,
                KEY_READ | KEY_WRITE,
                &ObjectAttributes
                );

    if (!NT_SUCCESS(Status)) {
        return;
    }

    if( CmpGetHiveName(CmHive, &EntryName) ) {
        ZwDeleteValueKey(KeyHandle, &EntryName);
        ExFreePool(EntryName.Buffer);
    }

    NtClose(KeyHandle);

    return;
}


BOOLEAN
CmpGetHiveName(
    PCMHIVE         CmHive,
    PUNICODE_STRING HiveName
    )
/*++

Routine Description:

    Compute full path to a hive.

Arguments:

    CmHive - pointer to CmHive structure

    HiveName - supplies pointer to unicode string structure that
                 will be filled in with pointer to name.

                CALL IS EXPECTED TO FREE BUFFER

Return Value:

    TRUE = it worked, FALSE = it failed (memory)

--*/
{
    HCELL_INDEX     RootCell;
    HCELL_INDEX     LinkCell;
    PCM_KEY_NODE    LinkKey;
    PCM_KEY_NODE    LinkParent;
    SIZE_T          size;
    SIZE_T          rsize;
    ULONG           KeySize;
    ULONG           ParentSize;
    PWCHAR          p;
    PCM_KEY_NODE    EntryKey;

    //
    // First find the link cell.
    //
    RootCell = CmHive->Hive.BaseBlock->RootCell;
    EntryKey = (PCM_KEY_NODE)HvGetCell((PHHIVE)CmHive, RootCell);
    if( EntryKey == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return FALSE;
    }
    LinkCell = EntryKey->Parent;
    HvReleaseCell((PHHIVE)CmHive, RootCell);

    // for master we don't need to count cell usage
    ASSERT( ((PHHIVE)CmpMasterHive)->ReleaseCellRoutine == NULL );
    //
    // Compute the value entry name, which is of the form:
    //      \registry\<parent of link node name>\<link node name>
    //
    LinkKey = (PCM_KEY_NODE)HvGetCell((PHHIVE)CmpMasterHive, LinkCell);
    if( LinkKey == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return FALSE;
    }
    LinkParent = (PCM_KEY_NODE)HvGetCell(
                                (PHHIVE)CmpMasterHive,
                                LinkKey->Parent
                                );
    if( LinkParent == NULL ) {
        //
        // we couldn't map a view for the bin containing this cell
        //
        return FALSE;
    }
    rsize = wcslen(L"\\REGISTRY\\");

    KeySize = CmpHKeyNameLen(LinkKey);
    ParentSize = CmpHKeyNameLen(LinkParent);
    size = KeySize + ParentSize +
           (rsize * sizeof(WCHAR)) + sizeof(WCHAR);

    HiveName->Buffer = ExAllocatePool(PagedPool, size);
    if (HiveName->Buffer == NULL) {
        return FALSE;
    }

    HiveName->Length = (USHORT)size;
    HiveName->MaximumLength = (USHORT)size;
    p = HiveName->Buffer;

    RtlCopyMemory(
        (PVOID)p,
        (PVOID)L"\\REGISTRY\\",
        rsize * sizeof(WCHAR)
        );
    p += rsize;

    if (LinkParent->Flags & KEY_COMP_NAME) {
        CmpCopyCompressedName(p,
                              ParentSize,
                              LinkParent->Name,
                              LinkParent->NameLength);
    } else {
        RtlCopyMemory(
            (PVOID)p,
            (PVOID)&(LinkParent->Name[0]),
            ParentSize
            );
    }

    p += ParentSize / sizeof(WCHAR);

    *p = OBJ_NAME_PATH_SEPARATOR;
    p++;

    if (LinkKey->Flags & KEY_COMP_NAME) {
        CmpCopyCompressedName(p,
                              KeySize,
                              LinkKey->Name,
                              LinkKey->NameLength);

    } else {
        RtlCopyMemory(
            (PVOID)p,
            (PVOID)&(LinkKey->Name[0]),
            KeySize
            );
    }

    return TRUE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\config\cmindex.c ===
//depot/main/Base/ntos/config/cmindex.c#12 - integrate change 19035 (text)
/*++

Copyright (c) 1991  Microsoft Corporation

Module Name:

    cmindex.c

Abstract:

    This module contains cm routines that understand the structure
    of child subkey indicies.

Author:

    Bryan M. Willman (bryanwi) 21-Apr-92

Revision History:

--*/

/*

The Structure:

    Use a 1 or 2 level tree.  Leaf nodes are arrays of pointers to
    cells, sorted.  Binary search to find cell of interest.  Directory
    node (can be only one) is an array of pointers to leaf blocks.
    Do compare on last entry of each leaf block.

    One Level:

        Key--->+----+
               |    |
               |  x----------><key whose name is "apple", string in key>
               |    |
               +----+
               |    |
               |  x----------><as above, but key named "banana">
               |    |
               +----+
               |    |
               |    |
               |    |
               +----+
               |    |
               |    |
               |    |
               +----+
               |    |
               |  x----------><as above, but key named "zumwat">
               |    |
               +----+


    Two Level:

        Key--->+----+
               |    |    +-----+
               |  x----->|     |
               |    |    |  x----------------->"aaa"
               +----+    |     |
               |    |    +-----+
               |    |    |     |
               |    |    |     |
               +----+    |     |
               |    |    +-----+
               |    |    |     |
               |    |    |  x----------------->"abc"
               +----+    |     |
               |    |    +-----+
               |    |
               |    |
               +----+
               |    |    +-----+
               |  x----->|     |
               |    |    |  x----------------->"w"
               +----+    |     |
                         +-----+
                         |     |
                         |     |
                         |     |
                         +-----+
                         |     |
                         |  x----------------->"z"
                         |     |
                         +-----+


    Never more than two levels.

    Each block must fix in on HBLOCK_SIZE Cell.  Allows about 1000
    entries.  Max of 1 million total, best case.  Worst case something
    like 1/4 of that.

*/

#include    "cmp.h"

ULONG
CmpFindSubKeyInRoot(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    PUNICODE_STRING SearchName,
    PHCELL_INDEX    Child
    );

ULONG
CmpFindSubKeyInLeaf(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    PUNICODE_STRING SearchName,
    PHCELL_INDEX    Child
    );

LONG
CmpCompareInIndex(
    PHHIVE          Hive,
    PUNICODE_STRING SearchName,
    ULONG           Count,
    PCM_KEY_INDEX   Index,
    PHCELL_INDEX    Child
    );

LONG
CmpDoCompareKeyName(
    PHHIVE          Hive,
    PUNICODE_STRING SearchName,
    HCELL_INDEX     Cell
    );

HCELL_INDEX
CmpDoFindSubKeyByNumber(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    ULONG           Number
    );

HCELL_INDEX
CmpAddToLeaf(
    PHHIVE          Hive,
    HCELL_INDEX     LeafCell,
    HCELL_INDEX     NewKey,
    PUNICODE_STRING NewName
    );

HCELL_INDEX
CmpSelectLeaf(
    PHHIVE          Hive,
    PCM_KEY_NODE    ParentKey,
    PUNICODE_STRING NewName,
    HSTORAGE_TYPE   Type,
    PHCELL_INDEX    *RootPointer
    );

HCELL_INDEX
CmpSplitLeaf(
    PHHIVE          Hive,
    HCELL_INDEX     RootCell,
    ULONG           RootSelect,
    HSTORAGE_TYPE   Type
    );

HCELL_INDEX
CmpFindSubKeyByHash(
    PHHIVE                  Hive,
    PCM_KEY_FAST_INDEX      FastIndex,
    PUNICODE_STRING         SearchName
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,CmpFindSubKeyByName)
#pragma alloc_text(PAGE,CmpFindSubKeyInRoot)
#pragma alloc_text(PAGE,CmpFindSubKeyInLeaf)
#pragma alloc_text(PAGE,CmpDoCompareKeyName)
#pragma alloc_text(PAGE,CmpCompareInIndex)
#pragma alloc_text(PAGE,CmpFindSubKeyByNumber)
#pragma alloc_text(PAGE,CmpDoFindSubKeyByNumber)
#pragma alloc_text(PAGE,CmpAddSubKey)
#pragma alloc_text(PAGE,CmpAddToLeaf)
#pragma alloc_text(PAGE,CmpSelectLeaf)
#pragma alloc_text(PAGE,CmpSplitLeaf)
#pragma alloc_text(PAGE,CmpMarkIndexDirty)
#pragma alloc_text(PAGE,CmpRemoveSubKey)
#pragma alloc_text(PAGE,CmpComputeHashKey)
#pragma alloc_text(PAGE,CmpComputeHashKeyForCompressedName)
#pragma alloc_text(PAGE,CmpFindSubKeyByHash)

#ifdef NT_RENAME_KEY
#pragma alloc_text(PAGE,CmpDuplicateIndex)
#pragma alloc_text(PAGE,CmpUpdateParentForEachSon)
#endif //NT_RENAME_KEY

#pragma alloc_text(PAGE,CmpRemoveSubKeyCellNoCellRef)
#endif


HCELL_INDEX
CmpFindSubKeyByName(
    PHHIVE          Hive,
    PCM_KEY_NODE    Parent,
    PUNICODE_STRING SearchName
    )
/*++

Routine Description:

    Find the child cell (either subkey or value) specified by name.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Parent - cell of key body which is parent of child of interest

    SearchName - name of child of interest

Return Value:

    Cell of matching child key, or HCELL_NIL if none.

--*/
{
    PCM_KEY_INDEX   IndexRoot;
    HCELL_INDEX     Child;
    ULONG           i;
    ULONG           FoundIndex;
    HCELL_INDEX     CellToRelease = HCELL_NIL;

#ifndef _CM_LDR_
    PAGED_CODE();
#endif //_CM_LDR_

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpFindSubKeyByName:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p Parent=%p SearchName=%p\n", Hive, Parent, SearchName));

    //
    // Try first the Stable, then the Volatile store.  Assumes that
    // all Volatile refs in Stable space are zeroed out at boot.
    //
    for (i = 0; i < Hive->StorageTypeCount; i++) {
        if (Parent->SubKeyCounts[i] != 0) {
            IndexRoot = (PCM_KEY_INDEX)HvGetCell(Hive, Parent->SubKeyLists[i]);
            ASSERT( (IndexRoot == NULL) || HvIsCellAllocated(Hive, Parent->SubKeyLists[i]) );
            if( IndexRoot == NULL ) {
                //
                // we couldn't map a view for the bin containing this cell
                //
                return HCELL_NIL;
            }
            CellToRelease = Parent->SubKeyLists[i];

            if (IndexRoot->Signature == CM_KEY_INDEX_ROOT) {
                if( INVALID_INDEX & CmpFindSubKeyInRoot(Hive, IndexRoot, SearchName, &Child) ) {
                    //
                    // couldn't map view inside
                    //
                    ASSERT( CellToRelease != HCELL_NIL );
                    HvReleaseCell(Hive,CellToRelease);
                    return HCELL_NIL;
                }

                ASSERT( CellToRelease != HCELL_NIL );
                HvReleaseCell(Hive,CellToRelease);

                if (Child == HCELL_NIL) {
                    continue;
                }
                IndexRoot = (PCM_KEY_INDEX)HvGetCell(Hive, Child);
                if( IndexRoot == NULL ) {
                    //
                    // we couldn't map a view for the bin containing this cell
                    //
                    return HCELL_NIL;
                }
                CellToRelease = Child;
            }
            ASSERT((IndexRoot->Signature == CM_KEY_INDEX_LEAF)  ||
                   (IndexRoot->Signature == CM_KEY_FAST_LEAF)   ||
                   (IndexRoot->Signature == CM_KEY_HASH_LEAF)
                   );


            if( IndexRoot->Signature == CM_KEY_HASH_LEAF ) {
                Child = CmpFindSubKeyByHash(Hive,(PCM_KEY_FAST_INDEX)IndexRoot,SearchName);
                ASSERT( CellToRelease != HCELL_NIL );
                HvReleaseCell(Hive,CellToRelease);
            } else {
                FoundIndex = CmpFindSubKeyInLeaf(Hive,
                                                 IndexRoot,
                                                 SearchName,
                                                 &Child);

                ASSERT( CellToRelease != HCELL_NIL );
                HvReleaseCell(Hive,CellToRelease);

                if( INVALID_INDEX & FoundIndex ) {
                    //
                    // couldn't map view
                    // 
                    return HCELL_NIL;
                }
            }

            if (Child != HCELL_NIL) {
                //
                // success
                //
                return Child;
            }
        }
    }
#if 0 //DBG
	//
	// Validation code. manually search for the key and break when found
	//
	if (Parent->SubKeyCounts[Stable] != 0) {
		ULONG			Cnt1,Cnt2;
		LONG			Result;
		HCELL_INDEX		Cell;
		PCM_KEY_INDEX   Leaf;
		PCM_KEY_INDEX   DbgIndexRoot = (PCM_KEY_INDEX)HvGetCell(Hive, Parent->SubKeyLists[Stable]);

		if(DbgIndexRoot->Signature == CM_KEY_INDEX_ROOT ) {
			for(Cnt1=0;Cnt1<DbgIndexRoot->Count;Cnt1++) {
				Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, DbgIndexRoot->List[Cnt1]);			
				for( Cnt2=0;Cnt2<Leaf->Count;Cnt2++) {
					Result = CmpCompareInIndex(	Hive,
												SearchName,
												Cnt2,
												Leaf,
												&Cell);

					if( Result == 0 ) {
						//
						// Found it !!! Error above !!!
						//
						DbgPrint("CmpFindSubKeyByName: Hive = %p, Parent = %p, SearchName = %p\n",Hive,Parent,SearchName);
						DbgPrint("                   : IndexRoot = %p, DbgIndexRoot = %p, Cnt1 = %lx, Cnt2 = %lx\n",IndexRoot,DbgIndexRoot,Cnt1,Cnt2);
						DbgPrint("                   : Leaf = %p\n",Leaf);

						DbgBreakPoint();

					}
					
				}
                HvReleaseCell(Hive,DbgIndexRoot->List[Cnt1]);
			}
		}
		HvReleaseCell(Hive,Parent->SubKeyLists[Stable]);
	}

#endif //0

    return HCELL_NIL;
}


ULONG
CmpFindSubKeyInRoot(
    PHHIVE          Hive,
    PCM_KEY_INDEX   Index,
    PUNICODE_STRING SearchName,
    PHCELL_INDEX    Child
    )
/*++

Routine Description:

    Find the leaf index that would contain a key, if there is one.

Arguments:

    Hive - pointer to hive control structure for hive of interest

    Index - pointer to root index block

    SearchName - pointer to name of key of interest

    Child - pointer to variable to receive hcell_index of found leaf index
            block, HCELL_NIL if none.  Non nil does not necessarily mean
            the key is present, call FindSubKeyInLeaf to decide that.

Return Value:

    Index in List of last Leaf Cell entry examined.  If Child != HCELL_NIL,
    Index is entry that matched, else, index is for last entry we looked
    at.  (Target Leaf will be this value plus or minus 1)

    If an error appears while searching the subkey (i.e. a cell cannot be 
    mapped into memory) INVALID_INDEX is returned.

--*/
{
    ULONG           High;
    ULONG           Low;
    ULONG           CanCount;
    HCELL_INDEX     LeafCell;
    PCM_KEY_INDEX   Leaf;
    LONG            Result;
    ULONG           ReturnIndex = INVALID_INDEX;

    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"CmpFindSubKeyInRoot:\n\t"));
    CmKdPrintEx((DPFLTR_CONFIG_ID,CML_INDEX,"Hive=%p Index=%p SearchName=%p\n",Hive,Index,SearchName));


    ASSERT(Index->Count != 0);
    ASSERT(Index->Signature == CM_KEY_INDEX_ROOT);

    High = Index->Count - 1;
    Low = 0;

    while (TRUE) {

        //
        // Compute where to look next, get correct pointer, do compare
        //
        CanCount = ((High-Low)/2)+Low;
        LeafCell = Index->List[CanCount];
        Leaf = (PCM_KEY_INDEX)HvGetCell(Hive, LeafCell);
        if( Leaf == NULL ) {
            //
            // we couldn't map the bin containing this cell
            //
            *Child = HCELL_NIL;
            ReturnIndex = INVALID_INDEX;
            goto JustReturn;
        }

        ASSERT((Leaf->Signature == CM_KEY_INDEX_LEAF) ||
               (Leaf->Signature == CM_KEY_FAST_LEAF)  || 
               (Leaf->Signature == CM_KEY_HASH_LEAF)
               );
        ASSERT(Leaf->Count != 0);

        Result = CmpCompareInIndex(Hive,
                                   SearchName,
                                   Leaf->Count-1,
                                   Leaf,
                                   Child);

        if( Result == 2 ) {
            //
            // couldn't map view inside; bail out
            //
            *Child = HCELL_NIL;
            ReturnIndex = INVALID_INDEX;
            goto JustReturn;
        }
        if (Result == 0) {

            //
            // SearchName == KeyName of last key in leaf, so
            //  this is our leaf
            //
            *Child = LeafCell;
            ReturnIndex = CanCount;
            goto JustReturn;
        }

        if (Result < 0) {

            ASSERT( Result == -1 );
            //
            // SearchName < KeyName, so this may still be our leaf
            //
            Result = CmpCompareInIndex(Hive,
                                       SearchName,
                                       0,
                                       Leaf,
                                       Child);

            if( Result == 2 ) {
                //
                // couldn't map view inside; bail out
                //
                *Child = HCELL_NIL;
                ReturnIndex = INVALID_INDEX;
                goto JustReturn;
            }

            if (Result >= 0) {

                ASSERT( (Result == 1) || (Result == 0) );
                //
                // we know from above that SearchName is less than
                // last key in leaf.
                // since it is also >= first key in leaf, it must
                // reside in leaf somewhere, and we are done
                //
                *Child = LeafCell;
                ReturnIndex = CanCount;
                goto JustReturn;
            }

            High = CanCount;

        } else {

            //
            // SearchName > KeyName
            //
            Low = CanCount;
        }

        if ((High - Low) <= 1) {
            break;
        }
        HvReleaseCell(Hive, LeafCell);
    }

    HvReleaseCell(Hive, LeafCell);
    //
    // If we get here, High - Low = 1 or High == Low
    //
    ASSERT((High - Low == 1) || (High == Low));
    LeafCell = Index->List[Low];
    Leaf = (PCM_KEY_INDEX