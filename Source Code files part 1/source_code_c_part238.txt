// We may be able to throw away op1 (unless it has side-effects)

                if ((op1->gtFlags & GTF_SIDE_EFFECT) == 0)
                {
                    DEBUG_DESTROY_NODE(op1);
                    DEBUG_DESTROY_NODE(tree);
                    return op2; // Just return the "0" node
                }

                // We need to keep op1 for the side-effects. Hang it off
                // a GT_COMMA node

                tree->ChangeOper(GT_COMMA);
                return tree;
            }
            else if (mult == 1)
            {
                DEBUG_DESTROY_NODE(op2);
                DEBUG_DESTROY_NODE(tree);
                return op1;
            }

            if (tree->gtOverflow())
                break;

            /* Is the multiplier a power of 2 ? */

            if  (mult == genFindLowestBit(mult))
            {
                /* Change the multiplication into a shift by log2(val) bits */

                op2->gtIntCon.gtIconVal = genLog2(mult) - 1;

                tree->gtOper = oper = GT_LSH;
                goto DONE_MORPHING_CHILDREN;
            }
        }

        break;

    case GT_NOT:
    case GT_NEG:
    case GT_CHS:

        /* Any constant cases should have been folded earlier */
        assert(!op1->OperIsConst());
        break;

#if!LONG_MATH_REGPARAM

    case GT_DIV:

        if  (typ == TYP_LONG)
        {
            tree = fgMorphLongBinop(tree, CPX_LONG_DIV);
            return tree;
        }

#if TGT_IA64

        if  (varTypeIsFloating(typ))
            return  fgMorphFltBinop(tree, (typ == TYP_FLOAT) ? CPX_R4_DIV
                                                             : CPX_R8_DIV);

#endif

#ifdef  USE_HELPERS_FOR_INT_DIV
        if  (typ == TYP_INT)
        {
            tree = fgMorphIntoHelperCall (tree,
                                          CPX_I4_DIV,
                                          gtNewArgList(op1, op2));
            return tree;
        }
#endif

        break;

    case GT_UDIV:

        if  (typ == TYP_LONG)
        {
            tree = fgMorphLongBinop(tree, CPX_LONG_UDIV);
            return tree;
        }

#ifdef  USE_HELPERS_FOR_INT_DIV

        if  (typ == TYP_INT)
        {
            tree = fgMorphIntoHelperCall (tree,
                                          CPX_U4_DIV,
                                          gtNewArgList(op1, op2));
            return tree;
        }

#endif

        break;

#endif

    case GT_MOD:

        if  (typ == TYP_DOUBLE ||
             typ == TYP_FLOAT)
        {
#if     USE_FASTCALL
            tree = fgMorphIntoHelperCall(tree,
                                         (typ == TYP_FLOAT) ? CPX_FLT_REM
                                                            : CPX_DBL_REM,
                                         gtNewArgList(op1, op2));
#else
            tree->gtOp.gtOp1 = op1 = fgMorphTree(op1);
            fgPtrArgCntCur += genTypeStSz(typ);

            tree->gtOp.gtOp2 = op2 = fgMorphTree(op2);
            fgPtrArgCntCur += genTypeStSz(typ);

            if  (fgPtrArgCntMax < fgPtrArgCntCur)
                fgPtrArgCntMax = fgPtrArgCntCur;

            tree = fgMorphIntoHelperCall(tree,
                                         (typ == TYP_FLOAT) ? CPX_FLT_REM
                                                            : CPX_DBL_REM,
                                         gtNewArgList(op1, op2));

            fgPtrArgCntCur -= 2*genTypeStSz(typ);
#endif
            return tree;
        }

        // fall-through

    case GT_UMOD:

#if !   LONG_MATH_REGPARAM

        if  (typ == TYP_LONG)
        {
            int         helper = CPX_LONG_MOD;

            if  (oper == GT_UMOD)
                helper = CPX_LONG_UMOD;

            tree = fgMorphLongBinop(tree, helper);
            return tree;
        }

#endif

#ifdef  USE_HELPERS_FOR_INT_DIV

        if  (typ == TYP_INT)
        {
            int         helper = CPX_I4_MOD;

            if  (oper == GT_UMOD)
                helper = CPX_U4_MOD;

            tree = fgMorphIntoHelperCall (tree,
                                          helper,
                                          gtNewArgList(op1, op2));
            return tree;
        }

#endif

        break;

    case GT_ASG_LSH:
    case GT_ASG_RSH:
    case GT_ASG_RSZ:

#if     TGT_SH3
        assert(!"not supported for now");
#endif

    case GT_RSH:
    case GT_RSZ:

#if     TGT_SH3

        /* Flip the sign on the shift count */

        tree->gtFlags |= GTF_SHF_NEGCNT;

        if  (op2->gtOper == GT_CNS_INT)
        {
            op2->gtIntCon.gtIconVal = -op2->gtIntCon.gtIconVal;
        }
        else
        {
            tree->gtOp.gtOp2 = op2 = gtNewOperNode(GT_NEG, TYP_INT, op2);
        }

        // Fall trough ...

#endif

    case GT_LSH:

        /* Don't bother with any narrowing casts on the shift count */

        if  (op2->gtOper == GT_CAST && !op2->gtOverflow())
        {
            /* The second sub-operand of the cast gives the type */

            assert(op2->gtOp.gtOp2->gtOper == GT_CNS_INT);

            if  (op2->gtOp.gtOp2->gtIntCon.gtIconVal < TYP_INT)
            {
                GenTreePtr      shf = op2->gtOp.gtOp1;

                if  (shf->gtType <= TYP_UINT)
                {
                    /* Cast of another int - just dump it */

                    tree->gtOp.gtOp2 = shf;
                }
                else
                {
                    /* Cast to 'int' is just as good and cheaper */

                    op2->gtOp.gtOp2->gtIntCon.gtIconVal = TYP_INT;
                }
            }
        }
        break;

    case GT_RETURN:

        if  (op1)
        {

#if     RET_64BIT_AS_STRUCTS

            /* Are we returning long/double as a struct? */

#ifdef  DEBUG
            bool        bashed = false;
#endif

            if  (fgRetArgUse)
            {
                GenTreePtr      ret;
                var_types       typ = tree->TypeGet();
                var_types       rvt = TYP_REF;

                // ISSUE: The retval arg is not (always) a GC ref!!!!!!!

#ifdef  DEBUG
                bashed = true;
#endif

                /* Convert "op1" to "*retarg = op1 , retarg" */

                ret = gtNewOperNode(GT_IND,
                                    typ,
                                    gtNewLclvNode(fgRetArgNum, rvt));

                ret = gtNewOperNode(GT_ASG, typ, ret, op1);
                ret->gtFlags |= GTF_ASG;

                op1 = gtNewOperNode(GT_COMMA,
                                    rvt,
                                    ret,
                                    gtNewLclvNode(fgRetArgNum, rvt));

                /* Update the return value and type */

                tree->gtOp.gtOp1 = op1;
                tree->gtType     = rvt;
            }

//              printf("Return expr:\n"); gtDispTree(op1);

#endif

#if!TGT_RISC
            if  (compCurBB == genReturnBB)
            {
                /* This is the 'monitorExit' call at the exit label */

                assert(op1->gtType == TYP_VOID);
                assert(op2 == 0);

#if USE_FASTCALL

                tree->gtOp.gtOp1 = op1 = fgMorphTree(op1);

#else

                /* We'll push/pop the return value around the call */

                fgPtrArgCntCur += genTypeStSz(info.compRetType);
                tree->gtOp.gtOp1 = op1 = fgMorphTree(op1);
                fgPtrArgCntCur -= genTypeStSz(info.compRetType);

#endif

                return tree;
            }
#endif

            /* This is a (real) return value -- check its type */

            if (genActualType(op1->TypeGet()) != genActualType(info.compRetType))
            {
                bool allowMismatch = false;

                // Allow TYP_BYREF to be returned as TYP_I_IMPL and vice versa
                if ((info.compRetType == TYP_BYREF &&
                     genActualType(op1->TypeGet()) == TYP_I_IMPL) ||
                    (op1->TypeGet() == TYP_BYREF &&
                     genActualType(info.compRetType) == TYP_I_IMPL))
                    allowMismatch = true;

                if (!allowMismatch)
#if     RET_64BIT_AS_STRUCTS
                    if  (!bashed)
#endif
                        NO_WAY("Return type mismatch");
            }

        }

#if     TGT_RISC

        /* Are we adding a "monitorExit" call to the exit sequence? */

        if  (genMonExitExp)
        {
            /* Is there exactly one return? */

            if  (genReturnCnt == 1)
            {
                /* Can we avoid storing the return value in a temp? */

                if  (!(op1->gtFlags & GTF_GLOB_EFFECT))
                {
                    /* Use "monExit , retval" for the return expression */

                    tree->gtOp.gtOp1 = op1 = gtNewOperNode(GT_COMMA,
                                                           op1->gtType,
                                                           genMonExitExp,
                                                           op1);

                    /* We're done with this monitorExit business */

                    genMonExitExp = NULL;

                    /* Don't forget to morph the entire expression */

                    tree->gtOp.gtOp1 = op1 = fgMorphTree(op1);
                    return tree;
                }
            }

            /* Keep track of how many return statements we've seen */

            genReturnLtm--;
        }

#endif

        break;

    case GT_ADDR:

        /* If we take the address of a local var, we don't need to insert cast */
        if (tree->gtOp.gtOp1->OperGet() == GT_LCL_VAR)
        {
            tree->gtOp.gtOp1 = fgMorphLocalVar(tree->gtOp.gtOp1, false);
            return tree;
        }
        break;


    case GT_CKFINITE:

        assert(varTypeIsFloating(op1->TypeGet()));

        fgAddCodeRef(compCurBB, compCurBB->bbTryIndex, ACK_ARITH_EXCPN, fgPtrArgCntCur);
        break;
    }


#if!CPU_HAS_FP_SUPPORT

    /*
        We have to use helper calls for all FP operations:

            FP operators that operate on FP values
            casts to and from FP
            comparisons of FP values
     */

    if  (varTypeIsFloating(typ) || (op1 && varTypeIsFloating(op1->TypeGet())))
    {
        int         helper;
        GenTreePtr  args;
        size_t      argc = genTypeStSz(typ);

        /* Not all FP operations need helper calls */

        switch (oper)
        {
        case GT_ASG:
        case GT_IND:
        case GT_LIST:
        case GT_ADDR:
        case GT_COMMA:
            goto NOT_FPH;
        }

#ifdef  DEBUG

        /* If the result isn't FP, it better be a compare or cast */

        if  (!(varTypeIsFloating(typ) ||
               tree->OperIsCompare()  || oper == GT_CAST))
            gtDispTree(tree);
        assert(varTypeIsFloating(typ) ||
               tree->OperIsCompare()  || oper == GT_CAST);
#endif

        /* Keep track of how many arguments we're passing */

        fgPtrArgCntCur += argc;

        /* Is this a binary operator? */

        if  (op2)
        {
            /* Add the second operand to the argument count */

            fgPtrArgCntCur += argc; argc *= 2;

            /* What kind of an operator do we have? */

            switch (oper)
            {
            case GT_ADD: helper = CPX_R4_ADD; break;
            case GT_SUB: helper = CPX_R4_SUB; break;
            case GT_MUL: helper = CPX_R4_MUL; break;
            case GT_DIV: helper = CPX_R4_DIV; break;
//              case GT_MOD: helper = CPX_R4_REM; break;

            case GT_EQ : helper = CPX_R4_EQ ; break;
            case GT_NE : helper = CPX_R4_NE ; break;
            case GT_LT : helper = CPX_R4_LT ; break;
            case GT_LE : helper = CPX_R4_LE ; break;
            case GT_GE : helper = CPX_R4_GE ; break;
            case GT_GT : helper = CPX_R4_GT ; break;

            default:
#ifdef  DEBUG
                gtDispTree(tree);
#endif
                assert(!"unexpected FP binary op");
                break;
            }

            args = gtNewArgList(tree->gtOp.gtOp2, tree->gtOp.gtOp1);
        }
        else
        {
            switch (oper)
            {
            case GT_RETURN:
                return tree;

            case GT_CAST:
                assert(!"FP cast");

            case GT_NEG: helper = CPX_R4_NEG; break;

            default:
#ifdef  DEBUG
                gtDispTree(tree);
#endif
                assert(!"unexpected FP unary op");
                break;
            }

            args = gtNewArgList(tree->gtOp.gtOp1);
        }

        /* If we have double result/operands, modify the helper */

        if  (typ == TYP_DOUBLE)
        {
            assert(CPX_R4_NEG+1 == CPX_R8_NEG);
            assert(CPX_R4_ADD+1 == CPX_R8_ADD);
            assert(CPX_R4_SUB+1 == CPX_R8_SUB);
            assert(CPX_R4_MUL+1 == CPX_R8_MUL);
            assert(CPX_R4_DIV+1 == CPX_R8_DIV);

            helper++;
        }
        else
        {
            assert(tree->OperIsCompare());

            assert(CPX_R4_EQ+1 == CPX_R8_EQ);
            assert(CPX_R4_NE+1 == CPX_R8_NE);
            assert(CPX_R4_LT+1 == CPX_R8_LT);
            assert(CPX_R4_LE+1 == CPX_R8_LE);
            assert(CPX_R4_GE+1 == CPX_R8_GE);
            assert(CPX_R4_GT+1 == CPX_R8_GT);
        }

        tree = fgMorphIntoHelperCall(tree, helper, args);

        if  (fgPtrArgCntMax < fgPtrArgCntCur)
            fgPtrArgCntMax = fgPtrArgCntCur;

        fgPtrArgCntCur -= argc;
        return tree;
    }

NOT_FPH:

#endif

    /*-------------------------------------------------------------------------
     * Optional morphing is done if tree transformations is permitted
     */

    if  ((opts.compFlags & CLFLG_TREETRANS) == 0)
        return tree;

    if  (GenTree::OperIsCommutative(oper))
    {
        /* Swap the operands so that the more expensive one is 'op1' */

        if  (tree->gtFlags & GTF_REVERSE_OPS)
        {
            tree->gtOp.gtOp1 = op2;
            tree->gtOp.gtOp2 = op1;

            op2 = op1;
            op1 = tree->gtOp.gtOp1;

            tree->gtFlags &= ~GTF_REVERSE_OPS;
        }

        if (oper == op2->gtOper)
        {
            /*  Reorder nested operators at the same precedence level to be
                left-recursive. For example, change "(a+(b+c))" to the
                equivalent expression "((a+b)+c)".
             */

            /* Things are handled differently for floating-point operators */

            if  (varTypeIsFloating(tree->TypeGet()))
            {
                /* Are we supposed to preserve float operand order? */

                if  (!genOrder)
                {
                    // CONSIDER: reorder operands if profitable (floats are
                    // CONSIDER: from integers, BTW)
                }
            }
            else
            {
                fgMoveOpsLeft(tree);
                op1 = tree->gtOp.gtOp1;
                op2 = tree->gtOp.gtOp2;
            }
        }

    }

#if REARRANGE_ADDS

    /* Change "((x+icon)+y)" to "((x+y)+icon)" if we have two (or more)
       '+' nodes. Ignore floating-point operation? */

    if  (oper        == GT_ADD && !tree->gtOverflow() &&
         op1->gtOper == GT_ADD && ! op1->gtOverflow() &&
         !varTypeIsFloating(typ))
    {
        GenTreePtr      ad1 = op1->gtOp.gtOp1;
        GenTreePtr      ad2 = op1->gtOp.gtOp2;

        if  (op2->OperIsConst() == 0 &&
             ad2->OperIsConst() != 0)
        {
            tree->gtOp.gtOp2 = ad2;
            op1 ->gtOp.gtOp2 = op2;

            // Change the flags

            // Make sure we arent throwing away any flags
            assert((op1->gtFlags & ~(GTF_PRESERVE|GTF_GLOB_EFFECT)) == 0);
            op1->gtFlags     = (op1->gtFlags & GTF_PRESERVE)    |
                               (ad1->gtFlags & GTF_GLOB_EFFECT) |
                               (op2->gtFlags & GTF_GLOB_EFFECT);

            ad2 = op2;
            op2 = tree->gtOp.gtOp2;
        }
    }

#endif

    /*-------------------------------------------------------------------------
     * Perform optional oper-specific postorder morphing
     */

    switch (oper)
    {
        genTreeOps      cmop;

    case GT_ASG:

        /* We'll convert "a = a <op> x" into "a <op>= x" */

#if !LONG_ASG_OPS
        if  (typ == TYP_LONG)
            break;
#endif

        /* Make sure we're allowed to do this */

        if  (op2->gtFlags & GTF_ASG)
            break;

        if  (op2->gtFlags & GTF_CALL)
        {
            if  (op1->gtFlags & GTF_GLOB_EFFECT)
                break;
        }

        /* Special case: a cast that can be thrown away */

        if  (op1->gtOper == GT_IND  &&
             op2->gtOper == GT_CAST &&
             !op2->gtOverflow()      )
        {
            var_types       srct;
            var_types       cast;
            var_types       dstt;

            /* The cast's 'op2' yields the 'real' type */

            assert(op2->gtOp.gtOp2);
            assert(op2->gtOp.gtOp2->gtOper == GT_CNS_INT);

            srct = (var_types)op2->gtOp.gtOp1->gtType;
            cast = (var_types)op2->gtOp.gtOp2->gtIntCon.gtIconVal;
            dstt = (var_types)op1->gtType;

            /* Make sure these are all ints and precision is not lost */

            if  (cast >= dstt && dstt <= TYP_INT && srct <= TYP_INT)
                op2 = tree->gtOp.gtOp2 = op2->gtOp.gtOp1;
        }

        cmop = op2->OperGet();

        /* Make sure we have the operator range right */

        assert(GT_SUB == GT_ADD + 1);
        assert(GT_MUL == GT_ADD + 2);
        assert(GT_DIV == GT_ADD + 3);
        assert(GT_MOD == GT_ADD + 4);
        assert(GT_UDIV== GT_ADD + 5);
        assert(GT_UMOD== GT_ADD + 6);

        assert(GT_OR  == GT_ADD + 7);
        assert(GT_XOR == GT_ADD + 8);
        assert(GT_AND == GT_ADD + 9);

        assert(GT_LSH == GT_ADD + 10);
        assert(GT_RSH == GT_ADD + 11);
        assert(GT_RSZ == GT_ADD + 12);

        /* Check for a suitable operator on the RHS */

        switch (cmop)
        {
        case GT_NEG:
            if  ( varTypeIsFloating(tree->TypeGet()))
                break;

#if TGT_IA64
            break;
#else
            goto ASG_OP;
#endif

        case GT_MUL:
            if  (!varTypeIsFloating(tree->TypeGet()))
                break;

            // Fall through

        case GT_ADD:
        case GT_SUB:
            if (op2->gtOverflow())
            {
                /* Disable folding into "<op>=" if the result can be
                   visible to anyone as <op> may throw an exception and
                   the assignment should not proceed
                   We are safe only with local variables
                 */
                if (compCurBB->bbTryIndex || (op1->gtOper != GT_LCL_VAR))
                    break;

#if TGT_x86
                /* This is hard for byte-operations as we need to make
                   sure both operands are in RBM_BYTE_REGS
                 */
                if (genTypeSize(op2->TypeGet()) == sizeof(char))
                    break;
#endif
            }
            goto ASG_OP;

        case GT_DIV:
        case GT_UDIV:
            if  (!varTypeIsFloating(tree->TypeGet()))
                break;

        case GT_LSH:
        case GT_RSH:
        case GT_RSZ:

#if LONG_ASG_OPS

            if  (typ == TYP_LONG)
                break;
#endif

        case GT_OR:
        case GT_XOR:
        case GT_AND:

#if LONG_ASG_OPS

            /* UNDONE: allow non-const long assignment operators */

            if  (typ == TYP_LONG && op2->gtOp.gtOp2->gtOper != GT_CNS_LNG)
                break;
#endif

        ASG_OP:

            /* Is the destination identical to the first RHS sub-operand? */

            if  (GenTree::Compare(op1, op2->gtOp.gtOp1))
            {
                /* Special case: "x |= -1" and "x &= 0" */

                if  (cmop == GT_AND || cmop == GT_OR)
                {
                    if  (op2->gtOp.gtOp2->gtOper == GT_CNS_INT)
                    {
                        long        icon = op2->gtOp.gtOp2->gtIntCon.gtIconVal;

                        assert(typ <= TYP_UINT);

                        if  ((cmop == GT_AND && icon == 0) ||
                             (cmop == GT_OR  && icon == -1))
                        {
                            /* Simply change to an assignment */

                            tree->gtOp.gtOp2 = op2->gtOp.gtOp2;
                            break;
                        }
                    }
                }

#if!TGT_IA64

                if  (cmop == GT_NEG)
                {
                    /* This is "x = -x;", use the flipsign operator */

                    tree->gtOper     = GT_CHS;
                    tree->gtOp.gtOp2 = gtNewIconNode(0);

                    goto ASGCO;
                }

#endif

            ASGOP:

                /* Replace with an assignment operator */

                assert(GT_ADD - GT_ADD == GT_ASG_ADD - GT_ASG_ADD);
                assert(GT_SUB - GT_ADD == GT_ASG_SUB - GT_ASG_ADD);
                assert(GT_OR  - GT_ADD == GT_ASG_OR  - GT_ASG_ADD);
                assert(GT_XOR - GT_ADD == GT_ASG_XOR - GT_ASG_ADD);
                assert(GT_AND - GT_ADD == GT_ASG_AND - GT_ASG_ADD);
                assert(GT_LSH - GT_ADD == GT_ASG_LSH - GT_ASG_ADD);
                assert(GT_RSH - GT_ADD == GT_ASG_RSH - GT_ASG_ADD);
                assert(GT_RSZ - GT_ADD == GT_ASG_RSZ - GT_ASG_ADD);

                tree->gtOper = (genTreeOps)(cmop - GT_ADD + GT_ASG_ADD);

                tree->gtOp.gtOp2 = op2->gtOp.gtOp2;

                /* Propagate GTF_OVERFLOW */

                if (op2->gtOverflowEx())
                {
                    tree->gtType   =  op2->gtType;
                    tree->gtFlags |= (op2->gtFlags &
                                     (GTF_OVERFLOW|GTF_EXCEPT|GTF_UNSIGNED));
                }

            ASGCO:

                /* The target is used as well as being defined */

                if  (op1->gtOper == GT_LCL_VAR)
                    op1->gtFlags |= GTF_VAR_USE;

#if CPU_HAS_FP_SUPPORT

                /* Check for the special case "x += y * x;" */

                op2 = tree->gtOp.gtOp2;

                /* For now we only support "*=" for FP values ... */

                if  (op2->gtOper == GT_MUL && varTypeIsFloating(tree->TypeGet()))
                {
                    if      (GenTree::Compare(op1, op2->gtOp.gtOp1))
                    {
                        /* Change "x += x * y" into "x *= (y + 1)" */

                        op2 = op2->gtOp.gtOp2;
                    }
                    else if (GenTree::Compare(op1, op2->gtOp.gtOp2))
                    {
                        /* Change "x += y * x" into "x *= (y + 1)" */

                        op2 = op2->gtOp.gtOp1;
                    }
                    else
                        break;

                    /* Create the "y + 1" node */

                    if  (tree->gtType == TYP_FLOAT)
                    {
                        op1 = gtNewFconNode(1);
                    }
                    else
                    {
                        double  one = 1;
                        op1 = gtNewDconNode(&one);
                    }

                    /* Now make the "*=" node */

                    tree->gtOp.gtOp2 = gtNewOperNode(GT_ADD,
                                                     tree->TypeGet(),
                                                     op2,
                                                     op1);

                    tree->gtOper = GT_ASG_MUL;
                }

#endif

            }

            break;

        case GT_NOT:

            /* Is the destination identical to the first RHS sub-operand? */

            if  (GenTree::Compare(op1, op2->gtOp.gtOp1))
            {
                /* This is "x = ~x" which is the same as "x ^= -1"
                 * Transform the node into a GT_ASG_XOR */

                assert(genActualType(typ) == TYP_INT ||
                       genActualType(typ) == TYP_LONG);

                static __int64 minus1 = -1;

                op2->gtOp.gtOp2 = (genActualType(typ) == TYP_INT)
                                    ? gtNewIconNode(-1)
                                    : gtNewLconNode(&minus1);

                cmop = GT_XOR;
                goto ASGOP;
            }

            break;
        }

        break;

    case GT_MUL:

        /* Check for the case "(val + icon) * icon" */

        if  (op2->gtOper == GT_CNS_INT &&
             op1->gtOper == GT_ADD)
        {
            GenTreePtr  add = op1->gtOp.gtOp2;

            if  (add->gtOper == GT_CNS_INT && op2->IsScaleIndexMul())
            {
                if (tree->gtOverflow() || op1->gtOverflow())
                    break;

                long        imul = op2->gtIntCon.gtIconVal;
                long        iadd = add->gtIntCon.gtIconVal;

                /* Change '(val+icon1)*icon2' -> '(val*icon2)+(icon1*icon2)' */

                tree->gtOper =
                oper         = GT_ADD;

                op2->gtIntCon.gtIconVal = iadd * imul;

                op1->gtOper  = GT_MUL;

                add->gtIntCon.gtIconVal = imul;
            }
        }

        break;

    case GT_DIV:

        /* For "val / 1", just return "val" */

        if  (op2->gtOper == GT_CNS_INT &&
             op2->gtIntCon.gtIconVal == 1)
        {
            DEBUG_DESTROY_NODE(tree);
            return op1;
        }

        break;

    case GT_LSH:

        /* Check for the case "(val + icon) << icon" */

        if  (op2->gtOper == GT_CNS_INT &&
             op1->gtOper == GT_ADD)
        {
            GenTreePtr  add = op1->gtOp.gtOp2;

            if  (add->gtOper == GT_CNS_INT && op2->IsScaleIndexShf())
            {
                long        ishf = op2->gtIntCon.gtIconVal;
                long        iadd = add->gtIntCon.gtIconVal;

//                  printf("Changing '(val+icon1)<<icon2' into '(val<<icon2+icon1<<icon2)'\n");

                /* Change "(val + iadd) << ishf" into "(val<<ishf + iadd<<ishf)" */

                tree->gtOper =
                oper         = GT_ADD;

                op2->gtIntCon.gtIconVal = iadd << ishf;

                op1->gtOper  = GT_LSH;

                add->gtIntCon.gtIconVal = ishf;
            }
        }

        break;

    case GT_XOR:

        if  (op2->gtOper == GT_CNS_INT && op2->gtIntCon.gtIconVal == -1)
        {
            /* "x ^ -1" is "~x" */

            tree->gtOper = GT_NOT;
        }
        else if  (op2->gtOper == GT_CNS_LNG && op2->gtLngCon.gtLconVal == -1)
        {
            /* "x ^ -1" is "~x" */

            tree->gtOper = GT_NOT;
        }

        break;

#if INLINING

    case GT_COMMA:

        /* Special case: assignments don't produce a value */

        if  (op2->OperKind() & GTK_ASGOP)
            tree->gtType = TYP_VOID;

        /* If the left operand is worthless, throw it away */

        if  (!(op1->gtFlags & GTF_SIDE_EFFECT))
        {
            DEBUG_DESTROY_NODE(tree);
            return op2;
        }

        break;

#endif

#if ALLOW_MIN_OPT

    // If opts.compMinOptim, then we just allocate lclvars to
    // RBM_MIN_OPT_LCLVAR_REGS (RBM_ESI|RBM_EDI).
    // However, these block instructions absolutely need these registers,
    // so we cant even use those for register allocation.
    //
    // This cannot be done in the raPredictRegUse() as that
    // function is not called if opts.compMinOptim.

#if TGT_x86
    case GT_INITBLK: raMinOptLclVarRegs &= ~(        RBM_EDI); break;
    case GT_COPYBLK: raMinOptLclVarRegs &= ~(RBM_ESI|RBM_EDI); break;
#else
    // ISSUE: Do we need any non-x86 handling here?
#endif
#endif

    case GT_ADDR:

        /* CONSIDER : For GT_ADDR(GT_IND(ptr)) (typically created by
           CONSIDER : ldflda), we perform a null-ptr check on 'ptr'
           CONSIDER : during codegen. We could hoist these for
           CONSIDER : consecutive ldflda on the same object.
         */
        if (op1->OperGet() == GT_IND && !(op1->gtFlags & GTF_IND_RNGCHK))
        {
            GenTreePtr addr = op1->gtInd.gtIndOp1;
            assert(varTypeIsGC(addr->gtType) || addr->gtType == TYP_I_IMPL);

            // obj+offset created for GT_FIELDs are incorrectly marked
            // as TYP_REFs. So we need to bash the type
            if (addr->gtType == TYP_REF)
                addr->gtType = TYP_BYREF;

            DEBUG_DESTROY_NODE(tree);
            return addr;
        }
        else if (op1->gtOper == GT_CAST)
        {
            GenTreePtr op11 = op1->gtOp.gtOp1;
            if (op11->gtOper == GT_LCL_VAR || op11->gtOper == GT_CLS_VAR)
            {
                DEBUG_DESTROY_NODE(op1);
                tree->gtOp.gtOp1 = op1 = op11;
            }
        }
        break;
    }

    return tree;
}

/*****************************************************************************
 *
 *  Transform the given tree for code generation.
 */

GenTreePtr          Compiler::fgMorphTree(GenTreePtr tree)
{
    assert(tree);
    assert(tree->gtOper != GT_STMT);

    /*-------------------------------------------------------------------------
     * fgMorphTree() can potentially replace a tree with another, and the
     * caller has to store the return value correctly.
     * Turn this on to always make copy of "tree" here to shake out
     * hidden/unupdated references.
     */

#ifdef DEBUG

    if  (false)
    {
        GenTreePtr      copy;

#ifdef SMALL_TREE_NODES
        if  (GenTree::s_gtNodeSizes[tree->gtOper] == TREE_NODE_SZ_SMALL)
            copy = gtNewLargeOperNode(GT_ADD, TYP_INT);
        else
#endif
            copy = gtNewOperNode     (GT_CALL, TYP_INT);

        copy->CopyFrom(tree);

#if defined(JIT_AS_COMPILER) || defined (LATE_DISASM)
        // GT_CNS_INT is considered small, so CopyFrom() wont copy all fields
        if  ((tree->gtOper == GT_CNS_INT) & (tree->gtFlags & GTF_ICON_HDL_MASK))
        {
            copy->gtIntCon.gtIconHdl.gtIconHdl1 = tree->gtIntCon.gtIconHdl.gtIconHdl1;
            copy->gtIntCon.gtIconHdl.gtIconHdl2 = tree->gtIntCon.gtIconHdl.gtIconHdl2;
        }
#endif

        DEBUG_DESTROY_NODE(tree);
        tree = copy;
    }

#endif // DEBUG----------------------------------------------------------------

    /* Figure out what kind of a node we have */

    unsigned        kind = tree->OperKind();

    /* Is this a constant node? */

    if  (kind & GTK_CONST)
        return fgMorphConst(tree);

    /* Is this a leaf node? */

    if  (kind & GTK_LEAF)
        return fgMorphLeaf(tree);

    /* Is it a 'simple' unary/binary operator? */

    if  (kind & GTK_SMPOP)
        return fgMorphSmpOp(tree);

    /* See what kind of a special operator we have here */

    switch  (tree->OperGet())
    {
    case GT_FIELD:
        return fgMorphField(tree);

    case GT_CALL:
        return fgMorphCall(tree);

    case GT_MKREFANY:
    case GT_LDOBJ:
        tree->gtLdObj.gtOp1 = fgMorphTree(tree->gtLdObj.gtOp1);
        return tree;

    case GT_JMP:
        return tree;

    case GT_JMPI:
        assert(tree->gtOp.gtOp1);
        tree->gtOp.gtOp1 = fgMorphTree(tree->gtOp.gtOp1);
        return tree;

    default:
#ifdef  DEBUG
        gtDispTree(tree);
#endif
        assert(!"unexpected operator");
    }

    assert(!"Shouldnt get here in fgMorphTree()");
    return tree;
}

/*****************************************************************************
 *
 *  Returns true if the block has any predecessors other than "ignore"
 *  between "beg" and "end".
 */

bool                Compiler::fgBlockHasPred(BasicBlock *block,
                                             BasicBlock *ignore,
                                             BasicBlock *beg,
                                             BasicBlock *end)
{
    assert(block);
    assert(beg);
    assert(end);

    assert(block->bbNum >= beg->bbNum);
    assert(block->bbNum <= end->bbNum);

    /* If a catch block has predecessors for sure
     * CONSIDER: this is kind of a hack since we shouldn't use this
     * function at all - instead use bbRefs after cleanup */

    if (block->bbCatchTyp) return true;

#if RNGCHK_OPT

    flowList   *    flow = block->bbPreds;

    if  (flow)
    {
        do
        {
            if  (flow->flBlock != ignore)
            {
                if  (flow->flBlock->bbNum >= beg->bbNum &&
                     flow->flBlock->bbNum <= end->bbNum)
                {
                    return  true;
                }
            }
        }
        while ((flow = flow->flNext) != 0);

        return  false;
    }

#endif

    /* No predecessor list available, do it the hard way */

    for (;;)
    {
        switch (beg->bbJumpKind)
        {
        case BBJ_COND:

            if  (beg->bbJumpDest == block)
            {
                if  (beg != block && beg != ignore)
                    return  true;
            }

        case BBJ_NONE:

            if  (beg->bbNext == block)
            {
                if  (beg != block && beg != ignore)
                    return  true;
            }

            break;

        case BBJ_RET:
        case BBJ_THROW:
        case BBJ_RETURN:
            break;

        case BBJ_ALWAYS:

            if  (beg->bbJumpDest == block)
            {
                if  (beg != block && beg != ignore)
                    return  true;
            }

            break;

        case BBJ_CALL:
        case BBJ_SWITCH:

        default:

            /* We're lazy to handle switches and such */

            return  true;
        }

        if  (beg == end)
            return  false;

        beg = beg->bbNext; assert(beg);
    }
}

/*****************************************************************************/
#if OPTIMIZE_TAIL_REC
/*****************************************************************************
 *
 *  Convert an argument list for a tail-recursive call.
 *
 *  We'll convert a call of the form f(x1, x2, x3) to the following expression:
 *
 *      f(x1 , x2 , (arg3 = x3,arg2 = pop,arg1 = pop))
 *
 *  This is done by recursively walking the argument list, adding those
 *  'arg = pop' assignments for each until we get to the last one. Why this
 *  rigmarole, you ask? Well, it's mostly to make the life-time analysis do
 *  the right thing with the arguments.
 *
 *  UNDONE: Skip arguments whose values are identical in both argument lists!
 */

void                Compiler::fgCnvTailRecArgList(GenTreePtr *argsPtr)
{
    unsigned        anum = 0;
    GenTreePtr      pops = 0;
    GenTreePtr      args = *argsPtr;

    GenTreePtr      argv;
    GenTreePtr      next;
    var_types       type;

    GenTreePtr      temp;

    /* Skip the first argument slot if there is a 'this' argument */

    if  (!info.compIsStatic)
        anum++;

    /* Now walk the argument list, appending the 'pop' expressions */

    for (;;)
    {
        /* Get hold of this and the next argument */

        assert(args);
        assert(args->gtOper == GT_LIST);

        argv = args->gtOp.gtOp1;
        next = args->gtOp.gtOp2;
        type = argv->TypeGet();

        /* Is this the last argument? */

        if  (!next)
            break;

        /* Add 'arg = pop' to the 'pops' list */

        temp = gtNewOperNode(GT_ASG, type, gtNewLclvNode(anum, type),
                                           gtNewNode(GT_POP,   type));
        temp->gtFlags |= GTF_ASG;

        pops = pops ? gtNewOperNode(GT_COMMA, TYP_VOID, temp, pops)
                    : temp;

        /* Figure out the slot# for the next argument */

        anum += genTypeStSz(type);

        /* Move on to the next argument */

        args = next; assert(args);
    }

    /* Assign the last argument value */

    temp = gtNewOperNode(GT_ASG, type, gtNewLclvNode(anum, type), argv);

    /* Mark the expression as containing an assignment */

    temp->gtFlags |= GTF_ASG;

    /* Glue the last argument assignment with the other pops, if any */

    if  (pops)
        temp = gtNewOperNode(GT_COMMA, TYP_VOID, temp, pops);

    /* Set the type of the last argument to 'void' */

    temp->gtType = TYP_VOID;

    /* Replace the last argument with the 'pops' expression */

    assert(args->gtOp.gtOp1 == argv); args->gtOp.gtOp1 = temp;
}

/*****************************************************************************/
#endif//OPTIMIZE_TAIL_REC
/*****************************************************************************/
#if     RNGCHK_OPT
/*****************************************************************************
 *
 *  Mark whether the edge "srcBB -> dstBB" forms a loop that will always
 *  execute a call or not.
 */

inline
void                Compiler::fgLoopCallTest(BasicBlock *srcBB,
                                             BasicBlock *dstBB)
{
    /* Bail if this is not a backward edge */

    if  (srcBB->bbNum < dstBB->bbNum)
        return;

    /* Unless we already know that there is a loop without a call here ... */

    if  (!(dstBB->bbFlags & BBF_LOOP_CALL0))
    {
        /* Check whether there is a loop path that doesn't call */

        if  (optReachWithoutCall(dstBB, srcBB))
        {
            dstBB->bbFlags |=  BBF_LOOP_CALL0;
            dstBB->bbFlags &= ~BBF_LOOP_CALL1;
        }
        else
            dstBB->bbFlags |=  BBF_LOOP_CALL1;
    }
}

/*****************************************************************************
 *
 *  Mark which loops are guaranteed to execute a call.
 */

void                Compiler::fgLoopCallMark()
{
    BasicBlock  *   block;

    /* If we've already marked all the block, bail */

    if  (fgLoopCallMarked)
        return;

    fgLoopCallMarked = true;

    /* Walk the blocks, looking for backward edges */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        switch (block->bbJumpKind)
        {
        case BBJ_COND:
            fgLoopCallTest(block, block->bbJumpDest);
            break;

        case BBJ_CALL:
        case BBJ_ALWAYS:
            fgLoopCallTest(block, block->bbJumpDest);
            break;

        case BBJ_NONE:
            break;

        case BBJ_RET:
        case BBJ_THROW:
        case BBJ_RETURN:
            break;

        case BBJ_SWITCH:

            unsigned        jumpCnt = block->bbJumpSwt->bbsCount;
            BasicBlock * *  jumpPtr = block->bbJumpSwt->bbsDstTab;

            do
            {
                fgLoopCallTest(block, *jumpPtr);
            }
            while (++jumpPtr, --jumpCnt);

            break;
        }
    }
}

/*****************************************************************************/
#endif//RNGCHK_OPT
/*****************************************************************************
 *
 *  Note the fact that the given block is a loop header.
 */

inline
void                Compiler::fgMarkLoopHead(BasicBlock *block)
{
    /* Is the loop head block known to execute a method call? */

    if  (block->bbFlags & BBF_HAS_CALL)
        return;

#if RNGCHK_OPT

    /* Have we decided to generate fully interruptible code already? */

    if  (genInterruptible)
    {
        assert(genFullPtrRegMap);
        return;
    }

    /* Are dominator sets available? */

    if  (fgComputedDoms)
    {
        /* Make sure that we know which loops will always execute calls */

        if  (!fgLoopCallMarked)
            fgLoopCallMark();

        /* Will every trip through our loop execute a call? */

        if  (block->bbFlags & BBF_LOOP_CALL1)
            return;
    }

#endif

    /*
     *  We have to make this method fully interruptible since we can not
     *  insure that this loop will execute a call every time it loops.
     *
     *  We'll also need to generate a full register map for this method.
     */

    assert(genIntrptibleUse == false);

    genInterruptible = true;
    genFullPtrRegMap = true;
}


/*****************************************************************************
 *
 *  Add any internal blocks/trees we may need
 *  Returns true if we change the basic block list.
 */

bool                Compiler::fgAddInternal()
{
    BasicBlock *    block;
    bool            chgBBlst = false;

    /* Assume we will generate a single return sequence */

    bool oneReturn = true;

    /*
        We generate an inline copy of the function epilog at each return
        point when compiling for speed, but we have to be careful since
        we won't (in general) know what callee-saved registers we're
        going to save and thus don't know which regs to pop at every
        return except the very last one.
     */

#if!TGT_RISC
    /*
        We generate just one epilog for methods calling into unmanaged code.
     */
#if INLINE_NDIRECT
    if (info.compCallUnmanaged == 0 && !opts.compEnterLeaveEventCB)
#else
    if (!opts.compEnterLeaveEventCB)
#endif
    {
        if  (opts.compFastCode)
        {
            /* Is this a 'synchronized' method? */

            if  (!(info.compFlags & FLG_SYNCH))
            {
                unsigned    retCnt;

                /* Make sure there are not 'too many' exit points */

                for (retCnt = 0, block = fgFirstBB; block; block = block->bbNext)
                {
                    if  (block->bbJumpKind == BBJ_RETURN)
                        retCnt++;
                }

                /* We'll only allow an arbitrarily small number of returns */

                if  (retCnt < 5)
                {
                    /* OK, let's generate multiple exits */

                    genReturnBB = 0;
                    oneReturn   = false;
                }
            }
        }


    }
#endif


#if TGT_RISC
    assert(oneReturn);  // this is needed for epilogs to work (for now) !
#endif

    if  (oneReturn)
    {
        genReturnBB = fgNewBasicBlock(BBJ_RETURN);
        genReturnBB->bbCodeSize = 0;
        genReturnBB->bbFlags   |= (BBF_INTERNAL|BBF_DONT_REMOVE);
    }

    /* If we need a locspace region, we will create a dummy variable of
     * type TYP_LCLBLK. Grab a slot and remember it */

#if INLINE_NDIRECT
    if (info.compCallUnmanaged != 0)
    {
        info.compLvFrameListRoot = lvaGrabTemp();
    }

    if (lvaScratchMem > 0 || info.compCallUnmanaged != 0)
        lvaScratchMemVar = lvaGrabTemp();
#else
    if  (lvaScratchMem > 0)
        lvaScratchMemVar = lvaGrabTemp();
#endif

#ifdef DEBUGGING_SUPPORT

    if (opts.compDbgCode)
    {
        /* Create a new empty basic block. We may add initialization of
         * variables which are in scope right from the start of the
         * (real) first BB (and therefore artifically marked as alive)
         * into this block
         */

        block = bbNewBasicBlock(BBJ_NONE);
        fgStoreFirstTree(block, gtNewNothingNode());

        /* Insert the new BB at the front of the block list */

        block->bbNext = fgFirstBB;

        fgFirstBB = block;
        block->bbFlags |= BBF_INTERNAL;
    }

#endif

#if TGT_RISC
    genMonExitExp    = NULL;
#endif


    /* Is this a 'synchronized' method? */

    if  (info.compFlags & FLG_SYNCH)
    {
        GenTreePtr      tree;

        void * monitor, **pMonitor;
        monitor = eeGetMethodSync(info.compMethodHnd, &pMonitor);
        assert((!monitor) != (!pMonitor));

        /* Insert the expression "monitorEnter(this)" or "monitorEnter(handle)" */

        if  (info.compIsStatic)
        {
            tree = gtNewIconEmbHndNode(monitor, pMonitor, GTF_ICON_METHOD_HDL);

            tree = gtNewHelperCallNode(CPX_MONENT_STAT,
                                       TYP_VOID,
                                       GTF_CALL_REGSAVE,
                                       gtNewArgList(tree));
        }
        else
        {
            tree = gtNewLclvNode(0, TYP_REF, 0);

            tree = gtNewHelperCallNode(CPX_MON_ENTER,
                                       TYP_VOID,
                                       GTF_CALL_REGSAVE,
                                       gtNewArgList(tree));
        }

        /* Create a new basic block and stick the call in it */

        block = bbNewBasicBlock(BBJ_NONE); fgStoreFirstTree(block, tree);

        /* Insert the new BB at the front of the block list */

        block->bbNext = fgFirstBB;

        if  (fgFirstBB == fgLastBB)
            fgLastBB = block;

        fgFirstBB = block;
        block->bbFlags |= BBF_INTERNAL;

#ifdef DEBUG
        if (verbose)
        {
            printf("\nSynchronized method - Add MonitorEnter statement in new first basic block [%08X]\n", block);
            gtDispTree(tree,0);
            printf("\n");
        }
#endif

        /* Remember that we've changed the basic block list */

        chgBBlst = true;

        /* We must be generating a single exit point for this to work */

        assert(oneReturn);
        assert(genReturnBB);

        /* Create the expression "monitorExit(this)" or "monitorExit(handle)" */

        if  (info.compIsStatic)
        {
            tree = gtNewIconEmbHndNode(monitor, pMonitor, GTF_ICON_METHOD_HDL);

            tree = gtNewHelperCallNode(CPX_MONEXT_STAT,
                                       TYP_VOID,
                                       GTF_CALL_REGSAVE,
                                       gtNewArgList(tree));
        }
        else
        {
            tree = gtNewLclvNode(0, TYP_REF, 0);

            tree = gtNewHelperCallNode(CPX_MON_EXIT,
                                       TYP_VOID,
                                       GTF_CALL_REGSAVE,
                                       gtNewArgList(tree));
        }

#if     TGT_RISC

        /* Is there a non-void return value? */

        if  (info.compRetType != TYP_VOID)
        {
            /* We'll add the monitorExit call later */

            genMonExitExp = tree;
            genReturnLtm  = genReturnCnt;
        }
        else
        {
            /* Add the 'monitorExit' call to the return block */

            fgStoreFirstTree(genReturnBB, tree);
        }

#else

        /* Make the monitorExit tree into a 'return' expression */

        tree = gtNewOperNode(GT_RETURN, TYP_VOID, tree);

        /* Add 'monitorExit' to the return block */

        fgStoreFirstTree(genReturnBB, tree);

#ifdef DEBUG
        if (verbose)
        {
            printf("\nAdded monitorExit to Synchronized method [%08X]\n", genReturnBB);
            gtDispTree(tree,0);
            printf("\n");
        }
#endif

#endif

    }

#if INLINE_NDIRECT || defined(PROFILER_SUPPORT)

    /* prepend a GT_RETURN statement to genReturnBB */
    if  (
#if INLINE_NDIRECT
         info.compCallUnmanaged ||
#endif
        opts.compEnterLeaveEventCB)
    {
        /* Only necessary if it isn't already done */
        if  (!(info.compFlags & FLG_SYNCH))
        {
            GenTreePtr      tree;

            assert(oneReturn);
            assert(genReturnBB);

            tree = gtNewOperNode(GT_RETURN, TYP_VOID, NULL);

            fgStoreFirstTree(genReturnBB, tree);

        }
    }
#endif

    return chgBBlst;
}

/*****************************************************************************
 *
 *  Morph the statements of the given block.
 *  *pLast and *pPrev are set to the last and last-but-one statement
 *    expression of the block.
 */

void                Compiler::fgMorphStmts(BasicBlock * block,
                                           GenTreePtr * pLast, GenTreePtr * pPrev,
                                           bool * mult, bool * lnot, bool * loadw)
{
    *mult = *lnot = *loadw = false;

    GenTreePtr stmt, prev, last;

    for (stmt = block->bbTreeList, last = NULL, prev = NULL;
         stmt;
         prev = stmt->gtStmt.gtStmtExpr, stmt = stmt->gtNext, last = stmt ? stmt->gtStmt.gtStmtExpr : last)
    {
        assert(stmt->gtOper == GT_STMT);

        fgMorphStmt      = stmt;
        GenTreePtr  tree = stmt->gtStmt.gtStmtExpr;

        /* Morph this statement tree */

        GenTreePtr  morph = fgMorphTree(tree);

        // Has fgMorphStmt been sneakily whacked ?

        if (stmt->gtStmt.gtStmtExpr != tree)
        {
            /* This must be tailcall. Ignore 'morph' and carry on with
               the tail-call node */

            morph = stmt->gtStmt.gtStmtExpr;

            assert(compTailCallUsed);
            assert((morph->gtOper == GT_CALL) &&
                   (morph->gtCall.gtCallMoreFlags & GTF_CALL_M_TAILCALL));
            assert(stmt->gtNext == NULL);
            assert(block->bbJumpKind == BBJ_THROW);
        }

        stmt->gtStmt.gtStmtExpr = tree = morph;

        /* Check if this statement was a conditional we folded */

        if (tree->gtOper == GT_JTRUE)
        {
            GenTreePtr cond = tree->gtOp.gtOp1; assert(cond);

            if (cond->gtOper == GT_CNS_INT)
            {
                assert(cond->gtIntCon.gtIconVal == 0 || cond->gtIntCon.gtIconVal == 1);

                /* Remove the comparison and modify the flowgraph
                 * this must be the tree statement in the block */
                assert(stmt->gtNext == 0);

                /* remove the statement from bbTreelist */
                fgRemoveStmt(block, stmt);

                /* modify the flow graph */
                block->bbJumpKind = cond->gtIntCon.gtIconVal ? BBJ_ALWAYS : BBJ_NONE;
            }
        }

        if  (block->bbFlags & BBF_HAS_HANDLER)
            continue;

#if OPT_MULT_ADDSUB

        /* Note whether we have two or more +=/-= operators in a row */

        if  (tree->gtOper == GT_ASG_ADD ||
             tree->gtOper == GT_ASG_SUB)
        {
            if  (prev && prev->gtOper == tree->gtOper)
                *mult = true;
        }

#endif

#if OPT_BOOL_OPS

        /* Note whether we have two "log0" assignments in a row */

        if  (tree->IsNotAssign() != -1)
        {
            fgMultipleNots |= *lnot; *lnot = true;
        }

#endif

        /* Note "x = a[i] & icon" followed by "x |= a[i] << 8" */

        if  (tree->gtOper == GT_ASG_OR &&
             prev &&
             prev->gtOper == GT_ASG)
        {
            *loadw = true;
        }
    }

    *pLast = last;
    *pPrev = prev;
}


/*****************************************************************************
 *
 *  Morph the blocks of the method.
 *  Returns true if the basic block list is modified.
 */

bool                Compiler::fgMorphBlocks()
{
    /* Since fgMorphTree can be called after various optimizations to re-arrange
     * the nodes we need a global flag to signal if we are during the one-pass
     * global morphing */

    fgGlobalMorph = true;

    /*-------------------------------------------------------------------------
     * Process all basic blocks in the function
     */

    bool    chgBBlst = false;

    BasicBlock *    block = fgFirstBB; assert(block);
    BasicBlock *    entry = fgFirstBB; /// Remember the first 'real' basic block

    do
    {
#if OPT_MULT_ADDSUB
        int             oper  = GT_NONE;
        bool            mult  = false;
#endif

#if OPT_BOOL_OPS
        bool            lnot  = false;
#endif

        bool            loadw = false;

        /* Make the current basic block address available globally */

        compCurBB = block;

#ifdef DEBUG
        if(verbose&&1)
            printf("\nMorphing basic block #%02u of '%s'\n", block->bbNum, info.compFullName);
#endif

#if COPY_PROPAG
        //
        // Clear out any currently recorded copy assignment candidates
        // before processing each basic block,
        // also we must  handle QMARK-COLON specially
        //
        optCopyAsgCount = 0;
#endif

        /* Process all statement trees in the basic block */

        GenTreePtr      tree, last, prev;

        fgMorphStmts(block, &last, &prev, &mult, &lnot, &loadw);

#if OPT_MULT_ADDSUB

        if  (mult && (opts.compFlags & CLFLG_TREETRANS) &&
             !opts.compDbgCode && !opts.compMinOptim)
        {
            for (tree = block->bbTreeList; tree; tree = tree->gtNext)
            {
                assert(tree->gtOper == GT_STMT);
                last = tree->gtStmt.gtStmtExpr;

                if  (last->gtOper == GT_ASG_ADD ||
                     last->gtOper == GT_ASG_SUB)
                {
                    GenTreePtr      temp;
                    GenTreePtr      next;

                    GenTreePtr      dst1 = last->gtOp.gtOp1;
                    GenTreePtr      src1 = last->gtOp.gtOp2;

                    // CONSIDER: allow non-int case

                    if  (last->gtType != TYP_INT)
                        goto NOT_CAFFE;

                    // CONSIDER: Allow non-constant case, that is in
                    // CONSIDER: general fold "a += x1" followed by
                    // CONSIDER: "a += x2" into "a += (x1+x2);".

                    if  (dst1->gtOper != GT_LCL_VAR)
                        goto NOT_CAFFE;
                    if  (src1->gtOper != GT_CNS_INT)
                        goto NOT_CAFFE;

                    for (;;)
                    {
                        GenTreePtr      dst2;
                        GenTreePtr      src2;

                        /* Look at the next statement */

                        temp = tree->gtNext;
                        if  (!temp)
                            goto NOT_CAFFE;

                        assert(temp->gtOper == GT_STMT);
                        next = temp->gtStmt.gtStmtExpr;

                        if  (next->gtOper != last->gtOper)
                            goto NOT_CAFFE;
                        if  (next->gtType != last->gtType)
                            goto NOT_CAFFE;

                        dst2 = next->gtOp.gtOp1;
                        src2 = next->gtOp.gtOp2;

                        if  (dst2->gtOper != GT_LCL_VAR)
                            goto NOT_CAFFE;
                        if  (dst2->gtLclVar.gtLclNum != dst1->gtLclVar.gtLclNum)
                            goto NOT_CAFFE;

                        if  (src2->gtOper != GT_CNS_INT)
                            goto NOT_CAFFE;

                        /* Fold the two increments/decrements into one */

                        src1->gtIntCon.gtIconVal += src2->gtIntCon.gtIconVal;

                        /* Remember that we've changed the basic block list */

                        chgBBlst = true;

                        /* Remove the second statement completely */

                        assert(tree->gtNext == temp);
                        assert(temp->gtPrev == tree);

//                      printf("Caffeine: %08X[%08X] subsumes %08X[%08X]\n", tree, tree->gtStmt.gtStmtExpr,
//                                                                           temp, temp->gtStmt.gtStmtExpr);

                        if  (temp->gtNext)
                        {
                            assert(temp->gtNext->gtPrev == temp);

                            temp->gtNext->gtPrev = tree;
                            tree->gtNext         = temp->gtNext;
                        }
                        else
                        {
                            tree->gtNext = 0;

                            assert(block->bbTreeList->gtPrev == temp);

                            block->bbTreeList->gtPrev = tree;
                        }
                    }
                }

            NOT_CAFFE:;

            }

        }

#endif

        if  (loadw && (opts.compFlags & CLFLG_TREETRANS))
        {
            GenTreePtr      last;

            for (tree = block->bbTreeList, last = 0;;)
            {
                GenTreePtr      nxts;

                GenTreePtr      exp1;
                GenTreePtr      exp2;

                GenTreePtr      op11;
                GenTreePtr      op12;
                GenTreePtr      op21;
                GenTreePtr      op22;

                GenTreePtr      indx;
                GenTreePtr      asg1;

                long            bas1;
                long            ind1;
                bool            mva1;
                long            ofs1;
                unsigned        mul1;

                long            bas2;
                long            ind2;
                bool            mva2;
                long            ofs2;
                unsigned        mul2;

                nxts = tree->gtNext;
                if  (!nxts)
                    break;

                assert(tree->gtOper == GT_STMT);
                exp1 = tree->gtStmt.gtStmtExpr;

                assert(nxts->gtOper == GT_STMT);
                exp2 = nxts->gtStmt.gtStmtExpr;

                /*
                    We're looking for the following statements:

                        x  =   a[i] & 0xFF;
                        x |= ((a[i] & 0xFF) << 8);
                 */

                if  (exp2->gtOper != GT_ASG_OR)
                    goto NEXT_WS;
                if  (exp1->gtOper != GT_ASG)
                    goto NEXT_WS;

                asg1 = exp1;

                op11 = exp1->gtOp.gtOp1;
                op21 = exp2->gtOp.gtOp1;

                if  (op11->gtOper != GT_LCL_VAR)
                    goto NEXT_WS;
                if  (op21->gtOper != GT_LCL_VAR)
                    goto NEXT_WS;
                if  (op11->gtLclVar.gtLclNum != op21->gtLclVar.gtLclNum)
                    goto NEXT_WS;

                op12 = exp1->gtOp.gtOp2;
                op22 = exp2->gtOp.gtOp2;

                /* The second operand should have "<< 8" on it */

                if  (op22->gtOper != GT_LSH)
                    goto NEXT_WS;
                op21 = op22->gtOp.gtOp2;
                if  (op21->gtOper != GT_CNS_INT)
                    goto NEXT_WS;
                if  (op21->gtIntCon.gtIconVal != 8)
                    goto NEXT_WS;
                op22 = op22->gtOp.gtOp1;

                /* Both operands should be "& 0xFF" */

                if  (op12->gtOper != GT_AND)
                    goto NEXT_WS;
                if  (op22->gtOper != GT_AND)
                    goto NEXT_WS;

                op11 = op12->gtOp.gtOp2;
                if  (op11->gtOper != GT_CNS_INT)
                    goto NEXT_WS;
                if  (op11->gtIntCon.gtIconVal != 0xFF)
                    goto NEXT_WS;
                op11 = op12->gtOp.gtOp1;

                op21 = op22->gtOp.gtOp2;
                if  (op21->gtOper != GT_CNS_INT)
                    goto NEXT_WS;
                if  (op21->gtIntCon.gtIconVal != 0xFF)
                    goto NEXT_WS;
                op21 = op22->gtOp.gtOp1;

                /* Both operands should be array index expressions */

                if  (op11->gtOper != GT_IND)
                    goto NEXT_WS;
                if  (op21->gtOper != GT_IND)
                    goto NEXT_WS;

                if  (op11->gtFlags & GTF_IND_RNGCHK)
                    goto NEXT_WS;
                if  (op21->gtFlags & GTF_IND_RNGCHK)
                    goto NEXT_WS;

                /* Break apart the index expression */

                if  (!gtCrackIndexExpr(op11, &indx, &ind1, &bas1, &mva1, &ofs1, &mul1))
                    goto NEXT_WS;
                if  (!gtCrackIndexExpr(op21, &indx, &ind2, &bas2, &mva2, &ofs2, &mul2))
                    goto NEXT_WS;

                if  (mva1 || mva2)   goto NEXT_WS;
                if  (ind1 != ind2)   goto NEXT_WS;
                if  (bas1 != bas2)   goto NEXT_WS;
                if  (ofs1 != ofs2-1) goto NEXT_WS;

                /* Got it - update the first expression */

                assert(op11->gtOper == GT_IND);
                assert(op11->gtType == TYP_BYTE);

                op11->gtType = TYP_CHAR;

                assert(asg1->gtOper == GT_ASG);
                asg1->gtOp.gtOp2 = asg1->gtOp.gtOp2->gtOp.gtOp1;

                /* Get rid of the second expression */

                nxts->gtStmt.gtStmtExpr = gtNewNothingNode();

            NEXT_WS:

                last = tree;
                tree = nxts;
            }
        }

#if  !  RNGCHK_OPT

        /* Is this block a loop header? */

        if  (block->bbFlags & BBF_LOOP_HEAD)
            fgMarkLoopHead(block);

#endif

        /*
            Check for certain stupid constructs some compilers might
            generate:

                1.      jump to a jump

                2.      conditional jump around an unconditional one
         */

        // fgMorphBlock()

        switch (block->bbJumpKind)
        {
            BasicBlock   *  nxtBlk;
            BasicBlock   *  jmpBlk;

            BasicBlock * *  jmpTab;
            unsigned        jmpCnt;

#if OPTIMIZE_TAIL_REC
            GenTreePtr      call;
#endif

        case BBJ_RET:
        case BBJ_THROW:
            break;

        case BBJ_COND:

            block->bbJumpDest = (block->bbJumpDest)->JumpTarget();

            /*
                Check for the following:

                        JCC skip

                        JMP label

                  skip:
             */

            nxtBlk = block->bbNext;
            jmpBlk = block->bbJumpDest;

            if  (nxtBlk->bbNext == jmpBlk)
            {
                /* Is the next block just a jump? */

                if  (nxtBlk->bbJumpKind == BBJ_ALWAYS &&
                     nxtBlk->bbTreeList == 0 &&
                     nxtBlk->bbJumpDest != nxtBlk)   /* skip infinite loops */
                {
                    GenTreePtr      test;

                    /* Reverse the jump condition */

                    test = block->bbTreeList;
                    assert(test && test->gtOper == GT_STMT);
                    test = test->gtPrev;
                    assert(test && test->gtOper == GT_STMT);

                    test = test->gtStmt.gtStmtExpr;
                    assert(test->gtOper == GT_JTRUE);

                    test->gtOp.gtOp1 = gtReverseCond(test->gtOp.gtOp1);

                    /*
                        Get rid of the following block; note that we can do
                        this even though other blocks could jump to it - the
                        reason is that elsewhere in this function we always
                        redirect jumps to jumps to jump to the final label,
                        and so even if someone targets the 'jump' block we
                        are about to delete it won't matter once we're done
                        since any such jump will be redirected to the final
                        target by the time we're done here.
                     */

                    block->bbNext     = jmpBlk;
                    block->bbJumpDest = nxtBlk->bbJumpDest;

                    chgBBlst = true;
                }
            }

            block->bbJumpDest = (block->bbJumpDest)->JumpTarget();
            break;

        case BBJ_CALL:
            block->bbJumpDest = (block->bbJumpDest)->JumpTarget();
            break;

        case BBJ_RETURN:

#if OPTIMIZE_TAIL_REC

            if  (opts.compFastCode)
            {
                /* Check for tail recursion */

                if  (last && last->gtOper == GT_RETURN)
                {
                    call = last->gtOp.gtOp1;

                    if  (!call)
                        call = prev;

                    if  (!call || call->gtOper != GT_CALL)
                        goto NO_TAIL_REC;

                CHK_TAIL:

                    /* This must not be a virtual/interface call */

                    if  (call->gtFlags & (GTF_CALL_VIRT|GTF_CALL_INTF))
                        goto NO_TAIL_REC;

                    /* Get hold of the constant pool index */

                    gtCallTypes callType  = call->gtCall.gtCallType;

                    /* For now, only allow directly recursive calls */

                    if  (callType == CT_HELPER || !eeIsOurMethod(call->gtCall.gtCallMethHnd))
                        goto NO_TAIL_REC;

                    /* TEMP: only allow static calls */

                    if  (call->gtCall.gtCallObjp)
                        goto NO_TAIL_REC;

//                  printf("found tail-recursive call:\n");
//                  gtDispTree(call);
//                  printf("\n");

                    call->gtFlags |= GTF_CALL_TAILREC;

                    /* Was there a non-void return value? */

                    if  (block->bbJumpKind == BBJ_RETURN)
                    {
                        assert(last->gtOper == GT_RETURN);
                        if  (last->gtType != TYP_VOID)
                        {
                            /* We're not returning a value any more */

                            assert(last->gtOp.gtOp1 == call);

                            last->gtOper     = GT_CAST;
                            last->gtType     = TYP_VOID;
                            last->gtOp.gtOp2 = gtNewIconNode(TYP_VOID);
                        }
                    }

                    /* Convert the argument list, if non-empty */

                    if  (call->gtCall.gtCallArgs)
                        fgCnvTailRecArgList(&call->gtCall.gtCallArgs);

#if 0
                    printf("generate code for tail-recursive call:\n");
                    gtDispTree(call);
                    printf("\n");
#endif

                    /* Make the basic block jump back to the top */

                    block->bbJumpKind = BBJ_ALWAYS;
                    block->bbJumpDest = entry;

                    /* This makes the whole method into a loop */

                    entry->bbFlags |= BBF_LOOP_HEAD; fgMarkLoopHead(entry);

                    // CONSIDER: If this was the only return, completely
                    // CONSIDER: get rid of the return basic block.

                    break;
                }
            }

        NO_TAIL_REC:

            if  (block->bbJumpKind != BBJ_RETURN)
                break;

#endif

            /* Are we using one return code sequence? */

            if  (!genReturnBB || genReturnBB == block)
                break;

            if (block->bbFlags & BBF_HAS_JMP)
                break;

            /* We'll jump to the return label */

            block->bbJumpKind = BBJ_ALWAYS;
            block->bbJumpDest = genReturnBB;


            // Fall into the the 'always' case ...

        case BBJ_ALWAYS:

#ifdef DEBUG
            BasicBlock  *   oldTarget;
            oldTarget = block->bbJumpDest;
#endif
            /* Update the GOTO target */

            block->bbJumpDest = (block->bbJumpDest)->JumpTarget();

#ifdef DEBUG
            if  (verbose)
            {
                if  (block->bbJumpDest != oldTarget)
                    printf("Unconditional jump to #%02u changed to #%02u\n",
                                                        oldTarget->bbNum,
                                                        block->bbJumpDest->bbNum);
            }
#endif

            /* Check for a jump to the very next block */

            if  (block->bbJumpDest == block->bbNext)
            {
                block->bbJumpKind = BBJ_NONE;
#ifdef DEBUG
                if  (verbose)
                {
                    printf("Unconditional jump to following basic block (#%02u -> #%02u)\n",
                                                                         block->bbNum,
                                                                         block->bbJumpDest->bbNum);
                    printf("Block #%02u becomes a BBJ_NONE\n\n", block->bbNum);
                }
#endif
            }
            break;

        case BBJ_NONE:

#if OPTIMIZE_TAIL_REC

            /* Check for tail recursion */

            if  (opts.compFastCode && last && last->gtOper == GT_CALL)
            {
                if  (block->bbNext)
                {
                    BasicBlock  *   bnext = block->bbNext;
                    GenTree     *   retx;

                    if  (bnext->bbJumpKind != BBJ_RETURN)
                        break;

                    assert(bnext->bbTreeList && bnext->bbTreeList->gtOper == GT_STMT);

                    retx = bnext->bbTreeList->gtStmt.gtStmtExpr; assert(retx);

                    if  (retx->gtOper != GT_RETURN)
                        break;
                    if  (retx->gtOp.gtOp1)
                        break;
                }

                call = last;
                goto CHK_TAIL;
            }

#endif

            break;

        case BBJ_SWITCH:

            // CONSIDER: Move the default clause so that it's the next block

            jmpCnt = block->bbJumpSwt->bbsCount;
            jmpTab = block->bbJumpSwt->bbsDstTab;

            do
            {
                *jmpTab = (*jmpTab)->JumpTarget();
            }
            while (++jmpTab, --jmpCnt);

            break;
        }

#ifdef  DEBUG
        assert(compCurBB == block);
        compCurBB = 0;
#endif

        block = block->bbNext;
    }
    while (block);

    /* We are done with the global morphing phase */

    fgGlobalMorph = false;

#if TGT_RISC

    /* Do we need to add a monitorExit call at the end? */

    if  (genMonExitExp)
    {
        unsigned        retTmp;
        GenTreePtr      retExp;
        GenTreePtr      retStm;

        var_types       retTyp = genActualType(info.compRetType);

        assert(retTyp != TYP_VOID);
        assert(genReturnLtm == 0);

        /* Grab a temp for the return value */

        retTmp = lvaGrabTemp();

        /* Assign the return value to the temp */

        retExp = gtNewOperNode(GT_RETURN, retTyp);

        /* The value will be present in the return register(s) */

        retExp->gtFlags |= GTF_REG_VAL;
        retExp->gtRegNum = (regNumberSmall)((genTypeStSz(retTyp) == 1) ? (regNumber)REG_INTRET
                                                                       : (regNumber)REG_LNGRET);

        retExp = gtNewTempAssign(retTmp, retExp);

        /* Create the expression "tmp = <retreg> , monitorExit" */

        retStm = gtNewOperNode(GT_COMMA, TYP_VOID, retExp, genMonExitExp);

        /* Now append the final return value */

        retExp = gtNewLclvNode(retTmp, retTyp);
        retExp = gtNewOperNode(GT_RETURN, retTyp, retExp);
        retStm = gtNewOperNode(GT_COMMA , retTyp, retStm, retExp);

        /* Make the whole thing into a 'return' expression */

        retExp = gtNewOperNode(GT_RETURN, retTyp, retStm);

        /* Add the return expression to the return block */

        retStm = fgStoreFirstTree(genReturnBB, retExp);

        /* Make sure we don't mess up when we morph the final expression */

        genMonExitExp = NULL;

#ifdef DEBUG
        if (verbose)
        {
            printf("\nAdded monitorExit to Synchronized method [%08X]\n", genReturnBB);
            gtDispTree(retExp, 0);
            printf("\n");
        }
#endif

        /* Make sure the monitorExit call gets morphed */

        fgMorphStmt = retStm;
        assert(retStm->gtStmt.gtStmtExpr == retExp);
        retStm->gtStmt.gtStmtExpr = retExp = fgMorphTree(retExp);
    }

#endif

    return chgBBlst;
}


/*****************************************************************************
 *
 *  Make some decisions about the kind of code to generate.
 */

void                Compiler::fgSetOptions()
{

    /* Should we force fully interruptible code ? */

#if 0
    if (opts.eeFlags & CORJIT_FLG_INTERRUPTIBLE)
    {
        assert(genIntrptibleUse == false);

        genInterruptible = true;        // debugging is easier this way ...
        genFullPtrRegMap = true;        // ISSUE: is this correct?
    }
#endif

#ifdef DEBUGGING_SUPPORT
    if (opts.compDbgCode)
    {
        assert(genIntrptibleUse == false);

        genInterruptible = true;        // debugging is easier this way ...
        genFullPtrRegMap = true;        // ISSUE: is this correct?
    }
    else
#endif

    /* Assume we won't need an explicit stack frame if this is allowed */

#if TGT_x86

    // CPX_TAILCALL wont work with localloc because of the restoring of
    // the callee-saved registers.
    assert(!compTailCallUsed || !compLocallocUsed);

    if (compLocallocUsed || compTailCallUsed)
    {
        genFPreqd                       = true;
        opts.compDoubleAlignDisabled    = true;
    }

    genFPreqd = genFPreqd || !genFPopt || info.compXcptnsCount;

    /*  If the virtual IL stack is very large we could overflow the
     *  32-bit argMask in the GC encodings so we force it to have
     *  an EBP frame.
     */
    if (info.compMaxStack >= 27)
        genFPreqd = true;

#endif

#if DOUBLE_ALIGN
    opts.compDoubleAlignDisabled = opts.compDoubleAlignDisabled ||
                                   (info.compXcptnsCount > 0);
#endif

#if INLINE_NDIRECT
    if (info.compCallUnmanaged)
    {
#if TGT_x86
        genFPreqd = true;
#endif
    }
#endif

#if SECURITY_CHECK
    if  (opts.compNeedSecurityCheck)
    {
#if TGT_x86
        genFPreqd = true;
#endif

#if DOUBLE_ALIGN
        /* another EBP special case, presumably too rare to justify the risk */
        opts.compDoubleAlignDisabled = true;
#endif
    }
#endif

    /* Record the max. number of arguments */

#if TGT_RISC
    genMaxCallArgs = fgPtrArgCntMax * sizeof(int);
#endif

//  printf("method will %s be fully interruptible\n", genInterruptible ? "   " : "not");
}


/*****************************************************************************
 *
 *  Transform all basic blocks for codegen.
 */

void                Compiler::fgMorph()
{
    /* Filter out unimported BBs */

    fgRemoveEmptyBlocks();

    /* This global flag should be set to true whenever a block becomes empty
     * It will be an indication the we have to update the flow graph */

    fgEmptyBlocks = false;

#if HOIST_THIS_FLDS
    if (!opts.compDbgCode && !opts.compMinOptim)
    {

        /* Figure out which field refs should be hoisted */

        optHoistTFRprep();
    }
#endif

    bool chgBBlst = false; // has the basic block list been changed

    /* Add any internal blocks/trees we may need */

    chgBBlst |= fgAddInternal();

    /* To prevent recursive expansion in the inliner initialize
     * the list of inlined methods with the current method info
     * CONSIDER: Sometimes it may actually help benchmarks to inline
     *           several levels (i.e. Tak or Hanoi) */

    inlExpLst   initExpDsc;

    initExpDsc.ixlMeth = info.compMethodHnd;
    initExpDsc.ixlNext = 0;
    fgInlineExpList = &initExpDsc;

#if OPT_BOOL_OPS
    fgMultipleNots = false;
#endif

    /* Morph the trees in all the blocks of the method */

    chgBBlst |= fgMorphBlocks();

    /* Decide the kind of code we want to generate */

    fgSetOptions();

#ifdef  DEBUG
    compCurBB = 0;
#endif

    /* Have we added any new basic blocks? - update bbNums */

    if  (fgIsCodeAdded() || chgBBlst)
        fgAssignBBnums(true);
}


/*****************************************************************************
 *
 *  Helper for Compiler::fgPerBlockDataFlow()
 *  The goal is to compute the USE and DEF sets for a basic block
 *  However with the new improvement to the DFA analysis
 *  we do not mark x as used in x = f(x) when there are no side effects in f(x)
 *  The boolean asgLclVar is set when the investigated local var is used to assign
 *  to another local var and there are no SIDE EFFECTS in RHS
 */

inline
void                 Compiler::fgMarkUseDef(GenTreePtr tree, bool asgLclVar, GenTreePtr op1)
{
    bool            rhsUSEDEF = false;
    unsigned        lclNum, lhsLclNum;
    LclVarDsc   *   varDsc;

    assert(tree->gtOper == GT_LCL_VAR);
    lclNum = tree->gtLclVar.gtLclNum;

    assert(lclNum < lvaCount);
    varDsc = lvaTable + lclNum;

    if (asgLclVar)
    {
        /* we have an assignment to a local var - op1 = ... tree ...
         * check for x = f(x) case */

        assert(op1->gtOper == GT_LCL_VAR);
        assert(op1->gtFlags & GTF_VAR_DEF);

        lhsLclNum = op1->gtLclVar.gtLclNum;

        if ((lhsLclNum == lclNum) &&
            ((tree->gtFlags & GTF_VAR_DEF) == 0) &&
            (tree != op1) )
        {
            /* bingo - we have an x = f(x) case */
            op1->gtFlags |= GTF_VAR_USEDEF;
            rhsUSEDEF = true;
        }
    }

    /* Is this a tracked variable? */

    if  (varDsc->lvTracked)
    {
        VARSET_TP       bitMask;

        assert(varDsc->lvVarIndex < lvaTrackedCount);

        bitMask = genVarIndexToBit(varDsc->lvVarIndex);

        if  ((tree->gtFlags & GTF_VAR_DEF) != 0 &&
             (tree->gtFlags & (GTF_VAR_USE | GTF_VAR_USEDEF)) == 0)
        {
//          if  (!(fgCurUseSet & bitMask)) printf("lcl #%02u[%02u] def at %08X\n", lclNum, varDsc->lvVarIndex, tree);
            if  (!(fgCurUseSet & bitMask))
                fgCurDefSet |= bitMask;
        }
        else
        {
//          if  (!(fgCurDefSet & bitMask)) printf("lcl #%02u[%02u] use at %08X\n", lclNum, varDsc->lvVarIndex, tree);

            /* We have the following scenarios:
             *   1. "x += something" - in this case x is flagged GTF_VAR_USE
             *   2. "x = ... x ..." - the LHS x is flagged GTF_VAR_USEDEF,
             *                        the RHS x is has rhsUSEDEF = true
             *                        (both set by the code above)
             *
             * We should not mark an USE of x in the above cases provided the value "x" is not used
             * further up in the tree. For example "while(i++)" is required to mark i as used.
             */

            /* make sure we don't include USEDEF variables in the USE set
             * The first test is for LSH, the second (!rhsUSEDEF) is for any var in the RHS */

            if  ((tree->gtFlags & (GTF_VAR_USE | GTF_VAR_USEDEF)) == 0)
            {
                /* Not a special flag - check to see if used to assign to itself */

                if (rhsUSEDEF)
                {
                    /* assign to itself - do not include it in the USE set */
                    if (!opts.compMinOptim && !opts.compDbgCode)
                        return;
                }
            }
            else
            {
                /* Special flag variable - make sure it is not used up the tree */

                GenTreePtr oper = tree->gtNext;
                assert(oper->OperKind() & GTK_ASGOP);

                /* not used if the next node is NULL */
                if (oper->gtNext == 0)
                    return;

                /* under a GT_COMMA, if used it will be marked as such later */

                if (oper->gtNext->gtOper == GT_COMMA)
                    return;
            }

            /* Fall through for the "good" cases above - add the variable to the USE set */

            if  (!(fgCurDefSet & bitMask))
                fgCurUseSet |= bitMask;
        }
    }

    return;
}

/*****************************************************************************/
#if TGT_x86
/*****************************************************************************/

void                Compiler::fgComputeFPlvls(GenTreePtr tree)
{
    genTreeOps      oper;
    unsigned        kind;
    bool            isflt;

    unsigned        savFPstkLevel;

    assert(tree);
    assert(tree->gtOper != GT_STMT);

    /* Figure out what kind of a node we have */

    oper  = tree->OperGet();
    kind  = tree->OperKind();
    isflt = varTypeIsFloating(tree->TypeGet()) ? 1 : 0;

    /* Is this a constant or leaf node? */

    if  (kind & (GTK_CONST|GTK_LEAF))
    {
        genFPstkLevel += isflt;
        goto DONE;
    }

    /* Is it a 'simple' unary/binary operator? */

    if  (kind & GTK_SMPOP)
    {
        GenTreePtr      op1 = tree->gtOp.gtOp1;
        GenTreePtr      op2 = tree->gtOp.gtOp2;

        /* Check for some special cases */

        switch (oper)
        {
        case GT_IND:

            fgComputeFPlvls(op1);

            /* Indirect loads of FP values push a new value on the FP stack */

            genFPstkLevel += isflt;
            goto DONE;

        case GT_CAST:

            fgComputeFPlvls(op1);

            /* Casts between non-FP and FP push on / pop from the FP stack */

            if  (varTypeIsFloating(op1->TypeGet()))
            {
                if  (isflt == false)
                    genFPstkLevel--;
            }
            else
            {
                if  (isflt != false)
                    genFPstkLevel++;
            }

            goto DONE;

        case GT_LIST:   /* GT_LIST presumably part of an argument list */
        case GT_COMMA:  /* Comma tosses the result of the left operand */

            savFPstkLevel = genFPstkLevel;
            fgComputeFPlvls(op1);
            genFPstkLevel = savFPstkLevel;

            if  (op2)
                fgComputeFPlvls(op2);

            goto DONE;
        }

        if  (!op1)
        {
            if  (!op2)
                goto DONE;

            fgComputeFPlvls(op2);
            goto DONE;
        }

        if  (!op2)
        {
            fgComputeFPlvls(op1);
            goto DONE;
        }

        /* FP assignments need a bit special handling */

        if  (isflt && (kind & GTK_ASGOP))
        {
            /* The target of the assignment won't get pushed */

            if  (tree->gtFlags & GTF_REVERSE_OPS)
            {
                fgComputeFPlvls(op2);
                fgComputeFPlvls(op1);
                 op1->gtFPlvl--;
                genFPstkLevel--;
            }
            else
            {
                fgComputeFPlvls(op1);
                 op1->gtFPlvl--;
                genFPstkLevel--;
                fgComputeFPlvls(op2);
            }

            genFPstkLevel--;
            goto DONE;
        }

        /* Here we have a binary operator; visit operands in proper order */

        if  (tree->gtFlags & GTF_REVERSE_OPS)
        {
            fgComputeFPlvls(op2);
            fgComputeFPlvls(op1);
        }
        else
        {
            fgComputeFPlvls(op1);
            fgComputeFPlvls(op2);
        }

        /*
            Binary FP operators pop 2 operands and produce 1 result;
            assignments consume 1 value and don't produce any.
         */

        if  (isflt)
            genFPstkLevel--;

        /* Float compares remove both operands from the FP stack */

        if  (kind & GTK_RELOP)
        {
            if  (varTypeIsFloating(op1->TypeGet()))
                genFPstkLevel -= 2;
        }

        goto DONE;
    }

    /* See what kind of a special operator we have here */

    switch  (oper)
    {
    case GT_MKREFANY:
    case GT_LDOBJ:
            // assert op1 is the same place for ldobj and for fields
        assert(&tree->gtField.gtFldObj == &tree->gtLdObj.gtOp1);
            // all through let field take care of it

    case GT_FIELD:
        fgComputeFPlvls(tree->gtField.gtFldObj);
        genFPstkLevel += isflt;
        break;

    case GT_CALL:

        if  (tree->gtCall.gtCallObjp)
            fgComputeFPlvls(tree->gtCall.gtCallObjp);

        if  (tree->gtCall.gtCallVptr)
            fgComputeFPlvls(tree->gtCall.gtCallVptr);

        if  (tree->gtCall.gtCallArgs)
        {
            savFPstkLevel = genFPstkLevel;
            fgComputeFPlvls(tree->gtCall.gtCallArgs);
            genFPstkLevel = savFPstkLevel;
        }

#if USE_FASTCALL
        if  (tree->gtCall.gtCallRegArgs)
        {
            savFPstkLevel = genFPstkLevel;
            fgComputeFPlvls(tree->gtCall.gtCallRegArgs);
            genFPstkLevel = savFPstkLevel;
        }
#endif

        genFPstkLevel += isflt;
        break;
    }

DONE:

    tree->gtFPlvl = genFPstkLevel;

    assert((int)genFPstkLevel >= 0);
}

/*****************************************************************************/
#endif//TGT_x86
/*****************************************************************************/

void                Compiler::fgFindOperOrder()
{
    BasicBlock *    block;
    GenTreePtr      stmt;

    /* Walk the basic blocks and for each statement determine
     * the evaluation order, cost, FP levels, etc... */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            /* Recursively process the statement */

            assert(stmt->gtOper == GT_STMT);
            gtSetStmtInfo(stmt);
        }
    }
}

/*****************************************************************************/

void                Compiler::fgPerBlockDataFlow()
{
    BasicBlock *    block;

#if CAN_DISABLE_DFA

    /* If we're not optimizing at all, things are simple */

    if  (opts.compMinOptim)
    {
        unsigned        lclNum;
        LclVarDsc   *   varDsc;

        VARSET_TP       liveAll = 0;

        /* We simply make everything live everywhere */

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            if  (varDsc->lvTracked)
                liveAll |= genVarIndexToBit(varDsc->lvVarIndex);
        }

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            GenTreePtr      stmt;
            GenTreePtr      tree;

            block->bbLiveIn  =
            block->bbLiveOut = liveAll;

            switch (block->bbJumpKind)
            {
            case BBJ_RET:
                if (block->bbFlags & BBF_ENDFILTER)
                    break;
            case BBJ_THROW:
            case BBJ_RETURN:
                block->bbLiveOut = 0;
                break;
            }

            for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
            {
                assert(stmt->gtOper == GT_STMT);

                for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
                {
//                  printf("[%08X]\n", tree);
//                  if  ((int)tree == 0x011d0ab4) debugStop(0);
                    tree->gtLiveSet = liveAll;
                }
            }
        }

        return;
    }

#endif

    if  (opts.compMinOptim || opts.compDbgCode)
        goto NO_IX_OPT;

    /* Locate all index operations and assign indices to them */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                if (tree->gtOper == GT_ARR_LENGTH)
                {
                    GenTreePtr      con;
                    GenTreePtr      arr;
                    GenTreePtr      add;

                    /* Create the expression "*(array_addr + ARR_ELCNT_OFFS)" */

                    arr = tree->gtOp.gtOp1;
                    assert(arr->gtNext == tree);

                    con = gtNewIconNode(ARR_ELCNT_OFFS, TYP_INT);
#if!TGT_IA64
                    con->gtRsvdRegs = 0;
#if TGT_x86
                    con->gtFPlvl    = arr->gtFPlvl;
#else
                    con->gtIntfRegs = arr->gtIntfRegs;
#endif
#endif
                    add = gtNewOperNode(GT_ADD, TYP_REF, arr, con);
#if!TGT_IA64
                    add->gtRsvdRegs = arr->gtRsvdRegs;
#if TGT_x86
                    add->gtFPlvl    = arr->gtFPlvl;
#else
                    add->gtIntfRegs = arr->gtIntfRegs;
#endif
#endif
                    arr->gtNext = con;
                                  con->gtPrev = arr;

                    con->gtNext = add;
                                  add->gtPrev = con;

                    add->gtNext = tree;
                                  tree->gtPrev = add;

                    tree->gtOper     = GT_IND;
                    tree->gtOp.gtOp1 = add;
                }
            }
        }
    }

NO_IX_OPT:

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;
        GenTreePtr      lshNode;
        bool            lscVarAsg;

        fgCurUseSet = fgCurDefSet = 0;

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            lscVarAsg = false;
            lshNode = 0;
            tree = stmt->gtStmt.gtStmtExpr;
            assert(tree);

            /* the following is to check if we have an assignment expression
             * which may become a GTF_VAR_USEDEF - x=f(x) */

            if (tree->gtOper == GT_ASG)
            {
                assert(tree->gtOp.gtOp1);
                assert(tree->gtOp.gtOp2);

                /* consider if LHS is local var - ignore if RHS contains SIDE_EFFECTS */

                if ((tree->gtOp.gtOp1->gtOper == GT_LCL_VAR) && ((tree->gtOp.gtOp2->gtFlags & GTF_SIDE_EFFECT) == 0))
                {
                    /* Assignement to local var with no SIDE EFFECTS
                     * set this flag so that genMarkUseDef will flag potential x=f(x) expressions as GTF_VAR_USEDEF
                     * lshNode is the variable being assigned */

                    lscVarAsg = true;
                    lshNode = tree->gtOp.gtOp1;
                }
            }

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                switch (tree->gtOper)
                {
                case GT_LCL_VAR:
                    fgMarkUseDef(tree, lscVarAsg, lshNode);
                    break;

#if RNGCHK_OPT
                case GT_IND:

                    /* We can add in call to error routine now */

                    if  (tree->gtFlags & GTF_IND_RNGCHK)
                    {
                        if  (opts.compMinOptim || opts.compDbgCode)
                        {
                            assert(tree->gtOp.gtOp2);
                            assert(tree->gtOp.gtOp2->gtOper == GT_LABEL);
                        }
                        else
                        {
                            BasicBlock *    rngErr;

                            /* Create/find the appropriate "rangefail" label */

                            rngErr = fgRngChkTarget(block, tree->gtInd.gtStkDepth);

                            /* Add the label to the indirection node */

                            tree->gtOp.gtOp2 = gtNewCodeRef(rngErr);
                        }
                    }
                    break;
#endif
                }
            }
        }

#if INLINE_NDIRECT

        /* Get the TCB local and mark it as used */

        if  (block->bbJumpKind == BBJ_RETURN && info.compCallUnmanaged)
        {
            VARSET_TP       bitMask;
            unsigned        varIndex = lvaTable[info.compLvFrameListRoot].lvVarIndex;

            assert(varIndex < lvaTrackedCount);

            bitMask = genVarIndexToBit(varIndex);

            fgCurUseSet |= bitMask;

        }
#endif

#ifdef  DEBUG   // {

        if  (verbose)
        {
            printf("BB #%3u", block->bbNum);
            printf(" USE="); lvaDispVarSet(fgCurUseSet, 28);
            printf(" DEF="); lvaDispVarSet(fgCurDefSet, 28);
            printf("\n");
        }

#endif   // DEBUG }

        block->bbVarUse = fgCurUseSet;
        block->bbVarDef = fgCurDefSet;

        /* also initialize the IN set, just in case we will do multiple DFAs */

        block->bbLiveIn = 0;
        //block->bbLiveOut = 0;
    }
}



/*****************************************************************************/

#ifdef DEBUGGING_SUPPORT

// Helper functions to mark variables live over their entire scope

/* static */
void                Compiler::fgBeginScopeLife(LocalVarDsc *var, unsigned clientData)
{
    ASSert(clientData);
    Compiler * _this = (Compiler *)clientData;
    Assert(var, _this);

    LclVarDsc * lclVarDsc1 = & _this->lvaTable[var->lvdVarNum];

    if (lclVarDsc1->lvTracked)
        _this->fgLiveCb |= genVarIndexToBit(lclVarDsc1->lvVarIndex);
}

/* static */
void                Compiler::fgEndScopeLife(LocalVarDsc * var, unsigned clientData)
{
    ASSert(clientData);
    Compiler * _this = (Compiler *)clientData;
    Assert(var, _this);

    LclVarDsc * lclVarDsc1 = &_this->lvaTable[var->lvdVarNum];

    if (lclVarDsc1->lvTracked)
        _this->fgLiveCb &= ~genVarIndexToBit(lclVarDsc1->lvVarIndex);
}

#endif

/*****************************************************************************/
#ifdef DEBUGGING_SUPPORT
/*****************************************************************************
 *
 * For debuggable code, we allow redundant assignments to vars
 * by marking them live over their entire scope
 */

void                fgMarkInScope(BasicBlock * block, VARSET_TP inScope)
{
    /* Record which vars are artifically kept alive for debugging */

    block->bbScope    = inScope & ~block->bbLiveIn;

    /* Artifically mark all vars in scope as alive */

    block->bbLiveIn  |= inScope;
    block->bbLiveOut |= inScope;
}


void                Compiler::fgExtendDbgLifetimes()
{
    assert(opts.compDbgCode && info.compLocalVarsCount>0);

    /*-------------------------------------------------------------------------
     *   Now extend the lifetimes
     */

    BasicBlock  *   block;
    VARSET_TP       inScope = 0;
    LocalVarDsc *   LocalVarDsc1;
    LclVarDsc   *   lclVarDsc1;
    unsigned        lastEndOffs = 0;

    compResetScopeLists();

    // Mark all tracked LocalVars live over their scope - walk the blocks
    // keeping track of the current life, and assign it to the blocks.

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        // If a block doesnt correspond to any IL opcodes, it can have no
        // scopes defined on its boundaries

        if ((block->bbFlags & BBF_INTERNAL) || block->bbCodeSize==0)
        {
            fgMarkInScope(block, inScope);
            continue;
        }

        // Find scopes becoming alive. If there is a gap in the IL opcode
        // sequence, we need to process any scopes on those missing offsets.

        if (lastEndOffs != block->bbCodeOffs)
        {
            assert(lastEndOffs < block->bbCodeOffs);

            fgLiveCb = inScope;
            compProcessScopesUntil (block->bbCodeOffs,
                                   fgBeginScopeLife, fgEndScopeLife,
                                   (unsigned) this);
            inScope  = fgLiveCb;
        }
        else
        {
            while (LocalVarDsc1 = compGetNextEnterScope(block->bbCodeOffs))
            {
                lclVarDsc1 = &lvaTable[LocalVarDsc1->lvdVarNum];

                if (!lclVarDsc1->lvTracked)
                    continue;

                inScope |= genVarIndexToBit(lclVarDsc1->lvVarIndex);
            }
        }

        fgMarkInScope(block, inScope);

        // Find scopes goind dead.

        while (LocalVarDsc1 = compGetNextExitScope(block->bbCodeOffs+block->bbCodeSize))
        {
            lclVarDsc1 = &lvaTable[LocalVarDsc1->lvdVarNum];

            if (!lclVarDsc1->lvTracked)
                continue;

            inScope &= ~genVarIndexToBit(lclVarDsc1->lvVarIndex);
        }

        lastEndOffs = block->bbCodeOffs + block->bbCodeSize;
    }

    /* Everything should be out of scope by the end of the method. But if the
       last BB got removed, then inScope may not be 0 */

    assert(inScope == 0 || lastEndOffs < info.compCodeSize);

#ifdef  DEBUG

    if  (verbose)
    {
        printf("\nLiveness after marking vars alive over their enitre scope :\n\n");

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            if  (!(block->bbFlags & BBF_INTERNAL))
            {
                printf("BB #%3u", block->bbNum);
                printf(" IN ="); lvaDispVarSet(block->bbLiveIn , 28);
                printf(" OUT="); lvaDispVarSet(block->bbLiveOut, 28);
                printf("\n");
            }
        }

        printf("\n");
    }

#endif // DEBUG


    //
    // Compute argsLiveIn mask:
    //   Basically this is the union of all the tracked arguments
    //
    VARSET_TP   argsLiveIn = 0;
    LclVarDsc * argDsc     = &lvaTable[0];
    for (unsigned argNum = 0; argNum < info.compArgsCount; argNum++, argDsc++)
    {
        assert(argDsc->lvIsParam);
        if (argDsc->lvTracked)
        {
            VARSET_TP curArgBit = genVarIndexToBit(argDsc->lvVarIndex);
            assert((argsLiveIn & curArgBit) == 0); // Each arg should define a different bit.
            argsLiveIn |= curArgBit;
        }
    }

    // For compDbgCode, we prepend an empty BB which will hold the initializations
    // of variables which are in scope at IL offset 0 (but not initialized by the
    // IL code) yet. If an argument is not live on entry but in scope, we would
    // not have extend the liveness to the BBF_INTERNAL fgFirstBB. Do that explicitly.

    assert((fgFirstBB->bbFlags & BBF_INTERNAL) && fgFirstBB->bbJumpKind == BBJ_NONE);

    fgMarkInScope(fgFirstBB, argsLiveIn & fgFirstBB->bbNext->bbScope);

    /*-------------------------------------------------------------------------
     * As we keep variables artifically alive over their entire scope,
     * we need to also artificially initialize them if the scope does
     * not exactly match the real lifetimes, or they will contain
     * garbage until they are initialized by the IL code
     */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        VARSET_TP initVars = 0; // Vars which are artificially made alive

        switch(block->bbJumpKind)
        {
        case BBJ_NONE:      initVars |= block->bbNext->bbScope;     break;

        case BBJ_ALWAYS:    initVars |= block->bbJumpDest->bbScope; break;

        case BBJ_CALL:
        case BBJ_COND:      initVars |= block->bbNext->bbScope;
                            initVars |= block->bbJumpDest->bbScope; break;

        case BBJ_SWITCH:    BasicBlock * *  jmpTab;
                            unsigned        jmpCnt;

                            jmpCnt = block->bbJumpSwt->bbsCount;
                            jmpTab = block->bbJumpSwt->bbsDstTab;

                            do
                            {
                                initVars |= (*jmpTab)->bbScope;
                            }
                            while (++jmpTab, --jmpCnt);
                            break;

        case BBJ_RET:
                            if (block->bbFlags & BBF_ENDFILTER)
                                initVars |= block->bbJumpDest->bbScope;
                            break;
        case BBJ_RETURN:    break;

        case BBJ_THROW:     /* HACK : We dont have to do anything as we mark
                             * all vars live on entry to a catch handler as
                             * volatile anyway
                             */
                            break;

        default:            assert(!"Invalid bbJumpKind");          break;
        }

        //
        // If the var is already live on entry to the current BB,
        // we would have already initialized it.
        // So we ignore bbLiveIn and argsLiveIn
        //
        initVars &= ~(block->bbLiveIn | argsLiveIn);

        /* Add statements initializing the vars */

        VARSET_TP        varBit = 0x1;

        for(unsigned     varIndex = 0;
            initVars && (varIndex < lvaTrackedCount);
            varBit<<=1,  varIndex++)
        {
            if (!(initVars & varBit))
                continue;

            initVars &= ~varBit;

            /* Create initialization tree */

            unsigned        varNum  = lvaTrackedVarNums[varIndex];
            LclVarDsc *     varDsc  = &lvaTable[varNum];
            var_types       type    = (var_types) varDsc->lvType;

            // Create a "zero" node

            GenTreePtr      zero    = gtNewZeroConNode(genActualType(type));

            // Create initialization node

            GenTreePtr      varNode = gtNewLclvNode(varNum, type);
            GenTreePtr      initNode= gtNewAssignNode(varNode, zero);
            GenTreePtr      initStmt= gtNewStmt(initNode);

            gtSetStmtInfo (initStmt);

            block->bbLiveOut   |= varBit;

            /* Assign numbers and next/prev links for this tree */

            fgSetStmtSeq(initStmt);

            /* Finally append the statement to the current BB */

            fgInsertStmtNearEnd(block, initStmt);
        }
    }
}


/*****************************************************************************/
#endif // DEBUGGING_SUPPORT
/*****************************************************************************
 *
 *  This is the standard Dragon Book Algorithm for Live Variable Analisys
 *
 */

void                Compiler::fgLiveVarAnalisys()
{
    BasicBlock *    block;
    bool            change;
#ifdef DEBUG
    VARSET_TP       extraLiveOutFromFinally = 0;
#endif

    /* Live Variable Analisys - Backward dataflow */

    do
    {
        change = false;

        /* Visit all blocks and compute new data flow values */

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            VARSET_TP       liveIn;
            VARSET_TP       liveOut;

            /* Compute the 'liveOut' set */

            liveOut = 0;

            switch (block->bbJumpKind)
            {
                BasicBlock * *  jmpTab;
                unsigned        jmpCnt;

                BasicBlock *    bcall;

            case BBJ_RET:

                /* Filter needs to look at its catch handler */

                if (block->bbFlags & BBF_ENDFILTER)
                {
                    liveOut                     |= block->bbJumpDest->bbLiveIn;
                    break;
                }

                /*
                    Variables that are live on entry to any block that follows
                    one that 'calls' our block will also be live on exit from
                    this block, since it will return to the block following the
                    call.

                    UNDONE: Since it's not a trivial proposition to figure out
                    UNDONE: which blocks may call this one, we'll include all
                    UNDONE: blocks that end in calls (to play it safe).
                 */

                for (bcall = fgFirstBB; bcall; bcall = bcall->bbNext)
                {
                    if  (bcall->bbJumpKind == BBJ_CALL)
                    {
                        assert(bcall->bbNext);

                        liveOut                 |= bcall->bbNext->bbLiveIn;
#ifdef DEBUG
                        extraLiveOutFromFinally |= bcall->bbNext->bbLiveIn;
#endif
                    }
                }
                break;

            case BBJ_THROW:

                /* For synchronized methods, "this" has to be kept alive past
                   the throw, as the EE will call CPX_MON_EXIT on it */

                if ((info.compFlags & FLG_SYNCH) &&
                    !info.compIsStatic && lvaTable[0].lvTracked)
                    liveOut |= genVarIndexToBit(lvaTable[0].lvIndex);
                break;

            case BBJ_RETURN:
                break;

            case BBJ_COND:
            case BBJ_CALL:
                liveOut |= block->bbNext    ->bbLiveIn;
                liveOut |= block->bbJumpDest->bbLiveIn;

                break;

            case BBJ_ALWAYS:
                liveOut |= block->bbJumpDest->bbLiveIn;

                break;

            case BBJ_NONE:
                liveOut |= block->bbNext    ->bbLiveIn;

                break;

            case BBJ_SWITCH:

                jmpCnt = block->bbJumpSwt->bbsCount;
                jmpTab = block->bbJumpSwt->bbsDstTab;

                do
                {
                    liveOut |= (*jmpTab)->bbLiveIn;
                }
                while (++jmpTab, --jmpCnt);

                break;
            }

            /* Compute the 'liveIn'  set */

            liveIn = block->bbVarUse | (liveOut & ~block->bbVarDef);

            /* Is this block part of a 'try' statement? */

            if  (block->bbFlags & BBF_HAS_HANDLER)
            {
                unsigned        XTnum;
                EHblkDsc *      HBtab;

                unsigned        blkNum = block->bbNum;

                /*
                    Note:   The following is somewhat over-eager since
                            only code that follows an operation that
                            may raise an exception may jump to a catch
                            block, e.g.:

                                try
                                {
                                    a = 10; // 'a' is not live at beg of try

                                    func(); // this might cause an exception

                                    b = 20; // 'b' is     live at beg of try
                                }
                                catch(...)
                                {
                                    ...
                                }

                            But, it's too tricky to be smarter about this
                            and most likely not worth the extra headache.
                 */

                for (XTnum = 0, HBtab = compHndBBtab;
                     XTnum < info.compXcptnsCount;
                     XTnum++  , HBtab++)
                {
                    /* Any handler may be jumped to from the try block */

                    if  (HBtab->ebdTryBeg->bbNum <= blkNum &&
                         HBtab->ebdTryEnd->bbNum >  blkNum)
                    {
                        /* Either we enter the filter or the catch/finally */

                        if (HBtab->ebdFlags & JIT_EH_CLAUSE_FILTER)
                        {
                            liveIn  |= HBtab->ebdFilter->bbLiveIn;
                            liveOut |= HBtab->ebdFilter->bbLiveIn;
                        }
                        else
                        {
                            liveIn  |= HBtab->ebdHndBeg->bbLiveIn;
                            liveOut |= HBtab->ebdHndBeg->bbLiveIn;
                        }

                    }
                }
            }

//          printf("BB#%2u: IN=%s OUT=%s\n", block->bbNum, genVS2str(liveIn), genVS2str(liveOut));

            /* Has there been any change in either live set? */

            if  (block->bbLiveIn  != liveIn ||
                 block->bbLiveOut != liveOut)
            {
                block->bbLiveIn   = liveIn;
                block->bbLiveOut  = liveOut;

                 change = true;
            }

        }

    }
    while (change);

    //-------------------------------------------------------------------------

#ifdef DEBUGGING_SUPPORT

    /* For debuggable code, we mark vars as live over their entire
     * reported scope, so that it will be visible over the entire scope
     */

    if (opts.compDbgCode && info.compLocalVarsCount>0)
    {
        fgExtendDbgLifetimes();
    }

#endif

    //-------------------------------------------------------------------------

#ifdef  DEBUG

    if  (verbose)
    {
        printf("\n");

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            printf("BB #%3u", block->bbNum);
            printf(" IN ="); lvaDispVarSet(block->bbLiveIn , 28);
            printf(" OUT="); lvaDispVarSet(block->bbLiveOut, 28);
            printf("\n");
        }

        printf("\n");
        fgDispBasicBlocks();
        printf("\n");
    }

#endif // DEBUG
}


/*****************************************************************************
 *
 * Compute the set of live variables at each node in a given statement
 * or subtree of a statement
 */

VARSET_TP           Compiler::fgComputeLife(VARSET_TP   life,
                                            GenTreePtr  startNode,
                                            GenTreePtr    endNode,
                                            VARSET_TP   notVolatile)
{
    GenTreePtr      tree;
    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    GenTreePtr      gtQMark = NULL;     // current GT_QMARK node (walking the trees backwards)
    GenTreePtr      nextColonExit = 0;  // gtQMark->gtOp.gtOp2 while walking the 'else' branch.
                                        // gtQMark->gtOp.gtOp1 while walking the 'then' branch
    VARSET_TP       entryLiveSet;       // liveness when we see gtQMark

    assert(compCurStmt->gtOper == GT_STMT);
    assert(endNode || (startNode == compCurStmt->gtStmt.gtStmtExpr));

    /* NOTE: Live variable analysis will not work if you try
     * to use the result of an assignment node directly */

    for (tree = startNode; tree != endNode; tree = tree->gtPrev)
    {
AGAIN:
        /* Store the current liveset in the node */

        tree->gtLiveSet = life;

#ifdef  DEBUG
        if (verbose && 1) printf("Visit [%08X(%10s)] life %s\n", tree,
                        GenTree::NodeName(tree->OperGet()), genVS2str(life));
#endif

        /* For ?: nodes if we're done with the second branch
         * then set the correct life as the reunion of the two branches */

        if (gtQMark && (tree == gtQMark->gtOp.gtOp1))
        {
            assert(tree->gtFlags & GTF_QMARK_COND);
            assert(gtQMark->gtOp.gtOp2->gtOper == GT_COLON);

            GenTreePtr  gtColon = gtQMark->gtOp.gtOp2;

            assert(gtColon->gtOp.gtOp1 && gtColon->gtOp.gtOp1);

            /* Check if we optimized away the ?: */

            if (gtColon->gtOp.gtOp1->IsNothingNode() &&
                gtColon->gtOp.gtOp2->IsNothingNode())
            {
                /* This can only happen for VOID ?: */
                assert(gtColon->gtType == TYP_VOID);

#ifdef  DEBUG
                if  (verbose || 0)
                {
                    printf("\nBlock #%02u - Removing dead QMark - Colon ...\n", compCurBB->bbNum);
                    gtDispTree(gtQMark); printf("\n");
                }
#endif

                /* Remove the '?:' - keep the side effects in the condition */

                assert(tree->OperKind() & GTK_RELOP);

                /* Bash the node to a NOP */

                gtQMark->gtBashToNOP();

                /* Extract and keep the side effects */

                if (tree->gtFlags & GTF_SIDE_EFFECT)
                {
                    GenTreePtr      sideEffList = 0;

                    gtExtractSideEffList(tree, &sideEffList);

                    if (sideEffList)
                    {
                        assert(sideEffList->gtFlags & GTF_SIDE_EFFECT);
#ifdef  DEBUG
                        if  (verbose || 0)
                        {
                            printf("\nExtracted side effects list from condition...\n");
                            gtDispTree(sideEffList); printf("\n");
                        }
#endif
                        /* The NOP node becomes a GT_COMMA holding the side effect list */

                        gtQMark->gtOper  = GT_COMMA;
                        gtQMark->gtFlags |= sideEffList->gtFlags & GTF_GLOB_EFFECT;

                        if (sideEffList->gtOper == GT_COMMA)
                        {
                            gtQMark->gtOp.gtOp1 = sideEffList->gtOp.gtOp1;
                            gtQMark->gtOp.gtOp2 = sideEffList->gtOp.gtOp2;
                        }
                        else
                        {
                            gtQMark->gtOp.gtOp1 = sideEffList;
                            gtQMark->gtOp.gtOp2 = gtNewNothingNode();
                        }
                    }
                }

                /* If top node without side effects remove it */

                if ((gtQMark == compCurStmt->gtStmt.gtStmtExpr) && gtQMark->IsNothingNode())
                {
                    fgRemoveStmt(compCurBB, compCurStmt, true);
                    break;
                }

                /* Re-link the nodes for this statement */

                fgSetStmtSeq(compCurStmt);

                /* Continue analisys from this node */

                tree = gtQMark;

                /* As the 'then' and 'else' branches are emtpy, liveness
                   should not have changed */

                assert(life == entryLiveSet && tree->gtLiveSet == life);
            }
            else
            {
                /* Variables in the two branches that are live at the split
                 * must interfere with each other */

                lvaMarkIntf(life, gtColon->gtLiveSet);

                /* The live set at the split is the union of the two branches */

                life |= gtColon->gtLiveSet;

                /* Update the current liveset in the node */

                tree->gtLiveSet = gtColon->gtLiveSet = life;

                /* Any new born variables in the ?: branches must interfere
                 * with any other variables live across the conditional */

                //lvaMarkIntf(life & entryLiveSet, life & ~entryLiveSet);
            }

            /* We are out of the parallel branches, the rest is sequential */

            gtQMark = NULL;
        }

        /* Is this a use/def of a local variable? */

        if  (tree->gtOper == GT_LCL_VAR)
        {
            lclNum = tree->gtLclVar.gtLclNum;

            assert(lclNum < lvaCount);
            varDsc = lvaTable + lclNum;

            /* Is this a tracked variable? */

            if  (varDsc->lvTracked)
            {
                unsigned        varIndex;
                VARSET_TP       varBit;

                varIndex = varDsc->lvVarIndex;
                assert(varIndex < lvaTrackedCount);
                varBit   = genVarIndexToBit(varIndex);

                /* Is this a definition or use? */

                if  ((tree->gtFlags & GTF_VAR_DEF) != 0)
                {
                    /*
                        The variable is being defined here. The variable
                        should be marked dead from here until its closest
                        previous use.

                        IMPORTANT OBSERVATION:

                            For GTF_VAR_USE (i.e. x <op>= a) we cannot
                            consider it a "pure" definition because it would
                            kill x (which would be wrong because x is
                            "used" in such a construct) -> see below the case when x is live
                     */

                    if  (life & varBit)
                    {
                        /* The variable is live */

                        if ((tree->gtFlags & GTF_VAR_USE) == 0)
                        {
                            /* Mark variable as dead from here to its closest use */
#ifdef  DEBUG
                            if (verbose&&0) printf("Def #%2u[%2u] at [%08X] life %s -> %s\n", lclNum, varIndex, tree, genVS2str(life), genVS2str(life & ~varBit));
#endif
                            life &= ~(varBit & notVolatile
#ifdef  DEBUGGING_SUPPORT                        /* Dont kill vars in scope */
                                             & ~compCurBB->bbScope
#endif
                                     );
                        }
                    }
                    else
#ifdef  DEBUGGING_SUPPORT
                    if (!opts.compMinOptim && !opts.compDbgCode)
#endif
                    {
                        /* Assignment to a dead variable - This is a dead store unless
                         * the variable is marked GTF_VAR_USE and we are in an interior statement
                         * that will be used (e.g. while(i++) or a GT_COMMA) */

                        GenTreePtr asgNode = tree->gtNext;

                        assert(asgNode->gtFlags & GTF_ASG);
                        assert(asgNode->gtOp.gtOp2);
                        assert(tree->gtFlags & GTF_VAR_DEF);

                        /* Do not remove if we need the address of the variable */
                        if(lvaVarAddrTaken(lclNum)) continue;

                        /* Test for interior statement */

                        if (asgNode->gtNext == 0)
                        {
                            /* This is a "NORMAL" statement with the
                             * assignment node hanging from the GT_STMT node */

                            assert(compCurStmt->gtStmt.gtStmtExpr == asgNode);

                            /* Check for side effects */

                            if (asgNode->gtOp.gtOp2->gtFlags & (GTF_SIDE_EFFECT & ~GTF_OTHER_SIDEEFF))
                            {
                                /* Extract the side effects */

                                GenTreePtr      sideEffList = 0;
#ifdef  DEBUG
                                if  (verbose || 0)
                                {
                                    printf("\nBlock #%02u - Dead assignment has side effects...\n", compCurBB->bbNum);
                                    gtDispTree(asgNode); printf("\n");
                                }
#endif
                                gtExtractSideEffList(asgNode->gtOp.gtOp2, &sideEffList);

                                if (sideEffList)
                                {
                                    assert(sideEffList->gtFlags & GTF_SIDE_EFFECT);
#ifdef  DEBUG
                                    if  (verbose || 0)
                                    {
                                        printf("\nExtracted side effects list...\n");
                                        gtDispTree(sideEffList); printf("\n");
                                    }
#endif
                                    /* Update the refCnts of removed lcl vars - The problem is that
                                     * we have to consider back the side effects trees so we first
                                     * increment all refCnts for side effects then decrement everything
                                     * in the statement
                                     *
                                     * UNDONE: We do it in this weird way to keep the RefCnt as accurate
                                     * as possible because currently we cannot decrement it to 0 during dataflow */

                                    fgWalkTree(sideEffList,                    Compiler::lvaIncRefCntsCB, (void *) this, true);
                                    fgWalkTree(compCurStmt->gtStmt.gtStmtExpr, Compiler::lvaDecRefCntsCB, (void *) this, true);


                                    /* Replace the assignment statement with the list of side effects */
                                    assert(sideEffList->gtOper != GT_STMT);

                                    tree = compCurStmt->gtStmt.gtStmtExpr = sideEffList;

                                    /* Update ordering, costs, FP levels, etc. */
                                    gtSetStmtInfo(compCurStmt);

                                    /* Re-link the nodes for this statement */
                                    fgSetStmtSeq(compCurStmt);

                                    /* Compute the live set for the new statement */
                                    goto AGAIN;
                                }
                                else
                                {
                                    /* No side effects, most likely we forgot to reset some flags */
                                    fgRemoveStmt(compCurBB, compCurStmt, true);
                                    break;
                                }
                            }
                            else
                            {
                                /* If this is GT_CATCH_ARG saved to a local var don't bother */

                                if (asgNode->gtFlags & GTF_OTHER_SIDEEFF)
                                {
                                    if (asgNode->gtOp.gtOp2->gtOper == GT_CATCH_ARG)
                                        continue;
                                }

                                /* No side effects - remove the whole statement from the block->bbTreeList */

                                fgRemoveStmt(compCurBB, compCurStmt, true);

                                /* Since we removed it do not process the rest (i.e. RHS) of the statement
                                 * variables in the RHS will not be marked as live, so we get the benefit of
                                 * propagating dead variables up the chain */

                                break;
                            }
                        }
                        else
                        {
                            /* This is an INTERIOR STATEMENT with a dead assignment - remove it */

                            assert(!(life & varBit));

//                          gtDispTree(compCurStmt);

                            if (asgNode->gtOp.gtOp2->gtFlags & GTF_SIDE_EFFECT)
                            {
                                /* Bummer we have side effects */

                                GenTreePtr      sideEffList = 0;

#ifdef  DEBUG
                                if  (verbose || 0)
                                {
                                    printf("\nBlock #%02u - INTERIOR dead assignment has side effects...\n", compCurBB->bbNum);
                                    gtDispTree(asgNode); printf("\n");
                                }
#endif

                                gtExtractSideEffList(asgNode->gtOp.gtOp2, &sideEffList);

                                assert(sideEffList); assert(sideEffList->gtFlags & GTF_SIDE_EFFECT);

#ifdef  DEBUG
                                if  (verbose || 0)
                                {
                                    printf("\nExtracted side effects list from condition...\n");
                                    gtDispTree(sideEffList); printf("\n");
                                }
#endif
                                /* Bash the node to a GT_COMMA holding the side effect list */

                                asgNode->gtBashToNOP();

                                asgNode->gtOper  = GT_COMMA;
                                asgNode->gtFlags |= sideEffList->gtFlags & GTF_GLOB_EFFECT;

                                if (sideEffList->gtOper == GT_COMMA)
                                {
                                    asgNode->gtOp.gtOp1 = sideEffList->gtOp.gtOp1;
                                    asgNode->gtOp.gtOp2 = sideEffList->gtOp.gtOp2;
                                }
                                else
                                {
                                    asgNode->gtOp.gtOp1 = sideEffList;
                                    asgNode->gtOp.gtOp2 = gtNewNothingNode();
                                }
                            }
                            else
                            {
                                /* No side effects - Remove the interior statement */
#ifdef DEBUG
                                if (verbose)
                                {
                                    printf("\nRemoving interior statement [%08X] in block #%02u as useless\n",
                                                                         asgNode, compCurBB->bbNum);
                                    gtDispTree(asgNode,0);
                                    printf("\n");
                                }
#endif
                                /* Update the refCnts of removed lcl vars */

                                fgWalkTree(asgNode, Compiler::lvaDecRefCntsCB, (void *) this, true);

                                /* Bash the assignment to a GT_NOP node */

                                asgNode->gtBashToNOP();
                            }

                            /* Re-link the nodes for this statement - Do not update ordering! */

                            fgSetStmtSeq(compCurStmt);

                            /* Continue analisys from this node */

                            tree = asgNode;

                            /* Store the current liveset in the node and
                             * continue the for loop with the next node */

                            tree->gtLiveSet = life;

                            continue;
                        }
                    }

                    continue;
                }

                /* Is the variable already known to be alive? */

                if  (life & varBit)
                    continue;
#ifdef  DEBUG
                if (verbose&&0) printf("Ref #%2u[%2u] at [%08X] life %s -> %s\n", lclNum, varIndex, tree, genVS2str(life), genVS2str(life | varBit));
#endif
                /* The variable is being used, and it is not currently live.
                 * So the variable is just coming to life */

                life |= varBit;

                /* Record interference with other live variables */

                lvaMarkIntf(life, varBit);
            }
        }
        else
        {
            if (tree->gtOper == GT_QMARK && tree->gtOp.gtOp1)
            {
                /* Special cases - "? :" operators.

                   The trees are threaded as shown below with nodes 1 to 11 linked
                   by gtNext. Both GT_<cond>->gtLiveSet and GT_COLON->gtLiveSet are
                   the union of the liveness on entry to thenTree and elseTree.

                                  +--------------------+
                                  |      GT_QMARK    11|
                                  +----------+---------+
                                             |
                                             *
                                            / \
                                          /     \
                                        /         \
                   +--------------------+        +--------------------+
                   |      GT_<cond>    3|        |     GT_COLON     7 |
                   |  w/ GTF_QMARK_COND |        |                    |
                   +----------+---------+        +---------+----------+
                              |                            |
                              *                            *
                             / \                          / \
                           /     \                      /     \
                         /         \                  /         \
                        2           1          thenTree 6       elseTree 10
                                   x               |                |
                                  /                *                *
      +----------------+        /                 / \              / \
      |prevExpr->gtNext+------/                 /     \          /     \
      +----------------+                      /         \      /         \
                                             5           4    9           8

                 */

                assert(tree->gtOp.gtOp1->OperKind() & GTK_RELOP);
                assert(tree->gtOp.gtOp1->gtFlags & GTF_QMARK_COND);
                assert(tree->gtOp.gtOp2->gtOper == GT_COLON);

                if (gtQMark)
                {
                    /* This is a nested QMARK sequence - we need to use recursivity
                     * Compute the liveness for each node of the COLON branches
                     * The new computation starts from the GT_QMARK node and ends
                     * when the COLON branch of the enclosing QMARK ends */

                    assert(nextColonExit && (nextColonExit == gtQMark->gtOp.gtOp1 ||
                                             nextColonExit == gtQMark->gtOp.gtOp2));

                    life = fgComputeLife(life, tree, nextColonExit, notVolatile);

                    /* Continue with exit node (the last node in the enclossing colon branch) */

                    tree = nextColonExit;
                    goto AGAIN;
                    //continue;
                }
                else
                {
                    gtQMark       = tree;
                    entryLiveSet  = life;
                    nextColonExit = gtQMark->gtOp.gtOp2;
                }
            }

            /* If found the GT_COLON, start the new branch with the original life */

            if (gtQMark && tree == gtQMark->gtOp.gtOp2)
            {
                /* The node better be a COLON with a valid 'if' branch
                 * Special case: both branches may be NOP */
                assert(tree->gtOper == GT_COLON);
                assert(!tree->gtOp.gtOp1->IsNothingNode()                                      ||
                       (tree->gtOp.gtOp1->IsNothingNode() && tree->gtOp.gtOp1->IsNothingNode()) );

                life          = entryLiveSet;
                nextColonExit = gtQMark->gtOp.gtOp1;
            }

            /* Special case: address modes with arrlen CSE's */

#if     CSELENGTH
#if     TGT_x86

            if  ((tree->gtFlags & GTF_IND_RNGCHK) != 0       &&
                 (tree->gtOper                    == GT_IND) &&
                 (tree->gtInd.gtIndLen            != NULL))
            {
                GenTreePtr      addr;
                GenTreePtr      indx;
                GenTreePtr      lenx;

                VARSET_TP       temp;

                /* Get hold of the array length node */

                lenx = tree->gtInd.gtIndLen;
                assert(lenx->gtOper == GT_ARR_RNGCHK);

                /* If there is no CSE, forget it */

                lenx = lenx->gtArrLen.gtArrLenCse;
                if  (!lenx)
                    continue;

                if  (lenx->gtOper == GT_COMMA)
                    lenx = lenx->gtOp.gtOp2;

                assert(lenx->gtOper == GT_LCL_VAR);

                /* Is this going to be an address mode? */

                addr = genIsAddrMode(tree->gtOp.gtOp1, &indx);
                if  (!addr)
                    continue;

                temp = addr->gtLiveSet;

//                      printf("addr:\n"); gtDispTree(addr); printf("\n");

                if  (indx)
                {
//                          printf("indx:\n"); gtDispTree(indx); printf("\n");

                    temp |= indx->gtLiveSet;
                }

                /* Mark any interference caused by the arrlen CSE */

                lclNum = lenx->gtLclVar.gtLclNum;
                assert(lclNum < lvaCount);
                varDsc = lvaTable + lclNum;

                /* Is this a tracked variable? */

                if  (varDsc->lvTracked)
                    lvaMarkIntf(temp, genVarIndexToBit(varDsc->lvVarIndex));
            }
#endif
#endif
        }
    }

    /* Return the set of live variables out of this statement */

    return life;
}


/*****************************************************************************
 *
 *  Iterative data flow for live variable info and availability of range
 *  check index expressions.
 */

void                Compiler::fgGlobalDataFlow()
{
    BasicBlock *    block;

    /* If we're not optimizing at all, things are simple */

    if  (opts.compMinOptim)
    {
        /* Simply assume that all variables interfere with each other */

        memset(lvaVarIntf, 0xFF, sizeof(lvaVarIntf));
        return;
    }
    else
    {
        memset(lvaVarIntf, 0, sizeof(lvaVarIntf));
    }

    /* This global flag is set whenever we remove a statement */

    fgStmtRemoved = false;

    /* Compute the IN and OUT sets for tracked variables */

    fgLiveVarAnalisys();

    /*-------------------------------------------------------------------------
     * Variables involved in exception-handlers and finally blocks need
     * to be specially marked
     */

    VARSET_TP    exceptVars = 0;    // vars live on entry to a handler
    VARSET_TP   finallyVars = 0;    // vars live on exit of a 'finally' block
    VARSET_TP    filterVars = 0;    // vars live on exit from a 'filter'

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        if  (block->bbCatchTyp)
        {
            /* Note the set of variables live on entry to exception handler */

            exceptVars  |= block->bbLiveIn;
        }

        if  (block->bbJumpKind == BBJ_RET)
        {

            if (block->bbFlags& BBF_ENDFILTER)
            {
                /* Get the set of live variables on exit from a 'filter' */
                filterVars |= block->bbLiveOut;
            }
            else
            {
                /* Get the set of live variables on exit from a 'finally' block */

                finallyVars |= block->bbLiveOut;
            }
        }
    }

    if (exceptVars || finallyVars || filterVars)
    {
        LclVarDsc   *   varDsc;
        unsigned        varNum;

        for (varNum = 0, varDsc = lvaTable;
             varNum < lvaCount;
             varNum++  , varDsc++)
        {
            /* Ignore the variable if it's not tracked */

            if  (!varDsc->lvTracked)
                continue;

            VARSET_TP   varBit = genVarIndexToBit(varDsc->lvVarIndex);

            /* Mark all variables that live on entry to an exception handler
               or on exit to a filter handler as volatile */

            if  ((varBit & exceptVars) || (varBit & filterVars))
            {
                /* Mark the variable appropriately */

                varDsc->lvVolatile = true;
            }

            /* Mark all pointer variables live on exit from a 'finally'
               block as 'explicitly initialized' (volatile and must-init) */

            if  (varBit & finallyVars)
            {
                /* Ignore if argument, or not a GC pointer */

                if  (!varTypeIsGC(varDsc->TypeGet()))
                    continue;

                if  (varDsc->lvIsParam)
#if USE_FASTCALL
                    if  (!varDsc->lvIsRegArg)
#endif
                        continue;

                /* Mark it */

                varDsc->lvVolatile = true;  // UNDONE: HACK: force the variable to the stack
                varDsc->lvMustInit = true;
            }
        }
    }


    /*-------------------------------------------------------------------------
     * Now fill in liveness info within each basic block - Backward DataFlow
     */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      firstStmt;
        GenTreePtr      nextStmt;

        VARSET_TP       life;
        VARSET_TP       notVolatile;

        /* Tell everyone what block we're working on */

        compCurBB = block;

        /* Get the first statement in the block */

        firstStmt = block->bbTreeList;

        if (!firstStmt) continue;

        /* Start with the variables live on exit from the block */

        life = block->bbLiveOut;

        /* Remember those vars life on entry to exception handlers */
        /* if we are part of a try block */

        if  (block->bbFlags & BBF_HAS_HANDLER)
        {
            unsigned        XTnum;
            EHblkDsc *      HBtab;

            unsigned        blkNum = block->bbNum;

            VARSET_TP       blockExceptVars = 0;

            for (XTnum = 0, HBtab = compHndBBtab;
                 XTnum < info.compXcptnsCount;
                 XTnum++  , HBtab++)
            {
                /* Any handler may be jumped to from the try block */

                if  (HBtab->ebdTryBeg->bbNum <= blkNum &&
                     HBtab->ebdTryEnd->bbNum >  blkNum)
                {
                    /* We either enter the filter or the catch/finally */

                    if (HBtab->ebdFlags & JIT_EH_CLAUSE_FILTER)
                        blockExceptVars |= HBtab->ebdFilter->bbLiveIn;
                    else
                        blockExceptVars |= HBtab->ebdHndBeg->bbLiveIn;
                }
            }

            // blockExceptVars is a subset of exceptVars
            assert((blockExceptVars & exceptVars) == blockExceptVars);

            notVolatile = ~(blockExceptVars);
        }
        else
            notVolatile = ~((VARSET_TP)0);

        /* Mark any interference we might have at the end of the block */

        lvaMarkIntf(life, life);

        /* Walk all the statements of the block backwards - Get the LAST stmt */

        nextStmt = firstStmt->gtPrev;

        do
        {
            assert(nextStmt);
            assert(nextStmt->gtOper == GT_STMT);

            compCurStmt = nextStmt;
                          nextStmt = nextStmt->gtPrev;

            /* Compute the liveness for each tree node in the statement */

            life = fgComputeLife(life, compCurStmt->gtStmt.gtStmtExpr, NULL, notVolatile);
        }
        while (compCurStmt != firstStmt);

        /* Done with the current block - if we removed any statements, some
         * variables may have become dead at the beginning of the block
         * -> have to update bbLiveIn */

        if (life != block->bbLiveIn)
        {
            /* some variables have become dead all across the block
               So life should be a subset of block->bbLiveIn */

            assert((life & block->bbLiveIn) == life);

            /* set the new bbLiveIn */

            block->bbLiveIn = life;

            /* compute the new bbLiveOut for all the predecessors of this block */

            /* UNDONE: since the predecessor list is currently in FindNaturalLoops
             * UNDONE: and limited to 64 basic blocks we can only set the OUT set
             * UNDONE: for the previous block, which doesn't make sense (see CONSIDER below)
             * UNDONE: The predecessor computation should be put in AssignBBnums */

            /* CONSIDER: Currently we do the DFA only on a per-block basis because
             * CONSIDER: we go through the BBlist forward!
             * CONSIDER: We should be able to combine PerBlockDataflow and GlobalDataFlow
             * CONSIDER: into one function that goes backward through the whole list and avoid
             * CONSIDER: computing the USE and DEF sets */

        }

#ifdef  DEBUG
        compCurBB = 0;
#endif

    }


#ifdef  DEBUG

    if  (verbose)
    {
        unsigned        lclNum;
        LclVarDsc   *   varDsc;

        printf("Var. interference graph for %s\n", info.compFullName);

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            if  (varDsc->lvTracked)
                printf("    Local %2u -> #%2u\n", lclNum, varDsc->lvVarIndex);
        }

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            unsigned        varIndex;
            VARSET_TP       varBit;
            VARSET_TP       varIntf;

            unsigned        refIndex;
            VARSET_TP       refBit;

            /* Ignore the variable if it's not tracked */

            if  (!varDsc->lvTracked)
                continue;

            /* Get hold of the index and the interference mask for the variable */

            varIndex = varDsc->lvVarIndex;
            varBit   = genVarIndexToBit(varIndex);
            varIntf  = lvaVarIntf[varIndex];

            printf("  var #%2u and ", varIndex);

            for (refIndex = 0, refBit = 1;
                 refIndex < lvaTrackedCount;
                 refIndex++  , refBit <<= 1)
            {
                if  ((varIntf & refBit) || (lvaVarIntf[refIndex] & varBit))
                    printf("%2u", refIndex);
                else
                    printf("  ");
            }

            printf("\n");
        }

        printf("\n");
    }

#endif

}

/*****************************************************************************
 *
 *  Walk all basic blocks and call the given function pointer for all tree
 *  nodes contained therein.
 */

int                     Compiler::fgWalkAllTrees(int (*visitor)(GenTreePtr, void *), void * pCallBackData)
{
    int             result = 0;

    BasicBlock *    block;

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      tree;

        for (tree = block->bbTreeList; tree; tree = tree->gtNext)
        {
            assert(tree->gtOper == GT_STMT);

            result = fgWalkTree(tree->gtStmt.gtStmtExpr, visitor, pCallBackData);
            if  (result)
                break;
        }
    }

    return result;
}




/*****************************************************************************
 *
 *  Given a basic block that has been removed, return an equivalent basic block
 *  that can be used instead of the removed block.
 */

/* static */ inline
BasicBlock *        Compiler::fgSkipRmvdBlocks(BasicBlock *block)
{
    /* We should always be called with a removed BB */

    ASSert(block->bbFlags & BBF_REMOVED);

    /* Follow the list until we find a block that will stick around */

    do
    {
        block = block->bbNext;
    }
    while (block && block->bbFlags & BBF_REMOVED);

    return block;
}

/*****************************************************************************
 *
 *  Find and remove any basic blocks that are useless (e.g. they have not been
 *  imported because they are not reachable, or they have been optimized away).
 */

void                Compiler::fgRemoveEmptyBlocks()
{
    BasicBlock **   lst;
    BasicBlock  *   cur;
    BasicBlock  *   nxt;

    unsigned        cnt;

    /* If we remove any blocks, we'll have to do additional work */

    unsigned        removedBlks = 0;

    /* 'lst' points to the link to the current block in the list */

    lst = &fgFirstBB;
    cur =  fgFirstBB;

    for (;;)
    {
        /* Make sure our pointers aren't messed up */

        assert(lst && cur && *lst == cur);

        /* Get hold of the next block */

        nxt = cur->bbNext;

        /* Should this block be removed? */

        if  (!(cur->bbFlags & BBF_IMPORTED))
        {
            assert(cur->bbTreeList == 0);

            /* Mark the block as removed */

            cur->bbFlags |= BBF_REMOVED;

#ifdef DEBUG
            // Make the block invalid
            cur->bbNum      = -cur->bbNum;
            cur->bbJumpKind = (BBjumpKinds)(-1 - cur->bbJumpKind);
#endif

            /* Drop the block from the list */

            *lst = nxt;

            /* Remember that we've removed a block from the list */

            removedBlks++;
        }
        else
        {
            /* It's a useful block; continue with the next one */

            lst = &(cur->bbNext);
        }

        /* stop if we're at the end */

        if  (!nxt)
            break;

        cur = nxt;
    }

    /* If no blocks were removed, we're done */

    if  (!removedBlks)
        return;

    /* Update all references in the exception handler table
     * Mark the new blocks as non-removable
     *
     * UNDONE: The code below can actually produce incorrect results
     * since we may have the entire try block unreacheable, thus we skip
     * to whatever follows the try-catch - Check for this case and remove
     * the exception from the table */

    if  (info.compXcptnsCount)
    {
        unsigned        XTnum;
        EHblkDsc *      HBtab;
        unsigned        origXcptnsCount = info.compXcptnsCount;

        for (XTnum = 0, HBtab = compHndBBtab;
             XTnum < origXcptnsCount;
             XTnum++  , HBtab++)
        {
            /* The beginning of the try block was not imported
             * Need to remove the exception from the exception table */

            if (HBtab->ebdTryBeg->bbFlags & BBF_REMOVED)
            {
                assert(!(HBtab->ebdTryBeg->bbFlags & BBF_IMPORTED));
#ifdef DEBUG
                if (verbose) printf("Beginning of try block (#%02u) not imported "
                                    "- remove the exception #%02u from the table\n",
                                            -(short)HBtab->ebdTryBeg->bbNum, XTnum);
#endif
                info.compXcptnsCount--;

                if (info.compXcptnsCount == 0)
                {
                    // No more exceptions remaining.
#ifdef DEBUG
                    compHndBBtab = (EHblkDsc *)0xBAADF00D;
#endif
                    break;
                }
                else
                {
                    // We need to update the table for the remaining exceptions

                    if (HBtab == compHndBBtab)
                    {
                        /* First entry - simply change the table pointer */
                        compHndBBtab++;
                        continue;
                    }
                    else if (XTnum < origXcptnsCount-1)
                    {
                        /* Middle entry - copy over */
                        memcpy(HBtab, HBtab + 1, (origXcptnsCount - XTnum - 1) * sizeof(*HBtab));
                        HBtab--; // HBtab has new contents now. Process again.
                        continue;
                    }
                    else
                    {
                        /* Last entry. Dont need to do anything */
                        assert(XTnum == origXcptnsCount-1);
                        break;
                    }
                }
            }

            /* At this point we know we have a try block and a handler */

#ifdef DEBUG
            assert(HBtab->ebdTryBeg->bbFlags & BBF_IMPORTED);
            assert(HBtab->ebdTryBeg->bbFlags & BBF_DONT_REMOVE);
            assert(HBtab->ebdTryBeg->bbNum <= HBtab->ebdTryEnd->bbNum);

            assert(HBtab->ebdHndBeg->bbFlags & BBF_IMPORTED);
            assert(HBtab->ebdHndBeg->bbFlags & BBF_DONT_REMOVE);

            if (HBtab->ebdFlags & JIT_EH_CLAUSE_FILTER)
            {
                assert(HBtab->ebdFilter->bbFlags & BBF_IMPORTED);
                assert(HBtab->ebdFilter->bbFlags & BBF_DONT_REMOVE);
            }
#endif

            /* Check if the Try END is reacheable */

            if (HBtab->ebdTryEnd->bbFlags & BBF_REMOVED)
            {
                /* The block has not been imported */
                assert(!(HBtab->ebdTryEnd->bbFlags & BBF_IMPORTED));
#ifdef DEBUG
                if (verbose)
                    printf("End of try block (#%02u) not imported for exception #%02u\n",
                                                -(short)HBtab->ebdTryEnd->bbNum, XTnum);
#endif
                HBtab->ebdTryEnd = fgSkipRmvdBlocks(HBtab->ebdTryEnd);

                if (HBtab->ebdTryEnd)
                {
                    HBtab->ebdTryEnd->bbFlags |= BBF_DONT_REMOVE;
#ifdef DEBUG
                    if (verbose)
                        printf("New end of try block (#%02u) for exception #%02u\n",
                                                     HBtab->ebdTryEnd->bbNum, XTnum);
#endif
                }
#ifdef DEBUG
                else
                {
                    if (verbose)
                        printf("End of Try block for exception #%02u is the end of program\n", XTnum);
                }
#endif
            }

            /* Check if the Hnd END is reacheable */

            if (HBtab->ebdHndEnd->bbFlags & BBF_REMOVED)
            {
                /* The block has not been imported */
                assert(!(HBtab->ebdHndEnd->bbFlags & BBF_IMPORTED));
#ifdef DEBUG
                if (verbose)
                    printf("End of catch handler block (#%02u) not imported for exception #%02u\n",
                                                     -(short)HBtab->ebdHndEnd->bbNum, XTnum);
#endif
                HBtab->ebdHndEnd = fgSkipRmvdBlocks(HBtab->ebdHndEnd);

                if (HBtab->ebdHndEnd)
                {
                    HBtab->ebdHndEnd->bbFlags |= BBF_DONT_REMOVE;
#ifdef DEBUG
                    if (verbose)
                        printf("New end of catch handler block (#%02u) for exception #%02u\n",
                                                     HBtab->ebdHndEnd->bbNum, XTnum);
#endif
                }
#ifdef DEBUG
                else
                {
                    if (verbose)
                        printf("End of Catch handler block for exception #%02u is the end of program\n", XTnum);
                }
#endif
            }
        }
    }

    /* Update the basic block numbers and jump targets
     * Update fgLastBB if we removed the last block */

    for (cur = fgFirstBB, cnt = 0; cur->bbNext; cur = cur->bbNext)
    {
        cur->bbNum = ++cnt;

        /* UNDONE: Now check and clean up the jump targets */
    }

    /* this is the last block */
    assert(cur);
    cur->bbNum = ++cnt;

    if (fgLastBB != cur)
    {
        fgLastBB = cur;
    }
}


/*****************************************************************************
 *
 * Remove a useless statement from a basic block
 * If updateRefCnt is true we update the reference counts for
 * all tracked variables in the removed statement
 */

void                Compiler::fgRemoveStmt(BasicBlock *    block,
                                           GenTreePtr      stmt,
                                           bool            updateRefCnt)
{
    GenTreePtr      tree = block->bbTreeList;

    assert(tree);
    assert(stmt->gtOper == GT_STMT);

    /* Is it the first statement in the list? */

    if  (tree == stmt)
    {
        if( !tree->gtNext )
        {
            assert (tree->gtPrev == tree);

            /* this is the only statement - basic block becomes empty */
            block->bbTreeList = 0;
            fgEmptyBlocks     = true;
        }
        else
        {
            block->bbTreeList         = tree->gtNext;
            block->bbTreeList->gtPrev = tree->gtPrev;
        }
        goto DONE;
    }

    /* Is it the last statement in the list? */

    if  (tree->gtPrev == stmt)
    {
        assert (stmt->gtNext == 0);

        stmt->gtPrev->gtNext      = 0;
        block->bbTreeList->gtPrev = stmt->gtPrev;
        goto DONE;
    }

    /* Find the given statement in the list */

    for (tree = block->bbTreeList; tree && (tree->gtNext != stmt); tree = tree->gtNext);

    if (!tree)
    {
        /* statement is not in this block */
        assert(!"Statement not found in this block");
        return;
    }

    tree->gtNext         = stmt->gtNext;
    stmt->gtNext->gtPrev = tree;

    fgStmtRemoved = true;

DONE:

#ifdef DEBUG
    if (verbose)
    {
        printf("Removing statement [%08X] in block #%02u as useless\n", stmt, block->bbNum);
        gtDispTree(stmt,0);

        if  (block->bbTreeList == 0)
        {
            printf("Block #%02u becomes empty\n", block->bbNum);
        }
        printf("\n");
    }
#endif

    if  (updateRefCnt)
        fgWalkTree(stmt->gtStmt.gtStmtExpr, Compiler::lvaDecRefCntsCB, (void *) this, true);

    return;
}

#define SHOW_REMOVED    0

/*****************************************************************************************************
 *
 *  Function called to compact two given blocks in the flowgraph
 *  Assumes that all necessary checks have been performed
 *  Uses for this function - whenever we change links, insert blocks,...
 *  It will keep the flowgraph data in synch - bbNums, bbRefs, bbPreds
 */

void                Compiler::fgCompactBlocks(BasicBlock * block, bool updateNums)
{
    BasicBlock  *   bNext;

    assert(block);
    assert(!(block->bbFlags & BBF_REMOVED));
    assert(block->bbJumpKind == BBJ_NONE);

    bNext = block->bbNext; assert(bNext);
    assert(!(bNext->bbFlags & BBF_REMOVED));
    assert(bNext->bbRefs == 1);
    assert(bNext->bbPreds);
    assert(bNext->bbPreds->flNext == 0);
    assert(bNext->bbPreds->flBlock == block);

    /* Make sure the second block is not a TRY block or an exception handler
     *(those should be marked BBF_DONT_REMOVE)
     * Also, if one has excep handler, then the other one must too */

    assert(!(bNext->bbFlags & BBF_DONT_REMOVE));
    assert(!bNext->bbCatchTyp);
    assert(!(bNext->bbFlags & BBF_IS_TRY));

    /* both or none must have an exception handler */

    assert(!((block->bbFlags & BBF_HAS_HANDLER) ^ (bNext->bbFlags & BBF_HAS_HANDLER)));

    /* Start compacting - move all the statements in the second block to the first block */

    GenTreePtr stmtList1 = block->bbTreeList;
    GenTreePtr stmtList2 = bNext->bbTreeList;

    /* the block may have an empty list */

    if (stmtList1)
    {
        GenTreePtr stmtLast1 = stmtList1->gtPrev;
        assert(stmtLast1->gtNext == 0);

        /* The second block may be a GOTO statement or something with an empty bbTreeList */

        if (stmtList2)
        {
            GenTreePtr stmtLast2 = stmtList2->gtPrev;
            assert(stmtLast2->gtNext == 0);

            /* append list2 to list 1 */

            stmtLast1->gtNext = stmtList2;
                                stmtList2->gtPrev = stmtLast1;
            stmtList1->gtPrev = stmtLast2;
        }
    }
    else
    {
        /* the list2 becomes the new bbTreeList */
        block->bbTreeList = stmtList2;
    }

    /* set the right links */

    block->bbNext     = bNext->bbNext;
    block->bbJumpKind = bNext->bbJumpKind;

    /* copy all the flags of bNext and other necessary fields */

    block->bbFlags  |= bNext->bbFlags;
    block->bbLiveOut = bNext->bbLiveOut;
    block->bbWeight  = (block->bbWeight + bNext->bbWeight) / 2;

    /* mark bNext as removed */

    bNext->bbFlags |= BBF_REMOVED;

    /* If bNext was the last block update fgLastBB */

    if  (bNext == fgLastBB)
        fgLastBB = block;

    /* set the jump tragets */

    switch (bNext->bbJumpKind)
    {
    case BBJ_COND:
    case BBJ_CALL:
    case BBJ_ALWAYS:
        block->bbJumpDest = bNext->bbJumpDest;

        /* Update the predecessor list for 'bNext->bbJumpDest' and 'bNext->bbNext' */
        fgReplacePred(bNext->bbJumpDest, bNext, block);

        if (bNext->bbJumpKind == BBJ_COND)
            fgReplacePred(bNext->bbNext, bNext, block);
        break;

    case BBJ_NONE:
        /* Update the predecessor list for 'bNext->bbNext' */
        fgReplacePred(bNext->bbNext,     bNext, block);
        break;

    case BBJ_RET:
        /* For all bbNext of BBJ_CALL blocks replace predecessor 'bbNext' with 'block' */
        assert("!NYI");
        break;

    case BBJ_THROW:
    case BBJ_RETURN:
        /* no jumps or fall through blocks to set here */
        break;

    case BBJ_SWITCH:
        block->bbJumpSwt = bNext->bbJumpSwt;

        /* For all jump targets of BBJ_SWITCH replace predecessor 'bbNext' with 'block' */
        unsigned        jumpCnt = bNext->bbJumpSwt->bbsCount;
        BasicBlock * *  jumpTab = bNext->bbJumpSwt->bbsDstTab;

        do
        {
            fgReplacePred(*jumpTab, bNext, block);
        }
        while (++jumpTab, --jumpCnt);

        break;
    }

    /* Update the bbNums */

    if  (updateNums)
    {
        BasicBlock *    auxBlock;
        for (auxBlock = block->bbNext; auxBlock; auxBlock = auxBlock->bbNext)
            auxBlock->bbNum--;
    }

    /* Check if the removed block is not part the loop table */

    for (unsigned loopNum = 0; loopNum < optLoopCount; loopNum++)
    {
        /* Some loops may have been already removed by
         * loop unrolling or conditional folding */

        if (optLoopTable[loopNum].lpFlags & LPFLG_REMOVED)
            continue;

        /* Check the loop head (i.e. the block preceding the loop) */

        if  (optLoopTable[loopNum].lpHead == bNext)
            optLoopTable[loopNum].lpHead = block;

        /* Check the loop bottom */

        if  (optLoopTable[loopNum].lpEnd == bNext)
            optLoopTable[loopNum].lpEnd = block;

        /* Check the loop exit */

        if  (optLoopTable[loopNum].lpExit == bNext)
        {
            assert(optLoopTable[loopNum].lpExitCnt == 1);
            optLoopTable[loopNum].lpExit = block;
        }

        /* The loop entry cannot be compacted */

        assert(optLoopTable[loopNum].lpEntry != bNext);
    }

#ifdef  DEBUG
    if  (verbose || SHOW_REMOVED)
        printf("\nCompacting blocks #%02u and #%02u:\n", block->bbNum, bNext->bbNum);
#if     SHOW_REMOVED
    printf("\nCompacting blocks in %s\n", info.compFullName);
#endif
    /* Check that the flowgraph data (bbNums, bbRefs, bbPreds) is up-to-date */
    if  (updateNums)
        fgDebugCheckBBlist();
#endif
}


/*****************************************************************************************************
 *
 *  Function called to remove a basic block
 *  As an optinal parameter it can update the bbNums
 */

void                Compiler::fgRemoveBlock(BasicBlock * block, BasicBlock * bPrev, bool updateNums)
{
    /* The block has to be either unreacheable or empty */

    assert(block);
    assert((block == fgFirstBB) || (bPrev && (bPrev->bbNext == block)));
    assert((block->bbRefs == 0) || (block->bbTreeList == 0));
    assert(!(block->bbFlags & BBF_DONT_REMOVE));

    if (block->bbRefs == 0)
    {
        /* no references -> unreacheable */

        assert(bPrev);
        assert(block->bbPreds == 0);

        bPrev->bbNext = block->bbNext;
        block->bbFlags |= BBF_REMOVED;

        /* If this is the last basic block update fgLastBB */
        if  (block == fgLastBB)
            fgLastBB = bPrev;

        /* update bbRefs and bbPreds for the blocks reached by this block */

        switch (block->bbJumpKind)
        {
        case BBJ_COND:
        case BBJ_CALL:
        case BBJ_ALWAYS:
            block->bbJumpDest->bbRefs--;

            /* Update the predecessor list for 'block->bbJumpDest' and 'block->bbNext' */
            fgRemovePred(block->bbJumpDest, block);

            /* If BBJ_COND fall through */
            if (block->bbJumpKind != BBJ_COND)
                break;

        case BBJ_NONE:
            block->bbNext->bbRefs--;

            /* Update the predecessor list for 'block->bbNext' */
            fgRemovePred(block->bbNext, block);
            break;

        case BBJ_RET:
            /* For all bbNext of BBJ_CALL blocks replace predecessor 'bbNext' with 'block' */
            assert("!NYI");
            break;

        case BBJ_THROW:
        case BBJ_RETURN:
            break;

        case BBJ_SWITCH:
            unsigned        jumpCnt = block->bbJumpSwt->bbsCount;
            BasicBlock * *  jumpTab = block->bbJumpSwt->bbsDstTab;

            do
            {
                (*jumpTab)->bbRefs--;

                /* For all jump targets of BBJ_SWITCH remove predecessor 'block'
                 * It may be that we have jump targets to the same label so
                 * we check that we have indeed a predecessor */

                if  (fgIsPredForBlock(*jumpTab, block))
                    fgRemovePred(*jumpTab, block);
            }
            while (++jumpTab, --jumpCnt);

            break;
        }

#ifdef  DEBUG
        if  (verbose || SHOW_REMOVED)
        {
            printf("\nRemoving unreacheable block #%02u\n", block->bbNum);
        }
#if  SHOW_REMOVED
        printf("\nRemoving unreacheable block in %s\n", info.compFullName);
#endif
#endif

        /* If an unreacheable block was part of a loop entry or bottom then the loop is unreacheable */
        /* Special case: the block was the head of a loop - or pointing to a loop entry */

        for (unsigned loopNum = 0; loopNum < optLoopCount; loopNum++)
        {
            bool            removeLoop = false;

            /* Some loops may have been already removed by
             * loop unrolling or conditional folding */

            if (optLoopTable[loopNum].lpFlags & LPFLG_REMOVED)
                continue;

            if (block == optLoopTable[loopNum].lpEntry ||
                block == optLoopTable[loopNum].lpEnd    )
            {
                    optLoopTable[loopNum].lpFlags |= LPFLG_REMOVED;
#ifdef DEBUG
                    if  (verbose)
                    {
                        printf("Removing loop #%02u (from #%02u to #%02u) because #%02u is unreacheable\n\n",
                                                    loopNum,
                                                    optLoopTable[loopNum].lpHead->bbNext->bbNum,
                                                    optLoopTable[loopNum].lpEnd ->bbNum,
                                                    block->bbNum);
                    }
#endif
                    continue;
            }

            /* If the loop is still in the table
             * any block in the loop must be reachable !!! */

            assert(optLoopTable[loopNum].lpEntry != block);
            assert(optLoopTable[loopNum].lpEnd   != block);
            assert(optLoopTable[loopNum].lpExit  != block);

            /* If this points to the actual entry in the loop
             * then the whole loop may become unreachable */

            switch (block->bbJumpKind)
            {
                case BBJ_NONE:
                case BBJ_COND:
                    if (block->bbNext == optLoopTable[loopNum].lpEntry)
                    {
                        removeLoop = true;
                        break;
                    }
                    if (block->bbJumpKind == BBJ_NONE)
                        break;

                    // fall through
                case BBJ_ALWAYS:
                    assert(block->bbJumpDest);
                    if (block->bbJumpDest == optLoopTable[loopNum].lpEntry)
                    {
                        removeLoop = true;
                    }
                    break;

                case BBJ_SWITCH:
                    unsigned        jumpCnt = block->bbJumpSwt->bbsCount;
                    BasicBlock * *  jumpTab = block->bbJumpSwt->bbsDstTab;

                    do
                    {
                        assert(*jumpTab);
                        if ((*jumpTab) == optLoopTable[loopNum].lpEntry)
                        {
                            removeLoop = true;
                        }
                    }
                    while (++jumpTab, --jumpCnt);
            }

            if  (removeLoop)
            {
                /* Check if the entry has other predecessors outside the loop
                 * UNDONE: Replace this when predecessors are available */

                BasicBlock  *   auxBlock;
                for (auxBlock = fgFirstBB; auxBlock; auxBlock = auxBlock->bbNext)
                {
                    /* Ignore blocks in the loop */

                    if  (auxBlock->bbNum >  optLoopTable[loopNum].lpHead->bbNum &&
                         auxBlock->bbNum <= optLoopTable[loopNum].lpEnd ->bbNum  )
                         continue;

                    switch (auxBlock->bbJumpKind)
                    {
                    case BBJ_NONE:
                    case BBJ_COND:
                        if (auxBlock->bbNext == optLoopTable[loopNum].lpEntry)
                        {
                            removeLoop = false;
                            break;
                        }
                        if (auxBlock->bbJumpKind == BBJ_NONE)
                            break;

                        // fall through
                    case BBJ_ALWAYS:
                        assert(auxBlock->bbJumpDest);
                        if (auxBlock->bbJumpDest == optLoopTable[loopNum].lpEntry)
                        {
                            removeLoop = false;
                        }
                        break;

                    case BBJ_SWITCH:
                        unsigned        jumpCnt = auxBlock->bbJumpSwt->bbsCount;
                        BasicBlock * *  jumpTab = auxBlock->bbJumpSwt->bbsDstTab;

                        do
                        {
                            assert(*jumpTab);
                            if ((*jumpTab) == optLoopTable[loopNum].lpEntry)
                            {
                                removeLoop = false;
                            }
                        }
                        while (++jumpTab, --jumpCnt);
                    }
                }

                if  (removeLoop)
                {
                    optLoopTable[loopNum].lpFlags |= LPFLG_REMOVED;
#ifdef DEBUG
                    if  (verbose)
                    {
                        printf("Removing loop #%02u (from #%02u to #%02u)\n\n",
                                                    loopNum,
                                                    optLoopTable[loopNum].lpHead->bbNext->bbNum,
                                                    optLoopTable[loopNum].lpEnd ->bbNum);
                    }
#endif
                }
            }
            else if (optLoopTable[loopNum].lpHead == block)
            {
                /* The loop has a new head - Just update the loop table */
                optLoopTable[loopNum].lpHead = bPrev;
            }
        }
    }
    else
    {
        assert(block->bbTreeList == 0);
        assert((block == fgFirstBB) || (bPrev && (bPrev->bbNext == block)));

        /* The block cannot follow a BBJ_CALL (because we don't know who may jump to it) */
        assert((block == fgFirstBB) || (bPrev && (bPrev->bbJumpKind != BBJ_CALL)));

        /* This cannot be the last basic block */
        assert(block != fgLastBB);

        /* Some extra checks for the empty case */

#ifdef DEBUG
        switch (block->bbJumpKind)
        {
        case BBJ_COND:
        case BBJ_SWITCH:
        case BBJ_THROW:
        case BBJ_CALL:
        case BBJ_RET:
        case BBJ_RETURN:
            /* can never happen */
            assert(!"Empty block of this type cannot be removed!");
            break;

        case BBJ_ALWAYS:
            /* Do not remove a block that jumps to itself - used for while(true){} */
            assert(block->bbJumpDest != block);

            /* Empty GOTO can be removed iff bPrev is BBJ_NONE */
            assert(bPrev && bPrev->bbJumpKind == BBJ_NONE);
        }
#endif

        assert(block->bbJumpKind == BBJ_NONE || block->bbJumpKind == BBJ_ALWAYS);

        /* Who is the "real" successor of this block? */

        BasicBlock  *   succBlock;
        BasicBlock  *   predBlock;
        flowList    *   pred;

        if (block->bbJumpKind == BBJ_ALWAYS)
            succBlock = block->bbJumpDest;
        else
            succBlock = block->bbNext;

        assert(succBlock);

        /* Remove the block */

        if (!bPrev)
        {
            /* special case if this is the first BB */

            assert(block == fgFirstBB);
            assert(block->bbJumpKind == BBJ_NONE);

            fgFirstBB = block->bbNext;
            assert(fgFirstBB->bbRefs >= 1);
        }
        else
            bPrev->bbNext = block->bbNext;

        /* mark the block as removed and set the change flag */

        block->bbFlags |= BBF_REMOVED;

        /* update bbRefs and bbPreds
         * All blocks jumping to 'block' now jump to 'succBlock' */

        assert(succBlock->bbRefs);
        succBlock->bbRefs--;
        succBlock->bbRefs += block->bbRefs;

        /* If the block has no predecessors, remove it from the successor's
         * pred list (because we won't have the chance to call fgReplacePred) */

        if  (block->bbPreds == 0)
        {
            assert(!bPrev);
            fgRemovePred(block->bbNext, block);
        }

        for (pred = block->bbPreds; pred; pred = pred->flNext)
        {
            predBlock = pred->flBlock;

            /* replace 'block' with 'predBlock' in the predecessor list of 'succBlock'
             * NOTE: 'block' may have several predecessors, while 'succBlock' may have only 'block'
             * as predecessor */

            if  (fgIsPredForBlock(succBlock, block))
                fgReplacePred(succBlock, block, predBlock);
            else
                fgAddRefPred(succBlock, predBlock, false, true);

            /* change all jumps to the removed block */
            switch(predBlock->bbJumpKind)
            {
            case BBJ_NONE:
                assert(predBlock == bPrev);

                /* In the case of BBJ_ALWAYS we have to change the type of its predecessor */
                if (block->bbJumpKind == BBJ_ALWAYS)
                {
                    /* bPrev now becomes a BBJ_ALWAYS */
                    bPrev->bbJumpKind = BBJ_ALWAYS;
                    bPrev->bbJumpDest = succBlock;
                }
                break;

            case BBJ_COND:
                /* The links for the direct predecessor case have already been updated above */
                if (predBlock->bbJumpDest != block)
                    break;
                /* Fall through for the jump case */

            case BBJ_ALWAYS:
                assert(predBlock->bbJumpDest == block);
                predBlock->bbJumpDest = succBlock;
                break;

            case BBJ_SWITCH:
                unsigned        jumpCnt = predBlock->bbJumpSwt->bbsCount;
                BasicBlock * *  jumpTab = predBlock->bbJumpSwt->bbsDstTab;

                do
                {
                    assert (*jumpTab);
                    if ((*jumpTab) == block)
                        (*jumpTab) = succBlock;
                }
                while (++jumpTab, --jumpCnt);
            }
        }

        /* have we removed the block? */

#ifdef  DEBUG
        if  (verbose || SHOW_REMOVED)
        {
            printf("\nRemoving empty block #%02u\n", block->bbNum);
        }

#if  SHOW_REMOVED
        printf("\nRemoving empty block in %s\n", info.compFullName);
#endif
#endif

        /* To Do - if the block was part of a loop update loop table */

    }

    if  (updateNums)
    {
        assert(!"Implement bbNums for remove block!");

#ifdef DEBUG
        /* Check that the flowgraph data (bbNums, bbRefs, bbPreds) is up-to-date */
        fgDebugCheckBBlist();
#endif
    }
}


/*****************************************************************************************************
 *
 *  Function called to "comb" the basic block list
 *  Removes any empty blocks, unreacheable blocks and redundant jumps
 *    Most of those appear after dead store removal and folding of conditionals
 *
 *  It also compacts basic blocks (consecutive basic blocks that should in fact be one)
 *
 *  CONSIDER:
 *    Those are currently introduced by field hoisting, MonitorEnter, Loop condition duplication, etc
 *    For hoisting and monitors why allocating an extra basic block and not prepending the statements
 *    to the first basic block list?
 *
 *  NOTE:
 *    Debuggable code and Min Optimization JIT also introduces basic blocks but we do not optimize those!
 */

void                Compiler::fgUpdateFlowGraph()
{
    BasicBlock  *   block;
    BasicBlock  *   bPrev;          // the parent of the current block
    BasicBlock  *   bNext;          // the successor of the curent block
    bool            change;
    bool            updateNums = false; // In case we removed blocks update the bbNums after we're finished


    /* This should never be called for debugabble code */

    assert(!opts.compMinOptim && !opts.compDbgCode);

    /* make sure you have up-to-date info about block bbNums, bbRefs and bbPreds */

#ifdef  DEBUG
    if  (verbose)
    {
        printf("\nBefore updating the flow graph:\n");
        fgDispBasicBlocks();
        printf("\n");
    }

    fgDebugCheckBBlist();
#endif

    /* Walk all the basic blocks - look for unconditional jumps, empty blocks, blocks to compact, etc...
     *
     * OBSERVATION:
     *      Once a block is removed the predecessors are not accurate (assuming they were at the beginning)
     *      For now we will only use the information in bbRefs because it is easier to be updated
     */

    do
    {
        change = false;

        bPrev = 0;
        for (block = fgFirstBB; block; block = block->bbNext)
        {
            /* Some blocks may be already marked removed by other optimizations
             * (e.g worthless loop removal), without being explicitely removed from the list
             * UNDONE: have to be consistent in the future and avoid having removed blocks in the list */

            if (block->bbFlags & BBF_REMOVED)
            {
                if (bPrev)
                {
                    bPrev->bbNext = block->bbNext;
                }
                else
                {
                    /* WEIRD first basic block is removed - should have an assert here */
                    assert(!"First basic block marked as BBF_REMOVED???");

                    fgFirstBB = block->bbNext;
                }
                continue;
            }

            /* we jump to the REPEAT label if we performed a change involving the current block
             * This is in case there are other optimizations that can show up (e.g. - compact 3 blocks in a row)
             * If nothing happens, we then finish the iteration and move to the next block
             */

REPEAT:
            bNext = block->bbNext;

            /* Remove JUMPS to the following block */

            if (block->bbJumpKind == BBJ_COND   ||
                block->bbJumpKind == BBJ_ALWAYS  )
            {
                if (block->bbJumpDest == bNext)
                {
                    assert(fgIsPredForBlock(bNext, block));

                    if (block->bbJumpKind == BBJ_ALWAYS)
                    {
                        /* the unconditional jump is to the next BB  */
                        block->bbJumpKind = BBJ_NONE;
                        change = true;

#ifdef  DEBUG
                        if  (verbose || SHOW_REMOVED)
                        {
                            printf("\nRemoving unconditional jump to following block (#%02u -> #%02u)\n",
                                   block->bbNum, bNext->bbNum);
                        }
#if SHOW_REMOVED
                        printf("\nRemoving unconditional jump to following block in %s\n", info.compFullName);
#endif
#endif
                    }
                    else
                    {
                        /* remove the conditional statement at the end of block */
                        assert(block->bbJumpKind == BBJ_COND);
                        assert(block->bbTreeList);

                        GenTreePtr      cond = block->bbTreeList->gtPrev;
                        assert(cond->gtOper == GT_STMT);
                        assert(cond->gtStmt.gtStmtExpr->gtOper == GT_JTRUE);

#ifdef  DEBUG
                        if  (verbose || SHOW_REMOVED)
                        {
                            printf("\nRemoving conditional jump to following block (#%02u -> #%02u)\n",
                                   block->bbNum, bNext->bbNum);
                        }
#if  SHOW_REMOVED
                        printf("\nRemoving conditional jump to following block in %s\n", info.compFullName);
#endif
#endif
                        /* check for SIDE_EFFECTS */

                        if (!(cond->gtStmt.gtStmtExpr->gtFlags & GTF_SIDE_EFFECT))
                        {
                            /* conditional has NO side effect - remove it */
                            fgRemoveStmt(block, cond, fgStmtListThreaded);
                        }
                        else
                        {
                            /* Extract the side effects from the conditional */

                            GenTreePtr      sideEffList = 0;
                            gtExtractSideEffList(cond->gtStmt.gtStmtExpr, &sideEffList);

                            assert(sideEffList); assert(sideEffList->gtFlags & GTF_SIDE_EFFECT);
#ifdef  DEBUG
                            if  (verbose || 0)
                            {
                                printf("\nConditional has side effects! Extracting side effects...\n");
                                gtDispTree(cond); printf("\n");
                                gtDispTree(sideEffList); printf("\n");
                            }
#endif
                            /* Replace the conditional statement with the list of side effects */
                            assert(sideEffList->gtOper != GT_STMT);
                            assert(sideEffList->gtOper != GT_JTRUE);

                            cond->gtStmt.gtStmtExpr = sideEffList;

                            if (fgStmtListThreaded)
                            {
                                /* Update ordering, costs, FP levels, etc. */
                                gtSetStmtInfo(cond);

                                /* Re-link the nodes for this statement */
                                fgSetStmtSeq(cond);
                            }

                            //assert(!"Found conditional with side effect!");
                        }

                        /* Conditional is gone - simply fall into the next block */

                        block->bbJumpKind = BBJ_NONE;

                        /* Update bbRefs and bbNums - Conditional predecessors to the same
                         * block are counted twice so we have to remove one of them */

                        assert(bNext->bbRefs > 1);
                        bNext->bbRefs--;
                        fgRemovePred(bNext, block);
                        change = true;
                    }
                }
            }

            assert(!(block->bbFlags & BBF_REMOVED));

            /* COMPACT blocks if possible */

            if ((block->bbJumpKind == BBJ_NONE) && bNext)
            {
                if ((bNext->bbRefs == 1) && !(bNext->bbFlags & BBF_DONT_REMOVE))
                {
                    fgCompactBlocks(block);

                    /* we compacted two blocks - goto REPEAT to catch similar cases */
                    change = true;
                    updateNums = true;
                    goto REPEAT;
                }
            }

            /* REMOVE UNREACHEABLE or EMPTY blocks - do not consider blocks marked BBF_DONT_REMOVE
             * These include first and last block of a TRY, exception handlers and RANGE_CHECK_FAIL THROW blocks */

            if (block->bbFlags & BBF_DONT_REMOVE)
            {
                bPrev = block;
                continue;
            }

            assert(!block->bbCatchTyp);
            assert(!(block->bbFlags & BBF_IS_TRY));

            /* Remove UNREACHEABLE blocks
             *
             * We'll look for blocks that have bbRefs = 0 (blocks may become
             * unreacheable due to a BBJ_ALWAYS introduced by conditional folding for example)
             *
             *  UNDONE: We don't remove the last and first block of a TRY block (they are marked BBF_DONT_REMOVE)
             *          The reason is we will have to update the exception handler tables and we are lazy
             *
             *  CONSIDER: it may be the case that the graph is divided into disjunct components
             *            and we may not remove the unreacheable ones until we find the connected
             *            components ourselves
             */

            if (block->bbRefs == 0)
            {
                /* no references -> unreacheable - remove it */
                /* For now do not update the bbNums, do it at the end */

                fgRemoveBlock(block, bPrev);

                change     = true;
                updateNums = true;

                /* we removed the current block - the rest of the optimizations won't have a target
                 * continue with the next one */

                continue;
            }

            assert(!(block->bbFlags & BBF_REMOVED));

            /* Remove EMPTY blocks */

            if (block->bbTreeList == 0)
            {
                switch (block->bbJumpKind)
                {
                case BBJ_COND:
                case BBJ_SWITCH:
                case BBJ_THROW:

                    /* can never happen */
                    assert(!"Conditional or throw block with empty body!");
                    break;

                case BBJ_CALL:
                case BBJ_RET:
                case BBJ_RETURN:

                    /* leave them as is */
                    /* OBS - some stupid compilers generate multiple retuns and
                     * puts all of them at the end - to solve that we need the predecessor list */

                    break;

                case BBJ_ALWAYS:

                    /* a GOTO - cannot be to the next block since that must
                     * have been fixed by the other optimization above */
                    assert(block->bbJumpDest != block->bbNext);

                    /* Cannot remove the first BB */
                    if (!bPrev) break;

                    /* Do not remove a block that jumps to itself - used for while(true){} */
                    if (block->bbJumpDest == block) break;

                    /* Empty GOTO can be removed iff bPrev is BBJ_NONE */
                    if (bPrev->bbJumpKind != BBJ_NONE) break;

                    /* Can follow through since this is similar with removing
                     * a BBJ_NONE block, only the successor is different */

                case BBJ_NONE:

                    /* special case if this is the first BB */
                    if (!bPrev)
                    {
                        assert (block == fgFirstBB);
                    }
                    else
                    {
                        /* If this block follows a BBJ_CALL do not remove it
                         * (because we don not know who may jump to it) */
                        if (bPrev->bbJumpKind == BBJ_CALL)
                            break;
                    }

                    /* Remove the block */
                    fgRemoveBlock(block, bPrev);
                    change     = true;
                    updateNums = true;
                    break;
                }

                /* have we removed the block? */

                if  (block->bbFlags & BBF_REMOVED)
                {
                    /* block was removed - no change to bPrev */
                    continue;
                }
            }

            /* Set the predecessor of the last reacheable block
             * If we removed the current block, the predecessor remains unchanged
             * otherwise, since the current block is ok, it becomes the predecessor */

            assert(!(block->bbFlags & BBF_REMOVED));

            bPrev = block;
        }
    }
    while (change);

    /* update the bbNums if required */

    if (updateNums)
        fgAssignBBnums(true);

#ifdef  DEBUG
    if  (verbose)
    {
        printf("\nAfter updating the flow graph:\n");
        fgDispBasicBlocks();
        printf("\n");
    }

    fgDebugCheckBBlist();
#endif

#if  DEBUG && 0

    /* debug only - check that the flow graph is really updated i.e.
     * no unreacheable blocks -> no blocks have bbRefs = 0
     * no empty blocks        -> no blocks have bbTreeList = 0
     * no un-imported blocks  -> no blocks have BBF_IMPORTED not set (this is kind of redundand with the above, but to make sure)
     * no un-compacted blocks -> BBJ_NONE followed by block with no jumps to it (bbRefs = 1)
     */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        /* no unreacheable blocks */

        if  ((block->bbRefs == 0)                &&
             !(block->bbFlags & BBF_DONT_REMOVE)  )
        {
            assert(!"Unreacheable block not removed!");
        }

        /* no empty blocks */

        if  ((block->bbTreeList == 0)            &&
             !(block->bbFlags & BBF_DONT_REMOVE)  )
        {
            switch (block->bbJumpKind)
            {
            case BBJ_CALL:
            case BBJ_RET:
            case BBJ_RETURN:
                /* for BBJ_ALWAYS is probably just a GOTO, but will have to be treated */
            case BBJ_ALWAYS:
                break;

            default:
                /* it may be the case that the block had more than one reference to it
                 * so we couldn't remove it */

                if (block->bbRefs == 0)
                    assert(!"Empty block not removed!");
            }
        }

        /* no un-imported blocks */

        if  (!(block->bbFlags & BBF_IMPORTED))
        {
            /* internal blocks do not count */

            if (!(block->bbFlags & BBF_INTERNAL))
                assert(!"Non IMPORTED block not removed!");
        }

        /* no jumps to the next block
         * Unless we go out of an exception handler (could optimize it but it's not worth it) */

        if (block->bbJumpKind == BBJ_COND   ||
            block->bbJumpKind == BBJ_ALWAYS  )
        {
            if (block->bbJumpDest == block->bbNext)
                //&& !block->bbCatchTyp)
            {
                assert(!"Jump to the next block!");
            }
        }

        /* no un-compacted blocks */

        if (block->bbJumpKind == BBJ_NONE)
        {
            if ((block->bbNext->bbRefs == 1) && !(block->bbNext->bbFlags & BBF_DONT_REMOVE))
            {
                assert(!"Found un-compacted blocks!");
            }
        }
    }

#endif

}


/*****************************************************************************
 *
 *  Find/create an added code entry associated with the given block and with
 *  the given kind.
 */

BasicBlock *        Compiler::fgAddCodeRef(BasicBlock   *srcBlk,
                                           unsigned     refData,
                                           addCodeKind  kind,
                                           unsigned     stkDepth)
{
    AddCodeDsc  *   add;

    GenTreePtr      tree;

    BasicBlock  *   newBlk;
    BasicBlock  *   jmpBlk;
    BasicBlock  *   block;
    unsigned        bbNum;

    static
    BYTE            jumpKinds[] =
    {
        BBJ_NONE,               // ACK_NONE
        BBJ_THROW,              // ACK_RNGCHK_FAIL
        BBJ_ALWAYS,             // ACK_PAUSE_EXEC
        BBJ_THROW,              // ACK_ARITH_EXCP, ACK_OVERFLOW
    };

    assert(sizeof(jumpKinds) == ACK_COUNT); // sanity check

    /* First look for an existing entry that matches what we're looking for */

    add = fgFindExcptnTarget(kind, refData);

    if (add) // found it
    {
#if TGT_x86
        // @ToDo: Performance opportunity
        //
        // If different range checks happen at different stack levels,
        // they cant all jump to the same "call @rngChkFailed" AND have
        // frameless methods, as the rngChkFailed may need to unwind the
        // stack, and we have to be able to report the stack level
        //
        // The following check forces most methods that references an
        // array element in a parameter list to have an EBP frame,
        // this restriction can be removed with more careful code
        // generation for BBJ_THROW (i.e. range check failed)
        //
        if  (add->acdStkLvl != stkDepth)
            genFPreqd = true;
#endif
        goto DONE;
    }

    /* We have to allocate a new entry and prepend it to the list */

    add = (AddCodeDsc *)compGetMem(sizeof(*fgAddCodeList));
    add->acdData   = refData;
    add->acdKind   = kind;
#if TGT_x86
    add->acdStkLvl = stkDepth;
#endif
    add->acdNext   = fgAddCodeList;
                     fgAddCodeList = add;

    /* Create the target basic block */

    add->acdDstBlk =
            newBlk = bbNewBasicBlock((BBjumpKinds)jumpKinds[kind]);

    /* Mark the block as added by the compiler and not removable by future flow
       graph optimizations. Note that no bbJumpDest points to these blocks. */

    newBlk->bbFlags |= BBF_INTERNAL | BBF_DONT_REMOVE;

    /* Remember that we're adding a new basic block */

    fgAddCodeModf = true;

    /*
        We need to find a good place to insert the block; first we'll look
        for any unconditional jumps that follow the block.
     */

    jmpBlk = srcBlk->FindJump();
    if  (!jmpBlk)
    {
        jmpBlk = (fgFirstBB)->FindJump();
        if  (!jmpBlk)
        {
            jmpBlk = (fgFirstBB)->FindJump(true);
            if  (!jmpBlk)
            {
                assert(!"need to insert a jump or something");
            }
        }
    }

    /* Here we know we want to insert our block right after 'jmpBlk' */

    newBlk->bbNext = jmpBlk->bbNext;
    jmpBlk->bbNext = newBlk;

    /* Update bbNums, bbRefs - since this is a throw block bbRefs = 0 */

    newBlk->bbRefs = 0;

    block = newBlk;
    bbNum = jmpBlk->bbNum;
    do
    {
        block->bbNum = ++bbNum;
        block        = block->bbNext;
    }
    while (block);

    /* Update fgLastBB if this is the last block */

    if  (newBlk->bbNext == 0)
    {
        assert(jmpBlk == fgLastBB);
        fgLastBB = newBlk;
    }

    /* Now figure out what code to insert */

    switch (kind)
    {
        int helper;

    case ACK_RNGCHK_FAIL:   helper = CPX_RNGCHK_FAIL;
                            goto ADD_HELPER_CALL;

    case ACK_ARITH_EXCPN:   helper = CPX_ARITH_EXCPN;
                            assert(ACK_OVERFLOW == ACK_ARITH_EXCPN);
                            goto ADD_HELPER_CALL;

    ADD_HELPER_CALL:

        /* Add the appropriate helper call */

        tree = gtNewIconNode(refData, TYP_INT);
#if TGT_x86
        tree->gtFPlvl = 0;
#endif
        tree = gtNewArgList(tree);
#if TGT_x86
        tree->gtFPlvl = 0;
#endif
        tree = gtNewHelperCallNode(helper, TYP_VOID, GTF_CALL_REGSAVE, tree);
#if TGT_x86
        tree->gtFPlvl = 0;
#endif

        /* Make sure that we have room for at least one argument */

        if (fgPtrArgCntMax == 0)
            fgPtrArgCntMax = 1;

#if USE_FASTCALL

        /* The constant argument must be passed in registers */

        assert(tree->gtOper == GT_CALL);
        assert(tree->gtCall.gtCallArgs->gtOper == GT_LIST);
        assert(tree->gtCall.gtCallArgs->gtOp.gtOp1->gtOper == GT_CNS_INT);
        assert(tree->gtCall.gtCallArgs->gtOp.gtOp2 == 0);

        tree->gtCall.gtCallRegArgs = gtNewOperNode(GT_LIST,
                                                   TYP_VOID,
                                                   tree->gtCall.gtCallArgs->gtOp.gtOp1, 0);

#if TGT_IA64
        tree->gtCall.regArgEncode  = (unsigned short)REG_INT_ARG_0;
#else
        tree->gtCall.regArgEncode  = (unsigned short)REG_ARG_0;
#endif

#if TGT_x86
        tree->gtCall.gtCallRegArgs->gtFPlvl = 0;
#endif

        tree->gtCall.gtCallArgs->gtOp.gtOp1 = gtNewNothingNode();
        tree->gtCall.gtCallArgs->gtOp.gtOp1->gtFlags |= GTF_REG_ARG;

#if TGT_x86
        tree->gtCall.gtCallArgs->gtOp.gtOp1->gtFPlvl = 0;
#endif

#endif

        break;

//  case ACK_PAUSE_EXEC:
//      assert(!"add code to pause exec");

    default:
        assert(!"unexpected code addition kind");
    }

    /* Store the tree in the new basic block */

    fgStoreFirstTree(newBlk, tree);

DONE:

    return  add->acdDstBlk;
}

/*****************************************************************************
 * Finds the block to jump to, to throw a given kind of exception
 * We maintain a cache of one AddCodeDsc for each kind, to make searching fast.
 * Note : Each block uses the same (maybe shared) block as the jump target for
 * a given type of exception
 */

Compiler::AddCodeDsc *      Compiler::fgFindExcptnTarget(addCodeKind  kind,
                                                         unsigned     refData)
{
    if (!(fgExcptnTargetCache[kind] &&  // Try the cached value first
          fgExcptnTargetCache[kind]->acdData == refData))
    {
        // Too bad, have to search for the jump target for the exception

        AddCodeDsc * add = NULL;

        for (add = fgAddCodeList; add; add = add->acdNext)
        {
            if  (add->acdData == refData && add->acdKind == kind)
                break;
        }

        fgExcptnTargetCache[kind] = add; // Cache it
    }

    return fgExcptnTargetCache[kind];
}

/*****************************************************************************
 *
 *  The given basic block contains an array range check; return the label this
 *  range check is to jump to upon failure.
 */

#if RNGCHK_OPT

inline
BasicBlock *        Compiler::fgRngChkTarget(BasicBlock *block, unsigned stkDepth)
{
    /* We attach the target label to the containing try block (if any) */

    return  fgAddCodeRef(block, block->bbTryIndex, ACK_RNGCHK_FAIL, stkDepth);
}

#else

inline
BasicBlock *        Compiler::fgRngChkTarget(BasicBlock *block)
{
    /* We attach the target label to the containing try block (if any) */

    return  fgAddCodeRef(block, block->bbTryIndex, ACK_RNGCHK_FAIL, fgPtrArgCntCur);
}

#endif

/*****************************************************************************
 *
 *  Store the given tree in the specified basic block (which must be empty).
 */

GenTreePtr          Compiler::fgStoreFirstTree(BasicBlock * block,
                                               GenTreePtr   tree)
{
    GenTreePtr      stmt;

    assert(block);
    assert(block->bbTreeList == 0);

    assert(tree);
    assert(tree->gtOper != GT_STMT);

    /* Allocate a statement node */

    stmt = gtNewStmt(tree);

    /* Now store the statement in the basic block */

    block->bbTreeList       =
    stmt->gtPrev            = stmt;
    stmt->gtNext            = 0;

    /*
     *  Since we add calls to raise range check error after ordering,
     *  we must set the order here.
     */

#if RNGCHK_OPT
    fgSetBlockOrder(block);
#endif

    block->bbFlags         |= BBF_IMPORTED;

    return  stmt;
}

/*****************************************************************************
 *
 *  Assigns sequence numbers to the given tree and its sub-operands, and
 *  threads all the nodes together via the 'gtNext' and 'gtPrev' fields.
 */

void                Compiler::fgSetTreeSeq(GenTreePtr tree)
{
    genTreeOps      oper;
    unsigned        kind;

    assert(tree && (int)tree != 0xDDDDDDDD);
    assert(tree->gtOper != GT_STMT);

    /* Figure out what kind of a node we have */

    oper = tree->OperGet();
    kind = tree->OperKind();

    /* Is this a leaf/constant node? */

    if  (kind & (GTK_CONST|GTK_LEAF))
        goto DONE;

    /* Is it a 'simple' unary/binary operator? */

    if  (kind & GTK_SMPOP)
    {
        GenTreePtr      op1 = tree->gtOp.gtOp1;
        GenTreePtr      op2 = tree->gtOp.gtOp2;

        /* Check for a nilary operator */

        if  (!op1)
        {
            assert(op2 == 0);
            goto DONE;
        }

        /* Is this a unary operator?
         * Although UNARY GT_IND has a special structure */

        if  (oper == GT_IND)
        {
            /* Visit the indirection first - op2 may point to the
             * jump Label for array-index-out-of-range */

            fgSetTreeSeq(op1);

#if CSELENGTH

            /* Special case: GT_IND may have a GT_ARR_RNGCHK node */

            if  (tree->gtInd.gtIndLen)
            {
                if  (tree->gtFlags & GTF_IND_RNGCHK)
                    fgSetTreeSeq(tree->gtInd.gtIndLen);
            }

#endif
            goto DONE;
        }

        /* Now this is REALLY a unary operator */

        if  (!op2)
        {
            /* Visit the (only) operand and we're done */

            fgSetTreeSeq(op1);
            goto DONE;
        }

#if INLINING

        /*
            For "real" ?: operators, we make sure the order is
            as follows:

                condition
                1st operand
                GT_COLON
                2nd operand
                GT_QMARK
         */

        if  (oper == GT_QMARK)
        {
            assert((tree->gtFlags & GTF_REVERSE_OPS) == 0);

            fgSetTreeSeq(op1);
            fgSetTreeSeq(op2->gtOp.gtOp1);
            fgSetTreeSeq(op2);
            fgSetTreeSeq(op2->gtOp.gtOp2);

            goto DONE;
        }

        if  (oper == GT_COLON)
            goto DONE;

#endif

        /* This is a binary operator */

        if  (tree->gtFlags & GTF_REVERSE_OPS)
        {
            fgSetTreeSeq(op2);
            fgSetTreeSeq(op1);
        }
        else
        {
            fgSetTreeSeq(op1);
            fgSetTreeSeq(op2);
        }

        goto DONE;
    }

    /* See what kind of a special operator we have here */

    switch  (oper)
    {
    case GT_MKREFANY:
    case GT_LDOBJ:
        fgSetTreeSeq(tree->gtLdObj.gtOp1);
        goto DONE;

    case GT_JMP:
        goto DONE;

    case GT_JMPI:
        fgSetTreeSeq(tree->gtOp.gtOp1);
        goto DONE;

    case GT_FIELD:
        assert(tree->gtField.gtFldObj == 0);
        break;

    case GT_CALL:

        /* We'll evaluate the 'this' argument value first */
        if  (tree->gtCall.gtCallObjp)
            fgSetTreeSeq(tree->gtCall.gtCallObjp);

        /* We'll evaluate the arguments next, left to right
         * NOTE: setListOrder neds cleanup - eliminate the #ifdef afterwards */

        if  (tree->gtCall.gtCallArgs)
        {
#if 1
            fgSetTreeSeq(tree->gtCall.gtCallArgs);
#else
            GenTreePtr      args = tree->gtCall.gtCallArgs;

            do
            {
                assert(args && args->gtOper == GT_LIST);
                fgSetTreeSeq(args->gtOp.gtOp1);
                args = args->gtOp.gtOp2;
            }
            while (args);
#endif
        }

#if USE_FASTCALL
        /* Evaluate the temp register arguments list
         * This is a "hidden" list and its only purpose is to
         * extend the life of temps until we make the call */

        if  (tree->gtCall.gtCallRegArgs)
        {
#if 1
            fgSetTreeSeq(tree->gtCall.gtCallRegArgs);
#else
            GenTreePtr      tmpArg = tree->gtCall.gtCallRegArgs;

            do
            {
                assert(tmpArg && tmpArg->gtOper == GT_LIST);
                fgSetTreeSeq(tmpArg->gtOp.gtOp1);
                tmpArg = tmpArg->gtOp.gtOp2;
            }
            while (tmpArg);
#endif
        }
#endif

        /* We'll evaluate the vtable address last */

        if  (tree->gtCall.gtCallVptr)
            fgSetTreeSeq(tree->gtCall.gtCallVptr);
        else if (tree->gtCall.gtCallType == CT_INDIRECT)
        {
            fgSetTreeSeq(tree->gtCall.gtCallAddr);
        }

        break;

#if CSELENGTH

    case GT_ARR_RNGCHK:

        if  (tree->gtFlags & GTF_ALN_CSEVAL)
            fgSetTreeSeq(tree->gtArrLen.gtArrLenAdr);

        if  (tree->gtArrLen.gtArrLenCse)
            fgSetTreeSeq(tree->gtArrLen.gtArrLenCse);

        break;

#endif


    default:
#ifdef  DEBUG
        gtDispTree(tree);
#endif
        assert(!"unexpected operator");
    }

DONE:

    /* Append to the node list */

#ifdef  DEBUG

    if  (verbose & 0)
        printf("SetTreeOrder: [%08X] followed by [%08X]\n", fgTreeSeqLst, tree);

#endif

    fgTreeSeqLst->gtNext = tree;
                           tree->gtNext = 0;
                           tree->gtPrev = fgTreeSeqLst;
                                          fgTreeSeqLst = tree;

    /* Remember the very first node */

    if  (!fgTreeSeqBeg) fgTreeSeqBeg = tree;
}

/*****************************************************************************
 *
 *  Figure out the order in which operators should be evaluated, along with
 *  other information (such as the register sets trashed by each subtree).
 */

void                Compiler::fgSetBlockOrder()
{
    /* Walk the basic blocks to assign sequence numbers */

#ifdef  DEBUG
    BasicBlock::s_nMaxTrees = 0;
#endif

    for (BasicBlock * block = fgFirstBB; block; block = block->bbNext)
    {
        /* If this block is a loop header, mark it appropriately */

#if RNGCHK_OPT
        if  (block->bbFlags & BBF_LOOP_HEAD)
            fgMarkLoopHead(block);
#endif

        fgSetBlockOrder(block);
    }

    /* Remember that now the tree list is threaded */

    fgStmtListThreaded = true;

#ifdef  DEBUG
//  printf("The biggest BB has %4u tree nodes\n", BasicBlock::s_nMaxTrees);
#endif
}


/*****************************************************************************/

void                Compiler::fgSetStmtSeq(GenTreePtr tree)
{
    GenTree         list;            // helper node that we use to start the StmtList
                                     // It's located in front of the first node in the list

    assert(tree->gtOper == GT_STMT);

    /* Assign numbers and next/prev links for this tree */

    fgTreeSeqNum = 0;
    fgTreeSeqLst = &list;
    fgTreeSeqBeg = 0;
    fgSetTreeSeq(tree->gtStmt.gtStmtExpr);

    /* Record the address of the first node */

    tree->gtStmt.gtStmtList = fgTreeSeqBeg;

#ifdef  DEBUG

    GenTreePtr temp;
    GenTreePtr last;

    if  (list.gtNext->gtPrev != &list)
    {
        printf("&list [%08X] != list.next->prev [%08X]\n", &list, list.gtNext->gtPrev);
        goto BAD_LIST;
    }

    for (temp = list.gtNext, last = &list; temp; last = temp, temp = temp->gtNext)
    {
        if (temp->gtPrev != last)
        {
            printf("%08X->gtPrev = %08X, but last = %08X\n", temp, temp->gtPrev, last);

        BAD_LIST:

            printf("\n");
            gtDispTree(tree->gtStmt.gtStmtExpr);
            printf("\n");

            for (GenTreePtr temp = &list; temp; temp = temp->gtNext)
                printf("  entry at %08x [prev=%08X,next=%08X]\n", temp, temp->gtPrev, temp->gtNext);

            printf("\n");
        }
    }
#endif

    /* Fix the first node's 'prev' link */

    assert(list.gtNext->gtPrev == &list);
           list.gtNext->gtPrev = 0;

    /* Keep track of the highest # of tree nodes */

#ifdef  DEBUG
    if  (BasicBlock::s_nMaxTrees < fgTreeSeqNum)
         BasicBlock::s_nMaxTrees = fgTreeSeqNum;
#endif

    /* Make sure the gtNext and gtPrev links for statements (GT_STMT) are set correctly */

    assert(tree->gtPrev);

}

/*****************************************************************************/

void                Compiler::fgSetBlockOrder(BasicBlock * block)
{
    GenTreePtr      tree;

    tree = block->bbTreeList;
    if  (!tree)
        return;

    for (;;)
    {
        fgSetStmtSeq(tree);

        /* Are there any more trees in this basic block? */

        if (!tree->gtNext)
        {
            /* last statement in the tree list */
            assert(block->bbTreeList->gtPrev == tree);
            break;
        }

#ifdef DEBUG
        if (block->bbTreeList == tree)
        {
            /* first statement in the list */
            assert(tree->gtPrev->gtNext == 0);
        }
        else
            assert(tree->gtPrev->gtNext == tree);

        assert(tree->gtNext->gtPrev == tree);
#endif

        tree = tree->gtNext;
    }
}

/*****************************************************************************
 *
 *  Callback (for fgWalkTree) used by the postfix ++/-- hoisting code to
 *  look for any assignments or uses of the variable that would make it
 *  illegal for hoisting to take place.
 */

struct  hoistPostfixDsc
{
    // Fields common to all phases:

    Compiler    *       hpComp;
    unsigned short      hpPhase;    // which pass are we performing?

    // Debugging fields:

#ifndef NDEBUG
    void    *           hpSelf;
#endif

    // Phase 1 fields:

    BasicBlock  *       hpBlock;
    GenTreePtr          hpStmt;

    // Phase 2 fields:

    GenTreePtr          hpExpr;     // the postfix ++/-- we're hoisting
    bool                hpPast;     // are we past the ++/-- tree node?
};

int                 Compiler::fgHoistPostfixCB(GenTreePtr tree, void *p, bool prefix)
{
    hoistPostfixDsc*desc;
    GenTreePtr      ivar;
    GenTreePtr      expr;

    /* Get hold of the descriptor */

    desc = (hoistPostfixDsc*)p; ASSert(desc && desc->hpSelf == desc);

    /* Which phase are we in? */

    if  (desc->hpPhase == 1)
    {
        /* In phase 1 we simply look for postfix nodes */

        switch (tree->gtOper)
        {
        case GT_POST_INC:
        case GT_POST_DEC:
            desc->hpComp->fgHoistPostfixOp(desc->hpStmt, tree);
            break;
        }

        return  0;
    }

    Assert(desc->hpPhase == 2, desc->hpComp);

    /* We're only interested in assignments and uses of locals */

    if  (!(tree->OperKind() & GTK_ASGOP) && tree->gtOper != GT_LCL_VAR)
        return  0;

    /* Get hold of the ++/-- expression */

    expr = desc->hpExpr;

    Assert(expr, desc->hpComp);
    Assert(expr->gtOper == GT_POST_INC ||
           expr->gtOper == GT_POST_DEC, , desc->hpComp);

    /* Is this the ++/-- we're hoisting? */

    if  (tree == expr)
    {
        /* Remember that we've seen our postfix node */

        Assert(desc->hpPast == false, , desc->hpComp);
               desc->hpPast =   true;

        return  0;
    }

    /* If we're not past the ++/-- node yet, bail */

    if  (!desc->hpPast)
        return  0;

    if  (tree->gtOper == GT_LCL_VAR)
    {
        /* Filter out the argument of the ++/-- we're hoisting */

        if  (expr->gtOp.gtOp1 == tree)
            return  0;
    }
    else
    {
        /* Get the target of the assignment */

        tree = tree->gtOp.gtOp1;
        if  (tree->gtOper != GT_LCL_VAR)
            return  0;
    }

    /* Is the use/def of the variable we're interested in? */

    ivar = expr->gtOp.gtOp1; Assert(ivar->gtOper == GT_LCL_VAR, , desc->hpComp);

    if  (ivar->gtLclVar.gtLclNum == tree->gtLclVar.gtLclNum)
        return  -1;

    return  0;
}

/*****************************************************************************
 *
 *  We've encountered a postfix ++/-- expression during morph, we'll try to
 *  hoist the increment/decrement out of the statement.
 */

bool                Compiler::fgHoistPostfixOp(GenTreePtr     stmt,
                                               GenTreePtr     expr)
{
    GenTreePtr      incr;
    GenTreePtr      next;
    hoistPostfixDsc desc;

    assert(expr->gtOper == GT_POST_INC || expr->gtOper == GT_POST_DEC);

    GenTreePtr      op1 = expr->gtOp.gtOp1;  assert(op1->gtOper == GT_LCL_VAR);
    GenTreePtr      op2 = expr->gtOp.gtOp2;  assert(op2->gtOper == GT_CNS_INT);

    /* Make sure we're not in a try block */

    assert(!(compCurBB->bbFlags & BBF_HAS_HANDLER));

    /*
        We have no place to append the hoisted statement if the current
        statement is part of a conditional jump at the end of the block.
     */

    if  (stmt->gtNext == 0 && compCurBB->bbJumpKind != BBJ_NONE)
        return  false;

    /* Make sure no other assignments to the same variable are present */

    desc.hpPhase = 2;
    desc.hpComp  = this;
    desc.hpExpr  = expr;
#ifndef NDEBUG
    desc.hpSelf  = &desc;
#endif
    desc.hpPast  = false;

    /* fgWalkTree is not re-entrant, need to save some state */

    fgWalkTreeReEnter();
    int res = fgWalkTreeDepth(stmt->gtStmt.gtStmtExpr, fgHoistPostfixCB, &desc);
    fgWalkTreeRestore();

    if  (res)
        return  false;

//  printf("Hoist postfix ++/-- expression - before:\n");
//  gtDispTree(stmt);
//  printf("\n");
//  gtDispTree(expr);
//  printf("\n\n");

    /* Create the hoisted +=/-= statement */

    incr = gtNewLclvNode(op1->gtLclVar.gtLclNum, TYP_INT);

    /* The new variable is used as well as being defined */

    incr->gtFlags |= GTF_VAR_DEF|GTF_VAR_USE;

    incr = gtNewOperNode((expr->gtOper == GT_POST_INC) ? GT_ASG_ADD
                                                       : GT_ASG_SUB,
                         expr->TypeGet(),
                         incr,
                         op2);

    /* This becomes an assignment operation */

    incr->gtFlags |= GTF_ASG;
    incr = gtNewStmt(incr);

    /* Append the new ++/-- statement right after "stmt" */

    next = stmt->gtNext;

    incr->gtNext = next;
    incr->gtPrev = stmt;
    stmt->gtNext = incr;

    /* Appending after the last statement is a little tricky */

    if  (!next)
        next = compCurBB->bbTreeList;

    assert(next && (next->gtPrev == stmt));
                    next->gtPrev =  incr;

    /* Replace the original expression with a simple variable reference */

    expr->CopyFrom(op1);

    /* Reset the GTF_VAR_DEF and GTF_VAR_USE flags */

    expr->gtFlags &= ~(GTF_VAR_DEF|GTF_VAR_USE);

#ifdef DEBUG
    if (verbose)
    {
        printf("Hoisted postfix ++/-- expression - after:\n");
        gtDispTree(stmt);
        printf("\n");
        gtDispTree(incr);
        printf("\n\n\n");
    }
#endif

    /* This basic block now contains an increment */

    compCurBB->bbFlags |= BBF_HAS_INC;
    fgIncrCount++;

    return  true;
}

/*****************************************************************************
 *
 *  Try to hoist any postfix ++/-- expressions out of statements.
 */

void                Compiler::fgHoistPostfixOps()
{
    BasicBlock  *   block;
    hoistPostfixDsc desc;

    /* Should we be doing this at all? */

    if  (!(opts.compFlags & CLFLG_TREETRANS))
        return;

    /* Did we find any postfix operators anywhere? */

    if  (!fgHasPostfix)
        return;

    /* The first phase looks for candidate postfix nodes */

    desc.hpPhase = 1;
    desc.hpComp  = this;
#ifndef NDEBUG
    desc.hpSelf  = &desc;
#endif

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        if  (block->bbFlags & BBF_HAS_HANDLER)
            continue;

        if  (block->bbFlags & BBF_HAS_POSTFIX)
        {
            GenTreePtr      stmt;

            desc.hpBlock = compCurBB = block;

            for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
            {
                assert(stmt->gtOper == GT_STMT);

                desc.hpStmt = stmt;

                fgWalkTreeDepth(stmt->gtStmt.gtStmtExpr, fgHoistPostfixCB, &desc);
            }
        }
    }
}


/*****************************************************************************
 *
 * For GT_INITBLK and GT_COPYBLK, the tree looks like this :
 *                                tree->gtOp
 *                                 /    \
 *                               /        \.
 *                           GT_LIST  [size/clsHnd]
 *                            /    \
 *                           /      \
 *                       [dest]     [val/src]
 *
 * ie. they are ternary operators. However we use nested binary trees so that
 * GTF_REVERSE_OPS will be set just like for other binary operators. As the
 * operands need to end up in specific registers to issue the "rep stos" or
 * the "rep movs" instruction, if we dont allow the order of evaluation of
 * the 3 operands to be mixed, we may generate really bad code
 *
 * eg. For "rep stos", [val] has to be in EAX. Then if [size]
 * has a division, we will have to spill [val] from EAX. It will be better to
 * evaluate [size] and the evaluate [val] into EAX.
 *
 * This function stores the operands in the order to be evaluated
 * into opsPtr[]. The regsPtr[] contains reg0,reg1,reg2 in the correspondingly
 * switched order.
 */


void            Compiler::fgOrderBlockOps( GenTreePtr   tree,
                                           unsigned     reg0,
                                           unsigned     reg1,
                                           unsigned     reg2,
                                           GenTreePtr   opsPtr [],  // OUT
                                           unsigned     regsPtr[])  // OUT
{
    ASSert(tree->OperGet() == GT_INITBLK || tree->OperGet() == GT_COPYBLK);

    ASSert(tree->gtOp.gtOp1 && tree->gtOp.gtOp1->OperGet() == GT_LIST);
    ASSert(tree->gtOp.gtOp1->gtOp.gtOp1 && tree->gtOp.gtOp1->gtOp.gtOp2);
    ASSert(tree->gtOp.gtOp2);

    GenTreePtr ops[3] =
    {
        tree->gtOp.gtOp1->gtOp.gtOp1,       // Dest address
        tree->gtOp.gtOp1->gtOp.gtOp2,       // Val / Src address
        tree->gtOp.gtOp2                    // Size of block
    };

    unsigned regs[3] = { reg0, reg1, reg2 };

    static int blockOpsOrder[4][3] =
                        //      tree->gtFlags    |  tree->gtOp.gtOp1->gtFlags
    {                   //  ---------------------+----------------------------
        { 0, 1, 2 },    //           -           |              -
        { 2, 0, 1 },    //     GTF_REVERSE_OPS   |              -
        { 1, 0, 2 },    //           -           |       GTF_REVERSE_OPS
        { 2, 1, 0 }     //     GTF_REVERSE_OPS   |       GTF_REVERSE_OPS
    };

    int orderNum =              ((tree->gtFlags & GTF_REVERSE_OPS) != 0) * 1 +
                    ((tree->gtOp.gtOp1->gtFlags & GTF_REVERSE_OPS) != 0) * 2;

    ASSert(orderNum < 4);

    int * order = blockOpsOrder[orderNum];

    // Fill in the OUT arrays according to the order we have selected

     opsPtr[0]  =  ops[ order[0] ];
     opsPtr[1]  =  ops[ order[1] ];
     opsPtr[2]  =  ops[ order[2] ];

    regsPtr[0]  = regs[ order[0] ];
    regsPtr[1]  = regs[ order[1] ];
    regsPtr[2]  = regs[ order[2] ];
}

/*****************************************************************************/
#if DEBUG
/*****************************************************************************
 *
 *  A DEBUG-only routine to display the basic block list.
 */

#if RNGCHK_OPT

#define MAX_PRED_SPACES  15

void                Compiler::fgDispPreds(BasicBlock * block)
{
    flowList    *   pred;
    unsigned        i=0;
    unsigned        spaces=0;

    for (pred = block->bbPreds; pred && spaces < MAX_PRED_SPACES;
         pred = pred->flNext)
    {
        if (i)
            spaces += printf("|");
        spaces += printf("%d", pred->flBlock->bbNum);
        i++;
    }
    if (spaces < MAX_PRED_SPACES)
       for ( ; spaces < MAX_PRED_SPACES; spaces++)
           printf(" ");
}

inline
BLOCKSET_TP         genBlocknum2bit(unsigned index);

void                Compiler::fgDispDoms()
{
    BasicBlock    *    block;
    unsigned           bit;

    printf("------------------------------------------------\n");
    printf("BBnum Dominated by \n");
    printf("------------------------------------------------\n");

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        printf(" #%02u ", block->bbNum);
        for (bit = 1; bit < BLOCKSET_SZ; bit++)
        {
            if  (block->bbDom & genBlocknum2bit(bit))
            {
                printf(" #%02u ", bit);
            }
        }
        printf("\n");
    }
}

#else
inline void Compiler::fgDispPreds(BasicBlock * block){}
#endif // RNGCHK_OPT

/*****************************************************************************/

void                Compiler::fgDispBasicBlocks(bool dumpTrees)
{
    BasicBlock  *   tmpBBdesc;
    unsigned        count;

    printf("\n");
    printf("----------------------------------------------------------------\n");
    printf("BBnum descAddr #refs preds           weight [ PC range ]  [jump]\n");
    printf("----------------------------------------------------------------\n");

    for (tmpBBdesc = fgFirstBB, count = 0;
         tmpBBdesc;
         tmpBBdesc = tmpBBdesc->bbNext)
    {
        unsigned        flags = tmpBBdesc->bbFlags;

        if  (++count != tmpBBdesc->bbNum)
        {
            printf("WARNING: the following BB has an out-of-sequence number!\n");
            count = tmpBBdesc->bbNum;
        }

        printf(" #%02u @%08X  %3u  ", tmpBBdesc->bbNum,
                                      tmpBBdesc,
                                      tmpBBdesc->bbRefs);

        fgDispPreds(tmpBBdesc);

        printf(" %6u ", tmpBBdesc->bbWeight);

        if  (flags & BBF_INTERNAL)
        {
            printf("[*internal*] ");
        }
        else
        {
            printf("[%4u..%4u] ", tmpBBdesc->bbCodeOffs,
                                  tmpBBdesc->bbCodeOffs + tmpBBdesc->bbCodeSize - 1);
        }

        switch (tmpBBdesc->bbJumpKind)
        {
        case BBJ_COND:
            printf("-> #%02u ( cond )", tmpBBdesc->bbJumpDest->bbNum);
            break;

        case BBJ_CALL:
            printf("-> #%02u ( call )", tmpBBdesc->bbJumpDest->bbNum);
            break;

        case BBJ_ALWAYS:
            printf("-> #%02u (always)", tmpBBdesc->bbJumpDest->bbNum);
            break;

        case BBJ_RET:
            printf("call-ret       ");
            break;

        case BBJ_THROW:
            printf(" throw         ");
            break;

        case BBJ_RETURN:
            printf("return         ");
            break;

        case BBJ_SWITCH:
            printf("switch ->      ");

            unsigned        jumpCnt;
                            jumpCnt = tmpBBdesc->bbJumpSwt->bbsCount;
            BasicBlock * *  jumpTab;
                            jumpTab = tmpBBdesc->bbJumpSwt->bbsDstTab;

            do
            {
                printf("%02u|", (*jumpTab)->bbNum);
            }
            while (++jumpTab, --jumpCnt);

            break;

        default:
            printf("               ");
            break;
        }

        switch(tmpBBdesc->bbCatchTyp)
        {
        case BBCT_FAULT          : printf(" %s ", "f"); break;
        case BBCT_FINALLY        : printf(" %s ", "F"); break;
        case BBCT_FILTER         : printf(" %s ", "r"); break;
        case BBCT_FILTER_HANDLER : printf(" %s ", "R"); break;
        default                  : printf(" %s ", "X"); break;
        case 0                   :
            if (flags & BBF_HAS_HANDLER)
                printf(" %s ", (flags & BBF_IS_TRY) ? "T" : "t");
        }

        printf("\n");

        if  (dumpTrees)
        {
            GenTreePtr      tree = tmpBBdesc->bbTreeList;

            if  (tree)
            {
                printf("\n");

                do
                {
                    assert(tree->gtOper == GT_STMT);

                    gtDispTree(tree);
                    printf("\n");

                    tree = tree->gtNext;
                }
                while (tree);

                if  (tmpBBdesc->bbNext)
                    printf("- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n\n");
            }
        }
    }

    printf("----------------------------------------------------------------\n");
}


/*****************************************************************************/

const SANITY_DEBUG_CHECKS = 0;

/*****************************************************************************
 *
 * A DEBUG routine to check the consistency of the flowgraph,
 * i.e. bbNums, bbRefs, bbPreds have to be up to date
 *
 *****************************************************************************/

void                Compiler::fgDebugCheckBBlist()
{
    // This is quite an expensive operation, so it is not always enabled.
    // Set SANITY_DEBUG_CHECKS to 1 to enable the check
    if (SANITY_DEBUG_CHECKS == 0)
        return;

    BasicBlock   *  block;
    BasicBlock   *  blockPred;
    BasicBlock   *  bcall;
    flowList     *  pred;

    unsigned        blockNum = 0;
    unsigned        blockRefs;

    /* Check bbNums, bbRefs and bbPreds */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        assert(block->bbNum == ++blockNum);

        blockRefs = 0;

        /* First basic block has bbRefs >= 1 */

        if  (block == fgFirstBB)
        {
            assert(block->bbRefs >= 1);
            blockRefs = 1;
        }

        for (pred = block->bbPreds; pred; pred = pred->flNext, blockRefs++)
        {
            /*  make sure this pred is part of the BB list */
            for (blockPred = fgFirstBB; blockPred; blockPred = blockPred->bbNext)
            {
                if (blockPred == pred->flBlock)
                    break;
            }
            assert(blockPred && "Predecessor is not part of BB list!");

            switch (blockPred->bbJumpKind)
            {
            case BBJ_COND:
                assert(blockPred->bbNext == block || blockPred->bbJumpDest == block);
                break;

            case BBJ_NONE:
                assert(blockPred->bbNext == block);
                break;

            case BBJ_ALWAYS:
            case BBJ_CALL:
                assert(blockPred->bbJumpDest == block);
                break;

            case BBJ_RET:

                if (blockPred->bbFlags & BBF_ENDFILTER)
                {
                    assert(blockPred->bbJumpDest == block);
                    break;
                }

                /*  UNDONE: Since it's not a trivial proposition to figure out
                    UNDONE: which blocks may call this one, we'll include all
                    UNDONE: blocks that end in calls (to play it safe).
                 */

                for (bcall = fgFirstBB; bcall; bcall = bcall->bbNext)
                {
                    if  (bcall->bbJumpKind == BBJ_CALL)
                    {
                        assert(bcall->bbNext);
                        if  (block == bcall->bbNext)
                            goto PRED_OK;
                    }
                }
                assert(!"BBJ_RET predecessor of block that doesn't follow a BBJ_CALL!");
                break;

            case BBJ_THROW:
            case BBJ_RETURN:
                assert(!"THROW and RETURN block cannot be in the predecessor list!");
                break;

            case BBJ_SWITCH:
                unsigned        jumpCnt = blockPred->bbJumpSwt->bbsCount;
                BasicBlock * *  jumpTab = blockPred->bbJumpSwt->bbsDstTab;

                do
                {
                    if  (block == *jumpTab)
                    goto PRED_OK;
                }
                while (++jumpTab, --jumpCnt);

                assert(!"SWITCH in the predecessor list with no jump label to BLOCK!");
                break;
            }
PRED_OK:;
        }

        /* Check the bbRefs */
        assert(block->bbRefs == blockRefs);
    }
    assert(fgLastBB->bbNum == blockNum);
}

/*****************************************************************************
 *
 * A DEBUG routine to check the that the exception flags are correctly set.
 *
 ****************************************************************************/

void                Compiler::fgDebugCheckFlags(GenTreePtr tree)
{
    assert(tree);
    assert(tree->gtOper != GT_STMT);

    unsigned        opFlags = 0;
    unsigned        flags   = tree->gtFlags & GTF_SIDE_EFFECT;
    GenTreePtr      op1     = tree->gtOp.gtOp1;
    GenTreePtr      op2     = tree->gtOp.gtOp2;

    /* Figure out what kind of a node we have */

    unsigned        kind = tree->OperKind();

    /* Is this a leaf node? */

    if  (kind & GTK_LEAF)
    {
        if (tree->gtOper == GT_CATCH_ARG)
            return;

        /* No exception flags are set on a leaf node */
        assert(!(tree->gtFlags & GTF_SIDE_EFFECT));
        return;
    }

    /* Is it a 'simple' unary/binary operator? */

    if  (kind & GTK_SMPOP)
    {
        if (op1) opFlags |= (op1->gtFlags & GTF_SIDE_EFFECT);

        if (op2) opFlags |= (op2->gtFlags & GTF_SIDE_EFFECT);

        /* If the two sets are equal we're fine */

        if (flags != opFlags)
        {
            /* Check if we have extra flags or missing flags (for the parent) */

            if (flags & ~opFlags)
            {
                /* Parent has extra flags */

                unsigned extra = flags & ~opFlags;

                /* The extra flags must be generated by the parent node itself */

                if ((extra & GTF_ASG) && !(kind & GTK_ASGOP))
                {
                    gtDispTree(tree);
                    assert(!"GTF_ASG flag set incorrectly on node!");
                }
                else if (extra & GTF_CALL)
                {
                    gtDispTree(tree);
                    assert(!"GTF_CALL flag set incorrectly!");
                }
                else if (extra & GTF_EXCEPT)
                    assert(tree->OperMayThrow());
            }

            if (opFlags & ~flags)
                assert(!"Parent has missing flags!");
        }

        /* Recursively check the subtrees */

        if (op1) fgDebugCheckFlags(op1);
        if (op2) fgDebugCheckFlags(op2);
    }

    /* See what kind of a special operator we have here */

    switch  (tree->OperGet())
    {
    case GT_CALL:

        GenTreePtr      args;
        GenTreePtr      argx;

        for (args = tree->gtCall.gtCallArgs; args; args = args->gtOp.gtOp2)
        {
            argx = args->gtOp.gtOp1;
            fgDebugCheckFlags(argx);

            opFlags |= (argx->gtFlags & GTF_SIDE_EFFECT);
        }

        for (args = tree->gtCall.gtCallRegArgs; args; args = args->gtOp.gtOp2)
        {
            argx = args->gtOp.gtOp1;
            fgDebugCheckFlags(argx);

            opFlags |= (argx->gtFlags & GTF_SIDE_EFFECT);
        }

        if (flags != opFlags)
        {
            /* Check if we have extra flags or missing flags (for the parent) */

            if (flags & ~opFlags)
            {
                /* Parent has extra flags - that can only be GTF_CALL */
                assert((flags & ~opFlags) == GTF_CALL);
            }

            //if (opFlags & ~flags)
              //  assert(!"Parent has missing flags!");
        }

        return;

    case GT_MKREFANY:
    case GT_LDOBJ:

    case GT_JMP:
    case GT_JMPI:

    default:
        return;
    }
}

/*****************************************************************************
 *
 * A DEBUG routine to check the correctness of the links between GT_STMT nodes
 * and ordinary nodes within a statement.
 *
 ****************************************************************************/

void                Compiler::fgDebugCheckLinks()
{
    // This is quite an expensive operation, so it is not always enabled.
    // Set SANITY_DEBUG_CHECKS to 1 to enable the check
    if (SANITY_DEBUG_CHECKS == 0)
        return;

    BasicBlock   *  block;
    GenTreePtr      stmt;
    GenTreePtr      tree;

    /* For each basic block check the bbTreeList links */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);
            assert(stmt->gtPrev);

            /* Verify that bbTreeList is threaded correctly */

            if  (stmt == block->bbTreeList)
                assert(stmt->gtPrev->gtNext == 0);
            else
                assert(stmt->gtPrev->gtNext == stmt);

            if  (stmt->gtNext)
                assert(stmt->gtNext->gtPrev == stmt);
            else
                assert(block->bbTreeList->gtPrev == stmt);

            /* For each statement check that the exception flags are properly set */

            assert(stmt->gtStmt.gtStmtExpr);

            fgDebugCheckFlags(stmt->gtStmt.gtStmtExpr);

            /* For each GT_STMT node check that the nodes are threaded correcly - gtStmtList */

            if  (!fgStmtListThreaded) continue;

            assert(stmt->gtStmt.gtStmtList);

            GenTreePtr      list = stmt->gtStmt.gtStmtList;

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                if  (tree->gtPrev)
                    assert(tree->gtPrev->gtNext == tree);
                else
                    assert(tree == stmt->gtStmt.gtStmtList);

                if  (tree->gtNext)
                    assert(tree->gtNext->gtPrev == tree);
                else
                    assert(tree == stmt->gtStmt.gtStmtExpr);
            }
        }
    }

}

/*****************************************************************************/
#endif // DEBUG
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\gcdecode.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
#include "jitpch.h"
#pragma hdrstop

/* Precompiled header nonsense requires that we do it this way  */

/* GCDecoder.cpp is a common source file bewtween VM and JIT/IL */
/* GCDecoder.cpp is located in $COM99/inc                       */

#if TRACK_GC_REFS
#include "GCDecoder.cpp"
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\infile.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\gcinfo.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                          GCInfo                                           XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

#include "GCInfo.h"
#include "emit.h"
#include "malloc.h"     // for alloca

/*****************************************************************************/
#if TRACK_GC_REFS
/*****************************************************************************/

/*****************************************************************************/
#define REGEN_SHORTCUTS 0
// To Regenerate the compressed info header shortcuts, define REGEN_SHORTCUTS
// and use the following UNIX command line pipe/filter to give you the 128
// most useful encodings.  Unix utilities available at www.cygnus.com
//
// jit -n:D- @all.lst | sort | uniq -c | sort -r | head -128

#define REGEN_CALLPAT 0
// To Regenerate the compressed info header shortcuts, define REGEN_CALLPAT
// and use the following UNIX command line pipe/filter to give you the 80
// most useful encodings.  Unix utilities available at www.cygnus.com
//
// jit -n:D- @all.lst | sort | uniq -c | sort -r | head -80

/*****************************************************************************/

#if GC_WRITE_BARRIER_CALL && defined(NOT_JITC)
extern int         JITGcBarrierCall;
#else
int                JITGcBarrierCall = 1;
#endif

/*****************************************************************************/

#if MEASURE_PTRTAB_SIZE
/* static */ unsigned       Compiler::s_gcRegPtrDscSize = 0;
/* static */ unsigned       Compiler::s_gcTotalPtrTabSize = 0;
#endif

#if GC_WRITE_BARRIER_CALL && defined(NOT_JITC)
/* static */ void *         Compiler::s_gcWriteBarrierPtr = NULL;
#else
/* static */ const void *   Compiler::s_GCptrTable[128];
/* static */ void *         Compiler::s_gcWriteBarrierPtr = Compiler::s_GCptrTable;
#endif

void                Compiler::gcInit()
{
}

/*****************************************************************************/
#ifndef OPT_IL_JIT
/*****************************************************************************
 *
 *  If the given tree value is sitting in a register, free it now.
 */

void                Compiler::gcMarkRegPtrVal(GenTreePtr tree)
{
    if  (varTypeIsGC(tree->TypeGet()))
    {
        if  (tree->gtOper == GT_LCL_VAR)
            genMarkLclVar(tree);

        if  (tree->gtFlags & GTF_REG_VAL)
            gcMarkRegSetNpt(genRegMask(tree->gtRegNum));
    }
}

/*****************************************************************************/

#ifdef  DEBUG

void                Compiler::gcRegPtrSetDisp(unsigned regMask, bool fixed)
{
    unsigned        regNum;

    assert(REG_STK+1 == REG_COUNT);

    for (regNum = 0; regNum < REG_STK; regNum++)
    {
        if  (regMask & genRegMask((regNumber)regNum))
        {
            char    reg[10];

            strcpy(reg, compRegVarName((regNumber)regNum));

#ifndef _WIN32_WCE
            _strlwr(reg+1);
#endif

            printf("%3s", reg);
        }
        else
        {
            if  (fixed)
                printf("   ");
        }
    }
}

#endif

/*****************************************************************************/
#endif // OPT_IL_JIT
/*****************************************************************************
 *
 *  Initialize the non-register pointer variable tracking logic.
 */

void                Compiler::gcVarPtrSetInit()
{
    gcVarPtrSetCur = 0;

    /* Initialize the list of lifetime entries */

    gcVarPtrList =
    gcVarPtrLast = (varPtrDsc *)compGetMem(sizeof(*gcVarPtrList));

    gcVarPtrList->vpdNext =
    gcVarPtrList->vpdPrev = 0;
}

/*****************************************************************************
 *
 *  Allocate a new pointer register set / pointer argument entry and append
 *  it to the list.
 */

Compiler::regPtrDsc  *        Compiler::gcRegPtrAllocDsc()
{
    regPtrDsc  *    regPtrNext;

    assert(genFullPtrRegMap);

    /* Allocate a new entry and initialize it */

    regPtrNext = (regPtrDsc *)compGetMem(sizeof(*regPtrNext));

    regPtrNext->rpdEpilog        = FALSE;
    regPtrNext->rpdIsThis        = FALSE;

    regPtrNext->rpdOffs          = 0;
//  regPtrNext->rpdNext          = 0;

    /* Append the entry to the end of the list */

    assert(gcRegPtrList);
    assert(gcRegPtrLast);

    /* Note that we don't set the 'next' link for the new entry */

    gcRegPtrLast->rpdNext  = regPtrNext;
    gcRegPtrLast           = regPtrNext;

#if MEASURE_PTRTAB_SIZE
    s_gcRegPtrDscSize += sizeof(*regPtrNext);
#endif

    return  regPtrNext;
}

/*****************************************************************************
 *
 *  Compute the various counts that get stored in the info block header.
 */

void                Compiler::gcCountForHeader(unsigned short* untrackedCount,
                                               unsigned short* varPtrTableSize)
{
    unsigned        varNum;
    LclVarDsc *     varDsc;
    varPtrDsc *     varTmp;

    assert(gcVarPtrList);
    assert(gcVarPtrLast);

    /* Terminate the linked list of variable lifetimes */

    gcVarPtrLast->vpdNext = 0;

    /* Skip over the initial fake lifetime entry */

    gcVarPtrList = gcVarPtrList->vpdNext;

    if  (genFullPtrRegMap)
    {
        assert(gcRegPtrList);
        assert(gcRegPtrLast);

        /* Terminate the linked list */

        gcRegPtrLast->rpdNext = 0;

        /* The first entry in the list is fake */

        gcRegPtrList = gcRegPtrList->rpdNext;
    }
    else
    {
        assert(gcCallDescList);
        assert(gcCallDescLast);

        /* Terminate the linked list of call descriptors */

        gcCallDescLast->cdNext = 0;

        /* Skip over the initial fake call entry */

        gcCallDescList = gcCallDescList->cdNext;
    }

    bool        thisIsInUntracked = false; // did we track "this" ?
    unsigned    count = 0;

    /* Count the untracked locals and non-enregistered args */

    for (varNum = 0, varDsc = lvaTable;
         varNum < lvaCount;
         varNum++  , varDsc++)
    {
        if  (varTypeIsGC(varDsc->TypeGet()))
        {
            /* Do we have an argument or local variable? */
            if  (!varDsc->lvIsParam)
            {
                if  (varDsc->lvTracked || !varDsc->lvOnFrame)
                    continue;
            }
            else
            {
                /* Stack-passed arguments which are not enregistered
                 * are always reported in this "untracked stack
                 * pointers" section of the GC info even if lvTracked==true
                 */

                /* Has this argument been enregistered? */
                if  (varDsc->lvRegister)
                {
                    /*
                       Special case: include the stack location of 'this'
                       for synchronized methods, so that runtime can find
                       'this' in case an exception goes by.
                     */
#if !USE_FASTCALL
                    if  (varNum != 0 || !(info.compFlags & FLG_SYNCH))
#endif
                        continue;
                }
                else
                {
                    if  (!varDsc->lvOnFrame)
                    {
                        /* If this non-enregistered pointer arg is never
                         * used, we dont need to report it
                         */
                        assert(varDsc->lvRefCnt == 0);
                        continue;
                    }
#if USE_FASTCALL
                    else  if (varDsc->lvIsRegArg && varDsc->lvTracked)
                    {
                        /* If this register-passed arg is tracked, then
                         * it has been allocated space near the other
                         * pointer variables and we have accurate life-
                         * time info. It will be reported with
                         * gcVarPtrList in the "tracked-pointer" section
                         */

                        continue;
                    }
#endif
                }
            }

            if (varDsc->lvIsThis)
            {
                // Encoding of untracked variables does not support reporting
                // "this". So report it as a tracked variable with a liveness
                // extending over the entire method.

                thisIsInUntracked = true;
                continue;
            }

#ifdef  DEBUG
            if  (verbose)
            {
                int         offs = varDsc->lvStkOffs;

                printf("GCINFO: untrckd %s lcl at [%s",
                        varTypeGCstring(varDsc->TypeGet()),
                        genFPused ? "EBP" : "ESP");

                if      (offs < 0)
                    printf("-%02XH", -offs);
                else if (offs > 0)
                    printf("+%02XH", +offs);

                printf("]\n");
            }
#endif

            count++;
        }
        else if  (varDsc->lvType == TYP_STRUCT && varDsc->lvOnFrame)
        {
            assert(!varDsc->lvTracked);

            CLASS_HANDLE cls = lvaLclClass(varNum);
            assert(cls != 0);
            if (cls == REFANY_CLASS_HANDLE)
            {
                count++;    // Any REFANY has one GC (interior) pointer
            }
            else
            {
                unsigned slots = roundUp(eeGetClassSize(cls), sizeof(void*)) / sizeof(void*);
                bool* gcPtrs = (bool*) _alloca(slots*sizeof(bool));
                eeGetClassGClayout(cls, gcPtrs);

                    // walk each member of the array
                for (unsigned i = 0; i < slots; i++)
                    if (gcPtrs[i])     // count only gc slots
                        count++;
            }
        }
    }

    /* Also count spill temps that hold pointers */

    for (TempDsc * tempThis = tmpListBeg();
         tempThis;
         tempThis = tmpListNxt(tempThis))
    {
        if  (varTypeIsGC(tempThis->tdTempType()) == false)
            continue;

#ifdef  DEBUG
        if  (verbose)
        {
            int         offs = tempThis->tdTempOffs();

            printf("GCINFO: untrck %s Temp at [%s",
                    varTypeGCstring(varDsc->TypeGet()),
                    genFPused ? "EBP" : "ESP");

            if      (offs < 0)
                printf("-%02XH", -offs);
            else if (offs > 0)
                printf("+%02XH", +offs);

            printf("]\n");
        }
#endif

        count++;
    }

#ifdef  DEBUG
    if (verbose) printf("GCINFO: untrckVars = %u\n", count);
#endif

    *untrackedCount = count;

    /* Count the number of entries in the table of non-register pointer
       variable lifetimes. */

    count = 0;

    if (thisIsInUntracked)
        count++;

    if  (gcVarPtrList)
    {
        /* We'll use a delta encoding for the lifetime offsets */

        for (varTmp = gcVarPtrList; varTmp; varTmp = varTmp->vpdNext)
        {
            /* Special case: skip any 0-length lifetimes */

            if  (varTmp->vpdBegOfs == varTmp->vpdEndOfs)
                continue;

            count++;
        }
    }

#ifdef  DEBUG
    if (verbose) printf("GCINFO: trackdLcls = %u\n", count);
#endif

    *varPtrTableSize = count;
}

/*****************************************************************************
 *
 *  Shutdown the 'pointer value' register tracking logic and save the necessary
 *  info (which will be used at runtime to locate all pointers) at the specified
 *  address. The number of bytes written to 'destPtr' must be identical to that
 *  returned from gcPtrTableSize().
 */

BYTE    *           Compiler::gcPtrTableSave(BYTE *          destPtr,
                                             const InfoHdr & header,
                                             unsigned        codeSize)
{
    /* Write the tables to the info block */

    return  destPtr + gcMakeRegPtrTable(destPtr, -1, header, codeSize);
}

/*****************************************************************************
 *
 *  Initialize the 'pointer value' register/argument tracking logic.
 */

void                Compiler::gcRegPtrSetInit()
{
    gcRegGCrefSetCur =
    gcRegByrefSetCur = 0;

    if  (genFullPtrRegMap)
    {
        gcRegPtrList =
        gcRegPtrLast = (regPtrDsc *)compGetMem(roundUp(sizeof(*gcRegPtrList)));

//      gcRegPtrList->rpdNext            = 0;
        gcRegPtrList->rpdOffs            = 0;
        gcRegPtrList->rpdCompiler.rpdAdd =
        gcRegPtrList->rpdCompiler.rpdDel = 0;
    }
    else
    {
        /* Initialize the 'call descriptor' list */

        gcCallDescList =
        gcCallDescLast = (CallDsc *)compGetMem(sizeof(*gcCallDescList));
    }
}

/*****************************************************************************
 *
 *  Helper passed to genEmitter.emitCodeEpilogLst() to generate
 *  the table of epilogs.
 */

/* static */ size_t Compiler::gcRecordEpilog(void * pCallBackData,
                                             unsigned offset)
{
    Compiler  *     pCompiler = (Compiler *)pCallBackData;

    ASSert(pCompiler);

    size_t result = encodeUDelta(pCompiler->gcEpilogTable,
                                 offset,
                                 pCompiler->gcEpilogPrevOffset);

    if (pCompiler->gcEpilogTable)
        pCompiler->gcEpilogTable += result;

    pCompiler->gcEpilogPrevOffset = offset;

    return result;
}

/*****************************************************************************/
#endif // TRACK_GC_REFS
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\gtlist.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef GTNODE
#error  Define GTNODE before including this file.
#endif
/*****************************************************************************/
//
//    Node enum
//                   , "Node name"
//                                  ,commutative
//                                    ,operKind

GTNODE(GT_NONE       , "<none>"     ,0,GTK_NONE)

//-----------------------------------------------------------------------------
//  Leaf nodes (i.e. these nodes have no sub-operands):
//-----------------------------------------------------------------------------

GTNODE(GT_LCL_VAR    , "lclVar"     ,0,GTK_LEAF)
GTNODE(GT_RET_ADDR   , "retAddr"    ,0,GTK_LEAF)
GTNODE(GT_CATCH_ARG  , "catchArg"   ,0,GTK_LEAF)
GTNODE(GT_LABEL      , "codeLabel"  ,0,GTK_LEAF)
GTNODE(GT_POP        , "pop"        ,0,GTK_LEAF)
GTNODE(GT_BREAK,     , "break"      ,0,GTK_LEAF)
GTNODE(GT_NO_OP      , "nop"        ,0,GTK_LEAF)
GTNODE(GT_FTN_ADDR   , "ftnAddr"    ,0,GTK_LEAF)

#if OPTIMIZE_QMARK
GTNODE(GT_BB_QMARK   , "_?"         ,0,GTK_LEAF)
GTNODE(GT_BB_COLON   , "_:"         ,0,GTK_UNOP)
#endif

//-----------------------------------------------------------------------------
//  Constant nodes:
//-----------------------------------------------------------------------------

GTNODE(GT_CNS_INT    , "int const"  ,0,GTK_LEAF|GTK_CONST)
GTNODE(GT_CNS_LNG    , "lng const"  ,0,GTK_LEAF|GTK_CONST)
GTNODE(GT_CNS_FLT    , "flt const"  ,0,GTK_LEAF|GTK_CONST)
GTNODE(GT_CNS_DBL    , "dbl const"  ,0,GTK_LEAF|GTK_CONST)
GTNODE(GT_CNS_STR    , "str const"  ,0,GTK_LEAF|GTK_CONST)

//-----------------------------------------------------------------------------
//  Unary  operators (1 operand):
//-----------------------------------------------------------------------------

GTNODE(GT_NOT        , "~"          ,0,GTK_UNOP)
GTNODE(GT_NOP        , "unary +"    ,0,GTK_UNOP)
GTNODE(GT_NEG        , "unary -"    ,0,GTK_UNOP)
GTNODE(GT_CHS        , "flipsign"   ,0,GTK_UNOP|GTK_ASGOP)

GTNODE(GT_LOG0       , "log 0"      ,0,GTK_UNOP)
GTNODE(GT_LOG1       , "log 1"      ,0,GTK_UNOP)

GTNODE(GT_ARR_LENGTH , "arrayLength",0,GTK_UNOP)
#if     CSELENGTH
GTNODE(GT_ARR_RNGCHK , "rangecheck" ,0,GTK_NONE)
#endif

#if     INLINE_MATH
GTNODE(GT_MATH       , "mathFN"     ,0,GTK_UNOP)
#endif

GTNODE(GT_CAST       , "cast"       ,0,GTK_BINOP)   // it's unary, really

GTNODE(GT_CKFINITE   , "ckfinite"   ,0,GTK_UNOP)
GTNODE(GT_LCLHEAP    , "lclHeap"    ,0,GTK_UNOP)
GTNODE(GT_VIRT_FTN   , "virtFtn"    ,0,GTK_BINOP)   // it's unary, really

GTNODE(GT_ADDR       , "addr"       ,0,GTK_UNOP)

//-----------------------------------------------------------------------------
//  Binary operators (2 operands):
//-----------------------------------------------------------------------------

GTNODE(GT_ADD        , "+"          ,1,GTK_BINOP)
GTNODE(GT_SUB        , "-"          ,0,GTK_BINOP)
GTNODE(GT_MUL        , "*"          ,1,GTK_BINOP)
GTNODE(GT_DIV        , "/"          ,0,GTK_BINOP)
GTNODE(GT_MOD        , "%"          ,0,GTK_BINOP)

GTNODE(GT_UDIV       , "/"          ,0,GTK_BINOP)
GTNODE(GT_UMOD       , "%"          ,0,GTK_BINOP)

GTNODE(GT_OR         , "|"          ,1,GTK_BINOP|GTK_LOGOP)
GTNODE(GT_XOR        , "^"          ,1,GTK_BINOP|GTK_LOGOP)
GTNODE(GT_AND        , "&"          ,1,GTK_BINOP|GTK_LOGOP)

GTNODE(GT_LSH        , "<<"         ,0,GTK_BINOP)
GTNODE(GT_RSH        , ">>"         ,0,GTK_BINOP)
GTNODE(GT_RSZ        , ">>>"        ,0,GTK_BINOP)

GTNODE(GT_ASG        , "="          ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_ADD    , "+="         ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_SUB    , "-="         ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_MUL    , "*="         ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_DIV    , "/="         ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_MOD    , "%="         ,0,GTK_BINOP|GTK_ASGOP)

GTNODE(GT_ASG_UDIV   , "/="         ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_UMOD   , "%="         ,0,GTK_BINOP|GTK_ASGOP)

GTNODE(GT_ASG_OR     , "|="         ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_XOR    , "^="         ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_AND    , "&="         ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_LSH    , "<<="        ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_RSH    , ">>="        ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_ASG_RSZ    , ">>>="       ,0,GTK_BINOP|GTK_ASGOP)

GTNODE(GT_POST_INC   , "++"         ,0,GTK_BINOP|GTK_ASGOP)
GTNODE(GT_POST_DEC   , "--"         ,0,GTK_BINOP|GTK_ASGOP)

GTNODE(GT_EQ         , "=="         ,0,GTK_BINOP|GTK_RELOP)
GTNODE(GT_NE         , "!="         ,0,GTK_BINOP|GTK_RELOP)
GTNODE(GT_LT         , "<"          ,0,GTK_BINOP|GTK_RELOP)
GTNODE(GT_LE         , "<="         ,0,GTK_BINOP|GTK_RELOP)
GTNODE(GT_GE         , ">="         ,0,GTK_BINOP|GTK_RELOP)
GTNODE(GT_GT         , ">"          ,0,GTK_BINOP|GTK_RELOP)

GTNODE(GT_COMMA      , ","          ,0,GTK_BINOP)

#if OPTIMIZE_QMARK
GTNODE(GT_QMARK      , "?"          ,0,GTK_BINOP)
GTNODE(GT_COLON      , ":"          ,0,GTK_BINOP)
#endif

GTNODE(GT_INSTOF     , "instanceof" ,0,GTK_BINOP)

GTNODE(GT_INDEX      , "[]"         ,0,GTK_BINOP)

GTNODE(GT_MKREFANY   , "mkrefany"   ,0,GTK_NONE)
GTNODE(GT_LDOBJ      , "ldobj"      ,0,GTK_NONE)

//-----------------------------------------------------------------------------
//  Other nodes that look like unary/binary operators:
//-----------------------------------------------------------------------------

GTNODE(GT_JTRUE      , "jmpTrue"    ,0,GTK_UNOP)

GTNODE(GT_LIST       , "<list>"     ,0,GTK_BINOP)

GTNODE(GT_GOTO       , "goto"       ,0,GTK_UNOP)

//-----------------------------------------------------------------------------
//  Other nodes that have special structure:
//-----------------------------------------------------------------------------

GTNODE(GT_FIELD      , "field"      ,0,GTK_NONE)
GTNODE(GT_CALL       , "call()"     ,0,GTK_NONE)

GTNODE(GT_JMP        , "jump"       ,0,GTK_NONE)
GTNODE(GT_JMPI       , "jumpi"   ,0,GTK_NONE)

//-----------------------------------------------------------------------------
//  Statement operator nodes:
//-----------------------------------------------------------------------------

GTNODE(GT_BLOCK      , "BasicBlock" ,0,GTK_UNOP)      // used only temporarily
GTNODE(GT_STMT       , "stmtExpr"   ,0,GTK_NONE)

GTNODE(GT_RET        , "ret"        ,0,GTK_UNOP)
GTNODE(GT_SWITCH     , "switch"     ,0,GTK_UNOP)
GTNODE(GT_RETURN     , "return"     ,0,GTK_UNOP)

GTNODE(GT_RETFILT,     "retfilt",    0,GTK_UNOP)
GTNODE(GT_INITBLK    , "initBlk"    ,0,GTK_BINOP)
GTNODE(GT_COPYBLK    , "copyBlk"    ,0,GTK_BINOP)

//-----------------------------------------------------------------------------
//  Nodes used only within the code generator:
//-----------------------------------------------------------------------------

GTNODE(GT_REG_VAR    , "regVar"     ,0,GTK_LEAF)      // register variable
GTNODE(GT_CLS_VAR    , "clsVar"     ,0,GTK_LEAF)      // static data member

GTNODE(GT_IND        , "indir"      ,0,GTK_UNOP)      // indirection

/*****************************************************************************/
#undef  GTNODE
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\host.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/

#if     HOST_x86

#define BreakIfDbgStmt() __try { __asm {int 3} } __except(EXCEPTION_EXECUTE_HANDLER) {}

#define BreakIfDebuggerPresent() do { BreakIfDbgStmt() } while(0)

#else

// While debugging in an Debugger, the "int 3" will cause the program to break
// Outside, the exception handler will just filter out the "int 3".

#define BreakIfDebuggerPresent() {}

#endif

/*****************************************************************************/

#ifndef NDEBUG

extern
const   char *      jitCurSource;

extern  "C"
void    __cdecl     assertAbort(const char *why,
                                const char *what,
                                const char *file, unsigned line);

#undef  assert
#undef  Assert
#undef  ASSert
#define assert(p)   do { if (!(p)) { BreakIfDbgStmt(); assertAbort(#p,           jitCurSource, __FILE__, __LINE__); } } while (0)
#define Assert(p,c) do { if (!(p)) { BreakIfDbgStmt(); assertAbort(#p,(c) ? (c)->jitCurSource \
                                                                          :    ::jitCurSource, __FILE__, __LINE__); } } while (0)
#define ASSert(p)   do { if (!(p)) { BreakIfDbgStmt(); assertAbort(#p,         ::jitCurSource, __FILE__, __LINE__); } } while (0)

#define UNIMPL(p)   do {             BreakIfDbgStmt(); assertAbort("NYI: " #p, ::jitCurSource, __FILE__, __LINE__);   } while (0)

#else

#undef  assert
#undef  Assert
#undef  ASSert
#define assert(p)		0
#define Assert(p,c) 	0
#define ASSert(p)		0
#define UNIMPL(p)

#endif

/*****************************************************************************/
#ifndef _HOST_H_
#define _HOST_H_
/*****************************************************************************/

#pragma warning(disable:4237)

/*****************************************************************************/

#if _MSC_VER < 1100

enum bool
{
    false = 0,
    true  = 1
};

#endif

/*****************************************************************************/

const   size_t       OS_page_size = (4*1024);

#if TGT_IA64
const   size_t      TGT_page_size  = 8192;
#else
const   size_t      TGT_page_size  = 4096;
#endif

/*****************************************************************************/

#ifdef  __ONE_BYTE_STRINGS__
#define _char_type  t_sgnInt08
#else
#define _char_type  t_sgnInt16
#endif

/*****************************************************************************/

#define size2mem(s,m)   (offsetof(s,m) + sizeof(((s *)0)->m))

/*****************************************************************************/

enum yesNo
{
    YN_ERR,
    YN_NO,
    YN_YES
};

/*****************************************************************************/
#endif
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\importer.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                           Importer                                        XX
XX                                                                           XX
XX   Imports the given method and converts it to semantic trees              XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

#include "malloc.h"     // for _alloca

/*****************************************************************************/

#if     TGT_IA64        // temp hack
bool                genFindFunctionBody(const char *name, NatUns *offsPtr);
#endif

/*****************************************************************************/

void                Compiler::impInit()
{
    impParamsUsed       = false;
    compFilterHandlerBB = NULL;
    impSpillLevel       = -1;
}

/*****************************************************************************
 *
 *  Pushes the given tree on the stack.
 */

inline
void                Compiler::impPushOnStack(GenTreePtr tree)
{
    /* Check for overflow. If inling, we may be using a bigger stack */
    assert( (impStkDepth < info.compMaxStack) ||
           ((impStkDepth < impStackSize) && (compCurBB && (compCurBB->bbFlags & BBF_IMPORTED))) ||
           info.compXcptnsCount); // @TODO. VC emits bad maxstack for try-catches

    assert(tree->gtType != TYP_STRUCT);     // should use the method below for structs
#ifdef DEBUG
    impStack[impStkDepth].structType = BAD_CLASS_HANDLE;
#endif
    impStack[impStkDepth++].val = tree;
}

inline
void                Compiler::impPushOnStack(GenTreePtr tree, CLASS_HANDLE structType)
{
    /* Check for overflow. If inling, we may be using a bigger stack */
    assert( (impStkDepth < info.compMaxStack) ||
           ((impStkDepth < impStackSize) && (compCurBB && (compCurBB->bbFlags & BBF_IMPORTED))) ||
           info.compXcptnsCount); // @TODO. VC emits bad maxstack for try-catches

    impStack[impStkDepth].structType = structType;
    impStack[impStkDepth++].val = tree;
}

/*****************************************************************************
 *
 *  Pop one tree from the stack.
 */

inline
GenTreePtr          Compiler::impPopStack()
{
#ifdef DEBUG
    if (! impStkDepth) {
        char buffer[200];
        sprintf(buffer, "Pop with empty stack at offset %4.4x in method %s.\n", impCurOpcOffs, info.compFullName);
        NO_WAY(buffer);
    }
#endif

    return impStack[--impStkDepth].val;
}

inline
GenTreePtr          Compiler::impPopStack(CLASS_HANDLE& structType)
{
    GenTreePtr ret = impPopStack();
    structType = impStack[impStkDepth].structType;
    return(ret);
}

/*****************************************************************************
 *
 *  Peep at n'th (0-based) tree on the top of the stack.
 */

inline
GenTreePtr          Compiler::impStackTop(unsigned n)
{
    assert(impStkDepth > n);

    return impStack[impStkDepth-n-1].val;
}

/*****************************************************************************
 *  Some of the trees are spilled specially. While unspilling them, or
 *  making a copy, these need to be handled specially. The function
 *  enumerates the operators possible after spilling.
 */

#ifdef DEBUG

static
bool                impValidSpilledStackEntry(GenTreePtr tree)
{
    if (tree->gtOper == GT_LCL_VAR)
        return true;

    if (tree->gtOper == GT_MKREFANY)
    {
        GenTreePtr var = tree->gtOp.gtOp1;

        if (var->gtOper == GT_LCL_VAR && var->gtType == TYP_BYREF)
            return true;
    }

    return false;
}

#endif // DEBUG

/*****************************************************************************
 *
 *  The following logic is used to save/restore stack contents.
 *  If 'copy' is true, then we make a copy of the trees on the stack. These
 *  have to all be cloneable/spilled values.
 */

void                Compiler::impSaveStackState(SavedStack *savePtr,
                                                bool        copy)
{
    savePtr->ssDepth = impStkDepth;

    if  (impStkDepth)
    {
        size_t  saveSize = impStkDepth*sizeof(*savePtr->ssTrees);

        savePtr->ssTrees = (StackEntry *) compGetMem(saveSize);

        if  (copy)
        {
            unsigned    count = impStkDepth;
            StackEntry *table = savePtr->ssTrees;

            /* Make a fresh copy of all the stack entries */

            for (unsigned level = 0; level < impStkDepth; level++, table++)
            {
                table->structType = impStack[level].structType;
                GenTreePtr  tree = impStack[level].val;

                assert(impValidSpilledStackEntry(tree));

                switch(tree->gtOper)
                {
                case GT_LCL_VAR:
                    table->val = gtNewLclvNode(tree->gtLclVar.gtLclNum, tree->gtType);
                    break;

                    // impSpillStackEntry() does not spill mkdrefany. It
                    // just spills the pointer. This needs to work in sync
                case GT_MKREFANY: {
                    GenTreePtr  var = tree->gtLdObj.gtOp1;
                    assert(var->gtOper == GT_LCL_VAR && var->gtType == TYP_BYREF);
                    table->val = gtNewOperNode(GT_MKREFANY, TYP_STRUCT,
                                     gtNewLclvNode(var->gtLclVar.gtLclNum, TYP_BYREF));
                    table->val->gtLdObj.gtClass = tree->gtLdObj.gtClass;
                    } break;

                default: assert(!"Bad oper - Not covered by impValidSpilledStackEntry()"); break;
                }
            }
        }
        else
        {
            memcpy(savePtr->ssTrees, impStack, saveSize);
        }
    }
}

void                Compiler::impRestoreStackState(SavedStack *savePtr)
{
    impStkDepth = savePtr->ssDepth;

    if (impStkDepth)
        memcpy(impStack, savePtr->ssTrees, impStkDepth*sizeof(*impStack));
}

/*****************************************************************************
 *
 *  Get the tree list started for a new basic block.
 */
inline
void       FASTCALL Compiler::impBeginTreeList()
{
    impTreeList =
    impTreeLast = gtNewOperNode(GT_BLOCK, TYP_VOID);
}


/*****************************************************************************
 *
 *  Store the given start and end stmt in the given basic block. This is
 *  mostly called by impEndTreeList(BasicBlock *block). It is called
 *  directly only for handling CEE_LEAVEs out of finally-protected try's.
 */

void            Compiler::impEndTreeList(BasicBlock *   block,
                                         GenTreePtr     stmt,
                                         GenTreePtr     lastStmt)
{
#ifdef DEBUG
    if  (verbose)
        gtDispTreeList(stmt);
#endif

    assert(stmt->gtOper == GT_STMT);

    /* Make the list circular, so that we can easily walk it backwards */

    stmt->gtPrev =  lastStmt;

    /* Store the tree list in the basic block */

    block->bbTreeList = stmt;

    block->bbFlags |= BBF_IMPORTED;
}

/*****************************************************************************
 *
 *  Store the current tree list in the given basic block.
 */

inline
void       FASTCALL Compiler::impEndTreeList(BasicBlock *block)
{
    assert(impTreeList->gtOper == GT_BLOCK);

    GenTreePtr      tree = impTreeList->gtNext;

    if  (!tree)
    {
        // Empty block. Just mark it as imported
        block->bbFlags |= BBF_IMPORTED;
    }
    else
    {
        // Remove the GT_BLOCK

        assert(tree->gtPrev == impTreeList);

        impEndTreeList(block, tree, impTreeLast);
    }

#ifdef DEBUG
    if (impLastILoffsStmt != NULL)
    {
        impLastILoffsStmt->gtStmt.gtStmtLastILoffs = impCurOpcOffs;
        impLastILoffsStmt = NULL;
    }
#endif
}

/*****************************************************************************
 *
 *  Append the given GT_STMT node to the current block's tree list.
 */

inline
void       FASTCALL Compiler::impAppendStmt(GenTreePtr stmt)
{
    assert(stmt->gtOper == GT_STMT);

    /* If the statement being appended has a call, we have to spill all
       GTF_GLOB_REFs on the stack as the call could modify them.  */

    if  (impSpillLevel != -1 && (impStkDepth > 0) &&
         (stmt->gtStmt.gtStmtExpr->gtFlags & GTF_CALL))
    {
        // This will not recurse because if (impSpillLevel != -1) means that
        // we are already in impSpillSideEffects and would have already
        // spilled any GTF_CALLs.

        impSpillGlobEffects();
    }

    /* Point 'prev' at the previous node, so that we can walk backwards */

    stmt->gtPrev = impTreeLast;

    /* Append the expression statement to the list */

    impTreeLast->gtNext = stmt;
    impTreeLast         = stmt;

#ifdef DEBUG
    if (impLastILoffsStmt == NULL)
    {
        impLastILoffsStmt = stmt;
    }
#endif
}

/*****************************************************************************
 *
 *  Insert the given GT_STMT node to the start of the current block's tree list.
 */

inline
void       FASTCALL Compiler::impInsertStmt(GenTreePtr stmt)
{
    assert(stmt->gtOper == GT_STMT);
    assert(impTreeList->gtOper == GT_BLOCK);

    /* Point 'prev' at the previous node, so that we can walk backwards */

    stmt->gtPrev = impTreeList;
    stmt->gtNext = impTreeList->gtNext;

    /* Insert the expression statement to the list (just behind GT_BLOCK) */

    impTreeList->gtNext  = stmt;
    stmt->gtNext->gtPrev = stmt;

    /* if the list was empty (i.e. just the GT_BLOCK) we have to advance treeLast */
    if (impTreeLast == impTreeList)
        impTreeLast = stmt;
}


/*****************************************************************************
 *
 *  Append the given expression tree to the current block's tree list.
 */

void       FASTCALL Compiler::impAppendTree(GenTreePtr tree, IL_OFFSET offset)
{
    assert(tree);

    /* Allocate an 'expression statement' node */

    GenTreePtr      expr = gtNewStmt(tree, offset);

    /* Append the statement to the current block's stmt list */

    impAppendStmt(expr);
}


/*****************************************************************************
 *
 *  Insert the given exression tree at the start of the current block's tree list.
 */

void       FASTCALL Compiler::impInsertTree(GenTreePtr tree, IL_OFFSET offset)
{
    GenTreePtr      expr;

    /* Allocate an 'expression statement' node */

    expr = gtNewStmt(tree, offset);

    /* Append the statement to the current block's stmt list */

    impInsertStmt(expr);
}

/*****************************************************************************
 *
 *  Append an assignment of the given value to a temp to the current tree list.
 */

inline
GenTreePtr          Compiler::impAssignTempGen(unsigned     tmp,
                                               GenTreePtr   val)
{
    GenTreePtr      asg = gtNewTempAssign(tmp, val);

    impAppendTree(asg, impCurStmtOffs);

    return  asg;
}

/*****************************************************************************
 * same as above, but handle the valueclass case too */

GenTreePtr          Compiler::impAssignTempGen(unsigned     tmpNum,
                                               GenTreePtr   val,
                                               CLASS_HANDLE structType)
{
    GenTreePtr asg;

    if (val->TypeGet() == TYP_STRUCT)
    {
#ifdef NOT_JITC
        assert(structType != BAD_CLASS_HANDLE);
#endif
        lvaAggrTableTempsSet(tmpNum, TYP_STRUCT, (SIZE_T) structType);
        asg = impAssignStruct(gtNewLclvNode(tmpNum, TYP_STRUCT), val, structType);
    }
    else
        asg = gtNewTempAssign(tmpNum, val);

    impAppendTree(asg, impCurStmtOffs);
    return  asg;
}

/*****************************************************************************
 *
 *  Insert an assignment of the given value to a temp to the start of the
 *  current tree list.
 */

inline
void                Compiler::impAssignTempGenTop(unsigned      tmp,
                                                  GenTreePtr    val)
{
    impInsertTree(gtNewTempAssign(tmp, val), impCurStmtOffs);
}

/*****************************************************************************
 *
 *  Pop the given number of values from the stack and return a list node with
 *  their values. The 'treeList' argument may optionally contain an argument
 *  list that is prepended to the list returned from this function.
 */

GenTreePtr          Compiler::impPopList(unsigned   count,
                                         unsigned * flagsPtr,
                                         GenTreePtr treeList)
{
    unsigned        flags = 0;

    CLASS_HANDLE structType;

    while(count--)
    {
        GenTreePtr      temp = impPopStack(structType);
            // Morph that aren't already LDOBJs or MKREFANY to be LDOBJs

        if (temp->TypeGet() == TYP_STRUCT)
            temp = impNormStructVal(temp, structType);

        /* NOTE: we defer bashing the type for I_IMPL to fgMorphArgs */

        flags |= temp->gtFlags;

        treeList = gtNewOperNode(GT_LIST, TYP_VOID, temp, treeList);
    }

    *flagsPtr = flags;

    return treeList;
}

/*****************************************************************************
   Assign (copy) the structure from 'src' to 'dest'.  The structure is a value
   class of type 'clsHnd'.  It returns the tree that should be appended to the
   statement list that represents the assignment

  @MIHAII: Here flags are not set properly - Need to mark the assignment with GTF_ASG
  @MIHAII: Need to mark local vars defines with GTF_VAR_DEF (see gtNewAssignNode)
 */

GenTreePtr Compiler::impAssignStruct(GenTreePtr dest, GenTreePtr src, CLASS_HANDLE clsHnd)
{
    assert(dest->TypeGet() == TYP_STRUCT);
    assert(dest->gtOper == GT_LCL_VAR || dest->gtOper == GT_RETURN ||
           dest->gtOper == GT_FIELD   || dest->gtOper == GT_IND    ||
           dest->gtOper == GT_LDOBJ);

    GenTreePtr destAddr;

    if (dest->gtOper == GT_IND || dest->gtOper == GT_LDOBJ)
        destAddr = dest->gtOp.gtOp1;
    else
    {
        destAddr = gtNewOperNode(GT_ADDR, TYP_BYREF, dest);
        if  (dest->gtOper == GT_LCL_VAR)
            lvaTable[dest->gtLclVar.gtLclNum].lvAddrTaken = true;    // IS THIS RIGHT????  [peteku]
    }

    return(impAssignStructPtr(destAddr, src, clsHnd));
}

GenTreePtr Compiler::impAssignStructPtr(GenTreePtr destAddr, GenTreePtr src, CLASS_HANDLE clsHnd)
{

    assert(src->TypeGet() == TYP_STRUCT);
    assert(src->gtOper == GT_LCL_VAR || src->gtOper == GT_FIELD || src->gtOper == GT_IND ||
           src->gtOper == GT_LDOBJ   || src->gtOper == GT_CALL  || src->gtOper == GT_MKREFANY ||
           src->gtOper == GT_COMMA );

    if (src->gtOper == GT_CALL)
    {
            // insert the return value buffer into the argument list as first byref parameter
        src->gtCall.gtCallArgs = gtNewOperNode(GT_LIST, TYP_VOID, destAddr, src->gtCall.gtCallArgs);
        src->gtType = TYP_VOID;               // now returns void not a struct
        src->gtFlags |= GTF_CALL_RETBUFFARG;  // remember that the first arg is return buffer

            // return the morphed call node
        return(src);
    }

    if (src->gtOper == GT_LDOBJ)
    {
#ifdef NOT_JITC
        assert(src->gtLdObj.gtClass == clsHnd);
#endif
        src = src->gtOp.gtOp1;
    }
    else if (src->gtOper == GT_MKREFANY)
    {
        GenTreePtr destAddrClone = gtClone(destAddr, true);
        if (destAddrClone == 0)
        {
            unsigned tNum = lvaGrabTemp();
            impAssignTempGen(tNum, destAddr);
            var_types typ = destAddr->TypeGet();
            destAddr = gtNewLclvNode(tNum, typ);
            destAddrClone = gtNewLclvNode(tNum, typ);
        }
        assert(offsetof(JIT_RefAny, dataPtr) == 0);
        GenTreePtr ptrSlot  = gtNewOperNode(GT_IND, TYP_BYREF, destAddr);
        GenTreePtr typeSlot = gtNewOperNode(GT_IND, TYP_I_IMPL,
                                  gtNewOperNode(GT_ADD, TYP_I_IMPL, destAddrClone,
                                      gtNewIconNode(offsetof(JIT_RefAny, type))));

            // Assign the pointer value
        GenTreePtr asg = gtNewAssignNode(ptrSlot, src->gtLdObj.gtOp1);
        impAppendTree(asg, impCurStmtOffs);

            // Assign the type value
        asg = gtNewAssignNode(typeSlot, gtNewIconEmbClsHndNode(src->gtLdObj.gtClass));
        return(asg);
    }

    else if (src->gtOper == GT_COMMA)
    {
        assert(src->gtOp.gtOp2->gtType == TYP_STRUCT);  // Second thing is the struct
        impAppendTree(src->gtOp.gtOp1, impCurStmtOffs);  // do the side effect

            // assign the structure value to the destination.
        return(impAssignStructPtr(destAddr, src->gtOp.gtOp2, clsHnd));
    }
    else
    {
        if  (src->gtOper == GT_LCL_VAR)
            lvaTable[src->gtLclVar.gtLclNum].lvAddrTaken = true;    // IS THIS RIGHT????  [peteku]

        src = gtNewOperNode(GT_ADDR, TYP_BYREF, src);
    }

        // copy the src to the destination.
    GenTreePtr ret = gtNewCpblkNode(destAddr, src, impGetCpobjHandle(clsHnd));

        // return the GT_COPYBLK node, to be appended to the statement list
    return(ret);
}

/*****************************************************************************
/* Given TYP_STRUCT value, and the class handle for that structure, return
   the expression for the Address for that structure value */

GenTreePtr Compiler::impGetStructAddr(GenTreePtr structVal, CLASS_HANDLE clsHnd)
{
    assert(structVal->TypeGet() == TYP_STRUCT);
    assert(structVal->gtOper == GT_LCL_VAR || structVal->gtOper == GT_FIELD ||
           structVal->gtOper == GT_CALL || structVal->gtOper == GT_LDOBJ ||
           structVal->gtOper == GT_IND  || structVal->gtOper == GT_COMMA);

    if (structVal->gtOper == GT_CALL)
    {
        unsigned tNum = lvaGrabTemp();
        lvaAggrTableTempsSet(tNum, TYP_STRUCT, (SIZE_T) clsHnd);
        GenTreePtr temp = gtNewLclvNode(tNum, TYP_STRUCT);

            // insert the return value buffer into the argument list as first byref parameter
        temp = gtNewOperNode(GT_ADDR, TYP_I_IMPL, temp);
        temp->gtFlags |= GTF_ADDR_ONSTACK;
lvaTable[tNum].lvAddrTaken = true;    // IS THIS RIGHT????  [peteku]
        structVal->gtCall.gtCallArgs = gtNewOperNode(GT_LIST, TYP_VOID, temp, structVal->gtCall.gtCallArgs);
        structVal->gtType = TYP_VOID;                   // now returns void not a struct
        structVal->gtFlags |= GTF_CALL_RETBUFFARG;      // remember that the first arg is return buffer

            // do the call
        impAppendTree(structVal, impCurStmtOffs);

            // Now the 'return value' of the call expression is the temp itself
        structVal = gtNewLclvNode(tNum, TYP_STRUCT);
        temp = gtNewOperNode(GT_ADDR, TYP_BYREF, structVal);
        temp->gtFlags |= GTF_ADDR_ONSTACK;
        return(temp);
    }
    else if (structVal->gtOper == GT_LDOBJ)
    {
        assert(structVal->gtLdObj.gtClass == clsHnd);
        return(structVal->gtLdObj.gtOp1);
    }
    else if (structVal->gtOper == GT_COMMA)
    {
        assert(structVal->gtOp.gtOp2->gtType == TYP_STRUCT);            // Second thing is the struct
        structVal->gtOp.gtOp2 = impGetStructAddr(structVal->gtOp.gtOp2, clsHnd);
        return(structVal);
    }
    else if (structVal->gtOper == GT_LCL_VAR)
    {
        lvaTable[structVal->gtLclVar.gtLclNum].lvAddrTaken = true;    // IS THIS RIGHT????  [peteku]
    }

    return(gtNewOperNode(GT_ADDR, TYP_BYREF, structVal));
}

/*****************************************************************************
/* Given TYP_STRUCT value 'structVal', make certain it is 'canonical', that is
   it is either a LDOBJ or a MKREFANY node.  */

GenTreePtr Compiler::impNormStructVal(GenTreePtr structVal, CLASS_HANDLE structType)
{
    assert(structVal->TypeGet() == TYP_STRUCT);
#ifdef NOT_JITC
    assert(structType != BAD_CLASS_HANDLE);
#endif
        // is it already normalized
    if (structVal->gtOper == GT_MKREFANY || structVal->gtOper == GT_LDOBJ)
        return(structVal);

    // OK normalize it by wraping it in a LDOBJ
    structVal = impGetStructAddr(structVal, structType);            // get the address of the structure
    structVal = gtNewOperNode(GT_LDOBJ, TYP_STRUCT, structVal);
    structVal->gtOp.gtOp1->gtFlags |= GTF_NON_GC_ADDR | GTF_EXCEPT | GTF_GLOB_REF;
    structVal->gtLdObj.gtClass = structType;
    return(structVal);
}

/*****************************************************************************
 * When a CEE_LEAVE jumps out of catches, we have to automatically call
 * CPX_ENCATCH for each catch. If we are also, CEE_LEAVEing finally-protected
 * try's, we also need to call the finallys's. In the correct order.
 */

void            Compiler::impAddEndCatches (BasicBlock *   callBlock,
                                            GenTreePtr     endCatches)
{
    assert((callBlock->bbJumpKind & BBJ_CALL) ||
           (callBlock->bbJumpKind & BBJ_ALWAYS));

    if (callBlock == compCurBB)
    {
        /* This is the block we are currently importing. Just add the
           endCatches to it */

        if (endCatches)
            impAppendTree(endCatches, impCurStmtOffs);
    }
    else
    {
        /* This must be one of the blocks we added in fgFindBasicBlocks()
           for CEE_LEAVE. We need to handle the adding of the tree properly */

        assert(callBlock->bbFlags & BBF_INTERNAL);
        assert(callBlock->bbTreeList == NULL);

        if (endCatches)
        {
            endCatches = gtNewStmt(endCatches, impCurStmtOffs);
            impEndTreeList(callBlock, endCatches, endCatches);
        }

        callBlock->bbFlags |= BBF_IMPORTED;
    }
}

/*****************************************************************************
 *
 *  Pop the given number of values from the stack in reverse order (STDCALL)
 */

GenTreePtr          Compiler::impPopRevList(unsigned   count,
                                            unsigned * flagsPtr)
{
    unsigned        flags = 0;
    GenTreePtr      treeList;
    GenTreePtr      lastList;

    assert(count);

    GenTreePtr      temp   = impPopStack();

    flags |= temp->gtFlags;

    treeList = lastList = gtNewOperNode(GT_LIST, TYP_VOID, temp, 0);
    count--;

    while(count--)
    {
        temp   = impPopStack();
        flags |= temp->gtFlags;

        assert(lastList->gtOper == GT_LIST);
        assert(lastList->gtOp.gtOp2 == 0);

        lastList = lastList->gtOp.gtOp2 = gtNewOperNode(GT_LIST, TYP_VOID, temp, 0);
    }

    *flagsPtr = flags;

    return treeList;
}

/*****************************************************************************
 *
 *  We have a jump to 'block' with a non-empty stack, and the block expects
 *  its input to come in a different set of temps than we have it in at the
 *  end of the previous block. Therefore, we'll have to insert a new block
 *  along the jump edge to transfer the temps to the expected place.
 */

BasicBlock *        Compiler::impMoveTemps(BasicBlock *block, unsigned baseTmp)
{
    unsigned        destTmp = block->bbStkTemps;

    BasicBlock *    mvBlk;
    unsigned        tmpNo;

    assert(impStkDepth);
    assert(destTmp != NO_BASE_TMP);
    assert(destTmp != baseTmp);

#ifdef DEBUG
    if  (verbose) printf("Transfer %u temps from #%u to #%u\n", impStkDepth, baseTmp, destTmp);
#endif

    /* Create the basic block that will transfer the temps */

    mvBlk               = fgNewBasicBlock(BBJ_ALWAYS);
    mvBlk->bbStkDepth   = impStkDepth;
    mvBlk->bbJumpDest   = block;

    /* Create the transfer list of trees */

    impBeginTreeList();

    tmpNo = impStkDepth;
    do
    {
        /* One less temp to deal with */

        assert(tmpNo); tmpNo--;

        GenTreePtr  tree = impStack[tmpNo].val;
        assert(impValidSpilledStackEntry(tree));

        /* Get hold of the type we're transferring */

        var_types       lclTyp;

        switch(tree->gtOper)
        {
        case GT_LCL_VAR:    lclTyp = tree->TypeGet();             break;
        case GT_MKREFANY:   lclTyp = tree->gtOp.gtOp1->TypeGet(); break;
        default: assert(!"Bad oper - Not covered by impValidSpilledStackEntry()");
        }

        /* Create the target of the assignment and mark it */

        GenTreePtr  destLcl = gtNewLclvNode(destTmp + tmpNo, lclTyp);
        destLcl->gtFlags |= GTF_VAR_DEF;

        /* Create the assignment node */

        GenTreePtr  asg = gtNewOperNode(GT_ASG, lclTyp,
                                        destLcl,
                                        gtNewLclvNode(baseTmp + tmpNo, lclTyp));

#if 0
        printf("    Temp move node at %08X: %s temp #%u := #%u\n", asg,
                                                                   varTypeName(asg->gtType),
                                                                   destTmp + tmpNo,
                                                                   baseTmp + tmpNo);
#endif

        /* Mark the expression as containing an assignment */

        asg->gtFlags |= GTF_ASG;

        /* Append the expression statement to the list */

        impAppendTree(asg, impCurStmtOffs);
    }
    while (tmpNo);

    impEndTreeList(mvBlk);

    return mvBlk;
}

/*****************************************************************************
   Set an entry in lvaAggrTableTemp[]. The array is allocated as needed
   and may have to be grown
 */

void                Compiler::lvaAggrTableTempsSet(unsigned     lclNum,
                                                   var_types    type,
                                                   SIZE_T       val)
{
    assert(type == TYP_STRUCT || type == TYP_BLK);
    assert(lclNum+1 <= lvaCount);

    unsigned    temp = lclNum - info.compLocalsCount;

    if (temp+1 <= lvaAggrTableTempsCount)
    {
        /* The temp is being reused. Must be for the same type */
        assert(lvaAggrTableTemps[temp].lvaiBlkSize == val);
        return;
    }

    // Store the older table

    LclVarAggrInfo *    oldTable    = lvaAggrTableTemps;
    unsigned            oldCount    = lvaAggrTableTempsCount;
    assert(oldTable == NULL || oldCount > 0);

    // Allocate the table to fit this temps, and note the new size

    lvaAggrTableTempsCount = temp + 1;

    lvaAggrTableTemps = (LclVarAggrInfo *)
        compGetMem(lvaAggrTableTempsCount * sizeof(lvaAggrTableTemps[0]));

    if  (type == TYP_STRUCT)
        lvaAggrTableTemps[temp].lvaiClassHandle = (CLASS_HANDLE)val;
    else
        lvaAggrTableTemps[temp].lvaiBlkSize     = val;

    /* If we had an older table, copy it over */

    if  (oldTable)
        memcpy(lvaAggrTableTemps, oldTable, sizeof(oldTable[0])*oldCount);
}


/******************************************************************************
 *  Spills the stack at impStack[level] and replaces it with a temp.
 *  If tnum!=BAD_VAR_NUM, the temp var used to replace the tree is tnum,
 *     else, grab a new temp.
 *  For structs (which can be pushed on the stack using ldobj, etc),
 *      special handling is needed
 */

void                Compiler::impSpillStackEntry(unsigned   level,
                                                 unsigned   tnum)
{
    GenTreePtr      tree = impStack[level].val;

    /* Allocate a temp if we havent been asked to use a particular one */

    assert(tnum == BAD_VAR_NUM || tnum < lvaCount);

    if (tnum == BAD_VAR_NUM)
        tnum = lvaGrabTemp();

        // Optimization.  For MKREFANY, we only need to spill the pointer (the type we know)
        // CONSIDER: is this optimization worth it?
    if (tree->gtOper == GT_MKREFANY)
    {
        /* We only need to spill the "defining" object pointer. */
        GenTreePtr      objPtr = tree->gtLdObj.gtOp1;
        assert(objPtr->TypeGet() == TYP_BYREF);

        /* Assign the spilled objPtr to the temp */
        impAssignTempGen(tnum, objPtr);

        // Replace the original object pointer with the temp
        tree->gtLdObj.gtOp1 = gtNewLclvNode(tnum, TYP_BYREF, impCurStmtOffs);
        return;
    }

    /* get the original type of the tree (it may be wacked by impAssignTempGen) */
    var_types type = genActualType(tree->gtType);

    /* Assign the spilled entry to the temp */
    impAssignTempGen(tnum, tree, impStack[level].structType);

    /* Replace the stack entry with the temp */
    impStack[level].val = gtNewLclvNode(tnum, type);
}

/*****************************************************************************
 *
 *  If the stack contains any trees with side effects in them, assign those
 *  trees to temps and append the assignments to the statement list.
 *  On return the stack is guaranteed to be empty.
 */

inline
void                Compiler::impEvalSideEffects()
{
    impSpillSideEffects();
    impStkDepth = 0;
}

/*****************************************************************************
 *
 *  If the stack contains any trees with references to global data in them,
 *  assign those trees to temps and replace them on the stack with refs to
 *  their temps.
 *  All GTF_SIDE_EFFECTs upto impSpillLevel should have already been spilled.
 */

inline
void                Compiler::impSpillGlobEffects()
{
    // We must be in the middle of impSpillSideEffects()
    assert(impSpillLevel != -1 && impSpillLevel <= impStkDepth);

    for (unsigned level = 0; level < impSpillLevel; level++)
    {
        // impSpillGlobEffects() is called from impAppendStmt() and expects
        // all GTF_SIDE_EFFECT to have been spilled upto impSpillLevel.
        assert((impStack[level].val->gtFlags & GTF_SIDE_EFFECT) == 0);

        if  (impStack[level].val->gtFlags & GTF_GLOB_EFFECT)
            impSpillStackEntry(level);
    }
}

/*****************************************************************************
 *
 *  If the stack contains any trees with side effects in them, assign those
 *  trees to temps and replace them on the stack with refs to their temps.
 */

inline
void                Compiler::impSpillSideEffects(bool spillGlobEffects)
{
    /* Before we make any appends to the tree list we must spill
     * the "special" side effects (GTF_OTHER_SIDEEFF) - GT_QMARK, GT_CATCH_ARG */

    impSpillSpecialSideEff();

    unsigned spillFlags = spillGlobEffects ? GTF_GLOB_EFFECT : GTF_SIDE_EFFECT;

    assert(impSpillLevel == -1);

    for (impSpillLevel = 0; impSpillLevel < impStkDepth; impSpillLevel++)
    {
        if  (impStack[impSpillLevel].val->gtFlags & spillFlags)
            impSpillStackEntry(impSpillLevel);
    }

    impSpillLevel = -1;
}

/*****************************************************************************
 *
 *  If the stack contains any trees with special side effects in them, assign those
 *  trees to temps and replace them on the stack with refs to their temps.
 */

inline
void                Compiler::impSpillSpecialSideEff()
{
    // Only exception objects and _?: need to be carefully handled

    if  (!compCurBB->bbCatchTyp &&
         !(isBBF_BB_QMARK(compCurBB->bbFlags) && compCurBB->bbStkDepth == 1))
         return;

    for (unsigned level = 0; level < impStkDepth; level++)
    {
        if  (impStack[level].val->gtFlags & GTF_OTHER_SIDEEFF)
            impSpillStackEntry(level);
    }
}

/*****************************************************************************
 *
 *  If the stack contains any trees with references to local #lclNum, assign
 *  those trees to temps and replace their place on the stack with refs to
 *  their temps.
 */

void                Compiler::impSpillLclRefs(int lclNum)
{
    /* Before we make any appends to the tree list we must spill
     * the "special" side effects (GTF_OTHER_SIDEEFF) - GT_QMARK, GT_CATCH_ARG */

    impSpillSpecialSideEff();

    for (unsigned level = 0; level < impStkDepth; level++)
    {
        GenTreePtr      tree = impStack[level].val;

        /* If the tree may throw an exception, and the block has a handler,
           then we need to spill assignments to the local if the local is
           live on entry to the handler.
           Just spill 'em all without considering the liveness */

        bool xcptnCaught = (compCurBB->bbFlags & BBF_HAS_HANDLER) &&
                           (tree->gtFlags & (GTF_CALL|GTF_EXCEPT));

        /* Skip the tree if it doesn't have an affected reference,
           unless xcptnCaught */

        if  (xcptnCaught || gtHasRef(tree, lclNum, false))
        {
            impSpillStackEntry(level);
        }
    }
}

/*****************************************************************************
 *
 * We need to provide accurate IP-mapping at this point.
 * So spill anything on the stack so that it will form gtStmts
 * with the correct stmt offset noted.
 */

#ifdef DEBUGGING_SUPPORT

void                Compiler::impSpillStmtBoundary()
{
    unsigned        level;

    assert(opts.compDbgCode);

    for (level = 0; level < impStkDepth; level++)
    {
        GenTreePtr      tree = impStack[level].val;

        /* Temps introduced by the importer itself dont need to be spilled
           as they are not visible to the debugger anyway
         */

        bool isTempLcl = (tree->OperGet() == GT_LCL_VAR) &&
                         (tree->gtLclVar.gtLclNum >= info.compLocalsCount);

        // @TODO : Do we really need to spill locals. Maybe only if addrTaken ?

        if  (!isTempLcl)
            impSpillStackEntry(level);
    }
}

#endif

/*****************************************************************************/
#if OPTIMIZE_QMARK
/*****************************************************************************
 *
 *  If the given block pushes a value on the stack and doesn't contain any
 *  assignments that would interfere with the current stack contents, return
 *  the type of the pushed value; otherwise, return 'TYP_UNDEF'.
 *  If the block pushes a floating type on the stack, *pHasFloat is set to true
 *    @TODO: Remove pHasFloat after ?: works with floating point values.
 *    Currently, raEnregisterFPvar() doesnt correctly handle the flow of control
 *    implicit in a ?:
 */

var_types           Compiler::impBBisPush(BasicBlock *  block,
                                          int        *  boolVal,
                                          bool       *  pHasFloat)
{
    const   BYTE *  codeAddr;
    const   BYTE *  codeEndp;

    unsigned char   stackCont[64];      // arbitrary stack depth restriction

    unsigned char * stackNext = stackCont;
    unsigned char * stackBeg  = stackCont;
    unsigned char * stackEnd  = stackCont + sizeof(stackCont);

    /* Walk the opcodes that comprise the basic block */

    codeAddr = info.compCode + block->bbCodeOffs;
    codeEndp =      codeAddr + block->bbCodeSize;
    unsigned        numArgs = info.compArgsCount;

    *boolVal = 0;

    while (codeAddr < codeEndp)
    {
        signed  int     sz;
        OPCODE          opcode;
        CLASS_HANDLE    clsHnd;
        /* Get the next opcode and the size of its parameters */

        opcode = OPCODE(getU1LittleEndian(codeAddr));
        codeAddr += sizeof(__int8);

    DECODE_OPCODE:

        /* Get the size of additional parameters */

        sz = opcodeSizes[opcode];

        /* See what kind of an opcode we have, then */

        switch (opcode)
        {
            var_types       lclTyp;
            unsigned        lclNum;
            int             memberRef, descr;
            JIT_SIG_INFO    sig;
            METHOD_HANDLE   methHnd;

        case CEE_PREFIX1:
            opcode = OPCODE(getU1LittleEndian(codeAddr) + 256);
            codeAddr += sizeof(__int8);
            goto DECODE_OPCODE;
        case CEE_LDARG_0:
        case CEE_LDARG_1:
        case CEE_LDARG_2:
        case CEE_LDARG_3:
            lclNum = (opcode - CEE_LDARG_0);
            assert(lclNum >= 0 && lclNum < 4);
            goto LDARG;

        case CEE_LDARG_S:
            lclNum = getU1LittleEndian(codeAddr);
            goto LDARG;

        case CEE_LDARG:
            lclNum = getU2LittleEndian(codeAddr);
                LDARG:
            lclNum = impArgNum(lclNum);     // account for possible hidden param
            goto LDLOC;

        case CEE_LDLOC_0:
        case CEE_LDLOC_1:
        case CEE_LDLOC_2:
        case CEE_LDLOC_3:
            lclNum = (opcode - CEE_LDLOC_0);
            assert(lclNum >= 0 && lclNum < 4);
            lclNum += numArgs;
            goto LDLOC;

        case CEE_LDLOC_S:
            lclNum = getU1LittleEndian(codeAddr) + numArgs;
            goto LDLOC;

        case CEE_LDLOC:
            lclNum = getU2LittleEndian(codeAddr) + numArgs;
                LDLOC:
            lclTyp = lvaGetType(lclNum);
            goto PUSH;

        case CEE_LDC_I4_M1 :
        case CEE_LDC_I4_0 :
        case CEE_LDC_I4_1 :
        case CEE_LDC_I4_2 :
        case CEE_LDC_I4_3 :
        case CEE_LDC_I4_4 :
        case CEE_LDC_I4_5 :
        case CEE_LDC_I4_6 :
        case CEE_LDC_I4_7 :
        case CEE_LDC_I4_8 :     lclTyp = TYP_I_IMPL;    goto PUSH;

        case CEE_LDC_I4_S :
        case CEE_LDC_I4 :       lclTyp = TYP_INT;       goto PUSH;

        case CEE_LDFTN :
        case CEE_LDVIRTFTN:

        case CEE_LDSTR :        lclTyp = TYP_REF;       goto PUSH;
        case CEE_LDNULL :       lclTyp = TYP_REF;       goto PUSH;
        case CEE_LDC_I8 :       lclTyp = TYP_LONG;      goto PUSH;
        case CEE_LDC_R4 :       lclTyp = TYP_FLOAT;     goto PUSH;
        case CEE_LDC_R8 :       lclTyp = TYP_DOUBLE;    goto PUSH;

    PUSH:
            /* Make sure there is room on our little stack */

            if  (stackNext == stackEnd)
                return  TYP_UNDEF;

            *stackNext++ = lclTyp;
            break;


        case CEE_LDIND_I1 :
        case CEE_LDIND_I2 :
        case CEE_LDIND_I4 :
        case CEE_LDIND_U1 :
        case CEE_LDIND_U2 :
        case CEE_LDIND_U4 :     lclTyp = TYP_INT;   goto LD_IND;

        case CEE_LDIND_I8 :     lclTyp = TYP_LONG;  goto LD_IND;
        case CEE_LDIND_R4 :     lclTyp = TYP_FLOAT; goto LD_IND;
        case CEE_LDIND_R8 :     lclTyp = TYP_DOUBLE;goto LD_IND;
        case CEE_LDIND_REF :    lclTyp = TYP_REF;   goto LD_IND;
        case CEE_LDIND_I :      lclTyp = TYP_I_IMPL;goto LD_IND;

    LD_IND:

            assert((TYP_I_IMPL == (var_types)stackNext[-1]) ||
                   (TYP_BYREF  == (var_types)stackNext[-1]));

            stackNext--;        // Pop the pointer

            if  (stackNext < stackBeg)
                return  TYP_UNDEF;

            goto PUSH;


        case CEE_UNALIGNED:
            break;

        case CEE_VOLATILE:
            break;

        case CEE_LDELEM_I1 :
        case CEE_LDELEM_I2 :
        case CEE_LDELEM_U1 :
        case CEE_LDELEM_U2 :
        case CEE_LDELEM_I  :
        case CEE_LDELEM_U4 :
        case CEE_LDELEM_I4 :    lclTyp = TYP_INT   ; goto ARR_LD;

        case CEE_LDELEM_I8 :    lclTyp = TYP_LONG  ; goto ARR_LD;
        case CEE_LDELEM_R4 :    lclTyp = TYP_FLOAT ; goto ARR_LD;
        case CEE_LDELEM_R8 :    lclTyp = TYP_DOUBLE; goto ARR_LD;
        case CEE_LDELEM_REF :   lclTyp = TYP_REF   ; goto ARR_LD;

        ARR_LD:

            /* Pop the index value and array address */

            assert(TYP_REF == (var_types)stackNext[-2]);    // Array object
            assert(TYP_INT == (var_types)stackNext[-1]);    // Index

            stackNext -= 2;

            if  (stackNext < stackBeg)
                return  TYP_UNDEF;

            /* Push the result of the indexing load */

            goto PUSH;

        case CEE_LDLEN :

            /* Pop the array object from the stack */

            assert(TYP_REF == (var_types)stackNext[-1]);    // Array object

            stackNext--;

            if  (stackNext < stackBeg)
                return  TYP_UNDEF;

            lclTyp = TYP_INT;
            goto PUSH;

        case CEE_LDFLD :

            /* Pop the address from the stack */

            assert(varTypeIsGC((var_types)stackNext[-1]));    // Array object
            stackNext--;

            if  (stackNext < stackBeg)
                return  TYP_UNDEF;

            // FALL Through

        case CEE_LDSFLD :

            memberRef = getU4LittleEndian(codeAddr);
            lclTyp = genActualType(eeGetFieldType(eeFindField(memberRef, info.compScopeHnd, 0), &clsHnd));
            goto PUSH;


        case CEE_STLOC_0:
        case CEE_STLOC_1:
        case CEE_STLOC_2:
        case CEE_STLOC_3:
        case CEE_STLOC_S:
        case CEE_STLOC:

        case CEE_STARG_S:
        case CEE_STARG:

            /* For now, don't bother with assignmnents */

            return  TYP_UNDEF;

        case CEE_LDELEMA :
        case CEE_LDLOCA :
        case CEE_LDLOCA_S :
        case CEE_LDARGA :
        case CEE_LDARGA_S :     lclTyp = TYP_BYREF;   goto PUSH;

        case CEE_ARGLIST :      lclTyp = TYP_I_IMPL;  goto PUSH;

        case CEE_ADD :
        case CEE_DIV :
        case CEE_DIV_UN :

        case CEE_REM :
        case CEE_REM_UN :

        case CEE_MUL :
        case CEE_SUB :
        case CEE_AND :

        case CEE_OR :

        case CEE_XOR :

            /* Make sure we're not reaching below our stack start */

            if  (stackNext <= stackBeg + 1)
                return  TYP_UNDEF;

            if  (stackNext[-1] != stackNext[-2])
                return TYP_UNDEF;

            /* Pop 2 operands, push one result -> pop one stack slot */

            stackNext--;
            break;


        case CEE_CEQ :
        case CEE_CGT :
        case CEE_CGT_UN :
        case CEE_CLT :
        case CEE_CLT_UN :

            /* Make sure we're not reaching below our stack start */

            if  (stackNext < stackBeg + 2)
                return  TYP_UNDEF;

            /* Pop one value off the stack, change the other one to TYP_INT */

            if  (stackNext[-1] != stackNext[-2])
                return TYP_UNDEF;

            stackNext--;
            stackNext[-1] = TYP_INT;
            break;

        case CEE_SHL :
        case CEE_SHR :
        case CEE_SHR_UN :

            /* Make sure we're not reaching below our stack start */

            if  (stackNext < stackBeg + 2)
                return  TYP_UNDEF;

            // Pop off the shiftAmount
            assert(TYP_INT == (var_types)stackNext[-1]);

            stackNext--;
            break;

        case CEE_NEG :

        case CEE_NOT :

        case CEE_CASTCLASS :
        case CEE_ISINST :

            /* Merely make sure the stack is non-empty */

            if  (stackNext == stackBeg)
                return  TYP_UNDEF;

            break;

        case CEE_CONV_I1 :
        case CEE_CONV_I2 :
        case CEE_CONV_I4 :
        case CEE_CONV_U1 :
        case CEE_CONV_U2 :
        case CEE_CONV_U4 :
        case CEE_CONV_OVF_I :
                case CEE_CONV_OVF_I_UN:
        case CEE_CONV_OVF_I1 :
        case CEE_CONV_OVF_I1_UN :
        case CEE_CONV_OVF_U1 :
        case CEE_CONV_OVF_U1_UN :
        case CEE_CONV_OVF_I2 :
        case CEE_CONV_OVF_I2_UN :
        case CEE_CONV_OVF_U2 :
        case CEE_CONV_OVF_U2_UN :
        case CEE_CONV_OVF_I4 :
        case CEE_CONV_OVF_I4_UN :
        case CEE_CONV_OVF_U :
                case CEE_CONV_OVF_U_UN:
        case CEE_CONV_OVF_U4 :
        case CEE_CONV_OVF_U4_UN :    lclTyp = TYP_INT;     goto CONV;
        case CEE_CONV_OVF_I8 :
                case CEE_CONV_OVF_I8_UN:
        case CEE_CONV_OVF_U8 :
                case CEE_CONV_OVF_U8_UN:
        case CEE_CONV_U8 :
        case CEE_CONV_I8 :        lclTyp = TYP_LONG;    goto CONV;

        case CEE_CONV_R4 :        lclTyp = TYP_FLOAT;   goto CONV;

        case CEE_CONV_R_UN :
        case CEE_CONV_R8 :        lclTyp = TYP_DOUBLE;  goto CONV;

    CONV:
            /* Make sure the stack is non-empty and bash the top type */

            if  (stackNext == stackBeg)
                return  TYP_UNDEF;

            stackNext[-1] = lclTyp;
            break;

        case CEE_POP :

            stackNext--;

            if (stackNext < stackBeg)
                return TYP_UNDEF;

            break;

        case CEE_DUP :

            /* Make sure the stack is non-empty */

            if  (stackNext == stackBeg)
                return  TYP_UNDEF;

            /* Repush what's at the top */

            lclTyp = (var_types)stackNext[-1];
            goto PUSH;

         case CEE_NEWARR :

            /* Make sure the stack is non-empty */

            if  (stackNext == stackBeg)
                return  TYP_UNDEF;

            // Replace the numElems with the array object

            assert(TYP_INT == (var_types)stackNext[-1]);

            stackNext[-1] = TYP_REF;
            break;

        case CEE_CALLI :
            descr  = getU4LittleEndian(codeAddr);
            eeGetSig(descr, info.compScopeHnd, &sig);
            goto CALL;

        case CEE_NEWOBJ :
        case CEE_CALL :
        case CEE_CALLVIRT :
            memberRef  = getU4LittleEndian(codeAddr);
            methHnd = eeFindMethod(memberRef, info.compScopeHnd, 0);
            eeGetMethodSig(methHnd, &sig);
            if  ((sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_VARARG)
            {
                /* Get the total number of arguments for this call site */
                unsigned    numArgsDef = sig.numArgs;
                eeGetCallSiteSig(memberRef, info.compScopeHnd, &sig);
                assert(numArgsDef <= sig.numArgs);
            }

#ifdef NOT_JITC
            if (!(eeGetMethodAttribs(methHnd) & FLG_STATIC) && opcode != CEE_NEWOBJ)
                sig.numArgs++;
#else
            if ((sig.callConv & JIT_CALLCONV_HASTHIS) && opcode != CEE_NEWOBJ)
                sig.numArgs++;
#endif

        CALL:

            /* Pop the arguments and make sure we pushed them */

            stackNext -= sig.numArgs;
            if  (stackNext < stackBeg)
                return  TYP_UNDEF;

            /* Push the result of the call if non-void */

            lclTyp = JITtype2varType(sig.retType);
            if  (lclTyp != TYP_VOID)
                goto PUSH;

            break;

        case CEE_BR :
        case CEE_BR_S :
        case CEE_LEAVE :
        case CEE_LEAVE_S :
            assert(codeAddr + sz == codeEndp);
            break;

        case CEE_ANN_DATA :
            assert(sz == 4);
            sz += getU4LittleEndian(codeAddr);
            break;

        case CEE_ANN_PHI :
            codeAddr += getU1LittleEndian(codeAddr) * 2 + 1;
            break;

        case CEE_ANN_DEF :
        case CEE_ANN_REF :
        case CEE_ANN_REF_S :
        case CEE_ANN_CALL :
        case CEE_ANN_HOISTED :
        case CEE_ANN_HOISTED_CALL :
        case CEE_ANN_LIVE :
        case CEE_ANN_DEAD :
        case CEE_ANN_LAB :
        case CEE_ANN_CATCH :
        case CEE_NOP :
            break;

#ifdef DEBUG
        case CEE_LDFLDA :
        case CEE_LDSFLDA :

        case CEE_MACRO_END :
        case CEE_CPBLK :
        case CEE_INITBLK :
        case CEE_LOCALLOC :
        case CEE_SWITCH :
        case CEE_STELEM_I1 :
        case CEE_STELEM_I2 :
        case CEE_STELEM_I4 :
        case CEE_STELEM_I :
        case CEE_STELEM_I8 :
        case CEE_STELEM_REF :
        case CEE_STELEM_R4 :
        case CEE_STELEM_R8 :
        case CEE_THROW :
        case CEE_RETHROW :
        case CEE_INITOBJ :
        case CEE_LDOBJ :
        case CEE_CPOBJ :
        case CEE_STOBJ :

        case CEE_BEQ:
        case CEE_BEQ_S:
        case CEE_BGE:
        case CEE_BGE_S:
        case CEE_BGE_UN:
        case CEE_BGE_UN_S:
        case CEE_BGT:
        case CEE_BGT_S:
        case CEE_BGT_UN:
        case CEE_BGT_UN_S:
        case CEE_BLE:
        case CEE_BLE_S:
        case CEE_BLE_UN:
        case CEE_BLE_UN_S:
        case CEE_BLT:
        case CEE_BLT_S:
        case CEE_BLT_UN:
        case CEE_BLT_UN_S:
        case CEE_BNE_UN:
        case CEE_BNE_UN_S:



        case CEE_BRFALSE_S :
        case CEE_BRTRUE_S :
        case CEE_BRFALSE :
        case CEE_BRTRUE :

        case CEE_BREAK :

        case CEE_RET :

        case CEE_STFLD :
        case CEE_STSFLD :

        case CEE_STIND_I1 :
        case CEE_STIND_I2 :
        case CEE_STIND_I4 :
        case CEE_STIND_I8 :
        case CEE_STIND_I :
        case CEE_STIND_REF :
        case CEE_STIND_R4 :
        case CEE_STIND_R8 :
        case CEE_SIZEOF:
        case CEE_UNBOX:
        case CEE_CKFINITE:
        case CEE_ENDFILTER:
        case CEE_LDTOKEN:
        case CEE_ENDFINALLY:
        case CEE_MKREFANY:


        //CONSIDER: these should be handled like regular arithmetic operations

        case CEE_SUB_OVF:
        case CEE_SUB_OVF_UN:
        case CEE_ADD_OVF:
        case CEE_ADD_OVF_UN:
        case CEE_MUL_OVF:
        case CEE_MUL_OVF_UN:
            return TYP_UNDEF;
#endif
        default :
            assert(!"Invalid opcode in impBBisPush()");
            return TYP_UNDEF;
        }

        codeAddr += sz;

        // Have we pushed a floating point value on the stack.
        // ?: doesnt work with floating points.

        if (stackNext > stackBeg && varTypeIsFloating((var_types)stackNext[-1]))
            *pHasFloat = true;
    }

    /* Did we end up with precisely one item on the stack? */

    if  (stackNext == stackCont+1)
        return  (var_types)stackCont[0];

    return  TYP_UNDEF;
}

/*****************************************************************************
 *
 *  If the given block (which is known to end with a conditional jump) forms
 *  a ?: expression, return the true/false/result blocks and the type of the
 *  result.
 */

bool                Compiler::impCheckForQmarkColon(BasicBlock *  block,
                                                     BasicBlock * * trueBlkPtr,
                                                     BasicBlock * *falseBlkPtr,
                                                     BasicBlock * * rsltBlkPtr,
                                                     var_types    * rsltTypPtr,
                                                     int          * isLogical,
                                                     bool         * pHasFloat)
{
    BasicBlock *     trueBlk;
    int              trueVal;
    BasicBlock *    falseBlk;
    int             falseVal;
    BasicBlock *     rsltBlk;
    var_types        rsltType;

    /*
        We'll look for the following flow-graph pattern:

            ---------------------
                   #refs   [jump]
            ---------------------
            block         -> falseBlk
            trueBlk   2   -> rsltBlk
            falseBlk  2
            rsltBlk   3
            ---------------------

        If both 'trueBlk' and 'falseBlk' push a value
        of the same type on the stack and don't contain
        any harmful side effects, we'll avoid spilling
        the entire stack.
     */

     trueBlk = block->bbNext;
    falseBlk = block->bbJumpDest;

    if  (trueBlk ->bbNext     != falseBlk)
        return  false;
    if  (trueBlk ->bbJumpKind != BBJ_ALWAYS)
        return  false;
    if  (falseBlk->bbJumpKind != BBJ_NONE)
        return  false;

    rsltBlk  = falseBlk->bbNext;
    if  ( trueBlk->bbJumpDest  != rsltBlk)
        return  false;

    if  ( trueBlk  ->bbRefs    != 2)
        return  false;
    if  (falseBlk ->bbRefs     != 2)
        return  false;
    if  ( rsltBlk->bbRefs      != 3)
        return  false;

    /* Too late if any of the blocks have been processed already */

    if  ( trueBlk->bbFlags & BBF_IMPORTED) return false;
    if  (falseBlk->bbFlags & BBF_IMPORTED) return false;
    if  ( rsltBlk->bbFlags & BBF_IMPORTED) return false;

    /* Now see if both trueBlk and falseBlk push a value */

    *pHasFloat = false;
    rsltType = impBBisPush(trueBlk, &trueVal, pHasFloat);
    if  (rsltType == TYP_UNDEF)
        return  false;
    if  (rsltType != impBBisPush(falseBlk, &falseVal, pHasFloat))
        return  false;
    /* CONSIDER: we might want to make ?: optimization work for structs */
    if (rsltType == TYP_STRUCT)
        return false;

    /* This is indeed a "?:" expression */

    * trueBlkPtr =  trueBlk;
    *falseBlkPtr = falseBlk;
    * rsltBlkPtr =  rsltBlk;
    * rsltTypPtr =  rsltType;

    /* Check for the special case of a logical value */

    *isLogical  = 0;

    if  (trueVal && falseVal && trueVal != falseVal)
    {
#ifdef DEBUG
        printf("Found ?: expression with 'logical' value\n");
#endif

        *isLogical = trueVal;
    }

    return  true;
}


/*****************************************************************************
 *
 *  If the given block (which is known to end with a conditional jump) forms
 *  a ?: expression, mark it appropriately.
 *  Returns true if the successors of the block have been processed.
 */

bool                Compiler::impCheckForQmarkColon(BasicBlock *  block)
{
    assert((opts.compFlags & CLFLG_QMARK) && !(block->bbFlags & BBF_HAS_HANDLER));
    assert(block->bbJumpKind == BBJ_COND);

    if (opts.compMinOptim || opts.compDbgCode)
        return false;

    BasicBlock *     trueBlk;
    BasicBlock *    falseBlk;
    BasicBlock *     rsltBlk;
    var_types        rsltType;
    int             logical;
    bool            hasFloat;

    if  (!impCheckForQmarkColon(block, & trueBlk,
                                       &falseBlk,
                                       & rsltBlk,
                                       & rsltType, &logical, &hasFloat))
        return false;

    if (hasFloat || rsltType == TYP_LONG)
    {
        // Currently FP enregistering doesn't know about GT_QMARK - GT_COLON
        if (impStkDepth)
            return false;

        // If impStkDepth is 0, we can use the simpler GT_BB_QMARK - GT_BB_COLON

    BB_QMARK_COLON:

         trueBlk->bbFlags |= BBF_BB_COLON;
        falseBlk->bbFlags |= BBF_BB_COLON;
        rsltBlk->bbFlags  |= BBF_BB_QMARK;

        return false;
    }

    /* We've detected a "?:" expression */

#ifdef DEBUG
    if (verbose&&0)
    {
        printf("Convert [type=%s] #%3u ? #%3u : #%3u -> #%3u:\n", varTypeName(rsltType),
                        block->bbNum, trueBlk->bbNum, falseBlk->bbNum, rsltBlk->bbNum);
        fgDispBasicBlocks();
        printf("\n");
    }
#endif

    /* Remember the conditional expression. This will be used as the
       condition of the GT_QMARK. */

    GenTreePtr condStmt = impTreeLast;
    GenTreePtr condExpr = condStmt->gtStmt.gtStmtExpr;
    assert(condExpr->gtOper == GT_JTRUE);

    if (block->bbCatchTyp && handlerGetsXcptnObj(block->bbCatchTyp))
    {
        // condStmt will be moved to rsltBlk as a child of the GT_QMARK.
        // This is a problem if it contains a reference to the GT_CATCH_ARG.
        // So use old style _?:

        if (condExpr->gtFlags & GTF_OTHER_SIDEEFF)
            goto BB_QMARK_COLON;

        /* Add a reference to the GT_CATCH_ARG so that our GC logic
           stays satisfied. */

        GenTreePtr xcptnObj = gtNewOperNode(GT_CATCH_ARG, TYP_REF);
        xcptnObj->gtFlags |= GTF_OTHER_SIDEEFF;
        impInsertTree(gtUnusedValNode(xcptnObj), impCurStmtOffs);
    }

    /* Finish the current BBJ_COND basic block */
    impEndTreeList(block);

    /* Remeber the stack state for the rsltBlk */

    SavedStack blockState;

    impSaveStackState(&blockState, false);

    //-------------------------------------------------------------------------
    //  Process the true and false blocks to get the expressions they evaluate
    //-------------------------------------------------------------------------

    /* Note that we dont need to make copies of the stack state as these
       blocks wont import the trees on the stack at all.
       To ensure that these blocks dont try to spill the current stack,
      overwrite it with non-spillable items */

    for (unsigned level = 0; level < impStkDepth; level++)
    {
        static GenTree nonSpill = { GT_CNS_INT, TYP_VOID };
        impStack[level].val = &nonSpill;
    }

    // Recursively import trueBlk and falseBlk. These are guaranteed not to
    // cause further recursion as they are both marked with BBF_COLON

     trueBlk->bbFlags |= BBF_COLON;
    impImportBlock(trueBlk);

    falseBlk->bbFlags |= BBF_COLON;
    impImportBlock(falseBlk);

    // Reset state for rsltBlk. Make sure that it didnt get recursively imported.
    assert((rsltBlk->bbFlags & BBF_IMPORTED) == 0);
    impRestoreStackState(&blockState);

    //-------------------------------------------------------------------------
    // Grab the expressions evaluated by the trueBlk and the falseBlk
    //-------------------------------------------------------------------------

    GenTreePtr  trueExpr = NULL;

    for (GenTreePtr trueStmt = trueBlk->bbTreeList; trueStmt; trueStmt = trueStmt->gtNext)
    {
        assert(trueStmt->gtOper == GT_STMT);
        GenTreePtr expr = trueStmt->gtStmt.gtStmtExpr;
        trueExpr = trueExpr ? gtNewOperNode(GT_COMMA, TYP_VOID, trueExpr, expr)
                            : expr;
    }

    if (trueExpr->gtOper == GT_COMMA)
        trueExpr->gtType = rsltType;

    // Now the falseBlk

    GenTreePtr  falseExpr = NULL;

    for (GenTreePtr falseStmt = falseBlk->bbTreeList; falseStmt; falseStmt = falseStmt->gtNext)
    {
        assert(falseStmt->gtOper == GT_STMT);
        GenTreePtr expr = falseStmt->gtStmt.gtStmtExpr;
        falseExpr = falseExpr ? gtNewOperNode(GT_COMMA, TYP_VOID, falseExpr, expr)
                              : expr;
    }

    if (falseExpr->gtOper == GT_COMMA)
        falseExpr->gtType = rsltType;

    //-------------------------------------------------------------------------
    // Make the GT_QMARK node for the rsltBlk
    //-------------------------------------------------------------------------

    // Create the GT_COLON

    GenTreePtr  colon       = gtNewOperNode(GT_COLON, rsltType, trueExpr, falseExpr);

    // Get the condition

    condExpr                = condExpr->gtOp.gtOp1;
    assert(GenTree::OperKind(condExpr->gtOper) & GTK_RELOP);
    condExpr->gtFlags      |= GTF_QMARK_COND;

    // Replace the condition in the original BBJ_COND block with a nop
    // and bash the block to unconditionally jump to rsltBlk.

    condStmt->gtStmt.gtStmtExpr = gtNewNothingNode();
    block->bbJumpKind           = BBJ_ALWAYS;
    block->bbJumpDest           = rsltBlk;

    // Discard the trueBlk and the falseBlk

     trueBlk->bbTreeList = NULL;
    falseBlk->bbTreeList = NULL;

    // Create the GT_QMARK, and push on the stack for rsltBlk

    GenTreePtr  qmark       = gtNewOperNode(GT_QMARK, rsltType, condExpr, colon);
    qmark->gtFlags         |= GTF_OTHER_SIDEEFF;

    impPushOnStack(qmark);

    impImportBlockPending(rsltBlk, false);

    /* We're done */

    return true;
}


/*****************************************************************************/
#endif // OPTIMIZE_QMARK
/*****************************************************************************
 *
 *  Given a stack value, return a local variable# that represents it. In other
 *  words, if the value is not a simple local variable value, assign it to a
 *  temp and return the temp's number.
 */

unsigned            Compiler::impCloneStackValue(GenTreePtr tree)
{
    unsigned        temp;

    /* Do we need to spill the value into a temp? */

    if  (tree->gtOper == GT_LCL_VAR)
        return  tree->gtLclVar.gtLclNum;

    /* Store the operand in a temp and return the temp# */

    temp = lvaGrabTemp(); impAssignTempGen(temp, tree);

    return  temp;
}

/*****************************************************************************
 *
 *  Remember the IL offset for the statements
 *
 *  When we do impAppendTree(tree), we cant set tree->gtStmtLastILoffs to
 *  impCurOpcOffs, if the append was done because of a partial stack spill,
 *  as some of the trees corresponding to code upto impCurOpcOffs might
 *  still be sitting on the stack.
 *  So we delay marking of gtStmtLastILoffs until impNoteLastILoffs().
 *  This should be called when an opcode expilicitly causes
 *  impAppendTree(tree) to be called (as opposed to being called becuase of
 *  a spill caused by the opcode)
 */

#ifdef DEBUG

void                Compiler::impNoteLastILoffs()
{
    if (impLastILoffsStmt == NULL)
    {
        // We should have added a statement for the current basic block
        // Is this assert correct ?

        assert(impTreeLast);
        assert(impTreeLast->gtOper == GT_STMT);

        impTreeLast->gtStmt.gtStmtLastILoffs = impCurOpcOffs;
    }
    else
    {
        impLastILoffsStmt->gtStmt.gtStmtLastILoffs = impCurOpcOffs;
        impLastILoffsStmt = NULL;
    }
}

#endif


/*****************************************************************************
 *
 *  Check for the special case where the object constant 0.
 *  As we cant even fold the tree (null+fldOffs), we are left with
 *  op1 and op2 both being a constant. This causes lots of problems.
 *  We simply grab a temp and assign 0 to it and use it in place of the NULL.
 */

inline
GenTreePtr          Compiler::impCheckForNullPointer(GenTreePtr obj)
{
    /* If it is not a GC type, we will be able to fold it.
       So dont need to do anything */

    if (!varTypeIsGC(obj->TypeGet()))
        return obj;

    if (obj->gtOper == GT_CNS_INT)
    {
        assert(obj->gtType == TYP_REF);
        assert (obj->gtIntCon.gtIconVal == 0);

        unsigned tmp = lvaGrabTemp();
        impAssignTempGen (tmp, obj);
        obj = gtNewLclvNode (tmp, obj->gtType);
    }

    return obj;
}

/*****************************************************************************/

static
bool        impOpcodeIsCall(OPCODE opcode)
{
    switch(opcode)
    {
        case CEE_CALLI:
        case CEE_CALLVIRT:
        case CEE_CALL:
        case CEE_JMP:
            return true;

        default:
            return false;
    }
}

/*****************************************************************************
/* return the tree that is needed to fetch a varargs argument 'lclNum' */

GenTreePtr      Compiler::impGetVarArgAddr(unsigned lclNum)
{
    assert(lclNum < info.compArgsCount);

    GenTreePtr  op1;
    unsigned    sigNum  = lclNum;
    int         argOffs = 0;

    if (!info.compIsStatic)
    {
#if USE_FASTCALL
        if (lclNum == 0)
        {
            // "this" is in ECX (the normal place)
            op1 = gtNewLclvNode(lclNum, lvaGetType(lclNum));
            op1 = gtNewOperNode(GT_ADDR, TYP_BYREF, // what about TYP_I_IMPL
                                op1);
            return op1;
        }
#else
        argOffs += sizeof(void*);
#endif
        sigNum--; // "this" is not present in sig
    }
        // return arg buff, is also not present in sig
    if (info.compRetBuffArg >= 0)
        sigNum--;

    // compute offset from the point arguments were pushed
    ARG_LIST_HANDLE     argLst      = info.compMethodInfo->args.args;
    unsigned            argSigLen   = info.compMethodInfo->args.numArgs;
    assert(sigNum < argSigLen);
    for(unsigned i = 0; i <= sigNum; i++)
    {
        argOffs -= eeGetArgSize(argLst, &info.compMethodInfo->args);
        assert(eeGetArgSize(argLst, &info.compMethodInfo->args));
        argLst = eeGetArgNext(argLst);
    }

    unsigned    argsStartVar = info.compLocalsCount; // This is always the first temp
    op1 = gtNewLclvNode(argsStartVar, TYP_I_IMPL);

    op1 = gtNewOperNode(GT_ADD, TYP_I_IMPL, op1, gtNewIconNode(argOffs));
    op1->gtFlags |= GTF_NON_GC_ADDR;

    return(op1);
}

GenTreePtr          Compiler::impGetVarArg(unsigned lclNum, CLASS_HANDLE clsHnd)
{
    assert(lclNum < info.compArgsCount);

    var_types type =lvaGetType(lclNum);

#if USE_FASTCALL
    if (!info.compIsStatic && lclNum == 0) // "this" is in ECX (the normal place)
        return(gtNewLclvNode(lclNum, type));
#endif

    GenTreePtr op1 = impGetVarArgAddr(lclNum);

    if (type == TYP_STRUCT)
    {
        op1 = gtNewOperNode(GT_LDOBJ, TYP_STRUCT, op1);
        op1->gtLdObj.gtClass = clsHnd;
    }
    else
    {
        op1 = gtNewOperNode(GT_IND, type, op1);
    }

    return op1;
}

/*****************************************************************************
 * CEE_CPOBJ can be treated either as a cpblk or a cpobj depending on
 * whether the ValueClass has any GC pointers. If there are no GC fields,
 * it will be treated like a CEE_CPBLK. If it does have GC fields,
 * we need to use a jit-helper fo the GC info.
 * Both cases are represented by GT_COPYBLK, and op2 stores
 * either the size (cpblk) or the class-handle (cpobj)
 */

GenTreePtr              Compiler::impGetCpobjHandle(CLASS_HANDLE clsHnd)
{
    unsigned    size = eeGetClassSize(clsHnd);

    /* Get the GC fields info */

    unsigned    slots   = roundUp(size, sizeof(void*)) / sizeof(void*);
    bool *      gcPtrs  = (bool*) _alloca(slots*sizeof(bool));

    eeGetClassGClayout(clsHnd, gcPtrs);

    bool        hasGCfield = false;

    for (unsigned i = 0; i < slots; i++)
    {
        if (gcPtrs[i])
        {
            hasGCfield = true;
            break;
        }
    }

    GenTreePtr handle;

    if (hasGCfield)
    {
        /* This will treated as a cpobj as we need to note GC info.
           Store the class handle and mark the node */

        handle = gtNewIconHandleNode((long)clsHnd, GTF_ICON_CLASS_HDL);
    }
    else
    {
        /* This class contains no GC pointers. Treat operation as a cpblk */

        handle = gtNewIconNode(size);
    }

    return handle;
}

/*****************************************************************************
 *  "&var" can be used either as TYP_BYREF or TYP_I_IMPL, but we
 *  set its type to TYP_BYREF when we create it. We know if it can be
 *  whacked to TYP_I_IMPL only at the point where we use it
 */

void        impBashVarAddrsToI(GenTreePtr  tree1,
                               GenTreePtr  tree2 = NULL)
{
    if (         tree1->IsVarAddr())
        tree1->gtType = TYP_I_IMPL;

    if (tree2 && tree2->IsVarAddr())
        tree2->gtType = TYP_I_IMPL;
}


/*****************************************************************************
 *
 *  Import the call instructions.
 *  For CEE_NEWOBJ, newobjThis should be the temp grabbed for
 */

var_types           Compiler::impImportCall (OPCODE         opcode,
                                             int            memberRef,
                                             GenTreePtr     newobjThis,
                                             bool           tailCall,
                                             unsigned     * pVcallTemp)
{
    assert(opcode == CEE_CALL   || opcode == CEE_CALLVIRT ||
           opcode == CEE_NEWOBJ || opcode == CEE_CALLI);
    assert((opcode != CEE_NEWOBJ) || varTypeIsGC(newobjThis->gtType));

    JIT_SIG_INFO    sig;
    var_types       callTyp = TYP_COUNT;
    METHOD_HANDLE   methHnd = NULL;
    CLASS_HANDLE    clsHnd  = NULL;
    unsigned        mflags  = 0, clsFlags = 0;
    GenTreePtr      call    = NULL, args = NULL;
    unsigned        argFlags= 0;

    // Synchronized methods need to call CPX_MON_EXIT at the end. We could
    // do that before tailcalls, but that is probably not the intended
    // semantic. So just disallow tailcalls from synchronized methods.
    // Also, popping arguments in a varargs function is more work and NYI
    bool            canTailCall = !(info.compFlags & FLG_SYNCH) &&
                                  !info.compIsVarArgs;

    /*-------------------------------------------------------------------------
     * First create the call node
     */

    if (opcode == CEE_CALLI)
    {
        /* Get the call sig */

        eeGetSig(memberRef, info.compScopeHnd, &sig);
        callTyp = JITtype2varType(sig.retType);

#if USE_FASTCALL
        /* The function pointer is on top of the stack - It may be a
         * complex expression. As it is evaluated after the args,
         * it may cause registered args to be spilled. Simply spill it.
         * CONSIDER : Lock the register args, and then generate code for
         * CONSIDER : the function pointer.
         */

        if  (impStackTop()->gtOper != GT_LCL_VAR) // ignore this trivial case. @TODO : lvAddrTaken
            impSpillStackEntry(impStkDepth - 1);
#endif
        /* Create the call node */

        call = gtNewCallNode(CT_INDIRECT, NULL, genActualType(callTyp),
                                                         GTF_CALL_USER, NULL);

        /* Get the function pointer */

        GenTreePtr fptr = impPopStack();
        assert(genActualType(fptr->gtType) == TYP_I_IMPL);

        fptr->gtFlags |= GTF_NON_GC_ADDR;

        call->gtCall.gtCallAddr = fptr;
        call->gtFlags |= GTF_EXCEPT | (fptr->gtFlags & GTF_GLOB_EFFECT);

        /*HACK: The EE wants us to believe that these are calls to "unmanaged"  */
        /*      functions. Right now we are calling just a managed stub         */

        /*@TODO/CONSIDER: Is it worthwhile to inline the PInvoke frame and call */
        /*                the unmanaged target directly?                        */
        if  ((sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_STDCALL ||
             (sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_C ||
             (sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_THISCALL ||
             (sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_FASTCALL)
        {
#ifdef NOT_JITC
            assert(eeGetPInvokeCookie(&sig) == (unsigned) info.compCompHnd->getVarArgsHandle(&sig));
#endif
            call->gtCall.gtCallCookie = eeGetPInvokeCookie(&sig);

            // @TODO: We go through the PInvoke stub. Can it work with CPX_TAILCALL?
            canTailCall = false;
        }

        mflags  = FLG_STATIC;
    }
    else
    {
        methHnd = eeFindMethod(memberRef, info.compScopeHnd, info.compMethodHnd);
        eeGetMethodSig(methHnd, &sig);
        callTyp = JITtype2varType(sig.retType);

        mflags   = eeGetMethodAttribs(methHnd);
        clsHnd   = eeGetMethodClass(methHnd);
        clsFlags = clsHnd ? eeGetClassAttribs(clsHnd):0;

#if HOIST_THIS_FLDS
        optHoistTFRhasCall();
#endif
        /* For virtual methods added by EnC, they wont exist in the
           original vtable. So we call a helper funciton to do the
           lookup and the dispatch */

        if ((mflags & FLG_VIRTUAL) && (mflags & FLG_EnC) &&
            (opcode == CEE_CALLVIRT))
        {
            unsigned    lclNum;

            impSpillSideEffects();

            args = impPopList(sig.numArgs, &argFlags);

            /* Get the address of the target function by calling helper */

            GenTreePtr helpArgs = gtNewOperNode(GT_LIST, TYP_VOID,
                                                gtNewIconEmbMethHndNode(methHnd));

            GenTreePtr thisPtr = impPopStack(); assert(thisPtr->gtType == TYP_REF);
            lclNum = lvaGrabTemp();
            impAssignTempGen(lclNum, thisPtr);
            thisPtr = gtNewLclvNode(lclNum, TYP_REF);

            helpArgs = gtNewOperNode(GT_LIST, TYP_VOID, thisPtr, helpArgs);

            // Call helper function

            GenTreePtr fptr = gtNewHelperCallNode(  CPX_EnC_RES_VIRT,
                                                    TYP_I_IMPL,
                                                    GTF_EXCEPT, helpArgs);

            /* Now make an indirect call through the function pointer */

            thisPtr = gtNewLclvNode(lclNum, TYP_REF);

            lclNum = lvaGrabTemp();
            impAssignTempGen(lclNum, fptr);
            fptr = gtNewLclvNode(lclNum, TYP_I_IMPL);

            // Create the acutal call node

            // @TODO: Need to reverse args and all that. "this" needs
            // to be in reg but we dont set gtCallObjp
            assert((sig.callConv & JIT_CALLCONV_MASK) != JIT_CALLCONV_VARARG);

            assert(thisPtr->gtOper == GT_LCL_VAR);
            args = gtNewOperNode(GT_LIST, TYP_VOID, gtClone(thisPtr), args);

            call = gtNewCallNode(CT_INDIRECT, (METHOD_HANDLE)fptr,
                                 genActualType(callTyp), 0, args);

            goto DONE_CALL;
        }

        call = gtNewCallNode(CT_USER_FUNC, methHnd, genActualType(callTyp),
                             GTF_CALL_USER, NULL);
        if (mflags & CORINFO_FLG_NOGCCHECK)
            call->gtCall.gtCallMoreFlags |= GTF_CALL_M_NOGCCHECK;

#ifndef NOT_JITC
        if (!(sig.callConv & JIT_CALLCONV_HASTHIS))
            mflags |= FLG_STATIC;
#endif
    }

    /* Some sanity checks */

    // CALL_VIRT and NEWOBJ must have a THIS pointer
    assert(!(opcode == CEE_CALLVIRT && opcode == CEE_NEWOBJ) ||
           (sig.callConv & JIT_CALLCONV_HASTHIS));
    // static bit and hasThis are negations of one another
    assert(((mflags & FLG_STATIC)                  != 0) ==
           ((sig.callConv & JIT_CALLCONV_HASTHIS) == 0));

    /*-------------------------------------------------------------------------
     * Set flags, check special-cases etc
     */

#if TGT_IA64
    if ((mflags & FLG_UNCHECKEDPINVOKE) && eeGetUnmanagedCallConv(methHnd) == UNMANAGED_CALLCONV_STDCALL)
        call->gtFlags |= GTF_CALL_UNMANAGED;
#endif

    /* Set the correct GTF_CALL_VIRT etc flags */

    if (opcode == CEE_CALLVIRT)
    {
        assert(!(mflags & FLG_STATIC));     // can't call a static method

        /* Cannot call virtual on a value class method */

        assert(!(clsFlags & FLG_VALUECLASS));

        /* Set the correct flags - virtual, interface, etc...
         * If the method is final or private mark it VIRT_RES
         * which indicates that we should check for a null this pointer */

        if (clsFlags & FLG_INTERFACE)
            call->gtFlags |= GTF_CALL_INTF | GTF_CALL_VIRT;
        else if (mflags & (FLG_PRIVATE | FLG_FINAL))
            call->gtFlags |= GTF_CALL_VIRT_RES;
        else
            call->gtFlags |= GTF_CALL_VIRT;
    }

    /* Special case - Check if it is a call to Delegate.Invoke(). */

    if (mflags & FLG_DELEGATE_INVOKE)
    {
        assert(!(mflags & FLG_STATIC));     // can't call a static method
        assert(mflags & FLG_FINAL);

        /* Set the delegate flag */
        call->gtFlags |= GTF_DELEGATE_INVOKE;

        if (opcode == CEE_CALLVIRT)
        {
            /* Although we use a CEE_CALLVIRT we don't need the gtCall.gtCallVptr -
             * we would throw it away anyway and we also have to make sure we get
             * the liveness right */

            assert(mflags & FLG_FINAL);

            /* It should have the GTF_CALL_VIRT_RES flag set. Reset it */
            assert(call->gtFlags & GTF_CALL_VIRT_RES);
            call->gtFlags &= ~GTF_CALL_VIRT_RES;
        }
    }

    /* Check for varargs */

    if  ((sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_VARARG)
    {
        /* Set the right flags */

        call->gtFlags |= GTF_CALL_POP_ARGS;

        // Cant allow tailcall for varargs as it is caller-pop. The caller
        // will be expecting to pop a certain number of arguments, but if we
        // tailcall to a function with a different number of arguments, we
        // are hosed. There are ways around this (caller remembers esp value,
        // varargs is not caller-pop, etc), but not worth it.
        assert(!tailCall);

        /* Get the total number of arguments - this is already correct
         * for CALLI - for methods we have to get it from the call site */

        if  (opcode != CEE_CALLI)
        {
            unsigned    numArgsDef = sig.numArgs;
            eeGetCallSiteSig(memberRef, info.compScopeHnd, &sig);
            assert(numArgsDef <= sig.numArgs);
        }

        /* We will have "cookie" as the last argument but we cannot push
         * it on the operand stack because we may overflow, so we append it
         * to the arg list next after we pop them */
    }

#if SECURITY_CHECK
    // If the current method calls a method which needs a security
    // check, we need to reserve a slot for the security object in
    // the current method's stack frame

    if (mflags & FLG_SECURITYCHECK)
       opts.compNeedSecurityCheck = true;
#endif

    //--------------------------- Inline NDirect ------------------------------

#if INLINE_NDIRECT

    if ((mflags & FLG_UNCHECKEDPINVOKE) && getInlineNDirectEnabled()
#ifdef DEBUGGING_SUPPORT
         && !opts.compDbgInfo
#endif
        )
    {
        if ((eeGetUnmanagedCallConv(methHnd) == UNMANAGED_CALLCONV_STDCALL) &&
            !eeNDMarshalingRequired(methHnd))
        {
            call->gtFlags |= GTF_CALL_UNMANAGED;
            info.compCallUnmanaged++;

            // We set up the unmanaged call by linking the frame, disabling GC, etc
            // This needs to be cleaned up on return
            canTailCall = false;

#ifdef DEBUG
            if (verbose)
                printf(">>>>>>%s has unmanaged callee\n", info.compFullName);
#endif
            eeGetEEInfo(&info.compEEInfo);
        }
    }

    if (sig.numArgs && (call->gtFlags & GTF_CALL_UNMANAGED))
    {
        /* Since we push the arguments in reverse order (i.e. right -> left)
         * spill any side effects from the stack
         *
         * OBS: If there is only one side effect we do not need to spill it
         *      thus we have to spill all side-effects except last one
         */

        unsigned    lastLevel;
        bool        moreSideEff = false;

        for (unsigned level = impStkDepth - sig.numArgs; level < impStkDepth; level++)
        {
            if  (impStack[level].val->gtFlags & GTF_SIDE_EFFECT)
            {
                if  (moreSideEff)
                {
                    /* We had a previous side effect - must spill it */
                    impSpillStackEntry(lastLevel);

                    /* Record the level for the current side effect in case we will spill it */
                    lastLevel   = level;
                }
                else
                {
                    /* This is the first side effect encountered - record its level */

                    moreSideEff = true;
                    lastLevel   = level;
                }
            }
        }

        /* The argument list is now "clean" - no out-of-order side effects
         * Pop the argument list in reverse order */

        args = call->gtCall.gtCallArgs = impPopRevList(sig.numArgs, &argFlags);

        call->gtFlags |= args->gtFlags & GTF_GLOB_EFFECT;

        goto DONE;
    }

#endif // INLINE_NDIRECT

    /*-------------------------------------------------------------------------
     * Create the argument list
     */

    /* Special case - for varargs we have an implicit last argument */

    GenTreePtr      extraArg;

    extraArg = 0;

#if!TGT_IA64

    if  ((sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_VARARG)
    {
        void *          varCookie, *pVarCookie;
#ifdef NOT_JITC
        varCookie = info.compCompHnd->getVarArgsHandle(&sig, &pVarCookie);
        assert((!varCookie) != (!pVarCookie));
#else
        varCookie = (void*)&sig;
        pVarCookie = NULL;
#endif
        GenTreePtr  cookie = gtNewIconEmbHndNode(varCookie, pVarCookie, GTF_ICON_VARG_HDL);

        extraArg = gtNewOperNode(GT_LIST, TYP_I_IMPL, cookie);
    }

#endif

    if (sig.callConv & CORINFO_CALLCONV_PARAMTYPE)
    {
        if (clsHnd == 0)
            NO_WAY("CALLI on parameterized type");

        // Parameterized type, add an extra argument which indicates the type parameter
        // This is pushed as the last argument

        // FIX NOW: clsHnd is not correct because it is been striped of the very information
        // we need to preserve
        extraArg = gtNewOperNode(GT_LIST, TYP_I_IMPL, gtNewIconEmbClsHndNode(clsHnd, 0, 0));
    }

    /* Now pop the arguments */

    args = call->gtCall.gtCallArgs = impPopList(sig.numArgs, &argFlags, extraArg);

    if (args)
        call->gtFlags |= args->gtFlags & GTF_GLOB_EFFECT;

    /* Are we supposed to have a 'this' pointer? */

    if (!(mflags & FLG_STATIC) || opcode == CEE_NEWOBJ)
    {
        GenTreePtr obj;

        if (opcode == CEE_NEWOBJ)
            obj = newobjThis;
        else
            obj = impPopStack();

        assert(varTypeIsGC(obj->gtType) ||      // "this" is a managed object
               (obj->TypeGet() == TYP_I_IMPL && // "this" is unmgd but the method's class doesnt care
                (( clsFlags & FLG_UNMANAGED) ||
                 ((clsFlags & FLG_VALUECLASS) && !(clsFlags & FLG_CONTAINS_GC_PTR)))));

        /* Is this a virtual or interface call? */

        if  (call->gtFlags & (GTF_CALL_VIRT|GTF_CALL_INTF|GTF_CALL_VIRT_RES))
        {
            GenTreePtr      vtp;
            unsigned        tmp;

            /* only true object pointers can be virtual */

            assert(obj->gtType == TYP_REF);

            /* If the obj pointer is not a lclVar, we cant clone it
             * so we need to spill it
             */

            if  (obj->gtOper != GT_LCL_VAR)
            {
                // Try to resue temps for non-nested calls to avoid
                // using so many temps that we cant track them

                if  (!(argFlags & GTF_CALL) && lvaCount > VARSET_SZ)
                {
                    /* Make sure the vcall temp has been assigned */

                    tmp = *pVcallTemp;

                    if  (tmp == BAD_VAR_NUM)
                        tmp = *pVcallTemp = lvaGrabTemp();
                }
                else
                {
                    tmp = lvaGrabTemp();
                }

                /* Append to the statement list */

                impSpillSideEffects();
                impAppendTree(gtNewTempAssign(tmp, obj), impCurStmtOffs);

                /* Create the 'obj' node */

                obj = gtNewLclvNode(tmp, obj->TypeGet());
            }

            /*  We have to pass the 'this' pointer as the last
                argument, but we will also need to get the vtable
                address. Thus we'll need to duplicate the value.
             */

            vtp = gtClone(obj); assert(vtp);

            /* Deref to get the vtable ptr (but not if interface call) */

            if  (!(call->gtFlags & GTF_CALL_INTF) || getNewCallInterface())
            {
                /* Extract the vtable pointer address */
#if VPTR_OFFS
                vtp = gtNewOperNode(GT_ADD,
                                    obj->TypeGet(),
                                    vtp,
                                    gtNewIconNode(VPTR_OFFS, TYP_INT));

#endif

                /* Note that the vtable ptr isn't subject to GC */

                vtp = gtNewOperNode(GT_IND, TYP_I_IMPL, vtp);
            }

            /* Store the vtable pointer address in the call */

            call->gtCall.gtCallVptr = vtp;
        }

        /* Store the "this" value in the call */

        call->gtFlags          |= obj->gtFlags & GTF_GLOB_EFFECT;
        call->gtCall.gtCallObjp = obj;
    }

    if (opcode == CEE_NEWOBJ)
    {
        if (clsFlags & FLG_VAROBJSIZE)
        {
            assert(!(clsFlags & FLG_ARRAY));    // arrays handled separately
            // This is a 'new' of a variable sized object, wher
            // the constructor is to return the object.  In this case
            // the constructor claims to return VOID but we know it
            // actually returns the new object
            assert(callTyp == TYP_VOID);
            callTyp = TYP_REF;
            call->gtType = TYP_REF;
        }
        else
        {
            // This is a 'new' of a non-variable sized object.
            // append the new node (op1) to the statement list,
            // and then push the local holding the value of this
            // new instruction on the stack.

            if (clsFlags & FLG_VALUECLASS)
            {
                assert(newobjThis->gtOper == GT_ADDR &&
                       newobjThis->gtOp.gtOp1->gtOper == GT_LCL_VAR);
                impPushOnStack(gtNewLclvNode(newobjThis->gtOp.gtOp1->gtLclVar.gtLclNum, TYP_STRUCT), clsHnd);
            }
            else
            {
                assert(newobjThis->gtOper == GT_LCL_VAR);
                impPushOnStack(gtNewLclvNode(newobjThis->gtLclVar.gtLclNum, TYP_REF));
            }
            goto SPILL_APPEND;
        }
    }

DONE:

    if (tailCall)
    {
        if (impStkDepth)
            NO_WAY("Stack should be empty after tailcall");

//      assert(compCurBB is not a catch, finally or filter block);
//      assert(compCurBB is not a try block protected by a finally block);
        assert(callTyp == info.compRetType);
        assert(compCurBB->bbJumpKind == BBJ_RETURN);

        // @TODO: We have to ensure to pass the incoming retValBuf as the
        // outgoing one. Using a temp will not do as this function will
        // not regain control to do the copy. For now, disallow such functions
        assert(info.compRetBuffArg < 0);

        /* Check for permission to tailcall */

        if (canTailCall)
        {
            METHOD_HANDLE calleeHnd = (opcode==CEE_CALL) ? methHnd : NULL;
#ifdef NOT_JITC
            canTailCall = info.compCompHnd->canTailCall(info.compMethodHnd, calleeHnd);
#endif
        }

        if (canTailCall)
        {
            call->gtCall.gtCallMoreFlags |= GTF_CALL_M_CAN_TAILCALL;
        }
    }

    /* If the call is of a small type, then we need to normalize its
       return value */

    if (varTypeIsIntegral(callTyp) &&
        genTypeSize(callTyp) < genTypeSize(TYP_I_IMPL))
    {
        call = gtNewOperNode(GT_CAST, genActualType(callTyp),
                             call, gtNewIconNode(callTyp));
    }

DONE_CALL:

    /* Push or append the result of the call */

    if  (callTyp == TYP_VOID)
    {
    SPILL_APPEND:
        if (impStkDepth > 0)
            impSpillSideEffects(true);
        impAppendTree(call, impCurStmtOffs);
    }
    else
    {
        impSpillSpecialSideEff();

        impPushOnStack(call, sig.retTypeClass);
    }

    return callTyp;
}

/*****************************************************************************/

#ifdef DEBUG
enum controlFlow_t {
    NEXT,
    CALL,
    RETURN,
    THROW,
    BRANCH,
    COND_BRANCH,
    BREAK,
    PHI,
    META,
};
controlFlow_t controlFlow[] =
{
#define OPDEF(c,s,pop,push,args,type,l,s1,s2,flow) flow,
#include "opcode.def"
#undef OPDEF
};
#endif


/*****************************************************************************
 *  Import the IL for the given basic block
 */

void                Compiler::impImportBlockCode(BasicBlock * block)
{
#ifdef  DEBUG
    if (verbose) printf("\nImporting basic block #%02u (PC=%03u) of '%s'",
                        block->bbNum, block->bbCodeOffs, info.compFullName);
#endif

#if defined(DEBUGGING_SUPPORT) || defined(DEBUG)

    /*-------------------------------------------------------------------------
     * Locate the next stmt boundary for which we need to record info.
     * We will have to spill the stack at such boundaries if it is not
     * already empty.
     */

    impCurStmtOffs                  = block->bbCodeOffs;

    IL_OFFSET       nxtStmtOffs     = BAD_IL_OFFSET;
    unsigned        nxtStmtIndex    = -1;

    if  (info.compStmtOffsetsCount)
    {
        unsigned        index;

        /* Find the lowest explicit stmt boundary within the block */

        IL_OFFSET       startOffs = block->bbCodeOffs;

        /* Start looking at an entry that is based on our IL offset */

        index = info.compStmtOffsetsCount * startOffs / info.compCodeSize;
        if  (index >= info.compStmtOffsetsCount)
             index  = info.compStmtOffsetsCount - 1;

        /* If we've guessed too far, back up */

        while (index > 0 &&
               info.compStmtOffsets[index-1] > startOffs)
        {
            index--;
        }

        /* If we guessed short, advance ahead */

        while (index < info.compStmtOffsetsCount-1 &&
               info.compStmtOffsets[index] <= startOffs)
        {
            index++;
        }

        /* If the offset is within the current block, note it. So we
           always have to look only at the offset one ahead to check if
           we crossed it. Note that info.compStmtBoundaries[] is sorted
         */

        unsigned nxtStmtOffsTentative = info.compStmtOffsets[index];

        if (nxtStmtOffsTentative > (startOffs) &&
            nxtStmtOffsTentative < (startOffs + block->bbCodeSize))
        {
            nxtStmtIndex = index;
            nxtStmtOffs  = nxtStmtOffsTentative;
        }
    }

#else

    impCurStmtOffs = BAD_IL_OFFSET;

#endif // DEBUGGING_SUPPORT ---------------------------------------------------

    /* We have not grabbed a temp for virtual calls */

    unsigned    vcallTemp   = BAD_VAR_NUM;

    /* Get the tree list started */

    impBeginTreeList();

    /* Walk the opcodes that comprise the basic block */

    const BYTE *codeAddr    = info.compCode + block->bbCodeOffs;
    const BYTE *codeEndp    = codeAddr + block->bbCodeSize;

    bool        tailCall    = false;    // set by CEE_TAILCALL and cleared by CEE_CALLxxx
    bool        volatil     = false;    // set by CEE_VOLATILE and cleared by following memory access

    unsigned    numArgs     = info.compArgsCount;

    /* Now process all the opcodes in the block */

    while (codeAddr < codeEndp)
    {
        var_types       callTyp;
        OPCODE          opcode;
        signed  int     sz;

#ifdef DEBUG
        callTyp = TYP_COUNT;
#endif

        /* Compute the current IL offset */

        IL_OFFSET       opcodeOffs = codeAddr - info.compCode;

        //---------------------------------------------------------------------

#if defined(DEBUGGING_SUPPORT) || defined(DEBUG)

#ifndef DEBUG
        if (opts.compDbgInfo)
#endif
        {
            /* Have we reached the next stmt boundary ? */

            if  (nxtStmtOffs != BAD_IL_OFFSET && opcodeOffs >= nxtStmtOffs)
            {
                if  (impStkDepth != 0 && opts.compDbgCode)
                {
                    /* We need to provide accurate IP-mapping at this point.
                       So spill anything on the stack so that it will form
                       gtStmts with the correct stmt offset noted */

                    impSpillStmtBoundary();
                }

                assert(nxtStmtOffs == info.compStmtOffsets[nxtStmtIndex]);

                /* Switch to the new stmt */

                impCurStmtOffs = nxtStmtOffs;

                /* Update the stmt boundary index */

                nxtStmtIndex++;
                assert(nxtStmtIndex <= info.compStmtOffsetsCount);

                /* Are there any more line# entries after this one? */

                if  (nxtStmtIndex < info.compStmtOffsetsCount)
                {
                    /* Remember where the next line# starts */

                    nxtStmtOffs = info.compStmtOffsets[nxtStmtIndex];
                }
                else
                {
                    /* No more line# entries */

                    nxtStmtOffs = BAD_IL_OFFSET;
                }
            }
            else if  ((info.compStmtOffsetsImplicit & STACK_EMPTY_BOUNDARIES) &&
                      (impStkDepth == 0))
            {
                /* At stack-empty locations, we have already added the tree to
                   the stmt list with the last offset. We just need to update
                   impCurStmtOffs
                 */

                impCurStmtOffs = opcodeOffs;
            }

            assert(impCurStmtOffs <= nxtStmtOffs || nxtStmtOffs == BAD_IL_OFFSET);
        }

#endif

        CLASS_HANDLE    clsHnd;
        var_types       lclTyp;

        /* Get the next opcode and the size of its parameters */

        opcode = OPCODE(getU1LittleEndian(codeAddr));
        codeAddr += sizeof(__int8);

#ifdef  DEBUG
        impCurOpcOffs   = codeAddr - info.compCode - 1;

        if  (verbose)
            printf("\n[%2u] %3u (0x%03x)",
                   impStkDepth, impCurOpcOffs, impCurOpcOffs);
#endif

DECODE_OPCODE:

        /* Get the size of additional parameters */

        sz = opcodeSizes[opcode];

#ifdef  DEBUG

        clsHnd          = BAD_CLASS_HANDLE;
        lclTyp          = (var_types) -1;
        callTyp         = (var_types) -1;

        impCurOpcOffs   = codeAddr - info.compCode - 1;
        impCurStkDepth  = impStkDepth;
        impCurOpcName   = opcodeNames[opcode];

        if (verbose && (controlFlow[opcode] != META))
            printf(" %s", impCurOpcName);
#endif

#if COUNT_OPCODES
        assert(opcode < OP_Count); genOpcodeCnt[opcode].ocCnt++;
#endif

        GenTreePtr      op1 = NULL, op2 = NULL;

        /* Use assertImp() to display the opcode */

#ifdef NDEBUG
#define assertImp(cond)     ((void)0)
#else
            char assertImpBuf[200];
#define assertImp(cond)                                                        \
            do { if (!(cond)) {                                                \
                sprintf(assertImpBuf,"%s : Possibly bad IL with CEE_%s at "  \
                                   "offset %04Xh (op1=%s op2=%s stkDepth=%d)", \
                        #cond, impCurOpcName, impCurOpcOffs,                   \
                        op1?varTypeName(op1->TypeGet()):"NULL",                \
                        op2?varTypeName(op2->TypeGet()):"NULL",impCurStkDepth);\
                assertAbort(assertImpBuf, jitCurSource, __FILE__, __LINE__);   \
            } } while(0)
#endif

        /* See what kind of an opcode we have, then */

        switch (opcode)
        {
            unsigned        lclNum;
            var_types       type;

            genTreeOps      oper;
            GenTreePtr      thisPtr, arr;

            int             memberRef, typeRef, val;

            METHOD_HANDLE   methHnd;
            FIELD_HANDLE    fldHnd;

            JIT_SIG_INFO    sig;
            unsigned        mflags, clsFlags;
            unsigned        flags, jmpAddr;
            bool            ovfl, uns, unordered, callNode;
            bool            needUnwrap, needWrap;

            union
            {
                long            intVal;
                float           fltVal;
                __int64         lngVal;
                double          dblVal;
            }
                            cval;

            case CEE_PREFIX1:
				opcode = OPCODE(getU1LittleEndian(codeAddr) + 256);
                codeAddr += sizeof(__int8);
                goto DECODE_OPCODE;

        case CEE_LDNULL:
            impPushOnStack(gtNewIconNode(0, TYP_REF));
            break;

        case CEE_LDC_I4_M1 :
        case CEE_LDC_I4_0 :
        case CEE_LDC_I4_1 :
        case CEE_LDC_I4_2 :
        case CEE_LDC_I4_3 :
        case CEE_LDC_I4_4 :
        case CEE_LDC_I4_5 :
        case CEE_LDC_I4_6 :
        case CEE_LDC_I4_7 :
        case CEE_LDC_I4_8 :
            cval.intVal = (opcode - CEE_LDC_I4_0);
            assert(-1 <= cval.intVal && cval.intVal <= 8);
            goto PUSH_I4CON;

        case CEE_LDC_I4_S: cval.intVal = getI1LittleEndian(codeAddr); goto PUSH_I4CON;
        case CEE_LDC_I4:   cval.intVal = getI4LittleEndian(codeAddr); goto PUSH_I4CON;
        PUSH_I4CON:
#ifdef DEBUG
            if (verbose) printf(" %d", cval.intVal);
#endif
            impPushOnStack(gtNewIconNode(cval.intVal));
            break;

        case CEE_LDC_I8:  cval.lngVal = getI8LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %I64d", cval.lngVal);
#endif
            impPushOnStack(gtNewLconNode(&cval.lngVal));
            break;

        case CEE_LDC_R8:  cval.dblVal = getR8LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %f", cval.dblVal);
#endif
            impPushOnStack(gtNewDconNode(&cval.dblVal));
            break;

        case CEE_LDC_R4:  cval.fltVal = getR4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %f", cval.fltVal);
#endif
            impPushOnStack(gtNewFconNode(cval.fltVal));
            break;

        case CEE_LDSTR:
            val = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", val);
#endif
            impPushOnStack(gtNewSconNode(val, info.compScopeHnd));
            break;

        case CEE_LDARG:
            lclNum = getU2LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %u", lclNum);
#endif
            goto LD_ARGVAR;

        case CEE_LDARG_S:
            lclNum = getU1LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %u", lclNum);
#endif
            goto LD_ARGVAR;

        case CEE_LDARG_0:
        case CEE_LDARG_1:
        case CEE_LDARG_2:
        case CEE_LDARG_3:
            lclNum = (opcode - CEE_LDARG_0);
            assert(lclNum >= 0 && lclNum < 4);

        LD_ARGVAR:
            lclNum = impArgNum(lclNum);   // account for possible hidden param
            assertImp(lclNum < numArgs);

                // Fetching a varargs argument is more work
            if (info.compIsVarArgs)
            {
                if (lvaGetType(lclNum) == TYP_STRUCT)
                    clsHnd = lvaLclClass(lclNum);
                impPushOnStack(impGetVarArg(lclNum, clsHnd), clsHnd);
                break;
            }
            goto LDVAR;


        case CEE_LDLOC:
            lclNum = getU2LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %u", lclNum);
#endif
            goto LD_LCLVAR;

        case CEE_LDLOC_S:
            lclNum = getU1LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %u", lclNum);
#endif
            goto LD_LCLVAR;

        case CEE_LDLOC_0:
        case CEE_LDLOC_1:
        case CEE_LDLOC_2:
        case CEE_LDLOC_3:
            lclNum = (opcode - CEE_LDLOC_0);
            assert(lclNum >= 0 && lclNum < 4);

        LD_LCLVAR:
            lclNum += numArgs;
            assertImp(lclNum < info.compLocalsCount);
        LDVAR:
            if (lvaGetType(lclNum) == TYP_STRUCT)
                clsHnd = lvaLclClass(lclNum);

            op1 = gtNewLclvNode(lclNum, lvaGetRealType(lclNum),
                                opcodeOffs + sz + 1);

            if  (getContextEnabled() &&
                 (lvaGetType(lclNum) == TYP_REF) && lvaIsContextFul(lclNum))
            {
                op1->gtFlags |= GTF_CONTEXTFUL;

                op1 = gtNewArgList(op1);

                op1 = gtNewHelperCallNode(CPX_UNWRAP, TYP_REF, GTF_CALL_REGSAVE, op1);

                op1->gtFlags |= GTF_CONTEXTFUL;
            }

            /* If the var is aliased, treat it as a global reference.
               NOTE : This is an overly-conservative approach - functions which
               dont take any byref arguments cannot modify aliased vars. */

            if (lvaTable[lclNum].lvAddrTaken)
                op1->gtFlags |= GTF_GLOB_REF;

            impPushOnStack(op1, clsHnd);
            break;

        case CEE_STARG:
            lclNum = getU2LittleEndian(codeAddr);
            goto STARG;

        case CEE_STARG_S:
            lclNum = getU1LittleEndian(codeAddr);
        STARG:
#ifdef DEBUG
            if (verbose) printf(" %u", lclNum);
#endif
            lclNum = impArgNum(lclNum);     // account for possible hidden param
            assertImp(lclNum < numArgs);
            goto VAR_ST;

        case CEE_STLOC:
            lclNum = getU2LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %u", lclNum);
#endif
            goto LOC_ST;

        case CEE_STLOC_S:
            lclNum = getU1LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %u", lclNum);
#endif
            goto LOC_ST;

        case CEE_STLOC_0:
        case CEE_STLOC_1:
        case CEE_STLOC_2:
        case CEE_STLOC_3:
            lclNum = (opcode - CEE_STLOC_0);
            assert(lclNum >= 0 && lclNum < 4);

        LOC_ST:
            lclNum += numArgs;

        VAR_ST:
            assertImp(lclNum < info.compLocalsCount);

            /* Pop the value being assigned */

            op1 = impPopStack();

            lclTyp = lvaGetType(lclNum);    // Get declared type of var

#if HOIST_THIS_FLDS
            if (varTypeIsGC(lclTyp))
                optHoistTFRasgThis();
#endif
            // We had better assign it a value of the correct type

            assertImp(lclTyp == genActualType(op1->gtType) ||
                      lclTyp == TYP_I_IMPL && op1->IsVarAddr() ||
                      (genActualType(lclTyp) == TYP_NAT_INT && op1->gtType == TYP_BYREF)||
                      (genActualType(op1->gtType) == TYP_NAT_INT && lclTyp == TYP_BYREF));
            // @TODO: Enable after bug 4886 is resolved
            assertImp(true || lclTyp != TYP_STRUCT ||
                      impStack[impStkDepth].structType == lvaLclClass(lclNum));

            /* If op1 is "&var" then its type is the transient "*" and it can
               be used either as TYP_BYREF or TYP_I_IMPL */

            if (op1->IsVarAddr())
            {
                assertImp(lclTyp == TYP_I_IMPL || lclTyp == TYP_BYREF);

                /* When "&var" is created, we assume it is a byref. If it is
                   being assigned to a TYP_I_IMPL var, bash the type to
                   prevent unnecessary GC info */

                if (lclTyp == TYP_I_IMPL)
                    op1->gtType = TYP_I_IMPL;
            }

            /* Filter out simple assignments to itself */

            if  (op1->gtOper == GT_LCL_VAR && lclNum == op1->gtLclVar.gtLclNum)
                break;


            /* do we need to wrap the contextful value
               (i.e. is the local an agile location)? */
            /*@TODO: right now all locals are agile locations */

            if  (getContextEnabled() &&
                 (lclTyp == TYP_REF) && (op1->gtFlags & FLG_CONTEXTFUL))
            {
                op1 = gtNewArgList(op1);

                op1 = gtNewHelperCallNode(CPX_WRAP, TYP_REF, GTF_CALL_REGSAVE, op1);

            }

            /* Create the assignment node */

            if (lclTyp == TYP_STRUCT)
                clsHnd = lvaLclClass(lclNum);

            if (info.compIsVarArgs && lclNum < info.compArgsCount)
                op2 = impGetVarArg(lclNum, clsHnd);
            else
                op2 = gtNewLclvNode(lclNum, lclTyp, opcodeOffs + sz + 1);

            if (lclTyp == TYP_STRUCT)
                op1 = impAssignStruct(op2, op1, clsHnd);
            else
                op1 = gtNewAssignNode(op2, op1);

            /* Mark the expression as containing an assignment */
            op1->gtFlags |= GTF_ASG;

            /* If the local is aliased, we need to spill calls and
               indirections from the stack. */

            if (lvaTable[lclNum].lvAddrTaken && impStkDepth > 0)
                impSpillSideEffects();

            /* Spill any refs to the local from the stack */

            impSpillLclRefs(lclNum);

            goto SPILL_APPEND;


        case CEE_LDLOCA:
            lclNum = getU2LittleEndian(codeAddr);
            goto LDLOCA;

        case CEE_LDLOCA_S:
            lclNum = getU1LittleEndian(codeAddr);
        LDLOCA:
#ifdef DEBUG
            if (verbose) printf(" %u", lclNum);
#endif
            lclNum += numArgs;
            assertImp(lclNum < info.compLocalsCount);
            goto ADRVAR;


        case CEE_LDARGA:
            lclNum = getU2LittleEndian(codeAddr);
            goto LDARGA;

        case CEE_LDARGA_S:
            lclNum = getU1LittleEndian(codeAddr);
        LDARGA:
#ifdef DEBUG
            if (verbose) printf(" %u", lclNum);
#endif
            assertImp(lclNum < numArgs);
            lclNum = impArgNum(lclNum);     // account for possible hidden param
            goto ADRVAR;

        ADRVAR:

            assert(lvaTable[lclNum].lvAddrTaken);

            /* Spill any refs to the local from the stack */

            impSpillLclRefs(lclNum);

            /* Remember that the variable's address was taken */


            if (info.compIsVarArgs && lclNum < info.compArgsCount)
            {
                op1 = impGetVarArgAddr(lclNum);
            }
            else
            {
                op1 = gtNewLclvNode(lclNum, lvaGetType(lclNum), opcodeOffs + sz + 1);

                /* Note that this is supposed to create the transient type "*"
                   which may be used as a TYP_I_IMPL. However we catch places
                   where it is used as a TYP_I_IMPL and bash the node if needed.
                   Thus we are pessimistic and may report byrefs in the GC info
                   where it wasnt absolutely needed, but it is safer this way.
                 */
                op1 = gtNewOperNode(GT_ADDR, TYP_BYREF, op1);
            }

            op1->gtFlags |= GTF_ADDR_ONSTACK;
            impPushOnStack(op1);
            break;

        case CEE_ARGLIST:
            assertImp((info.compMethodInfo->args.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_VARARG);
                /* The ARGLIST cookie is a hidden 'last' parameter, we have already
                   adjusted the arg count os this is like fetching the last param */
            assertImp(0 < numArgs);
            lclNum = numArgs-1;
lvaTable[lclNum].lvAddrTaken = true;    // IS THIS RIGHT????  [peteku]
            op1 = gtNewLclvNode(lclNum, TYP_I_IMPL, opcodeOffs + sz + 1);
            op1 = gtNewOperNode(GT_ADDR, TYP_BYREF, op1);
            op1->gtFlags |= GTF_ADDR_ONSTACK;
            impPushOnStack(op1);
            break;

        SPILL_APPEND:
            if (impStkDepth > 0)
                impSpillSideEffects();

        APPEND:
            /* Append 'op1' to the list of statements */

            impAppendTree(op1, impCurStmtOffs);

            // Remember at which BC offset the tree was finished
#ifdef DEBUG
            impNoteLastILoffs();
#endif
            break;

        case CEE_ENDFINALLY:
            if (impStkDepth != 0)   NO_WAY("Stack must be 0 on end of finally");
            op1 = gtNewOperNode(GT_RETFILT, TYP_VOID);
            goto APPEND;

        case CEE_ENDFILTER:
            op1 = impPopStack();

#if TGT_IA64
            assertImp(op1->gtType == TYP_NAT_INT || op1->gtType == TYP_INT);
#else
            assertImp(op1->gtType == TYP_NAT_INT);
#endif

            assertImp(compFilterHandlerBB);

            /* Mark current bb as end of filter */

            assert((compCurBB->bbFlags & (BBF_ENDFILTER|BBF_DONT_REMOVE)) ==
                                        (BBF_ENDFILTER|BBF_DONT_REMOVE));
            assert(compCurBB->bbJumpKind == BBJ_RET);

            /* Mark catch handler as successor */

            compCurBB->bbJumpDest = compFilterHandlerBB;

            compFilterHandlerBB = NULL;

            op1 = gtNewOperNode(GT_RETFILT, op1->TypeGet(), op1);
            if (impStkDepth != 0)   NO_WAY("Stack must be 0 on end of filter");
            goto APPEND;

        case CEE_RET:
        RET:

            op2 = 0;
            if (info.compRetType != TYP_VOID)
            {
                op2 = impPopStack(clsHnd);
                impBashVarAddrsToI(op2);
                assertImp((genActualType(op2->TypeGet()) == genActualType(info.compRetType)) ||
                          ((op2->TypeGet() == TYP_NAT_INT) && (info.compRetType == TYP_BYREF)) ||
                          ((op2->TypeGet() == TYP_BYREF) && (info.compRetType == TYP_NAT_INT)));
            }
            if (impStkDepth != 0)   NO_WAY("Stack must be 0 on return");

            if (info.compRetType == TYP_STRUCT)
            {
                    // Assign value to return buff (first param)
                GenTreePtr retBuffAddr = gtNewLclvNode(info.compRetBuffArg, TYP_BYREF, impCurStmtOffs);

                op2 = impAssignStructPtr(retBuffAddr, op2, clsHnd);
                impAppendTree(op2, impCurStmtOffs);
                    // and return void
                op1 = gtNewOperNode(GT_RETURN);
            }
            else
                op1 = gtNewOperNode(GT_RETURN, genActualType(info.compRetType), op2);


#if TGT_RISC
            genReturnCnt++;
#endif
            // We must have imported a tailcall and jumped to RET
            if (tailCall)
            {
                assert(impStkDepth == 0 && impOpcodeIsCall(opcode));
                opcode = CEE_RET; // To prevent trying to spill if CALL_SITE_BOUNDARIES
                tailCall = false; // clear the flag

                // impImportCall() would have already appended TYP_VOID calls
                if (info.compRetType == TYP_VOID)
                    break;
            }

            goto APPEND;

            /* These are similar to RETURN */

        case CEE_JMP:

            /* Create the GT_JMP node */

                memberRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
                if (verbose) printf(" %08X", memberRef);
#endif

DO_JMP:
                methHnd   = eeFindMethod(memberRef, info.compScopeHnd, info.compMethodHnd);

                /* The signature of the target has to be identical to ours.
                   At least check that argCnt and returnType match */

                eeGetMethodSig(methHnd, &sig);
                if  (sig.numArgs != info.compArgsCount || sig.retType != info.compMethodInfo->args.retType)
                    NO_WAY("Incompatible target for CEE_JMPs");

                op1 = gtNewOperNode(GT_JMP);
                op1->gtVal.gtVal1 = (unsigned) methHnd;

            if (impStkDepth != 0)   NO_WAY("Stack must be empty after CEE_JMPs");

            /* Mark the basic block as being a JUMP instead of RETURN */

            block->bbFlags |= BBF_HAS_JMP;

            /* Set this flag to make sure register arguments have a location assigned
             * even if we don't use them inside the method */

            impParamsUsed = true;

#if TGT_RISC
            genReturnCnt++;
#endif
            goto APPEND;

        case CEE_LDELEMA :
            assertImp(sz == sizeof(unsigned));
            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif
            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);
            clsFlags = eeGetClassAttribs(clsHnd);
            if (clsFlags & FLG_VALUECLASS)
                lclTyp = TYP_STRUCT;
            else
            {
                op1 = gtNewIconEmbClsHndNode(clsHnd, typeRef, info.compScopeHnd);
                op1 = gtNewOperNode(GT_LIST, TYP_VOID, op1);                // Type
                op1 = gtNewOperNode(GT_LIST, TYP_VOID, impPopStack(), op1); // index
                op1 = gtNewOperNode(GT_LIST, TYP_VOID, impPopStack(), op1); // array
                op1 = gtNewHelperCallNode(CPX_LDELEMA_REF, TYP_BYREF, GTF_EXCEPT, op1);

                impPushOnStack(op1);
                break;
            }

#ifdef NOT_JITC
            // @TODO : Remove once valueclass array headers are same as primitive types
            {
                JIT_types jitTyp = info.compCompHnd->asPrimitiveType(clsHnd);
                if (jitTyp != JIT_TYP_UNDEF)
                {
                    lclTyp = JITtype2varType(jitTyp);
                    assertImp(varTypeIsArithmetic(lclTyp));
                }
            }
#endif
            goto ARR_LD;

        case CEE_LDELEM_I1 : lclTyp = TYP_BYTE  ; goto ARR_LD;
        case CEE_LDELEM_I2 : lclTyp = TYP_SHORT ; goto ARR_LD;
        case CEE_LDELEM_I  :
        case CEE_LDELEM_U4 :
        case CEE_LDELEM_I4 : lclTyp = TYP_INT   ; goto ARR_LD;
        case CEE_LDELEM_I8 : lclTyp = TYP_LONG  ; goto ARR_LD;
        case CEE_LDELEM_REF: lclTyp = TYP_REF   ; goto ARR_LD;
        case CEE_LDELEM_R4 : lclTyp = TYP_FLOAT ; goto ARR_LD;
        case CEE_LDELEM_R8 : lclTyp = TYP_DOUBLE; goto ARR_LD;
        case CEE_LDELEM_U1 : lclTyp = TYP_UBYTE ; goto ARR_LD;
        case CEE_LDELEM_U2 : lclTyp = TYP_CHAR  ; goto ARR_LD;

        ARR_LD:

#if CSELENGTH
            fgHasRangeChks = true;
#endif

            /* Pull the index value and array address */

            op2 = impPopStack();
            op1 = impPopStack();   assertImp(op1->gtType == TYP_REF);

            needUnwrap = false;


            op1 = impCheckForNullPointer(op1);

            /* Mark the block as containing an index expression */

            if  (op1->gtOper == GT_LCL_VAR)
            {
                if  (op2->gtOper == GT_LCL_VAR ||
                     op2->gtOper == GT_ADD     ||
                     op2->gtOper == GT_POST_INC)
                {
                    block->bbFlags |= BBF_HAS_INDX;
                }
            }

            /* Create the index node and push it on the stack */
            op1 = gtNewIndexRef(lclTyp, op1, op2);
            if (opcode == CEE_LDELEMA)
            {
                    // rememer the element size
                if (lclTyp == TYP_REF)
                    op1->gtIndex.elemSize = sizeof(void*);
                else
                    op1->gtIndex.elemSize = eeGetClassSize(clsHnd);

                    // wrap it in a &
                op1 = gtNewOperNode(GT_ADDR, ((clsFlags & FLG_UNMANAGED) ? TYP_I_IMPL : TYP_BYREF), op1);
            }
            impPushOnStack(op1);
            break;


        case CEE_STELEM_REF:

            // CONSIDER: Check for assignment of null and generate inline code

            /* Call a helper function to do the assignment */

            if  (getContextEnabled())
            {
                op1 = impPopStack();

                if (op1->gtFlags & GTF_CONTEXTFUL)
                {
                    op1 = gtNewArgList(op1);

                    op1 = gtNewHelperCallNode(CPX_WRAP, TYP_REF, GTF_CALL_REGSAVE, op1);
                }

                impPushOnStack(op1);
            }

            op1 = gtNewHelperCallNode(CPX_ARRADDR_ST,
                                      TYP_REF,
                                      GTF_CALL_REGSAVE,
                                      impPopList(3, &flags));

            goto SPILL_APPEND;

        case CEE_STELEM_I1: lclTyp = TYP_BYTE  ; goto ARR_ST;
        case CEE_STELEM_I2: lclTyp = TYP_SHORT ; goto ARR_ST;
        case CEE_STELEM_I:
        case CEE_STELEM_I4: lclTyp = TYP_INT   ; goto ARR_ST;
        case CEE_STELEM_I8: lclTyp = TYP_LONG  ; goto ARR_ST;
        case CEE_STELEM_R4: lclTyp = TYP_FLOAT ; goto ARR_ST;
        case CEE_STELEM_R8: lclTyp = TYP_DOUBLE; goto ARR_ST;

        ARR_ST:

            if (info.compStrictExceptions &&
                (impStackTop()->gtFlags & GTF_SIDE_EFFECT) )
            {
                impSpillSideEffects();
            }

#if CSELENGTH
            fgHasRangeChks = true;
#endif

            /* Pull the new value from the stack */

            op2 = impPopStack();
            if (op2->IsVarAddr())
                op2->gtType = TYP_I_IMPL;

            /* Pull the index value */

            op1 = impPopStack();

            /* Pull the array address */

            arr = impPopStack();   assertImp(arr->gtType == TYP_REF);
            arr = impCheckForNullPointer(arr);

            /* Create the index node */

            op1 = gtNewIndexRef(lclTyp, arr, op1);

            /* Create the assignment node and append it */

            op1 = gtNewAssignNode(op1, op2);

            /* Mark the expression as containing an assignment */

            op1->gtFlags |= GTF_ASG;

            // CONSIDER: Do we need to spill assignments to array elements with the same type?

            goto SPILL_APPEND;

        case CEE_ADD:           oper = GT_ADD;      goto MATH_OP2;

        case CEE_ADD_OVF:       lclTyp = TYP_UNKNOWN; uns = false;  goto ADD_OVF;
        case CEE_ADD_OVF_UN:    lclTyp = TYP_UNKNOWN; uns = true; goto ADD_OVF;

        ADD_OVF:
                                ovfl = true;        callNode = false;
                                oper = GT_ADD;      goto MATH_OP2_FLAGS;

        case CEE_SUB:           oper = GT_SUB;      goto MATH_OP2;

        case CEE_SUB_OVF:       lclTyp = TYP_UNKNOWN; uns = false;  goto SUB_OVF;
        case CEE_SUB_OVF_UN:    lclTyp = TYP_UNKNOWN; uns = true; goto SUB_OVF;

        SUB_OVF:
                                ovfl = true;        callNode = false;
                                oper = GT_SUB;      goto MATH_OP2_FLAGS;

        case CEE_MUL:           oper = GT_MUL;      goto MATH_CALL_ON_LNG;

        case CEE_MUL_OVF:       lclTyp = TYP_UNKNOWN; uns = false;  goto MUL_OVF;
        case CEE_MUL_OVF_UN:    lclTyp = TYP_UNKNOWN; uns = true; goto MUL_OVF;

        MUL_OVF:
                                ovfl = true;        callNode = false;
                                oper = GT_MUL;      goto MATH_CALL_ON_LNG_OVF;

        // Other binary math operations

#if TGT_IA64
        case CEE_DIV :          oper = GT_DIV;
                                ovfl = false; callNode = true;
                                goto MATH_OP2_FLAGS;
        case CEE_DIV_UN :       oper = GT_UDIV;
                                ovfl = false; callNode = true;
                                goto MATH_OP2_FLAGS;
#else
        case CEE_DIV :          oper = GT_DIV;   goto MATH_CALL_ON_LNG;
        case CEE_DIV_UN :       oper = GT_UDIV;  goto MATH_CALL_ON_LNG;
#endif

        case CEE_REM:
            oper = GT_MOD;
            ovfl = false;
            callNode = true;

#if!TGT_IA64
            // can use small node for INT case
            if (impStackTop()->gtType == TYP_INT)
                callNode = false;
#endif

            goto MATH_OP2_FLAGS;

        case CEE_REM_UN :       oper = GT_UMOD;  goto MATH_CALL_ON_LNG;

        MATH_CALL_ON_LNG:
            ovfl = false;
        MATH_CALL_ON_LNG_OVF:

#if TGT_IA64
            callNode = true;
#else
            callNode = false;
            if (impStackTop()->gtType == TYP_LONG)
                callNode = true;
#endif
            goto MATH_OP2_FLAGS;

        case CEE_AND:        oper = GT_AND;  goto MATH_OP2;
        case CEE_OR:         oper = GT_OR ;  goto MATH_OP2;
        case CEE_XOR:        oper = GT_XOR;  goto MATH_OP2;

        MATH_OP2:       // For default values of 'ovfl' and 'callNode'

            ovfl        = false;
            callNode    = false;

        MATH_OP2_FLAGS: // If 'ovfl' and 'callNode' have already been set

            /* Pull two values and push back the result */

            op2 = impPopStack();
            op1 = impPopStack();

#if!CPU_HAS_FP_SUPPORT
            if (op1->gtType == TYP_FLOAT || op1->gtType == TYP_DOUBLE)
                callNode    = true;
#endif
            /* Cant do arithmetic with references */
            assertImp(genActualType(op1->TypeGet()) != TYP_REF &&
                      genActualType(op2->TypeGet()) != TYP_REF);

            // Arithemetic operations are generally only allowed with
            // primitive types, but certain operations are allowed
            // with byrefs

            if ((oper == GT_SUB) &&
                (genActualType(op1->TypeGet()) == TYP_BYREF ||
                 genActualType(op2->TypeGet()) == TYP_BYREF))
            {
                // byref1-byref2 => gives an int
                // byref - int   => gives a byref

                if ((genActualType(op1->TypeGet()) == TYP_BYREF) &&
                    (genActualType(op2->TypeGet()) == TYP_BYREF))
                {
                    // byref1-byref2 => gives an int
                    type = TYP_I_IMPL;
                    impBashVarAddrsToI(op1, op2);
                }
                else
                {
                    // byref - int => gives a byref
                    // (but if &var, then dont need to report to GC)

                    assertImp(genActualType(op1->TypeGet()) == TYP_I_IMPL ||
                              genActualType(op2->TypeGet()) == TYP_I_IMPL);

                    impBashVarAddrsToI(op1, op2);

                    if (genActualType(op1->TypeGet()) == TYP_BYREF ||
                        genActualType(op2->TypeGet()) == TYP_BYREF)
                        type = TYP_BYREF;
                    else
                        type = TYP_I_IMPL;
                }
            }
            else if ((oper == GT_ADD) &&
                     (genActualType(op1->TypeGet()) == TYP_BYREF ||
                      genActualType(op2->TypeGet()) == TYP_BYREF))
            {
                // only one can be a byref : byref+byref not allowed
                assertImp(genActualType(op1->TypeGet()) != TYP_BYREF ||
                          genActualType(op2->TypeGet()) != TYP_BYREF);
                assertImp(genActualType(op1->TypeGet()) == TYP_I_IMPL ||
                          genActualType(op2->TypeGet()) == TYP_I_IMPL);

                // byref + int => gives a byref
                // (but if &var, then dont need to report to GC)

                impBashVarAddrsToI(op1, op2);

                if (genActualType(op1->TypeGet()) == TYP_BYREF ||
                    genActualType(op2->TypeGet()) == TYP_BYREF)
                    type = TYP_BYREF;
                else
                    type = TYP_I_IMPL;
            }
            else
            {
                assertImp(genActualType(op1->TypeGet()) != TYP_BYREF &&
                          genActualType(op2->TypeGet()) != TYP_BYREF);

                assertImp(genActualType(op1->TypeGet()) ==
                          genActualType(op2->TypeGet()));

                type = genActualType(op1->gtType);
            }

            /* Special case: "int+0", "int-0", "int*1", "int/1" */

            if  (op2->gtOper == GT_CNS_INT)
            {
                if  (((op2->gtIntCon.gtIconVal == 0) && (oper == GT_ADD || oper == GT_SUB)) ||
                     ((op2->gtIntCon.gtIconVal == 1) && (oper == GT_MUL || oper == GT_DIV)))

                {
                    impPushOnStack(op1);
                    break;
                }
            }

#if SMALL_TREE_NODES
            if (callNode)
            {
                /* These operators later get transformed into 'GT_CALL' */

                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_MUL]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_DIV]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_UDIV]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_MOD]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_UMOD]);

                op1 = gtNewOperNode(GT_CALL, type, op1, op2);
                op1->ChangeOper(oper);
            }
            else
#endif
            {
                op1 = gtNewOperNode(oper,    type, op1, op2);
            }

            /* Special case: integer/long division may throw an exception */

            if  (varTypeIsIntegral(op1->TypeGet()) && op1->OperMayThrow())
            {
                op1->gtFlags |=  GTF_EXCEPT;
            }

            if  (ovfl)
            {
                assert(oper==GT_ADD || oper==GT_SUB || oper==GT_MUL);
                if (lclTyp != TYP_UNKNOWN)
                    op1->gtType   = lclTyp;
                op1->gtFlags |= (GTF_EXCEPT | GTF_OVERFLOW);
                if (uns)
                    op1->gtFlags |= GTF_UNSIGNED;
            }

            impPushOnStack(op1);
            break;


        case CEE_SHL:        oper = GT_LSH;  goto CEE_SH_OP2;

        case CEE_SHR:        oper = GT_RSH;  goto CEE_SH_OP2;
        case CEE_SHR_UN:     oper = GT_RSZ;  goto CEE_SH_OP2;

        CEE_SH_OP2:

            op2     = impPopStack();

#if TGT_IA64
            // The shiftAmount is a U8.
            assertImp(genActualType(op2->TypeGet()) == TYP_LONG);
#else
            // The shiftAmount is a U4.
            assertImp(genActualType(op2->TypeGet()) == TYP_INT);
#endif

            op1     = impPopStack();    // operand to be shifted

            type    = genActualType(op1->TypeGet());
            op1     = gtNewOperNode(oper, type, op1, op2);

            impPushOnStack(op1);
            break;

        case CEE_NOT:

            op1 = impPopStack();
            impPushOnStack(gtNewOperNode(GT_NOT, op1->TypeGet(), op1));
            break;

        case CEE_CKFINITE:

            op1 = impPopStack();
            op1 = gtNewOperNode(GT_CKFINITE, op1->TypeGet(), op1);
            op1->gtFlags |= GTF_EXCEPT;

            impPushOnStack(op1);
            break;

        case CEE_LEAVE:

            val     = getI4LittleEndian(codeAddr); // jump distance
            jmpAddr = (codeAddr - info.compCode + sizeof(__int32)) + val;
            goto LEAVE;

        case CEE_LEAVE_S:
            val     = getI1LittleEndian(codeAddr); // jump distance
            jmpAddr = (codeAddr - info.compCode + sizeof(__int8 )) + val;
            goto LEAVE;

        LEAVE:
            // jmpAddr should be set to the jump target
            assertImp(jmpAddr < info.compCodeSize);
            assertImp(fgLookupBB(jmpAddr) != NULL); // should be a BB boundary
#ifdef DEBUG
            if (verbose) printf(" %04X", jmpAddr);
#endif
            /* CEE_LEAVE may be jumping out of a protected block, viz, a
               catch or a finally-protected try.
               We find the finally's protecting the current offset (in order)
               by walking over the complete exception table and finding
               enclosing clauses. This assumes that the table is sorted.
               For n finally, there will be n+1 blocks as shown ('*' indicates
               a BBF_INTERNAL block) created by fgFindBasicBlocks().
               --> BBJ_CALL(1), BBJ_CALL*(2), ... BBJ_CALL*(n), BBJ_ALWAYS*
               If we are leaving a catch handler, we need to attach the
               CPX_ENDCATCHes to the correct BBJ_CALL blocks.
             */

            BasicBlock *    callBlock; // Walks over the BBJ_CALL blocks
            unsigned        XTnum;
            EHblkDsc *      HBtab;

            for (XTnum = 0, HBtab = compHndBBtab, callBlock = block, op1 = NULL;
                 XTnum < info.compXcptnsCount;
                 XTnum++  , HBtab++)
            {
                unsigned tryBeg = HBtab->ebdTryBeg->bbCodeOffs;
                unsigned tryEnd = HBtab->ebdTryEnd->bbCodeOffs;
                unsigned hndBeg = HBtab->ebdHndBeg->bbCodeOffs;
                unsigned hndEnd = HBtab->ebdHndEnd ? HBtab->ebdHndEnd->bbCodeOffs : info.compCodeSize;

                if      ( jitIsBetween(block->bbCodeOffs, hndBeg, hndEnd) &&
                         !jitIsBetween(jmpAddr,           hndBeg, hndEnd))
                {
                    /* Is this a catch-handler we are CEE_LEAVEing out of?
                       If so, we need to call CPX_ENDCATCH */

                    assertImp(!(HBtab->ebdFlags & JIT_EH_CLAUSE_FINALLY)); // Cant CEE_LEAVE a finally
                    // Make a list of all the endCatches
                    op2 = gtNewHelperCallNode(CPX_ENDCATCH, TYP_VOID, GTF_CALL_REGSAVE);
                    op1 = op1 ? gtNewOperNode(GT_COMMA, TYP_VOID, op1, op2) : op2;
                }
                else if ((HBtab->ebdFlags & JIT_EH_CLAUSE_FINALLY)        &&
                          jitIsBetween(block->bbCodeOffs, tryBeg, tryEnd) &&
                         !jitIsBetween(jmpAddr,           tryBeg, tryEnd))
                {
                    /* We are CEE_LEAVEing out of a finally-protected try block.
                       We would have made a BBJ_CALL block for each finally. If
                       we have any CPX_ENDCATCH calls currently pending, insert
                       them in the current callBlock. Note that the finallys
                       and the endCatches have to called  in the correct order */

                    impAddEndCatches(callBlock, op1);
                    callBlock = callBlock->bbNext;
                    op1 = NULL;
                }
            }

            // Append any remaining endCatches
            assertImp(block == callBlock || ((callBlock->bbJumpKind == BBJ_ALWAYS) &&
                                             (callBlock->bbFlags & BBF_INTERNAL  )));
            impAddEndCatches(callBlock, op1);

            break;

        case CEE_BR:
        case CEE_BR_S:

#if HOIST_THIS_FLDS
            if  (block->bbNum >= block->bbJumpDest->bbNum)
                optHoistTFRhasLoop();
#endif
            if (opts.compDbgInfo && impCurStmtOffs == opcodeOffs)
            {
                // We dont create any statement for a branch. For debugging
                // info, we need a placeholder so that we can note the IL offset
                // in gtStmt.gtStmtOffs. So append an empty statement

                op1 = gtNewNothingNode();
                goto APPEND;
            }
            break;


        case CEE_BRTRUE:
        case CEE_BRTRUE_S:
        case CEE_BRFALSE:
        case CEE_BRFALSE_S:

            /* Pop the comparand (now there's a neat term) from the stack */

            op1 = impPopStack();

            if (block->bbJumpDest == block->bbNext)
            {
                block->bbJumpKind = BBJ_NONE;

                if (op1->gtFlags & GTF_GLOB_EFFECT)
                {
                    op1 = gtUnusedValNode(op1);
                    goto SPILL_APPEND;
                }
                else break;
            }

            if (op1->OperIsCompare())
            {
                if (opcode == CEE_BRFALSE || opcode == CEE_BRFALSE_S)
                {
                    // Flip the sense of the compare

                    op1 = gtReverseCond(op1);
                }
            }
            else
            {
                /* We'll compare against an equally-sized integer 0 */
                /* For small types, we always compare against int   */
                op2 = gtNewIconNode(0, genActualType(op1->gtType));

                /* Create the comparison operator and try to fold it */

                oper = (opcode==CEE_BRTRUE || opcode==CEE_BRTRUE_S) ? GT_NE
                                                                    : GT_EQ;
                op1 = gtNewOperNode(oper, TYP_INT , op1, op2);
            }

            // fall through

        COND_JUMP:

            /* Come here when the current block ends with a conditional jump */

            if (!opts.compMinOptim && !opts.compDbgCode)
                op1 = gtFoldExpr(op1);

            /* Try to fold the really dumb cases like 'iconst *, ifne/ifeq'*/

            if  (op1->gtOper == GT_CNS_INT)
            {
                assertImp(block->bbJumpKind == BBJ_COND);

                block->bbJumpKind = op1->gtIntCon.gtIconVal ? BBJ_ALWAYS
                                                            : BBJ_NONE;
#ifdef DEBUG
                if (verbose)
                {
                    if (op1->gtIntCon.gtIconVal)
                        printf("\nThe conditional jump becomes an unconditional jump to block #%02u\n",
                                                                         block->bbJumpDest->bbNum);
                    else
                        printf("\nThe block falls through into the next block #%02u\n",
                                                                         block->bbNext    ->bbNum);
                }
#endif
                break;
            }

#if HOIST_THIS_FLDS
            if  (block->bbNum >= block->bbJumpDest->bbNum)
                optHoistTFRhasLoop();
#endif

            op1 = gtNewOperNode(GT_JTRUE, TYP_VOID, op1, 0);
            goto SPILL_APPEND;


        case CEE_CEQ:    oper = GT_EQ; goto CMP_2_OPs;

        case CEE_CGT_UN:
        case CEE_CGT: oper = GT_GT; goto CMP_2_OPs;

        case CEE_CLT_UN:
        case CEE_CLT: oper = GT_LT; goto CMP_2_OPs;

CMP_2_OPs:
            /* Pull two values */

            op2 = impPopStack();
            op1 = impPopStack();

            assertImp(genActualType(op1->TypeGet()) ==
                      genActualType(op2->TypeGet()));

            /* Create the comparison node */

            op1 = gtNewOperNode(oper, TYP_INT, op1, op2);

                /* REVIEW: I am settng both flags when only one is approprate */
            if (opcode==CEE_CGT_UN || opcode==CEE_CLT_UN)
                op1->gtFlags |= GTF_CMP_NAN_UN | GTF_UNSIGNED;

            // @ISSUE :  The next opcode will almost always be a conditional
            // branch. Should we try to look ahead for it here ?

            impPushOnStack(op1);
            break;

        case CEE_BEQ_S:
        case CEE_BEQ:           oper = GT_EQ; goto CMP_2_OPs_AND_BR;

        case CEE_BGE_S:
        case CEE_BGE:           oper = GT_GE; goto CMP_2_OPs_AND_BR;

        case CEE_BGE_UN_S:
        case CEE_BGE_UN:        oper = GT_GE; goto CMP_2_OPs_AND_BR_UN;

        case CEE_BGT_S:
        case CEE_BGT:           oper = GT_GT; goto CMP_2_OPs_AND_BR;

        case CEE_BGT_UN_S:
        case CEE_BGT_UN:        oper = GT_GT; goto CMP_2_OPs_AND_BR_UN;

        case CEE_BLE_S:
        case CEE_BLE:           oper = GT_LE; goto CMP_2_OPs_AND_BR;

        case CEE_BLE_UN_S:
        case CEE_BLE_UN:        oper = GT_LE; goto CMP_2_OPs_AND_BR_UN;

        case CEE_BLT_S:
        case CEE_BLT:           oper = GT_LT; goto CMP_2_OPs_AND_BR;

        case CEE_BLT_UN_S:
        case CEE_BLT_UN:        oper = GT_LT; goto CMP_2_OPs_AND_BR_UN;

        case CEE_BNE_UN_S:
        case CEE_BNE_UN:        oper = GT_NE; goto CMP_2_OPs_AND_BR_UN;

        CMP_2_OPs_AND_BR_UN:    uns = true;  unordered = true;  goto CMP_2_OPs_AND_BR_ALL;
        CMP_2_OPs_AND_BR:       uns = false; unordered = false; goto CMP_2_OPs_AND_BR_ALL;
        CMP_2_OPs_AND_BR_ALL:

            /* Pull two values */

            op2 = impPopStack();
            op1 = impPopStack();

            assertImp(genActualType(op1->TypeGet()) == genActualType(op2->TypeGet()) ||
                      varTypeIsI(op1->TypeGet()) && varTypeIsI(op2->TypeGet()));

            if (block->bbJumpDest == block->bbNext)
            {
                block->bbJumpKind = BBJ_NONE;

                if (op1->gtFlags & GTF_GLOB_EFFECT)
                {
                    impSpillSideEffects();
                    impAppendTree(gtUnusedValNode(op1), impCurStmtOffs);
                }
                if (op2->gtFlags & GTF_GLOB_EFFECT)
                {
                    impSpillSideEffects();
                    impAppendTree(gtUnusedValNode(op2), impCurStmtOffs);
                }

#ifdef DEBUG
                if ((op1->gtFlags | op2->gtFlags) & GTF_GLOB_EFFECT)
                    impNoteLastILoffs();
#endif
                break;
            }

            /* Create and append the operator */

            op1 = gtNewOperNode(oper, TYP_INT , op1, op2);

            if (uns)
                op1->gtFlags |= GTF_UNSIGNED;

            if (unordered)
                op1->gtFlags |= GTF_CMP_NAN_UN;

            goto COND_JUMP;


        case CEE_SWITCH:

            /* Pop the switch value off the stack */

            op1 = impPopStack();
            assertImp(genActualType(op1->TypeGet()) == TYP_NAT_INT);

            /* We can create a switch node */

            op1 = gtNewOperNode(GT_SWITCH, TYP_VOID, op1, 0);

            /* Append 'op1' to the list of statements */

            impSpillSideEffects();
            impAppendTree(op1, impCurStmtOffs);
#ifdef DEBUG
            impNoteLastILoffs();
#endif
            return;

        /************************** Casting OPCODES ***************************/

        case CEE_CONV_OVF_I1:   lclTyp = TYP_BYTE  ;    goto CONV_OVF;
        case CEE_CONV_OVF_I2:   lclTyp = TYP_SHORT ;    goto CONV_OVF;
        case CEE_CONV_OVF_I :
        case CEE_CONV_OVF_I4:   lclTyp = TYP_INT   ;    goto CONV_OVF;
        case CEE_CONV_OVF_I8:   lclTyp = TYP_LONG  ;    goto CONV_OVF;

        case CEE_CONV_OVF_U1:   lclTyp = TYP_UBYTE ;    goto CONV_OVF;
        case CEE_CONV_OVF_U2:   lclTyp = TYP_CHAR  ;    goto CONV_OVF;
        case CEE_CONV_OVF_U :
        case CEE_CONV_OVF_U4:   lclTyp = TYP_UINT  ;    goto CONV_OVF;
        case CEE_CONV_OVF_U8:   lclTyp = TYP_ULONG ;    goto CONV_OVF;

        case CEE_CONV_OVF_I1_UN:   lclTyp = TYP_BYTE  ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_I2_UN:   lclTyp = TYP_SHORT ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_I_UN :
        case CEE_CONV_OVF_I4_UN:   lclTyp = TYP_INT   ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_I8_UN:   lclTyp = TYP_LONG  ;    goto CONV_OVF_UN;

        case CEE_CONV_OVF_U1_UN:   lclTyp = TYP_UBYTE ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_U2_UN:   lclTyp = TYP_CHAR  ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_U_UN :
        case CEE_CONV_OVF_U4_UN:   lclTyp = TYP_UINT  ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_U8_UN:   lclTyp = TYP_ULONG ;    goto CONV_OVF_UN;

CONV_OVF_UN:
            uns      = true;    goto CONV_OVF_COMMON;
CONV_OVF:
            uns      = false;
CONV_OVF_COMMON:
            callNode = false;
            ovfl     = true;

            // all overflow converts from floats get morphed to calls
            // only converts from floating point get morphed to calls
            if (impStackTop()->gtType == TYP_DOUBLE ||
                impStackTop()->gtType == TYP_FLOAT)
            {
                callNode = true;
            }
            goto _CONV;

        case CEE_CONV_I1:       lclTyp = TYP_BYTE  ;    goto CONV_CALL;
        case CEE_CONV_I2:       lclTyp = TYP_SHORT ;    goto CONV_CALL;
        case CEE_CONV_I:
        case CEE_CONV_I4:       lclTyp = TYP_INT   ;    goto CONV_CALL;
        case CEE_CONV_I8:
            lclTyp   = TYP_LONG;
            uns      = false;
            ovfl     = false;
            callNode = true;

            // I4 to I8 can be a small node
            if (impStackTop()->gtType == TYP_INT)
                callNode = false;
            goto _CONV;

        case CEE_CONV_U1:       lclTyp = TYP_UBYTE ;    goto CONV_CALL_UN;
        case CEE_CONV_U2:       lclTyp = TYP_CHAR  ;    goto CONV_CALL_UN;
        case CEE_CONV_U:
        case CEE_CONV_U4:       lclTyp = TYP_UINT  ;    goto CONV_CALL_UN;
        case CEE_CONV_U8:       lclTyp = TYP_ULONG ;    goto CONV_CALL_UN;
        case CEE_CONV_R_UN :    lclTyp = TYP_DOUBLE;    goto CONV_CALL_UN;

        case CEE_CONV_R4:       lclTyp = TYP_FLOAT;     goto CONV_CALL;
        case CEE_CONV_R8:       lclTyp = TYP_DOUBLE;    goto CONV_CALL;

CONV_CALL_UN:
            uns      = true;    goto CONV_CALL_COMMON;
CONV_CALL:
            uns      = false;
CONV_CALL_COMMON:
            ovfl     = false;
            callNode = true;
            goto _CONV;

_CONV:      // At this point uns, ovf, callNode all set
            op1  = impPopStack();

            impBashVarAddrsToI(op1);

            /* Check for a worthless cast, such as "(byte)(int & 32)" */

            if  (lclTyp < TYP_INT && op1->gtType == TYP_INT
                                  && op1->gtOper == GT_AND)
            {
                op2 = op1->gtOp.gtOp2;

                if  (op2->gtOper == GT_CNS_INT)
                {
                    int         ival = op2->gtIntCon.gtIconVal;
                    int         mask;

                    switch (lclTyp)
                    {
                    case TYP_BYTE :
                    case TYP_UBYTE: mask = 0x00FF; break;
                    case TYP_CHAR :
                    case TYP_SHORT: mask = 0xFFFF; break;

                    default:
                        assert(!"unexpected type");
                    }

                    if  ((ival & mask) == ival)
                    {
                        /* Toss the cast, it's a waste of time */

                        impPushOnStack(op1);
                        break;
                    }
                }
            }

            /*  The 'op2' sub-operand of a cast is the 'real' type number,
                since the result of a cast to one of the 'small' integer
                types is an integer.
             */

            op2  = gtNewIconNode(lclTyp);
            type = genActualType(lclTyp);

#if SMALL_TREE_NODES
            if (callNode)
            {
                /* These casts get transformed into 'GT_CALL' or 'GT_IND' nodes */

                assert(GenTree::s_gtNodeSizes[GT_CALL] >  GenTree::s_gtNodeSizes[GT_CAST]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] >= GenTree::s_gtNodeSizes[GT_IND ]);

                op1 = gtNewOperNode(GT_CALL, type, op1, op2);
                op1->ChangeOper(GT_CAST);
            }
#endif
            else
            {
                op1 = gtNewOperNode(GT_CAST, type, op1, op2);
            }
            if (ovfl)
                op1->gtFlags |= (GTF_OVERFLOW|GTF_EXCEPT);
            if (uns)
                op1->gtFlags |= GTF_UNSIGNED;
            impPushOnStack(op1);
            break;

        case CEE_NEG:

            op1 = impPopStack();

            impPushOnStack(gtNewOperNode(GT_NEG, genActualType(op1->gtType), op1));
            break;

        case CEE_POP:

            /* Pull the top value from the stack */

            op1 = impPopStack(clsHnd);

            /* Get hold of the type of the value being duplicated */

            lclTyp = genActualType(op1->gtType);

            /* Does the value have any side effects? */

            // CONSIDER: is this right? GTF_SIDE_EFFECT is not recurisvely set
            // so we could have LDFLD(CALL), which would be dropped.
            // granted, this is stupid code, but it is legal
            if  (op1->gtFlags & GTF_SIDE_EFFECT)
            {
                // Since we are throwing away the value, just normalize
                // it to its address.  This is more efficient.
                if (op1->TypeGet() == TYP_STRUCT)
                    op1 = impGetStructAddr(op1, clsHnd);

                // If 'op1' is an expression, create an assignment node.
                // Helps analyses (like CSE) to work fine.

                if (op1->gtOper != GT_CALL)
                    op1 = gtUnusedValNode(op1);

                /* Append the value to the tree list */
                goto SPILL_APPEND;
            }

            /* No side effects - just throw the thing away */
            break;


        case CEE_DUP:
            /* Spill any side effects from the stack */

            impSpillSideEffects();

            /* Pull the top value from the stack */

            op1 = impPopStack(clsHnd);

            /* Get hold of the type of the value being duplicated */
            lclTyp = genActualType(op1->gtType);

            /* Is the value simple enough to be cloneable? */
            op2 = gtClone(op1);
            if  (op2)
            {
                /* Cool - we can stuff two copies of the value back */
                impPushOnStack(op1, clsHnd);
                impPushOnStack(op2, clsHnd);
                break;
            }

            /* No luck - we'll have to introduce a temp */
            lclNum = lvaGrabTemp();

            /* Append the assignment to the temp/local */
            impAssignTempGen(lclNum, op1, clsHnd);

            /* If we haven't stored it, push the temp/local value back */
            impPushOnStack(gtNewLclvNode(lclNum, lclTyp), clsHnd);

            /* We'll put another copy of the local/temp in the stack */
            impPushOnStack(gtNewLclvNode(lclNum, lclTyp), clsHnd);
            break;

        case CEE_STIND_I1:      lclTyp  = TYP_BYTE;     goto STIND;
        case CEE_STIND_I2:      lclTyp  = TYP_SHORT;    goto STIND;
        case CEE_STIND_I4:      lclTyp  = TYP_INT;      goto STIND;
        case CEE_STIND_I8:      lclTyp  = TYP_LONG;     goto STIND;
        case CEE_STIND_I:       lclTyp  = TYP_I_IMPL;   goto STIND;
        case CEE_STIND_REF:     lclTyp  = TYP_REF;      goto STIND;
        case CEE_STIND_R4:      lclTyp  = TYP_FLOAT;    goto STIND;
        case CEE_STIND_R8:      lclTyp  = TYP_DOUBLE;   goto STIND;
STIND:
            op2 = impPopStack();    // value to store
            op1 = impPopStack();    // address to store to

            // you can indirect off of a TYP_I_IMPL (if we are in C) or a BYREF
            assertImp(genActualType(op1->gtType) == TYP_I_IMPL ||
                                    op1->gtType  == TYP_INT    ||  // HACK!!!!!!!??????
                                    op1->gtType  == TYP_BYREF);

            impBashVarAddrsToI(op1, op2);

            if (opcode == CEE_STIND_REF)
            {
                // STIND_REF can be used to store TYP_I_IMPL, TYP_REF, or TYP_BYREF
                assertImp(op2->gtType == TYP_I_IMPL || varTypeIsGC(op2->gtType));
                lclTyp = genActualType(op2->TypeGet());
            }

                // Check target type.
#ifdef DEBUG
            if (op2->gtType == TYP_BYREF || lclTyp == TYP_BYREF)
            {
                if (op2->gtType == TYP_BYREF)
                    assertImp(lclTyp == TYP_BYREF || lclTyp == TYP_I_IMPL);
                else if (lclTyp == TYP_BYREF)
                    assertImp(op2->gtType == TYP_BYREF ||op2->gtType == TYP_I_IMPL);
            }
            else
                assertImp(genActualType(op2->gtType) == genActualType(lclTyp));
#endif

            op1->gtFlags |= GTF_NON_GC_ADDR;

            op1 = gtNewOperNode(GT_IND, lclTyp, op1);
            op1->gtFlags |= GTF_IND_TGTANYWHERE;
            if (volatil)
            {
                // Not really needed as we dont CSE the target of an assignment
                op1->gtFlags |= GTF_DONT_CSE;
                volatil = false;
            }

            op1 = gtNewAssignNode(op1, op2);
            op1->gtFlags |= GTF_EXCEPT | GTF_GLOB_REF;

            // Spill side-effects AND global-data-accesses
            if (impStkDepth > 0)
                impSpillSideEffects(true);

            goto APPEND;


        case CEE_LDIND_I1:      lclTyp  = TYP_BYTE;     goto LDIND;
        case CEE_LDIND_I2:      lclTyp  = TYP_SHORT;    goto LDIND;
        case CEE_LDIND_U4:
        case CEE_LDIND_I4:      lclTyp  = TYP_INT;      goto LDIND;
        case CEE_LDIND_I8:      lclTyp  = TYP_LONG;     goto LDIND;
        case CEE_LDIND_REF:     lclTyp  = TYP_REF;      goto LDIND;
        case CEE_LDIND_I:       lclTyp  = TYP_I_IMPL;   goto LDIND;
        case CEE_LDIND_R4:      lclTyp  = TYP_FLOAT;    goto LDIND;
        case CEE_LDIND_R8:      lclTyp  = TYP_DOUBLE;   goto LDIND;
        case CEE_LDIND_U1:      lclTyp  = TYP_UBYTE;    goto LDIND;
        case CEE_LDIND_U2:      lclTyp  = TYP_CHAR;     goto LDIND;
LDIND:
            op1 = impPopStack();    // address to load from

            impBashVarAddrsToI(op1);

            assertImp(genActualType(op1->gtType) == TYP_I_IMPL ||
                                    op1->gtType  == TYP_INT    ||   // HACK!!!!!
                                    op1->gtType  == TYP_BYREF);

            op1->gtFlags |= GTF_NON_GC_ADDR;

            op1 = gtNewOperNode(GT_IND, lclTyp, op1);
            op1->gtFlags |= GTF_EXCEPT | GTF_GLOB_REF;

            if (volatil)
            {
                op1->gtFlags |= GTF_DONT_CSE;
                volatil = false;
            }

            impPushOnStack(op1);
            break;


        case CEE_UNALIGNED:
            val = getU1LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %u", val);
#endif
#if !TGT_x86
            assert(!"CEE_UNALIGNED NYI for risc");
#endif
            break;


        case CEE_VOLATILE:
            volatil = true;
            break;

        case CEE_LDFTN:
            // Need to do a lookup here so that we perform an access check
            // and do a NOWAY if protections are violated
            memberRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", memberRef);
#endif
            methHnd   = eeFindMethod(memberRef, info.compScopeHnd, info.compMethodHnd);

#if     TGT_IA64

            NatUns      offs;

#ifdef  DEBUG

            const char *name;

            name = eeGetMethodFullName(methHnd); // printf("method name = '%s'\n", name);

            if  (!genFindFunctionBody(name, &offs))
            {
                printf("// DANGER: Address taken of an unknown/external method '%s' !\n", name);
                offs = 0;
            }

#else

            offs = 0;

#endif

            op1 = gtNewIconHandleNode(memberRef, GTF_ICON_FTN_ADDR, offs);
            op1->gtVal.gtVal2 = offs;

#else

            // @TODO use the handle instead of the token.
            op1 = gtNewIconHandleNode(memberRef, GTF_ICON_FTN_ADDR, (unsigned)info.compScopeHnd);
            op1->gtVal.gtVal2 = (unsigned)info.compScopeHnd;

#endif

            op1->ChangeOper(GT_FTN_ADDR);
            op1->gtType = TYP_I_IMPL;
            impPushOnStack(op1);
            break;

        case CEE_LDVIRTFTN:

            /* Get the method token */

            memberRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", memberRef);
#endif
            methHnd   = eeFindMethod(memberRef, info.compScopeHnd, info.compMethodHnd);

            mflags = eeGetMethodAttribs(methHnd);
            if (mflags & (FLG_PRIVATE|FLG_FINAL|FLG_STATIC))
                NO_WAY("CEE_LDVIRTFTN cant be used on private/final/static");

            op2 = gtNewIconNode((long)methHnd);

            /* Get the object-ref */

            op1 = impPopStack();
            assertImp(op1->gtType == TYP_REF);

            clsFlags = eeGetClassAttribs(eeGetMethodClass(methHnd));

            // If the method has been added via EnC, then it wont exit
            // in the original vtable. So use a helper which will resolve it.

            if ((mflags & FLG_EnC) && !(clsFlags & FLG_INTERFACE))
            {
                op1 = gtNewHelperCallNode(CPX_EnC_RES_VIRT, TYP_I_IMPL, GTF_EXCEPT);
                impPushOnStack(op1);
                break;
            }

            /* For non-interface calls, get the vtable-ptr from the object */

            if (!(clsFlags & FLG_INTERFACE) || getNewCallInterface())
                op1 = gtNewOperNode(GT_IND, TYP_I_IMPL, op1);

            op1 = gtNewOperNode(GT_VIRT_FTN, TYP_I_IMPL, op1, op2);

            op1->gtFlags |= GTF_EXCEPT; // Null-pointer exception

            /*@TODO this shouldn't be marked as a call anymore */

            if (clsFlags & FLG_INTERFACE)
                op1->gtFlags |= GTF_CALL_INTF | GTF_CALL;

            impPushOnStack(op1);
            break;

        case CEE_TAILCALL:
            tailCall = true;
            break;

        case CEE_NEWOBJ:

            memberRef = getU4LittleEndian(codeAddr);
            methHnd = eeFindMethod(memberRef, info.compScopeHnd, info.compMethodHnd);
            if (!methHnd) NO_WAY("no constructor for newobj found?");

            assertImp((eeGetMethodAttribs(methHnd) & FLG_STATIC) == 0);  // constructors are not static

            clsHnd = eeGetMethodClass(methHnd);

                // There are three different cases for new
                // Object size is variable (depends on arguments)
                //      1) Object is an array (arrays treated specially by the EE)
                //      2) Object is some other variable sized object (e.g. String)
                // 3) Class Size can be determined beforehand (normal case
                // In the first case, we need to call a NEWOBJ helper (multinewarray)
                // in the second case we call the constructor with a '0' this pointer
                // In the third case we alloc the memory, then call the constuctor

            clsFlags = eeGetClassAttribs(clsHnd);

            if (clsFlags & FLG_ARRAY)
            {
                // Arrays need to call the NEWOBJ helper.
                assertImp(clsFlags & FLG_VAROBJSIZE);

                /* The varargs helper needs the scope and method token as last
                   and  last-1 param (this is a cdecl call, so args will be
                   pushed in reverse order on the CPU stack) */

                op1 = gtNewIconEmbScpHndNode(info.compScopeHnd);
                op1 = gtNewOperNode(GT_LIST, TYP_VOID, op1);

                op2 = gtNewIconNode(memberRef, TYP_INT);
                op2 = gtNewOperNode(GT_LIST, TYP_VOID, op2, op1);

                eeGetMethodSig(methHnd, &sig);
                assertImp(sig.numArgs);

                flags = 0;
                op2 = impPopList(sig.numArgs, &flags, op2);

                op1 = gtNewHelperCallNode(  CPX_NEWOBJ,
                                            TYP_REF,
                                            GTF_CALL_REGSAVE,
                                            op2 );

                // varargs, so we pop the arguments
                op1->gtFlags |= GTF_CALL_POP_ARGS;

#ifdef DEBUG
                // At the present time we don't track Caller pop arguments
                // that have GC references in them
                GenTreePtr temp = op2;
                while(temp != 0)
                {
                    assertImp(temp->gtOp.gtOp1->gtType != TYP_REF);
                    temp = temp->gtOp.gtOp2;
                }
#endif
                op1->gtFlags |= op2->gtFlags & GTF_GLOB_EFFECT;

                impPushOnStack(op1);
                break;
            }
            else if (clsFlags & FLG_VAROBJSIZE)
            {
                // This is the case for varible sized objects that are not
                // arrays.  In this case, call the constructor with a null 'this'
                // pointer
                thisPtr = gtNewIconNode(0, TYP_REF);
            }
            else
            {
                // This is the normal case where the size of the object is
                // fixed.  Allocate the memory and call the constructor.

                /* get a temporary for the new object */
                lclNum = lvaGrabTemp();

                if (clsFlags & FLG_VALUECLASS)
                {
                    // The local variable itself is the alloated space
                    lvaAggrTableTempsSet(lclNum, TYP_STRUCT, (SIZE_T) clsHnd);
                    thisPtr = gtNewOperNode(GT_ADDR,
                                            ((clsFlags & FLG_UNMANAGED) ? TYP_I_IMPL : TYP_BYREF),
                                            gtNewLclvNode(lclNum, TYP_STRUCT));
                    thisPtr->gtFlags |= GTF_ADDR_ONSTACK;
                }
                else
                {
                    // Can we directly access the class handle ?

                    op1 = gtNewIconEmbClsHndNode(clsHnd);

                    op1 = gtNewHelperCallNode(  eeGetNewHelper(clsHnd, info.compMethodHnd),
                                                TYP_REF,
                                                GTF_CALL_REGSAVE,
                                                gtNewArgList(op1));

                    /* We will append a call to the stmt list
                     * Must spill side effects from the stack */

                    impSpillSideEffects();

                    /* Append the assignment to the temp/local */
                    impAssignTempGen(lclNum, op1);

                    thisPtr = gtNewLclvNode(lclNum, TYP_REF);
                }

            }
            goto CALL;

        case CEE_CALLI:

            /* Get the call sig */

            memberRef = getU4LittleEndian(codeAddr);
            goto CALL;

        case CEE_CALLVIRT:
        case CEE_CALL:

            /* Get the method token */

            memberRef = getU4LittleEndian(codeAddr);

    CALL:   // memberRef should be set.
            // thisPtr should be set for CEE_NEWOBJ

#ifdef DEBUG
            if (verbose) printf(" %08X", memberRef);
#endif
            callTyp = impImportCall(opcode, memberRef, thisPtr,
                                    tailCall, &vcallTemp);

            if (tailCall)
                goto RET;

            break;


        case CEE_LDFLD:
        case CEE_LDSFLD:
        case CEE_LDFLDA:
        case CEE_LDSFLDA:

            /* Get the CP_Fieldref index */
            assertImp(sz == sizeof(unsigned));
            memberRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", memberRef);
#endif
            fldHnd = eeFindField(memberRef, info.compScopeHnd, info.compMethodHnd);

            /* Figure out the type of the member */
            lclTyp = eeGetFieldType(fldHnd, &clsHnd);

            /* Preserve 'small' int types */
            if  (lclTyp > TYP_INT) lclTyp = genActualType(lclTyp);

            /* Get hold of the flags for the member */

            mflags = eeGetFieldAttribs(fldHnd);

#ifndef NOT_JITC
            /* In stand alone mode, ensure 'mflags' is consistant with opcode */
            if  (opcode == CEE_LDSFLD || opcode == CEE_LDSFLDA)
                mflags |= FLG_STATIC;
#endif

            needUnwrap = false;
            if  (getContextEnabled() &&
                 (lclTyp == TYP_REF) &&
                 (eeGetClassAttribs(clsHnd)&FLG_CONTEXTFUL))
            {
                needUnwrap =
                    ((mflags & FLG_STATIC) ||
                     (eeGetClassAttribs(eeGetFieldClass(fldHnd)) & FLG_CONTEXTFUL) == 0);
            }

            /* Is this a 'special' (COM) field? */

            if  (mflags & CORINFO_FLG_HELPER)
            {
                assertImp(!(mflags & FLG_STATIC));     // com fields can only be non-static
                    // TODO: Can we support load field adr on com objects?
                if  (opcode == CEE_LDFLDA)
                    NO_WAY("JIT doesn't support LDFLDA on com object fields");
                op1 = gtNewRefCOMfield(impPopStack(), memberRef, lclTyp, 0);
            }
            else if ((mflags & FLG_EnC) && !(mflags & FLG_STATIC))
            {
                /* We call a helper function to get the address of the
                   EnC-added non-static field. */

                GenTreePtr obj = impPopStack();

                op1 = gtNewOperNode(GT_LIST,
                                     TYP_VOID,
                                     gtNewIconEmbFldHndNode(fldHnd,
                                                            memberRef,
                                                            info.compScopeHnd));

                op1 = gtNewOperNode(GT_LIST, TYP_VOID, obj, op1);

                op1 = gtNewHelperCallNode(  CPX_GETFIELDADDR,
                                            TYP_BYREF,
                                            (obj->gtFlags & GTF_GLOB_EFFECT) | GTF_EXCEPT,
                                            op1);

                assertImp(opcode == CEE_LDFLD || opcode == CEE_LDFLDA);
                if (opcode == CEE_LDFLD)
                    op1 = gtNewOperNode(GT_IND, lclTyp, op1);
            }
            else
            {
                /* Create the data member node */

                op1 = gtNewFieldRef(lclTyp, fldHnd);

                if (mflags & FLG_TLS)   // fpMorphField will handle the transformation
                    op1->gtFlags |= GTF_IND_TLS_REF;

                    /* Pull the object's address if opcode say it is non-static */
                GenTreePtr      obj = 0;
                CLASS_HANDLE    objType;        // used for fields

                if  (opcode == CEE_LDFLD || opcode == CEE_LDFLDA)
                {
                    obj = impPopStack(objType);
                    if (obj->TypeGet() != TYP_STRUCT)
                        obj = impCheckForNullPointer(obj);
                }

                if  (!(mflags & FLG_STATIC))
                {
                    if (obj == 0)         NO_WAY("LDSFLD done on an instance field.");
                    if (mflags & FLG_TLS) NO_WAY("instance field can not be a TLS ref.");

                        // If the object is a struct, what we really want is
                        // for the field to operate on the address of the struct.
                    if (obj->TypeGet() == TYP_STRUCT)
                    {
                        assert(opcode == CEE_LDFLD);
                        obj = impGetStructAddr(obj, objType);
                    }

                    op1->gtField.gtFldObj = obj;

#if HOIST_THIS_FLDS
                    if  (obj->gtOper == GT_LCL_VAR && !obj->gtLclVar.gtLclNum)
                        optHoistTFRrecRef(fldHnd, op1);
#endif

                    op1->gtFlags |= (obj->gtFlags & GTF_GLOB_EFFECT) | GTF_EXCEPT;

                        // wrap it in a address of operator if necessary
                    if (opcode == CEE_LDFLDA)
                    {
#ifdef DEBUG
                        clsHnd = BAD_CLASS_HANDLE;
#endif
                        op1 = gtNewOperNode(GT_ADDR, varTypeIsGC(obj->TypeGet()) ?
                                                     TYP_BYREF : TYP_I_IMPL, op1);
                    }
                }
                else
                {
                    CLASS_HANDLE fldClass = eeGetFieldClass(fldHnd);
                    DWORD  fldClsAttr = eeGetClassAttribs(fldClass);

                    if  (fldClsAttr & FLG_GLOBVAR)
                    {
                        assert(obj == NULL && (fldClsAttr & FLG_UNMANAGED));

                        val = eeGetFieldAddress(fldHnd);
#ifdef DEBUG
//                      if (verbose) printf(" %08X", val);
#endif
                        val = (int)eeFindPointer(info.compScopeHnd, val);
#if     TGT_IA64
// UNDONE: We should use a 64-bit integer constant node for the address, right?
#endif
                        op1 = gtNewIconHandleNode(val, GTF_ICON_PTR_HDL);

                        assert(opcode == CEE_LDSFLDA || opcode == CEE_LDSFLD);

                        if  (opcode == CEE_LDSFLD)
                        {
                            // bizarre hack, not sure why it's needed

                            if  (op1->gtType == TYP_INT)
                                 op1->gtType  = TYP_I_IMPL;

                            op1 = gtNewOperNode(GT_IND, lclTyp, op1);
                        }

                        if  (op1->gtType == TYP_STRUCT)
                            impPushOnStack(op1, clsHnd);
                        else
                            impPushOnStack(op1);

                        break;
                    }

                    if (obj && (obj->gtFlags & GTF_SIDE_EFFECT))
                    {
                        /* We are using ldfld/a on a static field. We allow
                           it, but need to get side-effect from obj */

                        obj = gtUnusedValNode(obj);
                        impAppendTree(obj, impCurStmtOffs);
                    }

                    // @TODO : This is a hack. The EE will give us the handle to
                    // the boxed object. We then access the unboxed object from it.
                    // Remove when our story for static value classes changes.

                    if (lclTyp == TYP_STRUCT && !(fldClsAttr & FLG_UNMANAGED))
                    {
                        op1->gtType = TYP_REF;          // points at boxed object
#if     TGT_IA64
                        op2 = gtNewIconNode(            8, TYP_I_IMPL);
#else
                        op2 = gtNewIconNode(sizeof(void*), TYP_I_IMPL);
#endif
                        op1 = gtNewOperNode(GT_ADD, TYP_BYREF, op1, op2);
                        op1 = gtNewOperNode(GT_IND, TYP_STRUCT, op1);
                    }

                    // wrap it in a address of operator if necessary
                    if (opcode == CEE_LDSFLDA || opcode == CEE_LDFLDA)
                    {
#ifdef DEBUG
                        clsHnd = BAD_CLASS_HANDLE;
#endif
                        op1 = gtNewOperNode(GT_ADDR,
                                            (fldClsAttr & FLG_UNMANAGED) ? TYP_I_IMPL : TYP_BYREF,
                                            op1);
                    }

#ifdef NOT_JITC
                    /* For static fields check if the class is initialized or is our current class
                     * otherwise create the helper call node */

                    if ((eeGetMethodClass(info.compMethodHnd) != fldClass) &&
                        !(fldClsAttr & FLG_INITIALIZED))
                    {
                        GenTreePtr  helperNode;

                        helperNode = gtNewIconEmbClsHndNode(fldClass,
                                                            memberRef,
                                                            info.compScopeHnd);

                        helperNode = gtNewHelperCallNode(CPX_INIT_CLASS,
                                                     TYP_VOID,
                                                     GTF_CALL_REGSAVE,
                                                     gtNewArgList(helperNode));

                        op1 = gtNewOperNode(GT_COMMA, op1->TypeGet(), helperNode, op1);
                    }
#endif
                }
            }

            if (needUnwrap)
            {
                assert(getContextEnabled());
                assertImp(op1->gtType == TYP_REF);

                op1 = gtNewArgList(op1);

                op1 = gtNewHelperCallNode(CPX_UNWRAP, TYP_REF, GTF_CALL_REGSAVE, op1);
            }

            impPushOnStack(op1, clsHnd);
            break;

        case CEE_STFLD:
        case CEE_STSFLD:

            /* Get the CP_Fieldref index */

            assertImp(sz == sizeof(unsigned));
            memberRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", memberRef);
#endif
            fldHnd = eeFindField(memberRef, info.compScopeHnd, info.compMethodHnd);

            /* Figure out the type of the member */

            lclTyp  = eeGetFieldType  (fldHnd, &clsHnd);
            mflags  = eeGetFieldAttribs(fldHnd);

#ifndef NOT_JITC
                /* In stand alone mode, make certain 'mflags' is constant with opcode */
            if  (opcode == CEE_STSFLD)
                mflags |= FLG_STATIC;
#endif

            if (!eeCanPutField(fldHnd, mflags, 0, info.compMethodHnd))
                NO_WAY("Illegal access of final field");

            /* Preserve 'small' int types */

            if  (lclTyp > TYP_INT) lclTyp = genActualType(lclTyp);

            needWrap = 0;

            /* Check the targets type (i.e. is it contextbound or not) */
            if  (getContextEnabled() &&
                 (lclTyp == TYP_REF) && (mflags & FLG_STATIC))
            {
                if (!(eeGetClassAttribs(clsHnd) & FLG_OBJECT))
                    needWrap = true;
            }

            /* Pull the value from the stack */

            op2 = impPopStack(clsHnd);

            /* Spill any refs to the same member from the stack */

            impSpillLclRefs((int)fldHnd);

            /* Don't need to wrap if the value isn't contextful */

            needWrap = needWrap && ((op2->gtFlags & GTF_CONTEXTFUL) != 0);

            /* Is this a 'special' (COM) field? */

            if  (mflags & CORINFO_FLG_HELPER)
            {
                assertImp(opcode == CEE_STFLD);    // can't be static

                op1 = gtNewRefCOMfield(impPopStack(), memberRef, lclTyp, op2);
                goto SPILL_APPEND;
            }

            if ((mflags & FLG_EnC) && !(mflags & FLG_STATIC))
            {
                /* We call a helper function to get the address of the
                   EnC-added non-static field. */

                GenTreePtr obj = impPopStack();

                op1 = gtNewOperNode(GT_LIST,
                                     TYP_VOID,
                                     gtNewIconEmbFldHndNode(fldHnd,
                                                            memberRef,
                                                            info.compScopeHnd));

                op1 = gtNewOperNode(GT_LIST, TYP_VOID, obj, op1);

                op1 = gtNewHelperCallNode(  CPX_GETFIELDADDR,
                                            TYP_BYREF,
                                            (obj->gtFlags & GTF_GLOB_EFFECT) | GTF_EXCEPT,
                                            op1);

                op1 = gtNewOperNode(GT_IND, lclTyp, op1);
            }
            else
            {
                /* Create the data member node */

                op1 = gtNewFieldRef(lclTyp, fldHnd);

                if (mflags & FLG_TLS)   // fpMorphField will handle the transformation
                    op1->gtFlags |= GTF_IND_TLS_REF;

                /* Pull the object's address if opcode say it is non-static */
                GenTreePtr      obj = 0;
                if  (opcode == CEE_STFLD)
                {
                    obj = impPopStack();
                    obj = impCheckForNullPointer(obj);
                }

                if  (mflags & FLG_STATIC)
                {
                    if (obj && (obj->gtFlags & GTF_SIDE_EFFECT))
                    {
                        /* We are using stfld on a static field. We allow
                           it, but need to get side-effect from obj */

                        obj = gtUnusedValNode(obj);
                        impAppendTree(obj, impCurStmtOffs);
                    }

                    // @TODO : This is a hack. The EE will give us the handle to
                    // the boxed object. We then access the unboxed object from it.
                    // Remove when our story for static value classes changes.
                    if (lclTyp == TYP_STRUCT && (opcode == CEE_STSFLD))
                    {
                        op1->gtType = TYP_REF; // points at boxed object
                        op1 = gtNewOperNode(GT_ADD, TYP_BYREF,
                                            op1, gtNewIconNode(sizeof(void*), TYP_I_IMPL));
                        op1 = gtNewOperNode(GT_IND, TYP_STRUCT, op1);
                    }
                }
                else
                {
                    if (obj == 0)         NO_WAY("STSFLD done on an instance field.");
                    if (mflags & FLG_TLS) NO_WAY("instance field can not be a TLS ref.");

                    op1->gtField.gtFldObj = obj;

#if HOIST_THIS_FLDS
                    if  (obj->gtOper == GT_LCL_VAR && !obj->gtLclVar.gtLclNum)
                        optHoistTFRrecDef(fldHnd, op1);
#endif

                    op1->gtFlags |= (obj->gtFlags & GTF_GLOB_EFFECT) | GTF_EXCEPT;

#if GC_WRITE_BARRIER_CALL
                    if (obj->gtType == TYP_BYREF)
                        op1->gtFlags |= GTF_IND_TGTANYWHERE;
#endif
                }
            }

            if (needWrap)
            {
                assert(getContextEnabled());
                assertImp(op1->gtType == TYP_REF);

                op2 = gtNewArgList(op2);

                op2 = gtNewHelperCallNode(CPX_WRAP, TYP_REF, GTF_CALL_REGSAVE, op2);

            }

            /* Create the member assignment */
            if (lclTyp == TYP_STRUCT)
                op1 = impAssignStruct(op1, op2, clsHnd);
            else
                op1 = gtNewAssignNode(op1, op2);

            /* Mark the expression as containing an assignment */

            op1->gtFlags |= GTF_ASG;

#ifdef NOT_JITC
            if  (mflags & FLG_STATIC)
            {
                /* For static fields check if the class is initialized or is our current class
                 * otherwise create the helper call node */

                CLASS_HANDLE fldClass = eeGetFieldClass(fldHnd);

                if ((eeGetMethodClass(info.compMethodHnd) != fldClass) &&
                    !(eeGetClassAttribs(fldClass) & FLG_INITIALIZED))
                {
                    GenTreePtr  helperNode;

                    helperNode = gtNewIconEmbClsHndNode(fldClass,
                                                        memberRef,
                                                        info.compScopeHnd);

                    helperNode = gtNewHelperCallNode(CPX_INIT_CLASS,
                                                 TYP_VOID,
                                                 GTF_CALL_REGSAVE,
                                                 gtNewArgList(helperNode));

                    op1 = gtNewOperNode(GT_COMMA, op1->TypeGet(), helperNode, op1);
                }
            }
#endif

            goto SPILL_APPEND;

        case CEE_NEWARR:

            /* Get the class type index operand */

            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif
            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);

#ifdef NOT_JITC
            clsHnd = info.compCompHnd->getSDArrayForClass(clsHnd);
            if (clsHnd == 0)
                NO_WAY("Can't get array class");
#endif

            /* Form the arglist: array class handle, size */

            op2 = gtNewIconEmbClsHndNode(clsHnd,
                                         typeRef,
                                         info.compScopeHnd);

            op2 = gtNewOperNode(GT_LIST, TYP_VOID,           op2, 0);
            op2 = gtNewOperNode(GT_LIST, TYP_VOID, impPopStack(), op2);

            /* Create a call to 'new' */

            op1 = gtNewHelperCallNode(CPX_NEWARR_1_DIRECT,
                                      TYP_REF,
                                      GTF_CALL_REGSAVE,
                                      op2);
            /* Remember that this basic block contains 'new' of an array */

            block->bbFlags |= BBF_NEW_ARRAY;

            /* Push the result of the call on the stack */

            impPushOnStack(op1);
            break;

        case CEE_LOCALLOC:

            /* The FP register may not be back to the original value at the end
               of the method, even if the frame size is 0, as localloc may
               have modified it. So we will HAVE to reset it */

            compLocallocUsed                = true;

            // Get the size to allocate

            op2 = impPopStack();
            assertImp(genActualType(op2->gtType) == TYP_INT);

            if (impStkDepth != 0)
                NO_WAY("Localloc can only be used when the stack is empty");

            op1 = gtNewOperNode(GT_LCLHEAP, TYP_I_IMPL, op2);

            // May throw a stack overflow excptn

            op1->gtFlags |= (GTF_EXCEPT | GTF_NON_GC_ADDR);

            impPushOnStack(op1);
            break;


        case CEE_ISINST:

            /* Get the type token */

            assertImp(sz == sizeof(unsigned));
            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif

            /* Pop the address and create the 'instanceof' helper call */

            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);

            op2 = gtNewIconEmbClsHndNode(clsHnd,
                                         typeRef,
                                         info.compScopeHnd);
            op2 = gtNewArgList(op2, impPopStack());

            op1 = gtNewHelperCallNode(eeGetIsTypeHelper(clsHnd), TYP_INT,
                                      GTF_CALL_REGSAVE, op2);

            /* The helper does not normalize true values to 1, so we do it here */

            op2  = gtNewIconNode(0, TYP_REF);

            op1 = gtNewOperNode(GT_NE, TYP_INT , op1, op2);

            /* Push the result back on the stack */

            impPushOnStack(op1);
            break;

        case CEE_REFANYVAL:
            op1 = impPopStack();

                // get the class handle and make a ICON node out of it
            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif
                // make certain it is normalized;
            op1 = impNormStructVal(op1, REFANY_CLASS_HANDLE);
            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);

            op2 = gtNewIconEmbClsHndNode(clsHnd,
                                         typeRef,
                                         info.compScopeHnd);

                // Call helper GETREFANY(classHandle,op1);
            op2 = gtNewArgList(op2, op1);
            op1 = gtNewHelperCallNode(CPX_GETREFANY, TYP_BYREF, GTF_CALL_REGSAVE, op2);

                /* Push the result back on the stack */
            impPushOnStack(op1);
            break;

        case CEE_REFANYTYPE:
            op1 = impPopStack();
                // make certain it is normalized;
            op1 = impNormStructVal(op1, REFANY_CLASS_HANDLE);

            if (op1->gtOper == GT_LDOBJ) {
                // Get the address of the refany
                op1 = op1->gtOp.gtOp1;

                // Fetch the type from the correct slot
                op1 = gtNewOperNode(GT_ADD, TYP_BYREF, op1, gtNewIconNode(offsetof(JIT_RefAny, type)));
                op1 = gtNewOperNode(GT_IND, TYP_BYREF, op1);
            }
            else {
                assertImp(op1->gtOper == GT_MKREFANY);
                                        // we know its literal value
                op1 = gtNewIconEmbClsHndNode(op1->gtLdObj.gtClass, 0, 0);
            }
                /* Push the result back on the stack */
            impPushOnStack(op1);
            break;

        case CEE_LDTOKEN:
                /* Get the Class index */
            assertImp(sz == sizeof(unsigned));
            val = getU4LittleEndian(codeAddr);

            void * embedGenHnd, * pEmbedGenHnd;
            embedGenHnd = embedGenericHandle(val, info.compScopeHnd, info.compMethodHnd, &pEmbedGenHnd);

            op1 = gtNewIconEmbHndNode(embedGenHnd, pEmbedGenHnd, GTF_ICON_TOKEN_HDL);
            impPushOnStack(op1);
            break;

        case CEE_UNBOX:
            /* Get the Class index */
            assertImp(sz == sizeof(unsigned));

            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif
            /* Pop the address and create the unbox helper call */

            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);

            op2 = gtNewIconEmbClsHndNode(clsHnd,
                                         typeRef,
                                         info.compScopeHnd);
            op1 = impPopStack();
            assertImp(op1->gtType == TYP_REF);
            op2 = gtNewArgList(op2, op1);

            op1 = gtNewHelperCallNode(CPX_UNBOX, TYP_BYREF, GTF_CALL_REGSAVE, op2);

            /* Push the result back on the stack */

            impPushOnStack(op1);
            break;

        case CEE_BOX:
			assert(!"BOXVAL NYI");
            break;

        case CEE_SIZEOF:
            /* Get the Class index */
            assertImp(sz == sizeof(unsigned));
            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif
            /* Pop the address and create the box helper call */

            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);
            op1 = gtNewIconNode(eeGetClassSize(clsHnd));
            impPushOnStack(op1);
            break;

        case CEE_CASTCLASS:

            /* Get the Class index */

            assertImp(sz == sizeof(unsigned));
            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif
            /* Pop the address and create the 'checked cast' helper call */

            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);

            op2 = gtNewIconEmbClsHndNode(clsHnd,
                                         typeRef,
                                         info.compScopeHnd);
            op2 = gtNewArgList(op2, impPopStack());

            op1 = gtNewHelperCallNode(eeGetChkCastHelper(clsHnd), TYP_REF, GTF_CALL_REGSAVE, op2);

            /* Push the result back on the stack */

            impPushOnStack(op1);
            break;

        case CEE_THROW:

            /* Pop the exception object and create the 'throw' helper call */

            op1 = gtNewHelperCallNode(CPX_THROW,
                                      TYP_VOID,
                                      GTF_CALL_REGSAVE,
                                      gtNewArgList(impPopStack()));

EVAL_APPEND:
            if (impStkDepth > 0)
                impEvalSideEffects();

            assert(impStkDepth == 0);

            goto APPEND;

        case CEE_RETHROW:

            /* Create the 'rethrow' helper call */

            op1 = gtNewHelperCallNode(CPX_RETHROW, TYP_VOID, GTF_CALL_REGSAVE);

            goto EVAL_APPEND;

        case CEE_INITOBJ:
            /*HACKHACK - this instruction is no longer supported */
            /* remove this as soon as we wean cool from it */
//          assertImp(!"initobj is no longer supported");
            assertImp(sz == sizeof(unsigned));
            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif
            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);

            op1 = gtNewIconNode(eeGetClassSize(clsHnd));
            op2 = gtNewIconNode(0);
            goto  INITBLK_OR_INITOBJ;

        case CEE_INITBLK:

            op1 = impPopStack();        // Size
            op2 = impPopStack();        // Value
        INITBLK_OR_INITOBJ:
            arr = impPopStack();        // Addr

            op2 = gtNewOperNode(GT_LIST,    TYP_VOID,   //      GT_INITBLK
                                arr,        op2);       //      /        \.
            op1 = gtNewOperNode(GT_INITBLK, TYP_VOID,   // GT_LIST(op2)  [size]
                                op2,        op1);       //   /    \
                                                        // [addr] [val]

            op2->gtOp.gtOp1->gtFlags |= GTF_NON_GC_ADDR;

            assertImp(genActualType(op2->gtOp.gtOp1->gtType) == TYP_I_IMPL ||
                      genActualType(op2->gtOp.gtOp1->gtType) == TYP_BYREF);
            assertImp(genActualType(op2->gtOp.gtOp2->gtType) == TYP_INT );
            assertImp(genActualType(op1->gtOp.gtOp2->gtType) == TYP_INT );

            if (op2->gtOp.gtOp1->gtType == TYP_LONG)
            {
                op2->gtOp.gtOp1 =
                    gtNewOperNode(  GT_CAST, TYP_INT,
                                    op2->gtOp.gtOp1,
                                    gtNewIconNode((int)TYP_I_IMPL));
            }

            op1->gtFlags |= (GTF_EXCEPT | GTF_GLOB_REF);
            goto SPILL_APPEND;

        case CEE_CPOBJ:
            assertImp(sz == sizeof(unsigned));
            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif
            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);

            op1 = impGetCpobjHandle(clsHnd);
            goto  CPBLK_OR_CPOBJ;

        case CEE_CPBLK:
            op1 = impPopStack();        // Size
            goto CPBLK_OR_CPOBJ;

        CPBLK_OR_CPOBJ:
            assert(op1->gtType == TYP_INT); // should be size (CEE_CPBLK) or clsHnd (CEE_CPOBJ)
            op2 = impPopStack();        // Src
            arr = impPopStack();        // Dest

#if 0   // do we need this ???

            if  (op1->gtOper == GT_CNS_INT)
            {
                size_t          sz = op1->gtIntCon.gtIconVal;

                if  (sz > 16)
                    genUsesArLc = true;
            }
#endif

            op1 = gtNewCpblkNode(arr, op2, op1);
            if (volatil) volatil = false; // We never CSE cpblk
            goto SPILL_APPEND;

        case CEE_STOBJ:
            assertImp(sz == sizeof(unsigned));
            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf(" %08X", typeRef);
#endif
            clsHnd = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);

            op2 = impPopStack();        // Value
            op1 = impPopStack();        // Ptr
            assertImp(op2->TypeGet() == TYP_STRUCT);

            op1 = impAssignStructPtr(op1, op2, clsHnd);
            if (volatil) volatil = false; // We never CSE cpblk
            goto SPILL_APPEND;

        case CEE_MKREFANY:
            oper = GT_MKREFANY;
            goto LDOBJ_OR_MKREFANY;

        case CEE_LDOBJ:
            oper = GT_LDOBJ;
        LDOBJ_OR_MKREFANY:
            assertImp(sz == sizeof(unsigned));
            typeRef = getU4LittleEndian(codeAddr);
#ifdef DEBUG
            if (verbose) printf("%08X", typeRef);
#endif
            op1 = impPopStack();

            assertImp(op1->TypeGet() == TYP_BYREF || op1->TypeGet() == TYP_I_IMPL);

                    // LDOBJ (or MKREFANY) returns a struct
            op1 = gtNewOperNode(oper, TYP_STRUCT, op1);

                // It takes the pointer to the struct to load
            op1->gtOp.gtOp1->gtFlags |= GTF_NON_GC_ADDR;
            op1->gtFlags |= (GTF_EXCEPT | GTF_GLOB_REF);

                // and an inline argument which is the class token of the loaded obj
            op1->gtLdObj.gtClass = eeFindClass(typeRef, info.compScopeHnd, info.compMethodHnd);

#ifdef NOT_JITC
            if (oper == GT_LDOBJ) {
                JIT_types jitTyp = info.compCompHnd->asPrimitiveType(op1->gtLdObj.gtClass);
                if (jitTyp != JIT_TYP_UNDEF)
                {
                                        op1->gtOper = GT_IND;
                    op1->gtType = JITtype2varType(jitTyp);
                                        op1->gtOp.gtOp2 = 0;            // must be zero for tree walkers
                    assertImp(varTypeIsArithmetic(op1->gtType));
                }
            }
#endif
                        impPushOnStack(op1, op1->gtLdObj.gtClass);
                        if (volatil) volatil = false; // We never CSE ldblk
            break;

        case CEE_LDLEN:
#if RNGCHK_OPT
            if  (!opts.compMinOptim && !opts.compDbgCode)
            {
                /* Use GT_ARR_LENGTH operator so rng check opts see this */
                op1 = gtNewOperNode(GT_ARR_LENGTH, TYP_INT, impPopStack());
            }
            else
#endif
            {
                /* Create the expression "*(array_addr + ARR_ELCNT_OFFS)" */
                op1 = gtNewOperNode(GT_ADD, TYP_REF, impPopStack(),
                                                     gtNewIconNode(ARR_ELCNT_OFFS,
                                                                   TYP_INT));

                op1 = gtNewOperNode(GT_IND, TYP_INT, op1);
            }

            /* An indirection will cause a GPF if the address is null */
            op1->gtFlags |= GTF_EXCEPT;

            /* Push the result back on the stack */
            impPushOnStack(op1);
            break;

        case CEE_BREAK:
            op1 = gtNewHelperCallNode(CPX_USER_BREAKPOINT, TYP_VOID);
            goto SPILL_APPEND;

        case CEE_NOP:
            if (opts.compDbgCode)
            {
                op1 = gtNewOperNode(GT_NO_OP, TYP_VOID);
                goto SPILL_APPEND;
            }
            break;

         // OptIL annotations. Just skip

        case CEE_ANN_DATA:
            assertImp(sz == 4);
            sz += getU4LittleEndian(codeAddr);
            break;

        case CEE_ANN_PHI :
            codeAddr += getU1LittleEndian(codeAddr) * 2 + 1;
            break;

        case CEE_ANN_CALL :
        case CEE_ANN_HOISTED :
        case CEE_ANN_HOISTED_CALL :
        case CEE_ANN_LIVE:
        case CEE_ANN_DEAD:
        case CEE_ANN_LAB:
        case CEE_ANN_CATCH:
            break;

        /******************************** NYI *******************************/

        case CEE_ILLEGAL:
        case CEE_MACRO_END:

        default:
            BADCODE("unknown opcode");
            assertImp(!"unhandled opcode");
        }

#undef assertImp

        codeAddr += sz;

#ifdef DEBUGGING_SUPPORT

        opcodeOffs += sz;

        /* If this was a call opcode, and we need to report IP-mapping info
           for call sites, then spill the stack.
         */

        if  ((opts.compDbgCode)                                     &&
             (info.compStmtOffsetsImplicit & CALL_SITE_BOUNDARIES)  &&
             (impOpcodeIsCall(opcode))                              &&
             (callTyp != TYP_VOID)                                  &&
             (opcode != CEE_JMP))
        {
            assert((impStackTop()->OperGet() == GT_CALL) ||
                   (impStackTop()->OperGet() == GT_CAST && // Small return type
                    impStackTop()->gtOp.gtOp1->OperGet() == GT_CALL));
            assert(impStackTop()->TypeGet() == genActualType(callTyp));

            impSpillStmtBoundary();

            impCurStmtOffs = opcodeOffs;
        }
#endif

        assert(!volatil  || opcode == CEE_VOLATILE);
        assert(!tailCall || opcode == CEE_TAILCALL);
    }
}


/*****************************************************************************
 *
 *  Import the IL for the given basic block (and any blocks reachable
 *  from it).
 */

void                Compiler::impImportBlock(BasicBlock *block)
{
    SavedStack      blockState;

    unsigned        baseTmp;

AGAIN:

    assert(block);
    assert(!(block->bbFlags & BBF_INTERNAL));

    /* Make the block globaly available */

    compCurBB = block;

    /* If the block has already been imported, bail */

    if  (block->bbFlags & BBF_IMPORTED)
    {
        /* The stack should have the same height on entry to the block from
           all its predecessors */

        if (block->bbStkDepth != impStkDepth)
        {
#ifdef DEBUG
            char buffer[200];
            sprintf(buffer, "Block at offset %4.4x to %4.4x in %s entered with different stack depths.\n"
                            "Previous depth was %d, current depth is %d",
                            block->bbCodeOffs, block->bbCodeOffs+block->bbCodeSize, info.compFullName,
                            block->bbStkDepth, impStkDepth);
            NO_WAY(buffer);
#else
            NO_WAY("Block entered with different stack depths");
#endif
        }

        return;
    }

    /* Remember whether the stack is non-empty on entry */

    block->bbStkDepth = impStkDepth;

    if (block->bbCatchTyp == BBCT_FILTER)
    {
        /* Nesting/Overlapping of filters not allowed */

        assert(!compFilterHandlerBB);

        assert(block->bbFilteredCatchHandler);

        /* Remember the corresponding catch handler */

        compFilterHandlerBB = block->bbFilteredCatchHandler;

        block->bbFilteredCatchHandler = NULL;

        assert(compFilterHandlerBB->bbCatchTyp == BBCT_FILTER_HANDLER);
    }

    /* Now walk the code an import the IL into GenTrees */

    impImportBlockCode(block);

#ifdef  DEBUG
    if  (verbose) printf("\n\n");

    // compCurBB is no longer reliable as recursive calls to impImportBlock()
    // may change it.
    compCurBB = NULL;
#endif

#if OPTIMIZE_QMARK

    /* If max. optimizations enabled, check for an "?:" expression */

    if  ((opts.compFlags & CLFLG_QMARK) && !(block->bbFlags & BBF_HAS_HANDLER))
    {
        if  (block->bbJumpKind == BBJ_COND && impCheckForQmarkColon(block))
            return;
    }

    GenTreePtr  qcx = NULL;
#endif

    /* If the stack is non-empty, we might have to spill its contents */

    if  (impStkDepth)
    {
        unsigned        level;

        unsigned        multRef;
        unsigned        tempNum;

        GenTreePtr      addTree = 0;

#if OPTIMIZE_QMARK

        /* Special case: a block that computes one part of a "(?:)" value */

        if  (isBBF_BB_COLON(block->bbFlags))
        {
            /* Pop one value from the top of the stack */

            GenTreePtr      val = impPopStack();
            var_types       typ = genActualType(val->gtType);

            /* Append a GT_BB_COLON node */

            impAppendTree(gtNewOperNode(GT_BB_COLON, typ, val), impCurStmtOffs);

            assert(impStkDepth == 0);

            /* Create the "(?)" node for the 'result' block */

            qcx = gtNewOperNode(GT_BB_QMARK, typ);
            qcx->gtFlags |= GTF_OTHER_SIDEEFF;
            goto EMPTY_STK;
        }

        /* Special case: a block that computes one part of a "?:" value */

        if  (isBBF_COLON(block->bbFlags))
        {
            /* Pop one value from the top of the stack and append it to the
               stmt list. The rsltBlk will pick it up from there. */

            impAppendTree(impPopStack(), impCurStmtOffs);

            /* We are done here */

            impEndTreeList(block);

            return;
        }

#endif
        /* Do any of the blocks that follow have input temps assigned ? */

        multRef = 0;
        baseTmp = NO_BASE_TMP;

        switch (block->bbJumpKind)
        {
        case BBJ_COND:

            /* Temporarily remove the 'jtrue' from the end of the tree list */

            assert(impTreeLast);
            assert(impTreeLast                   ->gtOper == GT_STMT );
            assert(impTreeLast->gtStmt.gtStmtExpr->gtOper == GT_JTRUE);

            addTree = impTreeLast;
                      impTreeLast = impTreeLast->gtPrev;

            /* Note if the next block has more than one ancestor */

            multRef |= block->bbNext->bbRefs;

            /* Does the next block have temps assigned? */

            baseTmp = block->bbNext->bbStkTemps;
            if  (baseTmp != NO_BASE_TMP)
                break;

            /* Try the target of the jump then */

            multRef |= block->bbJumpDest->bbRefs;
            baseTmp  = block->bbJumpDest->bbStkTemps;

            /* the catch handler expects stack vars to be in CT_CATCH_ARG
               other bb expect them in temps.  To support this we would
               have to reconcile these */
            if (block->bbNext->bbCatchTyp)
                NO_WAY("Conditional jumps to catch handler unsupported");
            break;

        case BBJ_ALWAYS:
            multRef |= block->bbJumpDest->bbRefs;
            baseTmp  = block->bbJumpDest->bbStkTemps;

            if (block->bbJumpDest->bbCatchTyp)  // dest block is catch handler
                goto JMP_CATCH_HANDLER;
            break;

        case BBJ_NONE:
            multRef |= block->bbNext    ->bbRefs;
            baseTmp  = block->bbNext    ->bbStkTemps;

            // We dont allow falling into a handler
            assert(!block->bbNext->bbCatchTyp);

            // @DEPRECATED
            if (block->bbNext->bbCatchTyp)  // next block is catch handler
            {
                // if we are jumping to the begining of a catch handler, then
                // the item on the top of the stack will be GT_CATCH_ARG.  We
                // need to harminize all control flow paths that 'fall' into
                // a catch handler.
            JMP_CATCH_HANDLER:
                if (impStkDepth != 1)
                    NO_WAY("Stack depth inconsistant with catch handler");

                    /* The top of the stack represents the catch arg, make an
                       assignment to this special node type */
                GenTreePtr tree = gtNewOperNode(GT_CATCH_ARG, TYP_REF);
                tree = gtNewOperNode(GT_ASG, TYP_REF, tree, impPopStack());
                tree->gtFlags |= GTF_ASG;
                impAppendTree(tree, impCurStmtOffs);

                    /* push the catch arg on the stack */
                impPushOnStack(gtNewOperNode(GT_CATCH_ARG, TYP_REF));
                goto DONE_SETTING_TEMPS;
            }
            break;

        case BBJ_CALL:
            NO_WAY("ISSUE: 'leaveCall' with non-empty stack - do we have to handle this?");

        case BBJ_RETURN:
        case BBJ_RET:
        case BBJ_THROW:
            // CONSIDER: add code to evaluate side effects
            NO_WAY("can't have 'unreached' end of BB with non-empty stack");
            break;

        case BBJ_SWITCH:

            /* Switch with a non-empty stack is too much pain */

            NO_WAY("ISSUE: 'switch' with a non-empty stack - this is too much work!");
            break;
        }

        assert(multRef > 1);

        /* Do we have a base temp number? */

        if  (baseTmp == NO_BASE_TMP)
        {
            /* Grab enough temps for the whole stack */

            baseTmp = lvaGrabTemps(impStkDepth);
        }

        /* Spill all stack entries into temps */

        for (level = 0, tempNum = baseTmp; level < impStkDepth; level++)
        {
            unsigned        tnum;
            GenTreePtr      tree = impStack[level].val;

            /* If there aren't multiple ancestors, we may not spill everything */

            if  (multRef == 1)
            {
                /* Is this an 'easy' value? */

                switch (tree->gtOper)
                {
                case GT_CNS_INT:
                case GT_CNS_LNG:
                case GT_CNS_FLT:
                case GT_CNS_DBL:
                case GT_CNS_STR:
                case GT_LCL_VAR:
                    continue;
                }

                /* Oh, well, grab a temp for the value then */

                tnum = lvaGrabTemp();
            }
            else
            {
                tnum = tempNum++;
            }

            /* Spill the stack entry, and replace with the temp */

            impSpillStackEntry(level, tnum);
        }

        /* Put back the 'jtrue' if we removed it earlier */


    DONE_SETTING_TEMPS:
        if  (addTree)
            impAppendStmt(addTree);
    }

#if OPTIMIZE_QMARK
EMPTY_STK:
#endif

    /* Save the tree list in the block */

    impEndTreeList(block);

    /* Is this block the start of a try ? If so, then we need to
       process its exception handlers */

    if  (block->bbFlags & BBF_IS_TRY)
    {
        assert(block->bbFlags & BBF_HAS_HANDLER);

        /* Save the stack contents, we'll need to restore it later */

        assert(block->bbStkDepth == 0); // Stack has to be empty on entry to try
        impSaveStackState(&blockState, false);

        unsigned        XTnum;
        EHblkDsc *      HBtab;

        for (XTnum = 0, HBtab = compHndBBtab;
             XTnum < info.compXcptnsCount;
             XTnum++  , HBtab++)
        {
            if  (HBtab->ebdTryBeg != block)
                continue;

            /* Recursively process the handler block */
            impStkDepth = 0;

            BasicBlock * hndBegBB = HBtab->ebdHndBeg;
            GenTreePtr   arg;

            if (hndBegBB->bbCatchTyp &&
                handlerGetsXcptnObj(hndBegBB->bbCatchTyp))
            {
                /* Push the exception address value on the stack */
                GenTreePtr  arg = gtNewOperNode(GT_CATCH_ARG, TYP_REF);

                /* Mark the node as having a side-effect - i.e. cannot be
                 * moved around since it is tied to a fixed location (EAX) */
                arg->gtFlags |= GTF_OTHER_SIDEEFF;

                impPushOnStack(arg);
            }

            // Queue up the handler for importing

            impImportBlockPending(hndBegBB, false);

            if (HBtab->ebdFlags & JIT_EH_CLAUSE_FILTER)
            {
                impStkDepth = 0;
                arg = gtNewOperNode(GT_CATCH_ARG, TYP_REF);
                arg->gtFlags |= GTF_OTHER_SIDEEFF;
                impPushOnStack(arg);

                impImportBlockPending(HBtab->ebdFilter, false);
            }
        }

        /* Restore the stack contents */

        impRestoreStackState(&blockState);
    }

    /* Does this block jump to any other blocks? */

    switch (block->bbJumpKind)
    {
        BasicBlock * *  jmpTab;
        unsigned        jmpCnt;

    case BBJ_RET:
    case BBJ_THROW:
    case BBJ_RETURN:
        break;

    case BBJ_COND:

        if  (!impStkDepth)
        {
            /* Queue up the next block for importing */

            impImportBlockPending(block->bbNext, false);

            /* Continue with the target of the conditional jump */

            block = block->bbJumpDest;
            goto AGAIN;
        }

        /* Does the next block have a different input temp set? */

        if  (block->bbNext->bbStkTemps != NO_BASE_TMP)
        {
            assert(baseTmp != NO_BASE_TMP);

            if  (block->bbNext->bbStkTemps != baseTmp)
            {
                /* Ouch -- we'll have to move the temps around */

                assert(!"UNDONE: transfer temps between blocks");
            }
        }
        else
        {
            /* Tell the block where it's getting its input from */

            block->bbNext->bbStkTemps = baseTmp;

            /* Does the target block already have a temp base assigned? */

            if  (block->bbJumpDest->bbStkTemps == NO_BASE_TMP)
            {
                /* Make sure the jump target uses the same temps */

                block->bbJumpDest->bbStkTemps = baseTmp;
            }
        }

        /* Queue up the next block for importing */

        impImportBlockPending(block->bbNext,
                              (block->bbJumpDest->bbFlags & BBF_IMPORTED) == 0);

        /* Fall through, the jump target is also reachable */

    case BBJ_ALWAYS:

        if  (impStkDepth)
        {
            /* Does the jump target have a different input temp set? */

            if  (block->bbJumpDest->bbStkTemps != NO_BASE_TMP)
            {
                assert(baseTmp != NO_BASE_TMP);

                if  (block->bbJumpDest->bbStkTemps != baseTmp)
                {
                    /* Ouch -- we'll have to move the temps around */

#if DEBUG
                    if (verbose&&0) printf("Block #%u has temp=%u, from #%u we need %u\n",
                                                block->bbJumpDest->bbNum,
                                                block->bbJumpDest->bbStkTemps,
                                                block->bbNum,
                                                baseTmp);
#endif

                    block->bbJumpDest = impMoveTemps(block->bbJumpDest, baseTmp);

                    /* The new block will inherit this block's weight */

                    block->bbJumpDest->bbWeight = block->bbWeight;
                }
            }
            else
            {
                /* Tell the block where it's getting its input from */

                block->bbJumpDest->bbStkTemps = baseTmp;
            }
        }

#if OPTIMIZE_QMARK
        if (qcx)
        {
            assert(isBBF_BB_COLON(block->bbFlags));

            /* Push a GT_BB_QMARK node on the stack */

            impPushOnStack(qcx);
        }
#endif

        /* HACK: Avoid infinite recursion when block jumps to itself */

        if  (block->bbJumpDest == block)
            break;

        block = block->bbJumpDest;

        goto AGAIN;

    case BBJ_CALL:

        assert(impStkDepth == 0);

        // CEE_LEAVE is followed by BBJ_CALL blocks corresponding to each
        // try-protected finally it jumps out of. These are BBF_INTERNAL
        // blocks. So just import the finally's they call directly.

        BasicBlock * callFinBlk;

        for (callFinBlk = block->bbNext; callFinBlk->bbJumpKind == BBJ_CALL;
             callFinBlk = callFinBlk->bbNext)
        {
            assert(callFinBlk->bbFlags & BBF_INTERNAL);

            impStkDepth = 0;

            // UNDONE: If the 'leaveCall' never returns, we can stop processing
            //         further blocks. There is no way to detect this currently.

            impImportBlock(callFinBlk->bbJumpDest);
            callFinBlk->bbFlags |= BBF_IMPORTED;
            assert(impStkDepth == 0);
        }

        assert((callFinBlk->bbJumpKind == BBJ_ALWAYS) &&
               (callFinBlk->bbFlags & BBF_INTERNAL));
        callFinBlk->bbFlags |= BBF_IMPORTED;

        /* Now process the target of the CEE_LEAVE */

        assert(block);
        block = callFinBlk->bbJumpDest;

        /* If the dest-block has already been imported, we're done */

        if  (block->bbFlags & BBF_IMPORTED)
            break;

        goto AGAIN;

    case BBJ_NONE:

        if  (impStkDepth)
        {
            /* Does the next block have a different input temp set? */

            if  (block->bbNext->bbStkTemps != NO_BASE_TMP)
            {
                assert(baseTmp != NO_BASE_TMP);

                if  (block->bbNext->bbStkTemps != baseTmp)
                {
                    /* Ouch -- we'll have to move the temps around */

                    assert(!"UNDONE: transfer temps between blocks");
                }
            }
            else
            {
                /* Tell the block where it's getting its input from */

                block->bbNext->bbStkTemps = baseTmp;
            }
        }

#if OPTIMIZE_QMARK
        if (qcx)
        {
            assert(isBBF_BB_COLON(block->bbFlags));

            /* Push a GT_BB_QMARK node on the stack */

            impPushOnStack(qcx);
        }
#endif

        block = block->bbNext;
        goto AGAIN;

    case BBJ_SWITCH:

        assert(impStkDepth == 0);

        jmpCnt = block->bbJumpSwt->bbsCount;
        jmpTab = block->bbJumpSwt->bbsDstTab;

        do
        {
            /* Add the target case label to the pending list. */

            impImportBlockPending(*jmpTab, true);
        }
        while (++jmpTab, --jmpCnt);

        break;
    }
}

/*****************************************************************************
 *
 *  Adds 'block' to the list of BBs waiting to be imported. ie. it appends
 *  to the worker-list.
 */

void                Compiler::impImportBlockPending(BasicBlock * block,
                                                    bool         copyStkState)
{
    // BBF_COLON blocks are imported directly as they have to be processed
    // before the GT_QMARK to get to the expressions evaluated by these blocks.
    assert(!isBBF_COLON(block->bbFlags));

#ifndef DEBUG
    // Under DEBUG, add the block to the pending-list anyway as some
    // additional checks will get done on the block. For non-DEBUG, do nothing.
    if (block->bbFlags & BBF_IMPORTED)
        return;
#endif

    // Get an entry to add to the pending list

    PendingDsc * dsc;

    if (impPendingFree)
    {
        // We can reuse one of the freed up dscs.
        dsc = impPendingFree;
        impPendingFree = dsc->pdNext;
    }
    else
    {
        // We have to create a new dsc
        dsc = (PendingDsc *)compGetMem(sizeof(*dsc));
    }

    dsc->pdBB           = block;
    dsc->pdSavedStack.ssDepth = impStkDepth;

    // Save the stack trees for later

    if (impStkDepth)
        impSaveStackState(&dsc->pdSavedStack, copyStkState);

    // Add the entry to the pending list

    dsc->pdNext         = impPendingList;
    impPendingList      = dsc;

#ifdef DEBUG
    if (verbose&&0) printf("Added PendingDsc - %08X for BB#%03d\n",
                           dsc, block->bbNum);
#endif
}

/*****************************************************************************
 *
 *  Convert the IL opcodes ("import") into our internal format (trees). The
 *  basic flowgraph has already been constructed and is passed in.
 */

void                Compiler::impImport(BasicBlock *method)
{
    /* Allocate the stack contents */

#if INLINING
    if  (info.compMaxStack <= sizeof(impSmallStack)/sizeof(impSmallStack[0]))
    {
        /* Use local variable, don't waste time allocating on the heap */

        impStackSize = sizeof(impSmallStack)/sizeof(impSmallStack[0]);
        impStack     = impSmallStack;
    }
    else
#endif
    {
        impStackSize = info.compMaxStack;
        impStack     = (StackEntry *)compGetMem(impStackSize * sizeof(*impStack));
    }

    impStkDepth  = 0;

#if TGT_RISC
    genReturnCnt = 0;
#endif

#ifdef  DEBUG
    impLastILoffsStmt = NULL;
#endif

    if (info.compIsVarArgs)
    {
        unsigned lclNum = lvaGrabTemp();    // This variable holds a pointer to beginging of the arg list
            // I assume this later on, so I don't have to store it
        assert(lclNum == info.compLocalsCount);
    }

    impPendingList = impPendingFree = NULL;

    /* Add the entry-point to the worker-list */

    impImportBlockPending(method, false);

    /* Import blocks in the worker-list until there are no more */

    while(impPendingList)
    {
        /* Remove the entry at the front of the list */

        PendingDsc * dsc = impPendingList;
        impPendingList   = impPendingList->pdNext;

        /* Restore the stack state */

        impStkDepth = dsc->pdSavedStack.ssDepth;
        if (impStkDepth)
            impRestoreStackState(&dsc->pdSavedStack);

        /* Add the entry to the free list for reuse */

        dsc->pdNext = impPendingFree;
        impPendingFree = dsc;

        /* Now import the block */

        impImportBlock(dsc->pdBB);
    }
}

/*****************************************************************************/
#if INLINING
/*****************************************************************************
 *
 *  The inliner version of spilling side effects from the stack
 *  Doesn't need to handle value types.
 */

inline
void                Compiler::impInlineSpillStackEntry(unsigned   level)
{
    GenTreePtr      tree   = impStack[level].val;
    var_types       lclTyp = genActualType(tree->gtType);

    /* Allocate a temp */

    unsigned tnum = lvaGrabTemp(); impInlineTemps++;

    /* The inliner doesn't handle value types on the stack */

    assert(lclTyp != TYP_STRUCT);

    /* Assign the spilled entry to the temp */

    GenTreePtr asg = gtNewTempAssign(tnum, tree);

    /* Append to the "statement" list */

    impInitExpr = impConcatExprs(impInitExpr, asg);

    /* Replace the stack entry with the temp */

    impStack[level].val = gtNewLclvNode(tnum, lclTyp, tnum);

    JITLOG((INFO8, "INLINER WARNING: Spilled side effect from stack! - caller is %s\n", info.compFullName));
}

inline
void                Compiler::impInlineSpillSideEffects()
{
    unsigned        level;

    for (level = 0; level < impStkDepth; level++)
    {
        if  (impStack[level].val->gtFlags & GTF_SIDE_EFFECT)
            impInlineSpillStackEntry(level);
    }
}


void                Compiler::impInlineSpillLclRefs(int lclNum)
{
    unsigned        level;

    for (level = 0; level < impStkDepth; level++)
    {
        GenTreePtr      tree = impStack[level].val;

        /* Skip the tree if it doesn't have an affected reference */

        if  (gtHasRef(tree, lclNum, false))
        {
            impInlineSpillStackEntry(level);
        }
    }
}
/*****************************************************************************
 *
 *  Return an expression that contains both arguments; either of the arguments
 *  may be zero.
 */

GenTreePtr          Compiler::impConcatExprs(GenTreePtr exp1, GenTreePtr exp2)
{
    if  (exp1)
    {
        if  (exp2)
        {
            /* The first expression better be useful for something */

            assert(exp1->gtFlags & GTF_SIDE_EFFECT);

            /* The second expresion should not be a NOP */

            assert(exp2->gtOper != GT_NOP);

            /* Link the two expressions through a comma operator */

            return gtNewOperNode(GT_COMMA, exp2->gtType, exp1, exp2);
        }
        else
            return  exp1;
    }
    else
        return  exp2;
}

/*****************************************************************************
 *
 *  Extract side effects from a single expression.
 */

GenTreePtr          Compiler::impExtractSideEffect(GenTreePtr val, GenTreePtr *lstPtr)
{
    GenTreePtr      addx;

    assert(val && val->gtType != TYP_VOID && (val->gtFlags & GTF_SIDE_EFFECT));

    /* Special case: comma expression */

    if  (val->gtOper == GT_COMMA && !(val->gtOp.gtOp2->gtFlags & GTF_SIDE_EFFECT))
    {
        addx = val->gtOp.gtOp1;
        val  = val->gtOp.gtOp2;
    }
    else
    {
        unsigned        tnum;

        /* Allocate a temp and assign the value to it */

        tnum = lvaGrabTemp(); impInlineTemps++;

        addx = gtNewTempAssign(tnum, val);

        /* Use the value of the temp */

        val  = gtNewLclvNode(tnum, genActualType(val->gtType), tnum);
    }

    /* Add the side effect expression to the list */

    *lstPtr = impConcatExprs(*lstPtr, addx);

    return  val;
}


#define         MAX_ARGS         6      // does not include obj pointer
#define         MAX_LCLS         8

/*****************************************************************************
 *
 *  See if the given method and argument list can be expanded inline.
 *
 *  NOTE: Use the following logging levels for inlining info
 *        INFO6:  Use when reporting successful inline of a method
 *        INFO7:  Use when reporting NYI stuff about the inliner
 *        INFO8:  Use when reporting UNUSUAL situations why inlining FAILED
 *        INFO9:  Use when WARNING about incomming flags that prevent inlining
 *        INFO10: Verbose info including NORMAL inlining failures
 */

GenTreePtr          Compiler::impExpandInline(GenTreePtr      tree,
                                              METHOD_HANDLE   fncHandle)

{
    GenTreePtr      bodyExp = 0;

    BYTE *          codeAddr;
    const   BYTE *  codeBegp;
    const   BYTE *  codeEndp;

    size_t          codeSize;

    CLASS_HANDLE    clsHandle;
    SCOPE_HANDLE    scpHandle;


    struct inlArgInfo_tag  {
        GenTreePtr  argNode;
        GenTreePtr  argTmpNode;
        unsigned    argIsUsed     :1;       // is this arg used at all?
        unsigned    argIsConst    :1;       // the argument is a constant
        unsigned    argIsLclVar   :1;       // the argument is a local variable
        unsigned    argHasSideEff :1;       // the argument has side effects
        unsigned    argHasTmp     :1;       // the argument will be evaluated to a temp
        unsigned    argTmpNum     :12;      // the argument tmp number
    } inlArgInfo [MAX_ARGS + 1];

    int             lclTmpNum[MAX_LCLS];    // map local# -> temp# (-1 if unused)

    GenTreePtr      thisArg;
    GenTreePtr      argList;

    JIT_METHOD_INFO methInfo;

    unsigned        clsAttr;
    unsigned        methAttr = eeGetMethodAttribs(fncHandle);

    GenTreePtr      argTmp;
    unsigned        argCnt;
    unsigned        lclCnt;

    var_types       fncRetType;
    bool            inlineeHasRangeChks = false;
    bool            inlineeHasNewArray  = false;

    bool            dupOfLclVar = false;

    var_types       lclTypeInfo[MAX_LCLS + MAX_ARGS + 1];  // type information from local sig


#define INLINE_CONDITIONALS 1

#if     INLINE_CONDITIONALS

    GenTreePtr      stmList;                // pre-condition statement list
    GenTreePtr      ifStmts;                // contents of 'if' when in 'else'
    GenTreePtr      ifCondx;                // condition of 'if' statement
    bool            ifNvoid = false;        // does 'if' yield non-void value?
    const   BYTE *  jmpAddr = NULL;         // current pending jump address
    bool            inElse  = false;        // are we in an 'else' part?

    bool            hasCondReturn = false;  // do we have ret from a conditional
    unsigned        retLclNum;              // the return lcl var #

#endif

#ifdef DEBUG
    bool            hasFOC = false;         // has flow-of-control
#endif

    /* Cannot inline across assemblies - abort but don't mark as not inlinable */

    if (!eeCanInline(info.compMethodHnd, fncHandle))
    {
        JITLOG((INFO8, "INLINER FAILED: Cannot inline across assemblies: %s called by %s\n",
                                   eeGetMethodFullName(fncHandle), info.compFullName));

        return 0;
    }

    /* Get hold of class and scope handles for the method */

#ifdef  NOT_JITC
    clsHandle = eeGetMethodClass(fncHandle);
#else
    clsHandle = (CLASS_HANDLE) info.compScopeHnd;  // for now, assume the callee belongs to the same class
#endif

    /* Get class atrributes */

    clsAttr = clsHandle ? eeGetClassAttribs(clsHandle) : 0;

    /* So far we haven't allocate any temps */

    impInlineTemps = 0;

    /* Check if we tried to inline this method before */

    if (methAttr & FLG_DONT_INLINE)
    {
        JITLOG((INFO9, "INLINER FAILED: Method marked as not inline: %s called by %s\n",
                                   eeGetMethodFullName(fncHandle), info.compFullName));

        return 0;
    }

    /* Do not inline if caller or callee need security checks */

    if (methAttr & FLG_SECURITYCHECK)
    {
        JITLOG((INFO9, "INLINER FAILED: Callee needs security check: %s called by %s\n",
                                   eeGetMethodFullName(fncHandle), info.compFullName));

        goto INLINING_FAILED;
    }

    /* In the caller case do not mark as not inlinable */

    if (opts.compNeedSecurityCheck)
    {
        JITLOG((INFO9, "INLINER FAILED: Caller needs security check: %s called by %s\n",
                                   eeGetMethodFullName(fncHandle), info.compFullName));

        return 0;
    }

    /* Cannot inline the method if it's class has not been initialized
       as we dont want inlining to force loading of extra classes */

    if (clsHandle && !(clsAttr & FLG_INITIALIZED))
    {
        JITLOG((INFO9, "INLINER FAILED: Method class is not initialized: %s called by %s\n",
                                   eeGetMethodFullName(fncHandle), info.compFullName));

        /* Return but do not mark the method as not inlinable */
        return 0;
    }

    /* Try to get the code address/size for the method */

    if (!eeGetMethodInfo(fncHandle, &methInfo))
        goto INLINING_FAILED;

    /* Reject the method if it has exceptions or looks weird */

    codeBegp = codeAddr = methInfo.ILCode;
    codeSize = methInfo.ILCodeSize;

    if (methInfo.EHcount || !codeBegp || (codeSize == 0))
        goto INLINING_FAILED;

    /* For now we don't inline varargs (import code can't handle it) */

    if (methInfo.args.isVarArg())
        goto INLINING_FAILED;

    /* Check the IL size  */

    if  (codeSize > genInlineSize)
    {
        // UNDONE: Need better heuristic! For example, if the call is
        // UNDONE: in a loop we should allow much bigger methods to be
        // UNDONE: inlined.

        goto INLINING_FAILED;
    }

    JITLOG((INFO10, "INLINER: Considering %u IL opcodes of %s called by %s\n",
                               codeSize, eeGetMethodFullName(fncHandle), info.compFullName));

    /* Do not inline functions inside <clinit>
     * @MIHAII - Need a flag for clinit - I currently put this one here
     * because doing the strcmp and calling the VM is much more expensive than having the
     * size filtering do the job of rejecting - Move it back up when you can check
     * < clinit> by flags */

    const char *     className;

    if (!strcmp(COR_CCTOR_METHOD_NAME, eeGetMethodName(info.compMethodHnd, &className)))
    {
        JITLOG((INFO9, "INLINER FAILED: Do not inline method inside <clinit>: %s called by %s\n",
                                   eeGetMethodFullName(fncHandle), info.compFullName));

        /* Return but do not mark the method as not inlinable */
        return 0;
    }

    /* Reject if it has too many locals */

    lclCnt = methInfo.locals.numArgs;
    if (lclCnt > MAX_LCLS)
    {
        JITLOG((INFO10, "INLINER FAILED: Method has %u locals: %s called by %s\n",
                                   lclCnt, eeGetMethodFullName(fncHandle), info.compFullName));

        goto INLINING_FAILED;
    }

    /* Make sure there aren't too many arguments */

    if  (methInfo.args.numArgs > MAX_ARGS)
    {
        JITLOG((INFO10, "INLINER FAILED: Method has %u arguments: %s called by %s\n",
                       methInfo.args.numArgs, eeGetMethodFullName(fncHandle), info.compFullName));

        goto INLINING_FAILED;
    }

    /* Make sure maxstack it's not too big */

    if  (methInfo.maxStack > impStackSize)
    {
        // Make sure that we are using the small stack. Without the small stack,
        // we will silently stop inlining a bunch of methods.
        assert(impStackSize >= sizeof(impSmallStack)/sizeof(impSmallStack[0]));

        JITLOG((INFO10, "INLINER FAILED: Method has %u MaxStack bigger than callee stack %u: %s called by %s\n",
                                   methInfo.maxStack, info.compMaxStack, eeGetMethodFullName(fncHandle), info.compFullName));

        goto INLINING_FAILED;
    }

    /* For now, fail if the function returns a struct */

    if (methInfo.args.retType == JIT_TYP_VALUECLASS)
    {
        JITLOG((INFO7, "INLINER FAILED: Method %s returns a value class called from %s\n",
                                    eeGetMethodFullName(fncHandle), info.compFullName));

        goto INLINING_FAILED;
    }

    /* Get the return type */

    fncRetType = tree->TypeGet();

#ifdef DEBUG
    assert(genActualType(JITtype2varType(methInfo.args.retType)) == genActualType(fncRetType));
#endif

    /* init the argument stuct */

    memset(inlArgInfo, 0, (MAX_ARGS + 1) * sizeof(struct inlArgInfo_tag));

    /* Get hold of the 'this' pointer and the argument list proper */

    thisArg = tree->gtCall.gtCallObjp;
    argList = tree->gtCall.gtCallArgs;

    /* Count the arguments */

    argCnt = 0;

    if  (thisArg)
    {
        if (thisArg->gtOper == GT_CNS_INT)
        {
            if (thisArg->gtIntCon.gtIconVal == 0)
            {
                JITLOG((INFO7, "INLINER FAILED: Null this pointer: %s called by %s\n",
                                            eeGetMethodFullName(fncHandle), info.compFullName));

                /* Abort, but do not mark as not inlinable */
                return 0;
            }

            inlArgInfo[0].argIsConst = true;
        }
        else if (thisArg->gtOper == GT_LCL_VAR)
        {
            inlArgInfo[0].argIsLclVar = true;

            /* Remember the "original" argument number */
            thisArg->gtLclVar.gtLclOffs = 0;
        }
        else if (thisArg->gtFlags & GTF_SIDE_EFFECT)
        {
            inlArgInfo[0].argHasSideEff = true;
        }

        inlArgInfo[0].argNode = thisArg;
        argCnt++;
    }

    /* Record all possible data about the arguments */

    for (argTmp = argList; argTmp; argTmp = argTmp->gtOp.gtOp2)
    {
        GenTreePtr      argVal;

        assert(argTmp->gtOper == GT_LIST);
        argVal = argTmp->gtOp.gtOp1;

        inlArgInfo[argCnt].argNode = argVal;

        if (argVal->gtOper == GT_LCL_VAR)
        {
            inlArgInfo[argCnt].argIsLclVar = true;

            /* Remember the "original" argument number */
            argVal->gtLclVar.gtLclOffs = argCnt;
        }
        else if (argVal->OperKind() & GTK_CONST)
            inlArgInfo[argCnt].argIsConst = true;
        else if (argVal->gtFlags & GTF_SIDE_EFFECT)
            inlArgInfo[argCnt].argHasSideEff = true;

#ifdef DEBUG
        if (verbose)
        {
            if  (inlArgInfo[argCnt].argIsLclVar)
              printf("\nArgument #%u is a local var:\n", argCnt);
            else if  (inlArgInfo[argCnt].argIsConst)
              printf("\nArgument #%u is a constant:\n", argCnt);
            else if  (inlArgInfo[argCnt].argHasSideEff)
              printf("\nArgument #%u has side effects:\n", argCnt);
            else
              printf("\nArgument #%u:\n", argCnt);

            gtDispTree(argVal);
            printf("\n");
        }
#endif

        /* Count this argument */

        argCnt++;
    }

    /* Make sure we got the arg number right */
    assert(argCnt == (thisArg ? 1 : 0) + methInfo.args.numArgs);

    /* For IL we have typeless opcodes, so we need type information from the signature */

    if (thisArg)
    {
        assert(clsHandle);

        if (clsAttr & FLG_VALUECLASS)
            lclTypeInfo[0] = ((clsAttr & FLG_UNMANAGED) ? TYP_I_IMPL : TYP_BYREF);
        else
            lclTypeInfo[0] = TYP_REF;

        assert(varTypeIsGC(thisArg->gtType) ||      // "this" is managed
               (thisArg->gtType == TYP_I_IMPL &&    // "this" is unmgd but the method's class doesnt care
                (( clsAttr & FLG_UNMANAGED) ||
                 ((clsAttr & FLG_VALUECLASS) && !(clsAttr & FLG_CONTAINS_GC_PTR)))));
    }

    /* Init the types of the arguments and make sure the types
     * from the trees match the types in the signature */

    ARG_LIST_HANDLE     argLst;
    argLst = methInfo.args.args;

    unsigned i;
    for(i = (thisArg ? 1 : 0); i < argCnt; i++)
    {
        var_types type = (var_types) eeGetArgType(argLst, &methInfo.args);

        /* For now do not handle structs */
        if (type == TYP_STRUCT)
        {
            JITLOG((INFO7, "INLINER FAILED: No TYP_STRUCT arguments allowed: %s called by %s\n",
                                        eeGetMethodFullName(fncHandle), info.compFullName));

            goto INLINING_FAILED;
        }

        lclTypeInfo[i] = type;

        /* Does the tree type match the signature type? */
        if (type != inlArgInfo[i].argNode->gtType)
        {
            /* This can only happen for short integer types or byrefs <-> ints */

            assert(genActualType(type) == TYP_INT || type == TYP_BYREF);
            assert(genActualType(inlArgInfo[i].argNode->gtType) == TYP_INT  ||
                                 inlArgInfo[i].argNode->gtType  == TYP_BYREF );

            /* Is it a narrowing or widening cast?
             * Widening casts are ok since the value computed is already
             * normalized to an int (on the IL stack) */

            if (genTypeSize(inlArgInfo[i].argNode->gtType) >= genTypeSize(type))
            {
                if (type == TYP_BYREF)
                {
                    /* Arguments 'byref <- int' not currently supported */
                    JITLOG((INFO7, "INLINER FAILED: Arguments 'byref <- int' not currently supported: %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));

                    goto INLINING_FAILED;
                }
                else if (inlArgInfo[i].argNode->gtType == TYP_BYREF)
                {
                    assert(type == TYP_INT);

                    /* If possible bash the BYREF to an int */
                    if (inlArgInfo[i].argNode->IsVarAddr())
                    {
                        inlArgInfo[i].argNode->gtType = TYP_INT;
                    }
                    else
                    {
                        /* Arguments 'int <- byref' cannot be bashed */
                        JITLOG((INFO7, "INLINER FAILED: Arguments 'int <- byref' cannot be bashed: %s called by %s\n",
                                                    eeGetMethodFullName(fncHandle), info.compFullName));

                        goto INLINING_FAILED;
                    }
                }
                else if (genTypeSize(type) < 4 && type != TYP_BOOL)
                {
                    /* Narrowing cast */

                    assert(genTypeSize(type) == 2 || genTypeSize(type) == 1);

                    inlArgInfo[i].argNode = gtNewLargeOperNode(GT_CAST, TYP_INT,
                                                               inlArgInfo[i].argNode, gtNewIconNode(type));

                    inlArgInfo[i].argIsLclVar = false;

                    /* Try to fold the node in case we have constant arguments */

                    if (inlArgInfo[i].argIsConst)
                    {
                        inlArgInfo[i].argNode = gtFoldExprConst(inlArgInfo[i].argNode);
                        assert(inlArgInfo[i].argNode->OperIsConst());
                    }
                }
            }
        }

        /* Get the next argument */
        argLst = eeGetArgNext(argLst);
    }

    /* Init the types of the local variables */

    ARG_LIST_HANDLE     localsSig;
    localsSig = methInfo.locals.args;

    for(i = 0; i < lclCnt; i++)
    {
        lclTypeInfo[i + argCnt] = (var_types) eeGetArgType(localsSig, &methInfo.locals);

        /* For now do not handle structs */
        if (lclTypeInfo[i + argCnt] == TYP_STRUCT)
        {
            JITLOG((INFO7, "INLINER FAILED: No TYP_STRUCT arguments allowed: %s called by %s\n",
                                        eeGetMethodFullName(fncHandle), info.compFullName));

            goto INLINING_FAILED;
        }

        localsSig = eeGetArgNext(localsSig);
    }

#ifdef  NOT_JITC
    scpHandle = methInfo.scope;
#else
    scpHandle = info.compScopeHnd;
#endif

#ifdef DEBUG
    if (verbose || 0)
        printf("Inliner considering %2u IL opcodes of %s:\n", codeSize, eeGetMethodFullName(fncHandle));
#endif

    /* Clear the temp table */

    memset(lclTmpNum, -1, sizeof(lclTmpNum));

    /* The stack is empty */

    impStkDepth = 0;

    /* Initialize the inlined "statement" list */

    impInitExpr = 0;

    /* Convert the opcodes of the method into an expression tree */

    codeEndp = codeBegp + codeSize;

    while (codeAddr <= codeEndp)
    {
        signed  int     sz = 0;

        OPCODE          opcode;

        bool        volatil     = false;

#if INLINE_CONDITIONALS

        /* Have we reached the target of a pending if/else statement? */

        if  (jmpAddr == codeAddr)
        {
            GenTreePtr      fulStmt;
            GenTreePtr      noStmts = NULL;

            /* An end of 'if' (without 'else') or end of 'else' */

            if  (inElse)
            {
                /* The 'else' part is the current statement list */

                noStmts = impInitExpr;

                /* The end of 'if/else' - does the 'else' yield a value? */

                if  (impStkDepth)
                {
                    /* We retun a non void value */

                    if  (ifNvoid == false)
                    {
                        JITLOG((INFO7, "INLINER FAILED: If returns a value, else doesn't: %s called by %s\n",
                                                        eeGetMethodFullName(fncHandle), info.compFullName));
                        goto ABORT;
                    }

                    /* We must have an 'if' part */

                    assert(ifStmts);

                    if  (impStkDepth > 1)
                    {
                        JITLOG((INFO7, "INLINER FAILED: More than one return value in else: %s called by %s\n",
                                                        eeGetMethodFullName(fncHandle), info.compFullName));
                        goto ABORT;
                    }

                    /* Both the 'if' and 'else' yield one value */

                    noStmts = impConcatExprs(noStmts, impPopStack());
                    assert(noStmts);

                    /* Make sure both parts have matching types */

                    assert(genActualType(ifStmts->gtType) == genActualType(noStmts->gtType));
                }
                else
                {
                    assert(ifNvoid == false);
                }
            }
            else
            {
                /* This is a conditional with no 'else' part
                 * The 'if' part is the current statement list */

                ifStmts = impInitExpr;

                /* Did the 'if' part yield a value? */

                if  (impStkDepth)
                {
                    if  (impStkDepth > 1)
                    {
                        JITLOG((INFO7, "INLINER FAILED: More than one return value in if: %s called by %s\n",
                                                        eeGetMethodFullName(fncHandle), info.compFullName));
                        goto ABORT;
                    }

                    ifStmts = impConcatExprs(ifStmts, impPopStack());
                    assert(ifStmts);
                }
            }

            /* Check for empty 'if' or 'else' part */

            if (ifStmts == NULL)
            {
                if (noStmts == NULL)
                {
                    /* Both 'if' and 'else' are empty - useless conditional*/

                    assert(ifCondx->OperKind() & GTK_RELOP);

                    /* Restore the original statement list */

                    impInitExpr = stmList;

                    /* Append the side effects from the conditional
                     * CONSIDER - After you optimize impConcatExprs to
                     * truly extract the side effects can reduce the following to one call */

                    if  (ifCondx->gtOp.gtOp1->gtFlags & GTF_SIDE_EFFECT)
                        impInitExpr = impConcatExprs(impInitExpr, ifCondx->gtOp.gtOp1);

                    if  (ifCondx->gtOp.gtOp2->gtFlags & GTF_SIDE_EFFECT)
                        impInitExpr = impConcatExprs(impInitExpr, ifCondx->gtOp.gtOp2);

                    goto DONE_QMARK;
                }
                else
                {
                    /* Empty 'if', have 'else' - Swap the operands */

                    ifStmts = noStmts;
                    noStmts = gtNewNothingNode();

                    assert(!ifStmts->IsNothingNode());

                    /* Reverse the sense of the condition */

                    ifCondx->gtOper = GenTree::ReverseRelop(ifCondx->OperGet());
                }
            }
            else
            {
                /* 'if' is non empty */

                if (noStmts == NULL)
                {
                    /* The 'else' is empty */
                    noStmts = gtNewNothingNode();
                }
            }

            /* At this point 'ifStmt/noStmts' are the 'if/else' parts */

            assert(ifStmts);
            assert(!ifStmts->IsNothingNode());
            assert(noStmts);

            var_types   typ;

            /* Set the type to void if there is no value */

            typ = ifNvoid ? ifStmts->TypeGet() : TYP_VOID;

            /* FP values are not handled currently */

            assert(!varTypeIsFloating(typ));

            /* Do not inline longs at this time */

            if (typ == TYP_LONG)
            {
                JITLOG((INFO7, "INLINER FAILED: Inlining of conditionals that return LONG NYI: %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

#if 0
            int         sense;

            long        val1;
            long        val2;

            /* Check for the case "cond ? 0/1 : 1/0" */

            if      (ifCondx->gtOper == GT_EQ)
            {
                sense = 0;
            }
            else if (ifCondx->gtOper == GT_NE)
            {
                sense = 1;
            }
            else
                goto NOT_LOG;

            if  (ifCondx->gtOp.gtOp2->gtOper != GT_CNS_INT)
                goto NOT_LOG;
            if  (ifCondx->gtOp.gtOp2->gtIntCon.gtIconVal != 0)
                goto NOT_LOG;

            /* The simplest case is "cond ? 1/0 : 0/1" */

            if  (ifStmts->gtOper == GT_CNS_INT &&
                 noStmts->gtOper == GT_CNS_INT)
            {
                // UNDONE: Do the rest of this thing ....

            }

            /* Now see if we have "dest = cond ? 1/0 : 0/1" */

            if  (ifStmts->gtOper != GT_ASG)
                goto NOT_LOG;
            if  (ifStmts->gtOp.gtOp2->gtOper != GT_CNS_INT)
                goto NOT_LOG;
            val1 = ifStmts->gtOp.gtOp2->gtIntCon.gtIconVal;
            if  (val1 != 0 && val1 != 1)
                goto NOT_LOG;

            if  (noStmts->gtOper != GT_ASG)
                goto NOT_LOG;
            if  (noStmts->gtOp.gtOp2->gtOper != GT_CNS_INT)
                goto NOT_LOG;
            val2 = noStmts->gtOp.gtOp2->gtIntCon.gtIconVal;
            if  (val2 != (val1 ^ 1))
                goto NOT_LOG;

            /* Make sure the assignment targets are the same */

            if  (!GenTree::Compare(ifStmts->gtOp.gtOp1,
                                   noStmts->gtOp.gtOp1))
                goto NOT_LOG;

            /* We have the right thing, it would appear */

            fulStmt = ifStmts;
            fulStmt->gtOp.gtOp2 = gtNewOperNode((sense ^ val1) ? GT_LOG0
                                                               : GT_LOG1,
                                                TYP_INT,
                                                ifCondx->gtOp.gtOp1);

            goto DONE_IF;
#endif

//NOT_LOG:

            /* Create the "?:" expression */

            fulStmt = gtNewOperNode(GT_COLON, typ, ifStmts, noStmts);
            fulStmt = gtNewOperNode(GT_QMARK, typ, ifCondx, fulStmt);

            /* Mark the condition of the ?: node */

            ifCondx->gtFlags |= GTF_QMARK_COND;

            /* The ?: expression is sort of a side effect */

            fulStmt->gtFlags |= GTF_OTHER_SIDEEFF;

//DONE_IF:

            /* Restore the original expression */

            impInitExpr = stmList;

            /* Does the ?: expression yield a non-void value? */

            if  (ifNvoid)
            {
                /* Push the entire statement on the stack */

                // CONSIDER: extract any comma prefixes and append them

                assert(fulStmt->gtType != TYP_VOID);

                impPushOnStack(fulStmt);
            }
            else
            {
                /* 'if' yielded no value, just append the ?: */

                assert(fulStmt->gtType == TYP_VOID);
                impInitExpr = impConcatExprs(impInitExpr, fulStmt);
            }

            if (inElse && hasCondReturn)
            {
                assert(jmpAddr == codeEndp);
                assert(ifNvoid == false);
                assert(fncRetType != TYP_VOID);

                /* The return value is the return local variable */
                bodyExp = gtNewLclvNode(retLclNum, fncRetType, retLclNum);
            }

DONE_QMARK:
            /* We're no longer in an 'if' statement */

            jmpAddr = NULL;
        }

#endif  // INLINE_CONDITIONALS

        /* Done importing the IL */

        if (codeAddr == codeEndp)
            goto DONE;

        /* Get the next opcode and the size of its parameters */

        opcode = OPCODE(getU1LittleEndian(codeAddr));
        codeAddr += sizeof(__int8);

DECODE_OPCODE:

        /* Get the size of additional parameters */

        sz = opcodeSizes[opcode];

#ifdef  DEBUG

        impCurOpcOffs   = codeAddr - info.compCode - 1;
        impCurStkDepth  = impStkDepth;
        impCurOpcName   = opcodeNames[opcode];

        if  (verbose)
            printf("[%2u] %03u (0x%x) OP_%-18s ", impStkDepth, impCurOpcOffs, impCurOpcOffs, impCurOpcName);
#else

//      printf("[%2u] %03u OP#%u\n", impStkDepth, codeAddr - info.compCode - 1, op); _flushall();

#endif

        /* See what kind of an opcode we have, then */

        switch (opcode)
        {
            unsigned        lclNum;
            unsigned        initLclNum;
            var_types       lclTyp, type, callTyp;

            genTreeOps      oper;
            GenTreePtr      op1, op2, tmp;
            GenTreePtr      thisPtr, arr;

            int             memberRef;
            int             typeRef;
            int             val, tmpNum;

            CLASS_HANDLE    clsHnd;
            METHOD_HANDLE   methHnd;
            FIELD_HANDLE    fldHnd;

            JIT_SIG_INFO    sig;

#if INLINE_CONDITIONALS
            signed          jmpDist;
            bool            unordered;
#endif

            unsigned        clsFlags;
            unsigned        flags, mflags;

            unsigned        ptrTok;
          //unsigned        offs;
            bool            ovfl, uns;
            bool            callNode;

            union
            {
                long            intVal;
                float           fltVal;
                __int64         lngVal;
                double          dblVal;
            }
                            cval;

		case CEE_PREFIX1:
			opcode = OPCODE(getU1LittleEndian(codeAddr) + 256);
			codeAddr += sizeof(__int8);
			goto DECODE_OPCODE;

        case CEE_LDNULL:
            impPushOnStack(gtNewIconNode(0, TYP_REF));
            break;

        case CEE_LDC_I4_M1 :
        case CEE_LDC_I4_0 :
        case CEE_LDC_I4_1 :
        case CEE_LDC_I4_2 :
        case CEE_LDC_I4_3 :
        case CEE_LDC_I4_4 :
        case CEE_LDC_I4_5 :
        case CEE_LDC_I4_6 :
        case CEE_LDC_I4_7 :
        case CEE_LDC_I4_8 :
            cval.intVal = (opcode - CEE_LDC_I4_0);
            assert(-1 <= cval.intVal && cval.intVal <= 8);
            goto PUSH_I4CON;

        case CEE_LDC_I4_S: cval.intVal = getI1LittleEndian(codeAddr); goto PUSH_I4CON;
        case CEE_LDC_I4:   cval.intVal = getI4LittleEndian(codeAddr); goto PUSH_I4CON;
        PUSH_I4CON:
            impPushOnStack(gtNewIconNode(cval.intVal));
            break;

        case CEE_LDC_I8:
            cval.lngVal = getI8LittleEndian(codeAddr);
            impPushOnStack(gtNewLconNode(&cval.lngVal));
            break;

        case CEE_LDC_R8:
            cval.dblVal = getR8LittleEndian(codeAddr);
            impPushOnStack(gtNewDconNode(&cval.dblVal));
            break;

        case CEE_LDC_R4:
            cval.fltVal = getR4LittleEndian(codeAddr);
            impPushOnStack(gtNewFconNode(cval.fltVal));
            break;

        case CEE_LDSTR:
            val = getU4LittleEndian(codeAddr);
            impPushOnStack(gtNewSconNode(val, scpHandle));
            break;

        case CEE_LDARG_0:
        case CEE_LDARG_1:
        case CEE_LDARG_2:
        case CEE_LDARG_3:
                lclNum = (opcode - CEE_LDARG_0);
                assert(lclNum >= 0 && lclNum < 4);
                goto LOAD_ARG;

        case CEE_LDARG_S:
            lclNum = getU1LittleEndian(codeAddr);
            goto LOAD_ARG;

        case CEE_LDARG:
            lclNum = getU2LittleEndian(codeAddr);

        LOAD_ARG:

            assert(lclNum < argCnt);

            /* Get the argument type */

            lclTyp  = lclTypeInfo[lclNum];

            assert(lclTyp != TYP_STRUCT);

            /* Get the argument node */

            op1 = inlArgInfo[lclNum].argNode;

            /* Is the argument a constant or local var */

            if (inlArgInfo[lclNum].argIsConst)
            {
                if (inlArgInfo[lclNum].argIsUsed)
                {
                    /* Node already used - Clone the constant */
                    op1 = gtCloneExpr(op1, 0);
                }
            }
            else if (inlArgInfo[lclNum].argIsLclVar)
            {
                /* Argument is a local variable (of the caller)
                 * Can we re-use the passed argument node? */

                if (inlArgInfo[lclNum].argIsUsed)
                {
                    assert(op1->gtOper == GT_LCL_VAR);
                    assert(lclNum == op1->gtLclVar.gtLclOffs);

                    /* Create a new lcl var node - remember the argument lclNum */
                    op1 = gtNewLclvNode(op1->gtLclVar.gtLclNum, lclTyp, op1->gtLclVar.gtLclOffs);
                }
            }
            else
            {
                /* Argument is a complex expression - has it been eval to a temp */

                if (inlArgInfo[lclNum].argHasTmp)
                {
                    assert(inlArgInfo[lclNum].argIsUsed);
                    assert(inlArgInfo[lclNum].argTmpNum < lvaCount);

                    /* Create a new lcl var node - remember the argument lclNum */
                    op1 = gtNewLclvNode(inlArgInfo[lclNum].argTmpNum, lclTyp, lclNum);

                    /* This is the second use of the argument so NO bashing of temp */
                    inlArgInfo[lclNum].argTmpNode = NULL;
                }
                else
                {
                    /* First time use */
                    assert(inlArgInfo[lclNum].argIsUsed == false);

                    /* Allocate a temp for the expression - if no side effects
                     * use a large size node, maybe later we can bash it */

                    tmpNum = lvaGrabTemp();

                    lvaTable[tmpNum].lvType = lclTyp;
                    lvaTable[tmpNum].lvAddrTaken = 0;

                    impInlineTemps++;

                    inlArgInfo[lclNum].argHasTmp = true;
                    inlArgInfo[lclNum].argTmpNum = tmpNum;

                    if (inlArgInfo[lclNum].argHasSideEff)
                        op1 = gtNewLclvNode(tmpNum, lclTyp, lclNum);
                    else
                    {
                        op1 = gtNewLclLNode(tmpNum, lclTyp, lclNum);
                        inlArgInfo[lclNum].argTmpNode = op1;
                    }
                }
            }

            /* Mark the argument as used */

            inlArgInfo[lclNum].argIsUsed = true;

            /* Push the argument value on the stack */

            impPushOnStack(op1);
            break;

        case CEE_LDLOC:
            lclNum = getU2LittleEndian(codeAddr);
            goto LOAD_LCL_VAR;

        case CEE_LDLOC_0:
        case CEE_LDLOC_1:
        case CEE_LDLOC_2:
        case CEE_LDLOC_3:
                lclNum = (opcode - CEE_LDLOC_0);
                assert(lclNum >= 0 && lclNum < 4);
                goto LOAD_LCL_VAR;

        case CEE_LDLOC_S:
            lclNum = getU1LittleEndian(codeAddr);

        LOAD_LCL_VAR:

            assert(lclNum < lclCnt);

            /* Get the local type */

            lclTyp  = lclTypeInfo[lclNum + argCnt];

            assert(lclTyp != TYP_STRUCT);

            /* Have we allocated a temp for this local? */

            if  (lclTmpNum[lclNum] == -1)
            {
                /* Use before def - there must be a goto or something later on */

                JITLOG((INFO7, "INLINER FAILED: Use of local var before def: %s called by %s\n",
                                                  eeGetMethodFullName(fncHandle), info.compFullName));

                goto ABORT;
            }

            /* Remember the original lcl number */

            initLclNum = lclNum + argCnt;

            /* Get the temp lcl number */

            lclNum = lclTmpNum[lclNum];

            /* Since this is a load the type is normalized,
             * so we can bash it to the actual type
             * unless it is aliased, in which case we need to insert a cast */

            if ((genTypeSize(lclTyp) < sizeof(int)) && (lvaTable[lclNum].lvAddrTaken))
            {
                op1 = gtNewLargeOperNode(GT_CAST,
                                         (var_types)TYP_INT,
                                         gtNewLclvNode(lclNum, lclTyp, initLclNum),
                                         gtNewIconNode((var_types)TYP_INT));
            }
            else
                op1 = gtNewLclvNode(lclNum, genActualType(lclTyp), initLclNum);

            /* Push the local variable value on the stack */

            impPushOnStack(op1);
            break;

        /* STORES */

        case CEE_STARG_S:
        case CEE_STARG:
            /* Storing into arguments not allowed */

            JITLOG((INFO7, "INLINER FAILED: Storing into arguments not allowed: %s called by %s\n",
                                              eeGetMethodFullName(fncHandle), info.compFullName));

            goto ABORT;

        case CEE_STLOC:
            lclNum = getU2LittleEndian(codeAddr);
            goto LCL_STORE;

        case CEE_STLOC_0:
        case CEE_STLOC_1:
        case CEE_STLOC_2:
        case CEE_STLOC_3:
                lclNum = (opcode - CEE_STLOC_0);
                assert(lclNum >= 0 && lclNum < 4);
                goto LCL_STORE;

        case CEE_STLOC_S:
            lclNum = getU1LittleEndian(codeAddr);

        LCL_STORE:

            /* Make sure the local number isn't too high */

            assert(lclNum < lclCnt);

            /* Pop the value being assigned */

            op1 = impPopStack();

            // We had better assign it a value of the correct type

            lclTyp = lclTypeInfo[lclNum + argCnt];

            assert(genActualType(lclTyp) == genActualType(op1->gtType) ||
                   lclTyp == TYP_I_IMPL && op1->IsVarAddr() ||
                   (genActualType(lclTyp) == TYP_INT && op1->gtType == TYP_BYREF)||
                   (genActualType(op1->gtType) == TYP_INT && lclTyp == TYP_BYREF));

            /* If op1 is "&var" then its type is the transient "*" and it can
               be used either as TYP_BYREF or TYP_I_IMPL */

            if (op1->IsVarAddr())
            {
                assert(lclTyp == TYP_I_IMPL || lclTyp == TYP_BYREF);

                /* When "&var" is created, we assume it is a byref. If it is
                   being assigned to a TYP_I_IMPL var, bash the type to
                   prevent unnecessary GC info */

                if (lclTyp == TYP_I_IMPL)
                    op1->gtType = TYP_I_IMPL;
            }

            /* Have we allocated a temp for this local? */

            tmpNum = lclTmpNum[lclNum];

            if  (tmpNum == -1)
            {
                 lclTmpNum[lclNum] = tmpNum = lvaGrabTemp();

                 lvaTable[tmpNum].lvType = lclTyp;
                 lvaTable[tmpNum].lvAddrTaken = 0;

                 impInlineTemps++;
            }

            /* Record this use of the variable slot */

            //lvaTypeRefs[tmpNum] |= Compiler::lvaTypeRefMask(op1->TypeGet());

            /* Create the assignment node */

            op1 = gtNewAssignNode(gtNewLclvNode(tmpNum, lclTyp, lclNum + argCnt), op1);


INLINE_APPEND:

            /* CONSIDER: Spilling indiscriminantelly is too conservative */

            impInlineSpillSideEffects();

            /* The value better have side effects */

            assert(op1->gtFlags & GTF_SIDE_EFFECT);

            /* Append to the 'init' expression */

            impInitExpr = impConcatExprs(impInitExpr, op1);

            break;

        case CEE_ENDFINALLY:
        case CEE_ENDFILTER:
            assert(!"Shouldn't have exception handlers in the inliner!");
            goto ABORT;

        case CEE_RET:
            if (fncRetType != TYP_VOID)
            {
                bodyExp = impPopStack();

                if (genActualType(bodyExp->TypeGet()) != fncRetType)
                {
                    JITLOG((INFO7, "INLINER FAILED: Return types are not matching in %s called by %s\n",
                                   eeGetMethodFullName(fncHandle), info.compFullName));
                    goto ABORT;
                }
            }

#if INLINE_CONDITIONALS

            /* Are we in an if/else statement? */

            if  (jmpAddr)
            {
                /* For now ignore void returns inside if/else */

                if (fncRetType == TYP_VOID)
                {
                    JITLOG((INFO7, "INLINER FAILED: void return from within a conditional in %s called by %s\n",
                                   eeGetMethodFullName(fncHandle), info.compFullName));
                    goto ABORT;
                }

                /* We don't process cases that have two branches and only one return in the conditional
                 * E.g. if() {... no ret} else { ... return } ... return */

                assert(impStkDepth == 0);
                assert(ifNvoid == false);

                if (inElse)
                {
                    /* The 'if' part must have a return */
                    assert(hasCondReturn);

                    /* This must be the last instruction - i.e. cannot have code after else */
                    assert(codeAddr + sz == codeEndp);
                    if (codeAddr + sz != codeEndp)
                    {
                        JITLOG((INFO7, "INLINER FAILED: Cannot have code following else in %s called by %s\n",
                                       eeGetMethodFullName(fncHandle), info.compFullName));
                        goto ABORT;
                    }
                }
                else
                {
                    assert(!hasCondReturn);
                    hasCondReturn = true;

                    /* Grab a temp for the return local variable */
                    retLclNum = lvaGrabTemp();
                    impInlineTemps++;
                }

                /* Assign the return value to the return local variable */
                op1 = gtNewAssignNode(gtNewLclvNode(retLclNum, fncRetType, retLclNum), bodyExp);

                /* Append the assignment to the current body of the branch */
                impInitExpr = impConcatExprs(impInitExpr, op1);

                if (!inElse)
                {
                    /* Remember the 'if' statement part */
                    ifStmts = impInitExpr;
                              impInitExpr = NULL;

                    /* The next instruction will start at 'jmpAddr' */
                    codeAddr += (jmpAddr - codeAddr) - sz;

                    /* The rest of the code is the else part - so its end is the end of the code */
                    jmpAddr = codeEndp;
                    inElse  = true;
                }
                break;


#if 0
                /* UNDONE: Allow returns within if/else statements */

                JITLOG((INFO7, "INLINER FAILED: Cannot return from if / else in %s called by %s\n",
                               eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
#endif
            }
#endif

            if (impStkDepth != 0)   NO_WAY("Stack must be 0 on return");

            goto DONE;


        case CEE_LDELEMA :
            assert(sz == sizeof(unsigned));
            typeRef = getU4LittleEndian(codeAddr);
            clsHnd = eeFindClass(typeRef, scpHandle, fncHandle, false);
            clsFlags = eeGetClassAttribs(clsHnd);

            if (!clsHnd)
            {
                JITLOG((INFO8, "INLINER FAILED: Cannot get class handle: %s called by %s\n",
                               eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }

            if (clsFlags & FLG_VALUECLASS)
                lclTyp = TYP_STRUCT;
            else
            {
                op1 = gtNewIconEmbClsHndNode(clsHnd, typeRef, info.compScopeHnd);
                op1 = gtNewOperNode(GT_LIST, TYP_VOID, op1);                // Type
                op1 = gtNewOperNode(GT_LIST, TYP_VOID, impPopStack(), op1); // index
                op1 = gtNewOperNode(GT_LIST, TYP_VOID, impPopStack(), op1); // array
                op1 = gtNewHelperCallNode(CPX_LDELEMA_REF, TYP_BYREF, GTF_EXCEPT, op1);

                impPushOnStack(op1);
                break;
            }

#ifdef NOT_JITC
            // @TODO : Remove once valueclass array headers are same as primitive types
            JIT_types jitTyp;
            jitTyp = info.compCompHnd->asPrimitiveType(clsHnd);
            if (jitTyp != JIT_TYP_UNDEF)
            {
                lclTyp = JITtype2varType(jitTyp);
                assert(varTypeIsArithmetic(lclTyp));
            }
#endif
            goto ARR_LD;

        case CEE_LDELEM_I1 : lclTyp = TYP_BYTE  ; goto ARR_LD;
        case CEE_LDELEM_I2 : lclTyp = TYP_SHORT ; goto ARR_LD;
        case CEE_LDELEM_I  :
        case CEE_LDELEM_U4 :
        case CEE_LDELEM_I4 : lclTyp = TYP_INT   ; goto ARR_LD;
        case CEE_LDELEM_I8 : lclTyp = TYP_LONG  ; goto ARR_LD;
        case CEE_LDELEM_REF: lclTyp = TYP_REF   ; goto ARR_LD;
        case CEE_LDELEM_R4 : lclTyp = TYP_FLOAT ; goto ARR_LD;
        case CEE_LDELEM_R8 : lclTyp = TYP_DOUBLE; goto ARR_LD;
        case CEE_LDELEM_U1 : lclTyp = TYP_UBYTE ; goto ARR_LD;
        case CEE_LDELEM_U2 : lclTyp = TYP_CHAR  ; goto ARR_LD;

        ARR_LD:

#if CSELENGTH
            fgHasRangeChks = true;
#endif

            /* Pull the index value and array address */

            op2 = impPopStack();
            op1 = impPopStack();   assert (op1->gtType == TYP_REF);

            /* Check for null pointer - in the inliner case we simply abort */

            if (op1->gtOper == GT_CNS_INT)
            {
                JITLOG((INFO7, "INLINER FAILED: NULL pointer for LDELEM in %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

            /* Create the index node and push it on the stack */
            op1 = gtNewIndexRef(lclTyp, op1, op2);
            if (opcode == CEE_LDELEMA)
            {
                    // rememer the element size
                if (lclTyp == TYP_REF)
                    op1->gtIndex.elemSize = sizeof(void*);
                else
                                        op1->gtIndex.elemSize = eeGetClassSize(clsHnd);
                    // wrap it in a &
                op1 = gtNewOperNode(GT_ADDR, ((clsFlags & FLG_UNMANAGED) ? TYP_I_IMPL : TYP_BYREF), op1);
            }

            impPushOnStack(op1);
            break;


        case CEE_STELEM_REF:

            // CONSIDER: Check for assignment of null and generate inline code

            /* Call a helper function to do the assignment */

            op1 = gtNewHelperCallNode(CPX_ARRADDR_ST,
                                      TYP_REF,
                                      GTF_CALL_REGSAVE,
                                      impPopList(3, &flags));

            goto INLINE_APPEND;


        case CEE_STELEM_I1: lclTyp = TYP_BYTE  ; goto ARR_ST;
        case CEE_STELEM_I2: lclTyp = TYP_SHORT ; goto ARR_ST;
        case CEE_STELEM_I:
        case CEE_STELEM_I4: lclTyp = TYP_INT   ; goto ARR_ST;
        case CEE_STELEM_I8: lclTyp = TYP_LONG  ; goto ARR_ST;
        case CEE_STELEM_R4: lclTyp = TYP_FLOAT ; goto ARR_ST;
        case CEE_STELEM_R8: lclTyp = TYP_DOUBLE; goto ARR_ST;

        ARR_ST:

            if (info.compStrictExceptions &&
                (impStackTop()->gtFlags & GTF_SIDE_EFFECT) )
            {
                impInlineSpillSideEffects();
            }

#if CSELENGTH
            inlineeHasRangeChks = true;
#endif

            /* Pull the new value from the stack */

            op2 = impPopStack();
            if (op2->IsVarAddr())
                op2->gtType = TYP_I_IMPL;

            /* Pull the index value */

            op1 = impPopStack();

            /* Pull the array address */

            arr = impPopStack();   assert (arr->gtType == TYP_REF);

            /* Check for null pointer - in the inliner case we simply abort */

            if (arr->gtOper == GT_CNS_INT)
            {
                JITLOG((INFO7, "INLINER FAILED: NULL pointer for STELEM in %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

            /* Create the index node */

            op1 = gtNewIndexRef(lclTyp, arr, op1);

            /* Create the assignment node and append it */

            op1 = gtNewAssignNode(op1, op2);

            goto INLINE_APPEND;

        case CEE_DUP:

            if (jmpAddr)
            {
                JITLOG((INFO7, "INLINER FAILED: DUP inside of conditional in %s called by %s\n",
                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

            /* Spill any side effects from the stack */

            impInlineSpillSideEffects();

            /* Pull the top value from the stack */

            op1 = impPopStack(clsHnd);

            /* HACKHACK: We allow only cloning of simple nodes. That way
               it is easy for us to track the dup of a local var.
               CONSIDER: Don't globally disable the bashing of the temp node
               as soon as any local var has been duplicated! Unfortunately
               the local var node doesn't give us the index into inlArgInfo,
               i.e. we would have to linearly scan the array in order to reset
               argTmpNode.
            */

            /* Is the value simple enough to be cloneable? */

            op2 = gtClone(op1, false);

            if (!op2)
            {
                if  (op1->gtOper == GT_ADD)
                {
                    GenTreePtr  op3 = op1->gtOp.gtOp1;
                    GenTreePtr  op4 = op1->gtOp.gtOp2;

                    if  (op3->OperIsLeaf() &&
                         op4->OperIsLeaf())
                    {
                        op2 =  gtNewOperNode(GT_ADD,
                                             op1->TypeGet(),
                                             gtClone(op3),
                                             gtClone(op4));

                        op2->gtFlags |= (op1->gtFlags &
                                        (GTF_OVERFLOW|GTF_EXCEPT|GTF_UNSIGNED));

                        if (op3->gtOper == GT_LCL_VAR || op4->gtOper == GT_LCL_VAR)
                            dupOfLclVar = true;


                    }
                }
            }
            else if (op2->gtOper == GT_LCL_VAR)
            {
                dupOfLclVar = true;
            }

            if  (op2)
            {
                /* Cool - we can stuff two copies of the value back */
                impPushOnStack(op1, clsHnd);
                impPushOnStack(op2, clsHnd);
                break;
            }

            /* expression too complicated */

            JITLOG((INFO7, "INLINER FAILED: DUP of complex expression in %s called by %s\n",
                                            eeGetMethodFullName(fncHandle), info.compFullName));
            goto ABORT;


        case CEE_ADD:           oper = GT_ADD;      goto MATH_OP2;

        case CEE_ADD_OVF:       lclTyp = TYP_UNKNOWN; uns = false;  goto ADD_OVF;

        case CEE_ADD_OVF_UN:    lclTyp = TYP_UNKNOWN; uns = true; goto ADD_OVF;

ADD_OVF:

            ovfl = true;        callNode = false;
            oper = GT_ADD;      goto MATH_OP2_FLAGS;

        case CEE_SUB:           oper = GT_SUB;      goto MATH_OP2;

        case CEE_SUB_OVF:       lclTyp = TYP_UNKNOWN; uns = false;  goto SUB_OVF;

        case CEE_SUB_OVF_UN:    lclTyp = TYP_UNKNOWN; uns = true;   goto SUB_OVF;

SUB_OVF:
            ovfl = true;
            callNode = false;
            oper = GT_SUB;
            goto MATH_OP2_FLAGS;

        case CEE_MUL:           oper = GT_MUL;      goto MATH_CALL_ON_LNG;

        case CEE_MUL_OVF:       lclTyp = TYP_UNKNOWN; uns = false;  goto MUL_OVF;

        case CEE_MUL_OVF_UN:    lclTyp = TYP_UNKNOWN; uns = true; goto MUL_OVF;

        MUL_OVF:
                                ovfl = true;        callNode = false;
                                oper = GT_MUL;      goto MATH_CALL_ON_LNG_OVF;

        // Other binary math operations

        case CEE_DIV :          oper = GT_DIV;  goto MATH_CALL_ON_LNG;

        case CEE_DIV_UN :       oper = GT_UDIV;  goto MATH_CALL_ON_LNG;

        case CEE_REM:
            oper = GT_MOD;
            ovfl = false;
            callNode = true;
                // can use small node for INT case
            if (impStackTop()->gtType == TYP_INT)
                callNode = false;
            goto MATH_OP2_FLAGS;

        case CEE_REM_UN :       oper = GT_UMOD;  goto MATH_CALL_ON_LNG;

        MATH_CALL_ON_LNG:
            ovfl = false;
        MATH_CALL_ON_LNG_OVF:
            callNode = false;
            if (impStackTop()->gtType == TYP_LONG)
                callNode = true;
            goto MATH_OP2_FLAGS;

        case CEE_AND:        oper = GT_AND;  goto MATH_OP2;
        case CEE_OR:         oper = GT_OR ;  goto MATH_OP2;
        case CEE_XOR:        oper = GT_XOR;  goto MATH_OP2;

        MATH_OP2:       // For default values of 'ovfl' and 'callNode'

            ovfl        = false;
            callNode    = false;

        MATH_OP2_FLAGS: // If 'ovfl' and 'callNode' have already been set

            /* Pull two values and push back the result */

            op2 = impPopStack();
            op1 = impPopStack();

#if!CPU_HAS_FP_SUPPORT
            if (op1->gtType == TYP_FLOAT || op1->gtType == TYP_DOUBLE)
                callNode    = true;
#endif
            /* Cant do arithmetic with references */
            assert(genActualType(op1->TypeGet()) != TYP_REF &&
                   genActualType(op2->TypeGet()) != TYP_REF);

            // Arithemetic operations are generally only allowed with
            // primitive types, but certain operations are allowed
            // with byrefs

            if ((oper == GT_SUB) &&
                (genActualType(op1->TypeGet()) == TYP_BYREF ||
                 genActualType(op2->TypeGet()) == TYP_BYREF))
            {
                // byref1-byref2 => gives an int
                // byref - int   => gives a byref

                if ((genActualType(op1->TypeGet()) == TYP_BYREF) &&
                    (genActualType(op2->TypeGet()) == TYP_BYREF))
                {
                    // byref1-byref2 => gives an int
                    type = TYP_I_IMPL;
                    impBashVarAddrsToI(op1, op2);
                }
                else
                {
                    // byref - int => gives a byref
                    // (but if &var, then dont need to report to GC)

                    assert(genActualType(op1->TypeGet()) == TYP_I_IMPL ||
                           genActualType(op2->TypeGet()) == TYP_I_IMPL);

                    impBashVarAddrsToI(op1, op2);

                    if (genActualType(op1->TypeGet()) == TYP_BYREF ||
                        genActualType(op2->TypeGet()) == TYP_BYREF)
                        type = TYP_BYREF;
                    else
                        type = TYP_I_IMPL;
                }
            }
            else if ((oper == GT_ADD) &&
                     (genActualType(op1->TypeGet()) == TYP_BYREF ||
                      genActualType(op2->TypeGet()) == TYP_BYREF))
            {
                // only one can be a byref : byref+byref not allowed
                assert(genActualType(op1->TypeGet()) != TYP_BYREF ||
                       genActualType(op2->TypeGet()) != TYP_BYREF);
                assert(genActualType(op1->TypeGet()) == TYP_I_IMPL ||
                       genActualType(op2->TypeGet()) == TYP_I_IMPL);

                // byref + int => gives a byref
                // (but if &var, then dont need to report to GC)

                impBashVarAddrsToI(op1, op2);

                if (genActualType(op1->TypeGet()) == TYP_BYREF ||
                    genActualType(op2->TypeGet()) == TYP_BYREF)
                    type = TYP_BYREF;
                else
                    type = TYP_I_IMPL;
            }
            else
            {
                assert(genActualType(op1->TypeGet()) != TYP_BYREF &&
                       genActualType(op2->TypeGet()) != TYP_BYREF);

                assert(genActualType(op1->TypeGet()) ==
                       genActualType(op2->TypeGet()));

                type = genActualType(op1->gtType);
            }

            /* Special case: "int+0", "int-0", "int*1", "int/1" */

            if  (op2->gtOper == GT_CNS_INT)
            {
                if  (((op2->gtIntCon.gtIconVal == 0) && (oper == GT_ADD || oper == GT_SUB)) ||
                     ((op2->gtIntCon.gtIconVal == 1) && (oper == GT_MUL || oper == GT_DIV)))

                {
                    impPushOnStack(op1);
                    break;
                }
            }

            /* Special case: "int+0", "int-0", "int*1", "int/1" */

            if  (op2->gtOper == GT_CNS_INT)
            {
                if  (((op2->gtIntCon.gtIconVal == 0) && (oper == GT_ADD || oper == GT_SUB)) ||
                     ((op2->gtIntCon.gtIconVal == 1) && (oper == GT_MUL || oper == GT_DIV)))

                {
                    impPushOnStack(op1);
                    break;
                }
            }

#if SMALL_TREE_NODES
            if (callNode)
            {
                /* These operators later get transformed into 'GT_CALL' */

                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_MUL]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_DIV]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_UDIV]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_MOD]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] > GenTree::s_gtNodeSizes[GT_UMOD]);

                op1 = gtNewOperNode(GT_CALL, type, op1, op2);
                op1->ChangeOper(oper);
            }
            else
#endif
            {
                op1 = gtNewOperNode(oper,    type, op1, op2);
            }

            /* Special case: integer/long division may throw an exception */

            if  (varTypeIsIntegral(op1->TypeGet()) && op1->OperMayThrow())
            {
                op1->gtFlags |=  GTF_EXCEPT;
            }

            if  (ovfl)
            {
                assert(oper==GT_ADD || oper==GT_SUB || oper==GT_MUL);
                if (lclTyp != TYP_UNKNOWN)
                    op1->gtType   = lclTyp;
                op1->gtFlags |= (GTF_EXCEPT | GTF_OVERFLOW);
                if (uns)
                    op1->gtFlags |= GTF_UNSIGNED;
            }

            /* See if we can actually fold the expression */

            op1 = gtFoldExpr(op1);

            impPushOnStack(op1);
            break;

        case CEE_SHL:        oper = GT_LSH;  goto CEE_SH_OP2;

        case CEE_SHR:        oper = GT_RSH;  goto CEE_SH_OP2;
        case CEE_SHR_UN:     oper = GT_RSZ;  goto CEE_SH_OP2;

        CEE_SH_OP2:

            op2     = impPopStack();

            // The shiftAmount is a U4.
            assert(genActualType(op2->TypeGet()) == TYP_INT);

            op1     = impPopStack();    // operand to be shifted

            type    = genActualType(op1->TypeGet());
            op1     = gtNewOperNode(oper, type, op1, op2);

            op1 = gtFoldExpr(op1);
            impPushOnStack(op1);
            break;

        case CEE_NOT:

            op1 = impPopStack();

            op1 = gtNewOperNode(GT_NOT, op1->TypeGet(), op1);

            op1 = gtFoldExpr(op1);
            impPushOnStack(op1);
            break;

        case CEE_CKFINITE:

            op1 = impPopStack();
            op1 = gtNewOperNode(GT_CKFINITE, op1->TypeGet(), op1);
            op1->gtFlags |= GTF_EXCEPT;

            impPushOnStack(op1);
            break;


        /************************** Casting OPCODES ***************************/

        case CEE_CONV_OVF_I1:   lclTyp = TYP_BYTE  ;    goto CONV_OVF;
        case CEE_CONV_OVF_I2:   lclTyp = TYP_SHORT ;    goto CONV_OVF;
        case CEE_CONV_OVF_I :
        case CEE_CONV_OVF_I4:   lclTyp = TYP_INT   ;    goto CONV_OVF;
        case CEE_CONV_OVF_I8:   lclTyp = TYP_LONG  ;    goto CONV_OVF;

        case CEE_CONV_OVF_U1:   lclTyp = TYP_UBYTE ;    goto CONV_OVF;
        case CEE_CONV_OVF_U2:   lclTyp = TYP_CHAR  ;    goto CONV_OVF;
        case CEE_CONV_OVF_U :
        case CEE_CONV_OVF_U4:   lclTyp = TYP_UINT  ;    goto CONV_OVF;
        case CEE_CONV_OVF_U8:   lclTyp = TYP_ULONG ;    goto CONV_OVF;

        case CEE_CONV_OVF_I1_UN:   lclTyp = TYP_BYTE  ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_I2_UN:   lclTyp = TYP_SHORT ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_I_UN :
        case CEE_CONV_OVF_I4_UN:   lclTyp = TYP_INT   ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_I8_UN:   lclTyp = TYP_LONG  ;    goto CONV_OVF_UN;

        case CEE_CONV_OVF_U1_UN:   lclTyp = TYP_UBYTE ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_U2_UN:   lclTyp = TYP_CHAR  ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_U_UN :
        case CEE_CONV_OVF_U4_UN:   lclTyp = TYP_UINT  ;    goto CONV_OVF_UN;
        case CEE_CONV_OVF_U8_UN:   lclTyp = TYP_ULONG ;    goto CONV_OVF_UN;

CONV_OVF_UN:
            uns      = true;    goto CONV_OVF_COMMON;
CONV_OVF:
            uns      = false;
CONV_OVF_COMMON:
            callNode = false;
            ovfl     = true;

            // all overflow converts from floats get morphed to calls
            // only converts from floating point get morphed to calls
            if (impStackTop()->gtType == TYP_DOUBLE ||
                impStackTop()->gtType == TYP_FLOAT)
            {
                callNode = true;
            }
            goto _CONV;

        case CEE_CONV_I1:       lclTyp = TYP_BYTE  ;    goto CONV_CALL;
        case CEE_CONV_I2:       lclTyp = TYP_SHORT ;    goto CONV_CALL;
        case CEE_CONV_I:
        case CEE_CONV_I4:       lclTyp = TYP_INT   ;    goto CONV_CALL;
        case CEE_CONV_I8:
            lclTyp   = TYP_LONG;
            uns      = false;
            ovfl     = false;
            callNode = true;

            // I4 to I8 can be a small node
            if (impStackTop()->gtType == TYP_INT)
                callNode = false;
            goto _CONV;

        case CEE_CONV_U1:       lclTyp = TYP_UBYTE ;    goto CONV_CALL_UN;
        case CEE_CONV_U2:       lclTyp = TYP_CHAR  ;    goto CONV_CALL_UN;
        case CEE_CONV_U:
        case CEE_CONV_U4:       lclTyp = TYP_UINT  ;    goto CONV_CALL_UN;
        case CEE_CONV_U8:       lclTyp = TYP_ULONG ;    goto CONV_CALL_UN;
        case CEE_CONV_R_UN :    lclTyp = TYP_DOUBLE;    goto CONV_CALL_UN;

        case CEE_CONV_R4:       lclTyp = TYP_FLOAT;     goto CONV_CALL;
        case CEE_CONV_R8:       lclTyp = TYP_DOUBLE;    goto CONV_CALL;

CONV_CALL_UN:
            uns      = true;    goto CONV_CALL_COMMON;
CONV_CALL:
            uns      = false;
CONV_CALL_COMMON:
            ovfl     = false;
            callNode = true;
            goto _CONV;

_CONV:      // At this point uns, ovf, callNode all set
            op1  = impPopStack();

            impBashVarAddrsToI(op1);

            /* Check for a worthless cast, such as "(byte)(int & 32)" */

            if  (lclTyp < TYP_INT && op1->gtType == TYP_INT
                                  && op1->gtOper == GT_AND)
            {
                op2 = op1->gtOp.gtOp2;

                if  (op2->gtOper == GT_CNS_INT)
                {
                    int         ival = op2->gtIntCon.gtIconVal;
                    int         mask;

                    switch (lclTyp)
                    {
                    case TYP_BYTE :
                    case TYP_UBYTE: mask = 0x00FF; break;
                    case TYP_CHAR :
                    case TYP_SHORT: mask = 0xFFFF; break;

                    default:
                        assert(!"unexpected type");
                    }

                    if  ((ival & mask) == ival)
                    {
                        /* Toss the cast, it's a waste of time */

                        impPushOnStack(op1);
                        break;
                    }
                }
            }

            /*  The 'op2' sub-operand of a cast is the 'real' type number,
                since the result of a cast to one of the 'small' integer
                types is an integer.
             */

            op2  = gtNewIconNode(lclTyp);
            type = genActualType(lclTyp);

#if SMALL_TREE_NODES
            if (callNode)
            {
                /* These casts get transformed into 'GT_CALL' or 'GT_IND' nodes */

                assert(GenTree::s_gtNodeSizes[GT_CALL] >  GenTree::s_gtNodeSizes[GT_CAST]);
                assert(GenTree::s_gtNodeSizes[GT_CALL] >= GenTree::s_gtNodeSizes[GT_IND ]);

                op1 = gtNewOperNode(GT_CALL, type, op1, op2);
                op1->ChangeOper(GT_CAST);
            }
#endif
            else
            {
                op1 = gtNewOperNode(GT_CAST, type, op1, op2);
            }

            if (ovfl)
                op1->gtFlags |= (GTF_OVERFLOW|GTF_EXCEPT);
            if (uns)
                op1->gtFlags |= GTF_UNSIGNED;

            op1 = gtFoldExpr(op1);
            impPushOnStack(op1);
            break;

        case CEE_NEG:

            op1 = impPopStack();

            op1 = gtNewOperNode(GT_NEG, genActualType(op1->gtType), op1);

            op1 = gtFoldExpr(op1);
            impPushOnStack(op1);
            break;

        case CEE_POP:

            /* Pull the top value from the stack */

            op1 = impPopStack();

            /* Does the value have any side effects? */

            if  (op1->gtFlags & GTF_SIDE_EFFECT)
            {
                /* Create an unused node (a cast to void) which means
                 * we only need to evaluate the side effects */

                op1 = gtUnusedValNode(op1);

                goto INLINE_APPEND;
            }

            /* No side effects - just throw the thing away */

            break;

        case CEE_STIND_I1:      lclTyp  = TYP_BYTE;     goto STIND;
        case CEE_STIND_I2:      lclTyp  = TYP_SHORT;    goto STIND;
        case CEE_STIND_I4:      lclTyp  = TYP_INT;      goto STIND;
        case CEE_STIND_I8:      lclTyp  = TYP_LONG;     goto STIND;
        case CEE_STIND_I:       lclTyp  = TYP_I_IMPL;   goto STIND;
        case CEE_STIND_REF:     lclTyp  = TYP_REF;      goto STIND;
        case CEE_STIND_R4:      lclTyp  = TYP_FLOAT;    goto STIND;
        case CEE_STIND_R8:      lclTyp  = TYP_DOUBLE;   goto STIND;
STIND:
            op2 = impPopStack();    // value to store
            op1 = impPopStack();    // address to store to

            // you can indirect off of a TYP_I_IMPL (if we are in C) or a BYREF
            assert(genActualType(op1->gtType) == TYP_I_IMPL ||
                                 op1->gtType  == TYP_BYREF);

            impBashVarAddrsToI(op1, op2);

            if (opcode == CEE_STIND_REF)
            {
                                        // STIND_REF can be used to store TYP_I_IMPL, TYP_REF, or TYP_BYREF
                assert(op1->gtType == TYP_BYREF || op2->gtType == TYP_I_IMPL);
                lclTyp = genActualType(op2->TypeGet());
            }

                // Check target type.
#if 0           // enable if necessary
#ifdef DEBUG
            if (op2->gtType == TYP_BYREF || lclTyp == TYP_BYREF)
            {
                if (op2->gtType == TYP_BYREF)
                    assert(lclTyp == TYP_BYREF || lclTyp == TYP_I_IMPL);
                else if (lclTyp == TYP_BYREF)
                    assert(op2->gtType == TYP_BYREF ||op2->gtType == TYP_I_IMPL);
            }
            else
#endif
#endif
                assert(genActualType(op2->gtType) == genActualType(lclTyp));


            op1->gtFlags |= GTF_NON_GC_ADDR;

            op1 = gtNewOperNode(GT_IND, lclTyp, op1);
            op1->gtFlags |= GTF_IND_TGTANYWHERE;

            if (volatil)
            {
                // Not really needed as we dont CSE the target of an assignment
                op1->gtFlags |= GTF_DONT_CSE;
                volatil = false;
            }

            op1 = gtNewAssignNode(op1, op2);
            op1->gtFlags |= GTF_EXCEPT | GTF_GLOB_REF;

            goto INLINE_APPEND;


        case CEE_LDIND_I1:      lclTyp  = TYP_BYTE;     goto LDIND;
        case CEE_LDIND_I2:      lclTyp  = TYP_SHORT;    goto LDIND;
        case CEE_LDIND_U4:
        case CEE_LDIND_I4:      lclTyp  = TYP_INT;      goto LDIND;
        case CEE_LDIND_I8:      lclTyp  = TYP_LONG;     goto LDIND;
        case CEE_LDIND_REF:     lclTyp  = TYP_REF;      goto LDIND;
        case CEE_LDIND_I:       lclTyp  = TYP_I_IMPL;   goto LDIND;
        case CEE_LDIND_R4:      lclTyp  = TYP_FLOAT;    goto LDIND;
        case CEE_LDIND_R8:      lclTyp  = TYP_DOUBLE;   goto LDIND;
        case CEE_LDIND_U1:      lclTyp  = TYP_UBYTE;    goto LDIND;
        case CEE_LDIND_U2:      lclTyp  = TYP_CHAR;     goto LDIND;
LDIND:
            op1 = impPopStack();    // address to load from

            impBashVarAddrsToI(op1);

            assert(genActualType(op1->gtType) == TYP_I_IMPL ||
                                 op1->gtType  == TYP_BYREF);

            op1->gtFlags |= GTF_NON_GC_ADDR;

            op1 = gtNewOperNode(GT_IND, lclTyp, op1);
            op1->gtFlags |= GTF_EXCEPT | GTF_GLOB_REF;

            if (volatil)
            {
                op1->gtFlags |= GTF_DONT_CSE;
                volatil = false;
            }

            impPushOnStack(op1);
            break;

        case CEE_VOLATILE:
            volatil = true;
            break;

        case CEE_LDFTN:

            memberRef = getU4LittleEndian(codeAddr);
                                // Note need to do this here to perform the access check.
            methHnd   = eeFindMethod(memberRef, scpHandle, fncHandle, false);

            if (!methHnd)
            {
                JITLOG((INFO8, "INLINER FAILED: Cannot get method handle: %s called by %s\n",
                                                       eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }

            op1 = gtNewIconHandleNode(memberRef, GTF_ICON_FTN_ADDR, (unsigned)scpHandle);
            op1->gtVal.gtVal2 = (unsigned)scpHandle;
            op1->ChangeOper(GT_FTN_ADDR);
            op1->gtType = TYP_I_IMPL;
            impPushOnStack(op1);
            break;

        case CEE_LDVIRTFTN:

            /* Get the method token */

            memberRef = getU4LittleEndian(codeAddr);
            methHnd   = eeFindMethod(memberRef, scpHandle, fncHandle, false);

            if (!methHnd)
            {
                JITLOG((INFO8, "INLINER FAILED: Cannot get method handle: %s called by %s\n",
                                                       eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }

            mflags = eeGetMethodAttribs(methHnd);
            if (mflags & (FLG_PRIVATE|FLG_FINAL|FLG_STATIC))
                NO_WAY("CEE_LDVIRTFTN cant be used on private/final/static");

            op2 = gtNewIconEmbMethHndNode(methHnd);

            /* Get the object-ref */

            op1 = impPopStack();
            assert(op1->gtType == TYP_REF);

            clsFlags = eeGetClassAttribs(eeGetMethodClass(methHnd));

            /* For non-interface calls, get the vtable-ptr from the object */
            if (!(clsFlags & FLG_INTERFACE) || getNewCallInterface())
                op1 = gtNewOperNode(GT_IND, TYP_I_IMPL, op1);

            op1 = gtNewOperNode(GT_VIRT_FTN, TYP_I_IMPL, op1, op2);

            op1->gtFlags |= GTF_EXCEPT; // Null-pointer exception

            /*@TODO this shouldn't be marked as a call anymore */

            if (clsFlags & FLG_INTERFACE)
                op1->gtFlags |= GTF_CALL_INTF | GTF_CALL;

            impPushOnStack(op1);
            break;


        case CEE_LDFLD:
        case CEE_LDSFLD:
        case CEE_LDFLDA:
        case CEE_LDSFLDA:

            /* Get the CP_Fieldref index */
            assert(sz == sizeof(unsigned));
            memberRef = getU4LittleEndian(codeAddr);
            fldHnd = eeFindField(memberRef, scpHandle, fncHandle, false);

            if (!fldHnd)
            {
                JITLOG((INFO8, "INLINER FAILED: Cannot get field handle: %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }

            /* Figure out the type of the member */
            lclTyp = eeGetFieldType(fldHnd, &clsHnd);

            if (lclTyp == TYP_STRUCT && (opcode == CEE_LDFLD || opcode == CEE_LDSFLD))
            {
                JITLOG((INFO7, "INLINER FAILED: ldfld of valueclass\n"));
                goto ABORT;
            }


            /* Preserve 'small' int types */
            if  (lclTyp > TYP_INT) lclTyp = genActualType(lclTyp);

            /* Get hold of the flags for the member */

            flags = eeGetFieldAttribs(fldHnd);

#ifndef NOT_JITC
                /* In stand alone mode, make certain 'flags' is constant with opcode */
            if  (opcode == CEE_LDSFLD || opcode == CEE_LDSFLDA)
                flags |= FLG_STATIC;
#endif

            /* Is this a 'special' (COM) field? or a TLS ref static field? */

            if  (flags & (CORINFO_FLG_HELPER | FLG_TLS))
                goto ABORT;

            /* Create the data member node */

            op1 = gtNewFieldRef(lclTyp, fldHnd);

            /* Pull the object's address if opcode say it is non-static */

            tmp = 0;
            if  (opcode == CEE_LDFLD || opcode == CEE_LDFLDA)
            {
                tmp = impPopStack();

                /* Check for null pointer - in the inliner case we simply abort */

                if (tmp->gtOper == GT_CNS_INT && tmp->gtIntCon.gtIconVal == 0)
                {
                    JITLOG((INFO7, "INLINER FAILED: NULL pointer for LDFLD in %s called by %s\n",
                                                    eeGetMethodFullName(fncHandle), info.compFullName));
                    goto ABORT;
                }
            }

            if  (!(flags & FLG_STATIC))
            {
                if (tmp == 0)
                    NO_WAY("LDSFLD done on an instance field.  No obj pointer available");
                op1->gtField.gtFldObj = tmp;

                op1->gtFlags |= (tmp->gtFlags & GTF_GLOB_EFFECT) | GTF_EXCEPT;

                    // wrap it in a address of operator if necessary
                if (opcode == CEE_LDFLDA)
                    op1 = gtNewOperNode(GT_ADDR, varTypeIsGC(tmp->TypeGet()) ?
                                                 TYP_BYREF : TYP_I_IMPL, op1);
            }
            else
            {
                CLASS_HANDLE fldClass = eeGetFieldClass(fldHnd);
                DWORD  fldClsAttr = eeGetClassAttribs(fldClass);

                // @TODO : This is a hack. The EE will give us the handle to
                // the boxed object. We then access the unboxed object from it.
                // Remove when our story for static value classes changes.

                if (lclTyp == TYP_STRUCT && !(fldClsAttr & FLG_UNMANAGED))
                {
                    op1 = gtNewFieldRef(TYP_REF, fldHnd); // Boxed object
                    op2 = gtNewIconNode(sizeof(void*), TYP_I_IMPL);
                    op1 = gtNewOperNode(GT_ADD, TYP_REF, op1, op2);
                    op1 = gtNewOperNode(GT_IND, TYP_STRUCT, op1);
                }

                if (opcode == CEE_LDSFLDA || opcode == CEE_LDFLDA)
                {
#ifdef DEBUG
                    clsHnd = BAD_CLASS_HANDLE;
#endif
                    op1 = gtNewOperNode(GT_ADDR,
                                    (fldClsAttr & FLG_UNMANAGED) ? TYP_I_IMPL : TYP_BYREF,
                                        op1);
                }

#ifdef NOT_JITC
                /* No inline if the field class is not initialized */

                if (!(fldClsAttr & FLG_INITIALIZED))
                {
                    /* This cannot be our class, we should have refused earlier */
                    assert(eeGetMethodClass(fncHandle) != fldClass);

                    JITLOG((INFO8, "INLINER FAILED: Field class is not initialized: %s called by %s\n",
                                      eeGetMethodFullName(fncHandle), info.compFullName));

                    /* We refuse to inline this class, but don't mark it as not inlinable */
                    goto ABORT_THIS_INLINE_ONLY;
                }
#endif
            }

            impPushOnStack(op1);
            break;

        case CEE_STFLD:
        case CEE_STSFLD:

            /* Get the CP_Fieldref index */

            assert(sz == sizeof(unsigned));
            memberRef = getU4LittleEndian(codeAddr);
            fldHnd = eeFindField(memberRef, scpHandle, fncHandle, false);

            if (!fldHnd)
            {
                JITLOG((INFO8, "INLINER FAILED: Cannot get field handle: %s called by %s\n",
                                                       eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }

            flags   = eeGetFieldAttribs(fldHnd);

#ifndef NOT_JITC
                /* In stand alone mode, make certain 'flags' is constant with opcode */
            if  (opcode == CEE_STSFLD)
                 flags |= FLG_STATIC;
#endif


#ifdef NOT_JITC
            if (flags & FLG_STATIC)
            {
                /* No inline if the field class is not initialized */

                CLASS_HANDLE fldClass = eeGetFieldClass(fldHnd);

                if ( !(eeGetClassAttribs(fldClass) & FLG_INITIALIZED))
                {
                    /* This cannot be our class, we should have refused earlier */
                    assert(eeGetMethodClass(fncHandle) != fldClass);

                    JITLOG((INFO9, "INLINER FAILED: Field class is not initialized: %s called by %s\n",
                                               eeGetMethodFullName(fncHandle), info.compFullName));

                    /* We refuse to inline this class, but don't mark it as not inlinable */

                    goto ABORT_THIS_INLINE_ONLY;
                }
            }
#endif
            /* Figure out the type of the member */

            lclTyp  = eeGetFieldType   (fldHnd, &clsHnd);

            /* Check field access */

            assert(eeCanPutField(fldHnd, flags, 0, fncHandle));

            /* Preserve 'small' int types */

            if  (lclTyp > TYP_INT) lclTyp = genActualType(lclTyp);

            /* Pull the value from the stack */

            op2 = impPopStack();

            /* Spill any refs to the same member from the stack */

            impInlineSpillLclRefs(-memberRef);

            /* Is this a 'special' (COM) field? or a TLS ref static field? */

            if  (flags & (CORINFO_FLG_HELPER | FLG_TLS))
                goto ABORT;

            /* Create the data member node */

            op1 = gtNewFieldRef(lclTyp, fldHnd);

            /* Pull the object's address if opcode say it is non-static */

            tmp = 0;
            if  (opcode == CEE_STFLD)
            {
                tmp = impPopStack();

                /* Check for null pointer - in the inliner case we simply abort */

                if (tmp->gtOper == GT_CNS_INT)
                {
                    JITLOG((INFO7, "INLINER FAILED: NULL pointer for LDFLD in %s called by %s\n",
                                                    eeGetMethodFullName(fncHandle), info.compFullName));
                    goto ABORT;
                }
            }

            if  (!(flags & FLG_STATIC))
            {
                assert(tmp);
                op1->gtField.gtFldObj = tmp;
                op1->gtFlags |= (tmp->gtFlags & GTF_GLOB_EFFECT) | GTF_EXCEPT;

#if GC_WRITE_BARRIER_CALL
                if (tmp->gtType == TYP_BYREF)
                    op1->gtFlags |= GTF_IND_TGTANYWHERE;
#endif
            }

            /* Create the member assignment */

            op1 = gtNewAssignNode(op1, op2);

            goto INLINE_APPEND;


        case CEE_NEWOBJ:

            memberRef = getU4LittleEndian(codeAddr);
            methHnd = eeFindMethod(memberRef, scpHandle, fncHandle, false);

            if (!methHnd)
            {
                JITLOG((INFO8, "INLINER FAILED: Cannot get method handle: %s called by %s\n",
                                                       eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }

            assert((eeGetMethodAttribs(methHnd) & FLG_STATIC) == 0);  // constructors are not static

            clsHnd = eeGetMethodClass(methHnd);
                // There are three different cases for new
                // Object size is variable (depends on arguments)
                //      1) Object is an array (arrays treated specially by the EE)
                //      2) Object is some other variable sized object (e.g. String)
                // 3) Class Size can be determined beforehand (normal case
                // In the first case, we need to call a NEWOBJ helper (multinewarray)
                // in the second case we call the constructor with a '0' this pointer
                // In the third case we alloc the memory, then call the constuctor

            clsFlags = eeGetClassAttribs(clsHnd);

#ifdef NOT_JITC
                // We don't handle this in the inliner
            if (clsFlags & FLG_VALUECLASS)
            {
                JITLOG((INFO7, "INLINER FAILED: NEWOBJ of a value class\n"));
                goto ABORT_THIS_INLINE_ONLY;
            }
#endif

            if (clsFlags & FLG_ARRAY)
            {
                // Arrays need to call the NEWOBJ helper.
                assert(clsFlags & FLG_VAROBJSIZE);

                /* The varargs helper needs the scope and method token as last
                   and  last-1 param (this is a cdecl call, so args will be
                   pushed in reverse order on the CPU stack) */

                op1 = gtNewIconEmbScpHndNode(scpHandle);
                op1 = gtNewOperNode(GT_LIST, TYP_VOID, op1);

                op2 = gtNewIconNode(memberRef, TYP_INT);
                op2 = gtNewOperNode(GT_LIST, TYP_VOID, op2, op1);

                eeGetMethodSig(methHnd, &sig);
                assert(sig.numArgs);

                flags = 0;
                op2 = impPopList(sig.numArgs, &flags, op2);

                op1 = gtNewHelperCallNode(  CPX_NEWOBJ,
                                            TYP_REF,
                                            GTF_CALL_REGSAVE,
                                            op2 );

                // varargs, so we pop the arguments
                op1->gtFlags |= GTF_CALL_POP_ARGS;

#ifdef DEBUG
                // At the present time we don't track Caller pop arguments
                // that have GC references in them
                GenTreePtr temp = op2;
                while(temp != 0)
                {
                    assert(temp->gtOp.gtOp1->gtType != TYP_REF);
                    temp = temp->gtOp.gtOp2;
                }
#endif
                op1->gtFlags |= op2->gtFlags & GTF_GLOB_EFFECT;

                impPushOnStack(op1);
                break;
            }
            else if (clsFlags & FLG_VAROBJSIZE)
            {
                // This is the case for varible sized objects that are not
                // arrays.  In this case, call the constructor with a null 'this'
                // pointer
                thisPtr = gtNewIconNode(0, TYP_REF);
            }
            else
            {
                // This is the normal case where the size of the object is
                // fixed.  Allocate the memory and call the constructor.

                op1 = gtNewIconEmbClsHndNode(clsHnd,
                                            -1, // Note if we persist the code this will need to be fixed
                                            scpHandle);

                op1 = gtNewHelperCallNode(  eeGetNewHelper (clsHnd, fncHandle),
                                            TYP_REF,
                                            GTF_CALL_REGSAVE,
                                            gtNewArgList(op1));

                /* We will append a call to the stmt list
                 * Must spill side effects from the stack */

                impInlineSpillSideEffects();

                /* get a temporary for the new object */

                tmpNum = lvaGrabTemp(); impInlineTemps++;

                /* Create the assignment node */

                op1 = gtNewAssignNode(gtNewLclvNode(tmpNum, TYP_REF, tmpNum), op1);

                /* Append the assignment to the statement list so far */

                impInitExpr = impConcatExprs(impInitExpr, op1);

                /* Create the 'this' ptr for the call below */

                thisPtr = gtNewLclvNode(tmpNum, TYP_REF, tmpNum);
            }

            goto CALL_GOT_METHODHND;

        case CEE_CALLI:

            /* Get the call sig */

            val      = getU4LittleEndian(codeAddr);
            eeGetSig(val, scpHandle, &sig);
                        callTyp = genActualType(JITtype2varType(sig.retType));

#if USE_FASTCALL
            /* The function pointer is on top of the stack - It may be a
             * complex expression. As it is evaluated after the args,
             * it may cause registered args to be spilled. Simply spill it.
             * CONSIDER : Lock the register args, and then generate code for
             * CONSIDER : the function pointer.
             */

            if  (impStackTop()->gtOper != GT_LCL_VAR) // ignore this trivial case
                impInlineSpillStackEntry(impStkDepth - 1);
#endif
            /* Create the call node */

            op1 = gtNewCallNode(CT_INDIRECT, 0, callTyp, GTF_CALL_USER, 0);

            /* Get the function pointer */

            op2 = impPopStack();
            assert(genActualType(op2->gtType) == TYP_I_IMPL);

            op2->gtFlags |= GTF_NON_GC_ADDR;

            op1->gtCall.gtCallAddr  = op2;
            op1->gtFlags |= GTF_EXCEPT | (op2->gtFlags & GTF_GLOB_EFFECT);

            /*HACK: The EE wants us to believe that these are calls to "unmanaged"  */
            /*      functions. Right now we are calling just a managed stub         */

            /*@TODO/CONSIDER: Is it worthwhile to inline the PInvoke frame and call */
            /*                the unmanaged target directly?                        */
            if  ((sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_STDCALL ||
                 (sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_C ||
                 (sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_THISCALL ||
                 (sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_FASTCALL)
            {
    #ifdef NOT_JITC
                assert(eeGetPInvokeCookie(&sig) == (unsigned) info.compCompHnd->getVarArgsHandle(&sig));
    #endif
                op1->gtCall.gtCallCookie = eeGetPInvokeCookie(&sig);
            }

            mflags = FLG_STATIC;
            goto CALL;


        case CEE_CALLVIRT:
        case CEE_CALL:
            memberRef = getU4LittleEndian(codeAddr);
            methHnd = eeFindMethod(memberRef, scpHandle, fncHandle, false);

            if (!methHnd)
            {
                JITLOG((INFO8, "INLINER FAILED: Cannot get method handle: %s called by %s\n",
                                                       eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }

CALL_GOT_METHODHND:
            eeGetMethodSig(methHnd, &sig);
                        callTyp = genActualType(JITtype2varType(sig.retType));

            /* Create the function call node */
            op1 = gtNewCallNode(CT_USER_FUNC, methHnd,
                                callTyp, GTF_CALL_USER, 0);

            mflags = eeGetMethodAttribs(methHnd);
            if (mflags & CORINFO_FLG_NOGCCHECK)
                op1->gtCall.gtCallMoreFlags |= GTF_CALL_M_NOGCCHECK;

#if SECURITY_CHECK
            /* Does the inlinee need a security check token on the frame */

            if (mflags & FLG_SECURITYCHECK)
            {
                JITLOG((INFO9, "INLINER FAILED: Inlinee needs own frame for security object\n"));
                goto ABORT;
            }
#endif

            /* For now ignore delegate invoke */

            if (mflags & FLG_DELEGATE_INVOKE)
            {
                JITLOG((INFO7, "INLINER FAILED: DELEGATE_INVOKE not supported\n"));
                goto ABORT;
            }

            /* For now ignore varargs */

            if  ((sig.callConv & JIT_CALLCONV_MASK) == JIT_CALLCONV_VARARG)
            {
                JITLOG((INFO7, "INLINER FAILED: VarArgs not supported\n"));
                goto ABORT;
            }

            if (opcode == CEE_CALLVIRT)
            {
                assert(!(mflags & FLG_STATIC));     // can't call a static method

                /* Get the method class flags */

                clsFlags = eeGetClassAttribs(eeGetMethodClass(methHnd));

                /* Cannot call virtual on a value class method */

                assert(!(clsFlags & FLG_VALUECLASS));

                /* Set the correct flags - virtual, interface, etc...
                 * If the method is final or private mark it VIRT_RES
                 * which indicates that we should check for a null this pointer */

                if (clsFlags & FLG_INTERFACE)
                    op1->gtFlags |= GTF_CALL_INTF | GTF_CALL_VIRT;
                else if (mflags & (FLG_PRIVATE | FLG_FINAL))
                    op1->gtFlags |= GTF_CALL_VIRT_RES;
                else
                    op1->gtFlags |= GTF_CALL_VIRT;
            }

CALL:       // 'op1'      should be a GT_CALL node.
            // 'sig'      the signature for the call
            // 'mflags'   should be set
            if (callTyp == TYP_STRUCT)
            {
                JITLOG((INFO7, "INLINER FAILED call returned a valueclass\n"));
                goto ABORT;
            }

            assert(op1->OperGet() == GT_CALL);

            op2   = 0;
            flags = 0;

            /* Create the argument list
             * Special case - for varargs we have an implicit last argument */

            assert((sig.callConv & JIT_CALLCONV_MASK) != JIT_CALLCONV_VARARG);
            GenTreePtr      extraArg;

            extraArg = 0;

            /* Now pop the arguments */

            if  (sig.numArgs)
            {
                op2 = op1->gtCall.gtCallArgs = impPopList(sig.numArgs, &flags, extraArg);
                op1->gtFlags |= op2->gtFlags & GTF_GLOB_EFFECT;
            }

            /* Are we supposed to have a 'this' pointer? */

            if (!(mflags & FLG_STATIC) || opcode == CEE_NEWOBJ)
            {
                GenTreePtr  obj;

                /* Pop the 'this' value from the stack */

                if (opcode == CEE_NEWOBJ)
                    obj = thisPtr;
                else
                    obj = impPopStack();

#ifdef DEBUG
                clsFlags = eeGetClassAttribs(eeGetMethodClass(methHnd));
                assert(varTypeIsGC(obj->gtType) ||      // "this" is managed ptr
                       (obj->TypeGet() == TYP_I_IMPL && // "this" in ummgd but it doesnt matter
                        (( clsFlags & FLG_UNMANAGED) ||
                         ((clsFlags & FLG_VALUECLASS) && !(clsFlags & FLG_CONTAINS_GC_PTR)))));
#endif

                /* Is this a virtual or interface call? */

                if  (op1->gtFlags & (GTF_CALL_VIRT|GTF_CALL_INTF|GTF_CALL_VIRT_RES))
                {
                    GenTreePtr      vtPtr = NULL;

                    /* We cannot have objptr of TYP_BYREF - value classes cannot be virtual */

                    assert(obj->gtType == TYP_REF);

                    /* If the obj pointer is not a lclVar abort */

                    if  (obj->gtOper != GT_LCL_VAR)
                    {
                        JITLOG((INFO7, "INLINER FAILED: Call virtual with complicated obj ptr: %s called by %s\n",
                                                       eeGetMethodFullName(fncHandle), info.compFullName));
                        goto ABORT;
                    }

                    /* Special case: for GTF_CALL_VIRT_RES calls, if the caller
                     * (i.e. the function we are inlining) did the null pointer check
                     * we don't need a vtable pointer */

                    assert(tree->gtOper == GT_CALL);

                    if (tree->gtFlags & op1->gtFlags & GTF_CALL_VIRT_RES)
                    {
#if 0
                        assert(tree->gtCall.gtCallVptr);
#endif
                        assert(thisArg);

                        /* If the obj pointer is the same as the caller
                         * then we already have a null pointer check */

                        assert(obj->gtLclVar.gtLclOffs != BAD_IL_OFFSET);
                        if (obj->gtLclVar.gtLclOffs == 0)
                        {
                            /* Becomes a non-virtual call */

                            op1->gtFlags &= ~GTF_CALL_VIRT_RES;
                            assert(vtPtr == 0);
                        }
                    }
                    else
                    {
                        /* Create the vtable ptr by cloning the obj ptr */

                        lclNum = obj->gtLclVar.gtLclNum;

                        /* Make a copy of the simple 'this' value */

                        vtPtr = gtNewLclvNode(lclNum, TYP_REF, obj->gtLclVar.gtLclOffs);

                        /* If this was an argument temp have to update the arg info table */

                        lclNum = obj->gtLclVar.gtLclOffs; assert(lclNum != BAD_IL_OFFSET);

                        if (lclNum < argCnt && inlArgInfo[lclNum].argHasTmp)
                        {
                            assert(inlArgInfo[lclNum].argIsUsed);
                            assert(inlArgInfo[lclNum].argTmpNum == obj->gtLclVar.gtLclNum);

                            /* This is a multiple use of the argument so NO bashing of temp */
                            inlArgInfo[lclNum].argTmpNode = NULL;
                        }

                        /* Deref to get the vtable ptr (but not if interface call) */

                        if  (!(op1->gtFlags & GTF_CALL_INTF) || getNewCallInterface())
                        {
                            /* Extract the vtable pointer address */
#if VPTR_OFFS
                            vtPtr = gtNewOperNode(GT_ADD,
                                                  obj->TypeGet(),
                                                  vtPtr,
                                                  gtNewIconNode(VPTR_OFFS, TYP_INT));

#endif

                            /* Note that the vtable ptr isn't subject to GC */

                            vtPtr = gtNewOperNode(GT_IND, TYP_I_IMPL, vtPtr);
                        }
                    }

                    /* Store the vtable pointer address in the call */

                    op1->gtCall.gtCallVptr = vtPtr;
                }

                /* Store the "this" value in the call */

                op1->gtFlags          |= obj->gtFlags & GTF_GLOB_EFFECT;
                op1->gtCall.gtCallObjp = obj;
            }

            if (opcode == CEE_NEWOBJ)
            {
                if (clsFlags & FLG_VAROBJSIZE)
                {
                    assert(!(clsFlags & FLG_ARRAY));    // arrays handled separately
                    // This is a 'new' of a variable sized object, wher
                    // the constructor is to return the object.  In this case
                    // the constructor claims to return VOID but we know it
                    // actually returns the new object
                    assert(callTyp == TYP_VOID);
                    callTyp = TYP_REF;
                    op1->gtType = TYP_REF;
                }
                else
                {
                    // This is a 'new' of a non-variable sized object.
                    // append the new node (op1) to the statement list,
                    // and then push the local holding the value of this
                    // new instruction on the stack.

                    impInitExpr = impConcatExprs(impInitExpr, op1);

                    impPushOnStack(gtNewLclvNode(tmpNum, TYP_REF, tmpNum));
                    break;
                }
            }

            /* op1 is the call node */
            assert(op1->gtOper == GT_CALL);

            /* Push or append the result of the call */

            if  (callTyp == TYP_VOID)
                goto INLINE_APPEND;

            impPushOnStack(op1);

            break;


        case CEE_NEWARR:

            /* Get the class type index operand */

            typeRef = getU4LittleEndian(codeAddr);
            clsHnd = eeFindClass(typeRef, scpHandle, fncHandle, false);

            if (!clsHnd)
            {
                JITLOG((INFO8, "INLINER FAILED: Cannot get class handle: %s called by %s\n",
                               eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }

#ifdef NOT_JITC
            clsHnd = info.compCompHnd->getSDArrayForClass(clsHnd);
            if (!clsHnd)
            {
                JITLOG((INFO8, "INLINER FAILED: Cannot get SDArrayClass handle: %s called by %s\n",
                               eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }
#endif
            /* Form the arglist: array class handle, size */

            op2 = gtNewIconEmbClsHndNode(clsHnd,
                                         typeRef,
                                         scpHandle);

            op2 = gtNewOperNode(GT_LIST, TYP_VOID,           op2,   0);
            op2 = gtNewOperNode(GT_LIST, TYP_VOID, impPopStack(), op2);

            /* Create a call to 'new' */

            op1 = gtNewHelperCallNode(CPX_NEWARR_1_DIRECT,
                                      TYP_REF,
                                      GTF_CALL_REGSAVE,
                                      op2);

            /* Remember that this basic block contains 'new' of an array */

            inlineeHasNewArray = true;

            /* Push the result of the call on the stack */

            impPushOnStack(op1);
            break;


        case CEE_THROW:

            /* Do we have just the exception on the stack ?*/

            if (impStkDepth != 1)
            {
                /* if not, just don't inline the method */

                JITLOG((INFO8, "INLINER FAILED: Reaching 'throw' with too many things on stack: %s called by %s\n",
                                                       eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT_THIS_INLINE_ONLY;
            }

            /* Don't inline non-void conditionals that have a throw in one of the branches */

            /* NOTE: If we do allow this, note that we cant simply do a
              checkLiveness() to match the liveness at the end of the "then"
              and "else" branches of the GT_COLON. The branch with the throw
              will keep nothing live, so we should use the liveness at the
              end of the non-throw branch. */

            if  (jmpAddr && (fncRetType != TYP_VOID))
            {
                JITLOG((INFO7, "INLINER FAILED: No inlining for THROW within a non-void conditional in %s called by %s\n",
                               eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

            /* Pop the exception object and create the 'throw' helper call */

            op1 = gtNewHelperCallNode(CPX_THROW,
                                      TYP_VOID,
                                      GTF_CALL_REGSAVE,
                                      gtNewArgList(impPopStack()));

            goto INLINE_APPEND;


        case CEE_LDLEN:
            op1 = impPopStack();

            /* If the value is constant abort - This shouldn't happen if we
             * eliminate dead branches - have the assert only for debug, it aborts in retail */

            if (op1->gtOper == GT_CNS_INT)
            {
                //assert(!"Inliner has null object in ldlen - Ignore assert it works!");

                JITLOG((INFO7, "INLINER FAILED: Inliner has null object in ldlen in %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

#if RNGCHK_OPT
            if  (!opts.compMinOptim && !opts.compDbgCode)
            {
                /* Use GT_ARR_LENGTH operator so rng check opts see this */
                op1 = gtNewOperNode(GT_ARR_LENGTH, TYP_INT, op1);
            }
            else
#endif
            {
                /* Create the expression "*(array_addr + ARR_ELCNT_OFFS)" */
                op1 = gtNewOperNode(GT_ADD, TYP_REF, op1, gtNewIconNode(ARR_ELCNT_OFFS,
                                                                        TYP_INT));

                op1 = gtNewOperNode(GT_IND, TYP_INT, op1);
            }

            /* An indirection will cause a GPF if the address is null */
            op1->gtFlags |= GTF_EXCEPT;

            /* Push the result back on the stack */
            impPushOnStack(op1);
            break;


#if INLINE_CONDITIONALS

        case CEE_BR:
        case CEE_BR_S:

            assert(sz == 1 || sz == 4);

#ifdef DEBUG
            hasFOC = true;
#endif
            /* The jump must be a forward one (we don't allow loops) */

            jmpDist = (sz==1) ? getI1LittleEndian(codeAddr)
                              : getI4LittleEndian(codeAddr);

            if  (jmpDist <= 0)
            {
                JITLOG((INFO9, "INLINER FAILED: Cannot inline backward jumps in %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

            /* Check if this is part of an 'if' */

            if (!jmpAddr)
            {
                /* Unconditional branch, the if part has probably been folded
                 * Skip the dead code and continue */

#ifdef DEBUG
                if (verbose)
                    printf("\nUnconditional branch without 'if' - Skipping %d bytes\n", sz + jmpDist);
#endif
                    codeAddr += jmpDist;
                    break;
            }

            /* Is the stack empty? */

            if  (impStkDepth)
            {
                /* We allow the 'if' part to yield one value */

                if  (impStkDepth > 1)
                {
                    JITLOG((INFO9, "INLINER FAILED: More than one value on stack for 'if' in %s called by %s\n",
                                                    eeGetMethodFullName(fncHandle), info.compFullName));
                    goto ABORT;
                }

                impInitExpr = impConcatExprs(impInitExpr, impPopStack());

                ifNvoid = true;
            }
            else
                ifNvoid = false;

            /* We better be in an 'if' statement */

            if  ((jmpAddr != codeAddr + sz) || inElse)
            {
                JITLOG((INFO9, "INLINER FAILED: Not in an 'if' statment in %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

            /* Remember the 'if' statement part */

            ifStmts = impInitExpr;
                      impInitExpr = NULL;

            /* Record the jump target (where the 'else' part will end) */

            jmpAddr = codeBegp + (codeAddr - codeBegp) + sz + jmpDist;

            inElse  = true;
            break;


        case CEE_BRTRUE:
        case CEE_BRTRUE_S:
        case CEE_BRFALSE:
        case CEE_BRFALSE_S:

            /* Pop the comparand (now there's a neat term) from the stack */

            op1 = impPopStack();

            /* We'll compare against an equally-sized integer 0 */

            op2 = gtNewIconNode(0, genActualType(op1->gtType));

            /* Create the comparison operator and try to fold it */

            oper = (opcode==CEE_BRTRUE || opcode==CEE_BRTRUE_S) ? GT_NE
                                                                : GT_EQ;
            op1 = gtNewOperNode(oper, TYP_INT , op1, op2);


            // fall through

        COND_JUMP:

#ifdef DEBUG
            hasFOC = true;
#endif

            assert(op1->OperKind() & GTK_RELOP);
            assert(sz == 1 || sz == 4);

            /* The jump must be a forward one (we don't allow loops) */

            jmpDist = (sz==1) ? getI1LittleEndian(codeAddr)
                              : getI4LittleEndian(codeAddr);

            if  (jmpDist <= 0)
            {
                JITLOG((INFO9, "INLINER FAILED: Cannot inline backward jumps in %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

            /* Make sure the stack is empty */

            if  (impStkDepth)
            {
                JITLOG((INFO9, "INLINER FAILED: Non empty stack entering if statement in %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

            /* Currently we disallow nested if statements */

            if  (jmpAddr != NULL)
            {
                JITLOG((INFO7, "INLINER FAILED: Cannot inline nested if statements in %s called by %s\n",
                                                eeGetMethodFullName(fncHandle), info.compFullName));
                goto ABORT;
            }

            /* Try to fold the conditional */

            op1 = gtFoldExpr(op1);

            /* Have we folded the condition? */

            if  (op1->gtOper == GT_CNS_INT)
            {
                /* If unconditional jump, skip the dead code and continue
                 * If fall through, continue normally and the corresponding
                 * else part will be taken care later
                 * UNDONE!!! - revisit for nested if /else */

#ifdef DEBUG
                if (verbose)
                    printf("\nConditional folded - result = %d\n", op1->gtIntCon.gtIconVal);
#endif

                assert(op1->gtIntCon.gtIconVal == 1 || op1->gtIntCon.gtIconVal == 0);

                jmpAddr = NULL;

                if (op1->gtIntCon.gtIconVal)
                {
                    /* Skip the dead code */
#ifdef DEBUG
                    if (verbose)
                        printf("\nSkipping dead code %d bytes\n", sz + jmpDist);
#endif

                    codeAddr += jmpDist;
                }
                break;
            }

            /* Record the condition and save the current statement list */

            ifCondx = op1;
            stmList = impInitExpr;
                      impInitExpr = NULL;

            /* Record the jump target (where the 'if' part will end) */

            jmpAddr = codeBegp + (codeAddr - codeBegp) + sz + jmpDist;

            ifNvoid = false;
            inElse  = false;
            break;


        case CEE_CEQ:       oper = GT_EQ; goto CMP_2_OPs;

        case CEE_CGT_UN:
        case CEE_CGT:       oper = GT_GT; goto CMP_2_OPs;

        case CEE_CLT_UN:
        case CEE_CLT:       oper = GT_LT; goto CMP_2_OPs;

CMP_2_OPs:
            /* Pull two values */

            op2 = impPopStack();
            op1 = impPopStack();

            assert(genActualType(op1->TypeGet()) ==
                   genActualType(op2->TypeGet()));

            /* Create the comparison node */

            op1 = gtNewOperNode(oper, TYP_INT, op1, op2);

            /* REVIEW: I am settng both flags when only one is approprate */
            if (opcode==CEE_CGT_UN || opcode==CEE_CLT_UN)
                op1->gtFlags |= GTF_CMP_NAN_UN | GTF_UNSIGNED;

#ifdef DEBUG
            hasFOC = true;
#endif

            /* Definetely try to fold this one */

            op1 = gtFoldExpr(op1);

            // @ISSUE :  The next opcode will almost always be a conditional
            // branch. Should we try to look ahead for it here ?

            impPushOnStack(op1);
            break;


        case CEE_BEQ_S:
        case CEE_BEQ:       oper = GT_EQ; goto CMP_2_OPs_AND_BR;

        case CEE_BGE_S:
        case CEE_BGE:       oper = GT_GE; goto CMP_2_OPs_AND_BR;

        case CEE_BGE_UN_S:
        case CEE_BGE_UN:    oper = GT_GE; goto CMP_2_OPs_AND_BR_UN;

        case CEE_BGT_S:
        case CEE_BGT:       oper = GT_GT; goto CMP_2_OPs_AND_BR;

        case CEE_BGT_UN_S:
        case CEE_BGT_UN:    oper = GT_GT; goto CMP_2_OPs_AND_BR_UN;

        case CEE_BLE_S:
        case CEE_BLE:       oper = GT_LE; goto CMP_2_OPs_AND_BR;

        case CEE_BLE_UN_S:
        case CEE_BLE_UN:    oper = GT_LE; goto CMP_2_OPs_AND_BR_UN;

        case CEE_BLT_S:
        case CEE_BLT:       oper = GT_LT; goto CMP_2_OPs_AND_BR;

        case CEE_BLT_UN_S:
        case CEE_BLT_UN:    oper = GT_LT; goto CMP_2_OPs_AND_BR_UN;

        case CEE_BNE_UN_S:
        case CEE_BNE_UN:    oper = GT_NE; goto CMP_2_OPs_AND_BR_UN;


CMP_2_OPs_AND_BR_UN:
            uns = true;  unordered = true; goto CMP_2_OPs_AND_BR_ALL;

CMP_2_OPs_AND_BR:
            uns = false; unordered = false; goto CMP_2_OPs_AND_BR_ALL;

CMP_2_OPs_AND_BR_ALL:

            /* Pull two values */

            op2 = impPopStack();
            op1 = impPopStack();

            assert(genActualType(op1->TypeGet()) == genActualType(op2->TypeGet()) ||
                   varTypeIsI(op1->TypeGet()) && varTypeIsI(op2->TypeGet()));

            /* Create and append the operator */

            op1 = gtNewOperNode(oper, TYP_INT , op1, op2);

            if (uns)
                op1->gtFlags |= GTF_UNSIGNED;

            if (unordered)
                op1->gtFlags |= GTF_CMP_NAN_UN;

            goto COND_JUMP;

#endif //#if INLINE_CONDITIONALS


        case CEE_BREAK:
            op1 = gtNewHelperCallNode(CPX_USER_BREAKPOINT, TYP_VOID);
            goto INLINE_APPEND;

        case CEE_NOP:
            break;

        case CEE_TAILCALL:
            /* If the method is inlined we can ignore the tail prefix */
            break;

         // OptIL annotations. Just skip

        case CEE_ANN_DATA:
            assert(sz == 4);
            sz += getU4LittleEndian(codeAddr);
            break;

        case CEE_ANN_PHI :
            codeAddr += getU1LittleEndian(codeAddr) * 2 + 1;
            break;

        case CEE_ANN_CALL :
        case CEE_ANN_HOISTED :
        case CEE_ANN_HOISTED_CALL :
        case CEE_ANN_LIVE:
        case CEE_ANN_DEAD:
        case CEE_ANN_LAB:
        case CEE_ANN_CATCH:
            break;

        case CEE_LDLOCA_S:
        case CEE_LDLOCA:
        case CEE_LDARGA_S:
        case CEE_LDARGA:
            /* @MIHAII - If you decide to implement these disalow taking the address of arguments */
ABORT:
        default:
            JITLOG((INFO7, "INLINER FAILED due to opcode OP_%s\n", impCurOpcName));

#ifdef  DEBUG
            if (verbose || 0)
                printf("\n\nInline expansion aborted due to opcode [%02u] OP_%s\n", impCurOpcOffs, impCurOpcName);
#endif

            goto INLINING_FAILED;
        }

        codeAddr += sz;

#ifdef  DEBUG
        if  (verbose) printf("\n");
#endif

#if INLINE_CONDITIONALS
        /* Currently FP enregistering doesn't know about QMARK - Colon
         * so we need to disable inlining of conditionals if we have
         * floats in the COLON branches */

        if (jmpAddr && impStkDepth)
        {
            if (varTypeIsFloating(impStackTop()->TypeGet()))
            {
                /* Abort inlining */

                JITLOG((INFO7, "INLINER FAILED: Inlining of conditionals with FP not supported: %s called by %s\n",
                                           eeGetMethodFullName(fncHandle), info.compFullName));

                goto INLINING_FAILED;
            }
        }
#endif
    }

DONE:

    assert(impStkDepth == 0);

#if INLINE_CONDITIONALS
    assert(jmpAddr == NULL);
#endif

    /* Prepend any initialization / side effects to the return expression */

    bodyExp = impConcatExprs(impInitExpr, bodyExp);

    /* Treat arguments that had to be assigned to temps */

    if (argCnt)
    {
        GenTreePtr      initArg = 0;

        for (unsigned argNum = 0; argNum < argCnt; argNum++)
        {
            if (inlArgInfo[argNum].argHasTmp)
            {
                assert(inlArgInfo[argNum].argIsUsed);

                if (inlArgInfo[argNum].argTmpNode && !dupOfLclVar)
                {
                    /* Can bash this 'single' use of the argument */

                    inlArgInfo[argNum].argTmpNode->CopyFrom(inlArgInfo[argNum].argNode);
                    continue;
                }

                /* Create the temp assignment for this argument and append it to 'initArg' */

                initArg = impConcatExprs(initArg,
                                         gtNewTempAssign(inlArgInfo[argNum].argTmpNum,
                                                         inlArgInfo[argNum].argNode  ));
            }
            else
            {
                /* The argument is either not used or a const or lcl var */

                assert(!inlArgInfo[argNum].argIsUsed  ||
                        inlArgInfo[argNum].argIsConst ||
                        inlArgInfo[argNum].argIsLclVar );

                /* If the argument has side effects append it to 'initArg' */

                if (inlArgInfo[argNum].argHasSideEff)
                {
                    assert(inlArgInfo[argNum].argIsUsed == false);
                    initArg = impConcatExprs(initArg, gtUnusedValNode(inlArgInfo[argNum].argNode));
                }
            }
        }

        /* Prepend any arg initialization to the body */

        bodyExp = impConcatExprs(initArg, bodyExp);
    }

    /* Make sure we have something to return to the caller */

    if  (!bodyExp)
    {
        bodyExp = gtNewNothingNode();
    }
    else
    {
        /* Make sure the type matches the original call */

        if  (fncRetType != genActualType(bodyExp->gtType))
        {
            if  (fncRetType == TYP_VOID)
            {
                if (bodyExp->gtOper == GT_COMMA)
                {
                    /* Simply bash the comma operator type */
                    bodyExp->gtType = fncRetType;
                }
            }
            else
            {
                /* Abort inlining */

                JITLOG((INFO7, "INLINER FAILED: Return type mismatch: %s called by %s\n",
                                           eeGetMethodFullName(fncHandle), info.compFullName));

                goto INLINING_FAILED;

                /* Cast the expanded body to the correct type */
/*
                bodyExp = gtNewOperNode(GT_CAST,
                                        fncRetType,
                                        bodyExp,
                                        gtNewIconNode(fncRetType));
         */
            }
        }
    }


#ifdef  DEBUG
#ifdef  NOT_JITC

    JITLOG((INFO6, "Jit Inlined %s%s called by %s\n", hasFOC ? "FOC " : "", eeGetMethodFullName(fncHandle), info.compFullName));

    if (verbose || 0)
    {
        printf("\n\nInlined %s called by %s:\n", eeGetMethodFullName(fncHandle), info.compFullName);

        //gtDispTree(bodyExp);
    }

#endif

    if  (verbose||0)
    {
        printf("Call before inlining:\n");
        gtDispTree(tree);
        printf("\n");

        printf("Call  after inlining:\n");
        if  (bodyExp)
            gtDispTree(bodyExp);
        else
            printf("<NOP>\n");

        printf("\n");
        fflush(stdout);
    }

#endif

    /* Success we have inlined the method - set all the global cached flags */

    if (inlineeHasRangeChks)
        fgHasRangeChks = true;

    if (inlineeHasNewArray)
        compCurBB->bbFlags |= BBF_NEW_ARRAY;

    /* Return the inlined function as a chain of GT_COMMA "statements" */

    return  bodyExp;


INLINING_FAILED:

    /* Mark the method as not inlinable */

    eeSetMethodAttribs(fncHandle, FLG_DONT_INLINE);

ABORT_THIS_INLINE_ONLY:

    /* We couldn't inline the function, but we may
     * already have allocated temps so cleanup */

    if (impInlineTemps)
        lvaCount -= impInlineTemps;

    return 0;
}

/*****************************************************************************/
#endif//INLINING
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\instrsh3.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************
 *
 *  Microsoft confidential
 *
 *  SH-3 opcodes for [Opt]JIT
 *
 *  How to use this header file:
 *
 *       define INST1(id, nm, bd, um, rf, wf, rm, wm, i1) \
 *          id      -- the enum name for the instruction
 *          nm      -- textual name (for assembly dipslay)
 *          bd      -- branch-delayed execution [bit0=BD,bit1=conditional]
 *          um      -- update mode, see IUM_xx enum
 *          rf      -- read flags (1 => T, 2 => S)
 *          wf      -- write flags (1 => T, 2 => S)
 *          rx      -- read  extra register(s)
 *          wx      -- write extra register(s)
 *          br      -- branch/call/return instruction?
 *          i1      -- instruction encoding
 *
 *      _M_N    -- M is source, N is destination
 *
 *****************************************************************************/

#ifndef         SCHED_XDEP_DEF
#define         SCHED_XDEP_DEF

// Define extra dependency flag values for the table below

#define         SCHED_XDEP_ALL  0x0F    // assume we'll need <= 4 flags

#define         SCHED_XDEP_PR   0x01
#define         SCHED_XDEP_MAC  0x02

// Define short-cuts to make the table a bit more readable

#define XPR     SCHED_XDEP_PR
#define XMAC    SCHED_XDEP_MAC

#endif

//     enum     name      BD  updmode rf wf   rx    wx  br _I8_N   _I16_N  _I32_N
INST3(movi,    "movi",    0,  IUM_WR, 0, 0,    0,    0, 0, 0xE000, 0x9000, 0xD000)

//     enum     name      BD  updmode rf wf   rx    wx  br _M_N    _I_0    _I_G0
INST3(and,     "and",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x2009, 0xC900, 0xCD00)
INST3(cmpeq,   "cmpeq",   0,  IUM_RD, 0, 1,    0,    0, 0, 0x3000, 0x8800, BAD_CODE)
INST3(or,      "or",      0,  IUM_RW, 0, 0,    0,    0, 0, 0x200B, 0xCB00, 0xCF00)
INST3(tst,     "tst",     0,  IUM_RD, 0, 1,    0,    0, 0, 0x2008, 0xC800, 0xCC00)
INST3(xor,     "xor",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x200A, 0xCA00, 0xCE00)

//     enum     name      BD  updmode rf wf   rx    wx  br _M_N
INST1(addc,    "addc",    0,  IUM_RW, 1, 1,    0,    0, 0, 0x300E)
INST1(addv,    "addv",    0,  IUM_RW, 0, 1,    0,    0, 0, 0x300F)
INST1(cmpEQ,   "cmp/eq",  0,  IUM_RD, 0, 1,    0,    0, 0, 0x3000)
INST1(cmpGE,   "cmp/ge",  0,  IUM_RD, 0, 1,    0,    0, 0, 0x3003)
INST1(cmpGT,   "cmp/gt",  0,  IUM_RD, 0, 1,    0,    0, 0, 0x3007)
INST1(cmpHI,   "cmp/hi",  0,  IUM_RD, 0, 1,    0,    0, 0, 0x3006)
INST1(cmpHS,   "cmp/hs",  0,  IUM_RD, 0, 1,    0,    0, 0, 0x3002)
INST1(cmpSTR,  "cmp/str", 0,  IUM_RD, 0, 1,    0,    0, 0, 0x200C)
INST1(div0s,   "div0s",   0,  IUM_RD, 0, 1,    0,    0, 0, 0x2007)
INST1(div1,    "div1",    0,  IUM_RW, 0, 1,    0,    0, 0, 0x3004)
INST1(dmuls,   "dmuls",   0,  IUM_RD, 0, 0,    0, XMAC, 0, 0x300D)
INST1(dmulu,   "dmulu",   0,  IUM_RD, 0, 0,    0, XMAC, 0, 0x3005)
INST1(extsb,   "exts",    0,  IUM_RW, 0, 0,    0,    0, 0, 0x600E)
INST1(extsw,   "exts",    0,  IUM_RW, 0, 0,    0,    0, 0, 0x600F)
INST1(extub,   "extu",    0,  IUM_RW, 0, 0,    0,    0, 0, 0x600C)
INST1(extuw,   "extu",    0,  IUM_RW, 0, 0,    0,    0, 0, 0x600D)
INST1(mul,     "mul",     0,  IUM_RD, 0, 0,    0, XMAC, 0, 0x0007)
INST1(mulsw,   "mulsw",   0,  IUM_RD, 0, 0,    0, XMAC, 0, 0x200F)
INST1(muluw,   "muluw",   0,  IUM_RD, 0, 0,    0, XMAC, 0, 0x200E)
INST1(neg,     "neg",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x600B)
INST1(negc,    "negc",    0,  IUM_RW, 1, 1,    0,    0, 0, 0x600A)
INST1(not,     "not",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x6007)
INST1(shad,    "shad",    0,  IUM_RW, 0, 0,    0,    0, 0, 0x400C)
INST1(shld,    "shld",    0,  IUM_RW, 0, 0,    0,    0, 0, 0x400D)
INST1(sub,     "sub",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x3008)
INST1(subc,    "subc",    0,  IUM_RW, 1, 1,    0,    0, 0, 0x300A)
INST1(subv,    "subv",    0,  IUM_RW, 0, 1,    0,    0, 0, 0x300B)
INST1(swapb,   "swapb",   0,  IUM_RW, 0, 0,    0,    0, 0, 0x6008)
INST1(swapw,   "swapw",   0,  IUM_RW, 0, 0,    0,    0, 0, 0x6009)
INST1(xtrct,   "xtrct",   0,  IUM_RW, 0, 0,    0,    0, 0, 0x200D)

//     enum     name      BD  updmode rf wf   rx    wx  br _I8_0
INST1(mova,    "mova",    0,  IUM_WR, 0, 0,    0,    0, 0, 0xC700)

//     enum     name      BD  updmode rf wf   rx    wx  br _N
INST1(cmpPL,   "cmp/pl",  0,  IUM_RD, 0, 1,    0,    0, 0, 0x4015)
INST1(cmpPZ,   "cmp/pz",  0,  IUM_RD, 0, 1,    0,    0, 0, 0x4011)
INST1(jmp,     "jmp",     0,  IUM_RD, 0, 0,    0,    0, 1, 0x402B)
INST1(jsr,     "jsr",     1,  IUM_RD, 0, 0,    0, XPR , 1, 0x400B)
INST1(braf,    "braf",    0,  IUM_RD, 0, 0,    0,    0, 1, 0x0023)
INST1(bsrf,    "bsrf",    0,  IUM_WR, 0, 0,    0, XPR , 1, 0x0003)
INST1(dt,      "dt",      0,  IUM_RW, 0, 1,    0,    0, 0, 0x4010)
INST1(movt,    "movt",    0,  IUM_WR, 1, 0,    0,    0, 0, 0x0029)
INST1(pref,    "pref",    0,  IUM_RD, 0, 0,    0,    0, 0, 0x0083)
INST1(rotcl,   "rotcl",   0,  IUM_RW, 1, 1,    0,    0, 0, 0x4024)
INST1(rotcr,   "rotcr",   0,  IUM_RW, 1, 1,    0,    0, 0, 0x4025)
INST1(rotl,    "rotl",    0,  IUM_RW, 0, 1,    0,    0, 0, 0x4004)
INST1(rotr,    "rotr",    0,  IUM_RW, 0, 1,    0,    0, 0, 0x4005)
INST1(shal,    "shal",    0,  IUM_RW, 0, 1,    0,    0, 0, 0x4020)
INST1(shar,    "shar",    0,  IUM_RW, 0, 1,    0,    0, 0, 0x4021)
INST1(shll,    "shll",    0,  IUM_RW, 0, 1,    0,    0, 0, 0x4000)
INST1(shll2,   "shll2",   0,  IUM_RW, 0, 0,    0,    0, 0, 0x4008)
INST1(shll8,   "shll8",   0,  IUM_RW, 0, 0,    0,    0, 0, 0x4018)
INST1(shll16,  "shll16",  0,  IUM_RW, 0, 0,    0,    0, 0, 0x4028)
INST1(shlr,    "shlr",    0,  IUM_RW, 0, 1,    0,    0, 0, 0x4001)
INST1(shlr2,   "shlr2",   0,  IUM_RW, 0, 0,    0,    0, 0, 0x4009)
INST1(shlr8,   "shlr8",   0,  IUM_RW, 0, 0,    0,    0, 0, 0x4019)
INST1(shlr16,  "shlr16",  0,  IUM_RW, 0, 0,    0,    0, 0, 0x4029)

//     enum     name      BD  updmode rf wf   rx    wx  br _
INST1(clrmac,  "clrmac",  0,  IUM_RD, 0, 0,    0, XMAC, 0, 0x0028)
INST1(clrs,    "clrs",    0,  IUM_RD, 0, 2,    0,    0, 0, 0x0048)
INST1(clrt,    "clrt",    0,  IUM_RD, 0, 1,    0,    0, 0, 0x0008)
INST1(div0u,   "div0u",   0,  IUM_RD, 0, 1,    0,    0, 0, 0x0019)
INST1(nop,     "nop",     0,  IUM_RD, 0, 0,    0,    0, 0, 0x0009)
INST1(rts,     "rts",     1,  IUM_RD, 0, 0, XPR ,    0, 1, 0x000B)
INST1(sets,    "sets",    0,  IUM_RD, 0, 2,    0,    0, 0, 0x0058)
INST1(sett,    "sett",    0,  IUM_RD, 0, 1,    0,    0, 0, 0x0018)

//     enum     name      BD  updmode rf wf   rx    wx  br _@M+_@N+
INST1(macw,    "macw",    0,  IUM_RD, 2, 0, XMAC, XMAC, 0, 0x400F)
INST1(mac,     "mac",     0,  IUM_RD, 2, 0, XMAC, XMAC, 0, 0x000F)

//     enum     name      BD  updmode rf wf   rx    wx  br _D8
INST1(bf,      "bf",      0,  IUM_RD, 1, 0,    0,    0, 1, 0x8B00)
INST1(bfs,     "bf/s",    3,  IUM_RD, 1, 0,    0,    0, 1, 0x8F00)
INST1(bt,      "bt",      0,  IUM_RD, 1, 0,    0,    0, 1, 0x8900)
INST1(bts,     "bt/s",    3,  IUM_RD, 1, 0,    0,    0, 1, 0x8D00)

//     enum     name      BD  updmode rf wf   rx    wx  br _D12
INST1(bra,     "bra",     1,  IUM_RD, 0, 0,    0,    0, 1, 0xA000)
INST1(bsr,     "bsr",     1,  IUM_RD, 0, 0,    0, XPR , 1, 0xB000)

//     enum     name      BD  updmode rf wf   rx    wx  brreg/imm

INST1(mov,     "mov",     0,  IUM_WR, 0, 0,    0,    0, 0, 0x6003)
INST1(mov_imm, "mov",     0,  IUM_WR, 0, 0,    0,    0, 0, 0xE000)
INST1(add,     "add",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x300C)
INST1(add_imm, "add",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x7000)
INST1(xor_imm, "xor",     0,  IUM_RW, 0, 0,    0,    0, 0, 0xCA00)

//     enum     name      BD  updmode rf wf   rx    wx  br addr

INST1(mov_ind, "mov",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x2000)

//     enum     name      BD  updmode rf wf   rx    wx  br _ND4

INST1(mov_dsp, "mov",     0,  IUM_WR, 0, 0,    0,    0, 0, 0x1000)

//     enum     name      BD  updmode rf wf   rx    wx  brpcdisp

INST1(mov_PC,  "mov",     0,  IUM_WR, 0, 0,    0,    0, 0, 0x9000)

//     enum     name      BD  updmode rf wf   rx    wx  br _GD8_

INST1(mov_GBR, "mov",     0,  IUM_RW, 0, 0,    0,    0, 0, 0xC000)

//     enum     name      BD  updmode rf wf   rx    wx  br_@R0_RM

INST1(mov_ix0, "mov",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x0004)
INST1(movl_ix0, "mov",     0,  IUM_RW, 0, 0,    0,    0, 0, 0x000C)

//     enum     name      BD  updmode rf wf   rx    wx  br _@M+_SR
INST1(ldcgbr,  "ldc",     0,  IUM_WR, 0, 0,    0, XMAC, 0, 0x4017)
INST1(ldsmach, "lds",     0,  IUM_WR, 0, 0,    0, XMAC, 0, 0x4006)
INST1(ldsmacl, "lds",     0,  IUM_WR, 0, 0,    0, XMAC, 0, 0x4016)
INST1(ldspr,   "lds",     0,  IUM_WR, 0, 0,    0, XPR , 0, 0x4026)

//     enum     name      BD  updmode rf wf   rx    wx  br _SR_@-N
INST1(stcgbr,  "stc",     0,  IUM_RD, 0, 0, XMAC,    0, 0, 0x4013)
INST1(stsmach, "sts",     0,  IUM_RD, 0, 0, XMAC,    0, 0, 0x4002)
INST1(stsmacl, "sts",     0,  IUM_RD, 0, 0, XMAC,    0, 0, 0x4012)
INST1(stspr,   "sts",     0,  IUM_RD, 0, 0, XPR ,    0, 0, 0x4022)

//     enum     name      BD  updmode rf wf   rx    wx  br _@M+_SR
INST1(ldcgbr_reg,  "ldc",     0,  IUM_RW, 0, 0,    0, XMAC, 0, 0x401E)
INST1(ldsmach_reg, "lds",     0,  IUM_RW, 0, 0,    0, XMAC, 0, 0x400A)
INST1(ldsmacl_reg, "lds",     0,  IUM_RW, 0, 0,    0, XMAC, 0, 0x401A)
INST1(ldspr_reg,   "lds",     0,  IUM_RW, 0, 0,    0, XPR , 0, 0x402A)

//     enum     name      BD  updmode rf wf   rx    wx  br _SR_@-N
INST1(stcgbr_reg,  "stc",     0,  IUM_RW, 0, 0, XMAC,    0, 0, 0x0012)
INST1(stsmach_reg, "sts",     0,  IUM_RW, 0, 0, XMAC,    0, 0, 0x000A)
INST1(stsmacl_reg, "sts",     0,  IUM_RW, 0, 0, XMAC,    0, 0, 0x001A)
INST1(stspr_reg,   "sts",     0,  IUM_RW, 0, 0, XPR ,    0, 0, 0x002A)

//     enum     name      BD  updmode rf wf   rx    wx  br _SR_@-N
INST1(lod_gbr,  "mov",     0,  IUM_RW, 0, 0, XMAC,    0, 0, 0xC400)
INST1(sto_gbr,  "mov",     0,  IUM_RW, 0, 0, XMAC,    0, 0, 0xC000)

//     enum     name      BD  updmode rf wf   rx    wx  br  N/A
INST1(ignore,   "ignore",  0,  IUM_RD, 0, 0,    0,    0, 0, 0x0000)
#if SCHEDULER
INST1(noSched,  "noSched", 0,  IUM_RD, 0, 0,    0,    0, 0, 0x0000)
#endif

// FP
INST1(fdiv,     "fdiv",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf003)
INST1(fldi0,    "fldi0",   0,  IUM_RW, 0, 0,    0,    0, 0, 0x0000)
INST1(fldi1,    "fldi1",   0,  IUM_RW, 0, 0,    0,    0, 0, 0xf09d)
INST1(flds,     "flds",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf01d)
INST1(float,    "float",   0,  IUM_RW, 0, 0,    0,    0, 0, 0xf02d)
INST1(fmac,     "fmac",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf00e)
INST1(fmul,     "fmul",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf002)
INST1(fneg,     "fneg",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf04d)
INST1(fschg,    "fschg",   0,  IUM_RW, 0, 0,    0,    0, 0, 0xf3fd)
INST1(fsqrt,    "fsqrt",   0,  IUM_RW, 0, 0,    0,    0, 0, 0xf06d)
INST1(fsts,     "fsts",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf00d)
INST1(fsub,     "fsub",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf001)
INST1(fcmpEQ,   "fcmp/eq", 0,  IUM_RW, 0, 0,    0,    0, 0, 0xf004)
INST1(fcmpGT,   "fcmp/gt", 0,  IUM_RW, 0, 0,    0,    0, 0, 0xf005)
INST1(ftrc,     "ftrc",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf03d)
INST1(fabs,     "fabs",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf09d)
INST1(fadd,     "fadd",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf000)
INST1(fmov,     "fmov",    0,  IUM_WR, 0, 0,    0,    0, 0, 0xf00c)
INST1(fmov_ind, "fmov",    0,  IUM_RW, 0, 0,    0,    0, 0, 0xf008)
INST1(ldsfpul,  "ldsfpul", 0,  IUM_RW, 0, 0,    0,    0, 0, 0x405a)
INST1(stsfpul,  "stsfpul", 0,  IUM_RW, 0, 0,    0,    0, 0, 0x005a)
INST1(ldsfpscr, "ldsfpscr",0,  IUM_RW, 0, 0,    0,    0, 0, 0x406a)
INST1(stsfpscr, "stsfpscr",0,  IUM_RW, 0, 0,    0,    0, 0, 0x006a)
INST1(fcnvds,   "fcnvds"  ,0,  IUM_RW, 0, 0,    0,    0, 0, 0xf0bd)
INST1(fcnvsd,   "fcnvsd"  ,0,  IUM_RW, 0, 0,    0,    0, 0, 0xf0ad)

/*****************************************************************************/

#undef  INST1
#undef  INST2
#undef  INST3

/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\instr.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                           Instruction                                     XX
XX                                                                           XX
XX          The interface to generate a machine-instruction.                 XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

#include "instr.h"
#include "emit.h"

/*****************************************************************************
 *
 *  The following table is used by the instIsFP()/instUse/DefFlags() helpers.
 */

BYTE                Compiler::instInfo[] =
{

    #if     TGT_x86
    #define INST0(id, nm, fp, um, rf, wf, ss, mr                 ) (INST_USE_FL*rf|INST_DEF_FL*wf|INST_FP*fp|INST_SPSCHD*ss),
    #define INST1(id, nm, fp, um, rf, wf, ss, mr                 ) (INST_USE_FL*rf|INST_DEF_FL*wf|INST_FP*fp|INST_SPSCHD*ss),
    #define INST2(id, nm, fp, um, rf, wf, ss, mr, mi             ) (INST_USE_FL*rf|INST_DEF_FL*wf|INST_FP*fp|INST_SPSCHD*ss),
    #define INST3(id, nm, fp, um, rf, wf, ss, mr, mi, rm         ) (INST_USE_FL*rf|INST_DEF_FL*wf|INST_FP*fp|INST_SPSCHD*ss),
    #define INST4(id, nm, fp, um, rf, wf, ss, mr, mi, rm, a4     ) (INST_USE_FL*rf|INST_DEF_FL*wf|INST_FP*fp|INST_SPSCHD*ss),
    #define INST5(id, nm, fp, um, rf, wf, ss, mr, mi, rm, a4, rr ) (INST_USE_FL*rf|INST_DEF_FL*wf|INST_FP*fp|INST_SPSCHD*ss),
    #include "instrs.h"
    #undef  INST0
    #undef  INST1
    #undef  INST2
    #undef  INST3
    #undef  INST4
    #undef  INST5
    #endif

    #if     TGT_SH3
    #define INST1(id, nm, bd, um, rf, wf, rx, wx, br, i1         ) (INST_USE_FL*rf|INST_DEF_FL*wf|INST_BD*(bd&1)|INST_BD_C*((bd&2)!=0)|INST_BR*br|INST_SPSCHD*(rx||wx)),
    #define INST2(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2     ) (INST_USE_FL*rf|INST_DEF_FL*wf|INST_BD*(bd&1)|INST_BD_C*((bd&2)!=0)|INST_BR*br|INST_SPSCHD*(rx||wx)),
    #define INST3(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2, i3 ) (INST_USE_FL*rf|INST_DEF_FL*wf|INST_BD*(bd&1)|INST_BD_C*((bd&2)!=0)|INST_BR*br|INST_SPSCHD*(rx||wx)),
    #include "instrSH3.h"
    #undef  INST1
    #undef  INST2
    #undef  INST3
    #endif

    #if     TGT_IA64
    #error  Don't use this for now
    #define INST1(id, nm, rf, wf)                                  (INST_USE_FL*rf|INST_DEF_FL*wf),
    #include "instrIA64.h"
    #undef  INST1
    #endif
};

/*****************************************************************************/
#ifdef  DEBUG
/*****************************************************************************
 *
 *  Returns the string representation of the given CPU instruction.
 */

const   char *      Compiler::genInsName(instruction ins)
{
    static
    const   char *  insNames[] =
    {

        #if TGT_x86
        #define INST0(id, nm, fp, um, rf, wf, mr, ss                 ) nm,
        #define INST1(id, nm, fp, um, rf, wf, mr, ss                 ) nm,
        #define INST2(id, nm, fp, um, rf, wf, mr, ss, mi             ) nm,
        #define INST3(id, nm, fp, um, rf, wf, mr, ss, mi, rm         ) nm,
        #define INST4(id, nm, fp, um, rf, wf, mr, ss, mi, rm, a4     ) nm,
        #define INST5(id, nm, fp, um, rf, wf, mr, ss, mi, rm, a4, rr ) nm,
        #include "instrs.h"
        #undef  INST0
        #undef  INST1
        #undef  INST2
        #undef  INST3
        #undef  INST4
        #undef  INST5
        #endif

        #if TGT_SH3
        #define INST1(id, nm, bd, um, rf, wf, rx, wx, br, i1        ) nm,
        #define INST2(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2    ) nm,
        #define INST3(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2, i3) nm,
        #include "instrSH3.h"
        #undef  INST1
        #undef  INST2
        #undef  INST3
        #endif

        #if     TGT_IA64
        #error  Don't use this for now
        #define INST1(id, nm, rf, wf)                                 nm,
        #include "instrIA64.h"
        #undef  INST1
        #endif
    };

    ASSert(ins < sizeof(insNames)/sizeof(insNames[0]));

    ASSert(insNames[ins]);

    return insNames[ins];
}

void    __cdecl     Compiler::instDisp(instruction ins, bool noNL, const char *fmt, ...)
{
    if  (dspCode)
    {
        /* Display the instruction offset within the emit block */

//      printf("[%08X:%04X]", genEmitter.emitCodeCurBlock(), genEmitter.emitCodeOffsInBlock());

        /* Display the FP stack depth (before the instruction is executed) */

#if TGT_x86
//      printf("[FP=%02u] ", genFPstkLevel);
#endif

        /* Display the instruction mnemonic */

        printf("            %-8s", genInsName(ins));

        if  (fmt)
        {
            va_list  args;
            va_start(args, fmt);
            vprintf (fmt,  args);
            va_end  (args);
        }

        if  (!noNL)
            printf("\n");
    }
}

/*****************************************************************************/
#endif//DEBUG
/*****************************************************************************/

void                Compiler::instInit()
{
}

/*****************************************************************************/
#if TGT_x86
/*****************************************************************************/

#if!INLINING

#undef inst_IV_handle
#undef instEmitDataFixup
#undef inst_CV

#if INDIRECT_CALLS
#undef inst_SM
#endif

#undef inst_CV_RV
#undef inst_CV_IV
#undef inst_RV_CV
#undef instEmit_vfnCall

#endif

/*****************************************************************************
 *
 *  What a collossal hack, one of these we'll have to clean this up ...
 */

#if     DOUBLE_ALIGN
#define DOUBLE_ALIGN_BPREL_ARG  , genFPused || genDoubleAlign && varDsc->lvIsParam
#else
#define DOUBLE_ALIGN_BPREL_ARG
#endif

/*****************************************************************************
 *
 *  Return the size string (e.g. "word ptr") appropriate for the given size.
 */

#ifdef  DEBUG

const   char *      Compiler::genSizeStr(emitAttr attr)
{
    static
    const   char *  sizes[] =
    {
        "",
        "byte  ptr ",
        "word  ptr ",
        0,
        "dword ptr ",
        0,
        0,
        0,
        "qword ptr ",
    };

    unsigned size = EA_SIZE(attr);

    ASSert(size == 0 || size == 1 || size == 2 || size == 4 || size == 8);

    if (EA_ATTR(size) == attr)
        return sizes[size];
    else if (attr == EA_GCREF)
        return "gword ptr ";
    else if (attr == EA_BYREF)
        return "bword ptr ";
    else if (EA_IS_DSP_RELOC(attr))
        return "rword ptr ";
    else
    {
        ASSert(!"Unexpected");
        return "unknw ptr ";
    }
}

#endif

/*****************************************************************************
 *
 *  Generate an instruction.
 */

void                Compiler::instGen(instruction ins)
{
#ifdef  DEBUG

#if     INLINE_MATH
    if    (ins != INS_fabs    &&
           ins != INS_fsqrt   &&
           ins != INS_fsin    &&
           ins != INS_fcos)
#endif
    assert(ins == INS_cdq     ||
           ins == INS_f2xm1   ||
           ins == INS_fchs    ||
           ins == INS_fld1    ||
           ins == INS_fld1    ||
           ins == INS_fldl2e  ||
           ins == INS_fldz    ||
           ins == INS_fprem   ||
           ins == INS_frndint ||
           ins == INS_fscale  ||
           ins == INS_int3    ||
           ins == INS_leave   ||
           ins == INS_movsb   ||
           ins == INS_movsd   ||
           ins == INS_nop     ||
           ins == INS_r_movsb ||
           ins == INS_r_movsd ||
           ins == INS_r_stosb ||
           ins == INS_r_stosd ||
           ins == INS_ret     ||
           ins == INS_sahf    ||
           ins == INS_stosb   ||
           ins == INS_stosd      );

#endif

    genEmitter->emitIns(ins);
}

/*****************************************************************************
 *
 *  Generate a jump instruction.
 */

void        Compiler::inst_JMP(emitJumpKind     jmp,
                               BasicBlock *     block,
#if SCHEDULER
                               bool             except,
                               bool             moveable,
#endif
                               bool             newBlock)
{
    static
    instruction     EJtoINS[] =
    {
        INS_nop,

        #define JMP_SMALL(en, nm, op) INS_##en,
        #define JMP_LARGE(en, nm, op)
        #include "emitjmps.h"
        #undef  JMP_SMALL
        #undef  JMP_LARGE

        INS_call,
    };

    assert(jmp < sizeof(EJtoINS)/sizeof(EJtoINS[0]));

    genEmitter->emitIns_J(EJtoINS[jmp], except, moveable, block);
}

/*****************************************************************************
 *
 *  Generate a set instruction.
 */

void                Compiler::inst_SET(emitJumpKind   condition,
                                       regNumber      reg)
{
    instruction     ins;

    /* Convert the condition to a string */

    switch (condition)
    {
    case EJ_js  : ins = INS_sets  ; break;
    case EJ_jns : ins = INS_setns ; break;
    case EJ_je  : ins = INS_sete  ; break;
    case EJ_jne : ins = INS_setne ; break;

    case EJ_jl  : ins = INS_setl  ; break;
    case EJ_jle : ins = INS_setle ; break;
    case EJ_jge : ins = INS_setge ; break;
    case EJ_jg  : ins = INS_setg  ; break;

    case EJ_jb  : ins = INS_setb  ; break;
    case EJ_jbe : ins = INS_setbe ; break;
    case EJ_jae : ins = INS_setae ; break;
    case EJ_ja  : ins = INS_seta  ; break;

    case EJ_jpe : ins = INS_setpe ; break;
    case EJ_jpo : ins = INS_setpo ; break;

    default:      assert(!"unexpected condition type");
    }

    assert(genRegMask(reg) & RBM_BYTE_REGS);

    genEmitter->emitIns_R(ins, EA_4BYTE, (emitRegs)reg);
}

/*****************************************************************************
 *
 *  Generate a "op reg" instruction.
 */

void        Compiler::inst_RV(instruction ins, regNumber reg, var_types type, emitAttr size)
{
    if (size == EA_UNKNOWN)
        size = emitActualTypeSize(type);

    genEmitter->emitIns_R(ins, size, (emitRegs)reg);
}

/*****************************************************************************
 *
 *  Generate a "op reg1, reg2" instruction.
 */

void                Compiler::inst_RV_RV(instruction ins, regNumber reg1,
                                                          regNumber reg2,
                                                          var_types type,
                                                          emitAttr  size)
{
    assert(ins == INS_test ||
           ins == INS_add  ||
           ins == INS_adc  ||
           ins == INS_sub  ||
           ins == INS_sbb  ||
           ins == INS_imul ||
           ins == INS_idiv ||
           ins == INS_cmp  ||
           ins == INS_mov  ||
           ins == INS_and  ||
           ins == INS_or   ||
           ins == INS_xor  ||
           ins == INS_xchg ||
           ins == INS_movsx||
           ins == INS_movzx);

    if (size == EA_UNKNOWN)
        size = emitActualTypeSize(type);

    genEmitter->emitIns_R_R(ins, size, (emitRegs)reg1, (emitRegs)reg2);
}

/*****************************************************************************
 *
 *  Generate a "op icon" instruction.
 */

void                Compiler::inst_IV(instruction ins, long val)
{
    genEmitter->emitIns_I(ins,
                          EA_4BYTE,
                          val);
}

/*****************************************************************************
 *
 *  Generate a "op icon" instruction where icon is a handle of type specified
 *  by 'flags' and representing the CP index CPnum
 */

void                Compiler::inst_IV_handle(instruction    ins,
                                             long           val,
                                             unsigned       flags,
                                             unsigned       CPnum,
                                             CLASS_HANDLE   CLS)
{
#if!INLINING
    CLS = info.compScopeHnd;
#endif

#ifdef  JIT_AS_COMPILER

    execFixTgts     fixupKind;

    assert(ins == INS_push);

#ifdef  DEBUG
    instDisp(ins, false, "%d", val);
#endif

    fixupKind = (execFixTgts)((flags >> GTF_ICON_HDL_SHIFT)-1+FIX_TGT_CLASS_HDL);

    assert((GTF_ICON_CLASS_HDL  >> GTF_ICON_HDL_SHIFT)-1+FIX_TGT_CLASS_HDL == FIX_TGT_CLASS_HDL);
    assert((GTF_ICON_METHOD_HDL >> GTF_ICON_HDL_SHIFT)-1+FIX_TGT_CLASS_HDL == FIX_TGT_METHOD_HDL);
    assert((GTF_ICON_FIELD_HDL  >> GTF_ICON_HDL_SHIFT)-1+FIX_TGT_CLASS_HDL == FIX_TGT_FIELD_HDL);
    assert((GTF_ICON_STATIC_HDL >> GTF_ICON_HDL_SHIFT)-1+FIX_TGT_CLASS_HDL == FIX_TGT_STATIC_HDL);
    assert((GTF_ICON_IID_HDL    >> GTF_ICON_HDL_SHIFT)-1+FIX_TGT_CLASS_HDL == FIX_TGT_IID_HDL);
    assert((GTF_ICON_STRCNS_HDL >> GTF_ICON_HDL_SHIFT)-1+FIX_TGT_CLASS_HDL == FIX_TGT_STRCNS_HDL);

    assert(!"NYI for pre-compiled code");

#else   // not JIT_AS_COMPILER

    genEmitter->emitIns_I(ins, EA_4BYTE_CNS_RELOC, val);

#endif  // JIT_AS_COMPILER

}

#if!INLINING
#define inst_IV_handle(ins,val,flags,cpx,cls) inst_IV_handle(ins,val,flags,cpx,0)
#endif

/*****************************************************************************
 *
 *  Generate a "op ST(n), ST(0)" instruction.
 */

void                Compiler::inst_FS(instruction ins, unsigned stk)
{
    assert(stk < 8);

#ifdef  DEBUG

    switch (ins)
    {
    case INS_fld:
    case INS_fxch:
        assert(!"don't do this");
    }

#endif

    genEmitter->emitIns_F_F0(ins, stk);
}

/*****************************************************************************
 *
 *  Generate a "op ST(0), ST(n)" instruction
 */

void                Compiler::inst_FN(instruction ins, unsigned stk)
{
    assert(stk < 8);

#ifdef  DEBUG

    switch (ins)
    {
    case INS_fst:
    case INS_fstp:
    case INS_faddp:
    case INS_fsubp:
    case INS_fsubrp:
    case INS_fmulp:
    case INS_fdivp:
    case INS_fdivrp:
        assert(!"don't do this");
    }

#endif

    genEmitter->emitIns_F0_F(ins, stk);
}

/*****************************************************************************
 *
 *  Display a stack frame reference.
 */

inline
void                Compiler::inst_set_SV_var(GenTreePtr tree)
{
#ifdef  DEBUG

    assert(tree && tree->gtOper == GT_LCL_VAR);
    assert(tree->gtLclVar.gtLclNum < lvaCount);

    genEmitter->emitVarRefOffs = tree->gtLclVar.gtLclOffs;

#endif//DEBUG
}

/*****************************************************************************
 *
 *  Generate a "op reg, icon" instruction.
 */

void                Compiler::inst_RV_IV(instruction    ins,
                                         regNumber      reg,
                                         long           val,
                                         var_types      type)
{
    emitAttr  size = emitTypeSize(type);

    assert(size != EA_8BYTE);

    /* The 'imul' opcode is mapped to reg form in inst_RV_TT_IV, so it's
     * never seen here.
     */

    assert(ins != INS_imul);

    genEmitter->emitIns_R_I(ins, size, (emitRegs)reg, val);
}

/*****************************************************************************
 *
 *  Generate a "op    offset <class variable address>" instruction.
 */

void                Compiler::inst_AV(instruction  ins,
                                      GenTreePtr   tree, unsigned offs)
{
    assert(ins == INS_push);

    assert(tree->gtOper == GT_CLS_VAR);
        // This is a jit data offset, not a normal class variable.
    assert(eeGetJitDataOffs(tree->gtClsVar.gtClsVarHnd) >= 0);
    assert(tree->TypeGet() == TYP_INT);

    /* Size equal to EA_OFFSET indicates "push offset clsvar" */

    genEmitter->emitIns_C(ins, EA_OFFSET, tree->gtClsVar.gtClsVarHnd, offs);
}

/*****************************************************************************
 *
 *  Schedule an "ins reg, [r/m]" (rdst=true) or "ins [r/m], reg" (rdst=false)
 *  instruction (the r/m operand given by a tree). We also allow instructions
 *  of the form "ins [r/m], icon", these are signalled by setting 'cons' to
 *  true.
 */

void                Compiler::sched_AM(instruction  ins,
                                       emitAttr     size,
                                       regNumber    ireg,
                                       bool         rdst,
                                       GenTreePtr   addr,
                                       unsigned     offs,
                                       bool         cons,
                                       int          val)
{
    bool            rev;
    GenTreePtr      rv1;
    GenTreePtr      rv2;
    unsigned        cns;
    unsigned        mul;

    emitRegs       reg;
    emitRegs       rg2;
    emitRegs       irg = (emitRegs)ireg;

    /* Don't use this method for issuing calls. Use instEmit_xxxCall() */

    assert(ins != INS_call);

    assert(addr);
    assert(size != EA_UNKNOWN);

    assert(REG_EAX == SR_EAX);
    assert(REG_ECX == SR_ECX);
    assert(REG_EDX == SR_EDX);
    assert(REG_EBX == SR_EBX);
    assert(REG_ESP == SR_ESP);
    assert(REG_EBP == SR_EBP);
    assert(REG_ESI == SR_ESI);
    assert(REG_EDI == SR_EDI);

    /* Has the address been conveniently loaded into a register,
       or is it an absolute value ? */

    if  ((addr->gtFlags & GTF_REG_VAL) ||
         (addr->gtOper == GT_CNS_INT))
    {
        if (addr->gtFlags & GTF_REG_VAL)
        {
            /* The address is "[reg+offs]" */

            reg = (emitRegs)addr->gtRegNum;
        }
        else
        {
            /* The address is an absolute value */

            assert(addr->gtOper == GT_CNS_INT);

#ifdef RELOC_SUPPORT
            // Do we need relocations?
            if (opts.compReloc && (addr->gtFlags & GTF_ICON_HDL_MASK))
            {
                size = EA_SET_FLG(size, EA_DSP_RELOC_FLG);
            }
#endif
            reg = SR_NA;
            offs += addr->gtIntCon.gtIconVal;
        }

        if      (cons)
            genEmitter->emitIns_I_AR  (ins, size,      val, reg, offs);
        else if (rdst)
            genEmitter->emitIns_R_AR  (ins, size, irg,      reg, offs);
        else
            genEmitter->emitIns_AR_R  (ins, size, irg,      reg, offs);

        return;
    }

    /* Figure out what complex address mode to use */

    bool yes = genCreateAddrMode(addr, -1, true, 0, &rev, &rv1, &rv2, &mul, &cns);
    assert(yes);

    /* Add the constant offset value, if present */

    offs += cns;

    /* Is there an additional operand? */

    if  (rv2)
    {
        /* The additional operand must be sitting in a register */

        assert(rv2->gtFlags & GTF_REG_VAL); rg2 = (emitRegs)rv2->gtRegNum;

        /* Is the additional operand scaled? */

        if  (mul)
        {
            /* Is there a base address operand? */

            if  (rv1)
            {
                assert(rv1->gtFlags & GTF_REG_VAL); reg = (emitRegs)rv1->gtRegNum;

                /* The address is "[reg1 + {2/4/8} * reg2 + offs]" */

                if      (cons)
                    genEmitter->emitIns_I_ARX(ins, size, val, reg, rg2, mul, offs);
                else if (rdst)
                    genEmitter->emitIns_R_ARX(ins, size, irg, reg, rg2, mul, offs);
                else
                    genEmitter->emitIns_ARX_R(ins, size, irg, reg, rg2, mul, offs);
            }
            else
            {
                /* The address is "[{2/4/8} * reg2 + offs]" */

                if      (cons)
                    genEmitter->emitIns_I_AX (ins, size, val,      rg2, mul, offs);
                else if (rdst)
                    genEmitter->emitIns_R_AX (ins, size, irg,      rg2, mul, offs);
                else
                    genEmitter->emitIns_AX_R (ins, size, irg,      rg2, mul, offs);
            }
        }
        else
        {
            assert(rv1 && (rv1->gtFlags & GTF_REG_VAL)); reg = (emitRegs)rv1->gtRegNum;

            /* The address is "[reg1 + reg2 + offs]" */

            if      (cons)
                genEmitter->emitIns_I_ARR(ins, size, val, reg, rg2, offs);
            else if (rdst)
                genEmitter->emitIns_R_ARR(ins, size, irg, reg, rg2, offs);
            else
                genEmitter->emitIns_ARR_R(ins, size, irg, reg, rg2, offs);
        }
    }
    else
    {
        unsigned        cpx = 0;
        CLASS_HANDLE    cls = 0;

        /* No second operand: the address is "[reg  + icon]" */

        assert(rv1 && (rv1->gtFlags & GTF_REG_VAL)); reg = (emitRegs)rv1->gtRegNum;

#ifdef  LATE_DISASM

        /*
            Keep in mind that non-static data members (GT_FIELD nodes) were
            transformed into GT_IND nodes - we keep the CLS/CPX information
            in the GT_CNS_INT node representing the field offset of the
            class member
         */

        if  ((addr->gtOp.gtOp2->gtOper == GT_CNS_INT) &&
             ((addr->gtOp.gtOp2->gtFlags & GTF_ICON_HDL_MASK) == GTF_ICON_FIELD_HDL))
        {
            /* This is a field offset - set the CPX/CLS values to emit a fixup */

            cpx = addr->gtOp.gtOp2->gtIntCon.gtIconCPX;
            cls = addr->gtOp.gtOp2->gtIntCon.gtIconCls;
        }

#endif

        if      (cons)
            genEmitter->emitIns_I_AR(ins, size, val, reg, offs, cpx, cls);
        else if (rdst)
            genEmitter->emitIns_R_AR(ins, size, irg, reg, offs, cpx, cls);
        else
            genEmitter->emitIns_AR_R(ins, size, irg, reg, offs, cpx, cls);
    }
}

/*****************************************************************************
 *
 *  Emit a "call [r/m]" instruction (the r/m operand given by a tree).
 */

void                Compiler::instEmit_indCall(GenTreePtr   call,
                                               size_t       argSize,
                                               size_t       retSize)
{
    GenTreePtr              addr;

    emitter::EmitCallType   emitCallType;

    emitRegs                brg = SR_NA;
    emitRegs                xrg = SR_NA;
    unsigned                mul = 0;
    unsigned                cns = 0;

    assert(call->gtOper == GT_CALL);

    assert(REG_EAX == SR_EAX);
    assert(REG_ECX == SR_ECX);
    assert(REG_EDX == SR_EDX);
    assert(REG_EBX == SR_EBX);
    assert(REG_ESP == SR_ESP);
    assert(REG_EBP == SR_EBP);
    assert(REG_ESI == SR_ESI);
    assert(REG_EDI == SR_EDI);

    /* Get hold of the function address */

    assert(call->gtCall.gtCallType == CT_INDIRECT);
    addr = call->gtCall.gtCallAddr;
    assert(addr);

    /* Is there an indirection? */

    if  (addr->gtOper != GT_IND)
    {
        if (addr->gtFlags & GTF_REG_VAL)
        {
            emitCallType = emitter::EC_INDIR_R;
            brg = (emitRegs)addr->gtRegNum;
        }
        else
        {
            if (addr->OperGet() != GT_CNS_INT)
            {
                assert(addr->OperGet() == GT_LCL_VAR);

                emitCallType = emitter::EC_INDIR_SR;
                cns = addr->gtLclVar.gtLclNum;
            }
            else
            {
#ifdef _WIN64
                __int64     funcPtr = addr->gtLngCon.gtLconVal;
#else
                unsigned    funcPtr = addr->gtIntCon.gtIconVal;
#endif

                genEmitter->emitIns_Call( emitter::EC_FUNC_ADDR,
                                          (void*) funcPtr,
                                          argSize,
                                          retSize,
                                          gcVarPtrSetCur,
                                          gcRegGCrefSetCur,
                                          gcRegByrefSetCur);
                return;
            }
        }
    }
    else
    {
        /* This is an indirect call */

        emitCallType = emitter::EC_INDIR_ARD;

        /* Get hold of the address of the function pointer */

        addr = addr->gtOp.gtOp1;

        /* Has the address been conveniently loaded into a register? */

        if  (addr->gtFlags & GTF_REG_VAL)
        {
            /* The address is "reg" */

            brg = (emitRegs)addr->gtRegNum;
        }
        else
        {
            bool            rev;

            GenTreePtr      rv1;
            GenTreePtr      rv2;

            /* Figure out what complex address mode to use */

            {
             bool yes = genCreateAddrMode(addr, -1, true, 0, &rev, &rv1, &rv2, &mul, &cns); assert(yes);
            }

            /* Get the additional operands if any */

            if  (rv1)
            {
                assert(rv1->gtFlags & GTF_REG_VAL); brg = (emitRegs)rv1->gtRegNum;
            }

            if  (rv2)
            {
                assert(rv2->gtFlags & GTF_REG_VAL); xrg = (emitRegs)rv2->gtRegNum;
            }
        }
    }

    assert(emitCallType == emitter::EC_INDIR_R || emitCallType == emitter::EC_INDIR_SR ||
           emitCallType == emitter::EC_INDIR_C || emitCallType == emitter::EC_INDIR_ARD);

    genEmitter->emitIns_Call( emitCallType,
                              NULL,                 // will be ignored
                              argSize,
                              retSize,
                              gcVarPtrSetCur,
                              gcRegGCrefSetCur,
                              gcRegByrefSetCur,
                              brg, xrg, mul, cns);  // addressing mode values
}

/*****************************************************************************
 *
 *  Emit an "op [r/m]" instruction (the r/m operand given by a tree).
 */

void                Compiler::instEmit_RM(instruction  ins,
                                          GenTreePtr   tree,
                                          GenTreePtr   addr,
                                          unsigned     offs)
{
    emitAttr   size;

    if (!instIsFP(ins))
        size = emitTypeSize(tree->TypeGet());
    else
        size = EA_ATTR(genTypeSize(tree->TypeGet()));

    sched_AM(ins, size, REG_NA, false, addr, offs);
}

/*****************************************************************************
 *
 *  Emit an "op [r/m], reg" instruction (the r/m operand given by a tree).
 */

void                Compiler::instEmit_RM_RV(instruction  ins,
                                             emitAttr     size,
                                             GenTreePtr   tree,
                                             regNumber    reg,
                                             unsigned     offs)
{
    assert(instIsFP(ins) == 0);

    sched_AM(ins, size, reg, false, tree, offs);
}

/*****************************************************************************
 *
 *  Generate an instruction that has one operand given by a tree (which has
 *  been made addressable).
 */

void                Compiler::inst_TT(instruction   ins,
                                      GenTreePtr    tree,
                                      unsigned      offs,
                                      int           shfv,
                                      emitAttr      size)
{
    if (size == EA_UNKNOWN)
    {
        if (instIsFP(ins))
            size = EA_SIZE(genTypeSize(tree->TypeGet()));
        else
            size = emitActualTypeSize(tree->TypeGet());
    }

AGAIN:

    /* Is the value sitting in a register? */

    if  (tree->gtFlags & GTF_REG_VAL)
    {
        regNumber       reg;

    LONGREG_TT:

        reg = tree->gtRegNum;

        /* Is this a floating-point instruction? */

        if  (tree->gtType == TYP_DOUBLE)
        {
            assert(instIsFP(ins) && ins != INS_fst && ins != INS_fstp);
            assert(shfv == 0);

            inst_FS(ins, reg + genFPstkLevel);
            return;
        }

        assert(instIsFP(ins) == 0);

        if  (tree->gtType == TYP_LONG)
        {
            if  (offs)
            {
                assert(offs == sizeof(int));

                reg = genRegPairHi((regPairNo)reg);
            }
            else
                reg = genRegPairLo((regPairNo)reg);
        }

        /* Make sure it is not the "stack-half" of an enregistered long */

        if  (reg != REG_STK)
        {
            if  (size == EA_8BYTE)
                size = EA_4BYTE;

            if  (shfv)
                genEmitter->emitIns_R_I(ins, size, (emitRegs)reg, shfv);
            else
                inst_RV(ins, reg, tree->TypeGet(), size);

            return;
        }
    }

    /* Is this a spilled value? */

    if  (tree->gtFlags & GTF_SPILLED)
    {
        assert(!"ISSUE: If this can happen, we need to generate 'ins [ebp+spill]'");
    }

    switch (tree->gtOper)
    {
        unsigned        varNum;
        LclVarDsc   *   varDsc;
        int             varOfs;

    case GT_LCL_VAR:

        assert(genTypeSize(tree->gtType) >= sizeof(int));

        /* Is this an enregistered long ? */

        if  (tree->gtType == TYP_LONG && !(tree->gtFlags & GTF_REG_VAL))
        {
            /* Avoid infinite loop */

            if  (genMarkLclVar(tree))
                goto LONGREG_TT;
        }

        varNum = tree->gtLclVar.gtLclNum; assert(varNum < lvaCount);
        varDsc = lvaTable + varNum;
        varOfs = varDsc->lvStkOffs + offs;

        inst_set_SV_var(tree);

        if  (shfv)
            genEmitter->emitIns_S_I(ins, size, varNum, offs, shfv);
        else
            genEmitter->emitIns_S  (ins, size, varNum, offs);

        return;

    case GT_CLS_VAR:

        if  (shfv)
            genEmitter->emitIns_C_I(ins, size, tree->gtClsVar.gtClsVarHnd,
                                                offs,
                                                shfv);
        else
            genEmitter->emitIns_C  (ins, size, tree->gtClsVar.gtClsVarHnd,
                                                offs);
        return;

    case GT_IND:

        if  (shfv)
               sched_AM(ins, size, REG_NA, false, tree->gtOp.gtOp1, offs, true, shfv);
        else
            instEmit_RM(ins, tree,                tree->gtOp.gtOp1, offs);

        break;

    case GT_COMMA:
        //     tree->gtOp.gtOp1 - already processed by genCreateAddrMode()
        tree = tree->gtOp.gtOp2;
        goto AGAIN;

    default:
        assert(!"invalid address");
    }

}

/*****************************************************************************
 *
 *  Generate an instruction that has one operand given by a tree (which has
 *  been made addressable) and another that is a register.
 */

void                Compiler::inst_TT_RV(instruction   ins,
                                         GenTreePtr    tree,
                                         regNumber     reg, unsigned offs)
{
    assert(reg != REG_STK);

AGAIN:

    /* Is the value sitting in a register? */

    if  (tree->gtFlags & GTF_REG_VAL)
    {
        regNumber       rg2;

    LONGREG_TT_RV:

        assert(instIsFP(ins) == 0);

        rg2 = tree->gtRegNum;

        if  (tree->gtType == TYP_LONG)
        {
            if  (offs)
            {
                assert(offs == sizeof(int));

                rg2 = genRegPairHi((regPairNo)rg2);
            }
            else
                rg2 = genRegPairLo((regPairNo)rg2);
        }

        if  (rg2 != REG_STK)
        {
            inst_RV_RV(ins, rg2, reg, tree->TypeGet());

            return;
        }
    }

    /* Is this a spilled value? */

    if  (tree->gtFlags & GTF_SPILLED)
    {
        assert(!"ISSUE: If this can happen, we need to generate 'ins [ebp+spill]'");
    }

    emitAttr   size;

    if (!instIsFP(ins))
        size = emitTypeSize(tree->TypeGet());
    else
        size = EA_SIZE(genTypeSize(tree->TypeGet()));

    switch (tree->gtOper)
    {
        unsigned        varNum;
        LclVarDsc   *   varDsc;
        int             varOfs;

    case GT_LCL_VAR:

        if  (tree->gtType == TYP_LONG && !(tree->gtFlags & GTF_REG_VAL))
        {
            /* Avoid infinite loop */

            if  (genMarkLclVar(tree))
                goto LONGREG_TT_RV;
        }

        varNum = tree->gtLclVar.gtLclNum; assert(varNum < lvaCount);
        varDsc = lvaTable + varNum;
        varOfs = varDsc->lvStkOffs + offs;

        inst_set_SV_var(tree);

        genEmitter->emitIns_S_R(ins, size, (emitRegs)reg, varNum, offs);
        return;

    case GT_CLS_VAR:

        genEmitter->emitIns_C_R(ins, size, tree->gtClsVar.gtClsVarHnd,
                                            (emitRegs)reg,
                                            offs);
        return;

    case GT_IND:

        instEmit_RM_RV(ins, size, tree->gtOp.gtOp1, reg, offs);
        break;

    case GT_COMMA:
        //     tree->gtOp.gtOp1 - already processed by genCreateAddrMode()
        tree = tree->gtOp.gtOp2;
        goto AGAIN;

    default:
        assert(!"invalid address");
    }
}

/*****************************************************************************
 *
 *  Generate an instruction that has one operand given by a tree (which has
 *  been made addressable) and another that is an integer constant.
 */

void                Compiler::inst_TT_IV(instruction   ins,
                                         GenTreePtr    tree,
                                         long          val, unsigned offs)
{
AGAIN:

    /* Is the value sitting in a register? */

    if  (tree->gtFlags & GTF_REG_VAL)
    {
LONGREG_TT_IV:
        regNumber       reg = tree->gtRegNum;

        assert(instIsFP(ins) == 0);

        if  (tree->gtType == TYP_LONG)
        {
            if  (offs)
            {
                assert(offs == sizeof(int));

                reg = genRegPairHi((regPairNo)reg);
            }
            else
                reg = genRegPairLo((regPairNo)reg);
        }

        if  (reg != REG_STK)
        {
            if  (ins == INS_mov)
            {
                genSetRegToIcon(reg, val, tree->TypeGet());
            }
            else
                inst_RV_IV(ins, reg, val);

            return;
        }
    }

    /* Is this a spilled value? */

    if  (tree->gtFlags & GTF_SPILLED)
    {
        assert(!"ISSUE: If this can happen, we need to generate 'ins [ebp+spill], icon'");
    }

    emitAttr   size;

    if (!instIsFP(ins))
        size = emitTypeSize(tree->TypeGet());
    else
        size = EA_SIZE(genTypeSize(tree->TypeGet()));

    switch (tree->gtOper)
    {
        unsigned        varNum;
        LclVarDsc   *   varDsc;
        int             varOfs;

    case GT_LCL_VAR:

        /* Is this an enregistered long ? */

        if  (tree->gtType == TYP_LONG && !(tree->gtFlags & GTF_REG_VAL))
        {
            /* Avoid infinite loop */

            if  (genMarkLclVar(tree))
                goto LONGREG_TT_IV;
        }

        varNum = tree->gtLclVar.gtLclNum; assert(varNum < lvaCount);
        varDsc = lvaTable + varNum;
        varOfs = varDsc->lvStkOffs + offs;

        inst_set_SV_var(tree);

        /* Integer instructions never operate on more than EA_4BYTE */

        assert(instIsFP(ins) == false);

        if  (size == EA_8BYTE)
            size = EA_4BYTE;

        if (size < EA_4BYTE && !varTypeIsUnsigned((var_types)varDsc->lvType))
        {
            if (size == EA_1BYTE)
            {
                if ((val & 0x7f) != val)
                    val = val | 0xffffff00;
            }
            else
            {
                assert(size == EA_2BYTE);
                if ((val & 0x7fff) != val)
                    val = val | 0xffff0000;
            }
        }
        size = EA_4BYTE;

        genEmitter->emitIns_S_I(ins, size, varNum, offs, val);
        return;

    case GT_CLS_VAR:

        genEmitter->emitIns_C_I(ins, size, tree->gtClsVar.gtClsVarHnd, offs, val);
        return;

    case GT_IND:

        sched_AM(ins, size, REG_NA, false, tree->gtOp.gtOp1, offs, true, val);
        return;

    case GT_COMMA:
        //     tree->gtOp.gtOp1 - already processed by genCreateAddrMode()
        tree = tree->gtOp.gtOp2;
        goto AGAIN;

    default:
        assert(!"invalid address");
    }
}

/*****************************************************************************
 *
 *  Generate an instruction that has one operand given by a register and the
 *  other one by an indirection tree (which has been made addressable).
 */

void                Compiler::inst_RV_AT(instruction   ins,
                                         emitAttr      size,
                                         var_types     type, regNumber     reg,
                                                             GenTreePtr    tree,
                                                             unsigned      offs)
{
    assert(instIsFP(ins) == 0);

#if TRACK_GC_REFS

    /* Set "size" to EA_GCREF or EA_BYREF if the operand is a pointer */

    if  (type == TYP_REF)
    {
        if      (size == EA_4BYTE)
        {
            size = EA_GCREF;
        }
        else if (size == EA_GCREF)
        {
            /* Already marked as a pointer value */
        }
        else
        {
            /* Must be a derived pointer */

            assert(ins == INS_lea);
        }
    }
    else if (type == TYP_BYREF)
    {
        if      (size == EA_4BYTE)
        {
            size = EA_BYREF;
        }
        else if (size == EA_BYREF)
        {
            /* Already marked as a pointer value */
        }
        else
        {
            /* Must be a derived pointer */

            assert(ins == INS_lea);
        }
    }
    else
#endif
    {
        /* Integer instructions never operate on more than EA_4BYTE */

        if  (size == EA_8BYTE && !instIsFP(ins))
            size = EA_4BYTE;
    }

    sched_AM(ins, size, reg, true, tree, offs);
}

/*****************************************************************************
 *
 *  Generate an instruction that has one operand given by an indirection tree
 *  (which has been made addressable) and an integer constant.
 */

void        Compiler::inst_AT_IV(instruction   ins,
                                 emitAttr      size, GenTreePtr    tree,
                                                     long          icon,
                                                     unsigned      offs)
{
    sched_AM(ins, size, REG_NA, false, tree, offs, true, icon);
}

/*****************************************************************************
 *
 *  Generate an instruction that has one operand given by a register and the
 *  other one by a tree (which has been made addressable).
 */

void                Compiler::inst_RV_TT(instruction   ins,
                                         regNumber     reg,
                                         GenTreePtr    tree, unsigned offs,
                                                             emitAttr size)
{
    assert(reg != REG_STK);

    if (size == EA_UNKNOWN)
    {
        if (!instIsFP(ins))
            size = emitTypeSize(tree->TypeGet());
        else
            size = EA_SIZE(genTypeSize(tree->TypeGet()));
    }

#ifdef DEBUG
                // If it is a GC type and the result is not, then either
                // 1) it is an LEA
                // 2) we optimized if(ref != 0 && ref != 0) to if (ref & ref)
                // 3) we optimized if(ref == 0 || ref == 0) to if (ref | ref)
    if  (tree->gtType == TYP_REF   && !EA_IS_GCREF(size))
        assert(ins == INS_lea || ins == INS_and || ins == INS_or);
    if  (tree->gtType == TYP_BYREF && !EA_IS_BYREF(size))
        assert(ins == INS_lea || ins == INS_and || ins == INS_or);
#endif

AGAIN:

    /* Is the value sitting in a register? */

    if  (tree->gtFlags & GTF_REG_VAL)
    {
LONGREG_RVTT:

        regNumber       rg2 = tree->gtRegNum;

        assert(instIsFP(ins) == 0);

        if  (tree->gtType == TYP_LONG)
        {
            if  (offs)
            {
                assert(offs == sizeof(int));

                rg2 = genRegPairHi((regPairNo)rg2);
            }
            else
                rg2 = genRegPairLo((regPairNo)rg2);
        }
        if  (rg2 != REG_STK)
        {
            inst_RV_RV(ins, reg, rg2, tree->TypeGet(), size);

            return;
        }
    }

    /* Is this a spilled value? */

    if  (tree->gtFlags & GTF_SPILLED)
    {
        assert(!"ISSUE: If this can happen, we need to generate 'ins [ebp+spill]'");
    }

    switch (tree->gtOper)
    {
        unsigned        varNum;
        LclVarDsc   *   varDsc;
        int             varOfs;

    case GT_LCL_VAR:

        /* Is this an enregistered long ? */

        if  (tree->gtType == TYP_LONG && !(tree->gtFlags & GTF_REG_VAL))
        {

            /* Avoid infinite loop */

            if  (genMarkLclVar(tree))
                goto LONGREG_RVTT;
        }

        varNum = tree->gtLclVar.gtLclNum; assert(varNum < lvaCount);
        varDsc = lvaTable + varNum;
        varOfs = varDsc->lvStkOffs + offs;

        inst_set_SV_var(tree);

        genEmitter->emitIns_R_S(ins, size, (emitRegs)reg, varNum, offs);
        return;

    case GT_CLS_VAR:

        genEmitter->emitIns_R_C(ins, size, (emitRegs)reg,
                                            tree->gtClsVar.gtClsVarHnd,
                                            offs);

        return;

    case GT_IND:
        inst_RV_AT(ins, size, tree->TypeGet(), reg, tree->gtOp.gtOp1, offs);
        break;

    case GT_CNS_INT:

        assert(offs == 0);
        assert(size == EA_UNKNOWN || size == EA_4BYTE);

        inst_RV_IV(ins, reg, tree->gtIntCon.gtIconVal);
        break;

    case GT_CNS_LNG:

        assert(size == EA_4BYTE || size == EA_8BYTE);

        if  (offs == 0)
            inst_RV_IV(ins, reg, (long)(tree->gtLngCon.gtLconVal      ));
        else
            inst_RV_IV(ins, reg, (long)(tree->gtLngCon.gtLconVal >> 32));

        break;

    case GT_COMMA:
        tree = tree->gtOp.gtOp2;
        goto AGAIN;

    default:
        assert(!"invalid address");
    }

}

/*****************************************************************************
 *
 *  Generate "imul reg, [tree], icon".
 */

void                Compiler::inst_RV_TT_IV(instruction    ins,
                                            regNumber      reg,
                                            GenTreePtr     tree,
                                            long           val)
{
    static
    BYTE            imulIns[] =
    {
        INS_imul_AX,
        INS_imul_CX,
        INS_imul_DX,
        INS_imul_BX,

        INS_imul_SP,
        INS_imul_BP,
        INS_imul_SI,
        INS_imul_DI,
    };

    /* Only 'imul' uses this instruction format */

    assert(ins == INS_imul);
    assert(tree->gtType <= TYP_INT);

    genUpdateLife(tree);

    /* Make sure we use the appropriate flavor of 'imul' */

    assert(imulIns[REG_EAX] == INS_imul_AX);
    assert(imulIns[REG_ECX] == INS_imul_CX);
    assert(imulIns[REG_EDX] == INS_imul_DX);
    assert(imulIns[REG_EBX] == INS_imul_BX);

//  assert(imulIns[REG_ESP] == INS_imul_SP);
    assert(imulIns[REG_EBP] == INS_imul_BP);
    assert(imulIns[REG_ESI] == INS_imul_SI);
    assert(imulIns[REG_EDI] == INS_imul_DI);

    inst_TT_IV((instruction)imulIns[reg], tree, val);
}

/*****************************************************************************
 *
 *  Generate a "shift reg, icon" instruction.
 */

void        Compiler::inst_RV_SH(instruction ins, regNumber reg, unsigned val)
{
    assert(ins == INS_rcl  ||
           ins == INS_rcr  ||
           ins == INS_shl  ||
           ins == INS_shr  ||
           ins == INS_sar);

    /* Which format should we use? */

    if  (val == 1)
    {
        /* Use the shift-by-one format */

        assert(INS_rcl + 1 == INS_rcl_1);
        assert(INS_rcr + 1 == INS_rcr_1);
        assert(INS_shl + 1 == INS_shl_1);
        assert(INS_shr + 1 == INS_shr_1);
        assert(INS_sar + 1 == INS_sar_1);

        inst_RV((instruction)(ins+1), reg, TYP_INT);
    }
    else
    {
        /* Use the shift-by-NNN format */

        assert(INS_rcl + 2 == INS_rcl_N);
        assert(INS_rcr + 2 == INS_rcr_N);
        assert(INS_shl + 2 == INS_shl_N);
        assert(INS_shr + 2 == INS_shr_N);
        assert(INS_sar + 2 == INS_sar_N);

        genEmitter->emitIns_R_I((instruction)(ins+2),
                                 EA_4BYTE,
                                 (emitRegs)reg,
                                 val);
    }
}

/*****************************************************************************
 *
 *  Generate a "shift [r/m], icon" instruction.
 */

void                Compiler::inst_TT_SH(instruction   ins,
                                         GenTreePtr    tree,
                                         unsigned      val, unsigned offs)
{
    /* Which format should we use? */

    switch (val)
    {
    case 1:

        /* Use the shift-by-one format */

        assert(INS_rcl + 1 == INS_rcl_1);
        assert(INS_rcr + 1 == INS_rcr_1);
        assert(INS_shl + 1 == INS_shl_1);
        assert(INS_shr + 1 == INS_shr_1);
        assert(INS_sar + 1 == INS_sar_1);

        inst_TT((instruction)(ins+1), tree, offs);

        break;

    case 0:

        // Shift by 0 - why are you wasting our precious time????

        return;

    default:

        /* Use the shift-by-NNN format */

        assert(INS_rcl + 2 == INS_rcl_N);
        assert(INS_rcr + 2 == INS_rcr_N);
        assert(INS_shl + 2 == INS_shl_N);
        assert(INS_shr + 2 == INS_shr_N);
        assert(INS_sar + 2 == INS_sar_N);

        inst_TT((instruction)(ins+2), tree, offs, val);

        break;
    }
}

/*****************************************************************************
 *
 *  Generate a "shift [addr], CL" instruction.
 */

void                Compiler::inst_TT_CL(instruction   ins,
                                         GenTreePtr    tree, unsigned offs)
{
    inst_TT(ins, tree, offs);
}

/*****************************************************************************
 *
 *  Generate an instruction of the form "op reg1, reg2, icon".
 */

void                Compiler::inst_RV_RV_IV(instruction    ins,
                                            regNumber      reg1,
                                            regNumber      reg2,
                                            unsigned       ival)
{
    assert(ins == INS_shld || ins == INS_shrd);

    genEmitter->emitIns_R_R_I(ins, (emitRegs)reg1, (emitRegs)reg2, ival);
}

/*****************************************************************************
 *
 *  Generate an instruction with two registers, the second one being a byte
 *  or word register (i.e. this is something like "movzx eax, cl").
 */

void                Compiler::inst_RV_RR(instruction  ins,
                                         emitAttr     size,
                                         regNumber    reg1,
                                         regNumber    reg2)
{
    assert(size == EA_1BYTE || size == EA_2BYTE);
    assert(ins == INS_movsx || ins == INS_movzx);

    genEmitter->emitIns_R_R(ins, size, (emitRegs)reg1, (emitRegs)reg2);
}

/*****************************************************************************
 *
 *  The following should all end up inline in compiler.hpp at some point.
 */

void                Compiler::inst_ST_RV(instruction    ins,
                                         TempDsc    *   tmp,
                                         unsigned       ofs,
                                         regNumber      reg,
                                         var_types      type)
{
    genEmitter->emitIns_S_R(ins,
                            emitActualTypeSize(type),
                            (emitRegs)reg,
                            tmp->tdTempNum(),
                            ofs);
}

void                Compiler::inst_ST_IV(instruction    ins,
                                         TempDsc    *   tmp,
                                         unsigned       ofs,
                                         long           val,
                                         var_types      type)
{
    genEmitter->emitIns_S_I(ins,
                            emitActualTypeSize(type),
                            tmp->tdTempNum(),
                            ofs,
                            val);
}

/*****************************************************************************
 *
 *  Generate an instruction with one register and one operand that is byte
 *  or short (e.g. something like "movzx eax, byte ptr [edx]").
 */

void                Compiler::inst_RV_ST(instruction   ins,
                                         emitAttr      size,
                                         regNumber     reg,
                                         GenTreePtr    tree)
{
    assert(size == EA_1BYTE || size == EA_2BYTE);

    /* "movsx erx, rl" must be handled as a special case */

    if  (tree->gtFlags & GTF_REG_VAL)
        inst_RV_RR(ins, size, reg, tree->gtRegNum);
    else
        inst_RV_TT(ins, reg, tree, 0, size);
}

void                Compiler::inst_RV_ST(instruction    ins,
                                         regNumber      reg,
                                         TempDsc    *   tmp,
                                         unsigned       ofs,
                                         var_types      type,
                                         emitAttr       size)
{
    if (size == EA_UNKNOWN)
        size = emitActualTypeSize(type);

    genEmitter->emitIns_R_S(ins,
                            size,
                            (emitRegs)reg,
                            tmp->tdTempNum(),
                            ofs);
}

void                Compiler::inst_FS_ST(instruction    ins,
                                         emitAttr       size,
                                         TempDsc    *   tmp,
                                         unsigned       ofs)
{
    genEmitter->emitIns_S(ins,
                          size,
                          tmp->tdTempNum(),
                          ofs);
}

/*****************************************************************************/
#endif//TGT_x86
/*****************************************************************************/
#if     TGT_RISC && !TGT_IA64
/*****************************************************************************
 *
 *  Output an "ins reg, [r/m]" (rdst=true) or "ins [r/m], reg" (rdst=false)
 *  instruction (the r/m operand given by a tree).
 */

void                Compiler::sched_AM(instruction  ins,
                                       var_types    type,
                                       regNumber    ireg,
                                       bool         rdst,
                                       GenTreePtr   addr,
                                       unsigned     offs)
{
    int             rev;
    GenTreePtr      rv1;
    GenTreePtr      rv2;
    unsigned        cns;
#if SCALED_ADDR_MODES
    unsigned        mul;
#endif

    emitRegs        reg;
    emitRegs        rg2;
    emitRegs        irg = (emitRegs)ireg;

    emitAttr        size;

    assert(addr);

#if TGT_SH3
    assert(ins == INS_mov);
#endif

    /* Figure out the correct "size" value */

    size = emitTypeSize(type);

    /* Has the address been conveniently loaded into a register? */

    if  (addr->gtFlags & GTF_REG_VAL)
    {
        /* The address is "[reg]" or "[reg+offs]" */

        reg = (emitRegs)addr->gtRegNum;

        if  (offs)
        {
            if  (rdst)
                genEmitter->emitIns_R_RD(irg, reg,  offs, size);
            else
                genEmitter->emitIns_RD_R(reg, irg,  offs, size);
        }
        else
        {
            if  (rdst)
                genEmitter->emitIns_R_IR(irg, reg, false, size);
            else
                genEmitter->emitIns_IR_R(reg, irg, false, size);
        }

        return;
    }

    /* Figure out what complex address mode to use */

    bool yes = genCreateAddrMode(addr,
                                 -1,
                                 true,
                                 0,
#if!LEA_AVAILABLE
                                 type,
#endif
                                 &rev,
                                 &rv1,
                                 &rv2,
#if SCALED_ADDR_MODES
                                 &mul,
#endif
                                 &cns);

    assert(yes);

    /* Add the constant offset value, if present */

    offs += cns;

    /* Is there an additional operand? */

    if  (rv2)
    {
        /* The additional operand must be sitting in a register */

        assert(rv2->gtFlags & GTF_REG_VAL);
        rg2 = (emitRegs)rv2->gtRegNum;

        /* Is the additional operand scaled? */

#if SCALED_ADDR_MODES
        if  (mul)
        {
            /* Is there a base address operand? */

            if  (rv1)
            {
                assert(rv1->gtFlags & GTF_REG_VAL);
                reg = (emitRegs)rv1->gtRegNum;

                /* The address is "[reg1 + {2/4/8} * reg2 + offs]" */

                if  (offs)
                    assert(!"indirection [rg1+mul*rg2+disp]");
                else
                    assert(!"indirection [rg1+mul*rg2]");
            }
            else
            {
                /* The address is "[{2/4/8} * reg2 + offs]" */

                if  (offs)
                    assert(!"indirection [mul*rg2+disp]");
                else
                    assert(!"indirection [mul*rg2]");
            }
        }
        else
#endif
        {
            assert(rv1 && (rv1->gtFlags & GTF_REG_VAL));
            reg = (emitRegs)rv1->gtRegNum;

#if TGT_SH3
            assert(offs == 0);

            /* One of the operands must be in r0 */

            if  (reg == REG_r00)
                reg = rg2;
            else
                assert(rg2 == REG_r00);

            if  (rdst)
                genEmitter->emitIns_R_XR0(irg, reg, size);
            else
                genEmitter->emitIns_XR0_R(reg, irg, size);

#else
#error  Unexpected target
#endif

        }
    }
    else
    {
        /* No second operand: the address is "[reg  + icon]" */

        assert(rv1 && (rv1->gtFlags & GTF_REG_VAL));
        reg = (emitRegs)rv1->gtRegNum;

        // UNDONE: Pass handle for instance member name display

        if  (offs)
        {
            if  (rdst)
                genEmitter->emitIns_R_RD(irg, reg,  offs, size);
            else
                genEmitter->emitIns_RD_R(reg, irg,  offs, size);
        }
        else
        {
            if  (rdst)
                genEmitter->emitIns_R_IR(irg, reg, false, size);
            else
                genEmitter->emitIns_IR_R(reg, irg, false, size);
        }
    }
}

/*****************************************************************************
 *
 *  Generate an instruction that has one operand given by a tree (which has
 *  been made addressable) and another that is a register; the tree is the
 *  target of the operation, the register is the source.
 */

void                Compiler::inst_TT_RV(instruction   ins,
                                         GenTreePtr    tree,
                                         regNumber     reg, unsigned offs)
{
    emitAttr        size;

    assert(reg != REG_STK);

    /* Get hold of the correct size value (for GC refs, etc) */

    size = emitTypeSize(tree->TypeGet());

    /* Is the value sitting in a register? */

    if  (tree->gtFlags & GTF_REG_VAL)
    {
        regNumber       rg2;

    LONGREG_TT:

        rg2 = tree->gtRegNum;

        if  (tree->gtType == TYP_LONG)
        {
            if  (offs)
            {
                assert(offs == sizeof(int));

                rg2 = genRegPairHi((regPairNo)rg2);
            }
            else
                rg2 = genRegPairLo((regPairNo)rg2);
        }

        /* Make sure it is not the "stack-half" of an enregistered long/double */

        if  (rg2 != REG_STK)
        {
            genEmitter->emitIns_R_R(ins, EA_4BYTE, (emitRegs)rg2,
                                                   (emitRegs)reg);
            return;
        }
    }

    switch (tree->gtOper)
    {
        unsigned        varNum;
        LclVarDsc   *   varDsc;
        unsigned        varOfs;

        regNumber       rga;

    case GT_LCL_VAR:

        assert(genTypeSize(tree->gtType) >= sizeof(int));

        /* Is this an enregistered long ? */

        if  (tree->gtType == TYP_LONG && !(tree->gtFlags & GTF_REG_VAL))
        {
            /* Avoid infinite loop */

            if  (genMarkLclVar(tree))
                goto LONGREG_TT;
        }

        /* Figure out the variable's frame offset */

        varNum = tree->gtLclVar.gtLclNum; assert(varNum < lvaCount);
        varDsc = lvaTable + varNum;
        varOfs = varDsc->lvStkOffs + offs;

        assert(MAX_FPBASE_OFFS == MAX_SPBASE_OFFS);

        if  (varOfs > MAX_SPBASE_OFFS)
        {
            assert(!"local variable too far, need access code");
        }
        else
        {
            assert(ins == INS_mov);

            genEmitter->emitIns_S_R(INS_mov_dsp,
                                    size,
                                    (emitRegs)reg,
                                    varNum,
                                    offs);
        }
        return;

    case GT_IND:
        sched_AM(ins, tree->TypeGet(), reg, false, tree->gtOp.gtOp1, offs);
        break;

    case GT_CLS_VAR:

        assert(ins == INS_mov);
        assert(eeGetJitDataOffs(tree->gtClsVar.gtClsVarHnd) < 0);

        /* Get a temp register for the variable address */

        // CONSIDER: This should be moved to codegen.cpp, right?

        rga = rsGrabReg(RBM_ALL);

        /* UNDONE: Reuse addresses of globals via load suppression */

        genEmitter->emitIns_R_LP_V((emitRegs)rga,
                                   tree->gtClsVar.gtClsVarHnd);

        /* Store the value by indirecting via the address register */

        genEmitter->emitIns_IR_R((emitRegs)reg,
                                 (emitRegs)rga,
                                 false,
                                 emitTypeSize(tree->TypeGet()));
        return;

    default:

#ifdef  DEBUG
        gtDispTree(tree);
#endif
        assert(!"unexpected tree in inst_TT_RV()");
    }
}

/*****************************************************************************
 *
 *  Generate an instruction that has one operand given by a register and the
 *  other one by a tree (which has been made addressable); the tree is the
 *  source of the operation, the register is the target.
 */

void                Compiler::inst_RV_TT(instruction   ins,
                                         regNumber     reg,
                                         GenTreePtr    tree, unsigned offs,
                                                             emitAttr size)
{
    assert(reg != REG_STK);

    /* Set "size" to EA_GCREF or EA_BYREF if the operand is a pointer */

    if (size == EA_UNKNOWN)
        size = emitTypeSize(tree->TypeGet());

    assert(size != EA_8BYTE);

    /* Is the value sitting in a register? */

    if  (tree->gtFlags & GTF_REG_VAL)
    {
        regNumber       rg2;

    LONGREG_TT:

        rg2 = tree->gtRegNum;

        if  (tree->gtType == TYP_LONG)
        {
            if  (offs)
            {
                assert(offs == sizeof(int));

                rg2 = genRegPairHi((regPairNo)rg2);
            }
            else
                rg2 = genRegPairLo((regPairNo)rg2);
        }

        /* Make sure it is not the "stack-half" of an enregistered long/double */

        if  (rg2 != REG_STK)
        {
            genEmitter->emitIns_R_R(ins, EA_4BYTE, (emitRegs)reg,
                                                   (emitRegs)rg2);
            return;
        }
    }

    switch (tree->gtOper)
    {
        unsigned        varNum;
        LclVarDsc   *   varDsc;
        unsigned        varOfs;

    case GT_LCL_VAR:

        assert(genTypeSize(tree->gtType) >= sizeof(int));

        /* Is this an enregistered long ? */

        if  (tree->gtType == TYP_LONG && !(tree->gtFlags & GTF_REG_VAL))
        {
            /* Avoid infinite loop */

            if  (genMarkLclVar(tree))
                goto LONGREG_TT;
        }

        /* Figure out the variable's frame offset */

        varNum = tree->gtLclVar.gtLclNum; assert(varNum < lvaCount);
        varDsc = lvaTable + varNum;
        varOfs = varDsc->lvStkOffs + offs;

        assert(MAX_FPBASE_OFFS == MAX_SPBASE_OFFS);

        if  (varOfs > MAX_SPBASE_OFFS)
        {
            assert(!"local variable too far, need access code");
        }
        else
        {
            assert(ins == INS_mov);

            genEmitter->emitIns_R_S(INS_mov_dsp,
                                    size,
                                    (emitRegs)reg,
                                    varNum,
                                    offs);
        }
        return;

    case GT_IND:
        sched_AM(ins, tree->TypeGet(), reg,  true, tree->gtOp.gtOp1, offs);
        break;

    case GT_CLS_VAR:

        // CONSIDER: Sometimes it's better to use another reg for the addr!

        assert(ins == INS_mov);

        /* Load the variable address into the register */

        genEmitter->emitIns_R_LP_V((emitRegs)reg,
                                    tree->gtClsVar.gtClsVarHnd);

        // HACK: We know we always want the address of a data area

        if  (eeGetJitDataOffs(tree->gtClsVar.gtClsVarHnd) < 0)
        {
            /* Load the value by indirecting via the address */

            genEmitter->emitIns_R_IR((emitRegs)reg,
                                     (emitRegs)reg,
                                     false,
                                     emitTypeSize(tree->TypeGet()));
        }

        return;

    default:

#ifdef  DEBUG
        gtDispTree(tree);
#endif
        assert(!"unexpected tree in inst_RV_TT()");
    }
}

/*****************************************************************************/
#endif//TGT_RISC
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\instr.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef _INSTR_H_
#define _INSTR_H_
/*****************************************************************************/

#define BAD_CODE    0xFFFFFF        // better not match a real encoding!

/*****************************************************************************/

#if     !TGT_IA64

enum instruction
{

#if     TGT_x86

    #define INST0(id, nm, fp, um, rf, wf, ss, mr                ) INS_##id,
    #define INST1(id, nm, fp, um, rf, wf, ss, mr                ) INS_##id,
    #define INST2(id, nm, fp, um, rf, wf, ss, mr, mi            ) INS_##id,
    #define INST3(id, nm, fp, um, rf, wf, ss, mr, mi, rm        ) INS_##id,
    #define INST4(id, nm, fp, um, rf, wf, ss, mr, mi, rm, a4    ) INS_##id,
    #define INST5(id, nm, fp, um, rf, wf, ss, mr, mi, rm, a4, rr) INS_##id,
    #include "instrs.h"
    #undef  INST0
    #undef  INST1
    #undef  INST2
    #undef  INST3
    #undef  INST4
    #undef  INST5

#elif   TGT_SH3

    #define INST1(id, nm, bd, um, rf, wf, rx, wx, br, i1        ) INS_##id,
    #define INST2(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2    ) INS_##id,
    #define INST3(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2, i3) INS_##id,
    #include "instrSH3.h"
    #undef  INST1
    #undef  INST2
    #undef  INST3

#elif   TGT_MIPS32

    #define INST1(id, nm, bd, um, rf, wf, rx, wx, br, i1        ) INS_##id,
    #include "instrMIPS.h"
    #undef  INST1
    #undef  INST2
    #undef  INST3

#elif   TGT_ARM

    #define INST1(id, nm, bd, um, rf, wf, rx, wx, br, i1        ) INS_##id,
    #define INST2(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2    ) INS_##id,
    #define INST3(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2, i3) INS_##id,
    #include "instrARM.h"
    #undef  INST1
    #undef  INST2
    #undef  INST3

#elif   TGT_PPC

    #define INST1(id, nm, bd, um, rf, wf, rx, wx, br, i1        ) INS_##id,
    #include "instrPPC.h"
    #undef  INST1
    #undef  INST2
    #undef  INST3

#elif   TGT_IA64

//  #define INST1(id, sn, ik    , rf, wf, xu, ic                ) INS_##id,
//  #include "instrIA64.h"
//  #undef  INST1

#else

    #error  Unknown target

#endif

    INS_none,
    INS_count = INS_none
};

#endif

/*****************************************************************************/

enum insUpdateModes
{
    IUM_RD,
    IUM_WR,
    IUM_RW,
};

/*****************************************************************************/
#if     !TGT_IA64
/*****************************************************************************/

enum emitJumpKind
{
    EJ_NONE,

    #define JMP_SMALL(en, nm, op) EJ_##en,
    #define JMP_LARGE(en, nm, op)
    #include "emitjmps.h"
    #undef  JMP_SMALL
    #undef  JMP_LARGE

    EJ_call,
};

#if TGT_MIPSFP
enum opformat
{
    OPF_S = 16, OPF_D, OPF_W = 20
};
#endif

/*****************************************************************************/
#endif//!TGT_IA64
/*****************************************************************************/
#endif//_INSTR_H_
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\instrs.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************
 *  x86 instructions for [Opt]JIT compiler
 *
 *          id      -- the enum name for the instruction
 *          nm      -- textual name (for assembly dipslay)
 *          fp      -- floating point instruction
 *          um      -- update mode, see IUM_xx enum (rd, wr, or rw)
 *          rf      -- reads flags
 *          wf      -- writes flags
 *          ss      -- needs special scheduler handling (has implicit operands, etc.)
 *          mr      -- base encoding for R/M[reg] addressing mode
 *          mi      -- base encoding for R/M,icon addressing mode
 *          rm      -- base encoding for reg,R/M  addressing mode
 *          a4      -- base encoding for eax,i32  addressing mode
 *          rr      -- base encoding for register addressing mode
 *
******************************************************************************/
#ifndef INST1
#error  At least INST1 must be defined before including this file.
#endif
/*****************************************************************************/
#ifndef INST0
#define INST0(id, nm, fp, um, rf, wf, ss, mr                )
#endif
#ifndef INST2
#define INST2(id, nm, fp, um, rf, wf, ss, mr, mi            )
#endif
#ifndef INST3
#define INST3(id, nm, fp, um, rf, wf, ss, mr, mi, rm        )
#endif
#ifndef INST4
#define INST4(id, nm, fp, um, rf, wf, ss, mr, mi, rm, a4    )
#endif
#ifndef INST5
#define INST5(id, nm, fp, um, rf, wf, ss, mr, mi, rm, a4, rr)
#endif
/*****************************************************************************/
/*               The following is somewhat x86-specific                      */
/*****************************************************************************/

//    enum     name            FP  updmode rf wf ss R/M[reg]  R/M,icon  reg,R/M   eax,i32   register

INST5(push   , "push"         , 0, IUM_RD, 0, 0, 1, 0x0030FE, 0x000068, BAD_CODE, BAD_CODE, 0x000050)
INST5(pop    , "pop"          , 0, IUM_WR, 0, 0, 1, 0x00008E, BAD_CODE, BAD_CODE, BAD_CODE, 0x000058)

INST5(inc    , "inc"          , 0, IUM_RW, 0, 1, 0, 0x0000FE, BAD_CODE, BAD_CODE, BAD_CODE, 0x000040)
INST5(inc_l  , "inc"          , 0, IUM_RW, 0, 1, 0, 0x0000FE, BAD_CODE, BAD_CODE, BAD_CODE, 0x00C0FE)
INST5(dec    , "dec"          , 0, IUM_RW, 0, 1, 0, 0x0008FE, BAD_CODE, BAD_CODE, BAD_CODE, 0x000048)
INST5(dec_l  , "dec"          , 0, IUM_RW, 0, 1, 0, 0x0008FE, BAD_CODE, BAD_CODE, BAD_CODE, 0x00C8FE)

    // Note that version of push does not affect the stack tracking in the emitter
INST5(push_hide, "push_hide",   0, IUM_RD, 0, 0, 1, 0x0030FE, 0x000068, BAD_CODE, BAD_CODE, 0x000050)

//    enum     name            FP  updmode rf wf ss R/M,R/M[reg] R/M,icon  reg,R/M   eax,i32

INST4(add    , "add"          , 0, IUM_RW, 0, 1, 1, 0x000000, 0x000080, 0x000002, 0x000004)
INST4(or     , "or"           , 0, IUM_RW, 0, 1, 0, 0x000008, 0x000880, 0x00000A, 0x00000C)
INST4(adc    , "adc"          , 0, IUM_RW, 1, 1, 0, 0x000010, 0x001080, 0x000012, 0x000014)
INST4(sbb    , "sbb"          , 0, IUM_RW, 1, 1, 0, 0x000018, 0x001880, 0x00001A, 0x00001C)
INST4(and    , "and"          , 0, IUM_RW, 0, 1, 0, 0x000020, 0x002080, 0x000022, 0x000024)
INST4(sub    , "sub"          , 0, IUM_RW, 0, 1, 1, 0x000028, 0x002880, 0x00002A, 0x00002C)
INST4(xor    , "xor"          , 0, IUM_RW, 0, 1, 1, 0x000030, 0x003080, 0x000032, 0x000034)
INST4(cmp    , "cmp"          , 0, IUM_RD, 0, 1, 0, 0x000038, 0x003880, 0x00003A, 0x00003C)
INST4(test   , "test"         , 0, IUM_RD, 0, 1, 0, 0x000084, 0x0000F6, 0x000084, 0x0000A8)
INST4(mov    , "mov"          , 0, IUM_WR, 0, 0, 0, 0x000088, 0x0000C6, 0x00008A, 0x0000B0)

INST4(lea    , "lea"          , 0, IUM_WR, 0, 0, 0, BAD_CODE, BAD_CODE, 0x00008D, BAD_CODE)

//    enum     name            FP  updmode rf wf ss R/M,R/M[reg]  R/M,icon  reg,R/M

INST3(movsx  , "movsx"        , 0, IUM_WR, 0, 0, 0, BAD_CODE, BAD_CODE, 0x0F00BE)
INST3(movzx  , "movzx"        , 0, IUM_WR, 0, 0, 0, BAD_CODE, BAD_CODE, 0x0F00B6)

INST3(xchg   , "xchg"         , 0, IUM_RW, 0, 0, 0, 0x000084, BAD_CODE, 0x000084)
INST3(imul   , "imul"         , 0, IUM_RW, 0, 1, 0, 0x0F00AC, 0x000069, 0x0F00AF)

//    enum     name            FP  updmode rf wf ss R/M,R/M[reg]  R/M,icon

INST2(ret    , "ret"          , 0, IUM_RD, 0, 0, 0, 0x0000C3, 0x0000C2)
INST2(loop   , "loop"         , 0, IUM_RD, 0, 0, 0, BAD_CODE, 0x0000E2)
INST2(call   , "call"         , 0, IUM_RD, 0, 1, 0, 0x0010FF, 0x0000E8)

INST2(rcl    , "rcl"          , 0, IUM_RW, 1, 1, 1, 0x0010D2, BAD_CODE)
INST2(rcl_1  , "rcl"          , 0, IUM_RW, 1, 1, 0, 0x0010D0, 0x0010D0)
INST2(rcl_N  , "rcl"          , 0, IUM_RW, 1, 1, 0, 0x0010C0, 0x0010C0)
INST2(rcr    , "rcr"          , 0, IUM_RW, 1, 1, 1, 0x0018D2, BAD_CODE)
INST2(rcr_1  , "rcr"          , 0, IUM_RW, 1, 1, 0, 0x0018D0, 0x0018D0)
INST2(rcr_N  , "rcr"          , 0, IUM_RW, 1, 1, 0, 0x0018C0, 0x0018C0)
INST2(shl    , "shl"          , 0, IUM_RW, 0, 1, 1, 0x0020D2, BAD_CODE)
INST2(shl_1  , "shl"          , 0, IUM_RW, 0, 1, 0, 0x0020D0, 0x0020D0)
INST2(shl_N  , "shl"          , 0, IUM_RW, 0, 1, 0, 0x0020C0, 0x0020C0)
INST2(shr    , "shr"          , 0, IUM_RW, 0, 1, 1, 0x0028D2, BAD_CODE)
INST2(shr_1  , "shr"          , 0, IUM_RW, 0, 1, 0, 0x0028D0, 0x0028D0)
INST2(shr_N  , "shr"          , 0, IUM_RW, 0, 1, 0, 0x0028C0, 0x0028C0)
INST2(sar    , "sar"          , 0, IUM_RW, 0, 1, 1, 0x0038D2, BAD_CODE)
INST2(sar_1  , "sar"          , 0, IUM_RW, 0, 1, 0, 0x0038D0, 0x0038D0)
INST2(sar_N  , "sar"          , 0, IUM_RW, 0, 1, 0, 0x0038C0, 0x0038C0)

INST2(imul_AX, "imul    EAX, ", 0, IUM_RD, 0, 1, 1, BAD_CODE, 0x000068)
INST2(imul_CX, "imul    ECX, ", 0, IUM_RD, 0, 1, 1, BAD_CODE, 0x000868)
INST2(imul_DX, "imul    EDX, ", 0, IUM_RD, 0, 1, 1, BAD_CODE, 0x001068)
INST2(imul_BX, "imul    EBX, ", 0, IUM_RD, 0, 1, 1, BAD_CODE, 0x001868)

INST2(imul_SP, "imul    ESP, ", 0, IUM_RD, 0, 1, 1, BAD_CODE, BAD_CODE)
INST2(imul_BP, "imul    EBP, ", 0, IUM_RD, 0, 1, 1, BAD_CODE, 0x002868)
INST2(imul_SI, "imul    ESI, ", 0, IUM_RD, 0, 1, 1, BAD_CODE, 0x003068)
INST2(imul_DI, "imul    EDI, ", 0, IUM_RD, 0, 1, 1, BAD_CODE, 0x003868)

#ifndef instrIsImulReg
#define instrIsImulReg(ins) ((ins) >= INS_imul_AX && (ins) <= INS_imul_DI)
#endif

//    enum     name            FP  updmode rf wf ss R/M,R/M[reg]

INST1(r_movsb, "rep     movsb", 0, IUM_RD, 0, 0, 1, 0x00A4F3)
INST1(r_movsd, "rep     movsd", 0, IUM_RD, 0, 0, 1, 0x00A5F3)
INST1(movsb  , "movsb"        , 0, IUM_RD, 0, 0, 1, 0x0000A4)
INST1(movsd  , "movsd"        , 0, IUM_RD, 0, 0, 1, 0x0000A5)

INST1(r_stosb, "rep     stosb", 0, IUM_RD, 0, 0, 1, 0x00AAF3)
INST1(r_stosd, "rep     stosd", 0, IUM_RD, 0, 0, 1, 0x00ABF3)
INST1(stosb,   "stosb"        , 0, IUM_RD, 0, 0, 1, 0x0000AA)
INST1(stosd,   "stosd"        , 0, IUM_RD, 0, 0, 1, 0x0000AB)

INST1(int3   , "int3"         , 0, IUM_RD, 0, 0, 0, 0x0000CC)
INST1(nop    , "nop"          , 0, IUM_RD, 0, 0, 0, 0x000090)
INST1(leave  , "leave"        , 0, IUM_RD, 0, 0, 0, 0x0000C9)


INST1(neg    , "neg"          , 0, IUM_RW, 0, 1, 0, 0x0018F6)
INST1(not    , "not"          , 0, IUM_RW, 0, 1, 0, 0x0010F6)

INST1(cdq    , "cdq"          , 0, IUM_RD, 0, 1, 1, 0x000099)
INST1(idiv   , "idiv"         , 0, IUM_RD, 0, 1, 1, 0x0038F6)
INST1(imulEAX, "imul"         , 0, IUM_RD, 0, 1, 1, 0x0028F6)
INST1(div    , "div"          , 0, IUM_RD, 0, 1, 1, 0x0030F6)
INST1(mulEAX , "mul"          , 0, IUM_RD, 0, 1, 1, 0x0020F6)

INST1(sahf   , "sahf"         , 0, IUM_RD, 0, 1, 1, 0x00009E)

INST1(xadd   , "xadd"         , 0, IUM_RW, 0, 1, 0, 0x0F00C0)

INST1(shld   , "shld"         , 0, IUM_RW, 0, 1, 0, 0x0F00A4)
INST1(shrd   , "shrd"         , 0, IUM_RW, 0, 1, 0, 0x0F00AC)

INST1(fnstsw , "fnstsw"       , 1, IUM_WR, 1, 0, 0, 0x0020DF)
INST1(fcom   , "fcom"         , 1, IUM_RD, 0, 1, 0, 0x00D0D8)
INST1(fcomp  , "fcomp"        , 1, IUM_RD, 0, 1, 0, 0x0018D8)
INST1(fcompp , "fcompp"       , 1, IUM_RD, 0, 1, 0, 0x00D9DE)

INST1(fchs   , "fchs"         , 1, IUM_RW, 0, 1, 0, 0x00E0D9)
#if INLINE_MATH
INST1(fabs   , "fabs"         , 1, IUM_RW, 0, 1, 0, 0x00E1D9)
INST1(fsin   , "fsin"         , 1, IUM_RW, 0, 1, 0, 0x00FED9)
INST1(fcos   , "fcos"         , 1, IUM_RW, 0, 1, 0, 0x00FFD9)
INST1(fsqrt  , "fsqrt"        , 1, IUM_RW, 0, 1, 0, 0x00FAD9)
INST1(fldl2e , "fldl2e"       , 1, IUM_RW, 0, 1, 0, 0x00EAD9)
INST1(frndint, "frndint"      , 1, IUM_RW, 0, 1, 0, 0x00FCD9)
INST1(f2xm1  , "f2xm1"        , 1, IUM_RW, 0, 1, 0, 0x00F0D9)
INST1(fscale , "fscale"       , 1, IUM_RW, 0, 1, 0, 0x00FDD9)
#endif

INST1(fld    , "fld"          , 1, IUM_WR, 0, 0, 0, 0x0000D9)
INST1(fld1   , "fld1"         , 1, IUM_WR, 0, 0, 0, 0x00E8D9)
INST1(fldz   , "fldz"         , 1, IUM_WR, 0, 0, 0, 0x00EED9)
INST1(fstp   , "fstp"         , 1, IUM_WR, 0, 0, 1, 0x0018D9)
INST1(fst    , "fst"          , 1, IUM_WR, 0, 0, 0, 0x0010D9)

INST1(fadd   , "fadd"         , 1, IUM_RW, 0, 0, 0, 0x0000D8)
INST1(faddp  , "faddp"        , 1, IUM_RW, 0, 0, 0, 0x0000DA)
INST1(fsub   , "fsub"         , 1, IUM_RW, 0, 0, 0, 0x0020D8)
INST1(fsubp  , "fsubp"        , 1, IUM_RW, 0, 0, 0, 0x0028DA)
INST1(fsubr  , "fsubr"        , 1, IUM_RW, 0, 0, 0, 0x0028D8)
INST1(fsubrp , "fsubrp"       , 1, IUM_RW, 0, 0, 0, 0x0020DA)
INST1(fmul   , "fmul"         , 1, IUM_RW, 0, 0, 0, 0x0008D8)
INST1(fmulp  , "fmulp"        , 1, IUM_RW, 0, 0, 0, 0x0008DA)
INST1(fdiv   , "fdiv"         , 1, IUM_RW, 0, 0, 0, 0x0030D8)
INST1(fdivp  , "fdivp"        , 1, IUM_RW, 0, 0, 0, 0x0038DA)
INST1(fdivr  , "fdivr"        , 1, IUM_RW, 0, 0, 0, 0x0038D8)
INST1(fdivrp , "fdivrp"       , 1, IUM_RW, 0, 0, 0, 0x0030DA)

INST1(fxch   , "fxch"         , 1, IUM_RW, 0, 0, 0, 0x00C8D9)
INST1(fprem  , "fprem"        , 0, IUM_RW, 0, 1, 0, 0x00F8D9)

INST1(fild   , "fild"         , 1, IUM_RD, 0, 0, 0, 0x0000DB)
INST1(fildl  , "fild"         , 1, IUM_RD, 0, 0, 0, 0x0028DB)
INST1(fistp  , "fistp"        , 1, IUM_WR, 0, 0, 0, 0x0018DB)
INST1(fistpl , "fistp"        , 1, IUM_WR, 0, 0, 0, 0x0038DB)

INST1(fldcw  , "fldcw"        , 1, IUM_RD, 0, 0, 0, 0x0028D9)
INST1(fnstcw , "fnstcw"       , 1, IUM_WR, 0, 0, 0, 0x0038D9)

INST1(seto   , "seto"         , 0, IUM_WR, 1, 0, 0, 0x0F0090)
INST1(setno  , "setno"        , 0, IUM_WR, 1, 0, 0, 0x0F0091)
INST1(setb   , "setb"         , 0, IUM_WR, 1, 0, 0, 0x0F0092)
INST1(setae  , "setae"        , 0, IUM_WR, 1, 0, 0, 0x0F0093)
INST1(sete   , "sete"         , 0, IUM_WR, 1, 0, 0, 0x0F0094)
INST1(setne  , "setne"        , 0, IUM_WR, 1, 0, 0, 0x0F0095)
INST1(setbe  , "setbe"        , 0, IUM_WR, 1, 0, 0, 0x0F0096)
INST1(seta   , "seta"         , 0, IUM_WR, 1, 0, 0, 0x0F0097)
INST1(sets   , "sets"         , 0, IUM_WR, 1, 0, 0, 0x0F0098)
INST1(setns  , "setns"        , 0, IUM_WR, 1, 0, 0, 0x0F0099)
INST1(setpe  , "setpe"        , 0, IUM_WR, 1, 0, 0, 0x0F009A)
INST1(setpo  , "setpo"        , 0, IUM_WR, 1, 0, 0, 0x0F009B)
INST1(setl   , "setl"         , 0, IUM_WR, 1, 0, 0, 0x0F009C)
INST1(setge  , "setge"        , 0, IUM_WR, 1, 0, 0, 0x0F009D)
INST1(setle  , "setle"        , 0, IUM_WR, 1, 0, 0, 0x0F009E)
INST1(setg   , "setg"         , 0, IUM_WR, 1, 0, 0, 0x0F009F)

INST1(i_jmp  , "jmp"          , 0, IUM_RD, 0, 0, 0, 0x0020FE)

INST0(jmp    , "jmp"          , 0, IUM_RD, 0, 0, 0, 0x0000EB)
INST0(jo     , "jo"           , 0, IUM_RD, 1, 0, 0, 0x000070)
INST0(jno    , "jno"          , 0, IUM_RD, 1, 0, 0, 0x000071)
INST0(jb     , "jb"           , 0, IUM_RD, 1, 0, 0, 0x000072)
INST0(jae    , "jae"          , 0, IUM_RD, 1, 0, 1, 0x000073)
INST0(je     , "je"           , 0, IUM_RD, 1, 0, 0, 0x000074)
INST0(jne    , "jne"          , 0, IUM_RD, 1, 0, 0, 0x000075)
INST0(jbe    , "jbe"          , 0, IUM_RD, 1, 0, 1, 0x000076)
INST0(ja     , "ja"           , 0, IUM_RD, 1, 0, 0, 0x000077)
INST0(js     , "js"           , 0, IUM_RD, 1, 0, 0, 0x000078)
INST0(jns    , "jns"          , 0, IUM_RD, 1, 0, 0, 0x000079)
INST0(jpe    , "jpe"          , 0, IUM_RD, 1, 0, 0, 0x00007A)
INST0(jpo    , "jpo"          , 0, IUM_RD, 1, 0, 0, 0x00007B)
INST0(jl     , "jl"           , 0, IUM_RD, 1, 0, 0, 0x00007C)
INST0(jge    , "jge"          , 0, IUM_RD, 1, 0, 0, 0x00007D)
INST0(jle    , "jle"          , 0, IUM_RD, 1, 0, 0, 0x00007E)
INST0(jg     , "jg"           , 0, IUM_RD, 1, 0, 0, 0x00007F)

INST0(l_jmp  , "jmp"          , 0, IUM_RD, 0, 0, 0, 0x0000E9)
INST0(l_jo   , "jo"           , 0, IUM_RD, 1, 0, 0, 0x00800F)
INST0(l_jno  , "jno"          , 0, IUM_RD, 1, 0, 0, 0x00810F)
INST0(l_jb   , "jb"           , 0, IUM_RD, 1, 0, 0, 0x00820F)
INST0(l_jae  , "jae"          , 0, IUM_RD, 1, 0, 0, 0x00830F)
INST0(l_je   , "je"           , 0, IUM_RD, 1, 0, 0, 0x00840F)
INST0(l_jne  , "jne"          , 0, IUM_RD, 1, 0, 0, 0x00850F)
INST0(l_jbe  , "jbe"          , 0, IUM_RD, 1, 0, 0, 0x00860F)
INST0(l_ja   , "ja"           , 0, IUM_RD, 1, 0, 0, 0x00870F)
INST0(l_js   , "js"           , 0, IUM_RD, 1, 0, 0, 0x00880F)
INST0(l_jns  , "jns"          , 0, IUM_RD, 1, 0, 0, 0x00890F)
INST0(l_jpe  , "jpe"          , 0, IUM_RD, 1, 0, 0, 0x008A0F)
INST0(l_jpo  , "jpo"          , 0, IUM_RD, 1, 0, 0, 0x008B0F)
INST0(l_jl   , "jl"           , 0, IUM_RD, 1, 0, 0, 0x008C0F)
INST0(l_jge  , "jge"          , 0, IUM_RD, 1, 0, 0, 0x008D0F)
INST0(l_jle  , "jle"          , 0, IUM_RD, 1, 0, 0, 0x008E0F)
INST0(l_jg   , "jg"           , 0, IUM_RD, 1, 0, 0, 0x008F0F)

#ifdef  DEBUG
INST0(db     , "db"           , 0, IUM_RD, 0, 1, 0, BAD_CODE)
#endif

#if SCHEDULER
INST0(noSched, "noSched"      , 0, IUM_RD, 0, 1, 0, BAD_CODE)
#endif

/*****************************************************************************/
#undef  INST0
#undef  INST1
#undef  INST2
#undef  INST3
#undef  INST4
#undef  INST5
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\instria64.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
//    INS_name
//                  , string name
//                                    , kind
//                                            , reads flags
//                                              , writes flags
//                                                 , exec unit (A/M/I/B/L/X/F or N)
//                                                    , function unit (FU_xxx)
//                                                             , opcode encoding index
//                                                                , opcode encoding value (optional)
//
// Note: this file is included in the following places:
//
//      cgIA64.cpp      to initialize ins2kindTab[]
//                      to initialize genInsXUs[]
//                      to initialize genInsEncs[]
//                      to initialize ins2nameTab[]
//
//     loginstr.h       to create enum instruction

#ifndef INST2
#define INST2(id, sn, ik, rf, wf, xu, fu, ex, ev) INST1(id, sn, ik, rf, wf, xu, fu, ex, ev)
#endif

INST1(ignore        , "<IGNORE>"      ,NONE   ,0, 0, N, NONE   , 0,     0)

INST1(nop_m         , "nop.m"         ,NONE   ,0, 0, M, NOP    ,37,     0)
INST1(nop_i         , "nop.i"         ,NONE   ,0, 0, I, NOP    ,19,     0)
INST1(nop_b         , "nop.b"         ,NONE   ,0, 0, B, NOP    , 9,     0)
INST1(nop_f         , "nop.f"         ,NONE   ,0, 0, F, NOP    ,15,     0)
/////(nop_x         , "nop.x"         ,NONE   ,0, 0, X, NOP    , 1,     0)

INST1(br            , "br"            ,JUMP   ,0, 0, B, BR     , 1,     0)
INST1(br_cond       , "br.cond"       ,JUMP   ,1, 0, B, BR     , 1,     0)
INST1(br_cloop      , "br.cloop"      ,JUMP   ,0, 0, B, BR     , 2,     0)
INST1(br_ret        , "br.ret"        ,NONE   ,0, 0, B, BR     , 4,     0)
INST1(br_call_IP    , "br.call"       ,CALL   ,0, 0, B, BR     , 3,     0)
INST1(br_call_BR    , "br.call"       ,CALL   ,0, 0, B, BR     , 5,     0)
INST1(br_cond_BR    , "br.cond"       ,IJMP   ,0, 0, B, BR     , 4,     0)

//
// Integer compares: 8-byte and 4-byte, reg/reg and reg/imm, signed and unsigned
//
//
// The encoding value is determined as follows (individual bits listed):
//
//      (high)   0DCR | 00XS | OOOO | BBBB   (low)
//
//  Where:
//
//      BBBB    0x000F    opcode bits: [1:tb] [2:x2] [1:ta]
//
//          (note: the low bit of x2 encodes size: 0 => 8-byte, 1 => 4-byte)
//
//      OOOO    0x00F0    opcode value (0xC/0xD/0xE)
//
//      X       0x0200    extension bit (i.e. the "c" bit in position 12)
//
//      R       0x1000    1 => pseudo-opcode whose operands must be swapped
//      C       0x2000    1 => pseudo-opcode whose targets  must be swapped
//      D       0x4000    1 => pseudo-opcode whose imm. op. must be decremented

INST1(cmp8_reg_eq   , "cmp.eq"        ,COMP   ,0, 1, A, ICMP   , 6,0x00E0)
INST1(cmp8_reg_ne   , "cmp.ne"        ,COMP   ,0, 1, A, ICMP   , 6,0x20E0)  // -> cmp.eq

INST1(cmp8_reg_lt   , "cmp.lt"        ,COMP   ,0, 1, A, ICMP   , 6,0x00C0)
INST1(cmp8_reg_le   , "cmp.le"        ,COMP   ,0, 1, A, ICMP   , 6,0x30C0)  // -> cmp.ltu
INST1(cmp8_reg_ge   , "cmp.ge"        ,COMP   ,0, 1, A, ICMP   , 6,0x20C0)  // -> cmp.ltu
INST1(cmp8_reg_gt   , "cmp.gt"        ,COMP   ,0, 1, A, ICMP   , 6,0x10C0)  // -> cmp.ltu

INST1(cmp8_imm_eq   , "cmp.eq"        ,COMP   ,0, 1, A, ICMP   , 8,0x00E4)
INST1(cmp8_imm_ne   , "cmp.ne"        ,COMP   ,0, 1, A, ICMP   , 8,0x20E4)  // -> cmp.ne

INST1(cmp8_imm_lt   , "cmp.lt"        ,COMP   ,0, 1, A, ICMP   , 8,0x00C4)
INST1(cmp8_imm_le   , "cmp.le"        ,COMP   ,0, 1, A, ICMP   , 8,0x40C4)  // -> cmp.lt
INST1(cmp8_imm_ge   , "cmp.ge"        ,COMP   ,0, 1, A, ICMP   , 8,0x20C4)  // -> cmp.lt
INST1(cmp8_imm_gt   , "cmp.gt"        ,COMP   ,0, 1, A, ICMP   , 8,0x60C4)  // -> cmp.lt

INST1(cmp8_reg_lt_u , "cmp.ltu"       ,COMP   ,0, 1, A, ICMP   , 6,0x00D0)
INST1(cmp8_reg_le_u , "cmp.leu"       ,COMP   ,0, 1, A, ICMP   , 6,0x30D0)  // -> cmp.ltu
INST1(cmp8_reg_ge_u , "cmp.geu"       ,COMP   ,0, 1, A, ICMP   , 6,0x20D0)  // -> cmp.ltu
INST1(cmp8_reg_gt_u , "cmp.gtu"       ,COMP   ,0, 1, A, ICMP   , 6,0x10D0)  // -> cmp.ltu

INST1(cmp8_imm_lt_u , "cmp.ltu"       ,COMP   ,0, 1, A, ICMP   , 8,0x00D4)
INST1(cmp8_imm_le_u , "cmp.leu"       ,COMP   ,0, 1, A, ICMP   , 8,0x40D4)  // -> cmp.ltu
INST1(cmp8_imm_ge_u , "cmp.geu"       ,COMP   ,0, 1, A, ICMP   , 8,0x20D4)  // -> cmp.ltu
INST1(cmp8_imm_gt_u , "cmp.gtu"       ,COMP   ,0, 1, A, ICMP   , 8,0x60D4)  // -> cmp.ltu

INST1(cmp4_reg_eq   , "cmp4.eq"       ,COMP   ,0, 1, A, ICMP   , 6,0x00E2)
INST1(cmp4_reg_ne   , "cmp4.ne"       ,COMP   ,0, 1, A, ICMP   , 6,0x20E2)

INST1(cmp4_reg_lt   , "cmp4.lt"       ,COMP   ,0, 1, A, ICMP   , 6,0x00C2)
INST1(cmp4_reg_le   , "cmp4.le"       ,COMP   ,0, 1, A, ICMP   , 6,0x30C2)  // -> cmp4.lt
INST1(cmp4_reg_ge   , "cmp4.ge"       ,COMP   ,0, 1, A, ICMP   , 6,0x20C2)  // -> cmp4.lt
INST1(cmp4_reg_gt   , "cmp4.gt"       ,COMP   ,0, 1, A, ICMP   , 6,0x10C2)  // -> cmp4.lt

INST1(cmp4_imm_eq   , "cmp4.eq"       ,COMP   ,0, 1, A, ICMP   , 8,0x00E6)
INST1(cmp4_imm_ne   , "cmp4.ne"       ,COMP   ,0, 1, A, ICMP   , 8,0x20E6)  // -> cmp4.eq

INST1(cmp4_imm_lt   , "cmp4.lt"       ,COMP   ,0, 1, A, ICMP   , 8,0x00C6)
INST1(cmp4_imm_le   , "cmp4.le"       ,COMP   ,0, 1, A, ICMP   , 8,0x40C6)  // -> cmp4.lt
INST1(cmp4_imm_ge   , "cmp4.ge"       ,COMP   ,0, 1, A, ICMP   , 8,0x20C6)  // -> cmp4.lt
INST1(cmp4_imm_gt   , "cmp4.gt"       ,COMP   ,0, 1, A, ICMP   , 8,0x60C6)  // -> cmp4.lt

INST1(cmp4_reg_lt_u , "cmp4.ltu"      ,COMP   ,0, 1, A, ICMP   , 6,0x00D2)
INST1(cmp4_reg_le_u , "cmp4.leu"      ,COMP   ,0, 1, A, ICMP   , 6,0x30D2)  // -> cmp4.ltu
INST1(cmp4_reg_ge_u , "cmp4.geu"      ,COMP   ,0, 1, A, ICMP   , 6,0x20D2)  // -> cmp4.ltu
INST1(cmp4_reg_gt_u , "cmp4.gtu"      ,COMP   ,0, 1, A, ICMP   , 6,0x10D2)  // -> cmp4.ltu

INST1(cmp4_imm_lt_u , "cmp4.ltu"      ,COMP   ,0, 1, A, ICMP   , 8,0x00D6)
INST1(cmp4_imm_le_u , "cmp4.leu"      ,COMP   ,0, 1, A, ICMP   , 8,0x40D6)  // -> cmp4.ltu
INST1(cmp4_imm_ge_u , "cmp4.geu"      ,COMP   ,0, 1, A, ICMP   , 8,0x20D6)  // -> cmp4.ltu
INST1(cmp4_imm_gt_u , "cmp4.gtu"      ,COMP   ,0, 1, A, ICMP   , 8,0x60D6)  // -> cmp4.ltu

//
// FP compares
//
// The encoding value is determined as follows (individual bits listed):
//
//      (high)   00CR | 00XS | 0000 | 0TAB   (low)
//
//  Where:
//
//      T       0x0004    "ta" bit
//      A       0x0002    "ra" bit
//      B       0x0001    "rb" bit
//
//      R       0x1000    1 => pseudo-opcode whose operands must be swapped
//      C       0x2000    1 => pseudo-opcode whose targets  must be swapped

INST1(fcmp_eq       , "fcmp.eq"       ,COMP   ,0, 1, F, FCMP   , 4,0x0000)
INST1(fcmp_ne       , "fcmp.neq"      ,COMP   ,0, 1, F, FCMP   , 4,0x2000)  // -> fcmp.eq
INST1(fcmp_lt       , "fcmp.lt"       ,COMP   ,0, 1, F, FCMP   , 4,0x0001)
INST1(fcmp_le       , "fcmp.le"       ,COMP   ,0, 1, F, FCMP   , 4,0x0002)
INST1(fcmp_ge       , "fcmp.ge"       ,COMP   ,0, 1, F, FCMP   , 4,0x1002)  // -> fcmp.le
INST1(fcmp_gt       , "fcmp.gt"       ,COMP   ,0, 1, F, FCMP   , 4,0x1001)  // -> fcmp.lt

//////////////////////////////////////////////////////////////////////////////

INST1(ld1_ind       , "ld1"           ,BINOP  ,0, 0, M, LD     , 1,     0)
INST1(ld2_ind       , "ld2"           ,BINOP  ,0, 0, M, LD     , 1,     0)
INST1(ld4_ind       , "ld4"           ,BINOP  ,0, 0, M, LD     , 1,     0)
INST1(ld8_ind       , "ld8"           ,BINOP  ,0, 0, M, LD     , 1,     0)

INST1(ld1_ind_imm   , "ld1"           ,BINOP  ,0, 0, M, LD     , 3,     0)
INST1(ld2_ind_imm   , "ld2"           ,BINOP  ,0, 0, M, LD     , 3,     0)
INST1(ld4_ind_imm   , "ld4"           ,BINOP  ,0, 0, M, LD     , 3,     0)
INST1(ld8_ind_imm   , "ld8"           ,BINOP  ,0, 0, M, LD     , 3,     0)

INST1(st1_ind       , "st1"           ,BINOP  ,0, 0, M, ST     , 4,     0)
INST1(st2_ind       , "st2"           ,BINOP  ,0, 0, M, ST     , 4,     0)
INST1(st4_ind       , "st4"           ,BINOP  ,0, 0, M, ST     , 4,     0)
INST1(st8_ind       , "st8"           ,BINOP  ,0, 0, M, ST     , 4,     0)

INST1(st1_ind_imm   , "st1"           ,BINOP  ,0, 0, M, ST     , 5,     0)
INST1(st2_ind_imm   , "st2"           ,BINOP  ,0, 0, M, ST     , 5,     0)
INST1(st4_ind_imm   , "st4"           ,BINOP  ,0, 0, M, ST     , 5,     0)
INST1(st8_ind_imm   , "st8"           ,BINOP  ,0, 0, M, ST     , 5,     0)

//////////////////////////////////////////////////////////////////////////////

INST1(add_reg_reg   , "add"           ,BINOP  ,0, 0, A, IALU   , 1,     0)
INST1(add_reg_i14   , "adds"          ,BINOP  ,0, 0, A, IALU   , 4,     0)

INST1(sub_reg_reg   , "sub"           ,BINOP  ,0, 0, A, IALU   , 1,     0)

INST1(and_reg_reg   , "and"           ,BINOP  ,0, 0, A, IALU   , 1,     0)
INST1(ior_reg_reg   , "or"            ,BINOP  ,0, 0, A, IALU   , 1,     0)
INST1(xor_reg_reg   , "xor"           ,BINOP  ,0, 0, A, IALU   , 1,     0)

INST1(mov_reg_i64   , "movl"          ,BINOP  ,0, 0, L, IALU   , 2,     0)

INST1(mov_reg_ip    , "mov"           ,MOVIP  ,0, 0, I, FRIP   ,25,     0)

INST1(shladd        , "shladd"        ,TERNARY,0, 0, A, IALU   , 2,     0)

INST1(and_reg_imm   , "and"           ,BINOP  ,0, 0, A, MMSHF  , 3,     0)
INST1(ior_reg_imm   , "or"            ,BINOP  ,0, 0, A, MMSHF  , 3,     0)
INST1(xor_reg_imm   , "xor"           ,BINOP  ,0, 0, A, MMSHF  , 3,     0)

INST1(shl_reg_reg   , "shl"           ,BINOP  ,0, 0, I, IALU   , 7,     0)
INST1(shr_reg_reg   , "shr.u"         ,BINOP  ,0, 0, I, IALU   , 5,     0)
INST1(sar_reg_reg   , "shr"           ,BINOP  ,0, 0, I, IALU   , 5,     0)

INST1(zxt1          , "zxt1"          ,BINOP  ,0, 0, I, ILOG   ,29,     0)
INST1(zxt2          , "zxt2"          ,BINOP  ,0, 0, I, ILOG   ,29,     0)
INST1(zxt4          , "zxt4"          ,BINOP  ,0, 0, I, ILOG   ,29,     0)

INST1(sxt1          , "sxt1"          ,BINOP  ,0, 0, I, ILOG   ,29,     0)
INST1(sxt2          , "sxt2"          ,BINOP  ,0, 0, I, ILOG   ,29,     0)
INST1(sxt4          , "sxt4"          ,BINOP  ,0, 0, I, ILOG   ,29,     0)

INST1(extr          , "extr"          ,BINOP  ,0, 0, I, ISHF   ,12,     0)
INST1(extr_u        , "extr.u"        ,BINOP  ,0, 0, I, ISHF   ,12,     0)

//////////////////////////////////////////////////////////////////////////////

INST1(mov_reg_brr   , "mov"           ,BINOP  ,0, 0, I, FRBR   ,22,     0)
INST1(mov_brr_reg   , "mov"           ,BINOP  ,0, 0, I, TOBR   ,21,     0)

INST1(mov_reg_arr   , "mov.i"         ,BINOP  ,0, 0, I, FRAR   ,28,     0)
INST1(mov_arr_reg   , "mov.i"         ,BINOP  ,0, 0, I, TOAR   ,26,     0)
INST1(mov_arr_imm   , "mov.i"         ,BINOP  ,0, 0, I, TOAR   ,27,     0)

//////////////////////////////////////////////////////////////////////////////

INST1(alloc         , "alloc"         ,PROLOG ,0, 0, M, NONE   ,34,     0)  // morphed from "prolog"

//////////////////////////////////////////////////////////////////////////////

INST1(fmerge        , "fmerge"        ,BINOP  ,0, 0, F, FMISC  , 9,     0)
INST1(fmerge_ns     , "fmerge.ns"     ,BINOP  ,0, 0, F, FMISC  , 9,     0)

INST1(fcvt_xf       , "fcvt.xf"       ,BINOP  ,0, 0, F, FCVTFP ,11,     0)

INST1(fma_s         , "fma.s"         ,TERNARY,0, 0, F, FMAC   , 1,0x0011)
INST1(fma_d         , "fma.d"         ,TERNARY,0, 0, F, FMAC   , 1,0x0012)

INST1(fms_s         , "fms.s"         ,TERNARY,0, 0, F, FMAC   , 1,0x0015)
INST1(fms_d         , "fms.d"         ,TERNARY,0, 0, F, FMAC   , 1,0x0016)

INST1(xma_l         , "xma.l"         ,TERNARY,0, 0, F, XMPY   , 2,0x0000)

INST1(getf_sig      , "getf.sig"      ,BINOP  ,0, 0, M, FRFR   ,19,0x001C)
INST1(getf_exp      , "getf.exp"      ,BINOP  ,0, 0, M, FRFR   ,19,0x001D)
INST1(getf_s        , "getf.s"        ,BINOP  ,0, 0, M, FRFR   ,19,0x001E)
INST1(getf_d        , "getf.d"        ,BINOP  ,0, 0, M, FRFR   ,19,0x001F)

INST1(setf_sig      , "setf.sig"      ,BINOP  ,0, 0, M, TOFR   ,19,0x001C)
INST1(setf_exp      , "setf.exp"      ,BINOP  ,0, 0, M, TOFR   ,19,0x001D)
INST1(setf_s        , "setf.s"        ,BINOP  ,0, 0, M, TOFR   ,19,0x001E)
INST1(setf_d        , "setf.d"        ,BINOP  ,0, 0, M, TOFR   ,19,0x001F)

INST1(ldf_s         , "ldfs"          ,BINOP  ,0, 0, M, LD     , 6,0x0002)
INST1(ldf_d         , "ldfd"          ,BINOP  ,0, 0, M, LD     , 6,0x0003)

INST1(stf_s         , "stfs"          ,BINOP  ,0, 0, M, ST     , 9,0x0032)
INST1(stf_d         , "stfd"          ,BINOP  ,0, 0, M, ST     , 9,0x0033)

//////////////////////////////////////////////////////////////////////////////
//    Pseudo-instructions that trivially map 1:1 to "real" instructions     //
//////////////////////////////////////////////////////////////////////////////

INST2(mov_reg       , "mov"           ,BINOP  ,0, 0, A, IALU   , 1,     0)  // -> add r1=r0,r2
INST2(mov_reg_i22   , "mov"           ,BINOP  ,0, 0, A, IALU   , 5,     0)  // -> add r1=r0,imm22

INST1(fmov          , "mov"           ,BINOP  ,0, 0, F, FMISC  , 9,     0)  // -> fmerge

INST1(fneg          , "fneg"          ,BINOP  ,0, 0, F, FMISC  , 9,     0)  // -> fmerge.ns

INST1(fadd_s        , "fadd.s"        ,TERNARY,0, 0, F, FMAC   , 1,0x0011)  // -> fma.s
INST1(fadd_d        , "fadd.d"        ,TERNARY,0, 0, F, FMAC   , 1,0x0012)  // -> fma.d

INST1(fsub_s        , "fsub.s"        ,TERNARY,0, 0, F, FMAC   , 1,0x0015)  // -> fms.s
INST1(fsub_d        , "fsub.d"        ,TERNARY,0, 0, F, FMAC   , 1,0x0016)  // -> fms.d

INST1(fmpy_s        , "fmpy.s"        ,TERNARY,0, 0, F, FMAC   , 1,0x0011)  // -> fma.s
INST1(fmpy_d        , "fmpy.d"        ,TERNARY,0, 0, F, FMAC   , 1,0x0012)  // -> fma.d

INST1(fcvt_xuf_s    , "fcvt.xuf.s"    ,TERNARY,0, 0, F, FMAC   , 1,0x0011)  // -> fma.s
INST1(fcvt_xuf_d    , "fcvt.xuf.d"    ,TERNARY,0, 0, F, FMAC   , 1,0x0012)  // -> fma.d

INST1(shl_reg_imm   , "shl"           ,BINOP  ,0, 0, I, ISHF   ,12,     0)  // -> dep.z
INST1(shr_reg_imm   , "shr.u"         ,BINOP  ,0, 0, I, ISHF   ,11,     0)  // -> extr.u
INST1(sar_reg_imm   , "shr"           ,BINOP  ,0, 0, I, ISHF   ,11,     0)  // -> extr

//////////////////////////////////////////////////////////////////////////////
//             The following aren't really instructions at all              //
//////////////////////////////////////////////////////////////////////////////

INST2(PROLOG        , "<prolog>"      ,PROLOG ,0, 0, N, NONE   , 0,     0)  // -> "alloc", etc.
INST2(EPILOG        , "<epilog>"      ,EPILOG ,0, 0, N, NONE   , 0,     0)  // -> restore regs, ret

INST2(CNS_INT       , "<cnsInt>"      ,CONST  ,0, 0, N, NONE   , 0,     0)
INST2(CNS_FLT       , "<cnsFlt>"      ,CONST  ,0, 0, N, NONE   , 0,     0)

INST2(PHYSREG       , "<register>"    ,REG    ,0, 0, N, NONE   , 0,     0)
INST2(GLOBVAR       , "<globvar>"     ,GLOB   ,0, 0, N, NONE   , 0,     0)
INST2(FRMVAR        , "<frmvar>"      ,FVAR   ,0, 0, N, NONE   , 0,     0)
INST2(LCLVAR        , "<lclvar>"      ,VAR    ,0, 0, N, NONE   , 0,     0)
INST2(ADDROF        , "<addrof>"      ,VAR    ,0, 0, N, NONE   , 0,     0)
INST2(ARG           , "<arg>"         ,ARG    ,0, 0, N, NONE   , 0,     0)

INST2(SRCLINE       , "<source line>" ,SRCLINE,0, 0, N, NONE   , 0,     0)

#undef  INST1
#undef  INST2
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\lclvars.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                           LclVarsInfo                                     XX
XX                                                                           XX
XX   The variables to be used by the code generator.                         XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop
#include "emit.h"

/*****************************************************************************/

#if defined(DEBUG) && !defined(NOT_JITC)
#if DOUBLE_ALIGN
/* static */
unsigned            Compiler::s_lvaDoubleAlignedProcsCount = 0;
#endif
#endif


/*****************************************************************************/

void                Compiler::lvaInit()
{
    lvaAggrTableArgs        =
    lvaAggrTableLcls        =
    lvaAggrTableTemps       = NULL;

    /* lvaAggrTableArgs/Lcls[] are allocated if needed, ie if the signature
       has any ValueClasses.
       lvaAggrTableTemps[] is allocated as needed, and may grow during
       impImportBlock() as we dont know how many temps we will need in all.
       lvaAggrTableTempsCount is its current size.
     */

    lvaAggrTableTempsCount  = 0;
}

/*****************************************************************************/

void                Compiler::lvaInitTypeRef()
{
    ARG_LIST_HANDLE argLst;

    /* Allocate the variable descriptor table */

    lvaTableCnt = lvaCount * 2;

    if (lvaTableCnt < 16)
        lvaTableCnt = 16;

    size_t tableSize = lvaTableCnt * sizeof(*lvaTable);
    lvaTable = (LclVarDsc*)compGetMem(tableSize);
    memset(lvaTable, 0, tableSize);

    /* Count the arguments and initialize the resp. lvaTypeRefs entries */

    unsigned argsCount      = 0;
    unsigned argSlotCount   = 0;

    compArgSize             = 0;

    if  (!info.compIsStatic)
    {
        argsCount++;
        argSlotCount++;
        compArgSize       += sizeof(void *);

        lvaTable[0].lvIsParam = 1;
            // Mark the 'this' pointer for the method
        lvaTable[0].lvIsThis    = 1;

        DWORD clsFlags = eeGetClassAttribs(eeGetMethodClass(info.compMethodHnd));

        if (clsFlags & FLG_VALUECLASS)
        {
            lvaTable[0].lvType = (clsFlags & FLG_UNMANAGED) ? TYP_I_IMPL : TYP_BYREF;
        }
        else
        {
            lvaTable[0].lvType  = TYP_REF;

            if (clsFlags & FLG_CONTEXTFUL)
                lvaTable[0].lvContextFul = 1;
        }
    }

#if RET_64BIT_AS_STRUCTS

    /* Figure out whether we need to add a secret "retval addr" argument */

    fgRetArgUse = false;
    fgRetArgNum = 0xFFFF;

    if  (genTypeStSz(info.compDeclRetType) > 1)
    {
        /* Yes, we have to add the retvaladdr argument */

        fgRetArgUse = true;

        /* "this" needs to stay as argument 0, if present */

        fgRetArgNum = info.compIsStatic ? 0 : 1;

        /* Update the total argument size, slot count and variable count */

        compArgSize += sizeof(void *);
        lvaTable[argSlotCount].lvType   = TYP_REF;
        argSlotCount++;
        lvaCount++;
    }

#endif

    argLst              = info.compMethodInfo->args.args;
    unsigned argSigLen  = info.compMethodInfo->args.numArgs;

    /* if we have a hidden buffer parameter, that comes here */

    if (info.compRetBuffArg >= 0)
    {
        lvaTable[argSlotCount++].lvType   = TYP_BYREF;
        compArgSize += sizeof(void*);
        argsCount++;
    }

    for(unsigned i = 0; i < argSigLen; i++)
    {
        varType_t type = eeGetArgType(argLst, &info.compMethodInfo->args);

        if (type == TYP_REF)
        {
            if (eeGetClassAttribs(eeGetArgClass(argLst, &info.compMethodInfo->args)) & FLG_CONTEXTFUL)
                lvaTable[argSlotCount].lvContextFul = 1;
        }

        lvaTable[argSlotCount].lvType    = type;
        lvaTable[argSlotCount].lvIsParam = 1;
        argSlotCount++;

        /* Note the class handle in lvaAggrTableArgs[]. */

        if (type == TYP_STRUCT)
        {
            /* May not have been already allocated */

            if  (lvaAggrTableArgs == NULL)
                lvaAggrTableArgs = (LclVarAggrInfo *) compGetMem(info.compArgsCount * sizeof(lvaAggrTableArgs[0]));

            lvaAggrTableArgs[argsCount].lvaiClassHandle =
#ifdef NOT_JITC
                (info.compCompHnd->getArgType(&info.compMethodInfo->args, argLst) == JIT_TYP_REFANY)
                     ? REFANY_CLASS_HANDLE
                     : info.compCompHnd->getArgClass(&info.compMethodInfo->args, argLst);
#else
                eeGetArgClass(argLst, &info.compMethodInfo->args);
//              (CLASS_HANDLE) 1;
#endif
        }

        argsCount++;

        compArgSize += eeGetArgSize(argLst, &info.compMethodInfo->args);
        argLst = eeGetArgNext(argLst);
    }

    if (info.compIsVarArgs)
    {
        lvaTable[argSlotCount].lvType    = TYP_I_IMPL;
        lvaTable[argSlotCount].lvIsParam = 1;
        argSlotCount++;
        compArgSize += sizeof(void*);
        argsCount++;
    }

    /* We set info.compArgsCount in compCompile() */

    assert(argsCount == info.compArgsCount);

    /* The total argument size must be aligned. */

    assert((compArgSize % sizeof(int)) == 0);

#if TGT_x86
    /* We cant pass more than 2^16 dwords as arguments as the "ret"
       instruction can only pop 2^16 arguments. Could be handled correctly
       but it will be very difficult for fully interruptible code */

    if (compArgSize != (size_t)(unsigned short)compArgSize)
        NO_WAY("Too many arguments for the \"ret\" instruction to pop");
#endif

    /* Does it fit into LclVarDsc.lvStkOffs (which is a signed short) */

    if (compArgSize != (size_t)(signed short)compArgSize)
        NO_WAY("Arguments are too big for the jit to handle");

    /*  init the types of the local variables */

    ARG_LIST_HANDLE     localsSig = info.compMethodInfo->locals.args;
    unsigned short      localsStart = info.compArgsCount;

    for(i = 0; i < info.compMethodInfo->locals.numArgs; i++)
    {
        bool      isPinned;
        varType_t type = eeGetArgType(localsSig, &info.compMethodInfo->locals, &isPinned);

        /* For structs, store the class handle in lvaAggrTableLcls[] */
        if (type == TYP_STRUCT)
        {
            if  (lvaAggrTableLcls == NULL)
            {
                /* Lazily allocated so that we dont need it if the method
                   has no TYP_STRUCTs. */

                unsigned lclsCount = info.compLocalsCount - info.compArgsCount;
                lvaAggrTableLcls = (LclVarAggrInfo *) compGetMem(lclsCount * sizeof(lvaAggrTableLcls[0]));
            }

            lvaAggrTableLcls[i].lvaiClassHandle =
#ifdef NOT_JITC
                (eeGetArgType(localsSig, &info.compMethodInfo->locals) == JIT_TYP_REFANY)
                    ? REFANY_CLASS_HANDLE
                    : eeGetArgClass(localsSig, &info.compMethodInfo->locals);
#else
                eeGetArgClass(localsSig, &info.compMethodInfo->locals);
//              (CLASS_HANDLE) 1;
#endif
        }

        else if (type == TYP_REF)
        {
            if (eeGetClassAttribs(eeGetArgClass(localsSig, &info.compMethodInfo->locals)) & FLG_CONTEXTFUL)
                lvaTable[i+localsStart].lvContextFul = 1;
        }

        lvaTable[i+localsStart].lvType   = type;
        lvaTable[i+localsStart].lvPinned = isPinned;
        localsSig = eeGetArgNext(localsSig);
    }
}

/*****************************************************************************
 * Returns true if "ldloca" was used on the variable
 */

bool                Compiler::lvaVarAddrTaken(unsigned lclNum)
{
    assert(lclNum < lvaCount);

    return lvaTable[lclNum].lvAddrTaken;
}

/*****************************************************************************
 * Returns a pointer into the correct lvaAggrTableXXX[]
 */

Compiler::LclVarAggrInfo *  Compiler::lvaAggrTableGet(unsigned varNum)
{
    if       (varNum < info.compArgsCount)      // Argument
    {
        assert(lvaAggrTableArgs != NULL);
        unsigned argNum = varNum - 0;
        return &lvaAggrTableArgs[argNum];
    }
    else if  (varNum < info.compLocalsCount)    // LocalVar
    {
        assert(lvaAggrTableLcls != NULL);
        unsigned lclNum = varNum - info.compArgsCount;
        return &lvaAggrTableLcls[lclNum];
    }
    else                                        // Temp
    {
        assert(varNum < lvaCount);
        assert(lvaAggrTableTemps != NULL);

        unsigned tempNum = varNum - info.compLocalsCount;
        assert(tempNum < lvaAggrTableTempsCount);
        return &lvaAggrTableTemps[tempNum];
    }

}

/*****************************************************************************
 * Returns the handle to the class of the local variable lclNum
 */

CLASS_HANDLE        Compiler::lvaLclClass(unsigned varNum)
{
                // @TODO: remove the TypeGet == UNDEF when the lva table is properly filled out
    assert(lvaTable[varNum].TypeGet() == TYP_STRUCT ||
                   lvaTable[varNum].TypeGet() == TYP_UNDEF);
    LclVarAggrInfo * aggrInfo = lvaAggrTableGet(varNum);
    return aggrInfo->lvaiClassHandle;
}

/*****************************************************************************
 * Return the number of bytes needed for a local varable
 */

size_t              Compiler::lvaLclSize(unsigned varNum)
{
    var_types       varType = lvaTable[varNum].TypeGet();

    switch(varType)
    {
    case TYP_STRUCT:

        CLASS_HANDLE    cls;
        cls = lvaLclClass(varNum);
        assert(cls != 0);

        if (cls == REFANY_CLASS_HANDLE)
            return(2*sizeof(void*));

        mdToken             tpt;
        IMDInternalImport * mdi;

        tpt = (int)cls; // ((int)cls | mdtTypeDef)+1; // horrid hack
        mdi = info.compCompHnd->symMetaData;

//      printf("cls = %08X\n", cls);
//      printf("tpt = %08X\n", tpt);

        if  (TypeFromToken(tpt) == mdtTypeRef)
        {
            const char *    nmsp;
            const char *    name;

            info.compCompHnd->symMetaData->GetNameOfTypeRef(tpt, &nmsp, &name);

            // Disgusting hack!!!!!!

            if  (!strcmp(nmsp, "System"))
            {
                if  (!strcmp(name, "ArgIterator")) return 8;
            }

            printf("Typeref class name = '%s::%s'\n", nmsp, name);

            UNIMPL("can't handle struct typerefs right now");
        }

        if  (TypeFromToken(tpt) == mdtTypeDef)
        {
            DWORD           flags = 0;

            mdi->GetTypeDefProps(tpt, &flags, NULL);

//          printf("Flags = %04X\n", flags);

            if  ((flags & tdLayoutMask) == tdExplicitLayout ||
                 (flags & tdLayoutMask) == tdSequentialLayout)
            {
                ULONG           sz;

                if  (!mdi->GetClassTotalSize(tpt, &sz))
                    return  roundUp(sz, sizeof(void*));
            }
        }

        assert(!"can't get struct size???");

#pragma message("horrible struct size hack on line 323")
        return  64;

    case TYP_BLK:
        return lvaAggrTableGet(varNum)->lvaiBlkSize;

    case TYP_LCLBLK:
        assert(lvaScratchMem > 0);
        assert(varNum == lvaScratchMemVar);
        return lvaScratchMem;

    default:    // This is a primitve var. Fall out of switch statement
        break;
    }

    return genTypeStSz(varType)*sizeof(int);
}

/*****************************************************************************
 *
 *  Callback used by the tree walker to call lvaDecRefCnts
 */
int                Compiler::lvaDecRefCntsCB(GenTreePtr tree, void *p)
{
    ASSert(p);
    return ((Compiler *)p)->lvaDecRefCnts(tree);
}

/*****************************************************************************
 *
 *  Helper passed to the tree walker to decrement the refCnts for
 *  all local variables in an expression
 */
int                Compiler::lvaDecRefCnts(GenTreePtr tree)
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    /* This must be a local variable */

    assert(tree->gtOper == GT_LCL_VAR);

    /* Get the variable descriptor */

    lclNum = tree->gtLclVar.gtLclNum;

    assert(lclNum < lvaCount);
    varDsc = lvaTable + lclNum;

    /* Decrement its lvRefCnt and lvRefCntWtd */

    assert(varDsc->lvRefCnt);
    if  (varDsc->lvRefCnt > 1)
        varDsc->lvRefCnt--;
    varDsc->lvRefCntWtd -= compCurBB->bbWeight;

#ifdef DEBUG
    if (verbose)
        printf("\nNew refCnt for variable #%02u - refCnt = %u\n", lclNum, varDsc->lvRefCnt);
#endif

    return 0;

    /* If the ref count is zero mark the variable as un-tracked
     *
     * CONSIDER: to do that we also need to re-compute all tracked locals
     * otherwise we crash later on */

//                if  (varDsc->lvRefCnt == 0)
//                    varDsc->lvTracked  = 0;

}

/*****************************************************************************
 *
 *  Callback used by the tree walker to call lvaIncRefCnts
 */
int                Compiler::lvaIncRefCntsCB(GenTreePtr tree, void *p)
{
    ASSert(p);
    return ((Compiler *)p)->lvaIncRefCnts(tree);
}

/*****************************************************************************
 *
 *  Helper passed to the tree walker to increment the refCnts for
 *  all local variables in an expression
 */
int                Compiler::lvaIncRefCnts(GenTreePtr tree)
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    /* This must be a local variable */

    assert(tree->gtOper == GT_LCL_VAR);

    /* Get the variable descriptor */

    lclNum = tree->gtLclVar.gtLclNum;

    assert(lclNum < lvaCount);
    varDsc = lvaTable + lclNum;

    /* Increment its lvRefCnt and lvRefCntWtd */

    assert(varDsc->lvRefCnt);
    varDsc->lvRefCnt++;
    varDsc->lvRefCntWtd += compCurBB->bbWeight;

#ifdef DEBUG
    if (verbose)
        printf("\nNew refCnt for variable #%02u - refCnt = %u\n", lclNum, varDsc->lvRefCnt);
#endif

    return 0;
}

/*****************************************************************************
 *
 *  Compare function passed to qsort() by Compiler::lclVars.lvaSortByRefCount().
 */

/* static */
int __cdecl         Compiler::RefCntCmp(const void *op1, const void *op2)
{
    LclVarDsc *     dsc1 = *(LclVarDsc * *)op1;
    LclVarDsc *     dsc2 = *(LclVarDsc * *)op2;

    /* Make sure we preference int/long/ptr over double */

#if TGT_x86

    if  (dsc1->lvType != dsc2->lvType)
    {
        if  (dsc1->lvType == TYP_DOUBLE && dsc2->lvRefCnt) return +1;
        if  (dsc2->lvType == TYP_DOUBLE && dsc1->lvRefCnt) return -1;
    }

#endif

    return  dsc2->lvRefCntWtd - dsc1->lvRefCntWtd;
}

/*****************************************************************************
 *
 *  Sort the local variable table by refcount and assign tracking indices.
 */

void                Compiler::lvaSortByRefCount()
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    LclVarDsc * *   refTab;

#if DOUBLE_ALIGN
    /* Clear weighted ref count of all double locals */
    lvaDblRefsWeight = 0;
    lvaLclRefsWeight = 0;
#endif

    /* We'll sort the variables by ref count - allocate the sorted table */

    lvaRefSorted = refTab = (LclVarDsc **) compGetMem(lvaCount*sizeof(*refTab));

    /* Fill in the table used for sorting */

    for (lclNum = 0, varDsc = lvaTable;
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
        /* Append this variable to the table for sorting */

        *refTab++ = varDsc;

        /* For now assume we'll be able to track all locals */

        varDsc->lvTracked = 1;

        // If the address of the local var was taken, mark it as volatile
        // All structures are assumed to have their address taken
        // Also pinned locals must be untracked
        // All untracked locals later get lvMustInit set as well
        //
        if  (lvaVarAddrTaken(lclNum)      ||
             varDsc->lvType == TYP_STRUCT ||
             varDsc->lvPinned)
        {
            varDsc->lvVolatile = 1;
            varDsc->lvTracked = 0;
        }

        //  Are we not optimizing and we have exception handlers?
        //   if so mark all args and locals as volatile, so that they
        //   won't ever get enregistered.
        //
        if  (opts.compMinOptim && info.compXcptnsCount)
        {
            varDsc->lvVolatile = 1;
            continue;
        }

        /* Only integers/longs and pointers are ever enregistered */

#if DOUBLE_ALIGN
        lvaLclRefsWeight += varDsc->lvRefCntWtd;
#endif

        switch (varDsc->lvType)
        {
        case TYP_INT:
        case TYP_REF:
        case TYP_BYREF:
        case TYP_LONG:
#if!CPU_HAS_FP_SUPPORT
        case TYP_FLOAT:
#endif
            break;

        case TYP_DOUBLE:

#if DOUBLE_ALIGN

            /*
                Add up weighted ref counts of double locals for align
                heuristic (note that params cannot be double aligned).
             */

            if (!varDsc->lvIsParam)
                lvaDblRefsWeight += varDsc->lvRefCntWtd;

#endif

            break;

        case TYP_UNDEF:
        case TYP_UNKNOWN:
            varDsc->lvType = TYP_INT;
//            assert(!"All var types are set in lvaMarkLocalVars() using localsig");

        default:
            varDsc->lvTracked = 0;
        }
    }

    /* Now sort the variable table by ref-count */

    qsort(lvaRefSorted, lvaCount, sizeof(*lvaRefSorted), RefCntCmp);

#ifdef  DEBUG

    if  (verbose && lvaCount)
    {
        printf("refCnt table for '%s':\n", info.compMethodName);

        for (lclNum = 0; lclNum < lvaCount; lclNum++)
        {
            if  (!lvaRefSorted[lclNum]->lvRefCnt)
                break;

            printf("   var #%03u [%7s]: refCnt = %4u, refCntWtd = %6u\n",
                   lvaRefSorted[lclNum] - lvaTable,
                   varTypeName((var_types)lvaRefSorted[lclNum]->lvType),
                   lvaRefSorted[lclNum]->lvRefCnt,
                   lvaRefSorted[lclNum]->lvRefCntWtd);
        }

        printf("\n");
    }

#endif

    /* Decide which variables will be worth tracking */

    if  (lvaCount > lclMAX_TRACKED)
    {
        /* Mark all variables past the first 'lclMAX_TRACKED' as untracked */

        for (lclNum = lclMAX_TRACKED; lclNum < lvaCount; lclNum++)
        {
            // We need to always track the "this" pointer
            if (lvaRefSorted[lclNum]->lvIsThis &&
                (lvaRefSorted[lclNum]->lvRefCnt || opts.compDbgInfo))
            {
                // swap the "this" pointer with the last one in the ref sorted range
                varDsc                         = lvaRefSorted[lclMAX_TRACKED-1];
                lvaRefSorted[lclMAX_TRACKED-1] = lvaRefSorted[lclNum];
                lvaRefSorted[lclNum]           = varDsc;
            }
            lvaRefSorted[lclNum]->lvTracked = 0;
        }
    }

    /* Assign indices to all the variables we've decided to track */

    lvaTrackedCount = 0;
    lvaTrackedVars  = 0;

    for (lclNum = 0, varDsc = lvaTable;
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
        if  (varDsc->lvTracked)
        {
            /* Make sure the ref count is non-zero */

            if  (varDsc->lvRefCnt == 0)
            {
                varDsc->lvTracked  = 0;
            }
            else
            {
                /* This variable will be tracked - assign it an index */

                lvaTrackedVars |= genVarIndexToBit(lvaTrackedCount);

#ifdef DEBUGGING_SUPPORT
                lvaTrackedVarNums[lvaTrackedCount] = lclNum;
#endif

                varDsc->lvVarIndex = lvaTrackedCount++;
            }
        }
    }
}

/*****************************************************************************
 *
 *  This is called by lvaMarkLclRefsCallback() to do variable ref marking
 */

void                Compiler::lvaMarkLclRefs(GenTreePtr tree)
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;

#if INLINE_NDIRECT
    /* Is this a call to unmanaged code ?*/
    if (tree->gtOper == GT_CALL && tree->gtFlags & GTF_CALL_UNMANAGED)
    {
        lclNum = info.compLvFrameListRoot;

        assert(lclNum <= lvaCount);
        varDsc = lvaTable + lclNum;

        /* Bump the reference counts */

        //UNDONE: parse the pre/post-operation list of the call node

        assert(lvaMarkRefsWeight);

        varDsc->lvRefCnt    += 2;
        varDsc->lvRefCntWtd += (2*lvaMarkRefsWeight);
    }
#endif

#if TARG_REG_ASSIGN || OPT_BOOL_OPS

    /* Is this an assigment? */

    if (tree->OperKind() & GTK_ASGOP)
    {
        GenTreePtr      op2 = tree->gtOp.gtOp2;

#if TARG_REG_ASSIGN && TGT_x86

        /* Set target register for RHS local if assignment is of a "small" type */

        if  (op2->gtOper == GT_LCL_VAR && genTypeSize(tree->gtType) < sizeof(int))
        {
            unsigned        lclNum2;
            LclVarDsc   *   varDsc2;

            lclNum2 = op2->gtLclVar.gtLclNum;
            assert(lclNum2 < lvaCount);
            varDsc2 = lvaTable + lclNum2;

            varDsc2->lvPrefReg = RBM_BYTE_REGS;
        }

#endif

#if OPT_BOOL_OPS

        /* Is this an assignment to a local variable? */

        if  (tree->gtOp.gtOp1->gtOper == GT_LCL_VAR && op2->gtType != TYP_BOOL)
        {
            /* Only simple assignments allowed for booleans */

            if  (tree->gtOper != GT_ASG)
                goto NOT_BOOL;

            /* Is the RHS clearly a boolean value? */

            switch (op2->gtOper)
            {
                unsigned        lclNum;

            case GT_LOG0:
            case GT_LOG1:

                /* The result of log0/1 is always a true boolean */

                break;

            case GT_CNS_INT:

                if  (op2->gtIntCon.gtIconVal == 0)
                    break;
                if  (op2->gtIntCon.gtIconVal == 1)
                    break;

                // Not 0 or 1, fall through ....

            default:

            NOT_BOOL:

                lclNum = tree->gtOp.gtOp1->gtLclVar.gtLclNum;
                assert(lclNum < lvaCount);

                lvaTable[lclNum].lvNotBoolean = true;
                break;
            }
        }

#endif

    }

#endif

#if FANCY_ARRAY_OPT

    /* Special case: assignment node */

    if  (tree->gtOper == GT_ASG)
    {
        if  (tree->gtType == TYP_INT)
        {
            unsigned        lclNum1;
            LclVarDsc   *   varDsc1;

            GenTreePtr      op1 = tree->gtOp.gtOp1;

            if  (op1->gtOper != GT_LCL_VAR)
                return;

            lclNum1 = op1->gtLclVar.gtLclNum;
            assert(lclNum1 < lvaCount);
            varDsc1 = lvaTable + lclNum1;

            if  (varDsc1->lvAssignOne)
                varDsc1->lvAssignTwo = true;
            else
                varDsc1->lvAssignOne = true;
        }

        return;
    }

#endif

#if TARG_REG_ASSIGN && TGT_x86

    /* Special case: integer shift node by a variable amount */

    if  (tree->gtOper == GT_LSH ||
         tree->gtOper == GT_RSH ||
         tree->gtOper == GT_RSZ)
    {
        if  (tree->gtType == TYP_INT)
        {
            GenTreePtr      op2 = tree->gtOp.gtOp2;

            if  (op2->gtOper == GT_LCL_VAR)
            {
                lclNum = op2->gtLclVar.gtLclNum;
                assert(lclNum < lvaCount);
                varDsc = lvaTable + lclNum;

#ifdef  DEBUG
                if  (verbose) printf("Variable %02u wants to live in ECX\n", lclNum);
#endif

                varDsc->lvPrefReg   |= RBM_ECX;
                varDsc->lvRefCntWtd += varDsc->lvRefCntWtd/2;
            }
        }

        return;
    }

#endif

#if TARG_REG_ASSIGN && TGT_SH3

    if  (tree->gtOper == GT_IND)
    {
        /* Indexed address modes work well with r0 */

        int             rev;
        unsigned        mul;
        unsigned        cns;

        GenTreePtr      adr;
        GenTreePtr      idx;

        if  (genCreateAddrMode(tree->gtOp.gtOp1,    // address
                               0,                   // mode
                               false,               // fold
                               0,                   // reg mask
#if!LEA_AVAILABLE
                               tree->TypeGet(),     // operand type
#endif
                               &rev,                // reverse ops
                               &adr,                // base addr
                               &idx,                // index val
#if SCALED_ADDR_MODES
                               &mul,                // scaling
#endif
                               &cns,                // displacement
                               true))               // don't generate code
        {
            unsigned        varNum;
            LclVarDsc   *   varDsc;

            if  (!adr || !idx)
                goto NO_R0;
            if  (idx->gtOper == GT_CNS_INT)
                goto NO_R0;

            if      (adr->gtOper == GT_LCL_VAR)
                varNum = adr->gtLclVar.gtLclNum;
            else if (idx->gtOper == GT_LCL_VAR)
                varNum = idx->gtLclVar.gtLclNum;
            else
                goto NO_R0;

            assert(varNum < lvaCount);
            varDsc = lvaTable + varNum;

            varDsc->lvPrefReg |= RBM_r00;
        }

    NO_R0:;

    }

#endif

#if TARG_REG_ASSIGN || FANCY_ARRAY_OPT

    if  (tree->gtOper != GT_LCL_VAR)
        return;

#endif

    /* This must be a local variable reference */

    assert(tree->gtOper == GT_LCL_VAR);
    lclNum = tree->gtLclVar.gtLclNum;

    assert(lclNum < lvaCount);
    varDsc = lvaTable + lclNum;

    /* Bump the reference counts */

    assert(lvaMarkRefsWeight);

//  printf("Var[%02u] refCntWtd += %u\n", lclNum, lvaMarkRefsWeight);

    varDsc->lvRefCnt    += 1;
    varDsc->lvRefCntWtd += lvaMarkRefsWeight;

    /* Is this a compiler-introduced temp? */

    if  (lclNum > info.compLocalsCount)
    {
        /*
            This is a compiler-introduced temp - artifically (and arbitrary)
            bump its 'weighted' refcount on the theory that compiler temps
            are short-lived and thus less likely to interfere with other
            variables.
         */

        varDsc->lvRefCntWtd += lvaMarkRefsWeight; // + lvaMarkRefsWeight/2;
    }

    /* Variables must be used as the same type throughout the method */

    assert(varDsc->lvType == TYP_UNDEF   ||
             tree->gtType == TYP_UNKNOWN ||
           genActualType((var_types)varDsc->lvType) == genActualType(tree->gtType));

    /* Remember the type of the reference */

    if (tree->gtType == TYP_UNKNOWN || varDsc->lvType == TYP_UNDEF)
    {
        varDsc->lvType = tree->gtType;
        assert(genActualType((var_types)varDsc->lvType) == tree->gtType); // no truncation
    }

    if  (tree->gtFlags & GTF_VAR_NARROWED)
    {
        assert(tree->gtType == TYP_INT);
        varDsc->lvType = TYP_LONG;
        assert(varDsc->lvType == TYP_LONG); // no truncation
    }

    return;
}


/*****************************************************************************
 *
 *  Helper passed to Compiler::fgWalkAllTrees() to do variable ref marking.
 */

/* static */
int                 Compiler::lvaMarkLclRefsCallback(GenTreePtr tree, void *p)
{
    ASSert(p);

    ((Compiler*)p)->lvaMarkLclRefs(tree);

    return 0;
}

/*****************************************************************************
 *
 *  Create the local variable table and compute local variable reference
 *  counts.
 */

void                Compiler::lvaMarkLocalVars()
{

#ifdef DEBUG
    if (verbose)
    {
        printf("lvaCount = %d\n\n", lvaCount);

        // If we have the variable names, display them

        if (info.compLocalVarsCount>0)
        {
            for (unsigned i=0; i<info.compLocalsCount; i++)
            {
                LocalVarDsc * local = compFindLocalVar(i);
                if (!local) continue;
                printf("%3d: %s\n", i, lvdNAMEstr(local->lvdName));
            }
            printf("\n");
        }
    }
#endif

    BasicBlock *    block;

    unsigned        argNum;

    ARG_LIST_HANDLE argLst    = info.compMethodInfo->args.args;
    unsigned        argSigLen = info.compMethodInfo->args.numArgs;

#if USE_FASTCALL
    unsigned        maxRegArg = MAX_INT_ARG_REG;
#endif

    LclVarDsc   *   varDsc;

    //-------------------------------------------------------------------------
    /* Mark all parameter variables as such */

    argNum = 0;
    varDsc = lvaTable;

#if TGT_IA64 /////////////////////////////////////////////////////////////////

    unsigned        argIntRegNum = REG_INT_ARG_0;
    unsigned        argFltRegNum = REG_FLT_ARG_0;

    if  (!info.compIsStatic)
    {
        /* Note: the compiler won't assign an index to an unused parameter */

        if  (argNum < info.compLocalsCount)
        {
            var_types       argType;
            NatUns          clsFlags;

            varDsc->lvIsParam = 1;
            varDsc->lvIsThis  = 1;

            clsFlags = eeGetClassAttribs(eeGetMethodClass(info.compMethodHnd));

            if (clsFlags & FLG_VALUECLASS)
            {
                argType = genActualType((clsFlags & FLG_UNMANAGED) ? TYP_I_IMPL
                                                                   : TYP_BYREF);
            }
            else
            {
                argType = genActualType(TYP_REF);
            }

            varDsc->lvType       = argType;

            assert(varDsc->lvType == argType);   // make sure no truncation occurs

#if OPT_BOOL_OPS
            varDsc->lvNotBoolean = true;
#endif
            varDsc->lvIsRegArg   = 1;
#if TARG_REG_ASSIGN
            varDsc->lvPrefReg    =
#endif
            varDsc->lvArgReg     = (regNumberSmall)argIntRegNum++;
        }

        argNum++;
        varDsc++;
    }

    /* if we have a hidden buffer parameter, that comes here */

    if  (info.compRetBuffArg >= 0)
    {
        assert(varDsc->lvType == TYP_BYREF);

        varDsc->lvType     = TYP_BYREF;
        varDsc->lvIsParam  = 1;
        varDsc->lvIsRegArg = 1;

#if TARG_REG_ASSIGN
        varDsc->lvPrefReg  =
#endif
        varDsc->lvArgReg   = (regNumberSmall)argIntRegNum++;

        if  (impParamsUsed)
        {
            varDsc->lvRefCnt    = 1;
            varDsc->lvRefCntWtd = 1;
        }

        varDsc++;
        argNum++;
    }

#if 0
    if  (info.compIsVarArgs)
    {
        printf("// ISSUE: varargs function def -- do we need to do anything special?\n");
    }
#endif

    for (unsigned i = 0; i < argSigLen; i++)
    {
        varType_t       argTyp;
        var_types       argVtp;

        /* Note: the compiler may skip assigning an index to an unused parameter */

        if  (argNum >= info.compLocalsCount)
            goto NXT_ARG;

        /* Get hold of the argument type */

        argTyp = eeGetArgType(argLst, &info.compMethodInfo->args);

        /* Mark the variable as an argument and record its type */

        varDsc->lvIsParam = 1;
        varDsc->lvType    = argTyp; assert(varDsc->lvType == argTyp);    // no truncation

#if OPT_BOOL_OPS
        if  (argTyp != TYP_BOOL)
            varDsc->lvNotBoolean = true;
#endif

        /* Do we have any more generic argument slots available? */

        if  (argIntRegNum > MAX_INT_ARG_REG)
            goto NXT_ARG;

        /* Is the type of the argument amenable to being passed in a register? */

        argVtp = varDsc->TypeGet();

        if  (!isRegParamType(argVtp))
            goto NXT_ARG;

        /* Is this a FP or integer argument ? */

        if  (varTypeIsFloating(argVtp))
        {
            /* We better have another FP argument slot available */

            assert(argFltRegNum <= MAX_FLT_ARG_REG);

            varDsc->lvArgReg = (regNumberSmall)argFltRegNum++;
        }
        else
        {
            varDsc->lvArgReg = (regNumberSmall)argIntRegNum;
        }

        /* Every argument eats up an integer slot -- no kidding! */

        argIntRegNum++;

        /* Mark the argument as being passed in a register */

        varDsc->lvIsRegArg = 1;

#if TARG_REG_ASSIGN
        varDsc->lvPrefReg  = varDsc->lvArgReg;
#endif

        /* If we have JMP or JMPI all register arguments must have a location
         * even if we don't use them inside the method */

        if  (impParamsUsed)
        {
            varDsc->lvRefCnt    = 1;
            varDsc->lvRefCntWtd = 1;
        }

#ifdef  DEBUG
        if  (verbose)
            printf("Arg   #%3u    passed in register %u\n", argNum, varDsc->lvArgReg);
#endif

    NXT_ARG:

        argNum++;
        varDsc++;

        argLst = eeGetArgNext(argLst);
    }

#if 0

    for(i = 0, varDsc = lvaTable; i < info.compLocalsCount; i++)
    {
        printf("pref reg for local %2u is %d\n", varDsc - lvaTable, varDsc->lvPrefReg);

        argNum += 1;
        varDsc += 1;
    }

    printf("\n");

#endif

#else // TGT_IA64 ////////////////////////////////////////////////////////////

#if USE_FASTCALL
    unsigned        argRegNum  = 0;
#endif

    if  (!info.compIsStatic)
    {
        /* Note: the compiler won't assign an index to an unused parameter */

        if  (argNum < info.compLocalsCount)
        {
            varDsc->lvIsParam = 1;
            // Mark the 'this' pointer for the method
            varDsc->lvIsThis  = 1;

            DWORD clsFlags = eeGetClassAttribs(eeGetMethodClass(info.compMethodHnd));

            if (clsFlags & FLG_VALUECLASS)
            {
                var_types type = genActualType((clsFlags & FLG_UNMANAGED) ? TYP_I_IMPL : TYP_BYREF);
                varDsc->lvType = type;
                assert(varDsc->lvType == type);   // no truncation
            }
            else
            {
                varDsc->lvType = genActualType(TYP_REF);
                assert(varDsc->lvType == genActualType(TYP_REF));   // no truncation
            }
#if OPT_BOOL_OPS
            varDsc->lvNotBoolean = true;
#endif
#if USE_FASTCALL
            assert(argRegNum == 0);
            varDsc->lvIsRegArg = 1;
            varDsc->lvArgReg   = (regNumberSmall) genRegArgNum(0);
#if TARG_REG_ASSIGN
#if TGT_IA64
            varDsc->lvPrefReg  =            varDsc->lvArgReg;
#else
            varDsc->lvPrefReg  = genRegMask(varDsc->lvArgReg);
#endif
#endif
            argRegNum++;
#ifdef  DEBUG
        if  (verbose||0)
            printf("'this' passed in register\n");
#endif
#endif
        }

        argNum++;
        varDsc++;
    }

#if RET_64BIT_AS_STRUCTS

    /* Are we adding a secret "retval addr" argument? */

    if  (fgRetArgUse)
    {
        assert(fgRetArgNum == argNum);

        varDsc->lvIsParam    = 1;
        varDsc->lvType       = TYP_REF;

#if OPT_BOOL_OPS
        varDsc->lvNotBoolean = true;
#endif

#if USE_FASTCALL
        varDsc->lvIsRegArg  = 1;
        varDsc->lvArgReg    = (regNumberSmall)genRegArgNum(argRegNum);
#if TARG_REG_ASSIGN
        varDsc->lvPrefReg   = genRegMask(varDsc->lvArgReg);
#endif
        argRegNum++;
#endif

        varDsc++;
    }

#endif

    /* if we have a hidden buffer parameter, that comes here */

    if (info.compRetBuffArg >= 0)
    {
        assert(argRegNum < maxRegArg && varDsc->lvType == TYP_BYREF);
        varDsc->lvType = TYP_BYREF;
        varDsc->lvIsParam = 1;
        varDsc->lvIsRegArg = 1;
        varDsc->lvArgReg   = (regNumberSmall) genRegArgNum(argRegNum);

#if TARG_REG_ASSIGN
#if TGT_IA64
        varDsc->lvPrefReg  =            varDsc->lvArgReg;
#else
        varDsc->lvPrefReg  = genRegMask(varDsc->lvArgReg);
#endif
#endif

        argRegNum++;
        if  (impParamsUsed)
        {
                varDsc->lvRefCnt    = 1;
                varDsc->lvRefCntWtd = 1;
        }
        varDsc++;
        argNum++;
    }

    if (info.compIsVarArgs)
    {
        maxRegArg = 0;  // Note that this does not effect 'this' pointer enregistration above
        assert(argNum + argSigLen + 1 == info.compArgsCount);
        varDsc[argSigLen].lvVolatile = 1;
        varDsc[argSigLen].lvIsParam = 1;
        varDsc[argSigLen].lvType = TYP_I_IMPL;
                        // we should have allocated a temp to point at the begining of the args
        assert(info.compLocalsCount < lvaCount);
                lvaTable[info.compLocalsCount].lvType = TYP_I_IMPL;
    }

    for(unsigned i = 0; i < argSigLen; i++)
    {
        varType_t argTyp = eeGetArgType(argLst, &info.compMethodInfo->args);

        /* Note: the compiler may skip assigning an index to an unused parameter */

        if  (argNum < info.compLocalsCount)
        {
            varDsc->lvIsParam = 1;
            varDsc->lvType    = argTyp;
            assert(varDsc->lvType == argTyp);    // no truncation

#if OPT_BOOL_OPS
            if  (argTyp != TYP_BOOL)
                varDsc->lvNotBoolean = true;
#endif

#if USE_FASTCALL
            if (argRegNum < maxRegArg && isRegParamType(varDsc->TypeGet()))
            {
                /* Another register argument */

                varDsc->lvIsRegArg = 1;
                varDsc->lvArgReg   = (regNumberSmall) genRegArgNum(argRegNum);
#if TARG_REG_ASSIGN
#if TGT_IA64
#error This code should not be enabled for IA64
#else
                varDsc->lvPrefReg  = genRegMask(varDsc->lvArgReg);
#endif
#endif
                argRegNum++;

                /* If we have JMP or JMPI all register arguments must have a location
                 * even if we don't use them inside the method */

                if  (impParamsUsed)
                {
                    varDsc->lvRefCnt    = 1;
                    varDsc->lvRefCntWtd = 1;
                }

#ifdef  DEBUG
                if  (verbose||0)
                    printf("Arg   #%3u    passed in register\n", argNum);
#endif
            }

#endif // USE_FASTCALL

        }

        argNum += 1;
        varDsc += 1;

        argLst = eeGetArgNext(argLst);
    }

#endif// TGT_IA64 ////////////////////////////////////////////////////////////

    // Note that varDsc and argNum are TRASH (not updated for varargs case)

    //-------------------------------------------------------------------------
    // Use the Locals-sig and mark the type of all the variables
    //

    /***** FIX REMOVE THIS ****************************************

    ARG_LIST_HANDLE     localsSig   = info.compMethodInfo->locals.args;
    unsigned            lclNum      = info.compArgsCount;

    for(i = 0; i < info.compMethodInfo->locals.numArgs; i++, lclNum++)
    {
        varType_t type = eeGetArgType(localsSig, &info.compMethodInfo->locals);

        lvaTable[lclNum].lvType = type;
        localsSig = eeGetArgNext(localsSig);
    }

    **********************************************/

    /* If there is a call to an unmanaged target, we already grabbed a local slot for
       the current thread control block.
     */
#if INLINE_NDIRECT
    if (info.compCallUnmanaged != 0)
    {

        assert(info.compLvFrameListRoot >= info.compLocalsCount &&
               info.compLvFrameListRoot <  lvaCount);

        lvaTable[info.compLvFrameListRoot].lvType       = TYP_INT;

        /* Set the refCnt, it is used in the prolog and return block */

        lvaTable[info.compLvFrameListRoot].lvRefCnt     = 2;
        lvaTable[info.compLvFrameListRoot].lvRefCntWtd  = 1;

        info.compNDFrameOffset = lvaScratchMem;


        /* make room for the inlined frame and some spill area */
        /* return value */
        lvaScratchMem += info.compEEInfo.sizeOfFrame + (2*sizeof(int));
    }
#endif

    /* If there is a locspace region, we would have already grabbed a slot for
       the dummy var for the locspace region. Set its values in lvaTable[].
       We set lvRefCnt to 1 so that we reserve space for it on the stack
     */

    if (lvaScratchMem)
    {
        assert(lvaScratchMemVar >= info.compLocalsCount &&
               lvaScratchMemVar <  lvaCount);

        lvaTable[lvaScratchMemVar].lvType       = TYP_LCLBLK;
    }

    //-------------------------------------------------------------------------

#if USE_FASTCALL

#if TGT_IA64

    assert(argIntRegNum <= MAX_INT_ARG_REG+1);

    rsCalleeIntArgNum = argIntRegNum;
    rsCalleeFltArgNum = argFltRegNum;

#else

    assert(argRegNum <= MAX_INT_ARG_REG);
    rsCalleeRegArgNum = argRegNum;

#endif

#endif

#if 0

    // UNDONE: Can't skip this (expensive) step because it sets such
    // UNDONE: useful fields as "lvType".

    if  (opts.compMinOptim)
        goto NO_LCLMARK;

#endif

#if OPT_BOOL_OPS

    if  (fgMultipleNots && (opts.compFlags & CLFLG_TREETRANS))
    {
        for (block = fgFirstBB; block; block = block->bbNext)
        {
            GenTreePtr      tree;

            for (tree = block->bbTreeList; tree; tree = tree->gtNext)
            {
                GenTreePtr      expr;

                int             logVar;
                int             nxtVar;

                assert(tree->gtOper == GT_STMT); expr = tree->gtStmt.gtStmtExpr;

                /* Check for "lclVar = log0(lclVar);" */

                logVar = expr->IsNotAssign();
                if  (logVar != -1)
                {
                    GenTreePtr      next;
                    GenTreePtr      temp;

                    /* Look for any consecutive assignments */

                    for (next = tree->gtNext; next; next = next->gtNext)
                    {
                        assert(next->gtOper == GT_STMT); temp = next->gtStmt.gtStmtExpr;

                        /* If we don't have another assignment to a local, bail */

                        nxtVar = temp->IsNotAssign();

                        if  (nxtVar == -1)
                        {
                            /* It could be a "nothing" node we put in earlier */

                            if  (temp->IsNothingNode())
                                continue;
                            else
                                break;
                        }

                        /* Do we have an assignment to the same local? */

                        if  (nxtVar == logVar)
                        {
                            LclVarDsc   *   varDsc;
                            unsigned        lclNum;

                            assert(tree->gtOper == GT_STMT);
                            assert(next->gtOper == GT_STMT);

                            /* Change the first "log0" to "log1" */

                            assert(expr->                        gtOper == GT_ASG);
                            assert(expr->gtOp.gtOp2->            gtOper == GT_LOG0);
                            assert(expr->gtOp.gtOp2->gtOp.gtOp1->gtOper == GT_LCL_VAR);

                            expr->gtOp.gtOp2->gtOper = GT_LOG1;

                            /* Special case: is the variable a boolean? */

                            lclNum = expr->gtOp.gtOp1->gtLclVar.gtLclNum;
                            assert(lclNum < lvaCount);
                            varDsc = lvaTable + lclNum;

                            /* If the variable is boolean, toss the assignment */

                            if  (!varDsc->lvNotBoolean)
                                tree->gtStmt.gtStmtExpr = gtNewNothingNode();

                            /* Get rid of the second "log0" assignment */

                            next->gtStmt.gtStmtExpr = gtNewNothingNode();
                            break;
                        }
                    }
                }
            }
        }
    }

#endif

#if defined(DEBUGGING_SUPPORT) || defined(DEBUG)

// Assign slot numbers to all variables
// If compiler generated local variables, slot numbers will be
// invalid (out of range of info.compLocalVars)

// Also have to check if variable was not reallocated to another
// slot in which case we have to register the original slot #

#if !defined(DEBUG)
    if (opts.compScopeInfo && info.compLocalVarsCount>0)
#endif
    {
        unsigned                lclNum;

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            varDsc->lvSlotNum = lclNum;
        }
    }

#endif

    /* Mark all local variable references */

    for (block = fgFirstBB;
         block;
         block = block->bbNext)
    {
        GenTreePtr      tree;

        lvaMarkRefsBBN    = block->bbNum;
        lvaMarkRefsWeight = block->bbWeight; assert(lvaMarkRefsWeight);

        for (tree = block->bbTreeList; tree; tree = tree->gtNext)
        {
            assert(tree->gtOper == GT_STMT);

#if TARG_REG_ASSIGN || FANCY_ARRAY_OPT || OPT_BOOL_OPS
            fgWalkTree(tree->gtStmt.gtStmtExpr, Compiler::lvaMarkLclRefsCallback, (void *) this, false);
#else
            fgWalkTree(tree->gtStmt.gtStmtExpr, Compiler::lvaMarkLclRefsCallback,  (void *) this, true);
#endif
        }
    }

#if 0
NO_LCLMARK:
#endif

    lvaSortByRefCount();
}

/*****************************************************************************/
#if     TGT_IA64
/*****************************************************************************/

void                Compiler::lvaAddPrefReg(LclVarDsc *dsc, regNumber reg, NatUns cost)
{
    regPrefList     pref;

    /* Look for an existing matching preference */

    if  (dsc->lvPrefReg == reg)
    {
        dsc->lvPrefReg = (regNumber)0; cost += 1;
    }
    else
    {
        for (pref = dsc->lvPrefLst; pref; pref = pref->rplNext)
        {
            if  (pref->rplRegNum == reg)
            {
                pref->rplBenefit += (USHORT)cost;
                return;
            }
        }
    }

    /* Allocate a new entry and prepend it to the existing list */

    pref = (regPrefList)compGetMem(sizeof(*pref));

    assert(sizeof(pref->rplRegNum ) == sizeof(USHORT));
    assert(sizeof(pref->rplBenefit) == sizeof(USHORT));

    pref->rplRegNum  = (USHORT)reg;
    pref->rplBenefit = (USHORT)cost;
    pref->rplNext    = dsc->lvPrefLst;
                       dsc->lvPrefLst = pref;
}

/*****************************************************************************/
#else// TGT_IA64
/*****************************************************************************
 *
 *  Compute stack frame offsets for arguments, locals and optionally temps.
 *
 *  The frame is laid out as follows :
 *
 *              ESP frames                              EBP frames
 *
 *      |                       |               |                       |
 *      |-----------------------|               |-----------------------|
 *      |       incoming        |               |       incoming        |
 *      |       arguments       |               |       arguments       |
 *      +=======================+               +=======================+
 *      |       Temps           |               |    incoming EBP       |
 *      |-----------------------|     EBP ----->|-----------------------|
 *      |       locspace        |               |   security object     |
 *      |-----------------------|               |-----------------------|
 *      |                       |               |                       |
 *      |       Variables       |               |       Variables       |
 *      |                       |               |                       |
 *      |-----------------------|               |-----------------------|
 *      |Callee saved registers |               |       locspace        |
 *      |-----------------------|               |-----------------------|
 *      |   Arguments for the   |               |       Temps           |
 *      ~    next function      ~ <----- ESP    |-----------------------|
 *      |                       |               |Callee saved registers |
 *      |       |               |               |-----------------------|
 *      |       | Stack grows   |               |       localloc        |
 *              | downward                      |-----------------------|
 *              V                               |   Arguments for the   |
 *                                              ~    next function      ~
 *                                              |                       |
 *                                              |       |               |
 *                                              |       | Stack grows   |
 *                                                      | downward
 *                                                      V
 */

void                Compiler::lvaAssignFrameOffsets(bool final)
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    /* For RISC targets we assign offsets in order of ref count */

#if     TGT_RISC
#define ASSIGN_FRAME_OFFSETS_BY_REFCNT  1
#else
#define ASSIGN_FRAME_OFFSETS_BY_REFCNT  0
#endif

#if     ASSIGN_FRAME_OFFSETS_BY_REFCNT
    LclVarDsc * *   refTab;
    unsigned        refNum;
#endif

    unsigned        hasThis;
    ARG_LIST_HANDLE argLst;
    int             argOffs, firstStkArgOffs;

#ifdef  DEBUG

    const   char *  fprName;
    const   char *  sprName;

#if     TGT_x86
    fprName = "EBP";
    sprName = "ESP";
#elif   TGT_SH3
    fprName = "R14";
    sprName = " sp";
#elif   TGT_IA64
    fprName = "r32";
    sprName = " sp";
#else
#error  Unexpected target
#endif

#endif

#if TGT_RISC
    /* For RISC targets we asign frame offsets exactly once */
    assert(final);
#endif

#if USE_FASTCALL
    unsigned        argRegNum  = 0;
#endif

    assert(lvaDoneFrameLayout < 2);
           lvaDoneFrameLayout = 1+final;

    /*-------------------------------------------------------------------------
     *
     * First process the arguments.
     * For frameless methods, the argument offsets will need to be patched up
     *  after we know how many locals/temps are on the stack.
     *
     *-------------------------------------------------------------------------
     */

#if TGT_x86

    /* Figure out the base frame offset */

    if  (!DOUBLE_ALIGN_NEED_EBPFRAME)
    {
        /*
            Assume all callee-saved registers will be pushed. Why, you
            may ask? Well, if we're not conservative wrt stack offsets,
            we may end up generating a byte-displacement opcode and
            later discover that because we need to push more registers
            the larger offset doesn't fit in a byte. So what we do is
            assume the worst (largest offsets) and if we end up not
            pushing all registers we'll go back and reduce all the
            offsets by the appropriate amount.

            In addition to the pushed callee-saved registers we also
            need to count the return address on the stack in order to
            get to the first argument.
         */

        assert(compCalleeRegsPushed * sizeof(int) <= CALLEE_SAVED_REG_MAXSZ);

        firstStkArgOffs = (compCalleeRegsPushed * sizeof(int)) + sizeof(int);
    }
    else
    {
        firstStkArgOffs = FIRST_ARG_STACK_OFFS;
    }

#else // not TGT_x86

    // RISC target

    regMaskTP       regUse;

    /*
        The argument frame offset will depend on how many callee-saved
        registers we use. This is kind of hard to predict, though, so
        we use the following approach:

            If there are no arguments that are not enregistered and
            are used within the body of the method, it doesn't matter
            how many callee-saved registers we use.

            If we do have arguments that are on the stack and are also
            used within the method, we'll use the set of callee-saved
            registers holding register variables as our estimate of
            which callee-saved registers we'll use. We'll assign frame
            offsets based on this estimate and prevent any temps from
            being stored in any other callee-saved registers.
     */

    genEstRegUse = regUse = genEstRegUse & RBM_CALLEE_SAVED;

    /* See if we have any used stack-based arguments */

    for (lclNum = 0, varDsc = lvaTable;
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
        /* Is this an argument that lives on the frame and is used? */

        if  (varDsc->lvIsParam && varDsc->lvOnFrame)
        {
            /* We'll commit to a callee-saved reg area size right now */

            genFixedArgBase = true;

            /* Figure out the base frame offset */

            firstStkArgOffs = FIRST_ARG_STACK_OFFS;

            /* Each bit in the "regUse" mask represents a saved register */

            while (regUse)
            {
                regUse          -= genFindLowestBit(regUse);
                firstStkArgOffs += sizeof(int);
            }

            /* If this is a non-leaf method we'll have to save the retaddr */

            if  (genNonLeaf)
                firstStkArgOffs += sizeof(int);

//          printf("NOTE: Callee-saved area size fixed at %u bytes\n", firstStkArgOffs);

            goto DONE_CSR;
        }
    }

    /* We have found no used stack-based args */

//  printf("NOTE: Callee-saved area size not predicted\n");

    firstStkArgOffs = FIRST_ARG_STACK_OFFS;
    genEstRegUse    = ~(regMaskTP)regMaskNULL;
    genFixedArgBase = false;

DONE_CSR:

#endif // not TGT_x86 (RISC target)

    /*
        Assign stack offsets to arguments (in reverse order of passing).

        This means that if we pass arguments left->right, we start at
        the end of the list and work backwards, for right->left we start
        with the first argument and move forward.
     */

#if ARG_ORDER_R2L
    argOffs  = firstStkArgOffs;
#else
    argOffs  = firstStkArgOffs + compArgSize;
#endif

#if USE_FASTCALL && !STK_FASTCALL

    /* Update the argOffs to reflect arguments that are passed in registers */

    assert(rsCalleeRegArgNum <= MAX_INT_ARG_REG);
    assert(compArgSize >= rsCalleeRegArgNum * sizeof(void *));

    argOffs -= rsCalleeRegArgNum * sizeof(void *);

#endif

    /* Is there a "this" argument? */

    hasThis  = 0;

    if  (!info.compIsStatic)
    {
        hasThis++;
    }

    lclNum = hasThis;

#if RET_64BIT_AS_STRUCTS

    /* Are we adding a secret "retval addr" argument? */

    if  (fgRetArgUse)
    {
        assert(fgRetArgNum == lclNum); lclNum++;
    }

#endif

    argLst              = info.compMethodInfo->args.args;
    unsigned argSigLen  = info.compMethodInfo->args.numArgs;

    /* if we have a hidden buffer parameter, that comes here */

    if (info.compRetBuffArg >= 0 )
    {
#if     ARG_ORDER_R2L
        assert(!"Did not implement hidden param for R2L case");
#endif
        assert(lclNum < info.compArgsCount);                // this param better be there
        assert(lclNum == (unsigned) info.compRetBuffArg);   // and be where I expect
        assert(lvaTable[lclNum].lvIsRegArg);
        lclNum++;
    }

    for(unsigned i = 0; i < argSigLen; i++)
    {
#if     ARG_ORDER_L2R
        assert(eeGetArgSize(argLst, &info.compMethodInfo->args));
        argOffs -= eeGetArgSize(argLst, &info.compMethodInfo->args);
#endif

        varDsc = lvaTable + lclNum;
        assert(varDsc->lvIsParam);

#if USE_FASTCALL && !STK_FASTCALL
        if (varDsc->lvIsRegArg)
        {
            /* Argument is passed in a register, don't count it
             * when updating the current offset on the stack */

            assert(eeGetArgSize(argLst, &info.compMethodInfo->args) == sizeof(void *));
            argOffs += sizeof(void *);
        }
        else
#endif
            varDsc->lvStkOffs = argOffs;

#ifdef  DEBUG
        if  (final && (verbose||0))
        {
            const   char *  frmReg = fprName;

            if  (!varDsc->lvFPbased)
                frmReg = sprName;

            printf("%s-ptr arg   #%3u    passed at %s offset %3d (size=%u)\n",
                    varTypeGCstring(varDsc->TypeGet()),
                    lclNum,
                    frmReg,
                    varDsc->lvStkOffs,
                    eeGetArgSize(argLst, &info.compMethodInfo->args));
        }
#endif

#if     ARG_ORDER_R2L
        assert(eeGetArgSize(argLst, &info.compMethodInfo->args));
        argOffs += eeGetArgSize(argLst, &info.compMethodInfo->args);
#endif

        assert(lclNum < info.compArgsCount);
        lclNum += 1;

        argLst = eeGetArgNext(argLst);
    }

    if (info.compIsVarArgs)
    {
        argOffs -= sizeof(void*);
        lvaTable[lclNum].lvStkOffs = argOffs;
    }

#if RET_64BIT_AS_STRUCTS

    /* Are we adding a secret "retval addr" argument? */

    if  (fgRetArgUse)
    {
#if     ARG_ORDER_L2R
        argOffs -= sizeof(void *);
#endif

        lvaTable[fgRetArgNum].lvStkOffs = argOffs;

#if     ARG_ORDER_R2L
        argOffs += sizeof(void *);
#endif
    }

#endif  // RET_64BIT_AS_STRUCTS

    if  (hasThis)
    {

#if     USE_FASTCALL && !STK_FASTCALL

        /* The "this" pointer is always passed in a register */

        assert(lvaTable[0].lvIsRegArg);
        assert(lvaTable[0].lvArgReg == genRegArgNum(0));

#else
        /* The "this" pointer is pushed last (smallest offset) */

#if     ARG_ORDER_L2R
        argOffs -= sizeof(void *);
#endif

#ifdef  DEBUG
        if  (final && (verbose||0))
        {
            const   char *  frmReg = fprName;

            if  (!lvaTable[0].lvFPbased)
                frmReg = sprName;

            printf("%sptr arg   #%3u    passed at %s offset %3d (size=%u)\n",
                   varTypeGCstring(lvaTable[0].TypeGet()), 0, frmReg, argOffs,
                   lvaLclSize(0));
        }
#endif

        lvaTable[0].lvStkOffs = argOffs;

#if     ARG_ORDER_R2L
        argOffs += sizeof(void *);
#endif

#endif  // USE_FASTCALL && !STK_FASTCALL

    }

#if ARG_ORDER_R2L
    assert(argOffs == firstStkArgOffs + (int)compArgSize);
#else
    assert(argOffs == firstStkArgOffs);
#endif

    /*-------------------------------------------------------------------------
     *
     * Now compute stack offsets for any variables that don't live in registers
     *
     *-------------------------------------------------------------------------
     */

#if TGT_x86

    size_t calleeSavedRegsSize = 0;

    if (!genFPused)
    {
        // If FP is not used, the locals live beyond the callee-saved
        // registers. Need to add that size while accessing locals
        // relative to SP

        calleeSavedRegsSize = compCalleeRegsPushed * sizeof(int);

        assert(calleeSavedRegsSize <= CALLEE_SAVED_REG_MAXSZ);
    }

    compLclFrameSize = 0;

#else

    /* Make sure we leave enough room for outgoing arguments */

    if  (genNonLeaf && genMaxCallArgs < MIN_OUT_ARG_RESERVE)
                       genMaxCallArgs = MIN_OUT_ARG_RESERVE;

    compLclFrameSize = genMaxCallArgs;

#endif

#if SECURITY_CHECK

    /* If we need space for a security token, reserve it now */

    if  (opts.compNeedSecurityCheck)
    {
        /* This can't work without an explicit frame, so make sure */

        assert(genFPused);

        /* Reserve space on the stack by bumping the frame size */

        compLclFrameSize += sizeof(void *);
    }

#endif

    /* If we need space for slots for shadow SP, reserve it now */

    if (info.compXcptnsCount || compLocallocUsed)
    {
        assert(genFPused); // else offsets of locals of frameless methods will be incorrect

        lvaShadowSPfirstOffs = compLclFrameSize + sizeof(void *);
        compLclFrameSize += (compLocallocUsed + info.compXcptnsCount + 1) * sizeof(void *);
    }

    /*
        If we're supposed to track lifetimes of pointer temps, we'll
        assign frame offsets in the following order:

            non-pointer local variables (also untracked pointer variables)
                pointer local variables
                pointer temps
            non-pointer temps
     */

    bool    assignDone = false; // false in first pass, true in second
    bool    assignNptr = true;  // First pass,  assign offsets to non-ptr
    bool    assignPtrs = false; // Second pass, assign offsets to tracked ptrs
    bool    assignMore = false; // Are there any tracked ptrs (else 2nd pass not needed)

    /* We will use just one pass, and assign offsets to all variables */

    if  (opts.compDbgEnC)
        assignPtrs = true;

AGAIN1:

#if ASSIGN_FRAME_OFFSETS_BY_REFCNT
    for (refNum = 0, refTab = lvaRefSorted;
         refNum < lvaCount;
         refNum++  , refTab++)
    {
        assert(!opts.compDbgEnC); // For EnC, vars have to be assigned as they appear in the locals-sig
        varDsc = *refTab;
#else
    for (lclNum = 0, varDsc = lvaTable;
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
#endif

        /* Ignore variables that are not on the stack frame */

        if  (!varDsc->lvOnFrame)
        {
            /* For EnC, all variables have to be allocated space on the
               stack, even though they may actually be enregistered. This
               way, the frame layout can be directly inferred from the
               locals-sig.
             */

            if(!opts.compDbgEnC)
                continue;
            else if (lclNum >= info.compLocalsCount) // ignore temps for EnC
                continue;
        }

        if  (varDsc->lvIsParam)
        {
#if USE_FASTCALL
            /*  A register argument that is not enregistred ends up as
                a local variable which will need stack frame space,
             */

            if  (!varDsc->lvIsRegArg)
#endif
                continue;
        }

        /* Make sure the type is appropriate */

        if  (varTypeIsGC(varDsc->TypeGet()) && varDsc->lvTracked)
        {
            if  (!assignPtrs)
            {
                assignMore = true;
                continue;
            }
        }
        else
        {
            if  (!assignNptr)
            {
                assignMore = true;
                continue;
            }
        }

#if TGT_x86

        if  (!genFPused)
        {

#if DOUBLE_ALIGN

            /* Need to align the offset? */

            if (genDoubleAlign && varDsc->lvType == TYP_DOUBLE)
            {
                assert((compLclFrameSize & 3) == 0);

                /* This makes the offset of the double divisible by 8 */

                compLclFrameSize += (compLclFrameSize & 4);
            }
#endif

            /* The stack offset is positive relative to ESP */

            varDsc->lvStkOffs = +(int)compLclFrameSize + calleeSavedRegsSize;
        }

#else // not TGT_x86

        // RISC target

        /* Just save the offset, we'll figure out the rest later */

        varDsc->lvStkOffs = compLclFrameSize;

#endif // not TGT_x86

        /* Reserve the stack space for this variable */

        compLclFrameSize += lvaLclSize(lclNum);
        assert(compLclFrameSize % sizeof(int) == 0);

#if TGT_x86

        /* Record the stack offset */

        if  (genFPused)
        {
            /* The stack offset is negative relative to EBP */

            varDsc->lvStkOffs = -(int)compLclFrameSize;
        }

#ifdef  DEBUG
        if  (final && verbose)
        {
            var_types lclGCtype = TYP_VOID;

            if  (varTypeIsGC(varDsc->TypeGet()) && varDsc->lvTracked)
                lclGCtype = varDsc->TypeGet();

            printf("%s-ptr local #%3u located at %s offset ",
                varTypeGCstring(lclGCtype), lclNum, varDsc->lvFPbased ? fprName
                                                                      : sprName);
            if  (varDsc->lvStkOffs)
                printf(varDsc->lvStkOffs < 0 ? "-" : "+");
            else
                printf(" ");

            printf("0x%04X (size=%u)\n", abs(varDsc->lvStkOffs), lvaLclSize(lclNum));
        }
#endif

#endif // TGT_x86

    }

    /* If we've only assigned one type, go back and do the others now */

    if  (!assignDone && assignMore)
    {
        assignNptr = !assignNptr;
        assignPtrs = !assignPtrs;
        assignDone = true;

        goto AGAIN1;
    }

    /*-------------------------------------------------------------------------
     *
     * Now the temps
     *
     *-------------------------------------------------------------------------
     */

#if TGT_RISC
    assert(!"temp allocation NYI for RISC");
#endif

    size_t  tempsSize = 0;  // total size of all the temps

    /* Allocate temps */

    assignPtrs = true;

    if  (TRACK_GC_TEMP_LIFETIMES)
    {
         /* first pointers, then non-pointers in second pass */
        assignNptr = false;
        assignDone = false;
    }
    else
    {
        /* Pointers and non-pointers together in single pass */
        assignNptr = true;
        assignDone = true;
    }

AGAIN2:

    for (TempDsc * temp = tmpListBeg();
         temp;
         temp = tmpListNxt(temp))
    {
        size_t          size;

        /* Make sure the type is appropriate */

        if  (!assignPtrs &&  varTypeIsGC(temp->tdTempType()))
            continue;
        if  (!assignNptr && !varTypeIsGC(temp->tdTempType()))
            continue;

        size = temp->tdTempSize();

        tempsSize += size;

        /* Figure out and record the stack offset of the temp */

        if  (genFPused)
        {
            /* The stack offset is negative relative to EBP */

                                 compLclFrameSize += size;
            temp->tdOffs = -(int)compLclFrameSize;
        }
        else
        {
            /* The stack offset is positive relative to ESP */

#if TGT_x86
            temp->tdOffs =       compLclFrameSize + calleeSavedRegsSize;
                                 compLclFrameSize += size;
#else
            UNIMPL("stack offsets");
#endif
        }

#ifdef  DEBUG
#ifndef NOT_JITC
        if  (final&&(verbose||0))
        {
            const   char *  frmReg = fprName;

            if  (!genFPused)
                frmReg = sprName;

            printf("%s-ptr temp  #%3u located at %s offset ",
                varTypeGCstring(temp->tdTempType()),
                abs(temp->tdTempNum()),
                frmReg);

            if  (temp->tdTempOffs())
                printf(temp->tdTempOffs() < 0 ? "-" : "+");
            else
                printf(" ");

            printf("0x%04X (size=%u)\n", abs(temp->tdTempOffs()), temp->tdTempSize());
        }
#endif
#endif

    }

    /* If we've only assigned some temps, go back and do the rest now */

    if  (!assignDone)
    {
        assignNptr = !assignNptr;
        assignPtrs = !assignPtrs;
        assignDone = true;

        goto AGAIN2;
    }

    /*-------------------------------------------------------------------------
     *
     * For frameless methods, patch the argument offsets
     *
     *-------------------------------------------------------------------------
     */

#if TGT_x86
     if (compLclFrameSize && !DOUBLE_ALIGN_NEED_EBPFRAME)
#else
#if DOUBLE_ALIGN
     if (compLclFrameSize && !genDoubleAlign)
#endif
#endif
    {
        /* Adjust the argument offsets by the size of the locals/temps */

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            if  (varDsc->lvIsParam)
            {
#if USE_FASTCALL
                if  (varDsc->lvIsRegArg)
                    continue;
#endif
                varDsc->lvStkOffs += (int)compLclFrameSize;
            }
        }
    }

    /*-------------------------------------------------------------------------
     *
     * Now do some final stuff
     *
     *-------------------------------------------------------------------------
     */

#if TGT_x86

     // Did we underestimate the size of the temps? This means that we might
     // have expected to use 1 byte for encoding some local offsets whereas
     // we acutally need a bigger offset. This means our estimation of
     // generated code size is not conservative. Refuse to JIT in such
     // cases
     // @TODO: Instead of refusing to JIT, restart JITing with a bigger
     // estimate for tempSize

    if (final)
    {
        bool goodEstimate = true; // assume we guessed correctly/conservatively

        if (!genFPused)
        {
            // The furthest (stack) argument has to be accessible.
            // We use compArgSize as an upper bound on the size of the stack
            // arguments. It is not strictly correct as it includes the sizes
            // of the register arguments.

            if (compFrameSizeEst                       + sizeof(void*) + compArgSize <= CHAR_MAX &&
                calleeSavedRegsSize + compLclFrameSize + sizeof(void*) + compArgSize >  CHAR_MAX)
                goodEstimate = false;
        }
        else
        {
            // The furthest local has to be accessible via FP

            if (compFrameSizeEst                       <= CHAR_MAX &&
                calleeSavedRegsSize + compLclFrameSize >  CHAR_MAX)
                goodEstimate = false;
        }

        if (!goodEstimate)
            NO_WAY("Underestimated size of temps");
    }

#endif


#if TGT_RISC && !TGT_IA64

    /* If we have to set up an FP frame, the FP->SP distance isn't known */

    assert(genFPused == false || genFPtoSP == 0);

    /*
        We can now figure out what base register (frame vs. stack
        pointer) each variable will be addressed off of, and what
        the final offset will be.

        We'll count how many variables are beyond "direct" reach
        from the stack pointer, and if there are many we'll try
        to set up an FP register even if we don't have to.
     */

    if  (!genFPused && !genFPcant)
    {
        /* We haven't decided to use FP but the option is still open */

        unsigned        varOffs;
        unsigned        minOffs = 0xFFFF;
        unsigned        loffCnt = 0;

        /* Count the references that are too far from SP */

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            /* Ignore variables that are not on the stack frame */

            if  (!varDsc->lvOnFrame)
                continue;

            assert(varDsc->lvFPbased == false);

            /* Get hold of the SP offset of this variable */

            varOffs = varDsc->lvStkOffs; assert((int)varOffs >= 0);

            /* Is the offset of this variable very large? */

            if  (varOffs > MAX_SPBASE_OFFS)
            {
                loffCnt += varDsc->lvRefCnt;

                /* Keep track of the closest variable above the limit */

                if  (minOffs > varOffs)
                     minOffs = varOffs;
            }
        }

        if  (loffCnt > 8)       // arbitrary heuristic
        {
            /*
                The variables whose offset is less than or equal to
                MAX_SPBASE_OFFS will be addressed off of SP, others
                will be addressed off of FP (which will be set to
                the value "SP + minOffs".
             */

            genFPused = true;

            /* The value "minOffs" becomes the distance from SP to FP */

            genFPtoSP = minOffs;

            assert(minOffs < compLclFrameSize);
            assert(minOffs > MAX_SPBASE_OFFS);

            /* Mark all variables with high offsets to be FP-relative */

            for (lclNum = 0, varDsc = lvaTable;
                 lclNum < lvaCount;
                 lclNum++  , varDsc++)
            {
                /* Ignore variables that are not on the stack frame */

                if  (!varDsc->lvOnFrame)
                    continue;

                assert(varDsc->lvFPbased == false);

                /* Get hold of the SP offset of this variable */

                varOffs = varDsc->lvStkOffs; assert((int)varOffs >= 0);

                /* Is the offset of this variable very large? */

                if  (varOffs > MAX_SPBASE_OFFS)
                {
                    assert(varOffs >= minOffs);

                    /* This variable will live off of SP */

                    varDsc->lvFPbased = true;
                    varDsc->lvStkOffs = varOffs - minOffs;
                }
            }
        }
    }

#endif // TGT_RISC

    /*-------------------------------------------------------------------------
     *
     * Debug output
     *
     *-------------------------------------------------------------------------
     */

#ifdef  DEBUG
#ifndef NOT_JITC

    if  (final&&verbose)
    {
        const   char *  fprName;
        const   char *  sprName;

#if     TGT_x86
        fprName = "EBP";
        sprName = "ESP";
#elif   TGT_SH3
        fprName =  "fp";
        sprName =  "sp";
#elif   TGT_IA64
        fprName = "r32";
        sprName =  "sp";
#else
#error  Unexpected target
#endif

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            unsigned        sp = 16;

            const   char *  baseReg;

            if  (varDsc->lvIsParam)
            {
                printf("          arg ");
            }
            else
            {
                var_types lclGCtype = TYP_VOID;

                if  (varTypeIsGC(varDsc->TypeGet()) && varDsc->lvTracked)
                    lclGCtype = varDsc->TypeGet();

                printf("%s-ptr lcl ", varTypeGCstring(lclGCtype));
            }

            baseReg = varDsc->lvFPbased ? fprName : sprName;

            printf("#%3u located ", lclNum);

            /* Keep track of the number of characters printed */

            sp = 20;

            if  (varDsc->lvRegister)
            {
                const   char *  reg;

                sp -= printf("in ");

#if!TGT_IA64

                if  (isRegPairType((var_types)varDsc->lvType))
                {
                    if  (varDsc->lvOtherReg == REG_STK)
                    {
                        sp -= printf("[%s", baseReg);

                        if  (varDsc->lvStkOffs)
                        {
                            sp -= printf("%c0x%04X]", varDsc->lvStkOffs < 0 ? '-'
                                                                            : '+',
                                                      abs(varDsc->lvStkOffs));
                        }
                        else
                            sp -= printf("       ]");
                    }
                    else
                    {
                        reg = getRegName(varDsc->lvOtherReg);
                        sp -= printf("%s", reg);
                    }

                    sp -= printf(":");
                }

#endif

                reg = getRegName(varDsc->lvRegNum);
                sp -= printf("%s", reg);
            }
            else  if (varDsc->lvOnFrame)
            {
                sp -= printf("at [%s", baseReg);

                if  (varDsc->lvStkOffs)
                    sp -= printf(varDsc->lvStkOffs < 0 ? "-" : "+");
                else
                    sp -= printf(" ");

                sp -= printf("0x%04X]", abs(varDsc->lvStkOffs));
            }
            else
            {
                assert(varDsc->lvRefCnt == 0);
                sp -= printf("never used");
            }

            /* Pad to the desired fixed length */

            assert((int)sp >= 0);
            printf("%*c", -sp, ' ');

            printf(" (sz=%u)", genTypeSize((var_types)varDsc->lvType));
#if     ASSIGN_FRAME_OFFSETS_BY_REFCNT
            printf(" [refcnt=%04u]", varDsc->lvRefCntWtd);
#endif
            printf("\n");
        }
    }

#endif
#endif

}

/*****************************************************************************
 *
 *  Conservatively estimate the layout of the stack frame.
 */

size_t              Compiler::lvaFrameSize()
{

#if TGT_x86

    /* Layout the stack frame conservatively.
       Assume all callee-saved registers are spilled to stack */

    compCalleeRegsPushed = CALLEE_SAVED_REG_MAXSZ/sizeof(int);

    lvaAssignFrameOffsets(false);

    return  compLclFrameSize + CALLEE_SAVED_REG_MAXSZ;

#else

    lvaAssignFrameOffsets(true);

    return  compLclFrameSize;

#endif

}

/*****************************************************************************/
#endif//!TGT_IA64
/*****************************************************************************
 *
 *  Mark any variables currently live (as per 'life') as interfering with
 *  the variable specified by 'varIndex' and 'varBit'.
 */

void                Compiler::lvaMarkIntf(VARSET_TP life, VARSET_TP varBit)
{
    unsigned        refIndex;

    assert(opts.compMinOptim==false);

//  printf("Add interference: %08X and #%2u [%08X]\n", life, varIndex, varBit);

    // ISSUE: would using findLowestBit() here help?

    for (refIndex = 0;
         life > 0;
         refIndex++ , life >>= 1)
    {
        assert(varBit <= genVarIndexToBit(lvaTrackedCount-1) * 2 - 1);

        if  (life & 1)
            lvaVarIntf[refIndex] |= varBit;
    }
}

/*****************************************************************************/
#if 0
/*****************************************************************************
 *
 *  Based on variable interference levels computed earlier, adjust reference
 *  counts for all variables. The idea is that any variable that interferes
 *  with lots of other variables will cost more to enregister, and this way
 *  variables with e.g. short lifetimes (such as compiler temps) will have
 *  precedence over long-lived variables.
 */

inline
int                 genAdjRefCnt(unsigned refCnt, unsigned refLo,
                                                  unsigned refHi,
                                 unsigned intCnt, unsigned intLo,
                                                  unsigned intHi)
{
    /*
        multiplier        total size

           0.0             803334
           0.1             803825
           0.2             803908
           0.3             803959
           0.5             804205
           0.7             804736
           1.0             806632
     */

#if 0
    printf("ref=%4u [%04u..%04u] , int=%04u [%04u..%04u]",
            refCnt, refLo, refHi,
            intCnt, intLo, intHi);

    printf(" ratio=%lf , log = %lf\n", intCnt/(double)intHi,
                                       log(1+intCnt/(double)intHi));
#endif

    return  (int)(refCnt * (1 - 0.1 * log(1 + intCnt / (double)intHi)  ));
}

void                Compiler::lvaAdjustRefCnts()
{
    LclVarDsc   *   v1Dsc;
    unsigned        v1Num;

    LclVarDsc   *   v2Dsc;
    unsigned        v2Num;

    unsigned        refHi;
    unsigned        refLo;

    unsigned        intHi;
    unsigned        intLo;

    if  ((opts.compFlags & CLFLG_MAXOPT) != CLFLG_MAXOPT)
        return;

    /* Compute interference counts for all live variables */

    for (v1Num = 0, v1Dsc = lvaTable, refHi = 0, refLo = UINT_MAX;
         v1Num < lvaCount;
         v1Num++  , v1Dsc++)
    {
        VARSET_TP   intf;

        if  (!v1Dsc->lvTracked)
            continue;

        /* Figure out the range of ref counts */

        if  (refHi < v1Dsc->lvRefCntWtd)
             refHi = v1Dsc->lvRefCntWtd;
        if  (refLo > v1Dsc->lvRefCntWtd)
             refLo = v1Dsc->lvRefCntWtd;

        /* Now see what variables we interfere with */

        intf = lvaVarIntf[v1Dsc->lvVarIndex];

        for (v2Num = 0, v2Dsc = lvaTable;
             v2Num < v1Num;
             v2Num++  , v2Dsc++)
        {
            if  (!v2Dsc->lvTracked)
                continue;

            if  (intf & genVarIndexToBit(v2Dsc->lvVarIndex))
                v1Dsc->lvIntCnt += v2Dsc->lvRefCntWtd;
        }
    }

    refHi -= refLo;

    /* Figure out the range of int counts */

    for (v1Num = 0, v1Dsc = lvaTable, intHi = 0, intLo = UINT_MAX;
         v1Num < lvaCount;
         v1Num++  , v1Dsc++)
    {
        if  (v1Dsc->lvTracked)
        {
            if  (intHi < v1Dsc->lvIntCnt)
                 intHi = v1Dsc->lvIntCnt;
            if  (intLo > v1Dsc->lvIntCnt)
                 intLo = v1Dsc->lvIntCnt;
        }
    }

    /* Now compute the adjusted ref counts */

    for (v1Num = 0, v1Dsc = lvaTable;
         v1Num < lvaCount;
         v1Num++  , v1Dsc++)
    {
        if  (v1Dsc->lvTracked)
        {
            long        refs = genAdjRefCnt(v1Dsc->lvRefCntWtd,
                                            refLo,
                                            refHi,
                                            v1Dsc->lvIntCnt,
                                            intLo,
                                            intHi);

            if  (refs <= 0)
                refs = 1;

#ifdef DEBUG
            if  (verbose)
            {
                printf("Var #%02u ref=%4u [%04u..%04u] , int=%04u [%04u..%04u] ==> %4u\n",
                        v1Num,
                        v1Dsc->lvRefCntWtd,
                        refLo,
                        refHi,
                        v1Dsc->lvIntCnt,
                        intLo,
                        intHi,
                        refs);
            }
#endif

            v1Dsc->lvRefCntWtd = refs;
        }
    }

    /* Re-sort the variable table by ref-count */

    qsort(lvaRefSorted, lvaCount, sizeof(*lvaRefSorted), RefCntCmp);
}

#endif
/*****************************************************************************
 *
 *  A little routine that displays a local variable bitset.
 */

#ifdef  DEBUG

void                Compiler::lvaDispVarSet(VARSET_TP set, int col)
{
    unsigned        bit;

    printf("{");

    for (bit = 0; bit < VARSET_SZ; bit++)
    {
        if  (set & genVarIndexToBit(bit))
        {
            unsigned        lclNum;
            LclVarDsc   *   varDsc;

            /* Look for the matching variable */

            for (lclNum = 0, varDsc = lvaTable;
                 lclNum < lvaCount;
                 lclNum++  , varDsc++)
            {
                if  ((varDsc->lvVarIndex == bit) && varDsc->lvTracked)
                    break;
            }

            printf("%2u ", lclNum);
            col -= 3;
        }
    }

    while (col-- > 0) printf(" ");

    printf("}");
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\opcode.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                             opcodes.h                                     XX  
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

/*****************************************************************************/
#ifndef _OPCODE_H_
#define _OPCODE_H_

#define OLD_OPCODE_FORMAT 0			// Please remove after 7/1/99

#include "openum.h"

extern signed char      opcodeSizes     [];


#if COUNT_OPCODES || defined(DEBUG)
extern const char *     opcodeNames     [];
#endif


#ifdef DUMPER
extern BYTE             opcodeArgKinds  [];
#endif


/*****************************************************************************/
#endif // _OPCODE_H_
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\loginstr.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef _LOGINSTR_H_
#define _LOGINSTR_H_
/*****************************************************************************/
#pragma pack(push, 8)
/*****************************************************************************/
#pragma warning(disable:4200)
/*****************************************************************************/

enum IA64funcUnits
{
    #define FU_DEF(name,F0,I0,M0)   FU_##name,
    #include "fclsIA64.h"

    FU_COUNT
};

/*****************************************************************************
 *
 *  The following temporarily moved here from instr.h (for quicker rebuilds).
 */

enum instruction
{
    #define INST1(id, sn, ik    , rf, wf, xu, fu, ex, ev) INS_##id,
    #include "instrIA64.h"
    #undef  INST1

    INS_count
};

/*****************************************************************************/

enum insKinds
{
    IK_NONE,

    IK_LEAF,                                    // no further contents
    IK_CONST,                                   // integer/float constant
    IK_GLOB,                                    // variable (global)
    IK_FVAR,                                    // variable (stack frame)
    IK_VAR,                                     // variable (local)
    IK_REG,                                     // physical register
    IK_MOVIP,                                   // move from IP reg

    IK_ARG,                                     // argument value
    IK_UNOP,                                    //  unary  op: qOp1      present
    IK_BINOP,                                   // binary  op: qOp1,qOp2 present
    IK_ASSIGN,                                  // assignment
    IK_TERNARY,                                 // ternary op: qOp1,qOp2,qOp3

    IK_COMP,                                    // comparison (sets predicate regs)

    IK_JUMP,                                    // local jump (i.e. to another ins)
    IK_CALL,                                    // function call
    IK_IJMP,                                    // indirect jump

    IK_SWITCH,                                  // table jump

    IK_PROLOG,                                  // function prolog / alloc
    IK_EPILOG,                                  // function prolog / alloc

    IK_SRCLINE,                                 // source line# entry
};

extern  unsigned char   ins2kindTab[INS_count];

inline  insKinds     ins2kind(instruction ins)
{
    assert((unsigned)ins < INS_count); return (insKinds)ins2kindTab[ins];
}

#ifdef  DEBUG

extern  const char *    ins2nameTab[INS_count];

inline  const char *    ins2name(instruction ins)
{
    assert((unsigned)ins < INS_count); return           ins2nameTab[ins];
}

#endif

/*****************************************************************************
 *
 *  The following is used to capture the dependencies of each instruction,
 *  both inputs and outputs.
 */

enum   insDepKinds
{
    IDK_NONE,

    IDK_REG_BR,
    IDK_REG_INT,
    IDK_REG_FLT,
    IDK_REG_APP,
    IDK_REG_PRED,

    IDK_LCLVAR,

    IDK_TMP_INT,
    IDK_TMP_FLT,

    IDK_IND,

    IDK_COUNT
};

struct insDep
{
    NatUns              idepNum     :16;        // register or local variable number
    NatUns              idepKind    :8;         // see IDK_ enum values
};

/*****************************************************************************/

struct insDsc
{
    instruction         idInsGet() { return (instruction)idIns; }

#ifdef  FAST
    NatUns              idIns   :16;            // CPU instruction (see INS_xxx)
#else
    instruction         idIns;                  // CPU instruction (see INS_xxx)
#endif

    NatUns              idFlags :16;            // see IF_xxxx below

    NatUns              idTemp  :16;            // 0 or temp index of result

    var_types           idTypeGet() { return (var_types)idType; }

#ifdef  FAST
    NatUns              idKind  :3;             // ins kind (see IK_xxx)
    NatUns              idType  :5;             // operation type
#else
    insKinds            idKind;                 // ins kind (see IK_xxx)
    var_types           idType;                 // operation type
#endif

    NatUns              idReg   :REGNUM_BITS;   // register that holds result

    NatUns              idPred  :PRRNUM_BITS;   // non-zero if instruction predicated

#if TGT_IA64
    NatUns              idShift :3;             // optional shift count of op1
#endif

    NatUns              idSrcCnt:8;             // number of source dependencies
    NatUns              idDstCnt:8;             // number of dest.  dependencies

    insDep  *           idSrcTab;               // table  of source dependencies
    insDep  *           idDstTab;               // table  of dest.  dependencies

#ifdef  DEBUG
#define UNINIT_DEP_TAB  ((insDep*)-1)           // used to detect missing int
#endif

    insPtr              idRes;                  // result (target) or NULL

    insPtr              idPrev;
    insPtr              idNext;

#ifdef  DEBUG
    NatUns              idNum;                  // for friendly ins dumps
#endif

    union
    {
        struct  /* base -- empty */
        {
        }
                            idBase;

        struct /* unary/binary operator */
        {
            insPtr              iOp1;
            insPtr              iOp2;
        }
                            idOp;

        struct  /* local variable ref */
        {
            NatUns              iVar;
#ifdef  DEBUG
            BasicBlock *        iRef;           // which BB the ref was in
#endif
        }
                            idLcl;

        struct  /* global variable ref */
        {
            union
            {
                NatUns              iOffs;
                void    *           iImport;
            };
        }
                            idGlob;

        struct  /* frame  variable ref */
        {
            unsigned            iVnum;
        }
                            idFvar;

        union   /* integer/float constant */
        {
            __int64             iInt;
            double              iFlt;
        }
                            idConst;

        struct /* ternary operator */
        {
            insPtr              iOp1;
            insPtr              iOp2;
            insPtr              iOp3;
        }
                            idOp3;

        struct  /* comparison */
        {
            insPtr              iCmp1;
            insPtr              iCmp2;
            insPtr              iUser;          // consumer of predicates (?)
            unsigned short      iPredT;         // target predicate reg for true
            unsigned short      iPredF;         // target predicate reg for false
        }
                            idComp;

        struct  /* call */
        {
            insPtr              iArgs;          // backward list of arguments
            METHOD_HANDLE       iMethHnd;       // EE handle for method being called
            NatUns              iBrReg;         // used only for indirect calls
        }
                            idCall;

        struct  /* mov reg=IP */
        {
            BasicBlock  *       iStmt;
        }
                            idMovIP;

        struct  /* ijmp */
        {
            NatUns              iBrReg;         // branch register used
//          BasicBlock  *       iStmt;
        }
                            idIjmp;

        struct  /* argument of a call */
        {
            insPtr              iVal;           // instructions for the arg value
            insPtr              iPrev;          // arguments are linked backwards
        }
                            idArg;

        struct  /* function prolog / alloc */
        {
            unsigned char       iInp;
            unsigned char       iLcl;
            unsigned char       iOut;
            unsigned char       iRot;
        }
                            idProlog;

        struct  /* function epilog */
        {
            insPtr              iNxtX;          // all exits are linked together
            insBlk              iBlk;           // instruction block we belong to
        }
                            idEpilog;

        struct  /* local jump */
        {
            VARSET_TP           iLife;          // life after jump
            insPtr              iCond;          // non-NULL if conditional jump
            insBlk              iDest;          // destination
        }
                            idJump;

        struct  /* source line */
        {
            NatUns              iLine;
        }
                            idSrcln;
    };
};

const   size_t  ins_size_base    = (offsetof(insDsc, idBase  ));

const   size_t  ins_size_op      = (size2mem(insDsc, idOp    ));
const   size_t  ins_size_op3     = (size2mem(insDsc, idOp3   ));
const   size_t  ins_size_reg     = ins_size_base;
const   size_t  ins_size_arg     = (size2mem(insDsc, idArg   ));
const   size_t  ins_size_var     = (size2mem(insDsc, idLcl   ));
const   size_t  ins_size_glob    = (size2mem(insDsc, idGlob  ));
const   size_t  ins_size_fvar    = (size2mem(insDsc, idFvar  ));
const   size_t  ins_size_comp    = (size2mem(insDsc, idComp  ));
const   size_t  ins_size_call    = (size2mem(insDsc, idCall  ));
const   size_t  ins_size_jump    = (size2mem(insDsc, idJump  ));
const   size_t  ins_size_ijmp    = (size2mem(insDsc, idIjmp  ));
const   size_t  ins_size_movip   = (size2mem(insDsc, idMovIP ));
const   size_t  ins_size_const   = (size2mem(insDsc, idConst ));
const   size_t  ins_size_prolog  = (size2mem(insDsc, idProlog));
const   size_t  ins_size_epilog  = (size2mem(insDsc, idEpilog));
const   size_t  ins_size_srcline = (size2mem(insDsc, idSrcln ));

/*****************************************************************************/

enum insFlags
{
    IF_NO_CODE      = 0x0001,                   // doesn't generate code itself?

    IF_ASG_TGT      = 0x0002,                   // target of an assignment?

    IF_FNDESCR      = 0x0004,                   // needs to be in func descriptor

    IF_NOTE_EMIT    = 0x0008,                   // special handling needed in emitter

    // The following flags are specific to a particular set of inss;
    // thus, extreme caution must be used when setting/testing them!

    IF_VAR_BIRTH    = 0x0080,                   // variable born here ?
    IF_VAR_DEATH    = 0x0040,                   // variable dies here ?

    IF_CMP_UNS      = 0x0080,                   // unsigned compare?

    IF_LDIND_NTA    = 0x0080,                   // add ".nta"

    IF_GLB_IMPORT   = 0x0080,                   // global is an IAT entry
    IF_GLB_SWTTAB   = 0x0040,                   // global is a switch offset table

    IF_REG_GPSAVE   = 0x0080,                   // register is "GP save"

    IF_FMA_S1       = 0x0080,                   // set "s1" in fma instruction

    IF_BR_DPNT      = 0x0080,                   // .dpnt instead of .spnt
    IF_BR_FEW       = 0x0040,                   // .few  instead of .many
};

/*****************************************************************************/

struct insGrp;

/*****************************************************************************/
#pragma pack(pop)
/*****************************************************************************
 *
 *  Declare the IA64 template table.
 */

struct  templateDsc
{
    NatUns          tdNum   :8; // 0 or template encoding number + 1
    NatUns          tdIxu   :8; // execution unit
    NatUns          tdSwap  :1; // last two instructions should be swapped ?

    templateDsc *   tdNext[];   // NULL-terminated table of slots that follow
};

/*****************************************************************************/
#if     SCHEDULER
/*****************************************************************************
 *
 *  When we issue IA64 instructions we need to take into account the template
 *  we're using, as well as any instructions we may have issued already. The
 *  following holds the current IA64 instruction issue state.
 */

struct  scIssueDsc
{
    insPtr          iidIns;                     // instruction in this slot
};

#define MAX_ISSUE_CNT   6                       // for Merced track 2 full bundles

/*****************************************************************************
 *
 *  HACK - this should be shared with the non-IA64 emitter.
 */

enum emitAttr
{
    EA_1BYTE         = 0x001,
    EA_2BYTE         = 0x002,
    EA_4BYTE         = 0x004,
    EA_8BYTE         = 0x008,

#if 0
    EA_OFFSET_FLG    = 0x010,
    EA_OFFSET        = 0x014,       /* size ==  0 */
    EA_GCREF_FLG     = 0x020,
    EA_GCREF         = 0x024,       /* size == -1 */
    EA_BYREF_FLG     = 0x040,
    EA_BYREF         = 0x044,       /* size == -2 */
#endif

};

/*****************************************************************************/

typedef insDsc      instrDesc;
typedef insGrp      insGroup;

typedef regNumber   emitRegs;

#include "emit.h"

class   emitter
{
    Compiler *      emitComp;

public:
    void            scInit(Compiler *comp, NatUns maxScdCnt)
    {
        emitComp        = comp;

        emitMaxIGscdCnt = (maxScdCnt < SCHED_INS_CNT_MAX) ? maxScdCnt
                                                          : SCHED_INS_CNT_MAX;
    }

    void    *       emitGetAnyMem(size_t sz)
    {
        return  emitGetMem(sz);
    }

    inline
    void    *       emitGetMem(size_t sz)
    {
        assert(sz % sizeof(int) == 0);
        return  emitComp->compGetMem(sz);
    }

    unsigned        emitMaxIGscdCnt;        // max. schedulable instructions

//  size_t          emitIssue1Instr(insGroup *ig, instrDesc *id, BYTE **dp);

#ifdef  DEBUG

    const   char *  emitRegName(regNumber reg);

    void            emitDispIns(instrDesc *id, bool isNew,
                                               bool doffs,
                                               bool asmfm, unsigned offs = 0);

#endif

    static
    BYTE            emitSizeEnc[];
    static
    BYTE            emitSizeDec[];

    static
    unsigned        emitEncodeSize(emitAttr size);
    static
    emitAttr        emitDecodeSize(unsigned ensz);

    #include "sched.h"

static
void                scDepDefRegBR  (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepDefReg    (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepDefRegApp (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepDefRegPred(emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepDefLclVar (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepDefTmpInt (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepDefTmpFlt (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepDefInd    (emitter*,scDagNode*,instrDesc*,NatUns);

static
void                scUpdDefRegBR  (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdDefReg    (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdDefRegApp (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdDefRegPred(emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdDefLclVar (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdDefTmpInt (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdDefTmpFlt (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdDefInd    (emitter*,scDagNode*,instrDesc*,NatUns);

static
void                scDepUseRegBR  (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepUseReg    (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepUseRegApp (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepUseRegPred(emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepUseLclVar (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepUseTmpInt (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepUseTmpFlt (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scDepUseInd    (emitter*,scDagNode*,instrDesc*,NatUns);

static
void                scUpdUseRegBR  (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdUseReg    (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdUseRegApp (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdUseRegPred(emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdUseLclVar (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdUseTmpInt (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdUseTmpFlt (emitter*,scDagNode*,instrDesc*,NatUns);
static
void                scUpdUseInd    (emitter*,scDagNode*,instrDesc*,NatUns);

    static
    void          (*scDepDefTab[IDK_COUNT])(emitter*,scDagNode*,instrDesc*,NatUns);
    static
    void          (*scUpdDefTab[IDK_COUNT])(emitter*,scDagNode*,instrDesc*,NatUns);
    static
    void          (*scDepUseTab[IDK_COUNT])(emitter*,scDagNode*,instrDesc*,NatUns);
    static
    void          (*scUpdUseTab[IDK_COUNT])(emitter*,scDagNode*,instrDesc*,NatUns);

    void            scIssueBunch();

    void            scBlock(insBlk block);
    void            scRecordInsDeps(instrDesc *id, scDagNode *dag);
};

typedef emitter     IA64sched;

#include "emitInl.h"

/*****************************************************************************/
#endif//SCHEDULER
/*****************************************************************************
 *
 *  Obviously, the following belongs in compiler.h or some such place.
 */

extern
insPtr          scIA64nopTab[XU_COUNT];

inline
insPtr          scIA64nopGet(IA64execUnits xu)
{
    assert(xu < XU_COUNT); return scIA64nopTab[xu];
}

/*****************************************************************************/

#ifndef _BITVECT_H_
#include "bitvect.h"
#endif

/*****************************************************************************/

struct insGrp
{
    _uint32         igNum;

    __int32         igOffs;                     // offset (-1 if code not yet emitted)

    insBlk          igNext;                     // next block in flowgraph

#ifdef  DEBUG
    insBlk          igSelf;                     // to guard against bogus pointers
#endif

    _uint32         igInsCnt;                   // instruction count

    _uint32         igWeight;                   // loop-weighting heuristic

    unsigned short  igPredCnt;                  // count of predecessors
    unsigned short  igSuccCnt;                  // count of successors

    unsigned short  igPredTmp;                  // count of predecessors (temp)
    unsigned short  igSuccTmp;                  // count of successors   (temp)

    insBlk  *       igPredTab;                  // table of predecessors
    insBlk  *       igSuccTab;                  // table of successors

    insPtr          igList;                     // instruction list head
    insPtr          igLast;                     // instruction list tail

    bitVectBlks     igDominates;                // set of blocks this one dominates

    bitVectVars     igVarDef;                   // set of variables block defines
    bitVectVars     igVarUse;                   // set of variables block uses

    bitVectVars     igVarLiveIn;                // set of variables live on entry
    bitVectVars     igVarLiveOut;               // set of variables live on exit
};

/*****************************************************************************/
#endif//_LOGINSTR_H_
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\main.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                          main.cpp                                         XX
XX                                                                           XX
XX   For the standalone EXE.                                                 XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

#include <io.h>                 // For     _finddata_t     ffData;

#include <winwrap.h>
#include "CorPerm.h"

#undef  NO_WAY
#define NO_WAY(str)  {   fatal(ERRinternal, str, "");  }

/*****************************************************************************/
#pragma warning(disable:4200)           // allow arrays of 0 size inside structs
/*****************************************************************************/

unsigned    warnLvl        = 2;

#ifdef  DEBUG
bool        memChecks      = false; // FOR_JVC
bool        dumpTrees      = false;
const char* srcPath        = 0;     // path for source files
#endif

bool        regSwitch      = false; // for additional switches set in the registry
const char* methodName     = NULL;  // compile only method(s) with this name
const char* className      = NULL;  // compile only class(es) with this name

bool        verbose        = false;
unsigned    testMask       = 0;

bool        genOrder       =  true;
bool        genClinit      =  true;
unsigned    genMinSz       = 0;
bool        genAllSz       = false;
bool        native         =  true;
#if     TGT_IA64
bool        maxOpts        = false;
#else
bool        maxOpts        =  true;
#endif
bool        genFPopt       =  true;
#if     TGT_RISC
bool        rngCheck       = false; // disable range checking on RISC for now
#else
bool        rngCheck       =  true;
#endif
bool        goSpeed        =  true;
bool        savCode        =  true;
bool        runCode        = false;
unsigned    repCode        = 0;
bool        vmSdk3_0       = false;
#if     SCHEDULER
#if     TGT_x86 || TGT_IA64
bool        schedCode      =  true;
#else
bool        schedCode      = false;
#endif
#endif
#if     TGT_x86
bool        genStringObjects=  true;
#else
bool        genStringObjects= false;
#endif

bool        riscCode       =  true;
bool        disAsm         = false;
bool        disAsm2        = false;
unsigned    genCPU         = 5;
#if     INLINING
bool        genInline      = false;
#endif
#ifdef  DEBUG
bool        dspILopcodes   = false;
bool        dspEmit        = false;
bool        dspCode        = false;
bool        dspLines       = false;
bool        varNames       = false;
bool        dmpHex         = false;
double      CGknob         = 0.0;
#endif // DEBUG
#if     DUMP_INFOHDR
bool        dspInfoHdr     = false;
#endif
#if     DUMP_GC_TABLES
bool        dspGCtbls      = false;
bool        dspGCoffs      =  true;
#endif
bool        genGcChk       = false;
#ifdef  DEBUGGING_SUPPORT
bool        debugInfo      = false;
bool        debuggableCode = false;
bool        debugEnC       = false;
#endif
#if     TGT_IA64
bool        tempAlloc      = false;
bool        dspAsmCode     = false;
#endif

#ifdef  DUMPER
bool        dmpClass       = false;
bool        dmp4diff       = false;
bool        dmpPCofs       = false;
bool        dmpCodes       =  true;
bool        dmpSort        =  true;
#endif // DUMPER

bool        nothing        = false;

const char * jitDefaultFileExt = ".exe";

/*****************************************************************************/
#if COUNT_CYCLES
/*****************************************************************************/

#pragma warning(disable:4035)

#define CCNT_OVERHEAD64 13

static
__int64         GetCycleCount64()
{
__asm   _emit   0x0F
__asm   _emit   0x31
};

#define CCNT_OVERHEAD32 13

static
unsigned        GetCycleCount32()        // enough for about 40 seconds
{
__asm   push    EDX
__asm   _emit   0x0F
__asm   _emit   0x31
__asm   pop     EDX
};

#pragma warning(default:4035)

/*---------------------------------------------------------------------------*/

static
__int64         cycleBegin;

static
__int64         cycleTotal;

static
__int64         cycleStart;

static
unsigned        cyclePause;

static
void            cycleCounterInit()
{
    cycleBegin = GetCycleCount64();
    cycleTotal = 0;
    cycleStart = 0;
    cyclePause = 0;
}

static
__int64         cycleCounterDone(__int64 *realPtr)
{
    assert(cyclePause == 0);

    *realPtr = GetCycleCount64() - cycleBegin;

    return cycleTotal;
}

void            cycleCounterBeg()
{
    assert(cyclePause == 0);

    cycleStart = GetCycleCount64();
}

void            cycleCounterEnd()
{
    assert(cycleStart != 0);
    assert(cyclePause == 0);

    cycleTotal += GetCycleCount64() - cycleStart;

    cycleStart  = 0;
}

void            cycleCounterPause()
{
    assert(cycleStart != 0);

    if  (!cyclePause)
        cycleTotal += GetCycleCount64() - cycleStart;

    cyclePause++;
}

void            cycleCounterResume()
{
    assert(cycleStart != 0);
    assert(cyclePause != 0);

    if  (--cyclePause)
        return;

    cycleStart = GetCycleCount64();
}

/*****************************************************************************/
#endif

/*****************************************************************************
 * The following are stubs/copies of implementaion needed as we dont link
 * in all of mscoree.lib.
 * @TODO : Clean this up once the meta-data can be accessed more cleanly
 * by linking in just a few libs. Right now, we need to link in
 * Meta.lib StgDb.lib MsCorClb.lib Reg.lib besides the following stubs
 */

HRESULT                 ExportTypeLibFromModule(LPCWSTR a, LPCWSTR b, int bRegister) // VM\TlbExport.cpp
{   assert(!"Place-holder - Shouldnt be called"); return 0; }


HINSTANCE               GetModuleInst()                     // pagedump.cpp
{   assert(!"Place-holder - Shouldnt be called"); return 0;    }

/*****************************************************************************/

// The EE has a function named COMStartup, and we need one too for JPS
HRESULT g_ComInit = E_FAIL;

HRESULT COMStartup()
{
    if (FAILED(g_ComInit))
    {
        g_ComInit = CoInitialize(NULL);
    }

    return g_ComInit;
}

void COMShutdown()
{
    if (SUCCEEDED(g_ComInit))
    {
        CoUninitialize();
        g_ComInit = E_FAIL;
    }
}

/*****************************************************************************/
#if TGT_IA64

typedef
struct  fnNmDesc *  fnNmList;
struct  fnNmDesc
{
    fnNmList            fndNext;
    char                fndName[];
};

static
fnNmList            genFuncNameList;

static
void                genRecordFuncName(const char *name)
{
    size_t          nlen;
    fnNmList        desc;

    nlen = strlen(name) + 1;

    if  (nlen > 12 && !memcmp(name, "Globals.", 8))
    {
        name += 8;
        nlen -= 8;
    }

    desc          = (fnNmList)malloc(sizeof(*desc) + nlen);

    desc->fndNext = genFuncNameList;
                    genFuncNameList = desc;

    memcpy(desc->fndName, name, nlen);
}

bool                Compiler::genWillCompileFunction(const char *name)
{
    fnNmList        desc;

    const   char *  dpos;
    size_t          dch1;

    dpos = strstr(name, ", ...");
    if  (dpos)
        dch1 = dpos - name;

    for (desc = genFuncNameList; desc; desc = desc->fndNext)
    {
        const   char *  mnam = desc->fndName;

        if  (!strcmp(mnam, name))
            return  true;

        if  (dpos)
        {
            const   char *  mdot = strstr(mnam, ", ...");

            if  (mdot)
            {
                size_t          dch2 = min((size_t)(mdot - mnam), dch1);

                if  (!memcmp(mnam, name, dch2))
                    return  true;
            }
        }
    }

    return  false;
}

#endif
/******************************************************************************
 * Given a method descriptor and meta data, JIT it
 * funcName, cls, and mb will be 0 for global functions
 * If we want to JIT a single method (methodName != NULL), return TRUE
 * if this was the method we wanted.
 */

int  generateCodeForFunc(const char *           fileName,
                         PEFile *               peFile,
                         IMDInternalImport *    metaData,
                         COR_ILMETHOD *         ilMethod,
                         PCCOR_SIGNATURE        corSig,
                         mdTypeDef              cls,
                         mdMethodDef            mb,
                         DWORD                  attrs,
                         DWORD                  implflags,
                         LPCSTR                 funcName,
                         LPCSTR                 className,
                         bool                   forReal)
{
    assert (peFile && metaData);

    COR_ILMETHOD_DECODER header(ilMethod, metaData);

    /* Optionally compile one method only */

    if  (methodName && strcmp(methodName, funcName)) return FALSE;

    // get the signatures

    MetaSig         metaSig(corSig, NULL);

    // Stuff all the method info in a CompInfo

    CompInfo        method(peFile, metaData,
                            &header, cls, mb,
                            attrs, implflags, funcName, className,
                            &metaSig, corSig);

#if 0   // doesn't compile - what's the deal here??

    // @todo: temporary. Take this out when the metadata methods exist
    // to create a scopeless interface from metadata internal.
    method.symDebugMeta = debugMeta;

#endif

    // Get the allocator

    norls_allocator * pAlloc = nraGetTheAllocator();
    if (!pAlloc) NO_WAY("Could not get the allocator");

#ifdef OPT_IL_JIT

    generateCodeForFunc(&method, ilMethod);

#else

    /* Figure out the appropriate compile flags */

    unsigned        compFlags = maxOpts ? CLFLG_MAXOPT : 0;

    if (!goSpeed)
        compFlags &= ~CLFLG_CODESPEED;

#ifdef  DEBUG
    if  (dspLines || varNames)
        compFlags |= CORJIT_FLG_DEBUG_INFO;
#endif

    // Allocate the Compiler object and initalize it.

    Compiler * pComp = (Compiler*) pAlloc->nraAlloc(roundUp(sizeof(*pComp)));

    pComp->compInit(pAlloc);

    void *  methodCode;
    void *  methodCons;
    void *  methodData;
    void *  methodInfo;

    JIT_METHOD_INFO methInfo;
    methInfo.ftn            = (METHOD_HANDLE) &method;
    methInfo.scope          = (SCOPE_HANDLE) NULL;
    methInfo.ILCode         = const_cast<BYTE*>(header.Code);
    methInfo.ILCodeSize     = header.CodeSize;
    methInfo.maxStack       = header.MaxStack;
    methInfo.EHcount        = header.EHCount();
    methInfo.options        = (JIT_OPTIONS) header.Flags;
    SigPointer ptr(method.symSig);
    methInfo.args.callConv  = (JIT_CALL_CONV) ptr.GetData();
    methInfo.args.numArgs   = (unsigned short) ptr.GetData();
    methInfo.args.retType   = (JIT_types) ptr.PeekData();
    ptr.Skip();
    methInfo.args.args      = (*((ARG_LIST_HANDLE*) (&ptr)));

    if (header.LocalVarSig != 0) {
        header.LocalVarSig++;       // Skip the LOCAL_SIG calling convention
        methInfo.locals.numArgs = *header.LocalVarSig;
        methInfo.locals.args = (ARG_LIST_HANDLE) &header.LocalVarSig[1];

        if  (methInfo.locals.numArgs >= 128)
        {
            methInfo.locals.numArgs = (methInfo.locals.numArgs & 0x7F) << 8 | header.LocalVarSig[1];
            methInfo.locals.args = (ARG_LIST_HANDLE) &header.LocalVarSig[2];
        }
    }
    else {
        methInfo.locals.numArgs = 0;
        methInfo.locals.args = 0;
    }

#if TGT_IA64

    if  (!forReal)
    {
#if DEBUG
        const   char *  name;

        pComp->info.compMethodHnd   = (METHOD_HANDLE) &method;
        pComp->info.compCompHnd     = &method;
        pComp->info.compMethodInfo  = &methInfo;

        genRecordFuncName(pComp->eeGetMethodFullName((METHOD_HANDLE)&method));
#endif

        goto DONE;
    }

#endif

#if TGT_IA64
    pComp->genAddSourceData(fileName);  // should only be called once
#endif

    SIZE_T tempNativeSize;
    int    error;

    error     = pComp->compCompile((METHOD_HANDLE) &method,
                                   (SCOPE_HANDLE)0,
                                   &method,
                                   const_cast<BYTE*>(header.Code),
                                   header.CodeSize, &tempNativeSize,
                                   methInfo.locals.numArgs + methInfo.args.numArgs + !(IsMdStatic(attrs)),
                                   header.MaxStack,
                                   &methInfo,
                                   methInfo.EHcount,
                                   NULL,             // xcptn table
                                   0,
                                   0,
                                   0,
                                   0,
                                   &methodCode,
                                   &methodCons,
                                   &methodData,
                                   &methodInfo,
                                   compFlags);

#ifdef DEBUG
    if (dspCode) printf("\n");
#endif

DONE:

#endif // OPT_IL_JIT

    // Free the allocator we used

    nraFreeTheAllocator();

    return TRUE;
}

/*****************************************************************************/

void        genCodeForMethods(
                         const char *           fileName,
                         PEFile *               peFile,
                         IMDInternalImport *    metaData,
                         HENUMInternal *        methodEnum,
                         mdTypeDef              classTok,
                         LPCSTR                 className,
                         bool                   forReal)
{
    ULONG membersCount = metaData->EnumGetCount(methodEnum);

    // Walk all the methods in the enumerator

    for (ULONG m = 0; m < membersCount; m++)
    {
        mdMethodDef     methodTok;
        LPCSTR          memberName;
        DWORD           dwMemberAttrs;
        DWORD           codeRVA;
        COR_ILMETHOD *  ilMethod;
        PCCOR_SIGNATURE pSig;
        ULONG           sigSize;
        DWORD           implFlags;

        bool gotNext = metaData->EnumNext(methodEnum, &methodTok);
        assert(gotNext);

        dwMemberAttrs = metaData->GetMethodDefProps(methodTok);

        metaData->GetMethodImplProps(methodTok,
                                     &codeRVA,
                                     &implFlags);

        pSig = metaData->GetSigOfMethodDef(methodTok, &sigSize);
        if (codeRVA == 0)
            continue;

        ilMethod = (COR_ILMETHOD*)(peFile->GetBase() + codeRVA);

        if (IsMdPinvokeImpl(dwMemberAttrs) || IsMdAbstract(dwMemberAttrs))
            continue;           // No IL

        assert(implFlags == miIL || implFlags == miOPTIL);

#ifdef OPT_IL_JIT
        if  (!COR_IS_METHOD_MANAGED_OPTIL(implFlags))
        {
            printf("%10s : This method is not OPT-IL\n", memberName);
            continue;
        }
#endif

        memberName = metaData->GetNameOfMethodDef(methodTok);

#if TGT_IA64 && 0

if  (
     !strcmp(memberName, "cmpDeclClass")   ||
     !strcmp(memberName, "parsePrepSym")   ||
     !strcmp(memberName, "cmpBindExprRec") ||
    0)
{
    printf("// HACK: skipping compile of %s, too many registers needed\n", memberName);
    continue;
}

#endif

        int result = generateCodeForFunc(fileName, peFile, metaData,
                                     ilMethod, pSig,
                                     classTok, methodTok,
                                     dwMemberAttrs,
                                     implFlags,
                                     memberName, className,
                                     forReal);
    }
}

/*****************************************************************************/

// forward declaration.
STDAPI GetMDInternalInterface(
        LPVOID      pData,          // [IN] Buffer with the metadata.
        ULONG       cbData,         // [IN] Size of the data in the buffer.
        DWORD       flags,          // [IN] MDInternal_OpenForRead or MDInternal_OpenForENC
        REFIID      riid,           // [IN] The interface desired.
        void        **ppIUnk);      // [out] Return interface on success.

int                 generateCode(const char *fileName)
{
    HRESULT         hr;

    // Load the PE file (without calling DllMain for DLLs)

    HMODULE hMod = LoadLibraryEx(fileName, NULL, DONT_RESOLVE_DLL_REFERENCES);
    if (hMod == NULL) NO_WAY("Could not load PE file");

    // @TODO: Check for out of memory
    PEFile * peFile;

    hr = PEFile::Create(hMod, &peFile);
    if (hr != S_OK) NO_WAY("Could not initialize PE file");

#if TGT_IA64
    sourceFileImageBase = peFile->GetNTHeader();
#endif

    // Get to the COR Header section

    IMAGE_COR20_HEADER * pCORHeader = peFile->GetCORHeader();

    // Access the COM+ stuff
    IMAGE_DATA_DIRECTORY    meta = pCORHeader->MetaData;

    void *                  vaofmetadata = (LPVOID) (peFile->GetBase() +
                                                     meta.VirtualAddress);

    // Create an IMDInternalImport object
    IMDInternalImport * metaData = NULL;
    hr = GetMDInternalInterface(vaofmetadata, meta.Size, ofRead, IID_IMDInternalImport, (void**)&metaData);
    if (FAILED(hr)) fatal(ERRignore, "Could not get internal metadata interface", fileName);

    // @todo: this is temporary. We need to create a metadata
    // dispenser and do a duplicate open scope in order to get a
    // IMetaDataDebugImport scopeless interface. Jason Z. is gonna add
    // a method to IMetaDataInternal that will allow us to get such an
    // interface given a scope, but that doesn't exist right now.

    IMetaDataDispenser *dispenser;
    hr = CoCreateInstance(CLSID_CorMetaDataDispenser, NULL,
                          CLSCTX_INPROC_SERVER,
                          IID_IMetaDataDispenser,
                          (void**)&dispenser);
    if (FAILED(hr)) fatal(ERRignore, "Could not create metadata dispenser",
                          fileName);

    dispenser->Release();

    /*-------------------------------------------------------------------------
     * First access the class methods.
     */

    bool                    forReal = false;

LOOP:

    /* Crack the meta data */

    ULONG                   classesCount = 0;
    HENUMInternal           classEnum;
    HENUMInternal           methodEnum;

    // Access all the typeDefs in the file

    hr = metaData->EnumTypeDefInit(&classEnum);
    if (FAILED(hr)) NO_WAY("Could not get to the classes enumerator");

    classesCount = metaData->EnumTypeDefGetCount(&classEnum);

    // Walk all the typeDefs in the file

    for (ULONG c = 0; c < classesCount; c++)
    {
        mdTypeDef           classTok;
        DWORD               dwClassAttrs;
        LPCSTR              szClassName, szNamespaceName;

        bool gotNext = metaData->EnumTypeDefNext(&classEnum, &classTok);
        _ASSERTE(gotNext);

        metaData->GetTypeDefProps(classTok, &dwClassAttrs, NULL);

        // Ignore interfaces

        if ((dwClassAttrs & tdClassSemanticsMask) == tdInterface)
            continue;

        // Display name of the typeDef

        metaData->GetNameOfTypeDef(classTok,
                                   &szClassName,
                                   &szNamespaceName);

        if  (className && strcmp(className, szClassName)) continue;

//      if (!methodName && c>1)
//          printf("Class : %s/%s\n", szNamespaceName, szClassName);

        // Access all the members in the current typeDef

        hr = metaData->EnumInit(mdtMethodDef, classTok, &methodEnum);
        if (FAILED(hr)) NO_WAY("Could not get to the method enumerator");

        genCodeForMethods(fileName, peFile, metaData,
                          &methodEnum, classTok, szClassName,
                          forReal);

        metaData->EnumClose(&methodEnum);
    }

    metaData->EnumTypeDefClose(&classEnum);

    /*-------------------------------------------------------------------------
     * Next, access the global methods
     */

    hr = metaData->EnumInit(mdtMethodDef, COR_GLOBAL_PARENT_TOKEN, &methodEnum);
    if (FAILED(hr)) NO_WAY("Could not get to the global method enumerator");

    genCodeForMethods(fileName, peFile, metaData,
                      &methodEnum, COR_GLOBAL_PARENT_TOKEN, "Globals",
                      forReal);

    metaData->EnumClose(&methodEnum);

#if TGT_IA64

    if  (!forReal)
    {
        forReal = true;
        goto LOOP;
    }

#endif

    // Clean-up

    metaData->Release();

    delete peFile;

    return  0;
}

/*****************************************************************************/

int                 genCode4class(const char *fileName)
{
    int             result;

#ifndef NDEBUG
    jitCurSource = fileName;
#endif

    setErrorTrap()
    {
        printf("// Generating code for %s\n\n", fileName);

#if TGT_IA64
        if  (!strcmp(fileName, "smc64.exe") && dspAsmCode)
        {
            printf("@stringCns:\n");
            printf("@endcatch:\n");
            printf("@doubleToInt:\n");
            printf("@addrArrStore:\n");
            printf("@dblDiv:\n");
            printf("@doubleToLong:\n");
            printf("@doubleToUInt:\n");
            printf("@doubleToULong:\n");
            printf("@fltDiv:\n");
            printf("@GetRefAny:\n");
            printf("@longDiv:\n");
            printf("@longMod:\n");
            printf("@newObjArrayDirect:\n");
            printf("@ulongDiv:\n");
            printf("@ulongMod:\n");

            printf("System__ctor_struct_long_:\n");
            printf("System_End__:\n");
            printf("System_get_Chars_int__char:\n");
            printf("System_get_Length___int:\n");
            printf("System_GetNextArg___struct:\n");
            printf("System_Runtime_InteropServices_GetExceptionCode___int:\n");
            printf("compiler_cmpBindExprRec_long_long__long:\n");
            printf("compiler_cmpDeclClass_long_long_boolean_:\n");
        }
#endif

        result = generateCode(fileName);
    }
    impJitErrorTrap()
    {
        result = 0;
    }
    endErrorTrap()

#ifndef NDEBUG
    jitCurSource = NULL;
#endif

    return result;
}

/*****************************************************************************/

static
int                 processFileList(int             argc,
                                    char       *    argv[],
                                    int       (*    processOneFileFN)(const char *),
                                    const char *    defaultFileExt)
{
    char    *       file;

    long            ffHandle;
    _finddata_t     ffData;
    char            path[_MAX_PATH ];
    char            fnam[_MAX_FNAME];
    char            fdrv[_MAX_DRIVE];
    char            fdir[_MAX_DIR  ];
    char            fext[_MAX_EXT  ];

    int             status = 0;

    while (argc)
    {
        /* Pull the next file name from the list */

        file = *argv++;
                argc--;

        /* Is this a response file? */

        if  (*file == '@')
        {
            FILE    *   fp;

            fp = fopen(file+1, "rt");

            if  (!fp)
            {
                printf("ERROR: response file '%s' could not be opened.\n", file+1);
                return 1;
            }

            for (;;)
            {
                char        line[1024];
                size_t      llen;

                if  (!fgets(line, sizeof(line), fp))
                    break;

                llen = strlen(line);

                if  (llen && line[llen-1] == '\n')
                {
                    llen--;
                    line[llen] = 0;
                }

                if  (line[0] && line[0] != ';')
                {
                    char    *   name = line;

                    /* Recursive call */

                    status |= processFileList(1, &name, processOneFileFN,
                                                        defaultFileExt);
                }
            }

            fclose(fp);

            continue;
        }

        /* Split the filename */

        _splitpath(file, fdrv, fdir, fnam, fext);

        /* Make sure we set the extension appropriately */

        if  (!fext[0])
            strcpy(fext, defaultFileExt);

        /* Form a filename with the appropriate extension */

        _makepath(path, fdrv, fdir, fnam, fext);

        /* Look for the first match for the file pattern */

        ffHandle = _findfirst(path, &ffData);
        if  (ffHandle == -1)
        {
            printf("ERROR: source file '%s' not found.\n", file);
            return 1;
        }

        do
        {
            /* Make the matching file name into a complete path */

            _splitpath(ffData.name,   0,    0, fnam, fext);
            _makepath(path,        fdrv, fdir, fnam, fext);

            status |= processOneFileFN(path);
        }
        while (_findnext(ffHandle, &ffData) != -1);

        _findclose(ffHandle);
    }

    return  status;
}

/*****************************************************************************/

#ifdef  DUMPER

static
int                 dumpOneFile(const char *name)
{
    printf("PE file dumper NYI\n");
    return 0;
}
#endif // DUMPER

/*****************************************************************************/

extern  "C"
const   char *      COMPILER_VERSION;

void                DisplayBanner()
{
    printf("// Microsoft (R) Just-in-time compiler for IA64 Version %s\n", COMPILER_VERSION);
    printf("// Copyright (c) Microsoft Corporation.  All rights reserved.\n");
    printf("\n");
}

void                Usage()
{
    static const char usage[] =

    "Usage: jit [options] <filename>                                        \n"
    "                                                                       \n"
    "Note: '*' following an option indicates it's on by default             \n"
    "                                                                       \n"
    "  -verbose          print messages about compilation progress          \n"
    "  -w{0-4}           set warning level <default=2>                      \n"
#ifdef DEBUG
    " DEBUG SWITCHES:                                                       \n"
    "  -D:m[n]           check for memory leaks                             \n"
    "  -D:t[-]           dump trees                                         \n"
#endif // DEBUG

    " JIT COMPILER SWITCHES:                                                \n"
    "  -n[-]             enable native codegen (JIT compiler)               \n"
    "  -n:F[-]      *    preserve float operand order                       \n"
    "  -n:I[-]      *    JIT <clinit> methods                               \n"
    "  -n:M<size>        min. method size to JIT                            \n"
    "  -n:O[-]      *    max. optimizations                                 \n"
    "  -n:P[-]      *    allow FP omission                                  \n"
    "  -n:R[-]      *    array index range checking                         \n"
    "  -n:S[-]      *    generate for speed                                 \n"
#if     SCHEDULER
    "  -n:s[-]           enable code scheduler                              \n"
#ifdef  DEBUG
    "  -n:A[-]           enable display of scheduled code                   \n"
    "  -n:A2[-]          enable display of scheduled code using msdis       \n"
#endif
    "  -n:r[-]      *    enable riscification/round robin reg alloc         \n"
#else
    "  -n:r[-]      *    enable round robin reg alloc                       \n"
#endif
#if     TGT_IA64
#endif
    "  -n:4         *    generate code for 386/486                          \n"
    "  -n:5         *    generate code for Pentium                          \n"
    "  -n:6         *    generate code for Pentium Pro                      \n"
#if     INLINING
    "  -n:i              enable inliner                                     \n"
#endif
    "  -n:NmethodName    only compile method(s) matching the name           \n"
    "  -n:CclassName     only compile class(es) matching the name           \n"
#ifdef  DEBUG
    "  -n:B[-]           display byte-codes                                 \n"
    "  -n:E[-]           display native code - opcodes                      \n"
    "  -n:D[-]           display native code - ASM                          \n"
    "  -n:L[-]           display native code - line #'s                     \n"
    "  -n:V[-]           display native code - variable names               \n"
    "  -n:H[-]           display generated code/data/info in hex            \n"
    "  -n:e[-]           save native code                                   \n"
    "  -n:X[-]           run  native code (requires -n:s)                   \n"
    "  -n:JsourcePath    specify the path four source files                 \n"
#endif // DEBUG
#ifdef DEBUGGING_SUPPORT
    "  -n:k[-]           generate debug info                                \n"
    "  -n:K[-]           generate debuggable code                           \n"
    "  -n:n[-]           generate code for Edit-n-Continue                  \n"
#endif
#if DUMP_INFOHDR
    "  -n:h[-]           dump Info Block Headers                            \n"
#endif
#if DUMP_GC_TABLES
    "  -n:d[-]           dump GC tables                                     \n"
    "  -n:c[-]              : include code offsets and raw bytes            \n"
#endif

#ifdef  DUMPER
    " DUMPER SWITCHES:                                                      \n"
    "  -U                enable class file dumper                           \n"
    "  -U:C[-]           dump function bodies                               \n"
    "  -U:O[-]           dump with pcode offsets                            \n"
    "  -U:S[-]           dump in sorted order                               \n"
#endif // DUMPER

    "                                                                       \n"
    "Note that '-' turns flag off                                           \n"
    "                                                                       \n"
    /* end static const char usage[] */ ;

    printf("%s", usage);
}


/*****************************************************************************
 * Processes command line switches
 * Additional switches can also be in the registry
 * The global flag regSwitch is checked to see what type of switches we process
 *****************************************************************************/

static
int                 ProcessCommandLine(int argc, char *argv[])
{
    if (!regSwitch)
    {
        /* It's the ral command line - Skip the program argument position */

        argc--;
        argv++;
    }

    /* Process any command-line switches */

    while   (argc)
    {
        if  (**argv != '-' && **argv != '/')
            break;

                bool    *   flagPtr = NULL;

        const   char    **  argPtr;
        const   char    *   optStr;
        const   char    *   cmdPtr;

        optStr = argv[0];
        cmdPtr = argv[0] + 2;

        switch  (argv[0][1])
        {
        case 'n':

            if (*cmdPtr != ':')
            {
                flagPtr = &native;
                goto TOGGLE_FLAG;
            }

            cmdPtr++;

            switch (*cmdPtr++)
            {
            case 'F':
                flagPtr = &genOrder;
                goto TOGGLE_FLAG;

            case 'I':
                flagPtr = &genClinit;
                goto TOGGLE_FLAG;

            case 'M':
                genMinSz = atoi(cmdPtr);
                break;

            case 'O':
                flagPtr = &maxOpts;
                goto TOGGLE_FLAG;

            case 'a':
                flagPtr = &genAllSz;
                goto TOGGLE_FLAG;

            case 'P':
                flagPtr = &genFPopt;
                goto TOGGLE_FLAG;

            case 'R':
                flagPtr = &rngCheck;
                goto TOGGLE_FLAG;

            case 'S':
                flagPtr = &goSpeed;
                goto TOGGLE_FLAG;

            case '5':
            case '6':
                genCPU = *(cmdPtr-1) - '0';
                goto DONE_ARG;

#if     SCHEDULER

            case 's':
                flagPtr = &schedCode;
                goto TOGGLE_FLAG;

#endif

#ifdef  DEBUG

            case 'A':

                if (*cmdPtr == '2')
                {
                    flagPtr = &disAsm2;
                    cmdPtr++;
                }
                else
                {
                    flagPtr = &disAsm;
                }
                goto TOGGLE_FLAG;

#endif

            case 'r':
                flagPtr = &riscCode;
                goto TOGGLE_FLAG;

#if     TGT_IA64
            case 't':
                flagPtr = &tempAlloc;
                goto TOGGLE_FLAG;
#endif

#if     INLINING
            case 'i':
                flagPtr = &genInline;
                goto TOGGLE_FLAG;
#endif

            case 'N':
                methodName = cmdPtr;
                goto DONE_ARG;

            case 'C':
                className = cmdPtr;
                goto DONE_ARG;

#ifdef  DEBUG

            case 'B':
                flagPtr = &dspILopcodes;
                goto TOGGLE_FLAG;

            case 'E':
                flagPtr = &dspEmit;
                goto TOGGLE_FLAG;

            case 'D':
                flagPtr = &dspCode;
                goto TOGGLE_FLAG;

            case 'L':
                flagPtr = &dspLines;
                goto TOGGLE_FLAG;

            case 'V':
                flagPtr = &varNames;
                goto TOGGLE_FLAG;

            case 'J':
                srcPath = cmdPtr;
                goto DONE_ARG;

            case 'H':
                flagPtr = &dmpHex;
                goto TOGGLE_FLAG;

#if     TGT_IA64

            case 'U':
                flagPtr = &dspAsmCode;
                goto TOGGLE_FLAG;

#endif

            case 'T':
                CGknob = atof(cmdPtr);
                printf("Using CG knob of %lf\n", CGknob);
                goto DONE_ARG;

#endif // DEBUG

#if DUMP_INFOHDR
            case 'h':
                flagPtr = &dspInfoHdr;
                goto TOGGLE_FLAG;
#endif

#if DUMP_GC_TABLES
            case 'd':
                flagPtr = &dspGCtbls;
                goto TOGGLE_FLAG;
            case 'c':
                flagPtr = &dspGCoffs;
                goto TOGGLE_FLAG;
#endif

            case 'G':
                flagPtr = &genGcChk;
                goto TOGGLE_FLAG;

#ifdef DEBUGGING_SUPPORT
            case 'k':
                flagPtr = &debugInfo;
                goto TOGGLE_FLAG;

            case 'K':
                flagPtr = &debuggableCode;
                goto TOGGLE_FLAG;

            case 'n':
                flagPtr = &debugEnC;
                goto TOGGLE_FLAG;
#endif

            case 'X':
                flagPtr = &runCode;
                goto TOGGLE_FLAG;

            case 'o':
                repCode = atoi(cmdPtr);
                printf("Repeating compilation %u times.\n", repCode);
                goto DONE_ARG;

            case 'e':
                flagPtr = &savCode;
                goto TOGGLE_FLAG;

            // The following currently unused:

            case 'b':
            case 'f':
            case 'g':
            case 'j':
            case 'l':
            case 'm':
            case 'p':
#if !   TGT_IA64
            case 'U':
#endif
            case 'u':
            case 'v':
            case 'x':
            case 'Y':
            case 'y':
            case 'Z':
            case 'z':

            default:
                break;
            }

            goto USAGE;

        case 'v':
            // -verbose -- spew information about the compile
            if (!strncmp(argv[0]+1, "verbose", strlen("verbose")+1))
            {
                verbose = true;
                break;
            }
            goto USAGE;

        case 'w':
            // -w{0-4} -- set warning level
            switch (*cmdPtr)
            {
            default: goto USAGE;
            case '0': warnLvl = 0; break;
            case '1': warnLvl = 1; break;
            case '2': warnLvl = 2; break;
            case '3': warnLvl = 3; break;
            case '4': warnLvl = 4; break;
            }
            break;

#ifdef DEBUG

        case 'D':
            if (*cmdPtr != ':')
                goto USAGE;

            cmdPtr++;
            switch (*cmdPtr++)
            {
            default:
                goto USAGE;

            case 'm':
                memChecks = true;
                if  (*cmdPtr)
                    allocCntStop = atoi(cmdPtr);
                break;

            case 't':
                flagPtr = &dumpTrees;
                goto TOGGLE_FLAG;

            case 'T':
                testMask = atoi(cmdPtr);
                break;
            }
            break;

#endif //DEBUG

        case 'T':
            testMask = atoi(cmdPtr);
            break;

#ifdef DUMPER

        case 'U':

            if (*cmdPtr != ':')
            {
                if (*cmdPtr == 0)
                {
                    dmpClass = true;
                    break;
                }

                goto USAGE;
            }

            cmdPtr++;
            switch (*cmdPtr++)
            {
            case 'D': flagPtr = &dmp4diff; goto TOGGLE_FLAG;
            case 'O': flagPtr = &dmpPCofs; goto TOGGLE_FLAG;
            case 'C': flagPtr = &dmpCodes; goto TOGGLE_FLAG;
            case 'S': flagPtr = &dmpSort ; goto TOGGLE_FLAG;
            }
            goto USAGE;

#endif //DUMPER

        TOGGLE_FLAG:

            switch  (*cmdPtr)
            {
            case 0:
                *flagPtr = true;
                break;
            case '-':
                *flagPtr = false;
                break;
            default:
                goto USAGE;
            }
            break;

//        GET_NEXT_ARG:

            argc--;
            argv++;
            *argPtr = argv[0];
            if (**argPtr)
                break;
            goto USAGE;

        default:
        USAGE:

            printf("Invalid/unrecognized command-line option '%s'\n\n", optStr);

            Usage();

            goto EXIT;
        }

    DONE_ARG:

        argc--;
        argv++;
    }

    if (regSwitch)
    {
        // done processing registry switches, return
        return 0;
    }

#ifdef  DUMPER

    if  (dmpClass)
    {
        processFileList(argc, argv, dumpOneFile, jitDefaultFileExt);
        goto EXIT;
    }

#endif

#if COUNT_CYCLES

    /* Reset the cycle counter */

    cycleCounterInit();
    assert(cycleTotal == 0);

    cycleCounterBeg();

#endif

    if (native)
    {
        jitStartup ();
        processFileList(argc, argv, genCode4class, jitDefaultFileExt);
        jitShutdown();
    }

#if COUNT_CYCLES && 0

    __int64     cycleTotal;
    __int64     cycleSpent;

    cycleSpent = cycleCounterDone(&cycleTotal);

    if  (cycleTotal)
        printf("Gross cycles: %8.3f mil (est. %6.2f sec)\n", (float)cycleTotal/1000000, (float)cycleTotal/90000000);
    if  (cycleSpent)
        printf("Net   cycles: %8.3f mil (est. %6.2f sec)\n", (float)cycleSpent/1000000, (float)cycleSpent/90000000);

#endif

EXIT:

#ifdef  ICECAP
    StopCAP();
#endif

    COMShutdown();

      exit(ErrorCount);
    return ErrorCount;
}

/*****************************************************************************/

int     _cdecl      main(int argc, char *argv[])
{

#ifdef  ICECAP
    AllowCAP();
    StartCAP();
    SuspendCAP();
#endif

    DisplayBanner();

    /* Init the Unicode wrappers */

    OnUnicodeSystem();

    /* Process registry switches if any */

    const   MAX_SWITCHES_LEN = 512;
    CHAR    regSwitches[MAX_SWITCHES_LEN];

    if (getEERegistryString("Switches", regSwitches, sizeof(regSwitches)))
    {
        printf("jitc registry switches: %s\n", regSwitches);

        int     reg_argc = 0;
        const   MAX_SWITCHES = 20;
        char *  reg_argv[MAX_SWITCHES];
        char *  token;

        /* Find tokens separated by blank spaces */

        token = strtok( regSwitches, " " );
        while( token != NULL )
        {
            // While there are tokens in "string"
            reg_argv[reg_argc++] = token;
            assert ( reg_argc <= MAX_SWITCHES );

            // Get next switch
            token = strtok( NULL, " " );
        }

        // process registry switches
        regSwitch = true;
        ProcessCommandLine(reg_argc, reg_argv);
    }

    // process real command line switches
    regSwitch = false;
    return ProcessCommandLine(argc, argv);
}

/*****************************************************************************/
void    totalCodeSizeBeg(){}

/*****************************************************************************/
HRESULT STDMETHODCALLTYPE
TranslateSecurityAttributes(CORSEC_PSET    *pPset,
                            BYTE          **ppbOutput,
                            DWORD          *pcbOutput,
                            DWORD          *pdwErrorIndex)
{
    return E_NOTIMPL;
}

HRESULT STDMETHODCALLTYPE
GetAssembliesByName(LPCWSTR  szAppBase,
                    LPCWSTR  szPrivateBin,
                    LPCWSTR  szAssemblyName,
                    IUnknown *ppIUnk[],
                    ULONG    cMax,
                    ULONG    *pcAssemblies)
{
    return E_NOTIMPL;
}

mdAssemblyRef DefineAssemblyRefForImportedTypeLib(
    void        *pAssembly,             // Assembly importing the typelib.
    void        *pvModule,              // Module importing the typelib.
    IUnknown    *pIMeta,                // IMetaData* from import module.
    IUnknown    *pIUnk,                 // IUnknown to referenced Assembly.
    BSTR        *pwzNamespace)          // The namespace of the resolved assembly.
{
    return 0;
}

mdAssemblyRef DefineAssemblyRefForExportedAssembly(
    LPCWSTR     pszFullName,            // The full name of the assembly.
    IUnknown    *pIMeta)                // Metadata emit interface.
{
    return 0;
}

/*** EOF *********************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\jitpch.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
#ifndef OPT_IL_JIT

#include <windows.h>
#include <wincrypt.h>

#ifdef  UNDER_CE_GUI
#include "jitWCE.h"
#else
#include <assert.h>
#include <stdio.h>
#include <stddef.h>
#include <fcntl.h>
#include <io.h>
#define  sprintfA sprintf
#endif

#include <stdlib.h>
#include <limits.h>
#include <string.h>
#include <excpt.h>
#include <float.h>

#include "jit.h"
#include "Compiler.h"

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\jit.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef _JIT_H_
#define _JIT_H_
/*****************************************************************************/

#include "corhdr.h"

/*****************************************************************************/

#ifndef _WIN32_WCE
#if !   HOST_IA64
#define HOST_x86        1
#endif
#endif

/*****************************************************************************/

#pragma warning(disable:4201)   // nameless struct/union
#pragma warning(disable:4244)   // loss of data int -> char ..
#pragma warning(disable:4245)   // assigning signed / unsigned

#define TGT_RISC_CNT (TGT_SH3+TGT_ARM+TGT_PPC+TGT_MIPS16+TGT_MIPS32+TGT_IA64)

#if     TGT_RISC_CNT != 0
#if     TGT_RISC_CNT != 1 || defined(TGT_x86)
#error  Exactly one target CPU must be specified.
#endif
#define TGT_RISC    1
#else
#define TGT_RISC    0
#undef  TGT_x86
#define TGT_x86     1
#endif

#if     TGT_RISC
#pragma warning(disable:4101)       // temp hack: unreferenced variable
#pragma warning(disable:4102)       // temp hack: unreferenced label
#pragma warning(disable:4700)       // temp hack: unitialized  variable
#endif

/*****************************************************************************/

typedef unsigned __int64    _uint64;
typedef unsigned __int32    _uint32;

#if HOST_IA64

typedef   signed __int64    NatInt;
typedef unsigned __int64    NatUns;
const   NatUns              NatBits = 64;

extern  NatUns              NatBitnumToMasks[64];

#else

typedef   signed __int32    NatInt;
typedef unsigned __int32    NatUns;
const   NatUns              NatBits = 32;

extern  NatUns              NatBitnumToMasks[32];

#endif

inline  NatUns              NatBitnumToMask(unsigned bitnum)
{
    assert(bitnum < sizeof(NatBitnumToMasks)/sizeof(NatBitnumToMasks[0]));
    return  NatBitnumToMasks[bitnum];
}

/*****************************************************************************/
#if     TGT_IA64

        struct insDsc;
typedef struct insDsc         * insPtr;

        struct insGrp;
typedef struct insGrp         * insBlk;

#endif
/*****************************************************************************/

#define USE_FASTCALL    1

#ifndef TRACK_GC_REFS
#if     TGT_RISC
#define TRACK_GC_REFS   0           // GC ref tracking is NYI on RISC
#else
#define TRACK_GC_REFS   1
#endif
#endif

#if     TGT_IA64
#define NEW_EMIT_ATTR   1
#else
#define NEW_EMIT_ATTR   TRACK_GC_REFS
#endif

#define THIS_CLASS_CP_IDX   0   // a special CP index code for current class

/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                          jit.h                                            XX
XX                                                                           XX
XX             Interface of the JIT with jit.cpp                             XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#pragma warning(disable:4146)   // this one seems rather useless, so shut it up

#ifndef NDEBUG
#pragma warning(disable:4121)   // not terribly useful in debug builds
#endif

/*****************************************************************************/
#if defined(NOT_JITC) && defined(DEBUG)
#include "log.h"

#define INFO6       LL_INFO1000             // Did Jit or Inline succeeded?
#define INFO7       LL_INFO10000            // NYI stuff
#define INFO8       LL_INFO100000           // Weird failures
#define INFO9       LL_INFO1000000          // Info about incomming settings
#define INFO10      LL_EVERYTHING           // Totally verbose

#define JITLOG(x) info.compCompHnd->logError x
#else
#define JITLOG(x)
#endif

#define INJITDLL   // Defined if we export the functions in EE_Jit.h/vm2jit.h

#ifdef      NOT_JITC
typedef class ICorJitInfo*    COMP_HANDLE;
#else   //  !NOT_JITC
typedef struct CompInfo*   COMP_HANDLE;
#endif

#include "ee_jit.h"

/*****************************************************************************/

typedef unsigned    IL_OFFSET;
const IL_OFFSET     BAD_IL_OFFSET   = UINT_MAX;

const unsigned      BAD_LINE_NUMBER = UINT_MAX;
const unsigned      BAD_VAR_NUM     = UINT_MAX;

typedef size_t      NATIVE_IP;
typedef ptrdiff_t   NATIVE_OFFSET;

// For the following specially handled FIELD_HANDLES we need
//   values that are both even and in (0 > val > -8)
// See eeFindJitDataOffs and eeGetHitDataOffs in Compiler.hpp
//   for the gory details
#define FLD_GLOBAL_DS   ((FIELD_HANDLE) -2 )
#define FLD_GLOBAL_FS   ((FIELD_HANDLE) -4 )

/*****************************************************************************/

#include "host.h"
#include "vartype.h"

/*****************************************************************************
 *
 *  The various macros which determine which functionality is included in
 *  the build.
 */

#ifndef NDEBUG
#define DEBUG               1
#endif

#ifndef DEBUG
#define FAST 1
#endif

#ifdef  DEBUG
#define DUMPER
#define JVC_COMPILING_MSG   1
#endif

/*****************************************************************************/

// Debugging support is ON by default. Can be turned OFF by
// adding /DDEBUGGING_SUPPORT=0 on the command line.

#ifndef   DEBUGGING_SUPPORT
# define  DEBUGGING_SUPPORT
#elif    !DEBUGGING_SUPPORT
# undef   DEBUGGING_SUPPORT
#endif

/*****************************************************************************/

// Late disassembly is OFF by default. Can be turned ON by
// adding /DLATE_DISASM=1 on the command line.
// Always OFF in the non-debug version

#ifdef  DEBUG
    #if defined(LATE_DISASM) && (LATE_DISASM == 0)
    #undef  LATE_DISASM
    #endif
#else // DEBUG
    #undef  LATE_DISASM
#endif

/*****************************************************************************/

#if defined(FAST) && !defined(NOT_JITC) 
#define COUNT_CYCLES        1
#endif

/*****************************************************************************/

#define RNGCHK_OPT          1       // enable global range check optimizer

#ifndef SCHEDULER
#if     TGT_x86 || TGT_IA64
#define SCHEDULER           1       // scheduler defaults to on  for x86 / IA64
#else
#define SCHEDULER           0       // scheduler defaults to off for RISC
#endif
#endif

#define CSE                 1       // enable CSE logic
#define CSELENGTH           1       // expose length use in range check for CSE
#define MORECSES            0       // CSE other expressions besides indirs
#define COPY_PROPAG         1       // copy propagation within a basic block only
#define CODE_MOTION         1       // enable loop code motion etc.

#define SPECIAL_DOUBLE_ASG  0       // special handling for double assignments

#define CAN_DISABLE_DFA     1       // completely disable data flow (doesn't work!)
#define ALLOW_MIN_OPT       1       // allow "dumb" compilation mode

#define OPTIMIZE_RECURSION  1       // convert recursive methods into iterations

//=============================================================================

#define TARG_REG_ASSIGN     1       // targeted variable register assignment
#define FANCY_ARRAY_OPT     0       // optimize more complex index checks

//=============================================================================

#if     TGT_IA64
#define LONG_ASG_OPS        1       // a natural thing to do ...
#else
#define LONG_ASG_OPS        0       // implementation isn't complete yet
#endif

//=============================================================================

#define OPT_MULT_ADDSUB     1       // optimize consecutive "lclVar += or -= icon"
#define OPT_BOOL_OPS        1       // optimize boolean operations

#define OPTIMIZE_QMARK      1       // optimize "?:" expressions?

#if     USE_FASTCALL
#define OPTIMIZE_TAIL_REC   0       // UNDONE: no tail recursion for __fastcall
#else
#define OPTIMIZE_TAIL_REC   1       // optimize tail recursion
#endif

//=============================================================================

#define REDUNDANT_LOAD      1       // track locals in regs, suppress loads

//=============================================================================

#define INLINING            1       // inline calls to small methods

//=============================================================================

#define HOIST_THIS_FLDS     1       // hoist "this.fld" out of loops etc.

//=============================================================================

#define INLINE_NDIRECT      TGT_x86 // try to inline N/Direct stubs

//=============================================================================

#define PROFILER_SUPPORT    TGT_x86

/*****************************************************************************/

#define GEN_SHAREABLE_CODE  0       // access static data members via helper

/*****************************************************************************/

#define USE_SET_FOR_LOGOPS  1       // enable this only for P6's

/*****************************************************************************/

#define ROUND_FLOAT         TGT_x86 // round intermed float expression results

/*****************************************************************************/

#define LONG_MATH_REGPARAM  0       // args to long mul/div passed in registers

/*****************************************************************************/

#define VPTR_OFFS           0       // offset of vtable pointer from obj ptr

#ifdef NOT_JITC
#define ARR_ELCNT_OFFS      offsetof(JIT_Array, length)
#define ARR_ELEM1_OFFS      offsetof(JIT_Array, u1Elems)
#define OBJARR_ELEM1_OFFS   offsetof(JIT_RefArray, refElems)
#else
#if     TGT_RISC
#define ARR_ELCNT_OFFS      -1      // offset of the array length field
#define ARR_ELEM1_OFFS      0       // offset of the first array element
#define OBJARR_ELEM1_OFFS   0       // offset of the first array element for object arrays
#else
#define ARR_ELCNT_OFFS      4       // offset of the array length field
#define ARR_ELEM1_OFFS      8       // offset of the first array element
#define OBJARR_ELEM1_OFFS   8       // offset of the first array element for object arrays
#endif
#endif

/*****************************************************************************/

#ifdef  NOT_JITC
#define INDIRECT_CALLS      1
#else
#define INDIRECT_CALLS      0
#endif

/*****************************************************************************/

#if     COUNT_CYCLES
#ifndef NOT_JITC
#define REGVAR_CYCLES       0
#define  TOTAL_CYCLES       1
#endif
#endif

/*****************************************************************************/
#ifdef  NOT_JITC
/*****************************************************************************/

#define DISPLAY_SIZES       0
#define VERBOSE_SIZES       0
#define COUNT_BASIC_BLOCKS  0
#define INLINER_STATS       0
#define DUMP_INFOHDR        DEBUG
#define DUMP_GC_TABLES      DEBUG
#define VERIFY_GC_TABLES    0
#define GEN_COUNT_CODE      0       // enable *only* for debugging of crashes and such
#define GEN_COUNT_CALLS     0
#define GEN_COUNT_PTRASG    0
#define MEASURE_NODE_SIZE   0
#define MEASURE_NODE_HIST   0
#define MEASURE_BLOCK_SIZE  0
#define MEASURE_MEM_ALLOC   0
#define COUNT_RANGECHECKS   0
#define REARRANGE_ADDS      1
#define COUNT_OPCODES       0

#define INTERFACE_STATS     0

/*****************************************************************************/
#else
/*****************************************************************************/

#define DISPLAY_SIZES       1
#define VERBOSE_SIZES       0
#define COUNT_BASIC_BLOCKS  0
#define INLINER_STATS       0
#define COUNT_LOOPS         0
#define DATAFLOW_ITER       0
#define COUNT_DEAD_CALLS    0
#define DUMP_INFOHDR        DEBUG
#define DUMP_GC_TABLES      DEBUG
#define VERIFY_GC_TABLES    0
#define GEN_COUNT_CODE      0
#define GEN_COUNT_CALLS     0
#define GEN_COUNT_PTRASG    0
#define MEASURE_NODE_SIZE   0
#define MEASURE_NODE_HIST   0
#define MEASURE_BLOCK_SIZE  0
#define MEASURE_MEM_ALLOC   0
#define MEASURE_PTRTAB_SIZE 0
#define COUNT_RANGECHECKS   RNGCHK_OPT
#define REARRANGE_ADDS      1
#define COUNT_OPCODES       0
#define CALL_ARG_STATS      0
#define DEBUG_ON_ASSERT     DEBUG

/*****************************************************************************/
#endif
/*****************************************************************************/

#if     DUMP_GC_TABLES
#ifndef DEBUG
#pragma message("NOTE: this non-debug build has GC ptr table dumping always enabled!")
const   bool        dspGCtbls = true;
#endif
#endif

/*****************************************************************************
 *
 * Double alignment. This aligns ESP to 0 mod 8 in function prolog, then uses ESP
 * to reference locals, EBP to reference parameters.
 * It only makes sense if frameless method support is on.
 * (frameless method support is now always on)
 */


#if     TGT_x86
#define DOUBLE_ALIGN        1       // align ESP in prolog, align double local offsets
#endif

/*****************************************************************************/
#ifdef  DEBUG
extern  void _cdecl debugStop(const char *why, ...);
#endif
/*****************************************************************************/

extern  unsigned    warnLvl;
extern  unsigned    allocCntStop; // FOR_JVC?

extern  const char* methodName;
extern  const char* className;
extern  unsigned    testMask;

#ifdef DEBUG
extern  bool        memChecks;  // FOR_JVC ?
extern  const char* srcPath;
extern  bool        dumpTrees;
extern  bool        verbose;
#endif

extern  bool        genOrder;
extern  bool        genClinit;
extern  unsigned    genMinSz;
extern  bool        genAllSz;
extern  bool        native;
extern  bool        maxOpts;
extern  bool        genFPopt;
extern  bool        rngCheck;
extern  bool        goSpeed;
extern  bool        savCode;
extern  bool        runCode;
extern  unsigned    repCode;
extern  bool        vmSdk3_0;
extern  bool        disAsm;
extern  bool        disAsm2;
extern  bool        riscCode;
#ifdef  DEBUG
extern  bool        dspILopcodes;
extern  bool        dspEmit;
extern  bool        dspCode;
extern  bool        dspLines;
extern  bool        dmpHex;
extern  bool        varNames;
extern  bool        asmFile;
extern  double      CGknob;
#endif
#if     DUMP_INFOHDR
extern  bool        dspInfoHdr;
#endif
#if     DUMP_GC_TABLES
extern  bool        dspGCtbls;
extern  bool        dspGCoffs;
#endif
extern  bool        genGcChk;
#ifdef  DEBUGGING_SUPPORT
extern  bool        debugInfo;
extern  bool        debuggableCode;
extern  bool        debugEnC;
#endif

#if     TGT_IA64
extern  bool        tempAlloc;
extern  bool        dspAsmCode;
#endif

#ifdef  DUMPER
extern  bool        dmpClass;
extern  bool        dmp4diff;
extern  bool        dmpPCofs;
extern  bool        dmpCodes;
extern  bool        dmpSort;
#endif // DUMPER

extern  bool        nothing;

extern  bool        genStringObjects;

#if     INLINING
extern  bool        genInline;
#endif

/*****************************************************************************/

enum accessLevel
{
    ACL_NONE,
    ACL_PRIVATE,
    ACL_DEFAULT,
    ACL_PROTECTED,
    ACL_PUBLIC,
};

/*****************************************************************************/

#define castto(var,typ) (*(typ *)&var)

#define sizeto(typ,mem) (offsetof(typ, mem) + sizeof(((typ*)0)->mem))

/*****************************************************************************/

#ifdef  NO_MISALIGNED_ACCESS

#define MISALIGNED_RD_I2(src)                   \
    (*castto(src  , char  *) |                  \
     *castto(src+1, char  *) << 8)

#define MISALIGNED_RD_U2(src)                   \
    (*castto(src  , char  *) |                  \
     *castto(src+1, char  *) << 8)

#define MISALIGNED_WR_I2(dst, val)              \
    *castto(dst  , char  *) = val;              \
    *castto(dst+1, char  *) = val >> 8;

#define MISALIGNED_WR_I4(dst, val)              \
    *castto(dst  , char  *) = val;              \
    *castto(dst+1, char  *) = val >> 8;         \
    *castto(dst+2, char  *) = val >> 16;        \
    *castto(dst+3, char  *) = val >> 24;

#else

#define MISALIGNED_RD_I2(src)                   \
    (*castto(src  ,          short *))
#define MISALIGNED_RD_U2(src)                   \
    (*castto(src  , unsigned short *))

#define MISALIGNED_WR_I2(dst, val)              \
    *castto(dst  ,           short *) = val;
#define MISALIGNED_WR_I4(dst, val)              \
    *castto(dst  ,           long  *) = val;

#endif

/*****************************************************************************/

#if     COUNT_CYCLES

extern  void            cycleCounterInit  ();
extern  void            cycleCounterBeg   ();
extern  void            cycleCounterPause ();
extern  void            cycleCounterResume();
extern  void            cycleCounterEnd   ();

#else

inline  void            cycleCounterInit  (){}
inline  void            cycleCounterBeg   (){}
inline  void            cycleCounterPause (){}
inline  void            cycleCounterResume(){}
inline  void            cycleCounterEnd   (){}

#endif

/*****************************************************************************/

inline
size_t              roundUp(size_t size, size_t mult = sizeof(int))
{
//  assert(mult == 2 || mult == 4 || mult == 8);

    return  (size + (mult - 1)) & ~(mult - 1);
}

inline
size_t              roundDn(size_t size, size_t mult = sizeof(int))
{
    assert(mult == 2 || mult == 4 || mult == 8);

    return  (size             ) & ~(mult - 1);
}

/*****************************************************************************/

#if defined(DEBUG) || !defined(NOT_JITC)

struct  histo
{
                    histo(unsigned * sizeTab, unsigned sizeCnt = 0);
                   ~histo();

    void            histoClr();
    void            histoDsp();
    void            histoRec(unsigned siz, unsigned cnt);

private:

    unsigned        histoSizCnt;
    unsigned    *   histoSizTab;

    unsigned    *   histoCounts;
};

#endif

/*****************************************************************************/
#if    !_WIN32_WCE
/*****************************************************************************/
#ifdef  ICECAP
#include "icapexp.h"
#include "icapctrl.h"
#endif
/*****************************************************************************/
#endif//!_WIN32_WCE
/*****************************************************************************/

#if defined(LATE_DISASM) && defined(JIT_AS_COMPILER)
#error "LATE_DISASM and JIT_AS_COMPILER should not be defined together"
#endif

/*****************************************************************************/

#ifndef FASTCALL
#define FASTCALL    __fastcall
#endif

/*****************************************************************************/

extern  unsigned    genCPU;

/*****************************************************************************/

#define SECURITY_CHECK          1

/*****************************************************************************/

#if !defined(RELOC_SUPPORT) && defined(NOT_JITC)
#define RELOC_SUPPORT          1
#endif

/*****************************************************************************/

#define GC_WRITE_BARRIER        0
#define GC_WRITE_BARRIER_CALL   1

#if     GC_WRITE_BARRIER
#if     GC_WRITE_BARRIER_CALL
#error "Can't enable both version of GC_WRITE_BARRIER at the same time"
#endif
#endif

/*****************************************************************************/

#define NEW_CALLINTERFACE             1
#define NEW_CALLINTERFACE_WITH_PUSH   1

/*****************************************************************************/

#include "alloc.h"
#include "target.h"

/*****************************************************************************/

#ifndef INLINE_MATH
#if     CPU_HAS_FP_SUPPORT
#define INLINE_MATH         1       //  enable inline math intrinsics
#else
#define INLINE_MATH         0       // disable inline math intrinsics
#endif
#endif

/*****************************************************************************/

#define CLFLG_CODESIZE        0x00001
#define CLFLG_CODESPEED       0x00002
#define CLFLG_CSE             0x00004
#define CLFLG_REGVAR          0x00008
#define CLFLG_RNGCHKOPT       0x00010
#define CLFLG_DEADASGN        0x00020
#define CLFLG_CODEMOTION      0x00040
#define CLFLG_QMARK           0x00080
#define CLFLG_TREETRANS       0x00100
#define CLFLG_TEMP_ALLOC      0x00200       // only used for IA64

#define CLFLG_MAXOPT         (CLFLG_CODESPEED  | \
                              CLFLG_CSE        | \
                              CLFLG_REGVAR     | \
                              CLFLG_RNGCHKOPT  | \
                              CLFLG_DEADASGN   | \
                              CLFLG_CODEMOTION | \
                              CLFLG_QMARK      | \
                              CLFLG_TREETRANS  | \
                              CLFLG_TEMP_ALLOC)

#define CLFLG_MINOPT         (CLFLG_REGVAR     | \
                              CLFLG_TREETRANS)

/*****************************************************************************/

#ifndef OPT_IL_JIT

#ifdef DEBUG
#define COMP_FULL_NAME  info.compFullName
#else
#define COMP_FULL_NAME  "Unknown Ftn"
#endif

#define NO_WAY(str)  {   fatal(ERRinternal, str, COMP_FULL_NAME);  }

#define BADCODE(str) {   fatal(ERRbadCode,  str, COMP_FULL_NAME);  }

#define NOMEM()      {   fatal(ERRnoMemory, NULL, NULL);              }

#else

#define NO_WAY(str)  {   fatal(ERRinternal, str);  }

#define BADCODE(str) {   fatal(ERRbadCode,  str);  }

#define NOMEM()      {   fatal(ERRnoMemory, NULL); }


#endif

/*****************************************************************************/

#ifndef NOT_JITC
extern  void        FASTCALL    jitStartup();
extern  void        FASTCALL    jitShutdown();
#endif

/*****************************************************************************/

#if TGT_IA64
extern  void    *               sourceFileImageBase;
#endif

/*****************************************************************************/

extern  unsigned                dumpSingleILopcode(const BYTE * codeAddr,
                                                   IL_OFFSET    offs,
                                                   const char * prefix = NULL );
extern  void                    disInitForLateDisAsm();

/*****************************************************************************/


#ifndef NOT_JITC
extern  int                     genCode4class(const char *classFile);

#else


extern  int         FASTCALL    jitNativeCode(METHOD_HANDLE     methodHnd,
                                              SCOPE_HANDLE      classHnd,
                                              COMP_HANDLE       compHnd,
                                              const  BYTE *     codeAddr,
                                              size_t            codeSize,
                                              unsigned          lclCount,
                                              unsigned          maxStack,
                                              JIT_METHOD_INFO * methodInfo,
                                              void *          * methodCodePtr,
                                              SIZE_T    *       nativeSizeOfCode,
                                              void *          * methodConsPtr,
                                              void *          * methodDataPtr,
                                              void *          * methodInfoPtr,
                                              unsigned          compileFlags);

#endif



/*****************************************************************************/
#endif //_JIT_H_
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\optimizer.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                              Optimizer                                    XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

/*****************************************************************************/

/* static */
const size_t            Compiler::s_optCSEhashSize = EXPSET_SZ*2;
/* static */
const size_t            Compiler::optRngChkHashSize = RNGSET_SZ*2;

#if COUNT_RANGECHECKS
/* static */
unsigned                Compiler::optRangeChkRmv = 0;
/* static */
unsigned                Compiler::optRangeChkAll = 0;
#endif

/*****************************************************************************/

void                Compiler::optInit()
{

    optArrayInits = false;

    /* Initialize the # of tracked loops to 0 */

#if RNGCHK_OPT
    optLoopCount  = 0;
#endif

}

/*****************************************************************************/
#if RNGCHK_OPT
/*****************************************************************************/

#ifdef  DEBUG

inline
BLOCKSET_TP         B1DOMSB2(BasicBlock *b1, BasicBlock *b2, Compiler *comp)
{
    assert(comp->fgComputedDoms);

    return ((b2)->bbDom & genBlocknum2bit((b1)->bbNum));
}

#define B1DOMSB2(b1,b2) B1DOMSB2(b1,b2,this)

#else

inline
BLOCKSET_TP         B1DOMSB2(BasicBlock *b1, BasicBlock *b2)
{
    assert(comp->optComputedDoms);

    return ((b2)->bbDom & genBlocknum2bit((b1)->bbNum));
}

#endif

/*****************************************************************************
 *
 *  Record the loop in the loop table.
 */

void                Compiler::optRecordLoop(BasicBlock *    head,
                                            BasicBlock *    bottom,
                                            BasicBlock *    entry,
                                            BasicBlock *    exit,
                                            unsigned char   exitCnt)
{
    /* record this loop in the table */

    if (optLoopCount < MAX_LOOP_NUM)
    {
        optLoopTable[optLoopCount].lpHead     = head;
        optLoopTable[optLoopCount].lpEnd      = bottom;
        optLoopTable[optLoopCount].lpEntry    = entry;
        optLoopTable[optLoopCount].lpExit     = exit;
        optLoopTable[optLoopCount].lpExitCnt  = exitCnt;

        optLoopTable[optLoopCount].lpFlags    = 0;

        /* if DO-WHILE loop mark it as such */

        if (head->bbNext == entry)
            optLoopTable[optLoopCount].lpFlags |= LPFLG_DO_WHILE;

        /* if single exit loop mark it as such */

        if (exitCnt == 1)
        {
            assert(exit);
            optLoopTable[optLoopCount].lpFlags |= LPFLG_ONE_EXIT;
        }

        /* CONSIDER: also mark infinite loops */


        /* Try to find loops that have an iterator (i.e. for-like loops) "for (init; test; incr){ ... }"
         * We have the following restrictions:
         *     1. The loop condition must be a simple one i.e. only one JTRUE node
         *     2. There must be a loop iterator (a local var) that is
         *        incremented (decremented, etc) with a constant value
         *     3. The iterator is incremented exactly once
         *     4. The loop condition must use the iterator */

        if  (bottom->bbJumpKind == BBJ_COND)
        {
            BasicBlock   *  block;

            GenTree *       test;               // holds the test node
            GenTree *       incr;               // holds the incrementor node
            GenTree *       phdr;
            GenTree *       init;               // holds the initialization node

            GenTree *       opr1;
            GenTree *       opr2;

            unsigned        iterVar;            // the local var # of the iterator
            long            iterConst;          // the constant with which we increment the iterator (i.e. i+=const)

            long            constInit;          // constant to which iterator is initialized
            unsigned short  varInit;            // local var # to which iterator is initialized

            long            constLimit;         // constant limit of the iterator
            unsigned short  varLimit;           // local var # limit of the iterator


            /* Find the last two statements in the loop body
             * Those have to be the "increment" of the iterator
             * and the loop condition */

            assert(bottom->bbTreeList);
            test = bottom->bbTreeList->gtPrev;
            assert(test && test->gtNext == 0);

            incr = test->gtPrev;
            if  (!incr)
                goto DONE_LOOP;

            /* Special case: incr and test may be in separate BB's
             * for "while" loops because we first jump to the condition */

            if  ((incr == test) && (head->bbNext != bottom))
            {
                block = head;

                do
                {
                    block = block->bbNext;
                }
                while  (block->bbNext != bottom);

                incr = block->bbTreeList;
                if  (!incr)
                    goto DONE_LOOP;

                incr = incr->gtPrev; assert(incr && (incr->gtNext == 0));
            }

            /* Find the last statement in the loop pre-header
             * which we expect to be the initialization of
             * the loop iterator */

            phdr = head->bbTreeList;
            if  (!phdr)
                goto DONE_LOOP;

            init = phdr->gtPrev; assert(init && (init->gtNext == 0));

            /* if it is a duplicated loop condition, skip it */

            if  (init->gtStmt.gtStmtExpr->gtOper == GT_JTRUE)
            {
                /* Must be a duplicated loop condition */

                init = init->gtPrev;
            }

            /* Get hold of the expression trees */

            assert(init->gtOper == GT_STMT); init = init->gtStmt.gtStmtExpr;
            assert(test->gtOper == GT_STMT); test = test->gtStmt.gtStmtExpr;
            assert(incr->gtOper == GT_STMT); incr = incr->gtStmt.gtStmtExpr;

//          printf("Constant loop candidate:\n\n");
//          printf("init:\n"); gtDispTree(init);
//          printf("incr:\n"); gtDispTree(incr);
//          printf("test:\n"); gtDispTree(test);

            /* The increment statement must be "lclVar <op>= const;" */

            switch (incr->gtOper)
            {
            case GT_ASG_ADD:
            case GT_ASG_SUB:
            case GT_ASG_MUL:
            case GT_ASG_DIV:
            case GT_ASG_RSH:
            case GT_ASG_LSH:
            case GT_ASG_UDIV:
                break;

            default:
                goto DONE_LOOP;
            }

            opr1 = incr->gtOp.gtOp1;
            opr2 = incr->gtOp.gtOp2;

            if  (opr1->gtOper != GT_LCL_VAR)
                goto DONE_LOOP;
            iterVar = opr1->gtLclVar.gtLclNum;

            if  (opr2->gtOper != GT_CNS_INT)
                goto DONE_LOOP;
            iterConst = opr2->gtIntCon.gtIconVal;

            /* Make sure "iterVar" is not assigned in the loop (besides where we increment it) */

            if  (optIsVarAssigned(head->bbNext, bottom, incr, iterVar))
                goto DONE_LOOP;

            /* Make sure the "iterVar" initialization is never skipped, i.e. HEAD dominates the ENTRY */

            if (!B1DOMSB2(head, entry))
                goto DONE_LOOP;

            /* Make sure the block before the loop ends with "iterVar = icon"
             * or "iterVar = other_lvar" */

            if  (init->gtOper != GT_ASG)
                goto DONE_LOOP;

            opr1 = init->gtOp.gtOp1;
            opr2 = init->gtOp.gtOp2;

            if  (opr1->gtOper != GT_LCL_VAR)
                goto DONE_LOOP;
            if  (opr1->gtLclVar.gtLclNum != iterVar)
                goto DONE_LOOP;

            if  (opr2->gtOper == GT_CNS_INT)
            {
                constInit = opr2->gtIntCon.gtIconVal;
            }
            else if (opr2->gtOper == GT_LCL_VAR)
            {
                varInit = opr2->gtLclVar.gtLclNum;
            }
            else
                goto DONE_LOOP;

            /* check that the iterator is used in the loop condition */

            assert(test->gtOper == GT_JTRUE);
            assert(test->gtOp.gtOp1->OperKind() & GTK_RELOP);
            assert(bottom->bbTreeList->gtPrev->gtStmt.gtStmtExpr == test);

            opr1 = test->gtOp.gtOp1->gtOp.gtOp1;

            if  (opr1->gtOper != GT_LCL_VAR)
                goto DONE_LOOP;
            if  (opr1->gtLclVar.gtLclNum != iterVar)
                goto DONE_LOOP;

            /* We know the loop has an iterator at this point ->flag it as LPFLG_ITER
             * Record the iterator, the pointer to the test node
             * and the initial value of the iterator (constant or local var) */

            optLoopTable[optLoopCount].lpFlags    |= LPFLG_ITER;

            /* record iterator */

            optLoopTable[optLoopCount].lpIterTree  = incr;

            /* save the initial value of the iterator - can be lclVar or constant
             * Flag the loop accordingly */

            if (opr2->gtOper == GT_CNS_INT)
            {
                /* initializer is a constant */

                optLoopTable[optLoopCount].lpConstInit  = constInit;
                optLoopTable[optLoopCount].lpFlags     |= LPFLG_CONST_INIT;
            }
            else
            {
                /* initializer is a local variable */

                assert (opr2->gtOper == GT_LCL_VAR);
                optLoopTable[optLoopCount].lpVarInit    = varInit;
                optLoopTable[optLoopCount].lpFlags     |= LPFLG_VAR_INIT;
            }

#if COUNT_LOOPS
            iterLoopCount++;
#endif

            /* Now check if a simple condition loop (i.e. "iter REL_OP icon or lclVar"
             * UNDONE: Consider also instanceVar */

            //
            // UNSIGNED_ISSUE : Extend this to work with unsigned operators
            //

            assert(test->gtOper == GT_JTRUE);
            test = test->gtOp.gtOp1;
            assert(test->OperKind() & GTK_RELOP);

            opr1 = test->gtOp.gtOp1;
            opr2 = test->gtOp.gtOp2;

            if  (opr1->gtType != TYP_INT)
                goto DONE_LOOP;

            /* opr1 has to be the iterator */

            if  (opr1->gtOper != GT_LCL_VAR)
                goto DONE_LOOP;
            if  (opr1->gtLclVar.gtLclNum != iterVar)
                goto DONE_LOOP;

            /* opr2 has to be constant or lclVar */

            if  (opr2->gtOper == GT_CNS_INT)
            {
                constLimit = opr2->gtIntCon.gtIconVal;
            }
            else if (opr2->gtOper == GT_LCL_VAR)
            {
                varLimit  = opr2->gtLclVar.gtLclNum;
            }
            else
            {
                goto DONE_LOOP;
            }

            /* Record the fact that this is a SIMPLE_TEST iteration loop */

            optLoopTable[optLoopCount].lpFlags         |= LPFLG_SIMPLE_TEST;

            /* save the type of the comparisson between the iterator and the limit */

            optLoopTable[optLoopCount].lpTestTree       = test;

            /* save the limit of the iterator - flag the loop accordingly */

            if (opr2->gtOper == GT_CNS_INT)
            {
                /* iterator limit is a constant */

                optLoopTable[optLoopCount].lpFlags      |= LPFLG_CONST_LIMIT;
            }
            else
            {
                /* iterator limit is a local variable */

                assert (opr2->gtOper == GT_LCL_VAR);
                optLoopTable[optLoopCount].lpFlags      |= LPFLG_VAR_LIMIT;
            }

#if COUNT_LOOPS
            simpleTestLoopCount++;
#endif

            /* check if a constant iteration loop */

            if ((optLoopTable[optLoopCount].lpFlags & LPFLG_CONST_INIT) &&
                (optLoopTable[optLoopCount].lpFlags & LPFLG_CONST_LIMIT)  )
            {
                /* this is a constant loop */

                optLoopTable[optLoopCount].lpFlags      |= LPFLG_CONST;
#if COUNT_LOOPS
                constIterLoopCount++;
#endif
            }

#ifdef  DEBUG
            if (verbose&&0)
            {
                printf("\nConstant loop initializer:\n");
                gtDispTree(init);

                printf("\nConstant loop body:\n");

                block = head;
                do
                {
                    GenTree *       stmt;
                    GenTree *       expr;

                    block = block->bbNext;
                    stmt  = block->bbTreeList;

                    while (stmt)
                    {
                        assert(stmt);

                        expr = stmt->gtStmt.gtStmtExpr;
                        if  (expr == incr)
                            break;

                        printf("\n");
                        gtDispTree(expr);

                        stmt = stmt->gtNext;
                    }
                }
                while (block != bottom);
            }
#endif

        }


    DONE_LOOP:

#ifdef  DEBUG

        if (verbose)
        {
            printf("\nNatural loop from #%02u to #%02u", head->bbNext->bbNum,
                                                         bottom      ->bbNum);

            /* if an iterator loop print the iterator and the initialization */

            if  (optLoopTable[optLoopCount].lpFlags & LPFLG_ITER)
            {
                printf(" [over var #%u", optLoopTable[optLoopCount].lpIterVar());

                switch (optLoopTable[optLoopCount].lpIterOper())
                {
                    case GT_ASG_ADD:
                        printf(" ( += ");
                        break;

                    case GT_ASG_SUB:
                        printf(" ( -= ");
                        break;

                    case GT_ASG_MUL:
                        printf(" ( *= ");
                        break;

                    case GT_ASG_DIV:
                        printf(" ( /= ");
                        break;

                    case GT_ASG_UDIV:
                        printf(" ( /= ");
                        break;

                    case GT_ASG_RSH:
                        printf(" ( >>= ");
                        break;

                    case GT_ASG_LSH:
                        printf(" ( <<= ");
                        break;

                    default:
                        assert(!"Unknown operator for loop iterator");
                }

                printf("%d )", optLoopTable[optLoopCount].lpIterConst());

                if  (optLoopTable[optLoopCount].lpFlags & LPFLG_CONST_INIT)
                    printf(" from %d", optLoopTable[optLoopCount].lpConstInit);

                if  (optLoopTable[optLoopCount].lpFlags & LPFLG_VAR_INIT)
                    printf(" from var #%u", optLoopTable[optLoopCount].lpVarInit);

                /* if a simple test condition print operator and the limits */

                if  (optLoopTable[optLoopCount].lpFlags & LPFLG_SIMPLE_TEST)
                {
                    switch (optLoopTable[optLoopCount].lpTestOper())
                    {
                        case GT_EQ:
                            printf(" == ");
                            break;

                        case GT_NE:
                            printf(" != ");
                            break;

                        case GT_LT:
                            printf(" < ");
                            break;

                        case GT_LE:
                            printf(" <= ");
                            break;

                        case GT_GT:
                            printf(" > ");
                            break;

                        case GT_GE:
                            printf(" >= ");
                            break;

                        default:
                            assert(!"Unknown operator for loop condition");
                    }

                    if  (optLoopTable[optLoopCount].lpFlags & LPFLG_CONST_LIMIT)
                        printf("%d ", optLoopTable[optLoopCount].lpConstLimit());

                    if  (optLoopTable[optLoopCount].lpFlags & LPFLG_VAR_LIMIT)
                        printf("var #%u ", optLoopTable[optLoopCount].lpVarLimit());
                }

                printf("]");
            }

            printf("\n");
        }
#endif

        optLoopCount++;
    }
}


#ifdef DEBUG

void                Compiler::optCheckPreds()
{
    BasicBlock   *  block;
    BasicBlock   *  blockPred;
    flowList     *  pred;

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        for (pred = block->bbPreds; pred; pred = pred->flNext)
        {
            // make sure this pred is part of the BB list
            for (blockPred = fgFirstBB; blockPred; blockPred = blockPred->bbNext)
            {
                if (blockPred == pred->flBlock)
                    break;
            }
            assert(blockPred);
            switch (blockPred->bbJumpKind)
            {
            case BBJ_COND:
                if (blockPred->bbJumpDest == block)
                    break;
                // otherwise fall through
            case BBJ_NONE:
                assert(blockPred->bbNext == block);
                break;
            case BBJ_RET:
                if(!(blockPred->bbFlags & BBF_ENDFILTER))
                    break;
                // otherwise fall through
            case BBJ_ALWAYS:
                assert(blockPred->bbJumpDest == block);
                break;
            default:
                break;
            }
        }
    }
}

#endif

/*****************************************************************************
 * Find the natural loops, using dominators. Note that the test for
 * a loop is slightly different from the standard one, because we have
 * not done a depth first reordering of the basic blocks.
 */

void                Compiler::optFindNaturalLoops()
{
    flowList    *   pred;
    flowList    *   predTop;
    flowList    *   predEntry;

    /* UNDONE: Assert the flowgraph is up to date */

//  printf("block count = %u (max = %u)\n", fgBBcount, BLOCKSET_SZ);

    /* Limit our count of blocks for dominator sets */

    if (fgBBcount > BLOCKSET_SZ)
        return;

#ifdef DEBUG
    if (verbose)
        fgDispDoms();
#endif

#if COUNT_LOOPS
    hasMethodLoops  = false;
    loopsThisMethod = 0;
#endif

    /* We will use the following terminology:
     * HEAD    - the block right before entering the loop
     * TOP     - the first basic block in the loop (i.e. the head of the backward edge)
     * BOTTOM  - the last block in the loop (i.e. the block from which we jump to the top)
     * TAIL    - the loop exit or the block right after the bottom
     * ENTRY   - the entry in the loop (not necessarly the TOP), but there must be only one entry
     */

    BasicBlock   *  head;
    BasicBlock   *  top;
    BasicBlock   *  bottom;
    BasicBlock   *  entry;
    BasicBlock   *  exit = 0;
    unsigned char   exitCount = 0;


    for (head = fgFirstBB; head->bbNext; head = head->bbNext)
    {
        top = head->bbNext;

        for (pred = top->bbPreds; pred; pred = pred->flNext)
        {
            /* Is this a loop candidate? - We look for "back edges", i.e. an edge from BOTTOM
             * to TOP (note that this is an abuse of notation since this is not necesarly a back edge
             * as the definition says, but merely an indication that we have a loop there)
             * Thus, we have to be very careful and after entry discovery check that it is indeed
             * the only place we enter the loop (especially for non-reducible flow graphs) */

            bottom    = pred->flBlock;
            exitCount = 0;

            if (top->bbNum <= bottom->bbNum)    // is this a backward edge? (from BOTTOM to TOP)
            {
                if ((bottom->bbJumpKind == BBJ_RET)    ||
                    (bottom->bbJumpKind == BBJ_CALL  ) ||
                    (bottom->bbJumpKind == BBJ_SWITCH)  )
                {
                    /* RET and CALL can never form a loop
                     * SWITCH that has a backward jump appears only for labeled break */
                    goto NO_LOOP;
                }

                BasicBlock   *   loopBlock;

                /* The presence of a "back edge" is an indication that a loop might be present here
                 *
                 * LOOP:
                 *        1. A collection of STRONGLY CONNECTED nodes i.e. there is a path from any
                 *           node in the loop to any other node in the loop (wholly within the loop)
                 *        2. The loop has a unique ENTRY, i.e. there is only one way to reach a node
                 *           in the loop from outside the loop, and that is through the ENTRY
                 */

                /* Let's find the loop ENTRY */

                if ( head->bbJumpKind != BBJ_ALWAYS)
                {
                    /* The ENTRY is at the TOP (a do-while loop) */
                    entry = top;
                }
                else
                {
                    if (head->bbJumpDest->bbNum <= bottom->bbNum &&
                        head->bbJumpDest->bbNum >= top->bbNum  )
                    {
                        /* OK - we enter somewhere within the loop */
                        entry = head->bbJumpDest;

                        /* some useful asserts
                         * Cannot enter at the top - should have being caught by redundant jumps */

                        assert (entry != top);
                    }
                    else
                    {
                        /* special case - don't consider now */
                        //assert (!"Loop entered in weird way!");
                        goto NO_LOOP;
                    }
                }

                /* Make sure ENTRY dominates all blocks in the loop
                 * This is necessary to ensure condition 2. above
                 * At the same time check if the loop has a single exit
                 * point - those loops are easier to optimize */

                for (loopBlock = top; loopBlock != bottom->bbNext;
                     loopBlock = loopBlock->bbNext)
                {
                    if (!B1DOMSB2(entry, loopBlock))
                    {
                        goto NO_LOOP;
                    }

                    if (loopBlock == bottom)
                    {
                        if (bottom->bbJumpKind != BBJ_ALWAYS)
                        {
                            /* there is an exit at the bottom */

                            assert(bottom->bbJumpDest == top);
                            exit = bottom;
                            exitCount++;
                            continue;
                        }
                    }

                    BasicBlock  * exitPoint;

                    switch (loopBlock->bbJumpKind)
                    {
                    case BBJ_COND:
                    case BBJ_CALL:
                    case BBJ_ALWAYS:
                        assert (loopBlock->bbJumpDest);
                        exitPoint = loopBlock->bbJumpDest;

                        if (exitPoint->bbNum < top->bbNum     ||
                            exitPoint->bbNum > bottom->bbNum   )
                        {
                            /* exit from a block other than BOTTOM */
                            exit = loopBlock;
                            exitCount++;
                        }
                        break;

                    case BBJ_NONE:
                        break;

                    case BBJ_RET:
                        /* The "try" associated with this "finally" must be in the
                         * same loop, so the finally block will return control inside the loop */
                        break;

                    case BBJ_THROW:
                    case BBJ_RETURN:
                        /* those are exits from the loop */
                        exit = loopBlock;
                        exitCount++;
                        break;

                    case BBJ_SWITCH:

                        unsigned        jumpCnt = loopBlock->bbJumpSwt->bbsCount;
                        BasicBlock * *  jumpTab = loopBlock->bbJumpSwt->bbsDstTab;

                        do
                        {
                            assert(*jumpTab);
                            exitPoint = *jumpTab;

                            if (exitPoint->bbNum < top->bbNum     ||
                                exitPoint->bbNum > bottom->bbNum   )
                            {
                                exit = loopBlock;
                                exitCount++;
                            }
                        }
                        while (++jumpTab, --jumpCnt);
                        break;
                    }
                }

                /* Make sure we can iterate the loop (i.e. there is a way back to ENTRY)
                 * This is to ensure condition 1. above which prevents marking fake loops
                 *
                 * Below is an example:
                 *          for(....)
                 *          {
                 *            ...
                 *              computations
                 *            ...
                 *            break;
                 *          }
                 * The example above is not a loop since we bail after the first iteration
                 *
                 * The condition we have to check for is
                 *  1. ENTRY must have at least one predecessor inside the loop. Since we know that that block is reacheable,
                 *     it can only be reached through ENTRY, therefore we have a way back to ENTRY
                 *
                 *  2. If we have a GOTO (BBJ_ALWAYS) outside of the loop and that block dominates the
                 *     loop bottom then we cannot iterate
                 *
                 * NOTE that this doesn't entirely satisfy condition 1. since "break" statements are not
                 * part of the loop nodes (as per definition they are loop exits executed only once),
                 * but we have no choice but to include them because we consider all blocks within TOP-BOTTOM */


                for (loopBlock = top; loopBlock != bottom->bbNext; loopBlock = loopBlock->bbNext)
                {
                    switch(loopBlock->bbJumpKind)
                    {
                    case BBJ_ALWAYS:
                    case BBJ_THROW:
                    case BBJ_RETURN:
                        if  (B1DOMSB2(loopBlock, bottom))
                            goto NO_LOOP;
                    }
                }

                bool canIterateLoop = false;

                for (predEntry = entry->bbPreds; predEntry; predEntry = predEntry->flNext)
                {
                    if (predEntry->flBlock->bbNum >= top->bbNum    &&
                        predEntry->flBlock->bbNum <= bottom->bbNum  )
                    {
                        canIterateLoop = true;
                        break;
                    }
                }

                if (!canIterateLoop)
                    goto NO_LOOP;

                /* Double check - make sure that all loop blocks except ENTRY
                 * have no predecessors outside the loop - this ensures only one loop entry and prevents
                 * us from considering non-loops due to incorrectly assuming that we had a back edge
                 *
                 * OBSERVATION:
                 *    Loops of the form "while (a || b)" will be treated as 2 nested loops (with the same header)
                 */

                for (loopBlock = top; loopBlock != bottom->bbNext;
                     loopBlock = loopBlock->bbNext)
                {
                    if (loopBlock == entry)
                        continue;

                    for (predTop = loopBlock->bbPreds; predTop;
                         predTop = predTop->flNext)
                    {
                        if (predTop->flBlock->bbNum < top->bbNum    ||
                            predTop->flBlock->bbNum > bottom->bbNum  )
                        {
                            /* CONSIDER: if the predecessor is a jsr-ret, it can be outside the loop */
                            //assert(!"Found loop with multiple entries");
                            goto NO_LOOP;
                        }
                    }
                 }

                /* At this point we have a loop - record it in the loop table
                 * If we found only one exit, record it in the table too
                 * (otherwise an exit = 0 in the loop table means multiple exits) */

                assert (pred);
                if (exitCount > 1)
                {
                    exit = 0;
                }
                optRecordLoop(head, bottom, entry, exit, exitCount);

#if COUNT_LOOPS
                if (!hasMethodLoops)
                {
                    /* mark the method as containing natural loops */
                    totalLoopMethods++;
                    hasMethodLoops = true;
                }

                /* increment total number of loops found */
                totalLoopCount++;
                loopsThisMethod++;

                /* keep track of the number of exits */
                if (exitCount <= 6)
                {
                    exitLoopCond[exitCount]++;
                }
                else
                {
                    exitLoopCond[7]++;
                }
#endif
            }

            /* current predecessor not good for a loop - continue with another one, if any */
NO_LOOP: ;
        }
    }

#if COUNT_LOOPS
                if (maxLoopsPerMethod < loopsThisMethod)
                {
                    maxLoopsPerMethod = loopsThisMethod;
                }
#endif

}

/*****************************************************************************
 * If the : i += const" will cause an overflow exception for the small types.
 */

bool                jitIterSmallOverflow(long iterAtExit, var_types incrType)
{
    long            type_MAX;

    switch(incrType)
    {
    case TYP_BYTE:  type_MAX = SCHAR_MAX;   break;
    case TYP_UBYTE: type_MAX = UCHAR_MAX;   break;
    case TYP_SHORT: type_MAX =  SHRT_MAX;   break;
    case TYP_CHAR:  type_MAX = USHRT_MAX;   break;

    case TYP_UINT:                  // Detected by checking for 32bit ....
    case TYP_INT:   return false;   // ... overflow same as done for TYP_INT

    default:        assert(!"Bad type");    break;
    }

    if (iterAtExit > type_MAX)
        return true;
    else
        return false;
}

/*****************************************************************************
 * If the "i -= const" will cause an underflow exception for the small types
 */

bool                jitIterSmallUnderflow(long iterAtExit, var_types decrType)
{
    long            type_MIN;

    switch(decrType)
    {
    case TYP_BYTE:  type_MIN = SCHAR_MIN;   break;
    case TYP_SHORT: type_MIN =  SHRT_MIN;   break;
    case TYP_UBYTE: type_MIN =         0;   break;
    case TYP_CHAR:  type_MIN =         0;   break;

    case TYP_UINT:                  // Detected by checking for 32bit ....
    case TYP_INT:   return false;   // ... underflow same as done for TYP_INT

    default:        assert(!"Bad type");    break;
    }

    if (iterAtExit < type_MIN)
        return true;
    else
        return false;
}

/*****************************************************************************
 *
 *  Helper for unroll loops - Computes the number of repetitions
 *  in a constant loop. If it cannot prove the number is constant returns 0
 */

unsigned            Compiler::optComputeLoopRep(long            constInit,
                                                long            constLimit,
                                                long            iterInc,
                                                genTreeOps      iterOper,
                                                var_types       iterOperType,
                                                genTreeOps      testOper,
                                                bool            unsTest)
{
    assert(genActualType(iterOperType) == TYP_INT);

    __int64         constInitX, constLimitX;

    // Using this, we can just do a signed comparison with other 32 bit values.
    if (unsTest)    constLimitX = (unsigned long)constLimit;
    else            constLimitX = (  signed long)constLimit;

    switch(iterOperType)
    {
        // For small types, the iteration operator will narrow these values if big

        #define INIT_ITER_BY_TYPE(type) \
            constInitX = (type)constInit; iterInc = (type)iterInc;

    case TYP_BYTE:  INIT_ITER_BY_TYPE(  signed char );  break;
    case TYP_UBYTE: INIT_ITER_BY_TYPE(unsigned char );  break;
    case TYP_SHORT: INIT_ITER_BY_TYPE(  signed short);  break;
    case TYP_CHAR:  INIT_ITER_BY_TYPE(unsigned short);  break;

        // For the big types, 32 bit arithmetic is performed

    case TYP_INT:
    case TYP_UINT:  if (unsTest)    constInitX = (unsigned long)constInit;
                    else            constInitX = (  signed long)constInit;
                                                        break;

    default:        assert(!"Bad type");                break;
    }

    /* We require that the increment in a positive value */

    if (iterInc <= 0)
        return 0;

    /* Compute the number of repetitions */

    switch (testOper)
    {
        unsigned    loopCount;
        __int64     iterAtExitX;

        case GT_EQ:
            /* something like "for(i=init; i == lim; i++)" doesn't make sense */
            return 0;

        case GT_NE:
            /* "for(i=init; i != lim; i+=const)" - this is tricky since it may have a constant number
             * of iterations or loop forever - have to compute (lim-init) mod const and see if it is 0
             * Unlikely to appear in practice */

            //assert(!"for(i=init; i != lim; i+=const) situation in loop unrolling");
            return 0;

        case GT_LT:
            switch (iterOper)
            {
                case GT_ASG_ADD:
                    if (constInitX >= constLimitX)
                        return 0;

                    loopCount  = (unsigned)(1 + ((constLimitX - constInitX - 1) /
                                                       iterInc));

                    iterAtExitX = (long)(constInitX + iterInc * (long)loopCount);

                    if (unsTest)
                        iterAtExitX = (unsigned)iterAtExitX;

                    // Check if iteration incr will cause overflow for small types
                    if (jitIterSmallOverflow((long)iterAtExitX, iterOperType))
                        return 0;

                    // iterator with 32bit overflow. Bad for TYP_(U)INT
                    if (iterAtExitX < constLimitX)
                        return 0;

                    return loopCount;

                case GT_ASG_SUB:
                    /* doesn't make sense */
                    //assert(!"for(i=init; i < lim; i-=const) situation in loop unrolling");
                    return 0;

                case GT_ASG_MUL:
                case GT_ASG_DIV:
                case GT_ASG_RSH:
                case GT_ASG_LSH:
                case GT_ASG_UDIV:
                    return 0;

                default:
                    assert(!"Unknown operator for loop iterator");
                    return 0;
            }

        case GT_LE:
            switch (iterOper)
            {
                case GT_ASG_ADD:
                    if (constInitX > constLimitX)
                        return 0;

                    loopCount  = (unsigned)(1 + ((constLimitX - constInitX) /
                                                    iterInc));

                    iterAtExitX = (long)(constInitX + iterInc * (long)loopCount);

                    if (unsTest)
                        iterAtExitX = (unsigned)iterAtExitX;

                    // Check if iteration incr will cause overflow for small types
                    if (jitIterSmallOverflow((long)iterAtExitX, iterOperType))
                        return 0;

                    // iterator with 32bit overflow. Bad for TYP_(U)INT
                    if (iterAtExitX <= constLimitX)
                        return 0;

                    return loopCount;

                case GT_ASG_SUB:
                    /* doesn't make sense */
                    //assert(!"for(i=init; i <= lim; i-=const) situation in loop unrolling");
                    return 0;

                case GT_ASG_MUL:
                case GT_ASG_DIV:
                case GT_ASG_RSH:
                case GT_ASG_LSH:
                case GT_ASG_UDIV:
                    return 0;

                default:
                    assert(!"Unknown operator for loop iterator");
                    return 0;
            }

        case GT_GT:
            switch (iterOper)
            {
                case GT_ASG_ADD:
                    /* doesn't make sense */
                    //assert(!"for(i=init; i > lim; i+=const) situation in loop unrolling");
                    return 0;

                case GT_ASG_SUB:
                    if (constInitX <= constLimitX)
                        return 0;

                    loopCount  = (unsigned)(1 + ((constInitX - constLimitX - 1) /
                                                        iterInc));

                    iterAtExitX = (long)(constInitX - iterInc * (long)loopCount);

                    if (unsTest)
                        iterAtExitX = (unsigned)iterAtExitX;

                    // Check if small types will underflow
                    if (jitIterSmallUnderflow((long)iterAtExitX, iterOperType))
                        return 0;

                    // iterator with 32bit underflow. Bad for TYP_INT and unsigneds
                    if (iterAtExitX > constLimitX)
                        return 0;

                    return loopCount;

                case GT_ASG_MUL:
                case GT_ASG_DIV:
                case GT_ASG_RSH:
                case GT_ASG_LSH:
                case GT_ASG_UDIV:
                    return 0;

                default:
                    assert(!"Unknown operator for loop iterator");
                    return 0;
            }

        case GT_GE:
            switch (iterOper)
            {
                case GT_ASG_ADD:
                    /* doesn't make sense */
                    //assert(!"for(i=init; i >= lim; i+=const) situation in loop unrolling");
                    return 0;

                case GT_ASG_SUB:
                    if (constInitX < constLimitX)
                        return 0;

                    loopCount  = (unsigned)(1 + ((constInitX - constLimitX) /
                                                    iterInc));
                    iterAtExitX = (long)(constInitX - iterInc * (long)loopCount);

                    if (unsTest)
                        iterAtExitX = (unsigned)iterAtExitX;

                    // Check if small types will underflow
                    if (jitIterSmallUnderflow((long)iterAtExitX, iterOperType))
                        return 0;

                    // iterator with 32bit underflow. Bad for TYP_INT and unsigneds
                    if (iterAtExitX >= constLimitX)
                        return 0;

                    return loopCount;

                case GT_ASG_MUL:
                case GT_ASG_DIV:
                case GT_ASG_RSH:
                case GT_ASG_LSH:
                case GT_ASG_UDIV:
                    return 0;

                default:
                    assert(!"Unknown operator for loop iterator");
                    return 0;
            }

        default:
            assert(!"Unknown operator for loop condition");
            return 0;
    }

    return 0;
}


/*****************************************************************************
 *
 *  Look for loop unrolling candidates and unroll them
 */

void                Compiler::optUnrollLoops()
{
    /* Look for loop unrolling candidates */

    for (;;)
    {
        bool        change = false;

        for (unsigned lnum = 0; lnum < optLoopCount; lnum++)
        {
            BasicBlock *    block;
            BasicBlock *    head;
            BasicBlock *    bottom;

            GenTree *       loop;
            GenTree *       test;
            GenTree *       incr;
            GenTree *       phdr;
            GenTree *       init;

            long            lval;
            long            lbeg;               // initial value for iterator
            long            llim;               // limit value for iterator
            unsigned        lvar;               // iterator lclVar #
            long            iterInc;            // value to increment the iterator
            genTreeOps      iterOper;           // type of iterator increment (i.e. ASG_ADD, ASG_SUB, etc.)
            var_types       iterOperType;       // type result of the oper (for overflow instrs)
            genTreeOps      testOper;           // type of loop test (i.e. GT_LE, GT_GE, etc.)
            bool            unsTest;            // Is the comparison u/int

            unsigned        totalIter;          // total number of iterations in the constant loop
            unsigned        stmtCount;          // counts the statements in the unrolled loop

            GenTree *       loopList;           // new stmt list of the unrolled loop
            GenTree *       loopLast;

            /* Ignore the loop if it's not "constant" */

            if  (!(optLoopTable[lnum].lpFlags & LPFLG_CONST))
                continue;

            /* ignore if removed or marked as not unrollable */

            if  (optLoopTable[lnum].lpFlags & (LPFLG_DONT_UNROLL | LPFLG_REMOVED))
                continue;

            /* to unroll the loop it has to be a DO-WHILE loop
             * with a single EXIT at the bottom */

            if  (!(optLoopTable[lnum].lpFlags & LPFLG_DO_WHILE))
                continue;

            if  (!(optLoopTable[lnum].lpFlags & LPFLG_ONE_EXIT))
                continue;

            head = optLoopTable[lnum].lpHead; assert(head);
            bottom = optLoopTable[lnum].lpEnd; assert(bottom);

            assert(optLoopTable[lnum].lpExit);
            if  (optLoopTable[lnum].lpExit != bottom)
                continue;

            /* Unrolling loops with jumps in them is not worth the headache
             * Later we might consider unrolling loops after un-switching */

            /* Since the flowgraph has been updated (i.e. compacted blocks),
             * the loop to unroll consists of only one basic block */

            block = head;
            do
            {
                block = block->bbNext; assert(block);

                if  (block->bbJumpKind != BBJ_NONE)
                {
                    if  (block != bottom)
                        goto DONE_LOOP;
                }
            }
            while (block != bottom);

            /* Enable this assert after you fixed the bbPreds and compacted blocks after unroling */
            //assert(head->bbNext == bottom);

            /* Get the loop data:
                - initial constant
                - limit constant
                - iterator
                - iterator increment
                - increment operation type (i.e. ASG_ADD, ASG_SUB, etc...)
                - loop test type (i.e. GT_GE, GT_LT, etc...)
             */

            lbeg        = optLoopTable[lnum].lpConstInit;
            llim        = optLoopTable[lnum].lpConstLimit();
            testOper    = optLoopTable[lnum].lpTestOper();

            lvar        = optLoopTable[lnum].lpIterVar();
            iterInc     = optLoopTable[lnum].lpIterConst();
            iterOper    = optLoopTable[lnum].lpIterOper();

            iterOperType= optLoopTable[lnum].lpIterOperType();
            unsTest     =(optLoopTable[lnum].lpTestTree->gtFlags & GTF_UNSIGNED) != 0;
            if (lvaVarAddrTaken(lvar))
                continue;

            /* Find the number of iterations - the function returns 0 if not a constant number */

            totalIter = optComputeLoopRep(lbeg, llim,
                                          iterInc, iterOper, iterOperType,
                                          testOper, unsTest);

            /* Forget it if there are too many repetitions or not a constant loop */

            if  (!totalIter || (totalIter > 10))
                continue;

            /* Locate the initialization and increment/test statements */

            phdr = head->bbTreeList; assert(phdr);
            loop = bottom->bbTreeList; assert(loop);

            init = phdr->gtPrev; assert(init && (init->gtNext == 0));
            test = loop->gtPrev; assert(test && (test->gtNext == 0));
            incr = test->gtPrev; assert(incr);

            /* HACK */

            if  (init->gtFlags & GTF_STMT_CMPADD)
            {
                /* Must be a duplicated loop condition */

                init = init->gtPrev; assert(init);
            }

            assert(init->gtOper == GT_STMT); init = init->gtStmt.gtStmtExpr;
            assert(test->gtOper == GT_STMT); test = test->gtStmt.gtStmtExpr;
            assert(incr->gtOper == GT_STMT); incr = incr->gtStmt.gtStmtExpr;

            assert(init->gtOper             == GT_ASG);
            assert(incr->gtOp.gtOp1->gtOper == GT_LCL_VAR);
            assert(incr->gtOp.gtOp2->gtOper == GT_CNS_INT);
            assert(test->gtOper             == GT_JTRUE);

            /* Simple heuristic - total number of statements of the unrolled loop */

            stmtCount = 0;

            do
            {
                GenTree *       stmt;
                GenTree *       expr;

                /* Visit all the statements in the block */

                for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
                {
                    /* Get the expression and stop if end reached */

                    expr = stmt->gtStmt.gtStmtExpr;
                    if  (expr == incr)
                        break;

                    stmtCount++;
                }
            }
            while (block != bottom);

            /* Compute total number of statements in the unrolled loop */

            stmtCount *= totalIter;

            //printf("Statement count = %d\n", stmtCount);

            /* Don't unroll if too much code duplication would result */

            if  (stmtCount > 50)
            {
                /* prevent this loop from being revisited */
                optLoopTable[lnum].lpFlags |= LPFLG_DONT_UNROLL;
                goto DONE_LOOP;
            }

            /* Looks like a good idea to unroll this loop, let's do it! */

            /* Make sure everything looks ok */

            assert(init->gtOper                         == GT_ASG);
            assert(init->gtOp.gtOp1->gtOper             == GT_LCL_VAR);
            assert(init->gtOp.gtOp1->gtLclVar.gtLclNum  == lvar);
            assert(init->gtOp.gtOp2->gtOper             == GT_CNS_INT);
            assert(init->gtOp.gtOp2->gtIntCon.gtIconVal == lbeg);

            /* Create the unrolled loop statement list */

            loopList =
            loopLast = 0;

            for (lval = lbeg; totalIter; totalIter--)
            {
                block = head;

                do
                {
                    GenTree *       stmt;
                    GenTree *       expr;

                    block = block->bbNext; assert(block);

                    /* Visit all the statements in the block */

                    for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
                    {
                        /* Stop if we've reached the end of the loop */

                        if  (stmt->gtStmt.gtStmtExpr == incr)
                            break;

//                        printf("\nExpression before clonning:\n");
//                        gtDispTree(stmt);

                        /* Clone/substitute the expression */

                        expr = gtCloneExpr(stmt, 0, lvar, lval);

                        // HACK: cloneExpr doesn't handle everything

                        if  (!expr)
                        {
                            optLoopTable[lnum].lpFlags |= LPFLG_DONT_UNROLL;
                            goto DONE_LOOP;
                        }

//                        printf("\nExpression after clonning:\n");
//                        gtDispTree(expr);

                        /* Append the expression to our list */

                        if  (loopList)
                            loopLast->gtNext = expr;
                        else
                            loopList         = expr;

                        expr->gtPrev = loopLast;
                                       loopLast = expr;
                    }
                }
                while (block != bottom);

                /* update the new value for the unrolled iterator */

                switch (iterOper)
                {
                    case GT_ASG_ADD:
                        lval += iterInc;
                        break;

                    case GT_ASG_SUB:
                        lval -= iterInc;
                        break;

                    case GT_ASG_RSH:
                    case GT_ASG_LSH:
                        assert(!"Unrolling not implemented for this loop iterator");
                        goto DONE_LOOP;
                    default:
                        assert(!"Unknown operator for constant loop iterator");
                        goto DONE_LOOP;
                }
            }

#ifdef  DEBUG
            if (verbose)
            {
                printf("\nUnrolling loop [BB %2u..%2u] ", head->bbNext->bbNum,
                                                          bottom        ->bbNum);
                printf(" over var # %2u from %u to %u", lvar, lbeg, llim);
                printf(" [# of unrolled Stmts = %u]\n", stmtCount);
                printf("\n");
            }
#endif

            /* Finish the linked list */

            if (loopList)
            {
                loopList->gtPrev = loopLast;
                loopLast->gtNext = 0;
            }

            /* Replace the body with the unrolled one */

            /* Disable this when sure that loop is only one block */
            block = head;

            do
            {
                block             = block->bbNext; assert(block);
                block->bbTreeList = 0;
                block->bbJumpKind = BBJ_NONE;
            }
            while (block != bottom);

            bottom->bbJumpKind = BBJ_NONE;
            bottom->bbTreeList = loopList;

            /* Update bbRefs and bbPreds */
            /* Here head->bbNext is bottom !!! - Replace it */

            assert(head->bbNext->bbRefs);
            head->bbNext->bbRefs--;

            fgRemovePred(head->bbNext, bottom);

            /* If posible compact the blocks
             * Make sure to update loop table */


/*
            GenTreePtr s = loopList;
            printf("\nWhole unrolled loop:\n");

            do
            {
                assert(s->gtOper == GT_STMT);
                gtDispTree (s);
                s = s->gtNext;
            }
            while(s);

*/
            /* Now change the initialization statement in the HEAD to "lvar = lval;"
             * (the last value of the iterator in the loop)
             * and drop the jump condition since the unrolled loop will always execute */

            assert(init->gtOper                         == GT_ASG);
            assert(init->gtOp.gtOp1->gtOper             == GT_LCL_VAR);
            assert(init->gtOp.gtOp1->gtLclVar.gtLclNum  == lvar);
            assert(init->gtOp.gtOp2->gtOper             == GT_CNS_INT);
            assert(init->gtOp.gtOp2->gtIntCon.gtIconVal == lbeg);

            init->gtOp.gtOp2->gtIntCon.gtIconVal =  lval;

            /* if the HEAD is a BBJ_COND drop the condition (and make HEAD a BBJ_NONE block) */

            if (head->bbJumpKind == BBJ_COND)
            {
                phdr = head->bbTreeList; assert(phdr);
                test = phdr->gtPrev;

                assert(test && (test->gtNext == 0));
                assert(test->gtOper == GT_STMT);
                assert(test->gtStmt.gtStmtExpr->gtOper == GT_JTRUE);

                init = test->gtPrev; assert(init && (init->gtNext == test));
                assert(init->gtOper == GT_STMT);

                init->gtNext = 0;
                phdr->gtPrev = init;
                head->bbJumpKind = BBJ_NONE;

                /* Update bbRefs and bbPreds */

                assert(head->bbJumpDest->bbRefs);
                head->bbJumpDest->bbRefs--;

                fgRemovePred(head->bbJumpDest, head);
            }
            else
            {
                /* the loop must execute */
                assert(head->bbJumpKind == BBJ_NONE);
            }

//          fgDispBasicBlocks(true);

            /* Remember that something has changed */

            change = true;

            /* Use the LPFLG_REMOVED flag and update the bbLoopMask acordingly
             * (also make head and bottom NULL - to hit an assert or GPF) */

            optLoopTable[lnum].lpFlags |= LPFLG_REMOVED;
            optLoopTable[lnum].lpHead   =
            optLoopTable[lnum].lpEnd    = 0;

        DONE_LOOP:;
        }

        if  (!change)
            break;
    }

#ifdef  DEBUG
    fgDebugCheckBBlist();
#endif
}

/*****************************************************************************
 *
 *  Return non-zero if there is a code path from 'srcBB' to 'dstBB' that will
 *  not execute a method call.
 */

bool                Compiler::optReachWithoutCall(BasicBlock *srcBB,
                                                  BasicBlock *dstBB)
{
    /* @TODO : Currently BBF_HAS_CALL is not set for helper calls, as
     *  some helper calls are neither interruptible nor hijackable. If we
     *  can determine this, then we can set BBF_HAS_CALL for some helpers too.
     */

    assert(srcBB->bbNum <= dstBB->bbNum);

    /* Are dominator sets available? */

    if  (!fgComputedDoms)
    {
        /* All we can check is the src/dst blocks */

        return  ((srcBB->bbFlags|dstBB->bbFlags) & BBF_HAS_CALL) ? false
                                                                 : true;
    }

    for (;;)
    {
        assert(srcBB && srcBB->bbNum <= dstBB->bbNum);

        /* Does this block contain a call? */

        if  (srcBB->bbFlags & BBF_HAS_CALL)
        {
            /* Will this block always execute on the way to dstBB ? */

            if  (srcBB == dstBB || B1DOMSB2(srcBB, dstBB))
                return  false;
        }
        else
        {
            /* If we've reached the destination block, we're done */

            if  (srcBB == dstBB)
                return  true;
        }

        srcBB = srcBB->bbNext;
    }

    return  true;
}

/*****************************************************************************/
#endif // RNGCHK_OPT
/*****************************************************************************
 *
 *  Marks the blocks between 'begBlk' and 'endBlk' as part of a loop.
 */

static
void                genMarkLoopBlocks(BasicBlock *begBlk,
                                      BasicBlock *endBlk, unsigned loopBit)
{
    for (;;)
    {
        unsigned    weight;

        assert(begBlk);

        /* Bump the 'weight' on the block, carefully checking for overflow */

        weight = begBlk->bbWeight * 6;

        if  (weight > MAX_LOOP_WEIGHT)
             weight = MAX_LOOP_WEIGHT;

        begBlk->bbWeight    = weight;

        /* Mark the block as part of the loop */

//      begBlk->bbLoopMask |= loopBit;

        /* Stop if we've reached the last block in the loop */

        if  (begBlk == endBlk)
            break;

        begBlk = begBlk->bbNext;
    }
}

/*****************************************************************************
 *
 * Check if the termination test at the bottom of the loop
 * is of the form we want. We require that the first operand of the
 * compare is a leaf. The caller checks the second operand.
 */

static
GenTreePtr          genLoopTermTest(BasicBlock *top,
                                    BasicBlock *bottom, bool bigOK = false)
{
    GenTreePtr      testt;
    GenTreePtr      condt;
    GenTreePtr      op1;
    GenTreePtr      op2;

    testt = bottom->bbTreeList;
    assert(testt && testt->gtOper == GT_STMT);
#if FANCY_ARRAY_OPT
#pragma message("check with PeterMa about the change below")
    while (testt->gtNext)
        testt = testt->gtNext;
#else
    if  (testt->gtNext)
        return NULL;
#endif

    condt = testt->gtStmt.gtStmtExpr;
    assert(condt->gtOper == GT_JTRUE);
    condt = condt->gtOp.gtOp1;

    /* For now, let's only allow "int-leaf <relop> int-leaf" */

    if  (!condt->OperIsCompare())
        return NULL;

    op1 = condt->gtOp.gtOp1;
    op2 = condt->gtOp.gtOp2;

    if  (!op1->OperIsLeaf())
    {
        if  (!bigOK)
            return NULL;

        /* Allow "leaf + leaf" as well */

        if  (op1->gtOper != GT_ADD)
            return NULL;

        op2 = op1->gtOp.gtOp2;
        op1 = op1->gtOp.gtOp1;

        if  (!op1->OperIsLeaf())
            return NULL;
        if  (!op2->OperIsLeaf())
            return NULL;
    }

    /* Make sure the comparands have handy size */

    if  (condt->gtOp.gtOp1->gtType != TYP_INT)
        return NULL;

    return testt;
}

/*****************************************************************************
 *
 *  Perform loop inversion, find and classify natural loops
 */

void                Compiler::optOptimizeLoops()
{
    BasicBlock *    block;
    unsigned        lmask = 0;

    /*
        Optimize while-like loops to not always jump to the test at the bottom
        of the loop initially. Specifically, we're looking for the following
        case:
                ...
                ...
                jmp test
        loop:
                ...
                ...
        test:
                cond
                jtrue   loop

        If we find this, and the condition is a simple one, we change
        the loop to the following:

                ...
                ...

                cond
                jfalse done
        loop:
                ...
                ...
        test:
                cond
                jtrue   loop
        done:

        While we're doing the above, we'll also notice whether there are any
        loop headers, and if so we'll do more optimizations down below.
     */

#ifdef  DEBUG
    /* Check that the flowgraph data (bbNums, bbRefs, bbPreds) is up-to-date */
    fgDebugCheckBBlist();
#endif

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        BasicBlock *    testb;
        GenTreePtr      testt;
        GenTreePtr      conds;
        GenTreePtr      condt;

        /* Make sure the appropriate fields are initialized */

        assert(block->bbWeight   == 1);
        assert(block->bbLoopNum  == 0);
//      assert(block->bbLoopMask == 0);

        /* We'll only test for 'BBF_LOOP_HEAD' in 'lmask' */

        lmask |= block->bbFlags;

        /* Does the BB end with an unconditional jump? */

        if  (block->bbJumpKind != BBJ_ALWAYS)
            continue;

        /* Get hold of the jump target */

        testb = block->bbJumpDest; assert(testb != block->bbNext);

        /* It has to be a forward jump */

        if (testb->bbNum <= block->bbNum)
            continue;

        /* Does the block consist of 'jtrue(cond) block' ? */

        if  (testb->bbJumpKind != BBJ_COND)
            continue;
        if  (testb->bbJumpDest != block->bbNext)
            continue;

        assert(testb->bbNext);
        conds = genLoopTermTest(block, testb, true);

        /* If test not found or not right, keep going */

        if  (conds == NULL)
        {
            continue;
        }
        else
        {
            /* Get to the condition node from the statement tree */

            assert(conds->gtOper == GT_STMT);

            condt = conds->gtStmt.gtStmtExpr;
            assert(condt->gtOper == GT_JTRUE);

            condt = condt->gtOp.gtOp1;
            assert(condt->OperIsCompare());
        }


        /* If second operand of compare isn't leaf, don't want to dup */

        if  (!condt->gtOp.gtOp2->OperIsLeaf())
            continue;

        /* Looks good - duplicate the condition test
         * UNDONE: use the generic cloning here */

        unsigned savedFlags = condt->gtFlags;
        condt = gtNewOperNode(GenTree::ReverseRelop(condt->OperGet()),
                              TYP_INT,
                              gtClone(condt->gtOp.gtOp1, true),
                              gtClone(condt->gtOp.gtOp2, true));

        condt->gtFlags |= savedFlags;

        condt = gtNewOperNode(GT_JTRUE, TYP_VOID, condt, 0);

        /* Create a statement entry out of the condition */

        testt = gtNewStmt(condt); testt->gtFlags |= GTF_STMT_CMPADD;

#ifdef DEBUGGING_SUPPORT
        if  (opts.compDbgInfo)
            testt->gtStmtILoffs = conds->gtStmtILoffs;
#endif

        /* Append the condition test at the end of 'block' */

        fgInsertStmtAtEnd(block, testt);

        /* Change the block to end with a conditional jump */

        block->bbJumpKind = BBJ_COND;
        block->bbJumpDest = testb->bbNext;

        /* Update bbRefs and bbPreds for 'block->bbNext' 'testb' and 'testb->bbNext' */

        fgAddRefPred(block->bbNext, block, true, true);

        assert(testb->bbRefs);
        testb->bbRefs--;
        fgRemovePred(testb, block);

        fgAddRefPred(testb->bbNext, block, true, true);

#ifdef  DEBUG
        if  (verbose)
        {
            printf("\nDuplicating loop condition in block #%02u for loop (#%02u - #%02u)\n",
                block->bbNum, block->bbNext->bbNum, testb->bbNum);
        }

#endif
        /* Because we changed links, we can compact the last two blocks in the loop
         * if the direct predecessor of 'testb' is a BBJ_NONE */

        flowList     *  pred;
        BasicBlock   *  testbPred = 0;

        for (pred = testb->bbPreds; pred; pred = pred->flNext)
        {
            if  (pred->flBlock->bbNext == testb)
                    testbPred = pred->flBlock;
        }

        if ( testbPred                          &&
            (testbPred->bbJumpKind == BBJ_NONE) &&
            (testb->bbRefs == 1)                &&
            !(testb->bbFlags & BBF_DONT_REMOVE)  )
        {
            /* Compact the blocks and update bbNums also */
            fgCompactBlocks(testbPred, true);
        }
    }

#ifdef  DEBUG
    /* Check that the flowgraph data (bbNums, bbRefs, bbPreds) is up-to-date */
    fgDebugCheckBBlist();
#endif

    /* Were there any loops in the flow graph? */

    if  (lmask & BBF_LOOP_HEAD)
    {
        unsigned        lastLoopNum = 0;
        unsigned        lastLoopBit = 0;

        BasicBlock *    lastBlk;
        BasicBlock *    loopHdr;
        unsigned        loopNum;
        unsigned        loopBit;

        /* Compute the dominator set */

        fgAssignBBnums(false,false,false,true);

#if RNGCHK_OPT

        /* now that we have dominator information we can find loops */

        optFindNaturalLoops();
#endif

    AGAIN:

        lastBlk = 0;

        /* Iterate over the flow graph, marking all loops */

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            /* Look for the next unmarked backward edge */

            switch (block->bbJumpKind)
            {
                BasicBlock * *  jmpTab;
                unsigned        jmpCnt;

                BasicBlock *    jmpDest;

            case BBJ_COND:
            case BBJ_ALWAYS:

                jmpDest = block->bbJumpDest;

                if  (block->bbNum >= jmpDest->bbNum)
                {
                    /* Is this a new loop that's starting? */

                    if  (!lastBlk)
                    {
                        /* Make sure this loop has not been marked already */

                        if  (jmpDest->bbLoopNum)
                            break;

                        /* Yipee - we have a new loop */

                        loopNum = lastLoopNum; lastLoopNum  += 1;
                        loopBit = lastLoopBit; lastLoopBit <<= 1;
                        lastBlk = jmpDest;

#ifdef  DEBUG
                        if (verbose) printf("Marking block at %08X as loop #%2u because of jump from %08X\n", jmpDest, loopNum+1, block);
#endif

                        /* Mark the loop header as such */

                        jmpDest->bbLoopNum = loopNum+1;

                        /* Remember the loop header */

                        loopHdr = jmpDest;
                    }
                    else
                    {
                        /* Does the loop header match our loop? */

                        if  (jmpDest != loopHdr)
                            break;

                        /* We're adding more blocks to an existing loop */

                        lastBlk = lastBlk->bbNext;
                    }

                    /* Mark all blocks between 'lastBlk' and 'block' */

                    genMarkLoopBlocks(lastBlk, block, loopBit);

                    /* If we have more, we'll resume with the next block */

                    lastBlk = block;
                }
                break;

            case BBJ_SWITCH:

                jmpCnt = block->bbJumpSwt->bbsCount;
                jmpTab = block->bbJumpSwt->bbsDstTab;

                do
                {
                    jmpDest = *jmpTab;

                    if  (block->bbNum > jmpDest->bbNum)
                    {
#if 0
                        printf("WARNING: switch forms a loop, ignoring this\n");
#endif
                        break;
                    }
                }
                while (++jmpTab, --jmpCnt);

                break;
            }
        }

        /* Did we find a loop last time around? */

        if  (lastBlk)
        {
            /* Unless we've found the max. number of loops already, try again */

            if  (lastLoopNum < MAX_LOOP_NUM)
                goto AGAIN;
        }

#ifdef  DEBUG
        if  (lastLoopNum)
        {
            if  (verbose)
            {
                printf("After loop weight marking:\n");
                fgDispBasicBlocks();
                printf("\n");
            }
        }
#endif

    }
}

/*****************************************************************************
 * If the tree is a tracked local variable, return its LclVarDsc ptr.
 */

inline
Compiler::LclVarDsc *   Compiler::optIsTrackedLocal(GenTreePtr tree)
{
    LclVarDsc   *   varDsc;
    unsigned        lclNum;

    if (tree->gtOper != GT_LCL_VAR)
        return NULL;

    lclNum = tree->gtLclVar.gtLclNum;

    assert(lclNum < lvaCount);
    varDsc = lvaTable + lclNum;

    /* if variable not tracked, return NULL */
    if  (!varDsc->lvTracked)
        return NULL;

    return varDsc;
}

/*****************************************************************************/
#if CSE    //  {
/*****************************************************************************/


inline
void                Compiler::optRngChkInit()
{
    optRngIndPtr   =
    optRngIndScl   = 0;
    optRngGlbRef   = 0;
    optRngChkCount = 0;

    /* Allocate and clear the hash bucket table */

    size_t          byteSize = optRngChkHashSize * sizeof(*optRngChkHash);

    optRngChkHash = (RngChkDsc **)compGetMem(byteSize);
    memset(optRngChkHash, 0, byteSize);
}

int                 Compiler::optRngChkIndex(GenTreePtr tree)
{
    unsigned        refMask;
    VARSET_TP       depMask;

    unsigned        hash;
    unsigned        hval;

    RngChkDsc *     hashDsc;

    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    unsigned        index;
    unsigned        mask;

    assert(tree->gtOper == GT_IND);

    /* Compute the dependency mask and make sure the expression is acceptable */

    refMask = 0;
    depMask = lvaLclVarRefs(tree->gtOp.gtOp1, NULL, &refMask);
    if  (depMask == VARSET_NONE)
        return  -1;
    assert(depMask || refMask);

    /* Compute the hash value for the expression */

    hash = gtHashValue(tree);
    hval = hash % optRngChkHashSize;

    /* Look for a matching index in the hash table */

    for (hashDsc = optRngChkHash[hval];
         hashDsc;
         hashDsc = hashDsc->rcdNextInBucket)
    {
        if  (hashDsc->rcdHashValue == hash)
        {
            if  (GenTree::Compare(hashDsc->rcdTree, tree, true))
                return  hashDsc->rcdIndex;
        }
    }

    /* Not found, create a new entry (unless we have too many already) */

    if  (optRngChkCount == RNGSET_SZ)
        return  -1;

    hashDsc = (RngChkDsc *)compGetMem(sizeof(*hashDsc));

    hashDsc->rcdHashValue = hash;
    hashDsc->rcdIndex     = index = optRngChkCount++;
    hashDsc->rcdTree      = tree;

    /* Append the entry to the hash bucket */

    hashDsc->rcdNextInBucket = optRngChkHash[hval];
                               optRngChkHash[hval] = hashDsc;

#ifdef  DEBUG

    if  (verbose)
    {
        printf("Range check #%02u [depMask = %s]:\n", index, genVS2str(depMask));
        gtDispTree(tree);
        printf("\n");
    }

#endif

    /* Mark all variables this index depends on */

    for (lclNum = 0, varDsc = lvaTable, mask = (1 << index);
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
        VARSET_TP       lclBit;

        if  (!varDsc->lvTracked)
            continue;

        lclBit = genVarIndexToBit(varDsc->lvVarIndex);

        if  (depMask & lclBit)
        {
            varDsc->lvRngDep    |= mask;

            if  (lvaVarAddrTaken(lclNum))
                optRngAddrTakenVar  |= mask;

            depMask &= ~lclBit;
            if  (!depMask)
                break;
        }
    }

    /* Remember whether the index expression contains an indirection/global ref */

    if  (refMask & VR_IND_PTR) optRngIndPtr |= mask;
    if  (refMask & VR_IND_SCL) optRngIndScl |= mask;
    if  (refMask & VR_GLB_REF) optRngGlbRef |= mask;

    return  index;
}

/*****************************************************************************
 *
 *  Return the bit corresponding to a range check with the given index.
 */

inline
RNGSET_TP           genRngnum2bit(unsigned index)
{
    assert(index != -1 && index <= RNGSET_SZ);

    return  ((RNGSET_TP)1 << index);
}

/*****************************************************************************
 *
 *  The following is the upper limit on how many expressions we'll keep track
 *  of for the CSE analysis.
 */

const unsigned MAX_CSE_CNT = EXPSET_SZ;

/*****************************************************************************
 *
 *  The following determines whether the given expression is a worthy CSE
 *  candidate.
 */

inline
bool                Compiler::optIsCSEcandidate(GenTreePtr tree)
{
    /* No good if the expression contains side effects */

    if  (tree->gtFlags & (GTF_ASG|GTF_CALL|GTF_DONT_CSE))
        return  false;

    /*
        Unfortunately, we can't currently allow arbitrary expressions
        to be CSE candidates. The (yes, rather lame) reason for this
        is that if we make part of an address expression into a CSE,
        the code in optRemoveRangeCheck() that looks for the various
        parts of the index expression blows up (since it expects the
        address value to follow a certain pattern).
     */

    /* The only reason a TYP_STRUCT tree might occur is as an argument to
       GT_ADDR. It will never be actually materialized. So ignore them */
    if  (tree->TypeGet() == TYP_STRUCT)
        return false;

#if !MORECSES

    if  (tree->gtOper != GT_IND)
    {
#if CSELENGTH
        if  (tree->gtOper != GT_ARR_LENGTH &&
             tree->gtOper != GT_ARR_RNGCHK)
#endif
        {
            return  false;
        }
    }

    return  true;

#else

    /* Don't bother with leaves, constants, assignments and comparisons */

    if  (tree->OperKind() & (GTK_CONST|GTK_LEAF|GTK_ASGOP|GTK_RELOP))
        return  false;

    /* Check for some special cases */

    switch (tree->gtOper)
    {
    case GT_IND:
        return  true;

    case GT_NOP:
    case GT_RET:
    case GT_JTRUE:
    case GT_RETURN:
    case GT_SWITCH:
    case GT_RETFILT:
        return  false;

    case GT_ADD:
    case GT_SUB:

        /* Don't bother with computed addresses */

        if  (varTypeIsGC(tree->TypeGet()))
            return  false;

#if 0

        /* Don't bother with "local +/- icon" or "local +- local" */

        if  (tree->gtOp.gtOp1->gtOper == GT_LCL_VAR)
        {
            if  (tree->gtOp.gtOp2->gtOper == GT_LCL_VAR) return false;
            if  (tree->gtOp.gtOp2->gtOper == GT_CNS_INT) return false;
        }

        break;

#else

        /* For now, only allow "local +/- local" amd "local +/- icon" */

        if (tree->gtOp.gtOp1->gtOper == GT_LCL_VAR)
        {
            if  (tree->gtOp.gtOp2->gtOper == GT_LCL_VAR) return true;
//          if  (tree->gtOp.gtOp2->gtOper == GT_CNS_INT) return true;
        }

        return  false;

#endif

    case GT_LSH:

#if SCALED_ADDR_MODES

        /* Don't make scaled index values into CSE's */

        if  (tree->gtOp.gtOp1->gtOper == GT_NOP)
            return  false;

        break;

#else

        return  true;

#endif

    }

#if TGT_x86

    /* Don't bother if the potential savings are very low */

    if  (tree->gtCost < 3)
        return  false;

#endif

    // UNDONE: Need more heuristics for deciding which expressions
    // UNDONE: are worth considering for CSE!

    return  false;

#endif

}

/*****************************************************************************
 *
 *  Return the bit corresponding to a CSE with the given index.
 */

inline
EXPSET_TP           genCSEnum2bit(unsigned index)
{
    assert(index && index <= EXPSET_SZ);

    return  ((EXPSET_TP)1 << (index-1));
}

/*****************************************************************************
 *
 *  Initialize the CSE tracking logic.
 */

void                Compiler::optCSEinit()
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    for (lclNum = 0, varDsc = lvaTable;
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
        varDsc->lvRngDep =
        varDsc->lvExpDep = 0;
    }

    optCSEindPtr =
    optCSEindScl =
    optCSEglbRef = 0;

    optCSEcount  = 0;

#ifndef NDEBUG
    optCSEtab    = 0;
#endif

    /* Allocate and clear the hash bucket table */

    size_t          byteSize = s_optCSEhashSize * sizeof(*optCSEhash);

    optCSEhash = (CSEdsc **)compGetMem(byteSize);
    memset(optCSEhash, 0, byteSize);
}

/*****************************************************************************
 *
 *  We've found all the candidates, build the index for easy access.
 */

void                Compiler::optCSEstop()
{
    CSEdsc   *      dsc;
    CSEdsc   *   *  ptr;
    unsigned        cnt;

    optCSEtab = (CSEdsc **)compGetMem(optCSEcount * sizeof(*optCSEtab));

#ifndef NDEBUG
    memset(optCSEtab, 0, optCSEcount * sizeof(*optCSEtab));
#endif

    for (cnt = s_optCSEhashSize, ptr = optCSEhash;
         cnt;
         cnt--            , ptr++)
    {
        for (dsc = *ptr; dsc; dsc = dsc->csdNextInBucket)
        {
            assert(dsc->csdIndex);
            assert(dsc->csdIndex <= optCSEcount);
            assert(optCSEtab[dsc->csdIndex-1] == 0);

            optCSEtab[dsc->csdIndex-1] = dsc;
        }
    }
}

/*****************************************************************************
 *
 *  Return the descriptor for the CSE with the given index.
 */

inline
Compiler::CSEdsc   *   Compiler::optCSEfindDsc(unsigned index)
{
    assert(index);
    assert(index <= optCSEcount);
    assert(optCSEtab[index-1]);

    return  optCSEtab[index-1];
}

/*****************************************************************************
 *
 *  Assign an index to the given expression (adding it to the lookup table,
 *  if necessary). Returns the index or 0 if the expression can't be a CSE.
 */

int                 Compiler::optCSEindex(GenTreePtr tree, GenTreePtr stmt)
{
    unsigned        refMask;
    VARSET_TP       depMask;

    unsigned        hash;
    unsigned        hval;

    CSEdsc *        hashDsc;

    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    unsigned        index;
    unsigned        mask;

    assert(optIsCSEcandidate(tree));

    /* Compute the dependency mask and make sure the expression is acceptable */

    refMask = 0;
    depMask = lvaLclVarRefs(tree, NULL, &refMask);
    if  (depMask == VARSET_NONE)
        return  0;

    /* Compute the hash value for the expression */

    hash = gtHashValue(tree);
    hval = hash % s_optCSEhashSize;

    /* Look for a matching index in the hash table */

    for (hashDsc = optCSEhash[hval];
         hashDsc;
         hashDsc = hashDsc->csdNextInBucket)
    {
        if  (hashDsc->csdHashValue == hash)
        {
            if  (GenTree::Compare(hashDsc->csdTree, tree))
            {
                treeStmtLstPtr  list;

                /* Have we started the list of matching nodes? */

                if  (hashDsc->csdTreeList == 0)
                {
                    /* Start the list with the first CSE candidate
                     * recorded - matching CSE of itself */

                    hashDsc->csdTreeList =
                    hashDsc->csdTreeLast =
                    list                 = (treeStmtLstPtr)compGetMem(sizeof(*list));

                    list->tslTree  = hashDsc->csdTree;
                    list->tslStmt  = hashDsc->csdStmt;
                    list->tslBlock = hashDsc->csdBlock;

                    list->tslNext = 0;
                }

                /* Append this expression to the end of the list */

                list = (treeStmtLstPtr)compGetMem(sizeof(*list));

                list->tslTree  = tree;
                list->tslStmt  = stmt;
                list->tslBlock = compCurBB;
                list->tslNext  = 0;

                hashDsc->csdTreeLast->tslNext = list;
                hashDsc->csdTreeLast          = list;

                return  hashDsc->csdIndex;
            }
        }
    }

    /* Not found, create a new entry (unless we have too many already) */

    if  (optCSEcount == EXPSET_SZ)
        return  0;

    hashDsc = (CSEdsc *)compGetMem(sizeof(*hashDsc));

    hashDsc->csdHashValue = hash;
    hashDsc->csdIndex     = index = ++optCSEcount;

    hashDsc->csdDefCount  =
    hashDsc->csdUseCount  =
    hashDsc->csdDefWtCnt  =
    hashDsc->csdUseWtCnt  = 0;

    hashDsc->csdTree      = tree;
    hashDsc->csdStmt      = stmt;
    hashDsc->csdBlock     = compCurBB;
    hashDsc->csdTreeList  = 0;

    /* Append the entry to the hash bucket */

    hashDsc->csdNextInBucket = optCSEhash[hval];
                               optCSEhash[hval] = hashDsc;

#ifdef  DEBUG

    if  (verbose)
    {
        printf("CSE candidate #%02u [depMask = %s , refMask = ", index, genVS2str(depMask));
        if  (refMask & VR_IND_PTR) printf("Ptr");
        if  (refMask & VR_IND_SCL) printf("Scl");
        if  (refMask & VR_GLB_REF) printf("Glb");
        printf("]:\n");
        gtDispTree(tree);
        printf("\n");
    }

#endif

    /* Mark all variables this index depends on */

    for (lclNum = 0, varDsc = lvaTable, mask = genCSEnum2bit(index);
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
        VARSET_TP       lclBit;

        if  (!varDsc->lvTracked)
            continue;

        lclBit = genVarIndexToBit(varDsc->lvVarIndex);

        if  (depMask & lclBit)
        {
            varDsc->lvExpDep    |= mask;

            if  (lvaVarAddrTaken(lclNum))
                optCSEaddrTakenVar  |= mask;

            depMask &= ~lclBit;
            if  (!depMask)
                break;
        }
    }

    /* Remember whether the index expression contains an indirection/global ref */

    if  (refMask & VR_IND_PTR) optCSEindPtr |= mask;
    if  (refMask & VR_IND_SCL) optCSEindScl |= mask;
    if  (refMask & VR_GLB_REF) optCSEglbRef |= mask;

    return  index;
}

/*****************************************************************************
 *
 *  Helper passed to Compiler::fgWalkAllTrees() to unmark nested CSE's.
 */

/* static */
int                 Compiler::optUnmarkCSEs(GenTreePtr tree, void *p)
{
    Compiler *      comp = (Compiler *)p; ASSert(comp);

    tree->gtFlags |= GTF_DEAD;

//  printf("Marked dead node %08X (will be part of CSE use)\n", tree);

    if  (tree->gtCSEnum)
    {
        CSEdsc   *      desc;

        /* This must be a reference to a nested CSE */

        Assert(tree->gtCSEnum > 0, comp);

        desc = comp->optCSEfindDsc(tree->gtCSEnum);

#if 0
        printf("Unmark CSE #%02d at %08X: %3d -> %3d\n", tree->gtCSEnum,
                                                         tree,
                                                         desc->csdUseCount,
                                                         desc->csdUseCount - 1);
        comp->gtDispTree(tree);
#endif

        /* Reduce the nested CSE's 'use' count */

        if  (desc->csdUseCount > 0)
        {
             desc->csdUseCount -= 1;
             desc->csdUseWtCnt -= (comp->optCSEweight + 1)/2;
        }
    }

    /* Look for any local variable references */

    if  (tree->gtOper == GT_LCL_VAR)
    {
        unsigned        lclNum;
        LclVarDsc   *   varDsc;

        /* This variable ref is going away, decrease its ref counts */

        lclNum = tree->gtLclVar.gtLclNum;
        Assert(lclNum < comp->lvaCount, comp);
        varDsc = comp->lvaTable + lclNum;

        Assert(comp->optCSEweight < 99999, comp); // make sure it's been initialized

#if 0
        printf("Reducing refcnt of %2u: %3d->%3d / %3d->%3d\n", lclNum, varDsc->lvRefCnt,
                                                                        varDsc->lvRefCnt - 1,
                                                                        varDsc->lvRefCntWtd,
                                                                        varDsc->lvRefCntWtd - comp->optCSEweight);
#endif

        varDsc->lvRefCnt    -= 1;
        varDsc->lvRefCntWtd -= comp->optCSEweight;

        /* ISSUE: The following should not be necessary, so why is it? */

        if  ((int)varDsc->lvRefCntWtd < 0)
                  varDsc->lvRefCntWtd = varDsc->lvRefCnt;

        Assert((int)varDsc->lvRefCnt    >= 0, comp);
        Assert((int)varDsc->lvRefCntWtd >= 0, comp);
    }

    return  0;
}

/*****************************************************************************
 *
 *  Compare function passed to qsort() by optOptimizeCSEs().
 */

/* static */
int __cdecl         Compiler::optCSEcostCmp(const void *op1, const void *op2)
{
    CSEdsc *        dsc1 = *(CSEdsc * *)op1;
    CSEdsc *        dsc2 = *(CSEdsc * *)op2;

    GenTreePtr      exp1 = dsc1->csdTree;
    GenTreePtr      exp2 = dsc2->csdTree;

#if CSELENGTH
#endif

   return  exp2->gtCost - exp1->gtCost;
}

/*****************************************************************************
 *
 *  Adjust both the weighted and unweighted ref count of a local variable
 *  leaf as it is deleted by CSE.
 */
inline
void                Compiler::optCSEDecRefCnt(GenTreePtr tree, BasicBlock *block)
{
    LclVarDsc   *   varDsc;

    return;

    varDsc = optIsTrackedLocal(tree);

    /* Only need to update tracked locals */

    if (varDsc == NULL)
        return;

    /* We shouldn't ever underflow */

    assert(varDsc->lvRefCntWtd >= block->bbWeight);
    varDsc->lvRefCntWtd        -= block->bbWeight;

    assert(varDsc->lvRefCnt    >= 1);
    varDsc->lvRefCnt           -= 1;
}

/*****************************************************************************
 *
 *  Determine the kind of interference for the call.
 */

/* static */ inline
Compiler::callInterf    Compiler::optCallInterf(GenTreePtr call)
{
    ASSert(call->gtOper == GT_CALL);

    // if not a helper, kills everything
    if  (call->gtCall.gtCallType != CT_HELPER)
        return CALLINT_ALL;

    // array address store kills all indirections
    if (call->gtCall.gtCallMethHnd == eeFindHelper(CPX_ARRADDR_ST))
        return CALLINT_INDIRS;

    // other helpers kill nothing
    else
        return CALLINT_NONE;
}

/*****************************************************************************
 *
 *  Perform common sub-expression elimination.
 */

void                Compiler::optOptimizeCSEs()
{
    BasicBlock *    block;

    CSEdsc   *   *  ptr;
    unsigned        cnt;

    CSEdsc   *   *  sortTab;
    size_t          sortSiz;

    unsigned        add;

    /* Initialize the expression tracking logic (i.e. the lookup table) */

    optCSEinit();

    /* Initialize the range check tracking logic (i.e. the lookup table) */

    optRngChkInit();

    /* Locate interesting expressions, and range checks and assign indices
     * to them */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;

        /* Make the block publicly available */

        compCurBB = block;

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                tree->gtCSEnum = 0;

                /* If a ?: do not CSE at all
                 * UNDONE: This is a horrible hack and should be fixed asap */

                if (stmt->gtStmt.gtStmtExpr->gtFlags & GTF_OTHER_SIDEEFF)
                    return;

                // We cant CSE something hanging below GT_ADDR
                // Not entirely accurate as gtNext could be the left sibling.
                bool childOf_GT_ADDR = tree->gtNext && (tree->gtNext->gtOper == GT_ADDR);

                if  (!childOf_GT_ADDR && optIsCSEcandidate(tree))
                {
                    /* Assign an index to this expression */

                    tree->gtCSEnum = optCSEindex(tree, stmt);
                }
                else if (tree->OperKind() & GTK_ASGOP)
                {
                    /* Targets of assignments are never CSE's */

                    tree->gtOp.gtOp1->gtCSEnum = 0;
                }

                if  ((tree->gtFlags & GTF_IND_RNGCHK) && tree->gtOper == GT_IND)
                {
                    /* Assign an index to this range check */

                    tree->gtInd.gtIndex = optRngChkIndex(tree);
                }
            }
        }
    }

    /* We're finished building the expression lookup table */

    optCSEstop();

//  printf("Total number of CSE candidates: %u\n", optCSEcount);

    /* We're done if there were no interesting expressions */

    if  (!optCSEcount && !optRngChkCount)
        return;

    /* Compute 'gen' and 'kill' sets for all blocks */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;

        RNGSET_TP       rngGen  = 0;
        RNGSET_TP       rngKill = 0;

        EXPSET_TP       cseGen  = 0;
        EXPSET_TP       cseKill = 0;

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            // UNDONE: Need to do the right thing for ?: operators!!!!!

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                if  (tree->gtCSEnum)
                {
                    /* An interesting expression is computed here */

                    cseGen |= genCSEnum2bit(tree->gtCSEnum);
                }
                if  ((tree->gtFlags & GTF_IND_RNGCHK) && tree->gtOper == GT_IND)
                {
                    /* A range check is generated here */

                    if  (tree->gtInd.gtIndex != -1)
                        rngGen |= genRngnum2bit(tree->gtInd.gtIndex);
                }
                else if (tree->OperKind() & GTK_ASGOP)
                {
                    /* What is the target of the assignment? */

                    switch (tree->gtOp.gtOp1->gtOper)
                    {
                    case GT_CATCH_ARG:
                        break;

                    case GT_LCL_VAR:
                    {
                        unsigned        lclNum;
                        LclVarDsc   *   varDsc;

                        /* Assignment to a local variable */

                        assert(tree->gtOp.gtOp1->gtOper == GT_LCL_VAR);
                        lclNum = tree->gtOp.gtOp1->gtLclVar.gtLclNum;

                        assert(lclNum < lvaCount);
                        varDsc = lvaTable + lclNum;

                        /* All dependent exprs are killed here */

                        cseKill |=  varDsc->lvExpDep;
                        cseGen  &= ~varDsc->lvExpDep;

                        /* All dependent range checks are killed here */

                        rngKill |=  varDsc->lvRngDep;
                        rngGen  &= ~varDsc->lvRngDep;

                        /* If the var is aliased, then it could may be
                           accessed indirectly. Kill all indirect accesses */

                        if  (lvaVarAddrTaken(lclNum))
                        {
                            if  (varTypeIsGC(varDsc->TypeGet()))
                            {
                                cseKill |=  optCSEindPtr;
                                cseGen  &= ~optCSEindPtr;

                                rngKill |=  optRngIndPtr;
                                rngGen  &= ~optRngIndPtr;
                            }
                            else
                            {
                                cseKill |=  optCSEindScl;
                                cseGen  &= ~optCSEindScl;

                                rngKill |=  optRngIndScl;
                                rngGen  &= ~optRngIndScl;
                            }
                        }
                        break;
                    }

                    case GT_IND:

                        /* Indirect assignment - kill set is based on type */

                        if  (varTypeIsGC(tree->TypeGet()))
                        {
                            cseKill |=  optCSEindPtr;
                            cseGen  &= ~optCSEindPtr;

                            rngKill |=  optRngIndPtr;
                            rngGen  &= ~optRngIndPtr;
                        }
                        else
                        {
                            cseKill |=  optCSEindScl;
                            cseGen  &= ~optCSEindScl;

                            rngKill |=  optRngIndScl;
                            rngGen  &= ~optRngIndScl;
                        }

                        if  (tree->gtOp.gtOp1->gtInd.gtIndOp1->gtType == TYP_BYREF)
                        {
                            /* If the indirection is through a byref, we could
                               be modifying an aliased local, or a global
                               (in addition to indirections which are handled
                               above) */

                            cseKill |=  optCSEaddrTakenVar;
                            cseGen  &= ~optCSEaddrTakenVar;

                            rngKill  =  optRngAddrTakenVar;
                            rngGen   = ~optRngAddrTakenVar;

                            if  (varTypeIsGC(tree->TypeGet()))
                            {
                                cseKill |=  optCSEglbRef;
                                cseGen  &= ~optCSEglbRef;

                                rngKill |=  optRngGlbRef;
                                rngGen  &= ~optRngGlbRef;
                            }
                        }

                        break;

                    default:

                        /* Must be a static data member (global) assignment */

                        assert(tree->gtOp.gtOp1->gtOper == GT_CLS_VAR);

                        /* This is a global assignment */

                        cseKill |=  optCSEglbRef;
                        cseGen  &= ~optCSEglbRef;

                        rngKill |=  optRngGlbRef;
                        rngGen  &= ~optRngGlbRef;

                        break;
                    }
                }
                else if (tree->gtOper == GT_CALL)
                {
                    switch (optCallInterf(tree))
                    {
                    case CALLINT_ALL:

                        /* Play it safe: method calls kill all exprs */

                        cseKill = (EXPSET_TP)((EXPSET_TP)0 - 1);
                        cseGen  = 0;

                        /* Play it safe: method calls kill all range checks */

                        rngKill = (RNGSET_TP)((RNGSET_TP)0 - 1);
                        rngGen  = 0;
                        break;

                    case CALLINT_INDIRS:

                        /* Array elem assignment kills all pointer indirections */

                        cseKill |=  optCSEindPtr;
                        cseGen  &= ~optCSEindPtr;

                        rngKill |=  optRngIndPtr;
                        rngGen  &= ~optRngIndPtr;
                        break;

                    case CALLINT_NONE:

                        /* Other helpers kill nothing */

                        break;

                    }
                }
                else if (tree->gtOper == GT_COPYBLK ||
                         tree->gtOper == GT_INITBLK)
                {
                    /* Kill all pointer indirections */

                    if  (tree->gtType == TYP_REF)
                    {
                        cseKill |=  optCSEindPtr;
                        cseGen  &= ~optCSEindPtr;

                        rngKill |=  optRngIndPtr;
                        rngGen  &= ~optRngIndPtr;
                    }
                    else
                    {
                        cseKill |=  optCSEindScl;
                        cseGen  &= ~optCSEindScl;

                        rngKill |=  optRngIndScl;
                        rngGen  &= ~optRngIndScl;
                    }
                }
            }
        }

#ifdef  DEBUG

        if  (verbose)
        {
            if  (!(block->bbFlags & BBF_INTERNAL))
            {
                printf("BB #%3u", block->bbNum);
                printf(" expGen = %08X", cseGen );
                printf(" expKill= %08X", cseKill);
                printf(" rngGen = %08X", rngGen );
                printf(" rngKill= %08X", rngKill);
                printf("\n");
            }
        }

#endif

        block->bbExpGen  = cseGen;
        block->bbExpKill = cseKill;

        block->bbExpIn   = 0;

        block->bbRngIn   = 0;

        block->bbRngGen  = rngGen;
        block->bbRngKill = rngKill;
    }


    /* Compute the data flow values for all tracked expressions */

#if 1

    /* Peter's modified algorithm for CSE dataflow */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        block->bbExpOut = (EXPSET_TP)((EXPSET_TP)0 - 1) & ~block->bbExpKill;
        block->bbRngOut = (RNGSET_TP)((RNGSET_TP)0 - 1) & ~block->bbRngKill;
    }

    /* Nothing is available on entry to the method */

    fgFirstBB->bbExpOut = fgFirstBB->bbExpGen;
    fgFirstBB->bbRngOut = fgFirstBB->bbRngGen;

    // CONSIDER: This should be combined with live variable analysis
    // CONSIDER: and/or range check data flow analysis.

    for (;;)
    {
        bool        change = false;

#if DATAFLOW_ITER
        CSEiterCount++;
#endif

        /* Set 'in' to {ALL} in preparation for and'ing all predecessors */

        for (block = fgFirstBB->bbNext; block; block = block->bbNext)
        {
            block->bbExpIn = (EXPSET_TP)((EXPSET_TP)0 - 1);
            block->bbRngIn = (RNGSET_TP)((RNGSET_TP)0 - 1);
        }

        /* Visit all blocks and compute new data flow values */

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            EXPSET_TP       cseOut = block->bbExpOut;
            RNGSET_TP       rngOut = block->bbRngOut;

            switch (block->bbJumpKind)
            {
                BasicBlock * *  jmpTab;
                unsigned        jmpCnt;

                BasicBlock *    bcall;

            case BBJ_RET:

                if (block->bbFlags & BBF_ENDFILTER)
                {
                    block->bbJumpDest->bbExpIn &= cseOut;
                    block->bbJumpDest->bbRngIn &= rngOut;
                    break;
                }

                /*
                    UNDONE: Since it's not a trivial proposition to figure out
                    UNDONE: which blocks may call this one, we'll include all
                    UNDONE: blocks that end in calls (to play it safe).
                 */

                for (bcall = fgFirstBB; bcall; bcall = bcall->bbNext)
                {
                    if  (bcall->bbJumpKind == BBJ_CALL)
                    {
                        assert(bcall->bbNext);

                        bcall->bbNext->bbExpIn &= cseOut;
                        bcall->bbNext->bbRngIn &= rngOut;
                    }
                }

                break;

            case BBJ_THROW:
            case BBJ_RETURN:
                break;

            case BBJ_COND:
            case BBJ_CALL:
                block->bbNext    ->bbExpIn &= cseOut;
                block->bbJumpDest->bbExpIn &= cseOut;

                block->bbNext    ->bbRngIn &= rngOut;
                block->bbJumpDest->bbRngIn &= rngOut;
                break;

            case BBJ_ALWAYS:
                block->bbJumpDest->bbExpIn &= cseOut;
                block->bbJumpDest->bbRngIn &= rngOut;
                break;

            case BBJ_NONE:
                block->bbNext    ->bbExpIn &= cseOut;
                block->bbNext    ->bbRngIn &= rngOut;
                break;

            case BBJ_SWITCH:

                jmpCnt = block->bbJumpSwt->bbsCount;
                jmpTab = block->bbJumpSwt->bbsDstTab;

                do
                {
                    (*jmpTab)->bbExpIn &= cseOut;
                    (*jmpTab)->bbRngIn &= rngOut;
                }
                while (++jmpTab, --jmpCnt);

                break;
            }

            /* Is this block part of a 'try' statement? */

            if  (block->bbFlags & BBF_HAS_HANDLER)
            {
                unsigned        XTnum;
                EHblkDsc *      HBtab;

                unsigned        blkNum = block->bbNum;

                /*
                    Note:   The following is somewhat over-eager since
                            only code that follows an operation that
                            may raise an exception may jump to a catch
                            block, e.g.:

                                try
                                {
                                    a = 10; // 'a' is not live at beg of try

                                    func(); // this might cause an exception

                                    b = 20; // 'b' is     live at beg of try
                                }
                                catch(...)
                                {
                                    ...
                                }

                            But, it's too tricky to be smarter about this
                            and most likely not worth the extra headache.
                 */

                for (XTnum = 0, HBtab = compHndBBtab;
                     XTnum < info.compXcptnsCount;
                     XTnum++  , HBtab++)
                {
                    /* Any handler may be jumped to from the try block */

                    if  (HBtab->ebdTryBeg->bbNum <= blkNum &&
                         HBtab->ebdTryEnd->bbNum >  blkNum)
                    {
//                      HBtab->ebdHndBeg->bbExpIn &= cseOut;
//                      HBtab->ebdHndBeg->bbRngIn &= rngOut;

                        //CONSIDER: The following is too conservative,
                        //      but the old code above isn't good
                        //           enough (way too optimistic).

                        /* Either we enter the filter or the catch/finally */

                        if (HBtab->ebdFlags & JIT_EH_CLAUSE_FILTER)
                        {
                            HBtab->ebdFilter->bbExpIn = 0;
                            HBtab->ebdFilter->bbRngIn = 0;
                        }
                        else
                        {
                            HBtab->ebdHndBeg->bbExpIn = 0;
                            HBtab->ebdHndBeg->bbRngIn = 0;
                        }
                    }
                }
            }
        }

        /* Compute the new 'in' values and see if anything changed */

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            EXPSET_TP       newExpOut;
            RNGSET_TP       newRngOut;

            /* Compute new 'out' exp value for this block */

            newExpOut = block->bbExpOut & ((block->bbExpIn & ~block->bbExpKill) | block->bbExpGen);

            /* Has the 'out' set changed? */

            if  (block->bbExpOut != newExpOut)
            {
                /* Yes - record the new value and loop again */

//              printf("Change exp out of %02u from %08X to %08X\n", block->bbNum, (int)block->bbExpOut, (int)newExpOut);

                 block->bbExpOut  = newExpOut;
                 change = true;
            }

            /* Compute new 'out' exp value for this block */

            newRngOut = block->bbRngOut & ((block->bbRngIn & ~block->bbRngKill) | block->bbRngGen);

            /* Has the 'out' set changed? */

            if  (block->bbRngOut != newRngOut)
            {
                /* Yes - record the new value and loop again */

//              printf("Change rng out of %02u from %08X to %08X\n", block->bbNum, (int)block->bbRngOut, (int)newRngOut);

                 block->bbRngOut  = newRngOut;
                 change = true;
            }
        }

#if 0

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            if  (!(block->bbFlags & BBF_INTERNAL))
            {
                printf("BB #%3u", block->bbNum);
                printf(" expIn  = %08X", block->bbExpIn );
                printf(" expOut = %08X", block->bbExpOut);
                printf(" rngIn  = %08X", block->bbRngIn );
                printf(" rngOut = %08X", block->bbRngOut);
                printf("\n");
            }
        }

        printf("\nchange = %d\n", change);

#endif

        if  (!change)
            break;
    }

#endif

#ifdef  DEBUG

    if  (verbose)
    {
        printf("\n");

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            if  (!(block->bbFlags & BBF_INTERNAL))
            {
                printf("BB #%3u", block->bbNum);
                printf(" expIn  = %08X", block->bbExpIn );
                printf(" expOut = %08X", block->bbExpOut);
                printf(" rngIn  = %08X", block->bbRngIn );
                printf(" rngOut = %08X", block->bbRngOut);
                printf("\n");
            }
        }

        printf("\n");

        printf("Pointer indir: rng = %s, exp = %s\n", genVS2str(optRngIndPtr), genVS2str(optCSEindPtr));
        printf("Scalar  indir: rng = %s, exp = %s\n", genVS2str(optRngIndScl), genVS2str(optCSEindScl));
        printf("Global    ref: rng = %s, exp = %s\n", genVS2str(optRngGlbRef), genVS2str(optCSEglbRef));

        printf("\n");
    }

#endif

    /* Now mark any interesting CSE's as such, and
     *     mark any redundant range checks as such
     */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;

        EXPSET_TP       exp = block->bbExpIn;
        RNGSET_TP       rng = block->bbRngIn;

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

//          gtDispTree(stmt);

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                if  ((tree->gtFlags & GTF_IND_RNGCHK) && tree->gtOper == GT_IND)
                {
                    /* Is this range check redundant? */

#if COUNT_RANGECHECKS
                    optRangeChkAll++;
#endif

                    if  (tree->gtInd.gtIndex != -1)
                    {
                        unsigned    mask = genRngnum2bit(tree->gtInd.gtIndex);

                        if  (rng & mask)
                        {
                            /* This range check is redundant! */

#ifdef  DEBUG
                            if  (verbose)
                            {
                                printf("Eliminating redundant range check:\n");
                                gtDispTree(tree);
                                printf("\n");
                            }
#endif

#if COUNT_RANGECHECKS
                            optRangeChkRmv++;
#endif

                            optRemoveRangeCheck(tree, stmt);
                        }
                        else
                        {
                            rng |= mask;
                        }
                    }
                }

                if  (tree->gtCSEnum)
                {
                    unsigned    mask;
                    CSEdsc   *  desc;
//                    unsigned    stmw = (block->bbWeight+1)/2;
                    unsigned    stmw = block->bbWeight;

                    /* Is this expression available here? */

                    mask = genCSEnum2bit(tree->gtCSEnum);
                    desc = optCSEfindDsc(tree->gtCSEnum);

#if 0
                    if  (abs(tree->gtCSEnum) == 11)
                    {
                        printf("CSE #%2u is %s available here:\n", abs(tree->gtCSEnum), (exp & mask) ? "   " : "not");
                        gtDispTree(tree);
                        debugStop(0);
                    }
#endif
                    /* Is this expression available here? */

                    if  (exp & mask)
                    {
                        desc->csdUseCount += 1;
                        desc->csdUseWtCnt += stmw;

//                      printf("[%08X] Use of CSE #%u [weight=%2u]\n", tree, tree->gtCSEnum, stmw);
                    }
                    else
                    {
//                      printf("[%08X] Def of CSE #%u [weight=%2u]\n", tree, tree->gtCSEnum, stmw);

                        desc->csdDefCount += 1;
                        desc->csdDefWtCnt += stmw;

                        /* This CSE will be available after this def */

                        exp |= mask;

                        /* Mark the node as a CSE definition */

                        tree->gtCSEnum = -tree->gtCSEnum;
                    }
                }

                if (tree->OperKind() & GTK_ASGOP)
                {
                    /* What is the target of the assignment? */

                    switch (tree->gtOp.gtOp1->gtOper)
                    {
                    case GT_CATCH_ARG:
                        break;

                    case GT_LCL_VAR:
                    {
                        unsigned        lclNum;
                        LclVarDsc   *   varDsc;

                        /* Assignment to a local variable */

                        assert(tree->gtOp.gtOp1->gtOper == GT_LCL_VAR);
                        lclNum = tree->gtOp.gtOp1->gtLclVar.gtLclNum;

                        assert(lclNum < lvaCount);
                        varDsc = lvaTable + lclNum;

                        /* All dependent expressions and range checks are killed here */

                        exp &= ~varDsc->lvExpDep;
                        rng &= ~varDsc->lvRngDep;

                        /* If the var is aliased, then it could may be
                           accessed indirectly. Kill all indirect accesses */

                        if  (lvaVarAddrTaken(lclNum))
                        {
                            if  (varTypeIsGC(varDsc->TypeGet()))
                            {
                                exp &= ~optCSEindPtr;
                                rng &= ~optRngIndPtr;
                            }
                            else
                            {
                                exp &= ~optCSEindScl;
                                rng &= ~optRngIndScl;
                            }
                        }
                        break;
                    }

                    case GT_IND:

                        /* Indirect assignment - kill set is based on type */

                        if  (varTypeIsGC(tree->TypeGet()))
                        {
                            exp &= ~optCSEindPtr;
                            rng &= ~optRngIndPtr;
                        }
                        else
                        {
                            exp &= ~optCSEindScl;
                            rng &= ~optRngIndScl;
                        }

                        if  (tree->gtOp.gtOp1->gtInd.gtIndOp1->gtType == TYP_BYREF)
                        {
                            /* If the indirection is through a byref, we could
                               be modifying an aliased local, or a global
                               (in addition to indirections which are handled
                               above) */

                            exp &= ~optCSEaddrTakenVar;
                            rng &= ~optRngAddrTakenVar;

                            if  (varTypeIsGC(tree->TypeGet()))
                            {
                                exp &= ~optCSEglbRef;
                                rng &= ~optRngGlbRef;
                            }
                        }
                        break;

                    default:

                        /* Must be a static data member (global) assignment */

                        assert(tree->gtOp.gtOp1->gtOper == GT_CLS_VAR);

                        /* This is a global assignment */

                        exp &= ~optCSEglbRef;
                        rng &= ~optRngGlbRef;

                        break;
                    }
                }
                else if (tree->gtOper == GT_CALL)
                {
                    switch (optCallInterf(tree))
                    {
                    case CALLINT_ALL:

                        /* All exprs, range checks are killed here */

                        exp = 0;
                        rng = 0;
                        break;

                    case CALLINT_INDIRS:

                        /* Array elem assignment kills all indirect exprs */

                        exp &= ~optCSEindPtr;
                        rng &= ~optRngIndPtr;
                        break;

                    case CALLINT_NONE:

                        /* other helpers kill nothing */

                        break;
                    }
                }
                else if (tree->gtOper == GT_COPYBLK ||
                         tree->gtOper == GT_INITBLK)
                {
                    // Due to aliasing, assume all indirect exprs as killed

                    if  (tree->gtType == TYP_REF)
                    {
                        exp &= ~optCSEindPtr;
                        rng &= ~optRngIndPtr;
                    }
                    else
                    {
                        exp &= ~optCSEindScl;
                        rng &= ~optRngIndScl;
                    }

                }
            }
        }
    }

    /* Create an expression table sorted by decreasing cost */

    sortSiz = optCSEcount * sizeof(*sortTab);
    sortTab = (CSEdsc **)compGetMem(sortSiz);
    memcpy(sortTab, optCSEtab, sortSiz);

    qsort(sortTab, optCSEcount, sizeof(*sortTab), optCSEcostCmp);

    /* Consider each CSE candidate, in order of decreasing cost */

    for (cnt = optCSEcount, ptr = sortTab, add = 0;
         cnt;
         cnt--            , ptr++)
    {
        CSEdsc   *      dsc = *ptr;
        GenTreePtr      exp = dsc->csdTree;
        unsigned        def = dsc->csdDefWtCnt;
        unsigned        use = dsc->csdUseWtCnt;

#ifdef  DEBUG
        if  (verbose) // || dsc->csdTree->gtOper == GT_ARR_LENGTH)
        {
            printf("CSE #%02u [def=%2d, use=%2d, cost=%2u]:\n", dsc->csdIndex,
                                                                def,
                                                                use,
                                                                exp->gtCost);
            if  (0)
                gtDispTree(dsc->csdTree);
        }
#endif

        /* Assume we won't make this candidate into a CSE */

        dsc->csdVarNum = 0xFFFF;

        /* Did someone tell us to try hard to make this into a CSE? */

#if 0

        if  (exp->gtFlags & GTF_MAKE_CSE)
        {
            /* The following might be a little too aggressive */

            if  (use > 0)
                goto YES_CSE;
        }

#endif

        /* Do the use/def counts look promising? */

        if  (use > 0 && use >= def)
        {
            unsigned        tmp;
            treeStmtLstPtr  lst;

            if  (!(exp->gtFlags & GTF_MAKE_CSE))
            {
                /* Check for a marginal "outer" CSE case */

#if 0

                if  (exp->gtOper == GT_IND && CGknob >= 0)
                {
                    GenTreePtr      addr = exp->gtOp.gtOp1;

                    if  (addr->gtOper == GT_ADD)
                    {
                        GenTreePtr      add1 = addr->gtOp.gtOp1;
                        GenTreePtr      add2 = addr->gtOp.gtOp2;

                        if  (add1->gtCSEnum && add2->gtOper == GT_CNS_INT)
                        {
                            CSEdsc   *      nest;
                            unsigned        ndef;
                            unsigned        nuse;

                            int             ben;

                            /* Get the inner CSE's descriptor and use counts */

                            nest = optCSEtab[abs(add1->gtCSEnum)-1];
                            ndef = nest->csdDefWtCnt;
                            nuse = nest->csdUseWtCnt;

                            /*
                                Does it make sense to suppress the outer
                                CSE in order to "protect" the inner one?
                             */

                            ben  = nuse - ndef;

                            if  (use - def <= (int)(ben*CGknob))
                                goto NOT_CSE;
                        }
                    }
                }

#endif

#if 0

                /* For small use counts we require high potential savings */

                if  (exp->gtCost < 4)
                {
                    if  (use - def < 2)
                        if  (!(exp->gtFlags & GTF_MAKE_CSE))
                            goto NOT_CSE;
                }

                /* For floating-point and long values, we require a high payoff */

                if  (genTypeStSz(exp->TypeGet()) > 1)
                {
                    if  (exp->gtCost < 10)
                        goto NOT_CSE;
                    if  (use - def < 3)
                        goto NOT_CSE;
                }

#endif

#if CSELENGTH

                /* Is this an array length expression? */

                if  (exp->gtOper == GT_ARR_RNGCHK)
                {
                    /* There better be good use for this one */

                    if  (use < def*3)
                        goto NOT_CSE;
                }

#endif

                /* Are there many definitions? */

                if  (def > 2)
                {
                    /* There better be lots of uses, or this is too risky */

                    if  (use < def + def/2)
                        goto NOT_CSE;
                }
            }

        YES_CSE:

            /* We'll introduce a new temp for the CSE */

            dsc->csdVarNum = tmp = lvaCount++; add++;

#ifdef  DEBUG
            if  (verbose)
            {
                printf("Promoting CSE [temp=%u]:\n", tmp);
                gtDispTree(exp);
                printf("\n");
            }
#endif

            /*
                Walk all references to this CSE, adding an assignment
                to the CSE temp to all defs and changing all refs to
                a simple use of the CSE temp.

                We also unmark nested CSE's for all uses.
             */

#if CSELENGTH
            assert((exp->OperKind() & GTK_SMPOP) != 0 || exp->gtOper == GT_ARR_RNGCHK);
#else
            assert((exp->OperKind() & GTK_SMPOP) != 0);
#endif

            lst = dsc->csdTreeList; assert(lst);

            do
            {
                GenTreePtr      stm;
                BasicBlock  *   blk;
                var_types       typ;

                /* Get the next node in the list */

                exp = lst->tslTree;
                stm = lst->tslStmt; assert(stm->gtOper == GT_STMT);
                blk = lst->tslBlock;
                lst = lst->tslNext;

                /* Ignore the node if it's part of a removed CSE */

                if  (exp->gtFlags & GTF_DEAD)
                    continue;

                /* Ignore the node if it's been disabled as a CSE */

                if  (exp->gtCSEnum == 0)
                    continue;

                /* Figure out the actual type of the value */

                typ = genActualType(exp->TypeGet());

                if  (exp->gtCSEnum > 0)
                {
                    /* This is a use of the CSE */

#ifdef  DEBUG
                    if  (verbose) printf("CSE #%2u ref at %08X replaced with temp use.\n", exp->gtCSEnum, exp);
#endif

                    /* Array length CSE's are handled differently */

#if CSELENGTH
                    if  (exp->gtOper == GT_ARR_RNGCHK)
                    {
                        GenTreePtr      ref;
                        GenTreePtr      prv;
                        GenTreePtr      nxt;

                        /* Store the CSE use under the arrlen node */

                        ref = gtNewLclvNode(tmp, typ);
#if TGT_x86
                        ref->gtFPlvl            = exp->gtFPlvl;
#else
                        ref->gtTempRegs         = 1;
#if!TGT_IA64
                        ref->gtIntfRegs         = 0;
#endif
#endif
#if!TGT_IA64
                        ref->gtRsvdRegs         = 0;
#endif
                        ref->gtLclVar.gtLclOffs = BAD_IL_OFFSET;

                        exp->gtArrLen.gtArrLenCse = ref;

                        /* Insert the ref in the tree node list */

                        prv = exp->gtPrev; assert(prv && prv->gtNext == exp);
                        nxt = exp->gtNext; assert(nxt && nxt->gtPrev == exp);

                        prv->gtNext = ref;
                                      ref->gtPrev = prv;

                        ref->gtNext = exp;
                                      exp->gtPrev = ref;
                    }
                    else
#endif
                    {
                        /* Make sure we update the weighted ref count correctly */

                        optCSEweight = blk->bbWeight;

                        /* Unmark any nested CSE's in the sub-operands */

                        if  (exp->gtOp.gtOp1) fgWalkTree(exp->gtOp.gtOp1, optUnmarkCSEs, (void*)this);
                        if  (exp->gtOp.gtOp2) fgWalkTree(exp->gtOp.gtOp2, optUnmarkCSEs, (void*)this);

                        /* Replace the ref with a simple use of the temp */

                        exp->ChangeOper(GT_LCL_VAR);
                        exp->gtFlags           &= GTF_PRESERVE;
                        exp->gtType             = typ;

                        exp->gtLclVar.gtLclNum  = tmp;
                        exp->gtLclVar.gtLclOffs = BAD_IL_OFFSET;
                    }
                }
                else
                {
                    GenTreePtr      val;
                    GenTreePtr      asg;
                    GenTreePtr      tgt;
                    GenTreePtr      ref;

                    GenTreePtr      prv;
                    GenTreePtr      nxt;

                    /* This is a def of the CSE */

#ifdef  DEBUG
                    if  (verbose) printf("CSE #%2u ref at %08X replaced with def of temp %u\n", -exp->gtCSEnum, exp, tmp);
#endif

                    /* Make a copy of the expression */

#if CSELENGTH
                    if  (exp->gtOper == GT_ARR_RNGCHK)
                    {
                        /* Use a "nothing" node to prevent cycles */

                        val          = gtNewNothingNode();
#if TGT_x86
                        val->gtFPlvl = exp->gtFPlvl;
#endif
                        val->gtType  = exp->TypeGet();
                    }
                    else
#endif
                    {
                        val = gtNewNode(exp->OperGet(), typ); val->CopyFrom(exp);
                    }

                    /* Create an assignment of the value to the temp */

                    asg = gtNewTempAssign(tmp, val);
                    assert(asg->gtOp.gtOp1->gtOper == GT_LCL_VAR);
                    assert(asg->gtOp.gtOp2         == val);

#if!TGT_IA64
                    asg->gtRsvdRegs = val->gtRsvdRegs;
#endif
#if TGT_x86
                    asg->gtFPlvl    = exp->gtFPlvl;
#else
                    asg->gtTempRegs = val->gtTempRegs;
#if!TGT_IA64
                    asg->gtIntfRegs = val->gtIntfRegs;
#endif
#endif

                    tgt = asg->gtOp.gtOp1;
#if!TGT_IA64
                    tgt->gtRsvdRegs = 0;
#endif
#if TGT_x86
                    tgt->gtFPlvl    = exp->gtFPlvl;
#else
                    tgt->gtTempRegs = 0;    // ISSUE: is this correct?
#if!TGT_IA64
                    tgt->gtIntfRegs = 0;    // ISSUE: is this correct?
#endif
#endif

                    /* Create a reference to the CSE temp */

                    ref = gtNewLclvNode(tmp, typ);
#if!TGT_IA64
                    ref->gtRsvdRegs = 0;
#endif
#if TGT_x86
                    ref->gtFPlvl    = exp->gtFPlvl;
#else
                    ref->gtTempRegs = 0;    // ISSUE: is this correct?
#if!TGT_IA64
                    ref->gtIntfRegs = 0;    // ISSUE: is this correct?
#endif
#endif

                    /*
                        Update the tree node sequence list; the new order
                        will be: prv, val, tgt, asg, ref, exp (bashed to GT_COMMA), nxt
                     */

                    nxt = exp->gtNext; assert(!nxt || nxt->gtPrev == exp);
                    prv = exp->gtPrev;

#if CSELENGTH
                    if  (exp->gtOper == GT_ARR_RNGCHK && !prv)
                    {
                        assert(stm->gtStmt.gtStmtList == exp);
                               stm->gtStmt.gtStmtList =  val;
                    }
                    else
#endif
                    {
                        assert(prv && prv->gtNext == exp);

                        prv->gtNext = val;
                    }

                    val->gtPrev = prv;

                    val->gtNext = tgt;
                                  tgt->gtPrev = val;

                    tgt->gtNext = asg;
                                  asg->gtPrev = tgt;

                    /* Evaluating asg's RHS first, so set GTF_REVERSE_OPS */

                    asg->gtFlags |= GTF_REVERSE_OPS;

                    asg->gtNext = ref;
                                  ref->gtPrev = asg;

                    ref->gtNext = exp;
                                  exp->gtPrev = ref;

#if CSELENGTH
                    if  (exp->gtOper == GT_ARR_RNGCHK)
                    {
                        GenTreePtr      cse;

                        /* Create a comma node for the CSE assignment */

                        cse = gtNewOperNode(GT_COMMA, typ, asg, ref);
#if TGT_x86
                        cse->gtFPlvl = exp->gtFPlvl;
#endif

                        /* Insert the comma in the linked list of nodes */

                        ref->gtNext = cse;
                                      cse->gtPrev = ref;

                        cse->gtNext = exp;
                                      exp->gtPrev = cse;

                        /* Record the CSE expression in the array length node */

                        exp->gtArrLen.gtArrLenCse = cse;
                    }
                    else
#endif
                    {
                        /* Change the expression to "(tmp=val),tmp" */

                        exp->gtOper     = GT_COMMA;
                        exp->gtType     = typ;
                        exp->gtOp.gtOp1 = asg;
                        exp->gtOp.gtOp2 = ref;
                        exp->gtFlags   &= GTF_PRESERVE;
                    }

                    exp->gtFlags   |= asg->gtFlags & GTF_GLOB_EFFECT;

                    assert(!nxt || nxt->gtPrev == exp);
                }

#ifdef  DEBUG
                if  (verbose)
                {
                    printf("CSE transformed:\n");
                    gtDispTree(exp);
                    printf("\n");
                }
#endif

            }
            while (lst);

            continue;
        }

    NOT_CSE:

        /*
            Last-ditch effort to get some benefit out of this CSE. Consider
            the following code:

                int cse(int [] a, int i)
                {
                    if  (i > 0)
                    {
                        if  (a[i] < 0)  // def of CSE
                            i = a[i];   // use of CSE
                    }
                    else
                    {
                        if  (a[i] > 0)  // def of CSE
                            i = 0;
                    }

                    return  i;
                }

            We will see 2 defs and only 1 use of the CSE a[i] in the method
            but it's still a good idea to make the first def and use into a
            CSE.
         */

        if (dsc->csdTreeList && exp->gtCost > 3)
        {
            bool            fnd = false;
            treeStmtLstPtr  lst;

            /* Look for a definition followed by a use "nearby" */

            lst = dsc->csdTreeList;

//          fgDispBasicBlocks( true);
//          fgDispBasicBlocks(false);

            do
            {
                GenTreePtr      stm;
                treeStmtLstPtr  tmp;
                BasicBlock  *   beg;
                int             got;

                /* Get the next node in the list */

                exp = lst->tslTree; assert(exp);

                /* Ignore the node if it's part of a removed CSE */

                if  (exp->gtFlags & GTF_DEAD)
                    goto NEXT_NCSE;

                /* Is this a CSE definition? */

                if  (exp->gtCSEnum >= 0)
                {
                    /* Disable this CSE, it looks hopeless */

                    exp->gtCSEnum = 0;
                    goto NEXT_NCSE;
                }

                /* Now look for any uses that immediately follow */

                stm = lst->tslStmt; assert(stm->gtOper == GT_STMT);
                beg = lst->tslBlock;

                /* If the block doesn't flow into its successor, give up */

                if  (beg->bbJumpKind != BBJ_NONE &&
                     beg->bbJumpKind != BBJ_COND)
                {
                    /* Disable this CSE, it looks hopeless */

                    exp->gtCSEnum = 0;
                    goto NEXT_NCSE;
                }

//              printf("CSE def %08X (cost=%2u) in stmt %08X of block #%u\n", exp, exp->gtCost, stm, beg->bbNum);

                got = -exp->gtCost;

                for (tmp = lst->tslNext; tmp; tmp = tmp->tslNext)
                {
                    GenTreePtr      nxt;
                    BasicBlock  *   blk;
                    unsigned        ben;

                    nxt = tmp->tslTree;

                    /* Ignore it if it's part of a removed CSE */

                    if  (nxt->gtFlags & GTF_DEAD)
                        continue;

                    /* Is this a CSE def or use? */

                    if  (nxt->gtCSEnum < 0)
                        break;

                    /* We'll be computing the benefit of the CSE */

                    ben = nxt->gtCost;

                    /* Is this CSE in the same block as the def? */

                    blk = tmp->tslBlock;

                    if  (blk != beg)
                    {
                        unsigned        lnum;
                        LoopDsc     *   ldsc;

                        /* Does the use immediately follow the def ? */

                        if  (beg->bbNext != blk)
                            break;

                        if  (blk->bbFlags & BBF_LOOP_HEAD)
                        {
                            /* Is 'beg' right in front of a loop? */

                            for (lnum = 0, ldsc = optLoopTable;
                                 lnum < optLoopCount;
                                 lnum++  , ldsc++)
                            {
                                if  (beg == ldsc->lpHead)
                                {
                                    // UNDONE: Make sure no other defs within loop

                                    ben *= 4;
                                    goto CSE_HDR;
                                }
                            }

                            break;
                        }
                        else
                        {
                            /* Does any other block jump to the use ? */

//                          if  (blk->bbRefs > 1)   UNDONE: this doesn't work; why?
                            if  (fgBlockHasPred(blk, beg, fgFirstBB, fgLastBB))
                                break;
                        }
                    }

                CSE_HDR:

//                  printf("CSE use %08X (ben =%2u) in stmt %08X of block #%u\n", nxt, ben, tmp->tslStmt, blk->bbNum);

                    /* This CSE use is reached only by the above def */

                    got += ben;
                }

//              printf("Estimated benefit of CSE = %u\n", got);

                /* Did we find enough CSE's worth keeping? */

                if  (got > 0)
                {
                    /* Skip to the first unacceptable CSE */

                    lst = tmp;

                    /* Remember that we've found something worth salvaging */

                    fnd = true;
                }
                else
                {
                    /* Disable all the worthless CSE's we've just seen */

                    do
                    {
                        lst->tslTree->gtCSEnum = 0;
                    }
                    while ((lst = lst->tslNext) != tmp);
                }

                continue;

            NEXT_NCSE:

                lst = lst->tslNext;
            }
            while (lst);

            /* If we've kept any of the CSE defs/uses, go process them */

            if  (fnd)
                goto YES_CSE;
         }
    }

    /* Did we end up creating any CSE's ? */

    if  (add)
    {
        size_t              tabSiz;
        LclVarDsc   *       tabPtr;

        /* Remove any dead nodes from the sequence lists */

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            GenTreePtr      stmt;
            GenTreePtr      next;
            GenTreePtr      tree;

            // CONSIDER: The following is slow, is there a better way?

            for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
            {
                assert(stmt->gtOper == GT_STMT);

                tree = stmt->gtStmt.gtStmtList;

                /* Remove any initial dead nodes first */

                while (tree->gtFlags & GTF_DEAD)
                {
//                  printf("Remove dead node %08X (it was  part of CSE use)\n", tree);

                    /* Decrement local's ref count since removing */

                    optCSEDecRefCnt(tree, block);

                    tree = tree->gtNext; assert(tree);
                    stmt->gtStmt.gtStmtList = tree;
                    tree->gtPrev            = 0;
                }

                /* Remove any dead nodes in the middle of the list */

                while (tree)
                {
                    assert((tree->gtFlags & GTF_DEAD) == 0);

                    /*
                        Special case: in order for live variable analysis
                        to work correctly, we mark assignments as having
                        to evaluate the RHS first, *except* when the
                        assignment is of a local variable to another
                        local variable. The problem is that if we change
                        an assignment of a complex expression to a simple
                        assignment of a CSE temp, we must make sure we
                        clear the 'reverse' flag in case the target is
                        a simple local.
                     */

#if 0
                    if  (tree->OperKind() & GTK_ASGOP)
                    {
                        if  (tree->gtOp.gtOp2->gtOper == GT_LCL_VAR)
                            tree->gtFlags &= ~GTF_REVERSE_OPS;
                    }
#endif

                    next = tree->gtNext;

                    if  (next && (next->gtFlags & GTF_DEAD))
                    {
//                      printf("Remove dead node %08X (it was  part of CSE use)\n", next);

                        /* decrement local's ref count since removing */
                        optCSEDecRefCnt(next, block);

                        next = next->gtNext;

                        next->gtPrev = tree;
                        tree->gtNext = next;

                        continue;
                    }

                    /* propagate the right flags up the tree
                     * For the DEF of a CSE we have to propagate the GTF_ASG flag
                     * For the USE of a CSE we have to clear the GTF_EXCEPT flag */

                    if (tree->OperKind() & GTK_UNOP)
                    {
                        //assert (tree->gtOp.gtOp1); // some nodes likr GT_RETURN don't have an operand

                        if (tree->gtOp.gtOp1) tree->gtFlags |= tree->gtOp.gtOp1->gtFlags & GTF_GLOB_EFFECT;
                    }

                    if (tree->OperKind() & GTK_BINOP)
                    {
                        // assert (tree->gtOp.gtOp1); //same comment as above for GT_QMARK
                        // assert (tree->gtOp.gtOp2); // GT_COLON

                        if (tree->gtOp.gtOp1) tree->gtFlags |= tree->gtOp.gtOp1->gtFlags & GTF_GLOB_EFFECT;
                        if (tree->gtOp.gtOp2) tree->gtFlags |= tree->gtOp.gtOp2->gtFlags & GTF_GLOB_EFFECT;
                    }

                    tree = next;
                }
            }
        }

        /* Allocate the new, larger variable descriptor table */

        lvaTableCnt = lvaCount * 2;

        tabSiz      = lvaTableCnt * sizeof(*lvaTable);

        tabPtr      = lvaTable;
                      lvaTable = (LclVarDsc*)compGetMem(tabSiz);

        memset(lvaTable, 0, tabSiz);

        /* Copy the old part of the variable table */

        memcpy(lvaTable, tabPtr, (lvaCount - add) * sizeof(*tabPtr));

        /* Append entries for the CSE temps to the variable table */

        for (cnt = optCSEcount, ptr = sortTab;
             cnt;
             cnt--            , ptr++)
        {
            CSEdsc   *      dsc = *ptr;

            if  (dsc->csdVarNum != 0xFFFF)
            {
                LclVarDsc   *   varDsc = lvaTable + dsc->csdVarNum;

                varDsc->lvType      = genActualType(dsc->csdTree->gtType);
                varDsc->lvRefCnt    = dsc->csdUseCount + dsc->csdDefCount;
                varDsc->lvRefCntWtd = dsc->csdUseWtCnt + dsc->csdDefWtCnt;

//              printf("Creating CSE temp #%02u: refCnt=%2u,refWtd=%4u\n", dsc->csdVarNum, varDsc->lvRefCnt, varDsc->lvRefCntWtd);
            }
        }

        /* Resort the variable table */

        lvaSortByRefCount();
    }
}

/*****************************************************************************
 *
 *  Initialize the constant assignments tracking logic.
 */

void                Compiler::optCopyConstAsgInit()
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    for (lclNum = 0, varDsc = lvaTable;
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
        varDsc->lvCopyAsgDep  = 0;
        varDsc->lvConstAsgDep = 0;
    }

    optCopyAsgCount    = 0;
    optConstAsgCount   = 0;

    optCopyPropagated  = false;
    optConstPropagated = false;

    optConditionFolded = false;
}

/*****************************************************************************
 *
 *  Assign an index to the given copy assignment (adding it to the lookup table,
 *  if necessary). Returns the index - or 0 if the assignment is not a copy.
 */

int                 Compiler::optCopyAsgIndex(GenTreePtr tree)
{
    unsigned        leftLclNum;
    unsigned        rightLclNum;

    GenTreePtr      op1;
    GenTreePtr      op2;

    op1 = tree->gtOp.gtOp1;
    op2 = tree->gtOp.gtOp2;

    /* get the local var numbers */

    leftLclNum  = op1->gtLclVar.gtLclNum; assert(leftLclNum  < lvaCount);
    rightLclNum = op2->gtLclVar.gtLclNum; assert(rightLclNum < lvaCount);

    /* Check to see if the assignment is not already recorded in the table */

    for (unsigned i=0; i < optCopyAsgCount; i++)
    {
        if ((optCopyAsgTab[i].leftLclNum  ==  leftLclNum) &&
            (optCopyAsgTab[i].rightLclNum == rightLclNum)  )
        {
            /* we have a match - return the index */
            return i+1;
        }
    }

    /* Not found, add a new entry (unless we reached the maximum) */

    if  (optCopyAsgCount == EXPSET_SZ)
        return  0;

    unsigned index = optCopyAsgCount;

    optCopyAsgTab[index].leftLclNum  =  leftLclNum;
    optCopyAsgTab[index].rightLclNum = rightLclNum;

    optCopyAsgCount++;

    unsigned retval = index+1;
    assert(optCopyAsgCount == retval);

#ifdef  DEBUG
    if  (verbose)
    {
        printf("Copy assignment #%02u:\n", retval);
        gtDispTree(tree);
        printf("\n");
    }
#endif

    /* Mark the variables this index depends on */

    unsigned      mask    = genCSEnum2bit(retval);
    LclVarDsc *   varDsc;

    varDsc                = lvaTable + leftLclNum;
    varDsc->lvCopyAsgDep |= mask;

    varDsc                = lvaTable + rightLclNum;
    varDsc->lvCopyAsgDep |= mask;

    return  retval;
}

/*****************************************************************************
 *
 *  Assign an index to the given constant assignment (adding it to the lookup table,
 *  if necessary). Returns the index - or 0 if the assignment is not constant.
 */

int                 Compiler::optConstAsgIndex(GenTreePtr tree)
{
    unsigned        lclNum;

    assert(optIsConstAsg(tree));

    /* get the local var num and the constant value */

    assert(tree->gtOp.gtOp1->gtOper == GT_LCL_VAR);
    assert((tree->gtOp.gtOp2->OperKind() & GTK_CONST) &&
           (tree->gtOp.gtOp2->gtOper != GT_CNS_STR));

    lclNum = tree->gtOp.gtOp1->gtLclVar.gtLclNum;
    assert(lclNum < lvaCount);

    /* Check to see if the assignment is not already recorded in the table */

    for (unsigned i=0; i < optConstAsgCount; i++)
    {
        if ((optConstAsgTab[i].constLclNum == lclNum))
        {
            switch (genActualType(tree->gtOp.gtOp1->gtType))
            {
            case TYP_REF:
            case TYP_BYREF:
            case TYP_INT:
                assert (tree->gtOp.gtOp2->gtOper == GT_CNS_INT);
                if  (optConstAsgTab[i].constIval == tree->gtOp.gtOp2->gtIntCon.gtIconVal)
                {
                    /* we have a match - return the index */
                    return i+1;
                }
                break;

            case TYP_LONG:
                assert (tree->gtOp.gtOp2->gtOper == GT_CNS_LNG);
                if  (optConstAsgTab[i].constLval == tree->gtOp.gtOp2->gtLngCon.gtLconVal)
                {
                    /* we have a match - return the index */
                    return i+1;
                }
                break;

            case TYP_FLOAT:
                assert (tree->gtOp.gtOp2->gtOper == GT_CNS_FLT);

                /* If a NaN do not compare with it! */
                if  (_isnan(tree->gtOp.gtOp2->gtFltCon.gtFconVal))
                    return 0;

                if  (optConstAsgTab[i].constFval == tree->gtOp.gtOp2->gtFltCon.gtFconVal)
                {
                    /* we have a match - special case for floating point
                     * numbers - pozitive and negative zero !!! */

                    if  (_fpclass((double)optConstAsgTab[i].constFval) !=
                         _fpclass((double)tree->gtOp.gtOp2->gtFltCon.gtFconVal))
                        break;

                    /* return the index */
                    return i+1;
                }
                break;

            case TYP_DOUBLE:
                assert (tree->gtOp.gtOp2->gtOper == GT_CNS_DBL);

                /* Check for NaN */
                if  (_isnan(tree->gtOp.gtOp2->gtDblCon.gtDconVal))
                    return 0;

                if  (optConstAsgTab[i].constDval == tree->gtOp.gtOp2->gtDblCon.gtDconVal)
                {
                    /* we have a match - special case for floating point
                     * numbers - pozitive and negative zero !!! */

                    if  (_fpclass(optConstAsgTab[i].constDval) != _fpclass(tree->gtOp.gtOp2->gtDblCon.gtDconVal))
                        break;

                    /* we have a match - return the index */
                    return i+1;
                }
                break;

            default:
                assert (!"Constant assignment table contains local var of unsuported type");
            }
        }
    }

    /* Not found, add a new entry (unless we reached the maximum) */

    if  (optConstAsgCount == EXPSET_SZ)
        return  0;

    unsigned index = optConstAsgCount;

    switch (genActualType(tree->gtOp.gtOp1->gtType))
    {

    case TYP_REF:
    case TYP_BYREF:
    case TYP_INT:
        assert (tree->gtOp.gtOp2->gtOper == GT_CNS_INT);
        optConstAsgTab[index].constIval = tree->gtOp.gtOp2->gtIntCon.gtIconVal;
        break;

    case TYP_LONG:
        assert (tree->gtOp.gtOp2->gtOper == GT_CNS_LNG);
        optConstAsgTab[index].constLval = tree->gtOp.gtOp2->gtLngCon.gtLconVal;
        break;

    case TYP_FLOAT:
        assert (tree->gtOp.gtOp2->gtOper == GT_CNS_FLT);

        /* If a NaN then we don't record it - Return 0 which by default
         * means this is an untracked node */
        if  (_isnan(tree->gtOp.gtOp2->gtFltCon.gtFconVal))
            return 0;

        optConstAsgTab[index].constFval = tree->gtOp.gtOp2->gtFltCon.gtFconVal;
        break;

    case TYP_DOUBLE:
        assert (tree->gtOp.gtOp2->gtOper == GT_CNS_DBL);

        /* Check for NaN */
        if  (_isnan(tree->gtOp.gtOp2->gtDblCon.gtDconVal))
            return 0;

        optConstAsgTab[index].constDval = tree->gtOp.gtOp2->gtDblCon.gtDconVal;
        break;

    default:
        /* non tracked type - do not add it to the table
         * return 0 - cannot be a constant assignment */

        assert (!"Cannot insert a constant assignment to local var of unsupported type");
        return 0;
    }

    optConstAsgTab[index].constLclNum = lclNum;

    optConstAsgCount++;

    unsigned retval = index+1;
    assert(optConstAsgCount == retval);

#ifdef  DEBUG
    if  (verbose)
    {
        printf("Constant assignment #%02u:\n", retval);
        gtDispTree(tree);
        printf("\n");
    }
#endif

    /* Mark the variable this index depends on */

    unsigned       mask    = genCSEnum2bit(retval);
    LclVarDsc *    varDsc  = lvaTable + lclNum;

    varDsc->lvConstAsgDep |= mask;

    return retval;
}

/*****************************************************************************
 *
 *  Given a local var node and a set of available
 *  copy assignments tries to fold the node - returns true if a propagation
 *  took place, false otherwise
 */

bool                Compiler::optPropagateCopy(EXPSET_TP exp, GenTreePtr tree)
{
    unsigned        lclNum;
    unsigned        mask;
    unsigned        i;
    LclVarDsc *     varDsc;
    LclVarDsc *     varDscCopy;

    assert(exp && (tree->gtOper == GT_LCL_VAR));

    /* Get the local var number */

    lclNum = tree->gtLclVar.gtLclNum;
    assert(lclNum < lvaCount);

    /* See if the variable is a copy of another one */

    for (i=0, mask=1; i < optCopyAsgCount; i++, mask<<=1)
    {
        assert(mask == genCSEnum2bit(i+1));

        if  ((exp & mask) && (optCopyAsgTab[i].leftLclNum == lclNum))
        {
            /* hurah, our variable is a copy */
#ifdef  DEBUG
            if  (verbose)
            {
                printf("Propagating copy node for index #%02u in block #%02u:\n", i+1, compCurBB->bbNum);
                gtDispTree(tree);
                printf("\n");
            }
#endif
            /* Replace the copy with the original local var */

            assert(optCopyAsgTab[i].rightLclNum < lvaCount);
            tree->gtLclVar.gtLclNum = optCopyAsgTab[i].rightLclNum;

            /* record the fact that we propagated a copy */

            optCopyPropagated = true;

            /* Update the reference counts for both variables */

            varDsc     = lvaTable + lclNum;
            varDscCopy = lvaTable + optCopyAsgTab[i].rightLclNum;

            assert(varDsc->lvRefCnt);
            assert(varDscCopy->lvRefCnt);

            varDsc->lvRefCnt--;
            varDscCopy->lvRefCnt++;

            varDsc->lvRefCntWtd     -= compCurBB->bbWeight;
            varDscCopy->lvRefCntWtd += compCurBB->bbWeight;

#ifdef  DEBUG
            if  (verbose)
            {
                printf("New node for index #%02u:\n", i+1);
                gtDispTree(tree);
                printf("\n");
            }
#endif
            /* Check for cascaded copy prop's */
            exp &= ~mask;
            if (exp)
                optPropagateCopy(exp, tree);

            return true;
        }
    }

    /* No propagation took place - return false */

    return false;
}

/*****************************************************************************
 *
 *  Given a local var node and a set of available
 *  constant assignments tries to fold the node
 */

bool                Compiler::optPropagateConst(EXPSET_TP exp, GenTreePtr tree)
{
    unsigned        lclNum;
    unsigned        mask;
    unsigned        i;
    LclVarDsc *     varDsc;

    assert(exp);

    /* If node is already a constant return */

    if (tree->OperKind() & GTK_CONST)
        return false;

    /* Is this a simple local variable reference? */

    if  (tree->gtOper != GT_LCL_VAR)
        return false;

    /* Get the local var num */

    lclNum = tree->gtLclVar.gtLclNum;
    assert(lclNum < lvaCount);

    /* See if variable is in constant expr table */

    for (i=0, mask=1; i < optConstAsgCount; i++, mask<<=1)
    {
        assert(mask == genCSEnum2bit(i+1));

        if  ((exp & mask) && (optConstAsgTab[i].constLclNum == lclNum))
        {
            /* hurah, our variable can be folded to a constant */
#ifdef  DEBUG
            if  (verbose)
            {
                printf("Folding constant node for index #%02u in block #%02u:\n", i+1, compCurBB->bbNum);
                gtDispTree(tree);
                printf("\n");
            }
#endif
            switch (genActualType(tree->gtType))
            {
            case TYP_REF:
                 tree->ChangeOper(GT_CNS_INT);
                 tree->gtType             = TYP_REF;
                 tree->gtIntCon.gtIconVal = optConstAsgTab[i].constIval;
                 break;

            case TYP_BYREF:
                 tree->ChangeOper(GT_CNS_INT);
                 tree->gtType             = TYP_BYREF;
                 tree->gtIntCon.gtIconVal = optConstAsgTab[i].constIval;
                 break;

            case TYP_INT:
                 tree->ChangeOper(GT_CNS_INT);
                 tree->gtType             = TYP_INT;
                 tree->gtIntCon.gtIconVal = optConstAsgTab[i].constIval;
                 break;

            case TYP_LONG:
                tree->ChangeOper(GT_CNS_LNG);
                tree->gtType             = TYP_LONG;
                tree->gtLngCon.gtLconVal = optConstAsgTab[i].constLval;
                break;

            case TYP_FLOAT:
                tree->ChangeOper(GT_CNS_FLT);
                tree->gtType             = TYP_FLOAT;
                tree->gtFltCon.gtFconVal = optConstAsgTab[i].constFval;
                break;

            case TYP_DOUBLE:
                tree->ChangeOper(GT_CNS_DBL);
                tree->gtType             = TYP_DOUBLE;
                tree->gtDblCon.gtDconVal = optConstAsgTab[i].constDval;
                break;

            default:
                assert (!"Cannot fold local var of unsuported type");
                return false;
            }

            /* record the fact that we propagated a constant */

            optConstPropagated = true;

            /* Update the reference counts - the variable doesn't exist anymore */

            varDsc = lvaTable + lclNum;

            assert(varDsc->lvRefCnt);

            varDsc->lvRefCnt--;
            varDsc->lvRefCntWtd -= compCurBB->bbWeight;

#ifdef  DEBUG
            if  (verbose)
            {
                printf("New node for index #%02u:\n", i+1);
                gtDispTree(tree);
                printf("\n");
            }
#endif
            return true;
        }
    }

    /* No propagation took place - return false */

    return false;
}

/*****************************************************************************
 *
 *  The main constant / copy propagation procedure
 */

void                Compiler::optCopyConstProp()
{
    BasicBlock *    block;

#if TGT_IA64
    return;
#endif

    /* initialize the copy / constant assignments tracking logic */

    optCopyConstAsgInit();

    /* make sure you have up-to-date info about block bbNums, bbRefs and bbPreds */

#ifdef  DEBUG
    if  (verbose)
    {
        printf("\nFlowgraph before copy / constant propagation:\n");
        fgDispBasicBlocks();
        printf("\n");
    }

    fgDebugCheckBBlist();
#endif

    /* first discover all copy and constant assignments,
     * record them in the table and assign them an index */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            bool            inColon  = false;
            GenTreePtr      gtQMCond = 0;

            assert(stmt->gtOper == GT_STMT);

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                tree->gtConstAsgNum = 0;
                tree->gtCopyAsgNum  = 0;

                /* No assignments can be generated in a COLON */

                if (inColon == false)
                {
                    if  (optIsConstAsg(tree))
                    {
                        /* Assign an index to this constant assignment and mark
                         * the local descriptor for the variable as being part of this assignment */

                        tree->gtConstAsgNum = optConstAsgIndex(tree);
                    }
                    else if (optIsCopyAsg(tree))
                    {
                        /* Assign an index to this copy assignment and mark
                         * the local descriptor for the variable as being part of this assignment */

                        tree->gtCopyAsgNum  = optCopyAsgIndex(tree);
                    }
                    else if (tree->OperIsCompare() && (tree->gtFlags & GTF_QMARK_COND))
                    {
                        /* Remember the first ?: - this is needed in case of nested ?: */
                        if (inColon == false)
                        {
                            inColon = true;
                            gtQMCond = tree;
                        }
                    }
                }
                else if ((tree->gtOper == GT_QMARK) && tree->gtOp.gtOp1)
                {
                    assert(inColon);
                    assert(gtQMCond);

                    if (tree->gtOp.gtOp1 == gtQMCond)
                        inColon = false;
                }
            }

            assert(inColon == false);
        }
    }

    /* We're done if there were no constant or copy assignments */

    if  (!optConstAsgCount && !optCopyAsgCount)
        return;

    /* Compute 'gen' and 'kill' sets for all blocks
     * This is a classic available expressions forward
     * dataflow analysis */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;

        EXPSET_TP       constGen  = 0;
        EXPSET_TP       constKill = 0;

        EXPSET_TP       copyGen   = 0;
        EXPSET_TP       copyKill  = 0;

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                if (tree->OperKind() & GTK_ASGOP)
                {
                    /* What is the target of the assignment? */

                    if  (tree->gtOp.gtOp1->gtOper == GT_LCL_VAR)
                    {
                        unsigned        lclNum;
                        LclVarDsc   *   varDsc;

                        /* Assignment to a local variable */

                        lclNum = tree->gtOp.gtOp1->gtLclVar.gtLclNum;
                        assert(lclNum < lvaCount);
                        varDsc = lvaTable + lclNum;

                        /* All dependent copy / const assignments are killed here */

                        constKill |=  varDsc->lvConstAsgDep;
                        constGen  &= ~varDsc->lvConstAsgDep;

                        copyKill  |=  varDsc->lvCopyAsgDep;
                        copyGen   &= ~varDsc->lvCopyAsgDep;

                        /* Is this a tracked copy / constant assignment */

                        if  (tree->gtConstAsgNum)
                        {
                            /* A new constant assignment is generated here */
                            constGen  |=  genCSEnum2bit(tree->gtConstAsgNum);
                            constKill &= ~genCSEnum2bit(tree->gtConstAsgNum);
                        }
                        else if (tree->gtCopyAsgNum)
                        {
                            /* A new copy assignment is generated here */
                            copyGen   |=  genCSEnum2bit(tree->gtCopyAsgNum);
                            copyKill  &= ~genCSEnum2bit(tree->gtCopyAsgNum);
                        }
                    }
                }
            }
        }

#ifdef  DEBUG

        if  (verbose)
        {
            printf("BB #%3u", block->bbNum);
            printf(" constGen = %08X", constGen );
            printf(" constKill= %08X", constKill);
            printf("\n");
        }

#endif

        block->bbConstAsgGen  = constGen;
        block->bbConstAsgKill = constKill;

        block->bbCopyAsgGen   = copyGen;
        block->bbCopyAsgKill  = copyKill;
    }

    /* Compute the data flow values for all tracked expressions
     * IN and OUT never change for the initial basic block B1 */

    fgFirstBB->bbConstAsgIn  = 0;
    fgFirstBB->bbConstAsgOut = fgFirstBB->bbConstAsgGen;

    fgFirstBB->bbCopyAsgIn   = 0;
    fgFirstBB->bbCopyAsgOut  = fgFirstBB->bbCopyAsgGen;

    /* Initially estimate the OUT sets to everything except killed expressions
     * Also set the IN sets to 1, so that we can perform the intersection */

    for (block = fgFirstBB->bbNext; block; block = block->bbNext)
    {
        block->bbConstAsgOut   = ((EXPSET_TP) -1 ) & ~block->bbConstAsgKill;
        block->bbConstAsgIn    = ((EXPSET_TP) -1 );

        block->bbCopyAsgOut   = ((EXPSET_TP)  -1 ) & ~block->bbCopyAsgKill;
        block->bbCopyAsgIn    = ((EXPSET_TP)  -1 );
    }

#if 1

    /* Modified dataflow algorithm for available expressions */

    for (;;)
    {
        bool        change = false;

#if DATAFLOW_ITER
        CFiterCount++;
#endif

        /* Visit all blocks and compute new data flow values */

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            EXPSET_TP       constOut = block->bbConstAsgOut;
            EXPSET_TP       copyOut  = block->bbCopyAsgOut;

            switch (block->bbJumpKind)
            {
                BasicBlock * *  jmpTab;
                unsigned        jmpCnt;

                BasicBlock *    bcall;

            case BBJ_RET:

                if (block->bbFlags & BBF_ENDFILTER)
                {
                    block->bbJumpDest->bbConstAsgIn &= constOut;
                    block->bbJumpDest->bbCopyAsgIn  &=  copyOut;
                    break;
                }
                /*
                    UNDONE: Since it's not a trivial proposition to figure out
                    UNDONE: which blocks may call this one, we'll include all
                    UNDONE: blocks that end in calls (to play it safe).
                 */

                for (bcall = fgFirstBB; bcall; bcall = bcall->bbNext)
                {
                    if  (bcall->bbJumpKind == BBJ_CALL)
                    {
                        assert(bcall->bbNext);

                        bcall->bbNext->bbConstAsgIn &= constOut;
                        bcall->bbNext->bbCopyAsgIn  &=  copyOut;
                    }
                }

                break;

            case BBJ_THROW:
            case BBJ_RETURN:
                break;

            case BBJ_COND:
            case BBJ_CALL:
                block->bbNext    ->bbConstAsgIn &= constOut;
                block->bbJumpDest->bbConstAsgIn &= constOut;

                block->bbNext    ->bbCopyAsgIn  &=  copyOut;
                block->bbJumpDest->bbCopyAsgIn  &=  copyOut;
                break;

            case BBJ_ALWAYS:
                block->bbJumpDest->bbConstAsgIn &= constOut;
                block->bbJumpDest->bbCopyAsgIn  &=  copyOut;
                break;

            case BBJ_NONE:
                block->bbNext    ->bbConstAsgIn &= constOut;
                block->bbNext    ->bbCopyAsgIn  &=  copyOut;
                break;

            case BBJ_SWITCH:

                jmpCnt = block->bbJumpSwt->bbsCount;
                jmpTab = block->bbJumpSwt->bbsDstTab;

                do
                {
                    (*jmpTab)->bbConstAsgIn &= constOut;
                    (*jmpTab)->bbCopyAsgIn  &=  copyOut;
                }
                while (++jmpTab, --jmpCnt);

                break;
            }

            /* Is this block part of a 'try' statement? */

            if  (block->bbFlags & BBF_HAS_HANDLER)
            {
                unsigned        XTnum;
                EHblkDsc *      HBtab;

                unsigned        blkNum = block->bbNum;

                for (XTnum = 0, HBtab = compHndBBtab;
                     XTnum < info.compXcptnsCount;
                     XTnum++  , HBtab++)
                {
                    /* Any handler may be jumped to from the try block */

                    if  (HBtab->ebdTryBeg->bbNum <= blkNum &&
                         HBtab->ebdTryEnd->bbNum >  blkNum)
                    {
//                      HBtab->ebdHndBeg->bbConstAsgIn &= constOut;

                        //CONSIDER: The following is too conservative,
                        //      but the old code above isn't good
                        //           enough (way too optimistic).

                        /* Either we enter the filter or the catch/finally */

                        if (HBtab->ebdFlags & JIT_EH_CLAUSE_FILTER)
                        {
                            HBtab->ebdFilter->bbConstAsgIn = 0;
                            HBtab->ebdFilter->bbCopyAsgIn  = 0;
                        }
                        else
                        {
                            HBtab->ebdHndBeg->bbConstAsgIn = 0;
                            HBtab->ebdHndBeg->bbCopyAsgIn  = 0;
                        }
                    }
                }
            }
        }

        /* Compute the new 'in' values and see if anything changed */

        for (block = fgFirstBB->bbNext; block; block = block->bbNext)
        {
            EXPSET_TP       newConstAsgOut;
            EXPSET_TP       newCopyAsgOut;

            /* Compute new 'out' exp value for this block */

            newConstAsgOut = block->bbConstAsgOut & ((block->bbConstAsgIn & ~block->bbConstAsgKill) | block->bbConstAsgGen);
            newCopyAsgOut  = block->bbCopyAsgOut  & ((block->bbCopyAsgIn  & ~block->bbCopyAsgKill)  | block->bbCopyAsgGen);

            /* Has the 'out' set changed? */

            if  (block->bbConstAsgOut != newConstAsgOut)
            {
                /* Yes - record the new value and loop again */

//              printf("Change exp out of %02u from %08X to %08X\n", block->bbNum, (int)block->bbConstAsgOut, (int)newConstAsgOut);

                 block->bbConstAsgOut  = newConstAsgOut;
                 change = true;
            }

            if  (block->bbCopyAsgOut != newCopyAsgOut)
            {
                /* Yes - record the new value and loop again */

//              printf("Change exp out of %02u from %08X to %08X\n", block->bbNum, (int)block->bbConstAsgOut, (int)newConstAsgOut);

                 block->bbCopyAsgOut  = newCopyAsgOut;
                 change = true;
            }
        }

#if 0
        for (block = fgFirstBB; block; block = block->bbNext)
        {
            printf("BB #%3u", block->bbNum);
            printf(" expIn  = %08X", block->bbConstAsgIn );
            printf(" expOut = %08X", block->bbConstAsgOut);
            printf("\n");
        }

        printf("\nchange = %d\n", change);
#endif

        if  (!change)
            break;
    }

#else

    /* The standard Dragon book algorithm for available expressions */

    for (;;)
    {
        bool        change = false;

#if DATAFLOW_ITER
        CFiterCount++;
#endif

        /* Visit all blocks and compute new data flow values */

        for (block = fgFirstBB->bbNext; block; block = block->bbNext)
        {
            BasicBlock  *   predB;

            /* compute the IN set: IN[B] = intersect OUT[P}, for all P = predecessor of B */
            /* special case - this is a BBJ_RET block - cannot figure out which blocks may call it */


/*
            if  (block->bbJumpKind == BBJ_RET)
            {
                BasicBlock *    bcall;


                for (bcall = fgFirstBB; bcall; bcall = bcall->bbNext)
                {
                    if  (bcall->bbJumpKind == BBJ_CALL)
                    {
                        assert(bcall->bbNext);
                        bcall->bbNext->bbConstAsgInNew &= constOut;
                    }
                }
            }
*/

            for (predB = fgFirstBB; predB; predB = predB->bbNext)
            {
                EXPSET_TP       constOut = predB->bbConstAsgOut;
                EXPSET_TP       copyOut  = predB->bbCopyAsgOut;

                if  (predB->bbNext == block)
                {
                    /* we have a "direct" predecessor */

                    assert(predB->bbNum + 1 == block->bbNum);
                    block->bbConstAsgIn &= constOut;
                    block->bbCopyAsgIn  &= copyOut;
                    continue;
                }

                switch (predB->bbJumpKind)
                {
                    BasicBlock * *  jmpTab;
                    unsigned        jmpCnt;

                case BBJ_NONE:
                    /* the only interesting case - when this is a predecessor - was treated above */
                    break;

                case BBJ_RET:
                    if (predB->bbFlags & BBF_ENDFILTER)
                    {
                        block->bbConstAsgIn &= constOut;
                        block->bbCopyAsgIn  &= copyOut;
                    }
                    break;

                case BBJ_THROW:
                    /* THROW is an internal block and lets everything go through it - catched above */
                case BBJ_RETURN:
                    /* RETURN cannot have a successor */
                    break;

                case BBJ_COND:
                case BBJ_CALL:
                case BBJ_ALWAYS:

                    if  (predB->bbJumpDest == block)
                    {
                        block->bbConstAsgIn &= constOut;
                        block->bbCopyAsgIn  &= copyOut;
                    }
                    break;

                case BBJ_SWITCH:

                    jmpCnt = predB->bbJumpSwt->bbsCount;
                    jmpTab = predB->bbJumpSwt->bbsDstTab;

                    do
                    {
                        if  ((*jmpTab) == block)
                        {
                            block->bbConstAsgIn &= constOut;
                            block->bbCopyAsgIn  &= copyOut;
                        }
                    }
                    while (++jmpTab, --jmpCnt);

                    break;
                }
            }

            EXPSET_TP       constOldOut = block->bbConstAsgOut;
            EXPSET_TP       copyOldOut  = block->bbCopyAsgOut;

            /* compute the new OUT set */

            block->bbConstAsgOut = (block->bbConstAsgIn & ~block->bbConstAsgKill) |
                                    block->bbConstAsgGen;

            block->bbCopyAsgOut  = (block->bbCopyAsgIn  & ~block->bbCopyAsgKill)  |
                                    block->bbCopyAsgGen;

            if  ((constOldOut != block->bbConstAsgOut) ||
                 (copyOldOut  != block->bbCopyAsgOut)   )
            {
                change = true;
            }
        }

        if  (!change)
            break;
    }

#endif

#ifdef  DEBUG
    if  (verbose)
    {
        printf("\n");

        for (block = fgFirstBB; block; block = block->bbNext)
        {
            printf("BB #%3u", block->bbNum);
            printf(" constIn  = %08X", block->bbConstAsgIn );
            printf(" constOut = %08X", block->bbConstAsgOut);
            printf("\n");
        }

        printf("\n");
    }
#endif

    /* Perform copy / constant propagation (and constant folding) */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;
        EXPSET_TP       constExp = block->bbConstAsgIn;
        EXPSET_TP       copyExp  = block->bbCopyAsgIn;

        /* If IN = 0 and GEN = 0, there's nothing to do */

        if (((constExp|copyExp) == 0) && !block->bbConstAsgGen && !block->bbCopyAsgGen)
             continue;

        /* Make the current basic block address available globally */

        compCurBB = block;

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            /* - Propagate any constants - at the same time look for more
             *   opportunities to fold nodes (if the children are constants)
             * - Look for anything that can kill an available expression
             *   i.e assignments to local variables
             */

            bool        updateStmt = false;  // set to true if a propagation/folding took place
                                             // and thus we must morph, set order, re-link

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                /* If a local var on the RHS see if we can fold it
                 & (i.e. propagate constant or copy) */

                if (tree->gtOper == GT_LCL_VAR)
                {
                    /* Unless a constExp or copyExp is available we won't be doing anything here */
                    if ((constExp|copyExp) == 0)
                        continue;

                    if (!(tree->gtFlags & GTF_VAR_DEF))
                    {
                        /* First try to propagate the copy */

                        if (copyExp)
                            optPropagateCopy(copyExp,  tree);

                        /* Try to propagate the constant */
#if !   TGT_RISC
                        if  (constExp && optPropagateConst(constExp, tree))
                            updateStmt = true;
#else
                        /* For RISC we only propagate constants in conditionals */

                        if  (stmt->gtStmt.gtStmtExpr->gtOper == GT_JTRUE)
                        {
                            assert(block->bbJumpKind == BBJ_COND);
                            if  (constExp && optPropagateConst(constExp, tree))
                                updateStmt = true;
                        }
#endif
                    }
                }
                else
                {
                    if (tree->OperKind() & GTK_ASGOP)
                    {
                        /* Is the target of the assignment a local variable */

                        if  (tree->gtOp.gtOp1->gtOper == GT_LCL_VAR)
                        {
                            unsigned        lclNum;
                            LclVarDsc   *   varDsc;

                            /* Assignment to a local variable */

                            assert(tree->gtOp.gtOp1->gtOper == GT_LCL_VAR);
                            lclNum = tree->gtOp.gtOp1->gtLclVar.gtLclNum;

                            assert(lclNum < lvaCount);
                            varDsc = lvaTable + lclNum;

                            /* All dependent expressions are killed here */

                            constExp &= ~varDsc->lvConstAsgDep;
                            copyExp  &= ~varDsc->lvCopyAsgDep;

                            /* If this is a copy / constant assignment - make it available */

                            if  (tree->gtConstAsgNum)
                                constExp |= genCSEnum2bit(tree->gtConstAsgNum);

                            if  (tree->gtCopyAsgNum)
                                copyExp  |= genCSEnum2bit(tree->gtCopyAsgNum);
                        }
                    }

                    /* Try to fold the node further - Fold the subtrees */

                    if (tree->OperKind() & GTK_SMPOP)
                    {
                        GenTreePtr  op1 = tree->gtOp.gtOp1;
                        GenTreePtr  op2 = tree->gtOp.gtOp2;
                        GenTreePtr  foldTree;

                        if (op1 && (op1->OperKind() & GTK_SMPOP))
                        {
                            foldTree = gtFoldExpr(op1);

                            if ((foldTree->OperKind() & GTK_CONST) ||
                                (foldTree != op1)                  )
                            {
                                /* We have folded the subtree */

                                tree->gtOp.gtOp1 = foldTree;
                                updateStmt = true;
                            }
                        }

                        if (op2 && (op2->OperKind() & GTK_SMPOP))
                        {
                            foldTree = gtFoldExpr(op2);

                            if ((foldTree->OperKind() & GTK_CONST) ||
                                (foldTree != op2)                  )
                            {
                                /* We have folded the subtree */

                                tree->gtOp.gtOp2 = foldTree;
                                updateStmt = true;
                            }
                        }
                    }
                }
            }

            /* We have processed all nodes except the top node */

            tree = gtFoldExpr(stmt->gtStmt.gtStmtExpr);

            if (tree->OperKind() & GTK_CONST)
            {
                /* The entire statement is a constant - most likely a call
                 * Remove the statement from bbTreelist */

                fgRemoveStmt(block, stmt);

                /* since the statement is gone no re-morphing, etc. necessary */
                continue;
            }
            else if (tree != stmt->gtStmt.gtStmtExpr)
            {
                /* We have folded the subtree */

                stmt->gtStmt.gtStmtExpr = tree;
                updateStmt = true;
            }

            /* Was this a conditional statement */

            if  (stmt->gtStmt.gtStmtExpr->gtOper == GT_JTRUE)
            {
                assert(block->bbJumpKind == BBJ_COND);

                /* Did we fold the conditional */

                assert(stmt->gtStmt.gtStmtExpr->gtOp.gtOp1);
                GenTreePtr  cond = stmt->gtStmt.gtStmtExpr->gtOp.gtOp1;

                if (cond->OperKind() & GTK_CONST)
                {
                    /* Yupee - we folded the conditional!
                     * Remove the conditional statement */

                    assert(cond->gtOper == GT_CNS_INT);
                    assert((block->bbNext->bbRefs > 0) && (block->bbJumpDest->bbRefs > 0));

                    /* this must be the last statement in the block */
                    assert(stmt->gtNext == 0);

                    /* remove the statement from bbTreelist - No need to update
                     * the reference counts since there are no lcl vars */
                    fgRemoveStmt(block, stmt);

                    /* since the statement is gone no re-morphing, etc. necessary */
                    updateStmt = false;

                    /* record the fact that the flow graph has changed */
                    optConditionFolded = true;

                    /* modify the flow graph */

                    if (cond->gtIntCon.gtIconVal != 0)
                    {
                        /* JTRUE 1 - transform the basic block into a BBJ_ALWAYS */
                        block->bbJumpKind = BBJ_ALWAYS;
                        block->bbNext->bbRefs--;

                        /* Remove 'block' from the predecessor list of 'block->bbNext' */
                        fgRemovePred(block->bbNext, block);
                    }
                    else
                    {
                        /* JTRUE 0 - transform the basic block into a BBJ_NONE */
                        block->bbJumpKind = BBJ_NONE;
                        block->bbJumpDest->bbRefs--;

                        /* Remove 'block' from the predecessor list of 'block->bbJumpDest' */
                        fgRemovePred(block->bbJumpDest, block);
                    }

#ifdef DEBUG
                    if  (verbose)
                    {
                        printf("Conditional folded at block #%02u\n", block->bbNum);
                        printf("Block #%02u becomes a %s", block->bbNum,
                                                           cond->gtIntCon.gtIconVal ? "BBJ_ALWAYS" : "BBJ_NONE");
                        if  (cond->gtIntCon.gtIconVal)
                            printf(" to block #%02u", block->bbJumpDest->bbNum);
                        printf("\n\n");
                    }
#endif
                    /* if the block was a loop condition we may have to modify
                     * the loop table */

                    for (unsigned loopNum = 0; loopNum < optLoopCount; loopNum++)
                    {
                        /* Some loops may have been already removed by
                         * loop unrolling or conditional folding */

                        if (optLoopTable[loopNum].lpFlags & LPFLG_REMOVED)
                            continue;

                        /* We are only interested in the loop bottom */

                        if  (optLoopTable[loopNum].lpEnd == block)
                        {
                            if  (cond->gtIntCon.gtIconVal == 0)
                            {
                                /* This was a bogus loop (condition always false)
                                 * Remove the loop from the table */

                                optLoopTable[loopNum].lpFlags |= LPFLG_REMOVED;
#ifdef DEBUG
                                if  (verbose)
                                {
                                    printf("Removing loop #%02u (from #%02u to #%02u)\n\n",
                                                                 loopNum,
                                                                 optLoopTable[loopNum].lpHead->bbNext->bbNum,
                                                                 optLoopTable[loopNum].lpEnd         ->bbNum);
                                }
#endif
                            }
                        }
                    }
                }
            }

            if  (updateStmt)
            {
#ifdef  DEBUG
                if  (verbose)
                {
                    printf("Statement before morphing:\n");
                    gtDispTree(stmt);
                    printf("\n");
                }
#endif
                /* Have to re-morph the statement to get the constants right */

                stmt->gtStmt.gtStmtExpr = fgMorphTree(stmt->gtStmt.gtStmtExpr);

                /* Have to re-do the evaluation order since for example
                 * some later code does not expect constants as op1 */

                gtSetStmtInfo(stmt);

                /* Have to re-link the nodes for this statement */

                fgSetStmtSeq(stmt);

#ifdef  DEBUG
                if  (verbose)
                {
                    printf("Statement after morphing:\n");
                    gtDispTree(stmt);
                    printf("\n");
                }
#endif
            }
        }
    }

    /* Constant or copy propagation or statement removal have
     * changed the reference counts - Resort the variable table */

    if (optConstPropagated || optCopyPropagated || fgStmtRemoved)
    {
#ifdef  DEBUG
        if  (verbose)
            printf("Re-sorting the variable table:\n");
#endif

        lvaSortByRefCount();
    }
}


/*****************************************************************************
 *
 *  Take a morphed array index expression (i.e. an GT_IND node) and break it
 *  apart into its components. Returns 0 if the expression looks weird.
 */

GenTreePtr          Compiler::gtCrackIndexExpr(GenTreePtr   tree,
                                               GenTreePtr * indxPtr,
                                               long       * indvPtr,
                                               long       * basvPtr,
                                               bool       * mvarPtr,
                                               long       * offsPtr,
                                               unsigned   * multPtr)
{
    GenTreePtr      ind;
    GenTreePtr      op1;
    GenTreePtr      op2;
    unsigned        ofs;

    assert(tree->gtOper == GT_IND);

    /* Skip over the "ind" node to the operand */

    ind = tree->gtOp.gtOp1;

    /* Skip past the "+ offs" node, if present */

    ofs = 0;

    if  (ind->gtOper             == GT_ADD     &&
         ind->gtOp.gtOp2->gtOper == GT_CNS_INT)
    {
        ofs = ind->gtOp.gtOp2->gtIntCon.gtIconVal;
        ind = ind->gtOp.gtOp1;
    }

    /* We should have "array_base + [ size * ] index" */

    if  (ind->gtOper != GT_ADD)
        return 0;

    op1 = ind->gtOp.gtOp1;
    op2 = ind->gtOp.gtOp2;

    /* The index value may be scaled, of course */

    *multPtr = 1;

    if  (op2->gtOper == GT_LSH)
    {
        long        shf;

        if  (op2->gtOp.gtOp2->gtOper != GT_CNS_INT)
            return  0;

        shf = op2->gtOp.gtOp2->gtIntCon.gtIconVal;

        if  (shf < 1 || shf > 3)
            return  0;

        *multPtr <<= shf;

        op2 = op2->gtOp.gtOp1;
    }

    /* There might be a nop node on top of the index value */

    if  (op2->gtOper == GT_NOP)
        op2 = op2->gtOp.gtOp1;

    /* Report the index expression to the caller */

    *indxPtr = op2;

    /* Figure out the index offset */

    *offsPtr = 0;
    unsigned elemOffs = (tree->gtFlags & GTF_IND_OBJARRAY) ? OBJARR_ELEM1_OFFS:ARR_ELEM1_OFFS;

    if  (ofs)
        *offsPtr = (ofs - elemOffs) / *multPtr;

    /* Is the index a simple local ? */

    if  (op2->gtOper != GT_LCL_VAR)
    {
        /* Allow "local + icon" */

        if  (op2->gtOper == GT_ADD && op2->gtOp.gtOp1->gtOper == GT_LCL_VAR
                                   && op2->gtOp.gtOp2->gtOper == GT_CNS_INT)
        {
            *offsPtr += op2->gtOp.gtOp2->gtIntCon.gtIconVal;

            op2 = op2->gtOp.gtOp1;
        }
    }

    /* If the address/index values are local vars, report them */

    if  (op1->gtOper == GT_LCL_VAR)
    {
        if  (op2->gtOper == GT_LCL_VAR)
        {
            *indvPtr = op2->gtLclVar.gtLclNum;
            *basvPtr = op1->gtLclVar.gtLclNum;
            *mvarPtr = false;

            return  op1;
        }

        if  (op2->gtOper == GT_CNS_INT)
        {
            *indvPtr = -1;
            *basvPtr = op1->gtLclVar.gtLclNum;
            *mvarPtr = false;

            return  op1;
        }
    }

    *basvPtr =
    *indvPtr = -1;
    *mvarPtr = true;

    return  op1;
}

/*****************************************************************************
 *
 *  See if the given tree can be computed in the given precision (which must
 *  be smaller than the type of the tree for this to make sense). If 'doit'
 *  is false, we merely check to see whether narrowing is possible; if we
 *  get called with 'doit' being true, we actually perform the narrowing,
 *  and the caller better be 100% sure this will succeed as once we start
 *  rewriting the tree there is no turning back.
 */

bool                Compiler::optNarrowTree(GenTreePtr     tree,
                                            var_types      srct,
                                            var_types      dstt,
                                            bool           doit)
{
    genTreeOps      oper;
    unsigned        kind;

    assert(tree);
    assert(tree->gtType == srct);

    /* Assume we're only handling integer types */

    assert(varTypeIsIntegral(srct));
    assert(varTypeIsIntegral(dstt));

    /* Figure out what kind of a node we have */

    oper = tree->OperGet();
    kind = tree->OperKind();

    if  (kind & GTK_ASGOP)
    {
        assert(doit == false);
        return  false;
    }

    if  (kind & GTK_LEAF)
    {
        switch (oper)
        {
        case GT_CNS_LNG:

            if  (srct != TYP_LONG)
                return  false;

            if  (dstt == TYP_INT)
            {
                if  (doit)
                {
                    long        ival = (int)tree->gtLngCon.gtLconVal;

                    tree->gtOper             = GT_CNS_INT;
                    tree->gtIntCon.gtIconVal = ival;
                }

                return  true;
            }

            return  false;

        case GT_FIELD:
        case GT_LCL_VAR:

            /* Simply bash the type of the tree */

            if  (doit)
            {
                tree->gtType = dstt;

                /* Make sure we don't mess up the variable type */

                if  (oper == GT_LCL_VAR)
                    tree->gtFlags |= GTF_VAR_NARROWED;
            }

            return  true;
        }

        assert(doit == false);
        return  false;

    }

    if (kind & (GTK_BINOP|GTK_UNOP))
    {
        GenTreePtr      op1 = tree->gtOp.gtOp1;
        GenTreePtr      op2 = tree->gtOp.gtOp2;

        switch(tree->gtOper)
        {
        case GT_ADD:
        case GT_SUB:
        case GT_MUL:

            if (tree->gtOverflow())
            {
                assert(doit == false);
                return false;
            }
            break;

        case GT_IND:

            /* Simply bash the type of the tree */

            if  (doit)
                tree->gtType = dstt;

            return  true;

        case GT_CAST:
            {
                var_types       oprt;
                var_types       cast;

                /* The cast's 'op2' yields the 'real' type */

                assert(op2 && op2->gtOper == GT_CNS_INT);

                oprt = (var_types)op1->gtType;
                cast = (var_types)op2->gtIntCon.gtIconVal;

                /* The following may not work in the future but it's OK now */

                assert(cast == srct);

                /* Is this a cast from the type we're narrowing to or a smaller one? */

                if  (oprt <= dstt)
                {
                    /* Easy case: cast from our destination type */

                    if  (oprt == dstt)
                    {
                        /* Simply toss the cast */

                        if  (doit)
                            tree->CopyFrom(tree->gtOp.gtOp1);
                    }
                    else
                    {
                        /* The cast must be from a smaller type, then */

                        assert(oprt < srct);

                        /* Bash the target type of the cast */

                        if  (doit)
                        {
                             op2->gtIntCon.gtIconVal =
                             op2->gtType             =
                            tree->gtType             = dstt;
                        }
                    }

                    return  true;
                }
            }

            return  false;

        default:
            // CONSIDER: Handle more cases
            assert(doit == false);
            return  false;
        }

        assert(tree->gtType == op1->gtType);
        assert(tree->gtType == op2->gtType);

        if  (!optNarrowTree(op1, srct, dstt, doit) ||
             !optNarrowTree(op2, srct, dstt, doit))
        {
            assert(doit == false);
            return  false;
        }

        /* Simply bash the type of the tree */

        if  (doit)
            tree->gtType = dstt;

        return  true;
    }

    return  false;
}

/*****************************************************************************/
#if 0 // the following optimization disabled for now
/*****************************************************************************
 *
 *  Callback (for fgWalkTree) used by the loop-based range check optimization
 *  code.
 */

struct loopRngOptDsc
{
    Compiler    *       lpoComp;

    unsigned short      lpoCandidateCnt;    // count of variable candidates

    unsigned short      lpoIndexVar;        // phase2: index variable
      signed short      lpoAaddrVar;        // phase2: array address or -1
    unsigned short      lpoIndexHigh;       // phase2: highest index offs
    unsigned            lpoIndexOff;        // phase2: current offset
    GenTreePtr          lpoStmt;            // phase2: containing statement

    unsigned char       lpoElemType;        // phase2: element type

    unsigned char       lpoCheckRmvd:1;     // phase2: any range checks removed?
    unsigned char       lpoDomExit  :1;     // current BB dominates loop exit?
    unsigned char       lpoPhase2   :1;     // the second phase in progress

#ifndef NDEBUG
    void    *           lpoSelf;
    unsigned            lpoVarCount;        // total number of locals
#endif
    Compiler::LclVarDsc*lpoVarTable;        // variable descriptor table

    unsigned char       lpoHadSideEffect:1; // we've found a side effect
};

int                 Compiler::optFindRangeOpsCB(GenTreePtr tree, void *p)
{
    LclVarDsc   *   varDsc;

    GenTreePtr      op1;
    GenTreePtr      op2;

    loopRngOptDsc * dsc = (loopRngOptDsc*)p; assert(dsc && dsc->lpoSelf == dsc);

    /* Do we have an assignment node? */

    if  (tree->OperKind() & GTK_ASGOP)
    {
        unsigned        lclNum;

        op1 = tree->gtOp.gtOp1;
        op2 = tree->gtOp.gtOp2;

        /* What is the target of the assignment? */

        if  (op1->gtOper != GT_LCL_VAR)
        {
            /* Indirect/global assignment - bad news! */

            dsc->lpoHadSideEffect = true;
            return -1;
        }

        /* Get hold of the variable descriptor */

        lclNum = op1->gtLclVar.gtLclNum;
        assert(lclNum < dsc->lpoVarCount);
        varDsc = dsc->lpoVarTable + lclNum;

        /* After a side effect is found, all is hopeless */

        if  (dsc->lpoHadSideEffect)
        {
            varDsc->lvLoopAsg = true;
            return  0;
        }

        /* Is this "i += icon" ? */

        if  (tree->gtOper             == GT_ASG_ADD &&
             tree->gtOp.gtOp2->gtOper == GT_CNS_INT)
        {
            if  (dsc->lpoDomExit)
            {
                /* Are we in phase2 ? */

                if  (dsc->lpoPhase2)
                {
                    /* Is this the variable we're interested in? */

                    if  (dsc->lpoIndexVar != lclNum)
                        return  0;

                    /* Update the current offset of the index */

                    dsc->lpoIndexOff += tree->gtOp.gtOp2->gtIntCon.gtIconVal;

                    return  0;
                }

//              printf("Found increment of variable %u at %08X\n", lclNum, tree);
            }

            if  (varDsc->lvLoopInc == false)
            {
                varDsc->lvLoopInc = true;

                if  (varDsc->lvIndex)
                    dsc->lpoCandidateCnt++;
            }
        }
        else
        {
            varDsc->lvLoopAsg = true;
        }

        return 0;
    }

    /* After a side effect is found, all is hopeless */

    if  (dsc->lpoHadSideEffect)
        return  0;

    /* Look for array index expressions */

    if  (tree->gtOper == GT_IND && (tree->gtFlags & GTF_IND_RNGCHK))
    {
        GenTreePtr      base;
        long            basv;
        GenTreePtr      indx;
        long            indv;
        long            offs;
        unsigned        mult;

        /* Does the current block dominate the loop exit? */

        if  (!dsc->lpoDomExit)
            return 0;

        /* Break apart the index expression */

        base = dsc->lpoComp->gtCrackIndexExpr(tree, &indx, &indv, &basv, &offs, &mult);
        if  (!base)
            return 0;

        /* The index value must be a simple local, possibly with "+ positive offset" */

        if  (indv == -1)
            return 0;
        if  (offs < 0)
            return 0;

        /* For now the array address must be a simple local */

        if  (basv == -1)
            return  0;

        /* Get hold of the index variable's descriptor */

        assert((unsigned)indv < dsc->lpoVarCount);
        varDsc = dsc->lpoVarTable + indv;

        /* Are we in phase2 ? */

        if  (dsc->lpoPhase2)
        {
            LclVarDsc   *   arrDsc;

            /* Is this the index variable we're interested in? */

            if  (dsc->lpoIndexVar != indv)
            {
                dsc->lpoHadSideEffect = true;
                return  0;
            }

            /* Is the array base reassigned within the loop? */

            assert((unsigned)basv < dsc->lpoVarCount);
            arrDsc = dsc->lpoVarTable + basv;

            if  (arrDsc->lvLoopAsg)
            {
                dsc->lpoHadSideEffect = true;
                return  0;
            }

            /* Is this the array we're looking for? */

            if  (dsc->lpoAaddrVar != basv)
            {
                /* Do we know which array we're looking for? */

                if  (dsc->lpoAaddrVar != -1)
                    return  0;

                dsc->lpoAaddrVar = (SHORT)basv;
            }

            /* Calculate the actual index offset */

            offs += dsc->lpoIndexOff; assert(offs >= 0);

            /* Is this statement guaranteed to be executed? */

            if  (varDsc->lvIndexDom)
            {
                /* Is this higher than the highest known offset? */

                if  (dsc->lpoIndexHigh < offs)
                     dsc->lpoIndexHigh = (unsigned short)offs;
            }
            else
            {
                /* The offset may not exceed the max. found thus far */

                if  (dsc->lpoIndexHigh < offs)
                    return  0;
            }

                /* we are going to just bail on structs for now */
            if (tree->gtType == TYP_STRUCT)
                return(0);

            dsc->lpoCheckRmvd = true;
            dsc->lpoElemType  = tree->gtType;

//          printf("Remove index (at offset %u):\n", off); dsc->lpoComp->gtDispTree(tree); printf("\n\n");

            dsc->lpoComp->optRemoveRangeCheck(tree, dsc->lpoStmt);

            return  0;
        }

        /* Mark the index variable as being used as an array index */

        if  (varDsc->lvLoopInc || offs)
        {
            if  (varDsc->lvIndexOff == false)
            {
                 varDsc->lvIndexOff = true;
                 dsc->lpoCandidateCnt++;
            }
        }
        else
        {
            if  (varDsc->lvIndex    == false)
            {
                 varDsc->lvIndex    = true;
                 dsc->lpoCandidateCnt++;
            }
        }

        varDsc->lvIndexDom = true;

        return 0;
    }

    if  (dsc->lpoComp->gtHasSideEffects(tree))
    {
        dsc->lpoHadSideEffect = true;
        return -1;
    }

    return  0;
}

/*****************************************************************************
 *
 *  Look for opportunities to remove range checks based on natural loop and
 *  constant propagation info.
 */

void                Compiler::optRemoveRangeChecks()
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;

    unsigned        lnum;
    LoopDsc     *   ldsc;

    // UNDONE: The following needs to be done to enable this logic:
    //
    //          Fix the dominator business
    //          Detect inner loops
    //          Set a flag during morph that says whether it's worth
    //              our while to look for these things, since this
    //              optimization is very expensive (several tree
    //              walks).

    /*
        Look for loops that contain array index expressions of the form

            a[i] and a[i+1] or a[i-1]

        Note that the equivalent thing we look for is as follows:

            a[i++] and a[i++] and ...

        In both cases, if there are no calls or assignments to global
        data, and we can prove that the index value is not negative,
        we can replace both/all the range checks with one (for the
        highest index value).

        In all the cases, we first look for array index expressions
        of the appropriate form that will execute every time around
        the loop - if we can find a non-negative initializer for the
        index variable, we can thus prove that the index values will
        never be negative.
     */

    for (lnum = 0, ldsc = optLoopTable;
         lnum < optLoopCount;
         lnum++  , ldsc++)
    {
        BasicBlock *    block;
        BasicBlock *    head;
        BasicBlock *    lbeg;
        BasicBlock *    tail;

        loopRngOptDsc   desc;

        /* Get hold of the beg and end blocks of the loop */

        head = ldsc->lpHead;

        /* Get hold of the top and bottom of the loop */

        tail = ldsc->lpEnd;
        lbeg = head->bbNext;

//      printf("Consider loop %u .. %u for range checks\n", lbeg->bbNum, tail->bbNum);

#if 0

        /* If no constant values are known on entry, bail */

        if  (head->bbConstAsgOut == 0)
            continue;

        /* Mark which variables have potential for optimization */

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            varDsc->lvRngOptDone = true;

            assert(varDsc->lvLoopInc    == false);
            assert(varDsc->lvLoopAsg    == false);
            assert(varDsc->lvIndex      == false);
            assert(varDsc->lvIndexOff   == false);
        }

        EXPSET_TP       cnst = head->bbConstAsgOut;

        for (unsigned i=0; i < optConstAsgCount; i++)
        {
            if  (genCSEnum2bit(i+1) & cnst)
            {
                if  (optConstAsgTab[i].constIval >= 0)
                {
                    /* This variable sure looks promising */

                    lclNum = optConstAsgTab[i].constLclNum;
                    assert(lclNum < lvaCount);

                    lvaTable[lclNum].lvRngOptDone = false;
                }
            }
        }

#else

        // UNDONE: Need to walk backwards and look for a constant
        // UNDONE: initializer for index variables as we don't
        // UNDONE: have the constant propagation info available
        // UNDONE: at this stage of the compilation process.


        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            // HACK: Pretend all variables have constant positive initializers

            varDsc->lvRngOptDone = false;

            assert(varDsc->lvLoopInc    == false);
            assert(varDsc->lvLoopAsg    == false);
            assert(varDsc->lvIndex      == false);
            assert(varDsc->lvIndexOff   == false);
        }

#endif

        /* Initialize the struct that holds the state of the optimization */

        desc.lpoComp          = this;
        desc.lpoCandidateCnt  = 0;
        desc.lpoPhase2        = false;
        desc.lpoHadSideEffect = false;
#ifndef NDEBUG
        desc.lpoSelf          = &desc;
        desc.lpoVarCount      = lvaCount;
#endif
        desc.lpoVarTable      = lvaTable;
        desc.lpoDomExit       = true;

        /* Walk the trees of the loop, looking for indices and increments */

        block = head;
        do
        {
            GenTree *       stmt;

            block = block->bbNext;
            stmt  = block->bbTreeList;

            /* Make sure the loop is not in a try block */

            if  (block->bbFlags & BBF_HAS_HANDLER)
                goto NEXT_LOOP;

            /* Does the current block dominate the loop exit? */

#if 0

            // The following doesn't work - due to loop guard duplication, maybe?

            desc.lpoDomExit = (B1DOMSB2(block, tail) != 0);

#else

            // UNDONE: Handle nested loops! The following is just a hack!

            if  (block != lbeg)
            {
                flowList   *    flow;
                unsigned        pcnt;

                for (flow = block->bbPreds, pcnt = 0;
                     flow;
                     flow = flow->flNext  , pcnt++)
                {
                    if  (flow->flBlock         != tail &&
                         flow->flBlock->bbNext != block)
                    {
                        /* Looks like a nested loop or something */

                        desc.lpoDomExit = false;
                        break;
                    }
                }
            }

#endif

            /* Walk all the statements in this basic block */

            while (stmt)
            {
                assert(stmt && stmt->gtOper == GT_STMT);

                fgWalkTree(stmt->gtStmt.gtStmtExpr, optFindRangeOpsCB, &desc);

                stmt = stmt->gtNext;
            }
        }
        while (block != tail);

        /* Did we find any candidates? */

        if  (desc.lpoCandidateCnt)
        {
            /* Visit each variable marked as a candidate */

            for (lclNum = 0, varDsc = lvaTable;
                 lclNum < lvaCount;
                 lclNum++  , varDsc++)
            {
                if  (varDsc->lvRngOptDone != false)
                    continue;
                if  (varDsc->lvLoopInc    == false)
                    continue;
                if  (varDsc->lvLoopAsg    != false)
                    continue;
                if  (varDsc->lvIndex      == false)
                    continue;
                if  (varDsc->lvIndexOff   == false)
                    continue;
                if  (varDsc->lvIndexDom   == false)
                    continue;

//              printf("Candidate variable %u\n", lclNum);

                /*
                    Find the highest offset that is added to the variable
                    to index into a given array. This index expression has
                    to dominate the exit of the loop, since otherwise it
                    might be skipped. Also, it must not be preceded by any
                    side effects. The array must not be modified within
                    the loop.
                 */

                desc.lpoPhase2        = true;
                desc.lpoHadSideEffect = false;
                desc.lpoDomExit       = true;
                desc.lpoIndexVar      = lclNum;
                desc.lpoAaddrVar      = -1;
                desc.lpoIndexOff      = 0;
                desc.lpoIndexHigh     = 0;
                desc.lpoCheckRmvd     = false;

                // UNDONE: If the index variable is incremented several
                // UNDONE: times in the loop, its only use is to index
                // UNDONE: into arrays, and all these index operations
                // UNDONE: have their range checks removed, remove the
                // UNDONE: increments, substitute a simple "i += icon"
                // UNDONE: and change the index to be "i + 1", etc.

                /* Walk the trees of the loop, looking for indices and increments */

                block = head;
                do
                {
                    GenTree *       stmt;

                    block = block->bbNext;
                    stmt  = block->bbTreeList;

                    assert(!(block->bbFlags & BBF_HAS_HANDLER));

                    // UNDONE: Same issue as the corresponding code above

                    if  (block != lbeg)
                    {
                        flowList   *    flow;
                        unsigned        pcnt;

                        for (flow = block->bbPreds, pcnt = 0;
                             flow;
                             flow = flow->flNext  , pcnt++)
                        {
                            if  (flow->flBlock         != tail &&
                                 flow->flBlock->bbNext != block)
                            {
                                /* Looks like a nested loop or something */

                                desc.lpoDomExit = false;
                                break;
                            }
                        }
                    }

                    /* Walk all the statements in this basic block */

                    while (stmt)
                    {
                        desc.lpoStmt = stmt;

                        assert(stmt && stmt->gtOper == GT_STMT);

                        fgWalkTree(stmt->gtStmt.gtStmtExpr, optFindRangeOpsCB, &desc);

                        stmt = stmt->gtNext;
                    }
                }
                while (block != tail);

                /* Did we remove any range checks? */

                if  (desc.lpoCheckRmvd)
                {
                    GenTreePtr  chks;
                    GenTreePtr  loop;
                    GenTreePtr  ends;
                    GenTreePtr  temp;

                    assert(desc.lpoIndexHigh);      // ISSUE: Could this actually happen?

                    /* The following needed for gtNewRngChkNode() */

                    compCurBB      = lbeg;
                    fgPtrArgCntCur = 0;

                    /* Create the combined range check */

                    chks = gtNewLclvNode(desc.lpoIndexVar , TYP_INT);

                    temp = gtNewIconNode(desc.lpoIndexHigh, TYP_INT);

                    chks = gtNewOperNode(GT_ADD, TYP_INT, chks, temp);

                    temp = gtNewLclvNode(desc.lpoAaddrVar, TYP_REF);

                    assert(desc.lpoElemType != TYP_STRUCT);     // We don't handle structs for now
                    chks = gtNewRngChkNode(NULL,
                                           temp,
                                           chks,
                                           (var_types)desc.lpoElemType, genTypeSize(desc.lpoElemType));

#if CSE
                    chks->gtFlags |= GTF_DONT_CSE;
#endif
                    chks = gtNewStmt(chks);
                    chks->gtFlags |= GTF_STMT_CMPADD;

//                  printf("Insert combined range check [0 .. %u] for %u[%u]:\n", desc.lpoIndexHigh, desc.lpoAaddrVar, lclNum);
//                  gtDispTree(chks);

                    /* Insert the range check at the loop head */

                    loop = lbeg->bbTreeList; assert(loop);
                    ends = loop->gtPrev;

                    lbeg->bbTreeList = chks;

                    chks->gtNext = loop;
                    chks->gtPrev = ends;

                    loop->gtPrev = chks;
                }
            }
        }

    NEXT_LOOP:

        /* Clear all the flags for the next round */

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            varDsc->lvRngOptDone =
            varDsc->lvLoopInc    =
            varDsc->lvLoopAsg    =
            varDsc->lvIndex      =
            varDsc->lvIndexOff   = false;
        }
    }
}

/*****************************************************************************/
#else
/*****************************************************************************/
void                Compiler::optRemoveRangeChecks(){}
/*****************************************************************************/
#endif
/*****************************************************************************
 *
 *  The following logic figures out whether the given variable is assigned
 *  somewhere in a list of basic blocks (or in an entire loop).
 */

struct  isVarAssgDsc
{
    GenTreePtr          ivaSkip;
#ifndef NDEBUG
    void    *           ivaSelf;
#endif
    unsigned            ivaVar;
    VARSET_TP           ivaMaskVal;
    BYTE                ivaMaskInd;
    BYTE                ivaMaskBad;
    BYTE                ivaMaskCall;
};

int                 Compiler::optIsVarAssgCB(GenTreePtr tree, void *p)
{
    if  (tree->OperKind() & GTK_ASGOP)
    {
        GenTreePtr      dest = tree->gtOp.gtOp1;

        if  (dest->gtOper == GT_LCL_VAR)
        {
            unsigned        tvar = dest->gtLclVar.gtLclNum;
            isVarAssgDsc *  desc = (isVarAssgDsc*)p;

            ASSert(desc && desc->ivaSelf == desc);

            if  (tvar < VARSET_SZ)
                desc->ivaMaskVal |= genVarIndexToBit(tvar);
            else
                desc->ivaMaskBad  = true;

            if  (tvar == desc->ivaVar)
            {
                if  (tree != desc->ivaSkip)
                    return  -1;
            }
        }
        else
        {
            isVarAssgDsc *  desc = (isVarAssgDsc*)p;

            ASSert(desc && desc->ivaSelf == desc);

            /* Set the proper indirection bits */

            desc->ivaMaskInd |= (varTypeIsGC(tree->TypeGet()) ? VR_IND_PTR
                                                              : VR_IND_SCL);
        }
    }
    else if (tree->gtOper == GT_CALL)
    {
        isVarAssgDsc *  desc = (isVarAssgDsc*)p;

        ASSert(desc && desc->ivaSelf == desc);

        desc->ivaMaskCall = optCallInterf(tree);
    }

    return  0;
}

bool                Compiler::optIsVarAssigned(BasicBlock *   beg,
                                               BasicBlock *   end,
                                               GenTreePtr     skip,
                                               long           var)
{
    bool            result;
    isVarAssgDsc    desc;

    desc.ivaSkip     = skip;
#ifndef NDEBUG
    desc.ivaSelf     = &desc;
#endif
    desc.ivaVar      = var;
    desc.ivaMaskCall = CALLINT_NONE;

    fgWalkTreeReEnter();

    for (;;)
    {
        GenTreePtr      stmt;

        assert(beg);

        for (stmt = beg->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            if  (fgWalkTree(stmt->gtStmt.gtStmtExpr, optIsVarAssgCB, &desc))
            {
                result = true;
                goto DONE;
            }
        }

        if  (beg == end)
            break;

        beg = beg->bbNext;
    }

    result = false;

DONE:

    fgWalkTreeRestore();

    return  result;
}

int                 Compiler::optIsSetAssgLoop(unsigned     lnum,
                                               VARSET_TP    vars,
                                               unsigned     inds)
{
    LoopDsc *       loop;

    /* Get hold of the loop descriptor */

    assert(lnum < optLoopCount);
    loop = optLoopTable + lnum;

    /* Do we already know what variables are assigned within this loop? */

    if  (!(loop->lpFlags & LPFLG_ASGVARS_YES))
    {
        isVarAssgDsc    desc;

        BasicBlock  *   beg;
        BasicBlock  *   end;

        /* Prepare the descriptor used by the tree walker call-back */

        desc.ivaVar     = -1;
        desc.ivaSkip    = NULL;
#ifndef NDEBUG
        desc.ivaSelf    = &desc;
#endif
        desc.ivaMaskVal = 0;
        desc.ivaMaskInd = 0;
        desc.ivaMaskBad = false;

        /* Now we will know what variables are assigned in the loop */

        loop->lpFlags |= LPFLG_ASGVARS_YES;

        /* Now walk all the statements of the loop */

        fgWalkTreeReEnter();

        beg = loop->lpHead->bbNext;
        end = loop->lpEnd;

        for (;;)
        {
            GenTreePtr      stmt;

            assert(beg);

            for (stmt = beg->bbTreeList; stmt; stmt = stmt->gtNext)
            {
                assert(stmt->gtOper == GT_STMT);

                fgWalkTree(stmt->gtStmt.gtStmtExpr, optIsVarAssgCB, &desc);

                if  (desc.ivaMaskBad)
                {
                    loop->lpFlags |= LPFLG_ASGVARS_BAD;
                    return  -1;
                }
            }

            if  (beg == end)
                break;

            beg = beg->bbNext;
        }

        fgWalkTreeRestore();

        loop->lpAsgVars = desc.ivaMaskVal;
        loop->lpAsgInds = desc.ivaMaskInd;
        loop->lpAsgCall = desc.ivaMaskCall;
    }

    /* If we know we can't compute the mask, bail */

    if  (loop->lpFlags & LPFLG_ASGVARS_BAD)
        return  -1;

    /* Now we can finally test the caller's mask against the loop's */

    if  ((loop->lpAsgVars & vars) ||
         (loop->lpAsgInds & inds))
    {
        return  1;
    }

    switch (loop->lpAsgCall)
    {
    case CALLINT_ALL:

        /* All exprs are killed */

        return  1;

    case CALLINT_INDIRS:

        /* Object array elem assignment kills all pointer indirections */

        if  (inds & VR_IND_PTR)
            return  1;

        break;

    case CALLINT_NONE:

        /* Other helpers kill nothing */

        break;
    }

    return  0;
}

/*****************************************************************************
 *
 *  Callback (for fgWalkTree) used by the loop code hoisting logic.
 */

struct  codeHoistDsc
{
    Compiler    *       chComp;
#ifndef NDEBUG
    void        *       chSelf;
#endif

    GenTreePtr          chHoistExpr;    // the hoisting candidate
    unsigned short      chLoopNum;      // number of the loop we're working on
    bool                chSideEffect;   // have we encountered side effects?
};

int                 Compiler::optHoistLoopCodeCB(GenTreePtr tree,
                                                 void *     p,
                                                 bool       prefix)
{
    codeHoistDsc  * desc;
    GenTreePtr      oldx;
    GenTreePtr      depx;
    VARSET_TP       deps;
    unsigned        refs;

    /* Get hold of the descriptor */

    desc = (codeHoistDsc*)p; ASSert(desc && desc->chSelf == desc);

    /* After we find a side effect, we just give up */

    if  (desc->chSideEffect)
        return  -1;

    /* Is this an assignment? */

    if  (tree->OperKind() & GTK_ASGOP)
    {
        /* Is the target a simple local variable? */

        if  (tree->gtOp.gtOp1->gtOper != GT_LCL_VAR)
        {
            desc->chSideEffect = true;
            return  -1;
        }

        /* Assignment to a local variable, ignore it */

        return  0;
    }

#if INLINING

    if  (tree->gtOper == GT_QMARK && tree->gtOp.gtOp1)
    {
        // UNDONE: Need to handle ?: correctly; for now just bail

        desc->chSideEffect = true;
        return  -1;
    }

#endif

#if CSELENGTH
    /* An array length value depends on the array address */

    if      (tree->gtOper == GT_ARR_RNGCHK)
    {
        depx = tree->gtArrLen.gtArrLenAdr;
    }
    else if (tree->gtOper == GT_ARR_LENGTH)
    {
        depx = tree->gtOp.gtOp1;
    }
    else
#endif
         if (tree->gtOper != GT_IND)
    {
        /* Not an indirection, is this a side effect? */

        if  (desc->chComp->gtHasSideEffects(tree))
        {
            desc->chSideEffect = true;
            return  -1;
        }

        return  0;
    }
    else
    {
        GenTreePtr      addr;

        depx = tree;

        /* Special case: instance variable reference */

        addr = tree->gtOp.gtOp1;

        if  (addr->gtOper == GT_ADD)
        {
            GenTreePtr      add1 = addr->gtOp.gtOp1;
            GenTreePtr      add2 = addr->gtOp.gtOp2;

            if  (add1->gtOper == GT_LCL_VAR &&
                 add2->gtOper == GT_CNS_INT)
            {
                /* Special case: "this" is almost always non-null */

                if  (add1->gtLclVar.gtLclNum == 0 && desc->chComp->optThisPtrModified)
                {
                    /* Do we already have a hoisting candidate? */

                    if  (desc->chHoistExpr)
                        return  0;
                }
            }
        }
    }

#if 0

    printf("Considering loop hoisting candidate [cur=%08X]:\n", tree);
    desc->chComp->gtDispTree(tree);
    printf("\n");

    if  (tree->gtOper == GT_ARR_RNGCHK)
    {
        desc->chComp->gtDispTree(depx);
        printf("\n");
    }

#endif

    /* Find out what variables the expression depends on */

    oldx = desc->chHoistExpr;
    deps = desc->chComp->lvaLclVarRefs(depx, &oldx, &refs);
    if  (deps == VARSET_NONE)
        return  0;

    if  (oldx)
    {
        /*
            We already have a candidate and the current expression
            doesn't contain it as a sub-operand, so we'll just
            ignore the new expression and stick with the old one.
         */

        return  0;
    }

    /* Make sure the expression is loop-invariant */

    if  (desc->chComp->optIsSetAssgLoop(desc->chLoopNum, deps, refs))
    {
        /* Can't hoist something that changes within the loop! */

        return  -1;
    }

    desc->chHoistExpr = tree;

    return  0;
}

/*****************************************************************************
 *
 *  Looks for a hoisting candidate starting at the given basic block. The idea
 *  is that we explore each path through the loop and make sure that on every
 *  trip we will encounter the same expression before any other side effects.
 *
 *  Returns -1 if a side effect is encountered, 0 if nothing interesting at
 *  all is found, and +1 if a hoist candidate is found (the candidate tree
 *  must either match "*hoistxPtr" if non-zero, or "*hoistxPtr" will be set
 *  to the hoist candidate).
 */

int                 Compiler::optFindHoistCandidate(unsigned    lnum,
                                                    unsigned    lbeg,
                                                    unsigned    lend,
                                                    BasicBlock *block,
                                                    GenTreePtr *hoistxPtr)
{
    GenTree *       stmt;
    codeHoistDsc    desc;

    int             res1;
    int             res2;

    /* Is this block outside of the loop? */

    if  (block->bbNum < lbeg)
        return  -1;
    if  (block->bbNum > lend)
        return  -1;

    /* For now, we don't try to hoist out of catch blocks */

    if  (block->bbCatchTyp)
        return  -1;

    /* Does this block have a handler? */

    if  (block->bbFlags & BBF_IS_TRY)
    {
        /* Is this the first block in the loop? */

        if  (optLoopTable[lnum].lpEntry != block)
        {
            /*
                Not the same try block as loop (or loop isn't in one),
                don't hoist out of it.
             */

            return  -1;
        }
    }

    /* Have we visited this block before? */

    if  (block->bbFlags & BBF_VISITED)
    {
        if  (block->bbFlags & BBF_MARKED)
            return  1;
        else
            return  0;
    }

    /* Remember that we've visited this block */

    block->bbFlags |= BBF_VISITED;

    /* Look for any loop hoisting candidates in the block */

    desc.chComp    = this;
#ifndef NDEBUG
    desc.chSelf    = &desc;
#endif
    desc.chLoopNum = lnum;

    for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
    {
        assert(stmt->gtOper == GT_STMT);

        desc.chHoistExpr  = 0;
        desc.chSideEffect = false;

//      printf("Walking     loop hoisting candidate:\n"); gtDispTree(stmt->gtStmt.gtStmtExpr); printf("\n");

        fgWalkTreeDepth(stmt->gtStmt.gtStmtExpr, optHoistLoopCodeCB, &desc);

        if  (desc.chHoistExpr)
        {
            /* Have we found a candidate in another block already? */

            if  (*hoistxPtr)
            {
                /* The two candidate expressions must be identical */

                if  (!GenTree::Compare(desc.chHoistExpr, *hoistxPtr))
                    return  -1;
            }
            else
                *hoistxPtr = desc.chHoistExpr;

            /* Remember that this block has a hoistable expression */

            block->bbFlags |= BBF_MARKED;

            return  +1;
        }
    }

    /* Nothing interesting found in this block, consider its successors */

    switch (block->bbJumpKind)
    {
    case BBJ_COND:
        res1 = optFindHoistCandidate(lnum,
                                     lbeg,
                                     lend,
                                     block->bbJumpDest,
                                     hoistxPtr);

        if  (res1 == -1)
            return  -1;

        block = block->bbNext;
        break;

    case BBJ_ALWAYS:
        block = block->bbJumpDest;
        res1 = 1;
        break;

    case BBJ_NONE:
        block = block->bbNext;
        res1  = 1;
        break;

    case BBJ_RET:
    case BBJ_CALL:
    case BBJ_THROW:
    case BBJ_RETURN:
        return  -1;

    case BBJ_SWITCH:
        // CONSIDER: Don't be lazy and add support for switches
        return  -1;
    }

    /* Here we have BBJ_NONE/BBJ_COND/BBJ_ALWAYS */

    res2 = optFindHoistCandidate(lnum, lbeg, lend, block, hoistxPtr);
    if  (res2 == -1)
        return  res2;

    return  res1 & res2;
}

/*****************************************************************************
 *
 *  Look for expressions to hoist out of loops.
 */

void                    Compiler::optHoistLoopCode()
{
    bool            fgModified = false;

    for (unsigned lnum = 0; lnum < optLoopCount; lnum++)
    {
        BasicBlock *    block;
        BasicBlock *    head;
        BasicBlock *    lbeg;
        BasicBlock *    tail;

        unsigned        begn;
        unsigned        endn;

        GenTree *       hoist;

        /* If loop was removed continue */

        if  (optLoopTable[lnum].lpFlags & LPFLG_REMOVED)
            continue;

        /* Get the head and tail of the loop */

        head = optLoopTable[lnum].lpHead;
        tail = optLoopTable[lnum].lpEnd;
        lbeg = optLoopTable[lnum].lpEntry;

        /* Make sure the loop always executes at least once!!!! */

        if  (head->bbNext != lbeg)
            continue;

        assert (optLoopTable[lnum].lpFlags & LPFLG_DO_WHILE);

        /* For now, we don't try to hoist out of catch blocks */

        if  (lbeg->bbCatchTyp)
            continue;

        begn = lbeg->bbNum;
        endn = tail->bbNum;

//      fgDispBasicBlocks(false);

        /* Make sure the "visited" bit is cleared for all blocks */

#ifndef NDEBUG
        block = head;
        do
        {
            block = block->bbNext;

            assert(block && (block->bbFlags & (BBF_VISITED|BBF_MARKED)) == 0);
        }
        while (block != tail);
#endif

        /* Recursively look for a hoisting candidate */

        hoist = 0; optFindHoistCandidate(lnum, begn, endn, lbeg, &hoist);

        /* Now clear all the "visited" bits on all the blocks */

        block = head;
        do
        {
            block = block->bbNext; assert(block);
            block->bbFlags &= ~(BBF_VISITED|BBF_MARKED);
        }
        while (block != tail);

        /* Did we find a candidate for hoisting? */

        if  (hoist)
        {
            unsigned        bnum;
#ifdef DEBUG
            GenTreePtr      orig = hoist;
#endif
            BasicBlock  *   lpbeg;

            /* Create a copy of the expression and mark it for CSE's */

#if CSELENGTH

            if  (hoist->gtOper == GT_ARR_RNGCHK)
            {
                GenTreePtr      oldhx;

                /* Make sure we clone the address exoression */

                oldhx = hoist;
                oldhx->gtFlags |=  GTF_ALN_CSEVAL;
                hoist = gtCloneExpr(oldhx, GTF_MAKE_CSE);
                oldhx->gtFlags &= ~GTF_ALN_CSEVAL;
            }
            else
#endif
                hoist = gtCloneExpr(hoist, GTF_MAKE_CSE);

            hoist->gtFlags |= GTF_MAKE_CSE;

            /* Get hold of the first block of the loop body */

            lpbeg = head->bbNext;

            /* The value of the expression isn't used */

            hoist = gtUnusedValNode(hoist);
            hoist = gtNewStmt(hoist);
            hoist->gtFlags |= GTF_STMT_CMPADD;

            /* Allocate a new basic block */

            block = bbNewBasicBlock(BBJ_NONE);
            block->bbFlags |= (lpbeg->bbFlags & BBF_HAS_HANDLER) | BBF_INTERNAL;

            /* The new block becomes the 'head' of the loop - update bbRefs and bbPreds
             * All predecessors of 'lbeg', (which is the entry in the loop)
             * now have to jump to 'block' */

            block->bbRefs = 0;

            BasicBlock  *   predBlock;
            flowList    *   pred;

            for (pred = lbeg->bbPreds; pred; pred = pred->flNext)
            {
                predBlock = pred->flBlock;

                /* The predecessor has to be outside the loop */

                if(predBlock->bbNum >= lbeg->bbNum)
                    continue;

                switch(predBlock->bbJumpKind)
                {
                case BBJ_NONE:
                    assert(predBlock == head);

                case BBJ_COND:
                    if  (predBlock == head)
                    {
                        fgReplacePred(lpbeg, head, block);
                        fgAddRefPred(block, head, true, true);
                        break;
                    }

                    /* Fall through for the jump case */

                case BBJ_ALWAYS:
                    assert(predBlock->bbJumpDest == lbeg);
                    predBlock->bbJumpDest = block;

                    if (!fgIsPredForBlock(lpbeg, block))
                        fgAddRefPred(lpbeg, block, true, true);

                    assert(lpbeg->bbRefs);
                    lpbeg->bbRefs--;
                    fgRemovePred(lpbeg, predBlock);
                    fgAddRefPred(block, predBlock, true, true);
                    break;

                case BBJ_SWITCH:
                    unsigned        jumpCnt = predBlock->bbJumpSwt->bbsCount;
                    BasicBlock * *  jumpTab = predBlock->bbJumpSwt->bbsDstTab;

                    if (!fgIsPredForBlock(lpbeg, block))
                        fgAddRefPred(lpbeg, block, true, true);

                    do
                    {
                        assert (*jumpTab);
                        if ((*jumpTab) == lbeg)
                        {
                            (*jumpTab) = block;

                            fgRemovePred(lpbeg, predBlock);
                            fgAddRefPred(block, predBlock, true, true);
                        }
                    }
                    while (++jumpTab, --jumpCnt);
                }
            }

            /* 'block' becomes the new 'head' */

            optLoopTable[lnum].lpHead = block;

            head ->bbNext   = block;
            block->bbNext   = lpbeg;

            /* Store the single statement in the block */

            block->bbTreeList = hoist;
            hoist->gtNext     = 0;
            hoist->gtPrev     = hoist;

            /* Assign the new block the appropriate number */

            bnum = head->bbNum;

            /* Does the loop start a try block? */

            if  (lbeg->bbFlags & BBF_IS_TRY)
            {
                unsigned        XTnum;
                EHblkDsc *      HBtab;

                /* Make sure this block isn't removed */

                block->bbFlags |= BBF_DONT_REMOVE;

                /*
                    Update the EH table to make the hoisted block
                    part of the loop's try block.
                 */

                for (XTnum = 0, HBtab = compHndBBtab;
                     XTnum < info.compXcptnsCount;
                     XTnum++  , HBtab++)
                {
                    /* If try/catch began at loop, it begins at hoist block */

                    if  (HBtab->ebdTryBeg == lpbeg)
                         HBtab->ebdTryBeg =  block;
                    if  (HBtab->ebdHndBeg == lpbeg)
                         HBtab->ebdHndBeg =  block;
                    if (HBtab->ebdFlags & JIT_EH_CLAUSE_FILTER)
                        if  (HBtab->ebdFilter == lpbeg)
                             HBtab->ebdFilter =  block;
                }
            }

            /* mark the new block as the loop pre-header */

            optLoopTable[lnum].lpFlags |= LPFLG_HAS_PREHEAD;

            /* Update the block numbers for all following blocks
             * OBS: Don't update the bbNums since it will mess up
             * the dominators and we need them for loop invariants below */

            fgModified = true;

//            do
//            {
//                block->bbNum = ++bnum;
//                block = block->bbNext;
//            }
//            while (block);

#ifdef DEBUG
            if (verbose)
            {
//              printf("Copying expression to hoist:\n");
//              gtDispTree(orig);
                printf("Hoisted copy of %08X for loop <%u..%u>:\n", orig, head->bbNext->bbNum, tail->bbNum);
                gtDispTree(hoist->gtStmt.gtStmtExpr->gtOp.gtOp1);
//              printf("\n");
//              fgDispBasicBlocks(false);
                printf("\n");
            }
#endif

            // CONSIDER: Now that we've hoisted this expression, repeat
            // CONSIDER: the analysis and this time simply ignore the
            // CONSIDER: expression just hoisted since it's now known
            // CONSIDER: not to be a side effect.
        }


#if 0

        /* This stuff is OK, but disabled until we fix the problem of
         * keeping the dominators in synch and remove the limitation
         *on the number of BB */


        /* Look for loop invariant statements
         * For now consider only single exit loops since we will
         * have to show that the invariant dominates all exits */

        if (!optLoopTable[lnum].lpExit)
            continue;

        assert (optLoopTable[lnum].lpFlags & LPFLG_ONE_EXIT);

        /* Conditions to hoist an invariant statement s (of the form "x = something"):
         *    1. The statement has to dominate all loop exits
         *    2. x is never assigned in the loop again
         *    3. Any use of x is used by this definition of x (i.e the block dominates all uses of x)
         *    4. The are no side effects on any path from the ENTRy to s
         */

        /* For now consider only the first BB since it will automatically satisfy 1 and 3 above */

        GenTreePtr  stmt;
        GenTreePtr  tree;

        for (stmt = lbeg->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert (stmt->gtOper == GT_STMT);

            tree = stmt->gtStmt.gtStmtExpr;
            assert(tree);

            /* if any side effect encountered bail - satisfy condition 4 */

            if (tree->gtFlags & (GTF_SIDE_EFFECT & ~GTF_ASG))
                break;

            /* interested only in assignments */

            if (tree->gtOper != GT_ASG)
                continue;

            /* has to be an assignment to a local var */

            GenTreePtr  op1 = tree->gtOp.gtOp1;
            GenTreePtr  op2 = tree->gtOp.gtOp2;
            bool        isInvariant = false;

            if (op1->gtOper != GT_LCL_VAR)
                continue;

            if (!optIsTreeLoopInvariant(lnum, lbeg, tail, op2))
                continue;

            /* Great - the RHS is loop invariant, now we have to make sure
             * the local var in LSH is never re-defined in the loop */

            assert (op1->gtOper == GT_LCL_VAR);

            if (optIsVarAssigned(lbeg, tail, tree, op1->gtLclVar.gtLclNum))
                continue;

            /* Yupee - we have an invariant statement - Remove it from the
             * current block and put it in the preheader */

#ifdef  DEBUG
                if  (verbose)
                {
                    printf("Hoisting invariant statement from loop #%02u (#%02u - #%02u)\n", lnum, lbeg->bbNum, tail->bbNum);
                    gtDispTree(stmt);
                    printf("\n");
                }
#endif

            /* remove the invariant statement from the loop (remember is in the first block) */

            assert (lbeg == optLoopTable[lnum].lpHead->bbNext);
            assert (lbeg == optLoopTable[lnum].lpEntry);
            fgRemoveStmt(lbeg, stmt);

            /* put the invariant statement in the pre-header */

            BasicBlock  * preHead;

            if (!(optLoopTable[lnum].lpFlags & LPFLG_HAS_PREHEAD))
            {
                /* have to create our own pre-header */
                fgCreateLoopPreHeader(lnum);
                fgModified = true;
            }

            assert (optLoopTable[lnum].lpFlags & LPFLG_HAS_PREHEAD);
            preHead = optLoopTable[lnum].lpHead;

            assert (preHead->bbJumpKind == BBJ_NONE);
            assert (preHead->bbNext == optLoopTable[lnum].lpEntry);

            /* simply append the statement at the end of the preHead's list */

            tree = preHead->bbTreeList;

            if (tree)
            {
                /* append after last statement */

                GenTreePtr  last = tree->gtPrev;
                assert (last->gtNext == 0);

                last->gtNext        = stmt;
                stmt->gtNext        = 0;
                stmt->gtPrev        = last;
                tree->gtPrev        = stmt;
            }
            else
            {
                /* Empty pre-header - store the single statement in the block */

                preHead->bbTreeList = stmt;
                stmt->gtNext        = 0;
                stmt->gtPrev        = stmt;
            }
        }

        /* Look for loop "iterative" invariants nad put them in "post-blocks" */
#endif

    }

    /* If we inserted any pre-header or post-blocks - update the bbNums */

    if (fgModified)
    {
        fgAssignBBnums(true);

#ifdef  DEBUG
        if  (verbose)
        {
            printf("\nFlowgraph after loop hoisting:\n");
            fgDispBasicBlocks();
            printf("\n");
        }

        fgDebugCheckBBlist();
#endif

    }

}


/*****************************************************************************
 *
 *  Creates a pre-header block for the given loop - the pre-header will replace the current
 *  lpHead in the loop table. The loop has to be a do-while loop
 *
 *  NOTE: We don't update the bbNums so the dominator relation still holds inside inner loops
 *        For nested loops we're still OK, as long as we check for new inserted blocks
 *
 *  CONSIDER: Incremental update of Dominators
 */

void                 Compiler::fgCreateLoopPreHeader(unsigned   lnum)
{
    BasicBlock   *   block;
    BasicBlock   *   top;
    BasicBlock   *   head;

    assert (!(optLoopTable[lnum].lpFlags & LPFLG_HAS_PREHEAD));

    head = optLoopTable[lnum].lpHead;
    assert (head->bbJumpKind != BBJ_NONE);

    /* has to be a "do while" loop */

    assert (optLoopTable[lnum].lpFlags & LPFLG_DO_WHILE);

    /* Get hold of the first block of the loop body */

    top = head->bbNext;
    assert (top == optLoopTable[lnum].lpEntry);

#ifdef  DEBUG
    if  (verbose)
    {
        printf("Creating Pre-Header for loop #%02u (#%02u - #%02u)\n", lnum,
                               top->bbNum, optLoopTable[lnum].lpEnd->bbNum);
        printf("\n");
    }
#endif

    /* Allocate a new basic block */

    block = bbNewBasicBlock(BBJ_NONE);
    block->bbFlags |= (top->bbFlags & BBF_HAS_HANDLER) | BBF_INTERNAL;
    block->bbNext   = top;
    head ->bbNext   = block;

    /* Update the loop entry */

    optLoopTable[lnum].lpHead = block;

    /* mark the new block as the loop pre-header */

    optLoopTable[lnum].lpFlags |= LPFLG_HAS_PREHEAD;

    /* Does the loop start a try block? */

    if  (top->bbFlags & BBF_IS_TRY)
    {
        unsigned        XTnum;
        EHblkDsc *      HBtab;

        /* Make sure this block isn't removed */

        block->bbFlags |= BBF_DONT_REMOVE;

        /*
            Update the EH table to make the hoisted block
            part of the loop's try block.
         */

        for (XTnum = 0, HBtab = compHndBBtab;
             XTnum < info.compXcptnsCount;
             XTnum++  , HBtab++)
        {
            /* If try/catch began at loop, it begins at hoist block */

            if  (HBtab->ebdTryBeg == top)
                 HBtab->ebdTryBeg =  block;
            if  (HBtab->ebdHndBeg == top)
                 HBtab->ebdHndBeg =  block;
            if (HBtab->ebdFlags & JIT_EH_CLAUSE_FILTER)
                if  (HBtab->ebdFilter == top)
                     HBtab->ebdFilter =  block;
        }
    }
}


/*****************************************************************************
 *
 *  Given a loop and a tree, checks if the tree is loop invariant
 *  i.e. has no side effects and all variables being part of it are
 *  never assigned in the loop
 */

bool                 Compiler::optIsTreeLoopInvariant(unsigned        lnum,
                                                      BasicBlock  *   top,
                                                      BasicBlock  *   bottom,
                                                      GenTreePtr      tree)
{
    assert (optLoopTable[lnum].lpEnd   == bottom);
    assert (optLoopTable[lnum].lpEntry == top);

    assert (!(tree->gtFlags & GTF_SIDE_EFFECT));

    switch (tree->gtOper)
    {
    case GT_CNS_INT:
    case GT_CNS_LNG:
    case GT_CNS_FLT:
    case GT_CNS_DBL:
        return true;

    case GT_LCL_VAR:
        return !optIsVarAssigned(top, bottom, 0, tree->gtLclVar.gtLclNum);

    case GT_ADD:
    case GT_SUB:
    case GT_MUL:
    case GT_DIV:
    case GT_MOD:

    case GT_OR:
    case GT_XOR:
    case GT_AND:

    case GT_LSH:
    case GT_RSH:
    case GT_RSZ:

        assert(tree->OperKind() & GTK_BINOP);

        GenTreePtr  op1 = tree->gtOp.gtOp1;
        GenTreePtr  op2 = tree->gtOp.gtOp2;

        assert(op1 && op2);

        return (optIsTreeLoopInvariant(lnum, top, bottom, op1) &&
                optIsTreeLoopInvariant(lnum, top, bottom, op2));
    }

    return false;
}

/*****************************************************************************/
#endif  // CSE
/*****************************************************************************
 *
 *  Callback (for fgWalkTree) used by the increment / range check optimization
 *  code.
 */

struct optIncRngDsc
{
    // Fields common to all phases:

    Compiler    *       oirComp;
    unsigned short      oirPhase;    // which pass are we performing?

    var_types           oirElemType;
    bool                oirSideEffect;

    unsigned char       oirFoundX:1;// have we found an array/index pair?
    unsigned char       oirExpVar:1;// have we just expanded an index value?

    // Debugging fields:

#ifndef NDEBUG
    void    *           oirSelf;
#endif

    BasicBlock  *       oirBlock;
    GenTreePtr          oirStmt;

    unsigned short      oirArrVar;  // # of index variable
    unsigned short      oirInxVar;  // # of index variable

    unsigned short      oirInxCnt;  // # of uses of index variable as index
    unsigned short      oirInxUse;  // # of uses of index variable, overall

    unsigned short      oirInxOff;  // how many times index incremented?
};

int                 Compiler::optIncRngCB(GenTreePtr tree, void *p)
{
    optIncRngDsc*   desc;
    GenTreePtr      expr;

    /* Get hold of the descriptor */

    desc = (optIncRngDsc*)p; ASSert(desc && desc->oirSelf == desc);

    /* After we find a side effect, we just give up */

    if  (desc->oirSideEffect)
        return  -1;

    /* Is this an assignment? */

    if  (tree->OperKind() & GTK_ASGOP)
    {
        /* Is the target a simple local variable? */

        expr = tree->gtOp.gtOp1;
        if  (expr->gtOper != GT_LCL_VAR)
            goto SIDE_EFFECT;

        /* Is this either the array or the index variable? */

        if  (expr->gtLclVar.gtLclNum == desc->oirInxVar ||
             expr->gtLclVar.gtLclNum == desc->oirArrVar)
        {
            /* Variable is modified, consider this a side effect */

            goto SIDE_EFFECT;
        }

        /* Assignment to a boring local variable, ignore it */

        return  0;
    }

    /* Is this an index expression? */

    if  (tree->gtOper == GT_INDEX)
    {
        int         arrx;
        int         indx;

        /* Is the array address a simple local variable? */

        expr = tree->gtOp.gtOp1;
        if  (expr->gtOper != GT_LCL_VAR)
            goto SIDE_EFFECT;

        arrx = expr->gtLclVar.gtLclNum;

        /* Is the index value   a simple local variable? */

        expr = tree->gtOp.gtOp2;
        if  (expr->gtOper != GT_LCL_VAR)
            goto SIDE_EFFECT;

        indx = expr->gtLclVar.gtLclNum;

        /* Have we decided which array and index to track? */

        if  (arrx != desc->oirArrVar ||
             indx != desc->oirInxVar)
        {
            /* If we have decided, these must be the wrong variables */

            if  (desc->oirFoundX)
                goto SIDE_EFFECT;

            /* Looks like we're deciding now */

            desc->oirArrVar = arrx;
            desc->oirInxVar = indx;
            desc->oirFoundX = true;
        }

        /* Are we in the second phase? */

        if  (desc->oirPhase == 2)
        {
            /* This range check is eliminated */

            tree->gtFlags &= ~GTF_INX_RNGCHK;

            /* Record the element type while we're at it */

            desc->oirElemType = tree->TypeGet();
        }

        /* Count this as a use as array index */

        desc->oirInxCnt++;

        return  0;
    }

    /* Is this a use of the index variable? */

    if  (tree->gtOper == GT_LCL_VAR)
    {
        /* Is this a use of the index variable? */

        if  (tree->gtLclVar.gtLclNum == desc->oirInxVar)
        {
            /* Count this as a use as array index */

            desc->oirInxUse++;

            /* Are we in the second phase? */

            if  (desc->oirPhase == 2)
            {
                /* Add the appropriate offset to the variable value */

                if  (desc->oirInxOff)
                {
                    /* Avoid recursive death */

                    if  (desc->oirExpVar)
                    {
                        desc->oirExpVar = false;
                    }
                    else
                    {
                        tree->gtOper     = GT_ADD;
                        tree->gtOp.gtOp1 = desc->oirComp->gtNewLclvNode(desc->oirInxVar, TYP_INT);
                        tree->gtOp.gtOp2 = desc->oirComp->gtNewIconNode(desc->oirInxOff, TYP_INT);

                        desc->oirExpVar = true;
                    }
                }
            }
        }
    }

    /* Are any other side effects here ? */

    if  (!desc->oirComp->gtHasSideEffects(tree))
        return  0;

SIDE_EFFECT:

//  printf("Side effect:\n"); desc->oirComp->gtDispTree(tree); printf("\n\n");

    desc->oirSideEffect = true;
    return  -1;
}

/*****************************************************************************
 *
 *  Try to optimize series of increments and array index expressions.
 */

void                Compiler::optOptimizeIncRng()
{
    BasicBlock  *   block;
    optIncRngDsc    desc;

    /* Did we find enough increments to make this worth while? */

    if  (fgIncrCount < 10)
        return;

    /* First pass: look for increments followed by index expressions */

    desc.oirComp  = this;
#ifndef NDEBUG
    desc.oirSelf  = &desc;
#endif

    /*
        Walk all the basic blocks, and look for blocks that are known
        to contain both index and increment expressions. For all such
        blocks, walk their trees and do the following:

            Remember the last index expression found. Also remember
            where the last side effect was encountered.

            When an increment is found, see if the variable matches
            the index of the last index expression recorded above,
            if it does this will determine the array and index we
            will try to optimize.

        The values in the following loop are as follows:


                ..... stuff ......
                ..... stuff ......

            sideEff:

                ..... last stmt with unrelated side effects .....

            arrStmt:

                ..... stmt 1 with a matching array expr  .....

                ..... increment 1 .....

                ..... stmt 2 with a matching array expr  .....

                ..... increment 2 .....

                ...
                ... above two repeated N times
                ...

            arrLast:

                ..... stmt <N> with a matching array expr  .....

            incLast:

                ..... increment <N> .....

     */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      sideEff;        // stmt with last side-effect

        GenTreePtr      arrStmt;        // stmt with first array ref
        GenTreePtr      arrLast;        // stmt with last  array ref
        unsigned        arrLstx;        // index of above
        GenTreePtr      incLast;        // stmt with last  increment
        unsigned        incLstx;        // index of above

        unsigned        arrXcnt;        // total number of array exprs

        GenTreePtr      stmt;
        unsigned        snum;

        if  ((block->bbFlags & BBF_HAS_HANDLER) != 0)
            continue;
        if  ((block->bbFlags & BBF_HAS_INC    ) == 0)
            continue;
        if  ((block->bbFlags & BBF_HAS_INDX   ) == 0)
            continue;

        /* This basic block shows potential, let's process it */

        desc.oirBlock  = compCurBB = block;
        desc.oirFoundX = false;
        desc.oirInxOff = 0;

        /* Remember the statements with interesting things in them */

        sideEff =
        arrStmt = 0;
        arrXcnt = 0;

        /* Phase 1 of our algorithm is now beginning */

        desc.oirPhase = 1;

        for (stmt = block->bbTreeList, snum = 0;
             stmt;
             stmt = stmt->gtNext     , snum++)
        {
            GenTreePtr      expr;

            assert(stmt->gtOper == GT_STMT); expr = stmt->gtStmt.gtStmtExpr;

            /* Is this an integer increment statement? */

            if  (expr->gtOper == GT_ASG_ADD && desc.oirFoundX)
            {
                GenTreePtr      op1 = expr->gtOp.gtOp1;
                GenTreePtr      op2 = expr->gtOp.gtOp2;

                if  (op1->gtOper != GT_LCL_VAR)
                    goto NOT_INC1;
                if  (op1->gtLclVar.gtLclNum != desc.oirInxVar)
                    goto NOT_INC1;

                if  (op2->gtOper != GT_CNS_INT)
                    goto NOT_INC1;
                if  (op2->gtIntCon.gtIconVal != 1)
                    goto NOT_INC1;

                /* We've found an increment of the index variable */

//              printf("Increment index [%u]:\n", desc.oirInxOff); gtDispTree(expr);

                desc.oirInxOff++;

                /* Remember the last increment statement */

                incLast = stmt;
                incLstx = snum;

                /* Continue if there are any more statements left */

                if  (stmt->gtNext)
                    continue;

                /* We've reached the end of the basic block */

                goto END_LST;
            }

        NOT_INC1:

            /* Recursively process this tree */

            desc.oirStmt       = stmt;
            desc.oirSideEffect = false;
            desc.oirInxUse     =
            desc.oirInxCnt     = 0;

            fgWalkTree(expr, optIncRngCB, &desc);

            /* Was there a side effect in the expression? */

            if  (desc.oirSideEffect)
                goto END_LST;

            /* Was the index variable used after being incremented? */

            if  (desc.oirInxUse > desc.oirInxCnt)
            {
                /* For now, we simply give up */

                goto END_LST;
            }

            /* Did the expression contain interesting array exprs? */

            if  (desc.oirInxCnt)
            {
                assert(desc.oirFoundX);

                /* Record the last array statement and the total count */

                arrXcnt += desc.oirInxCnt;
                arrLast  = stmt;
                arrLstx  = snum;
            }

            /* Is this the last statement of this basic block? */

            if  (stmt->gtNext == NULL)
                goto END_LST;

            /* Have we found an incremented index/array pair yet? */

            if  (desc.oirFoundX && desc.oirInxOff == 0)
            {
                /* Remember the first stmt with an index in it */

                arrStmt = stmt;
            }

            continue;

        END_LST:

            /* Have we decided on an array expression yet? */

            if  (desc.oirFoundX)
            {
                /* End of list; did we find enough interesting expressions? */

                if  (desc.oirInxOff >= 3 && arrXcnt >= 3)
                {
                    GenTreePtr      list;
                    GenTreePtr      ends;

                    GenTreePtr      rng1;
                    GenTreePtr      rng2;

                    GenTreePtr      next;

                    /* Process statements from "arrStmt" to incLast */

                    list = arrStmt; assert(list);
                    ends = incLast; assert(ends && ends != list);

                    /* Begin phase 2 of tree walking */

                    desc.oirInxOff = 0;
                    desc.oirPhase  = 2;

                    for (;;)
                    {
                        GenTreePtr      expr;

                    AGAIN:

                        assert(list->gtOper == GT_STMT); expr = list->gtStmt.gtStmtExpr;

                        /* Is this an integer increment statement? */

                        if  (expr->gtOper == GT_ASG_ADD)
                        {
                            GenTreePtr      prev;
                            GenTreePtr      next;

                            GenTreePtr      op1 = expr->gtOp.gtOp1;
                            GenTreePtr      op2 = expr->gtOp.gtOp2;

                            if  (op1->gtOper != GT_LCL_VAR)
                                goto NOT_INC2;
                            if  (op1->gtLclVar.gtLclNum != desc.oirInxVar)
                                goto NOT_INC2;

                            if  (op2->gtOper != GT_CNS_INT)
                                goto NOT_INC2;
                            if  (op2->gtIntCon.gtIconVal != 1)
                                goto NOT_INC2;

                            /* Keep track of how many times incremented */

                            desc.oirInxOff++;

                            /* Is this the last increment? */

                            if  (list == ends)
                            {
                                /* Replace with "+= total_count" */

                                op2->gtIntCon.gtIconVal = desc.oirInxOff;

                                /* We're done now */

                                break;
                            }

                            /* Remove this increment statement */

                            prev = list->gtPrev; assert(prev);
                            next = list->gtNext; assert(next);

                            assert(prev->gtNext == list);
                            assert(next->gtPrev == list);

                            prev->gtNext = next;
                            next->gtPrev = prev;

                            /* Don't follow the "next" link, block is now gone */

                            list = next;

                            goto AGAIN;
                        }

                    NOT_INC2:

                        assert(list != ends);

                        /* Recursively process this tree */

                        desc.oirStmt       = list;
                        desc.oirSideEffect = false;
                        desc.oirInxUse     =
                        desc.oirInxCnt     = 0;

                        fgWalkTree(expr, optIncRngCB, &desc);

                        if  (list == ends)
                            break;

                        list = list->gtNext;
                    }

                    /* Create the combined range checks */

                    rng1 = gtNewIndexRef(desc.oirElemType,
                                         gtNewLclvNode(desc.oirArrVar  , TYP_REF),
                                         gtNewLclvNode(desc.oirInxVar  , TYP_INT));

#if CSE
                    rng1->gtFlags |= GTF_DONT_CSE;
#endif
                    rng1 = gtNewStmt(rng1);
                    rng1->gtFlags |= GTF_STMT_CMPADD;

                    rng2 = gtNewOperNode(GT_ADD,
                                         TYP_INT,
                                         gtNewLclvNode(desc.oirInxVar  , TYP_INT),
                                         gtNewIconNode(desc.oirInxOff-1, TYP_INT));

                    rng2 = gtNewIndexRef(desc.oirElemType,
                                         gtNewLclvNode(desc.oirArrVar  , TYP_REF),
                                         rng2);

#if CSE
                    rng2->gtFlags |= GTF_DONT_CSE;
#endif
                    rng2 = gtNewStmt(rng2);
                    rng2->gtFlags |= GTF_STMT_CMPADD;

                    rng1->gtNext = rng2;
                    rng2->gtPrev = rng1;

                    /* Insert the combined range checks */

                    list = sideEff;
                    if  (list)
                    {
                        next = list->gtNext;

                        list->gtNext = rng1;
                        rng1->gtPrev = list;
                    }
                    else
                    {
                        next = block->bbTreeList;
                               block->bbTreeList = rng1;

                        rng1->gtPrev = next->gtPrev;
                    }

                    next->gtPrev = rng2;
                    rng2->gtNext = next;
                }

                /* Clear everything, we're starting over */

                desc.oirInxVar = -1;
                desc.oirArrVar = -1;
                desc.oirInxOff = 0;
            }
            else
            {
                /* Remember this as the last side-effect statement */

                sideEff = stmt;

                /* We have not found any matching array expressions */

                arrXcnt = 0;
            }
        }
    }
}

/*****************************************************************************
 *
 *  Given an array index node, mark it as not needing a range check.
 */

void                Compiler::optRemoveRangeCheck(GenTreePtr tree, GenTreePtr stmt)
{
    GenTreePtr      add1;
    GenTreePtr  *   addp;

    GenTreePtr      nop1;
    GenTreePtr  *   nopp;

    GenTreePtr      icon;
    GenTreePtr      mult;

    GenTreePtr      temp;
    GenTreePtr      base;

    long            ival;

#if !REARRANGE_ADDS
    assert(!"can't remove range checks without REARRANGE_ADDS right now");
#endif

    assert(stmt->gtOper     == GT_STMT);
    assert(tree->gtOper     == GT_IND);
    assert(tree->gtOp.gtOp2 == 0);
    assert(tree->gtFlags & GTF_IND_RNGCHK);

    /* Unmark the topmost node */

    tree->gtFlags &= ~GTF_IND_RNGCHK;

#if CSELENGTH

    /* Is there an array length expression? */

    if  (tree->gtInd.gtIndLen)
    {
        GenTreePtr      len = tree->gtInd.gtIndLen;

        assert(len->gtOper == GT_ARR_RNGCHK);

        /* It doesn't make much sense to CSE this range check
         * remove the range check and re-thread the statement nodes */

        len->gtCSEnum        = 0;
        tree->gtInd.gtIndLen = NULL;
    }

#endif

    /* Locate the 'nop' node so that we can remove it */

    addp = &tree->gtOp.gtOp1;
    add1 = *addp; assert(add1->gtOper == GT_ADD);

    /* Is "+icon" present? */

    icon = 0;

    // CONSIDER: Also check for "-icon" here

    if  (add1->gtOp.gtOp2->gtOper == GT_CNS_INT)
    {
        icon =  add1->gtOp.gtOp2;
        addp = &add1->gtOp.gtOp1;
        add1 = *addp;
    }

    /* 'addp' points to where 'add1' came from, 'add1' must be a '+' */

    assert(*addp == add1); assert(add1->gtOper == GT_ADD);

    /*  Figure out which is the array address and which is the index;
        the index value is always a 'NOP' node possibly wrapped with
        a multiplication (left-shift) operator.
     */

    temp = add1->gtOp.gtOp1;
    base = add1->gtOp.gtOp2;

    if      (temp->gtOper == GT_NOP)
    {
        /* 'op1' is the index value, and it's not multiplied */

        mult = 0;

        nopp = &add1->gtOp.gtOp1;
        nop1 =  add1->gtOp.gtOp1;

        assert(base->gtType == TYP_REF);
    }
    else if ((temp->gtOper == GT_LSH || temp->gtOper == GT_MUL) && temp->gtOp.gtOp1->gtOper == GT_NOP)
    {
        /* 'op1' is the index value, and it *is*  multiplied */

        mult =  temp;

        nopp = &temp->gtOp.gtOp1;
        nop1 =  temp->gtOp.gtOp1;

        assert(base->gtType == TYP_REF);
    }
    else
    {
        base = temp;
        assert(base->gtType == TYP_REF);

        temp = add1->gtOp.gtOp2;

        if  (temp->gtOper == GT_NOP)
        {
            /* 'op2' is the index value, and it's not multiplied */

            mult = 0;

            nopp = &add1->gtOp.gtOp2;
            nop1 =  add1->gtOp.gtOp2;
        }
        else
        {
            /* 'op2' is the index value, and it *is*  multiplied */

            assert((temp->gtOper == GT_LSH || temp->gtOper == GT_MUL) && temp->gtOp.gtOp1->gtOper == GT_NOP);
            mult =  temp;

            nopp = &temp->gtOp.gtOp1;
            nop1 =  temp->gtOp.gtOp1;
        }
    }

    /* 'addp' points to where 'add1' came from, 'add1' is the NOP node */

    assert(*nopp == nop1 && nop1->gtOper == GT_NOP);

    /* Get rid of the NOP node */

    assert(nop1->gtOp.gtOp2 == NULL);

    nop1 = *nopp = nop1->gtOp.gtOp1;

    /* Can we hoist "+icon" out of the index computation? */

    if  (nop1->gtOper == GT_ADD && nop1->gtOp.gtOp2->gtOper == GT_CNS_INT)
    {
        addp = nopp;
        add1 = nop1;
        base = add1->gtOp.gtOp1;

        ival = add1->gtOp.gtOp2->gtIntCon.gtIconVal;
    }
    else if (nop1->gtOper == GT_CNS_INT)
    {
        /* in this case the index itself is a constant */

        ival = nop1->gtIntCon.gtIconVal;
    }
    else
        goto DONE;

    /* 'addp' points to where 'add1' came from, 'add1' must be a '+' */

    assert(*addp == add1); assert(add1->gtOper == GT_ADD);

    /* remove the added constant */

    *addp = base;

    /* Multiply the constant if the index is scaled */

    if  (mult)
    {
        assert(mult->gtOper == GT_LSH || mult->gtOper == GT_MUL);
        assert(mult->gtOp.gtOp2->gtOper == GT_CNS_INT);

        if (mult->gtOper == GT_MUL)
            ival  *= mult->gtOp.gtOp2->gtIntCon.gtIconVal;
        else
            ival <<= mult->gtOp.gtOp2->gtIntCon.gtIconVal;
    }

    /* Was there a constant added to the offset? */

    assert(icon);
    assert(icon->gtOper == GT_CNS_INT);

    icon->gtIntCon.gtIconVal += ival;

DONE:

    /* Re-thread the nodes if necessary */

    if (fgStmtListThreaded)
        fgSetStmtSeq(stmt);
}

/*****************************************************************************/
#if RNGCHK_OPT
/*****************************************************************************
 * parse the array reference, return
 *    pointer to nop (which is above index)
 *    pointer to scaling multiply/shift (or NULL if no multiply/shift)
 *    pointer to the address of the array
 * Since this is called before and after reordering, we have to be distinguish
 * between the array address and the index expression.
 */

GenTreePtr    *           Compiler::optParseArrayRef(GenTreePtr tree,
                                                     GenTreePtr *pmul,
                                                     GenTreePtr *parrayAddr)
{
    GenTreePtr     mul;
    GenTreePtr     index;
    GenTreePtr   * ptr;

    assert(tree->gtOper == GT_ADD);

#if REARRANGE_ADDS
    /* ignore constant offset added to array */
    if  (tree->gtOp.gtOp2->gtOper == GT_CNS_INT)
        tree = tree->gtOp.gtOp1;
#endif

    /* the array address is TYP_REF */

    if (tree->gtOp.gtOp1->gtType == TYP_REF)
    {
        /* set the return value for the array address */
        *parrayAddr = tree->gtOp.gtOp1;

        /* Op2 must be the index expression */
        ptr = &tree->gtOp.gtOp2; index = *ptr;
    }
    else
    {
        assert(tree->gtOp.gtOp2->gtType == TYP_REF);

        /* set the return value for the array address */
        *parrayAddr = tree->gtOp.gtOp2;

        /* Op1 must be the index expression */
        ptr = &tree->gtOp.gtOp1; index = *ptr;
    }

    /* Get rid of the base element address, if present */

    if  (index->gtOper == GT_ADD)
    {
        ptr = &index->gtOp.gtOp1; index = *ptr;
    }

    /* Get rid of a scaling operator, if present */

    mul = 0;

    if  (index->gtOper == GT_MUL ||
         index->gtOper == GT_LSH)
    {
        mul = index;
        ptr = &index->gtOp.gtOp1; index = *ptr;
    }

    /* We should have the index value at this point */

    assert(index == *ptr);
    assert(index->gtOper == GT_NOP);
    assert(index->gtFlags & GTF_NOP_RNGCHK);

    *pmul = mul;

    return ptr;
}

/*****************************************************************************
 * find the last assignment to of the local variable in the block. return
 * RHS or NULL. If any local variable in the RHS has been killed in
 * intervening code, return NULL.
 *
 */

GenTreePtr       Compiler::optFindLocalInit(BasicBlock *block, GenTreePtr local)
{

    GenTreePtr      rhs;
    GenTreePtr      list;
    GenTreePtr      stmt;
    GenTreePtr      tree;
    unsigned        LclNum;
    VARSET_TP       killedLocals = 0;
    unsigned        rhsRefs;
    VARSET_TP       rhsLocals;
    LclVarDsc   *   varDsc;

    rhs = NULL;
    list = block->bbTreeList;

    if  (!list)
        return NULL;

    LclNum = local->gtLclVar.gtLclNum;

    stmt = list;
    do
    {

        stmt = stmt->gtPrev;
        if  (!stmt)
            break;

        tree = stmt->gtStmt.gtStmtExpr;
        if (tree->gtOper == GT_ASG && tree->gtOp.gtOp1->gtOper == GT_LCL_VAR)
        {
            if (tree->gtOp.gtOp1->gtLclVar.gtLclNum == LclNum)
            {
                rhs = tree->gtOp.gtOp2;
                break;
            }
            varDsc = optIsTrackedLocal(tree->gtOp.gtOp1);

            if (varDsc == NULL)
                return NULL;

            killedLocals |= genVarIndexToBit(varDsc->lvVarIndex);

        }

    }
    while (stmt != list);

    if (rhs == NULL)
        return NULL;

    /* if any local in the RHS is killed in intervening code, or RHS has an
     * in indirection, return NULL
     */
    rhsRefs   = 0;
    rhsLocals = lvaLclVarRefs(rhs, NULL, &rhsRefs);
    if ((rhsLocals & killedLocals) || rhsRefs)
        return NULL;

    return rhs;
}

/*****************************************************************************
 *
 *  Return true if "op1" is guaranteed to be less then or equal to "op2".
 */

#if FANCY_ARRAY_OPT

bool                Compiler::optIsNoMore(GenTreePtr op1, GenTreePtr op2, int add1
                                                              , int add2)
{
    if  (op1->gtOper == GT_CNS_INT &&
         op2->gtOper == GT_CNS_INT)
    {
        add1 += op1->gtIntCon.gtIconVal;
        add2 += op2->gtIntCon.gtIconVal;
    }
    else
    {
        /* Check for +/- constant on either operand */

        if  (op1->gtOper == GT_ADD && op1->gtOp.gtOp2->gtOper == GT_CNS_INT)
        {
            add1 += op1->gtOp.gtOp2->gtIntCon.gtIconVal;
            op1   = op1->gtOp.gtOp1;
        }

        if  (op2->gtOper == GT_ADD && op2->gtOp.gtOp2->gtOper == GT_CNS_INT)
        {
            add2 += op2->gtOp.gtOp2->gtIntCon.gtIconVal;
            op2   = op2->gtOp.gtOp1;
        }

        /* We only allow local variable references */

        if  (op1->gtOper != GT_LCL_VAR)
            return false;
        if  (op2->gtOper != GT_LCL_VAR)
            return false;
        if  (op1->gtLclVar.gtLclNum != op2->gtLclVar.gtLclNum)
            return false;

        /* NOTE: Caller ensures that this variable has only one def */

//      printf("limit [%d]:\n", add1); gtDispTree(op1);
//      printf("size  [%d]:\n", add2); gtDispTree(op2);
//      printf("\n");

    }

    return  (bool)(add1 <= add2);
}

#endif
/*****************************************************************************
 *
 * Delete range checks in a loop if can prove that the index expression is
 * in range.
 *
 * Loop looks like:
 *
 *  head->  <init code>
 *          <possible zero trip test>
 *
 *  beg->   <top of loop>
 *
 *
 *  end->   <conditional branch to top of loop>
 */

void                Compiler::optOptimizeInducIndexChecks(BasicBlock *head, BasicBlock *end)
{
    BasicBlock  *   beg;
    GenTreePtr      conds, condt;
    GenTreePtr      stmt;
    GenTreePtr      tree;
    GenTreePtr      op1;
    GenTreePtr      op2;
    GenTreePtr      init;
    GenTreePtr      rc;
    VARSET_TP       lpInducVar = 0;
    VARSET_TP       lpAltered =  0;
    BasicBlock  *   block;
    unsigned        ivLclNum;
    unsigned        arrayLclNum;
    LclVarDsc   *   varDscIv;
    LclVarDsc   *   varDsc;
    VARSET_TP       mask;
    long            negBias;
    long            posBias;

#if FANCY_ARRAY_OPT
    const unsigned  CONST_ARRAY_LEN = ((unsigned)-1);
    GenTreePtr      loopLim;
#endif

    beg = head->bbNext;

    /* first find the loop termination test. if can't, give up */
    if (end->bbJumpKind != BBJ_COND)
        return;

    /* conditional branch must go back to top of loop */
    if  (end->bbJumpDest != beg)
        return;

    conds = genLoopTermTest(beg, end);

    if  (conds == NULL)
    {
        return;
    }
    else
    {
        /* Get to the condition node from the statement tree */

        assert(conds->gtOper == GT_STMT);

        condt = conds->gtStmt.gtStmtExpr;
        assert(condt->gtOper == GT_JTRUE);

        condt = condt->gtOp.gtOp1;
        assert(condt->OperIsCompare());
    }

    /* if test isn't less than, forget it */

    if (condt->gtOper != GT_LT)
    {
#if FANCY_ARRAY_OPT
        if (condt->gtOper != GT_LE)
#endif
            return;
    }

    op1 = condt->gtOp.gtOp1;

    /* is first operand a local var (ie has chance of being induction var? */
    if (op1->gtOper != GT_LCL_VAR)
        return;

    init = optFindLocalInit(head, op1);

    if (init == NULL || init->gtOper != GT_CNS_INT)
        return;

    /* any non-negative constant is a good initial value */
    posBias = init->gtIntCon.gtIconVal;

    if (posBias < 0)
        return;

    varDscIv = optIsTrackedLocal(op1);

    if (varDscIv == NULL)
        return;

    ivLclNum = op1->gtLclVar.gtLclNum;

    /* now scan the loop for invariant locals and induction variables */
    for (block = beg;;)
    {

#if FANCY_ARRAY_OPT
#pragma message("check with PeterMa about the change below")
#else
        if  (block == end)
            break;
#endif

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            tree = stmt->gtStmt.gtStmtExpr;

            if (tree->OperKind() & GTK_ASGOP)
            {
                op1 = tree->gtOp.gtOp1;

                varDsc = optIsTrackedLocal(op1);

                if (varDsc == NULL)
                    continue;

                mask = genVarIndexToBit(varDsc->lvVarIndex);

                if (tree->gtOper == GT_ASG_ADD)
                {
                    op2 = tree->gtOp.gtOp2;

                    /* if its not already altered, it can be an induc var */
                    if (op2->gtOper == GT_CNS_INT && !(lpAltered & mask))
                        lpInducVar |= mask;
                    else
                        /* variable can't be an induction variable */
                        lpInducVar &= ~mask;
                }
                else
                {
                    /* variable can't be an induction variable */
                    lpInducVar &= ~mask;
                }

                /* variable is altered in the loop */
                lpAltered |= mask;
            }
        }

        if  (block == end)
            break;

        block = block->bbNext;
    }

#ifdef DEBUG
    if (verbose)
    {
        printf("loop: BB %d to BB %d\n", beg->bbNum, end->bbNum);
        printf(" ALTERED="); lvaDispVarSet(lpAltered, 28);
        printf(" INDUC="); lvaDispVarSet(lpInducVar, 28);
        printf("\n");
    }
#endif

    if (!(lpInducVar & genVarIndexToBit(varDscIv->lvVarIndex)))
        return;

    /* condt is the loop termination test */
    op2 = condt->gtOp.gtOp2;

    /* is second operand a region constant. we could allow some expressions
     * here like length - 1
     */
    rc = op2;
    negBias = 0;

AGAIN:
    switch (rc->gtOper)
    {
    case GT_ADD:
        /* we allow length + negconst */
        if (rc->gtOp.gtOp2->gtOper == GT_CNS_INT
            && rc->gtOp.gtOp2->gtIntCon.gtIconVal < 0
            && rc->gtOp.gtOp1->gtOper == GT_ARR_LENGTH)
        {
            negBias = -rc->gtOp.gtOp2->gtIntCon.gtIconVal;
            op2 = rc = rc->gtOp.gtOp1;
            goto AGAIN;
        }
        break;

    case GT_SUB:
        /* we allow length - posconst */
        if (rc->gtOp.gtOp2->gtOper == GT_CNS_INT
            && rc->gtOp.gtOp2->gtIntCon.gtIconVal > 0
            && rc->gtOp.gtOp1->gtOper == GT_ARR_LENGTH)
        {
            negBias = rc->gtOp.gtOp2->gtIntCon.gtIconVal;
            op2 = rc = rc->gtOp.gtOp1;
            goto AGAIN;
        }
        break;

    case GT_ARR_LENGTH:
        /* recurse to check if operand is RC */
        rc = rc->gtOp.gtOp1;
        goto AGAIN;

    case GT_LCL_VAR:
        varDsc = optIsTrackedLocal(rc);

        /* if variable not tracked, quit */
        if  (!varDsc)
            return;

        /* if altered, then quit */
        if ((lpAltered & genVarIndexToBit(varDsc->lvVarIndex)))
            return;

        break;

    default:
        return;
    }

    if (op2->gtOper  == GT_LCL_VAR)
        op2 = optFindLocalInit(head, op2);

#if FANCY_ARRAY_OPT
    arrayLclNum = CONST_ARRAY_LEN;
#endif

    /* only thing we want is array length (note we update op2 above
     * to allow arrlen - posconst
     */
    if (op2 == NULL || op2->gtOper != GT_ARR_LENGTH
                    || op2->gtOp.gtOp1->gtOper != GT_LCL_VAR)
    {
#if FANCY_ARRAY_OPT
        loopLim = rc;
#else
        return;
#endif
    }
    else
    {
#if FANCY_ARRAY_OPT
        if (condt->gtOper == GT_LT)
#endif
            arrayLclNum = op2->gtOp.gtOp1->gtLclVar.gtLclNum;
    }

#if FANCY_ARRAY_OPT
    if  (arrayLclNum != CONST_ARRAY_LEN)
#endif
    {
        varDsc = optIsTrackedLocal(op2->gtOp.gtOp1);

        /* If array local not tracked, quit */

        if  (!varDsc)
            return;

        /* If the array has been altered in the loop, forget it */

        if  (lpAltered & genVarIndexToBit(varDsc->lvVarIndex))
            return;
    }

    /* now scan for range checks on the induction variable */
    for (block = beg;;)
    {

#if FANCY_ARRAY_OPT
#pragma message("check with PeterMa about the change below")
#else
        if  (block == end)
            break;
#endif

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                /* no more can be done if we see the increment of induc var */
                if (tree->OperKind() & GTK_ASGOP)
                {
                    if (tree->gtOp.gtOp1->gtOper == GT_LCL_VAR
                        && tree->gtOp.gtOp1->gtLclVar.gtLclNum == ivLclNum)
                        goto NOMORE;
                }

                if  ((tree->gtFlags & GTF_IND_RNGCHK) && tree->gtOper == GT_IND)
                {
                    GenTreePtr * pnop;

                    pnop = optParseArrayRef(tree->gtOp.gtOp1, &op2, &op1);

                    /* does the array ref match our known array */
                    if (op1->gtOper != GT_LCL_VAR)
                        break;

                    if  (op1->gtLclVar.gtLclNum != arrayLclNum)
                    {
#if FANCY_ARRAY_OPT
                        if  (arrayLclNum == CONST_ARRAY_LEN)
                        {
                            LclVarDsc   *   arrayDsc;

                            assert(op1->gtLclVar.gtLclNum < lvaCount);
                            arrayDsc = lvaTable + op1->gtLclVar.gtLclNum;

                            if  (arrayDsc->lvKnownDim)
                            {
                                if  (optIsNoMore(loopLim, arrayDsc->lvKnownDim, (condt->gtOper == GT_LE)))
                                {
                                    op1 = (*pnop)->gtOp.gtOp1;

                                    // UNDONE: Allow "i+1" and things like that

                                    goto RMV;
                                }
                            }
                        }
#endif
                        break;
                    }

                    op1 = (*pnop)->gtOp.gtOp1;

                    /* allow sub of non-neg constant from induction variable
                     * if we had bigger initial value
                     */
                    if (op1->gtOper == GT_SUB
                        && op1->gtOp.gtOp2->gtOper == GT_CNS_INT)
                    {
                        long ival = op1->gtOp.gtOp2->gtIntCon.gtIconVal;
                        if (ival >= 0 && ival <= posBias)
                            op1 = op1->gtOp.gtOp1;
                    }

                    /* allow add of constant to induction variable
                     * if we had a sub from length
                     */
                    if (op1->gtOper == GT_ADD
                        && op1->gtOp.gtOp2->gtOper == GT_CNS_INT)
                    {
                        long ival = op1->gtOp.gtOp2->gtIntCon.gtIconVal;
                        if (ival >= 0 && ival <= negBias)
                            op1 = op1->gtOp.gtOp1;
                    }

#if FANCY_ARRAY_OPT
                RMV:
#endif

                    /* is index our induction var? */
                    if (!(op1->gtOper == GT_LCL_VAR
                        && op1->gtLclVar.gtLclNum == ivLclNum))
                        break;

                    /* no need for range check */
                    optRemoveRangeCheck(tree, stmt);

#if COUNT_RANGECHECKS
                    optRangeChkRmv++;
#endif
                }
            }
        }

        if  (block == end)
            break;

        block = block->bbNext;
    }

    NOMORE: ;
}

/*****************************************************************************
 *
 *  Try to optimize away as many array index range checks as possible.
 */

void                Compiler::optOptimizeIndexChecks()
{
    BasicBlock *    block;

    unsigned        arrayVar;
    long            arrayDim;
#if FANCY_ARRAY_OPT
    LclVarDsc   *   arrayDsc;
#endif

    unsigned
    const           NO_ARR_VAR = (unsigned)-1;

    if  (!rngCheck)
        return;

    /* Walk all the basic blocks in the function */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;

        /* Ignore the block if it doesn't contain 'new' of an array */

        if  (!(block->bbFlags & BBF_NEW_ARRAY))
            continue;

        /* We have not noticed any array allocations yet */

        arrayVar = NO_ARR_VAR;

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                switch (tree->gtOper)
                {
                    GenTreePtr      op1;
                    GenTreePtr      op2;

                case GT_ASG:

                    op1 = tree->gtOp.gtOp1;
                    op2 = tree->gtOp.gtOp2;

                    /* We are only interested in assignments to locals */

                    if  (op1->gtOper != GT_LCL_VAR)
                        break;

                    /* Are we trashing the variable that holds the array addr? */

                    if  (arrayVar == op1->gtLclVar.gtLclNum)
                    {
                        /* The variable no longer holds the array it had */

                        arrayVar = NO_ARR_VAR;
                    }

                    /* Is this an assignment of 'new array' ? */

                    if  (op2->gtOper            == GT_CALL   &&
                         op2->gtCall.gtCallType == CT_HELPER  )
                    {
                        if (op2->gtCall.gtCallMethHnd == eeFindHelper(CPX_NEWARR_1_DIRECT))
                        {
                            /* Extract the array dimension from the helper call */

                            op2 = op2->gtCall.gtCallArgs;
                            assert(op2->gtOper == GT_LIST);
                            op2 = op2->gtOp.gtOp1;

                            if  (op2->gtOper == GT_CNS_INT)
                            {
                                /* We have a constant-sized array */

                                arrayVar = op1->gtLclVar.gtLclNum;
                                arrayDim = op2->gtIntCon.gtIconVal;
                            }
#if FANCY_ARRAY_OPT
                            else
                            {
                                GenTreePtr  tmp;

                                /* Make sure the value looks promising */

                                tmp = op2;
                                if  (tmp->gtOper == GT_ADD &&
                                     tmp->gtOp.gtOp2->gtOper == GT_CNS_INT)
                                    tmp = tmp->gtOp.gtOp1;

                                if  (tmp->gtOper != GT_LCL_VAR)
                                    break;

                                assert(tmp->gtLclVar.gtLclNum < lvaCount);
                                arrayDsc = lvaTable + tmp->gtLclVar.gtLclNum;

                                if  (arrayDsc->lvAssignTwo)
                                    break;
                                if  (arrayDsc->lvAssignOne && arrayDsc->lvIsParam)
                                    break;
                            }

                            /* Is there one assignment to the array? */

                            assert(op1->gtLclVar.gtLclNum < lvaCount);
                            arrayDsc = lvaTable + op1->gtLclVar.gtLclNum;

                            if  (arrayDsc->lvAssignTwo)
                                break;

                            /* Record the array size for later */

                            arrayDsc->lvKnownDim = op2;
#endif
                        }
                    }
                    break;

                case GT_IND:

#if FANCY_ARRAY_OPT
                    if  ((tree->gtFlags & GTF_IND_RNGCHK))
#else
                    if  ((tree->gtFlags & GTF_IND_RNGCHK) && arrayVar != NO_ARR_VAR)
#endif
                    {
                        GenTreePtr      mul;
                        GenTreePtr  *   pnop;

                        long            size;

                        pnop = optParseArrayRef(tree->gtOp.gtOp1, &mul, &op1);

                        /* Is the address of the array a simple variable? */

                        if  (op1->gtOper != GT_LCL_VAR)
                            break;

                        /* Is the index value a constant? */

                        op2 = (*pnop)->gtOp.gtOp1;

                        if  (op2->gtOper != GT_CNS_INT)
                            break;

                        /* Do we know the size of the array? */

                        if  (op1->gtLclVar.gtLclNum != arrayVar)
                        {
#if FANCY_ARRAY_OPT
                            GenTreePtr  dimx;

                            assert(op1->gtLclVar.gtLclNum < lvaCount);
                            arrayDsc = lvaTable + op1->gtLclVar.gtLclNum;

                            dimx = arrayDsc->lvKnownDim;
                            if  (!dimx)
                                break;
                            size = dimx->gtIntCon.gtIconVal;
#else
                            break;
#endif
                        }
                        else
                            size = arrayDim;

                        /* Is the index value within the correct range? */

                        if  (op2->gtIntCon.gtIconVal < 0)
                            break;
                        if  (op2->gtIntCon.gtIconVal >= size)
                            break;

                        /* no need for range check */
                        optRemoveRangeCheck(tree, stmt);


                        /* Get rid of the range check */
                        //*pnop = op2; tree->gtFlags &= ~GTF_IND_RNGCHK;

                        /* Remember that we have array initializer(s) */

                        optArrayInits = true;

                        /* Is the index value scaled? */

                        if  (mul && mul->gtOp.gtOp2->gtOper == GT_CNS_INT)
                        {
                            long        index =             op2->gtIntCon.gtIconVal;
                            long        scale = mul->gtOp.gtOp2->gtIntCon.gtIconVal;

                            assert(mul->gtOp.gtOp1 == op2);

                            if  (op2->gtOper == GT_MUL)
                                index  *= scale;
                            else
                                index <<= scale;

                            mul->ChangeOper(GT_CNS_INT);
                            mul->gtIntCon.gtIconVal = index;

#if 0

                            /* Was there an additional offset? [this is not finished] */

                            if  (tree->gtOp.gtOp2            ->gtOper == GT_ADD &&
                                 tree->gtOp.gtOp2->gtOp.gtOp2->gtOper == GT_CNS_INT)
                            {
                                mul->ChangeOper(GT_CNS_INT);
                                mul->gtIntCon.gtIconVal = index +
                            }

#endif

                        }
                    }
                    break;
                }
            }
        }
    }

    /* optimize range checks on induction variables */

    for (unsigned i=0; i < optLoopCount; i++)
    {
        /* Beware, some loops may be thrown away by unrolling or loop removal */

        if (!(optLoopTable[i].lpFlags & LPFLG_REMOVED))
           optOptimizeInducIndexChecks(optLoopTable[i].lpHead, optLoopTable[i].lpEnd);
    }
}

/*****************************************************************************/
#endif//RNGCHK_OPT
/*****************************************************************************/

/*****************************************************************************
 *
 *  Optimize array initializers.
 */

void                Compiler::optOptimizeArrayInits()
{

#if 0

    BasicBlock *    block;

    if  (!optArrayInits)
        return;

    /* Until interior pointers are allowed, we can't generate "rep movs" */

#ifdef  DEBUG
    genIntrptibleUse = true;
#endif

//  if  (genInterruptible)
//      return;

    /* Walk the basic block list, looking for promising initializers */

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;
        GenTreePtr      tree;

        /* Ignore the block if it doesn't contain 'new' of an array */

        if  (!(block->bbFlags & BBF_NEW_ARRAY))
            continue;

        /* Walk the statement trees in this basic block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
            {
                switch (tree->gtOper)
                {
                    GenTreePtr      op1;
                    GenTreePtr      op2;
                    long            off;

                case GT_ASG:

                    op2  = tree->gtOp.gtOp2;
                    if  (!(op2->OperKind() & GTK_CONST))
                        break;

                    op1  = tree->gtOp.gtOp1;
                    if  (op1->gtOper != GT_IND || op1->gtOp.gtOp2 != NULL)
                        break;

                    op1  = op1->gtOp.gtOp1;
                    if  (op1->gtOper != GT_ADD || op1->gtOp.gtOp2->gtOper != GT_CNS_INT)
                        break;

                    off  = op1->gtOp.gtOp2->gtIntCon.gtIconVal;
                    op1  = op1->gtOp.gtOp1;
                    if  (op1->gtOper != GT_ADD || op1->gtOp.gtOp2->gtOper != GT_CNS_INT)
                        break;

                    off += op1->gtOp.gtOp2->gtIntCon.gtIconVal;
                    op1  = op1->gtOp.gtOp1;
                    if  (op1->gtOper != GT_LCL_VAR)
                        break;

                    printf("Array init candidate: offset = %d\n", off);
                    gtDispTree(op2);
                    printf("\n");

                    break;
                }
            }
        }
    }

#endif

}

/*****************************************************************************/
#if     OPTIMIZE_RECURSION
/*****************************************************************************
 *
 *  A little helper to form the expression "arg * (arg + 1) / 2".
 */

/* static */
GenTreePtr          Compiler::gtNewArithSeries(unsigned argNum, var_types argTyp)
{
    GenTreePtr      tree;

    tree = gtNewOperNode(GT_ADD, argTyp, gtNewLclvNode(argNum, argTyp),
                                         gtNewIconNode(1, argTyp));
    tree = gtNewOperNode(GT_MUL, argTyp, gtNewLclvNode(argNum, argTyp),
                                         tree);
    tree = gtNewOperNode(GT_RSH, argTyp, tree,
                                         gtNewIconNode(1, argTyp));

    return  tree;
}

/*****************************************************************************
 *
 *  Converts recursive methods into iterative ones whenever possible.
 */

void                Compiler::optOptimizeRecursion()
{
    BasicBlock  *   blk0;
    BasicBlock  *   blk1;
    BasicBlock  *   blk2;
    BasicBlock  *   blk3;

    unsigned        argNum;
    var_types       argTyp;

    GenTreePtr      expTmp;
    GenTreePtr      asgTmp;

    GenTreePtr      tstIni;
    GenTreePtr      cnsIni;
    GenTreePtr      tstExp;
    GenTreePtr      cnsLim;
    GenTreePtr      expRet;
    GenTreePtr      expAdd;
    GenTreePtr      argAdd;
    GenTreePtr      cnsAdd;

    union
    {
        long            intVal;
        float           fltVal;
        __int64         lngVal;
        double          dblVal;
    }
                    iniVal, limVal, addVal;

    unsigned        resTmp;
    bool            isArith;
    genTreeOps      expOp;

    /* Check for a flow graph that looks promising */

    if  (fgBBcount != 3)
        return;

    blk1 = fgFirstBB;
    blk2 = blk1->bbNext;
    blk3 = blk2->bbNext; assert(blk3->bbNext == NULL);

    if  (blk1->bbJumpKind != BBJ_COND  ) return;
    if  (blk1->bbJumpDest != blk3      ) return;
    if  (blk2->bbJumpKind != BBJ_RETURN) return;
    if  (blk3->bbJumpKind != BBJ_RETURN) return;

    /* Check argument count and figure out index of first real arg */

    argNum = 0;
    if (!info.compIsStatic)
        argNum++;

    if  (info.compArgsCount < argNum+1)
        return;

    // CONSIDER: Allow the second and third blocks to be swapped.

    /* Second block must be "return cnsIni" */

    tstIni = blk2->bbTreeList; assert(tstIni->gtOper == GT_STMT);
    tstIni = tstIni->gtStmt.gtStmtExpr;
    if  (tstIni->gtOper != GT_RETURN)
        return;
    cnsIni = tstIni->gtOp.gtOp1;
    if  (!cnsIni || !(cnsIni->OperKind() & GTK_CONST))
        return;

    /* First block must be "if (arg1 <relop> cnsLim)" */

    tstExp = blk1->bbTreeList; assert(tstExp->gtOper == GT_STMT);
    tstExp = tstExp->gtStmt.gtStmtExpr;
    if  (tstExp->gtOper != GT_JTRUE)
        return;
    tstExp = tstExp->gtOp.gtOp1;
    if  (!(tstExp->OperKind() & GTK_RELOP))
        return;

    expTmp = tstExp->gtOp.gtOp1;
    if  (expTmp->gtOper != GT_LCL_VAR)
        return;
    if  (expTmp->gtLclVar.gtLclNum != argNum)
        return;

    cnsLim = tstExp->gtOp.gtOp2;
    if  (!(cnsLim->OperKind() & GTK_CONST))
        return;

    /* Third block must be "return arg1 <add/mul> f(arg1 +/- cnsAdd)" */

    expRet = blk3->bbTreeList; assert(expRet->gtOper == GT_STMT);
    expRet = expRet->gtStmt.gtStmtExpr;
    if  (expRet->gtOper != GT_RETURN)
        return;
    expAdd = expRet->gtOp.gtOp1;

    /* Inspect the return expression */

    switch (expAdd->gtOper)
    {
    case GT_ADD:
        expOp = GT_ASG_ADD;
        break;
    case GT_MUL:
        expOp = GT_ASG_MUL;
        break;

    default:
        return;
    }

    /* Look for "arg1" on either side of the operation */

    expTmp = expAdd->gtOp.gtOp1;
    cnsAdd = expAdd->gtOp.gtOp2;

    if  (expTmp->gtOper != GT_LCL_VAR)
    {
        /* Try it the other way around */

        expTmp = expAdd->gtOp.gtOp2;
        cnsAdd = expAdd->gtOp.gtOp1;

        if  (expTmp->gtOper != GT_LCL_VAR)
            return;
    }

    if  (expTmp->gtLclVar.gtLclNum != argNum)
        return;

    /* The other operand must be a directly recursive call */

    if  (cnsAdd->gtOper != GT_CALL)
        return;
    if  (cnsAdd->gtFlags & (GTF_CALL_VIRT|GTF_CALL_INTF))
        return;

    gtCallTypes callType = cnsAdd->gtCall.gtCallType;
    if  (callType == CT_HELPER || !eeIsOurMethod(cnsAdd->gtCall.gtCallMethHnd))
        return;

    /* If the method is not static, check the 'this' value */

    if  (cnsAdd->gtCall.gtCallObjp)
    {
        if  (cnsAdd->gtCall.gtCallObjp->gtOper != GT_LCL_VAR)   return;
        if  (cnsAdd->gtCall.gtCallObjp->gtLclVar.gtLclNum != 0) return;
    }

    /* There must be at least one argument */

    argAdd = cnsAdd->gtCall.gtCallArgs; assert(argAdd && argAdd->gtOper == GT_LIST);
    argAdd = argAdd->gtOp.gtOp1;

    /* Inspect the argument value */

    switch (argAdd->gtOper)
    {
    case GT_ADD:
    case GT_SUB:
        break;

    default:
        return;
    }

    /* Look for "arg1" on either side of the operation */

    expTmp = argAdd->gtOp.gtOp1;
    cnsAdd = argAdd->gtOp.gtOp2;

    if  (expTmp->gtOper != GT_LCL_VAR)
    {
        if  (argAdd->gtOper != GT_ADD)
            return;

        /* Try it the other way around */

        expTmp = argAdd->gtOp.gtOp2;
        cnsAdd = argAdd->gtOp.gtOp1;

        if  (expTmp->gtOper != GT_LCL_VAR)
            return;
    }

    if  (expTmp->gtLclVar.gtLclNum != argNum)
        return;

    /* Get hold of the adjustment constant */

    if  (!(cnsAdd->OperKind() & GTK_CONST))
        return;

    /* Make sure all the constants have the same type */

    argTyp = cnsAdd->TypeGet();

    if  (argTyp != cnsLim->gtType)
        return;
    if  (argTyp != cnsIni->gtType)
        return;

    switch (argTyp)
    {
    case TYP_INT:

        iniVal.intVal = cnsIni->gtIntCon.gtIconVal;
        limVal.intVal = cnsLim->gtIntCon.gtIconVal;
        addVal.intVal = cnsAdd->gtIntCon.gtIconVal;

        if  (argAdd->gtOper == GT_SUB)
            addVal.intVal = -addVal.intVal;

        break;

    default:
        // CONSIDER: Allow types other than 'int'
        return;
    }

#ifdef  DEBUG

    if  (verbose)
    {
        fgDispBasicBlocks(true);

        printf("\n");
        printf("Unrecursing method '%s':\n", info.compMethodName);
        printf("    Init  value = %d\n", iniVal.intVal);
        printf("    Limit value = %d\n", limVal.intVal);
        printf("    Incr. value = %d\n", addVal.intVal);

        printf("\n");
    }

#endif

    /*
        We have a method with the following definition:

            int     rec(int arg, ....)
            {
                if  (arg == limVal)
                    return  iniVal;
                else
                    return  arg + rec(arg + addVal, ...);
            }

        We'll change the above into the following:

            int     rec(int arg, ....)
            {
                int     res = iniVal;

                while (arg != limVal)
                {
                    res += arg;
                    arg += addVal;
                }

                return  res;
            }

        But first, let's check for the following special case:

            int     rec(int arg)
            {
                if  (arg <= 0)
                    return  0;
                else
                    return  arg + rec(arg - 1);
            }

        The above can be transformed into the following:

            int     rec(int arg)
            {
                if  (arg <= 0)
                    return  0;
                else
                    return  (arg * (arg + 1)) / 2;
            }

        We check for this special case first.
     */

    isArith = false;

    if  (argTyp == TYP_INT && iniVal.intVal == 0
                           && limVal.intVal == 0
                           && addVal.intVal == -1)
    {
        if  (tstExp->gtOper != GT_LE)
        {
            if  (tstExp->gtOper == GT_NE)
                isArith = true;

            goto NOT_ARITH;
        }

        /* Simply change the final return statement and we're done */

        assert(expRet->gtOper == GT_RETURN);

        expRet->gtOp.gtOp1 = gtNewArithSeries(argNum, argTyp);

        return;
    }

NOT_ARITH:

    /* Create an initialization block with "tmp = iniVal" */

    resTmp = lvaGrabTemp();
    expTmp = gtNewTempAssign(resTmp, gtNewIconNode(iniVal.intVal, argTyp));

    /* Prepend a block with the tree to our method */

    blk0 = fgPrependBB(expTmp);

    /* Flip the condition on the first block */

    assert(tstExp->OperKind() & GTK_RELOP);
    tstExp->gtOper = GenTree::ReverseRelop(tstExp->OperGet());

    /* Now replace block 2 with "res += arg ; arg += addVal" */

    expTmp = gtNewLclvNode(resTmp, argTyp); expTmp->gtFlags |= GTF_VAR_DEF;

    if (expOp == GT_ASG_ADD)
    {
        expTmp = gtNewOperNode(GT_ASG_ADD, argTyp, expTmp,
                                               gtNewLclvNode(argNum, argTyp));
    }
    else
    {
        //UNDONE: Unfortunately the codegenerator cannot digest
        //        GT_ASG_MUL, so we have to generate a bigger tree.

        GenTreePtr op1;
        op1    = gtNewOperNode(GT_MUL, argTyp, gtNewLclvNode(argNum, argTyp),
                                               gtNewLclvNode(resTmp, argTyp));
        expTmp = gtNewAssignNode(expTmp, op1);
    }

    expTmp->gtFlags |= GTF_ASG;
    expTmp = gtNewStmt(expTmp);

    asgTmp = gtNewLclvNode(argNum, argTyp); asgTmp->gtFlags |= GTF_VAR_DEF;
    asgTmp = gtNewOperNode(GT_ASG_ADD, argTyp, asgTmp,
                                               gtNewIconNode(addVal.intVal, argTyp));
    asgTmp->gtFlags |= GTF_ASG;
    asgTmp = gtNewStmt(asgTmp);

    /* Store the two trees in the second block */

    blk2->bbTreeList = expTmp;

    asgTmp->gtPrev = expTmp;
    expTmp->gtNext = asgTmp;
    expTmp->gtPrev = asgTmp;

    /* Make the second block jump back to the top */

    blk2->bbJumpKind = BBJ_ALWAYS;
    blk2->bbJumpDest = blk1;

    /* Finally, change the return value of the third block to the temp */

    expRet->gtOp.gtOp1 = gtNewLclvNode(resTmp, argTyp);

    /* Special case: arithmetic series with non-negative check */

    if  (isArith)
    {
        BasicBlock  *   retBlk;
        BasicBlock  *   tstBlk;

        /* Create the "easy" return expression */

        expTmp = gtNewOperNode(GT_RETURN, argTyp, gtNewArithSeries(argNum, argTyp));

        /* Prepend the "easy" return expression to the method */

        retBlk = fgPrependBB(expTmp);
        retBlk->bbJumpKind = BBJ_RETURN;

        /* Create the test expression */

        expTmp = gtNewOperNode(GT_AND  ,  argTyp, gtNewLclvNode(argNum, argTyp),
                                                  gtNewIconNode(0xFFFF8000, argTyp));
        expTmp = gtNewOperNode(GT_NE   , TYP_INT, expTmp,
                                                  gtNewIconNode(0, TYP_INT));
        expTmp = gtNewOperNode(GT_JTRUE, TYP_INT, expTmp);

        /* Prepend the test to the method */

        tstBlk = fgPrependBB(expTmp);
        tstBlk->bbJumpKind = BBJ_COND;
        tstBlk->bbJumpDest = blk0;
    }

    /* Update the basic block numbers and refs */

    //fgAssignBBnums(true);
#ifdef  DEBUG
    fgDebugCheckBBlist();
#endif

}

/*****************************************************************************/
#endif//OPTIMIZE_RECURSION
/*****************************************************************************/



/*****************************************************************************/
#if CODE_MOTION
/*****************************************************************************
 *
 *  For now, we only remove entire worthless loops.
 */

#define RMV_ENTIRE_LOOPS_ONLY    1

/*****************************************************************************
 *
 *  Remove the blocks from 'head' (inclusive) to 'tail' (exclusive) from
 *  the flow graph.
 */

void                genRemoveBBsection(BasicBlock *head, BasicBlock *tail)
{
    BasicBlock *    block;

    VARSET_TP       liveExit = tail->bbLiveIn;

    for (block = head; block != tail; block = block->bbNext)
    {
        block->bbLiveIn   =
        block->bbLiveOut  = liveExit;

        block->bbTreeList = 0;
        block->bbJumpKind = BBJ_NONE;
        block->bbFlags   |= BBF_REMOVED;
    }
}

/*****************************************************************************
 *
 *  Tree walker used by loop code motion. Returns non-zero if the expression
 *  is not acceptable for some reason.
 */

bool                Compiler::optFindLiveRefs(GenTreePtr tree, bool used, bool cond)
{
    genTreeOps      oper;
    unsigned        kind;

AGAIN:

    assert(tree);
    assert(tree->gtOper != GT_STMT);

    /* Figure out what kind of a node we have */

    oper = tree->OperGet();
    kind = tree->OperKind();

    /* Is this a constant or leaf node? */

    if  (kind & (GTK_CONST|GTK_LEAF))
    {
        if  (oper == GT_LCL_VAR)
        {
            unsigned        lclNum;
            LclVarDsc   *   varDsc;

            assert(tree->gtOper == GT_LCL_VAR);
            lclNum = tree->gtLclVar.gtLclNum;

            assert(lclNum < lvaCount);
            varDsc = lvaTable + lclNum;

            /* Give up if volatile or untracked variable */

            if  (varDsc->lvVolatile || !varDsc->lvTracked)
                return  true;

            /* Mark the use of this variable, if appropriate */

#if !RMV_ENTIRE_LOOPS_ONLY
            if  (used) optLoopLiveExit |= genVarIndexToBit(varDsc->lvVarIndex);
            if  (cond) optLoopCondTest |= genVarIndexToBit(varDsc->lvVarIndex);
#endif
        }
//      else if (oper == GT_CLS_VAR)
//      {
//          return  true;
//      }

        return  false;
    }

    /* Is it a 'simple' unary/binary operator? */

    if  (kind & GTK_SMPOP)
    {
        if  (tree->gtOp.gtOp2)
        {
            /* It's a binary operator; is it an assignment? */

            if  (kind & GTK_ASGOP)
            {
                unsigned        lclNum;
                LclVarDsc   *   varDsc;
                VARSET_TP       varBit;

                GenTreePtr      dest = tree->gtOp.gtOp1;

                /* The target better be a variable */

                if  (dest->gtOper != GT_LCL_VAR)
                    return  true;

                /* Is the target variable in the 'live exit' set? */

                assert(dest->gtOper == GT_LCL_VAR);
                lclNum = dest->gtLclVar.gtLclNum;

                assert(lclNum < lvaCount);
                varDsc = lvaTable + lclNum;

                /* Give up if volatile or untracked variable */

                if  (varDsc->lvVolatile || !varDsc->lvTracked)
                    return  true;

                varBit = genVarIndexToBit(varDsc->lvVarIndex);

                /* Keep track of all assigned variables */

                optLoopAssign |= varBit;

                /* Is the variable live on exit? */

                if  (optLoopLiveExit & varBit)
                {
#if !RMV_ENTIRE_LOOPS_ONLY
                    /* The value assigned to this variable is useful */

                    used = true;

                    /* This assignment could depend on a condition */

                    optLoopLiveExit |= optLoopCondTest;
#else
                    /* Assignment is useful - loop is not worthless */

                    return  true;
#endif
                }
            }
            else
            {
                if  (optFindLiveRefs(tree->gtOp.gtOp1, used, cond))
                    return  true;
            }

            tree = tree->gtOp.gtOp2; assert(tree);
            goto AGAIN;
        }
        else
        {
            /* It's a unary (or nilary) operator */

            tree = tree->gtOp.gtOp1;
            if  (tree)
                goto AGAIN;

            return  false;
        }
    }

    /* We don't allow any 'special' operators */

    return  true;
}


/*****************************************************************************
 *
 *  Perform loop code motion / worthless code removal.
 */
void                Compiler::optLoopCodeMotion()
{
    unsigned        loopNum;
    unsigned        loopCnt;
    unsigned        loopSkp;

    LOOP_MASK_TP    loopRmv;
    LOOP_MASK_TP    loopBit;

    bool            repeat;

#ifdef DEBUG
#ifndef _WIN32_WCE
// @todo - The following static was changed due to the fact that
//         VC7 generates eh code for procedure local statics that
//         call functions to initialize. This causes our __try to generate a compile error.
//         When the next VC7 LKG comes out, hopefully we can return to the cleaner code
//    static  const   char *  noLoop = getenv("NOCODEMOTION");
    static char * noLoop = NULL;
    static bool initnoLoop = true;
    if (initnoLoop) {
        noLoop = getenv("NOCODEMOTION");
        initnoLoop = false;
    }
    if (noLoop) return;
#endif
#endif

    /* Process all loops, looking for worthless code that can be removed */

    loopRmv = 0;
    loopCnt = 0;
    loopSkp = 1;

AGAIN:

    do
    {
        repeat = false;

        for (loopNum = 0, loopBit = 1;
             loopNum < optLoopCount;
             loopNum++  , loopBit <<= 1)
        {
            BasicBlock *    block;
            GenTreePtr      tree;

#if !RMV_ENTIRE_LOOPS_ONLY
            VARSET_TP       liveExit;
            VARSET_TP       loopCond;
#endif

            /* Some loops may have been already removed by loop unrolling */

            if (optLoopTable[loopNum].lpFlags & LPFLG_REMOVED)
                continue;

            BasicBlock *    head   = optLoopTable[loopNum].lpHead->bbNext;
            BasicBlock *    bottom = optLoopTable[loopNum].lpEnd;
            BasicBlock *    tail   = bottom->bbNext;

            /* Skip the loop if it's already been removed or
             * if it's at the end of the method (while("true"){};)
             * or if it's a nested loop and the outer loop was
             * removed first - can happen in stupid benchmarks like LoopMark */

            if  ((loopRmv & loopBit)     ||
                 tail == 0               ||
                 head->bbTreeList == 0    )
            {
                continue;
            }

            /* get the loop condition - if not a conditional jump bail */

            if (bottom->bbJumpKind != BBJ_COND)
                continue;

            GenTreePtr      cond   = bottom->bbTreeList->gtPrev->gtStmt.gtStmtExpr;
            assert (cond->gtOper == GT_JTRUE);

            /* check if a simple termination condition - operands have to be leaves */

            GenTreePtr         op1 = cond->gtOp.gtOp1->gtOp.gtOp1;
            GenTreePtr         op2 = cond->gtOp.gtOp1->gtOp.gtOp2;

            GenTreePtr keepStmtList = 0;                    // list with statements we will keep
            GenTreePtr keepStmtLast = 0;

            if ( !(op1->OperIsLeaf() || op2->OperIsLeaf()) )
                continue;

            /* Make sure no side effects other than assignments are present */

            for (block = head; block != tail; block = block->bbNext)
            {
                for (tree = block->bbTreeList; tree; tree = tree->gtNext)
                {
                    GenTreePtr      stmt = tree->gtStmt.gtStmtExpr;

                    /* We must not remove return or side-effect statements */

                    if  (stmt->gtOper != GT_RETURN                        &&
                         !(stmt->gtFlags & (GTF_SIDE_EFFECT & ~GTF_ASG))  )
                    {
                        /* If a statement is a comparisson marked GLOBAL
                         * it must be the loop condition */

                        if (stmt->gtOper == GT_JTRUE)
                        {
                            if (stmt->gtFlags & GTF_GLOB_REF)
                            {
                                /* must be the loop condition */

                                if (stmt != cond)
                                {
                                    loopRmv |= loopBit;
                                    goto NEXT_LOOP;
                                }
                            }
                        }

                        /* Does the statement contain an assignment? */

                        if  (!(stmt->gtFlags & GTF_ASG))
                            continue;

                        /* Don't remove assignments to globals */

                        if  (!(stmt->gtFlags & GTF_GLOB_REF))
                            continue;

                        /* It's OK if the global is only in the RHS */

                        if  (stmt->OperKind() & GTK_ASGOP)
                        {
                            GenTreePtr  dst = stmt->gtOp.gtOp1;
                            GenTreePtr  src = stmt->gtOp.gtOp2;

                            /* The RHS must not have another assignment */

                            if  (!(dst->gtFlags & GTF_GLOB_REF) &&
                                 !(src->gtFlags & GTF_ASG))
                            {
                                continue;
                            }
                        }
                    }

                    /* Don't waste time with this loop any more */

                    loopRmv |= loopBit;
                    goto NEXT_LOOP;
                }
            }

            /* We have a candidate loop */

#ifdef  DEBUG

            if  (verbose)
            {
                printf("Candidate loop for worthless code removal:\n");

                for (block = head; block != tail; block = block->bbNext)
                {
                    printf("Block #%02u:\n", block->bbNum);

                    for (tree = block->bbTreeList; tree; tree = tree->gtNext)
                    {
                        gtDispTree(tree->gtStmt.gtStmtExpr, 0);
                        printf("\n");
                    }
                    printf("\n");
                }
                printf("This is currently busted because the dominators are out of synch - Skip it!\nThe whole thing should be combined with loop invariants\n");
            }

#endif

            /* This is currently busted because the dominators are out of synch
             * The whole thing should be combined with loop invariants */

            goto NEXT_LOOP;


            /* Get hold of the set of variables live on exit from the loop */

            optLoopLiveExit = tail->bbLiveIn;

            /* Keep track of what variables are being assigned in the loop */

            optLoopAssign   = 0;

            /* Keep track of what variables are being assigned in the loop */

#if !RMV_ENTIRE_LOOPS_ONLY
            optLoopCondTest = 0;
#endif

            /*
                Find variables assigned in the loop that are used to compute
                any values that are live on exit. We repeat this until we
                don't find any more variables to add to the set.
             */

#if !RMV_ENTIRE_LOOPS_ONLY
            do
            {
                liveExit = optLoopLiveExit;
                loopCond = optLoopCondTest;
#endif

                for (block = head; block != tail; block = block->bbNext)
                {
                    /* Make sure the block is of an acceptable kind */

                    switch (block->bbJumpKind)
                    {
                    case BBJ_ALWAYS:
                    case BBJ_COND:

                        /* Since we are considering only loops with a single loop condition
                         * the only backward edge allowed is the loop jump (from bottom to top) */

                        if (block->bbJumpDest->bbNum <= block->bbNum)
                        {
                            /* we have a backward edge */

                            if ((block != bottom) && (block->bbJumpDest != head))
                                goto NEXT_LOOP;
                        }

                        /* fall through */

                    case BBJ_NONE:
                    case BBJ_THROW:
                    case BBJ_RETURN:
                        break;

                    case BBJ_RET:
                    case BBJ_CALL:
                    case BBJ_SWITCH:
                        goto NEXT_LOOP;
                    }

                    /* Check all statements in the block */

                    for (tree = block->bbTreeList; tree; tree = tree->gtNext)
                    {
                        GenTreePtr      stmt = tree->gtStmt.gtStmtExpr;

#if !RMV_ENTIRE_LOOPS_ONLY
                        if (stmt->gtOper == GT_JTRUE)
                        {
                            /* The condition might affect live variables */

                            if  (optFindLiveRefs(stmt, false,  true))
                            {
                                /* An unacceptable tree was detected; give up */

                                goto NEXT_LOOP;
                            }
                        }
                        else
#endif
                        if  (stmt->gtFlags & GTF_ASG)
                        {
                            /* There is an assignment - look for more live refs */

                            if  (optFindLiveRefs(stmt, false, false))
                            {
                                /* An unacceptable tree was detected; give up */

                                goto NEXT_LOOP;
                            }
                        }
                    }
                }
#if !RMV_ENTIRE_LOOPS_ONLY
            }
            while (liveExit != optLoopLiveExit || loopCond != optLoopCondTest);
#endif

#ifdef  DEBUG

            if  (verbose)
            {
                printf("Loop [%02u..%02u]", head->bbNum, tail->bbNum - 1);
                printf(" exit="); lvaDispVarSet(optLoopLiveExit, 28);
                printf(" assg="); lvaDispVarSet(optLoopAssign  , 28);
                printf("\n");
            }

#endif

            /* The entire loop seems totally worthless but we can only throw away
             * the loop body since at this point we cannot guarantee the loop is not infinite */

            /* UNDONE: So far we only consider while-do loops with only one condition - Expand the logic
             * UNDONE: to allow multiple conditions, but mark the one condition loop as special cause
             * UNDONE: we can do a lot of optimizations with them */

            /* the last statement in the loop has to be the conditional jump */

            assert (bottom->bbJumpKind == BBJ_COND);
            assert (cond->gtOper == GT_JTRUE);

            unsigned        lclNum;
            LclVarDsc   *   varDsc;
            unsigned        varIndex;
            VARSET_TP       bitMask;

            unsigned        rhsLclNum;
            VARSET_TP       rhsBitMask;

            /* find who's who - the loop condition has to be a simple comparisson
             * between locals and/or constants */

            if (op2->OperKind() & GTK_CONST)
            {
                /* op1 must be a local var, otherwise we bail */

                if (op1->gtOper != GT_LCL_VAR)
                    goto NEXT_LOOP;

                lclNum = op1->gtLclVar.gtLclNum;

                /* UNDONE: this is a special loop that iterates a KNOWN constant
                 * UNDONE: number of times (provided we can later tell if the iterator
                 * UNDONE: is i++ (or similar) - treat this case separately */
            }
            else
            {
                /* if op2 not a local var quit */

                if (op2->gtOper != GT_LCL_VAR)
                    goto NEXT_LOOP;

                /* op1 has to be either constant or local var
                 * if constant things are simple */

                if (op1->OperKind() & GTK_CONST)
                {
                    /* here is our iterator */
                    lclNum = op2->gtLclVar.gtLclNum;
                }
                else if (op1->gtOper == GT_LCL_VAR)
                {
                    /* special case - both are local vars
                     * check if one of them is not assigned in the loop
                     * then the other one is the iterator */

                    lclNum = op1->gtLclVar.gtLclNum;
                    assert(lclNum < lvaCount);
                    varDsc = lvaTable + lclNum;
                    varIndex = varDsc->lvVarIndex;
                    assert(varIndex < lvaTrackedCount);
                    bitMask  = genVarIndexToBit(varIndex);

                    rhsLclNum = op2->gtLclVar.gtLclNum;
                    assert(rhsLclNum < lvaCount);
                    varDsc = lvaTable + rhsLclNum;
                    varIndex = varDsc->lvVarIndex;
                    assert(varIndex < lvaTrackedCount);
                    rhsBitMask  = genVarIndexToBit(varIndex);

                    if (optLoopAssign & bitMask)
                    {
                        /* op1 is assigned in the loop */

                        if (optLoopAssign & rhsBitMask)
                        {
                            /* both are assigned in the loop - bail */
                            goto NEXT_LOOP;
                        }

                        /* op1 is our iterator - already catched by lclNum */
                    }
                    else
                    {
                        /* op2 must be the iterator  - check that is asigned in the loop
                         * otherwise we have a loop that is probably infinite */

                        if (optLoopAssign & rhsBitMask)
                        {
                            lclNum = rhsLclNum;
                        }
                        else
                        {
                            /* none is assigned in the loop !!!
                             * so they are both "constants" - better not worry about this loop */
                            goto NEXT_LOOP;
                        }
                    }
                }
                else
                    goto NEXT_LOOP;
            }

            /* we have the loop iterator - it has to be a tracked and
               non volatile variable (checked by optFindLiveRefs) */

            assert(lclNum < lvaCount);
            varDsc = lvaTable + lclNum;
            assert ((varDsc->lvTracked && !varDsc->lvVolatile));

            varIndex = varDsc->lvVarIndex;
            assert(varIndex < lvaTrackedCount);
            bitMask  = genVarIndexToBit(varIndex);

            /* we can remove the whole body of the loop except the
             * statements that control the iterator and the loop test */

            /* We'll create a list to hold these statements and attach it
             * to the last BB in the list and remove the other BBs */

            for (block = head; block != tail; block = block->bbNext)
            {
                /* Check all statements in the block */

                for (GenTreePtr stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
                {
                    assert (stmt->gtOper == GT_STMT);

                    /* look for assignments */

                    if ((stmt->gtStmt.gtStmtExpr->gtFlags & GTF_ASG) == 0)
                        continue;

                    for (tree = stmt->gtStmt.gtStmtList; tree; tree = tree->gtNext)
                    {
                        /* we only look for assignments that are at the top node
                         * if an assignment to the iterator is made in a subtree we bail */

                        if  (tree->OperKind() & GTK_ASGOP)
                        {
                            /* Look for assignments to the iterator */

                            GenTreePtr      iterVar = tree->gtOp.gtOp1;

                            if (iterVar->gtOper == GT_LCL_VAR)
                            {
                                /* check if this is the iterator */

                                if (iterVar->gtLclVar.gtLclNum == lclNum)
                                {
                                    /* make sure we are at the top of the tree */
                                    /* also require that the iterator is a GTF_VAR_USE */

                                    if ((tree->gtNext != 0) || ((iterVar->gtFlags & GTF_VAR_USE) == 0))
                                        goto NEXT_LOOP;

                                    /* this is the iterator - make sure it is in a block
                                     * that dominates the loop bottom */

                                    if ( !B1DOMSB2(block, bottom) )
                                    {
                                        /* iterator is conditionally updated - too complicated to track */
                                        goto NEXT_LOOP;
                                    }

                                    /* require that the RHS is either a constant or
                                       a local var not assigned in the loop */

                                    if (tree->gtOp.gtOp2->OperKind() & GTK_CONST)
                                        goto ITER_STMT;

                                    if (tree->gtOp.gtOp2->gtOper == GT_LCL_VAR)
                                    {
                                        rhsLclNum = tree->gtOp.gtOp2->gtLclVar.gtLclNum;

                                        assert(rhsLclNum < lvaCount);
                                        varDsc = lvaTable + rhsLclNum;

                                        varIndex = varDsc->lvVarIndex;
                                        assert(varIndex < lvaTrackedCount);
                                        rhsBitMask  = genVarIndexToBit(varIndex);

                                        if (optLoopAssign & rhsBitMask)
                                        {
                                            /* variable is assigned in the loop - bail */

                                            goto NEXT_LOOP;
                                        }

ITER_STMT:
                                        /* everything OK - add this statement to the list of
                                         * statements we won't throw away */

                                        assert(stmt->gtOper == GT_STMT);

                                        if (keepStmtList)
                                        {
                                            /* we already have statements in the list - append the new statement */

                                            assert(keepStmtLast);

                                            /* Point 'prev' at the previous node, so that we can walk backwards */

                                            stmt->gtPrev = keepStmtLast;

                                            /* Append the expression statement to the list */

                                            keepStmtLast->gtNext = stmt;
                                            keepStmtLast         = stmt;
                                        }
                                        else
                                        {
                                            /* first statement in the list */

                                            assert(keepStmtLast == 0);
                                            keepStmtList = keepStmtLast = stmt;
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }

            /* check if we found any valid iterators in the loop */

            if (keepStmtList)
            {
                /* append the termination condition */

                GenTreePtr condStmt = bottom->bbTreeList->gtPrev;
                assert(condStmt->gtOper == GT_STMT);

                assert(keepStmtLast);
                condStmt->gtPrev = keepStmtLast;
                keepStmtLast->gtNext = condStmt;

                /* Make the list circular, so that we can easily walk it backwards */

                keepStmtList->gtPrev =  condStmt;
            }
            else
            {
                /* bail */

                goto NEXT_LOOP;
            }

            /* the loop will now consist of only the last BB with the new list of statements */

            genRemoveBBsection(head, bottom);

            /* bottom is the last and only block in the loop - store the new tree list */

            bottom->bbTreeList = keepStmtList;

            /* make it jump to itself */

            assert (bottom->bbJumpKind == BBJ_COND);
            bottom->bbJumpDest = bottom;

#ifdef  DEBUG
            if  (verbose)
            {
                printf("Partially worthless loop found [%02u..%02u]\n", head->bbNum, tail->bbNum - 1);
                printf("Removing the body of the loop and keeping the loop condition:\n");

                printf("New loop condition block #%02u:\n", block->bbNum);

                for (tree = bottom->bbTreeList; tree; tree = tree->gtNext)
                {
                    gtDispTree(tree->gtStmt.gtStmtExpr, 0);
                    printf("\n");
                }

                printf("\n");
            }
#endif

            /* Mark the loop as removed and force another pass */

            loopRmv |= loopBit;
            repeat   = true;

        NEXT_LOOP:;

        }
    }
    while (repeat);

    if  (optLoopCount == 16 && loopSkp == 1 && loopCnt == 14)
    {
        loopSkp = -1;
        goto AGAIN;
    }
}

/*****************************************************************************/
#endif // CODE_MOTION
/*****************************************************************************/
#if HOIST_THIS_FLDS
/*****************************************************************************/

void                Compiler::optHoistTFRinit()
{
    optThisFldLst  = 0;
    optThisFldCnt  = 0;
    optThisFldLoop = false;
    optThisFldDont = true;
    optThisPtrModified = false;

    if  (opts.compMinOptim)
        return;

    if (info.compIsStatic)
        return;

    optThisFldDont = false;
}


Compiler::thisFldPtr      Compiler::optHoistTFRlookup(FIELD_HANDLE hnd)
{
    thisFldPtr      fld;

    for (fld = optThisFldLst; fld; fld = fld->tfrNext)
    {
        if  (fld->tfrField == hnd)
            return  fld;
    }

    fld = (thisFldPtr)compGetMem(sizeof(*fld));

    fld->tfrField   = hnd;
    fld->tfrIndex   = ++optThisFldCnt;

    fld->tfrUseCnt  = 0;
    fld->tfrDef     = 0;
    fld->tfrTempNum = 0;

#ifndef NDEBUG
    fld->optTFRHoisted = false;
#endif

    fld->tfrNext    = optThisFldLst;
                      optThisFldLst = fld;

    return  fld;
}


void                Compiler::optHoistTFRprep()
{
    thisFldPtr      fld;
    BasicBlock *    blk;
    GenTreePtr      lst;
    GenTreePtr      beg;

    assert(fgFirstBB);

    if  (optThisFldDont)
        return;

    if  (optThisFldLoop == false)
    {
        optThisFldDont = true;
        return;
    }

    for (fld = optThisFldLst, blk = 0; fld; fld = fld->tfrNext)
    {
        unsigned        tmp;
        GenTreePtr      val;
        GenTreePtr      asg;

        assert(fld->optTFRHoisted == false);

//      printf("optHoist candidate [handle=%08X,refcnt=%02u]\n", fld->tfrField, fld->tfrUseCnt);

#if INLINING
        assert(fld->tfrTree->gtOper == GT_FIELD);
        assert(eeGetFieldClass(fld->tfrTree->gtField.gtFldHnd) == eeGetMethodClass(info.compMethodHnd));
#endif

        /* If this field has been assigned, forget it */

        if  (fld->tfrDef)
            continue;

        /* If the use count is not high enough, forget it */

        if  (fld->tfrUseCnt < 1)
        {
            /* Mark the field as off limits for later logic */

            fld->tfrDef = true;
            continue;
        }

#ifndef NDEBUG
        fld->optTFRHoisted = true;
#endif

        /* Make sure we've allocated the initialization block */

        if  (!blk)
        {
            /* Allocate the block descriptor */

            blk = bbNewBasicBlock(BBJ_NONE);

            /* Make sure the block doesn't get thrown away! */

            blk->bbFlags |= (BBF_IMPORTED | BBF_INTERNAL);

            /* Prepend the block to the global basic block list */

            blk->bbNext = fgFirstBB;
                          fgFirstBB = blk;

            /* We don't have any trees yet */

            lst = 0;
        }

        /* Grab a temp for this field */

        fld->tfrTempNum = tmp = lvaGrabTemp();

        /* Remember the cloned value so that we don't replace it */

        val = fld->tfrTree = gtClone(fld->tfrTree, true);

        assert(val->gtOper == GT_FIELD);
        assert(val->gtOp.gtOp1->gtOper == GT_LCL_VAR &&
               val->gtOp.gtOp1->gtLclVar.gtLclNum == 0);

        /* Create an assignment to the temp */

        asg = gtNewStmt();
        asg->gtStmt.gtStmtExpr = gtNewTempAssign(tmp, val);

        /* make sure the right flags are passed on to the temp */

        // asg->gtStmt.gtStmtExpr->gtOp.gtOp1->gtFlags |= val->gtFlags & GTF_GLOB_EFFECT;

#ifdef  DEBUG

        if  (verbose)
        {
            printf("\nHoisted field ref [handle=%08X,refcnt=%02u]\n", fld->tfrField, fld->tfrUseCnt);
            gtDispTree(asg);
        }

#endif

        /* Prepend the assignment to the list */

        asg->gtPrev = lst;
        asg->gtNext = 0;

        if  (lst)
            lst->gtNext = asg;
        else
            beg         = asg;

        lst = asg;
    }

    /* Have we added a basic block? */

    if  (blk)
    {
        /* Store the assignment statement list in the block */

        blk->bbTreeList = beg;

        /* Point the "prev" field of first entry to the last one */

        beg->gtPrev = lst;

        /* Update the basic block numbers */

        fgAssignBBnums(true);
    }
    else
    {
        /* We didn't hoist anything, so pretend nothing ever happened */

        optThisFldDont = true;
    }
}



/*****************************************************************************/
#endif//HOIST_THIS_FLDS
/*****************************************************************************/

/******************************************************************************
 * Function used by folding of boolean conditionals
 * Given a GT_JTRUE node, checks that it is a boolean comparisson of the form "if (bool)"
 * This is translated into a GT_GE node with "op1" a boolean lclVar and "op2" the const 0
 * In valPtr returns "true" if the node is GT_NE (jump true) or false if GT_EQ (jump false)
 * In compPtr returns the compare node (i.e. GT_GE or GT_NE node)
 * If all the above conditions hold returns the comparand (i.e. the local var node)
 */

GenTree *           Compiler::optIsBoolCond(GenTree *   cond,
                                            GenTree * * compPtr,
                                            bool      * valPtr)
{
    GenTree *       opr1;
    GenTree *       opr2;

    assert(cond->gtOper == GT_JTRUE);
    opr1 = cond->gtOp.gtOp1;

    /* The condition must be "!= 0" or "== 0" */

    switch (opr1->gtOper)
    {
    case GT_NE:
        *valPtr =  true;
        break;

    case GT_EQ:
        *valPtr = false;
        break;

    default:
        return  0;
    }

    /* Return the compare node to the caller */

    *compPtr = opr1;

    /* Get hold of the comparands */

    opr2 = opr1->gtOp.gtOp2;
    opr1 = opr1->gtOp.gtOp1;

    if  (opr2->gtOper != GT_CNS_INT)
        return  0;
    if  (opr2->gtIntCon.gtIconVal != 0)
        return  0;

    /* Make sure the value is boolean
     * We can either have a boolean expression (marked GTF_BOOLEAN) or
     * a local variable that is marked as being boolean (lvNotBoolean) */

    if  (!(opr1->gtFlags & GTF_BOOLEAN))
    {
        LclVarDsc   *   varDsc;
        unsigned        lclNum;

        /* Not a boolean expression - must be a boolean local variable */

        if  (opr1->gtOper != GT_LCL_VAR)
            return 0;

        /* double check */

        lclNum = opr1->gtLclVar.gtLclNum;

        assert(lclNum < lvaCount);
        varDsc = lvaTable + lclNum;

        if  (varDsc->lvNotBoolean)
            return 0;

        /* everything OK, return the comparand */

        return opr1;
    }
    else
    {
        /* this is a boolean expression - return the comparand */

        return opr1;
    }
}

void                Compiler::optOptimizeBools()
{
    bool            change;
    bool            condFolded = false;

#ifdef  DEBUG
    fgDebugCheckBBlist();
#endif

    do
    {
        BasicBlock   *  b1;
        BasicBlock   *  b2;

        change = false;

        for (b1 = fgFirstBB; b1; b1 = b1->bbNext)
        {
            GenTree *       c1;
            GenTree *       s1;
            GenTree *       t1;
            bool            v1;
            unsigned        n1 = b1->bbNum;

            GenTree *       c2;
            GenTree *       s2;
            GenTree *       t2;
            bool            v2;

            /* We're only interested in conditional jumps here */

            if  (b1->bbJumpKind != BBJ_COND)
                continue;

            /* If there is no next block, we're done */

            b2 = b1->bbNext;
            if  (!b2)
                break;

            /* The next block also needs to be a condition */

            if  (b2->bbJumpKind != BBJ_COND)
                continue;

            /* Does this block conditionally skip the following one? */

            if  (b1->bbJumpDest == b2->bbNext /*b1->bbJumpDest->bbNum == n1+2*/)
            {
                /* The second block must contain a single statement */

                s2 = b2->bbTreeList;
                if  (s2->gtPrev != s2)
                    continue;

                assert(s2->gtOper == GT_STMT); t2 = s2->gtStmt.gtStmtExpr;
                assert(t2->gtOper == GT_JTRUE);

                /* Find the condition for the first block */

                s1 = b1->bbTreeList->gtPrev;

                assert(s1->gtOper == GT_STMT); t1 = s1->gtStmt.gtStmtExpr;
                assert(t1->gtOper == GT_JTRUE);

                /* UNDONE: make sure nobody else jumps to "b2" */

                if  (b2->bbRefs > 1)
                    continue;

                // CONSIDER: Allow this for non-booleans, since testing
                //           the result of "or val1, val2" will work for
                //           all types.

                /* The b1 condition must be "if true", the b2 condition "if false" */

                c1 = optIsBoolCond(t1, &t1, &v1);
                if (v1 == false || !c1) continue;

                c2 = optIsBoolCond(t2, &t2, &v2);
                if (v2 != false || !c2) continue;

                /* The second condition must not contain side effects */

                if  (c2->gtFlags & GTF_SIDE_EFFECT)
                    continue;

                /* The second condition must not be too expensive */

                // CONSIDER: smarter heuristics

                if  (!c2->OperIsLeaf())
                    continue;

#ifdef DEBUG
                if  (verbose)
                {
                    printf("Fold boolean condition 'c1!=0' to '(c1|c2)==0' at block #%02u\n", b1->bbNum);
                    gtDispTree(s1); printf("\n");
                    printf("Block #%02u\n", b2->bbNum);
                    gtDispTree(s2);
                }
#endif
                /* Modify the first condition from "c1!=0" to "(c1|c2)==0" */

                assert(t1->gtOper == GT_NE);
                assert(t1->gtOp.gtOp1 == c1);

                t1->gtOper     = GT_EQ;
                t1->gtOp.gtOp1 = t2 = gtNewOperNode(GT_OR, TYP_INT, c1, c2);

                /* When we 'or' two booleans, the result is boolean as well */

                t2->gtFlags |= GTF_BOOLEAN;

                /* Modify the target of the conditional jump and update bbRefs and bbPreds */

                b1->bbJumpDest->bbRefs--;
                fgRemovePred(b1->bbJumpDest, b1);

                b1->bbJumpDest = b2->bbJumpDest;

                fgAddRefPred(b2->bbJumpDest, b1, true, true);

                goto RMV_NXT;
            }

            /* Does the next block conditionally jump to the same target? */

            if  (b1->bbJumpDest == b2->bbJumpDest)
            {
                /* The second block must contain a single statement */

                s2 = b2->bbTreeList;
                if  (s2->gtPrev != s2)
                    continue;

                assert(s2->gtOper == GT_STMT); t2 = s2->gtStmt.gtStmtExpr;
                assert(t2->gtOper == GT_JTRUE);

                /* Find the condition for the first block */

                s1 = b1->bbTreeList->gtPrev;

                assert(s1->gtOper == GT_STMT); t1 = s1->gtStmt.gtStmtExpr;
                assert(t1->gtOper == GT_JTRUE);

                /* UNDONE: make sure nobody else jumps to "b2" */

                if  (b2->bbRefs > 1)
                    continue;

                /* Both conditions must be "if false" */

                c1 = optIsBoolCond(t1, &t1, &v1);
                if (v1 || !c1) continue;

                c2 = optIsBoolCond(t2, &t2, &v2);
                if (v2 || !c2) continue;

                /* The second condition must not contain side effects */

                if  (c2->gtFlags & GTF_SIDE_EFFECT)
                    continue;

                /* The second condition must not be too expensive */

                // CONSIDER: smarter heuristics

                if  (!c2->OperIsLeaf())
                    continue;

#ifdef DEBUG
                if  (verbose)
                {
                    printf("Fold boolean condition 'c1==0' to '(c1&c2)==0' at block #%02u\n", b1->bbNum);
                    gtDispTree(s1); printf("\n");
                    printf("Block #%02u\n", b2->bbNum);
                    gtDispTree(s2);
                }
#endif
                /* Modify the first condition from "c1==0" to "(c1&c2)==0" */

                assert(t1->gtOper == GT_EQ);
                assert(t1->gtOp.gtOp1 == c1);

                t1->gtOp.gtOp1 = t2 = gtNewOperNode(GT_AND, TYP_INT, c1, c2);

                /* When we 'and' two booleans, the result is boolean as well */

                t2->gtFlags |= GTF_BOOLEAN;

                goto RMV_NXT;
            }

            continue;

        RMV_NXT:

            /* Get rid of the second block (which is a BBJ_COND) */

            assert(b1->bbJumpKind == BBJ_COND);
            assert(b2->bbJumpKind == BBJ_COND);
            assert(b1->bbJumpDest == b2->bbJumpDest);
            assert(b1->bbNext == b2); assert(b2->bbNext);

            b1->bbNext = b2->bbNext;

            /* Update bbRefs and bbPreds */

            /* Replace pred 'b2' for 'b2->bbNext' with 'b1'
             * Remove pred 'b2' for 'b2->bbJumpDest' */

            fgReplacePred(b2->bbNext, b2, b1);

            b2->bbJumpDest->bbRefs--;
            fgRemovePred(b2->bbJumpDest, b2);

#ifdef DEBUG
            if  (verbose)
            {
                printf("\nRemoving short-circuited block #%02u\n\n", b2->bbNum);
            }
#endif
            //printf("Optimize bools in %s\n", info.compFullName);

            /* Update the block numbers and try again */

            change = true;
            condFolded = true;
/*
            do
            {
                b2->bbNum = ++n1;
                b2 = b2->bbNext;
            }
            while (b2);
*/
        }
    }
    while (change);

    /* If we folded anything update the flow graph */

    if  (condFolded)
    {
        fgAssignBBnums(true);
#ifdef DEBUG
        if  (verbose)
        {
            printf("After boolean conditionals folding:\n");
            fgDispBasicBlocks();
            printf("\n");
        }

        fgDebugCheckBBlist();
#endif
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\outfile.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/

#include "jitpch.h"
#pragma hdrstop

#include "outfile.h"

/*****************************************************************************/

#include <io.h>
#include <conio.h>
#include <fcntl.h>
#include <sys/stat.h>

/*****************************************************************************
 *
 *  Open an output file by path name; the 'buffSize' paremeter specifies
 *  the output buffer size, and 'buffAddr' (when NULL) is the address of
 *  a caller-supplied output buffer (if NULL, we allocate one locally).
 */

void                outFile::outFileOpen(Compiler   *   comp,
                                         const char *   name,
                                         bool           tempFile,
                                         size_t         buffSize,
                                         char *         buffAddr)
{
    outFileComp      = comp;

    /* Assume we won't be allocating a buffer */

    outFileBuffAlloc = false;
    outFileBuffAddr  = buffAddr;

    /* Save the output file name (for error messages and deletion upon error) */

    strcpy(outFileName, name);

    /* Open/create the output file */

    cycleCounterPause();
    outFileHandle = _open(name, _O_WRONLY|_O_BINARY|_O_CREAT|_O_TRUNC|_O_SEQUENTIAL, _S_IWRITE|_S_IREAD);
    cycleCounterResume();

    if  (outFileHandle == -1)
        fatal(ERRopenWrErr, name);

    /* Use default buffer size if caller didn't choose */

    if  (!buffSize)
        buffSize = 4*1024;      // 4K seems a good size

    outFileBuffSize = buffSize;

    /* Do we need to allocate a buffer? */

    if  (!buffAddr)
    {
        outFileBuffAddr = (char *)VirtualAlloc(NULL, buffSize, MEM_COMMIT, PAGE_READWRITE);
        if  (!outFileBuffAddr)
            fatal(ERRnoMemory);
        outFileBuffAlloc = true;
    }

    /* Set the next and last free byte values */

    outFileBuffNext = outFileBuffAddr;
    outFileBuffLast = outFileBuffAddr + outFileBuffSize;

    /* We are at the beginning of the file */

    outFileBuffOffs = 0;
}

#ifdef  DLL

void                outFile::outFileOpen(Compiler comp, void *dest)
{
    outFileBuffAlloc = false;
    outFileBuffAddr  = (char*)dest;
    outFileBuffSize  = UINT_MAX;
    outFileBuffOffs  = 0;

    outFileBuffNext  = outFileBuffAddr;
    outFileBuffLast  = outFileBuffAddr + outFileBuffSize;

    outFileHandle    = -1; strcpy(outFileName, ":memory:");
}

#endif
/*****************************************************************************
 *
 *  Flush and close the file.
 */

void                outFile::outFileClose()
{
    if  (outFileHandle == -1)
        return;

    assert(outFileBuffAddr);
    assert(outFileBuffNext >= outFileBuffAddr);
    assert(outFileBuffNext <  outFileBuffLast);

    /* Flush the output buffer */

    outFileFlushBuff();

    /* Free up the output buffer if we allocated it on the heap */

    if  (outFileBuffAlloc)
    {
        VirtualFree(outFileBuffAddr, 0, MEM_RELEASE);
                    outFileBuffAddr = NULL;
    }

#ifndef NDEBUG

    /* To catch any abuses, zero everything */

    outFileBuffAddr =
    outFileBuffNext =
    outFileBuffLast = NULL;

#endif

    /* Close the file */

    cycleCounterPause();
    _close(outFileHandle); outFileHandle = -1;
    cycleCounterResume();
}

/*****************************************************************************
 *
 *  Close the given file, free up the resources owned by it, and (optionally)
 *  delete it.
 */

void                outFile::outFileDone(bool delFlag)
{
    /* If we're not deleting the file, make sure the output buffer is flushed */

    if  (!delFlag)
        outFileClose();

    cycleCounterPause();

    /* Close the file */

    if  (outFileHandle != -1)
    {
        _close(outFileHandle);
               outFileHandle = -1;
    }

    /* Delete the file if the caller wishes so */

    if  (delFlag)
        _unlink(outFileName);

    cycleCounterResume();

    /* Free up the output buffer if we allocated it on the heap */

    if  (outFileBuffAlloc)
    {
        VirtualFree(outFileBuffAddr, 0, MEM_RELEASE);
                    outFileBuffAddr = NULL;
    }
}

/*****************************************************************************
 *
 *  Flush whatever is in the output buffer, and reset it to be empty.
 */

void                outFile::outFileFlushBuff()
{
    /* Compute the number of bytes waiting to be written */

    size_t          size = outFileBuffNext - outFileBuffAddr;

    /* Now that we know the size, reset the buffer pointer */

    outFileBuffNext = outFileBuffAddr;

    /* If there was anything in the buffer, write it out */

    if  (size)
    {
        size_t          written;

        cycleCounterPause();
        written = _write(outFileHandle, outFileBuffAddr, size);
        cycleCounterResume();

        if  (written != size)
            fatal(ERRwriteErr, outFileName);

        /* Update the current buffer offset */

        outFileBuffOffs += size;
    }
}

/*****************************************************************************
 *
 *  Write the given number of bytes from the specified address.
 */

void                outFile::outFileWriteData(const void *data, size_t size)
{
    assert  (size);

    for (;;)
    {
        size_t      room;
        size_t      copy;

        /* Figure out how much room is in the output buffer */

        room = outFileBuffLast - outFileBuffNext; assert(room);

        /* We'll copy "min(room, size)" bytes */

        copy = room;
        if  (copy > size)
            copy = size;

        memcpy(outFileBuffNext, data, copy); outFileBuffNext += copy;

        /* Did we fill all of the remaining buffer space? */

        if  (copy == room)
        {
            assert(outFileBuffNext == outFileBuffLast);

            outFileFlushBuff();
        }

        /* Did we copy everything? */

        size -= copy;
        if  (!size)
            return;

        /* We have more data to write */

        *(char **)&data += copy;
    }
}

/*****************************************************************************/
#ifdef  OLD_IL
/*****************************************************************************
 *
 *  Go back to the given offset in the output file and patch one byte.
 */

void        outFile::outFilePatchByte(unsigned long offset, int value)
{
    /* We must be patching something that is already written */

    assert(outFileOffset() > offset);

    /* Has the byte being patched gone to disk? */

    if  (outFileBuffOffs > offset)
    {
        /* Make sure we remember the correct file position */

        assert((unsigned long)outFileBuffOffs == (unsigned long)_lseek(outFileHandle, 0, SEEK_CUR));

        /* Seek to the patch position */

        _lseek(outFileHandle, offset, SEEK_SET);

        /* Write the patch value out */

        if  (_write(outFileHandle, &value, 1) != 1)
            outFilefatal(ERRwriteErr, outFileName);

        /* Seek back to where we were to begin with */

        _lseek(outFileHandle, outFileBuffOffs, SEEK_SET);
    }
    else
    {
        /* The patch byte must be in the output buffer */

        outFileBuffAddr[offset - outFileBuffOffs] = value;
    }
}

/*****************************************************************************
 *
 *  Go back to the given offset in the output file and patch the given
 *  number of bytes with a new value.
 */

void        outFile::outFilePatchData(unsigned long offset,
                                      const void *  data,
                                      size_t        size)
{
    /* We must be patching something that is already written */

    assert(outFileOffset() >= offset + size);

    /* Has the entire section being patched gone to disk? */

    if  (outFileBuffOffs >= offset + size)
    {
        /* Make sure we remember the correct file position */

        assert((unsigned long)outFileOffset() == (unsigned long)_lseek(outFileHandle, 0, SEEK_CUR));

        /* Seek to the patch position */

        _lseek(outFileHandle, offset, SEEK_SET);

        /* Write the patch value out */

        if  (_write(outFileHandle, data, size) != (int)size)
            outFilefatal(ERRwriteErr, outFileName);

        /* Seek back to where we were to begin with */

        _lseek(outFileHandle, outFileBuffOffs, SEEK_SET);

        return;
    }

    /* Is the entire patch section within the output buffer? */

    if  (outFileBuffOffs <= offset)
    {
        /* Patch the data in memory */

        memcpy(outFileBuffAddr + offset - outFileBuffOffs, data, size);

        return;
    }

    /* The patch section spans the output buffer - do it one byte at a time */

    char    *   temp = (char *)data;

    do
    {
        outFilePatchByte(offset, *temp);
    }
    while   (++offset, ++temp, --size);
}

/*****************************************************************************/
#endif//OLD_IL
/*****************************************************************************
 *
 *  Append the specified number of 0 bytes to the file.
 */

void                outFile::outFileWritePad (size_t size)
{
    assert((int)size > 0);

    static
    BYTE            zeros[32];

    /* This is a bit lame .... */

    while (size >= sizeof(zeros))
    {
        outFileWriteData(zeros, sizeof(zeros)); size -= sizeof(zeros);
    }

    if  (size)
        outFileWriteData(zeros, size);
}

/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\outfile.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef _OUTFILE_H_
#define _OUTFILE_H_
/*****************************************************************************
 *
 *  A bufferred file write class.
 */

class   outFile;
typedef outFile *   OutFile;

class   outFile
{
private:

    Compiler    *   outFileComp;

    char            outFileName[_MAX_PATH];
    int             outFileHandle;

    bool            outFileBuffAlloc;   // did we allocate output buffer?

    size_t          outFileBuffSize;    // size    of outout buffer
    char    *       outFileBuffAddr;    // address of output buffer

    char    *       outFileBuffNext;    // address of next free byte
    char    *       outFileBuffLast;    // address of last free byte

    size_t          outFileBuffOffs;    // current buffer offs within file

    void            outFileFlushBuff();

public:

    void            outFileOpen(Compiler   *    comp,
                                const char *    name,
                                bool            tempFile = false,
                                size_t          buffSize = 0,
                                char *          buffAddr = NULL);

#ifdef  DLL
    void            outFileOpen(Compiler        comp,
                                void        *   dest);
#endif

    void            outFileClose();

    void            outFileDone(bool delFlag = false);

    const char *    outFilePath()
    {
        return  outFileName;
    }

    void            outFileWriteData(const void *   data,
                                     size_t         size);

#ifdef  OLD_IL
    void            outFilePatchByte(unsigned long  offset,
                                     int            newVal);
    void            outFilePatchData(unsigned long  offset,
                                     const void *   data,
                                     size_t         size);
#endif

    void            outFileWritePad (size_t         size);

    void            outFileWriteByte(int x)
    {
        assert(outFileBuffNext >= outFileBuffAddr);
        assert(outFileBuffNext <  outFileBuffLast);

        *outFileBuffNext++ = x;

        if  (outFileBuffNext == outFileBuffLast)
            outFileFlushBuff();

        assert(outFileBuffNext >= outFileBuffAddr);
        assert(outFileBuffNext <  outFileBuffLast);
    }

    size_t          outFileOffset()
    {
        return  outFileBuffOffs + (outFileBuffNext - outFileBuffAddr);
    }
};

/*****************************************************************************/
#endif
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\peloader.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
// ===========================================================================
// File: PEFILE.H
// 

// CEELOAD.H defines the class use to represent the PE file
// ===========================================================================
#ifndef PEFILE_H_
#define PEFILE_H_

#define CEELOAD_H_ // don't include this file from the VM directory

#include <windows.h>
#include <wtypes.h> // for HFILE, HANDLE, HMODULE


//
// A PEFile is the runtime's abstraction of an executable image.
// It may or may not have an actual file associated with it.  PEFiles
// exist mostly to be turned into Modules later.
//

class PEFile
{
  private:

    WCHAR               m_wszSourceFile[MAX_PATH];

    HMODULE             m_hModule;
    BYTE                *m_base;
    IMAGE_NT_HEADERS    *m_pNT;
    IMAGE_COR20_HEADER  *m_pCOR;

    HRESULT ReadHeaders();

    PEFile();

    HRESULT GetFileNameFromImage();

	struct CEStuff
	{
		HMODULE hMod;
		LPVOID  pBase;
		DWORD	dwRva14;
		CEStuff *pNext;
	};

	static CEStuff *m_pCEStuff;

  public:

    ~PEFile();

	static HRESULT RegisterBaseAndRVA14(HMODULE hMod, LPVOID pBase, DWORD dwRva14);

    static HRESULT Create(HMODULE hMod, PEFile **ppFile);
    static HRESULT Create(LPCWSTR moduleNameIn, PEFile **ppFile);

    BYTE *GetBase()
    { 
        return m_base; 
    }
    IMAGE_NT_HEADERS *GetNTHeader()
    { 
        return m_pNT; 
    }
    IMAGE_COR20_HEADER *GetCORHeader() 
    { 
        return m_pCOR; 
    }

    IMAGE_DATA_DIRECTORY *GetSecurityHeader();

    HRESULT VerifyDirectory(IMAGE_DATA_DIRECTORY *dir);
    HRESULT VerifyFlags(DWORD flag);

    BOOL IsTLSAddress(void* address);
    IMAGE_TLS_DIRECTORY* GetTLSDirectory();

    LPCWSTR GetFileName();
    LPCWSTR GetLeafFileName();

    HRESULT GetFileName(LPSTR name, SIZE_T max, SIZE_T *count);
};

#endif // PEFILE_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\peloader.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==

// ===========================================================================
// File: CEELOAD.CPP
// 

// CEELOAD reads in the PE file format using LoadLibrary
// ===========================================================================

#include "jitpch.h"
#pragma hdrstop

#undef memcpy

// ===========================================================================
// PEFile
// ===========================================================================

PEFile::PEFile()
{
	m_wszSourceFile[0] = 0;
    m_hModule = NULL;
    m_base = NULL;
    m_pNT = NULL;
    m_pCOR = NULL;
}

PEFile::~PEFile()
{
	// Unload the dll so that refcounting of EE will be done correctly

	if (m_pNT && (m_pNT->FileHeader.Characteristics & IMAGE_FILE_DLL))  
		FreeLibrary(m_hModule);
}

HRESULT PEFile::ReadHeaders()
{
    IMAGE_DOS_HEADER *pDOS = (IMAGE_DOS_HEADER*) m_base;
    IMAGE_NT_HEADERS *pNT;
    
    if ((pDOS->e_magic != IMAGE_DOS_SIGNATURE) ||
        (pDOS->e_lfanew == 0))
        return HRESULT_FROM_WIN32(ERROR_BAD_FORMAT);
        
    pNT = (IMAGE_NT_HEADERS*) (pDOS->e_lfanew + m_base);

    if ((pNT->Signature != IMAGE_NT_SIGNATURE) ||
        (pNT->FileHeader.SizeOfOptionalHeader != IMAGE_SIZEOF_NT_OPTIONAL_HEADER) ||
        (pNT->OptionalHeader.Magic != IMAGE_NT_OPTIONAL_HDR_MAGIC))
        return HRESULT_FROM_WIN32(ERROR_BAD_FORMAT);

    IMAGE_DATA_DIRECTORY *entry 
      = &pNT->OptionalHeader.DataDirectory[IMAGE_DIRECTORY_ENTRY_COMHEADER];
    
    if (entry->VirtualAddress == 0 || entry->Size == 0
        || entry->Size < sizeof(IMAGE_COR20_HEADER))
        return HRESULT_FROM_WIN32(ERROR_BAD_FORMAT);

    //verify RVA and size of the COM+ header
    HRESULT hr = VerifyDirectory(entry);
    if (FAILED(hr))
        return hr;

    m_pNT = pNT;
    m_pCOR = (IMAGE_COR20_HEADER *) (entry->VirtualAddress + m_base);

    return S_OK;
}

PEFile::CEStuff *PEFile::m_pCEStuff = NULL;

HRESULT PEFile::RegisterBaseAndRVA14(HMODULE hMod, LPVOID pBase, DWORD dwRva14)
{
	// @todo: these are currently leaked.
	
	CEStuff *pStuff = new CEStuff;
	if (pStuff == NULL)
		return E_OUTOFMEMORY;

	pStuff->hMod = hMod;
	pStuff->pBase = pBase;
	pStuff->dwRva14 = dwRva14;

	pStuff->pNext = m_pCEStuff;
	m_pCEStuff = pStuff;

	return S_OK;
}

HRESULT PEFile::Create(HMODULE hMod, PEFile **ppFile)
{
    HRESULT hr;

    PEFile *pFile = new PEFile();
    if (pFile == NULL)
        return E_OUTOFMEMORY;

    pFile->m_hModule = hMod;

	CEStuff *pStuff = m_pCEStuff;
	while (pStuff != NULL)
	{
		if (pStuff->hMod == hMod)
			break;
		pStuff = pStuff->pNext;
	}

	if (pStuff == NULL)
	{
		pFile->m_base = (BYTE*) hMod;
    
		hr = pFile->ReadHeaders();
		if (FAILED(hr))
		{
			delete pFile;
			return hr;
		}
	}
	else
	{
	   pFile->m_base = (BYTE*) pStuff->pBase;
	   pFile->m_pNT = NULL;
	   pFile->m_pCOR = (IMAGE_COR20_HEADER *) (pFile->m_base + pStuff->dwRva14);

	   // @todo: if we want to clean this stuff up, we need a critical section
	}

    *ppFile = pFile;
    return pFile->GetFileNameFromImage();
}

//#define WIN95_TEST 1
HRESULT PEFile::Create(LPCWSTR moduleName, PEFile **ppFile)
{    
    HRESULT hr;
    _ASSERTE(moduleName);

#ifndef WIN95_TEST

    HMODULE hMod;
    hMod = WszLoadLibrary(moduleName);
    if (hMod)
        return Create(hMod, ppFile);

#ifdef _DEBUG
    hr = HRESULT_FROM_WIN32(GetLastError());
#endif //_DEBUG

#endif

	return hr;
}

HRESULT PEFile::VerifyDirectory(IMAGE_DATA_DIRECTORY *dir) 
{
    // Under CE, we have no NT header.
    if (m_pNT == NULL)
        return S_OK;

    int section_num = 1;
    int max_section = m_pNT->FileHeader.NumberOfSections;

    // @TODO: need to use 64 bit version??
    IMAGE_SECTION_HEADER* pCurrSection = IMAGE_FIRST_SECTION(m_pNT);
    IMAGE_SECTION_HEADER* prevSection = NULL;

    if (dir->VirtualAddress == NULL && dir->Size == NULL)
        return S_OK;

    // find which section the (input) RVA belongs to
    while (dir->VirtualAddress >= pCurrSection->VirtualAddress 
           && section_num <= max_section)
    {
        section_num++;
        prevSection = pCurrSection;
        pCurrSection++;
    }

    // check if (input) size fits within section size
    if (prevSection != NULL)     
    {
        if (dir->VirtualAddress <= prevSection->VirtualAddress + prevSection->Misc.VirtualSize)
        {
            if (dir->VirtualAddress + dir->Size 
                <= prevSection->VirtualAddress + prevSection->Misc.VirtualSize)
                return S_OK;
        }
    }   

    return HRESULT_FROM_WIN32(ERROR_BAD_FORMAT);
}

HRESULT PEFile::VerifyFlags(DWORD flags)
{

    DWORD validBits = COMIMAGE_FLAGS_ILONLY | COMIMAGE_FLAGS_32BITREQUIRED | COMIMAGE_FLAGS_TRACKDEBUGDATA;
    DWORD mask = ~validBits;

    if (!(flags & mask))
        return S_OK;

    return HRESULT_FROM_WIN32(ERROR_BAD_FORMAT);
}

IMAGE_DATA_DIRECTORY *PEFile::GetSecurityHeader()
{
    if (m_pNT == NULL)
        return NULL;
    else
        return &m_pNT->OptionalHeader.DataDirectory[IMAGE_DIRECTORY_ENTRY_SECURITY];
}

LPCWSTR PEFile::GetFileName()
{
	return m_wszSourceFile;
}

LPCWSTR PEFile::GetLeafFileName()
{
	WCHAR *pStart = m_wszSourceFile;
	WCHAR *pEnd = pStart + wcslen(m_wszSourceFile);
	WCHAR *p = pEnd;
	
	while (p > pStart)
	{
		if (--*p == '\\')
		{
			p++;
			break;
		}
	}

	return p;
}

HRESULT PEFile::GetFileNameFromImage()
{
	HRESULT hr;

	DWORD dwSourceFile;

	if (m_hModule)
    {
        dwSourceFile = WszGetModuleFileName(m_hModule, m_wszSourceFile, MAX_PATH);
        if (dwSourceFile == 0)
		{
			*m_wszSourceFile = 0;
            hr = HRESULT_FROM_WIN32(GetLastError());
			if (SUCCEEDED(hr)) // GetLastError doesn't always do what we'd like
				hr = E_FAIL;
		}
        dwSourceFile++; // add in the null terminator
    }

	_ASSERTE(dwSourceFile <= MAX_PATH);

    return S_OK;
}

HRESULT PEFile::GetFileName(LPSTR psBuffer, DWORD dwBuffer, DWORD* pLength)
{
	if (m_hModule)
    {
        DWORD length = GetModuleFileNameA(m_hModule, psBuffer, dwBuffer);
        if (length == 0)
		{
            HRESULT hr = HRESULT_FROM_WIN32(GetLastError());
			if (SUCCEEDED(hr)) // GetLastError doesn't always do what we'd like
				hr = E_FAIL;
		}
        *pLength = length;
    }
    else
    {
        *pLength = 0;
    }

    return S_OK;
}


/*** For reference, from ntimage.h
    typedef struct _IMAGE_TLS_DIRECTORY {
        ULONG   StartAddressOfRawData;
        ULONG   EndAddressOfRawData;
        PULONG  AddressOfIndex;
        PIMAGE_TLS_CALLBACK *AddressOfCallBacks;
        ULONG   SizeOfZeroFill;
        ULONG   Characteristics;
    } IMAGE_TLS_DIRECTORY;
***/

IMAGE_TLS_DIRECTORY* PEFile::GetTLSDirectory() 
{
    if (m_pNT == 0) 
        return NULL;

    IMAGE_DATA_DIRECTORY *entry 
      = &m_pNT->OptionalHeader.DataDirectory[IMAGE_DIRECTORY_ENTRY_TLS];
    
    if (entry->VirtualAddress == 0 || entry->Size == 0) 
        return NULL;

    return (IMAGE_TLS_DIRECTORY*) (m_base + entry->VirtualAddress);
}

BOOL PEFile::IsTLSAddress(void* address)  
{
    IMAGE_TLS_DIRECTORY* tlsDir = GetTLSDirectory();
    if (tlsDir == 0)
        return FALSE;

    ULONG asInt = (DWORD) address;

    return (tlsDir->StartAddressOfRawData <= asInt 
            && asInt < tlsDir->EndAddressOfRawData);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\pewrite.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/

#include "jitpch.h"
#pragma hdrstop

#include "PEwrite.h"

#include <time.h>
#include <sys/types.h>
#include <sys/stat.h>

/*****************************************************************************/

bool            genDLL;
bool            genQuiet;
unsigned        genBase;
unsigned        genSize;
unsigned        genSubSys;

/*****************************************************************************/
#if TGT_IA64
const   NatUns      IAT_entry_size = 8;
#else
const   NatUns      IAT_entry_size = 4;
#endif
/*****************************************************************************/

#define VERBOSE_IMPORT  (verbose||0)

/*****************************************************************************/

static
unsigned            hashComputeHashVal(const char *name)
{
    unsigned        val = 0;

    while (*name)
        val = val << 3 ^ *name++;

    return  val;
}

/*****************************************************************************
 *
 *  Return the size of the hint/name table entry for the given name.
 */

inline
size_t              hintNameSize(WPEname name)
{
    /* Is this a "real" name or is it an import by ordinal? */

    if  (*name->PEnmSpelling() == '#')
    {
        return 0;
    }
    else
    {
        return  2 + (name->PEnmNlen + 2) & ~1;
    }
}

/*****************************************************************************
 *
 *  Initialize the name hash table.
 */

void                WPEhashTab::WPEhashInit(Compiler        *comp,
                                            norls_allocator *alloc,
                                            unsigned         count)
{
    WPEname *       buck;
    size_t          size;

    /* Figure out the size of the bucket table and allocate/clear it */

    size = count * sizeof(*buck);
    buck = (WPEname*)alloc->nraAlloc(size);
    memset(buck, 0, size);

    /* Initialize all the other fields */

    WPEhashSize   = count;
    WPEhashMask   = count - 1;
    WPEhashComp   = comp;
    WPEhashAlloc  = alloc;
    WPEhashTable  = buck;
    WPEhashStrLen = 0;
}

/*****************************************************************************
 *
 *  Find/add the given name to the import name table ('owner' specifies the
 *  DLL that the import belongs to). The value at '*isNewPtr' will be set to
 *  true if the name was not in the table and has been added.
 */

WPEndef             WPEhashTab::WPEhashName(const char *name,
                                            WPEimpDLL   owner, bool *isNewPtr)
{
    bool            isNew;

    WPEname         nameEnt;
    WPEndef         nameDsc;

    assert(owner);

    /* Look for an existing entry that matches the name */

    nameEnt = WPEhashName(name, &isNew);

    if  (!isNew && (nameEnt->PEnmFlags & PENMF_IMP_NAME))
    {
        /* Existing import - look for a matching entry on the owning DLL */

        for (nameDsc = nameEnt->PEnmDefs;
             nameDsc;
             nameDsc = nameDsc->PEndNext)
        {
            assert(nameDsc->PEndName == nameEnt);

            if  (nameDsc->PEndDLL == owner)
            {
                *isNewPtr = false;

                return  nameDsc;
            }
        }
    }
    else
    {
        /* New import - record the name's offset within the name/hint table */

        nameEnt->PEnmOffs   = WPEhashStrLen;

        /* Remember that this entry is an import */

        nameEnt->PEnmFlags |= PENMF_IMP_NAME;

        /* Update the total name table size */

        WPEhashStrLen += hintNameSize(nameEnt);
    }

    /* Add a new DLL to the list of import definitions */

    nameDsc = (WPEndef)WPEhashAlloc->nraAlloc(sizeof(*nameDsc));

    nameDsc->PEndName      = nameEnt;

    nameDsc->PEndNext      = nameEnt->PEnmDefs;
                             nameEnt->PEnmDefs = nameDsc;

    nameDsc->PEndDLL       = owner;

    /* Append to the DLL's linked list of imports */

    nameDsc->PEndNextInDLL = NULL;

    if  (owner->PEidImpList)
        owner->PEidImpLast->PEndNextInDLL = nameDsc;
    else
        owner->PEidImpList                = nameDsc;

    owner->PEidImpLast = nameDsc;

    /* Tell the caller that we've create a new import entry */

    *isNewPtr = true;

    return  nameDsc;
}

/*****************************************************************************
 *
 *  Find/add the given name to the import name table. The value at '*isNewPtr'
 *  will be set to true if the name was not in the table and has been added.
 */

WPEname             WPEhashTab::WPEhashName(const char *name, bool *isNewPtr)
{
    WPEname    *    lastPtr;
    unsigned        hash;
    WPEname         nm;
    size_t          sz;

    size_t          nlen = strlen(name);
    unsigned        hval = hashComputeHashVal(name);

    /* Mask the appropriate bits from the hash value */

    hash = hval & WPEhashMask;

    /* Search the hash table for an existing match */

    lastPtr = &WPEhashTable[hash];

    for (;;)
    {
        nm = *lastPtr;
        if  (!nm)
            break;

        /* Check whether the hash value and identifier lengths match */

        if  (nm->PEnmHash == hval && nm->PEnmNlen == nlen)
        {
            if  (!memcmp(nm->PEnmName, name, nlen+1))
            {
                *isNewPtr = false;
                return  nm;
            }
        }

        lastPtr = &nm->PEnmNext;
    }

    /* Figure out the size to allocate */

    sz  = sizeof(*nm);

    /* Include space for name string + terminating null and round the size */

    sz +=   sizeof(int) + nlen;
    sz &= ~(sizeof(int) - 1);

    /* Allocate space for the identifier */

    nm = (WPEname)WPEhashAlloc->nraAlloc(sz);

    /* Insert the identifier into the hash list */

    *lastPtr = nm;

    /* Fill in the identifier record */

    nm->PEnmNext   = NULL;
    nm->PEnmFlags  = 0;
    nm->PEnmHash   = hval;
    nm->PEnmNlen   = nlen;
    nm->PEnmDefs   = NULL;

    /* Copy the name string */

    memcpy(nm->PEnmName, name, nlen+1);

    *isNewPtr = true;

    return  nm;
}

/*****************************************************************************
 *
 *  The following maps a section id to its name string.
 */

const   char        writePE::WPEsecNames[PE_SECT_count][IMAGE_SIZEOF_SHORT_NAME] =
{
    ".text",
    ".pdata",
    ".rdata",
    ".sdata",
    ".data",
    ".rsrc",
    ".reloc",
};

const   char    *   writePE::WPEsecName(WPEstdSects sect)
{
    assert(sect < PE_SECT_count);

    assert(strcmp(WPEsecNames[PE_SECT_text ], ".text" ) == 0);
    assert(strcmp(WPEsecNames[PE_SECT_pdata], ".pdata") == 0);
    assert(strcmp(WPEsecNames[PE_SECT_rdata], ".rdata") == 0);
    assert(strcmp(WPEsecNames[PE_SECT_sdata], ".sdata") == 0);
    assert(strcmp(WPEsecNames[PE_SECT_data ], ".data" ) == 0);
    assert(strcmp(WPEsecNames[PE_SECT_rsrc ], ".rsrc" ) == 0);
    assert(strcmp(WPEsecNames[PE_SECT_reloc], ".reloc") == 0);

    return  WPEsecNames[sect];
}

/*****************************************************************************
 *
 *  Initialize an instance of the PE writer for the specified output file,
 *  using the given memory allocator. Returns false on success.
 */

bool                writePE::WPEinit(Compiler *comp, norls_allocator*alloc)
{
    unsigned        offs;

#if!TGT_IA64

    static
    BYTE            entryCode[16] =
    {
        0xFF, 0x25
    };

#endif

    /* We don't know the name of the output file yet */

#ifndef NDEBUG
    WPEoutFnam  = NULL;
#endif

    /* Initialize/clear/record various things */

    WPEcomp     = comp;
    WPEalloc    = alloc;

    WPEsectCnt  = 0;

    memset(&WPEsections, 0, sizeof(WPEsections));
    memset(&WPEsecTable, 0, sizeof(WPEsecTable));

#ifdef  DEBUG
    WPEstrPoolBase = 0xBEEFCAFE;
#endif

    /* Create the standard sections */

    WPEaddSection(PE_SECT_text , 0, MAX_PE_TEXT_SIZE);
    WPEaddSection(PE_SECT_data , 0, MAX_PE_DATA_SIZE);
    WPEaddSection(PE_SECT_pdata, 0, MAX_PE_PDTA_SIZE);
    WPEaddSection(PE_SECT_rdata, 0, MAX_PE_RDTA_SIZE);
    WPEaddSection(PE_SECT_sdata, 0, MAX_PE_SDTA_SIZE);

    /* If we're creating a DLL, we'll need to output relocations */

    if  (genDLL)
        WPEaddSection(PE_SECT_reloc, 0, 0);

    /* Initialize the import table logic */

    WPEimportInit();

    /* Initialize the RC file import logic */

    WPEinitRCimp();

#if!TGT_IA64

    /* Add the appropriate import for the runtime's entry point */

    WPEcorMain = WPEimportAdd("MSCOREE.DLL", genDLL ? "_CorDllMain"
                                                    : "_CorExeMain");

#endif

    /* Reserve space for the entry point code */

#if!TGT_IA64
    offs = WPEsecAddData(PE_SECT_text, entryCode, sizeof(entryCode)); assert(offs == 0);
#endif

    return  false;
}

/*****************************************************************************
 *
 *  Set the name of the output file, this function has to be called (and at the
 *  right time) if an output file is to be generated!
 */

void                writePE::WPEsetOutputFileName(const char *outfile)
{
    char    *       buff;

    assert(WPEoutFnam == NULL);

    /* Make a durable copy of the file name, can't trust those callers */

    WPEoutFnam = buff = (char *)WPEalloc->nraAlloc(roundUp(strlen(outfile) + 1));

    strcpy(buff, outfile);
}

/*****************************************************************************
 *
 *  Add a new section with the given name to the PE file.
 */

void                writePE::WPEaddSection(WPEstdSects sect, unsigned attrs,
                                                             size_t   maxSz)
{
    BYTE          * buff;
    PEsection       sec;

    assert(WPEsectCnt < PEmaxSections);
    sec = WPEsections + WPEsectCnt++;

    /* Make sure the max. size is rounded */

    assert((maxSz % OS_page_size) == 0);

    /* Allocate the uncommitted buffer */

    buff = maxSz ? (BYTE *)VirtualAlloc(NULL, maxSz, MEM_RESERVE, PAGE_READWRITE)
                 : NULL;

    /* Initialize the section state */

    sec->PEsdBase     =
    sec->PEsdNext     = buff;
    sec->PEsdLast     = buff;
    sec->PEsdEndp     = buff + maxSz;

    sec->PEsdRelocs   = NULL;

#ifdef  DEBUG
    sec->PEsdIndex    = sect;
    sec->PEsdFinished = false;
#endif

    /* Record the entry in the table */

    WPEsecTable[sect] = sec;
}

/*****************************************************************************
 *
 *  Reserve a given amount of space in the specified section.
 */

unsigned            writePE::WPEsecRsvData(WPEstdSects sect, size_t   size,
                                                             size_t   align,
                                                             BYTE * & outRef)
{
    PEsection       sec = WPEgetSection(sect);

    unsigned        ofs;
    BYTE        *   nxt;

    assert(align ==  1 ||
           align ==  2 ||
           align ==  4 ||
           align ==  8 ||
           align == 16);

    /* Compute the offset of the new data */

    ofs = sec->PEsdNext - sec->PEsdBase;

    /* Do we need to align the allocation? */

    if  (align > 1)
    {
        /* Pad if necessary */

        if  (ofs & (align - 1))
        {
            WPEsecRsvData(sect, align - (ofs & (align - 1)), 1, outRef);

            ofs = sec->PEsdNext - sec->PEsdBase;

            assert((ofs & (align - 1)) == 0);
        }
    }

    /* See if we have enough committed space in the buffer */

    nxt = sec->PEsdNext + size;

    if  (nxt > sec->PEsdLast)
    {
        size_t          tmp;
        BYTE    *       end;

        /* Round up the desired end-point */

        tmp  = ofs + size;
        tmp +=  (OS_page_size - 1);
        tmp &= ~(OS_page_size - 1);

        end  = sec->PEsdBase + tmp;

        /* Make sure we're not at the end of the buffer */

        if  (end > sec->PEsdEndp)
            fatal(ERRnoMemory);

        /* Commit some more memory */

        if  (!VirtualAlloc(sec->PEsdLast, end - sec->PEsdLast, MEM_COMMIT, PAGE_READWRITE))
            fatal(ERRnoMemory);

        /* Update the 'last' pointer */

        sec->PEsdLast = end;
    }

    /* Return the address of the first byte to the caller and update it */

    outRef = sec->PEsdNext;
             sec->PEsdNext = nxt;

    return  ofs;
}

/*****************************************************************************
 *
 *  Append the given blob of data to the specified section.
 */

unsigned            writePE::WPEsecAddData(WPEstdSects sect, const BYTE * data,
                                                                   size_t size)
{
    BYTE *          dest;
    unsigned        offs;

    offs = WPEsecRsvData(sect, size, 1, dest);

    memcpy(dest, data, size);

    return  offs;
}

/*****************************************************************************
 *
 *  Returns the address of the data of a section at the given offset.
 */

BYTE *          writePE::WPEsecAdrData(WPEstdSects sect, unsigned offs)
{
    PEsection       sec = WPEgetSection(sect);

    assert(offs <= (unsigned)(sec->PEsdNext - sec->PEsdBase));

    return  sec->PEsdBase + offs;
}

/*****************************************************************************
 *
 *  Returns the relative offset of the data area within the section.
 */

unsigned            writePE::WPEsecAddrOffs(WPEstdSects sect, BYTE * addr)
{
    PEsection       sec = WPEgetSection(sect);

    assert(addr >= sec->PEsdBase);
    assert(addr <= sec->PEsdNext);

    return addr -  sec->PEsdBase;
}

/*****************************************************************************
 *
 *  Reserve space in the code section of the given size and return the address
 *  of where the code bytes are to be copied and the corresponding RVA.
 */

unsigned            writePE::WPEallocCode(size_t size,
                                          size_t align, BYTE * & dataRef)
{
    return  CODE_BASE_RVA + WPEsecRsvData(PE_SECT_text, size, align, dataRef);
}

/*****************************************************************************
 *
 *  Reserve space for the given amount of string data and return the address
 *  of where the string pool contents are to be copied. This routine must be
 *  called exactly once (just before the PE file is closed), and the base of
 *  the space reserved here will be used to process all string data fixups.
 */

void                writePE::WPEallocString(size_t size,
                                            size_t align, BYTE * & dataRef)
{
    /* Allocate the space and remember the relative offset */

    WPEstrPoolBase = WPEsecRsvData(PE_SECT_data, size, align, dataRef);
}

/*****************************************************************************
 *
 *  Record a fixup: the datum being fixed up is within section 'ssrc' at
 *  offset 'offs', and the value there is to be updated by the base RVA
 *  of section 'sdst'.
 */

void                writePE::WPEsecAddFixup(WPEstdSects ssrc,
                                            WPEstdSects sdst, unsigned offs,
                                                              bool     abs)
{
    PEsection       sec = WPEgetSection(ssrc);
    PEreloc         rel = (PEreloc)WPEalloc->nraAlloc(sizeof(*rel));

    /* Make sure the offset is within range */

#if TGT_IA64
    assert(offs <= WPEsecNextOffs(ssrc) || sdst == PE_SECT_GPref && (offs & ~0xF) <= WPEsecNextOffs(ssrc));
#else
    assert(offs <= WPEsecNextOffs(ssrc));
#endif

    /* Add the relocation to the section's list */

    rel->perSect = sdst; assert(rel->perSect == (unsigned)sdst);
    rel->perOffs = offs; assert(rel->perOffs == (unsigned)offs);
    rel->perAbs  = abs;

    rel->perNext = sec->PEsdRelocs;
                   sec->PEsdRelocs = rel;
}

/*****************************************************************************
 *
 *  Add an import to the import tables. Returns a cookie for the import that
 *  can later be used to obtain the actual address of the corresponding IAT
 *  entry.
 */

void    *           writePE::WPEimportAdd(const char *DLLname,
                                          const char *impName)
{
    WPEname         nameDLL;
    WPEndef         nameImp;
    WPEimpDLL       DLLdesc;
    bool            newName;

#if TGT_IA64
    if  (!strcmp(DLLname, "kernel32.dll")) WPEimpKernelDLL = true;  // HACK!!!!
    if  (!strcmp(DLLname, "KERNEL32.DLL")) WPEimpKernelDLL = true;  // HACK!!!!
#endif

//  printf("Add external import for %s::%s\n", DLLname, impName);

    /* Hash the DLL name first */

    nameDLL = WPEimpHash->WPEhashName(DLLname, &newName);

    /* Look for an existing DLL entry with a matching name */

    if  (newName)
    {
        /* New DLL name - make sure we update the total string length */

        WPEimpDLLstrLen += (nameDLL->PEnmNlen + 1) & ~1;
    }
    else
    {
        for (DLLdesc = WPEimpDLLlist; DLLdesc; DLLdesc = DLLdesc->PEidNext)
        {
            if  (DLLdesc->PEidName == nameDLL)
                goto GOT_DSC;
        }
    }

    /* The DLL is not known, add a new entry for it */

    DLLdesc = (WPEimpDLL)WPEalloc->nraAlloc(sizeof(*DLLdesc));

    DLLdesc->PEidName    = nameDLL;
    DLLdesc->PEidIndex   = WPEimpDLLcnt++;
    DLLdesc->PEidImpCnt  = 0;
    DLLdesc->PEidImpList =
    DLLdesc->PEidImpLast = NULL;
    DLLdesc->PEidNext    = NULL;

    /* Append the DLL entry to the end of the DLL list */

    if  (WPEimpDLLlast)
        WPEimpDLLlast->PEidNext = DLLdesc;
    else
        WPEimpDLLlist           = DLLdesc;

    WPEimpDLLlast = DLLdesc;

GOT_DSC:

    /* We've got the DLL entry, now look for an existing import from it */

    nameImp = WPEimpHash->WPEhashName(impName, DLLdesc, &newName);

    if  (newName)
    {
        /* This is a new import */

#if TGT_IA64
        nameImp->PEndIndex = WPEimportCnt++;
#endif

        DLLdesc->PEidImpCnt++;
    }

    return  nameImp;
}

/*****************************************************************************
 *
 *  Record a reference to an import; we'll patch the import entry offset into
 *  the opcode at the end (when we finally lay out the import table).
 */

#if TGT_IA64

NatUns              writePE::WPEimportRef(void *imp, NatUns offs, NatUns slot)
{
    WPEndef         nameImp = (WPEndef)imp;

#if 0
    printf("Ref at %04X:%u to import %s : %s\n", offs,
                                                 slot,
                                                 nameImp->PEndDLL->PEidName->PEnmSpelling(),
                                                 nameImp->PEndName         ->PEnmSpelling());
#endif

    assert((offs & 0xF) == 0 && slot <= 3);

    WPEsecAddFixup(PE_SECT_text, PE_SECT_GPref, offs | slot);

    return  nameImp->PEndIndex;
}

#endif

/*****************************************************************************
 *
 *  Initialize the import tracking logic.
 */

void                writePE::WPEimportInit()
{
    WPEhash         hash;

    /* Create and initialize the name hash table */

    hash = WPEimpHash = (WPEhash)WPEalloc->nraAlloc(sizeof(*hash));
    hash->WPEhashInit(WPEcomp, WPEalloc);

    /* Initialize all the other import table-related values */

    WPEimpDLLcnt    = 0;
    WPEimpDLLlist   =
    WPEimpDLLlast   = NULL;

#if TGT_IA64
    WPEimportCnt    = 0;
    WPEimpKernelDLL = false;
#endif

    WPEimpDLLstrLen = 0;
}

/*****************************************************************************
 *
 *  Finalize the import table logic and return the total size of the import
 *  tables - return value indicates the size that goes into .rdata, and the
 *  *sdatSzPtr value is set to the size of the data that goes into .sdata.
 */

size_t              writePE::WPEimportDone(unsigned offs, size_t *sdatSzPtr)
{
    WPEimpDLL       DLLdesc;

    size_t          temp;
    size_t          tsiz;

    unsigned        next;
    size_t          size = 0;

#if TGT_IA64

    WPEndef       * map;

    /* Allocate the import index -> import descriptor mapping table */

    map = WPEimportMap = (WPEndef*)WPEalloc->nraAlloc(WPEimportCnt * sizeof(*map));

#endif

    /* Reserve space for the IAT's */

#if TGT_IA64
    WPEimpOffsIAT  = next = WPEsecNextOffs(PE_SECT_sdata);
#else
    WPEimpOffsIAT  = next = offs;
#endif

    assert((offs & (IAT_entry_size - 1)) == 0);

    for (DLLdesc = WPEimpDLLlist, tsiz = 0;
         DLLdesc;
         DLLdesc = DLLdesc->PEidNext)
    {
        /* Record the base offset of this IAT */

        DLLdesc->PEidIATbase = next;

#if TGT_IA64

        WPEndef         imp;
        NatUns          ofs;

        /* For each import, record the address of its IAT entry */

        for (imp = DLLdesc->PEidImpList, ofs = next;
             imp;
             imp = imp->PEndNextInDLL  , ofs += IAT_entry_size)
        {
            assert(imp->PEndIndex < WPEimportCnt);

#if 0
            printf("Import #%u -> %04X %s : %s\n", imp->PEndIndex,
                                                   ofs,
                                                   DLLdesc->PEidName->PEnmSpelling(),
                                                   imp->PEndName->PEnmSpelling());
#endif

            /* Record the IAT entry offset of the import */

            imp->PEndIAToffs = ofs;

            /* Record the import in the mapping table */

            map[imp->PEndIndex] = imp;
        }

#endif

        /* Compute the size of the IAT (it's null-terminated) */

        temp  = IAT_entry_size * (DLLdesc->PEidImpCnt + 1);

        /* Reserve space for the IAT */

        size += temp;
        next += temp;
        tsiz += temp;
    }

    WPEimpSizeIAT  = tsiz; assert(tsiz);

#if TGT_IA64
    *sdatSzPtr = size; size = 0;
#else
    *sdatSzPtr =    0; offs = next;
#endif

    /* Next comes the import directory table */

    WPEimpOffsIDT  = offs; assert((offs & (IAT_entry_size - 1)) == 0);

    /* The import directory is NULL-terminated */

    temp  = (WPEimpDLLcnt + 1) * sizeof(IMAGE_IMPORT_DESCRIPTOR);
    size += temp;
    offs += temp;

    WPEimpSizeIDT  = temp;

    /* Next comes the import lookup table */

#if TGT_IA64

    if  (offs & (IAT_entry_size - 1))
    {
        size_t          pad = IAT_entry_size - (offs & (IAT_entry_size - 1));

        size += pad;
        offs += pad;
    }

#endif

    WPEimpOffsLook = offs; assert((offs & (IAT_entry_size - 1)) == 0);

    for (DLLdesc = WPEimpDLLlist;
         DLLdesc;
         DLLdesc = DLLdesc->PEidNext)
    {
        /* Record the base offset of this lookup table */

        DLLdesc->PEidILTbase = offs;

        /* Compute the size of the ILT (it's null-terminated) */

        temp  = IAT_entry_size * (DLLdesc->PEidImpCnt + 1);

        /* Reserve space for the ILT */

        size += temp;
        offs += temp;
    }

    /* Next comes the hint/name table */

    WPEimpOffsName = offs; assert((offs & (IAT_entry_size - 1)) == 0);

    size += WPEimpHash->WPEhashStrLen;
    offs += WPEimpHash->WPEhashStrLen;

    /* The last thing is the DLL name table */

    WPEimpOffsDLLn = offs;

    size += WPEimpDLLstrLen;
    offs += WPEimpDLLstrLen;

    /* Record the total size of all the tables */

    WPEimpSizeAll  = size;

    return  size;
}

/*****************************************************************************
 *
 *  Write the import table to the output file.
 */

void                writePE::WPEimportGen(OutFile outf, WPEstdSects sectNum)
{
    unsigned        baseDiff;
    unsigned        baseFile;
    unsigned        baseRVA;

    unsigned        nextIAT;
    unsigned        nextLook;
    unsigned        nextDLLn;
#if TGT_IA64
    _uint64         nextName;
#else
    unsigned        nextName;
#endif

    WPEimpDLL       DLLdesc;

    PEsection       sect = WPEgetSection(sectNum);

    assert(WPEimpSizeIAT);
    assert(WPEimpSizeIDT);

    assert(sizeof(nextName) == IAT_entry_size);

    baseFile = sect->PEsdAddrFile;
    baseDiff = outf->outFileOffset() - sect->PEsdAddrFile;
    baseRVA  = sect->PEsdAddrRVA;

#ifdef  DEBUG
    if  (VERBOSE_IMPORT) printf("\n");
#endif

#if TGT_IA64
    if  (sectNum != PE_SECT_sdata) goto SKIP_IAT;
#endif

    /* Output the IAT entries s for all imports of all DLL's */

    assert(outf->outFileOffset() == baseFile + WPEimpOffsIAT);

#if TGT_IA64
    nextName = WPErdatRVA + WPEimpOffsName;
#else
    nextName =    baseRVA + WPEimpOffsName;
#endif

    for (DLLdesc = WPEimpDLLlist;
         DLLdesc;
         DLLdesc = DLLdesc->PEidNext)
    {
        WPEndef         imp;

        assert(DLLdesc->PEidIATbase == outf->outFileOffset() - baseFile);

#ifdef  DEBUG
        if  (VERBOSE_IMPORT) printf("IAT starts at %04X           for '%s'\n", outf->outFileOffset(), DLLdesc->PEidName->PEnmSpelling());
#endif

        /* For each import, output the RVA of its hint/name table entry */

        for (imp = DLLdesc->PEidImpList; imp; imp = imp->PEndNextInDLL)
        {
            WPEname         name = imp->PEndName;

            assert(name->PEnmFlags & PENMF_IMP_NAME);

#ifdef  DEBUG
            if  (VERBOSE_IMPORT) printf("    entry --> %04X           for '%s.%s'\n", (int)nextName, DLLdesc->PEidName->PEnmSpelling(), name->PEnmSpelling());
#endif

            outf->outFileWriteData(&nextName, sizeof(nextName));

            nextName += hintNameSize(name);
        }

        /* Output a null entry to terminate the table */

        outf->outFileWritePad(sizeof(nextName));
    }

#if TGT_IA64
    if  (sectNum == PE_SECT_sdata) return;
SKIP_IAT:
#endif

#ifdef  DEBUG
    if  (VERBOSE_IMPORT) printf("\n");
#endif

    /* Output the import directory */

    assert(outf->outFileOffset() == baseFile + WPEimpOffsIDT);

#if TGT_IA64
    nextIAT  = WPEsdatRVA + WPEimpOffsIAT;
#else
    nextIAT  =    baseRVA + WPEimpOffsIAT;
#endif

    nextLook =    baseRVA + WPEimpOffsLook;
    nextDLLn =    baseRVA + WPEimpOffsDLLn;

    for (DLLdesc = WPEimpDLLlist;
         DLLdesc;
         DLLdesc = DLLdesc->PEidNext)
    {
        IMAGE_IMPORT_DESCRIPTOR impDsc;

#ifdef  DEBUG
        if  (VERBOSE_IMPORT) printf("IDT entry --> %04X/%04X/%04X for '%s'\n", nextIAT, nextLook, nextDLLn, DLLdesc->PEidName->PEnmSpelling());
#endif

        /* Fill in the entry and append it to the file */

        impDsc.Characteristics = nextLook;
        impDsc.TimeDateStamp   = 0;
        impDsc.ForwarderChain  = 0;
        impDsc.Name            = nextDLLn;
        impDsc.FirstThunk      = nextIAT;

        outf->outFileWriteData(&impDsc, sizeof(impDsc));

        /* Update the offsets for the next entry */

        nextIAT  += IAT_entry_size * (DLLdesc->PEidImpCnt + 1);
        nextLook += IAT_entry_size * (DLLdesc->PEidImpCnt + 1);;
        nextDLLn += (DLLdesc->PEidName->PEnmNlen + 2) & ~1;
    }

    /* Output a null entry to terminate the table */

    outf->outFileWritePad(sizeof(IMAGE_IMPORT_DESCRIPTOR));

#ifdef  DEBUG
    if  (VERBOSE_IMPORT) printf("\n");
#endif

    /* Pad if necessary */

#if TGT_IA64

    size_t          curOffs = outf->outFileOffset();

    if  (curOffs & 7)
        outf->outFileWritePad(8 - (curOffs & 7));

#endif

    /* Output the lookup table */

    assert(outf->outFileOffset() == baseFile + WPEimpOffsLook);

    nextName = baseRVA + WPEimpOffsName;
    nextDLLn = baseRVA + WPEimpOffsDLLn;

    for (DLLdesc = WPEimpDLLlist;
         DLLdesc;
         DLLdesc = DLLdesc->PEidNext)
    {
        WPEndef         imp;

        assert(DLLdesc->PEidILTbase == outf->outFileOffset() - baseFile);

#ifdef  DEBUG
        if  (VERBOSE_IMPORT) printf("ILT starts at %04X           for '%s'\n", outf->outFileOffset(), DLLdesc->PEidName->PEnmSpelling());
#endif

        /* For each import, output the RVA of its hint/name table entry */

        for (imp = DLLdesc->PEidImpList; imp; imp = imp->PEndNextInDLL)
        {
            WPEname         name = imp->PEndName;

            assert(name->PEnmFlags & PENMF_IMP_NAME);

#ifdef  DEBUG
        if  (VERBOSE_IMPORT) printf("    entry --> %04X           for '%s.%s'\n", (int)nextName, DLLdesc->PEidName->PEnmSpelling(), name->PEnmSpelling());
#endif

            outf->outFileWriteData(&nextName, sizeof(nextName));

            nextName += hintNameSize(name);
        }

        /* Output a null entry to terminate the table */

        outf->outFileWritePad(sizeof(nextName));
    }

#ifdef  DEBUG
    if  (VERBOSE_IMPORT) printf("\n");
#endif

    /* Output the hint/name table */

    assert(outf->outFileOffset() == baseFile + WPEimpOffsName);

    for (DLLdesc = WPEimpDLLlist;
         DLLdesc;
         DLLdesc = DLLdesc->PEidNext)
    {
        WPEndef         imp;
        unsigned        one = 1;

#ifdef  DEBUG
        if  (VERBOSE_IMPORT) printf("HNT starts at %04X           for '%s'\n", outf->outFileOffset(), DLLdesc->PEidName->PEnmSpelling());
#endif

        /* For each import, output the RVA of its hint/name table entry */

        for (imp = DLLdesc->PEidImpList; imp; imp = imp->PEndNextInDLL)
        {
            WPEname         name = imp->PEndName;

            assert(name->PEnmFlags & PENMF_IMP_NAME);

#ifdef  DEBUG
            if  (VERBOSE_IMPORT)  printf("    entry  at %04X               '%s.%s'\n", outf->outFileOffset(), DLLdesc->PEidName->PEnmSpelling(), name->PEnmSpelling());
#endif

            outf->outFileWriteData(&one, 2);
            outf->outFileWriteData(name->PEnmName, name->PEnmNlen+1);

            /* Padd if the name has an even size (odd with null terminator) */

            if  (!(name->PEnmNlen & 1))
                outf->outFileWriteByte(0);
        }
    }

#ifdef  DEBUG
    if  (VERBOSE_IMPORT) printf("\n");
#endif

    /* Finally, output the DLL name table */

    assert(outf->outFileOffset() == baseFile + WPEimpOffsDLLn);

    for (DLLdesc = WPEimpDLLlist;
         DLLdesc;
         DLLdesc = DLLdesc->PEidNext)
    {
        WPEname         name = DLLdesc->PEidName;

#ifdef  DEBUG
        if  (VERBOSE_IMPORT) printf("DLL entry  at %04X               '%s'\n", outf->outFileOffset(), name->PEnmSpelling());
#endif

        outf->outFileWriteData(name->PEnmName, name->PEnmNlen+1);

        /* Padd if the name has an even size (odd with null terminator) */

        if  (!(name->PEnmNlen & 1))
            outf->outFileWriteByte(0);
    }
}

/*****************************************************************************
 *
 *  Token remapping logic.
 */

#if     MD_TOKEN_REMAP

struct  tokenMap;
typedef tokenMap  * TokenMapper;

struct  tokenMap : IMapToken
{
    unsigned        refCount;

    virtual HRESULT _stdcall QueryInterface(REFIID iid, void **ppv);
    virtual ULONG   _stdcall AddRef();
    virtual ULONG   _stdcall Release();
    virtual HRESULT _stdcall Map(unsigned __int32 oldToken, unsigned __int32 newToken);
};

HRESULT
_stdcall            tokenMap::QueryInterface(REFIID iid, void **ppv)
{
    if      (iid == IID_IUnknown)
    {
        *ppv = (void *)this;
        return S_OK;
    }
    else if (iid == IID_IMapToken)
    {
        *ppv = (void *)this;
        return S_OK;
    }
    else
        return E_NOINTERFACE;
}

ULONG
_stdcall            tokenMap::AddRef()
{
    return ++refCount;
}

ULONG
_stdcall            tokenMap::Release()
{
    unsigned i = --refCount;

#ifndef __SMC__

    if (i == 0)
        delete this;

#endif

    return i;
}

HRESULT
_stdcall            tokenMap::Map(unsigned __int32 oldToken, unsigned __int32 newToken)
{
    UNIMPL(!"token remapper called, this is NYI");

    return E_NOTIMPL;
}

#endif

/*****************************************************************************/

static
char                COFFmagic[4] = { 'P', 'E', 0, 0 };

/*****************************************************************************
 *
 *  Finish writing the output file, flush it and close it. Returns false if
 *  successful.
 */

bool                writePE::WPEdone(bool errors, NatUns entryOfs, const char *PDBname,
                                                                   NB10I *     PDBhdr)
{
    unsigned        fileOffs;
    unsigned        fImgSize;
    unsigned        filePad;

    unsigned        DOS_hdrOffs, DOS_hdrSize;
    unsigned        COFFhdrOffs, COFFhdrSize;
    unsigned        OPTLhdrOffs, OPTLhdrSize;
    unsigned        sectTabOffs, sectTabSize;

    unsigned        virtBase;
    unsigned        virtOffs;

    unsigned        sectNum;
    PEsection       sectPtr;

#if!TGT_IA64
    unsigned        entryAdr;
    unsigned    *   ecodePtr;
#endif

    unsigned        codeOffs, codeVirt, codeSize;
    unsigned        pdatOffs, pdatVirt, pdatSize;
    unsigned        rdatOffs, rdatVirt, rdatSize;
    unsigned        sdatOffs, sdatVirt, sdatSize;
    unsigned        dataOffs, dataVirt, dataSize;
    unsigned        rsrcOffs, rsrcVirt, rsrcSize;
    unsigned        rlocOffs, rlocVirt, rlocSize;
    unsigned        ddbgOffs,           ddbgSize;
    unsigned       /*bssOffs,*/          bssSize;

    unsigned        impAddrRVA;
    size_t          impSdataSize;

    unsigned        strPoolRVA;
    unsigned        strPoolAdr;

    outFile     *   outf;

#ifdef  DLL
    void    *       fileBuff;
#endif

    static
    BYTE            DOSstub[] =
    {
        /*0040*/ 0x0E,              //  PUSH    CS
        /*0041*/ 0x1F,              //  POP     DS
        /*0042*/ 0xE8, 0x00, 0x00,  //  CALL    $+3
        /*0045*/ 0x5A,              //  POP     DX
        /*0046*/ 0x83, 0xC2, 0x0D,  //  ADD     DX,+0D
        /*0049*/ 0xB4, 0x09,        //  MOV     AH,09
        /*004B*/ 0xCD, 0x21,        //  INT     21
        /*004D*/ 0xB8, 0x01, 0x4C,  //  MOV     AX,4C01
        /*0050*/ 0xCD, 0x21,        //  INT     21
        /*0052*/ "This program cannot be run in DOS mode\r\n$\0\0\0\0"
    };

    static
    IMAGE_DOS_HEADER fileHdrTemplate =
    {
        0x5A4D,                     // magic
        0x0090,                     // bytes in last page
        0x0003,                     // number of pages
             0,                     // relocations
        0x0004,                     // header size
             0,                     // min extra
        0xFFFF,                     // max extra
             0,                     // initial SS
        0x0080,                     // initial SP
             0,                     // checksum
             0,                     // initial IP
             0,                     // initial CS
        0x0040,                     // reloc table
             0,                     // overlay num
            {0},                    // reserved
             0,                     // OEM id
             0,                     // OEM info
            {0},                    // reserved
        0x0080,                     // addr of new header
    };

    IMAGE_DOS_HEADER        fileHdr;

    IMAGE_FILE_HEADER       COFFhdr;
    time_t                  COFFstamp;

#if TGT_IA64
    IMAGE_OPTIONAL_HEADER64 OPTLhdr;
#else
    IMAGE_OPTIONAL_HEADER   OPTLhdr;
#endif

    /* Bail if there were any compilation errors */

    if  (errors)
    {
        // UNDONE: Free up all resources, etc.

        return true;
    }

#if TGT_IA64

    /* Add a fake reference to KERNEL32.DLL or the PE32+ file won't load */

    if  (!WPEimpKernelDLL)
        WPEimportAdd("KERNEL32.DLL", "BaseProcessStartThunk");

    /* Are we generating debug info ? */

    if  (PDBname)
    {
        size_t          PDBnlen = strlen(PDBname) + 1;

        #pragma pack(push, 2)

        struct  _dbgDir
        {
            unsigned __int32    ddChar;
            unsigned __int32    ddTime;
            unsigned __int32    ddVer;
            unsigned __int32    ddType;
            unsigned __int32    ddSize;
            unsigned __int32    ddRVA;
            unsigned __int32    ddFpos;
        }
                            dbgDir;

        struct
        {
            unsigned __int32    ddSign;
            unsigned __int32    ddVer1;
            unsigned __int32    ddTime;
            unsigned __int32    ddVer2;
        }
                            dbgTab;

        #pragma pack(pop)

        /* Remember the offset and size of the debug directory */

        ddbgSize = sizeof(dbgDir);
        ddbgOffs = WPEsecNextOffs(PE_SECT_rdata);

        /* Add the debug directory to the rdata section */

        dbgDir.ddChar = 0;
        dbgDir.ddTime = PDBhdr->sig;
        dbgDir.ddVer  = 0;
        dbgDir.ddType = 2;
        dbgDir.ddSize = sizeof(*PDBhdr) + PDBnlen;
        dbgDir.ddRVA  = ddbgOffs + ddbgSize;
        dbgDir.ddFpos = ddbgOffs + ddbgSize;

        WPEsecAddData (PE_SECT_rdata, (BYTE*)&dbgDir, sizeof(dbgDir));

        WPEsecAddFixup(PE_SECT_rdata,
                       PE_SECT_rdata,
                       ddbgOffs + offsetof(_dbgDir,ddRVA));

        WPEsecAddFixup(PE_SECT_rdata,
                       PE_SECT_filepos,
                       ddbgOffs + offsetof(_dbgDir,ddFpos));

        /* Make sure the debug table lands at the expected offset */

        assert(dbgDir.ddRVA == WPEsecNextOffs(PE_SECT_rdata));

        /* Output the debug table (with the PDB filename at the end) */

        WPEsecAddData (PE_SECT_rdata, (BYTE*)PDBhdr , sizeof(*PDBhdr));
        WPEsecAddData (PE_SECT_rdata, (BYTE*)PDBname, PDBnlen);
    }
    else
        ddbgSize = 0;

#else

    assert(PDBname == NULL);

#endif

    /* Drop any image sections that are empty */

    for (sectNum = 0; sectNum < PE_SECT_count; sectNum++)
    {
        /* Get hold of the section entry */

        sectPtr = WPEsecTable[sectNum];
        if  (!sectPtr)
            continue;

        assert(sectPtr->PEsdIndex == (int)sectNum);

        /* Is this section empty? */

        if  (sectPtr->PEsdNext == sectPtr->PEsdBase)
        {
            /* The ".rdata" section is never empty */

            if  (sectNum == PE_SECT_rdata)
                continue;

#if TGT_IA64

            /* The IAT goes into the .sdata section */

            if  (sectNum == PE_SECT_sdata)
                continue;

#endif

            /* Don't drop non-empty ".rsrc"/".reloc" sections */

            if  (sectNum == PE_SECT_rsrc  && WPErsrcSize)
                continue;
            if  (sectNum == PE_SECT_reloc && genDLL)
                continue;

            /* We must have a non-empty .sdata section (not sure why) */

#if TGT_IA64
            assert(sectNum != PE_SECT_sdata);
#endif

            /* Drop this section from the table */

            WPEsecTable[sectNum] = NULL; WPEsectCnt--;
        }
    }

    /* Figure out the virtual base address of the image */

#if TGT_IA64

    virtBase = 0x400000;

#else

    if  (genBase)
    {
        size_t          align;

        /* The base must be a multiple of 64K, at least */

        align = (PEvirtAlignment >= 64*1024) ? PEvirtAlignment
                                             : 64*1024;

        /* The base address was specified, make sure it's aligned */

        virtBase  = genBase;

        virtBase +=  (align - 1);
        virtBase &= ~(align - 1);

        /* The base must be at least 0x400000 */

        if  (virtBase < 0x400000)
             virtBase = 0x400000;
    }
    else
    {
        /* Use the default base address */

        virtBase  = genDLL ? 0x10000000
                           : 0x00400000;
    }

#endif

    WPEvirtBase = virtBase;

    /* Count/reserve space for the file headers */

    fileOffs    = 0;

    /* The first thing is the DOS hader */

    DOS_hdrSize = sizeof(IMAGE_DOS_HEADER);
    DOS_hdrOffs = fileOffs;
                  fileOffs += 0xB8; // DOS_hdrSize;

    /* The PE/COFF headers are next */

    COFFhdrSize = sizeof(IMAGE_FILE_HEADER) + 4;    // 4 bytes = "magic" signature
    COFFhdrOffs = fileOffs;
                  fileOffs += COFFhdrSize;

    OPTLhdrSize = sizeof(IMAGE_OPTIONAL_HEADER);
    OPTLhdrOffs = fileOffs;
                  fileOffs += OPTLhdrSize;

    /* Next comes the section table */

    sectTabSize = sizeof(IMAGE_SECTION_HEADER) * WPEsectCnt;
    sectTabOffs = fileOffs;
                  fileOffs += sectTabSize;

    /* Allocate space for the various sections (properly aligning them) */

    virtOffs = PEvirtAlignment;

    /* Figure out the RVA of the main entry point */

#if!TGT_IA64
    entryOfs  = virtOffs;           // UNDONE: Compute RVA of entry point
    entryAdr  = entryOfs + 2;
#endif

#ifdef  DEBUG

    if  (verbose)
    {
        printf("DOS  header is at 0x%04X (size=0x%02X)\n", DOS_hdrOffs, DOS_hdrSize);
        printf("COFF header is at 0x%04X (size=0x%02X)\n", COFFhdrOffs, COFFhdrSize);
        printf("Opt. header is at 0x%04X (size=0x%02X)\n", OPTLhdrOffs, OPTLhdrSize);
        printf("Section tab is at 0x%04X (size=0x%02X)\n", sectTabOffs, sectTabSize);
        printf("Section[0]  is at 0x%04X\n"              , fileOffs);
    }

#endif

    dataVirt = dataSize =
    rlocVirt = rlocSize =
    rsrcVirt = rsrcSize = bssSize = fImgSize = 0;

    for (sectNum = 0; sectNum < PE_SECT_count; sectNum++)
    {
        size_t          size;
        unsigned        attr;

        /* Get hold of the section entry */

        sectPtr = WPEsecTable[sectNum];
        if  (!sectPtr)
            continue;

        assert(sectPtr->PEsdIndex == (int)sectNum);

        /* Each section must be properly aligned */

        fileOffs = (fileOffs + (PEfileAlignment-1)) & ~(PEfileAlignment-1);
        virtOffs = (virtOffs + (PEvirtAlignment-1)) & ~(PEvirtAlignment-1);

        /* Figure out how much data we've stored in the section */

        size = sectPtr->PEsdSizeData = sectPtr->PEsdNext - sectPtr->PEsdBase;

        /* What kind of a section is this? */

        switch (sectNum)
        {
        case PE_SECT_text:

            /* Check the RVA of the section */

            assert(virtOffs == CODE_BASE_RVA);

            /* Below we'll patch the entry point code sequence */

#if!TGT_IA64
            ecodePtr = (unsigned *)(sectPtr->PEsdBase + 2);
#endif

            /* Remember the code size and base offset */

            codeSize = size;
            codeOffs = fileOffs;
            codeVirt = virtOffs;

            assert(codeVirt == CODE_BASE_RVA);

            attr     = IMAGE_SCN_CNT_CODE  |
                       IMAGE_SCN_MEM_READ  |
                       IMAGE_SCN_MEM_EXECUTE;
            break;

        case PE_SECT_data:

            /* Record the RVA of the .data section */

            WPEdataRVA = virtOffs;

            /* Figure out the size and flags for the section */

            dataSize = size;
            dataOffs = fileOffs;
            dataVirt = virtOffs;

            attr     = IMAGE_SCN_MEM_READ  |
                       IMAGE_SCN_MEM_WRITE |
                       IMAGE_SCN_CNT_INITIALIZED_DATA;
            break;

        case PE_SECT_pdata:

            /* Record the RVA of the .pdata section */

            WPEpdatRVA = virtOffs;

            /* Set the proper attributes */

            pdatSize    = size;
            pdatOffs    = fileOffs;
            pdatVirt    = virtOffs;

            attr        = IMAGE_SCN_MEM_READ  |
                          IMAGE_SCN_CNT_INITIALIZED_DATA;
            break;

#if TGT_IA64

        case PE_SECT_sdata:

            assert(WPEimpOffsIAT == size);

            /* Record the RVA of the .sdata section */

            WPEsdatRVA  = virtOffs;

            /* Add the size and remember the offset of the IAT */

            size       += impSdataSize;
            impAddrRVA  = WPEimpOffsIAT + virtOffs;

            /* Set the proper attributes */

            sdatSize    = size;
            sdatOffs    = fileOffs;
            sdatVirt    = virtOffs;

            attr        = IMAGE_SCN_MEM_READ  |
                          IMAGE_SCN_MEM_WRITE |
                          IMAGE_SCN_CNT_INITIALIZED_DATA;
            break;

#endif

        case PE_SECT_rdata:

            /* Record the RVA of the .rdata section */

            WPErdatRVA = virtOffs;

#if TGT_IA64

            /* Make sure the thing is aligned */

            if  (size & 7)
            {
                NatUns          pads = 8 - (size & 7);
                BYTE *          toss;

                WPEsecRsvData(PE_SECT_rdata, pads, 8, toss);

                size = sectPtr->PEsdSizeData = size + pads;
            }

#endif

            /* Patch the entry code sequence */

#if TGT_IA64
            entryOfs   += virtOffs;
#else
            *ecodePtr   = virtOffs + virtBase + size;
#endif

            /* Finish up the import directory */

            size       += WPEimportDone(size, &impSdataSize);

            /* Remember the IAT address */

#if!TGT_IA64
            impAddrRVA  = WPEimpOffsIAT + rdatVirt;
#endif

            /* Remember the offset and size of the section */

            rdatSize    = size;
            rdatOffs    = fileOffs;
            rdatVirt    = virtOffs;

            attr        = IMAGE_SCN_MEM_READ  |
                          IMAGE_SCN_CNT_INITIALIZED_DATA;
            break;

        case PE_SECT_rsrc:

            /* Record the RVA and size of the .rdata section */

            WPErsrcRVA  = virtOffs;
            size        = sectPtr->PEsdSizeData = WPErsrcSize;

            /* Remember the offset and size of the section */

            rsrcSize    = size;
            rsrcOffs    = fileOffs;
            rsrcVirt    = virtOffs;

            attr        = IMAGE_SCN_MEM_READ  |
                          IMAGE_SCN_CNT_INITIALIZED_DATA;
            break;

        case PE_SECT_reloc:

            assert(genDLL);

            /* The following is kind of lame, but it's good enough for now */

            sectPtr->PEsdSizeData = size = 4 + 4 + 2 * 2;    // space for 2 fixups

            /* Remember the offset and size of the section */

            rlocSize    = size;
            rlocOffs    = fileOffs;
            rlocVirt    = virtOffs;

            attr        = IMAGE_SCN_MEM_READ        |
                          IMAGE_SCN_MEM_DISCARDABLE |
                          IMAGE_SCN_CNT_INITIALIZED_DATA;

            break;

        default:
            UNIMPL(!"check for unusual section type");
        }

#ifdef  DEBUG
        if  (verbose) printf("  Section hdr #%u at 0x%04X = %08X (size=0x%04X)\n", sectNum, fileOffs, virtOffs, size);
#endif

        /* Update the rounded-up file image size */

        fImgSize += roundUp(size, PEvirtAlignment);

        /* Record the flags (read/write, execute, and so on */

        sectPtr->PEsdFlags    = attr;

        /* Assign a file and virtual base offset to the section */

        sectPtr->PEsdAddrFile = fileOffs;
                                fileOffs += size;

        sectPtr->PEsdAddrRVA  = virtOffs;
                                virtOffs += size;
    }

    /* Make sure the size isn't too big */

//  if  (virtOffs > genSize && genSize)
//      warn(WRNpgm2big, virtOffs, genSize);

    /* The file size has to be a page multiple */

    fileOffs = roundUp(fileOffs, PEfileAlignment);

    /* Figure out the RVA of the string pool */

    strPoolRVA = WPEstrPoolBase + dataVirt;
    strPoolAdr = strPoolRVA + virtBase;

    /* Start writing to the output file */

    outf = WPEoutFile = (OutFile)WPEalloc->nraAlloc(sizeof(*outf));

#ifdef  DLL
    if  (*WPEoutFnam == ':' && !stricmp(WPEoutFnam, ":memory:"))
    {
        fileBuff = VirtualAlloc(NULL, fileOffs, MEM_COMMIT, PAGE_READWRITE);
        if  (!fileBuff)
            fatal(ERRnoMemory);

        outf->outFileOpen(WPEcomp, fileBuff);

        WPEcomp->cmpOutputFile = fileBuff;
    }
    else
#endif
        outf->outFileOpen(WPEcomp, WPEoutFnam);

    /* Fill in the DOS file header */

    fileHdr        = fileHdrTemplate;

    fileHdr.e_cblp = (fileOffs        & 511);
    fileHdr.e_cp   = (fileOffs + 511) / 512;

    /* Write out the DOS header */

    outf->outFileWriteData(&fileHdr, sizeof(fileHdr));

    /* Write out the DOS stub */

    assert(outf->outFileOffset() == 16U*fileHdr.e_cparhdr);
    outf->outFileWriteData(DOSstub, sizeof(DOSstub));

    /* Next comes the COFF header */

    assert(outf->outFileOffset() == (unsigned)fileHdr.e_lfanew);
    outf->outFileWriteData(COFFmagic, sizeof(COFFmagic));

    /* Compute the timedate stamp */

    time(&COFFstamp);

    /* Fill in and write out the COFF header */

#if TGT_IA64
    COFFhdr.Machine                     = IMAGE_FILE_MACHINE_IA64;
#else
    COFFhdr.Machine                     = IMAGE_FILE_MACHINE_I386;
#endif
    COFFhdr.NumberOfSections            = WPEsectCnt;
    COFFhdr.TimeDateStamp               = COFFstamp;
    COFFhdr.PointerToSymbolTable        = 0;
    COFFhdr.NumberOfSymbols             = 0;
    COFFhdr.SizeOfOptionalHeader        = sizeof(OPTLhdr);
    COFFhdr.Characteristics             = IMAGE_FILE_EXECUTABLE_IMAGE    |
                                          IMAGE_FILE_32BIT_MACHINE       |
#if TGT_IA64
                                          IMAGE_FILE_LARGE_ADDRESS_AWARE |
#endif
                                          IMAGE_FILE_LINE_NUMS_STRIPPED  |
                                          IMAGE_FILE_LOCAL_SYMS_STRIPPED;

    if  (genDLL)
        COFFhdr.Characteristics |= IMAGE_FILE_DLL;
    else
        COFFhdr.Characteristics |= IMAGE_FILE_RELOCS_STRIPPED;

    outf->outFileWriteData(&COFFhdr, sizeof(COFFhdr));

    /* Next comes the optional COFF header */

    memset(&OPTLhdr, 0, sizeof(OPTLhdr));

#if TGT_IA64
    OPTLhdr.Magic                       = IMAGE_NT_OPTIONAL_HDR64_MAGIC;
#else
    OPTLhdr.Magic                       = IMAGE_NT_OPTIONAL_HDR_MAGIC;
#endif
    OPTLhdr.MajorLinkerVersion          = 7;
//  OPTLhdr.MinorLinkerVersion          = 0;
    OPTLhdr.SizeOfCode                  = roundUp(codeSize, PEfileAlignment);
    OPTLhdr.SizeOfInitializedData       = roundUp(dataSize, PEfileAlignment) + 0x400;
    OPTLhdr.SizeOfUninitializedData     = roundUp( bssSize, PEfileAlignment);
    OPTLhdr.AddressOfEntryPoint         = entryOfs;
    OPTLhdr.BaseOfCode                  = codeVirt;
#if!TGT_IA64
    OPTLhdr.BaseOfData                  = dataVirt;
#endif
    OPTLhdr.ImageBase                   = virtBase;
    OPTLhdr.SectionAlignment            = PEvirtAlignment;
    OPTLhdr.FileAlignment               = PEfileAlignment;
    OPTLhdr.MajorOperatingSystemVersion = 4;
    OPTLhdr.MinorOperatingSystemVersion = 0;
//  OPTLhdr.Win32VersionValue           = 0;
    OPTLhdr.SizeOfImage                 = fImgSize + TGT_page_size;
    OPTLhdr.SizeOfHeaders               = roundUp(sizeof(fileHdr  ) +
                                                  sizeof(DOSstub  ) +
                                                  sizeof(COFFmagic) +
                                                  sizeof(OPTLhdr  ), PEfileAlignment);
//  OPTLhdr.MajorImageVersion           = 0;
//  OPTLhdr.MinorImageVersion           = 0;
#if TGT_IA64
    OPTLhdr.MajorSubsystemVersion       = 5;
#else
    OPTLhdr.MajorSubsystemVersion       = 4;
#endif
//  OPTLhdr.MinorSubsystemVersion       = 0;
//  OPTLhdr.Win32VersionValue           = 0;
    OPTLhdr.Subsystem                   = genSubSys ? genSubSys : 3;
    OPTLhdr.DllCharacteristics          = 0x8000;   // IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE
    OPTLhdr.SizeOfStackReserve          = 0x100000;
    OPTLhdr.SizeOfStackCommit           = TGT_page_size;
    OPTLhdr.SizeOfHeapReserve           = 0x100000;
    OPTLhdr.SizeOfHeapCommit            = TGT_page_size;
//  OPTLhdr.LoaderFlags                 = 0;
    OPTLhdr.NumberOfRvaAndSizes         = IMAGE_NUMBEROF_DIRECTORY_ENTRIES;

    /* Fill in the dictionary */

#if TGT_IA64

    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_EXCEPTION     ].VirtualAddress = pdatVirt;
    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_EXCEPTION     ].Size           = pdatSize;

    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_GLOBALPTR     ].VirtualAddress = sdatVirt;
    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_GLOBALPTR     ].Size           = sdatSize;

    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_DEBUG         ].VirtualAddress = ddbgOffs + rdatVirt;
    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_DEBUG         ].Size           = ddbgSize;

#endif

    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_IMPORT        ].VirtualAddress = WPEimpOffsIDT+rdatVirt;
    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_IMPORT        ].Size           = WPEimpSizeIDT;

    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_IAT           ].VirtualAddress = impAddrRVA;
    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_IAT           ].Size           = WPEimpSizeIAT;

    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_RESOURCE      ].VirtualAddress = rsrcVirt;
    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_RESOURCE      ].Size           = rsrcSize;

    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_BASERELOC     ].VirtualAddress = rlocVirt;
    OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_BASERELOC     ].Size           = rlocSize;

//  OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_COM_DESCRIPTOR].VirtualAddress = WPEcomPlusOffs+rdatVirt;
//  OPTLhdr.DataDirectory[IMAGE_DIRECTORY_ENTRY_COM_DESCRIPTOR].Size           = sizeof(IMAGE_COR20_HEADER);

    /* Write out the optional header */

    outf->outFileWriteData(&OPTLhdr, sizeof(OPTLhdr));

    /* Write out the section table */

    for (sectNum = 0; sectNum < PE_SECT_count; sectNum++)
    {
        size_t                  dataSize;
        IMAGE_SECTION_HEADER    sectHdr;

        /* Get hold of the section entry */

        sectPtr = WPEsecTable[sectNum];
        if  (!sectPtr)
            continue;

        assert(sectPtr->PEsdIndex == (int)sectNum);

        /* The import table size needs to be added for the .rdata section */

        dataSize = sectPtr->PEsdSizeData;
        if  (sectNum == PE_SECT_rdata)
            dataSize += WPEimpSizeAll /* + WPEcomPlusSize */;

#if TGT_IA64
        if  (sectNum == PE_SECT_sdata)
            dataSize += impSdataSize;
#endif

        memcpy(&sectHdr.Name, WPEsecName((WPEstdSects)sectNum), sizeof(sectHdr.Name));

        sectHdr.Misc.VirtualSize     = dataSize;
        sectHdr.VirtualAddress       = sectPtr->PEsdAddrRVA;
        sectHdr.SizeOfRawData        = roundUp(dataSize, PEfileAlignment);
        sectHdr.PointerToRawData     = sectPtr->PEsdAddrFile;
        sectHdr.PointerToRelocations = 0;
        sectHdr.PointerToLinenumbers = 0;
        sectHdr.NumberOfRelocations  = 0;
        sectHdr.NumberOfLinenumbers  = 0;
        sectHdr.Characteristics      = sectPtr->PEsdFlags;

        /* Write out the section table entry */

        outf->outFileWriteData(&sectHdr, sizeof(sectHdr));
    }

    /* Output the contents of all the sections */

    for (sectNum = 0; sectNum < PE_SECT_count; sectNum++)
    {
        size_t          padSize;

        /* Get hold of the section entry */

        sectPtr = WPEsecTable[sectNum];
        if  (!sectPtr)
            continue;

        assert(sectPtr->PEsdIndex == (int)sectNum);

        /* Pad to get to the next file alignment boundary */

        padSize = sectPtr->PEsdAddrFile - outf->outFileOffset(); assert((int)padSize >= 0);

        if  (padSize)
            outf->outFileWritePad(padSize);

        /* Are there any relocs in this section? */

        if  (sectPtr->PEsdRelocs)
        {
            PEreloc         rel;

            for (rel = sectPtr->PEsdRelocs; rel; rel = rel->perNext)
            {
                unsigned        adjustv;
                PEsection       sectDst;
                BYTE        *   patch;

                /* Check for some special cases */

                switch (rel->perSect)
                {

#if TGT_IA64

                case PE_SECT_GPref:     // GP-relative offset

                    WPEcomp->genPatchGPref(sectPtr->PEsdBase + (rel->perOffs & ~0xF),
                                                                rel->perOffs &  0xF);
                    continue;

                case PE_SECT_filepos:   // file position fixup

                    /* Adjust by the file offset of the section */

                    adjustv = sectPtr->PEsdAddrFile;
                    break;

#else

                case PE_SECT_string:    // string pool fixup

                    /* Adjust by the RVA of the string pool */

                    adjustv = (sectNum == PE_SECT_text) ? strPoolRVA
                                                        : strPoolAdr;

                    /* Make sure the string pool has been allocated */

                    assert(WPEstrPoolBase != 0xBEEFCAFE);
                    break;

#endif

                default:

                    /* Get hold of the target section */

                    sectDst = WPEgetSection((WPEstdSects)rel->perSect);

                    /* The value needs to be adjusted by the section's RVA */

                    adjustv = sectDst->PEsdAddrRVA;

                    /* Some refs need to use the "absolute" offset value */

                    if  (rel->perAbs)
                        adjustv += virtBase;

                    break;
                }

                /* Compute the address to be patched */

                patch = sectPtr->PEsdBase + rel->perOffs;

                /* Make sure the patched value is within the section */

                assert(patch + sizeof(int) <= sectPtr->PEsdNext);

                /* Update the value with the section's RVA */

#ifdef  DEBUG
//              printf("Reloc patch: %04X -> %04X\n", *(unsigned *)patch, *(unsigned *)patch + adjustv);
#endif

                *(unsigned *)patch += adjustv;
            }
        }

        /* Output the contents of the section */

        switch (sectNum)
        {
        case PE_SECT_rdata:
#if TGT_IA64
        case PE_SECT_sdata:
#endif

            /* Output the contents of the section if non-empty */

            if  (sectPtr->PEsdSizeData)
                outf->outFileWriteData(sectPtr->PEsdBase, sectPtr->PEsdSizeData);

            /* Output the import table */

            WPEimportGen     (outf, (WPEstdSects)sectNum);

            /* Output the COM+ data */

#if!TGT_IA64
            WPEgenCOMplusData(outf, sectPtr, entryTok);
#endif
            break;

        case PE_SECT_rsrc:

            WPEgenRCcont(outf, sectPtr);
            break;

        case PE_SECT_reloc:
            {
                unsigned    temp;

                /* Output the page RVA and total fixup block size */

                temp = CODE_BASE_RVA; outf->outFileWriteData(&temp, 4);
                temp = 4 + 4 + 2 * 2; outf->outFileWriteData(&temp, 4);

#if TGT_IA64

                UNIMPL("output relocs");

#else

                /* Output the first  offset + type pair */

                assert(entryAdr - CODE_BASE_RVA < 0x1000);

                temp = (IMAGE_REL_BASED_HIGHLOW << 12) + (entryAdr - CODE_BASE_RVA);
                outf->outFileWriteData(&temp, 2);

#endif

                /* Output the second offset + type pair */

                temp = 0;
                outf->outFileWriteData(&temp, 2);
            }
            break;

        default:

            /* Output the contents of the section */

            if  (sectPtr->PEsdSizeData)
                outf->outFileWriteData(sectPtr->PEsdBase, sectPtr->PEsdSizeData);

            break;
        }
    }

    /* Pad the file to a multiple of page size */

    filePad = fileOffs - outf->outFileOffset();

    if  (filePad)
    {
        assert((int)filePad > 0);
        assert((int)filePad < PEfileAlignment);

        outf->outFileWritePad(filePad);
    }

    /* Tell the compiler that we're just about done */

//  WPEcomp->cmpOutputFileDone(outf);

    /* Close the output file and we're done */

    outf->outFileDone();

    if  (!genQuiet)
        printf("// %u bytes written to '%s'\n", fileOffs, WPEoutFnam);

    return  false;
}

/*****************************************************************************
 *
 *  Initialize and shut down the RC file import logic.
 */

void                writePE::WPEinitRCimp()
{
    WPErsrcFile =
    WPErsrcFmap = 0;
    WPErsrcSize = 0;
}

void                writePE::WPEdoneRCimp()
{
    if  (WPErsrcFmap) { CloseHandle(WPErsrcFmap);WPErsrcFmap = 0; }
    if  (WPErsrcFile) { CloseHandle(WPErsrcFile);WPErsrcFile = 0; }
}

/*****************************************************************************
 *
 *  Add a resource file to the output.
 */

bool                writePE::WPEaddRCfile(const char *filename)
{
    UNIMPL(!"WPEaddRCfile() removed");
    return  false;
}

void                writePE::WPEgenRCcont(OutFile  outf, PEsection sect)
{
    UNIMPL(!"WPEgenRCcont() removed");
}

/*****************************************************************************/
#if TGT_IA64
/*****************************************************************************
 *
 *  Add the .data section of the specified file to the output.
 */

void    *           sourceFileImageBase;

void                writePE::WPEaddFileData(const char *filename)
{
    struct  _stat   fileInfo;

    HANDLE          fileFile = 0;
    HANDLE          fileFMap = 0;

    size_t          fileSize;
    const   BYTE  * fileBase;

    /* See if the source file exists */

    if  (_stat(filename, &fileInfo))
        fatal(ERRopenRdErr, filename);

    /* Open the file (we know it exists, but we check for errors anyway) */

    fileFile = CreateFileA(filename, GENERIC_READ,
                                     FILE_SHARE_READ,
                                     NULL,
                                     OPEN_EXISTING,
                                     FILE_ATTRIBUTE_NORMAL,
                                     0);
    if  (!fileFile)
        fatal(ERRopenRdErr, filename);

    /* Create a mapping on the input file */

    fileFMap = CreateFileMappingA(fileFile, NULL, PAGE_READONLY, 0, 0, NULL);
    if  (!fileFMap)
    {
    ERR:
        if  (fileFMap) CloseHandle(fileFMap);
        if  (fileFile) CloseHandle(fileFile);

        return;
    }

    /* Map the whole file into memory for easy access */

    fileSize = fileInfo.st_size;
    fileBase = (const BYTE*)MapViewOfFileEx(fileFMap, FILE_MAP_READ, 0, 0, 0, NULL);
    if  (!fileBase)
        goto ERR;

    IMAGE_DOS_HEADER *  DOShdr = (IMAGE_DOS_HEADER*)fileBase;
    if  (DOShdr->e_magic != IMAGE_DOS_SIGNATURE || DOShdr->e_lfanew == 0)
        goto ERR;

    IMAGE_NT_HEADERS *  hdrPtr = (IMAGE_NT_HEADERS*)(DOShdr->e_lfanew + (NatUns)fileBase);

    if  (hdrPtr->Signature != IMAGE_NT_SIGNATURE)
        goto ERR;
    if  (hdrPtr->FileHeader.SizeOfOptionalHeader != IMAGE_SIZEOF_NT_OPTIONAL_HEADER)
        goto ERR;
    if  (hdrPtr->OptionalHeader.Magic != IMAGE_NT_OPTIONAL_HDR_MAGIC)
        goto ERR;

    IMAGE_SECTION_HEADER *  sectPtr = (IMAGE_SECTION_HEADER*)(hdrPtr+1);
    unsigned                sectCnt = hdrPtr->FileHeader.NumberOfSections;

    do
    {
        if  (!strcmp((char*)sectPtr->Name, ".data"))
            goto GOT_SEC;
    }
    while (++sectPtr, --sectCnt);

    /* No .data section found, just bail */

    WPEsrcDataSize =
    WPEsrcDataRVA  = 0;

    return;

GOT_SEC:

    /* Record the size and RVA of the .data section */

    WPEsrcDataSize = sectPtr->Misc.VirtualSize;
    WPEsrcDataRVA  = sectPtr->VirtualAddress;

    /* Copy the bits to our own .data section */

    WPEsrcDataOffs = WPEsecAddData(PE_SECT_data, fileBase + sectPtr->PointerToRawData,
                                                 WPEsrcDataSize);
}

/*****************************************************************************/
#endif//TGT_IA64
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\pewrite.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef _PEWRITE_H_
#define _PEWRITE_H_
/*****************************************************************************/

#ifndef _OUTFILE_H_
#include "outfile.h"
#endif

/*****************************************************************************/

#pragma warning(disable:4200)

/*****************************************************************************/

const   unsigned    PEfileAlignment  = 512;
const   unsigned    PEvirtAlignment  = TGT_page_size;

/*****************************************************************************/

const   unsigned    PEmaxSections    = 8;

/*****************************************************************************/

const   unsigned    MAX_PE_TEXT_SIZE = 1024*1024*16;
const   unsigned    MAX_PE_DATA_SIZE = 1024*1024*8;
const   unsigned    MAX_PE_SDTA_SIZE = 1024*1024*2; // we use positive offsets
const   unsigned    MAX_PE_RDTA_SIZE = 1024*512;
const   unsigned    MAX_PE_PDTA_SIZE = 1024*16;
const   unsigned    MAX_PE_RLOC_SIZE = 1024*4;

/*****************************************************************************/

const   unsigned    CODE_BASE_RVA    = PEvirtAlignment;  // ISSUE: Not exactly robust!

/*****************************************************************************/

enum    WPEstdSects
{
    PE_SECT_text,
    PE_SECT_pdata,
    PE_SECT_rdata,
    PE_SECT_sdata,
    PE_SECT_data,
    PE_SECT_rsrc,
    PE_SECT_reloc,

    PE_SECT_count,
};

#if TGT_IA64

const   WPEstdSects PE_SECT_filepos = (WPEstdSects)(PE_SECT_count+1);
const   WPEstdSects PE_SECT_GPref   = (WPEstdSects)(PE_SECT_count+2);

#else

const   WPEstdSects PE_SECT_string  = PE_SECT_count;

#endif

/*****************************************************************************/

struct  PErelocDsc;
typedef PErelocDsc *PEreloc;

struct  PErelocDsc
{
    PEreloc         perNext;

    unsigned        perSect     :4;     // enough to store 'PEmaxSections'
    unsigned        perOffs     :27;
    unsigned        perAbs      :1;
};

/*****************************************************************************/

struct  PEsecData;
typedef PEsecData * PEsection;

struct  PEsecData
{
    BYTE    *       PEsdBase;
    BYTE    *       PEsdNext;
    BYTE    *       PEsdLast;
    BYTE    *       PEsdEndp;

    WPEstdSects     PEsdIndex;

    PEreloc         PEsdRelocs;

#ifdef  DEBUG
    bool            PEsdFinished;
#endif

    unsigned        PEsdAddrFile;
    unsigned        PEsdAddrRVA;
    unsigned        PEsdSizeData;
    unsigned        PEsdFlags;
};

/*****************************************************************************
 *
 *  The following is used to build the import tables. We hash all DLL names
 *  along with the imports into a hash table, and keep track of the number
 *  of imports for each DLL and all that.
 */

class   WPEnameRec;
typedef WPEnameRec *WPEname;
struct  WPEndefRec;
typedef WPEndefRec *WPEndef;
class   WPEhashTab;
typedef WPEhashTab *WPEhash;
struct  WPEiDLLdsc;
typedef WPEiDLLdsc *WPEimpDLL;

class   WPEnameRec
{
public:

    WPEname         PEnmNext;       // next name in this hash bucket
    WPEndef         PEnmDefs;       // list of imports for this name

    unsigned        PEnmHash;       // hash value

    unsigned        PEnmOffs;       // offset within hint/name table

    const   char *  PEnmSpelling() { assert(this); return PEnmName; }

    unsigned short  PEnmFlags;      // see PENMF_xxxx below

    unsigned short  PEnmNlen;       // length of the identifier's name
    char            PEnmName[];     // the spelling follows
};

enum    WPEnameFlags
{
    PENMF_IMP_NAME   = 0x01,        // the identifier is an import name
};

class   WPEhashTab
{
public:

    void            WPEhashInit(Compiler        *comp,
                                norls_allocator *alloc,
                                unsigned         count = 512);

    WPEname         WPEhashName(const char * name, bool *isNewPtr);
    WPEndef         WPEhashName(const char * name,
                                WPEimpDLL   owner, bool *isNewPtr);

    norls_allocator*WPEhashAlloc;

    WPEname    *    WPEhashTable;
    unsigned        WPEhashSize;
    unsigned        WPEhashMask;
    Compiler   *    WPEhashComp;

    size_t          WPEhashStrLen;  // total length of all non-DLL strings
};

struct  WPEiDLLdsc                  // describes each imported DLL
{
    WPEimpDLL       PEidNext;       // mext DLL name
    WPEname         PEidName;       // name record for this DLL

    unsigned        PEidIndex;      // each DLL has an index assigned to it
    unsigned        PEidIATbase;    // offset of first IAT entry
    unsigned        PEidILTbase;    // offset of first import lookup entry

    WPEndef         PEidImpList;    // list of imports - head
    WPEndef         PEidImpLast;    // list of imports - tail
    unsigned        PEidImpCnt;     // number of imports in this DLL
};

struct  WPEndefRec                  // describes each unique (DLL,import) pair
{
    WPEndef         PEndNext;       // next import with this name (other DLL's)
    WPEname         PEndName;       // the name entry itself
#if TGT_IA64
    NatUns          PEndIndex;      // used for IA64 code fixups
    NatUns          PEndIAToffs;    // used for IA64 code fixups
#endif
    WPEndef         PEndNextInDLL;  // next import of the same DLL
    WPEimpDLL       PEndDLL;        // the DLL this import comes from
};

#if TGT_IA64

struct NB10I                           // NB10 debug info
{
    DWORD   nb10;                      // NB10
    DWORD   off;                       // offset, always 0
    DWORD   sig;
    DWORD   age;
};

#endif

/*****************************************************************************/

class   writePE
{
private:

    Compiler       *WPEcomp;
    norls_allocator*WPEalloc;
    outFile        *WPEoutFile;

    const   char *  WPEoutFnam;

public:

    /*************************************************************************/
    /* Prepare to output a PE file, flush and write the file to disk         */
    /*************************************************************************/

    bool            WPEinit(Compiler *comp, norls_allocator*alloc);
    bool            WPEdone(bool errors, NatUns entryOfs, const char *PDBname,
                                                          NB10I *     PDBhdr);

    /*************************************************************************/
    /* Set the name of the output file, this better be done (and on time)!   */
    /*************************************************************************/

    void            WPEsetOutputFileName(const char *outfile);


    /*************************************************************************/
    /* Add the .data section of the specified file to the output             */
    /*************************************************************************/

#if TGT_IA64
public:
    void            WPEaddFileData(const char *filename);
#endif

    /*************************************************************************/
    /* Add a resource file to the output image                               */
    /*************************************************************************/

public:
    bool            WPEaddRCfile(const char *filename);

private:
    size_t          WPErsrcSize;

    HANDLE          WPErsrcFile;
    HANDLE          WPErsrcFmap;
    const   BYTE  * WPErsrcBase;

    void            WPEinitRCimp();
    void            WPEdoneRCimp();

    void            WPEgenRCcont(OutFile  outf, PEsection sect);

    /*************************************************************************/
    /* The following members create and manage PE file sections              */
    /*************************************************************************/

private:

    PEsecData       WPEsections[PEmaxSections];
    unsigned        WPEsectCnt;

    PEsecData     * WPEgetSection(WPEstdSects sect)
    {
        assert(sect < PE_SECT_count);
        assert(WPEsecTable[sect]);
        return WPEsecTable[sect];
    }

    PEsection       WPEsecList;
    PEsection       WPEsecLast;

//  unsigned        WPEcodeRVA;             // RVA of the .text  section
    unsigned        WPEpdatRVA;             // RVA of the .pdata section
    unsigned        WPErdatRVA;             // RVA of the .rdata section
    unsigned        WPEsdatRVA;             // RVA of the .sdata section
    unsigned        WPEdataRVA;             // RVA of the .data  section
    unsigned        WPErsrcRVA;             // RVA of the .rsrc  section

    unsigned        WPEvirtBase;

#if TGT_IA64
    bool            WPEimpKernelDLL;
#endif

    PEsection       WPEsecTable[PE_SECT_count];

    static
    const   char    WPEsecNames[PE_SECT_count][IMAGE_SIZEOF_SHORT_NAME];

public:

    const   char *  WPEsecName    (WPEstdSects sect);

    void            WPEaddSection (WPEstdSects sect, unsigned attrs,
                                                     size_t   maxSz);

    unsigned        WPEsecAddrRVA (WPEstdSects sect);
    unsigned        WPEsecAddrVirt(WPEstdSects sect);
    unsigned        WPEsecAddrOffs(WPEstdSects sect, BYTE *   addr);
    size_t          WPEsecSizeData(WPEstdSects sect);
    size_t          WPEsecNextOffs(WPEstdSects sect);

    unsigned        WPEsecRsvData (WPEstdSects sect, size_t       size,
                                                     size_t       align,
                                                     BYTE *     & outRef);

    unsigned        WPEsecAddData (WPEstdSects sect, const BYTE * data,
                                                           size_t size);

    BYTE *          WPEsecAdrData (WPEstdSects sect, unsigned     offs);

    void            WPEsecAddFixup(WPEstdSects ssrc,
                                   WPEstdSects sdst, unsigned     offs,
                                                     bool         abs = false);

    unsigned        WPEgetCodeBase()
    {
        return  CODE_BASE_RVA;
    }

#if TGT_IA64

private:
    size_t          WPEsrcDataSize;
    NatUns          WPEsrcDataRVA;
    NatUns          WPEsrcDataOffs;

public:
    NatUns          WPEsrcDataRef(NatUns offs)
    {
        assert(offs >= WPEsrcDataRVA);
        assert(offs <= WPEsrcDataRVA + WPEsrcDataSize);

        return  offs - WPEsrcDataRVA + WPEsrcDataOffs;
    }

private:

    WPEndef       * WPEimportMap;
    NatUns          WPEimportCnt;

#endif

    unsigned        WPEallocCode  (size_t size, size_t align, BYTE * & dataRef);
    void            WPEallocString(size_t size, size_t align, BYTE * & dataRef);
private:
    unsigned        WPEstrPoolBase;

    /*************************************************************************/
    /* The following members manage the import tables                        */
    /*************************************************************************/

    WPEhash         WPEimpHash;

    void    *       WPEcorMain;             // IAT entry for _CorMain

    unsigned        WPEimpDLLcnt;
    WPEimpDLL       WPEimpDLLlist;
    WPEimpDLL       WPEimpDLLlast;

    unsigned        WPEimpSizeAll;          // size of all import tables

    unsigned        WPEimpOffsIAT;          // offset of the IAT
    unsigned        WPEimpSizeIAT;          // size   of the IAT

    unsigned        WPEimpOffsIDT;          // offset of the import directory
    unsigned        WPEimpSizeIDT;          // size   of the import directory

    unsigned        WPEimpOffsLook;         // offset of the lookup    table
    unsigned        WPEimpOffsName;         // offset of the name/hint table
    unsigned        WPEimpOffsDLLn;         // offset of the DLL name  table

    unsigned        WPEimpDLLstrLen;        // length of all DLL  strings

    void            WPEimportInit();
    size_t          WPEimportDone(unsigned offs, size_t *sdatSzPtr);
    void            WPEimportGen (OutFile  outf, WPEstdSects sectNum);

public:

#if     TGT_IA64

    NatUns          WPEimportRef (void *imp, NatUns offs, NatUns slot);

#ifdef  DEBUG
    NatUns          WPEimportNum (void *imp)
    {
        WPEndef         nameImp = (WPEndef)imp;

        return  nameImp->PEndIndex;
    }
#endif

    NatUns          WPEimportAddr(NatUns cookie)
    {
        assert(cookie < WPEimportCnt);
        assert(WPEimportMap[cookie]->PEndIndex == cookie);

        return  WPEimportMap[cookie]->PEndIAToffs;
    }

#endif

    void          * WPEimportAdd (const char *DLLname, const char *impName);
};

/*****************************************************************************/

inline
unsigned            writePE::WPEsecAddrRVA (WPEstdSects sect)
{
    PEsecData     * sec = WPEgetSection(sect);

    assert(sec->PEsdFinished);
    return sec->PEsdAddrFile;
}

inline
unsigned            writePE::WPEsecAddrVirt(WPEstdSects sect)
{
    PEsecData     * sec = WPEgetSection(sect);

    assert(sec->PEsdFinished);
    return sec->PEsdAddrRVA;
}

inline
size_t              writePE::WPEsecSizeData(WPEstdSects sect)
{
    PEsecData     * sec = WPEgetSection(sect);

    assert(sec->PEsdFinished);
    return sec->PEsdSizeData;
}

inline
size_t              writePE::WPEsecNextOffs(WPEstdSects sect)
{
    PEsecData     * sec = WPEgetSection(sect);

    return sec->PEsdNext - sec->PEsdBase;
}

/*****************************************************************************/
#endif//_PEWRITE_H_
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\pdb.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
// Debug Information API

#ifndef _VC_VER_INC
#include "vcver.h"
#endif

#ifndef __PDB_INCLUDED__
#define __PDB_INCLUDED__

typedef int BOOL;
typedef unsigned UINT;
typedef unsigned char BYTE;
typedef unsigned short WORD;
typedef unsigned long DWORD;
typedef unsigned __int64 DWORDLONG;
typedef unsigned short USHORT;
typedef unsigned long ULONG;
typedef ULONG   INTV;       // interface version number
typedef ULONG   IMPV;       // implementation version number
typedef ULONG   SIG;        // unique (across PDB instances) signature
typedef ULONG   AGE;        // no. of times this instance has been updated
typedef const char*     SZ_CONST;   // const string

#ifndef GUID_DEFINED
#define GUID_DEFINED

typedef struct _GUID {          // size is 16
    DWORD Data1;
    WORD   Data2;
    WORD   Data3;
    BYTE  Data4[8];
} GUID;

#endif // !GUID_DEFINED

#ifndef _WCHAR_T_DEFINED
typedef unsigned short wchar_t;
#define _WCHAR_T_DEFINED
#endif

enum {
    PDBIntv70   = 19990511,
    PDBIntv61   = 19980914,
    PDBIntv50a  = 19970116,
    PDBIntv60   = PDBIntv50a,
    PDBIntv50   = 19960502,
    PDBIntv41   = 920924,
    PDBIntvAlt  = PDBIntv50,   // Alternate (backward compatible) supported interface
    PDBIntvAlt2 = PDBIntv60,   // Alternate (backward compatible) supported interface
    PDBIntvAlt3 = PDBIntv61,
    PDBIntv     = PDBIntv70,
};

enum {
    niNil        = 0,
    PDB_MAX_PATH = 260,
    cbErrMax     = 1024,
};

// cvinfo.h type index, intentionally typedef'ed here to check equivalence.
typedef unsigned short  CV_typ16_t;
typedef unsigned long   CV_typ_t;

typedef CV_typ_t        TI;     // PDB name for type index
typedef CV_typ16_t      TI16;   // 16-bit version
typedef unsigned long   NI;     // name index
typedef TI *            PTi;
typedef TI16 *          PTi16;

typedef BYTE            ITSM;   // type server map index
typedef ITSM*           PITSM;

typedef BOOL    (__stdcall *PFNVALIDATEDEBUGINFOFILE) (const char * szFile, ULONG * errcode );

typedef struct _tagSEARCHDEBUGINFO {
    DWORD   cb;                         // doubles as version detection
    BOOL    fMainDebugFile;             // indicates "core" or "ancilliary" file
                                        // eg: main.exe has main.pdb and foo.lib->foo.pdb
    char *  szMod;                      // exe/dll
    char *  szLib;                      // lib if appropriate
    char *  szObj;                      // object file
    char * *rgszTriedThese;             // list of ones that were tried,
                                        // NULL terminated list of LSZ's
    char  szValidatedFile[PDB_MAX_PATH];// output of validated filename,
    PFNVALIDATEDEBUGINFOFILE
            pfnValidateDebugInfoFile;   // validation function
    char *  szExe;                      // exe/dll
} SEARCHDEBUGINFO, *PSEARCHDEBUGINFO;

typedef BOOL ( __stdcall * PfnFindDebugInfoFile) ( PSEARCHDEBUGINFO );

#define PdbInterface struct

PdbInterface PDB;                   // program database
PdbInterface DBI;                   // debug information within the PDB
PdbInterface Mod;                   // a module within the DBI
PdbInterface TPI;                   // type info within the DBI
PdbInterface GSI;                   // global symbol info
PdbInterface SO;
PdbInterface Stream;                // some named bytestream in the PDB
PdbInterface StreamImage;           // some memory mapped stream
PdbInterface NameMap;              // name mapping
PdbInterface Enum;                 // generic enumerator
PdbInterface EnumNameMap;          // enumerate names within a NameMap
PdbInterface EnumContrib;          // enumerate contributions
PdbInterface Dbg;                   // misc debug data (FPO, OMAP, etc)
PdbInterface Src;                   // Src file data
PdbInterface EnumSrc;               // Src file enumerator

typedef PdbInterface PDB PDB;
typedef PdbInterface DBI DBI;
typedef PdbInterface Mod Mod;
typedef PdbInterface TPI TPI;
typedef PdbInterface GSI GSI;
typedef PdbInterface SO SO;
typedef PdbInterface Stream Stream;
typedef PdbInterface StreamImage StreamImage;
typedef PdbInterface NameMap NameMap;
typedef PdbInterface Enum Enum;
typedef PdbInterface EnumStreamNames EnumStreamNames;
typedef PdbInterface EnumNameMap EnumNameMap;
typedef PdbInterface EnumContrib EnumContrib;
typedef PdbInterface WidenTi WidenTi;
typedef PdbInterface Dbg Dbg;
typedef PdbInterface EnumThunk EnumThunk;
typedef PdbInterface Src Src;
typedef PdbInterface EnumSrc EnumSrc;


typedef long EC;            // error code
enum PDBErrors {
    EC_OK,                  // -, no problemo
    EC_USAGE,               // -, invalid parameter or call order
    EC_OUT_OF_MEMORY,       // -, out of RAM
    EC_FILE_SYSTEM,         // "pdb name", can't write file, out of disk, etc.
    EC_NOT_FOUND,           // "pdb name", PDB file not found
    EC_INVALID_SIG,         // "pdb name", PDB::OpenValidate() and its clients only
    EC_INVALID_AGE,         // "pdb name", PDB::OpenValidate() and its clients only
    EC_PRECOMP_REQUIRED,    // "obj name", Mod::AddTypes() only
    EC_OUT_OF_TI,           // "pdb name", TPI::QueryTiForCVRecord() only
    EC_NOT_IMPLEMENTED,     // -
    EC_V1_PDB,              // "pdb name", PDB::Open* only
    EC_FORMAT,              // accessing pdb with obsolete format
    EC_LIMIT,
    EC_CORRUPT,             // cv info corrupt, recompile mod
    EC_TI16,                // no 16-bit type interface present
    EC_ACCESS_DENIED,       // "pdb name", PDB file read-only
    EC_ILLEGAL_TYPE_EDIT,   // trying to edit types in read-only mode
    EC_INVALID_EXECUTABLE,  // not recogized as a valid executable
    EC_DBG_NOT_FOUND,       // A required .DBG file was not found
    EC_NO_DEBUG_INFO,       // No recognized debug info found
    EC_INVALID_EXE_TIMESTAMP, // Invalid timestamp on Openvalidate of exe
    EC_RESERVED, // RESERVED for future use
    EC_DEBUG_INFO_NOT_IN_PDB, // returned by OpenValidateX
    EC_MAX
};

#define  pure = 0

#ifndef PDBCALL
#define PDBCALL  __cdecl
#endif

#ifdef PDB_SERVER
#define PDB_IMPORT_EXPORT(RTYPE)    __declspec(dllexport) RTYPE PDBCALL
#elif   defined(PDB_LIBRARY)
#define PDB_IMPORT_EXPORT(RTYPE)    RTYPE PDBCALL
#else
#define PDB_IMPORT_EXPORT(RTYPE)    __declspec(dllimport) RTYPE PDBCALL
#endif

#define PDBAPI PDB_IMPORT_EXPORT

#ifndef IN
#define IN                  /* in parameter, parameters are IN by default */
#endif
#ifndef OUT
#define OUT                 /* out parameter */
#endif

// type of callback arg to PDB::OpenValidate5
typedef void (PDBCALL *PfnPDBDebugDir)(BOOL, const struct _IMAGE_DEBUG_DIRECTORY *);

// type of callback arg to PDB::GetRawBytes
typedef BOOL (PDBCALL *PFNfReadPDBRawBytes)(const void *, long);

// WidenTi interface needs a couple of structures to communicate info back
// and forth.
struct OffMap {
    ULONG       offOld;
    ULONG       offNew;
};
typedef struct OffMap   OffMap;
typedef OffMap *        POffMap;

struct SymConvertInfo {
    ULONG       cbSyms;             // size necessary for converting a block
    ULONG       cSyms;              // count of symbols, necessary to allocate
                                    // mpoffOldoffNew array.
    BYTE *      pbSyms;             // block of symbols (output side)
    OffMap *    rgOffMap;           // OffMap rgOffMap[cSyms]
};
typedef struct SymConvertInfo   SymConvertInfo;
enum { wtiSymsNB09 = 0, wtiSymsNB10 = 1 };

// Filter values for PDBCopyTo
enum {
    copyRemovePrivate       = 0x00000001,   // remove private debug information
    copyCreateNewSig        = 0x00000002,   // create new signature for target pdb
};

enum DBGTYPE {
    dbgtypeFPO,
    dbgtypeException,
    dbgtypeFixup,
    dbgtypeOmapToSrc,
    dbgtypeOmapFromSrc,
    dbgtypeSectionHdr,
};

typedef enum DBGTYPE DBGTYPE;

// Linker data necessary for relinking an image.  Record contains two SZ strings
// off of the end of the record with two offsets from the base
//
enum VerLinkInfo {
    vliOne = 1,
    vliTwo = 2,
    vliCur = vliTwo,
};

struct LinkInfo {
    ULONG           cb;             // size of the whole record.  computed as
                                    //  sizeof(LinkInfo) + strlen(szCwd) + 1 +
                                    //  strlen(szCommand) + 1
    ULONG           ver;            // version of this record (VerLinkInfo)
    ULONG           offszCwd;       // offset from base of this record to szCwd
    ULONG           offszCommand;   // offset from base of this record
    ULONG           ichOutfile;     // index of start of output file in szCommand
    ULONG           offszLibs;      // offset from base of this record to szLibs

    // The command includes the full path to the linker, the -re and -out:...
    // swithches.
    // A sample might look like the following:
    // "c:\program files\msdev\bin\link.exe -re -out:debug\foo.exe"
    // with ichOutfile being 48.
    // the -out switch is guaranteed to be the last item in the command line.
#ifdef __cplusplus
    VerLinkInfo Ver() const {
        return VerLinkInfo(ver);
    }
    long Cb() const {
        return cb;
    }
    char *     SzCwd() const {
        return (char *)((char *)(this) + offszCwd);
    }
    char *    SzCommand() const {
        return (char *)((char *)(this) + offszCommand);
    }
    char *    SzOutFile() const {
        return SzCommand() + ichOutfile;
    }
    LinkInfo() :
        cb(0), ver(vliCur), offszCwd(0), offszCommand(0), ichOutfile(0)
    {
    }
    char *    SzLibs() const {
        return (char *)((char *)(this) + offszLibs);
    }

#endif
};

#ifdef LNGNM
#ifdef __cplusplus
struct LinkInfoW : public LinkInfo
{
    wchar_t* SzCwdW() const {
        return (wchar_t *)((wchar_t *)(this) + offszCwd);
    }
    wchar_t* SzCommandW() const {
        return (wchar_t *)((wchar_t *)(this) + offszCommand);
    }
    wchar_t* SzOutFileW() const {
        return SzCommandW() + ichOutfile;
    }
    wchar_t* SzLibsW() const {
        return (wchar_t *)((wchar_t *)(this) + offszLibs);
    }
};
#else
typedef struct LinkInfo LinkInfoW;
#endif  // __cplusplus

typedef LinkInfoW * PLinkInfoW;

#endif  // LNGNM

typedef struct LinkInfo LinkInfo;
typedef LinkInfo *      PLinkInfo;


//
// Source (Src) info
//
// This is the source file server for virtual and real source code.
// It is structured as an index on the object file name concatenated
// with
enum SrcVer {
    srcverOne = 19980827,
};

enum SrcCompress {
    srccompressNone,
    srccompressRLE,
    srccompressHuffman,
    srccompressLZ,
};

#ifdef LNGNM
struct tagSrcHeader {
#else
struct SrcHeader {
#endif
    unsigned long   cb;         // record length
    unsigned long   ver;        // header version
    unsigned long   sig;        // CRC of the data for uniqueness w/o full compare
    unsigned long   cbSource;   // count of bytes of the resulting source
    unsigned char   srccompress;// compression algorithm used
    union {
        unsigned char       grFlags;
        struct {
            unsigned char   fVirtual : 1;   // file is a virtual file (injected)
            unsigned char   pad : 7;        // must be zero
        };
    };
#ifndef LNGNM
    unsigned char   szNames[1]; // file names (szFile "\0" szObj "\0" szVirtual,
                                //  as in: "f.cpp" "\0" "f.obj" "\0" "*inj:1:f.obj")
                                // in the case of non-virtual files, szVirtual is
                                // the same as szFile.
#endif
};

#ifdef LNGNM
struct SrcHeader : public tagSrcHeader
{
    unsigned char szNames[1];   // see comment above
};

struct SrcHeaderW : public tagSrcHeader
{
    wchar_t szNames[1];   // see comment above
};

typedef struct SrcHeaderW    SrcHeaderW;
typedef SrcHeaderW *         PSrcHeaderW;
typedef const SrcHeaderW *   PCSrcHeaderW;

//cassert(offsetof(SrcHeader,szNames) == sizeof(tagSrcHeader));
//cassert(offsetof(SrcHeaderW,szNames) == sizeof(tagSrcHeader));

#endif      // LNGNM

typedef struct SrcHeader    SrcHeader;
typedef SrcHeader *         PSrcHeader;
typedef const SrcHeader *   PCSrcHeader;

// header used for storing the info and for output to clients who are reading
//
struct SrcHeaderOut {
    unsigned long   cb;         // record length
    unsigned long   ver;        // header version
    unsigned long   sig;        // CRC of the data for uniqueness w/o full compare
    unsigned long   cbSource;   // count of bytes of the resulting source
    unsigned long   niFile;
    unsigned long   niObj;
    unsigned long   niVirt;
    unsigned char   srccompress;// compression algorithm used
    union {
        unsigned char       grFlags;
        struct {
            unsigned char   fVirtual : 1;   // file is a virtual file (injected)
            unsigned char   pad : 7;        // must be zero
        };
    };
    short           sPad;
    union {
        void *      pvReserved1;
        __int64     pv64Reserved2;
    };
};

typedef struct SrcHeaderOut SrcHeaderOut;
typedef SrcHeaderOut *      PSrcHeaderOut;
typedef const SrcHeaderOut *PCSrcHeaderOut;

struct SrcHeaderBlock {
    __int32     ver;
    __int32     cb;
    struct {
        DWORD   dwLowDateTime;
        DWORD   dwHighDateTime;
    } ft;
    __int32     age;
    BYTE        rgbPad[44];
};

typedef struct SrcHeaderBlock   SrcHeaderBlock;


#ifdef __cplusplus

struct IStream;

// C++ Binding

PdbInterface PDB {                 // program database
    enum {
        intv  = PDBIntv,
        intvAlt = PDBIntvAlt,
        intvAlt2 = PDBIntvAlt2,
        intvAlt3 = PDBIntvAlt3,
    };

    static PDBAPI(BOOL)
           OpenValidate(
               /* const */ char *szPDB,
               /* const */ char *szPath,
               /* const */ char *szMode,
               SIG sig,
               AGE age,
               OUT EC* pec,
               OUT char szError[cbErrMax],
               OUT PDB **pppdb);

    static PDBAPI(BOOL)
           OpenValidateEx(
               /* const */ char *szPDB,
               /* const */ char *szPathOrig,
               /* const */ char *szSearchPath,
               /* const */ char *szMode,
               SIG sig,
               AGE age,
               OUT EC *pec,
               OUT char szError[cbErrMax],
               OUT PDB **pppdb);

    static PDBAPI(BOOL)
           Open(
               /* const */ char *szPDB,
               /* const */ char *szMode,
               SIG sigInitial,
               OUT EC *pec,
               OUT char szError[cbErrMax],
               OUT PDB **pppdb);

    static PDBAPI(BOOL)
           OpenValidate2(
               /* const */ char *szPDB,
               /* const */ char *szPath,
               /* const */ char *szMode,
               SIG sig,
               AGE age,
               long cbPage,
               OUT EC *pec,
               OUT char szError[cbErrMax],
               OUT PDB **pppdb);

    static PDBAPI(BOOL)
           OpenValidateEx2(
               /* const */ char *szPDB,
               /* const */ char *szPathOrig,
               /* const */ char *szSearchPath,
               /* const */ char *szMode,
               SIG sig,
               AGE age,
               long cbPage,
               OUT EC* pec,
               OUT char szError[cbErrMax],
               OUT PDB **pppdb);

    static PDBAPI(BOOL)
           OpenEx(
               /* const */ char *szPDB,
               /* const */ char *szMode,
               SIG sigInitial,
               long cbPage,
               OUT EC *pec,
               OUT char szError[cbErrMax],
               OUT PDB **pppdb);

    static PDBAPI(BOOL)
           OpenValidate3(
               const char *szExecutable,
               const char *szSearchPath,
               OUT EC *pec,
               OUT char szError[cbErrMax],
               OUT char szDbgPath[PDB_MAX_PATH],
               OUT DWORD *pfo,
               OUT DWORD *pcb,
               OUT PDB **pppdb);

    static PDBAPI(BOOL)
           OpenValidate4(
               const wchar_t *wszPDB,
               const char *szMode,
               const struct _GUID *pguidSig,
               SIG sig,
               AGE age,
               OUT EC *pec,
               OUT wchar_t *wszError,
               size_t cchErrMax,
               OUT PDB **pppdb);

    static PDBAPI(BOOL) OpenInStream(
               IStream *pIStream,
               const char *szMode,
               OUT EC *pec,
               OUT wchar_t *wszError,
               size_t cchErrMax,
               OUT PDB **pppdb);

    static PDBAPI(BOOL) ExportValidateInterface(INTV intv);
    virtual INTV QueryInterfaceVersion() pure;
    virtual IMPV QueryImplementationVersion() pure;
    virtual EC   QueryLastError(OUT char szError[cbErrMax]) pure;
    virtual char*QueryPDBName(OUT char szPDB[PDB_MAX_PATH]) pure;
    virtual SIG  QuerySignature() pure;
    virtual AGE  QueryAge() pure;
    virtual BOOL CreateDBI(const char* szTarget, OUT DBI** ppdbi) pure;
    virtual BOOL OpenDBI(const char* szTarget, const char* szMode, OUT DBI** ppdbi ) pure;
    virtual BOOL OpenTpi(const char* szMode, OUT TPI** pptpi) pure;

    virtual BOOL Commit() pure;
    virtual BOOL Close() pure;
    virtual BOOL OpenStream(const char* szStream, OUT Stream** ppstream) pure;
    virtual BOOL GetEnumStreamNameMap(OUT Enum** ppenum) pure;
    virtual BOOL GetRawBytes(PFNfReadPDBRawBytes fSnarfRawBytes) pure;
    virtual IMPV QueryPdbImplementationVersion() pure;

    virtual BOOL OpenDBIEx(const char* szTarget, const char* szMode, OUT DBI** ppdbi, PfnFindDebugInfoFile pfn=0) pure;

    virtual BOOL CopyTo(const char *szDst, DWORD dwCopyFilter, DWORD dwReserved) pure;

    //
    // support for source file data
    //
    virtual BOOL OpenSrc(OUT Src** ppsrc) pure;

    virtual EC   QueryLastErrorExW(OUT wchar_t *wszError, size_t cchMax) pure;
    virtual wchar_t *QueryPDBNameExW(OUT wchar_t *wszPDB, size_t cchMax) pure;
    virtual BOOL QueryGuid(struct _GUID *pguid) pure;
    virtual BOOL CopyToW(const wchar_t *szDst, DWORD dwCopyFilter, DWORD dwReserved) pure;

    inline BOOL ValidateInterface()
    {
        return ExportValidateInterface(intv);
    }

    static PDBAPI(BOOL)
           Open2W(
               const wchar_t *wszPDB,
               const char *szMode,
               OUT EC *pec,
               OUT wchar_t *wszError,
               size_t cchErrMax,
               OUT PDB **pppdb);

    static PDBAPI(BOOL)
           OpenEx2W(
               const wchar_t *wszPDB,
               const char *szMode,
               long cbPage,
               OUT EC *pec,
               OUT wchar_t *wszError,
               size_t cchErrMax,
               OUT PDB **pppdb);

    static PDBAPI(BOOL)
           OpenValidate5(
               const wchar_t *wszExecutable,
               const wchar_t *wszSearchPath,
               PfnPDBDebugDir pfndbgdir,
               OUT wchar_t *wszDbgPath,
               size_t cchDbgMax,
               OUT EC *pec,
               OUT wchar_t *wszError,
               size_t cchErrMax,
               OUT PDB **pppdb);


#ifdef LNGNM
    virtual BOOL fIsSZPDB() pure;

    static PDBAPI(BOOL) OpenW(const wchar_t* szPDB, const char* szMode, SIG sigInitial,
                OUT EC* pec, OUT char szError[cbErrMax], OUT PDB** pppdb);
    static PDBAPI(BOOL) OpenValidate3W(const wchar_t *szExecutable,const wchar_t *szSearchPath,
                OUT EC *pec, OUT char szError[cbErrMax],
                OUT wchar_t szDbgPath[PDB_MAX_PATH], OUT DWORD *pfo, OUT DWORD *pcb,
                OUT PDB **pppdb);
    virtual wchar_t* QueryPDBNameW(OUT wchar_t szPDB[PDB_MAX_PATH]) pure;
    virtual BOOL OpenStreamW(const wchar_t * szStream, OUT Stream** ppstream) pure;
#endif
};


// Review: a stream directory service would be more appropriate
// than Stream::Delete, ...

PdbInterface Stream {
    virtual long   QueryCb() pure;
    virtual BOOL Read(long off, void* pvBuf, long* pcbBuf) pure;
    virtual BOOL Write(long off, void* pvBuf, long cbBuf) pure;
    virtual BOOL Replace(void* pvBuf, long cbBuf) pure;
    virtual BOOL Append(void* pvBuf, long cbBuf) pure;
    virtual BOOL Delete() pure;
    virtual BOOL Release() pure;
    virtual BOOL Read2(long off, void* pvBuf, long cbBuf) pure;
    virtual BOOL Truncate(long cb) pure;
};

PdbInterface StreamImage {
    static PDBAPI(BOOL) open(Stream* pstream, long cb, OUT StreamImage** ppsi);
    virtual long size() pure;
    virtual void* base() pure;
    virtual BOOL noteRead(long off, long cb, OUT void** ppv) pure;
    virtual BOOL noteWrite(long off, long cb, OUT void** ppv) pure;
    virtual BOOL writeBack() pure;
    virtual BOOL release() pure;
};

PdbInterface DBI {             // debug information
    enum { intv = PDBIntv };
    virtual IMPV QueryImplementationVersion() pure;
    virtual INTV QueryInterfaceVersion() pure;
    virtual BOOL OpenMod(const char* szModule, const char* szFile, OUT Mod** ppmod) pure;
    virtual BOOL DeleteMod(const char* szModule) pure;
    virtual BOOL QueryNextMod(Mod* pmod, Mod** ppmodNext) pure;
    virtual BOOL OpenGlobals(OUT GSI **ppgsi) pure;
    virtual BOOL OpenPublics(OUT GSI **ppgsi) pure;
    virtual BOOL AddSec(USHORT isect, USHORT flags, long off, long cb) pure;
    virtual BOOL QueryModFromAddr(USHORT isect, long off, OUT Mod** ppmod,
                    OUT USHORT* pisect, OUT long* poff, OUT long* pcb) pure;
    virtual BOOL QuerySecMap(OUT BYTE* pb, long* pcb) pure;
    virtual BOOL QueryFileInfo(OUT BYTE* pb, long* pcb) pure;
    virtual void DumpMods() pure;
    virtual void DumpSecContribs() pure;
    virtual void DumpSecMap() pure;

    virtual BOOL Close() pure;
    virtual BOOL AddThunkMap(long* poffThunkMap, unsigned nThunks, long cbSizeOfThunk,
                    struct SO* psoSectMap, unsigned nSects,
                    USHORT isectThunkTable, long offThunkTable) pure;
    virtual BOOL AddPublic(const char* szPublic, USHORT isect, long off) pure;
    virtual BOOL getEnumContrib(OUT Enum** ppenum) pure;
    virtual BOOL QueryTypeServer( ITSM itsm, OUT TPI** pptpi ) pure;
    virtual BOOL QueryItsmForTi( TI ti, OUT ITSM* pitsm ) pure;
    virtual BOOL QueryNextItsm( ITSM itsm, OUT ITSM *inext ) pure;
    virtual BOOL QueryLazyTypes() pure;
    virtual BOOL SetLazyTypes( BOOL fLazy ) pure;   // lazy is default and can only be turned off
    virtual BOOL FindTypeServers( OUT EC* pec, OUT char szError[cbErrMax] ) pure;
    virtual void DumpTypeServers() pure;
    virtual BOOL OpenDbg(DBGTYPE dbgtype, OUT Dbg **ppdbg) pure;
    virtual BOOL QueryDbgTypes(OUT DBGTYPE *pdbgtype, OUT long* pcDbgtype) pure;
    // apis to support EnC work
    virtual BOOL QueryAddrForSec(OUT USHORT* pisect, OUT long* poff,
            USHORT imod, long cb, DWORD dwDataCrc, DWORD dwRelocCrc) pure;
    virtual BOOL QuerySupportsEC() pure;
    virtual BOOL QueryPdb( OUT PDB** pppdb ) pure;
    virtual BOOL AddLinkInfo(IN PLinkInfo ) pure;
    virtual BOOL QueryLinkInfo(PLinkInfo, OUT long * pcb) pure;
    // new to vc6
    virtual AGE  QueryAge() const pure;
    virtual void * QueryHeader() const pure;
    virtual void FlushTypeServers() pure;
    virtual BOOL QueryTypeServerByPdb( const char* szPdb, OUT ITSM* pitsm ) pure;

#ifdef LNGNM        // Long filename support
    virtual BOOL OpenModW(const wchar_t* szModule, const wchar_t* szFile, OUT Mod** ppmod) pure;
    virtual BOOL DeleteModW(const wchar_t* szModule) pure;
    virtual BOOL AddPublicW(const wchar_t* szPublic, USHORT isect, long off) pure;
    virtual BOOL QueryTypeServerByPdbW( const wchar_t* szPdb, OUT ITSM* pitsm ) pure;
    virtual BOOL AddLinkInfoW(IN PLinkInfoW ) pure;
#endif

};

PdbInterface Mod {             // info for one module within DBI
    enum { intv = PDBIntv };
    virtual INTV QueryInterfaceVersion() pure;
    virtual IMPV QueryImplementationVersion() pure;
    virtual BOOL AddTypes(BYTE* pbTypes, long cb) pure;
    virtual BOOL AddSymbols(BYTE* pbSym, long cb) pure;
    virtual BOOL AddPublic(const char* szPublic, USHORT isect, long off) pure;
    virtual BOOL AddLines(const char* szSrc, USHORT isect, long offCon, long cbCon, long doff,
                          USHORT lineStart, BYTE* pbCoff, long cbCoff) pure;
    virtual BOOL AddSecContrib(USHORT isect, long off, long cb, ULONG dwCharacteristics) pure;
    virtual BOOL QueryCBName(OUT long* pcb) pure;
    virtual BOOL QueryName(OUT char szName[PDB_MAX_PATH], OUT long* pcb) pure;
    virtual BOOL QuerySymbols(BYTE* pbSym, long* pcb) pure;
    virtual BOOL QueryLines(BYTE* pbLines, long* pcb) pure;

    virtual BOOL SetPvClient(void *pvClient) pure;
    virtual BOOL GetPvClient(OUT void** ppvClient) pure;
    virtual BOOL QuerySecContrib(OUT USHORT* pisect, OUT long* poff, OUT long* pcb, OUT ULONG* pdwCharacteristics) pure;
    virtual BOOL QueryImod(OUT USHORT* pimod) pure;
    virtual BOOL QueryDBI(OUT DBI** ppdbi) pure;
    virtual BOOL Close() pure;
    virtual BOOL QueryCBFile(OUT long* pcb) pure;
    virtual BOOL QueryFile(OUT char szFile[PDB_MAX_PATH], OUT long* pcb) pure;
    virtual BOOL QueryTpi(OUT TPI** pptpi) pure; // return this Mod's Tpi
    // apis to support EnC work
    virtual BOOL AddSecContribEx(USHORT isect, long off, long cb, ULONG dwCharacteristics, DWORD dwDataCrc, DWORD dwRelocCrc) pure;
    virtual BOOL QueryItsm(OUT USHORT* pitsm) pure;
    virtual BOOL QuerySrcFile(OUT char szFile[PDB_MAX_PATH], OUT long* pcb) pure;
    virtual BOOL QuerySupportsEC() pure;
    virtual BOOL QueryPdbFile(OUT char szFile[PDB_MAX_PATH], OUT long* pcb) pure;
    virtual BOOL ReplaceLines(BYTE* pbLines, long cb) pure;
#ifdef LNGNM
    // Long filenames support
    virtual BOOL AddPublicW(const wchar_t* szPublic, USHORT isect, long off) pure;
    virtual BOOL AddLinesW(const wchar_t* szSrc, USHORT isect, long offCon, long cbCon, long doff,
                          USHORT lineStart, BYTE* pbCoff, long cbCoff) pure;
    virtual BOOL QueryNameW(OUT wchar_t szName[PDB_MAX_PATH], OUT long* pcc) pure;
    virtual BOOL QueryFileW(OUT wchar_t szFile[PDB_MAX_PATH], OUT long* pcc) pure;
    virtual BOOL QuerySrcFileW(OUT wchar_t szFile[PDB_MAX_PATH], OUT long* pcc) pure;
    virtual BOOL QueryPdbFileW(OUT wchar_t szFile[PDB_MAX_PATH], OUT long* pcc) pure;
#endif
};

PdbInterface TPI {             // type info

    enum { intv = PDBIntv };

    virtual INTV QueryInterfaceVersion() pure;
    virtual IMPV QueryImplementationVersion() pure;

    virtual BOOL QueryTi16ForCVRecord(BYTE* pb, OUT TI16* pti) pure;
    virtual BOOL QueryCVRecordForTi16(TI16 ti, OUT BYTE* pb, IN OUT long* pcb) pure;
    virtual BOOL QueryPbCVRecordForTi16(TI16 ti, OUT BYTE** ppb) pure;
    virtual TI16 QueryTi16Min() pure;
    virtual TI16 QueryTi16Mac() pure;

    virtual long QueryCb() pure;
    virtual BOOL Close() pure;
    virtual BOOL Commit() pure;

    virtual BOOL QueryTi16ForUDT(char* sz, BOOL fCase, OUT TI16* pti) pure;
    virtual BOOL SupportQueryTiForUDT() pure;

    // the new versions that truly take 32-bit types
    virtual BOOL fIs16bitTypePool() pure;
    virtual BOOL QueryTiForUDT(char* sz, BOOL fCase, OUT TI* pti) pure;
    virtual BOOL QueryTiForCVRecord(BYTE* pb, OUT TI* pti) pure;
    virtual BOOL QueryCVRecordForTi(TI ti, OUT BYTE* pb, IN OUT long* pcb) pure;
    virtual BOOL QueryPbCVRecordForTi(TI ti, OUT BYTE** ppb) pure;
    virtual TI   QueryTiMin() pure;
    virtual TI   QueryTiMac() pure;
    virtual BOOL AreTypesEqual( TI ti1, TI ti2 ) pure;
    virtual BOOL IsTypeServed( TI ti ) pure;
#ifdef LNGNM
    virtual BOOL QueryTiForUDTW(wchar_t* wcs, BOOL fCase, OUT TI* pti) pure;
#endif
};

PdbInterface GSI {
    enum { intv = PDBIntv };
    virtual INTV QueryInterfaceVersion() pure;
    virtual IMPV QueryImplementationVersion() pure;
    virtual BYTE* NextSym (BYTE* pbSym) pure;
    virtual BYTE* HashSym (const char* szName, BYTE* pbSym) pure;
    virtual BYTE* NearestSym (USHORT isect, long off, OUT long* pdisp) pure;      //currently only supported for publics
    virtual BOOL Close() pure;
    virtual BOOL getEnumThunk( USHORT isect, long off, OUT EnumThunk** ppenum ) pure;
    virtual unsigned long OffForSym( BYTE* pbSym ) pure;
    virtual BYTE* SymForOff( unsigned long off ) pure;
#ifdef LNGNM
    virtual BYTE* HashSymW(wchar_t *wcsName, BYTE* pbSym) pure;
#endif
};


PdbInterface NameMap {
    static PDBAPI(BOOL) open(PDB* ppdb, BOOL fWrite, OUT NameMap** ppnm);
    virtual BOOL close() pure;
    virtual BOOL reinitialize() pure;
    virtual BOOL getNi(const char* sz, OUT NI* pni) pure;
    virtual BOOL getName(NI ni, OUT const char** psz) pure;
    virtual BOOL getEnumNameMap(OUT Enum** ppenum) pure;
    virtual BOOL contains(const char* sz, OUT NI* pni) pure;
    virtual BOOL commit() pure;
    virtual BOOL isValidNi(NI ni) pure;
#ifdef LNGNM
    virtual BOOL getNiW(const wchar_t* sz, OUT NI* pni) pure;
    virtual BOOL getNameW(NI ni, OUT wchar_t* szName, IN OUT unsigned long* pcc) pure;
    virtual BOOL containsW(const wchar_t* sz, OUT NI* pni) pure;
#endif
};

#define __ENUM_INCLUDED__
PdbInterface Enum {
    virtual void release() pure;
    virtual void reset() pure;
    virtual BOOL next() pure;
};

PdbInterface EnumNameMap : Enum {
    virtual void get(OUT const char** psz, OUT NI* pni) pure;
};

PdbInterface EnumContrib : Enum {
    virtual void get(OUT USHORT* pimod, OUT USHORT* pisect, OUT long* poff, OUT long* pcb, OUT ULONG* pdwCharacteristics) pure;
    virtual void getCrcs(OUT DWORD* pcrcData, OUT DWORD* pcrcReloc ) pure;
    virtual bool fUpdate(IN long off, IN long cb) pure;
};

PdbInterface EnumThunk: Enum {
        virtual void get( OUT USHORT* pisect, OUT long* poff, OUT long* pcb ) pure;
};

//
// interface to use to widen type indices from 16 to 32 bits
// and store the results in a new location.
//
PdbInterface WidenTi {
public:
    static PDBAPI(BOOL)
    fCreate (
        WidenTi *&,
        unsigned cTypeInitialCache =256,
        BOOL fNB10Syms =wtiSymsNB09
        );

    virtual void
    release() pure;

    virtual BYTE /* TYPTYPE */ *
    pTypeWidenTi ( TI ti16, BYTE /* TYPTYPE */ * ) pure;

    virtual BYTE /* SYMTYPE */ *
    pSymWidenTi ( BYTE /* SYMTYPE */ * ) pure;

    virtual BOOL
    fTypeWidenTiNoCache ( BYTE * pbTypeDst, BYTE * pbTypeSrc, long & cbDst ) pure;

    virtual BOOL
    fSymWidenTiNoCache ( BYTE * pbSymDst, BYTE * pbSymSrc, long & cbDst ) pure;

    virtual BOOL
    fTypeNeedsWidening ( BYTE * pbType ) pure;

    virtual BOOL
    fSymNeedsWidening ( BYTE * pbSym ) pure;

    virtual BOOL
    freeRecord ( void * ) pure;

    // symbol block converters/query.  symbols start at doff from pbSymIn,
    // converted symbols will go at sci.pbSyms + doff, cbSyms are all including
    // doff.
    virtual BOOL
        fQuerySymConvertInfo (
        SymConvertInfo &    sciOut,
        BYTE *              pbSym,
        long                cbSym,
        int                 doff =0
        ) pure;

    virtual BOOL
    fConvertSymbolBlock (
        SymConvertInfo &    sciOut,
        BYTE *              pbSymIn,
        long                cbSymIn,
        int                 doff =0
        ) pure;
};

// interface for managing Dbg data
PdbInterface Dbg {
   // close Dbg Interface
   virtual BOOL Close() pure;
   // return number of elements (NOT bytes)
   virtual long QuerySize() pure;
   // reset enumeration index
   virtual void Reset() pure;
   // skip next celt elements (move enumeration index)
   virtual BOOL Skip(ULONG celt) pure;
   // query next celt elements into user-supplied buffer
   virtual BOOL QueryNext(ULONG celt, OUT void *rgelt) pure;
   // search for an element and fill in the entire struct given a field.
   // Only supported for the following debug types and fields:
   // DBG_FPO              'ulOffStart' field of FPO_DATA
   // DBG_FUNC             'StartingAddress' field of IMAGE_FUNCTION_ENTRY
   // DBG_OMAP             'rva' field of OMAP
   virtual BOOL Find(IN OUT void *pelt) pure;
   // remove debug data
   virtual BOOL Clear() pure;
   // append celt elements
   virtual BOOL Append(ULONG celt, const void *rgelt) pure;
   // replace next celt elements
   virtual BOOL ReplaceNext(ULONG celt, const void *rgelt) pure;
};

PdbInterface Src {
    // close and commit the changes (when open for write)
    virtual bool
    Close() pure;

    // add a source file or file-ette
    virtual bool
    Add(IN PCSrcHeader psrcheader, IN const void * pvData) pure;

    // remove a file or file-ette or all of the injected code for
    // one particular compiland (using the object file name)
    virtual bool
    Remove(IN SZ_CONST szFile) pure;

    // query and copy the header/control data to the output buffer
    virtual bool
    QueryByName(IN SZ_CONST szFile, OUT PSrcHeaderOut psrcheaderOut) const pure;

    // copy the file data (the size of the buffer is in the SrcHeaderOut
    // structure) to the output buffer.
    virtual bool
    GetData(IN PCSrcHeaderOut pcsrcheader, OUT void * pvData) const pure;

    // create an enumerator to traverse all of the files included
    // in the mapping.
    virtual bool
    GetEnum(OUT EnumSrc ** ppenum) const pure;

    // Get the header block (master header) of the Src data.
    // Includes age, time stamp, version, and size of the master stream
    virtual bool
    GetHeaderBlock(SrcHeaderBlock & shb) const pure;
#ifdef LNGNM
    virtual bool RemoveW(IN wchar_t *wcsFile) pure;
    virtual bool QueryByNameW(IN wchar_t *wcsFile, OUT PSrcHeaderOut psrcheaderOut) const pure;
    virtual bool Add(IN PCSrcHeaderW psrcheader, IN const void * pvData) pure;
#endif
};

PdbInterface EnumSrc : Enum {
    virtual void get(OUT PCSrcHeaderOut * ppcsrcheader) pure;
};

#endif  // __cplusplus

// ANSI C Binding

#if __cplusplus
extern "C" {
#endif

typedef BOOL (PDBCALL *PfnPDBOpen)(
    char *,
    char *,
    SIG,
    EC *,
    char [cbErrMax],
    PDB **);

PDBAPI(BOOL)
PDBOpen(
    /* const */ char *szPDB,
    /* const */ char *szMode,
    SIG sigInitial,
    OUT EC *pec,
    OUT char szError[cbErrMax],
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpenEx(
    /* const */ char *szPDB,
    /* const */ char *szMode,
    SIG sigInitial,
    long cbPage,
    OUT EC *pec,
    OUT char szError[cbErrMax],
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpen2W(
    const wchar_t *wszPDB,
    const char *szMode,
    OUT EC *pec,
    OUT wchar_t *wszError,
    size_t cchErrMax,
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpenEx2W(
    const wchar_t *wszPDB,
    const char *szMode,
    long cbPage,
    OUT EC *pec,
    OUT wchar_t *wszError,
    size_t cchErrMax,
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpenValidate(
    /* const */ char *szPDB,
    /* const */ char *szPath,
    /* const */ char *szMode,
    SIG sig,
    AGE age,
    OUT EC* pec,
    OUT char szError[cbErrMax],
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpenValidateEx(
    /* const */ char *szPDB,
    /* const */ char *szPathOrig,
    /* const */ char *szSearchPath,
    /* const */ char *szMode,
    SIG sig,
    AGE age,
    OUT EC *pec,
    OUT char szError[cbErrMax],
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpenValidate2(
    /* const */ char *szPDB,
    /* const */ char *szPath,
    /* const */ char *szMode,
    SIG sig,
    AGE age,
    long cbPage,
    OUT EC *pec,
    OUT char szError[cbErrMax],
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpenValidateEx2(
    /* const */ char *szPDB,
    /* const */ char *szPathOrig,
    /* const */ char *szSearchPath,
    /* const */ char *szMode,
    SIG sig,
    AGE age,
    long cbPage,
    OUT EC* pec,
    OUT char szError[cbErrMax],
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpenValidate3(
    const char *szExecutable,
    const char *szSearchPath,
    OUT EC *pec,
    OUT char szError[cbErrMax],
    OUT char szDbgPath[PDB_MAX_PATH],
    OUT DWORD *pfo,
    OUT DWORD *pcb,
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpenValidate4(
    const wchar_t *wszPDB,
    const char *szMode,
    const struct _GUID *pguidSig,
    SIG sig,
    AGE age,
    OUT EC *pec,
    OUT wchar_t *wszError,
    size_t cchErrMax,
    OUT PDB **pppdb);

PDBAPI(BOOL)
PDBOpenValidate5(
    const wchar_t *wszExecutable,
    const wchar_t *wszSearchPath,
    PfnPDBDebugDir pfndbgdir,
    OUT wchar_t *wszDbgPath,
    size_t cchDbgMax,
    OUT EC *pec,
    OUT wchar_t *wszError,
    size_t cchErrMax,
    OUT PDB **pppdb);

// a dbi client should never call PDBExportValidateInterface directly - use PDBValidateInterface
PDBAPI(BOOL)
PDBExportValidateInterface(
    INTV intv);

__inline BOOL PDBValidateInterface()
{
    return PDBExportValidateInterface(PDBIntv);
}

typedef BOOL (PDBCALL *PfnPDBExportValidateInterface)(INTV);

__inline BOOL PDBValidateInterfacePfn(PfnPDBExportValidateInterface pfn)
{
    return (*pfn)(PDBIntv);
}

PDBAPI(EC)     PDBQueryLastError(PDB *ppdb, OUT char szError[cbErrMax]);
PDBAPI(INTV)   PDBQueryInterfaceVersion(PDB* ppdb);
PDBAPI(IMPV)   PDBQueryImplementationVersion(PDB* ppdb);
PDBAPI(char*)  PDBQueryPDBName(PDB* ppdb, OUT char szPDB[PDB_MAX_PATH]);
PDBAPI(SIG)    PDBQuerySignature(PDB* ppdb);
PDBAPI(AGE)    PDBQueryAge(PDB* ppdb);
PDBAPI(BOOL)   PDBCreateDBI(PDB* ppdb, const char* szTarget, OUT DBI** ppdbi);
PDBAPI(BOOL)   PDBOpenDBIEx(PDB* ppdb, const char* szMode, const char* szTarget, OUT DBI** ppdbi, PfnFindDebugInfoFile pfn);
PDBAPI(BOOL)   PDBOpenDBI(PDB* ppdb, const char* szMode, const char* szTarget, OUT DBI** ppdbi);
PDBAPI(BOOL)   PDBOpenTpi(PDB* ppdb, const char* szMode, OUT TPI** pptpi);
PDBAPI(BOOL)   PDBCommit(PDB* ppdb);
PDBAPI(BOOL)   PDBClose(PDB* ppdb);
PDBAPI(BOOL)   PDBOpenStream(PDB* ppdb, const char* szStream, OUT Stream** ppstream);
PDBAPI(BOOL)   PDBCopyTo(PDB *ppdb, const char *szTargetPdb, DWORD dwCopyFilter, DWORD dwReserved);
PDBAPI(BOOL)   PDBCopyToW(PDB *ppdb, const wchar_t *szTargetPdb, DWORD dwCopyFilter, DWORD dwReserved);
PDBAPI(BOOL)   PDBfIsSZPDB(PDB *ppdb);

PDBAPI(INTV)   DBIQueryInterfaceVersion(DBI* pdbi);
PDBAPI(IMPV)   DBIQueryImplementationVersion(DBI* pdbi);
PDBAPI(BOOL)   DBIOpenMod(DBI* pdbi, const char* szModule, const char* szFile, OUT Mod** ppmod);
PDBAPI(BOOL)   DBIDeleteMod(DBI* pdbi, const char* szModule);
PDBAPI(BOOL)   DBIQueryNextMod(DBI* pdbi, Mod* pmod, Mod** ppmodNext);
PDBAPI(BOOL)   DBIOpenGlobals(DBI* pdbi, OUT GSI **ppgsi);
PDBAPI(BOOL)   DBIOpenPublics(DBI* pdbi, OUT GSI **ppgsi);
PDBAPI(BOOL)   DBIAddSec(DBI* pdbi, USHORT isect, USHORT flags, long off, long cb);
PDBAPI(BOOL)   DBIAddPublic(DBI* pdbi, const char* szPublic, USHORT isect, long off);
PDBAPI(BOOL)   DBIQueryModFromAddr(DBI* pdbi, USHORT isect, long off, OUT Mod** ppmod, OUT USHORT* pisect, OUT long* poff, OUT long* pcb);
PDBAPI(BOOL)   DBIQuerySecMap(DBI* pdbi, OUT BYTE* pb, long* pcb);
PDBAPI(BOOL)   DBIQueryFileInfo(DBI* pdbi, OUT BYTE* pb, long* pcb);
PDBAPI(BOOL)   DBIQuerySupportsEC(DBI* pdbi);
PDBAPI(void)   DBIDumpMods(DBI* pdbi);
PDBAPI(void)   DBIDumpSecContribs(DBI* pdbi);
PDBAPI(void)   DBIDumpSecMap(DBI* pdbi);
PDBAPI(BOOL)   DBIClose(DBI* pdbi);
PDBAPI(BOOL)   DBIAddThunkMap(DBI* pdbi, long* poffThunkMap, unsigned nThunks, long cbSizeOfThunk,
                              struct SO* psoSectMap, unsigned nSects, USHORT isectThunkTable, long offThunkTable);
PDBAPI(BOOL)   DBIGetEnumContrib(DBI* pdbi, OUT Enum** ppenum);
PDBAPI(BOOL)   DBIQueryTypeServer(DBI* pdbi, ITSM itsm, OUT TPI** pptpi );
PDBAPI(BOOL)   DBIQueryItsmForTi(DBI* pdbi, TI ti, OUT ITSM* pitsm );
PDBAPI(BOOL)   DBIQueryNextItsm(DBI* pdbi, ITSM itsm, OUT ITSM *inext );
PDBAPI(BOOL)   DBIQueryLazyTypes(DBI* pdbi);
PDBAPI(BOOL)   DBIFindTypeServers( DBI* pdbi, OUT EC* pec, OUT char szError[cbErrMax] );
PDBAPI(BOOL)   DBIOpenDbg(DBI* pdbi, DBGTYPE dbgtype, OUT Dbg **ppdbg);
PDBAPI(BOOL)   DBIQueryDbgTypes(DBI* pdbi, OUT DBGTYPE *pdbgtype, OUT long* pcDbgtype);
PDBAPI(BOOL)   DBIAddLinkInfo(DBI* pdbi, IN PLinkInfo);
PDBAPI(BOOL)   DBIQueryLinkInfo(DBI* pdbi, PLinkInfo, IN OUT long * pcb);

PDBAPI(INTV)   ModQueryInterfaceVersion(Mod* pmod);
PDBAPI(IMPV)   ModQueryImplementationVersion(Mod* pmod);
PDBAPI(BOOL)   ModAddTypes(Mod* pmod, BYTE* pbTypes, long cb);
PDBAPI(BOOL)   ModAddSymbols(Mod* pmod, BYTE* pbSym, long cb);
PDBAPI(BOOL)   ModAddPublic(Mod* pmod, const char* szPublic, USHORT isect, long off);
PDBAPI(BOOL)   ModAddLines(Mod* pmod, const char* szSrc, USHORT isect, long offCon, long cbCon, long doff,
                           USHORT lineStart, BYTE* pbCoff, long cbCoff);
PDBAPI(BOOL)   ModAddSecContrib(Mod * pmod, USHORT isect, long off, long cb, ULONG dwCharacteristics);
PDBAPI(BOOL)   ModQueryCBName(Mod* pmod, OUT long* pcb);
PDBAPI(BOOL)   ModQueryName(Mod* pmod, OUT char szName[PDB_MAX_PATH], OUT long* pcb);
PDBAPI(BOOL)   ModQuerySymbols(Mod* pmod, BYTE* pbSym, long* pcb);
PDBAPI(BOOL)   ModQueryLines(Mod* pmod, BYTE* pbLines, long* pcb);
PDBAPI(BOOL)   ModSetPvClient(Mod* pmod, void *pvClient);
PDBAPI(BOOL)   ModGetPvClient(Mod* pmod, OUT void** ppvClient);
PDBAPI(BOOL)   ModQuerySecContrib(Mod* pmod, OUT USHORT* pisect, OUT long* poff, OUT long* pcb, OUT ULONG* pdwCharacteristics);
PDBAPI(BOOL)   ModQueryImod(Mod* pmod, OUT USHORT* pimod);
PDBAPI(BOOL)   ModQueryDBI(Mod* pmod, OUT DBI** ppdbi);
PDBAPI(BOOL)   ModClose(Mod* pmod);
PDBAPI(BOOL)   ModQueryCBFile(Mod* pmod, OUT long* pcb);
PDBAPI(BOOL)   ModQueryFile(Mod* pmod, OUT char szFile[PDB_MAX_PATH], OUT long* pcb);
PDBAPI(BOOL)   ModQuerySrcFile(Mod* pmod, OUT char szFile[PDB_MAX_PATH], OUT long* pcb);
PDBAPI(BOOL)   ModQueryPdbFile(Mod* pmod, OUT char szFile[PDB_MAX_PATH], OUT long* pcb);
PDBAPI(BOOL)   ModQuerySupportsEC(Mod* pmod);
PDBAPI(BOOL)   ModQueryTpi(Mod* pmod, OUT TPI** pptpi);
PDBAPI(BOOL)   ModReplaceLines(Mod* pmod, BYTE* pbLines, long cb);

PDBAPI(INTV)   TypesQueryInterfaceVersion(TPI* ptpi);
PDBAPI(IMPV)   TypesQueryImplementationVersion(TPI* ptpi);
// can't use the same api's for 32-bit TIs.
PDBAPI(BOOL)   TypesQueryTiForCVRecordEx(TPI* ptpi, BYTE* pb, OUT TI* pti);
PDBAPI(BOOL)   TypesQueryCVRecordForTiEx(TPI* ptpi, TI ti, OUT BYTE* pb, IN OUT long* pcb);
PDBAPI(BOOL)   TypesQueryPbCVRecordForTiEx(TPI* ptpi, TI ti, OUT BYTE** ppb);
PDBAPI(TI)     TypesQueryTiMinEx(TPI* ptpi);
PDBAPI(TI)     TypesQueryTiMacEx(TPI* ptpi);
PDBAPI(long)   TypesQueryCb(TPI* ptpi);
PDBAPI(BOOL)   TypesClose(TPI* ptpi);
PDBAPI(BOOL)   TypesCommit(TPI* ptpi);
PDBAPI(BOOL)   TypesQueryTiForUDTEx(TPI* ptpi, char* sz, BOOL fCase, OUT TI* pti);
PDBAPI(BOOL)   TypesSupportQueryTiForUDT(TPI*);
PDBAPI(BOOL)   TypesfIs16bitTypePool(TPI*);
// Map all old ones to new ones for new compilands.
#define TypesQueryTiForCVRecord     TypesQueryTiForCVRecordEx
#define TypesQueryCVRecordForTi     TypesQueryCVRecordForTiEx
#define TypesQueryPbCVRecordForTi   TypesQueryPbCVRecordForTiEx
#define TypesQueryTiMin             TypesQueryTiMinEx
#define TypesQueryTiMac             TypesQueryTiMacEx
#define TypesQueryTiForUDT          TypesQueryTiForUDTEx
PDBAPI(BOOL)    TypesAreTypesEqual( TPI* ptpi, TI ti1, TI ti2 );
PDBAPI(BOOL)    TypesIsTypeServed( TPI* ptpi, TI ti );

PDBAPI(BYTE*)  GSINextSym (GSI* pgsi, BYTE* pbSym);
PDBAPI(BYTE*)  GSIHashSym (GSI* pgsi, const char* szName, BYTE* pbSym);
PDBAPI(BYTE*)  GSINearestSym (GSI* pgsi, USHORT isect, long off,OUT long* pdisp);//currently only supported for publics
PDBAPI(BOOL)   GSIClose(GSI* pgsi);
PDBAPI(unsigned long)   GSIOffForSym( GSI* pgsi, BYTE* pbSym );
PDBAPI(BYTE*)   GSISymForOff( GSI* pgsi, unsigned long off );

PDBAPI(long)   StreamQueryCb(Stream* pstream);
PDBAPI(BOOL)   StreamRead(Stream* pstream, long off, void* pvBuf, long* pcbBuf);
PDBAPI(BOOL)   StreamWrite(Stream* pstream, long off, void* pvBuf, long cbBuf);
PDBAPI(BOOL)   StreamReplace(Stream* pstream, void* pvBuf, long cbBuf);
PDBAPI(BOOL)   StreamAppend(Stream* pstream, void* pvBuf, long cbBuf);
PDBAPI(BOOL)   StreamDelete(Stream* pstream);
PDBAPI(BOOL)   StreamTruncate(Stream* pstream, long cb);
PDBAPI(BOOL)   StreamRelease(Stream* pstream);

PDBAPI(BOOL)   StreamImageOpen(Stream* pstream, long cb, OUT StreamImage** ppsi);
PDBAPI(void*)  StreamImageBase(StreamImage* psi);
PDBAPI(long)   StreamImageSize(StreamImage* psi);
PDBAPI(BOOL)   StreamImageNoteRead(StreamImage* psi, long off, long cb, OUT void** ppv);
PDBAPI(BOOL)   StreamImageNoteWrite(StreamImage* psi, long off, long cb, OUT void** ppv);
PDBAPI(BOOL)   StreamImageWriteBack(StreamImage* psi);
PDBAPI(BOOL)   StreamImageRelease(StreamImage* psi);

PDBAPI(BOOL)   NameMapOpen(PDB* ppdb, BOOL fWrite, OUT NameMap** ppnm);
PDBAPI(BOOL)   NameMapClose(NameMap* pnm);
PDBAPI(BOOL)   NameMapReinitialize(NameMap* pnm);
PDBAPI(BOOL)   NameMapGetNi(NameMap* pnm, const char* sz, OUT NI* pni);
PDBAPI(BOOL)   NameMapGetName(NameMap* pnm, NI ni, OUT const char** psz);
PDBAPI(BOOL)   NameMapGetEnumNameMap(NameMap* pnm, OUT Enum** ppenum);
PDBAPI(BOOL)   NameMapCommit(NameMap* pnm);

PDBAPI(void)   EnumNameMapRelease(EnumNameMap* penum);
PDBAPI(void)   EnumNameMapReset(EnumNameMap* penum);
PDBAPI(BOOL)   EnumNameMapNext(EnumNameMap* penum);
PDBAPI(void)   EnumNameMapGet(EnumNameMap* penum, OUT const char** psz, OUT NI* pni);

PDBAPI(void)   EnumContribRelease(EnumContrib* penum);
PDBAPI(void)   EnumContribReset(EnumContrib* penum);
PDBAPI(BOOL)   EnumContribNext(EnumContrib* penum);
PDBAPI(void)   EnumContribGet(EnumContrib* penum, OUT USHORT* pimod, OUT USHORT* pisect, OUT long* poff, OUT long* pcb, OUT ULONG* pdwCharacteristics);
PDBAPI(void)   EnumContribGetCrcs(EnumContrib* penum, OUT DWORD* pcrcData, OUT DWORD* pcrcReloc);
PDBAPI(BOOL)   EnumContribfUpdate(EnumContrib* penum, IN long off, IN long cb);

PDBAPI(SIG)    SigForPbCb(BYTE* pb, size_t cb, SIG sig);
PDBAPI(void)   TruncStFromSz(char *stDst, const char *szSrc, size_t cbSrc);

PDBAPI(BOOL)   DbgClose(Dbg *pdbg);
PDBAPI(long)   DbgQuerySize(Dbg *pdbg);
PDBAPI(void)   DbgReset(Dbg *pdbg);
PDBAPI(BOOL)   DbgSkip(Dbg *pdbg, ULONG celt);
PDBAPI(BOOL)   DbgQueryNext(Dbg *pdbg, ULONG celt, OUT void *rgelt);
PDBAPI(BOOL)   DbgFind(Dbg *pdbg, IN OUT void *pelt);
PDBAPI(BOOL)   DbgClear(Dbg *pdbg);
PDBAPI(BOOL)   DbgAppend(Dbg *pdbg, ULONG celt, const void *rgelt);
PDBAPI(BOOL)   DbgReplaceNext(Dbg *pdbg, ULONG celt, const void *rgelt);

#if __cplusplus
};
#endif

struct SO {
    long off;
    USHORT isect;
    unsigned short pad;
};

#ifndef cbNil
#define cbNil   ((long)-1)
#endif
#define tsNil   ((TPI*)0)
#define tiNil   ((TI)0)
#define imodNil ((USHORT)(-1))

#define pdbWrite                "w"
#define pdbRead                 "r"
#define pdbGetTiOnly            "i"
#define pdbGetRecordsOnly       "c"
#define pdbFullBuild            "f"
#define pdbTypeAppend           "a"
#define pdbRepro                "z"

#endif // __PDB_INCLUDED__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\register.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#if  !  TGT_x86
#error  This file can only be used when targetting x86!
#endif
/*****************************************************************************/
#ifndef REGDEF
#error  Must define REGDEF macro before including this file
#endif
/*****************************************************************************/
/*                  The following is x86 specific                            */
/*****************************************************************************/

REGDEF(EAX,0,0x01,1)
REGDEF(ECX,1,0x02,1)
REGDEF(EDX,2,0x04,1)
REGDEF(EBX,3,0x08,1)

REGDEF(ESP,4,0x10,0)
REGDEF(EBP,5,0x20,0)
REGDEF(ESI,6,0x40,0)
REGDEF(EDI,7,0x80,0)

/* we recycle esp's mask for the pseudo register */
REGDEF(STK,8,0x00,0)

/*****************************************************************************/
#undef  REGDEF
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\regpair.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef PAIRDEF
#error  Must define PAIRDEF macro before including this file
#endif
/*****************************************************************************/

#ifndef PAIRBEG
#define PAIRBEG(reg)
#endif

#ifndef PAIRSTK
#define PAIRSTK(r1,r2) PAIRDEF(r1,r2)
#endif

/*****************************************************************************/
#if     TGT_x86
/*****************************************************************************/
/*                  The following is for x86                                 */
/*****************************************************************************/

//      rlo rhi

PAIRBEG(EAX    )
PAIRDEF(EAX,ECX)
PAIRDEF(EAX,EDX)
PAIRDEF(EAX,EBX)
PAIRDEF(EAX,EBP)
PAIRDEF(EAX,ESI)
PAIRDEF(EAX,EDI)
PAIRSTK(EAX,STK)

PAIRBEG(ECX    )
PAIRDEF(ECX,EAX)
PAIRDEF(ECX,EDX)
PAIRDEF(ECX,EBX)
PAIRDEF(ECX,EBP)
PAIRDEF(ECX,ESI)
PAIRDEF(ECX,EDI)
PAIRSTK(ECX,STK)

PAIRBEG(EDX    )
PAIRDEF(EDX,EAX)
PAIRDEF(EDX,ECX)
PAIRDEF(EDX,EBX)
PAIRDEF(EDX,EBP)
PAIRDEF(EDX,ESI)
PAIRDEF(EDX,EDI)
PAIRSTK(EDX,STK)

PAIRBEG(EBX    )
PAIRDEF(EBX,EAX)
PAIRDEF(EBX,EDX)
PAIRDEF(EBX,ECX)
PAIRDEF(EBX,EBP)
PAIRDEF(EBX,ESI)
PAIRDEF(EBX,EDI)
PAIRSTK(EBX,STK)

PAIRBEG(EBP    )
PAIRDEF(EBP,EAX)
PAIRDEF(EBP,EDX)
PAIRDEF(EBP,ECX)
PAIRDEF(EBP,EBX)
PAIRDEF(EBP,ESI)
PAIRDEF(EBP,EDI)
PAIRSTK(EBP,STK)

PAIRBEG(ESI    )
PAIRDEF(ESI,EAX)
PAIRDEF(ESI,EDX)
PAIRDEF(ESI,ECX)
PAIRDEF(ESI,EBX)
PAIRDEF(ESI,EBP)
PAIRDEF(ESI,EDI)
PAIRSTK(ESI,STK)

PAIRBEG(EDI    )
PAIRDEF(EDI,EAX)
PAIRDEF(EDI,EDX)
PAIRDEF(EDI,ECX)
PAIRDEF(EDI,EBX)
PAIRDEF(EDI,EBP)
PAIRDEF(EDI,ESI)
PAIRSTK(EDI,STK)

PAIRBEG(STK    )
PAIRSTK(STK,EAX)
PAIRSTK(STK,EDX)
PAIRSTK(STK,ECX)
PAIRSTK(STK,EBX)
PAIRSTK(STK,EBP)
PAIRSTK(STK,ESI)
PAIRSTK(STK,EDI)

/*****************************************************************************/
#endif//TGT_x86
/*****************************************************************************/
#if     TGT_SH3
/*****************************************************************************/
/*                  The following is for SH3                                 */
/*****************************************************************************/

//      rlo rhi

PAIRBEG(r00    )
PAIRDEF(r00,r01)
PAIRDEF(r00,r02)
PAIRDEF(r00,r03)
PAIRDEF(r00,r04)
PAIRDEF(r00,r05)
PAIRDEF(r00,r06)
PAIRDEF(r00,r07)
PAIRDEF(r00,r08)
PAIRDEF(r00,r09)
PAIRDEF(r00,r10)
PAIRDEF(r00,r11)
PAIRDEF(r00,r12)
PAIRDEF(r00,r13)
PAIRDEF(r00,r14)
PAIRSTK(r00,STK)

PAIRBEG(r01    )
PAIRDEF(r01,r02)
PAIRDEF(r01,r03)
PAIRDEF(r01,r04)
PAIRDEF(r01,r05)
PAIRDEF(r01,r06)
PAIRDEF(r01,r07)
PAIRDEF(r01,r08)
PAIRDEF(r01,r09)
PAIRDEF(r01,r10)
PAIRDEF(r01,r11)
PAIRDEF(r01,r12)
PAIRDEF(r01,r13)
PAIRDEF(r01,r14)
PAIRSTK(r01,STK)

PAIRBEG(r02    )
PAIRDEF(r02,r00)
PAIRDEF(r02,r01)
PAIRDEF(r02,r03)
PAIRDEF(r02,r04)
PAIRDEF(r02,r05)
PAIRDEF(r02,r06)
PAIRDEF(r02,r07)
PAIRDEF(r02,r08)
PAIRDEF(r02,r09)
PAIRDEF(r02,r10)
PAIRDEF(r02,r11)
PAIRDEF(r02,r12)
PAIRDEF(r02,r13)
PAIRDEF(r02,r14)
PAIRSTK(r02,STK)

PAIRBEG(r03    )
PAIRDEF(r03,r00)
PAIRDEF(r03,r01)
PAIRDEF(r03,r02)
PAIRDEF(r03,r04)
PAIRDEF(r03,r05)
PAIRDEF(r03,r06)
PAIRDEF(r03,r07)
PAIRDEF(r03,r08)
PAIRDEF(r03,r09)
PAIRDEF(r03,r10)
PAIRDEF(r03,r11)
PAIRDEF(r03,r12)
PAIRDEF(r03,r13)
PAIRDEF(r03,r14)
PAIRSTK(r03,STK)

PAIRBEG(r04    )
PAIRDEF(r04,r00)
PAIRDEF(r04,r01)
PAIRDEF(r04,r02)
PAIRDEF(r04,r03)
PAIRDEF(r04,r05)
PAIRDEF(r04,r06)
PAIRDEF(r04,r07)
PAIRDEF(r04,r08)
PAIRDEF(r04,r09)
PAIRDEF(r04,r10)
PAIRDEF(r04,r11)
PAIRDEF(r04,r12)
PAIRDEF(r04,r13)
PAIRDEF(r04,r14)
PAIRSTK(r04,STK)

PAIRBEG(r05    )
PAIRDEF(r05,r00)
PAIRDEF(r05,r01)
PAIRDEF(r05,r02)
PAIRDEF(r05,r03)
PAIRDEF(r05,r04)
PAIRDEF(r05,r06)
PAIRDEF(r05,r07)
PAIRDEF(r05,r08)
PAIRDEF(r05,r09)
PAIRDEF(r05,r10)
PAIRDEF(r05,r11)
PAIRDEF(r05,r12)
PAIRDEF(r05,r13)
PAIRDEF(r05,r14)
PAIRSTK(r05,STK)

PAIRBEG(r06    )
PAIRDEF(r06,r00)
PAIRDEF(r06,r01)
PAIRDEF(r06,r02)
PAIRDEF(r06,r03)
PAIRDEF(r06,r04)
PAIRDEF(r06,r05)
PAIRDEF(r06,r07)
PAIRDEF(r06,r08)
PAIRDEF(r06,r09)
PAIRDEF(r06,r10)
PAIRDEF(r06,r11)
PAIRDEF(r06,r12)
PAIRDEF(r06,r13)
PAIRDEF(r06,r14)
PAIRSTK(r06,STK)

PAIRBEG(r07    )
PAIRDEF(r07,r00)
PAIRDEF(r07,r01)
PAIRDEF(r07,r02)
PAIRDEF(r07,r03)
PAIRDEF(r07,r04)
PAIRDEF(r07,r05)
PAIRDEF(r07,r06)
PAIRDEF(r07,r08)
PAIRDEF(r07,r09)
PAIRDEF(r07,r10)
PAIRDEF(r07,r11)
PAIRDEF(r07,r12)
PAIRDEF(r07,r13)
PAIRDEF(r07,r14)
PAIRSTK(r07,STK)

PAIRBEG(r08    )
PAIRDEF(r08,r00)
PAIRDEF(r08,r01)
PAIRDEF(r08,r02)
PAIRDEF(r08,r03)
PAIRDEF(r08,r04)
PAIRDEF(r08,r05)
PAIRDEF(r08,r06)
PAIRDEF(r08,r07)
PAIRDEF(r08,r09)
PAIRDEF(r08,r10)
PAIRDEF(r08,r11)
PAIRDEF(r08,r12)
PAIRDEF(r08,r13)
PAIRDEF(r08,r14)
PAIRSTK(r08,STK)

PAIRBEG(r09    )
PAIRDEF(r09,r00)
PAIRDEF(r09,r01)
PAIRDEF(r09,r02)
PAIRDEF(r09,r03)
PAIRDEF(r09,r04)
PAIRDEF(r09,r05)
PAIRDEF(r09,r06)
PAIRDEF(r09,r07)
PAIRDEF(r09,r08)
PAIRDEF(r09,r10)
PAIRDEF(r09,r11)
PAIRDEF(r09,r12)
PAIRDEF(r09,r13)
PAIRDEF(r09,r14)
PAIRSTK(r09,STK)

PAIRBEG(r10    )
PAIRDEF(r10,r00)
PAIRDEF(r10,r01)
PAIRDEF(r10,r02)
PAIRDEF(r10,r03)
PAIRDEF(r10,r04)
PAIRDEF(r10,r05)
PAIRDEF(r10,r06)
PAIRDEF(r10,r07)
PAIRDEF(r10,r08)
PAIRDEF(r10,r09)
PAIRDEF(r10,r11)
PAIRDEF(r10,r12)
PAIRDEF(r10,r13)
PAIRDEF(r10,r14)
PAIRSTK(r10,STK)

PAIRBEG(r11    )
PAIRDEF(r11,r00)
PAIRDEF(r11,r01)
PAIRDEF(r11,r02)
PAIRDEF(r11,r03)
PAIRDEF(r11,r04)
PAIRDEF(r11,r05)
PAIRDEF(r11,r06)
PAIRDEF(r11,r07)
PAIRDEF(r11,r08)
PAIRDEF(r11,r09)
PAIRDEF(r11,r10)
PAIRDEF(r11,r12)
PAIRDEF(r11,r13)
PAIRDEF(r11,r14)
PAIRSTK(r11,STK)

PAIRBEG(r12    )
PAIRDEF(r12,r00)
PAIRDEF(r12,r01)
PAIRDEF(r12,r02)
PAIRDEF(r12,r03)
PAIRDEF(r12,r04)
PAIRDEF(r12,r05)
PAIRDEF(r12,r06)
PAIRDEF(r12,r07)
PAIRDEF(r12,r08)
PAIRDEF(r12,r09)
PAIRDEF(r12,r10)
PAIRDEF(r12,r11)
PAIRDEF(r12,r13)
PAIRDEF(r12,r14)
PAIRSTK(r12,STK)

PAIRBEG(r13    )
PAIRDEF(r13,r00)
PAIRDEF(r13,r01)
PAIRDEF(r13,r02)
PAIRDEF(r13,r03)
PAIRDEF(r13,r04)
PAIRDEF(r13,r05)
PAIRDEF(r13,r06)
PAIRDEF(r13,r07)
PAIRDEF(r13,r08)
PAIRDEF(r13,r09)
PAIRDEF(r13,r10)
PAIRDEF(r13,r11)
PAIRDEF(r13,r12)
PAIRDEF(r13,r14)
PAIRSTK(r13,STK)

PAIRBEG(r14    )
PAIRDEF(r14,r00)
PAIRDEF(r14,r01)
PAIRDEF(r14,r02)
PAIRDEF(r14,r03)
PAIRDEF(r14,r04)
PAIRDEF(r14,r05)
PAIRDEF(r14,r06)
PAIRDEF(r14,r07)
PAIRDEF(r14,r08)
PAIRDEF(r14,r09)
PAIRDEF(r14,r10)
PAIRDEF(r14,r11)
PAIRDEF(r14,r12)
PAIRDEF(r14,r13)
PAIRSTK(r14,STK)

PAIRBEG(STK    )
PAIRSTK(STK,r00)
PAIRSTK(STK,r01)
PAIRSTK(STK,r02)
PAIRSTK(STK,r03)
PAIRSTK(STK,r04)
PAIRSTK(STK,r05)
PAIRSTK(STK,r06)
PAIRSTK(STK,r07)
PAIRSTK(STK,r08)
PAIRSTK(STK,r09)
PAIRSTK(STK,r10)
PAIRSTK(STK,r11)
PAIRSTK(STK,r12)
PAIRSTK(STK,r13)
PAIRSTK(STK,r14)

/*****************************************************************************/
#endif//TGT_SH3
/*****************************************************************************/

#undef PAIRSTK

/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\regsh3.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#if  !  TGT_SH3
#error  This file can only be used when targetting SH3!
#endif
/*****************************************************************************/
#ifndef REGDEF
#error  Must define REGDEF macro before including this file
#endif
/*****************************************************************************/
/*                  The following is SH3 specific                            */
/*****************************************************************************/

REGDEF(r00, "r0", 0,(0x1 <<  0))
REGDEF(r01, "r1", 1,(0x1 <<  1))
REGDEF(r02, "r2", 2,(0x1 <<  2))
REGDEF(r03, "r3", 3,(0x1 <<  3))
REGDEF(r04, "r4", 4,(0x1 <<  4))
REGDEF(r05, "r5", 5,(0x1 <<  5))
REGDEF(r06, "r6", 6,(0x1 <<  6))
REGDEF(r07, "r7", 7,(0x1 <<  7))
REGDEF(r08, "r8", 8,(0x1 <<  8))
REGDEF(r09, "r9", 9,(0x1 <<  9))
REGDEF(r10,"r10",10,(0x1 << 10))
REGDEF(r11,"r11",11,(0x1 << 11))
REGDEF(r12,"r12",12,(0x1 << 12))
REGDEF(r13,"r13",13,(0x1 << 13))
REGDEF(r14,"r14",14,(0x1 << 14))
REGDEF(r15,"sp" ,15,(0x1 << 15))

/* we recycle sp's mask for the pseudo register */
#ifndef SHX_SH4
REGDEF(STK,NULL ,16,0x8000)
#else
REGDEF(fr00, "fr0",16,(0x1 << 16))
REGDEF(fr01, "fr1",17,(0x1 << 17))
REGDEF(fr02, "fr2",18,(0x1 << 18))
REGDEF(fr03, "fr3",19,(0x1 << 19))
REGDEF(fr04, "fr4",20,(0x1 << 20))
REGDEF(fr05, "fr5",21,(0x1 << 21))
REGDEF(fr06, "fr6",22,(0x1 << 22))
REGDEF(fr07, "fr7",23,(0x1 << 23))
REGDEF(fr08, "fr8",24,(0x1 << 24))
REGDEF(fr09, "fr9",25,(0x1 << 25))
REGDEF(fr10,"fr10",26,(0x1 << 26))
REGDEF(fr11,"fr11",27,(0x1 << 27))
REGDEF(fr12,"fr12",28,(0x1 << 28))
REGDEF(fr13,"fr13",29,(0x1 << 29))
REGDEF(fr14,"fr14",30,(0x1 << 30))
REGDEF(fr15,"fr15",31,(0x1 << 31))
REGDEF(STK , NULL, 32, 0x8000)
#endif

/*****************************************************************************/
#undef  REGDEF
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\regset.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                           RegSet                                          XX
XX                                                                           XX
XX  Represents the register set, and their states during code generation     XX
XX  Can select an unused register, keeps track of the contents of the        XX
XX  registers, and can spill registers                                       XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

/*****************************************************************************/
#if!TGT_IA64
/*****************************************************************************/

regMaskSmall        regMasks[] =
{
    #if     TGT_x86
    #define REGDEF(name, rnum, mask, byte) mask,
    #include "register.h"
    #undef  REGDEF
    #endif

    #if     TGT_SH3
    #define REGDEF(name, strn, rnum, mask) mask,
    #include "regSH3.h"
    #undef  REGDEF
    #endif

    #if     TGT_IA64
    #define REGDEF(name, strn, rnum, mask) mask,
    #include "regIA64.h"
    #undef  REGDEF
    #endif
};

/*****************************************************************************/
#if SCHEDULER || USE_SET_FOR_LOGOPS

/* round robin register allocation. When scheduling, the following table is
 * cycled through for register allocation, to create more scheduling opportunities.
 * Also, when a redundant load is performed (not a true register allocation) we
 * still reset the global index to the table, so our next selection can be scheduled
 * with respect to the reused register
 */

#if TGT_x86

const regMaskSmall  rsREG_MASK_ORDER[] =
{
    RBM_EAX,
    RBM_EDX,
    RBM_ECX,
    RBM_EBX,
    RBM_EBP,
    RBM_ESI,
    RBM_EDI,
};

#endif

#if TGT_SH3

const regMaskSmall  rsREG_MASK_ORDER[] =
{
    RBM_r00,
    RBM_r01,
    RBM_r02,
    RBM_r03,
    RBM_r04,
    RBM_r05,
    RBM_r06,
    RBM_r07,
    RBM_r14,
    RBM_r08,
    RBM_r09,
    RBM_r10,
    RBM_r11,
    RBM_r12,
    RBM_r13,
};

#endif

#if TGT_IA64

const regMaskSmall  rsREG_MASK_ORDER[] =
{
    RBM_r11,
    RBM_r12,
    RBM_r13,
    RBM_r14,
    RBM_r15,
};

#endif

inline
unsigned            Compiler::rsREGORDER_SIZE()
{
    return (sizeof(rsREG_MASK_ORDER)/sizeof(*rsREG_MASK_ORDER));
}

/*****************************************************************************
 *
 *  This function is called when we reuse a register. It updates
 *  rsNextPickRegIndex as if we had just allocated that register,
 *  so that the next allocation will be some other register.
 */

void                Compiler::rsUpdateRegOrderIndex(regNumber reg)
{
    for (unsigned i = 0; i < rsREGORDER_SIZE(); i++)
    {
        if (rsREG_MASK_ORDER[i] & genRegMask(reg))
        {
            rsNextPickRegIndex = (i + 1) % rsREGORDER_SIZE();
            return;
        }
    }

    assert(!"bad reg passed to genRegOrderIndex");
}

/*****************************************************************************/
#endif//SCHEDULER || USE_SET_FOR_LOGOPS
/*****************************************************************************/

void                Compiler::rsInit()
{
    /* Initialize the spill logic */

    rsSpillInit();

    /* Initialize this to 0 so method compiles are for sure reproducible */

#if SCHEDULER || USE_SET_FOR_LOGOPS
    rsNextPickRegIndex = 0;
#endif

#if USE_FASTCALL
    /* Initialize the argument register count */
    rsCurRegArg = 0;
#endif
}

/*****************************************************************************
 *
 *  Marks the register that holds the given operand value as 'used'. If 'addr'
 *  is non-zero, the register is part of a complex address mode that needs to
 *  be marked if the register is ever spilled.
 */

void                Compiler::rsMarkRegUsed(GenTreePtr tree, GenTreePtr addr)
{
    regNumber       regNum;
    regMaskTP       regMask;

    /* The value must be sitting in a register */

    assert(tree);
    assert(tree->gtFlags & GTF_REG_VAL);
#if CPU_HAS_FP_SUPPORT
    assert(genActualType(tree->gtType) == TYP_INT ||
           genActualType(tree->gtType) == TYP_REF ||
                         tree->gtType  == TYP_BYREF);
#else
    assert(genTypeSize(genActualType(tree->TypeGet())) == genTypeSize(TYP_INT));
#endif

    regNum  = tree->gtRegNum;
    regMask = genRegMask(regNum);

#ifdef  DEBUG
    if  (verbose) printf("The register %s currently holds [%08X/%08X]\n", compRegVarName(regNum), tree, addr);
#endif

    /* Remember whether the register holds a pointer */

    gcMarkRegPtrVal(regNum, tree->TypeGet());

    /* No locked register may ever be marked as free */

    assert((rsMaskLock & rsRegMaskFree()) == 0);

    /* Is the register used by two different values simultaneously? */

    if  (regMask & rsMaskUsed)
    {
        /* Save the preceding use information */

        rsRecMultiReg(regNum);
    }

    /* Set the register's bit in the 'used' bitset */

    rsMaskUsed |= regMask;

    /* Remember what values are in what registers, in case we have to spill */

    assert(rsUsedTree[regNum] == 0); rsUsedTree[regNum] = tree;
    assert(rsUsedAddr[regNum] == 0); rsUsedAddr[regNum] = addr;
}

/*****************************************************************************/
#ifndef TGT_IA64
/*****************************************************************************
 *
 *  Marks the register pair that holds the given operand value as 'used'.
 */

void                Compiler::rsMarkRegPairUsed(GenTreePtr tree)
{
    regNumber       regLo;
    regNumber       regHi;
    regPairNo       regPair;
    unsigned        regMask;

    /* The value must be sitting in a register */

    assert(tree);
#if SPECIAL_DOUBLE_ASG
    assert(genTypeSize(tree->TypeGet()) == genTypeSize(TYP_LONG));
#else
#if CPU_HAS_FP_SUPPORT
    assert(tree->gtType == TYP_LONG);
#else
    assert(tree->gtType == TYP_LONG || tree->gtType == TYP_DOUBLE);
#endif
#endif
    assert(tree->gtFlags & GTF_REG_VAL);

    regPair = tree->gtRegPair;
    regMask = genRegPairMask(regPair);

    regLo   = genRegPairLo(regPair);
    regHi   = genRegPairHi(regPair);

    /* Neither register obviously holds a pointer value */

    gcMarkRegSetNpt(regMask);

    /* No locked register may ever be marked as free */

    assert((rsMaskLock & rsRegMaskFree()) == 0);

    /* Are the registers used by two different values simultaneously? */

    if  (rsMaskUsed & genRegMask(regLo))
    {
        /* Save the preceding use information */

        rsRecMultiReg(regLo);
    }

    if  (rsMaskUsed & genRegMask(regHi))
    {
        /* Save the preceding use information */

        rsRecMultiReg(regHi);
    }

    /* Can't mark a register pair more than once as used */

//    assert((regMask & rsMaskUsed) == 0);

    /* Mark the registers as 'used' */

    rsMaskUsed |= regMask;

    /* Remember what values are in what registers, in case we have to spill */

    if  (regLo != REG_STK)
    {
        assert(rsUsedTree[regLo] == 0);
        rsUsedTree[regLo] = tree;
    }

    if  (regHi != REG_STK)
    {
        assert(rsUsedTree[regHi] == 0);
        rsUsedTree[regHi] = tree;
    }
}

/*****************************************************************************/
#endif//TGT_IA64
/*****************************************************************************
 *
 *  Returns true is the given tree is currently held in reg.
 *  Note that reg may by used by multiple trees, in which case we have
 *  to search rsMultiDesc[reg].
 */

bool                Compiler::rsIsTreeInReg(regNumber reg, GenTreePtr tree)
{
    /* First do the trivial check */

    if (rsUsedTree[reg] == tree)
        return true;

    /* If the register is used by mutliple trees, we have to search the list
       in rsMultiDesc[reg] */

    if (genRegMask(reg) & rsMaskMult)
    {
        SpillDsc * multiDesc = rsMultiDesc[reg];
        assert(multiDesc);

        for (/**/; multiDesc; multiDesc = multiDesc->spillNext)
        {
            if (multiDesc->spillTree == tree)
                return true;

            assert((!multiDesc->spillNext) == (!multiDesc->spillMoreMultis));
        }
    }

    /* Not found. It must be spilled */

    return false;
}

/*****************************************************************************
 *
 *  Mark the register set given by the register mask as not used.
 */

void                Compiler::rsMarkRegFree(regMaskTP regMask)
{
    gcMarkRegSetNpt(regMask);

    /* Are we freeing any multi-use registers? */

    if  (regMask & rsMaskMult)
    {
        rsMultRegFree(regMask);
        return;
    }

    /* Remove the register set from the 'used' set */

    assert((regMask & rsMaskUsed) == regMask); rsMaskUsed -= regMask;

#ifndef NDEBUG

    unsigned        regNum;
    regMaskTP       regBit;

    for (regNum = 0, regBit = regMaskOne;
         regNum < REG_COUNT;
         regNum++, incRegMask(regBit))
    {
        if  (regBit & regMask)
        {
#ifdef  DEBUG
            if  (verbose) printf("The register %s no longer holds [%08X/%08X]\n",
                compRegVarName((regNumber)regNum), rsUsedTree[regNum], rsUsedAddr[regNum]);
#endif

            assert(rsUsedTree[regNum] != 0);
                   rsUsedTree[regNum] = 0;
                   rsUsedAddr[regNum] = 0;
        }
    }

#endif

    /* No locked register may ever be marked as free */

    assert((rsMaskLock & rsRegMaskFree()) == 0);
}

/*****************************************************************************
 *
 *  Mark the register set given by the register mask as not used; there may
 *  be some 'multiple-use' registers in the set.
 */

void                Compiler::rsMultRegFree(regMaskTP regMask)
{
    regMaskTP       mulMask;

    /* Free any multiple-use registers first */

    mulMask = regMask & rsMaskMult;

    if  (mulMask)
    {
        regNumber       regNum;
        regMaskTP       regBit;

        for (regNum = (regNumber)0           , regBit = regMaskOne;
             regNum < REG_COUNT;
             regNum = (regNumber)(regNum + 1), incRegMask(regBit))
        {
            if  (regBit & mulMask)
            {
                /* Free the multi-use register 'regNum' */

                rsRmvMultiReg(regNum);

                /* This register has been taken care of */

                regMask -= regBit;
            }
        }
    }

    /* If there are any single-use registers, free them */

    if  (regMask)
        rsMarkRegFree(regMask);
}

/*****************************************************************************
 *
 *  Returns the number of registers that are currently free which appear in needReg.
 */

unsigned            Compiler::rsFreeNeededRegCount(regMaskTP needReg)
{
    regMaskTP       regNeededFree = rsRegMaskFree() & needReg;
    unsigned        cntFree = 0;

    /* While some registers are free ... */

    while (regNeededFree)
    {
        /* Remove the next register bit and bump the count */

        regNeededFree -= (regMaskTP)genFindLowestBit(regNeededFree);
        cntFree += 1;
    }

    return cntFree;
}

/*****************************************************************************
 *
 *  Record the fact that the given register now contains the given local
 *  variable. Pointers are handled specially since reusing the register
 *  will extend the lifetime of a pointer register which is not a register
 *  variable.
 */

void                Compiler::rsTrackRegLclVar(regNumber reg, unsigned var)
{
    regMaskTP       regMask;

#if CPU_HAS_FP_SUPPORT
#if!CPU_FLT_REGISTERS
    assert(reg != REG_STK);
    assert(varTypeIsFloating(lvaTable[var].TypeGet()) == false);
#endif
#endif

    /* For volatile vars, we could track them until the next possible
       aliased read/write. But its probably not worth it. So just dont
       track them.
     */

    if (lvaTable[var].lvAddrTaken || lvaTable[var].lvVolatile)
        return;

    /* Keep track of which registers we ever touch */

    regMask = genRegMask(reg);

    rsMaskModf |= regMask;

#if REDUNDANT_LOAD

    /* Is the variable a pointer? */

    if (varTypeIsGC(lvaTable[var].TypeGet()))
    {
        /* Don't track pointer register vars */

        if (lvaTable[var].lvRegister)
            return;

        /* Complexity with non-interruptible GC, so only track callee-trash
           for fully interruptible don't track at all */

        if (((regMask & RBM_CALLEE_TRASH) == 0) || genInterruptible)
            return;

    }
    else if (lvaTable[var].TypeGet() < TYP_INT)
        return;

#endif

    /* Record the new value for the register. ptr var needed for
     * lifetime extension
     */

#ifdef  DEBUG
    if  (verbose) printf("The register %s now holds local #%02u\n", compRegVarName(reg), var);
#endif

    rsRegValues[reg].rvdKind      = RV_LCL_VAR;
    rsRegValues[reg].rvdLclVarNum = var;
}

void                Compiler::rsTrackRegSwap(regNumber reg1, regNumber reg2)
{
    RegValDsc       tmp;

    tmp = rsRegValues[reg1];
          rsRegValues[reg1] = rsRegValues[reg2];
                              rsRegValues[reg2] = tmp;
}

void                Compiler::rsTrackRegCopy(regNumber reg1, regNumber reg2)
{
    /* Keep track of which registers we ever touch */

    rsMaskModf |= genRegMask(reg1);

#if REDUNDANT_LOAD

    if (rsRegValues[reg2].rvdKind == RV_LCL_VAR)
    {
        LclVarDsc   *   varDsc = &(lvaTable[rsRegValues[reg2].rvdLclVarNum]);

        /* Is the variable a pointer? */

        if (varTypeIsGC(varDsc->TypeGet()))
        {
            /* Don't track pointer register vars */

            if (varDsc->lvRegister)
                return;

            /* Complexity with non-interruptible GC, so only track callee-trash */

            if ((genRegMask(reg1) & RBM_CALLEE_TRASH) == 0)
                return;
        }
    }
#endif

    rsRegValues[reg1] = rsRegValues[reg2];
}


/*****************************************************************************
 *  One of the operands of this complex address mode has been spilled
 */

void                rsAddrSpillOper(GenTreePtr addr)
{
    if  (addr)
    {
        assert (addr->gtOper == GT_IND);

        // GTF_SPILLED_OP2 says "both operands have been spilled"
        assert((addr->gtFlags & GTF_SPILLED_OP2) == 0);

        if ((addr->gtFlags & GTF_SPILLED_OPER) == 0)
            addr->gtFlags |= GTF_SPILLED_OPER;
        else
            addr->gtFlags |= GTF_SPILLED_OP2;
    }
}

void            rsAddrUnspillOper(GenTreePtr addr)
{
    if (addr)
    {
        assert (addr->gtOper == GT_IND);

        assert((addr->gtFlags &       GTF_SPILLED_OPER) != 0);

        // Both operands spilled? */
        if    ((addr->gtFlags &       GTF_SPILLED_OP2 ) != 0)
            addr->gtFlags         &= ~GTF_SPILLED_OP2 ;
        else
            addr->gtFlags         &= ~GTF_SPILLED_OPER;
    }
}

/*****************************************************************************
 *
 *  Spill the given register (which we assume to be currently marked as used).
 */

void                Compiler::rsSpillReg(regNumber reg)
{
    SpillDsc   *    spill;
    TempDsc    *    temp;
    GenTreePtr      tree;
    var_types       type;

    regMaskTP       mask = genRegMask(reg);

    /* The register we're spilling must be used but not locked
       or an enregistered variable. */

    assert((mask & rsMaskUsed) != 0);
    assert((mask & rsMaskLock) == 0);
    assert((mask & rsMaskVars) == 0);

    /* Is this a 'multi-use' register? */

    /* We must know the value in the register that we are spilling */

    tree = rsUsedTree[reg]; assert(tree);

    /* Are we spilling a part of a register pair? */

#ifndef TGT_IA64
    if  (tree->gtType == TYP_LONG)
    {
        assert(genRegPairLo(tree->gtRegPair) == reg ||
               genRegPairHi(tree->gtRegPair) == reg);
    }
    else
#endif
    {
        assert(tree->gtFlags & GTF_REG_VAL);
        assert(tree->gtRegNum == reg);
        assert(genActualType(tree->gtType) == TYP_INT ||
               genActualType(tree->gtType) == TYP_REF ||
                             tree->gtType  == TYP_BYREF);
    }

    /* Are any registers free for spillage? */

//  if  (rsRegMaskFree())
    {
        // CONSIDER: Spill to another register: this should only be done
        // CONSIDER: under controlled circumstances (such as when a call
        // CONSIDER: is spilling registers) since it's relatively likely
        // CONSIDER: that the other register may end up being spilled as
        // CONSIDER: well, thus generating an extra move.
    }

    /* Allocate/reuse a spill descriptor */

    spill = rsSpillFree;
    if  (spill)
    {
        rsSpillFree = spill->spillNext;
    }
    else
    {
        spill = (SpillDsc *)compGetMem(sizeof(*spill));
    }

    /* Figure out the type of the spill temp */

    type = tree->TypeGet();

    if  (genActualType(type) == TYP_LONG)
        type = TYP_INT;

    /* Grab a temp to store the spilled value */

    spill->spillTemp = temp = tmpGetTemp(type);

    /* Remember what it is we have spilled */

    spill->spillTree = rsUsedTree[reg];
    spill->spillAddr = rsUsedAddr[reg];

#ifdef  DEBUG
    if  (verbose) printf("The register %s spilled with    [%08X/%08X]\n",
                    compRegVarName(reg),rsUsedTree[reg], rsUsedAddr[reg]);
#endif

    /* Is the register part of a complex address mode? */

    rsAddrSpillOper(rsUsedAddr[reg]);

    /* 'lastDsc' is 'spill' for simple cases, and will point to the last
       multi-use descriptor if 'reg' is being multi-used */

    SpillDsc *  lastDsc = spill;

    if  ((rsMaskMult & mask) == 0)
    {
        spill->spillMoreMultis = false;
    }
    else
    {
        /* The register is being multi-used and will have entries in
           rsMultiDesc[reg]. Spill all of them (ie. move them to
           rsSpillDesc[reg]).
           When we unspill the reg, they will all be moved back to
           rsMultiDesc[].
         */

        spill->spillMoreMultis = true;

        SpillDsc * nextDsc = rsMultiDesc[reg];

        do
        {
            assert(nextDsc);

            /* Is this multi-use part of a complex address mode? */

            rsAddrSpillOper(nextDsc->spillAddr);

            /* Mark the tree node as having been spilled */

            nextDsc->spillTree->gtFlags &= ~GTF_REG_VAL;
            nextDsc->spillTree->gtFlags |=  GTF_SPILLED;
            nextDsc->spillTemp = temp;

            /* lastDsc points to the last of the multi-spill decrs for 'reg' */

            lastDsc->spillNext = nextDsc;
            lastDsc = nextDsc;

            nextDsc = nextDsc->spillNext;
        }
        while (lastDsc->spillMoreMultis);

        rsMultiDesc[reg] = nextDsc;

        /* 'reg' is no longer considered to be multi-used. We will set this
           mask again when this value gets unspilled */

        rsMaskMult &= ~mask;
    }

    /* Insert the spill descriptor(s) in the list */

    lastDsc->spillNext = rsSpillDesc[reg];
                         rsSpillDesc[reg] = spill;

    /* Generate the code to spill the register */

#if TGT_x86

    inst_ST_RV(INS_mov, temp, 0, reg, tree->TypeGet());

    genTmpAccessCnt++;

#else

#ifdef  DEBUG
    printf("Need to spill %s\n", getRegName(reg));
#endif
    assert(!"need non-x86 code for spilling");

#endif

    /* Mark the tree node as having been spilled */

    tree->gtFlags &= ~GTF_REG_VAL;
    tree->gtFlags |=  GTF_SPILLED;

    /* The register is now free */

    rsMarkRegFree(mask);

    /* The register no longer holds its original value */

    rsUsedTree[reg] = 0;
}

/*****************************************************************************
 *
 *  Spill all registers in 'regMask' that are currently marked as used.
 */

void                Compiler::rsSpillRegs(regMaskTP regMask)
{
    unsigned        regNum;
    regMaskTP       regBit;

    /* The registers we're spilling must not be locked,
       or enregistered variables */

    assert((regMask & rsMaskLock) == 0);
    assert((regMask & rsMaskVars) == 0);

    /* Only spill what's currently marked as used */

    regMask &= rsMaskUsed; assert(regMask);

    for (regNum = 0, regBit = regMaskOne;
         regNum < REG_COUNT;
         regNum++  , incRegMask(regBit))
    {
        if  (regMask & regBit)
        {
            rsSpillReg((regNumber)regNum);

            regMask -= regBit;
            if  (!regMask)
                break;
        }
    }
}

/*****************************************************************************
 *
 *  The following shows the code sizes that correspond to the order in which
 *  registers are picked in the routines that follow:
 *
 *
 *          EDX, EAX, ECX   [338662 VM, 688808/609151 x86 203%]
 *          ECX, EDX, EAX   [338662 VM, 688715/609029 x86 203%]
 *          EAX, ECX, EDX   [338662 VM, 687988/608337 x86 203%]
 *          EAX, EDX, ECX   [338662 VM, 687945/608314 x86 203%]
 */

/*****************************************************************************
 *
 *  Choose a register from the given set; if no registers in the set are
 *  currently free, one of them will have to be spilled (even if other
 *  registers - not in the set - are currently free).
 */

regNumber           Compiler::rsGrabReg(regMaskTP regMask)
{
    regMaskTP       OKmask;
    regMaskTP       regBit;
    unsigned        regNum;

    assert(regMask);
    regMask &= ~rsMaskLock;
    assert(regMask);

    /* See if one of the desired registers happens to be free */

    OKmask = regMask & rsRegMaskFree();

#if TGT_x86

    if  (OKmask & RBM_EAX) { regNum = REG_EAX; goto RET; }
    if  (OKmask & RBM_EDX) { regNum = REG_EDX; goto RET; }
    if  (OKmask & RBM_ECX) { regNum = REG_ECX; goto RET; }
    if  (OKmask & RBM_EBX) { regNum = REG_EBX; goto RET; }
    if  (OKmask & RBM_EBP) { regNum = REG_EBP; goto RET; }
    if  (OKmask & RBM_ESI) { regNum = REG_ESI; goto RET; }
    if  (OKmask & RBM_EDI) { regNum = REG_EDI; goto RET; }

#else

    /* Grab the lowest-numbered available register */

    if  (OKmask)
    {
        regNum = genRegNumFromMask(genFindLowestBit(OKmask));
        goto RET;
    }

#endif

    /* We'll have to spill one of the registers in 'regMask' */

    OKmask = rsRegMaskCanGrab() & regMask; assert(OKmask);

    // CONSIDER: Rotate the registers we consider for spilling, so that
    // CONSIDER: we avoid repeatedly spilling the same register; maybe.

    for (regNum = 0, regBit = regMaskOne; regNum < REG_COUNT; regNum++, incRegMask(regBit))
    {
        /* If the register isn't acceptable, ignore it */

        if  ((regBit & OKmask) == 0)
            continue;

        /* This will be the victim -- spill the sucker */

        rsSpillReg((regNumber)regNum);
        break;
    }

    /* Make sure we did find a register to spill */

    assert(genIsValidReg((regNumber)regNum));

RET:

    rsMaskModf |= genRegMask((regNumber)regNum);
    return  (regNumber)regNum;
}

/*****************************************************************************
 *
 *  Choose a register from the given set if possible (i.e. if any register
 *  in the set is currently free, choose it), otherwise pick any other reg
 *  that is currently free.
 *
 *  In other words, 'regMask' (if non-zero) is purely a recommendation and
 *  can be safely ignored (with likely loss of code quality, of course).
 */

regNumber           Compiler::rsPickReg(regMaskTP regMask,
                                        regMaskTP regBest,
                                        var_types regType)
{
    regMaskTP       OKmask;
    regNumber       reg;

#if SCHEDULER || USE_SET_FOR_LOGOPS

    unsigned i;
    unsigned count;
#endif

AGAIN:

    /* By default we'd prefer to accept all available registers */

    OKmask = rsRegMaskFree();

    /* Is there a 'best' register set? */

    if  (regBest)
    {
        OKmask &= regBest;
        if  (OKmask)
            goto TRY_REG;
        else
            goto TRY_ALL;
    }

    /* Was a register set recommended by the caller? */

    if  (regMask)
    {
        OKmask &= regMask;
        if  (!OKmask)
            goto TRY_ALL;
    }

TRY_REG:

    /* Any takers in the recommended/free set? */

#if SCHEDULER || USE_SET_FOR_LOGOPS

#if SCHEDULER
    if (!varTypeIsGC(regType) && rsRiscify(TYP_INT, OKmask))
#else
    if (!varTypeIsGC(regType))
#endif
    {
        i = rsNextPickRegIndex;
    }
    else
    {
        i = 0;
    }

    for (count = 0; count < rsREGORDER_SIZE(); count++)
    {
        if (OKmask & rsREG_MASK_ORDER[i])
        {
            reg = genRegNumFromMask(rsREG_MASK_ORDER[i]);
            goto RET;
        }

        i = (i + 1) % rsREGORDER_SIZE();
    }

#else

#if TGT_x86

    if  (OKmask & RBM_EAX) { reg = REG_EAX; goto RET; }
    if  (OKmask & RBM_EDX) { reg = REG_EDX; goto RET; }
    if  (OKmask & RBM_ECX) { reg = REG_ECX; goto RET; }
    if  (OKmask & RBM_EBX) { reg = REG_EBX; goto RET; }
    if  (OKmask & RBM_EBP) { reg = REG_EBP; goto RET; }
    if  (OKmask & RBM_ESI) { reg = REG_ESI; goto RET; }
    if  (OKmask & RBM_EDI) { reg = REG_EDI; goto RET; }

#else

    assert(!"need non-x86 code");

#endif

#endif

TRY_ALL:

    /* Were we considering 'regBest' ? */

    if  (regBest)
    {
        /* 'regBest' is no good -- ignore it and try 'regMask' instead */

        regBest = regMaskNULL;
        goto AGAIN;
    }

    regMaskTP        freeMask;
    regMaskTP       spillMask;

    /* Now let's consider all available registers */

    freeMask = rsRegMaskFree();

    /* Were we limited in out consideration? */

    if  (!regMask)
    {
        /* We need to spill one of the free registers */

        spillMask = freeMask;
    }
    else
    {
        /* Did we not consider all free registers? */

        if  ((regMask & freeMask) != freeMask)
        {
            /* The recommended regset didn't work, so try all available regs */

#if SCHEDULER || USE_SET_FOR_LOGOPS

#if SCHEDULER
            if (!varTypeIsGC(regType) && rsRiscify(TYP_INT, freeMask))
#else
            if (!varTypeIsGC(regType))
#endif
            {
                i = rsNextPickRegIndex;
            }
            else
            {
                i = 0;
            }

            for (count = 0; count < rsREGORDER_SIZE(); count++)
            {
                if (freeMask & rsREG_MASK_ORDER[i])
                {
                    reg = genRegNumFromMask(rsREG_MASK_ORDER[i]);
                    goto RET;
                }

                i = (i + 1) % rsREGORDER_SIZE();
            }

#else

#if TGT_x86

            if  (freeMask & RBM_EAX) { reg = REG_EAX; goto RET; }
            if  (freeMask & RBM_EDX) { reg = REG_EDX; goto RET; }
            if  (freeMask & RBM_ECX) { reg = REG_ECX; goto RET; }
            if  (freeMask & RBM_EBX) { reg = REG_EBX; goto RET; }
            if  (freeMask & RBM_EBP) { reg = REG_EBP; goto RET; }
            if  (freeMask & RBM_ESI) { reg = REG_ESI; goto RET; }
            if  (freeMask & RBM_EDI) { reg = REG_EDI; goto RET; }

#else

            assert(!"need non-x86 code");

#endif

#endif

        }

        /* If we're going to spill, might as well go for the right one */

        spillMask = regMask;
    }

    /* Make sure we can spill some register. */

    if  ((spillMask & rsRegMaskCanGrab()) == 0)
        spillMask = rsRegMaskCanGrab();

    assert(spillMask);

    /* We have no choice but to spill one of the regs */

    return  rsGrabReg(spillMask);

RET:

#if SCHEDULER || USE_SET_FOR_LOGOPS
    rsNextPickRegIndex = (i + 1) % rsREGORDER_SIZE();
#endif

    rsMaskModf |= genRegMask((regNumber)reg);
    return  (regNumber)reg;
}

/*****************************************************************************
 *
 *  Get the temp that was spilled from the given register (and free its
 *  spill descriptor while we're at it). Returns the temp (i.e. local var)
 */

Compiler::TempDsc *    Compiler::rsGetSpillTempWord(regNumber oldReg)
{
    SpillDsc   *   dsc;
    TempDsc    *   temp;

    // ISSUE: We should search the list of values for a matching tree node,
    // ISSUE: since we can't simply assume that the value is the last value
    // ISSUE: to have been loaded into the given register.

    /* Get hold of the spill descriptor for the register */

    dsc = rsSpillDesc[oldReg]; assert(dsc);

    /* Remove this spill entry from the register's list */

    rsSpillDesc[oldReg] = dsc->spillNext;

    /* Remember which temp the value is in */

    temp = dsc->spillTemp;

    /* Add the entry to the free list */

    dsc->spillNext = rsSpillFree;
                     rsSpillFree = dsc;

    /* return the temp variable */

    return temp;
}

/*****************************************************************************
 *
 *  Reload the value that was spilled from the given register (and free its
 *  spill descriptor while we're at it). Returns the new register (which will
 *  be a member of 'needReg' if that value is non-zero).
 *
 *  'willKeepOldReg' indicates if the caller intends to mark newReg as used.
 *      If not, then we cant unspill the other multi-used descriptor (if any).
 *      Instead, we will just hold on to the temp and unspill them
 *      again as needed.
 */

regNumber           Compiler::rsUnspillOneReg(regNumber  oldReg, bool willKeepOldReg,
                                              regMaskTP needReg)
{
    TempDsc  *      temp;
    regNumber       newReg;

    /* Was oldReg multi-used when it was spilled */

    bool            multiUsed       = rsSpillDesc[oldReg]->spillMoreMultis;
    SpillDsc    *   unspillMultis   = NULL;

    /* Get the temp and free the spill-descriptor */

    temp = rsGetSpillTempWord(oldReg);

    if (multiUsed && willKeepOldReg)
    {
        /* If we are going to unspill all the multi-use decrs of the current
           value, grab them and remove them from rsSpillDesc[oldReg] as
           rsGrabReg() might add to the front of rsSpillDesc[oldReg]
           if oldReg==newReg */

        unspillMultis = rsSpillDesc[oldReg];

        SpillDsc * dsc = unspillMultis;
        while(dsc->spillMoreMultis)
            dsc = dsc->spillNext;
        rsSpillDesc[oldReg] = dsc->spillNext;
    }

    /*
        Pick a new home for the value (this must be a register matching
        the 'needReg' mask, if non-zero); note that the rsGrabReg call
        below may cause the chosen register to be spilled.
     */

    newReg = rsGrabReg(isNonZeroRegMask(needReg) ? needReg
                                                 : RBM_ALL);

    /* UNDONE: the following isn't right, but it's good enough for v1 */

    rsTrackRegTrash(newReg);

    /* Reload the value from the saved location into the new register */

#if TGT_x86

    inst_RV_ST(INS_mov, newReg, temp, 0, temp->tdTempType());

    genTmpAccessCnt++;

#else

    assert(!"need non-x86 code");

#endif

    if (!multiUsed)
    {
        /* Free the temp, it's no longer used */

        tmpRlsTemp(temp);
    }

    /* If this register was multi-used when it was spilled, move the
       remaining uses from rsSpillDesc[oldReg] (which we have grabbed into
       unspillMultis) to rsMultiDesc[newReg] and free the temp.
       However, if willKeepOldReg==false, we will let them stay spilled
       and hold on to the temp.
     */

    else if (unspillMultis)
    {
        SpillDsc *  dsc = unspillMultis;
        SpillDsc *  prev;

        do
        {
            rsAddrUnspillOper(dsc->spillAddr);

            /* The value is now residing in the new register */

            GenTreePtr  tree = dsc->spillTree;

            tree->gtFlags |=  GTF_REG_VAL;
            tree->gtFlags &= ~GTF_SPILLED;
            tree->gtRegNum = newReg;

            prev = dsc;
            dsc  = dsc->spillNext;
        }
        while(prev->spillMoreMultis);

        /* prev points to the last multi-used descriptor from the spill-list
           for the current value (prev->spillMoreMultis == false) */

        prev->spillNext = rsMultiDesc[newReg];
                          rsMultiDesc[newReg] = unspillMultis;

        rsMaskMult |= genRegMask(newReg);

        /* Free the temp, it's no longer used */

        tmpRlsTemp(temp);
    }

    return newReg;
}

/*****************************************************************************
 *
 *  The given tree operand has been spilled; just mark it as unspilled so
 *  that we can use it as "normal" local.
  */

void               Compiler::rsUnspillInPlace(GenTreePtr tree)
{
    TempDsc  *      temp;
    regNumber      oldReg;

    oldReg = tree->gtRegNum;

    /* We can't be unspilling the current value sitting in the register */

    assert(!rsIsTreeInReg(oldReg, tree));

    /* Make sure the tree/register have been properly recorded */

    assert(rsSpillDesc[oldReg]);
    assert(rsSpillDesc[oldReg]->spillTree == tree);

    /* Get the temp */

    temp = rsGetSpillTempWord(oldReg);

    /* The value is now unspilled */

    tree->gtFlags &= ~GTF_SPILLED;

#ifdef  DEBUG
    if  (verbose) printf("Tree-Node marked unspilled from  [%08X]\n", tree);
#endif

    /* Free the temp, it's no longer used */

    tmpRlsTemp(temp);
}

/*****************************************************************************
 *
 *  The given tree operand has been spilled; reload it into a register that
 *  is in 'regMask' (if 'regMask' is 0, any register will do). If 'keepReg'
 *  is non-zero, we'll mark the new register as used.
 */

void                Compiler::rsUnspillReg(GenTreePtr tree,
                                           regMaskTP  needReg,
                                           bool       keepReg)
{
    regNumber       oldReg;
    regNumber       newReg;
    GenTreePtr      unspillAddr = NULL;

    oldReg = tree->gtRegNum;

    /* We can't be unspilling the current value sitting in the register */

    assert(!rsIsTreeInReg(oldReg, tree));

    // ISSUE: We should search the list of values for a matching tree node,
    // ISSUE: since we can't simply assume that the value is the last value
    // ISSUE: to have been loaded into the given register.

    /* Make sure the tree/register have been properly recorded */

    assert(       rsSpillDesc[oldReg]);
    assert(       rsSpillDesc[oldReg]->spillTree == tree);

    /* Before rsSpillDesc is cleared by rsUnspillOneReg(), note whether
     * the reg was part of an address mode
     */
#if 0
    /* @BUGBUG 1855 - This was probably added by PeterMa, and doesnt seem
       to make sense. */
    if  (rsSpillDesc[oldReg]->spillAddr != NULL &&
        (rsSpillDesc[oldReg]->spillAddr == rsUsedAddr[oldReg]))
#endif
        unspillAddr = rsSpillDesc[oldReg]->spillAddr;

    /* Pick a new home for the value */

    newReg = rsUnspillOneReg(oldReg, keepReg, needReg);

    /* The value is now residing in the new register */

    tree->gtFlags |=  GTF_REG_VAL;
    tree->gtFlags &= ~GTF_SPILLED;
    tree->gtRegNum = newReg;

    // If this reg was part of a complex address mode, need to clear this flag which
    // tells address mode building that a component has been spilled

    rsAddrUnspillOper(unspillAddr);

#ifdef  DEBUG
    if  (verbose) printf("The register %s unspilled from  [%08X]\n", compRegVarName(newReg), tree);
#endif

    /* Mark the new value as used, if the caller desires so */

    if  (keepReg)
        rsMarkRegUsed(tree);
}

/*****************************************************************************/
#ifndef TGT_IA64
/*****************************************************************************
 *
 *  Choose a register pair from the given set (note: only registers in the
 *  given set will be considered).
 */

regPairNo           Compiler::rsGrabRegPair(unsigned regMask)
{
    regPairNo       regPair;

    unsigned        OKmask;

    regMaskTP       regBit;

    unsigned        reg1;
    unsigned        reg2;

    assert(regMask);
    regMask &= ~rsMaskLock;
    assert(regMask);

    /* We'd prefer to choose a free register pair if possible */

    OKmask = regMask & rsRegMaskFree();

#if TGT_x86

    /* Any takers in the recommended/free set? */

    if  (OKmask & RBM_EAX)
    {
        /* EAX is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EDX) { regPair = REG_PAIR_EAXEDX; goto RET; }
        if  (OKmask & RBM_ECX) { regPair = REG_PAIR_EAXECX; goto RET; }
        if  (OKmask & RBM_EBX) { regPair = REG_PAIR_EAXEBX; goto RET; }
        if  (OKmask & RBM_ESI) { regPair = REG_PAIR_EAXESI; goto RET; }
        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_EAXEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_EAXEBP; goto RET; }
    }

    if  (OKmask & RBM_ECX)
    {
        /* ECX is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EDX) { regPair = REG_PAIR_ECXEDX; goto RET; }
        if  (OKmask & RBM_EBX) { regPair = REG_PAIR_ECXEBX; goto RET; }
        if  (OKmask & RBM_ESI) { regPair = REG_PAIR_ECXESI; goto RET; }
        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_ECXEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_ECXEBP; goto RET; }
    }

    if  (OKmask & RBM_EDX)
    {
        /* EDX is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EBX) { regPair = REG_PAIR_EDXEBX; goto RET; }
        if  (OKmask & RBM_ESI) { regPair = REG_PAIR_EDXESI; goto RET; }
        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_EDXEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_EDXEBP; goto RET; }
    }

    if  (OKmask & RBM_EBX)
    {
        /* EBX is available, see if we can pair it with another reg */

        if  (OKmask & RBM_ESI) { regPair = REG_PAIR_EBXESI; goto RET; }
        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_EBXEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_EBXEBP; goto RET; }
    }

    if  (OKmask & RBM_ESI)
    {
        /* ESI is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_ESIEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_ESIEBP; goto RET; }
    }

    if  (OKmask & RBM_EDI)
    {
        /* EDI is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_EDIEBP; goto RET; }
    }

#else

    assert(!"need non-x86 code");

#endif

    /* We have no choice but to spill one or two used regs */

    if  (OKmask)
    {
        /* One (and only one) register is free and acceptable - grab it */

        assert(genOneBitOnly(OKmask));

        for (reg1 = 0, regBit = regMaskOne; reg1 < REG_COUNT; reg1++, incRegMask(regBit))
        {
            if  (regBit & OKmask)
                break;
        }
    }
    else
    {
        /* No register is free and acceptable - we'll have to spill two */

        reg1 = rsGrabReg(regMask);
    }

    /* Temporarily lock the first register so it doesn't go away */

    rsLockReg(genRegMask((regNumber)reg1));

    /* Now grab another register */

    reg2 = rsGrabReg(regMask);

    /* We can unlock the first register now */

    rsUnlockReg(genRegMask((regNumber)reg1));

    /* Convert the two register numbers into a pair */
     if  (reg1 < reg2)
        regPair = gen2regs2pair((regNumber)reg1, (regNumber)reg2);
     else
        regPair = gen2regs2pair((regNumber)reg2, (regNumber)reg1);

RET:

    return  regPair;
}

/*****************************************************************************
 *
 *  Choose a register pair from the given set (if non-zero) or from the set of
 *  currently available registers (if 'regMask' is zero).
 */

regPairNo           Compiler::rsPickRegPair(unsigned regMask)
{
    regPairMaskTP   OKmask;
    regPairNo       regPair;

    int             repeat = 0;

    /* By default we'd prefer to accept all available registers */

    OKmask = rsRegMaskFree();

    if  (regMask)
    {
        /* A register set was recommended by the caller */

        OKmask &= regMask;
    }

AGAIN:

#if TGT_x86

    /* Any takers in the recommended/free set? */

    if  (OKmask & RBM_EAX)
    {
        /* EAX is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EDX) { regPair = REG_PAIR_EAXEDX; goto RET; }
        if  (OKmask & RBM_ECX) { regPair = REG_PAIR_EAXECX; goto RET; }
        if  (OKmask & RBM_EBX) { regPair = REG_PAIR_EAXEBX; goto RET; }
        if  (OKmask & RBM_ESI) { regPair = REG_PAIR_EAXESI; goto RET; }
        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_EAXEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_EAXEBP; goto RET; }
    }

    if  (OKmask & RBM_ECX)
    {
        /* ECX is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EDX) { regPair = REG_PAIR_ECXEDX; goto RET; }
        if  (OKmask & RBM_EBX) { regPair = REG_PAIR_ECXEBX; goto RET; }
        if  (OKmask & RBM_ESI) { regPair = REG_PAIR_ECXESI; goto RET; }
        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_ECXEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_ECXEBP; goto RET; }
    }

    if  (OKmask & RBM_EDX)
    {
        /* EDX is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EBX) { regPair = REG_PAIR_EDXEBX; goto RET; }
        if  (OKmask & RBM_ESI) { regPair = REG_PAIR_EDXESI; goto RET; }
        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_EDXEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_EDXEBP; goto RET; }
    }

    if  (OKmask & RBM_EBX)
    {
        /* EBX is available, see if we can pair it with another reg */

        if  (OKmask & RBM_ESI) { regPair = REG_PAIR_EBXESI; goto RET; }
        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_EBXEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_EBXEBP; goto RET; }
    }

    if  (OKmask & RBM_ESI)
    {
        /* ESI is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EDI) { regPair = REG_PAIR_ESIEDI; goto RET; }
        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_ESIEBP; goto RET; }
    }

    if  (OKmask & RBM_EDI)
    {
        /* EDI is available, see if we can pair it with another reg */

        if  (OKmask & RBM_EBP) { regPair = REG_PAIR_EDIEBP; goto RET; }
    }

#else

    /* Get hold of the two lowest bits in the avaialble mask */

    if  (OKmask)
    {
        regPairMaskTP   OKtemp;

        regPairMaskTP   regMask1;
        regPairMaskTP   regMask2;

        /* Get the lowest bit */

        regMask1 = genFindLowestBit(OKmask);

        /* Remove the lowest bit and look for another one */

        OKtemp   = OKmask - regMask1;

        if  (OKtemp)
        {
            /* We know we have two bits available at this point */

            regMask2 = genFindLowestBit(OKtemp);

            /* Convert the masks to register numbers */

            regPair  = gen2regs2pair(genRegNumFromMask(regMask1),
                                     genRegNumFromMask(regMask2));

            goto RET;
        }
    }

#endif

    regMaskTP freeMask;
    regMaskTP spillMask;

    /* Now let's consider all available registers */

    freeMask = rsRegMaskFree();

    /* Were we limited in our consideration? */

    if  (!regMask)
    {
        /* We need to spill two of the free registers */

        spillMask = freeMask;
    }
    else
    {
        /* Did we not consider all free registers? */

        if  ((regMask & freeMask) != freeMask && repeat == 0)
        {
            /* The recommended regset didn't work, so try all available regs */

            OKmask = freeMask;
            repeat++;
            goto AGAIN;
        }

        /* If we're going to spill, might as well go for the right one */

        spillMask = regMask;
    }

    /* Make sure that we have at least two bits set */

    if (genOneBitOnly(spillMask & rsRegMaskCanGrab()))
        spillMask = rsRegMaskCanGrab();

    assert(!genOneBitOnly(spillMask));

    /* We have no choice but to spill 1/2 of the regs */

    return  rsGrabRegPair(spillMask);

RET:

    return  regPair;
}

/*****************************************************************************
 *
 *  The given tree operand has been spilled; reload it into a register pair
 *  that is in 'regMask' (if 'regMask' is 0, any register pair will do). If
 *  'keepReg' is non-zero, we'll mark the new register pair as used. It is
 *  assumed that the current register pair has been marked as used (modulo
 *  any spillage, of course).
 */

void                Compiler::rsUnspillRegPair(GenTreePtr tree, unsigned needReg,
                                                                bool     keepReg)
{
    regPairNo       regPair;
    regNumber       regLo;
    regNumber       regHi;

    regPair = tree->gtRegPair;
    regLo   = genRegPairLo(regPair);
    regHi   = genRegPairHi(regPair);

    /* Has the register holding the lower half been spilled? */

    if  (!rsIsTreeInReg(regLo, tree))
    {
        /* Is the upper half already in the right place? */

        if  (rsIsTreeInReg(regHi, tree))
        {
            /* Temporarily lock the high part */

            rsLockUsedReg(genRegMask(regHi));

            /* Pick a new home for the lower half */

            regLo = rsUnspillOneReg(regLo, keepReg, needReg);

            /* We can unlock the high part now */

            rsUnlockUsedReg(genRegMask(regHi));
        }
        else
        {
            /* Pick a new home for the lower half */

            regLo = rsUnspillOneReg(regLo, keepReg, needReg);
        }
    }
    else
    {
        /* Free the register holding the lower half */

        rsMarkRegFree(genRegMask(regLo));
    }

    /* Has the register holding the upper half been spilled? */

    if  (!rsIsTreeInReg(regHi, tree))
    {
        unsigned    regLoUsed;

        /* Temporarily lock the low part so it doesnt get spilled */

        rsLockReg(genRegMask(regLo), &regLoUsed);

        /* Pick a new home for the upper half */

        regHi = rsUnspillOneReg(regHi, keepReg, needReg);

        /* We can unlock the low register now */

        rsUnlockReg(genRegMask(regLo), regLoUsed);
    }
    else
    {
        /* Free the register holding the upper half */

        rsMarkRegFree(genRegMask(regHi));
    }

    /* The value is now residing in the new register */

    tree->gtFlags    |=  GTF_REG_VAL;
    tree->gtFlags    &= ~GTF_SPILLED;
    tree->gtRegPair   = gen2regs2pair(regLo, regHi);
#ifdef  SET_USED_REG_SET_DURING_CODEGEN
    tree->gtUsedRegs |= genRegMask(regLo) | genRegMask(regHi);
#endif

    /* Mark the new value as used, if the caller desires so */

    if  (keepReg)
        rsMarkRegPairUsed(tree);
}

/*****************************************************************************/
#endif//TGT_IA64
/*****************************************************************************
 *
 *  The given register is being used by multiple trees (all of which represent
 *  the same logical value). Happens mainly because of REDUNDANT_LOAD;
 *  We dont want to really spill the register as it actually holds the
 *  value we want. But the multiple trees may be part of different
 *  addressing modes.
 *  Save the previous 'use' info so that when we return the register will
 *  appear unused.
 */

void                Compiler::rsRecMultiReg(regNumber reg)
{
    SpillDsc   *    spill;

    regMaskTP       regMask = genRegMask(reg);

#ifdef  DEBUG
    if  (verbose) printf("Register %s multi-use inc for   [%08X/%08X] multMask=%08X->%08X\n",
        compRegVarName(reg), rsUsedTree[reg], rsUsedAddr[reg], rsMaskMult, rsMaskMult | regMask);
#endif

    /* The register is supposed to be already used */

    assert(regMask & rsMaskUsed);
    assert(rsUsedTree[reg]);

    /* Allocate/reuse a spill descriptor */

    spill = rsSpillFree;
    if  (spill)
    {
        rsSpillFree = spill->spillNext;
    }
    else
    {
        spill = (SpillDsc *)compGetMem(sizeof(*spill));
    }

    /* Record the current 'use' info in the spill descriptor */

    spill->spillTree = rsUsedTree[reg]; rsUsedTree[reg] = 0;
    spill->spillAddr = rsUsedAddr[reg]; rsUsedAddr[reg] = 0;

    /* Remember whether the register is already 'multi-use' */

    spill->spillMoreMultis = ((rsMaskMult & regMask) != 0);

    /* Insert the new multi-use record in the list for the register */

    spill->spillNext = rsMultiDesc[reg];
                       rsMultiDesc[reg] = spill;

    /* This register is now 'multi-use' */

    rsMaskMult |= regMask;
}

/*****************************************************************************
 *
 *  Free the given register, which is known to have multiple uses.
 */

void                Compiler::rsRmvMultiReg(regNumber reg)
{
    SpillDsc   *   dsc;

    assert(rsMaskMult & genRegMask(reg));

#ifdef  DEBUG
    if  (verbose) printf("Register %s multi-use dec for   [%08X/%08X] multMask=%08X\n",
                    compRegVarName(reg), rsUsedTree[reg], rsUsedAddr[reg], rsMaskMult);
#endif

    /* Get hold of the spill descriptor for the register */

    dsc = rsMultiDesc[reg]; assert(dsc);
          rsMultiDesc[reg] = dsc->spillNext;

    /* Copy the previous 'use' info from the descriptor */

    rsUsedTree[reg] = dsc->spillTree;
    rsUsedAddr[reg] = dsc->spillAddr;

    if (!(dsc->spillTree->gtFlags & GTF_SPILLED))
        gcMarkRegPtrVal(reg, dsc->spillTree->TypeGet());

    /* Is only one use of the register left? */

    if  (!dsc->spillMoreMultis)
        rsMaskMult -= genRegMask(reg);

#ifdef  DEBUG
    if  (verbose) printf("Register %s multi-use dec - now [%08X/%08X] multMask=%08X\n",
                    compRegVarName(reg), rsUsedTree[reg], rsUsedAddr[reg], rsMaskMult);
#endif

    /* Put the spill entry on the free list */

    dsc->spillNext = rsSpillFree;
                     rsSpillFree = dsc;
}

/*****************************************************************************/
#if REDUNDANT_LOAD
/*****************************************************************************
 *
 *  Assume all non-integer registers contain garbage (this is called when
 *  we encounter a code label that isn't jumped by any block; we need to
 *  clear pointer values our of the table lest the GC pointer tables get
 *  out of whack).
 */

void                Compiler::rsTrackRegClrPtr()
{
    unsigned        reg;

    for (reg = 0; reg < REG_COUNT; reg++)
    {
        /* Preserve constant values */

        if  (rsRegValues[reg].rvdKind == RV_INT_CNS)
        {
            /* Make sure we don't preserve NULL (it's a pointer) */

            if  (rsRegValues[reg].rvdIntCnsVal != NULL)
                continue;
        }

        /* Preserve variables known to not be pointers */

        if  (rsRegValues[reg].rvdKind == RV_LCL_VAR)
        {
            if  (!varTypeIsGC(lvaTable[rsRegValues[reg].rvdLclVarNum].TypeGet()))
                continue;
        }

        rsRegValues[reg].rvdKind = RV_TRASH;
    }
}

/*****************************************************************************
 *
 *  Search for a register which contains the given local var.
 *  Return success/failure and set the register if success.
 *  Return FALSE on register variables, because otherwise their lifetimes
 *  can get messed up with respect to pointer tracking.
 *
 *  @MIHAII: Return FALSE if the variable is aliased
 */

regNumber           Compiler::rsLclIsInReg(unsigned var)
{
    unsigned        reg;

#ifdef  DEBUG
    genIntrptibleUse = true;
#endif

    assert(var < lvaCount);

    if  (opts.compMinOptim || opts.compDbgCode)
        return REG_NA;

    /* return false if register var so genMarkLclVar can do its job */

    if (lvaTable[var].lvRegister)
        return REG_NA;

    for (reg = 0; reg < REG_COUNT; reg++)
    {
        if (rsRegValues[reg].rvdLclVarNum == var)
        {
            /* matching variable number, now check kind of variable */
            if (rsRegValues[reg].rvdKind == RV_LCL_VAR)
            {
                /* special actions for a redundant load on a pointer */
                if (varTypeIsGC(lvaTable[var].TypeGet()))
                {
                    /* If not a callee trash, don't do it */
                    if ((RBM_CALLEE_TRASH & genRegMask((regNumber)reg)) == 0)
                        return REG_NA;
                }

                /* We don't allow redundant loads on aliased variables */
                assert(!lvaTable[var].lvAddrTaken);

#if SCHEDULER
                rsUpdateRegOrderIndex((regNumber)reg);
#endif
                return (regNumber)reg;
            }
        }
    }
    return REG_NA;
}

#ifndef TGT_IA64

regPairNo           Compiler::rsLclIsInRegPair(unsigned var)
{
    unsigned reg;
    regValKind rvKind = RV_TRASH;
    regNumber regNo;

    assert(var < lvaCount);

    if  (opts.compMinOptim || opts.compDbgCode)
        return REG_PAIR_NONE;

    for (reg = 0; reg < REG_COUNT; reg++)
    {
        if  (rvKind != rsRegValues[reg].rvdKind &&
             rsTrackIsLclVarLng(rsRegValues[reg].rvdKind) &&
             rsRegValues[reg].rvdLclVarNum == var)
        {
            /* first occurrence of this variable ? */

            if  (rvKind == RV_TRASH)
            {
                regNo = (regNumber) reg;
                rvKind = rsRegValues[reg].rvdKind;
            }
            else if (rvKind == RV_LCL_VAR_LNG_HI)
            {
                /* We found the lower half of the long */

                return gen2regs2pair((regNumber)reg, regNo);
            }
            else
            {
                /* We found the upper half of the long */

                assert(rvKind == RV_LCL_VAR_LNG_LO);
                return gen2regs2pair(regNo, (regNumber)reg);
            }

        }
    }

    return REG_PAIR_NONE;
}

#endif

void                Compiler::rsTrashLclLong(unsigned var)
{
    if  (opts.compMinOptim || opts.compDbgCode)
        return;

    for  (unsigned reg = 0; reg < REG_COUNT; reg++)
    {
        if  (rsTrackIsLclVarLng(rsRegValues[reg].rvdKind) &&
             rsRegValues[reg].rvdLclVarNum == var)
        {
            rsRegValues[reg].rvdKind = RV_TRASH;
        }
     }
}

/*****************************************************************************
 *
 *  Local's value has changed, mark all regs which contained it as trash.
 */

void                Compiler::rsTrashLcl(unsigned var)
{
    if  (opts.compMinOptim || opts.compDbgCode)
        return;

    for (unsigned reg = 0; reg < REG_COUNT; reg++)
    {
        if (rsRegValues[reg].rvdKind == RV_LCL_VAR &&
            rsRegValues[reg].rvdLclVarNum == var)
        {
            rsRegValues[reg].rvdKind = RV_TRASH;
        }
    }
}

/*****************************************************************************
 *
 *  Return a mask of registers that hold no useful value.
 */

regMaskTP           Compiler::rsUselessRegs()
{
    unsigned        reg;
    regMaskTP       mask;

    if  (opts.compMinOptim || opts.compDbgCode)
        return  RBM_ALL;

    for (reg = 0, mask = regMaskNULL; reg < REG_COUNT; reg++)
    {
        if  (rsRegValues[reg].rvdKind == RV_TRASH)
            mask |= genRegMask((regNumbers)reg);
    }

    return  mask;
}

/*****************************************************************************/
#endif//REDUNDANT_LOAD
/*****************************************************************************/




/*
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                           TempsInfo                                       XX
XX                                                                           XX
XX  The temporary lclVars allocated by the compiler for code generation      XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/


void                Compiler::tmpInit()
{
    tmpCount  = 0;

    memset(tmpFree, 0, sizeof(tmpFree));
}

/*****************************************************************************
 *
 *  Allocate a temp of the given size (and type, if tracking pointers for
 *  the garbage collector).
 */

Compiler::TempDsc * Compiler::tmpGetTemp(var_types type)
{
    size_t          size = roundUp(genTypeSize(type));

    /* We only care whether a temp is pointer or not */

    if  (!varTypeIsGC(type))
    {
        switch (genTypeStSz(type))
        {
        case 1: type = TYP_INT   ; break;
        case 2: type = TYP_DOUBLE; break;
        default: assert(!"unexpected type");
        }
    }

    /* Find the slot to search for a free temp of the right size */

    unsigned    slot = tmpFreeSlot(size);

    /* Look for a temp with a matching type */

    TempDsc * * last = &tmpFree[slot];
    TempDsc *   temp;

    for (temp = *last; temp; last = &temp->tdNext, temp = *last)
    {
        /* Does the type match? */

        if  (temp->tdType == type)
        {
            /* We have a match -- remove it from the free list */

            *last = temp->tdNext;
            break;
        }
    }

    /* Do we need to allocate a new temp */

    if  (!temp)
    {
        tmpCount++;
        temp = (TempDsc *)compGetMem(sizeof(*temp));
        temp->tdType = type;
        temp->tdSize = size;

        /* For now, only assign an index to the temp */

#ifndef NDEBUG
        temp->tdOffs = (short)0xDDDD;
#endif
        temp->tdNum  = -tmpCount;
    }

#ifdef  DEBUG
    if  (verbose) printf("get temp[%u->%u] at [EBP-%04X]\n",
                         temp->tdSize, slot, -temp->tdOffs);
#endif

    return temp;
}

/*****************************************************************************
 *
 *  Release the given temp.
 */

void                Compiler::tmpRlsTemp(TempDsc *temp)
{
    unsigned        slot;

    /* Add the temp to the 'free' list */

    slot = tmpFreeSlot(temp->tdSize);

#ifdef  DEBUG
    if  (verbose) printf("rls temp[%u->%u] at [EBP-%04X]\n", temp->tdSize, slot, -temp->tdOffs);
#endif

    temp->tdNext = tmpFree[slot];
                   tmpFree[slot] = temp;
}

/*****************************************************************************
 *
 *  Given a temp number, find the corresponding temp.
 */

Compiler::TempDsc * Compiler::tmpFindNum(int tnum)
{
    /* CONSIDER: Do something smarter, a linear search is dumb!!!! */

    for (TempDsc * temp = tmpListBeg(); temp; temp = tmpListNxt(temp))
    {
        if  (temp->tdTempNum() == tnum)
            return  temp;
    }

    return  NULL;
}

/*****************************************************************************
 * Used with tmpListBeg() to iterate over the list of temps.
 */

Compiler::TempDsc *     Compiler::tmpListNxt(TempDsc * curTemp)
{
    TempDsc     *       temp;

    assert(curTemp);

    temp = curTemp->tdNext;

    if (temp == 0)
    {
        size_t size = curTemp->tdSize;

        // If there are no more temps in the list, check if there are more
        // slots (for bigger sized temps) to walk

        if (size < TEMP_MAX_SIZE)
        {
            // Using "if" above instead of "while" assumes only 2 sizes
            assert(size + sizeof(int) == TEMP_MAX_SIZE);

            unsigned slot = tmpFreeSlot(size + sizeof(int));
            temp = tmpFree[slot];

            assert(temp == 0 || temp->tdSize == size + sizeof(int));
        }
    }

    assert(temp == 0 || temp->tdTempOffs() != 0xDDDD);

    return temp;
}

/*****************************************************************************
 *
 *  Returns whether regPair is a combination of two x86 registers or
 *  contains a pseudo register.
 *  In debug it also asserts that reg1 and reg2 are not the same.
 */

#ifndef TGT_IA64

BOOL                genIsProperRegPair(regPairNo regPair)
{
    regNumber rlo = genRegPairLo(regPair);
    regNumber rhi = genRegPairHi(regPair);

    assert(regPair >= REG_PAIR_FIRST &&
           regPair <= REG_PAIR_LAST);

    if  (rlo == rhi)
        return false;

    if  (rlo == REG_L_STK || rhi == REG_L_STK)
        return false;

    if  (rlo >= REG_COUNT || rhi >= REG_COUNT)
        return false;

    return (rlo != REG_STK && rhi != REG_STK);
}

#endif

/*****************************************************************************/
#endif//TGT_IA64
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\regia64.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
#ifndef REG_IF
#define REG_IF(name, strn)  REGDEF(name, strn)
#endif
#ifndef REG_IL
#define REG_IL(name, strn)  REGDEF(name, strn)
#endif

#ifndef REG_FF
#define REG_FF(name, strn)  REGDEF(name, strn)
#endif
#ifndef REG_FL
#define REG_FL(name, strn)  REGDEF(name, strn)
#endif

#ifndef REG_CF
#define REG_CF(name, strn)  REGDEF(name, strn)
#endif
#ifndef REG_CL
#define REG_CL(name, strn)  REGDEF(name, strn)
#endif

#ifndef REG_BF
#define REG_BF(name, strn)  REGDEF(name, strn)
#endif
#ifndef REG_BL
#define REG_BL(name, strn)  REGDEF(name, strn)
#endif

REG_IF(r000,   "r0")
REGDEF(r001,   "r1")
REGDEF(r002,   "r2")
REGDEF(r003,   "r3")
REGDEF(r004,   "r4")
REGDEF(r005,   "r5")
REGDEF(r006,   "r6")
REGDEF(r007,   "r7")
REGDEF(r008,   "r8")
REGDEF(r009,   "r9")
REGDEF(r010,  "r10")
REGDEF(r011,  "r11")
REGDEF(r012,  "r12")
REGDEF(r013,  "r13")
REGDEF(r014,  "r14")
REGDEF(r015,  "r15")
REGDEF(r016,  "r16")
REGDEF(r017,  "r17")
REGDEF(r018,  "r18")
REGDEF(r019,  "r19")
REGDEF(r020,  "r20")
REGDEF(r021,  "r21")
REGDEF(r022,  "r22")
REGDEF(r023,  "r23")
REGDEF(r024,  "r24")
REGDEF(r025,  "r25")
REGDEF(r026,  "r26")
REGDEF(r027,  "r27")
REGDEF(r028,  "r28")
REGDEF(r029,  "r29")
REGDEF(r030,  "r30")
REGDEF(r031,  "r31")
REGDEF(r032,  "r32")
REGDEF(r033,  "r33")
REGDEF(r034,  "r34")
REGDEF(r035,  "r35")
REGDEF(r036,  "r36")
REGDEF(r037,  "r37")
REGDEF(r038,  "r38")
REGDEF(r039,  "r39")
REGDEF(r040,  "r40")
REGDEF(r041,  "r41")
REGDEF(r042,  "r42")
REGDEF(r043,  "r43")
REGDEF(r044,  "r44")
REGDEF(r045,  "r45")
REGDEF(r046,  "r46")
REGDEF(r047,  "r47")
REGDEF(r048,  "r48")
REGDEF(r049,  "r49")
REGDEF(r050,  "r50")
REGDEF(r051,  "r51")
REGDEF(r052,  "r52")
REGDEF(r053,  "r53")
REGDEF(r054,  "r54")
REGDEF(r055,  "r55")
REGDEF(r056,  "r56")
REGDEF(r057,  "r57")
REGDEF(r058,  "r58")
REGDEF(r059,  "r59")
REGDEF(r060,  "r60")
REGDEF(r061,  "r61")
REGDEF(r062,  "r62")
REGDEF(r063,  "r63")
REGDEF(r064,  "r64")
REGDEF(r065,  "r65")
REGDEF(r066,  "r66")
REGDEF(r067,  "r67")
REGDEF(r068,  "r68")
REGDEF(r069,  "r69")
REGDEF(r070,  "r70")
REGDEF(r071,  "r71")
REGDEF(r072,  "r72")
REGDEF(r073,  "r73")
REGDEF(r074,  "r74")
REGDEF(r075,  "r75")
REGDEF(r076,  "r76")
REGDEF(r077,  "r77")
REGDEF(r078,  "r78")
REGDEF(r079,  "r79")
REGDEF(r080,  "r80")
REGDEF(r081,  "r81")
REGDEF(r082,  "r82")
REGDEF(r083,  "r83")
REGDEF(r084,  "r84")
REGDEF(r085,  "r85")
REGDEF(r086,  "r86")
REGDEF(r087,  "r87")
REGDEF(r088,  "r88")
REGDEF(r089,  "r89")
REGDEF(r090,  "r90")
REGDEF(r091,  "r91")
REGDEF(r092,  "r92")
REGDEF(r093,  "r93")
REGDEF(r094,  "r94")
REGDEF(r095,  "r95")
REGDEF(r096,  "r96")
REGDEF(r097,  "r97")
REGDEF(r098,  "r98")
REGDEF(r099,  "r99")
REGDEF(r100, "r100")
REGDEF(r101, "r101")
REGDEF(r102, "r102")
REGDEF(r103, "r103")
REGDEF(r104, "r104")
REGDEF(r105, "r105")
REGDEF(r106, "r106")
REGDEF(r107, "r107")
REGDEF(r108, "r108")
REGDEF(r109, "r109")
REGDEF(r110, "r110")
REGDEF(r111, "r111")
REGDEF(r112, "r112")
REGDEF(r113, "r113")
REGDEF(r114, "r114")
REGDEF(r115, "r115")
REGDEF(r116, "r116")
REGDEF(r117, "r117")
REGDEF(r118, "r118")
REGDEF(r119, "r119")
REGDEF(r120, "r120")
REGDEF(r121, "r121")
REGDEF(r122, "r122")
REGDEF(r123, "r123")
REGDEF(r124, "r124")
REGDEF(r125, "r125")
REGDEF(r126, "r126")
REG_IL(r127, "r127")

REGDEF(NA,     NULL)

REG_FF(f000,    "f")
REGDEF(f001,   "f1")
REGDEF(f002,   "f2")
REGDEF(f003,   "f3")
REGDEF(f004,   "f4")
REGDEF(f005,   "f5")
REGDEF(f006,   "f6")
REGDEF(f007,   "f7")
REGDEF(f008,   "f8")
REGDEF(f009,   "f9")
REGDEF(f010,  "f10")
REGDEF(f011,  "f11")
REGDEF(f012,  "f12")
REGDEF(f013,  "f13")
REGDEF(f014,  "f14")
REGDEF(f015,  "f15")
REGDEF(f016,  "f16")
REGDEF(f017,  "f17")
REGDEF(f018,  "f18")
REGDEF(f019,  "f19")
REGDEF(f020,  "f20")
REGDEF(f021,  "f21")
REGDEF(f022,  "f22")
REGDEF(f023,  "f23")
REGDEF(f024,  "f24")
REGDEF(f025,  "f25")
REGDEF(f026,  "f26")
REGDEF(f027,  "f27")
REGDEF(f028,  "f28")
REGDEF(f029,  "f29")
REGDEF(f030,  "f30")
REGDEF(f031,  "f31")
REGDEF(f032,  "f32")
REGDEF(f033,  "f33")
REGDEF(f034,  "f34")
REGDEF(f035,  "f35")
REGDEF(f036,  "f36")
REGDEF(f037,  "f37")
REGDEF(f038,  "f38")
REGDEF(f039,  "f39")
REGDEF(f040,  "f40")
REGDEF(f041,  "f41")
REGDEF(f042,  "f42")
REGDEF(f043,  "f43")
REGDEF(f044,  "f44")
REGDEF(f045,  "f45")
REGDEF(f046,  "f46")
REGDEF(f047,  "f47")
REGDEF(f048,  "f48")
REGDEF(f049,  "f49")
REGDEF(f050,  "f50")
REGDEF(f051,  "f51")
REGDEF(f052,  "f52")
REGDEF(f053,  "f53")
REGDEF(f054,  "f54")
REGDEF(f055,  "f55")
REGDEF(f056,  "f56")
REGDEF(f057,  "f57")
REGDEF(f058,  "f58")
REGDEF(f059,  "f59")
REGDEF(f060,  "f60")
REGDEF(f061,  "f61")
REGDEF(f062,  "f62")
REGDEF(f063,  "f63")
REGDEF(f064,  "f64")
REGDEF(f065,  "f65")
REGDEF(f066,  "f66")
REGDEF(f067,  "f67")
REGDEF(f068,  "f68")
REGDEF(f069,  "f69")
REGDEF(f070,  "f70")
REGDEF(f071,  "f71")
REGDEF(f072,  "f72")
REGDEF(f073,  "f73")
REGDEF(f074,  "f74")
REGDEF(f075,  "f75")
REGDEF(f076,  "f76")
REGDEF(f077,  "f77")
REGDEF(f078,  "f78")
REGDEF(f079,  "f79")
REGDEF(f080,  "f80")
REGDEF(f081,  "f81")
REGDEF(f082,  "f82")
REGDEF(f083,  "f83")
REGDEF(f084,  "f84")
REGDEF(f085,  "f85")
REGDEF(f086,  "f86")
REGDEF(f087,  "f87")
REGDEF(f088,  "f88")
REGDEF(f089,  "f89")
REGDEF(f090,  "f90")
REGDEF(f091,  "f91")
REGDEF(f092,  "f92")
REGDEF(f093,  "f93")
REGDEF(f094,  "f94")
REGDEF(f095,  "f95")
REGDEF(f096,  "f96")
REGDEF(f097,  "f97")
REGDEF(f098,  "f98")
REGDEF(f099,  "f99")
REGDEF(f100, "f100")
REGDEF(f101, "f101")
REGDEF(f102, "f102")
REGDEF(f103, "f103")
REGDEF(f104, "f104")
REGDEF(f105, "f105")
REGDEF(f106, "f106")
REGDEF(f107, "f107")
REGDEF(f108, "f108")
REGDEF(f109, "f109")
REGDEF(f110, "f110")
REGDEF(f111, "f111")
REGDEF(f112, "f112")
REGDEF(f113, "f113")
REGDEF(f114, "f114")
REGDEF(f115, "f115")
REGDEF(f116, "f116")
REGDEF(f117, "f117")
REGDEF(f118, "f118")
REGDEF(f119, "f119")
REGDEF(f120, "f120")
REGDEF(f121, "f121")
REGDEF(f122, "f122")
REGDEF(f123, "f123")
REGDEF(f124, "f124")
REGDEF(f125, "f125")
REG_FL(f126, "f126")    // note: we don't use/track f127

REG_CF( p00,   "p0")
REGDEF( p01,   "p1")
REGDEF( p02,   "p2")
REGDEF( p03,   "p3")
REGDEF( p04,   "p4")
REGDEF( p05,   "p5")
REGDEF( p06,   "p6")
REGDEF( p07,   "p7")
REGDEF( p08,   "p8")
REGDEF( p09,   "p9")
REGDEF( p10,  "p10")
REGDEF( p11,  "p11")
REGDEF( p12,  "p12")
REGDEF( p13,  "p13")
REGDEF( p14,  "p14")
REG_CL( p15,  "p15")

REG_BF(  b0,   "b0")
REGDEF(  b1,   "b1")
REGDEF(  b2,   "b2")
REGDEF(  b3,   "b3")
REGDEF(  b4,   "b4")
REGDEF(  b5,   "b5")
REGDEF(  b6,   "b6")
REG_BL(  b7,   "b7")

#undef  REGDEF
#undef  REG_IF
#undef  REG_IL
#undef  REG_FF
#undef  REG_FL
#undef  REG_CF
#undef  REG_CL
#undef  REG_BF
#undef  REG_BL
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\regalloc.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                           RegAlloc                                        XX
XX                                                                           XX
XX  Does the register allocation and puts the remaining lclVars on the stack XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

/*****************************************************************************/
#if!TGT_IA64
/*****************************************************************************/

void                Compiler::raInit()
{
    // If opts.compMinOptim, then we dont dont raPredictRegUse(). We simply
    // only use RBM_MIN_OPT_LCLVAR_REGS for register allocation

#if ALLOW_MIN_OPT && !TGT_IA64
    raMinOptLclVarRegs = RBM_MIN_OPT_LCLVAR_REGS;
#endif

    /* We have not assigned any FP variables to registers yet */

#if TGT_x86
    optAllFPregVars = 0;
#endif
}

/*****************************************************************************
 *
 *  The following table determines the order in which registers are considered
 *  for variables to live in (this actually doesn't matter much).
 */

static
BYTE                genRegVarList[] = { REG_VAR_LIST };

/*****************************************************************************
 *
 *  Helper passed to fgWalkAllTrees() to do variable interference marking.
 */

/* static */
int                 Compiler::raMarkVarIntf(GenTreePtr tree, void *p)
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;
    VARSET_TP       varBit;

    /* Ignore assignment nodes */

    if  (tree->gtOper == GT_ASG)
        return  0;

    ASSert(p); Compiler *comp = (Compiler *)p;

    /* This must be a local variable reference; is it tracked? */

    Assert(tree->gtOper == GT_LCL_VAR, comp);
    lclNum = tree->gtLclVar.gtLclNum;

    Assert(lclNum < comp->lvaCount, comp);
    varDsc = comp->lvaTable + lclNum;

    if  (!varDsc->lvTracked)
        return  0;

#ifdef  DEBUG
    if (verbose) printf("%02u[%02u] interferes newly with %08X\n",
                        lclNum, varDsc->lvVarIndex, comp->raVarIntfMask);
#endif

    varBit = genVarIndexToBit(varDsc->lvVarIndex);

    /* Mark all registers that might interfere */

#if TGT_x86

    unsigned        intfMask = comp->raVarIntfMask;
    VARSET_TP   *   intfRegP = comp->raLclRegIntf;

    if  (intfMask & RBM_EAX) intfRegP[REG_EAX] |= varBit;
    if  (intfMask & RBM_EBX) intfRegP[REG_EBX] |= varBit;
    if  (intfMask & RBM_ECX) intfRegP[REG_ECX] |= varBit;
    if  (intfMask & RBM_EDX) intfRegP[REG_EDX] |= varBit;
    if  (intfMask & RBM_ESI) intfRegP[REG_ESI] |= varBit;
    if  (intfMask & RBM_EDI) intfRegP[REG_EDI] |= varBit;
    if  (intfMask & RBM_EBP) intfRegP[REG_EBP] |= varBit;

#else

    comp->raMarkRegSetIntf(varBit, comp->raVarIntfMask);

#endif

    return 0;
}

/*****************************************************************************
 *
 *  Consider the case "a / b" - we'll need to trash EDX (via "CDQ") before
 *  we can safely allow the "b" value to die. Unfortunately, if we simply
 *  mark the node "b" as using EDX, this will not work if "b" is a register
 *  variable that dies with this particular reference. Thus, if we want to
 *  avoid this situation (where we would have to spill the variable from
 *  EDX to someplace else), we need to explicitly mark the interference
 *  of the variable at this point.
 */

void                Compiler::raMarkRegIntf(GenTreePtr tree, regNumber regNum, bool isFirst)
{
    genTreeOps      oper;
    unsigned        kind;

AGAIN:

    assert(tree);
    assert(tree->gtOper != GT_STMT);

    /* Mark the interference for this node */

    raLclRegIntf[regNum] |= tree->gtLiveSet;

    /* Figure out what kind of a node we have */

    oper = tree->OperGet();
    kind = tree->OperKind();

    /* Is this a constant or leaf node? */

    if  (kind & (GTK_CONST|GTK_LEAF))
    {
        if (isFirst && tree->gtOper == GT_LCL_VAR)
        {
            unsigned        lclNum;
            LclVarDsc   *   varDsc;

            assert(tree->gtOper == GT_LCL_VAR);
            lclNum = tree->gtLclVar.gtLclNum;

            assert(lclNum < lvaCount);
            varDsc = lvaTable + lclNum;

            raLclRegIntf[regNum] |= genVarIndexToBit(varDsc->lvVarIndex);

        }
        return;
    }

    isFirst = false;

    /* Is it a 'simple' unary/binary operator? */

    if  (kind & GTK_SMPOP)
    {
        if  (tree->gtOp.gtOp2)
        {
            raMarkRegIntf(tree->gtOp.gtOp1, regNum);

            tree = tree->gtOp.gtOp2;
            goto AGAIN;
        }
        else
        {
            tree = tree->gtOp.gtOp1;
            if  (tree)
                goto AGAIN;

            return;
        }
    }

    /* See what kind of a special operator we have here */

    switch  (oper)
    {
    case GT_MKREFANY:
    case GT_LDOBJ:
            // check that ldObj and fields have their child a the same place
        assert(&tree->gtField.gtFldObj == &tree->gtLdObj.gtOp1);
            // fall through to the GT_FIELD case

    case GT_FIELD:
        tree = tree->gtField.gtFldObj;
        break;

    case GT_CALL:

        assert(tree->gtFlags & GTF_CALL);

        if  (tree->gtCall.gtCallObjp)
            raMarkRegIntf(tree->gtCall.gtCallObjp, regNum);

        if  (tree->gtCall.gtCallArgs)
            raMarkRegIntf(tree->gtCall.gtCallArgs, regNum);

#if USE_FASTCALL
        if  (tree->gtCall.gtCallRegArgs)
            raMarkRegIntf(tree->gtCall.gtCallRegArgs, regNum);
#endif

        if  (tree->gtCall.gtCallVptr)
            tree = tree->gtCall.gtCallVptr;
        else if  (tree->gtCall.gtCallType == CT_INDIRECT)
            tree = tree->gtCall.gtCallAddr;
        else
            tree = NULL;

        break;

    default:
#ifdef  DEBUG
        gtDispTree(tree);
#endif
        assert(!"unexpected operator");
    }

    if  (tree)
        goto AGAIN;
}


/*****************************************************************************
 *
 *  Find the interference between variables and registers
 *  FPlvlLife[] is an OUT argument. It is filled with the interference of
 *      FP vars with a FP stack level
 *  trkGCvars is the set of all tracked GC and byref vars.
 */

void                Compiler::raMarkRegIntf(VARSET_TP * FPlvlLife,
                                            VARSET_TP   trkGCvars)
{

#if TGT_x86
    /* We'll keep track of FP depth and interference */
    memset(FPlvlLife, 0, sizeof(VARSET_TP) * FP_STK_SIZE);
    FPlvlLife[0] = ~(VARSET_TP)0;
#endif

    for (BasicBlock * block = fgFirstBB;
         block;
         block = block->bbNext)
    {
        GenTreePtr      list;
        GenTreePtr      stmt;
        VARSET_TP       vars = 0;

        list = block->bbTreeList;
        if  (!list)
            goto DONE_BB;

        /* Walk all the statements of the block backwards */

        stmt = list;
        do
        {
            GenTreePtr      tree;

            stmt = stmt->gtPrev;
            if  (!stmt)
                break;

            assert(stmt->gtOper == GT_STMT);

#if TGT_x86
            stmt->gtStmtFPrvcOut = 0;
#endif

            for (tree = stmt->gtStmt.gtStmtExpr;
                 tree;
                 tree = tree->gtPrev)
            {
                VARSET_TP       life;
#if TGT_x86
                regMaskTP       regUse;
#else
                unsigned        regUse;
                regMaskTP       regInt;
#endif

                /* Get hold of the liveset for this node */

                life  = tree->gtLiveSet;

                /* Remember all variables live anywhere in the block */

                vars |= life;

#if TGT_x86

                /* Now's a good time to clear field(s) used later on */

                tree->gtFPregVars = 0;

                /* Will the FP stack be non-empty at this point? */

                if  (tree->gtFPlvl)
                {
                    /*
                        Any variables that are live at this point
                        cannot be enregistered at or above this
                        stack level.
                     */

                    if (tree->gtFPlvl < FP_STK_SIZE)
                        FPlvlLife[tree->gtFPlvl] |= life;
                    else
                        FPlvlLife[FP_STK_SIZE-1] |= life;
                }

                /* Compute interference with busy registers */

                regUse = tree->gtUsedRegs;

#else

#ifdef  DEBUG
                if  ((USHORT)regInt == 0xDDDD) printf("RegUse at [%08X] was never set!\n", tree);
#endif

//              printf("RegUse at [%08X] is %2u/%04X life is %08X\n", tree, tree->gtTempRegs, tree->gtIntfRegs, life); gtDispTree(tree, 0, true);

                regUse = tree->gtTempRegs; assert(regUse < (unsigned)REG_COUNT);

#if TGT_IA64

                UNIMPL(!"assign reg");

#else

                regInt = tree->gtIntfRegs; assert((USHORT)regInt != 0xDDDD);

                /* Check for some special cases of interference */

                switch (tree->gtOper)
                {
                case GT_CALL:

                    /* Mark interference due to callee-trashed registers */

                    if  (life)
                    {
                        raMarkRegSetIntf(life, RBM_CALLEE_TRASH);
                    }

                    break;
                }

#endif

#endif

                /* Check for special case of an assignment to an indirection */

                if  (tree->OperKind() & GTK_ASGOP)
                {
                    switch (tree->gtOp.gtOp1->gtOper)
                    {
                    case GT_IND:

                        /* Local vars in the LHS should avoid regs trashed by RHS */

#if!TGT_IA64
                        if  (tree->gtOp.gtOp2->gtRsvdRegs)
                        {
                            raVarIntfMask = tree->gtOp.gtOp2->gtRsvdRegs;

                            fgWalkTree(tree->gtOp.gtOp1,
                                       raMarkVarIntf,
                                       (void *)this,
                                       true);
                        }
#endif

                        break;

                    case GT_LCL_VAR:

#if TGT_x86

                        /* Check for special case of an assignment to a local */

                        if  (tree->gtOper == GT_ASG)
                        {
                            /*
                                Consider a simple assignment to a local:

                                    lcl = expr;

                                Since the "=" node is visited after the variable
                                is marked live (assuming it's live after the
                                assignment), we don't want to use the register
                                use mask of the "=" node but rather that of the
                                variable itself.
                             */

                            regUse = tree->gtOp.gtOp1->gtUsedRegs;
                        }

#else

                        // ISSUE: Anything similar needed for RISC?

#endif

                        break;
                    }

                    goto SET_USE;
                }

                switch (tree->gtOper)
                {
                case GT_DIV:
                case GT_MOD:

                case GT_UDIV:
                case GT_UMOD:
#if TGT_x86

                    /* Special case: 32-bit integer divisor */

                    // @TODO : This should be done in the predictor

                if  ((tree->gtOper == GT_DIV  || tree->gtOper == GT_MOD ||
                      tree->gtOper == GT_UDIV || tree->gtOper == GT_UMOD ) &&
                     (tree->gtType == TYP_INT)                              )
                    {
                        /* We will trash EDX while the operand is still alive */

                        /* Mark all live vars interfering with EAX and EDX */

                        raMarkRegIntf(tree->gtOp.gtOp1, REG_EAX, false);
                        raMarkRegIntf(tree->gtOp.gtOp1, REG_EDX, false);

                        /* Mark all live vars and local Var */

                        raMarkRegIntf(tree->gtOp.gtOp2, REG_EAX, true);
                        raMarkRegIntf(tree->gtOp.gtOp2, REG_EDX, true);
                    }

#endif

                    break;

                case GT_CALL:

#if INLINE_NDIRECT
                    //UNDONE: we should do proper dataflow and generate
                    //        the code for saving to/restoring from
                    //        the inlined N/Direct frame instead.

                    /* GC refs interfere with calls to unmanaged code */

                    if ((tree->gtFlags & GTF_CALL_UNMANAGED) &&
                        (life & trkGCvars))
                    {
                        unsigned reg;

                        for (reg = 0; reg < (unsigned) REG_COUNT; reg++)
                        {
                            if (genRegMask((regNumbers)reg) & RBM_CALLEE_SAVED)
                                raLclRegIntf[reg] |= (life & trkGCvars);
                        }
                    }
#endif
#if TGT_x86
                    /* The FP stack must be empty at all calls */

                    FPlvlLife[FP_STK_SIZE-1] |= life;
#endif
                    break;
                }

            SET_USE:

                if  (!regUse)
                    continue;

#if TGT_x86

//              printf("RegUse at [%08X] is %08X life is %08X\n", tree, regUse, life);

                if  (regUse & (RBM_EAX|RBM_EBX|RBM_ECX|RBM_EDX))
                {
                    if  (regUse & RBM_EAX) raLclRegIntf[REG_EAX] |= life;
                    if  (regUse & RBM_EBX) raLclRegIntf[REG_EBX] |= life;
                    if  (regUse & RBM_ECX) raLclRegIntf[REG_ECX] |= life;
                    if  (regUse & RBM_EDX) raLclRegIntf[REG_EDX] |= life;
                }

                assert((regUse & RBM_ESP) == 0);

                if  (regUse & (RBM_ESI|RBM_EDI|RBM_EBP|RBM_ESP))
                {
                    if  (regUse & RBM_EBP) raLclRegIntf[REG_EBP] |= life;
                    if  (regUse & RBM_ESI) raLclRegIntf[REG_ESI] |= life;
                    if  (regUse & RBM_EDI) raLclRegIntf[REG_EDI] |= life;
                }

#else

                for (unsigned rnum = 0; rnum < regUse; rnum++)
                    raLclRegIntf[rnum] |= life;

                if  (regInt && life)
                    raMarkRegSetIntf(life, regInt);

#endif

            }
        }
        while (stmt != list);

        /* Does the block end with a local 'call' instruction? */

        if  (block->bbJumpKind == BBJ_CALL)
        {
            VARSET_TP           outLife = block->bbLiveOut;

            /* The call may trash any register */

            for (unsigned reg = 0; reg < REG_COUNT; reg++)
                raLclRegIntf[reg] |= outLife;
        }

    DONE_BB:

        /* Note: we're reusing one of the fields not used at this stage */

        block->bbVarUse = vars;
    }

    //-------------------------------------------------------------------------

#ifdef  DEBUG

    if  (verbose)
    {
        printf("Reg. interference graph for %s\n", info.compFullName);

        unsigned    lclNum;
        LclVarDsc * varDsc;

        for (lclNum = 0, varDsc = lvaTable;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            unsigned        varNum;
            VARSET_TP       varBit;

            unsigned        regNum;

            /* Ignore the variable if it's not tracked */

            if  (!varDsc->lvTracked)
                continue;

            /* Get hold of the index and the interference mask for the variable */

            varNum = varDsc->lvVarIndex;
            varBit = genVarIndexToBit(varNum);

            printf("  var #%2u[%2u] and ", lclNum, varNum);

            if  (varDsc->lvType == TYP_DOUBLE)
            {
#if TGT_x86
                for (regNum = 0; regNum < FP_STK_SIZE; regNum++)
                {
                    if  (FPlvlLife[regNum] & varBit)
                    {
                        printf("ST(%u) ", regNum);
                    }
                }
#endif
            }
            else
            {
                for (regNum = 0; regNum < REG_COUNT; regNum++)
                {
                    if  (raLclRegIntf[regNum] & varBit)
                        printf("%3s ", compRegVarName((regNumber)regNum));
                    else
                        printf("    ");
                }
            }

            printf("\n");
        }

        printf("\n");
    }

#endif
}

/*****************************************************************************
 *
 *  Adjust the ref counts based on interference.
 *
 */

void                Compiler::raAdjustVarIntf()
{
    if (true) // @Disabled
        return;

#if 0

    unsigned        lclNum;
    LclVarDsc * *   cntTab;

    for (lclNum = 0, cntTab = lvaRefSorted;
         lclNum < lvaCount;
         lclNum++  , cntTab++)
    {
        /* Get hold of the variable descriptor */

        LclVarDsc *     varDsc = *cntTab;

        /* Skip the variable if it's not tracked */

        if  (!varDsc->lvTracked)
            continue;

        /* Skip the variable if it's already enregistered */

        if  (varDsc->lvRegister)
            continue;

        /* Skip the variable if it's marked as 'volatile' */

        if  (varDsc->lvVolatile)
            continue;

        /* Stop if we've reached the point of no use */

        if  (varDsc->lvRefCnt < 1)
            break;

        /* See how many registers this variable interferes with */

        unsigned        varIndex = varDsc->lvVarIndex;
        VARSET_TP       regIntf  = raLclRegIntf[varIndex];

        unsigned        reg;
        unsigned        regCnt;

        for (reg = regCnt = 0;
             reg < sizeof(genRegVarList)/sizeof(genRegVarList[0]);
             reg++)
        {
            regNumber       regNum = (regNumber)genRegVarList[reg];
            regMaskTP       regBit = genRegMask(regNum);

            if  (isNonZeroRegMask((regIntf & regBit))
                regCnt++;
        }

        printf("Variable #%02u interferes with %u registers\n", varDsc-lvaTable, regCnt);
    }

#endif

}

/*****************************************************************************/
#if TGT_x86
/*****************************************************************************
 *
 *  Predict register choice for a type.
 */

unsigned                Compiler::raPredictRegPick(var_types    type,
                                                   unsigned     lockedRegs)
{
    /* Watch out for byte register */

    if  (genTypeSize(type) == 1)
        lockedRegs |= (RBM_ESI|RBM_EDI|RBM_EBP);

    switch (type)
    {
    case TYP_CHAR:
    case TYP_BYTE:
    case TYP_SHORT:
    case TYP_BOOL:
    case TYP_INT:

    case TYP_UBYTE:
    case TYP_UINT:

    case TYP_REF:
    case TYP_BYREF:
    case TYP_UNKNOWN:

        if  (!(lockedRegs & RBM_EAX)) { return RBM_EAX; }
        if  (!(lockedRegs & RBM_EDX)) { return RBM_EDX; }
        if  (!(lockedRegs & RBM_ECX)) { return RBM_ECX; }
        if  (!(lockedRegs & RBM_EBX)) { return RBM_EBX; }
        if  (!(lockedRegs & RBM_EBP)) { return RBM_EBP; }
        if  (!(lockedRegs & RBM_ESI)) { return RBM_ESI; }
        if  (!(lockedRegs & RBM_EDI)) { return RBM_EDI; }
        /* Otherwise we have allocated all registers, so do nothing */
        break;

    case TYP_LONG:
        if  (!(lockedRegs & RBM_EAX))
        {
            /* EAX is available, see if we can pair it with another reg */

            if  (!(lockedRegs & RBM_EDX)) { return RBM_EAX|RBM_EDX; }
            if  (!(lockedRegs & RBM_ECX)) { return RBM_EAX|RBM_ECX; }
            if  (!(lockedRegs & RBM_EBX)) { return RBM_EAX|RBM_EBX; }
            if  (!(lockedRegs & RBM_ESI)) { return RBM_EAX|RBM_ESI; }
            if  (!(lockedRegs & RBM_EDI)) { return RBM_EAX|RBM_EDI; }
            if  (!(lockedRegs & RBM_EBP)) { return RBM_EAX|RBM_EBP; }
        }

        if  (!(lockedRegs & RBM_ECX))
        {
            /* ECX is available, see if we can pair it with another reg */

            if  (!(lockedRegs & RBM_EDX)) { return RBM_ECX|RBM_EDX; }
            if  (!(lockedRegs & RBM_EBX)) { return RBM_ECX|RBM_EBX; }
            if  (!(lockedRegs & RBM_ESI)) { return RBM_ECX|RBM_ESI; }
            if  (!(lockedRegs & RBM_EDI)) { return RBM_ECX|RBM_EDI; }
            if  (!(lockedRegs & RBM_EBP)) { return RBM_ECX|RBM_EBP; }
        }

        if  (!(lockedRegs & RBM_EDX))
        {
            /* EDX is available, see if we can pair it with another reg */

            if  (!(lockedRegs & RBM_EBX)) { return RBM_EDX|RBM_EBX; }
            if  (!(lockedRegs & RBM_ESI)) { return RBM_EDX|RBM_ESI; }
            if  (!(lockedRegs & RBM_EDI)) { return RBM_EDX|RBM_EDI; }
            if  (!(lockedRegs & RBM_EBP)) { return RBM_EDX|RBM_EBP; }
        }

        if  (!(lockedRegs & RBM_EBX))
        {
            /* EBX is available, see if we can pair it with another reg */

            if  (!(lockedRegs & RBM_ESI)) { return RBM_EBX|RBM_ESI; }
            if  (!(lockedRegs & RBM_EDI)) { return RBM_EBX|RBM_EDI; }
            if  (!(lockedRegs & RBM_EBP)) { return RBM_EBX|RBM_EBP; }
        }

        if  (!(lockedRegs & RBM_ESI))
        {
            /* ESI is available, see if we can pair it with another reg */

            if  (!(lockedRegs & RBM_EDI)) { return RBM_ESI|RBM_EDI; }
            if  (!(lockedRegs & RBM_EBP)) { return RBM_ESI|RBM_EBP; }
        }

        if  (!(lockedRegs & (RBM_EDI|RBM_EBP)))
        {
            return RBM_EDI|RBM_EBP;
        }

        /* Otherwise we have allocated all registers, so do nothing */
        return 0;

    case TYP_FLOAT:
    case TYP_DOUBLE:
        return 0;

    default:
        assert(!"unexpected type in reg use prediction");
    }
    return 0;

}

/* Make sure a specific register is free for reg use prediction. If it is
 * locked, code generation will spill. This is simulated by allocating
 * another reg (possible reg pair).
 */

unsigned            Compiler::raPredictGrabReg(var_types    type,
                                               unsigned     lockedRegs,
                                               unsigned     mustReg)
{
    assert(mustReg);

    if (lockedRegs & mustReg)
        return raPredictRegPick(type, lockedRegs|mustReg);

    return mustReg;
}

/* return the register mask for the low register of a register pair mask */

unsigned                Compiler::raPredictGetLoRegMask(unsigned regPairMask)
{
    int pairNo;

    /* first map regPairMask to reg pair number */
    for (pairNo = REG_PAIR_FIRST; pairNo <= REG_PAIR_LAST; pairNo++)
    {
        if (!genIsProperRegPair((regPairNo)pairNo))
            continue;
        if (genRegPairMask((regPairNo)pairNo)==regPairMask)
            break;
    }

    assert(pairNo <= REG_PAIR_LAST);

    /* now get reg mask for low register */
    return genRegMask(genRegPairLo((regPairNo)pairNo));
}


/*****************************************************************************
 *
 *  Predict integer register use for generating an address mode for a tree,
 *  by setting tree->gtUsedRegs to all registers used by this tree and its
 *  children.
 *    lockedRegs - registers which are currently held by a sibling
 *  Return the registers held by this tree.
 * TODO: may want to make this more thorough so it can be called from other
 * places like CSE.
 */

unsigned                Compiler::raPredictAddressMode(GenTreePtr tree,
                                                       unsigned   lockedRegs)
{
    GenTreePtr      op1;
    GenTreePtr      op2;
    genTreeOps      oper  = tree->OperGet();
    unsigned        regMask;

    /* if not a plus, then just force it to a register */
    if (oper != GT_ADD)
        return raPredictTreeRegUse(tree, true, lockedRegs);

    op1 = tree->gtOp.gtOp1;
    op2 = tree->gtOp.gtOp2;

    assert(op1->OperGet() != GT_CNS_INT);

    /* reg + icon address mode, recurse to look for address mode below */
    if (op2->OperGet() == GT_CNS_INT) {
        regMask = raPredictAddressMode(op1, lockedRegs);
        tree->gtUsedRegs = op1->gtUsedRegs;
        return regMask;
    }

    /* we know we have to evaluate op1 to a register */
    regMask = raPredictTreeRegUse(op1, true, lockedRegs);
    tree->gtUsedRegs = op1->gtUsedRegs;

    /* otherwise we assume that two registers are used */
    regMask |= raPredictTreeRegUse(op2, true, lockedRegs | regMask);
    tree->gtUsedRegs |= op2->gtUsedRegs;

    return regMask;
}

/*****************************************************************************
 *
 * Evaluate the tree to a register. If result intersects with awayFromMask, grab a
 * new register for the result.
 */

unsigned                Compiler::raPredictComputeReg(GenTreePtr tree,
                                             unsigned awayFromMask,
                                             unsigned lockedRegs)
{
    unsigned regMask = raPredictTreeRegUse(tree, true, lockedRegs);

    if (regMask & awayFromMask)
    {
        regMask = raPredictRegPick(tree->TypeGet(), lockedRegs|awayFromMask);
    }

    tree->gtUsedRegs |= regMask;

    return regMask;
}


/*****************************************************************************/

/* Determine register mask for a call/return from type. TODO: this switch
 * is used elsewhere, so that code should call this thing too.
 */

inline
unsigned               genTypeToReturnReg(var_types type)
{
    /* TODO: use a table */

    switch (type)
    {
        case TYP_CHAR:
        case TYP_BYTE:
        case TYP_SHORT:
        case TYP_BOOL:
        case TYP_INT:
        case TYP_REF:
        case TYP_BYREF:
        case TYP_UBYTE:
            return RBM_INTRET;

        case TYP_LONG:
            return RBM_LNGRET;

        case TYP_FLOAT:
        case TYP_DOUBLE:
        case TYP_VOID:
            return 0;

        default:
            assert(!"unhandled/unexpected type");
            return 0;
    }
}

/*****************************************************************************
 *
 *  Predict integer register use for a tree, by setting tree->gtUsedRegs
 *  to all registers used by this tree and its children.
 *    mustReg - tree must be computed to a register
 *    lockedRegs - registers which are currently held by a sibling
 *  Return the registers held by this tree.
 */

unsigned            Compiler::raPredictTreeRegUse(GenTreePtr    tree,
                                                  bool          mustReg,
                                                  unsigned      lockedRegs)
{
    genTreeOps      oper;
    unsigned        kind;
    unsigned        regMask;
    var_types       type;
    bool            op1MustReg, op2MustReg;

    assert(tree);

#ifndef NDEBUG
    /* impossible value, to make sure that we set them */
    tree->gtUsedRegs = RBM_STK;
    regMask = RBM_STK;
#endif

    /* Figure out what kind of a node we have */

    oper = tree->OperGet();
    kind = tree->OperKind();
    type = tree->TypeGet();

    /* Is this a constant or leaf node? */

    if  (kind & (GTK_CONST|GTK_LEAF))
    {
        switch(oper)
        {
        case GT_BREAK:
        case GT_NO_OP:
            // These leaf nodes are statements. Dont need any registers.
            mustReg = false;
            break;

#if OPTIMIZE_QMARK
        case GT_BB_QMARK:
            regMask = genTypeToReturnReg(type);
            tree->gtUsedRegs |= regMask;
            goto RETURN_CHECK;
#endif

        case GT_LCL_VAR:
            if (type == TYP_STRUCT)
                break;

            // As the local may later get enregistered, hold a register
            // for it, even if we havent been asked for it.

            unsigned lclNum;
            lclNum = tree->gtLclVar.gtLclNum;
            LclVarDsc * varDsc = &lvaTable[lclNum];
            if ((varDsc->lvTracked) &&
                (tree->gtLiveSet & genVarIndexToBit(varDsc->lvVarIndex)))
                mustReg = true;
            break;
        }

        /* If don't need to evaluate to register, it's NULL */

        if (!mustReg)
            regMask = 0;
        else
            regMask = raPredictRegPick(type, lockedRegs);

        tree->gtUsedRegs = regMask;
        goto RETURN_CHECK;
    }

    /* Is it a 'simple' unary/binary operator? */

    if  (kind & GTK_SMPOP)
    {
#if GC_WRITE_BARRIER_CALL
        unsigned op2Reg = 0;
#endif
        GenTreePtr      op1 = tree->gtOp.gtOp1;
        GenTreePtr      op2 = tree->gtOp.gtOp2;

        GenTreePtr      opsPtr [3];
        unsigned        regsPtr[3];

        switch (oper)
        {
        case GT_ASG:
        case GT_CHS:
        case GT_ASG_OR:
        case GT_ASG_XOR:
        case GT_ASG_AND:
        case GT_ASG_SUB:
        case GT_ASG_ADD:
        case GT_ASG_MUL:
        case GT_ASG_DIV:
        case GT_ASG_UDIV:

            /* initialize forcing of operands */
            op2MustReg = true;
            op1MustReg = false;

            /* Is the value being assigned a simple one? */
            switch (op2->gtOper)
            {
            case GT_CNS_LNG:
            case GT_CNS_INT:
            case GT_RET_ADDR:
            case GT_POP:

                op2MustReg = false;
                break;
            }

#if     !GC_WRITE_BARRIER_CALL

#ifdef  SSB
            if  (gcIsWriteBarrierAsgNode(tree))
            {
                unsigned regMask1;

                if (tree->gtFlags & GTF_REVERSE_OPS)
                {
                    regMask  = raPredictTreeRegUse(op2, op2MustReg, lockedRegs);
                    regMask  = raPredictTreeRegUse(op1, op1MustReg, regMask|lockedRegs);

                    regMask1 = raPredictRegPick(TYP_REF, regMask|lockedRegs);
                }
                else
                {
                    regMask1 = raPredictTreeRegUse(op1, op1MustReg, lockedRegs);
                    regMask  = raPredictTreeRegUse(op2, op2MustReg, regMask1|lockedRegs);

                    regMask1 = raPredictRegPick(TYP_REF, regMask1|lockedRegs);
                }

                regMask |= regMask1;

                tree->gtUsedRegs = op1->gtUsedRegs | op2->gtUsedRegs | regMask1;

                goto RETURN_CHECK;
            }
#endif

            /* are we supposed to evaluate RHS first? if so swap
             * operand pointers and operand force flags
             */

            if  (tree->gtFlags & GTF_REVERSE_OPS)
            {
                GenTreePtr temp =     op1;
                bool       tempBool = op1MustReg;
                op1 = op2;               op2 = temp;
                op1MustReg = op2MustReg; op2MustReg = tempBool;
            }

            regMask = raPredictTreeRegUse(op1, op1MustReg, lockedRegs);

            regMask = raPredictTreeRegUse(op2, op2MustReg, regMask|lockedRegs);

            tree->gtUsedRegs = op1->gtUsedRegs | op2->gtUsedRegs;

            goto RETURN_CHECK;

#else // GC_WRITE_BARRIER_CALL

            /* are we supposed to evaluate RHS first? if so swap
             * operand pointers and operand force flags
             */

            if  (tree->gtFlags & GTF_REVERSE_OPS)
            {

                regMask = raPredictTreeRegUse(op2, op2MustReg, lockedRegs);
                op2Reg  = regMask;

                regMask = raPredictTreeRegUse(op1, op1MustReg, regMask|lockedRegs);
            }
            else
            {
                regMask = raPredictTreeRegUse(op1, op1MustReg, lockedRegs);
                op2Reg  = raPredictTreeRegUse(op2, op2MustReg, regMask|lockedRegs);
            }

            tree->gtUsedRegs = op1->gtUsedRegs | op2->gtUsedRegs;

            if  (gcIsWriteBarrierAsgNode(tree))
            {
                /* Steer computation away from EDX as the pointer is
                   passed to the write-barrier call in EDX */

                tree->gtUsedRegs |= raPredictGrabReg(tree->TypeGet(),
                                                    lockedRegs|op2Reg|regMask,
                                                    RBM_EDX);
                regMask = op2Reg;

                if (op1->gtOper == GT_IND)
                {
                    GenTreePtr  rv1, rv2;
                    unsigned mul, cns;
                    bool rev;

                    /* Special handling of indirect assigns for write barrier */

                    bool yes = genCreateAddrMode(op1->gtOp.gtOp1, -1, true, 0, &rev, &rv1, &rv2, &mul, &cns);

                    /* Check address mode for enregisterable locals */

                    if  (yes)
                    {
                        if  (rv1 != NULL && rv1->gtOper == GT_LCL_VAR)
                        {
                            lvaTable[rv1->gtLclVar.gtLclNum].lvRefAssign = 1;
                        }
                        if  (rv2 != NULL && rv2->gtOper == GT_LCL_VAR)
                        {
                            lvaTable[rv2->gtLclVar.gtLclNum].lvRefAssign = 1;
                        }
                    }
                }

                if  (op2->gtOper == GT_LCL_VAR)
                    lvaTable[op2->gtLclVar.gtLclNum].lvRefAssign = 1;
            }

            goto RETURN_CHECK;

#endif // GC_WRITE_BARRIER_CALL

        case GT_ASG_LSH:
        case GT_ASG_RSH:
        case GT_ASG_RSZ:
            /* assigning shift operators */

            assert(type != TYP_LONG);

            regMask = raPredictTreeRegUse(op1, false, lockedRegs);

            /* shift count is handled same as ordinary shift */
            goto HANDLE_SHIFT_COUNT;

        case GT_CAST:

            /* Cannot cast to VOID */
            assert(type != TYP_VOID);

            /* cast to long is special */
            if  (type == TYP_LONG && op1->gtType <= TYP_INT)
            {
                var_types dstt = (var_types) op2->gtIntCon.gtIconVal;
                assert(dstt==TYP_LONG || dstt==TYP_ULONG);

                // Cast to TYP_ULONG can use any registers
                // Cast to TYP_LONG needs EAX,EDX to sign extend op1 using cdq

                if (dstt == TYP_ULONG)
                {
                    regMask  = raPredictTreeRegUse(op1, true, lockedRegs);
                    // Now get one more reg
                    regMask |= raPredictRegPick(TYP_INT, regMask|lockedRegs);
                }
                else
                {
                    raPredictTreeRegUse(op1, false, lockedRegs);
                    // Grab EAX,EDX
                    regMask = raPredictGrabReg(type, lockedRegs, RBM_EAX|RBM_EDX);
                }

                tree->gtUsedRegs = op1->gtUsedRegs | regMask;
                goto RETURN_CHECK;
            }

            /* cast to float/double is special */
            if (varTypeIsFloating(type))
            {
                switch(op1->TypeGet())
                {
                /* uses fild, so don't need to be loaded to reg */
                case TYP_INT:
                case TYP_LONG:
                    raPredictTreeRegUse(op1, false, lockedRegs);
                    tree->gtUsedRegs = op1->gtUsedRegs;
                    regMask = 0;
                    goto RETURN_CHECK;
                }
            }

            /* cast from long is special - it frees a register */
            if  (type <= TYP_INT && op1->gtType == TYP_LONG)
            {
                regMask = raPredictTreeRegUse(op1, true, lockedRegs);
                // If we have 2 regs, free one.
                if (!genOneBitOnly(regMask))
                    regMask = raPredictGetLoRegMask(regMask);
                tree->gtUsedRegs = op1->gtUsedRegs;
                goto RETURN_CHECK;
            }

            /* otherwise must load operand to register */
            goto GENERIC_UNARY;

        case GT_ADDR:
        {
            regMask = raPredictTreeRegUse(op1, false, lockedRegs);

                //Need register for LEA instruction, this is the only 'held' instruciton
            regMask = raPredictRegPick(TYP_REF, lockedRegs|regMask);
            tree->gtUsedRegs = op1->gtUsedRegs | regMask;
            goto RETURN_CHECK;
        }

        case GT_RET:
        case GT_NOT:
        case GT_NOP:
        case GT_NEG:
            /* generic unary operators */

    GENERIC_UNARY:

#if INLINING || OPT_BOOL_OPS

            if  (!op1)
            {
                tree->gtUsedRegs = regMask = 0;
                goto RETURN_CHECK;
            }

#endif

            regMask = raPredictTreeRegUse(op1, true, lockedRegs);
            tree->gtUsedRegs = op1->gtUsedRegs;
            goto RETURN_CHECK;

#if INLINE_MATH
        case GT_MATH:
            goto GENERIC_UNARY;
#endif

        case GT_IND:
            /* check for address mode */
            regMask = raPredictAddressMode(op1, lockedRegs);

            /* forcing to register? */
            if (mustReg)
            {
                /* careful about overlap between reg pair and address mode */
                if  (type==TYP_LONG)
                    regMask = raPredictRegPick(type, lockedRegs | regMask);
                else
                    regMask = raPredictRegPick(type, lockedRegs);

            }

#if CSELENGTH

            /* Some GT_IND have "secret" subtrees */

            if  ((tree->gtFlags & GTF_IND_RNGCHK) && tree->gtInd.gtIndLen)
            {
                GenTreePtr      len = tree->gtInd.gtIndLen;

                assert(len->gtOper == GT_ARR_RNGCHK);

                if  (len->gtArrLen.gtArrLenCse)
                {
                    len = len->gtArrLen.gtArrLenCse;
                    regMask |= raPredictTreeRegUse(len, true, regMask|lockedRegs);
                }
            }

#endif

            tree->gtUsedRegs = regMask;
            goto RETURN_CHECK;

        case GT_LOG0:
        case GT_LOG1:
            /* For SETE/SETNE (P6 only), we need an extra register */
            raPredictTreeRegUse(op1, (genCPU == 5) ? false : true, lockedRegs);
            regMask = raPredictRegPick(type, lockedRegs|op1->gtUsedRegs);
            tree->gtUsedRegs = op1->gtUsedRegs | regMask;
            goto RETURN_CHECK;

        case GT_POST_INC:
        case GT_POST_DEC:
            // ISSUE: Is the following correct?
            raPredictTreeRegUse(op1, true, lockedRegs);
            regMask = raPredictRegPick(type, lockedRegs|op1->gtUsedRegs);
            tree->gtUsedRegs = op1->gtUsedRegs | regMask;
            goto RETURN_CHECK;

        case GT_EQ:
        case GT_NE:
        case GT_LT:
        case GT_LE:
        case GT_GE:
        case GT_GT:

            /* Floating point comparison uses EAX for flags */

            if  (varTypeIsFloating(op1->TypeGet()))
            {
                regMask = raPredictGrabReg(TYP_INT, lockedRegs, RBM_EAX);
            }
            else if (!(tree->gtFlags & GTF_JMP_USED))
            {
                // Longs and float comparisons are converted to ?:
                assert(genActualType    (op1->TypeGet()) != TYP_LONG &&
                       varTypeIsFloating(op1->TypeGet()) == false);

                // The set instructions need a byte register
                regMask = raPredictGrabReg(TYP_BYTE, lockedRegs, RBM_EAX);
            }

            tree->gtUsedRegs = regMask;
            goto GENERIC_BINARY;

        case GT_MUL:

#if LONG_MATH_REGPARAM
        if  (type == TYP_LONG)
            goto LONG_MATH;
#endif
        if  (type == TYP_LONG)
        {
            /* Special case: "(long)i1 * (long)i2" */

            if  (op1->gtOper == GT_CAST && op1->gtOp.gtOp1->gtType == TYP_INT &&
                 op2->gtOper == GT_CAST && op2->gtOp.gtOp1->gtType == TYP_INT)
            {
                /* This will done by a simple "imul eax, reg" */

                op1 = op1->gtOp.gtOp1;
                op2 = op2->gtOp.gtOp2;

                /* are we supposed to evaluate op2 first? */

                if  (tree->gtFlags & GTF_REVERSE_OPS)
                {
                    regMask = raPredictTreeRegUse(op2,  true, lockedRegs);
                    regMask = raPredictTreeRegUse(op1,  true, lockedRegs | regMask);
                }
                else
                {
                    regMask = raPredictComputeReg(op1, RBM_ALL^RBM_EAX , lockedRegs);
                    regMask = raPredictTreeRegUse(op2,  true, lockedRegs|regMask);
                }

                /* grab EAX, EDX for this tree node */

                regMask |= raPredictGrabReg(TYP_INT, lockedRegs, RBM_EAX|RBM_EDX);

                tree->gtUsedRegs = RBM_EAX | RBM_EDX | regMask;

                tree->gtUsedRegs |= op1->gtUsedRegs | op2->gtUsedRegs;

                regMask = RBM_EAX|RBM_EDX;

                goto RETURN_CHECK;
            }
        }

        case GT_OR:
        case GT_XOR:
        case GT_AND:

        case GT_ADD:
        case GT_SUB: tree->gtUsedRegs = 0;

    GENERIC_BINARY:

            regMask = raPredictTreeRegUse(op1, true,  lockedRegs | op2->gtRsvdRegs);

                      raPredictTreeRegUse(op2, false, lockedRegs | regMask);

            tree->gtUsedRegs |= op1->gtUsedRegs | op2->gtUsedRegs;

            /* If the tree type is small, it must be an overflow instr. Special
               requirements for byte overflow instrs */

            if (genTypeSize(tree->TypeGet()) == sizeof(char))
            {
                assert(tree->gtOverflow());

                /* For 8 bit arithmetic, one operands has to be in a
                   byte-addressable register, and the other has to be
                   in a byte-addrble reg or in memory. Assume its in a reg */

                regMask = 0;
                if (!(op1->gtUsedRegs & RBM_BYTE_REGS))
                    regMask  = raPredictGrabReg(TYP_BYTE, lockedRegs          , RBM_EAX);
                if (!(op2->gtUsedRegs & RBM_BYTE_REGS))
                    regMask |= raPredictGrabReg(TYP_BYTE, lockedRegs | regMask, RBM_EAX);

                tree->gtUsedRegs |= regMask;
            }
            goto RETURN_CHECK;

        case GT_DIV:
        case GT_MOD:

        case GT_UDIV:
        case GT_UMOD:

            /* non-integer division handled in generic way */
            if  (!varTypeIsIntegral(type))
            {
                tree->gtUsedRegs = 0;
                goto GENERIC_BINARY;
            }

#if!LONG_MATH_REGPARAM
            assert(type != TYP_LONG);
#else
            if  (type == TYP_LONG)
            {
            LONG_MATH:

                // ISSUE: Is the following correct?

                regMask = raPredictGrabReg(TYP_LONG, lockedRegs, RBM_EAX|RBM_EDX);
                raPredictTreeRegUse(op1, true, lockedRegs);
                op1->gtUsedRegs |= RBM_EAX|RBM_EDX;
                regMask = raPredictGrabReg(TYP_LONG, lockedRegs, RBM_EBX|RBM_ECX);
                raPredictTreeRegUse(op2, true, lockedRegs);
                tree->gtUsedRegs = op1->gtUsedRegs |
                                   op2->gtUsedRegs |
                                   regMask;

                regMask = RBM_EAX|RBM_EDX;
                goto RETURN_CHECK;
            }
#endif

            /* no divide immediate, so force integer constant which is not
             * a power of two to register
             */

            if (opts.compFastCode && op2->gtOper == GT_CNS_INT)
            {
                unsigned    ival = op2->gtIntCon.gtIconVal;

                if (ival > 0 && (long)ival == (long)genFindLowestBit(ival))
                {
                    goto GENERIC_UNARY;
                }
                else
                    op2MustReg = true;
            }
            else
                op2MustReg = (op2->gtOper != GT_LCL_VAR);

            /* are we supposed to evaluate op2 first? */
            if  (tree->gtFlags & GTF_REVERSE_OPS)
            {
                if (op2MustReg)
                    regMask = raPredictComputeReg(op2, RBM_EAX|RBM_EDX, lockedRegs|RBM_EAX|RBM_EDX);
                else
                    regMask = raPredictTreeRegUse(op2, op2MustReg, lockedRegs|RBM_EAX|RBM_EDX);

                regMask = raPredictTreeRegUse(op1, true,
                                                lockedRegs | regMask);
            }
            else
            {
                regMask = raPredictTreeRegUse(op1, true, lockedRegs);
                if (op2MustReg)
                    regMask = raPredictComputeReg(op2, RBM_EAX|RBM_EDX,
                                   lockedRegs | regMask | RBM_EAX|RBM_EDX);
                else
                    regMask = raPredictTreeRegUse(op2, op2MustReg,
                                   lockedRegs | regMask | RBM_EAX|RBM_EDX);
            }

            /* grab EAX, EDX for this tree node */
            regMask |= raPredictGrabReg(TYP_INT, lockedRegs,
                                                 RBM_EAX|RBM_EDX);

            tree->gtUsedRegs = RBM_EAX | RBM_EDX | regMask;

            tree->gtUsedRegs |= op1->gtUsedRegs | op2->gtUsedRegs;

            /* set the held register based on opcode */

            regMask = (oper == GT_DIV || oper == GT_UDIV) ? RBM_EAX : RBM_EDX;

            goto RETURN_CHECK;

        case GT_LSH:
        case GT_RSH:
        case GT_RSZ:
            if (type == TYP_LONG)
            {
                if  (!(op2->gtOper == GT_CNS_INT && op2->gtIntCon.gtIconVal >= 0
                                                 && op2->gtIntCon.gtIconVal <= 32))
                {
                    // count goes to ECX, shiftee to EAX:EDX
                    raPredictTreeRegUse(op1, false, lockedRegs);
                    op1->gtUsedRegs |= RBM_EAX|RBM_EDX;
                    regMask = raPredictGrabReg(TYP_LONG, lockedRegs,
                                        RBM_EAX|RBM_EDX);
                    raPredictTreeRegUse(op2, false, lockedRegs|regMask);
                    tree->gtUsedRegs = op1->gtUsedRegs | op2->gtUsedRegs |
                                regMask | (RBM_EAX|RBM_EDX|RBM_ECX);
                }
                else
                {
                    regMask = raPredictTreeRegUse(op1, true, lockedRegs);
                    // no register used by op2
                    op2->gtUsedRegs = 0;
                    tree->gtUsedRegs = op1->gtUsedRegs;
                }
            }
            else
            {
                regMask = raPredictTreeRegUse(op1, true, lockedRegs);

        HANDLE_SHIFT_COUNT:
                /* this code is also used by assigning shift operators */
                if  (op2->gtOper != GT_CNS_INT)
                {

                    /* evaluate shift count, don't have to force to reg
                     * since we're going to grab ECX
                     */
                    raPredictTreeRegUse(op2, false, lockedRegs | regMask);

                    /* must grab ECX for shift count */
                    tree->gtUsedRegs = op1->gtUsedRegs | op2->gtUsedRegs |
                            raPredictGrabReg(TYP_INT, lockedRegs | regMask,
                                                      RBM_ECX);

                    goto RETURN_CHECK;
                }
                tree->gtUsedRegs = op1->gtUsedRegs;
            }

            goto RETURN_CHECK;

        case GT_COMMA:
            raPredictTreeRegUse(op1, false, lockedRegs);
            regMask = raPredictTreeRegUse(op2, mustReg, lockedRegs);
            tree->gtUsedRegs = op1->gtUsedRegs | op2->gtUsedRegs;
            goto RETURN_CHECK;

#if OPTIMIZE_QMARK
        case GT_QMARK:
            assert(op1 != NULL && op2 != NULL);
            regMask  = raPredictTreeRegUse(op1, false, lockedRegs);

            tree->gtUsedRegs |= regMask;

            assert(op2->gtOper == GT_COLON);
            assert(op2->gtOp.gtOp1 && op2->gtOp.gtOp2);

            regMask  = raPredictTreeRegUse(op2->gtOp.gtOp1, mustReg, lockedRegs);
            regMask |= raPredictTreeRegUse(op2->gtOp.gtOp2, mustReg, lockedRegs);

            op2->gtUsedRegs   = op2->gtOp.gtOp1->gtUsedRegs | op2->gtOp.gtOp2->gtUsedRegs;
            tree->gtUsedRegs |= op1->gtUsedRegs | op2->gtUsedRegs;
            goto RETURN_CHECK;
#endif

        case GT_BB_COLON:
        case GT_RETFILT:
        case GT_RETURN:

            if (op1 != NULL)
            {
                raPredictTreeRegUse(op1, false, lockedRegs);
                regMask = genTypeToReturnReg(type);
                tree->gtUsedRegs = op1->gtUsedRegs | regMask;
                goto RETURN_CHECK;
            }
            tree->gtUsedRegs = regMask = 0;

            goto RETURN_CHECK;

        case GT_JTRUE:

            /* This must be a test of a relational operator */

            assert(op1->OperIsCompare());

            /* Only condition code set by this operation */

            raPredictTreeRegUse(op1, false, lockedRegs);

            tree->gtUsedRegs = op1->gtUsedRegs;
            regMask = 0;

            goto RETURN_CHECK;

        case GT_SWITCH:
            assert(type <= TYP_INT);
            raPredictTreeRegUse(op1, true, lockedRegs);
            tree->gtUsedRegs = op1->gtUsedRegs;
            regMask = 0;
            goto RETURN_CHECK;

        case GT_CKFINITE:
            lockedRegs |= raPredictTreeRegUse(op1, true, lockedRegs);
            raPredictRegPick(TYP_INT, lockedRegs); // Need a reg to load exponent into
            tree->gtUsedRegs = op1->gtUsedRegs;
            regMask = 0;
            goto RETURN_CHECK;

        case GT_LCLHEAP:

            lockedRegs |= raPredictTreeRegUse(op1, false, lockedRegs);

            if (info.compInitMem)
                regMask = raPredictGrabReg(TYP_INT, lockedRegs, RBM_ECX);
            else
                regMask = raPredictRegPick(TYP_I_IMPL, lockedRegs);

            op1->gtUsedRegs |= regMask;
            lockedRegs      |= regMask;

            tree->gtUsedRegs = op1->gtUsedRegs;

            // The result will be put in the reg we picked for the size
            // regMask = <already set as we want it to be>

            goto RETURN_CHECK;

        case GT_INITBLK:
        case GT_COPYBLK:

                /* For INITBLK we have only special treatment for
                   for constant patterns.
                 */

            if ((op2->OperGet() == GT_CNS_INT) &&
                ((oper == GT_INITBLK && (op1->gtOp.gtOp2->OperGet() == GT_CNS_INT)) ||
                 (oper == GT_COPYBLK && (op2->gtFlags & GTF_ICON_HDL_MASK) != GTF_ICON_CLASS_HDL)))
            {
                unsigned length = (unsigned) op2->gtIntCon.gtIconVal;

                if (length <= 16)
                {
                    unsigned op2Reg = ((oper == GT_INITBLK)? RBM_EAX : RBM_ESI);

                    if (op1->gtFlags & GTF_REVERSE_OPS)
                    {
                        regMask |= raPredictTreeRegUse(op1->gtOp.gtOp2,
                                                       false,         lockedRegs);
                        regMask |= raPredictGrabReg(TYP_INT, regMask|lockedRegs, op2Reg);
                        op1->gtOp.gtOp2->gtUsedRegs |= op2Reg;

                        regMask |= raPredictTreeRegUse(op1->gtOp.gtOp1,
                                                       false, regMask|lockedRegs);
                        regMask |= raPredictGrabReg(TYP_INT, regMask|lockedRegs, RBM_EDI);
                        op1->gtOp.gtOp1->gtUsedRegs |= RBM_EDI;
                    }
                    else
                    {
                        regMask |= raPredictTreeRegUse(op1->gtOp.gtOp1,
                                                       false,         lockedRegs);
                        regMask |= raPredictGrabReg(TYP_INT, regMask|lockedRegs, RBM_EDI);
                        op1->gtOp.gtOp1->gtUsedRegs |= RBM_EDI;

                        regMask |= raPredictTreeRegUse(op1->gtOp.gtOp2,
                                                       false, regMask|lockedRegs);
                        regMask |= raPredictGrabReg(TYP_INT, regMask|lockedRegs, op2Reg);
                        op1->gtOp.gtOp2->gtUsedRegs |= op2Reg;
                    }

                    tree->gtUsedRegs = op1->gtOp.gtOp1->gtUsedRegs |
                                       op1->gtOp.gtOp2->gtUsedRegs |
                                       regMask;

                    regMask = 0;

                    goto RETURN_CHECK;
                }
            }
            // What order should the Dest, Val/Src, and Size be calculated

            fgOrderBlockOps(tree,
                    RBM_EDI, (oper == GT_INITBLK) ? RBM_EAX : RBM_ESI, RBM_ECX,
                    opsPtr, regsPtr);

            regMask |= raPredictTreeRegUse(opsPtr[0], false,         lockedRegs);
            regMask |= raPredictGrabReg(TYP_INT, regMask|lockedRegs, regsPtr[0]); // TYP_PTR
            opsPtr[0]->gtUsedRegs |= regsPtr[0];

            regMask |= raPredictTreeRegUse(opsPtr[1], false, regMask|lockedRegs);
            regMask |= raPredictGrabReg(TYP_INT, regMask|lockedRegs, regsPtr[1]);
            opsPtr[1]->gtUsedRegs |= regsPtr[1];

            regMask |= raPredictTreeRegUse(opsPtr[2], false, regMask|lockedRegs);
            regMask |= raPredictGrabReg(TYP_INT, regMask|lockedRegs, regsPtr[2]);
            opsPtr[2]->gtUsedRegs |= regsPtr[2];

            tree->gtUsedRegs =  opsPtr[0]->gtUsedRegs | opsPtr[1]->gtUsedRegs |
                                opsPtr[2]->gtUsedRegs | regMask;
            regMask = 0;

            goto RETURN_CHECK;


        case GT_VIRT_FTN:

            if ((tree->gtFlags & GTF_CALL_INTF) && !getNewCallInterface())
            {
                regMask  = raPredictTreeRegUse(op1, false, lockedRegs);
                regMask |= raPredictGrabReg(TYP_REF,    regMask|lockedRegs, RBM_ECX);
                regMask |= raPredictGrabReg(TYP_I_IMPL, regMask|lockedRegs, RBM_EAX);

                tree->gtUsedRegs = regMask;
                regMask = RBM_EAX;
            }
            else
            {
                regMask = raPredictTreeRegUse(op1, true, lockedRegs);
                tree->gtUsedRegs = regMask;
            }
            goto RETURN_CHECK;

        default:
#ifdef  DEBUG
            gtDispTree(tree);
#endif
            assert(!"unexpected simple operator in reg use prediction");
            break;
        }
    }

    /* See what kind of a special operator we have here */

    switch  (oper)
    {
        GenTreePtr      args;
        GenTreePtr      list;
#if USE_FASTCALL
        unsigned        regArgsNum;
        unsigned        i, tmpIdx, tmpNum;
        unsigned        regArgCnt;
        unsigned        regArgMask;

        struct tag_regArgTab
        {
            GenTreePtr  node;
            regNumber   regNum;
        } regArgTab[MAX_REG_ARG];
#endif

    case GT_MKREFANY:
    case GT_LDOBJ:
        raPredictTreeRegUse(tree->gtLdObj.gtOp1, true, lockedRegs);
        tree->gtUsedRegs = tree->gtLdObj.gtOp1->gtUsedRegs;
        regMask = 0;
        goto RETURN_CHECK;

    case GT_JMP:
        regMask = 0;
        goto RETURN_CHECK;

    case GT_JMPI:
        /* We need EAX to evaluate the function pointer */
        regMask = raPredictGrabReg(TYP_REF, lockedRegs, RBM_EAX);
        goto RETURN_CHECK;

    case GT_CALL:

        /* initialize so we can just or in various bits */
        tree->gtUsedRegs = 0;

#if USE_FASTCALL

        regArgsNum = 0;
        regArgCnt  = 0;

        /* Construct the "shuffled" argument table */

        /* UNDONE: We need to use this extra shift mask becuase of a VC bug
         * that doesn't perform the shift - at cleanup get rid of the
         * mask and pass the registers in the list nodes */

        unsigned short shiftMask;
        shiftMask = tree->gtCall.regArgEncode;

        for (list = tree->gtCall.gtCallRegArgs, regArgCnt = 0; list; regArgCnt++)
        {
            args = list;
            if  (args->gtOper == GT_LIST)
            {
                args = list->gtOp.gtOp1;
                list = list->gtOp.gtOp2;
            }
            else
            {
                list = 0;
            }

            regArgTab[regArgCnt].node   = args;
            regArgTab[regArgCnt].regNum =
                //(regNumber) ((tree->gtCall.regArgEncode >> (4*regArgCnt)) & 0x000F);
                (regNumber) (shiftMask & 0x000F);

            shiftMask >>= 4;

            //printf("regArgTab[%d].regNum = %2u\n", regArgCnt, regArgTab[regArgCnt].regNum);
            //printf("regArgTab[%d].regNum = %2u\n", regArgCnt, tree->gtCall.regArgEncode >> (4*regArgCnt));
        }

        /* Is there an object pointer? */
        if  (tree->gtCall.gtCallObjp)
        {
            /* the objPtr always goes to a register (through temp or directly) */
            assert(regArgsNum == 0);
            regArgsNum++;
        }
#endif

#if 1 //ndef IL
        /* Is there an object pointer? */
        if  (tree->gtCall.gtCallObjp)
        {
            args = tree->gtCall.gtCallObjp;
            raPredictTreeRegUse(args, false, lockedRegs);
            tree->gtUsedRegs |= args->gtUsedRegs;

#if USE_FASTCALL
            /* Must be passed in a register */

            assert(args->gtFlags & GTF_REG_ARG);
            assert(gtIsaNothingNode(args) || (args->gtOper == GT_ASG));

            /* If a temp make sure it interferes with
             * already used argument registers */

            if (args->gtOper == GT_ASG)
            {
                assert(args->gtOp.gtOp1->gtOper == GT_LCL_VAR);
                assert(regArgCnt > 0);

                /* Find the shuffled position of the temp */

                tmpNum = args->gtOp.gtOp1->gtLclVar.gtLclNum;

                for(tmpIdx = 0; tmpIdx < regArgCnt; tmpIdx++)
                {
                    if ((regArgTab[tmpIdx].node->gtOper == GT_LCL_VAR)        &&
                        (regArgTab[tmpIdx].node->gtLclVar.gtLclNum == tmpNum)  )
                    {
                        /* this is the shuffled position of the argument */
                        break;
                    }
                }

                if  (tmpIdx < regArgCnt)
                {
                    /* this temp is a register argument - it must not end up in argument registers
                     * that will be needed before the temp is consumed
                     * UNDONE: DFA should also remove dead assigmnets part of GT_COMMA or subtrees */

                    for(i = 0; i < tmpIdx; i++)
                        args->gtOp.gtOp1->gtUsedRegs |= genRegMask(regArgTab[i].regNum);
                }
                else
                {
                    /* This temp is not an argument register anymore
                     * A copy propagation must have taken place */
                    assert(optCopyPropagated);
                }
            }
#endif
        }
#endif

        /* process argument list */
        for (list = tree->gtCall.gtCallArgs; list; )
        {
            args = list;
            if  (args->gtOper == GT_LIST)
            {
                args = list->gtOp.gtOp1;
                list = list->gtOp.gtOp2;
            }
            else
            {
                list = 0;
            }
            raPredictTreeRegUse(args, false, lockedRegs);

#if USE_FASTCALL
            if (args->gtFlags & GTF_REG_ARG)
            {
                assert(gtIsaNothingNode(args) || (args->gtOper == GT_ASG));
                assert(regArgsNum < MAX_REG_ARG);

                if (args->gtOper == GT_ASG)
                {
                    assert (args->gtOp.gtOp1->gtOper == GT_LCL_VAR);
                    assert (regArgCnt > 0);

                    /* Find the shuffled position of the temp */

                    tmpNum = args->gtOp.gtOp1->gtLclVar.gtLclNum;

                    for(tmpIdx = 0; tmpIdx < regArgCnt; tmpIdx++)
                    {
                        if ((regArgTab[tmpIdx].node->gtOper == GT_LCL_VAR)        &&
                            (regArgTab[tmpIdx].node->gtLclVar.gtLclNum == tmpNum)  )
                        {
                            /* this is the shuffled position of the argument */
                            break;
                        }
                    }

                    if  (tmpIdx < regArgCnt)
                    {
                        /* this temp is a register argument - it must not end up in argument registers
                         * that will be needed before the temp is consumed */

                        for(i = 0; i < tmpIdx; i++)
                            args->gtOp.gtOp1->gtUsedRegs |= genRegMask(regArgTab[i].regNum);
                    }
                    else
                    {
                        /* This temp is not an argument register anymore
                         * A copy propagation must have taken place */
                        assert(optCopyPropagated);
                    }
                }

                regArgsNum++;
            }
#endif

            tree->gtUsedRegs |= args->gtUsedRegs;
        }

#if USE_FASTCALL
        /* Is there a register argument list */

        assert (regArgsNum <= MAX_REG_ARG);
        assert (regArgsNum == regArgCnt);

        for (i = 0, regArgMask = 0; i < regArgsNum; i++)
        {
            args = regArgTab[i].node;

            raPredictTreeRegUse(args, false, lockedRegs | regArgMask);
            regArgMask       |= genRegMask(regArgTab[i].regNum);
            args->gtUsedRegs |= raPredictGrabReg(genActualType(args->gtType),
                                                 lockedRegs,
                                                 genRegMask(regArgTab[i].regNum));

            tree->gtUsedRegs |= args->gtUsedRegs;
            tree->gtCall.gtCallRegArgs->gtUsedRegs |= args->gtUsedRegs;
        }

        /* OBSERVATION:
         * With the new argument shuffling the stuff below shouldn't be necessary
         * but I didn't tested it yet*/

        /* At this point we have to go back and for all temps (place holders
         * for register vars) we have to make sure they do not get enregistered
         * in something thrashed before we make the call (worst case - nested calls)
         * For example if the two register args are a "temp" and a "call" then the
         * temp must not be assigned to EDX, which is thrashed by the call */

        /* process object pointer */
        if  (tree->gtCall.gtCallObjp)
        {
            args = tree->gtCall.gtCallObjp;
            assert(args->gtFlags & GTF_REG_ARG);

            if (args->gtOper == GT_ASG)
            {
                /* here we have a temp */
                assert (args->gtOp.gtOp1->gtOper == GT_LCL_VAR);
                args->gtOp.gtOp1->gtUsedRegs |= tree->gtCall.gtCallRegArgs->gtUsedRegs;
            }
        }

        /* process argument list */
        for (list = tree->gtCall.gtCallArgs; list; )
        {
            args = list;
            if  (args->gtOper == GT_LIST)
            {
                args = list->gtOp.gtOp1;
                list = list->gtOp.gtOp2;
            }
            else
            {
                list = 0;
            }

            if (args->gtFlags & GTF_REG_ARG)
            {
                assert (gtIsaNothingNode(args) || (args->gtOper == GT_ASG));

                /* If a temp add the registers used by arguments */

                if (args->gtOper == GT_ASG)
                {
                    assert (args->gtOp.gtOp1->gtOper == GT_LCL_VAR);
                    args->gtOp.gtOp1->gtUsedRegs |= tree->gtCall.gtCallRegArgs->gtUsedRegs;
                }
            }
        }
#endif  // USE_FASTCALL

#if 0 //def IL
        /* Is there an object pointer? */
        if  (tree->gtCall.gtCallObjp)
        {
            args = tree->gtCall.gtCallObjp;
            raPredictTreeRegUse(args, false, lockedRegs);
            tree->gtUsedRegs |= args->gtUsedRegs;
#if USE_FASTCALL
            /* Must be passed in a register - by definition in IL
             * the objPtr is the last "argument" passed and thus
             * doesn't need a temp */

            assert(args->gtFlags & GTF_REG_ARG);
            assert(gtIsaNothingNode(args));
#endif
        }
#endif

        if (tree->gtCall.gtCallType == CT_INDIRECT)
        {
            args = tree->gtCall.gtCallAddr;
#if USE_FASTCALL
            /* Do not use the argument registers */
            tree->gtUsedRegs |= raPredictTreeRegUse(args, true, lockedRegs | regArgMask);
#else
            tree->gtUsedRegs |= raPredictTreeRegUse(args, true, lockedRegs);
#endif
        }

        /* set the return register */
        regMask = genTypeToReturnReg(type);

        /* must grab this register (ie force extra alloc for spill) */
        if (regMask != 0)
            regMask = raPredictGrabReg(type, lockedRegs, regMask);

        /* or in registers killed by the call */
#if GTF_CALL_REGSAVE
        if  (call->gtFlags & GTF_CALL_REGSAVE)
        {
            /* only return registers (if any) are killed */

            tree->gtUsedRegs |= regMask;
        }
        else
#endif
        {
            tree->gtUsedRegs |= (RBM_CALLEE_TRASH | regMask);
        }

        /* virtual function call uses a register */

        if  ((tree->gtFlags & GTF_CALL_VIRT) ||
                    ((tree->gtFlags & GTF_CALL_VIRT_RES) && tree->gtCall.gtCallVptr))
        {
            GenTreePtr      vptrVal;

            /* Load the vtable address goes to a register */

            vptrVal = tree->gtCall.gtCallVptr;

#if USE_FASTCALL
            /* Do not use the argument registers */
            tree->gtUsedRegs |= raPredictTreeRegUse(vptrVal, true, lockedRegs | regArgMask);
#else
            tree->gtUsedRegs |= raPredictTreeRegUse(vptrVal, true, lockedRegs);
#endif
        }

        goto RETURN_CHECK;

#if CSELENGTH

    case GT_ARR_RNGCHK:
        if  (tree->gtFlags & GTF_ALN_CSEVAL)
        {
            GenTreePtr      addr = tree->gtArrLen.gtArrLenAdr;

            /* check for address mode */
            regMask = raPredictAddressMode(addr, lockedRegs);

            /* forcing to register? */
            if (mustReg)
                regMask = raPredictRegPick(TYP_INT, lockedRegs);

            tree->gtUsedRegs = regMask;
        }
        break;

#endif

    default:
        assert(!"unexpected special operator in reg use prediction");

        break;
    }

RETURN_CHECK:

//  tree->gtUsedRegs & ~(RBM_ESI|RBM_EDI);      // HACK!!!!!

#ifndef NDEBUG
    /* make sure we set them to something reasonable */
    if (tree->gtUsedRegs & RBM_STK)
        assert(!"used regs not set in reg use prediction");
    if (regMask & RBM_STK)
        assert(!"return value not set in reg use prediction");
#endif

    tree->gtUsedRegs |= lockedRegs;

    //printf("Used regs for [%0x] = [%0x]\n", tree, tree->gtUsedRegs);

    return regMask;
}

/*****************************************************************************/
#else //TGT_x86
/*****************************************************************************
 *
 *  Predict the temporary register needs of a list of expressions (typically,
 *  an argument list).
 */

unsigned            Compiler::raPredictListRegUse(GenTreePtr list)
{
    unsigned        count = 0;

    do
    {
        assert(list && list->gtOper == GT_LIST);

        count = max(count, raPredictTreeRegUse(list->gtOp.gtOp1));

        list  = list->gtOp.gtOp2;
    }
    while (list);

    return  count;
}

/*****************************************************************************
 *
 *  Predict the temporary register needs (and insert any temp spills) for
 *  the given tree. Returns the number of temps needed by the subtree.
 */

unsigned            Compiler::raPredictTreeRegUse(GenTreePtr tree)
{
    genTreeOps      oper;
    unsigned        kind;

    unsigned        op1cnt;
    unsigned        op2cnt;

    unsigned        valcnt;
    unsigned        regcnt;

    assert(tree);
    assert(tree->gtOper != GT_STMT);

    /* Assume we'll need just the register(s) to hold the value */

    valcnt = regcnt = genTypeRegs(tree->TypeGet());

    /* Figure out what kind of a node we have */

    oper = tree->OperGet();
    kind = tree->OperKind();

    /* Is this a constant or leaf node? */

    if  (kind & (GTK_CONST|GTK_LEAF))
    {
        goto DONE;
    }

    /* Is it a 'simple' unary/binary operator? */

    if  (kind & GTK_SMPOP)
    {
        GenTreePtr      op1 = tree->gtOp.gtOp1;
        GenTreePtr      op2 = tree->gtOp.gtOp2;

        /* Check for a nilary operator */

        if  (!op1)
        {
            assert(op2 == 0);
            goto DONE;
        }

        /* Is this a unary operator? */

        if  (!op2)
        {
            /* Process the operand of the operator */

        UNOP:

            op1cnt = raPredictTreeRegUse(op1);

            /* Special handling for some operators */

            switch (oper)
            {
            case GT_NOP:

                /* Special case: array range check */

                if  (tree->gtFlags & GTF_NOP_RNGCHK)
                {
                    assert(!"what temps are needed for a range check?");
                }

                break;

            case GT_CAST:

                /* The second operand isn't "for real" */

                op2->gtTempRegs = 0;

                // ISSUE: Do we need anything special here?
                break;

            case GT_IND:

                /* Are we loading a value into 2 registers? */

                if  (valcnt > 1)
                {
                    assert(valcnt == 2);
                    assert(op1cnt <= 2);

                    /* Note that the address needs "op1cnt" registers */

                    if  (op1cnt != 1)
                    {
                        /* The address must not fully overlap */

                        regcnt = valcnt + 1;
                    }
                }

#if     CSELENGTH

                if  (tree->gtInd.gtIndLen && (tree->gtFlags & GTF_IND_RNGCHK))
                {
                    GenTreePtr      len = tree->gtInd.gtIndLen;

                    /* Make sure the array length gets costed */

                    assert(len->gtOper == GT_ARR_RNGCHK);

                    assert(!"what (if any) temps are needed for an array length?");
                }
#endif

#if     TGT_SH3

#if 0

                /* Is this an indirection with an index address? */

                if  (op1->gtOper == GT_ADD)
                {
                    bool            rev;
#if SCALED_ADDR_MODES
                    unsigned        mul;
#endif
                    unsigned        cns;
                    GenTreePtr      adr;
                    GenTreePtr      idx;

                    if  (genCreateAddrMode(op1,             // address
                                           0,               // mode
                                           false,           // fold
                                           0,               // reg mask
#if!LEA_AVAILABLE
                                           tree->TypeGet(), // operand type
#endif
                                           &rev,            // reverse ops
                                           &adr,            // base addr
                                           &idx,            // index val
#if SCALED_ADDR_MODES
                                           &mul,            // scaling
#endif
                                           &cns,            // displacement
                                           true))           // don't generate code
                    {
                        if  (adr && idx)
                        {
                            /* The address is "[adr+idx]" */

                            ??? |= RBM_r00;
                        }
                    }
                }

#else
#pragma message("Interference marking of SH3/R0 suppressed")
#endif

#endif

                break;
            }

            /* Use the default temp number count for a unary operator */

            regcnt = max(regcnt, op1cnt);
            goto DONE;
        }

        /* Binary operator - check for certain special cases */

        switch (oper)
        {
        case GT_COMMA:

            /* Comma tosses the result of the left operand */

            op1cnt =             raPredictTreeRegUse(op1);
            regcnt = max(op1cnt, raPredictTreeRegUse(op2));

            goto DONE;

        case GT_IND:
        case GT_CAST:

            /* The second operand of an indirection/cast is just a fake */

            goto UNOP;
        }

        /* Process the sub-operands in the proper order */

        if  (tree->gtFlags & GTF_REVERSE_OPS)
        {
            op1 = tree->gtOp.gtOp1;
            op2 = tree->gtOp.gtOp2;
        }

        regcnt =
        op1cnt = raPredictTreeRegUse(op1);
        op2cnt = raPredictTreeRegUse(op2);

        if      (op1cnt <  op2cnt)
        {
            regcnt  = op2cnt;
        }
        else if (op1cnt == op2cnt)
        {
            regcnt += valcnt;
        }

        /* Check for any 'interesting' cases */

//      switch (oper)
//      {
//      }

        goto DONE;
    }

    /* See what kind of a special operator we have here */

    switch  (oper)
    {
    case GT_MKREFANY:
    case GT_LDOBJ:
        UNIMPL(!"predict ldobj/mkrefany");
//      op1cnt = raPredictTreeRegUse(op1);
//      regcnt = max(regcnt, op1cnt);
        goto DONE;

    case GT_FIELD:
        assert(!"can this ever happen?");
        assert(tree->gtField.gtFldObj == 0);
        break;

    case GT_CALL:

        assert(tree->gtFlags & GTF_CALL);

        /* Process the 'this' argument, if present */

        if  (tree->gtCall.gtCallObjp)
        {
            op1cnt = raPredictTreeRegUse(tree->gtCall.gtCallObjp);
            regcnt = max(regcnt, op1cnt);
        }

        /* Process the argument list */

        if  (tree->gtCall.gtCallArgs)
        {
            op1cnt = raPredictListRegUse(tree->gtCall.gtCallArgs);
            regcnt = max(regcnt, op1cnt);
        }

#if USE_FASTCALL

        /* Process the temp register arguments list */

        if  (tree->gtCall.gtCallRegArgs)
        {
            op1cnt = raPredictListRegUse(tree->gtCall.gtCallRegArgs);
            regcnt = max(regcnt, op1cnt);
        }

#endif

        /* Process the vtable pointer, if present */

        if  (tree->gtCall.gtCallVptr)
        {
            op1cnt = raPredictTreeRegUse(tree->gtCall.gtCallVptr);
            regcnt = max(regcnt, op1cnt);
        }

        /* Process the function address, if present */

        if  (tree->gtCall.gtCallType == CT_INDIRECT)
        {
            op1cnt = raPredictTreeRegUse(tree->gtCall.gtCallAddr);
            regcnt = max(regcnt, op1cnt);
        }

        break;

#if CSELENGTH

    case GT_ARR_RNGCHK:
        assert(!"range checks NYI for RISC");
        break;

#endif


    default:
#ifdef  DEBUG
        gtDispTree(tree);
#endif
        assert(!"unexpected operator");
    }

DONE:

//  printf("[tempcnt=%u]: ", regcnt); gtDispTree(tree, 0, true);

    tree->gtTempRegs = regcnt;

    return  regcnt;
}

/*****************************************************************************/
#endif//TGT_x86
/*****************************************************************************
 *
 *  Predict register use for every tree in the function. Note that we do this
 *  at different times (not to mention in a totally different way) for x86 vs
 *  RISC targets.
 */

void                Compiler::raPredictRegUse()
{
    BasicBlock *    block;

#if TGT_x86

    /* TODO: !!! We need to keep track of the number of temp-refs */
    /* right now we just clear this variable, and hence don't count
     * any codegen-created temps as frame references in our calculation
     * of whether it's worth it to use EBP as a register variable
     */

    genTmpAccessCnt = 0;

    /* Walk the basic blocks and predict reg use for each tree */

    for (block = fgFirstBB;
         block;
         block = block->bbNext)
    {
        GenTreePtr      tree;

        for (tree = block->bbTreeList; tree; tree = tree->gtNext)
            raPredictTreeRegUse(tree->gtStmt.gtStmtExpr, true, 0);
    }

#else

    /* Walk the basic blocks and predict reg use for each tree */

    for (block = fgFirstBB;
         block;
         block = block->bbNext)
    {
        GenTreePtr      tree;

        for (tree = block->bbTreeList; tree; tree = tree->gtNext)
            raPredictTreeRegUse(tree->gtStmt.gtStmtExpr);
    }

#endif

}

/****************************************************************************/

#ifdef  DEBUG

static
void                dispLifeSet(Compiler *comp, VARSET_TP mask, VARSET_TP life)
{
    unsigned                lclNum;
    Compiler::LclVarDsc *   varDsc;

    for (lclNum = 0, varDsc = comp->lvaTable;
         lclNum < comp->lvaCount;
         lclNum++  , varDsc++)
    {
        VARSET_TP       vbit;

        if  (!varDsc->lvTracked)
            continue;

        vbit = genVarIndexToBit(varDsc->lvVarIndex);

        if  (!(vbit & mask))
            continue;

        if  (life & vbit)
            printf("%2d ", lclNum);
    }
}

#endif

/*****************************************************************************/
#ifdef  DEBUG
/*****************************************************************************
 *
 *  Debugging helpers - display variables liveness info.
 */

void                dispFPvarsInBBlist(BasicBlock * beg,
                                       BasicBlock * end,
                                       VARSET_TP    mask,
                                       Compiler   * comp)
{
    do
    {
        printf("Block #%2u: ", beg->bbNum);

        printf(" in  = [ ");
        dispLifeSet(comp, mask, beg->bbLiveIn );
        printf("] ,");

        printf(" out = [ ");
        dispLifeSet(comp, mask, beg->bbLiveOut);
        printf("]");

        if  (beg->bbFlags & BBF_VISITED)
            printf(" inner=%u", beg->bbStkDepth);

        printf("\n");

        beg = beg->bbNext;
        if  (!beg)
            return;
    }
    while (beg != end);
}

void                Compiler::raDispFPlifeInfo()
{
    BasicBlock  *   block;

    for (block = fgFirstBB;
         block;
         block = block->bbNext)
    {
        GenTreePtr      stmt;

        printf("BB %u: in  = [ ", block->bbNum);
        dispLifeSet(this, optAllFloatVars, block->bbLiveIn);
        printf("]\n\n");

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            GenTreePtr      tree;

            assert(stmt->gtOper == GT_STMT);

            for (tree = stmt->gtStmt.gtStmtList;
                 tree;
                 tree = tree->gtNext)
            {
                VARSET_TP       life = tree->gtLiveSet;

                dispLifeSet(this, optAllFloatVars, life);
                printf("   ");
                gtDispTree(tree, NULL, true);
            }

            printf("\n");
        }

        printf("BB %u: out = [ ", block->bbNum);
        dispLifeSet(this, optAllFloatVars, block->bbLiveOut);
        printf("]\n\n");
    }
}

/*****************************************************************************/
#endif//DEBUG
/*****************************************************************************/
#if     TGT_x86
/*****************************************************************************
 *
 *  Upon a transfer of control from 'srcBlk' to '*dstPtr', the given FP
 *  register variable dies. We need to arrange for its value to be popped
 *  from the FP stack when we land on the destination block.
 */

void                Compiler::raInsertFPregVarPop(BasicBlock *  srcBlk,
                                                  BasicBlock * *dstPtr,
                                                  unsigned      varNum)
{
    BasicBlock  *   dstBlk = *dstPtr;

    LclVarDsc   *   varDsc;
    VARSET_TP       varBit;

    VARSET_TP       newLife;

    flowList    *   predList;

    GenTreePtr      rvar;
    GenTreePtr      kill;
    GenTreePtr      stmt;

    bool            addb;

    /* Get hold of the variable's lifeset bit */

    assert(varNum < lvaCount);
    varDsc = lvaTable + varNum;
    assert(varDsc->lvTracked);
    varBit = genVarIndexToBit(varDsc->lvVarIndex);

    /*
        Check all predecessors of the target block; if all of them jump
        to the block with our variable live, we can simply prepend the
        killing statement to the target block since all the paths to
        the block need to kill our variable. If there is at least one
        path where death doesn't occur we'll have to insert a killing
        basic block into those paths that need the death.
     */

#ifdef DEBUG
    fgDebugCheckBBlist();
#endif

    addb = false;

    for (predList = dstBlk->bbPreds; predList; predList = predList->flNext)
    {
        BasicBlock  *   pred = predList->flBlock;

        if  (!(pred->bbLiveOut & varBit))
        {
            /* No death along this particular edge, we'll have to add a block */

            addb = true;
        }
    }

    /* Do we need to add a "killing block" ? */

    if  (addb)
    {
        BasicBlock  *   tmpBlk;

        bool            addBlk = true;

        /* Allocate a new basic block */

        tmpBlk = bbNewBasicBlock(BBJ_NONE);
        tmpBlk->bbFlags   |= BBF_INTERNAL;

        tmpBlk->bbTreeList = 0;

        tmpBlk->bbLiveIn   = dstBlk->bbLiveIn | varBit; //srcBlk->bbLiveOut;
        tmpBlk->bbLiveOut  = dstBlk->bbLiveIn;

        tmpBlk->bbVarUse   = dstBlk->bbVarUse | varBit;
        tmpBlk->bbVarDef   = dstBlk->bbVarDef;
        tmpBlk->bbVarTmp   = dstBlk->bbVarTmp;

#ifdef  DEBUG
        if  (verbose) printf("Added FP regvar killing basic block for variable %u [bit=%08X]\n", varNum, varBit);
#endif

        for (predList = dstBlk->bbPreds; predList; predList = predList->flNext)
        {
            BasicBlock  *   pred = predList->flBlock;

#ifdef  DEBUG

            if  (verbose)
            {
                printf("BB %u: out = %08X [ ",   pred->bbNum,   pred->bbLiveOut);
                dispLifeSet(this, optAllFloatVars,   pred->bbLiveOut);
                printf("]\n");

                printf("BB %u: in  = %08X [ ", dstBlk->bbNum, dstBlk->bbLiveIn );
                dispLifeSet(this, optAllFloatVars, dstBlk->bbLiveIn );
                printf("]\n\n");
            }

#endif

            /* Ignore this block if it doesn't need the kill */

            if  (!(pred->bbLiveOut & varBit))
                continue;

            /* Is this a convenient place to place the kill block? */

            if  (pred->bbNext == dstBlk)
            {
                /* Insert the kill block right after this predecessor */

                  pred->bbNext = tmpBlk;
                tmpBlk->bbNext = dstBlk;

                /* Remember that we've already inserted the target block */

                addBlk = false;
            }
            else
            {
                /* Need to update the link to point to the new block */

                switch (pred->bbJumpKind)
                {
                    BasicBlock * *  jmpTab;
                    unsigned        jmpCnt;

                case BBJ_COND:

                    if  (pred->bbJumpDest == dstBlk)
                         pred->bbJumpDest =  tmpBlk;

                    // Fall through ...

                case BBJ_NONE:

                    if  (pred->bbNext     == dstBlk)
                         pred->bbNext     =  tmpBlk;

                    break;

                case BBJ_ALWAYS:

                    if  (pred->bbJumpDest == dstBlk)
                         pred->bbJumpDest =  tmpBlk;

                    break;

                case BBJ_SWITCH:

                    jmpCnt = pred->bbJumpSwt->bbsCount;
                    jmpTab = pred->bbJumpSwt->bbsDstTab;

                    do
                    {
                        if  (*jmpTab == dstBlk)
                             *jmpTab =  tmpBlk;
                    }
                    while (++jmpTab, --jmpCnt);

                    break;

                default:
                    assert(!"unexpected jump kind");
                }
            }
        }

        if  (addBlk)
        {
            /* Append the kill block at the end of the method */

            fgLastBB->bbNext = tmpBlk;
            fgLastBB         = tmpBlk;

            /* We have to jump from the kill block to the target block */

            tmpBlk->bbJumpKind = BBJ_ALWAYS;
            tmpBlk->bbJumpDest = dstBlk;
        }

        /* Update the predecessor lists and the like */

        fgAssignBBnums(true, true, true, false);

#ifdef DEBUG
        if (verbose)
            fgDispBasicBlocks();
        fgDebugCheckBBlist();
#endif

        /* We have a new destination block */

        *dstPtr = dstBlk = tmpBlk;
    }

    /*
        At this point we know that all paths to 'dstBlk' involve the death
        of our variable. Create the expression that will kill it.
     */

    rvar = gtNewOperNode(GT_REG_VAR, TYP_DOUBLE);
    rvar->gtRegNum             =
    rvar->gtRegVar.gtRegNum    = (regNumbers)0;
    rvar->gtRegVar.gtRegVar    = varNum;
    rvar->gtFlags             |= GTF_REG_DEATH;

    kill = gtNewOperNode(GT_NOP, TYP_DOUBLE, rvar);
    kill->gtFlags |= GTF_NOP_DEATH;

    /* Create a statement entry out of the nop/kill expression */

    stmt = gtNewStmt(kill); stmt->gtFlags |= GTF_STMT_CMPADD;

    /* Create the linked list of tree nodes for the statement */

    stmt->gtStmt.gtStmtList     = rvar;
    stmt->gtStmtFPrvcOut = genCountBits(dstBlk->bbLiveIn & optAllFPregVars);

    rvar->gtPrev                = 0;
    rvar->gtNext                = kill;

    kill->gtPrev                = rvar;
    kill->gtNext                = 0;

    /*
        If any nested FP register variables are killed on entry to this block,
        we need to insert the new kill node after the ones for the inner vars.
     */

    if  (dstBlk->bbStkDepth)
    {
        GenTreePtr      next;
        GenTreePtr      list = dstBlk->bbTreeList;
        unsigned        kcnt = dstBlk->bbStkDepth;

        /* Update the number of live FP regvars after our statement */

        stmt->gtStmtFPrvcOut -= kcnt;

        /* Skip over any "inner" kill statements */

        for (;;)
        {
            assert(list);
            assert(list->gtOper == GT_STMT);
            assert(list->gtFlags & GTF_STMT_CMPADD);
            assert(list->gtStmt.gtStmtExpr->gtOper == GT_NOP);
            assert(list->gtStmt.gtStmtExpr->gtOp.gtOp1->gtOper == GT_REG_VAR);
            assert(list->gtStmt.gtStmtExpr->gtOp.gtOp1->gtFlags & GTF_REG_DEATH);

            /* Remember the liveness at the preceding statement */

            newLife = list->gtStmt.gtStmtExpr->gtLiveSet;

            /* Our variable is still live at this (innner) kill block */

            //list                               ->gtLiveSet |= varBit;
            list->gtStmt.gtStmtExpr            ->gtLiveSet |= varBit;
            list->gtStmt.gtStmtExpr->gtOp.gtOp1->gtLiveSet |= varBit;

            /* Have we skipped enough kill statements? */

            if  (--kcnt == 0)
                break;

            /* Get the next kill and continue */

            list = list->gtNext;
        }

        /* Insert the new statement into the list */

        next = list->gtNext; assert(next && next->gtPrev == list);

        list->gtNext = stmt;
        stmt->gtPrev = list;
        stmt->gtNext = next;
        next->gtPrev = stmt;
    }
    else
    {
        /* Append the kill statement at the beginning of the target block */

        fgInsertStmtAtBeg(dstBlk, stmt);

        /* Use the liveness on entry to the block */

        newLife = dstBlk->bbLiveIn;
    }

    /* Set the appropriate liveness values */

    rvar->gtLiveSet =
    kill->gtLiveSet = newLife & ~varBit;

    /* Now our variable is live on entry to the target block */

    dstBlk->bbLiveIn  |= varBit;
    dstBlk->bbVarDef  |= varBit;

#ifndef NOT_JITC
//  fgDispBasicBlocks(false);
//  raDispFPlifeInfo();
//  dispFPvarsInBBlist(fgFirstBB, NULL, optAllFloatVars, this);
#endif

}

/*****************************************************************************
 *
 *  While looking for FP variables to be enregistered, we've reached the end
 *  of a basic block which has a control path to the given target block.
 *
 *  Returns true if there is an unresolvable conflict, false upon success.
 */

bool                Compiler::raMarkFPblock(BasicBlock *srcBlk,
                                            BasicBlock *dstBlk,
                                            unsigned    icnt,
                                            VARSET_TP   life,
                                            VARSET_TP   lifeOuter,
                                            VARSET_TP   varBit,
                                            VARSET_TP   intVars,
                                            bool    *    deathPtr,
                                            bool    *   repeatPtr)
{
    *deathPtr = false;

#if 0

    if  ((int)varBit == 1 && dstBlk->bbNum == 4 )
    {
        printf("Var[%08X]: %2u->%2u icnt=%u,life=%08X,outer=%08X,dstOuter=%08X\n",
                (int)varBit, srcBlk->bbNum, dstBlk->bbNum,
                icnt, (int)life, (int)lifeOuter, (int)dstBlk->bbVarTmp);
    }

#endif

//  if  ((int)varBit == 0x10 && dstBlk->bbNum == 42) debugStop(0);

    /* Has we seen this block already? */

    if  (dstBlk->bbFlags & BBF_VISITED)
    {
        /* Our variable may die, but otherwise the life set must match */

        if  (lifeOuter == dstBlk->bbVarTmp)
        {
            if  (life ==  dstBlk->bbVarDef)
            {
                /* The "inner" count better match */

                assert(icnt == dstBlk->bbStkDepth);

                return  false;
            }

            if  (life == (dstBlk->bbVarDef|varBit))
            {
                *deathPtr = true;
                return  false;
            }
        }

#ifdef  DEBUG

        if  (verbose)
        {
            printf("Incompatible edge from block %2u to %2u: ",
                   srcBlk->bbNum, dstBlk->bbNum);

            VARSET_TP diffLife = lifeOuter ^ dstBlk->bbVarTmp;
            if (!diffLife)
            {
                diffLife = lifeOuter ^ dstBlk->bbVarDef;
                if (diffLife & varBit)
                    diffLife &= ~varBit;
            }
            assert(diffLife);
            diffLife = genFindLowestBit(diffLife);
            printf("Incompatible outer life for variable %2u\n", genLog2(diffLife)-1);
        }

#endif

        return  true;
    }
    else
    {
        VARSET_TP       dstl = dstBlk->bbLiveIn & intVars;

        /* This is the first time we've encountered this block */

        /* Is anything dying upon reaching the target block? */

        if  (dstl != life)
        {
            /* The only change here should be the death of our variable */

            assert((dstl | varBit) == life);
            assert((life - varBit) == dstl);

            *deathPtr = true;
        }

        dstBlk->bbFlags    |= BBF_VISITED;

        /* Store the values from the predecessor block */

        dstBlk->bbVarDef    = dstl;
        dstBlk->bbStkDepth  = icnt;
        dstBlk->bbVarTmp    = lifeOuter;

//      printf("Set vardef of %u to %08X at %s(%u)\n", dstBlk->bbNum, (int)dstBlk->bbVarDef, __FILE__, __LINE__);

        /* Have we already skipped past this block? */

        if  (srcBlk->bbNum > dstBlk->bbNum)
            *repeatPtr = true;

        return  false;
    }
}

/*****************************************************************************
 *
 *  Check the variable's lifetime for any conflicts. Basically,
 *  we make sure the following are all true for the variable:
 *
 *      1.  Its lifetime is properly nested within or wholly
 *          contain any other enregistered FP variable (i.e.
 *          the lifetimes nest within each other and don't
 *          "cross over".
 *
 *      2.  Whenever a basic block boundary is crossed, one of
 *          the following must hold:
 *
 *              a.  The variable was live but becomes dead; in
 *                  this case a "pop" must be inserted. Note
 *                  that in order to prevent lots of such pops
 *                  from being added, we keep track of how
 *                  many would be necessary and not enregister
 *                  the variable if this count is excessive.
 *
 *              b.  The variable isn't live at the end of the
 *                  previous block, and it better not be live
 *                  on entry to the successor block; no action
 *                  need be taken in this case.
 *
 *              c.  The variable is live in both places; we
 *                  make sure any enregistered variables that
 *                  were live when the variable was born are
 *                  also live at the successor block, and that
 *                  the number of live enregistered FP vars
 *                  that were born after our variable matches
 *                  the number at the successor block.
 *
 *  We begin our search by looking for a block that starts with
 *  our variable dead but contains a reference to it. Of course
 *  since we need to keep track of which blocks we've already
 *  visited, we first make sure all the blocks are marked as
 *  "not yet visited" (everyone who uses the BBF_VISITED and
 *  BBF_MARKED flags is required to clear them on all blocks
 *  after using them).
 */

bool                Compiler::raEnregisterFPvar(unsigned varNum, bool convert)
{
    bool            repeat;

    BasicBlock  *   block;

    LclVarDsc   *   varDsc;
    VARSET_TP       varBit;

    VARSET_TP       intVars;

    unsigned        popCnt  = 0;
    unsigned        popMax;

    bool            result  = false;
    bool            hadLife = false;

#ifndef NDEBUG
    for (block = fgFirstBB; block; block = block->bbNext)
    {
        assert((block->bbFlags & BBF_VISITED) == 0);
        assert((block->bbFlags & BBF_MARKED ) == 0);
    }
#endif

#ifdef DEBUG
    fgDebugCheckBBlist();
#endif

    assert(varNum < lvaCount);
    varDsc = lvaTable + varNum;

    assert(varDsc->lvTracked);
    assert(varDsc->lvRefCntWtd > 1);

    popMax = 1 + (varDsc->lvRefCnt / 2);

    varBit = genVarIndexToBit(varDsc->lvVarIndex);

    /* We're interested in enregistered FP variables + our variable */

    intVars = optAllFPregVars | varBit;

    /*
        Note that since we don't want to bloat the basic block
        descriptor solely to support the logic here, we simply
        reuse two fields that are not used at this stage of the
        compilation process:

            bbVarDef        set   of "outer" live FP regvars
            bbStkDepth      count of "inner" live FP regvars
     */

AGAIN:

    repeat = false;

#ifndef NOT_JITC
//  dispFPvarsInBBlist(fgFirstBB, NULL, optAllFloatVars, this);
#endif

    for (block = fgFirstBB; block; block = block->bbNext)
    {
        GenTreePtr      stmt;

        VARSET_TP       outerLife;
        unsigned        innerVcnt;

        bool            isLive;

        VARSET_TP       lastLife;

        /* Have we already visited this block? */

        if  (block->bbFlags & BBF_VISITED)
        {
            /* Has this block been completely processed? */

            if  (block->bbFlags & BBF_MARKED)
                continue;

            /*
                We have earlier seen an edge to this block from
                another one where our variable was live at the
                point of transfer. To avoid having to recurse, we
                simply marked the block as VISITED at that time
                and now we finish with it.
             */

            innerVcnt = block->bbStkDepth;
            outerLife = block->bbVarTmp;

            assert((outerLife & varBit) == 0);

            if  (block->bbVarDef & varBit)
            {
                /* Our variable is live on entry to this block */

                isLive = true;
            }
            else
            {
                /* Our variable is dead on entry to this block */

                isLive = false;

                /* If there is some "inner" life, this won't work */

                if  (innerVcnt)
                {
#ifdef  DEBUG
                    if (verbose) printf("Can't enregister FP var #%2u due to inner var's life.\n", varNum);
#endif

                    assert(convert == false);
                    goto DONE_FP_RV;
                }
            }
        }
        else
        {
            /* We're seing this block for this first time just now */

            block->bbFlags    |= BBF_VISITED;

            /* The block had nothing interesting on entry */

            block->bbVarDef    = block->bbLiveIn & intVars;
            block->bbStkDepth  = 0;

            /* Is the variable ever live in this block? */

            if  (!(block->bbVarUse & varBit))
                continue;

            /* Is the variable live on entry to the block? */

            if  (!(block->bbLiveIn & varBit))
            {
                /* It is not live on entry */
                isLive    = false;
                innerVcnt = 0;
            }
            else
            {
                /*  We're looking for all the births of the given
                    variable, so this block doesn't look useful
                    at this point, since the variable was born
                    already by the time the block starts.

                    The exception to this are arguments and locals
                    which appear to have a read before write.
                    (a possible uninitialized read)

                    Such variables are effectively born on entry to
                    the method, and if they are enregistered are
                    automatically initialized in the prolog.

                    The order of initialization of these variables in
                    the prolog is the same as the weighted ref count order
                 */

                if  (block != fgFirstBB)
                {
                    /* We might have to revisit this block again */

                    block->bbFlags &= ~BBF_VISITED;
                    continue;
                }

                //  This is an argument or local with a possible
                //  read before write, thus is initialized in the prolog

                isLive = true;

                //  We consider all arguments (and locals) that have
                //  already been assigned to registers as "outer"
                //  and none as "inner".

                outerLife = block->bbLiveIn & optAllFPregVars;
                innerVcnt = 0;
            }
        }

        /* We're going to process this block now */

        block->bbFlags |= BBF_MARKED;

        /* We'll look for lifetime changes of FP variables */

        lastLife = block->bbLiveIn & intVars;

        /* Walk all the statements of the block */

        for (stmt = block->bbTreeList; stmt; stmt = stmt->gtNext)
        {
            assert(stmt->gtOper == GT_STMT);

            for (GenTreePtr tree = stmt->gtStmt.gtStmtList;
                            tree;
                            tree = tree->gtNext)
            {
                unsigned        curLvl  = tree->gtFPregVars;
                VARSET_TP       preLife = lastLife;
                VARSET_TP       curLife = tree->gtLiveSet & intVars;
                VARSET_TP       chgLife;

                // HACK: Detect completely dead variables; get rid of this
                // HACK: once dead store elimination is fixed.

                hadLife |= isLive;

//              if (convert) printf("Convert %08X in block %u\n", tree, block->bbNum);
//              gtDispTree(tree, 0, true);

                /* Make sure we're keeping track of life correctly */

                assert(isLive == ((lastLife & varBit) != 0));

                /* Compute the "change" mask */

                 chgLife = lastLife ^ curLife;
                lastLife =  curLife;

                /* Are we in the second pase (marking the trees) ? */

                if  (convert)
                {
                    /* We have to make changes to some tree nodes */

                    switch (tree->gtOper)
                    {
                    case GT_LCL_VAR:

                        /* Is this a reference to our own variable? */

                        if  (tree->gtLclVar.gtLclNum == varNum)
                        {
                            /* Convert to a reg var node */

                            tree->ChangeOper(GT_REG_VAR);
                            tree->gtRegNum             =
                            tree->gtRegVar.gtRegNum    = (regNumbers)innerVcnt;
                            tree->gtRegVar.gtRegVar    = varNum;

//                          gtDispTree(tree, 0, true);
                        }
                        break;

                    case GT_REG_VAR:

                        /* Is our variable live along with any outer ones? */

                        if (isLive && outerLife)
                        {
                            LclVarDsc   *   tmpDsc;

                            /* Is this an "outer" register variable ref? */

                            assert(tree->gtRegVar.gtRegVar < lvaCount);
                            tmpDsc = lvaTable + tree->gtRegVar.gtRegVar;
                            assert(tmpDsc->lvTracked);

                            if  (outerLife & genVarIndexToBit(tmpDsc->lvVarIndex))
                            {
                                /* Outer variable - bump its stack level */

                                tree->gtRegNum          =
                                tree->gtRegVar.gtRegNum = (regNumbers)(tree->gtRegNum+1);
                            }
                        }
                    }
                }

                /* Is there a change in the set of live FP vars? */

                if  (!chgLife)
                {
                    /* Special case: dead assignments */

                    if  (tree->gtOper            == GT_LCL_VAR &&
                         tree->gtLclVar.gtLclNum == varNum     && !isLive)
                    {
                        // UNDONE: This should never happen, fix dead store removal!!!!

#ifdef  DEBUG
                        assert(!"Can't enregister FP var #%2u due to the presence of a dead store.\n");
#endif

                        assert(convert == false);
                        goto DONE_FP_RV;
                    }

                    continue;
                }

                /* We expect only one thing to change at a time */

                assert(genFindLowestBit(chgLife) == chgLife);

                /* Is the life of our variable changing here? */

                if  (chgLife & varBit)
                {
                    /* Flip the liveness indicator */

                    isLive ^= 1;

//                  printf("P%uL%u: ", convert, isLive); gtDispTree(tree, NULL, true);

                    /* Are we in the second phase already? */

                    if  (convert)
                    {
                        /* The node should have been converted into regvar */

                        assert(tree->gtOper            == GT_REG_VAR &&
                               tree->gtRegVar.gtRegVar == varNum);

//                      printf("%s ", isLive ? "birth" : "death"); gtDispTree(tree, NULL, true);

                        /* Mark birth/death as appropriate */

                        tree->gtFlags |= isLive ? GTF_REG_BIRTH
                                                : GTF_REG_DEATH;
                    }
                    else
                    {
                        /* This better be a ref to our variable */

                        assert(tree->gtOper == GT_LCL_VAR);
                        assert(tree->gtLclVar.gtLclNum == varNum);

                        /* Restrict the places where death can occur */

                        if  (!isLive && tree->gtFPlvl > 1)
                        {
                            GenTreePtr      tmpExpr;

//                          printf("Defer death: "); gtDispTree(tree, NULL, true);

                            /* Death with a non-empty stack is deferred */

                            for (tmpExpr = tree;;)
                            {
                                if  (!tmpExpr->gtNext)
                                    break;

//                              printf("Defer death interim expr [%08X] L=%08X\n", tmpExpr, (int)tmpExpr->gtLiveSet & (int)intVars);

                                tmpExpr = tmpExpr->gtNext;
                            }

//                          printf("Defer death final   expr [%08X] L=%08X\n", tmpExpr, (int)tmpExpr->gtLiveSet & (int)intVars);

                            if  ((tmpExpr->gtLiveSet & intVars) != curLife)
                            {
                                /* We won't be able to defer the death */

#ifdef  DEBUG
                                if (verbose) printf("Can't enregister FP var #%2u due to untimely death.\n", varNum);
#endif

                                assert(convert == false);
                                goto DONE_FP_RV;
                            }
                        }
                    }

                    /* Is this the beginning or end of its life? */

                    if  (isLive)
                    {
                        /* Our variable is being born here */

                        outerLife = curLife & optAllFPregVars;
                        innerVcnt = 0;
                    }
                    else
                    {
                        /* Our variable is dying here */

                        /*
                            Make sure the same exact set of FP reg
                            variables is live here as was the case
                            at the birth of our variable. If this
                            is not the case, it means that some
                            lifetimes "crossed" in an unacceptable
                            manner.
                         */

                        if  (innerVcnt)
                        {
#ifdef  DEBUG
                            if (verbose)
                                printf("Block %2u,tree %08X: Can't enregister FP var #%2u due to inner var's life.\n",
                                       block->bbNum, tree, varNum);
#endif
                            assert(convert == false);
                            goto DONE_FP_RV;
                        }

                        if  (outerLife != (curLife & optAllFPregVars))
                        {
#ifdef DEBUG
                            if (verbose)
                            {
                                VARSET_TP diffLife = outerLife ^ (curLife & optAllFPregVars);
                                diffLife =  genFindLowestBit(diffLife);
                                printf("Block %2u,tree %08X: Can't enregister FP var #%2u due to outer var #%2u death.\n",
                                       block->bbNum, tree, varNum, genLog2(diffLife)-1);
                            }
#endif

                            assert(convert == false);
                            goto DONE_FP_RV;
                        }
                    }
                }
                else
                {
                    /* The life of a previously enregister variable is changing here */

                    /* Is our variable live at this node? */

                    if  (isLive)
                    {
                        VARSET_TP   inLife;
                        VARSET_TP   inDied;
                        VARSET_TP   inBorn;

                        /* Make sure none of the "outer" vars has died */

                        if  (chgLife & outerLife)
                        {
                            /* The lifetimes "cross", give up */

#ifdef  DEBUG
                            if (verbose)
                            {
                                printf("Block %2u,tree %08X: Can't enregister FP var #%2u due to outer var #%2u death.\n",
                                       block->bbNum, tree, varNum, genLog2(chgLife)-1);
                            }
#endif

                            assert(convert == false);
                            goto DONE_FP_RV;
                        }

                        /* Update the "inner life" count */

                        inLife  = ~outerLife & optAllFPregVars;

                        inBorn = (~preLife &  curLife) & inLife;
                        inDied = ( preLife & ~curLife) & inLife;

                        /* We expect only one inner variable to change at one time */

                        assert(inBorn == 0 || inBorn == genFindLowestBit(inBorn));
                        assert(inDied == 0 || inDied == genFindLowestBit(inDied));

                        if  (inBorn)
                            innerVcnt++;
                        if  (inDied)
                            innerVcnt--;
                    }
                    else
                    {
                        assert(innerVcnt == 0);
                    }
                }
            }

            /* Is our variable is live at the end of the statement? */

            if  (isLive && convert)
            {
                /* Remember the position from the bottom of the FP stack
                 * Currently there can be only one value for a given var, as
                 * we do not enregister the individual webs, in which case the
                 * value would have to be tracked per web/GenTree
                 */

                lvaTable[varNum].lvRegNum = (regNumber)stmt->gtStmtFPrvcOut;

                /* Increment the count of FP regs enregisterd at this point */

                stmt->gtStmtFPrvcOut++;
            }
        }

        /* Consider this block's successors */

        switch (block->bbJumpKind)
        {
            BasicBlock * *  jmpTab;
            unsigned        jmpCnt;

            bool            death;

        case BBJ_COND:

            if  (raMarkFPblock(block, block->bbJumpDest, innerVcnt,
                                                          lastLife,
                                                         outerLife,
                                                         varBit,
                                                         intVars,
                                                         &death,
                                                         &repeat))
            {
                assert(convert == false);
                goto DONE_FP_RV;
            }

            if  (death)
            {
                if  (convert)
                    raInsertFPregVarPop(block, &block->bbJumpDest, varNum);
                else
                    popCnt++;
            }

            // Fall through ...

        case BBJ_NONE:

            if  (raMarkFPblock(block, block->bbNext    , innerVcnt,
                                                          lastLife,
                                                         outerLife,
                                                         varBit,
                                                         intVars,
                                                         &death,
                                                         &repeat))
            {
                assert(convert == false);
                goto DONE_FP_RV;
            }

            if  (death)
            {
                if  (convert)
                    raInsertFPregVarPop(block, &block->bbNext    , varNum);
                else
                    popCnt++;
            }

            break;

        case BBJ_ALWAYS:

            if  (raMarkFPblock(block, block->bbJumpDest, innerVcnt,
                                                          lastLife,
                                                         outerLife,
                                                         varBit,
                                                         intVars,
                                                         &death,
                                                         &repeat))
            {
                assert(convert == false);
                goto DONE_FP_RV;
            }

            if  (death)
            {
                if  (convert)
                    raInsertFPregVarPop(block, &block->bbJumpDest, varNum);
                else
                    popCnt++;
            }

            break;

        case BBJ_RET:
        case BBJ_THROW:
        case BBJ_RETURN:
            break;

        case BBJ_CALL:
            assert(convert == false);
            goto DONE_FP_RV;

        case BBJ_SWITCH:

            jmpCnt = block->bbJumpSwt->bbsCount;
            jmpTab = block->bbJumpSwt->bbsDstTab;

            do
            {
                if  (raMarkFPblock(block, *jmpTab, innerVcnt,
                                                    lastLife,
                                                   outerLife,
                                                   varBit,
                                                   intVars,
                                                   &death,
                                                   &repeat))
                {
                    assert(convert == false);
                    goto DONE_FP_RV;
                }

                if  (death)
                {
                    if  (convert)
                        raInsertFPregVarPop(block, jmpTab, varNum);
                    else
                        popCnt++;
                }
            }
            while (++jmpTab, --jmpCnt);

            break;

        default:
            assert(!"unexpected jump kind");
        }
    }

    /* Do we have too many "pop" locations already? */

    if  (popCnt > popMax)
    {
#ifdef  DEBUG
        if (verbose) printf("Can't enregister FP var #%2u, too many pops needed.\n", varNum);
#endif

        assert(convert == false);
        goto DONE_FP_RV;
    }

    /* Did we skip past any blocks? */

    if  (repeat)
        goto AGAIN;

    // HACK: Detect completely dead variables; get rid of this when
    // HACK: dead store elimination is fixed.

    if  (!hadLife)
    {
        /* Re-enable this assert after fixing reference counts */
#ifdef  DEBUG
        //assert(!"Can't enregister FP var due to its complete absence of life - Fix reference counts!\n");
#endif

        assert(convert == false);
        goto DONE_FP_RV;
    }

    /* Success: this variable will be enregistered */

    result = true;

DONE_FP_RV:

    /* If we're converting, we must succeed */

    assert(result == true || convert == false);

    /* Clear the 'visited' and 'marked' bits */

    for (block = fgFirstBB;
         block;
         block = block->bbNext)
    {
        block->bbFlags &= ~(BBF_VISITED|BBF_MARKED);
    }

    if (convert)
    {
        varDsc->lvRegNum = REG_STK;
    }

    return  result;
}

/*****************************************************************************
 *
 *  Try to enregister the FP var
 */

bool                Compiler::raEnregisterFPvar(LclVarDsc   *   varDsc,
                                                unsigned    *   pFPRegVarLiveInCnt,
                                                VARSET_TP   *   FPlvlLife)
{
    assert(varDsc->lvType == TYP_DOUBLE);

    /* Figure out the variable's number */

    unsigned        varNum      = varDsc - lvaTable;
    unsigned        varIndex    = varDsc->lvVarIndex;
    VARSET_TP       varBit      = genVarIndexToBit(varIndex);

    /* Try to find an available FP stack slot for this variable */

    unsigned        stkMin = FP_STK_SIZE;

    do
    {
        if  (varBit & FPlvlLife[--stkMin])
            break;
    }
    while (stkMin > 1);

    /* Here stkMin is the lowest avaiable stack slot */

    if  (stkMin == FP_STK_SIZE - 1)
    {
        /* FP stack full or call present within lifetime */

        goto NO_FPV;
    }

#ifdef  DEBUG
    if (verbose) printf("Consider FP var #%2u [%2u] (refcnt=%3u,refwtd=%5u)\n", varDsc - lvaTable, varIndex, varDsc->lvRefCnt, varDsc->lvRefCntWtd);
#endif

    /* Check the variable's lifetime behavior */

    if  (raEnregisterFPvar(varNum, false))
    {
        /* The variable can be enregistered */

#ifdef  DEBUG
        if  (verbose)
        {
            printf("; var #%2u", varNum);
            if  (verbose||1) printf("[%2u] (refcnt=%3u,refwtd=%5u) ",
                varIndex, varDsc->lvRefCnt, varDsc->lvRefCntWtd);
            printf(" enregistered on the FP stack\n");
        }
#endif

        //
        // If the varible is liveIn to the first Basic Block then
        // we must enregister this varible in the prolog,
        // Typically it will be an incoming argument, but for
        // variables that appear to have an uninitialized read before write
        // then we still must initialize the FPU stack with a 0.0
        //
        // We must remember the order of initialization so that we can
        // perform the FPU stack loads in the correct order
        //
        if (fgFirstBB->bbLiveIn & varBit)
        {
            lvaFPRegVarOrder[*pFPRegVarLiveInCnt] = varNum;
            (*pFPRegVarLiveInCnt)++;
            lvaFPRegVarOrder[*pFPRegVarLiveInCnt] = -1;       // Mark the end of this table
            assert(*pFPRegVarLiveInCnt < FP_STK_SIZE);
        }

        /* Update the trees and statements */

        raEnregisterFPvar(varNum, true);

#ifdef DEBUGGING_SUPPORT
        lvaTrackedVarNums[varDsc->lvVarIndex] = varNum;
#endif

        lvaTrackedVars |=  genVarIndexToBit(varDsc->lvVarIndex);

        varDsc->lvTracked  = true;
        varDsc->lvRegister = true;

        /* Remember that we have a new enregistered FP variable */

        optAllFPregVars |= varBit;

#if     DOUBLE_ALIGN

        /* Adjust the refcount for double alignment */

        if (!varDsc->lvIsParam)
            lvaDblRefsWeight -= varDsc->lvRefCntWtd;

#endif

        return true;
    }
    else
    {
        /* This FP variable will not be enregistered */

    NO_FPV:

#ifdef DEBUGGING_SUPPORT
        lvaTrackedVarNums[varDsc->lvVarIndex] = 0;
#endif

        lvaTrackedVars &= ~genVarIndexToBit(varDsc->lvVarIndex);

        varDsc->lvTracked  =
        varDsc->lvRegister = false;

        return false;
    }
}


/*****************************************************************************/
#else //TGT_x86
/*****************************************************************************
 *
 *  Record the fact that all the variables in the 'vars' set interefere with
 *  with the registers in 'regs'.
 */

void                Compiler::raMarkRegSetIntf(VARSET_TP vars, regMaskTP regs)
{
    while (regs)
    {
        regMaskTP   temp;
        regNumber   rnum;

        /* Get the next bit in the mask */

        temp  = genFindLowestBit(regs);

        /* Convert the register bit to a register number */

        rnum  = genRegNumFromMask(temp);

//      printf("Register %s interferes with %08X\n", getRegName(rnum), int(vars));

        /* Mark interference with the corresponding register */

        raLclRegIntf[rnum] |= vars;

        /* Clear the bit and continue if any more left */

        regs -= temp;
    }
}

/*****************************************************************************/
#endif//TGT_x86
/*****************************************************************************/

/*****************************************************************************
 *
 *  Try to allocate register(s) for the given var from 'regAvail'
 *  Tries to use 'prefReg' if possible. If prefReg is 0, it is ignored.
 *  Returns the mask of allocated register(s).
 */

regMaskTP           Compiler::raAssignRegVar(LclVarDsc   *  varDsc,
                                             regMaskTP      regAvail,
                                             regMaskTP      prefReg)
{
    unsigned        varIndex    = varDsc->lvVarIndex;
    VARSET_TP       varBit      = genVarIndexToBit(varIndex);
    regMaskTP       regMask     = regMaskNULL;

    for (unsigned regCandidate = 0;
         regCandidate < sizeof(genRegVarList)/sizeof(genRegVarList[0]);
         regCandidate++)
    {
        regNumber       regNum = (regNumber)genRegVarList[regCandidate];
        regMaskTP       regBit = genRegMask(regNum);

#if TARG_REG_ASSIGN

        /* Does this variable have a register preference? */

        if  (prefReg)
        {
            if  (!(prefReg & regBit))
                continue;

            prefReg = regMaskNULL;
        }

#endif

        /* Skip this register if it isn't available */

        if  (!(regAvail & regBit))
            continue;

        /* Has the variable been used as a byte/short? */

#if 0

        if  (false) // @Disabled if (varDsc->lvSmallRef)
        {
            /* Make sure the register can be used as a byte/short */

            if  (!isByteReg(regNum))
                continue;
        }

#endif

        bool onlyOneVarPerReg = true;

        /* Does the register and the variable interfere? */

        if  (raLclRegIntf[regNum] & varBit)
            continue;

        if (!opts.compMinOptim)
            onlyOneVarPerReg = false;

        if (onlyOneVarPerReg)
        {
            /* Only one variable per register allowed */

            if  (regBit & regAvail)
                continue;
        }


        /* Looks good - mark the variable as living in the register */

#if !   TGT_IA64

        if  (isRegPairType(varDsc->lvType))
        {
            if  (!varDsc->lvRegister)
            {
                 varDsc->lvRegNum   = regNum;
                 varDsc->lvOtherReg = REG_STK;
            }
            else
            {
               /* Ensure 'well-formed' register pairs */
               /* (those returned by gen[Pick|Grab]RegPair) */

               if  (regNum < varDsc->lvRegNum)
               {
                   varDsc->lvOtherReg = varDsc->lvRegNum;
                   varDsc->lvRegNum   = regNum;
               }
               else
               {
                   varDsc->lvOtherReg = regNum;
               }
            }
        }
        else
#endif
        {
            varDsc->lvRegNum = regNum;
        }

        varDsc->lvRegister = true;

#ifdef  DEBUG

        if  (dspCode || disAsm || disAsm2 || verbose)
        {
            printf("; var #%2u", varDsc - lvaTable);
            printf("[%2u] (refcnt=%3u,refwtd=%5u) ", varIndex, varDsc->lvRefCnt, varDsc->lvRefCntWtd);
            printf(" assigned to %s\n", getRegName(regNum));
        }
#endif

        if (!onlyOneVarPerReg)
        {
            /* The reg is now ineligible for all interefering variables */

            unsigned        intfIndex;
            VARSET_TP       intfBit;
            VARSET_TP       varIntf = lvaVarIntf[varIndex];

            for (intfIndex = 0, intfBit = 1;
                 intfIndex < lvaTrackedCount;
                 intfIndex++  , intfBit <<= 1)
            {
                assert(genVarIndexToBit(intfIndex) == intfBit);

                if  ((varIntf & intfBit) || (lvaVarIntf[intfIndex] & varBit))
                {
                    raLclRegIntf[regNum] |= intfBit;
                }
            }
        }

        regMask |= regBit;

        /* We only need one register for a given variable */

#if !   TGT_IA64
        if  (isRegPairType(varDsc->lvType) && varDsc->lvOtherReg == REG_STK)
            continue;
#endif

        break;
    }

    return regMask;
}

/*****************************************************************************
 *
 *  Mark all variables as to whether they live on the stack frame
 *  (part or whole), and if so what the base is (FP or SP).
 */

void                Compiler::raMarkStkVars()
{
    unsigned        lclNum;
    LclVarDsc *     varDsc;

    for (lclNum = 0, varDsc = lvaTable;
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
        varDsc->lvOnFrame = false;

        /* Fully enregistered variables don't need any frame space */

        if  (varDsc->lvRegister)
        {
#if TGT_IA64
            goto NOT_STK;
#else
            if  (!isRegPairType((var_types)varDsc->lvType))
                goto NOT_STK;

            /* For "large" variables make sure both halves are enregistered */

            if  (varDsc->lvRegNum   != REG_STK &&
                 varDsc->lvOtherReg != REG_STK)
            {
                goto NOT_STK;
            }
#endif
        }
        /* Unused variables don't get any frame space either */
        else  if  (varDsc->lvRefCnt == 0)
        {
            bool    needSlot = false;

            bool    stkFixedArgInVarArgs = info.compIsVarArgs &&
                                           varDsc->lvIsParam &&
                                           !varDsc->lvIsRegArg;

            /* If its address has been taken, ignore lvRefCnt. However, exclude
               fixed arguments in varargs method as lvOnFrame shouldnt be set
               for them as we dont want to explicitly report them to GC. */

            if (!stkFixedArgInVarArgs)
                needSlot |= lvaVarAddrTaken(lclNum);

            /* Is this the dummy variable representing GT_LCLBLK ? */

            needSlot |= lvaScratchMem && lclNum == lvaScratchMemVar;

#ifdef DEBUGGING_SUPPORT
            /* Assign space for all vars while debugging.
               CONSIDER : Assign space only for those variables whose scopes
                          we need to report, unless EnC.
             */

            if (opts.compDbgCode && !stkFixedArgInVarArgs)
            {
                needSlot |= (lclNum < info.compLocalsCount);
            }
#endif
            if (!needSlot)
                goto NOT_STK;
        }

        /* The variable (or part of it) lives on the stack frame */

        varDsc->lvOnFrame = true;

    NOT_STK:;

        varDsc->lvFPbased = genFPused;

#if DOUBLE_ALIGN

        if  (genDoubleAlign)
        {
            assert(genFPused == false);

            /* All arguments are off of the FP with double-aligned frames */

            if  (varDsc->lvIsParam)
                varDsc->lvFPbased = true;
        }

#endif

        /* Some basic checks */

        /* If neither lvRegister nor lvOnFrame is set, it must be unused */

        assert( varDsc->lvRegister ||  varDsc->lvOnFrame ||
                varDsc->lvRefCnt == 0);

#if TGT_IA64

        assert( varDsc->lvRegister !=  varDsc->lvOnFrame);

#else

        /* If both are set, it must be partially enregistered */

        assert(!varDsc->lvRegister || !varDsc->lvOnFrame ||
               (varDsc->lvType == TYP_LONG && varDsc->lvOtherReg == REG_STK));

#endif

#if _DEBUG
            // For varargs functions, there should be no direct references to
            // parameter variables except for 'this' (these were morphed in the importer)
            // and the 'arglist' parameter (which is not a GC pointer). and the
            // return buffer argument (if we are returning a struct).
            // This is important because we don't want to try to report them to the GC, as
            // the frame offsets in these local varables would not be correct.
        if (info.compIsVarArgs && varDsc->lvIsParam &&
            !varDsc->lvIsRegArg && lclNum != info.compArgsCount - 1)
        {
            assert( varDsc->lvRefCnt == 0 &&
                   !varDsc->lvRegister    &&
                   !varDsc->lvOnFrame        );
        }
#endif
    }
}


/*****************************************************************************
 *
 *  Assign registers to variables ('regAvail' gives the set of registers we
 *  are allowed to use). Returns non-zero if any new register assignments
 *  were performed.
 */

int                 Compiler::raAssignRegVars(regMaskTP regAvail)
{
    unsigned        lclNum;
    LclVarDsc   *   varDsc;
    LclVarDsc * *   cntTab;
    bool            newRegVars;
    bool            OKpreds = false;
    regMaskTP       regVar  = regMaskNULL;

#if REGVAR_CYCLES
    unsigned        cycleStart = GetCycleCount32();
#endif

#if TGT_x86
    VARSET_TP       FPlvlLife[FP_STK_SIZE];
    unsigned        FPparamRV = 0;
#else
    VARSET_TP   *   FPlvlLife = NULL;
#endif

#if INLINE_NDIRECT
    VARSET_TP       trkGCvars;
#else
    const
    VARSET_TP       trkGCvars = 0;
#endif

    unsigned        passes = 0;

    /* We have to decide on the FP locally, don't trust the caller */

#if!TGT_IA64
    regAvail &= ~RBM_FPBASE;
#endif

    /* Is the method eligible for FP omission? */

#if TGT_x86
    genFPused = genFPreqd;
#else
    genFPused = false;      // UNDONE: If there is alloca, need FP frame!!!!!
#endif

    /*-------------------------------------------------------------------------
     *
     *  Initialize the variable/register interference graph
     *
     */

#ifdef DEBUG
    fgDebugCheckBBlist();
#endif

    memset(raLclRegIntf, 0, sizeof(raLclRegIntf));

    /* While we're at it, compute the masks of tracked FP/non-FP variables */

    optAllNonFPvars = 0;
    optAllFloatVars = 0;

#if INLINE_NDIRECT
    /* Similarly, compute the mask of all tracked GC/ByRef locals */

    trkGCvars       = 0;
#endif

    for (lclNum = 0, varDsc = lvaTable;
         lclNum < lvaCount;
         lclNum++  , varDsc++)
    {
        unsigned        varNum;
        VARSET_TP       varBit;

        /* Ignore the variable if it's not tracked */

        if  (!varDsc->lvTracked)
            continue;

        /* Get hold of the index and the interference mask for the variable */

        varNum = varDsc->lvVarIndex;
        varBit = genVarIndexToBit(varNum);

        /* Make sure tracked pointer variables never land in EDX */

#if TGT_x86
#if GC_WRITE_BARRIER_CALL
        if  (varDsc->lvRefAssign)
            raLclRegIntf[REG_EDX] |= varBit;
#endif
#endif

#if INLINE_NDIRECT

        /* Is this a GC/ByRef local? */

        if (varTypeIsGC((var_types)varDsc->lvType))
            trkGCvars       |= varBit;
#endif

        /* Record the set of all tracked FP/non-FP variables */

        if  (varDsc->lvType == TYP_DOUBLE)
            optAllFloatVars |= varBit;
        else
            optAllNonFPvars |= varBit;
    }

    /*-------------------------------------------------------------------------
     *
     *  Find the interference between variables and registers
     *
     */

    if  (!opts.compMinOptim)
        raMarkRegIntf(FPlvlLife, trkGCvars);

#if REGVAR_CYCLES
    unsigned    cycleMidle = GetCycleCount32() - cycleStart - CCNT_OVERHEAD32;
#endif

    // We'll adjust the ref counts based on interference

    raAdjustVarIntf();

#ifdef  DEBUG
#ifndef NOT_JITC

    if  ((verbose||(testMask&32)) && optAllFloatVars)
    {
        fgDispBasicBlocks();
//        raDispFPlifeInfo();
    }

#endif
#endif

    /*-------------------------------------------------------------------------
     *
     *  Assign registers to locals in ref-count order
     *
     */


#if USE_FASTCALL
    /* register to be avoided by non-register arguments */
    regMaskTP       avoidArgRegMask = rsCalleeRegArgMaskLiveIn;
#endif

    unsigned        FPRegVarLiveInCnt = 0; // How many enregistered doubles are live on entry to the method

#if TGT_x86
    lvaFPRegVarOrder[FPRegVarLiveInCnt] = -1;     // Mark the end of this table
#endif

AGAIN:

    passes++;

    const  bool    oneVar = false;

    // ISSUE: Should we always assign 'this' to e.g. ESI ?

    // ISSUE: Should we try to gather and use hints as to which variable would
    // ISSUE: be most profitable in a particular register, and so on ?

    for (lclNum = 0, cntTab = lvaRefSorted, newRegVars = false;
         lclNum < lvaCount && !oneVar;
         lclNum++  , cntTab++)
    {
        unsigned        varIndex;
        VARSET_TP       varBit;

#if TARG_REG_ASSIGN
        regMaskTP       prefReg;
#endif

        /* Get hold of the variable descriptor */

        varDsc = *cntTab; assert(varDsc);

        /* Ignore the variable if it's not tracked */

        if  (!varDsc->lvTracked)
            continue;

        /* Skip the variable if it's already enregistered */

        if  (varDsc->lvRegister)
        {
            /* Keep track of all the registers we use for variables */

            regVar |= genRegMask(varDsc->lvRegNum);

#if TGT_IA64

            continue;

            if  (!isRegPairType(varDsc->lvType))
                continue;

#else

            /* Check if both halves of long/double are already enregistered */

            if  (varDsc->lvOtherReg != REG_STK)
            {
                /* Keep track of all the registers we use for variables */
                regVar |= genRegMask(varDsc->lvOtherReg);
                continue;
            }

#endif

        }

        /* Skip the variable if it's marked as 'volatile' */

        if  (varDsc->lvVolatile)
            continue;

#if USE_FASTCALL
        /* UNDONE: For now if we have JMP or JMPI all register args go to stack
         * UNDONE: Later consider extending the life of the argument or make a copy of it */

        if  (impParamsUsed && varDsc->lvIsRegArg)
            continue;
#endif

        /* Is the unweighted ref count too low to be interesting? */

        if  (varDsc->lvRefCnt <= 1)
        {
            /* Stop if we've reached the point of no use */

            if (varDsc->lvRefCnt == 0)
                break;

            /* Sometimes it's useful to enregister a variable with only one use */

            /* arguments referenced in loops are one example */

            if (varDsc->lvIsParam && varDsc->lvRefCntWtd > 1)
                goto OK_TO_ENREGISTER;

#if TARG_REG_ASSIGN
            /* If the variable has a preferred register set it may be useful to put it there */
            if (varDsc->lvPrefReg)
                goto OK_TO_ENREGISTER;
#endif

            /* Keep going; the table is sorted by "weighted" ref count */
            continue;
        }

OK_TO_ENREGISTER:

//      printf("Ref count for #%02u[%02u] is %u\n", lclNum, varDsc->lvVarIndex, varDsc->lvRefCnt);

        /* Get hold of the variable index, bit mask and interference mask */

        varIndex = varDsc->lvVarIndex;
        varBit   = genVarIndexToBit(varIndex);

#if CPU_HAS_FP_SUPPORT

        /* Is this a floating-point variable? */

        if  (varDsc->lvType == TYP_DOUBLE)
        {

            /* Don't waste time if code speed is not important */

            if  (!opts.compFastCode || opts.compMinOptim)
                continue;

            /* We only want to do this once, who cares about EBP here ... */

            if  (passes > 1)
                continue;

#if TGT_x86
            raEnregisterFPvar(varDsc, &FPRegVarLiveInCnt, FPlvlLife);
#else
#if     CPU_DBL_REGISTERS
            assert(!"enregister double var");
#endif
#endif  // TGT_x86

            continue;
        }

#endif  // CPU_HAS_FP_SUPPORT

        /* Try to find a suitable register for this variable */

#if TARG_REG_ASSIGN

        prefReg  = varDsc->lvPrefReg;

#if TGT_SH3

        /* Make r0 take preference over r4-r6 -- basically, a hack */

        /*
            CONSIDER: What we really need is preference levels. Allocating
            an argument to its incoming register is nice, but if that same
            argument is frequently used in an indexed addressing mode it
            might be much more profitable to allocate it to r0.
         */

        if  (prefReg & RBM_r00) prefReg &= ~RBM_ARG_REGS;

#endif

        // If there is no chance of satisfying prefReg, dont use it.
        if  (!isNonZeroRegMask(prefReg & regAvail))
            prefReg = regMaskNULL;

#endif // TARG_REG_ASSIGN

#if USE_FASTCALL
        // Try to avoid using the registers of the register arguments
        regMaskTP    avoidRegs = avoidArgRegMask;

        /* For register arguments, avoid everything except yourself */
        if (varDsc->lvIsRegArg)
            avoidRegs &= ~genRegMask(varDsc->lvArgReg);
#endif

#ifdef  DEBUG
//      printf(" %s var #%2u[%2u] (refcnt=%3u,refwtd=%5u)\n", oneVar ? "Copy" : "    ",
//                  varDsc - lvaTable, varIndex, varDsc->lvRefCnt, varDsc->lvRefCntWtd);
#endif

    AGAIN_VAR:

        regMaskTP varRegs = raAssignRegVar(varDsc, regAvail & ~avoidRegs, prefReg);

        // Did we succeed in enregistering the var? In this try or the previous one?

        if (varDsc->lvRegister && varRegs)
        {
            assert((genRegMask(varDsc->lvRegNum  ) & varRegs) ||
                   (genRegMask(varDsc->lvOtherReg) & varRegs) && isRegPairType(varDsc->lvType));

            /* Remember that we have assigned a new variable */

            newRegVars = true;

            /* Keep track of all the registers we use for variables */

            regVar |= varRegs;

            /* Remember that we are using this register */

            rsMaskModf |= varRegs;

#if USE_FASTCALL
            /* If a register argument, remove its prefered register
             * from the "avoid" list */

            if (varDsc->lvIsRegArg)
                avoidArgRegMask &= ~genRegMask(varDsc->lvArgReg);
#endif


            /* Only one variable per register */

            if (opts.compMinOptim)
                regAvail &= ~varRegs;
        }
        else
        {
            assert(varRegs == regMaskNULL);

            /* If we were trying for a preferred register, try again */

#if TARG_REG_ASSIGN
            if  (prefReg)
            {
                prefReg = regMaskNULL;
                goto AGAIN_VAR;
            }
#endif

#if USE_FASTCALL
            /* If we tried but failed to avoid argument registers, try again */
            if (avoidRegs)
            {
                avoidRegs = regMaskNULL;
                goto AGAIN_VAR;
            }
#endif
        }
    }

    /* If we were allocating a single "copy" variable, go start all over again */

    if  (oneVar)
        goto AGAIN;

#if!TGT_IA64

    /*-------------------------------------------------------------------------
     *
     *  Should we use an explicit stack frame ?
     *
     */

    if  (!genFPused && !(regVar & RBM_FPBASE))
    {

#if TGT_x86

        /*
            It's possible to avoid setting up an EBP stack frame, but
            we have to make sure that this will actually be beneficial
            since on the x86 references relative to ESP are larger.
         */

        unsigned        lclNum;
        LclVarDsc   *   varDsc;

        unsigned        refCnt;
        unsigned        maxCnt;

        for (lclNum = 0, varDsc = lvaTable, refCnt = genTmpAccessCnt;
             lclNum < lvaCount;
             lclNum++  , varDsc++)
        {
            /* Is this a register variable? */

            if  (!varDsc->lvRegister)
            {
                /* We use the 'real' (unweighted) ref count, of course */

//              printf("Variable #%02u referenced %02u times\n", lclNum, varDsc->lvRefCnt);

                refCnt += varDsc->lvRefCnt;
            }
        }

//      printf("A total of %u stack references found\n", refCnt);

        /*
            Each stack reference is an extra byte of code; we use
            heuristics to guess whether it's likely a good idea to
            try to omit the stack frame. Note that we don't really
            know how much we might save by assigning a variable to
            EBP or by using EBP as a scratch register ahead of time
            so we have to guess.

            The following is somewhat arbitrary: if we've already
            considered EBP for register variables we only allow a
            smaller number of references; otherwise (in the hope
            that some variable(s) will end up living in EBP) we
            allow a few more stack references.
         */

        if  (regAvail & RBM_EBP)
            maxCnt  = 5;
        else
            maxCnt  = 6;

        if  (opts.compFastCode)
            maxCnt *= 10;

        if  (refCnt > maxCnt)
        {
            /* We'll have to create a normal stack frame */

            genFPused = true;
            goto DONE_FPO;
        }

#else // not TGT_x86

        // UNDONE: We need FPO heuristics for RISC targets!!!!

        if  (0)
        {
            /* We'll have to create a normal stack frame */

//          genFPused = true;
//          genFPtoSP = 0;
            goto DONE_FPO;
        }

#endif

        /* Have we already considered the FP register for variables? */

        if  (!(regAvail & RBM_FPBASE))
        {
            /*
                Here we've decided to omit setting up an explicit stack
                frame; make the FP reg available for register allocation.
             */

            regAvail |= RBM_FPBASE;
            goto AGAIN;
        }
    }

DONE_FPO:

#endif

#if TGT_x86

    /* If we are generating an EBP-less frame then for the purposes
     * of generating the GC tables and tracking the stack-pointer deltas
     * we force a full pointer register map to be generated
     * Actually we don't need all of the becomes live/dead stuff
     * only the pushes for the stack-pointer tracking.
     * The live registers for calls are recorded at the call site
     */
    if (!genFPused)
        genFullPtrRegMap = true;

#endif

    //-------------------------------------------------------------------------

#if REGVAR_CYCLES

    static
    unsigned    totalMidle;
    static
    unsigned    totalCount;

    unsigned    cycleCount = GetCycleCount32() - cycleStart - CCNT_OVERHEAD32;

    totalMidle += cycleMidle;
    totalCount += cycleCount;

    printf("REGVARS: %5u / %5u cycles --> total %5u / %5u\n", cycleMidle, cycleCount,
                                                              totalMidle, totalCount);

#endif

#if DOUBLE_ALIGN

#define DOUBLE_ALIGN_THRESHOLD   5

    genDoubleAlign = false;

#ifndef NOT_JITC
#ifdef  DEBUG
#ifndef _WIN32_WCE
    static  const   char *  noDblAlign = getenv("NODOUBLEALIGN");
    if  (noDblAlign)
        goto NODOUBLEALIGN;
#endif
#endif

    /* If we have a frame pointer, but don't HAVE to have one, then we can double
     * align if appropriate
     */
#ifdef DEBUG
    if (verbose)
    {
        printf("double alignment: double refs = %u , local refs = %u", lvaDblRefsWeight, lvaLclRefsWeight);
        printf(" genFPused: %s  genFPreqd: %s  opts.compDoubleAlignDisabled: %s\n",
                 genFPused     ? "yes" : "no ",
                 genFPreqd ? "yes" : "no ",
                 opts.compDoubleAlignDisabled ? "yes" : "no ");
    }
#endif
#endif // NOT_JITC

#ifndef _WIN32_WCE
#ifndef NOT_JITC
#ifdef DEBUG
NODOUBLEALIGN:
#endif
#endif
#endif

#endif // DOUBLE_ALIGN

    raMarkStkVars();

    //-------------------------------------------------------------------------

#if TGT_RISC

    /* Record the initial estimate of register use */

    genEstRegUse = regVar;

    /* If the FP register is used for a variable, can't use it for a frame */

#if!TGT_IA64
    genFPcant    = ((regVar & RBM_FPBASE) != 0);
#endif

#endif
    return newRegVars;
}

/*****************************************************************************
 *
 *  Assign variables to live in registers, etc.
 */

void                Compiler::raAssignVars()
{
    /* We need to keep track of which registers we ever touch */

    rsMaskModf = regMaskNULL;

    //-------------------------------------------------------------------------

#if USE_FASTCALL

    /* Determine the regsiters holding incoming register arguments */

    rsCalleeRegArgMaskLiveIn = regMaskNULL;

    LclVarDsc *     argsEnd = lvaTable + info.compArgsCount;

    for (LclVarDsc * argDsc = lvaTable; argDsc < argsEnd; argDsc++)
    {
        assert(argDsc->lvIsParam);

        // Is it a register argument ?
        if (!argDsc->lvIsRegArg)
            continue;

        // Is it dead on entry ? If impParamsUsed is true, then the arguments
        // have to be kept alive. So we have to consider it as live on entry.
        // This will work as long as arguments dont get enregistered for impParamsUsed.

        if (!impParamsUsed && argDsc->lvTracked &&
            (fgFirstBB->bbLiveIn & genVarIndexToBit(argDsc->lvVarIndex)) == 0)
            continue;

        rsCalleeRegArgMaskLiveIn |= genRegMask(argDsc->lvArgReg);
    }

#endif

    //-------------------------------------------------------------------------

    if (!(opts.compFlags & CLFLG_REGVAR))
        return;

    /* Are we supposed to optimize? */

    if  (!opts.compMinOptim)
    {

        /* Assume we will need an explicit frame pointer */

        genFPused = true;

        /* Predict registers used by code generation */

        raPredictRegUse();

#ifdef DEBUG
        if (verbose&&0)
        {
            printf("Trees after reg use prediction:\n");
            fgDispBasicBlocks(true);
        }
#endif

        /* Assign register variables */

        raAssignRegVars(RBM_ALL);
    }

#if ALLOW_MIN_OPT
    else
    {

#if TGT_x86
        genTmpAccessCnt = 0;
#endif

        /* Assign regvars based on a conservative estimate of register needs.
         * This is poor man's register-interference.
         */

        raAssignRegVars(raMinOptLclVarRegs);
    }
#endif
}

/*****************************************************************************/
#endif//TGT_IA64
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\quads.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
QUAD1(NOP       , "nop"               , QK_LEAF)

QUAD1(CNSI32    , "cnsI32"            , QK_CONST)
QUAD1(CNSI64    , "cnsI64"            , QK_CONST)
QUAD1(CNSF32    , "cnsF32"            , QK_CONST)
QUAD1(CNSF64    , "cnsF64"            , QK_CONST)

QUAD1(LCLVAR    , "lclvar"            , QK_VAR)
QUAD1(GLOBAL    , "glbvar"            , QK_VAR)

QUAD1(LDIND     , "ld.ind"            , QK_UNOP)
QUAD1(STIND     , "st.ind"            , QK_ASSIGN)
QUAD1(STORE     , "store"             , QK_ASSIGN)

QUAD1(ADD       , "add"               , QK_BINOP)
QUAD1(SUB       , "sub"               , QK_BINOP)
QUAD1(MUL       , "mul"               , QK_BINOP)
QUAD1(DIV       , "div"               , QK_BINOP)
QUAD1(MOD       , "mod"               , QK_BINOP)
QUAD1(SHL       , "shl"               , QK_BINOP)
QUAD1(SHR       , "shr"               , QK_BINOP)
QUAD1(SAR       , "sar"               , QK_BINOP)

QUAD1(ASG_ADD   , "add="              , QK_ASSIGN)
QUAD1(ASG_SUB   , "sub="              , QK_ASSIGN)
QUAD1(ASG_MUL   , "mul="              , QK_ASSIGN)
QUAD1(ASG_DIV   , "div="              , QK_ASSIGN)
QUAD1(ASG_MOD   , "mod="              , QK_ASSIGN)
QUAD1(ASG_SHL   , "shl="              , QK_ASSIGN)
QUAD1(ASG_SHR   , "shr="              , QK_ASSIGN)
QUAD1(ASG_SAR   , "sar="              , QK_ASSIGN)

QUAD1(CMP       , "cmp"               , QK_COMP)

QUAD1(RET       , "ret"               , QK_UNOP)

QUAD1(JMP       , "jmp"               , QK_JUMP)
QUAD1(CALL      , "call"              , QK_CALL)
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\schedia64.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
#include "jitpch.h"
#pragma hdrstop
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\sched.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
    /************************************************************************/
    /*          Members/methods used for instruction scheduling             */
    /************************************************************************/

#if SCHEDULER

#if TGT_x86
#define EMIT_MAX_INSTR_STACK_CHANGE     sizeof(double)  // Max stk change effected by a single instr
#define SCHED_MAX_STACK_CHANGE          6*sizeof(void*) // Max stk change that will be scheduled
#endif

    struct  scDagNode
    {
        schedDepMap_tp      sdnDepsAll;     // mask of all  dependents
        schedDepMap_tp      sdnDepsFlow;    // mask of flow dependents

#if     TGT_IA64
        schedDepMap_tp      sdnDepsAnti;    // mask of anti dependents
        schedDepMap_tp      sdnDepsMore;    // mask of non-anti and non-flow deps
#endif

        scDagNode    *      sdnNext;        // links the "ready" list

        schedInsCnt_tp      sdnIndex;       // node/ins index [0..count-1]
        schedInsCnt_tp      sdnPreds;       // count of predecessors

#ifdef  DEBUG
        schedInsCnt_tp      sdnIssued   :1; // ins. has already been issued
#endif

#if     MAX_BRANCH_DELAY_LEN
        schedInsCnt_tp      sdnBranch   :1; // branch with delay slot(s)?
#endif

#if     TGT_IA64
        unsigned short      sdnEEtime;      // earliest execution time - hard requirement
#endif

        unsigned short      sdnHeight;      // "height" of the node
    };

#if SCHED_INS_CNT_MAX > 64

    bool            scDagTestNodeX(schedDepMap_tp mask, unsigned index)
    {
        assert(index < SCHED_INS_CNT_MAX);

        return  bitset128test(mask, index);
    }

    bool            scDagTestNodeP(schedDepMap_tp mask, scDagNode *node)
    {
        return  scDagTestNodeX(mask, node->sdnIndex);
    }

    void            scDagSet_NodeX(schedDepMap_tp *mask, unsigned index)
    {
        assert(index < SCHED_INS_CNT_MAX);

        bitset128set(mask, index);
    }

    void            scDagSet_NodeP(schedDepMap_tp *mask, scDagNode *node)
    {
        scDagSet_NodeX(mask, node->sdnIndex);
    }

    schedDepMap_tp  scDagNodeX2mask(unsigned index)
    {
        schedDepMap_tp  mask;

        assert(index < SCHED_INS_CNT_MAX);

        bitset128make1(&mask, index);

        return  mask;
    }

#else

    schedDepMap_tp  scDagNodeX2mask(unsigned index)
    {
        assert(index < SCHED_INS_CNT_MAX);

        return  ((schedDepMap_tp)1) << index;   // CONSIDER: Is this fast enough?
    }

#endif

    schedDepMap_tp  scDagNodeP2mask(scDagNode *node)
    {
        return  scDagNodeX2mask(node->sdnIndex);
    }

    struct  scDagList
    {
        scDagList    *   sdlNext;
        scDagNode    *   sdlNode;
    };

    typedef
    scDagList     * schedUse_tp;            // tracks schedulable use(s)
    typedef
    scDagNode     * schedDef_tp;            // tracks schedulable def (0 or 1)

    instrDesc   * * scInsTab;               // table of schedulable instructions
    unsigned        scInsCnt;               // count of schedulable instructions
    instrDesc   * * scInsMax;               // table end
    scDagNode     * scDagTab;               // table of corresponding dag nodes
    instrDesc   * * scDagIns;               // base  of schedulable ins group

#if MAX_BRANCH_DELAY_LEN

    unsigned        scBDTmin;               // minimal time for branch
    unsigned        scBDTbeg;               // count when branch issued
    unsigned        scIssued;               // count of instr's issued so far

    bool            scIsBranchTooEarly(scDagNode *node);

#endif

    /*----------------------------------------------------------------------*/
    /*  The following macros to walk through the successor list of a node   */
    /*----------------------------------------------------------------------*/

    #define         scWalkSuccDcl(n)                                    \
                                                                        \
        schedDepMap_tp  n##deps;

    #define         scWalkSuccBeg(n,d)                                  \
                                                                        \
        n##deps = d->sdnDepsAll;                                        \
                                                                        \
        while (schedDepIsNonZ(n##deps))                                 \
        {                                                               \
            schedDepMap_tp  n##depm;                                    \
            unsigned        n##depx;                                    \
            scDagNode   *   n##depn;                                    \
                                                                        \
            n##depx  = schedDepLowX(n##deps);                           \
            assert((int)n##depx >= 0);                                  \
                                                                        \
            n##depn  = scDagTab + n##depx;                              \
            n##depm  = scDagNodeP2mask(n##depn);                        \
                                                                        \
            schedDepClear(&n##deps, n##depm);

    #define         scWalkSuccRmv(n,d)                                  \
                                                                        \
        assert(schedDepOvlp(d->sdnDepsAll, n##depm));                   \
        schedDepClear(&d->sdnDepsAll, n##depm);

    #define         scWalkSuccCur(n) n##depn

    #define         scWalkSuccEnd(n) }

    /*----------------------------------------------------------------------*/
    /*               The following handle the "ready" list                  */
    /*----------------------------------------------------------------------*/

    scDagNode    *  scReadyList;
    scDagNode    *  scLastIssued;

#if TGT_IA64
    NatUns          scCurrentTime;
    NatUns          scRlstBegTime;
    NatUns          scRlstCurTime;
    void            scUpdateSuccEET(scDagNode *node);
#endif

    void            scReadyListAdd(scDagNode *node)
    {
        node->sdnNext = scReadyList;
                        scReadyList = node;
    }

    // pick the next ready node to issue

    enum            scPick
    {
        PICK_SCHED,
#if     TGT_IA64
        PICK_NO_TEMPL,              // ignore current template, force a choice
#endif
#ifdef  DEBUG
        PICK_NO_SCHED,
        PICK_MAX_SCHED,
#endif
    };

    scDagNode    *  scPickNxt(scPick pick);

    /*----------------------------------------------------------------------*/
    /*             Misc members/methods used for scheduling                 */
    /*----------------------------------------------------------------------*/

    unsigned        scLatency(scDagNode *node,
                              scDagNode *succ      = NULL,
                              NatUns    *minLatPtr = NULL);

    unsigned        scGetDagHeight(scDagNode *node);

#ifdef  DEBUG
    void            scDispDag(bool         noDisp = false);
#endif

    instrDesc   *   scGetIns(unsigned     nodex)
    {
        assert(nodex < scInsCnt);

        return  scDagIns[nodex];
    }

    instrDesc   *   scGetIns(scDagNode   *node)
    {
        return  scGetIns(node->sdnIndex);
    }

    /*----------------------------------------------------------------------*/
    /*      The following detects and records dependencies in the dag       */
    /*----------------------------------------------------------------------*/

    schedUse_tp     scUseOld;          // list of free "use" entries

    schedUse_tp     scGetUse     ();
    void            scRlsUse     (schedUse_tp  use);

    instrDesc   *   scInsOfDef   (schedDef_tp  def);
    instrDesc   *   scInsOfUse   (schedUse_tp  use);

    void            scAddUse     (schedUse_tp *usePtr,
                                  scDagNode   *node);
    void            scClrUse     (schedUse_tp *usePtr);

    emitRegs        scSpecInsDep (instrDesc   *id,
                                  scDagNode   *dagDsc,
                                  scExtraInfo *xptr);

    void            scSpecInsUpd (instrDesc   *id,
                                  scDagNode   *dagDsc,
                                  scExtraInfo *xptr);

    enum    scDepKinds
    {
        SC_DEP_NONE,
        SC_DEP_FLOW,
        SC_DEP_ANTI,
        SC_DEP_OUT,
    };

#ifdef  DEBUG

    static
    const   char *  scDepNames[];   // keep in sync with the above enum!

#else

    #define         scAddDep(src,dst,kind,dagn) scAddDep(src,dst,kind)

#endif

    void            scAddDep(scDagNode   *src,
                             scDagNode   *dst,
                             scDepKinds   depKind, const char *dagName);

    schedDef_tp     scRegDef[REG_COUNT];
    schedUse_tp     scRegUse[REG_COUNT];

    schedDef_tp     scIndDef[5];            // 8-bit/16-bit/32-bit/64-bit/GCref
    schedUse_tp     scIndUse[5];            // 8-bit/16-bit/32-bit/64-bit/GCref

#if TGT_IA64

    schedDef_tp     scPRrDef[64];
    schedUse_tp     scPRrUse[64];

    schedDef_tp     scAPrDef[1];            // we only track ar.lc for now
    schedUse_tp     scAPrUse[1];            // we only track ar.lc for now

    schedDef_tp     scBRrDef[8];
    schedUse_tp     scBRrUse[8];

#else

    schedDef_tp   * scFrmDef;               // frame value def table
    schedUse_tp   * scFrmUse;               // frame value use table
    unsigned        scFrmUseSiz;            // frame value     table size

#endif

    schedDef_tp     scGlbDef;
    schedUse_tp     scGlbUse;

    scDagNode    *  scExcpt;                // most recent exceptional ins node

    scTgtDepDcl();                          // declare target-specific members

    /*
        Dependencies on flags are handled in a special manner, as we
        want to avoid creating tons of output dependencies for nodes
        that set flags but those flags are never used (which happens
        all the time). Instead, we do the following (note that we
        walk the instructions backward when constructing the dag):

            When an instruction that consumes flags is found (which
            is relativel rare), we set 'scFlgUse' to this node. The
            next instruction we encounter that sets the flags will
            have a flow dependency added and it will be recorded in
            'scFlgDef'. Any subsequent instruction that sets flags
            will have an output dependency on 'scFlgDef' which will
            prevent incorrect ordering.

            There is only one problem - when we encounter another
            instruction that uses flags, we somehow need to add
            anti-dependencies for all instructions that set flags
            which we've already processed (i.e. those that follow
            the flag-consuming instruction in the initial order).
            Since we don't want to keep a table of these nodes we
            simply walk the nodes we've already added and add the
            dependencies that way.
     */

#if SCHED_USE_FL

    bool            scFlgEnd;               // must set flags at end of group
    scDagNode   *   scFlgUse;               // last node consuming flags
    scDagNode   *   scFlgDef;               // node defining flags for above

#endif

    /*----------------------------------------------------------------------*/

#ifndef DEBUG
    #define         scDepDef(node,name,def,use,anti) scDepDef(node,def,use,anti)
    #define         scDepUse(node,name,def,use)      scDepUse(node,def,use     )
#endif

    void            scDepDef          (scDagNode   *node,
                                       const char  *name,
                                       schedDef_tp  def,
                                       schedUse_tp  use,
                                       bool         antiOnly);
    void            scDepUse          (scDagNode   *node,
                                       const char  *name,
                                       schedDef_tp  def,
                                       schedUse_tp  use);

    void            scUpdDef          (scDagNode   *node,
                                       schedDef_tp *defPtr,
                                       schedUse_tp *usePtr);
    void            scUpdUse          (scDagNode   *node,
                                       schedDef_tp *defPtr,
                                       schedUse_tp *usePtr);

    /*----------------------------------------------------------------------*/

#if SCHED_USE_FL

    void            scDepDefFlg       (scDagNode   *node);
    void            scDepUseFlg       (scDagNode   *node,
                                       scDagNode   *begp,
                                       scDagNode   *endp);
    void            scUpdDefFlg       (scDagNode   *node);
    void            scUpdUseFlg       (scDagNode   *node);

#endif

    /*----------------------------------------------------------------------*/

    void            scDepDefReg       (scDagNode   *node,
                                       emitRegs    reg);
    void            scDepUseReg       (scDagNode   *node,
                                       emitRegs    reg);
    void            scUpdDefReg       (scDagNode   *node,
                                       emitRegs    reg);
    void            scUpdUseReg       (scDagNode   *node,
                                       emitRegs    reg);

    /*----------------------------------------------------------------------*/

#if TGT_IA64

    struct  scStkDepDsc
    {
        scStkDepDsc *   ssdNext;
        size_t          ssdOffs;

        schedDef_tp     ssdDef;
        schedUse_tp     ssdUse;
    };

    scStkDepDsc * * scStkDepHashAddr;
    scStkDepDsc *   scStkDepHashFree;

#define scStkDepHashSize  7
#define scStkDepHashBytes (scStkDepHashSize * sizeof(*scStkDepHashAddr))

    void            scStkDepInit()
    {
        scStkDepHashAddr = (scStkDepDsc**)emitGetMem(scStkDepHashBytes);
        scStkDepHashFree = NULL;

        memset(scStkDepHashAddr, 0, scStkDepHashBytes);
    }

    void            scStkDepBegBlk()
    {
#ifdef  DEBUG
        for (unsigned hval = 0; hval < scStkDepHashSize; hval++) assert(scStkDepHashAddr[hval] == 0);
#endif
    }

    void            scStkDepEndBlk();

    scStkDepDsc *   scStkDepDesc      (Compiler::LclVarDsc *varDsc);

    typedef
    scStkDepDsc *   scStkDepRTP;

#else

    unsigned        scStkDepIndex     (instrDesc   *id,
                                       int          ebpLo,
                                       unsigned     ebpFrmSz,
                                       int          espLo,
                                       unsigned     espFrmSz,
                                       size_t      *opCntPtr);

    typedef
    unsigned        scStkDepRTP;

#endif

#ifndef DEBUG
    #define         scDepDefFrm(node,id,frm) scDepDefFrm(node,frm)
    #define         scDepUseFrm(node,id,frm) scDepUseFrm(node,frm)
#endif

    void            scDepDefFrm       (scDagNode   *node,
                                       instrDesc   *id,
                                       scStkDepRTP  frm);
    void            scDepUseFrm       (scDagNode   *node,
                                       instrDesc   *id,
                                       scStkDepRTP  frm);
    void            scUpdDefFrm       (scDagNode   *node,
                                       scStkDepRTP  frm);
    void            scUpdUseFrm       (scDagNode   *node,
                                       scStkDepRTP  frm);

    /*----------------------------------------------------------------------*/

    static
    unsigned        scIndDepIndex(instrDesc   *id);

    void            scDepDefInd       (scDagNode   *node,
                                       unsigned     am);
    void            scDepUseInd       (scDagNode   *node,
                                       unsigned     am);
    void            scUpdDefInd       (scDagNode   *node,
                                       unsigned     am);
    void            scUpdUseInd       (scDagNode   *node,
                                       unsigned     am);

    /*----------------------------------------------------------------------*/

    void            scDepDefGlb       (scDagNode   *node,
                                       FIELD_HANDLE MBH);
    void            scDepUseGlb       (scDagNode   *node,
                                       FIELD_HANDLE MBH);
    void            scUpdDefGlb       (scDagNode   *node,
                                       FIELD_HANDLE MBH);
    void            scUpdUseGlb       (scDagNode   *node,
                                       FIELD_HANDLE MBH);

    /*----------------------------------------------------------------------*/

#if TGT_IA64

    unsigned        scInsSchedOpInfo  (instrDesc   *id)
    {
        UNIMPL("");
        return  0;
    }

#else

    static
    unsigned        scFmtToISops[];

#ifdef  DEBUG
    static
    unsigned        scFmtToIScnt;
#endif

    unsigned        scInsSchedOpInfo  (instrDesc   *id)
    {
        assert((unsigned)id->idInsFmt < scFmtToIScnt);
        return  scFmtToISops[id->idInsFmt];
    }

#endif

    /*----------------------------------------------------------------------*/
    /*             Other members/methods used scheduling                    */
    /*----------------------------------------------------------------------*/

    void            scInsNonSched     (instrDesc   *id = NULL);

    int             scGetFrameOpInfo  (instrDesc   *id,
                                       size_t      *szp,
                                       bool        *ebpPtr);

    bool            scIsSchedulable   (instruction ins);
    bool            scIsSchedulable   (instrDesc   *id);

    bool            scIsBranchIns     (instruction ins);
    bool            scIsBranchIns     (scDagNode * node);

#if TGT_IA64

    static
    templateDsc *   scIA64tmpTab_M;
    static
    templateDsc *   scIA64tmpTab_B;

    templateDsc *   scIssueTmpPtr;
    NatUns          scIssueTmpNum;
    bool            scIssueTmpSwp;

    void            scIssueTmpUpdate(templateDsc *nxt);

    static
    BYTE            scIssueFnMax [XU_COUNT];

    // The following holds the number of executing units busy with previous
    // instructions (we only use the F,I,M entries).

    BYTE            scIssueFnBusy[XU_COUNT];

    bool            scSwapOK(scDagNode *node)
    {
        if  (scIssueTmpSwp)
        {
            assert((scIssueCnt % 3) == 2);

            if  (scRlstCurTime > scRlstBegTime)
                return  false;
        }

        return  true;
    }

    IA64execUnits   scCheckTemplate(insPtr id, bool update,
                                               bool noSwap   = false,
                                               bool needStop = false);

    BYTE            scIssueTmp[MAX_ISSUE_CNT/3];
    BYTE            scIssueSwp[MAX_ISSUE_CNT/3];
    scIssueDsc      scIssueTab[MAX_ISSUE_CNT];
    scIssueDsc  *   scIssueNxt;
    NatUns          scIssueCnt;
    NatUns          scIssueTcc;

    void            scIssueAdd(insPtr ins);

    void            scIssueClr(bool complete)
    {
        scIssueTmpPtr  = NULL;
        scIssueTmpNum  = 0;
        scIssueTmpSwp  = false;

        scRlstBegTime  = scRlstCurTime;

        if  (complete)
        {
            scIssueNxt = scIssueTab;
            scIssueCnt = 0;
            scIssueTcc = 0;

            memset(scIssueFnBusy, 0, sizeof(scIssueFnBusy));
        }
    }

#if!MAX_BRANCH_DELAY_LEN
    #define         scGroup(ig,ni,nc,bp,ep,bl)                  \
                    scGroup(ig,ni,nc,bp,ep)
#endif

    void            scGroup           (insGroup    *ig,
                                       instrDesc * *ni,
                                       NatUns       nc,
                                       instrDesc * *begPtr,
                                       instrDesc * *endPtr,
                                       unsigned     bdLen);

#else

#if!MAX_BRANCH_DELAY_LEN
    #define         scGroup(ig,ni,dp,bp,ep,fl,fh,sl,sh,bl)      \
                    scGroup(ig,ni,dp,bp,ep,fl,fh,sl,sh)
#endif

    void            scGroup           (insGroup    *ig,
                                       instrDesc   *ni,
                                       BYTE *      *dp,
                                       instrDesc * *begPtr,
                                       instrDesc * *endPtr,
                                       int          fpLo,
                                       int          fpHi,
                                       int          spLo,
                                       int          spHi,
                                       unsigned     bdLen);

#endif

    void            scPrepare();

#else //SCHEDULER

    void            scPrepare() {}

#endif//SCHEDULER
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\sched.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                             sched.cpp                                     XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

#include "alloc.h"
#include "instr.h"
#include "emit.h"
#include "target.h"

#if     TGT_IA64
#include "loginstr.h"
#endif

/*****************************************************************************/
#if     SCHEDULER
/*****************************************************************************/

#if     0
#define VERBOSE 1
#else
#define VERBOSE verbose
#endif

/*****************************************************************************/

#define MAX_NORMAL_DAG_HEIGHT   1000        // don't make this more than 4500

/*****************************************************************************/
#ifdef  DEBUG

const bool NO_REAL_SCHED = false;           // preserves instruction order
const bool MAXIMUM_SCHED = false;           // max. movement (for testing)

#endif
/*****************************************************************************/
#if 0

    for each block
    {
        build the dag for an extended basic block; initialize the ready list

        while (ready-list is not empty)
        {
            for (;;)
            {
                from ready-list, pick an instruction in priority order which
                   (1) has the required function unit available
                   (2) and fits into the current template

                if  (fail to find one)
                {
                    if  (stop-bit available)
                    {
                        consume stop-bit in template
                        continue;
                    }

                    choose a NOP for the current template
                }
                else
                {
                    if  ("A" instruction)
                        choose M or I for it by looking ahead the ready list

                    resolve instruction's out-going dependence(s) and update ready-list
                }

                if  (end of issue window or a must-split template)
                    break;
            }

            schedule the issued instructions (up to 6 for Merced)
        }
    }

#endif

/*****************************************************************************
 *
 *  Make sure to keep the following in sync with the enum declaration.
 */

#ifdef  DEBUG

const   char    *   emitter::scDepNames[] =
{
    NULL,   // SC_DEP_NONE
    "Flow", // SC_DEP_FLOW
    "Anti", // SC_DEP_ANTI
    "Out-", // SC_DEP_OUT
};

#endif
/*****************************************************************************
 *
 *  Prepare for scheduling the current method.
 */

void                emitter::scPrepare()
{
    /* Are we supposed to do instruction scheduling ? */

    if  (!emitComp->opts.compSchedCode)
        return;

#if EMITTER_STATS
    scdCntTable.histoRec(emitMaxIGscdCnt, 1);
#endif

#if TGT_x86

    /* Make sure the 'depmap' type matches the max. instruction count */

    assert(8*sizeof(schedDepMap_tp) == SCHED_INS_CNT_MAX);

    /* Make sure all the "IS_xx" values are different */

    assert(IS_R1_RD  != IS_R1_WR );
    assert(IS_R1_WR  != IS_R2_RD );
    assert(IS_R2_RD  != IS_R2_WR );
    assert(IS_R2_WR  != IS_SF_RD );
    assert(IS_SF_RD  != IS_SF_WR );
    assert(IS_SF_WR  != IS_GM_RD );
    assert(IS_GM_RD  != IS_GM_WR );
    assert(IS_GM_WR  != IS_AM_RD );
    assert(IS_AM_RD  != IS_AM_WR );
    assert(IS_AM_WR  != IS_FP_STK);
    assert(IS_FP_STK !=         0);

#else

    // UNDONE: need equivalent RISC asserts

#endif

    /* There is an upper limit on how many instructions we can handle */

    if  (emitMaxIGscdCnt > SCHED_INS_CNT_MAX)
         emitMaxIGscdCnt = SCHED_INS_CNT_MAX;

    /* We have not allocated the frame def/use tables yet */

#if !   TGT_IA64

#ifdef  DEBUG
    scFrmDef    = NULL;
    scFrmUse    = NULL;
#endif
    scFrmUseSiz = 0;

#endif

#if     USE_LCL_EMIT_BUFF

    size_t          space;
    unsigned        count;

    /* Is there any unused space at the end of the local buffer? */

    space = emitLclAvailMem();

    /* Compute how many entries we might be able to get */

    count = roundDn(space / (sizeof(*scFrmDef) + sizeof(*scFrmUse)));

    if  (count > 1)
    {
        /* Let's not get too greedy ... */

        count = min(count, SCHED_FRM_CNT_MAX);

        /* Grab the space for the two frame tracking tables */

        scFrmUseSiz = count;
        scFrmDef    = (schedDef_tp*)emitGetAnyMem(count*sizeof(*scFrmDef)); assert(scFrmDef);
        scFrmUse    = (schedUse_tp*)emitGetAnyMem(count*sizeof(*scFrmUse)); assert(scFrmUse);
    }

#endif

    /* Initialize the stack frame hashing/tracking logic */

#if TGT_IA64
    scStkDepInit();
#endif

    /* Allocate the instruction table */

    scInsTab = (instrDesc**)emitGetAnyMem(emitMaxIGscdCnt*sizeof(*scInsTab));
    scInsMax = scInsTab + emitMaxIGscdCnt;

    /* Allocate the dag node    table */

    scDagTab = (scDagNode *)emitGetAnyMem(emitMaxIGscdCnt*sizeof(*scDagTab));

    /* We haven't allocated any "use" entries yet */

    scUseOld = NULL;
}

/*****************************************************************************/
#ifdef  DEBUG
/*****************************************************************************
 *
 *  Display the current state of the scheduling dag.
 */

void                emitter::scDispDag(bool noDisp)
{
    unsigned        num;
    scDagNode    *  node;

    unsigned        pcnt[SCHED_INS_CNT_MAX];

    memset(&pcnt, 0, sizeof(pcnt));

    if  (!noDisp) printf("Scheduling dag [%02u nodes]:\n", scInsCnt);

    for (num = 0, node = scDagTab;
         num < scInsCnt;
         num++  , node++)
    {
        bool            ready;

        unsigned        depn;
        scDagNode    *  depp;
        unsigned        deps;

        scDagNode    *  temp;

        if  (!noDisp)
        {
            /* Figure out whether the node is on the "ready" list */

            ready = false;
            for (temp = scReadyList; temp; temp = temp->sdnNext)
            {
                if  (temp == node)
                {
                    ready = true;
                    break;
                }
            }

            printf("%c", node->sdnIssued ? 'I' : ' ');
            printf("%c", ready           ? 'R' : ' ');

#if TGT_IA64
            printf(" EET=%u", node->sdnEEtime);
#endif

            printf(" %02u:"  , num);
//          printf(" dep=%016I64X", node->sdnDepsAll);
            printf(" H=%03u ", node->sdnHeight);
            printf(" %03uP", node->sdnPreds);
        }

        for (depn = 0, depp = scDagTab, deps = 0;
             depn < scInsCnt;
             depn++  , depp++)
        {
            if  (scDagTestNodeP(node->sdnDepsAll, depp))
            {
                if  (!noDisp)
                {
                    if  (!deps)
                        printf(" Deps:");

                    printf(" %u", depp->sdnIndex);

#if TGT_IA64
                    if  (scDagTestNodeP(node->sdnDepsAnti, depp))
                        printf("A");
                    if  (scDagTestNodeP(node->sdnDepsMore, depp))
                        printf("*");
#endif

                    if  (scDagTestNodeP(node->sdnDepsFlow, depp))
                        printf("F");
                }

                deps++; pcnt[depp->sdnIndex]++;
            }
        }

        if  (!noDisp)
        {
            printf("\n");
            emitDispIns(scGetIns(node), false, false, true);
            printf("\n");
        }

        assert(node->sdnIndex == num);
    }

    for (num = 0; num < scInsCnt; num++)
    {
        if  (pcnt[num] != scDagTab[num].sdnPreds)
        {
            printf("ERROR: predecessor count wrong for ins #%u:", num);
            printf(" %u (expected %u)\n", scDagTab[num].sdnPreds, pcnt[num]);
        }

        assert(pcnt[num] == scDagTab[num].sdnPreds);
    }
}

/*****************************************************************************/
#endif//DEBUG
/*****************************************************************************
 *
 *  This method is called when the instruction being added cannot participate
 *  in instruction scheduling (or we're at the end of a schedulable group) to
 *  perform the necessary book-keeping.
 */

#if!TGT_IA64

void                emitter::scInsNonSched(instrDesc *id)
{
    unsigned        scdCnt;
    unsigned        begOfs;
    unsigned        endOfs;
    instrDescJmp  * jmpTmp;

    size_t          extras = 0;

    /* Figure out how many instructions are in this group */

    scdCnt = emitCurIGinsCnt - emitCurIGscd1st; assert((int)scdCnt >= 0);

    /* Did we just add a non-schedulable instruction? */

    if  (id)
    {
        extras = emitInstCodeSz(id);

        /* Don't include the added instruction in the total count */

        assert(scdCnt > 0); scdCnt--;
    }

    /* Keep track of the max. schedulable instruction count */

    if  (emitMaxIGscdCnt < scdCnt)
         emitMaxIGscdCnt = scdCnt;

    /* Compute the code offset range of the group */

    begOfs = emitCurIGscdOfs;
    endOfs = emitCurIGsize + extras;

//  printf("%2u schedulable instrs (max=%02u), offs = [%03X..%04X]\n", scdCnt, scMaxIGscdCnt, begOfs, endOfs);

    /* Fill in the offset range for any jumps within the group */

    for (jmpTmp = emitCurIGjmpList; jmpTmp; jmpTmp = jmpTmp->idjNext)
    {
        assert(jmpTmp->idjOffs < endOfs);

        if  (jmpTmp->idjOffs < begOfs)
            break;

//      printf("Schedulable jump #%02u: offset range is %04X..%04X\n", jmpTmp->idNum, begOfs, endOfs);

        jmpTmp->idjTemp.idjOffs[0] = begOfs;
        jmpTmp->idjTemp.idjOffs[1] = endOfs;
    }

    emitCurIGscd1st = emitCurIGinsCnt;
    emitCurIGscdOfs = endOfs;
}

#endif

/*****************************************************************************
 *
 *  Compute the latency between the given node and its successor (i.e. return
 *  the estimated number of cycles that will elapse between the beginning of
 *  execution of 'node' and that of 'succ'). Note that 'succ' will be NULL to
 *  indicate that the following instruction is not known.
 */

inline
unsigned            emitter::scLatency(scDagNode *node, scDagNode *succ,
                                                        NatUns    *minLatPtr)
{
    unsigned        latency = 1;
    NatUns          minLat  = 0;

    assert(node);

#if MAX_BRANCH_DELAY_LEN

    if  (scIsBranchIns(node))
        latency += Compiler::instBranchDelayL(scGetIns(node)->idIns);

#endif

#if TGT_IA64

    insPtr          ins = scGetIns(node);

    if  (succ)
    {
        assert(scDagTestNodeP(node->sdnDepsAll, succ));

        /* Special case: anti-dep (only) has a min. latency of 0 */

        if  (scDagTestNodeP(node->sdnDepsAnti, succ) != 0 &&
             scDagTestNodeP(node->sdnDepsFlow, succ) == 0 &&
             scDagTestNodeP(node->sdnDepsMore, succ) == 0)
        {
#if 0
            printf("========== lat0\n");
            printf("Node: "); emitDispIns(scGetIns(node), false, false, true);
            printf("Succ: "); emitDispIns(scGetIns(succ), false, false, true);
            printf("========== lat0\n");
#endif
        }
        else
        {
            minLat = 1;

            /* Make sure "alloc" always gets scheduled first */

            if  (ins->idIns == INS_alloc)
                latency = 9999;
        }
    }

#endif

DONE:

    if  (minLatPtr)
        *minLatPtr = minLat;

    return  latency;
}

/*****************************************************************************
 *
 *  Recursive method to compute the "dag height" of a given node.
 */

unsigned            emitter::scGetDagHeight(scDagNode *node)
{
    unsigned        height = node->sdnHeight;

    /* Have we computed the height of this node already? */

    if  (!height)
    {
        /* Compute the max. height + latency of all successors */

        if  (schedDepIsZero(node->sdnDepsAll))
        {
            /* This a leaf node (no successors) */

            height = scLatency(node);
            goto REC;
        }

        height = 1;

        scWalkSuccDcl(temp)

        scWalkSuccBeg(temp, node)
        {
            scDagNode   *   succ = scWalkSuccCur(temp);
            unsigned        shgt = succ->sdnHeight;

            if  (!shgt)
                shgt = scGetDagHeight(succ);

            shgt += scLatency(node, succ);

            if  (height < shgt)
                 height = shgt;
        }
        scWalkSuccEnd(temp)

        if  (height > MAX_NORMAL_DAG_HEIGHT - 100 && height != 9999)
             height = MAX_NORMAL_DAG_HEIGHT - 100;

    REC:

#if TGT_IA64

        /* Give M/I precedence over A (the latter are easier to place) */

//      if  ((int)node == 0x02be1284) __asm int 3

        if  (height < 9999)
        {
            insPtr          ins = scGetIns(node);

            // CONSIDER: boost instructions that can only execute in F0/I0/M0

            switch (genInsXU(ins->idInsGet()))
            {
            case XU_A:
                break;

            case XU_M:

//              printf("Promoting [M] %u", height);

                height += height / 2 + (height == 1);

                if  (height > MAX_NORMAL_DAG_HEIGHT - 100)
                     height = MAX_NORMAL_DAG_HEIGHT - 100;

//              printf(" -> %u: ", height);
//              emitDispIns(ins, false, false, true);

                /* HACK: make sure "alloc" is always scheduled first */

                if  (ins->idIns == INS_alloc)
                    height = 9999;

                break;

            default:

//              printf("Promoting [*] %u", height);

                height += height / 3 + (height == 1);

                if  (height > MAX_NORMAL_DAG_HEIGHT - 100)
                     height = MAX_NORMAL_DAG_HEIGHT - 100;

//              printf(" -> %u: ", height);
//              emitDispIns(ins, false, false, true);

                break;
            }
        }

#endif

        /* Record the height in the node, making sure no precision is lost */

        node->sdnHeight = height; assert(node->sdnHeight == height && height <= 9999);
    }

    assert(height < MAX_NORMAL_DAG_HEIGHT || height == 9999);

    return  height;
}

/*****************************************************************************
 *
 *  Define operand info for each instruction.
 */

#if!TGT_IA64

unsigned            emitter::scFmtToISops[] =
{
    #define IF_DEF(en, op1, op2) op1,
    #include "emitfmts.h"
    #undef  IF_DEF
};

#ifdef  DEBUG
unsigned            emitter::scFmtToIScnt = sizeof(scFmtToISops)/sizeof(scFmtToISops[0]);
#endif

#endif

/*****************************************************************************/
#if     TGT_IA64
/*****************************************************************************
 *
 *  Convert a frame variable reference into a scheduling frame index.
 */

emitter::scStkDepDsc*emitter::scStkDepDesc(Compiler::LclVarDsc *varDsc)
{
    size_t          offs;
    unsigned        hval;
    scStkDepDsc *   desc;

    assert(varDsc->lvOnFrame);

    /* Get hold of the variable's offset */

    offs = varDsc->lvStkOffs;

    /* Compute the hash function */

    hval = offs % scStkDepHashSize; assert(hval < scStkDepHashSize);

    /* Look for an existing entry in the hash table */

    for (desc = scStkDepHashAddr[hval]; desc; desc = desc->ssdNext)
    {
        if  (desc->ssdOffs == offs)
            return  desc;
    }

    /* Variable not found, create a new entry */

    if  (scStkDepHashFree)
    {
        desc = scStkDepHashFree;
               scStkDepHashFree = desc->ssdNext;
    }
    else
    {
        desc = (scStkDepDsc*)emitGetMem(sizeof(*desc));
    }

    desc->ssdOffs = offs;

    desc->ssdNext = NULL;

    desc->ssdDef  = NULL;
    desc->ssdUse  = NULL;

    return  desc;
}

void                emitter::scStkDepEndBlk()
{
    unsigned        hval;

    for (hval = 0; hval < scStkDepHashSize; hval++)
    {
        scStkDepDsc *   desc = scStkDepHashAddr[hval];

        if  (desc)
        {
            do
            {
                scStkDepDsc *   next;

                next = desc->ssdNext;
                       desc->ssdNext = scStkDepHashFree;
                                       scStkDepHashFree = desc;

                desc = next;
            }
            while (desc);
        }
    }
}

/*****************************************************************************/
#else //TGT_IA64
/*****************************************************************************
 *
 *  Convert a frame variable reference into a scheduling frame index. Also
 *  returns the count of referenced items in "*opCntPtr".
 */

unsigned            emitter::scStkDepIndex(instrDesc*id,
                                           int       ebpLo,
                                           unsigned  ebpFrmSz,
                                           int       espLo,
                                           unsigned  espFrmSz,
                                           size_t   *opCntPtr)
{
    int             ofs;
    bool            ebp;

    /* Get the frame location for the variable */

    ofs = scGetFrameOpInfo(id, opCntPtr, &ebp);

    if  (ebp)
    {
        assert(ebpLo                 <= ofs);
        assert(ebpLo + (int)ebpFrmSz >  ofs);

        return  ofs - ebpLo;
    }
    else
    {
        assert(espLo                 <= ofs);
        assert(espLo + (int)espFrmSz >  ofs);

        return  ofs - espLo + ebpFrmSz;
    }
}

/*****************************************************************************/
#endif//TGT_IA64
/*****************************************************************************/

#ifdef  DEBUG

const   char    *   indDepIndex2string(unsigned amx)
{
    static
    const   char*   indNames[] =
    {
        "[08-bit]",
        "[16-bit]",
        "[32-bit]",
        "[64-bit]",
#if TRACK_GC_REFS
        "[GC-ref]",
#endif
    };

    assert(amx < sizeof(indNames)/sizeof(indNames[0]));

    return  indNames[amx];
}

#endif

/*****************************************************************************
 *
 *  Grab an available "use" entry.
 */

inline
emitter::schedUse_tp  emitter::scGetUse()
{
    schedUse_tp     use;

    if  (scUseOld)
    {
        use = scUseOld;
              scUseOld = use->sdlNext;
    }
    else
    {
        use = (schedUse_tp)emitGetAnyMem(sizeof(*use));
    }

    return  use;
}

/*****************************************************************************
 *
 *  Relase the given "use" entry, it's no longer needed.
 */

inline
void                emitter::scRlsUse(schedUse_tp use)
{
    use->sdlNext = scUseOld;
                   scUseOld = use;
}

/*****************************************************************************
 *
 *  Add the given dag node to the list of "use" entries at *usePtr.
 */

void                emitter::scAddUse(schedUse_tp *usePtr, scDagNode *node)
{
    schedUse_tp     use = scGetUse();

    use->sdlNode = node;
    use->sdlNext = *usePtr;
                   *usePtr = use;
}

/*****************************************************************************
 *
 *  Free up all the "use" entries at *usePtr.
 */

void                emitter::scClrUse(schedUse_tp *usePtr)
{
    schedUse_tp     use = *usePtr;

    while (use)
    {
        schedUse_tp     nxt = use->sdlNext;
        scRlsUse(use);
        use = nxt;
    }

    *usePtr = NULL;
}

/*****************************************************************************
 *
 *  Record a dependency of "dst" on "src" of the given type.
 */

void                emitter::scAddDep(scDagNode  *   src,
                                      scDagNode  *   dst,
                                      scDepKinds     depKind,
                                      const char *   dagName)
{
    schedDepMap_tp  dep = scDagNodeP2mask(dst);

    /* Do we already have a dependency between the nodes? */

    if  (!scDagTestNodeP(src->sdnDepsAll, dst))
    {
        /* This is a new dependency */

        scDagSet_NodeP(&src->sdnDepsAll, dst);

        /* The target node now has one more dependency */

        dst->sdnPreds++;

#ifdef  DEBUG
        if (VERBOSE) printf("    [%sDep] on %-8s refd at #%u\n", scDepNames[depKind], dagName, dst->sdnIndex);
#endif
    }

    /* Record a flow dependency if appropriate */

    switch (depKind)
    {
    case SC_DEP_FLOW:
        scDagSet_NodeP(&src->sdnDepsFlow, dst);
        break;

#if TGT_IA64

    case SC_DEP_ANTI:
        scDagSet_NodeP(&src->sdnDepsAnti, dst);
        break;

    default:
        scDagSet_NodeP(&src->sdnDepsMore, dst);
        break;

#endif

    }
}

/*****************************************************************************
 *
 *  Record a dependency for an instruction that defs the given indirection.
 */

inline
void                emitter::scDepDefInd(scDagNode   *node,
                                         unsigned     am)
{
    assert(am < sizeof(scIndUse));
    scDepDef(node, indDepIndex2string(am), scIndDef[am], scIndUse[am], false);
}

/*****************************************************************************
 *
 *  Record a dependency for an instruction that uses the given indirection.
 */

inline
void                emitter::scDepUseInd(scDagNode   *node,
                                         unsigned     am)
{
    assert(am < sizeof(scIndUse));
    scDepUse(node, indDepIndex2string(am), scIndDef[am], scIndUse[am]);
}

/*****************************************************************************
 *
 *  Pick the best ready instruction node to be issued next.
 */

emitter::scDagNode* emitter::scPickNxt(scPick pick)
{
    scDagNode   * * lptr;
    scDagNode   *   node;

#ifdef  DEBUG

    assert(pick == PICK_SCHED || pick == PICK_NO_SCHED);

    if  (NO_REAL_SCHED)
        pick = PICK_NO_SCHED;
    else if (MAXIMUM_SCHED && pick == PICK_SCHED)
        pick = PICK_MAX_SCHED;

    if (pick != PICK_SCHED)
    {
        scDagNode   *   minp;               // node with min. instruction index
        unsigned        minx = (pick == PICK_MAX_SCHED) ? 0 : INT_MAX;
        scDagNode   * * minl;

        /*
            Walk the list of nodes that are ready to be issued, and pick
            the one that has min. instruction index. Doing this will have
            the effect that instructions will be issued in the same exact
            order as they appear in the original sequence.
         */

        for (lptr = &scReadyList; true; /**/)
        {
            /* Get the next node and stop if we're at the end of the list */

            node = *lptr;
            if  (!node)
                break;

#if MAX_BRANCH_DELAY_LEN

            /* Make sure this is not a branch instruction that isn't ready */

            if  (scIsBranchTooEarly(node))
                goto NEXT1;

#endif

#if TGT_IA64

            /* Make sure the instruction can fit in the current template */

            UNIMPL("check for template fit");

#endif

            /* Compare the new node against the current best */

            bool betterChoice = (pick == PICK_MAX_SCHED) ? (minx <= node->sdnIndex)
                                                         : (minx  > node->sdnIndex);
            if (betterChoice)
            {
                /* This node looks best so far, remember it */

                minx = node->sdnIndex;
                minp = node;
                minl = lptr;
            }

#if MAX_BRANCH_DELAY_LEN
        NEXT1:
#endif

            /* Move on to the next node in the "ready" list */

            lptr = &node->sdnNext;
        }

        assert(minl && *minl == minp && minp->sdnIndex == minx);

        /* Remove the node from the "ready" list and return it */

        *minl = minp->sdnNext;

        return  minp;
    }

#endif

    scDagNode   *   mxap;               // node with max. height
    unsigned        mxax = 0;
    scDagNode   * * mxal;

    scDagNode   *   mxfp;               // node with max. height + no flow-dep
    unsigned        mxfx = 0;
    scDagNode   * * mxfl;

    schedDepMap_tp  flow;

#ifdef  DEBUG
//  static int x; if (++x == 0) BreakIfDebuggerPresent();
#endif

    /*
        Walk the list of nodes that are ready to be issued, and pick
        the one that has max. height, preferring a node that doesn't
        have a dependency on the node we issued last.
     */

    schedDepClear(&flow);

    if  (scLastIssued)
        flow = scLastIssued->sdnDepsFlow;

    for (lptr = &scReadyList; true; /**/)
    {
        unsigned        hgt;

        /* Get the next node and stop if we're at the end of the list */

        node = *lptr;
        if  (!node)
            break;

        /* Make sure the EE time has been set to something reasonable */

        assert((unsigned short)node->sdnEEtime != 0xCCCC);

        /* Get the height of the current node */

        hgt = node->sdnHeight; assert(hgt);

        /* The restricted max. height should never exceed the overall one */

        assert(mxfx <= mxax);

        /* Does this node look like a potential candidate? */

        if  (hgt > mxfx)
        {

#if MAX_BRANCH_DELAY_LEN

            /* Make sure this is not a branch instruction that isn't ready */

            if  (scIsBranchTooEarly(node))
                goto NEXT2;

#endif

#if TGT_IA64

            insPtr          ins;

            bool            stp;
            bool            swp;

            /* Make sure the instruction can fit in the current template */

            ins = scGetIns(node);

            /* See if we need to insert a stop bit before the instruction */

            stp = (node->sdnEEtime > scCurrentTime);

            /*
                Determine whether this instruction can go into the next
                slot - if we are in a "swapped" part of a template, and
                the instruction just became ready (because of an earlier
                instruction within the same group) we can't use it.
             */

            swp = scSwapOK(node);

#if 0
            printf("EET=%u,cur=%u: ", node->sdnEEtime, scCurrentTime);
            emitDispIns(ins, false, false, true);
#endif

//          if  (ins->idNum == 30) BreakIfDebuggerPresent();

            if  (scCheckTemplate(ins, false, swp, stp) == XU_N)
                goto NEXT2;

            /* Penalize an instruction that requires a stop bit */

            if  (stp)
                hgt -= hgt / 2;

            /* Promote FP instructions, precious few "F" slots are available */

            if  (genInsXU(ins->idInsGet()) == XU_F)
                hgt *= 2;

#endif

//          printf("[%c] node #%02u height = %u\n", scDagTestNodeP(flow, node) ? 'F' : 'N', node->sdnIndex, hgt);

#if!TGT_IA64

            /* Is there a flow dependency on the node issued last? */

            if  (scDagTestNodeP(flow, node))
                goto FLOW_DEP;

#endif

            /* Compare against the current non-flow-dep max */

            if  (hgt > mxfx)
            {
                mxfx = hgt;
                mxfp = node;
                mxfl = lptr;
            }

        FLOW_DEP:

            /* Is the height higher than the overall best so far? */

            if  (hgt > mxax)
            {
                mxax = hgt;
                mxap = node;
                mxal = lptr;
            }
        }

#if MAX_BRANCH_DELAY_LEN || TGT_IA64
    NEXT2:
#endif

        /* Move on to the next node in the "ready" list */

        lptr = &node->sdnNext;
    }

#if TGT_IA64
    assert(mxax == 0 || *mxal == mxap);
    assert(mxfx == 0 || *mxfl == mxfp);
#else
    assert(mxax != 0 && *mxal == mxap && mxap->sdnHeight == mxax);
    assert(mxfx == 0 || *mxfl == mxfp && mxfp->sdnHeight == mxfx);
#endif

//  printf("Max. non-dep height node is #%02d = %03u\n", mxfx ? mxfp->sdnIndex : -1, mxfx);
//  printf("Max.   any   height node is #%02d = %03u\n", mxax ? mxap->sdnIndex : -1, mxax);

    /* Always give non-flow-dep nodes precedence */

    if  (mxfx)
    {
        /* Remove the node from the "ready" list and return it */

#ifdef  DEBUG
        if  (VERBOSE)
        {
            printf("Picked nonFlow node #%02u [H=%03u]: ", mxfp->sdnIndex, mxfx);
            emitDispIns(scGetIns(mxfp), false, false, true);
        }
#endif

        *mxfl = mxfp->sdnNext;

//  if  (mxfp->sdnIndex == 8) BreakIfDebuggerPresent();
//  if  (mxfp->sdnIndex == 4 && scGetIns(mxfp)->idIns == INS_shladd) BreakIfDebuggerPresent();

#if TGT_IA64
        scCheckTemplate(scGetIns(mxfp), true, false, (mxfp->sdnEEtime > scCurrentTime));
#endif

        return  mxfp;
    }
    else
    {

#if TGT_IA64
        if  (!mxax)
            return  NULL;
#endif

        /* Remove the node from the "ready" list and return it */

#ifdef  DEBUG
        if  (VERBOSE)
        {
            printf("Picked flowdep node #%02u [H=%03u]: ", mxap->sdnIndex, mxax);
            emitDispIns(scGetIns(mxap), false, false, true);
        }
#endif

        *mxal = mxap->sdnNext;

#if TGT_IA64
        scCheckTemplate(scGetIns(mxap), true, false, (mxfp->sdnEEtime > scCurrentTime));
#endif

        return  mxap;
    }
}

/*****************************************************************************/
#if TGT_IA64
/*****************************************************************************
 *
 *  Initialize the IA64 template table.
 */

templateDsc         tmpl_eB    = {      0, XU_B, false, { NULL } };
templateDsc         tmpl_eF    = {      0, XU_F, false, { NULL } };
templateDsc         tmpl_eI    = {      0, XU_I, false, { NULL } };
templateDsc         tmpl_eL    = {      0, XU_L, false, { NULL } };
templateDsc         tmpl_eM    = {      0, XU_M, false, { NULL } };

templateDsc         tmpl_MI_sI = { 0x02+1, XU_P, false, { &tmpl_eI   , NULL } };
templateDsc         tmpl_MI_B  = { 0x10+1, XU_B, false, { NULL } };
templateDsc         tmpl_MI_F  = { 0x0C+1, XU_F,  true, { NULL } };
templateDsc         tmpl_MI_I  = { 0x00+1, XU_I, false, { NULL } };
templateDsc         tmpl_MI_M  = { 0x08+1, XU_M,  true, { NULL } };
templateDsc         tmpl_M_I   = {      0, XU_I, false, { &tmpl_MI_I ,
                                                          &tmpl_MI_M ,
                                                          &tmpl_MI_sI,
                                                          &tmpl_MI_B ,
                                                          &tmpl_MI_F , NULL } };

templateDsc         tmpl_MM_B  = { 0x18+1, XU_B, false, { NULL } };
templateDsc         tmpl_MM_F  = { 0x0E+1, XU_F, false, { NULL } };
templateDsc         tmpl_MM_I  = { 0x08+1, XU_I, false, { NULL } };
templateDsc         tmpl_M_M   = {      0, XU_M, false, { &tmpl_MM_I ,
                                                          &tmpl_MM_F ,
                                                          &tmpl_MM_B , NULL } };

templateDsc         tmpl_MF_B  = { 0x1C+1, XU_B, false, { NULL } };
templateDsc         tmpl_MF_I  = { 0x0C+1, XU_I, false, { NULL } };
templateDsc         tmpl_MF_M  = { 0x0E+1, XU_M,  true, { NULL } };
templateDsc         tmpl_M_F   = {      0, XU_F, false, { &tmpl_MF_I ,
                                                          &tmpl_MF_M ,
                                                          &tmpl_MF_B , NULL } };

templateDsc         tmpl_M_L   = { 0x04+1, XU_L, false, { NULL } };

templateDsc         tmpl_Ms_MI = {      0, XU_M, false, { &tmpl_eI   , NULL } };
templateDsc         tmpl_M_sMI = { 0x0A+1, XU_P, false, { &tmpl_Ms_MI, NULL } };

templateDsc         tmpl_M_BB  = { 0x12+1, XU_B, false, { &tmpl_eB   , NULL } };

templateDsc         tmpl_M     = {      0, XU_M, false, { &tmpl_M_M  ,
                                                          &tmpl_M_I  ,
                                                          &tmpl_M_F  ,
                                                          &tmpl_M_L  ,
                                                          &tmpl_M_sMI,
                                                          &tmpl_M_BB , NULL } };

templateDsc         tmpl_B_BB  = { 0x16+1, XU_B, false, { &tmpl_eB   , NULL } };
templateDsc         tmpl_B     = {      0, XU_B, false, { &tmpl_B_BB , NULL } };

templateDsc     *   IA64sched::scIA64tmpTab_B = &tmpl_B;
templateDsc     *   IA64sched::scIA64tmpTab_M = &tmpl_M;

#ifdef  DEBUG

static
char                dumpTempBuff[10];
static
NatUns              dumpTempNum;

const   char *      genXUname(IA64execUnits xu);

void                dumpTemplate(templateDsc *tmp, char *dst, bool swp)
{
    templateDsc * * next = tmp->tdNext;

    strcpy(dst, genXUname((IA64execUnits)tmp->tdIxu));

    dst += strlen(dst);

    if  (tmp->tdNum)
        dumpTempNum = tmp->tdNum;

    if  (tmp->tdSwap)
        swp = true;

    if  (*next == NULL)
    {
        *dst = 0;
        printf("%02X: %s", dumpTempNum - 1, dumpTempBuff);
        if  (swp)
            printf(" [s]");
        printf("\n");
        return;
    }

    do
    {
        dumpTemplate(*next, dst, swp);
    }
    while (*++next);
}

void                dumpTemplate(templateDsc *tmp)
{
    dumpTemplate(tmp, dumpTempBuff, false);
    printf("\n");
}

#endif//DEBUG

/*****************************************************************************
 *
 *  Non-zero if a group split is forced after the given template.
 */

static
BYTE                IA64forceSplit[32] =
{
    0,  // M I I        0x00
    0,  // M I I *      0x01
    0,  // M I * I      0x02
    0,  // M I * I *    0x03
    0,  // M L          0x04
    0,  // M L   *      0x05
    0,  //              0x06
    0,  //              0x07
    0,  // M M I        0x08
    0,  // M M I *      0x09
    0,  // M * M I      0x0A
    0,  // M * M I *    0x0B
    0,  // M F I        0x0C
    0,  // M F I *      0x0D
    2,  // M M F        0x0E
    2,  // M M F *      0x0F

    1,  // M I B        0x10
    1,  // M I B *      0x11
    1,  // M B B        0x12
    1,  // M B B *      0x13
    0,  //              0x14
    0,  //              0x15
    1,  // B B B        0x16
    1,  // B B B *      0x17
    1,  // M M B        0x18
    1,  // M M B *      0x19
    0,  //              0x1A
    0,  //              0x1B
    1,  // M F B        0x1C
    1,  // M F B *      0x1D
    0,  //              0x1E
    0,  //              0x1F
};

/*****************************************************************************
 *
 *  Pardon these temp hacks.
 */

regNumber           insOpDest(insPtr ins);
regNumber           insOpReg (insPtr ins);
regNumber           insOpTmp (insPtr ins);

#ifdef  DEBUG
const   char *      genXUname(IA64execUnits xu);
void                insDisp(insPtr ins, bool detail, bool codelike);
#endif

extern
regNumber           genPrologSrGP;

extern
NatUns              cntTmpIntReg;
extern
regNumber   *       genTmpIntRegMap;

extern
NatUns              cntTmpFltReg;
extern
regNumber   *       genTmpFltRegMap;

/*****************************************************************************
 *
 *  Record scheduling dependencies of the given instruction.
 */

void                IA64sched::scDepDefRegBR  (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val < sizeof(emit->scBRrDef)/sizeof(emit->scBRrDef[0]));
    emit->scDepDef(dag, "BR", emit->scBRrDef[val], emit->scBRrUse[val], false);
}
void                IA64sched::scDepDefReg    (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    emit->scDepDefReg(dag, (regNumber)val);
}
void                IA64sched::scDepDefRegApp (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val == REG_APP_LC);
    emit->scDepDef(dag, "AR", emit->scAPrDef[0], emit->scAPrUse[0], true);
}
void                IA64sched::scDepDefRegPred(emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val < sizeof(emit->scPRrDef)/sizeof(emit->scPRrDef[0]));

    /* Special case: predicate regs only have anti-deps */

    emit->scDepDef(dag, "PR", emit->scPRrDef[val], emit->scPRrUse[val], true);
}
void                IA64sched::scDepDefLclVar (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    Compiler::LclVarDsc*dsc;
    NatUns              reg;

    assert(val && val <= emit->emitComp->lvaCount);
    dsc = emit->emitComp->lvaTable + val - 1;

    if  (dsc->lvOnFrame)
    {
        emit->scDepDefFrm(dag, id, emit->scStkDepDesc(dsc));
    }
    else
    {
if  (!dsc->lvRegNum) printf("OUCH: local variable [%08X] #%u is not enregistered\n", dsc, val-1);
        assert(dsc->lvRegNum);

        emit->scDepDefReg(dag, dsc->lvRegNum);
    }
}
void                IA64sched::scDepDefTmpInt (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    NatUns          reg;

    assert(val && val <= cntTmpIntReg);
    assert(genTmpIntRegMap);

    reg = genTmpIntRegMap[val - 1];

    assert(reg >= REG_INT_FIRST && reg <= REG_INT_LAST);

    emit->scDepDefReg(dag, (regNumber)reg);
}
void                IA64sched::scDepDefTmpFlt (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    NatUns          reg;

    assert(val && val <= cntTmpFltReg);
    assert(genTmpFltRegMap);

    reg = genTmpFltRegMap[val - 1];

    assert(reg >= REG_FLT_FIRST && reg <= REG_FLT_LAST);

    emit->scDepDefReg(dag, (regNumber)reg);
}
void                IA64sched::scDepDefInd    (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    emit->scDepDefInd(dag, val);
}

void                IA64sched::scUpdDefRegBR  (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val < sizeof(emit->scBRrDef)/sizeof(emit->scBRrDef[0]));
    emit->scUpdDef(dag, &emit->scBRrDef[val], &emit->scBRrUse[val]);
}
void                IA64sched::scUpdDefReg    (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    emit->scUpdDefReg(dag, (regNumber)val);
}
void                IA64sched::scUpdDefRegApp (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val == REG_APP_LC);
    emit->scUpdDef(dag, &emit->scAPrDef[0], &emit->scAPrUse[0]);
}
void                IA64sched::scUpdDefRegPred(emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val < sizeof(emit->scPRrDef)/sizeof(emit->scPRrDef[0]));
    emit->scUpdDef(dag, &emit->scPRrDef[val], &emit->scPRrUse[val]);
}
void                IA64sched::scUpdDefLclVar (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    Compiler::LclVarDsc*dsc;
    NatUns              reg;

    assert(val && val <= emit->emitComp->lvaCount);
    dsc = emit->emitComp->lvaTable + val - 1;

    if  (dsc->lvOnFrame)
    {
        emit->scUpdDefFrm(dag, emit->scStkDepDesc(dsc));
    }
    else
    {
        assert(dsc->lvRegNum);

        emit->scUpdDefReg(dag, dsc->lvRegNum);
    }
}
void                IA64sched::scUpdDefTmpInt (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    NatUns          reg;

    assert(val && val <= cntTmpIntReg);
    assert(genTmpIntRegMap);

    reg = genTmpIntRegMap[val - 1];

    assert(reg >= REG_INT_FIRST && reg <= REG_INT_LAST);

    emit->scUpdDefReg(dag, (regNumber)reg);
}
void                IA64sched::scUpdDefTmpFlt (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    NatUns          reg;

    assert(val && val <= cntTmpFltReg);
    assert(genTmpFltRegMap);

    reg = genTmpFltRegMap[val - 1];

    assert(reg >= REG_FLT_FIRST && reg <= REG_FLT_LAST);

    emit->scUpdDefReg(dag, (regNumber)reg);
}
void                IA64sched::scUpdDefInd    (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    emit->scUpdDefInd(dag, val);
}

void                IA64sched::scDepUseRegBR  (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val < sizeof(emit->scBRrDef)/sizeof(emit->scBRrDef[0]));
    emit->scDepUse(dag, "BR", emit->scBRrDef[val], emit->scBRrUse[val]);
}
void                IA64sched::scDepUseReg    (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    emit->scDepUseReg(dag, (regNumber)val);
}
void                IA64sched::scDepUseRegApp (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val == REG_APP_LC);
    emit->scDepUse(dag, "AR", emit->scAPrDef[0], emit->scAPrUse[0]);
}
void                IA64sched::scDepUseRegPred(emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val < sizeof(emit->scPRrDef)/sizeof(emit->scPRrDef[0]));
    emit->scDepUse(dag, "PR", emit->scPRrDef[val], emit->scPRrUse[val]);
}
void                IA64sched::scDepUseLclVar (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    Compiler::LclVarDsc*dsc;
    NatUns              reg;

    assert(val && val <= emit->emitComp->lvaCount);
    dsc = emit->emitComp->lvaTable + val - 1;

    if  (dsc->lvOnFrame)
    {
        emit->scDepUseFrm(dag, id, emit->scStkDepDesc(dsc));
    }
    else
    {
        assert(dsc->lvRegNum);

        emit->scDepUseReg(dag, dsc->lvRegNum);
    }
}
void                IA64sched::scDepUseTmpInt (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    NatUns          reg;

    assert(val && val <= cntTmpIntReg);
    assert(genTmpIntRegMap);

    reg = genTmpIntRegMap[val - 1];

    assert(reg >= REG_INT_FIRST && reg <= REG_INT_LAST);

    emit->scDepUseReg(dag, (regNumber)reg);
}
void                IA64sched::scDepUseTmpFlt (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    NatUns          reg;

    assert(val && val <= cntTmpFltReg);
    assert(genTmpFltRegMap);

    reg = genTmpFltRegMap[val - 1];

    assert(reg >= REG_FLT_FIRST && reg <= REG_FLT_LAST);

    emit->scDepUseReg(dag, (regNumber)reg);
}
void                IA64sched::scDepUseInd    (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    emit->scDepUseInd(dag, val);
}

void                IA64sched::scUpdUseRegBR  (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val < sizeof(emit->scBRrDef)/sizeof(emit->scBRrDef[0]));
    emit->scUpdUse(dag, &emit->scBRrDef[val], &emit->scBRrUse[val]);
}
void                IA64sched::scUpdUseReg    (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    emit->scUpdUseReg(dag, (regNumber)val);
}
void                IA64sched::scUpdUseRegApp (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val == REG_APP_LC);
    emit->scUpdUse(dag, &emit->scAPrDef[0], &emit->scAPrUse[0]);
}
void                IA64sched::scUpdUseRegPred(emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    assert(val < sizeof(emit->scPRrDef)/sizeof(emit->scPRrDef[0]));
    emit->scUpdUse(dag, &emit->scPRrDef[val], &emit->scPRrUse[val]);
}
void                IA64sched::scUpdUseLclVar (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    Compiler::LclVarDsc*dsc;
    NatUns              reg;

    assert(val && val <= emit->emitComp->lvaCount);
    dsc = emit->emitComp->lvaTable + val - 1;

    if  (dsc->lvOnFrame)
    {
        emit->scUpdUseFrm(dag, emit->scStkDepDesc(dsc));
    }
    else
    {
        assert(dsc->lvRegNum);

        emit->scUpdUseReg(dag, dsc->lvRegNum);
    }
}
void                IA64sched::scUpdUseTmpInt (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    NatUns          reg;

    assert(val && val <= cntTmpIntReg);
    assert(genTmpIntRegMap);

    reg = genTmpIntRegMap[val - 1];

    assert(reg >= REG_INT_FIRST && reg <= REG_INT_LAST);

    emit->scUpdUseReg(dag, (regNumber)reg);
}
void                IA64sched::scUpdUseTmpFlt (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    NatUns          reg;

    assert(val && val <= cntTmpFltReg);
    assert(genTmpFltRegMap);

    reg = genTmpFltRegMap[val - 1];

    assert(reg >= REG_FLT_FIRST && reg <= REG_FLT_LAST);

    emit->scUpdUseReg(dag, (regNumber)reg);
}
void                IA64sched::scUpdUseInd    (emitter*emit, IA64sched::scDagNode*dag, instrDesc *id, NatUns val)
{
    emit->scUpdUseInd(dag, val);
}

/*****************************************************************************/

void              (*IA64sched::scDepDefTab[IDK_COUNT])(emitter*,IA64sched::scDagNode*, instrDesc *, NatUns) =
{
    NULL,           // IDK_NONE

    scDepDefRegBR,  // IDK_REG_BR
    scDepDefReg,    // IDK_REG_INT
    scDepDefReg,    // IDK_REG_FLT
    scDepDefRegApp, // IDK_REG_APP
    scDepDefRegPred,// IDK_REG_PRED

    scDepDefLclVar, // IDK_LCLVAR
    scDepDefTmpInt, // IDK_TMP_INT
    scDepDefTmpFlt, // IDK_TMP_FLT
    scDepDefInd,    // IDK_IND
};

void              (*IA64sched::scUpdDefTab[IDK_COUNT])(emitter*,IA64sched::scDagNode*, instrDesc *, NatUns) =
{
    NULL,           // IDK_NONE

    scUpdDefRegBR,  // IDK_REG_BR
    scUpdDefReg,    // IDK_REG_INT
    scUpdDefReg,    // IDK_REG_FLT
    scUpdDefRegApp, // IDK_REG_APP
    scUpdDefRegPred,// IDK_REG_PRED

    scUpdDefLclVar, // IDK_LCLVAR
    scUpdDefTmpInt, // IDK_TMP_INT
    scUpdDefTmpFlt, // IDK_TMP_FLT
    scUpdDefInd,    // IDK_IND
};

void              (*IA64sched::scDepUseTab[IDK_COUNT])(emitter*,IA64sched::scDagNode*, instrDesc *, NatUns) =
{
    NULL,           // IDK_NONE

    scDepUseRegBR,  // IDK_REG_BR
    scDepUseReg,    // IDK_REG_INT
    scDepUseReg,    // IDK_REG_FLT
    scDepUseRegApp, // IDK_REG_APP
    scDepUseRegPred,// IDK_REG_PRED

    scDepUseLclVar, // IDK_LCLVAR
    scDepUseTmpInt, // IDK_TMP_INT
    scDepUseTmpFlt, // IDK_TMP_FLT
    scDepUseInd,    // IDK_IND
};

void              (*IA64sched::scUpdUseTab[IDK_COUNT])(emitter*,IA64sched::scDagNode*, instrDesc *, NatUns) =
{
    NULL,           // IDK_NONE

    scUpdUseRegBR,  // IDK_REG_BR
    scUpdUseReg,    // IDK_REG_INT
    scUpdUseReg,    // IDK_REG_FLT
    scUpdUseRegApp, // IDK_REG_APP
    scUpdUseRegPred,// IDK_REG_PRED

    scUpdUseLclVar, // IDK_LCLVAR
    scUpdUseTmpInt, // IDK_TMP_INT
    scUpdUseTmpFlt, // IDK_TMP_FLT
    scUpdUseInd,    // IDK_IND
};

void                IA64sched::scRecordInsDeps(instrDesc *id, scDagNode *dag)
{
    instruction     ins = id->idInsGet();

    assert(scDepDefTab[IDK_COUNT-1] != NULL);
    assert(scUpdDefTab[IDK_COUNT-1] != NULL);
    assert(scDepUseTab[IDK_COUNT-1] != NULL);
    assert(scUpdUseTab[IDK_COUNT-1] != NULL);

//  if  (id->idIns == INS_ld8_ind && (id->idFlags & IF_LDIND_NTA)) BreakIfDebuggerPresent();
//  if  ((int)id == 0x029b0320) BreakIfDebuggerPresent();

    NatUns          depNum;
    insDep  *       depPtr;

//  if  (id->idIns == INS_sxt4) BreakIfDebuggerPresent();

    for (depNum = id->idSrcCnt, depPtr = id->idSrcTab;
         depNum;
         depNum--             , depPtr++)
    {
        assert(depPtr->idepKind < IDK_COUNT);

        if  (depPtr->idepKind != IDK_NONE)
        {
            assert(scDepUseTab[depPtr->idepKind]);
//          printf("DepUse[%u]\n", depPtr->idepKind);
            scDepUseTab[depPtr->idepKind](this, dag, id, depPtr->idepNum);
        }
    }

    for (depNum = id->idDstCnt, depPtr = id->idDstTab;
         depNum;
         depNum--             , depPtr++)
    {
        assert(depPtr->idepKind < IDK_COUNT);

        if  (depPtr->idepKind != IDK_NONE)
        {
            assert(scDepDefTab[depPtr->idepKind]);
//          printf("DepDef[%u]\n", depPtr->idepKind);
            scDepDefTab[depPtr->idepKind](this, dag, id, depPtr->idepNum);
        }
    }

#if 1

    // HACK: record the fact that "alloc" creates all stacked registers

    if  (id->idIns == INS_alloc)
    {
        unsigned        reg;

        for (reg = REG_INT_MIN_STK; reg <= REG_INT_MAX_STK; reg++)
            scDepDefReg(dag, (regNumber)reg);
    }

#endif

    for (depNum = id->idSrcCnt, depPtr = id->idSrcTab;
         depNum;
         depNum--             , depPtr++)
    {
        assert(depPtr->idepKind < IDK_COUNT);

        if  (depPtr->idepKind != IDK_NONE)
        {
            assert(scUpdUseTab[depPtr->idepKind]);
//          printf("UpdUse[%u]\n", depPtr->idepKind);
            scUpdUseTab[depPtr->idepKind](this, dag, id, depPtr->idepNum);
        }
    }

    for (depNum = id->idDstCnt, depPtr = id->idDstTab;
         depNum;
         depNum--             , depPtr++)
    {
        assert(depPtr->idepKind < IDK_COUNT);

        if  (depPtr->idepKind != IDK_NONE)
        {
            assert(scUpdDefTab[depPtr->idepKind]);
//          printf("UpdDef[%u]\n", depPtr->idepKind);
            scUpdDefTab[depPtr->idepKind](this, dag, id, depPtr->idepNum);
        }
    }
}

/*****************************************************************************
 *
 *  The given instruction has just been issued, compute EET for all successors.
 */

void                emitter::scUpdateSuccEET(scDagNode *node)
{
    scWalkSuccDcl(temp)

    scWalkSuccBeg(temp, node)
    {
        scDagNode   *   succ = scWalkSuccCur(temp);
        NatUns          minl;
        NatUns          time;

#ifdef  DEBUG
minl = -1;
#endif

        scLatency(node, succ, &minl);

assert(minl != -1); // make sure the call set the value

        time = scCurrentTime + minl;

//      if  (scGetIns(succ)->idNum == 20 && scGetIns(succ)->idIns == INS_fcvt_xf) BreakIfDebuggerPresent();

//      printf("%3u -> ", scCurrentTime); emitDispIns(scGetIns(node), false, false, true);
//      printf("-> %3u ",          time); emitDispIns(scGetIns(succ), false, false, true);

        if  (succ->sdnEEtime < time)
             succ->sdnEEtime = (USHORT)time;
    }
    scWalkSuccEnd(temp)
}

/*****************************************************************************/
#endif//TGT_IA64
/*****************************************************************************
 *
 *  Schedule and issue all the instructions recorded between the instruction
 *  table values 'begPtr' and 'endPtr'.
 */

#if TGT_IA64

void                emitter::scGroup(insGroup   *ig,        // Current insGroup
                                     instrDesc* *ni,        // non-sched instr(s) that follow
                                     NatUns      nc,        // non-sched instr(s) count
                                     instrDesc* *begPtr,    // First  instr to schedule
                                     instrDesc* *endPtr,    // Last+1 instr to schedule
                                     unsigned    bdLen)     // # of branch delay slots

#else

void                emitter::scGroup(insGroup   *ig,        // Current insGroup
                                     instrDesc  *ni,        // Next instr in "ig", NULL if end of "ig"
                                     BYTE *     *dp,        // output buffer
                                     instrDesc* *begPtr,    // First  instr to schedule
                                     instrDesc* *endPtr,    // Last+1 instr to schedule
                                     int         fpLo,      // FP relative vars
                                     int         fpHi,
                                     int         spLo,      // SP relative slots
                                     int         spHi,
                                     unsigned    bdLen)     // # of branch delay slots

#endif

{
    instrDesc   * * tmpPtr;
    unsigned        insCnt;
    unsigned        insNum;
    scDagNode     * dagPtr;
    scDagNode     * dagEnd;

#if!MAX_BRANCH_DELAY_LEN
    const unsigned  bdLen = 0;
#endif

#if     TGT_IA64

    NatUns          xjumps = nc;

    NatUns          FPcmpPredT;
    NatUns          FPcmpPredF;
    NatUns          FPcmpClock;

    NatUns          BRsetClock;

    /* Start up the scheduling/issue clock */

    scCurrentTime = 0;

#ifdef  DEBUG

    if  (0)
    {
        // Use the following to display the template tables

        dumpTemplate(scIA64tmpTab_M);
        dumpTemplate(scIA64tmpTab_B);

        UNIMPL("finished dumping template tables, disable this code to proceed");
    }

    if (VERBOSE) printf("Schedule G_%02u:\n", ig->igNum);

#endif

    /* Initialize the stack frame hashing/tracking logic */

    scStkDepBegBlk();

#else

    size_t           fpFrmSz;
    size_t           spFrmSz;
    size_t          stkFrmSz;

#ifdef  DEBUG
    if (VERBOSE) printf("Scheduler : G_%d (instr %d to inst %d):\n",
        ig->igNum, (*begPtr)?(*begPtr)->idNum:-1, (*(endPtr-1))?(*(endPtr-1))->idNum:-1);
#endif

#if EMITTER_STATS
    for (tmpPtr = begPtr; tmpPtr != endPtr; tmpPtr++)
        schedFcounts[(*tmpPtr)->idInsFmt]++;
#endif

    /* If there are no stack references, clear the range[s] */

    if  (fpLo == INT_MAX)
    {
        assert(fpHi == INT_MIN);

        fpLo =
        fpHi = 0;
    }

    if  (spLo == INT_MAX)
    {
        assert(spHi == INT_MIN);

        spLo =
        spHi = 0;
    }

    /* Compute the number of frame values that we'll need to track */

     spFrmSz = spHi - spLo;
     fpFrmSz = fpHi - fpLo;
    stkFrmSz = fpFrmSz + spFrmSz;

#ifdef  DEBUG

    if  (verbose && stkFrmSz)
    {
        printf("Schedulable frame refs: ");

        printf("%s[", getRegName(REG_FPBASE));
        if      (fpLo <  0)
        {
            printf("-%04X", -fpLo);
        }
        else if (fpLo >= 0)
        {
            printf("+%04X", +fpLo);
        }
        printf("..");
        if      (fpHi <  0)
        {
            printf("-%04X", -fpHi);
        }
        else if (fpHi >= 0)
        {
            printf("+%04X", +fpHi);
        }
        printf("] , ");

        printf("%s[", getRegName(REG_SPBASE));
        if      (spLo <  0)
        {
            printf("-%04X", -spLo);
        }
        else if (spLo >= 0)
        {
            printf("+%04X", +spLo);
        }
        printf("..");
        if      (spHi <  0)
        {
            printf("-%04X", -spHi);
        }
        else if (spHi >= 0)
        {
            printf("+%04X", +spHi);
        }
        printf("] %3u items.\n", stkFrmSz);
    }

#endif

#if EMITTER_STATS
    scdFrmCntTable.histoRec(stkFrmSz, 1);
#endif

#endif

    /* We do this early in case there are no schedulable instructions */

    scReadyList = NULL;

    /* Tell other methods where the instruction table starts */

    scDagIns = begPtr;

    /* How many instructions are we supposed to schedule ? */

    scInsCnt = insCnt = endPtr - begPtr; assert((int)insCnt >= 0 && insCnt <= SCHED_INS_CNT_MAX);

#if TGT_IA64

    /* Clear the instruction issue table */

    scIssueClr(true);

    /* If we have no instructions to schedule, skip the scheduling step */

    if  (!insCnt)
    {
        assert(nc);
        goto APP_NS;
    }

#else

    assert(insCnt);

#if 0

emitDispIns(*begPtr, false, false, true);

for (NatUns i = 0; i < nc; i++)
    emitDispIns(ni[i], false, false, true);

UNIMPL("emit unscheduled code");

#endif

    /* Are there enough instructions to make scheduling worth our while? */

    if  (insCnt < SCHED_INS_CNT_MIN)
    {
        /* No scheduling, just issue the instructions in the original order */

    NO_SCHED:

        do
        {
            emitIssue1Instr(ig, *begPtr++, dp);
        }
        while (begPtr != endPtr);

        return;
    }

    /* Is the current stack frame tracking table big enough? */

    if  (stkFrmSz > scFrmUseSiz)
    {
        /* We don't have a big enough table - should we grow it? */

        if  (stkFrmSz > SCHED_FRM_CNT_MAX)
        {
            /* There are too many stack slots to track, just give up */

            // CONSIDER: Use hash table for tracking stack frame values
            // CONSIDER: when scheduling code with a very large frame,
            // CONSIDER: so that we don't stupidly give up like this.

            goto NO_SCHED;
        }

        /* Reallocate the stack tracking tables to have sufficient capacity */

        scFrmUseSiz = roundUp(stkFrmSz + stkFrmSz/2);
        scFrmDef    = (schedDef_tp*)emitGetMem(scFrmUseSiz*sizeof(*scFrmDef));
        scFrmUse    = (schedUse_tp*)emitGetMem(scFrmUseSiz*sizeof(*scFrmUse));
    }

#endif

#if MAX_BRANCH_DELAY_LEN

    /* Do we have any branch-delay slots to schedule? */

    scBDTmin = 0;
    scIssued = 0;

    if  (bdLen)
    {
        assert(insCnt > bdLen);

        /* Don't bother scheduling the branch-delay nop's at the end */

        scInsCnt = insCnt = insCnt - bdLen; assert(insCnt >= 1);

        /* Compute the earliest time the jump/call may be issued */

        scBDTmin = max(insCnt - bdLen - 1, 0);
    }

#endif

    /* Clear all of the tracking tables/values */

    memset(scDagTab, 0, sizeof(*scDagTab) * insCnt);

#if TGT_IA64
    memset(scPRrDef, 0, sizeof( scPRrDef));
    memset(scPRrUse, 0, sizeof( scPRrUse));
    memset(scAPrDef, 0, sizeof( scAPrDef));
    memset(scAPrUse, 0, sizeof( scAPrUse));
    memset(scBRrDef, 0, sizeof( scBRrDef));
    memset(scBRrUse, 0, sizeof( scBRrUse));
#else
    memset(scFrmDef, 0, sizeof(*scFrmDef) * stkFrmSz);
    memset(scFrmUse, 0, sizeof(*scFrmUse) * stkFrmSz);
#endif

    memset(scRegDef, 0, sizeof( scRegDef));
    memset(scRegUse, 0, sizeof( scRegUse));

    memset(scIndDef, 0, sizeof( scIndDef));
    memset(scIndUse, 0, sizeof( scIndUse));

    scExcpt = 0;

    scGlbDef     = 0;
    scGlbUse     = 0;

    scTgtDepClr();

#if SCHED_USE_FL

    scFlgDef     = 0;
    scFlgUse     = 0;

    /*
        Since the group we're scheduling may in general end at an arbitrary
        point, we have to be careful about flags. If there is a possibility
        that one of the last instructions at the end of the group sets the
        flags which are later used by an instruction that follows the group
        we have to make sure to issue the instruction that sets the flags
        at the end of the scheduled group.
     */

    scFlgEnd = false;

     /* See if we know the instruction that will follow the group */

    if  (ni == NULL)
    {
        insGroup    *   ng;

        /* Check the IG that follows ours */

        ng = ig->igNext;

        if (!ng) goto NO_FL;

        /* Is the next IG a target of a jump? */

        if  (ng->igFlags & IGF_HAS_LABEL)
        {
            // ISSUE: We assume labels don't ever expect flags to be set!

            goto NO_FL;
        }

        /* Get hold of the first instruction on the next IG */

        ni = (instrDesc *)ng->igData;
    }

    if  (ni != NULL)
    {
        /* We know the instruction that follows, check its flag effect
           ISSUE: If ni doesnt use flags, can any of its successors ? */

        if  (Compiler::instUseFlags((instruction)ni->idIns) == 0)
        {
            /* The next doesn't read flags */

            goto NO_FL;
        }
    }

    /* Looks like we're going to have to set the flags at the end */

    scFlgEnd = true;

NO_FL:

#endif

    /*-------------------------------------------------------------------------
     * Build the dag by walking the instructions backwards
     */

#ifdef  DEBUG
    if (VERBOSE) printf("Building scheduling dag [%2u instructions]:\n", insCnt);
#endif

    tmpPtr = endPtr - bdLen;
    insNum = insCnt;
    dagPtr = dagEnd = scDagTab + insNum;

    do
    {
        instrDesc   *   id;

        instruction     ins;
#if!TGT_IA64
        insFormats      fmt;
#endif
        unsigned        inf;
        unsigned        flg;

        FIELD_HANDLE    MBH;
        int             frm;
        size_t          siz;
        unsigned        amx;

        emitRegs        rg1;
        emitRegs        rg2;

        bool            extraDep;
        bool            stackDep;
        emitRegs        extraReg;
        scExtraInfo     extraInf;

        /* We start past the end and go backwards */

        tmpPtr--;
        insNum--;
        dagPtr--;

        /* Make sure our variables are in synch */

        assert((int)insNum == dagPtr - scDagTab);
        assert((int)insNum == tmpPtr - begPtr);

        /* Get hold of the next (actually, previous) instruction */

        id = *tmpPtr;

#if!TGT_IA64
        assert(scIsSchedulable(id));
#endif

        /* Fill in the instruction index in the dag descriptor */

        dagPtr->sdnIndex = insNum; assert((int)insNum == tmpPtr - scDagIns);

#ifdef  DEBUG
        if  (VERBOSE)
        {
#if     TGT_IA64
            printf("Sched[%02u] ", insNum);
#else
            printf("Sched[%02u]%16s:\n", insNum, emitIfName(id->idInsFmt));
#endif
            emitDispIns(id, false, false, true);
        }
#endif

        /* Get hold of the instruction and its format */

        ins = id->idInsGet();
#if!TGT_IA64
        fmt = (insFormats )id->idInsFmt;
#endif

#if MAX_BRANCH_DELAY_LEN

        /* Remember whether this a branch with delay slot(s) */

        if  (bdLen && scIsBranchIns(ins))
            dagPtr->sdnBranch = true;

        /* We should never encounter a nop, right? */

        assert(ins != INS_nop);

#endif

//      if  (id->idNum == <put instruction number # to stop at here>) debugStop(0);

        /********************************************************************/
        /*             Record the dependencies of the instruction           */
        /********************************************************************/

#if TGT_IA64
        scRecordInsDeps(id, dagPtr);
#else
        #include "schedDep.h"   // temporarily moved into a separate source file
#endif

#ifdef  DEBUG
        if  (VERBOSE) printf("\n");
#endif

    }
    while (tmpPtr != begPtr);

    /* Make sure we ended up in the right place */

    assert(dagPtr == scDagTab);
    assert(tmpPtr == begPtr);
    assert(insNum == 0);

    /*
        Create the "ready" list (which consists of all nodes with no
        predecessors), and also compute the height of each node in
        the dag.
     */

    for (insNum = scInsCnt, dagPtr = scDagTab;
         insNum;
         insNum--         , dagPtr++)
    {

#if     EMITTER_STATS

        unsigned        succ = 0;
        schedDepMap_tp  mask = dagPtr->sdnDepsAll;

        while (mask)
        {
            succ++;
            mask -= genFindLowestBit(mask);
        }

        scdSucTable.histoRec(succ, 1);

#endif

        /* If the node doesn't depend on any other, it's ready */

        if  (dagPtr->sdnPreds == 0)
        {
            scReadyListAdd(dagPtr);
#if TGT_IA64
            assert(dagPtr->sdnEEtime == 0);
#endif
            scGetDagHeight(dagPtr);
        }
    }

#ifdef  DEBUG

    if  (VERBOSE)
    {
        if  (nc)
        {
            for (NatUns i = 0; i < nc; i++)
            {
                printf("NonSched: ");

                emitDispIns(ni[i], false, false, true);
            }
        }
        printf("\n");
    }

    scDispDag(!VERBOSE);

#endif

    /*-------------------------------------------------------------------------
     * Now issue the best-looking ready instruction until all are gone
     */

#if TGT_IA64

APP_NS:

    FPcmpPredT =
    FPcmpPredF = 0;
    FPcmpClock = 0;

    BRsetClock = -1;

#endif

#ifdef  DEBUG
    unsigned        issued = 0;
#endif

    scLastIssued  = NULL;

#if TGT_x86
    const unsigned  startStackLvl = emitCurStackLvl;
#endif

    scPick          pick = PICK_SCHED;

#if TGT_IA64
    for (scRlstCurTime = scRlstBegTime = 0;;)
#else
    do
#endif
    {
        scDagNode   *   node;
        insPtr          ins;

//      printf("Current time = %u\n", scCurrentTime);

#if TGT_IA64

//          dispersal = 08
//
//              0:  M   adds    r14 = 0x10, sp
//              1:  M   ld8.nta r3 = [sp]
//              2:  I   add     r37 = r0, r14

        /* Are we still working on the ready list? */

        if  (scReadyList)
        {
            IA64execUnits   xu;

            /* Pick the next node to be issued */

            node = scPickNxt(pick);

            /* Did we find an instruction that fits in the current template ? */

            if  (node)
            {
                ins = scGetIns(node);

                /* Special case: result of "fcmp" isn't avaialable right away */

                if  (genInsFU(ins->idInsGet()) == FU_FCMP)
                {
                    assert(ins->idIns == INS_fcmp_eq ||
                           ins->idIns == INS_fcmp_ne ||
                           ins->idIns == INS_fcmp_lt ||
                           ins->idIns == INS_fcmp_le ||
                           ins->idIns == INS_fcmp_ge ||
                           ins->idIns == INS_fcmp_gt);

                    FPcmpPredT = ins->idComp.iPredT;
                    FPcmpPredF = ins->idComp.iPredF;
                    FPcmpClock = scCurrentTime;
                }

                /* Special case: catch "mov b0=xxx" followed by "ret b0" */

                if  (ins->idIns == INS_mov_brr_reg)
                    BRsetClock = scCurrentTime;
            }
            else
            {
                /* Are we at the end of a bundle anyway ? */

                if  (scIssueCnt && (scIssueCnt % 3) == 0)
                {
                    /* Simply flush the bundle and start over */

                    scIssueAdd(NULL);
                    continue;
                }

                /* Look for a stop bit or a NOP slot in the current template */

                xu = scCheckTemplate(NULL, true);

                if  (xu == XU_P)
                {
                    /* Stop bit has been appended, bump the clock */

                    scCurrentTime++;
                }
                else
                    scIssueAdd(scIA64nopGet(xu));

                continue;
            }
        }
        else
        {
            IA64execUnits   xu;
            instruction     iop;

            /* Do we have any non-schedulable instructions to append ? */

            if  (!nc)
                break;

            node = NULL;

        REP_JMP:

            /* Get hold of the next instruction to append */

            ins = *ni;

            /* Make sure it's not too early */

            if  (ins->idPred && (ins->idPred == FPcmpPredT ||
                                 ins->idPred == FPcmpPredF))
            {
                if  (FPcmpClock == scCurrentTime)
                {
                    scIssueAdd(NULL);
                    goto REP_JMP;
                }
            }

            iop = ins->idInsGet();

            if  (iop == INS_br_ret && BRsetClock == scCurrentTime)
            {
                /* Are we at the end of a bundle by any chance ? */

                if  ((scIssueCnt % 3) == 0)
                {
                    scIssueAdd(NULL);
                    goto REP_JMP;
                }

                xu = scCheckTemplate(NULL, true);
            }
            else if (iop == INS_br_cloop && (scIssueCnt % 3) != 0)
            {
                xu = scCheckTemplate(NULL, true);
            }
            else
                xu = scCheckTemplate( *ni, true);

            switch (xu)
            {
            case XU_N:
                scIssueAdd(NULL);
                goto REP_JMP;

            case XU_P:
                scCurrentTime++;
                continue;

            case XU_B:
                ni++; nc--;
#ifdef  DEBUG
                issued++;
#endif
                break;

            default:
                ins = scIA64nopGet(xu);
                break;
            }

            scIssueAdd(ins);
            continue;
        }

        scIssueAdd(ins);

        /* Bump the current ready list time */

        scRlstCurTime++;

#else

        /* Pick the next node to be issued */

        node = scPickNxt(pick);

        /* Issue the corresponding instruction */

        emitIssue1Instr(ig, scGetIns(node), dp);

#endif

        assert(node);

#ifdef  DEBUG
        node->sdnIssued = true; scDispDag(true); issued++;
#endif

#if MAX_BRANCH_DELAY_LEN

        /* Did we just issue a branch? */

        if  (scIsBranchIns(node))
        {
            /* Make sure we haven't issued the branch too early */

            assert(scIssued >= scBDTmin);

            /* Remember when we issued the branch */

            scBDTbeg = scIssued;
        }

        /* Update the number of instructions issued */

        scIssued++;

#endif

        /* Keep track of the most recently issued node */

        scLastIssued = node;

#if TGT_IA64
        scUpdateSuccEET(node);
#endif

        /* Update the predecessor counts for all dependents */

        scWalkSuccDcl(temp)

        scWalkSuccBeg(temp, node)
        {
            scDagNode   *   succ = scWalkSuccCur(temp);

            scWalkSuccRmv(temp, node);

//          printf("Succ of %02u: %02u / predCnt=[%02u->%02u]\n", node->sdnIndex,
//                                                                succ->sdnIndex,
//                                                                succ->sdnPreds,
//                                                                succ->sdnPreds-1);

            assert(succ->sdnPreds != 0);
            if  (--succ->sdnPreds == 0)
            {
                /* This successor node is now ready to be issued */

                scReadyListAdd(succ);
            }
        }
        scWalkSuccEnd(temp)

#if TGT_x86
        if  (pick == PICK_SCHED && !emitEBPframe)
        {
            /* For non-EBP frames, locals are accessed related to ESP. If we have
               pushed any values on the stack, the offset reqd to access the
               locals increases. Restrict this to a value such that our
               estimation of the instruction encoding size isnt violated */

            // Make sure we allow atleast 2 pushes
            assert(SCHED_MAX_STACK_CHANGE > 2*EMIT_MAX_INSTR_STACK_CHANGE);

            /* If we have already emitted some pushes, dont take any chances
               scheduling any more pushes. Just emit all the remaining
               instructions and be done. */

            if  ((emitComp->compLclFrameSize + emitMaxStackDepth*sizeof(void*)) > (size_t)SCHAR_MAX &&
                 (emitCurStackLvl - startStackLvl) >= (SCHED_MAX_STACK_CHANGE - EMIT_MAX_INSTR_STACK_CHANGE))
            {
                pick = PICK_NO_SCHED;
            }
        }
#endif

    }
#if!TGT_IA64
    while (scReadyList);
#endif

    /* Make sure all the instructions have been issued */

#if     TGT_IA64
    assert(issued == insCnt + xjumps);
#else
    assert(issued == insCnt);
#endif

    /* Do we need to fill any additional branch-delay slots? */

#if MAX_BRANCH_DELAY_LEN

    if  (bdLen)
    {
        int         nopCnt;

        /* Compute how many nop's we need to fill the remaining BD slots */

        nopCnt = scBDTbeg + bdLen + 1 - scIssued; assert(nopCnt >= 0);

        /* Point at the nop's at the tail of the scheduling table */

        tmpPtr = begPtr + insCnt;

        while (nopCnt)
        {
            assert((*tmpPtr)->idIns == INS_nop);

            emitIssue1Instr(ig, *tmpPtr, dp);

            tmpPtr++;
            nopCnt--;
        }

        // UNDONE: If some of the branch-delay slots were actually filled
        //         by useful instructions, we need to update the size of
        //         the instruction group, as we have generated less code
        //         then originally anticipated (i.e. we're ignoring some
        //         of the nop(s) that were added to fill the BD slots).
    }

#endif

#if TGT_IA64

    /* Flush any incomplete bundles */

    scIssueAdd(NULL);

    /* We're done scheduling the block */

    scStkDepEndBlk();

#endif

    /*
        ISSUE:  When we rearrange instructions due to scheduling, it's not
                currently possible to keep track of their offsets. Thus,
                anyone who uses scCodeOffset() when scheduling is enabled
                is in for a rude surprise. What to do?
     */

#if!TGT_IA64
    ig->igFlags |= IGF_UPD_ISZ;     // better than nothing, I suppose ....
#endif

}

/*****************************************************************************/
#if TGT_IA64
/*****************************************************************************
 *
 *  The following table holds the max. number of available execution units.
 */

BYTE                emitter::scIssueFnMax[XU_COUNT] =   // Merced specific
{
    0,  // XU_N

    0,  // XU_A
    2,  // XU_M
    2,  // XU_I
    3,  // XU_B
    2,  // XU_F

    0,  // XU_L
    0,  // XU_X
};

/*****************************************************************************
 *
 *  Update the current issue template position.
 */

inline
void                emitter::scIssueTmpUpdate(templateDsc *nxt)
{
    scIssueTmpPtr = nxt;

//  printf("Update template [past %s]\n", genXUname((IA64execUnits)nxt->tdIxu));

    if  (nxt->tdNum)  scIssueTmpNum = nxt->tdNum;
    if  (nxt->tdSwap) scIssueTmpSwp = true;
}

/*****************************************************************************
 *
 *  See if the given instruction fits in the current IA64 template. If 'node'
 *  is NULL on entry, it means that we know that there is no avaialable match
 *  and we need to find a stop or insert a NOP.
 */

IA64execUnits       emitter::scCheckTemplate(insPtr id, bool update,
                                                        bool noSwap,
                                                        bool needStop)
{
    templateDsc *   nxt;
    templateDsc * * tmp;

    IA64execUnits   xu;

//  static int x; if (++x == 0) __asm int 3

    /* Check for the special case of a NOP first */

    if  (!id)
    {
        templateDsc *   nop;

        assert(needStop == false);

        /* Have we picked a template already ? */

        if  (!scIssueTmpPtr)
        {
            /* Pick the "M" template, it's the only one that guarantees progress */

            nop = scIA64tmpTab_M;
            xu  = XU_M;

            goto GOT_NOP;
        }

        for (tmp = scIssueTmpPtr->tdNext;;)
        {
            IA64execUnits   tu;

            nxt = *tmp++;

            if  (!nxt)
                break;

            tu = (IA64execUnits)nxt->tdIxu;

            if  (tu == XU_P && update) // ???? WHY ???? && scIssueTmpPtr != scIA64tmpTab_M)
            {
                /* We've found a stop, consume it */

                xu = tu;
                goto MATCH;
            }

            /* Can we use this slot for a nop ? */

            switch (tu)
            {
            case XU_B:
            case XU_F:
            case XU_I:
            case XU_M:
                xu = tu; nop = nxt;

                if  (!update)
                    goto GOT_NOP;

                break;
            }
        }

    GOT_NOP:

        nxt = nop; assert(nxt); update = true;
    }
    else
    {
        instruction     ins;
        templateDsc *   stop;

        templateDsc *   nxtM = NULL;
        templateDsc *   nxtI = NULL;

        ins = id->idInsGet();
        xu  = genInsXU(ins);

        /* Have we started a template yet? */

        if  (scIssueTmpPtr == NULL)
        {
            /* Can't have a stop bit at the start of a bundle */

            if  (needStop)
            {
                assert(update == false);
                return  XU_N;
            }

            /* This is easy: we can only start with M/A or B */

            if  (xu == XU_A || xu == XU_M)
            {
                nxt = scIA64tmpTab_M;
            }
            else
            {
                if  (xu != XU_B)
                {
                    assert(update == false);
                    return  XU_N;
                }

                nxt = scIA64tmpTab_B;

                /* Bizarre special case: "br.cloop" has to be last in bundle */

                if  (ins == INS_br_cloop)
                {
                    if  (!update)
                        return  XU_N;

                    scIssueTmpUpdate(nxt);

                    for (NatUns cnt = 2; cnt; cnt--)
                        scIssueAdd(scIA64nopGet(XU_B));

                    goto AGAIN;
                }
            }

            goto MATCH;
        }

        /* Are we supposed to find a stop bit first ? */

        if  (needStop)
            xu = XU_P;

        nxt = scIssueTmpPtr;

    AGAIN:

        for (tmp = nxt->tdNext, stop = NULL;;)
        {
            IA64execUnits   tu;

            nxt = *tmp++;

            if  (!nxt)
            {
                if  (nxtI || nxtM)
                    break;

                if  (stop)
                {
                    templateDsc *   save;

                    /* This is a pretty disgusting hack */

                    save = scIssueTmpPtr;
                           scIssueTmpPtr = stop;

                    xu = scCheckTemplate(id, false);

                           scIssueTmpPtr = save;

                    if  (xu != XU_N)
                    {
                        printf("// UNDONE: need to penalize this case!!!!\n");

                        return  xu;
                    }
                }

                return  XU_N;
            }

            /* See what the next available execution unit is */

            tu = (IA64execUnits)nxt->tdIxu;

            /* Do we have a stop bit ? */

            if  (tu == XU_P)
            {
                /* Remember that we've seen a stop bit */

                stop = nxt;

                /* Do we happen to be looking for a stop bit ? */

                if  (xu == XU_P)
                {
                    /* This must be the stop bit we were looking for */

                    assert(needStop); needStop = false;

//  if  (id->idNum == 55) BreakIfDebuggerPresent();

                    if  (update)
                    {
                        scIssueTmpUpdate(nxt);

                        /* Stop bit has been appended, bump the clock */

                        scCurrentTime++;
                    }

                    /* Now look for the right value right after the stop */

                    xu = genInsXU(ins);
                    goto AGAIN;
                }

                continue;
            }

            /* Does the execution unit match? */

            if  (tu != xu)
            {
                /* Second chance: A can execute as both M and I */

                if  (xu != XU_A || (tu != XU_M && tu != XU_I))
                    continue;
            }

            /* Make sure the functional unit is avaialable */

            if  (scIssueFnBusy[tu])
            {
                /* Check against max. number of execution units */

                assert(scIssueFnMax[XU_M] == 2);
                assert(scIssueFnMax[XU_I] == 2);
                assert(scIssueFnMax[XU_B] == 3);
                assert(scIssueFnMax[XU_F] == 2);

                assert(scIssueFnMax[tu]);

                if  (scIssueFnBusy[tu] >= scIssueFnMax[tu])
                    continue;

                /* Special case: some units are crippled */

                if  (scIssueFnBusy[tu])
                {
                    static
                    BYTE        zeroOnly[FU_COUNT] =
                    {
                        #define FU_DEF(name,F0,I0,M0) ((F0)|(I0<<1)|(M0<<2)),
                        #include "fclsIA64.h"
                    };

                    assert(genInsFU(ins) < FU_COUNT);

                    NatUns      zeroMask = zeroOnly[genInsFU(ins)];

                    switch (tu)
                    {
                    case XU_F: if (zeroMask & 1) continue; else break;
                    case XU_I: if (zeroMask & 2) continue; else break;
                    case XU_M: if (zeroMask & 4) continue; else break;
                    }
                }
            }

            /* Make sure we're not swapping something we shouldn't */

            if  (noSwap && nxt->tdSwap)
                continue;

            /* Everything looks good, we've got a match */

            if  (xu != XU_A)
                break;

            /* We have a A->M/I match, need to decide which mapping to use */

            assert(tu == XU_M || tu == XU_I);

            if  (tu == XU_M)
            {
                /* We have A->M, have we already seen A->I ? */

                nxtM = nxt;

                if  (nxtI)
                    break;
                else
                    continue;
            }
            else
            {
                /* We have A->I, have we already seen A->M ? */

                nxtI = nxt;

                if  (nxtM)
                    break;
                else
                    continue;
            }
        }

        /* We have a match - did we find both A->M and A->I ? */

        if  (nxtI || nxtM)
        {
            if  (nxtI && nxtM)
            {
                scDagNode * node;

                NatUns      rd_I;
                NatUns      rd_M;

                if  (!update)
                    return  XU_A;

                // ISSUE:   The following is a bit dumb, we simply look
                //          at the entries in the current ready list as
                //          well as their immediate dependents and add
                //          up the number of M/I instructions. We then
                //          choose the execution unit that has fewer
                //          instructions ready (or close to being so).

                for (node = scReadyList, rd_I = rd_M = 0;
                     node;
                     node = node->sdnNext)
                {
                    insPtr          ird = scGetIns(node);

                    if  (ird != id)
                    {
                        switch (genInsXU(id->idInsGet()))
                        {
                        case XU_I:
                            rd_I += 3;
                            break;

                        case XU_M:
                            rd_M += 3;
                            break;
                        }

                        scWalkSuccDcl(temp)

                        scWalkSuccBeg(temp, node)
                        {
                            scDagNode   *   succ = scWalkSuccCur(temp);

                            switch (genInsXU(scGetIns(succ)->idInsGet()))
                            {
                            case XU_I:
                                rd_I += 1;
                                break;

                            case XU_M:
                                rd_M += 1;
                                break;
                            }
                        }
                        scWalkSuccEnd(temp)
                    }
                }

//              printf("ISSUE: Potential A->M/I (ready counts: I=%u, M=%u)\n", rd_I, rd_M);

                if  (rd_I > rd_M)
                {
                    xu  = XU_M;
                    nxt = nxtM;
                }
                else
                {
                    xu  = XU_I;
                    nxt = nxtI;
                }
            }
            else
            {
                nxt = nxtI;
                xu  = XU_I;

                if  (!nxtI)
                {
                    nxt = nxtM;
                    xu  = XU_M;
                }
            }
        }

        assert(nxt);
    }

MATCH:

    if  (update)
        scIssueTmpUpdate(nxt);

    return  xu;
}

void                emitter::scIssueAdd(insPtr ins)
{
    NatUns          tmpNum;

    /* Special case: "flush" request */

    if  (!ins)
    {
        NatUns          insCnt = scIssueCnt % 3;

        if  (insCnt)
        {
            insCnt = 3 - insCnt;

//          printf("NOTE: Appending %u nop's to finish bundle\n", insCnt);

            while (insCnt)
            {
                IA64execUnits   xu = scCheckTemplate(NULL, false);

                assert(xu != XU_P);

                scIssueAdd(scIA64nopGet(xu));

                insCnt--;
            }
        }
        else
        {
            assert(scIssueTcc*3 == scIssueCnt);
        }

        if  (!scIssueCnt)
            return;

        assert(scIssueTmp[scIssueTcc - 1]);
        goto ISSUE;
    }
    else
    {
        /* Append the instruction to the issue buffer */

        assert(scIssueCnt < MAX_ISSUE_CNT);

        scIssueNxt->iidIns = ins;

        scIssueNxt++;
        scIssueCnt++;

        /* Unfortunate special case: "L" takes up two slots */

        if  (ins->idIns == INS_mov_reg_i64)
        {
            assert(genInsXU(ins->idInsGet()) == XU_L);

            /* Special case: "L" takes up two slots */

            assert((scIssueCnt % 3) == 2);
            assert(scIssueTmpPtr == &tmpl_M_L);

            scIssueNxt->iidIns = NULL;

            scIssueNxt++;
            scIssueCnt++;
        }
        else
        {
            assert(genInsXU(ins->idInsGet()) != XU_L);
        }

        /* Have we reached a potential split point? */

        if  (scIssueCnt % 3)
            return;
    }

    /* Grab the template number and append it to the table */

    scIssueSwp[scIssueTcc] = (BYTE)scIssueTmpSwp;
    scIssueTmp[scIssueTcc] = (BYTE)scIssueTmpNum; assert(scIssueTmpNum);

    scIssueTcc++;

    /* The template number should always be even */

    tmpNum = scIssueTmpNum - 1; assert((tmpNum & 1) == 0);

    /* Make sure we have a full number of bundles as expected */

    assert((scIssueCnt % 3) == 0);
    assert((scIssueTcc * 3) == scIssueCnt);

    assert((NatUns)tmpNum == (NatUns)(scIssueTmp[scIssueTcc-1] - 1));

    /* Do we have to force a split at this point ? */

    if  (scIssueCnt == MAX_ISSUE_CNT || IA64forceSplit[tmpNum])
    {
#ifdef  DEBUG
        if  (VERBOSE && scIssueCnt < MAX_ISSUE_CNT) printf("NOTE: force-splitting at end of bundle\n");
#endif

    ISSUE:

        scIssueBunch();

        /* The whole thing is gone, clear the issue table */

        scIssueClr(true);

        /* End of instruction group, advance the clock */

        scCurrentTime++;
    }
    else
    {
        /* We can continue accumulating instructions */

        scIssueClr(false);
    }
}

#endif//TGT_IA64
/*****************************************************************************/
#endif//SCHEDULER
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\scheddep.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
        inf      = scInsSchedOpInfo(id);
        flg      = emitComp->instInfo[ins] & (INST_USE_FL|INST_DEF_FL);   // this is a bit rude ....

        extraDep =
        stackDep = false;
        extraReg = SR_NA;

        /* Is this an instruction that may cause an exception? */

        if  (!emitIsTinyInsDsc(id) && id->idInfo.idMayFault)
        {
            if  (scExcpt)
                scAddDep(dagPtr, scExcpt, "Out-", "except", false);

            scExcpt = dagPtr;
        }

        /* Does this instruction require "extra special" handling? */

        extraDep = emitComp->instSpecialSched(ins);
        if  (extraDep)
        {
            extraReg = scSpecInsDep(id, dagPtr, &extraInf);

            /* "xor reg,reg" doesn't actually read "reg" */

            if  (ins == INS_xor    &&
                 fmt == IF_RWR_RRD && id->idReg == id->idRg2)
            {
                assert(inf == (IS_R1_RW|IS_R2_RD));

                inf = IS_R1_WR;
            }
        }

#if     SCHED_USE_FL

        /* Does the instruction define or use flags? */

        if  (flg)
        {
            if  (flg & INST_DEF_FL)
                scDepDefFlg(dagPtr);
            if  (flg & INST_USE_FL)
                scDepUseFlg(dagPtr, dagPtr+1, dagEnd);
        }

#endif

        /* Does the instruction reference the "main"  register operand? */

        if  (inf & IS_R1_RW)
        {
            rg1 = id->idRegGet();

            if  (inf & IS_R1_WR)
                scDepDefReg(dagPtr, rg1);
            if  (inf & IS_R1_RD)
                scDepUseReg(dagPtr, rg1);
        }

        /* Does the instruction reference the "other" register operand? */

        if  (inf & IS_R2_RW)
        {
            rg2 = (emitRegs)id->idRg2;

            if  (inf & IS_R2_WR)
                scDepDefReg(dagPtr, rg2);
            if  (inf & IS_R2_RD)
                scDepUseReg(dagPtr, rg2);
        }

        /* Does the instruction reference a stack frame variable? */

        if  (inf & IS_SF_RW)
        {
            frm = scStkDepIndex(id, fpLo, fpFrmSz,
                                    spLo, spFrmSz, &siz);

            assert(siz == 1 || siz == 2);

//          printf("stkfrm[%u;%u]: %04X\n", frm, siz, (inf & IS_SF_RW));

            unsigned varNum = id->idAddr.iiaLclVar.lvaVarNum;
            if (varNum >= emitComp->info.compLocalsCount ||
                emitComp->lvaVarAddrTaken(varNum))
            {
                /* If the variable is aliased, then track it individually.
                   It will interfere with all indirections.
                   CONSIDER : We cant use lvaVarAddrTaken() for temps,
                   CONSIDER : so cant track them. Should be able to do this */

                amx = scIndDepIndex(id);

                if  (inf & IS_SF_WR)
                    scDepDefInd(dagPtr, id, amx);
                if  (inf & IS_SF_RD)
                    scDepUseInd(dagPtr, id, amx);
            }
            else
            {
                /* If the variable isnt aliased, it is tracked individually */

                if  (inf & IS_SF_WR)
                {
                    scDepDefFrm(dagPtr, id, frm);
                    if  (siz > 1)
                    scDepDefFrm(dagPtr, id, frm+1);
                }
                if  (inf & IS_SF_RD)
                {
                    scDepUseFrm(dagPtr, id, frm);
                    if  (siz > 1)
                    scDepUseFrm(dagPtr, id, frm+1);
                }
            }
        }

        /* Does the instruction reference a global variable? */

        if  (inf & IS_GM_RW)
        {
            MBH = id->idAddr.iiaFieldHnd;

            if  (inf & IS_GM_WR)
                scDepDefGlb(dagPtr, MBH);
            if  (inf & IS_GM_RD)
                scDepUseGlb(dagPtr, MBH);
        }

        /* Does the instruction reference an indirection? */

        if  (inf & IS_INDIR_RW)
        {
            /* Process the indirected value */

            amx = scIndDepIndex(id);

            if  (inf & IS_INDIR_WR)
                scDepDefInd(dagPtr, id, amx);
            if  (inf & IS_INDIR_RD)
                scDepUseInd(dagPtr, id, amx);

            /* Process the address register(s) */

#if TGT_x86
            if  (id->idAddr.iiaAddrMode.amBaseReg != SR_NA)
                scDepUseReg(dagPtr, (emitRegs)id->idAddr.iiaAddrMode.amBaseReg);
            if  (id->idAddr.iiaAddrMode.amIndxReg != SR_NA)
                scDepUseReg(dagPtr, (emitRegs)id->idAddr.iiaAddrMode.amIndxReg);
#else
            if  (1)
                scDepUseReg(dagPtr, (emitRegs)id->idAddr.iiaRegAndFlg.rnfReg);
#endif
        }

        /* Process any fixed target-specific dependencies */

        scTgtDepDep(id, inf, dagPtr);

        /********************************************************************/
        /*                    Update the dependency state                   */
        /********************************************************************/

        /* Does the instruction define or use flags? */

        if  (flg)
        {
            if  (flg & INST_DEF_FL)
                scUpdDefFlg(dagPtr);
            if  (flg & INST_USE_FL)
                scUpdUseFlg(dagPtr);
        }

        /* Does the instruction reference the "main"  register operand? */

        if  (inf & IS_R1_RW)
        {
            assert(rg1 == id->idReg);

            if  (inf & IS_R1_WR)
                scUpdDefReg(dagPtr, rg1);
            if  (inf & IS_R1_RD)
                scUpdUseReg(dagPtr, rg1);
        }

        /* Does the instruction reference the "other" register operand? */

        if  (inf & IS_R2_RW)
        {
            assert(rg2 == id->idRg2);

            if  (inf & IS_R2_WR)
                scUpdDefReg(dagPtr, rg2);
            if  (inf & IS_R2_RD)
                scUpdUseReg(dagPtr, rg2);
        }

        /* Does the instruction reference a stack frame variable? */

        if  (inf & IS_SF_RW)
        {
            unsigned varNum = id->idAddr.iiaLclVar.lvaVarNum;
            if (varNum >= emitComp->info.compLocalsCount ||
                emitComp->lvaVarAddrTaken(varNum))
            {
                /* If the variable is aliased, then track it individually.
                   It will interfere with all indirections.
                   CONSIDER : We cant use lvaVarAddrTaken() for temps,
                   CONSIDER : so cant track them. Should be able to do this */

                assert(amx == scIndDepIndex(id));

                if  (inf & IS_SF_WR)
                    scUpdDefInd(dagPtr, id, amx);
                if  (inf & IS_SF_RD)
                    scUpdUseInd(dagPtr, id, amx);
            }
            else
            {
                if  (inf & IS_SF_WR)
                {
                    scUpdDefFrm(dagPtr, frm);
                    if  (siz > 1)
                    scUpdDefFrm(dagPtr, frm+1);
                }
                if  (inf & IS_SF_RD)
                {
                    scUpdUseFrm(dagPtr, frm);
                    if  (siz > 1)
                    scUpdUseFrm(dagPtr, frm+1);
                }
            }
        }

        /* Does the instruction reference a global variable? */

        if  (inf & IS_GM_RW)
        {
            if  (inf & IS_GM_WR)
                scUpdDefGlb(dagPtr, MBH);
            if  (inf & IS_GM_RD)
                scUpdUseGlb(dagPtr, MBH);
        }

        /* Does the instruction reference an indirection? */

        if  (inf & IS_INDIR_RW)
        {
            /* Process the indirected value */

            assert(amx == scIndDepIndex(id));

            if  (inf & IS_INDIR_WR)
                scUpdDefInd(dagPtr, id, amx);
            if  (inf & IS_INDIR_RD)
                scUpdUseInd(dagPtr, id, amx);

            /* Process the address register(s) */

#if TGT_x86
            if  (id->idAddr.iiaAddrMode.amBaseReg != SR_NA)
                scUpdUseReg(dagPtr, (emitRegs)id->idAddr.iiaAddrMode.amBaseReg);
            if  (id->idAddr.iiaAddrMode.amIndxReg != SR_NA)
                scUpdUseReg(dagPtr, (emitRegs)id->idAddr.iiaAddrMode.amIndxReg);
#else
            if  (1)
                scUpdUseReg(dagPtr, (emitRegs)id->idAddr.iiaRegAndFlg.rnfReg);
#endif

        }

        /* Process any fixed target-specific dependencies */

        scTgtDepUpd(id, inf, dagPtr);

        /* Do we have an "extra" register dependency? */

        if  (extraReg != SR_NA)
        {
            scUpdDefReg(dagPtr, extraReg);
            scUpdUseReg(dagPtr, extraReg);
        }

        /* Any other "extra" dependencies we need to update? */

        if  (extraDep)
            scSpecInsUpd(id, dagPtr, &extraInf);
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\schedx86.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                           schedX86.cpp                                    XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

#include "alloc.h"
#include "instr.h"
#include "emit.h"
#include "target.h"

/*****************************************************************************/
#if     SCHEDULER && TGT_x86
/*****************************************************************************
 *
 *  Records any "extra" target-dependent scheduling dependencies.
 */

emitRegs            emitter::scSpecInsDep(instrDesc   * id,
                                          scDagNode   * dagDsc,
                                          scExtraInfo * xptr)
{
    emitRegs        extraReg;

    /* Assume no additional dependencies will be needed later */

    extraReg       = SR_NA;
    xptr->stackDep = false;

    /* Check for an interesting instruction */

    switch (id->idIns)
    {
    case INS_add:
    case INS_sub:

        /* Check for "add/sub sp, <icon>" */

        if  (id->idInsFmt != IF_RRW_CNS)
            break;
        if  (id->idReg != SR_ESP)
            break;

        // Fall through ...

    case INS_push:
    case INS_pop:

    STACK_DEP:

        scDepUseReg(dagDsc, SR_ESP);
        scDepDefReg(dagDsc, SR_ESP);

        xptr->stackDep = true;
        break;

    case INS_jae:
    case INS_jbe:

        /*
            Can't move "jae/jbe indexError" across push/pop in FPO
            methods (for now), as it messes up ESP level tracking.
         */

        if  (!emitEBPframe)
            goto STACK_DEP;

        break;

    case INS_fstp:

        if  (id->idInsFmt != IF_AWR_TRD)
            break;
        if  (id->idAddr.iiaAddrMode.amBaseReg != SR_ESP)
            break;

        goto STACK_DEP;

    case INS_cdq:
        scDepUseReg(dagDsc, SR_EAX);
        scDepDefReg(dagDsc, SR_EDX);
        scUpdUseReg(dagDsc, SR_EAX);
        scUpdDefReg(dagDsc, SR_EDX);
        break;

    case INS_imulEAX:
    case INS_mulEAX:
        scDepDefReg(dagDsc, SR_EAX);
        scDepDefReg(dagDsc, SR_EDX);
        scDepUseReg(dagDsc, SR_EAX);
        break;

    case INS_div:
    case INS_idiv:
        scDepDefReg(dagDsc, SR_EAX);
        scDepDefReg(dagDsc, SR_EDX);
        scDepUseReg(dagDsc, SR_EAX);
        scDepUseReg(dagDsc, SR_EDX);
        break;

    case INS_sahf:
        scDepUseReg(dagDsc, SR_EAX);
        break;

    case INS_rcl:
    case INS_rcr:
    case INS_shl:
    case INS_shr:
    case INS_sar:

        /* Record dependency on "CL" (actually, ECX) */

        scDepUseReg(dagDsc, SR_ECX);
        break;

    case INS_imul_AX:
    case INS_imul_BX:
    case INS_imul_CX:
    case INS_imul_DX:
    case INS_imul_BP:
    case INS_imul_SI:
    case INS_imul_DI:
        extraReg = ((emitRegs) Compiler::instImulReg((instruction)id->idIns));
        scDepDefReg(dagDsc, extraReg);
        scDepUseReg(dagDsc, extraReg);
        break;

    case INS_r_movsb:
    case INS_r_movsd:
        scDepUseReg(dagDsc, SR_ECX);
        scDepDefReg(dagDsc, SR_ECX);
        scUpdUseReg(dagDsc, SR_ECX);
        scUpdDefReg(dagDsc, SR_ECX);

        // fall through

    case INS_movsd:
    case INS_movsb:
        scDepUseReg(dagDsc, SR_ESI);
        scDepDefReg(dagDsc, SR_ESI);
        scDepUseReg(dagDsc, SR_EDI);
        scDepDefReg(dagDsc, SR_EDI);

        scUpdUseReg(dagDsc, SR_ESI);
        scUpdDefReg(dagDsc, SR_ESI);
        scUpdUseReg(dagDsc, SR_EDI);
        scUpdDefReg(dagDsc, SR_EDI);
        break;

    case INS_r_stosb:
    case INS_r_stosd:
        scDepUseReg(dagDsc, SR_ECX);
        scDepDefReg(dagDsc, SR_ECX);
        scUpdUseReg(dagDsc, SR_ECX);
        scUpdDefReg(dagDsc, SR_ECX);

        // fall through

    case INS_stosb:
    case INS_stosd:
        scDepUseReg(dagDsc, SR_EDI);
        scDepDefReg(dagDsc, SR_EDI);
        scDepUseReg(dagDsc, SR_EAX);

        scUpdUseReg(dagDsc, SR_EDI);
        scUpdDefReg(dagDsc, SR_EDI);
        scUpdUseReg(dagDsc, SR_EAX);
        break;
    }

    return  extraReg;
}

/*****************************************************************************
 *
 *  Updates any "extra" target-dependent scheduling dependencies.
 */

void                emitter::scSpecInsUpd(instrDesc   * id,
                                          scDagNode   * dagDsc,
                                          scExtraInfo * xptr)
{
    /* Do we have an "extra" stack dependency? */

    if  (xptr->stackDep)
    {
        scUpdDefReg(dagDsc, SR_ESP);
        scUpdUseReg(dagDsc, SR_ESP);
    }

    /* Check for an interesting instruction */

    switch (id->idIns)
    {
    case INS_imulEAX:
    case INS_mulEAX:
        scUpdDefReg(dagDsc, SR_EAX);
        scUpdDefReg(dagDsc, SR_EDX);
        scUpdUseReg(dagDsc, SR_EAX);
        break;

    case INS_div:
    case INS_idiv:
        scUpdDefReg(dagDsc, SR_EAX);
        scUpdDefReg(dagDsc, SR_EDX);
        scUpdUseReg(dagDsc, SR_EAX);
        scUpdUseReg(dagDsc, SR_EDX);
        break;

    case INS_sahf:
        scUpdUseReg(dagDsc, SR_EAX);
        break;

    case INS_rcl:
    case INS_rcr:
    case INS_shl:
    case INS_shr:
    case INS_sar:
        scUpdUseReg(dagDsc, SR_ECX);
        break;
    }
}

/*****************************************************************************/
#endif//SCHEDULER && TGT_x86
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\siginfo.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/

#include "jitpch.h"
#pragma hdrstop

#include <corpriv.h>

#undef   Module

#define  INDEBUG(x)
#include "typehandle.h"
#undef   INDEBUG

/*****************************************************************************/

#define DECLARE_DATA

#define Module mdScope

const ElementTypeInfo gElementTypeInfo[] = {
//const MetaSig::ElementTypeInfo MetaSig::m_aTypeInfo[] = {


#ifdef _DEBUG
#define DEFINEELEMENTTYPEINFO(etname, cbsize, gcness, isfp, inreg, base) {(int)(etname),cbsize,gcness,isfp,inreg,base},
#else
#define DEFINEELEMENTTYPEINFO(etname, cbsize, gcness, isfp, inreg, base) {cbsize,gcness,isfp,inreg,base},
#endif

// Meaning of columns:
//
//     name     - The checked build uses this to verify that the table is sorted
//                correctly. This is a lookup table that uses ELEMENT_TYPE_*
//                as an array index.
//
//     cbsize   - The byte size of this value as returned by SizeOf(). SPECIAL VALUE: -1
//                requires type-specific treatment.
//
//     gc       - 0    no embedded objectrefs
//                1    value is an objectref
//                2    value is an interior pointer - promote it but don't scan it
//                3    requires type-specific treatment
//
//
//     fp       - boolean: does this require special fpu treatment on return?
//
//     reg      - put in a register?
//
//                    name                         cbsize               gc      fp reg Base
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_END,            -1,             TYPE_GC_NONE, 0, 0,  0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_VOID,           0,              TYPE_GC_NONE, 0, 0,  0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_BOOLEAN,        1,              TYPE_GC_NONE, 0, 1,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_CHAR,           2,              TYPE_GC_NONE, 0, 1,  1)

DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_I1,             1,              TYPE_GC_NONE, 0, 1,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_U1,             1,              TYPE_GC_NONE, 0, 1,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_I2,             2,              TYPE_GC_NONE, 0, 1,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_U2,             2,              TYPE_GC_NONE, 0, 1,  1)

DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_I4,             4,              TYPE_GC_NONE, 0, 1,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_U4,             4,              TYPE_GC_NONE, 0, 1,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_I8,             8,              TYPE_GC_NONE, 0, 0,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_U8,             8,              TYPE_GC_NONE, 0, 0,  1)

DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_R4,             4,              TYPE_GC_NONE, 1, 0,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_R8,             8,              TYPE_GC_NONE, 1, 0,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_STRING,         sizeof(LPVOID), TYPE_GC_REF,  0, 1,  0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_PTR,            sizeof(LPVOID), TYPE_GC_NONE, 0, 1,  0)

DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_BYREF,          sizeof(LPVOID), TYPE_GC_BYREF, 0, 1, 0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_VALUETYPE,      -1,             TYPE_GC_OTHER, 0, 0,  0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_CLASS,          sizeof(LPVOID), TYPE_GC_REF,   0, 1,  0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_VAR,            sizeof(LPVOID), TYPE_GC_REF, 0, 1,  0)

DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_ARRAY,          sizeof(LPVOID), TYPE_GC_REF,  0, 1,  0)

//DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_COPYCTOR,       sizeof(LPVOID), TYPE_GC_BYREF, 0, 1,  0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_ARRAY+1,        0,              TYPE_GC_NONE, 0, 0,  0)

DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_TYPEDBYREF,         sizeof(LPVOID)*2,TYPE_GC_BYREF, 0, 0,0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_VALUEARRAY,     -1,             TYPE_GC_OTHER, 0, 0, 0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_I,              4,              TYPE_GC_NONE, 0, 1,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_U,              4,              TYPE_GC_NONE, 0, 1,  1)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_R,              8,              TYPE_GC_NONE, 1, 0,  1)
// @todo: VanceM
// Do we need a tuple or a single pointer. Make sure the size is correct.
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_FNPTR,          sizeof(LPVOID), TYPE_GC_NONE, 0, 1,  0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_OBJECT,         sizeof(LPVOID), TYPE_GC_REF, 0, 1,  0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_SZARRAY,        sizeof(LPVOID), TYPE_GC_REF,  0, 1,  0)
DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_SZARRAY+1,      0,              TYPE_GC_NONE, 0, 0,  0)

DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_CMOD_REQD,      -1,             TYPE_GC_NONE,  0, 1,  0)

DEFINEELEMENTTYPEINFO(ELEMENT_TYPE_CMOD_OPT,       -1,             TYPE_GC_NONE,  0, 1,  0)
};


unsigned GetSizeForCorElementType(CorElementType etyp)
{
        _ASSERTE(gElementTypeInfo[etyp].m_elementType == etyp);
        return gElementTypeInfo[etyp].m_cbSize;
}

const ElementTypeInfo* GetElementTypeInfo(CorElementType etyp)
{
        _ASSERTE(gElementTypeInfo[etyp].m_elementType == etyp);
        return &gElementTypeInfo[etyp];
}

BOOL    IsFP(CorElementType etyp)
{
        _ASSERTE(gElementTypeInfo[etyp].m_elementType == etyp);
        return gElementTypeInfo[etyp].m_fp;
}

BOOL    IsBaseElementType(CorElementType etyp)
{
        _ASSERTE(gElementTypeInfo[etyp].m_elementType == etyp);
        return gElementTypeInfo[etyp].m_isBaseType;

}

// This skips one element and no longer checks for and skips a varargs sentinal. [peteku]
VOID SigPointer::Skip()
{
    SkipExactlyOne();
}

VOID SigPointer::SkipExactlyOne()
{
    ULONG typ;

    typ = GetElemType();

    if (!CorIsPrimitiveType((CorElementType)typ))
    {
        switch (typ)
        {
            default:
                _ASSERTE(!"Illegal or unimplement type in CLR sig.");
                break;
            case ELEMENT_TYPE_OBJECT:
            case ELEMENT_TYPE_TYPEDBYREF:
            case ELEMENT_TYPE_U:
            case ELEMENT_TYPE_I:
            case ELEMENT_TYPE_R:
                break;

//          case ELEMENT_TYPE_COPYCTOR:
            case ELEMENT_TYPE_BYREF: //fallthru
            case ELEMENT_TYPE_PTR:
            case ELEMENT_TYPE_PINNED:
            case ELEMENT_TYPE_SZARRAY:
                SkipExactlyOne();              // Skip referenced type
                break;

            case ELEMENT_TYPE_VALUETYPE: //fallthru
            case ELEMENT_TYPE_CLASS:
                GetToken();          // Skip RID
                break;

            case ELEMENT_TYPE_VALUEARRAY:
                SkipExactlyOne();         // Skip element type
                GetData();      // Skip array size
                break;

            case ELEMENT_TYPE_FNPTR:
                {
                    GetData();                  // consume calling convention
                    UINT32 argCnt = GetData();
                    SkipExactlyOne();           // Skip return type
                    while(argCnt > 0) {
                        SkipExactlyOne();       // Skip arg type
                        --argCnt;
                    }
                }
                break;

            case ELEMENT_TYPE_ARRAY:
                {
                    SkipExactlyOne();     // Skip element type
                    UINT32 rank = GetData();    // Get rank
                    if (rank)
                    {
                        UINT32 nsizes = GetData(); // Get # of sizes
                        while (nsizes--)
                        {
                            GetData();           // Skip size
                        }

                        UINT32 nlbounds = GetData(); // Get # of lower bounds
                        while (nlbounds--)
                        {
                            GetData();           // Skip lower bounds
                        }
                    }

                }
                break;

            case ELEMENT_TYPE_SENTINEL:
                break;
        }
    }
}


//------------------------------------------------------------------------
// Get info about single-dimensional arrays
//------------------------------------------------------------------------
VOID SigPointer::GetSDArrayElementProps(SigPointer *pElemType, ULONG *pElemCount) const
{
    SigPointer sp = *this;
    ULONG typ = sp.GetElemType();
    _ASSERTE(typ == ELEMENT_TYPE_VALUEARRAY || typ == ELEMENT_TYPE_SZARRAY);
    *pElemType = sp;
    sp.Skip();
    *pElemCount = sp.GetData();
}

//------------------------------------------------------------------
// Constructor.
//------------------------------------------------------------------

MetaSig::MetaSig(PCCOR_SIGNATURE szMetaSig, Module* pModule,
                 BOOL fConvertSigAsVarArg, MetaSigKind kind)
{
#ifdef _DEBUG
    FillMemory(this, sizeof(*this), 0xcc);
#endif
    m_pModule = pModule;
    m_pszMetaSig = szMetaSig;
    SigPointer psig(szMetaSig);

    if (kind == sigLocalVars)
    {
        m_nArgs     = psig.GetData();  // Store number of arguments.
    }
    else
    {
        m_CallConv = (BYTE)psig.GetCallingConvInfo(); // Store calling convention
        m_nArgs     = psig.GetData();  // Store number of arguments.
        m_pRetType  = psig;
        psig.Skip();
    }

    m_pStart    = psig;
    // used to treat some sigs as special case vararg
    // used by calli to unmanaged target
    m_fTreatAsVarArg = fConvertSigAsVarArg;

    // Intialize the actual sizes
    m_nActualStack = (UINT32) -1;
    m_nVirtualStack = (UINT32) -1;
    m_cbSigSize = (UINT32) -1;

    // Reset the iterator fields
    Reset();
}


//------------------------------------------------------------------
// Returns type of current argument index. Returns ELEMENT_TYPE_END
// if already past end of arguments.
//------------------------------------------------------------------
CorElementType MetaSig::PeekArg()
{
    if (m_iCurArg == m_nArgs)
    {
        return ELEMENT_TYPE_END;
    }
    else
    {
        CorElementType mt = m_pWalk.PeekElemType();
        return mt;
    }
}


//------------------------------------------------------------------
// Returns type of current argument, then advances the argument
// index. Returns ELEMENT_TYPE_END if already past end of arguments.
//------------------------------------------------------------------
CorElementType MetaSig::NextArg()
{
    m_pLastType = m_pWalk;
    if (m_iCurArg == m_nArgs)
    {
        return ELEMENT_TYPE_END;
    }
    else
    {
        m_iCurArg++;
        CorElementType mt = m_pWalk.PeekElemType();
        m_pWalk.Skip();
        return mt;
    }
}

//------------------------------------------------------------------
// Retreats argument index, then returns type of the argument
// under the new index. Returns ELEMENT_TYPE_END if already at first
// argument.
//------------------------------------------------------------------
CorElementType MetaSig::PrevArg()
{
    if (m_iCurArg == 0)
    {
        return ELEMENT_TYPE_END;
    }
    else
    {
        m_iCurArg--;
        m_pWalk = m_pStart;
        for (UINT32 i = 0; i < m_iCurArg; i++)
        {
            m_pWalk.Skip();
        }
        m_pLastType = m_pWalk;
        return m_pWalk.PeekElemType();
    }
}

//------------------------------------------------------------------------
// Returns # of arguments. Does not count the return value.
// Does not count the "this" argument (which is not reflected om the
// sig.) 64-bit arguments are counted as one argument.
//------------------------------------------------------------------------
/*static*/ UINT MetaSig::NumFixedArgs(Module* pModule, PCCOR_SIGNATURE pSig)
{
    MetaSig msig(pSig, pModule);

    return msig.NumFixedArgs();
}

//------------------------------------------------------------------
// reset: goto start pos
//------------------------------------------------------------------
VOID MetaSig::Reset()
{
    m_pWalk = m_pStart;
    m_iCurArg  = 0;
}

//------------------------------------------------------------------
// Moves index to end of argument list.
//------------------------------------------------------------------
VOID MetaSig::GotoEnd()
{
    m_pWalk = m_pStart;
    for (UINT32 i = 0; i < m_nArgs; i++)
    {
        m_pWalk.Skip();
    }
    m_iCurArg = m_nArgs;

}



//------------------------------------------------------------------------
// Tests for the existence of a custom modifier
//------------------------------------------------------------------------
BOOL SigPointer::HasCustomModifier(Module *pModule, LPCSTR szModName, CorElementType cmodtype) const
{
    return FALSE;
}

CorElementType SigPointer::Normalize(Module* pModule) const
{
    CorElementType type = PeekElemType();
    return Normalize(pModule, type);
}

CorElementType SigPointer::Normalize(Module* pModule, CorElementType type) const
{
    if (type == ELEMENT_TYPE_VALUETYPE)
    {

#if 0

        TypeHandle typeHnd = GetTypeHandle(pModule);        // @TODO we probably could get away with not loading this

        // If we cannot resolve to the type, we cannot determine that a value type is
        // actually an enum is actually an int32 (or whatever).  Except for wierd race
        // conditions where the type becomes available a little later and proves to be
        // an enum=int32, it's fine for us to say "it's a value class" here.  Later the
        // calling code will notice that it can't figure out what kind of value class
        // and will generate a more appropriate error.
        //
        // @TODO -- cwb/vancem -- in M11, allow GetTypeHandle to throw the exception.
        // The JITs will tolerate this.  The check for IsNull() here can go away & the
        // race condition will be eliminated.
        if (!typeHnd.IsNull())
            return(typeHnd.GetNormCorElementType());

#endif

    }
    return(type);
}

#if 0

CorElementType MetaSig::PeekArgNormalized()
{
    if (m_iCurArg == m_nArgs)
    {
        return ELEMENT_TYPE_END;
    }
    else
    {
        CorElementType mt = m_pWalk.Normalize(m_pModule);
        return mt;
    }
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\schedsh3.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                             schedSH3.cpp                                  XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

#include "alloc.h"
#include "instr.h"
#include "emit.h"
#include "target.h"

/*****************************************************************************/
#if     SCHEDULER && TGT_SH3
/*****************************************************************************
 *
 *  We store two values in each entry of the "extra dependency" table, with
 *  the "write" value shifted by the following amount.
 */

const
unsigned        SCHED_XDEP_SHF = 4;

/*****************************************************************************
 *
 *  Records any "extra" target-dependent scheduling dependencies.
 */

emitRegs            emitter::scSpecInsDep(instrDesc   * id,
                                          scDagNode   * dagDsc,
                                          scExtraInfo * xptr)
{
    unsigned        extra;
    unsigned        extraRD;
    unsigned        extraWR;

    /* Make sure the bits in our table don't overlap */

    assert(SCHED_XDEP_ALL < 1 << SCHED_XDEP_SHF);

    static
    BYTE            extraDep[] =
    {
        #define INST1(id, nm, bd, um, rf, wf, rx, wx, br, i1         ) (wx)<<SCHED_XDEP_SHF|(rx),
        #define INST2(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2     ) (wx)<<SCHED_XDEP_SHF|(rx),
        #define INST3(id, nm, bd, um, rf, wf, rx, wx, br, i1, i2, i3 ) (wx)<<SCHED_XDEP_SHF|(rx),
        #include "instrSH3.h"
        #undef  INST1
        #undef  INST2
        #undef  INST3
    };

    /* Get hold of the "extra dependency" bitset for our instruction */

    assert(id->idIns < sizeof(extraDep)/sizeof(extraDep[0]));

    extra   = extraDep[id->idIns];

    extraRD = extra &  SCHED_XDEP_ALL;
    extraWR = extra >> SCHED_XDEP_SHF;

//  printf("%10s %02X[XR=%1X,XW=%1X]\n", emitComp->genInsName(id->idIns), extra, extraRD, extraWR);

    /* Process any read and write dependencies */

    if  (extraRD)
    {
        if  (extraRD & SCHED_XDEP_PR ) scDepUse(dagDsc, "MAC", scMACdef, scMACuse);
        if  (extraRD & SCHED_XDEP_MAC) scDepUse(dagDsc, "PR" , scPRRdef, scPRRuse);
    }

    if  (extraWR)
    {
        if  (extraWR & SCHED_XDEP_PR ) scDepDef(dagDsc, "MAC", scMACdef, scMACuse);
        if  (extraWR & SCHED_XDEP_MAC) scDepDef(dagDsc, "PR" , scPRRdef, scPRRuse);
    }

    return SR_NA;
}

/*****************************************************************************
 *
 *  Updates any "extra" target-dependent scheduling dependencies.
 */

void                emitter::scSpecInsUpd(instrDesc   * id,
                                          scDagNode   * dagDsc,
                                          scExtraInfo * xptr)
{
    unsigned        extra;
    unsigned        extraRD;
    unsigned        extraWR;

    /* Get hold of the "extra dependency" bitset for our instruction */

    extra   = xptr->scxDeps;

    extraRD = extra &  SCHED_XDEP_ALL;
    extraWR = extra >> SCHED_XDEP_SHF;

    /* Process any read and write dependencies */

    if  (extraRD)
    {
        if  (extraRD & SCHED_XDEP_PR ) scUpdUse(dagDsc, &scMACdef, &scMACuse);
        if  (extraRD & SCHED_XDEP_MAC) scUpdUse(dagDsc, &scPRRdef, &scPRRuse);
    }

    if  (extraWR)
    {
        if  (extraWR & SCHED_XDEP_PR ) scUpdDef(dagDsc, &scMACdef, &scMACuse);
        if  (extraWR & SCHED_XDEP_MAC) scUpdDef(dagDsc, &scPRRdef, &scPRRuse);
    }
}

/*****************************************************************************/
#endif//SCHEDULER && TGT_SH3
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\scopeinfo.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                                  ScopeInfo                                XX
XX                                                                           XX
XX   Classes to gather the Scope information from the local variable info.   XX
XX   Translates the given LocalVarTab from IL offsets into EIP.        XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

/******************************************************************************
 *                                  Debuggable code
 *
 *  We break up blocks at the start and end IL ranges of the local variables.
 *  This is because IL offsets do not correspond exactly to native offsets
 *  except at block boundaries. No basic-blocks are deleted (not even
 *  unreachable), so there will not be any missing address-ranges, though the
 *  blocks themselves may not be ordered. (Also internal blocks may be added).
 *  o At the start of each basic block, siBeginBlock() checks if any variables
 *    are coming in scope, adds an open scope to siOpenScopeList if needed.
 *  o At the end of each basic block, siEndBlock() checks if any variables
 *    are going out of scope and moves the open scope from siOpenScopeLast
 *    to siScopeList.
 *
 *                                  Optimized code
 *
 *  We cannot break up the blocks as this will produce different code under
 *  the debugger. Instead we try to do a best effort.
 *  o At the start of each basic block, siBeginBlock() adds open scopes
 *    corresponding to compCurBB->bbLiveIn to siOpenScopeList. Also siUpdate()
 *    is called to close scopes for variables which are not live anymore.
 *  o siEndBlock() closes scopes for any variables which goes out of range
 *    before (bbCodeOffs+bbCodeSize).
 *  o siCloseAllOpenScopes() closes any open scopes after all the blocks.
 *    This should only be needed if some basic block are deleted/out of order,
 *    etc.
 *  Also,
 *  o At every assignment to a variable, siCheckVarScope() adds an open scope
 *    for the variable being assigned to.
 *  o genChangeLife() calls siUpdate() which closes scopes for variables which
 *    are not live anymore.
 *
 ******************************************************************************
 */

#include "jitpch.h"
#pragma hdrstop
#include "emit.h"

/*****************************************************************************/
#ifdef DEBUGGING_SUPPORT
/*****************************************************************************/

bool        Compiler::siVarLoc::vlIsInReg(regNumber     reg)
{
    switch(vlType)
    {
    case VLT_REG:       return ( vlReg.vlrReg      == reg);
    case VLT_REG_REG:   return ((vlRegReg.vlrrReg1 == reg) ||
                                (vlRegReg.vlrrReg2 == reg));
    case VLT_REG_STK:   return ( vlRegStk.vlrsReg  == reg);
    case VLT_STK_REG:   return ( vlStkReg.vlsrReg  == reg);

    case VLT_STK:
    case VLT_STK2:
    case VLT_FPSTK:     return false;

    default:            ASSert(!"Bad locType");
                        return false;
    }
}

bool        Compiler::siVarLoc::vlIsOnStk(regNumber     reg,
                                          signed        offset)
{
    switch(vlType)
    {

    case VLT_REG_STK:   return ((vlRegStk.vlrsStk.vlrssBaseReg == reg) &&
                                (vlRegStk.vlrsStk.vlrssOffset  == offset));
    case VLT_STK_REG:   return ((vlStkReg.vlsrStk.vlsrsBaseReg == reg) &&
                                (vlStkReg.vlsrStk.vlsrsOffset  == offset));
    case VLT_STK:       return ((vlStk.vlsBaseReg == reg) &&
                                (vlStk.vlsOffset  == offset));
    case VLT_STK2:      return ((vlStk2.vls2BaseReg == reg) &&
                                ((vlStk2.vls2Offset == offset) ||
                                 (vlStk2.vls2Offset == (offset - 4))));

    case VLT_REG:
    case VLT_REG_REG:
    case VLT_FPSTK:     return false;

    default:            ASSert(!"Bad locType");
                        return false;
    }
}

/*============================================================================
 *
 *              Implementation for ScopeInfo
 *
 *
 * Whenever a variable comes into scope, add it to the list.
 * When a varDsc goes dead, end its previous scope entry, and make a new one
 * which is unavailable
 * When a varDsc goes live, end its previous un-available entry (if any) and
 * set its new entry as available.
 *
 *============================================================================
 */


/*****************************************************************************
 *                      siNewScope
 *
 * Creates a new scope and adds it to the Open scope list.
 */

Compiler::siScope *         Compiler::siNewScope( unsigned short LVnum,
                                                  unsigned       varNum,
                                                  bool           avail)
{
    bool        tracked      = lvaTable[varNum].lvTracked;
    unsigned    varIndex     = lvaTable[varNum].lvVarIndex;

    if (tracked)
    {
        siEndTrackedScope(varIndex);
    }


    siScope * newScope       = (siScope*) compGetMem(sizeof(*newScope));

#if!TGT_IA64
    newScope->scStartBlock   = genEmitter->emitCurBlock();
    newScope->scStartBlkOffs = genEmitter->emitCurOffset();
#endif

    assert(newScope->scStartBlock);

    newScope->scEndBlock     = NULL;
    newScope->scEndBlkOffs   = 0;

    newScope->scLVnum        = LVnum;
    newScope->scVarNum       = varNum;
    newScope->scAvailable    = avail;
    newScope->scNext         = NULL;
#if TGT_x86
    newScope->scStackLevel   = genStackLevel;       // used only by stack vars
#endif

    siOpenScopeLast->scNext  = newScope;
    newScope->scPrev         = siOpenScopeLast;
    siOpenScopeLast          = newScope;

    if (tracked)
    {
        siLatestTrackedScopes[varIndex] = newScope;
    }

    return newScope;
}



/*****************************************************************************
 *                          siRemoveFromOpenScopeList
 *
 * Removes a scope from the open-scope list and puts it into the done-scope list
 */

void        Compiler::siRemoveFromOpenScopeList(Compiler::siScope * scope)
{
    assert(scope);
    assert(scope->scEndBlock);

    // Remove from open-scope list

    scope->scPrev->scNext       = scope->scNext;
    if (scope->scNext)
    {
        scope->scNext->scPrev   = scope->scPrev;
    }
    else
    {
        siOpenScopeLast         = scope->scPrev;
    }

    // Add to the finished scope list. (Try to) filter out scopes of length 0.

    if (scope->scStartBlock   != scope->scEndBlock ||
        scope->scStartBlkOffs != scope->scEndBlkOffs)
    {
        siScopeLast->scNext     = scope;
        siScopeLast             = scope;
        siScopeCnt++;
    }
}



/*----------------------------------------------------------------------------
 * These functions end scopes given different types of parameters
 *----------------------------------------------------------------------------
 */


/*****************************************************************************
 * For tracked vars, we dont need to search for the scope in the list as we
 * have a pointer to the open scopes of all tracked variables
 */

void        Compiler::siEndTrackedScope(unsigned varIndex)
{
    siScope * scope     = siLatestTrackedScopes[varIndex];
    if (!scope)
        return;

#if!TGT_IA64
    scope->scEndBlock    = genEmitter->emitCurBlock();
    scope->scEndBlkOffs  = genEmitter->emitCurOffset();
#endif

    assert(scope->scEndBlock);

    siRemoveFromOpenScopeList(scope);

    siLatestTrackedScopes[varIndex] = NULL;
}


/*****************************************************************************
 * If we dont know that the variable is tracked, this function handles both
 * cases.
 */

void        Compiler::siEndScope(unsigned varNum)
{
    for (siScope * scope = siOpenScopeList.scNext; scope; scope = scope->scNext)
    {
        if (scope->scVarNum == varNum)
        {
#if!TGT_IA64
            scope->scEndBlock    = genEmitter->emitCurBlock();
            scope->scEndBlkOffs  = genEmitter->emitCurOffset();
#endif

            assert(scope->scEndBlock);

            siRemoveFromOpenScopeList(scope);

            LclVarDsc & lclVarDsc1  = lvaTable[varNum];
            if (lclVarDsc1.lvTracked)
            {
                siLatestTrackedScopes[lclVarDsc1.lvVarIndex] = NULL;
            }

            return;
        }
    }

    // At this point, we probably have a bad LocalVarTab

    if (opts.compDbgCode)
    {
        // LocalVarTab is good?? Then WE messed up.
        assert(!siVerifyLocalVarTab());

        opts.compScopeInfo = false;
    }
}



/*****************************************************************************
 * If we have a handle to the siScope structure, we handle ending this scope
 * differenly than if we just had a variable number. This saves us searching
 * the open-scope list again.
 */

void        Compiler::siEndScope(siScope * scope)
{

#if!TGT_IA64
    scope->scEndBlock    = genEmitter->emitCurBlock();
    scope->scEndBlkOffs  = genEmitter->emitCurOffset();
#endif

    assert(scope->scEndBlock);

    siRemoveFromOpenScopeList(scope);

    LclVarDsc & lclVarDsc1  = lvaTable[scope->scVarNum];
    if (lclVarDsc1.lvTracked)
    {
        siLatestTrackedScopes[lclVarDsc1.lvVarIndex] = NULL;
    }
}



/*****************************************************************************
 *                          siIgnoreBlock
 *
 * If the block is an internally created block, or does not correspond
 * to any IL opcodes (eg. monitor-enter and exit), then we dont
 * need to update LocalVar info
 */

bool        Compiler::siIgnoreBlock(BasicBlock * block)
{
    if ((block->bbFlags & BBF_INTERNAL) || (block->bbCodeSize == 0))
    {
        return true;
    }

    return false;
}


/*****************************************************************************
 *                          siBeginBlockSkipSome
 *
 * If the current block does not follow the previous one in terms of
 * IL ordering, then we have to walk the scope lists to see if
 * there are any scopes beginning or closing at the missing IL.
 */

/* static */
void        Compiler::siNewScopeCallback(LocalVarDsc * var, unsigned clientData)
{
    Assert(var && clientData, ((Compiler*)clientData));

    ((Compiler*)clientData)->siNewScope(var->lvdLVnum, var->lvdVarNum);
}

/* static */
void        Compiler::siEndScopeCallback(LocalVarDsc * var, unsigned clientData)
{
    Assert(var && clientData, ((Compiler*)clientData));

    ((Compiler*)clientData)->siEndScope(var->lvdVarNum);
}



/*****************************************************************************
 *                      siVerifyLocalVarTab
 *
 * Checks the LocalVarTab for consistency. The VM may not have properly
 * verified the LocalVariableTable.
 */

#ifdef DEBUG

bool            Compiler::siVerifyLocalVarTab()
{
    // No entries with overlapping lives should have the same slot.

    for (unsigned i=0; i<info.compLocalVarsCount; i++)
    {
        for (unsigned j=i+1; j<info.compLocalVarsCount; j++)
        {
            unsigned slot1  = info.compLocalVars[i].lvdVarNum;
            unsigned beg1   = info.compLocalVars[i].lvdLifeBeg;
            unsigned end1   = info.compLocalVars[i].lvdLifeEnd;

            unsigned slot2  = info.compLocalVars[j].lvdVarNum;
            unsigned beg2   = info.compLocalVars[j].lvdLifeBeg;
            unsigned end2   = info.compLocalVars[j].lvdLifeEnd;

            if (slot1==slot2 && (end1>beg2 && beg1<end2))
            {
                return false;
            }
        }
    }

    return true;
}

#endif



/*============================================================================
 *           INTERFACE (public) Functions for ScopeInfo
 *============================================================================
 */


void            Compiler::siInit()
{

#if TGT_IA64

    UNIMPL("scope info");

#else

    assert(IJitDebugInfo::REGNUM_EAX == REG_EAX);
    assert(IJitDebugInfo::REGNUM_ECX == REG_ECX);
    assert(IJitDebugInfo::REGNUM_EDX == REG_EDX);
    assert(IJitDebugInfo::REGNUM_EBX == REG_EBX);
    assert(IJitDebugInfo::REGNUM_ESP == REG_ESP);
    assert(IJitDebugInfo::REGNUM_EBP == REG_EBP);
    assert(IJitDebugInfo::REGNUM_ESI == REG_ESI);
    assert(IJitDebugInfo::REGNUM_EDI == REG_EDI);

    assert(IJitDebugInfo::VLT_REG        ==      Compiler::VLT_REG    );
    assert(IJitDebugInfo::VLT_STK        ==      Compiler::VLT_STK    );
    assert(IJitDebugInfo::VLT_REG_REG    ==      Compiler::VLT_REG_REG);
    assert(IJitDebugInfo::VLT_REG_STK    ==      Compiler::VLT_REG_STK);
    assert(IJitDebugInfo::VLT_STK_REG    ==      Compiler::VLT_STK_REG);
    assert(IJitDebugInfo::VLT_STK2       ==      Compiler::VLT_STK2   );
    assert(IJitDebugInfo::VLT_FPSTK      ==      Compiler::VLT_FPSTK  );
    assert(IJitDebugInfo::VLT_MEMORY     ==      Compiler::VLT_MEMORY  );
    assert(IJitDebugInfo::VLT_COUNT      ==      Compiler::VLT_COUNT  );
    assert(IJitDebugInfo::VLT_INVALID    ==      Compiler::VLT_INVALID  );

    /* IJitDebugInfo::VarLoc and siVarLoc should overlap exactly as we cast
     * one to the other in eeSetLVinfo()
     * Below is a "reqired but not sufficient" condition
     */

    assert(sizeof(IJitDebugInfo::VarLoc) == sizeof(Compiler::siVarLoc));

    assert(opts.compScopeInfo && info.compLocalVarsCount>0);

    assert(compEnterScopeList);
    assert(compExitScopeList);

    siOpenScopeList.scNext = NULL;
    siOpenScopeLast        = & siOpenScopeList;
    siScopeLast            = & siScopeList;

    for (unsigned i=0; i<lclMAX_TRACKED; i++)
    {
        siLatestTrackedScopes[i] = NULL;
    }

    siScopeCnt          = 0;
    siLastStackLevel    = 0;
    siLastLife          = 0;
    siLastEndOffs       = 0;

#endif

}



/*****************************************************************************
 *                          siBeginBlock
 *
 * Called at the beginning of code-gen for a block. Checks if any scopes
 * need to be opened.
 */

void        Compiler::siBeginBlock()
{
    assert(opts.compScopeInfo && info.compLocalVarsCount>0);

    LocalVarDsc * LocalVarDsc1;

    if (!opts.compDbgCode)
    {
        /* For non-debuggable code */

        // End scope of variable which are not live for this block

        siUpdate();

        // Check that vars which are live on entry have an open scope

        unsigned i;
        VARSET_TP varbit, liveIn = compCurBB->bbLiveIn;

        for (i = 0, varbit=1;
            (i < lvaTrackedCount) && (liveIn);
            varbit<<=1, i++)
        {
            if (!(varbit & liveIn))
                continue;

            liveIn &= ~varbit;
            siCheckVarScope(lvaTrackedVarNums[genVarBitToIndex(varbit)],
                            compCurBB->bbCodeOffs);
        }
    }
    else
    {
        // For debuggable code, scopes can begin only on block-boundaries.
        // Check if there are any scopes on the current block's start boundary.

        if  (siIgnoreBlock(compCurBB))
            return;

        if  (siLastEndOffs != compCurBB->bbCodeOffs)
        {
            assert(siLastEndOffs < compCurBB->bbCodeOffs);
            siBeginBlockSkipSome();
            return;
        }

        while (LocalVarDsc1 = compGetNextEnterScope(compCurBB->bbCodeOffs))
        {
            siScope *   scope = siNewScope(LocalVarDsc1->lvdLVnum, LocalVarDsc1->lvdVarNum);

            assert(compCurBB);
            LclVarDsc * lclVarDsc1 = &lvaTable[LocalVarDsc1->lvdVarNum];
            assert(  !lclVarDsc1->lvTracked                                   \
                    || (genVarIndexToBit(lclVarDsc1->lvVarIndex) & compCurBB->bbLiveIn) );
        }
    }
}

/*****************************************************************************
 *                          siEndBlock
 *
 * Called at the end of code-gen for a block. Any closing scopes are marked
 * as such. Note that if we are collecting LocalVar info, scopes can
 * only begin or end at block boundaries for debuggable code.
 */

void        Compiler::siEndBlock()
{
    assert(opts.compScopeInfo && info.compLocalVarsCount>0);

    if (siIgnoreBlock(compCurBB))
        return;

    LocalVarDsc * LocalVarDsc1;
    unsigned      endOffs = compCurBB->bbCodeOffs + compCurBB->bbCodeSize;

    // If non-debuggable code, find all scopes which end over this block
    // and close them. For debuggable code, scopes will only end on block
    // boundaries.

    while (LocalVarDsc1 = compGetNextExitScope(endOffs, !opts.compDbgCode))
    {
        unsigned    varNum     = LocalVarDsc1->lvdVarNum;
        LclVarDsc * lclVarDsc1 = &lvaTable[varNum];

        assert(lclVarDsc1);

        if (lclVarDsc1->lvTracked)
        {
            siEndTrackedScope(lclVarDsc1->lvVarIndex);
        }
        else
        {
            siEndScope(LocalVarDsc1->lvdVarNum);
        }
    }

    siLastEndOffs = endOffs;

#ifdef DEBUG
    if (verbose&&0) siDispOpenScopes();
#endif

}

/*****************************************************************************
 *                          siUpdate
 *
 * Called at the start of basic blocks, and during code-gen of a block,
 * for non-debuggable code, whenever the
 * life of any tracked variable changes and the appropriate code has
 * been generated. For debuggable code, variables are
 * live over their enitre scope, and so they go live or dead only on
 * block boundaries.
 */

void        Compiler::siUpdate ()
{
    assert(opts.compScopeInfo && !opts.compDbgCode && info.compLocalVarsCount>0);

    unsigned        i;
    VARSET_TP       varbit, killed = siLastLife & ~genCodeCurLife & lvaTrackedVars;

    for (i = 0, varbit=1;
        (i < lvaTrackedCount) && (killed);
        varbit<<=1, i++)
    {
        if (! (varbit & killed))
            continue;

        killed             &= ~varbit;       // delete the bit
        unsigned varIndex   = genVarBitToIndex(varbit);

        assert(lvaTable[lvaTrackedVarNums[varIndex]].lvTracked);

        siScope * scope = siLatestTrackedScopes[varIndex];
        siEndTrackedScope(varIndex);

        if (scope)
        {
            /* @TODO : A variable dies when its GenTree is processed,
             * even before the corresponding instruction has been emitted.
             * We need to extend the lifetime a bit (even by 1 byte)
             * for correct results
             */

//          assert(!"Var should go dead *after* the current instr is emitted");
        }
    }

    siLastLife = genCodeCurLife;
}

/*****************************************************************************
 *  In optimized code, we may not have access to gtLclVar.gtLclOffs.
 *  So there may be ambiguity as to which entry in info.compLocalVars
 *  to use. We search the entire table and find the entry whose life
 *  begins closest to the given offset
 */

void            Compiler::siNewScopeNear(unsigned           varNum,
                                         NATIVE_IP          offs)
{
    assert(opts.compDbgInfo && !opts.compDbgCode);

    LocalVarDsc *   local           = info.compLocalVars;
    int             closestLifeBeg  = INT_MAX;
    LocalVarDsc *   closestLocal    = NULL;

    for (unsigned i=0; i<info.compLocalVarsCount; i++, local++)
    {
        if (local->lvdVarNum == varNum)
        {
            int diff = local->lvdLifeBeg - offs;
            if (diff < 0) diff = -diff;

            if (diff < closestLifeBeg)
            {
                closestLifeBeg = diff;
                closestLocal   = local;
            }
        }
    }

    assert(closestLocal);
    siNewScope(closestLocal->lvdLVnum, varNum, true);
}

/*****************************************************************************
 *                          siCheckVarScope
 *
 * For non-debuggable code, whenever we come across a GenTree which is an
 * assignment to a local variable, this function is called to check if the
 * variable has an open scope. Also, check if it has the correct LVnum.
 */

void            Compiler::siCheckVarScope (unsigned         varNum,
                                           IL_OFFSET        offs)
{
    assert(opts.compScopeInfo && !opts.compDbgCode && info.compLocalVarsCount>0);

    siScope *       scope;
    LclVarDsc *     lclVarDsc1 = &lvaTable[varNum];

    // If there is an open scope correspongind to varNum, find it

    if (lclVarDsc1->lvTracked)
    {
        scope = siLatestTrackedScopes[lclVarDsc1->lvVarIndex];
    }
    else
    {
        for (scope = siOpenScopeList.scNext; scope; scope = scope->scNext)
        {
            if (scope->scVarNum == varNum)
                break;
        }
    }

    // UNDONE : This needs to be changed to do a better lookup

    // Look up the info.compLocalVars[] to find the local var info for (varNum->lvSlotNum, offs)

    LocalVarDsc * LocalVarDsc1 = NULL;

    for (unsigned i=0; i<info.compLocalVarsCount; i++)
    {
        if (   (info.compLocalVars[i].lvdVarNum  == varNum)
            && (info.compLocalVars[i].lvdLifeBeg <= offs)
            && (info.compLocalVars[i].lvdLifeEnd >  offs) )
        {
            LocalVarDsc1 = & info.compLocalVars[i];
            break;
        }
    }

    // UNDONE
    //assert(LocalVarDsc1 || !"This could be coz of a temp. Need to handle that case");
    if (!LocalVarDsc1)
        return;

    // If the currently open scope does not have the correct LVnum, close it
    // and create a new scope with this new LVnum

    if (scope)
    {
        if (scope->scLVnum != LocalVarDsc1->lvdLVnum)
        {
            siEndScope (scope);
            siNewScope (LocalVarDsc1->lvdLVnum, LocalVarDsc1->lvdVarNum);
        }
    }
    else
    {
        siNewScope (LocalVarDsc1->lvdLVnum, LocalVarDsc1->lvdVarNum);
    }
}



/*****************************************************************************
 *                          siStackLevelChanged
 *
 * If the code-gen changes the stack, we have to change the stack-offsets
 * of any live stack variables we may have.
 */

void            Compiler::siStackLevelChanged()
{
    assert(opts.compScopeInfo && info.compLocalVarsCount>0);

#if TGT_x86
    if (genStackLevel == siLastStackLevel)
        return;
    else
        siLastStackLevel = genStackLevel;
#endif

    // If EBP is used for both parameters and locals, do nothing

    if (genFPused)
    {
#if DOUBLE_ALIGN
        assert(!genDoubleAlign);
#endif
        return;
    }

    if (siOpenScopeList.scNext == NULL)
    {
        return;
    }

    siScope * last = siOpenScopeLast;
    siScope * prev = NULL;

    for (siScope * scope = siOpenScopeList.scNext; ; scope = scope->scNext)
    {
        siScope *   newScope;

        if (prev == last)
            break;
        else
            prev = scope;

        assert(scope);

        // ignore register variables
        if (lvaTable[scope->scVarNum].lvRegister)
            continue;

        // ignore EBP-relative vars
        if  (lvaTable[scope->scVarNum].lvFPbased)
            continue;

        siEndScope(scope);

        newScope = siNewScope(scope->scLVnum, scope->scVarNum, scope->scAvailable);
    }
}

/*****************************************************************************
 *                          siCloseAllOpenScopes
 *
 * For unreachable code, or optimized code with blocks reordered, there may be
 * scopes left open at the end. Simply close them.
 */

void            Compiler::siCloseAllOpenScopes()
{
    assert(siOpenScopeList.scNext);

    while(siOpenScopeList.scNext)
        siEndScope(siOpenScopeList.scNext);
}

/*****************************************************************************
 *                          siDispOpenScopes
 *
 * Displays all the vars on the open-scope list
 */

#ifdef DEBUG

void            Compiler::siDispOpenScopes()
{
    assert(opts.compScopeInfo && info.compLocalVarsCount>0);

    printf ("Open scopes = ");

    for (siScope * scope = siOpenScopeList.scNext; scope; scope = scope->scNext)
    {
        LocalVarDsc * localVars = info.compLocalVars;

        for (unsigned i=0; i < info.compLocalVarsCount; i++, localVars++)
        {
            if (localVars->lvdLVnum == scope->scLVnum)
            {
                printf ("%s ", lvdNAMEstr(localVars->lvdName));
                break;
            }
        }
    }
    printf ("\n");
}

#endif



/*============================================================================
 *
 *              Implementation for PrologScopeInfo
 *
 *============================================================================
 */


/*****************************************************************************
 *                      psiNewPrologScope
 *
 * Creates a new scope and adds it to the Open scope list.
 */

Compiler::psiScope *
                Compiler::psiNewPrologScope(unsigned        LVnum,
                                            unsigned        slotNum)
{
    psiScope * newScope = (psiScope *) compGetMem(sizeof(*newScope));

#if!TGT_IA64
    newScope->scStartBlock   = genEmitter->emitCurBlock();
    newScope->scStartBlkOffs = genEmitter->emitCurOffset();
#endif

    assert(newScope->scStartBlock);

    newScope->scEndBlock     = NULL;
    newScope->scEndBlkOffs   = 0;

    newScope->scLVnum        = LVnum;
    newScope->scSlotNum      = slotNum;

    newScope->scNext         = NULL;
    psiOpenScopeLast->scNext = newScope;
    newScope->scPrev         = psiOpenScopeLast;
    psiOpenScopeLast         = newScope;

    return newScope;
}



/*****************************************************************************
 *                          psiEndPrologScope
 *
 * Remove the scope from the Open-scope list and add it to the finished-scopes
 * list if its length is non-zero
 */

void                Compiler::psiEndPrologScope(psiScope * scope)
{

#if!TGT_IA64
    scope->scEndBlock    = genEmitter->emitCurBlock();
    scope->scEndBlkOffs  = genEmitter->emitCurOffset();
#endif

    assert(scope->scEndBlock);

    // Remove from open-scope list
    scope->scPrev->scNext       = scope->scNext;
    if (scope->scNext)
    {
        scope->scNext->scPrev   = scope->scPrev;
    }
    else
    {
        psiOpenScopeLast        = scope->scPrev;
    }

    // add to the finished scope list, if the length is non-zero.
    if (scope->scStartBlock   != scope->scEndBlock ||
        scope->scStartBlkOffs != scope->scEndBlkOffs)
    {
        psiScopeLast->scNext = scope;
        psiScopeLast         = scope;
        psiScopeCnt++;
    }
}



/*============================================================================
 *           INTERFACE (public) Functions for PrologScopeInfo
 *============================================================================
 */

/*****************************************************************************
 *                          psiBegProlog
 *
 * Initializes the PrologScopeInfo, and creates open scopes for all the
 * parameters of the method.
 */

void                Compiler::psiBegProlog()
{
    LocalVarDsc * LocalVarDsc1;

    psiOpenScopeList.scNext     = NULL;
    psiOpenScopeLast            = &psiOpenScopeList;
    psiScopeLast                = &psiScopeList;
    psiScopeCnt                 = 0;

    compResetScopeLists();

    while (LocalVarDsc1 = compGetNextEnterScope(0))
    {
        LclVarDsc * lclVarDsc1 = &lvaTable[LocalVarDsc1->lvdVarNum];

        if (!lclVarDsc1->lvIsParam)
            continue;

        psiScope * newScope      = psiNewPrologScope(LocalVarDsc1->lvdLVnum,
                                                     LocalVarDsc1->lvdVarNum);
#if USE_FASTCALL

        if  (lclVarDsc1->lvIsRegArg)
        {
#if!TGT_IA64 // temp hack
            assert(genRegArgIdx(lclVarDsc1->lvArgReg) != -1);
#endif

            newScope->scRegister     = true;
            newScope->scRegNum       = lclVarDsc1->lvArgReg;
        }
        else
#endif
        {
            newScope->scRegister     = false;
            newScope->scBaseReg      = REG_SPBASE;

            if (DOUBLE_ALIGN_NEED_EBPFRAME)
            {
                // sizeof(int) - for one DWORD for the pushed value of EBP
                newScope->scOffset   =   lclVarDsc1->lvStkOffs - sizeof(int);
            }
            else
            {
                /* compCalleeRegsPushed gets set in genFnProlog(). That should
                   have been been called by now */
                assert(compCalleeRegsPushed != 0xDD);

                newScope->scOffset   =   lclVarDsc1->lvStkOffs
                                       - compLclFrameSize
                                       - compCalleeRegsPushed * sizeof(int);
            }
        }
    }
}

/*****************************************************************************
 *                          psiAdjustStackLevel
 *
 * When ESP changes, all scopes relative to ESP have to be updated.
 */

void                Compiler::psiAdjustStackLevel(unsigned size)
{
    psiScope * scope;

    // walk the list backwards
    // Works as psiEndPrologScope does not change scPrev
    for (scope = psiOpenScopeLast; scope != &psiOpenScopeList; scope = scope->scPrev)
    {
#if USE_FASTCALL
        if  (scope->scRegister)
        {
            assert(lvaTable[scope->scSlotNum].lvIsRegArg);
            continue;
        }
#else
        assert(!scope->scRegister);
#endif
        assert(scope->scBaseReg == REG_SPBASE);

        psiScope * newScope     = psiNewPrologScope(scope->scLVnum, scope->scSlotNum);
        newScope->scRegister    = false;
        newScope->scBaseReg     = REG_SPBASE;
        newScope->scOffset      = scope->scOffset + size;

        psiEndPrologScope (scope);
    }
}



/*****************************************************************************
 *                          psiMoveESPtoEBP
 *
 * For EBP-frames, the parameters are accessed via ESP on entry to the function,
 * but via EBP right after a "mov ebp,esp" instruction
 */

void                Compiler::psiMoveESPtoEBP()
{
    assert(DOUBLE_ALIGN_NEED_EBPFRAME);

    psiScope * scope;

    // walk the list backwards
    // Works as psiEndPrologScope does not change scPrev
    for (scope = psiOpenScopeLast; scope != &psiOpenScopeList; scope = scope->scPrev)
    {
#if USE_FASTCALL
        if  (scope->scRegister)
        {
            assert(lvaTable[scope->scSlotNum].lvIsRegArg);
            continue;
        }
#else
        assert(!scope->scRegister);
#endif
        assert(scope->scBaseReg == REG_SPBASE);

        psiScope * newScope     = psiNewPrologScope(scope->scLVnum, scope->scSlotNum);
        newScope->scRegister    = false;
        newScope->scBaseReg     = REG_FPBASE;
        newScope->scOffset      = scope->scOffset;

        psiEndPrologScope (scope);
    }
}



/*****************************************************************************
 *                          psiMoveToReg
 *
 * Called when a parameter is loaded into its assigned register from the stack,
 *
#if USE_FASTCALL
 *
 * or when parameters are moved around due to circular dependancy.
 * If reg!=REG_NA, then the parameter is being moved into its assigned
 * register, else it may be being moved to a temp register.
 *
#endif
 *
 */

void            Compiler::psiMoveToReg (unsigned    varNum,
                                        regNumber   reg,
                                        regNumber   otherReg)
{
    assert(lvaTable[varNum].lvRegister);

#if USE_FASTCALL
    /* If reg!=REG_NA, the parameter is part of a cirular dependancy, and is
     * being moved through temp register "reg".
     * If reg==REG_NA, it is being moved to its assigned register.
     */
    if  (reg == REG_NA)
#endif
    {
        // Grab the assigned registers.

        reg      = lvaTable[varNum].lvRegNum;
        otherReg = lvaTable[varNum].lvOtherReg;
    }

    psiScope * scope;

    // walk the list backwards
    // Works as psiEndPrologScope does not change scPrev
    for (scope = psiOpenScopeLast; scope != &psiOpenScopeList; scope = scope->scPrev)
    {
        if (scope->scSlotNum != lvaTable[varNum].lvSlotNum)
            continue;

#if !USE_FASTCALL
        assert(!scope->scRegister);
        assert((DOUBLE_ALIGN_NEED_EBPFRAME && scope->scBaseReg == REG_FPBASE) ||
                                              scope->scBaseReg == REG_SPBASE);
        assert(lvaTable[varNum].lvRegister);
#endif

        psiScope * newScope     = psiNewPrologScope(scope->scLVnum, scope->scSlotNum);
        newScope->scRegister    = true;
        newScope->scRegNum      = (regNumberSmall)reg;
        newScope->scOtherReg    = (regNumberSmall)otherReg;

        psiEndPrologScope (scope);
        return;
    }

    // May happen if a parameter does not have an entry in the LocalVarTab
    // But assert() just in case it is because of something else.
    assert(!"Parameter scope not found (Assert doesnt always indicate error)");
}


/*****************************************************************************
 *                      Compiler::psiMoveToStack
 *
 * A incoming register-argument is being moved to its final home on the stack
 * (ie. all adjustements to {F/S}PBASE have been made
 */

#if USE_FASTCALL

void                Compiler::psiMoveToStack(unsigned   varNum)
{
    assert( lvaTable[varNum].lvIsRegArg);
    assert(!lvaTable[varNum].lvRegister);

    psiScope * scope;

    // walk the list backwards
    // Works as psiEndPrologScope does not change scPrev
    for (scope = psiOpenScopeLast; scope != &psiOpenScopeList; scope = scope->scPrev)
    {
        if (scope->scSlotNum != lvaTable[varNum].lvSlotNum)
            continue;

        /* The param must be currently sitting in the register in which it
           was passed in */
        assert(scope->scRegister);
        assert(scope->scRegNum == lvaTable[varNum].lvArgReg);

        psiScope * newScope     = psiNewPrologScope(scope->scLVnum, scope->scSlotNum);
        newScope->scRegister    = false;
        newScope->scBaseReg     = (lvaTable[varNum].lvFPbased) ? REG_FPBASE
                                                               : REG_SPBASE;
        newScope->scOffset      = lvaTable[varNum].lvStkOffs;

        psiEndPrologScope (scope);
        return;
    }

    // May happen if a parameter does not have an entry in the LocalVarTab
    // But assert() just in case it is because of something else.
    assert(!"Parameter scope not found");
}

#endif

/*****************************************************************************
 *                          psiEndProlog
 */

void                Compiler::psiEndProlog()
{
    psiScope * scope;

    while (scope = psiOpenScopeList.scNext)
    {
        psiEndPrologScope(scope);
    }
}

/*****************************************************************************/
#endif // DEBUGGING_SUPPORT
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\target.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef _TARGET_H_
#define _TARGET_H_
/*****************************************************************************/

#ifndef SCHEDULER
#error 'SCHEDULER' should be defined by the time we get here (like in jit.h) !
#endif

/*****************************************************************************/
/*                  The following is for x86                                 */
/*****************************************************************************/
#if     TGT_x86
/*****************************************************************************/

#define CPU_NAME        "x86"

/*****************************************************************************/

#define STK_FASTCALL    0           // reserve space on stack for reg args?
#define NST_FASTCALL    1           // fastcall calls allowed to nest?

#define ARG_ORDER_L2R   1
#define ARG_ORDER_R2L   0

/*****************************************************************************/

enum regNumbers
{
    #define REGDEF(name, rnum, mask, byte)  REG_##name = rnum,
    #include "register.h"
    #undef  REGDEF

    REG_COUNT,
    REG_NA = REG_COUNT
};

enum regMasks
{
    RBM_NONE = 0,

    #define REGDEF(name, rnum, mask, byte)  RBM_##name = mask,
    #include "register.h"
    #undef  REGDEF
};

/* The following are used to hold 'long' (64-bit integer) operands */

#ifndef NDEBUG
#define REG_PAIR_FIRST 0x70
#else
#define REG_PAIR_FIRST 0x0
#endif

enum regPairNos
{
    #define PAIRDEF(rlo,rhi)    REG_PAIR_##rlo##rhi = REG_##rlo + (REG_##rhi << 4) + REG_PAIR_FIRST,
    #include "regpair.h"
    #undef  PAIRDEF

    REG_PAIR_LAST  = REG_PAIR_STKEDI + REG_PAIR_FIRST,
    REG_PAIR_NONE  = REG_PAIR_LAST + 1
};

enum regPairMask
{
    #define PAIRDEF(rlo,rhi)    RBM_PAIR_##rlo##rhi = (RBM_##rlo|RBM_##rhi),
    #include "regpair.h"
    #undef  PAIRDEF
};

/* We're using the encoding for ESP to indicate a half-long on the frame */

#define REG_L_STK               REG_ESP

/*
    The following yield the number of bits and the mask of a register
    number in a register pair.
 */

#define REG_PAIR_NBITS          4
#define REG_PAIR_NMASK          ((1<<REG_PAIR_NBITS)-1)

/*****************************************************************************/

#define CPU_FLT_REGISTERS       0
#define CPU_DBL_REGISTERS       0

#define CPU_HAS_FP_SUPPORT      1

/*****************************************************************************/

#define MAX_REGRET_STRUCT_SZ    8
#define RET_64BIT_AS_STRUCTS    0

/*****************************************************************************/

#define LEA_AVAILABLE           1
#define SCALED_ADDR_MODES       1

/*****************************************************************************/

#ifndef BIRCH_SP2               // this comes from the WinCE build switches
#define EMIT_USE_LIT_POOLS      0
#endif
#define EMIT_DSP_INS_NAME       "      %-11s "

#define EMIT_TRACK_STACK_DEPTH  1

/*****************************************************************************/

#ifdef  DEBUG
#define DSP_SRC_OPER_LEFT       0
#define DSP_SRC_OPER_RIGHT      1
#define DSP_DST_OPER_LEFT       1
#define DSP_DST_OPER_RIGHT      0
#endif

/*****************************************************************************/

enum addrModes
{
    AM_NONE,

    AM_REG,                         // register value
    AM_LCL,                         // local variable (on stack frame)
    AM_CONS,                        // constant

    AM_IND_ADDR,                    // [addr               ]

    AM_IND_REG1,                    // [reg1               ]
    AM_IND_REG1_DISP,               // [reg1          +disp]

    AM_IND_MUL2,                    // [     mult*reg2     ]
    AM_IND_MUL2_DISP,               // [     mult*reg2+disp]

    AM_IND_REG1_REG2,               // [reg1+reg2          ]
    AM_IND_REG1_REG2_DISP,          // [reg1+reg2     +disp]

    AM_IND_REG1_MUL2,               // [reg1+mult*reg2     ]
    AM_IND_REG1_MUL2_DISP,          // [reg1+mult*reg2+disp]
};

/*****************************************************************************/

#define RBM_ALL                 (RBM_EAX|RBM_EDX|RBM_ECX|RBM_EBX|   \
                                 RBM_ESI|RBM_EDI|RBM_EBP|RBM_ESP)

#define RBM_BYTE_REGS           (RBM_EAX|RBM_EBX|RBM_ECX|RBM_EDX)

#define RBM_CALLEE_SAVED        (RBM_EBX|RBM_ESI|RBM_EDI|RBM_EBP)
#define RBM_CALLEE_TRASH        (RBM_EAX|RBM_ECX|RBM_EDX)

#define MAX_EPILOG_SIZE          20

#define REG_VAR_LIST             REG_EAX,REG_EDX,REG_ECX,REG_ESI,REG_EDI,REG_EBX,REG_EBP

// Where is the exception object on entry to the handler block ?
#define REG_EXCEPTION_OBJECT     REG_EAX
#define RBM_EXCEPTION_OBJECT     RBM_EAX

// Which register are int and long values returned in ?
#define REG_INTRET               REG_EAX
#define RBM_INTRET               RBM_EAX
#define REG_LNGRET               REG_PAIR_EAXEDX
#define RBM_LNGRET              (RBM_EDX|RBM_EAX)

#define REG_FPBASE               REG_EBP
#define RBM_FPBASE               RBM_EBP
#define REG_SPBASE               REG_ESP
#define RBM_SPBASE               RBM_ESP

#if     ALLOW_MIN_OPT
#define RBM_MIN_OPT_LCLVAR_REGS (RBM_ESI|RBM_EDI)
#endif

#define FIRST_ARG_STACK_OFFS    8

#ifdef  NOT_JITC
#define RETURN_ADDR_OFFS        1       // in DWORDS
#endif

#define CALLEE_SAVED_REG_MAXSZ  (4*sizeof(int)) // EBX,ESI,EDI,EBP

/*****************************************************************************/

#if     USE_FASTCALL

#define MAX_REG_ARG             2

#define REG_ARG_0               REG_ECX //REG_ECX
#define REG_ARG_1               REG_EDX //REG_EAX
#define REG_ARG_2               REG_EAX //REG_EDX

#define RBM_ARG_0               RBM_ECX //RBM_ECX
#define RBM_ARG_1               RBM_EDX //RBM_EAX
#define RBM_ARG_2               RBM_EAX //RBM_EDX

#define RBM_ARG_REGS            (RBM_ARG_0|RBM_ARG_1)
//#define RBM_ARG_REGS            (RBM_ARG_0|RBM_ARG_1|RBM_ARG_2)

inline
bool                isRegParamType(var_types type)
{
    return  (type <= TYP_INT ||
             type == TYP_REF ||
             type == TYP_BYREF);
}

#endif

/*****************************************************************************/

#define FP_STK_SIZE             8

/*****************************************************************************/

#define REGNUM_BITS             3               // number of bits in reg#

typedef unsigned                regMaskTP;
typedef unsigned char           regMaskSmall;
typedef unsigned                regPairMaskTP;
typedef unsigned short          regPairMaskSmall;

#ifdef  FAST
typedef unsigned int            regNumber;
typedef unsigned int            regPairNo;
typedef unsigned char           regNumberSmall;
typedef unsigned char           regPairNoSmall;
#else
typedef regNumbers              regNumber;
typedef regPairNos              regPairNo;
typedef regNumber               regNumberSmall;
typedef regPairNo               regPairNoSmall;
#endif

inline  int                     isByteReg(regNumber reg) { return reg <= REG_EBX; }

#define JMP_DIST_SMALL_MAX_NEG  (-128)
#define JMP_DIST_SMALL_MAX_POS  (+127)

#define JCC_DIST_SMALL_MAX_NEG  (-128)
#define JCC_DIST_SMALL_MAX_POS  (+127)

#define JMP_SIZE_SMALL          (2)
#define JMP_SIZE_LARGE          (5)

#define JCC_SIZE_SMALL          (2)
#define JCC_SIZE_LARGE          (6)

#define JMP_SIZE_SMALL_MIN      (2)     // smaller of JMP_SIZE_SMALL and JCC_SIZE_SMALL
#define JMP_SIZE_SMALL_MAX      (2)     // larger  of JMP_SIZE_SMALL and JCC_SIZE_SMALL

#define CALL_INST_SIZE          (5)

#define LARGEST_JUMP_SIZE       (6)

#define JMP_INSTRUCTION         INS_jmp

#define MAX_BRANCH_DELAY_LEN    0       // the x86 has no branch-delay slots

/*****************************************************************************/
#if     SCHEDULER
/*****************************************************************************
 *
 *  Define target-dependent scheduling values that need to be kept track of.
 */

#define SCHED_USE_FL            1       // scheduler needs to know about flags

struct  scExtraInfo
{
    bool        stackDep;
};

#define             scTgtDepDcl()                                   \
                                                                    \
    schedDef_tp     scFPUdef;                                       \
    schedUse_tp     scFPUuse;

#define             scTgtDepClr()                                   \
                                                                    \
    scFPUdef = 0;                                                   \
    scFPUuse = 0;

#define             scTgtDepDep(id,inf,dag)                         \
                                                                    \
    if  (inf & IS_FP_STK)                                           \
    {                                                               \
        scDepDef(dag, "FPUstk",  scFPUdef,  scFPUuse);              \
        scDepUse(dag, "FPUstk",  scFPUdef,  scFPUuse);              \
    }

#define             scTgtDepUpd(id,inf,dag)                         \
                                                                    \
    if  (inf & IS_FP_STK)                                           \
    {                                                               \
        scUpdDef(dag, &scFPUdef, &scFPUuse);                        \
        scUpdUse(dag, &scFPUdef, &scFPUuse);                        \
    }

#endif
/*****************************************************************************/
#endif//TGT_x86
/*****************************************************************************/

#ifdef  TGT_SH3

        #include "targetSH3.h"

#endif  //TGT_SH3

#ifdef  TGT_MIPS32

        #include "targetMIPS.h"

#endif  // TGT_MIPS32

#ifdef  TGT_ARM

        #include "targetARM.h"

#endif  //TGT_ARM

#ifdef  TGT_PPC

        #include "targetPPC.h"

#endif  //TGT_PPC

#ifdef  TGT_IA64

        #include "targetIA64.h"

#endif  //TGT_IA64

/*****************************************************************************/

#ifndef regMaskNULL

#define regMaskNULL 0
#define regMaskOne  1
#define incRegMask(m)   m <<= 1
#define isNonZeroRegMask(m) ((m) != 0)
#endif

/*****************************************************************************/

#ifdef DEBUG
const   char *      getRegName(unsigned  regNum);
extern  void        dspRegMask(regMaskTP regMask, size_t minSiz = 0);
#endif

/*****************************************************************************
 *
 * Return true if the registers is a valid value
 */

inline
bool                genIsValidReg(regNumber reg)
{
    return (reg < (unsigned)REG_COUNT);
}

/*****************************************************************************/
#ifndef TGT_IA64
/*****************************************************************************
 *
 *  Map a register number to a register mask.
 */

extern
regMaskSmall        regMasks[REG_COUNT];

inline
regMaskTP           genRegMask(regNumber reg)
{
    assert(reg < sizeof(regMasks)/sizeof(regMasks[0]));

    return regMasks[reg];
}

/*****************************************************************************/
#ifndef BIRCH_SP2
/*****************************************************************************
 *
 *  Returns the register that holds the low  32 bits of the long value given
 *  by the register pair 'regPair'.
 */

inline
regNumber           genRegPairLo(regPairNo regPair)
{
    assert(regPair >= REG_PAIR_FIRST &&
           regPair <= REG_PAIR_LAST);

    return  (regNumber)((regPair - REG_PAIR_FIRST) & REG_PAIR_NMASK);
}

/*****************************************************************************
 *
 *  Returns the register that holds the high 32 bits of the long value given
 *  by the register pair 'regPair'.
 */

inline
regNumber           genRegPairHi(regPairNo regPair)
{
    assert(regPair >= REG_PAIR_FIRST &&
           regPair <= REG_PAIR_LAST);

    return (regNumber)(((regPair - REG_PAIR_FIRST) >> REG_PAIR_NBITS) & REG_PAIR_NMASK);
}

/*****************************************************************************
 *
 *  Returns whether regPair is a combination of two "real" registers
 *  or whether it contains a pseudo register.
 *
 *  In debug it also asserts that reg1 and reg2 are not the same.
 */

BOOL                genIsProperRegPair(regPairNo regPair);

/*****************************************************************************
 *
 *  Returns the register pair number that corresponds to the given two regs.
 */

inline
regPairNo           gen2regs2pair(regNumber reg1, regNumber reg2)
{
    assert(reg1 != reg2);
    assert(genIsValidReg(reg1) && genIsValidReg(reg2));
    assert(reg1 != REG_L_STK && reg2 != REG_L_STK);

    return (regPairNo)(reg1+(reg2<<REG_PAIR_NBITS)+REG_PAIR_FIRST);
}

/*****************************************************************************/

inline
unsigned            genRegPairMask(regPairNo regPair)
{
    assert(regPair >= REG_PAIR_FIRST &&
           regPair <= REG_PAIR_LAST);

    return genRegMask(genRegPairLo(regPair))|genRegMask(genRegPairHi(regPair));
}

/*****************************************************************************/
#endif // not BIRCH_SP2
/*****************************************************************************/

#if USE_FASTCALL

inline
regNumber           genRegArgNum(unsigned argNum)
{
    assert (argNum < MAX_REG_ARG);

#if TGT_IA64

    return  (regNumber)(argNum + REG_ARG_0);

#else

    switch (argNum)
    {
    case 0: return REG_ARG_0;
#if MAX_REG_ARG >= 2
    case 1: return REG_ARG_1;
#if MAX_REG_ARG >= 3
    case 2: return REG_ARG_2;
#if MAX_REG_ARG >= 4
    case 3: return REG_ARG_3;
#if MAX_REG_ARG >= 5
#error  Add some more code over here, will ya?!
#endif
#endif
#endif
#endif
    default: assert(!"too many reg args!"); return REG_NA;
    }

#endif

}

inline
unsigned           genRegArgIdx(regNumber regNum)
{
    assert(genRegMask(regNum) & RBM_ARG_REGS);

#if TGT_IA64

    return  regNum - REG_ARG_0;

#else

    switch (regNum)
    {
    case REG_ARG_0: return 0;
    case REG_ARG_1: return 1;
#if MAX_REG_ARG >= 3
    case REG_ARG_2: return 2;
#if MAX_REG_ARG >= 4
    case REG_ARG_3: return 3;
#if MAX_REG_ARG >= 5
    case REG_ARG_4: return 4;
#endif
#endif
#endif
    default: assert(!"invalid register arg register"); return (unsigned)-1;
    }

#endif

}

extern
regMaskTP           genRegArgMasks[MAX_REG_ARG+1];

inline
regMaskTP           genRegArgMask(unsigned totalArgs)
{
    assert(totalArgs <= MAX_REG_ARG);
    return  genRegArgMasks[totalArgs];
}

#endif // not TGT_IA64

#endif // FASTCALL

/*****************************************************************************/
#if ARG_ORDER_L2R != !ARG_ORDER_R2L
#error  Please make up your mind as to what order are arguments pushed in.
#endif
#if STK_FASTCALL  != !NST_FASTCALL && !TGT_IA64
#error  Please make up your mind as to whether stack space is needed for register args.
#endif
/*****************************************************************************/

#if TGT_x86
// This isnt used now anymore (3/11/99). Remove after sometime
//#define SET_USED_REG_SET_DURING_CODEGEN
#endif

/*****************************************************************************/
#endif  // _TARGET_H_
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\targetia64.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/************************************************************************
*
 Confidential.
*
***********************************************************************/

#define CPU_NAME        "IA64"

/*****************************************************************************/

enum    instruction;                // moved out for quicker rebuilds

/*****************************************************************************/

#define USE_FASTCALL    1           // use fastcall calling convention?
#define STK_FASTCALL    0           // reserve space on stack for reg args?
#define NST_FASTCALL    0           // fastcall calls allowed to nest?

#define ARG_ORDER_L2R   1
#define ARG_ORDER_R2L   0

/*****************************************************************************/

enum regNumbers
{
    #define REGDEF(name, strn) REG_##name,

    #define REG_IF(name, strn) REG_##name, REG_INT_FIRST = REG_##name,
    #define REG_IL(name, strn) REG_##name, REG_INT_LAST  = REG_##name,

    #define REG_FF(name, strn) REG_##name, REG_FLT_FIRST = REG_##name,
    #define REG_FL(name, strn) REG_##name, REG_FLT_LAST  = REG_##name,

    #define REG_CF(name, strn) REG_##name, REG_CND_FIRST = REG_##name,
    #define REG_CL(name, strn) REG_##name, REG_CND_LAST  = REG_##name,

    #define REG_BF(name, strn) REG_##name, REG_BRR_FIRST = REG_##name,
    #define REG_BL(name, strn) REG_##name, REG_BRR_LAST  = REG_##name,

    #include "regIA64.h"

    REG_COUNT
};

const
regNumbers          REG_gp      = REG_r001;
const
regNumbers          REG_sp      = REG_r012;

const
NatUns              REG_APP_PFS = 64;

const
NatUns              REG_APP_LC  = 65;

/*****************************************************************************/

#define REGNUM_BITS             8               // number of bits in reg#
#define TRACKED_REG_CNT         280             // must be >= REG_COUNT

#define PRRNUM_BITS             4               // number of bits in predication reg#
#define TRACKED_PRR_CNT         16              // must be >= REG_CND_LAST - REG_CND_FIRST

/*****************************************************************************/

enum IA64execUnits
{
    XU_N,                       // "none" (used for pseudo-instructions, etc)

    XU_A,
    XU_M,
    XU_I,
    XU_B,
    XU_F,

    XU_L,
    XU_X,

    XU_COUNT,
    XU_P = XU_COUNT             // intra-bundle ILP "stop" pseudo-entry
};

/*****************************************************************************/
// The following isn't really used, but for now it's needed to build all of the code
/*****************************************************************************/

union   regMask
{
    unsigned __int64            longs[TRACKED_REG_CNT / sizeof(__int64) / 8];
    unsigned char               bytes[TRACKED_REG_CNT / sizeof(   char) / 8];

    inline
    void    operator&=(regMask op)
    {
        longs[0] &= op.longs[0];
        longs[1] &= op.longs[1];
        longs[2] &= op.longs[2];
        longs[3] &= op.longs[3];
    }

    inline
    void    operator|=(regMask op)
    {
        longs[0] |= op.longs[0];
        longs[1] |= op.longs[1];
        longs[2] |= op.longs[2];
        longs[3] |= op.longs[3];
    }

    inline
    void    operator-=(regMask op)
    {
        longs[0] -= op.longs[0];
        longs[1] -= op.longs[1];
        longs[2] -= op.longs[2];
        longs[3] -= op.longs[3];
    }

    inline
    operator bool()
    {
        return (longs[0] != 0 ||
                longs[1] != 0 ||
                longs[2] != 0 ||
                longs[3] != 0);
    }
};

typedef union regMask           regMaskTP;
typedef union regMask           regMaskSmall;

#ifdef  FAST
typedef NatUns                  regNumber;
typedef unsigned char           regNumberSmall;
#else
typedef regNumbers              regNumber;
typedef regNumber               regNumberSmall;
#endif

extern  regMask         regMaskNULL;
#define regMaskNULL     regMaskNULL
extern  regMask         regMaskOne;
#define regMaskOne      regMaskOne

inline  regMask         operator~ (regMask m1)
{
    m1.longs[0] = ~m1.longs[0];
    m1.longs[1] = ~m1.longs[1];
    m1.longs[2] = ~m1.longs[2];
    m1.longs[3] = ~m1.longs[3];

    return m1;
}

inline  regMask         operator| (regMask m1, regMask m2)
{
    m1.longs[0] |= m2.longs[0];
    m1.longs[1] |= m2.longs[1];
    m1.longs[2] |= m2.longs[2];
    m1.longs[3] |= m2.longs[3];

    return m1;
}

inline  regMask         operator& (regMask m1, regMask m2)
{
    m1.longs[0] &= m2.longs[0];
    m1.longs[1] &= m2.longs[1];
    m1.longs[2] &= m2.longs[2];
    m1.longs[3] &= m2.longs[3];

    return m1;
}

inline  bool            operator==(regMask m1, regMask m2)
{
    return (m1.longs[0] == m2.longs[0] &&
            m1.longs[1] == m2.longs[1] &&
            m1.longs[2] == m2.longs[2] &&
            m1.longs[3] == m2.longs[3]);
}

#if 0

inline  bool            operator!=(regMask m1, int     i2)
{
    assert(i2 == 0);

    return (m1.longs[0] != 0 ||
            m1.longs[1] != 0 ||
            m1.longs[2] != 0 ||
            m1.longs[3] != 0);
}

inline  bool            operator!=(int     i1, regMask m2)
{
    assert(i1 == 0);

    return (m2.longs[0] != 0 ||
            m2.longs[1] != 0 ||
            m2.longs[2] != 0 ||
            m2.longs[3] != 0);
}

#else

inline  bool            isNonZeroRegMask(regMask m)
{
    return (m.longs[0] != 0 ||
            m.longs[1] != 0 ||
            m.longs[2] != 0 ||
            m.longs[3] != 0);
}

#endif

extern  bool            genOneBitOnly   (regMask mask);
extern  regMaskTP       genFindLowestBit(regMask mask);
extern  void            incRegMask      (regMask&mask);

/*****************************************************************************/

typedef union
{
    unsigned __int64    longs[128 / sizeof(__int64) / 8];
    unsigned char       bytes[128 / sizeof(   char) / 8];
}
                    bitset128;

inline
void                bitset128clear(bitset128 *mask)
{
    mask->longs[0] =
    mask->longs[1] = 0;
}

NatUns              bitset128lowest0(bitset128  mask);
NatUns              bitset128lowest1(bitset128  mask);

void                bitset128set    (bitset128 *mask, NatUns bitnum, NatInt newval);
void                bitset128set    (bitset128 *mask, NatUns bitnum);

void                bitset128clear  (bitset128 *mask, NatUns bitnum);

inline
void                bitset128clear  (bitset128 *dest, bitset128 rmv)
{
    dest->longs[0] &= ~(rmv.longs[0]);
    dest->longs[1] &= ~(rmv.longs[1]);
}

inline
void                bitset128nset   (bitset128 *dest, bitset128 src)
{
    dest->longs[0] |= ~(src.longs[0]);
    dest->longs[1] |= ~(src.longs[1]);
}

bool                bitset128test   (bitset128  mask, NatUns bitnum);

inline
void                bitset128or     (bitset128 *dest, bitset128 src)
{
    dest->longs[0] |=   src.longs[0];
    dest->longs[1] |=   src.longs[1];
}

inline
void                bitset128mkOr   (bitset128 *dest, bitset128 src1,
                                                      bitset128 src2)
{
    dest->longs[0]  =  src1.longs[0] | src2.longs[0];
    dest->longs[1]  =  src1.longs[1] | src2.longs[1];
}

inline
void                bitset128and    (bitset128 *dest, bitset128 src)
{
    dest->longs[0] &=   src.longs[0];
    dest->longs[1] &=   src.longs[1];
}

inline
bool                bitset128ovlp   (bitset128  src1, bitset128 src2)
{
    return  (src1.longs[0] & src2.longs[0]) ||
            (src1.longs[1] & src2.longs[1]);
}

inline
bool                bitset128iszero (bitset128  mask)
{
    return  (mask.longs[0]|mask.longs[1]) == 0;
}

inline
bool                bitset128equal  (bitset128 mask1, bitset128 mask2)
{
    return  (mask1.longs[0] == mask2.longs[0] &&
             mask1.longs[1] == mask2.longs[1]);
}

inline
void                bitset128make1(bitset128 *mask, NatUns bitnum)
{
    mask->longs[0] =
    mask->longs[1] = 0;

    bitset128set(mask, bitnum);
}

/*****************************************************************************/

#define CPU_FLT_REGISTERS       1
#define CPU_DBL_REGISTERS       1

#define CPU_HAS_FP_SUPPORT      1

#define USE_HELPERS_FOR_INT_DIV 1

/*****************************************************************************/

#define MAX_REGRET_STRUCT_SZ    32
#define RET_64BIT_AS_STRUCTS    0

/*****************************************************************************/

#define LEA_AVAILABLE           0
#define SCALED_ADDR_MODES       0

/*****************************************************************************/

#define EMIT_USE_LIT_POOLS      0
#define EMIT_DSP_INS_NAME       "      %-11s "

#define EMIT_TRACK_STACK_DEPTH  0

/*****************************************************************************/

#define JMP_SIZE_SMALL          (16)
#define JMP_SIZE_LARGE          (16)

#define JMP_DIST_SMALL_MAX_NEG  (-0xFFFF)
#define JMP_DIST_SMALL_MAX_POS  (+0xFFFF)

#define JCC_SIZE_SMALL          (16)
#define JCC_SIZE_LARGE          (16)

#define JCC_DIST_SMALL_MAX_NEG  (-0xFFFF)
#define JCC_DIST_SMALL_MAX_POS  (+0xFFFF)

/*****************************************************************************/

#ifdef  DEBUG
#define DSP_SRC_OPER_LEFT       1
#define DSP_SRC_OPER_RIGHT      0
#define DSP_DST_OPER_LEFT       1
#define DSP_DST_OPER_RIGHT      0
#endif

/*****************************************************************************/

enum addrModes
{
    AM_NONE,
    AM_REG,                         //  register value
    AM_IND_REG,                     // [register]
};

/*****************************************************************************/

extern  regMask         RBM_ALL;

extern  regMask         RBM_CALLEE_SAVED;
extern  regMask         RBM_CALLEE_TRASH; // (RBM_ALL & ~RBM_CALLEE_SAVED)

#define CALLEE_SAVED_REG_MAXSZ  ((8+1)*sizeof(int)) // callee-saved + retaddr

#define MAX_EPILOG_SIZE          128

#if     ALLOW_MIN_OPT
#define RBM_MIN_OPT_LCLVAR_REGS  0
#endif

#define REG_VAR_LIST            REG_r10,REG_r11     // temp hack !!!!!!!!!!!!

#define REG_INTRET              REG_r008
//efine RBM_INTRET              RBM_r008
extern
regMask RBM_INTRET;
#define REG_LNGRET              REG_r008
//efine RBM_LNGRET              RBM_r008
extern
regMask RBM_LNGRET;

#define REG_FPBASE              REG_r014
//efine RBM_FPBASE              RBM_r014
#define REG_SPBASE              REG_r015
//efine RBM_SPBASE              RBM_r015

#define MAX_SPBASE_OFFS         (MAX_INDREG_DISP*sizeof(int))
#define MAX_FPBASE_OFFS         (MAX_INDREG_DISP*sizeof(int))

/*****************************************************************************/

#define REG_INT_MIN_STK         REG_r032
#define REG_INT_MAX_STK         REG_r127

#define REG_INT_ARG_0           REG_r032
#define MAX_INT_ARG_REG         REG_r039

#define REG_FLT_ARG_0           REG_f008
#define MAX_FLT_ARG_REG         REG_f015

#define MAX_REG_ARG             8

inline
bool                isRegParamType(var_types type)
{
    if  (type == TYP_STRUCT)
    {
        // UNDONE: check the size and contents of the struct

        return  false;
    }

    return  true;
}

/*****************************************************************************/

#define FIRST_ARG_STACK_OFFS    0
#define MIN_OUT_ARG_RESERVE     16

/*****************************************************************************/

#define INSTRUCTION_SIZE        16

/*****************************************************************************/
#if     SCHEDULER
/*****************************************************************************
 *
 *  Define target-dependent scheduling values that need to be kept track of.
 */

#define SCHED_USE_FL            0       // IA64 uses predicate regs not flags

struct  scExtraInfo
{
    unsigned        scxDeps;
};

#define             scTgtDepDcl()                                   \
                                                                    \
    schedDef_tp     scMACdef, scPRRdef;                             \
    schedUse_tp     scMACuse, scPRRuse;

#define             scTgtDepClr()                                   \
                                                                    \
    scMACdef = scPRRdef = 0;                                        \
    scMACuse = scPRRuse = 0;

#define             scTgtDepDep(id,inf,dag)
#define             scTgtDepUpd(id,inf,dag)

/*****************************************************************************/
#endif  // SCHEDULER
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\siginfo.hpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
//
// siginfo.hpp
//
#ifndef _H_SIGINFO
#define _H_SIGINFO

#include <corhdr.h>
#include <cor.h>
#include <corpriv.h>
#include <metadata.h>

#define Module mdScope

// uncompress encoded element type. throw away any custom modifier prefixes along
// the way.
FORCEINLINE CorElementType CorSigEatCustomModifiersAndUncompressElementType(//Element type
    PCCOR_SIGNATURE &pData)             // [IN,OUT] compressed data
{
    while (ELEMENT_TYPE_CMOD_REQD == *pData || ELEMENT_TYPE_CMOD_OPT == *pData)
    {
        pData++;
        CorSigUncompressToken(pData);
    }
    return (CorElementType)*pData++;
}


struct ElementTypeInfo {
#ifdef _DEBUG
    int            m_elementType;     
#endif
    int            m_cbSize;
    CorInfoGCType  m_gc         : 3;
    int            m_fp         : 1;
    int            m_enregister : 1;
    int            m_isBaseType : 1;

};
extern const ElementTypeInfo gElementTypeInfo[];

unsigned GetSizeForCorElementType(CorElementType etyp);
const ElementTypeInfo* GetElementTypeInfo(CorElementType etyp);
BOOL    IsFP(CorElementType etyp);
BOOL    IsBaseElementType(CorElementType etyp);

//----------------------------------------------------------------------------
// enum StringType
// defines the various string types
enum StringType
{
    enum_BSTR = 0,
    enum_WSTR = 1,
    enum_CSTR = 2,
    enum_AnsiBSTR = 3,
};


//----------------------------------------------------------------------------
// IsAnsi
inline  BOOL IsAnsi(StringType styp)
{
    return styp == enum_CSTR;
}


//----------------------------------------------------------------------------
// IsBSTR
inline  BOOL IsBSTR(StringType styp)
{
    return styp == enum_BSTR;
}


//----------------------------------------------------------------------------
// IsWSTR
inline  BOOL IsWSTR(StringType styp)
{
    return styp == enum_WSTR;
}

//----------------------------------------------------------------------------
// Free String call appropriate free
inline VOID FreeString(LPVOID pv, StringType styp)
{
    if (pv != NULL)
    {
        if (IsBSTR(styp))
        {
            SysFreeString((BSTR)pv);
        }
        else
        {
            CoTaskMemFree(pv);
        }
    }
}


//------------------------------------------------------------------------
// Encapsulates how compressed integers and typeref tokens are encoded into
// a bytestream.
//
// For M3.5, the bytestream *is* a bytestream. Later on, we may change
// to a nibble-based or var-length encoding, in which case, the implementation
// of this class will become more complex.
//------------------------------------------------------------------------
class SigPointer
{
    private:
        PCCOR_SIGNATURE m_ptr;

    public:
        //------------------------------------------------------------------------
        // Constructor.
        //------------------------------------------------------------------------
        SigPointer() {}

        //------------------------------------------------------------------------
        // Initialize
        //------------------------------------------------------------------------
        FORCEINLINE SigPointer(PCCOR_SIGNATURE ptr)
        {
            m_ptr = ptr;
        }

                FORCEINLINE SetSig(PCCOR_SIGNATURE ptr)
                {
                        m_ptr = ptr;
                }

        //------------------------------------------------------------------------
        // Remove one compressed integer (using CorSigUncompressData) from
        // the head of the stream and return it.
        //------------------------------------------------------------------------
        FORCEINLINE ULONG GetData()
        {
            return CorSigUncompressData(m_ptr);
        }


                //-------------------------------------------------------------------------
                // Remove one byte and return it.
                //-------------------------------------------------------------------------
                FORCEINLINE BYTE GetByte()
                {
                        return *(m_ptr++);
                }


        FORCEINLINE CorElementType GetElemType()
        {
            return (CorElementType) CorSigEatCustomModifiersAndUncompressElementType(m_ptr);
        }

        ULONG GetCallingConvInfo()
        {
            return CorSigUncompressCallingConv(m_ptr);
        }

        ULONG GetCallingConv()
        {
            return IMAGE_CEE_CS_CALLCONV_MASK & CorSigUncompressCallingConv(m_ptr);
        }

        //------------------------------------------------------------------------
        // Non-destructive read of compressed integer.
        //------------------------------------------------------------------------
        ULONG PeekData() const
        {
            PCCOR_SIGNATURE tmp = m_ptr;
            return CorSigUncompressData(tmp);
        }


        //------------------------------------------------------------------------
        // Non-destructive read of element type.
        //
        // This routine makes it look as if the String type is encoded
        // via ELEMENT_TYPE_CLASS followed by a token for the String class,
        // rather than the ELEMENT_TYPE_STRING. This is partially to avoid
        // rewriting client code which depended on this behavior previously.
        // But it also seems like the right thing to do generally.
        //------------------------------------------------------------------------
        CorElementType PeekElemType() const
        {
            PCCOR_SIGNATURE tmp = m_ptr;
            CorElementType typ = CorSigEatCustomModifiersAndUncompressElementType(tmp);
            if (typ == ELEMENT_TYPE_STRING)
                return ELEMENT_TYPE_CLASS;
            return typ;
        }


        //------------------------------------------------------------------------
        // Removes a compressed metadata token and returns it.
        //------------------------------------------------------------------------
        FORCEINLINE mdTypeRef GetToken()
        {
            return CorSigUncompressToken(m_ptr);
        }


        //------------------------------------------------------------------------
        // Tests if two SigPointers point to the same location in the stream.
        //------------------------------------------------------------------------
        FORCEINLINE BOOL Equals(SigPointer sp) const
        {
            return m_ptr == sp.m_ptr;
        }


        //------------------------------------------------------------------------
        // Assumes that the SigPointer points to the start of an element type
        // (i.e. function parameter, function return type or field type.)
        // Advances the pointer to the first data after the element type.  This
                // will skip the following varargs sentinal if it is there.
        //------------------------------------------------------------------------
        VOID Skip();

        //------------------------------------------------------------------------
                // Like Skip, but will not skip a following varargs sentinal.
        //------------------------------------------------------------------------
        VOID SkipExactlyOne();


        //------------------------------------------------------------------------
        // Get info about single-dimensional arrays
        //------------------------------------------------------------------------
        VOID GetSDArrayElementProps(SigPointer *pElemType, ULONG *pElemCount) const;


        //------------------------------------------------------------------------
        // Move signature to another scope
        //------------------------------------------------------------------------
                PCOR_SIGNATURE GetImportSignature(IMetaDataImport *pInputScope,
                                                                                  IMetaDataEmit *pEmitScope,
                                                                                  PCOR_SIGNATURE buffer,
                                                                                  PCOR_SIGNATURE bufferMax);

                PCOR_SIGNATURE GetImportFunctionSignature(IMetaDataImport *pInputScope,
                                                                                                  IMetaDataEmit *pEmitScope,
                                                                                                  PCOR_SIGNATURE buffer,
                                                                                                  PCOR_SIGNATURE bufferMax);

// This functionality needs to "know" about internal VM structures (like EEClass).
// It is conditionally included so that other projects can use the rest of the
// functionality in this file.

        CorElementType Normalize(Module* pModule) const;
        CorElementType Normalize(Module* pModule, CorElementType type) const;

        FORCEINLINE CorElementType PeekElemTypeNormalized(Module* pModule) const {
            return Normalize(pModule);
        }

                //------------------------------------------------------------------------
        // Tests for the existence of a custom modifier
                //------------------------------------------------------------------------
                BOOL HasCustomModifier(Module *pModule, LPCSTR szModName, CorElementType cmodtype) const;


                //------------------------------------------------------------------------
                // Return pointer
                //------------------------------------------------------------------------
        PCCOR_SIGNATURE GetPtr() const
                {
                        return m_ptr;
                }

};


//------------------------------------------------------------------------
// Encapsulates the format and simplifies walking of MetaData sigs.
//------------------------------------------------------------------------

class MetaSig
{
    public:
        enum MetaSigKind {
            sigMember,
            sigLocalVars,
            };

        //------------------------------------------------------------------
        // Constructor. Warning: Does NOT make a copy of szMetaSig.
        //------------------------------------------------------------------
        MetaSig(PCCOR_SIGNATURE szMetaSig, Module* pModule, BOOL fConvertSigAsVarArg = FALSE, MetaSigKind kind = sigMember);

        //------------------------------------------------------------------
        // Returns type of current argument, then advances the argument
        // index. Returns ELEMENT_TYPE_END if already past end of arguments.
        //------------------------------------------------------------------
        CorElementType NextArg();

        //------------------------------------------------------------------
        // Retreats argument index, then returns type of the argument
        // under the new index. Returns ELEMENT_TYPE_END if already at first
        // argument.
        //------------------------------------------------------------------
        CorElementType PrevArg();

        //------------------------------------------------------------------
        // Returns type of current argument index. Returns ELEMENT_TYPE_END if already past end of arguments.
        //------------------------------------------------------------------
        CorElementType PeekArg();

        //------------------------------------------------------------------
        // Returns a read-only SigPointer for the last type to be returned
        // via NextArg() or PrevArg(). This allows extracting more information
        // for complex types.
        //------------------------------------------------------------------
        const SigPointer & GetArgProps() const
        {
            return m_pLastType;
        }

        //------------------------------------------------------------------
        // Returns a read-only SigPointer for the return type.
        // This allows extracting more information for complex types.
        //------------------------------------------------------------------
        const SigPointer & GetReturnProps() const
        {
            return m_pRetType;
        }


        // Returns the number of bytes to accomodate these args as local variables on the interpreted stack frame
        DWORD CountLocVarBytes();


        //------------------------------------------------------------------------
        // Returns # of arguments. Does not count the return value.
        // Does not count the "this" argument (which is not reflected om the
        // sig.) 64-bit arguments are counted as one argument.
        //------------------------------------------------------------------------
        static UINT NumFixedArgs(Module* pModule, PCCOR_SIGNATURE pSig);


        //------------------------------------------------------------------------
        // Returns # of arguments. Does not count the return value.
        // Does not count the "this" argument (which is not reflected om the
        // sig.) 64-bit arguments are counted as one argument.
        //------------------------------------------------------------------------
        UINT NumFixedArgs()
        {
            return m_nArgs;
        }


        //----------------------------------------------------------
        // Returns the calling convention (see IMAGE_CEE_CS_CALLCONV_*
        // defines in cor.h)
        //----------------------------------------------------------
        static BYTE GetCallingConvention(Module* pModule, PCCOR_SIGNATURE pSig)
        {
            return (BYTE)(IMAGE_CEE_CS_CALLCONV_MASK & (CorSigUncompressCallingConv(/*modifies*/pSig)));
        }





        //----------------------------------------------------------
        // Returns the calling convention (see IMAGE_CEE_CS_CALLCONV_*
        // defines in cor.h)
        //----------------------------------------------------------
        static BYTE GetCallingConventionInfo(Module* pModule, PCCOR_SIGNATURE pSig)
        {
            return (BYTE)CorSigUncompressCallingConv(/*modifies*/pSig);
        }


        //----------------------------------------------------------
        // Returns the calling convention (see IMAGE_CEE_CS_CALLCONV_*
        // defines in cor.h)
        //----------------------------------------------------------
        BYTE GetCallingConvention()
        {
            return m_CallConv & IMAGE_CEE_CS_CALLCONV_MASK;
        }

        //----------------------------------------------------------
        // Returns the calling convention & flags (see IMAGE_CEE_CS_CALLCONV_*
        // defines in cor.h)
        //----------------------------------------------------------
        BYTE GetCallingConventionInfo()
        {
            return m_CallConv;
        }


        //----------------------------------------------------------
        // Has a 'this' pointer?
        //----------------------------------------------------------
        BOOL HasThis()
        {
            return m_CallConv & IMAGE_CEE_CS_CALLCONV_HASTHIS;
        }

        //----------------------------------------------------------
        // Is vararg?
        //----------------------------------------------------------
        BOOL IsVarArg()
        {
            return GetCallingConvention() == IMAGE_CEE_CS_CALLCONV_VARARG;
        }

        //----------------------------------------------------------
        // Is vararg?
        //----------------------------------------------------------
        static BOOL IsVarArg(Module* pModule, PCCOR_SIGNATURE pSig)
        {
            return GetCallingConvention(pModule, pSig) == IMAGE_CEE_CS_CALLCONV_VARARG;
        }



        //------------------------------------------------------------------
        // Moves index to end of argument list.
        //------------------------------------------------------------------
        VOID GotoEnd();

        //------------------------------------------------------------------
        // reset: goto start pos
        //------------------------------------------------------------------
        VOID Reset();

        //------------------------------------------------------------------
        // Returns type of return value.
        //------------------------------------------------------------------
        FORCEINLINE CorElementType GetReturnType() const
        {
            return m_pRetType.PeekElemType();
        }


    // These are protected because Reflection subclasses Metasig
    protected:

        static const UINT32 s_cSigHeaderOffset;

        // @todo: These fields are only used for new-style signatures.
        Module*      m_pModule;
        SigPointer   m_pStart;
        SigPointer   m_pWalk;
        SigPointer   m_pLastType;
        SigPointer   m_pRetType;
        UINT32       m_nArgs;
        UINT32       m_iCurArg;
        UINT32       m_cbSigSize;
        PCCOR_SIGNATURE m_pszMetaSig;


        // The following are cached so we don't the signature
        //  multiple times
        UINT32       m_nVirtualStack;   // Size of the virtual stack
        UINT32       m_nActualStack;    // Size of the actual stack

        BYTE         m_CallConv;
        BYTE         m_WalkStatic;      // The type of function we walked
                        // used to treat some sigs as special case vararg
                        // used by calli to unmanaged target
                BYTE             m_fTreatAsVarArg;
                BOOL            IsTreatAsVarArg()
                {
                                        return m_fTreatAsVarArg;
                }
};


class FieldSig
{
    // For new-style signatures only.
    SigPointer m_pStart;
    Module*    m_pModule;
public:
        //------------------------------------------------------------------
        // Constructor. Warning: Does NOT make a copy of szMetaSig.
        //------------------------------------------------------------------

        FieldSig(PCCOR_SIGNATURE szMetaSig, Module* pModule)
        {
            _ASSERTE(*szMetaSig == IMAGE_CEE_CS_CALLCONV_FIELD);
            m_pModule = pModule;
            m_pStart = SigPointer(szMetaSig);
            m_pStart.GetData();     // Skip "calling convention"
        }
        //------------------------------------------------------------------
        // Returns type of the field
        //------------------------------------------------------------------
        CorElementType GetFieldType()
        {
            return m_pStart.PeekElemType();
        }


};




//=========================================================================
// Indicates whether an argument is to be put in a register using the
// default IL calling convention. This should be called on each parameter
// in the order it appears in the call signature. For a non-static method,
// this function should also be called once for the "this" argument, prior
// to calling it for the "real" arguments. Pass in a typ of IMAGE_CEE_CS_OBJECT.
//
//  *pNumRegistersUsed:  [in,out]: keeps track of the number of argument
//                       registers assigned previously. The caller should
//                       initialize this variable to 0 - then each call
//                       will update it.
//
//  typ:                 the signature type
//  structSize:          for structs, the size in bytes
//  fThis:               is this about the "this" pointer?
//  callconv:            see IMAGE_CEE_CS_CALLCONV_*
//  *pOffsetIntoArgumentRegisters:
//                       If this function returns TRUE, then this out variable
//                       receives the identity of the register, expressed as a
//                       byte offset into the ArgumentRegisters structure.
//
//
//=========================================================================
BOOL IsArgumentInRegister(int   *pNumRegistersUsed,
                          BYTE   typ,
                          UINT32 structSize,
                          BOOL   fThis,
                          BYTE   callconv,
                          int   *pOffsetIntoArgumentRegisters);


#endif /* _H_SIGINFO */
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\tempia64.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************
 *
 *  The following temporarily moved here from instr.h (for quicker rebuilds).
 */

enum instruction
{
    #define INST1(id, sn, ik, rf, wf, xu, fu, ic) INS_##id,
    #include "instrIA64.h"
    #undef  INST1

    INS_count
};

/*****************************************************************************/

enum insKinds
{
    IK_NONE,

    IK_LEAF,                                    // no further contents
    IK_CONST,                                   // integer/float constant
    IK_VAR,                                     // variable (local/global)
    IK_REG,                                     // physical register

    IK_UNOP,                                    //  unary op: qOp1      present
    IK_BINOP,                                   // binary op: qOp1+qOp2 present
    IK_ASSIGN,                                  // assignment

    IK_JUMP,                                    // local jump (i.e. to another ins)
    IK_CALL,                                    // function call

    IK_SWITCH,                                  // table jump
};

extern  unsigned char   ins2kindTab[INS_count];

inline  insKinds     ins2kind(instruction ins)
{
    assert((unsigned)ins < INS_count); return (insKinds)ins2kindTab[ins];
}

#ifdef  DEBUG

extern  const char *    ins2nameTab[INS_count];

inline  const char *    ins2name(instruction ins)
{
    assert((unsigned)ins < INS_count); return           ins2nameTab[ins];
}

#endif

/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\targetsh3.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/************************************************************************
*
 Confidential.
*
***********************************************************************/
// -*- C++ -*-


#define CPU_NAME        "SH3"

/*****************************************************************************/

#define STK_FASTCALL    1           // reserve space on stack for reg args?
#define NST_FASTCALL    0           // fastcall calls allowed to nest?

#define ARG_ORDER_L2R   0
#define ARG_ORDER_R2L   1

/*****************************************************************************/

enum regNumbers
{
    #define REGDEF(name, strn, rnum, mask) REG_##name = rnum,
    #include "regSH3.h"
    #undef  REGDEF

    REG_COUNT,
    REG_NA = REG_COUNT
};

enum regMasks
{
    #define REGDEF(name, strn, rnum, mask) RBM_##name = mask,
    #include "regSH3.h"
    #undef  REGDEF
};

#ifndef BIRCH_SP2
/* The following are used to hold 64-bit integer operands */

#ifndef NDEBUG
#define REG_PAIR_FIRST 0x70
#else
#define REG_PAIR_FIRST 0x0
#endif

enum regPairNos
{
    #define PAIRDEF(rlo,rhi)    REG_PAIR_##rlo##rhi = REG_##rlo + (REG_##rhi << 4) + REG_PAIR_FIRST,
    #include "regpair.h"
    #undef  PAIRDEF

    REG_PAIR_LAST  = REG_PAIR_STKr14 + REG_PAIR_FIRST,
    REG_PAIR_NONE  = REG_PAIR_LAST + 1
};

enum regPairMask
{
    #define PAIRDEF(rlo,rhi)    RBM_PAIR_##rlo##rhi = (RBM_##rlo|RBM_##rhi),
    #include "regpair.h"
    #undef  PAIRDEF
};
#endif

/* We're using the encoding for r15 to indicate a half-long on the frame */

#define REG_L_STK               REG_r15

#ifndef BIRCH_SP2
/*
    The following yield the number of bits and the mask of a register
    number in a register pair.
 */

#define REG_PAIR_NBITS          4
#define REG_PAIR_NMASK          ((1<<REG_PAIR_NBITS)-1)
#endif

/*****************************************************************************/

#define REGNUM_BITS             4               // number of bits in reg#

#ifdef BIRCH_SP2
typedef unsigned                regMaskTP;
typedef unsigned short          regMaskSmall;

typedef regNumbers              regNumber;
typedef regNumber               regNumberSmall;
#else
typedef unsigned                regMaskTP;
typedef unsigned short          regMaskSmall;
typedef unsigned                regPairMaskTP;
typedef unsigned short          regPairMaskSmall;

#ifdef  FAST
typedef unsigned int            regNumber;
typedef unsigned int            regPairNo;
typedef unsigned char           regNumberSmall;
typedef unsigned short          regPairNoSmall;
#else
typedef regNumbers              regNumber;
typedef regPairNos              regPairNo;
typedef regNumber               regNumberSmall;
typedef regPairNo               regPairNoSmall;
#endif
#endif

/*****************************************************************************/

#define CPU_FLT_REGISTERS       0
#define CPU_DBL_REGISTERS       0

#define CPU_HAS_FP_SUPPORT      0

#define USE_HELPERS_FOR_INT_DIV 1

/*****************************************************************************/

#define MAX_REGRET_STRUCT_SZ    4
#define RET_64BIT_AS_STRUCTS    1

/*****************************************************************************/

#define LEA_AVAILABLE           0
#define SCALED_ADDR_MODES       0

/*****************************************************************************/

#define EMIT_USE_LIT_POOLS      1
#define EMIT_DSP_INS_NAME       "      %-11s "

#define EMIT_TRACK_STACK_DEPTH  0

/*****************************************************************************/

#ifdef  DEBUG
#define DSP_SRC_OPER_LEFT       1
#define DSP_SRC_OPER_RIGHT      0
#define DSP_DST_OPER_LEFT       0
#define DSP_DST_OPER_RIGHT      1
#endif

/*****************************************************************************/

#define MAX_INDREG_DISP         15  // NOTE: always scaled by operand size

/*****************************************************************************/

enum addrModes
{
    AM_NONE,

    AM_REG,                         // register value
    AM_LCL,                         // local variable (on stack frame)
    AM_CONS,                        // constant
    AM_GLOBAL,                      // global variable / static data member

    AM_IND_REG1,                    // [reg1       ]
    AM_IND_REG1_REG0,               // [reg1 + reg0]
    AM_IND_REG1_DISP,               // [reg1 + disp]
};

/*****************************************************************************/

#define RBM_ALL                 (RBM_r00|RBM_r01|RBM_r02|RBM_r03|       \
                                 RBM_r04|RBM_r05|RBM_r06|RBM_r07|       \
                                 RBM_r08|RBM_r09|RBM_r10|RBM_r11|       \
                                 RBM_r12|RBM_r13|RBM_r14|RBM_r15)

#define RBM_CALLEE_SAVED        (RBM_r08|RBM_r09|RBM_r10|RBM_r11|RBM_r12|RBM_r13|RBM_r14|RBM_r15)
#define RBM_CALLEE_TRASH        (RBM_ALL & ~RBM_CALLEE_SAVED)

#define CALLEE_SAVED_REG_MAXSZ  ((8+1)*sizeof(int)) // callee-saved + retaddr

#define MAX_EPILOG_SIZE          16

#if     ALLOW_MIN_OPT
#define RBM_MIN_OPT_LCLVAR_REGS  REG_r04,REG_r05,REG_r06,REG_r07,REG_r08,\
                                 REG_r09,REG_r10,REG_r11,REG_r12,REG_r13
#endif

#define REG_VAR_LIST                             REG_r02,REG_r03,REG_r04,REG_r05,REG_r06,REG_r07,\
                                 REG_r08,REG_r09,REG_r10,REG_r11,REG_r12,REG_r13,REG_r14,REG_r00

// Where is the exception object on entry to the handler block ?
#define REG_EXCEPTION_OBJECT     REG_r00
#define RBM_EXCEPTION_OBJECT     RBM_r00

// Which register are int and long values returned in ?
#define REG_INTRET               REG_r00
#define RBM_INTRET               RBM_r00
#define REG_LNGRET               REG_PAIR_r00r01
#define RBM_LNGRET              (RBM_r00|RBM_r01)

#define REG_FPBASE               REG_r14
#define RBM_FPBASE               RBM_r14
#define REG_SPBASE               REG_r15
#define RBM_SPBASE               RBM_r15

#define MAX_SPBASE_OFFS          (MAX_INDREG_DISP*sizeof(int))
#define MAX_FPBASE_OFFS          (MAX_INDREG_DISP*sizeof(int))

/*****************************************************************************/

#if     USE_FASTCALL

#define MAX_REG_ARG             4

#define REG_ARG_0               REG_r04
#define REG_ARG_1               REG_r05
#define REG_ARG_2               REG_r06
#define REG_ARG_3               REG_r07

#define RBM_ARG_0               RBM_r04
#define RBM_ARG_1               RBM_r05
#define RBM_ARG_2               RBM_r06
#define RBM_ARG_3               RBM_r07

#define RBM_ARG_REGS            (RBM_ARG_0|RBM_ARG_1|RBM_ARG_2|RBM_ARG_3)

inline
bool                isRegParamType(var_types type)
{
    // temp hack: don't pass longs/doubles in regs

    if  (type <= TYP_INT || type == TYP_FLOAT ||
         type == TYP_REF || type == TYP_BYREF)
        return  true;
    else
        return  false;
}

#endif

/*****************************************************************************/

#define FIRST_ARG_STACK_OFFS    0
#define MIN_OUT_ARG_RESERVE     16

/*****************************************************************************/

#define INSTRUCTION_SIZE        2

/*****************************************************************************/

#define IMMED_INT_MIN           (-128)
#define IMMED_INT_MAX           (+127)

/*****************************************************************************/

#define JMP_DIST_SMALL_MAX_NEG  (-0x2000)
#define JMP_DIST_SMALL_MAX_POS  (+0x1FFF)

#define JMP_DIST_MIDDL_MAX_NEG  (0)
#define JMP_DIST_MIDDL_MAX_POS  (0)

#define JMP_SIZE_SMALL          (2)     // bra target
#define JMP_SIZE_MIDDL          (0)     // no such thing
#define JMP_SIZE_LARGE          (12)     // mov [addr], rt ; jmp @rt ; nop

#define JCC_DIST_SMALL_MAX_NEG  (-0x00FE)
#define JCC_DIST_SMALL_MAX_POS  (+0x0100)

#define JCC_DIST_MIDDL_MAX_NEG  JMP_DIST_SMALL_MAX_NEG
#define JCC_DIST_MIDDL_MAX_POS  JMP_DIST_SMALL_MAX_POS

#define JCC_SIZE_SMALL          (2)
#define JCC_SIZE_MIDDL          (6)
#define JCC_SIZE_LARGE          (14)

#define JMP_SIZE_SMALL_MIN      (2)     // smaller of JMP_SIZE_SMALL and JCC_SIZE_SMALL
#define JMP_SIZE_SMALL_MAX      (2)     // larger  of JMP_SIZE_SMALL and JCC_SIZE_SMALL

#define LARGEST_JUMP_SIZE       (8)

#define JMP_INSTRUCTION         INS_bra

#define MAX_BRANCH_DELAY_LEN    1       // the max. number of branch-delay slots

/*****************************************************************************/

#ifndef BIRCH_SP2               // this comes from the Wce build switches
#define SMALL_DIRECT_CALLS      1
#endif

#define CALL_DIST_MAX_NEG       (-0x0200)
#define CALL_DIST_MAX_POS       (+0x01FE)

inline
BYTE  * emitDirectCallBase(BYTE *orig)
{
    return  orig + 2 * INSTRUCTION_SIZE;
}

/* Indirect calls consist of LIT_POOL_LOAD_INS followed by INDIRECT_CALL_INS */

#define LIT_POOL_LOAD_INS       INS_mov_PC
#define INDIRECT_CALL_INS       INS_jsr
#define   DIRECT_CALL_INS       INS_bsr

/*****************************************************************************/

#define LIT_POOL_MAX_OFFS_WORD  (0x100*sizeof(short))
#define LIT_POOL_MAX_OFFS_LONG  (0x100*sizeof(long ))

enum    LPfixTypes
{
    LPF_CLSVAR,                         // static data member
    LPF_METHOD,                         // non-virtual method
};

/*****************************************************************************/
#if     SCHEDULER
/*****************************************************************************
 *
 *  Define target-dependent scheduling values that need to be kept track of.
 */

#define SCHED_USE_FL            1       // scheduler needs to know about flags

struct  scExtraInfo
{
    unsigned        scxDeps;
};

#define             scTgtDepDcl()                                   \
                                                                    \
    schedDef_tp     scMACdef, scPRRdef;                             \
    schedUse_tp     scMACuse, scPRRuse;

#define             scTgtDepClr()                                   \
                                                                    \
    scMACdef = scPRRdef = 0;                                        \
    scMACuse = scPRRuse = 0;

#define             scTgtDepDep(id,inf,dag)
#define             scTgtDepUpd(id,inf,dag)

#endif  // SCHEDULER
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\typedefs.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef _TYPEDEFS_H_
#define _TYPEDEFS_H_
/*****************************************************************************/

        struct  ident;
typedef struct  ident         * identPtr;

/*---------------------------------------------------------------------------*/

        struct  symLst;
typedef struct  symLst        * symLstPtr;

        struct  typLst;
typedef struct  typLst        * typLstPtr;

        struct  namLst;
typedef struct  namLst        * namLstPtr;

/*---------------------------------------------------------------------------*/

        struct  symDef;
typedef struct  symDef        * symDefPtr;

        struct  typDef;
typedef struct  typDef        * typDefPtr;

        struct  dimDef;
typedef struct  dimDef        * dimDefPtr;

        struct  argDef;
typedef struct  argDef        * argDefPtr;

        struct  attrDef;
typedef struct  attrDef       * attrDefPtr;

/*---------------------------------------------------------------------------*/

        struct  stmtExpr;
typedef struct  stmtExpr      * stmtExprPtr;

typedef struct  stmtExpr        parseTree;
typedef struct  stmtExpr      * parseTreePtr;

/*---------------------------------------------------------------------------*/

        struct PCblock;
typedef struct PCblock        * PCblockPtr;

        struct swtGenDsc;
typedef struct swtGenDsc      * swtGenDscPtr;

/*****************************************************************************/
#endif
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\tuple.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
// tuple.h
//
// This file defines the tuple data structure and support structures
// which are at the core of the Unified Tuples Compiler.  Tuples are
// defined in a hierarchy such that each tuple inherits all the fields
// from its base structures.
//
// Tuple hierarchy:
//
// BASE
//    ILLEGAL
//    LEAFANDCODE
//        LEAF
//            SYMREF
//               REG
//               SYM
//               ADDR
//                   DATAADDR
//                   CODEADDR
//            MEMREF
//               EA
//               INDIR
//            CONST
//               INTCONST
//               SYMCONST
//               FLOATCONST
//            REGSET
//            SYMSET
//            TEXTCONST
//        CODE
//            INSTR
//                OP
//                MBOP
//                CALL
//                RETURN
//                QUESTION
//                BRANCH
//                SWITCH
//                INTRINSIC
//                TUPLIST
//                EXCEPT
//            BLOCK
//            LABEL
//            ENTRY
//            EXIT
//            PRAGMA
//            SPLITPOINT
//            PCODE
//    LIST
//        BRANCHLIST
//        CASELIST
//        CONDSETTERLIST
//

// Tuple types.  This type system is used by the
// entire tuples compiler including both tuples and symbols.
// The type system includes machine types (e.g. TY_INT32) and
// abstract types (e.g. TY_PTR).

#define TY_SIZEFIELDWIDTH     12
#define TY_BASETYPEFIELDWIDTH 4
#define TY_MBSIZETHRESHOLD    (1 << TY_SIZEFIELDWIDTH)

#if defined(CC_TYPEINFO)
// Expanded type information includes primitive type, size, alignment,
// and tag information.
//
// TYPEIDENTIFIER is an unsigned short.  Use unsigned short to declare
// the bit fields to get the same behavior as TYPE previously provided
// before it was widened to unsigned long.  An unsigned short compared
// to a long will not generate a warning because the unsigned short
// is converted to long (it fits) prior to the comparison.  If TYPE
// (unsigned long) is used to declare the bit fields, the unsigned to
// signed comparison warning will fire wherever UTC compares a long
// size to the type size.
//

// Type identifier is defined as primitive type and size
// Type identifier = ((baseType << bitsizeof(size)) | size)
#define TY_TYPEIDENTIFIERMASK ((1 << (TY_SIZEFIELDWIDTH+TY_BASETYPEFIELDWIDTH)) - 1)

// Type qualifier is everything else
#define TY_TYPEQUALIFIERMASK (~TY_TYPEIDENTIFIERMASK)

// Alignment information
#define TY_ALIGNFIELDPOSITION (1 << (TY_SIZEFIELDWIDTH+TY_BASETYPEFIELDWIDTH))
#define TY_ALIGNFIELDWIDTH    8

// Tag information bitfields
#define TY_TAGFIELDPOSITION   (1 << (TY_SIZEFIELDWIDTH+TY_BASETYPEFIELDWIDTH+TY_ALIGNFIELDWIDTH))
#define TY_TAGFIELDWIDTH      8

typedef union tagTYPEINFO
{
    TYPE                 type;
    struct
    {
#ifndef HBIGEND
        union
        {
            struct
            {
                TYPEIDENTIFIER       typeIdentifier;
                TYPEIDENTIFIER       typeQualifier;
            };
            struct
            {
                TYPEIDENTIFIER   size       : TY_SIZEFIELDWIDTH;
                TYPEIDENTIFIER   baseType   : TY_BASETYPEFIELDWIDTH;
                TYPEIDENTIFIER   align      : TY_ALIGNFIELDWIDTH;
                TYPEIDENTIFIER   tagInfo    : TY_TAGFIELDWIDTH;
            };
            // Use the tag bitfields to add additional type infomation.
            struct
            {
                TYPEIDENTIFIER              : TY_SIZEFIELDWIDTH;
                TYPEIDENTIFIER              : TY_BASETYPEFIELDWIDTH;
                TYPEIDENTIFIER              : TY_ALIGNFIELDWIDTH;
                TYPEIDENTIFIER   unused     : 1;
                TYPEIDENTIFIER   unused2    : 1;
#if defined(TP7)
                TYPEIDENTIFIER   isHFA      : 1;
#else
                TYPEIDENTIFIER              : 1;
#endif
                TYPEIDENTIFIER              : 1;
                TYPEIDENTIFIER              : 1;
                TYPEIDENTIFIER              : 1;
                TYPEIDENTIFIER              : 1;
                TYPEIDENTIFIER              : 1;
            };
        };
#else   // HBIGEND
        union
        {
            struct
            {
                TYPEIDENTIFIER       typeQualifier;
                TYPEIDENTIFIER       typeIdentifier;
            };
            struct
            {
                TYPEIDENTIFIER              : 1;
                TYPEIDENTIFIER              : 1;
                TYPEIDENTIFIER              : 1;
                TYPEIDENTIFIER              : 1;
                TYPEIDENTIFIER              : 1;
#if defined(TP7)
                TYPEIDENTIFIER   isHFA      : 1;
#else
                TYPEIDENTIFIER              : 1;
#endif
                TYPEIDENTIFIER   unused     : 1;
                TYPEIDENTIFIER   unused2    : 1;
                TYPEIDENTIFIER              : TY_ALIGNFIELDWIDTH;
                TYPEIDENTIFIER              : TY_BASETYPEFIELDWIDTH;
                TYPEIDENTIFIER              : TY_SIZEFIELDWIDTH;
            };
            struct
            {
                TYPEIDENTIFIER   tagInfo    : TY_TAGFIELDWIDTH;
                TYPEIDENTIFIER   align      : TY_ALIGNFIELDWIDTH;
                TYPEIDENTIFIER   baseType   : TY_BASETYPEFIELDWIDTH;
                TYPEIDENTIFIER   size       : TY_SIZEFIELDWIDTH;
            };
        };
#endif  // HBIGEND
    };
} TYPEINFO;

#else

// Original type system which defines type as primitive type and size.
// Tuple (and symbol) types: type = ((baseType << bitsizeof(size)) | size)

typedef union tagTYPEINFO
{
    TYPE        type;
    struct
    {
#ifndef HBIGEND
        TYPE    size     : TY_SIZEFIELDWIDTH;
        TYPE    baseType : TY_BASETYPEFIELDWIDTH;
#else
        TYPE    baseType : TY_BASETYPEFIELDWIDTH;
        TYPE    size     : TY_SIZEFIELDWIDTH;
#endif
    };
} TYPEINFO;
#endif

#if ((2 * MACH_BITS) != (TY_BASETYPEFIELDWIDTH + TY_SIZEFIELDWIDTH))
#error Type structure definition inconsistency
#endif

// Tuple base types.

enum
{
#define TUPBASETYPE(ucname, type1, type2, type4, type6, type8, type10, type16, regClass)\
    TY_BASE ## ucname,
#include "tupbtype.h"
#undef TUPBASETYPE
    TY_NUMBEROFBASETYPES
};

#if (TY_NUMBEROFTYPES >= (1 << TY_BASETYPEFIELDWIDTH))
#error Number of tuple base types exceeds baseType field witdh
#endif

// Tuple type compile time sizeof in bytes.


enum
{
#define TUPTYPE(ucname, baseType, size, align, bitSize, attr, dname)\
    TY_SIZEOF ## ucname = size,
#include "tuptypes.h"
#undef TUPTYPE
};

// Tuple type compile time sizeof in bits.

enum
{
#define TUPTYPE(ucname, baseType, size, align, bitSize, attr, dname)\
    TY_BITSIZEOF ## ucname = bitSize,
#include "tuptypes.h"
#undef TUPTYPE
};

#if defined(CC_TYPEINFO) && !defined(CC_SYMALIGN)
// Tuple type compile time alignment in log2(byte_alignment) format.
enum
{
#define TUPTYPE(ucname, baseType, size, align, bitSize, attr, dname)\
    TY_ALIGN ## ucname = align,
#include "tuptypes.h"
#undef TUPTYPE
};
#elif defined(CC_SYMALIGN)
// Tuple type compile time alignment in log2(byte_alignment)+1 format.
enum
{
#define TUPTYPE(ucname, baseType, size, align, bitSize, attr, dname)\
    TY_ALIGN ## ucname = align + 1,
#include "tuptypes.h"
#undef TUPTYPE
};
#endif

#if defined(CC_TYPEINFO)
// Tuple type encodings fullType including baseType, size, and alignment

#define TY_MAKE(baseType, size) TyMake(baseType, size)
#define TY_MAKETYPEINFO(baseType, size, align)\
    ((TYPE) ((TYPE)(baseType << TY_SIZEFIELDWIDTH) | (TYPE)(size) | (TYPE)(align << (TY_SIZEFIELDWIDTH + TY_BASETYPEFIELDWIDTH))))

enum
{
#define TUPTYPE(ucname, baseType, size, align, bitSize, attr, dname)\
    TY_ ## ucname = TY_MAKETYPEINFO(TY_BASE ## baseType, TY_SIZEOF ## ucname, TY_ALIGN ## ucname),
#include "tuptypes.h"
#undef TUPTYPE
};
#else
// Tuple type encodings fullType = ((baseType << bitsizeof(size)) | size)

#define TY_MAKE(baseType, size)\
    ((TYPE) ((TYPE)(baseType << TY_SIZEFIELDWIDTH) | (TYPE)(size)))

enum
{
#define TUPTYPE(ucname, baseType, size, align, bitSize, attr, dname)\
    TY_ ## ucname = TY_MAKE(TY_BASE ## baseType, TY_SIZEOF ## ucname),
#include "tuptypes.h"
#undef TUPTYPE
};
#endif

// Tuple type index values, creates a linear index for types
// to support table driven mechanisms.  Use TY_MAKEMAP(...) to create
// tables and TY_INDEX(type) to index into these types of tables.

enum
{
#define TUPTYPE(ucname, baseType, size, align, bitSize, attr, dname)\
    TY_INDEX ## ucname,
#include "tuptypes.h"
#undef TUPTYPE
    TY_NUMBEROFTYPES
};

// Tuple make type map for scalar types, indexed by type index.

#if defined(TMIPS) && COLOR_SPILLS_TO_REGISTERS
// Need an extra field for the TY_SPILL data type
#define TY_MAKEMAP(i8, i16, i32, i64, u8, u16, u32, u64, f32, f64, p)\
    {0, i8, i16, 0, i32, 0, i64, u8, u16, 0, u32, 0, u64, f32, f64, 0, p, 0}
#else
#define TY_MAKEMAP(i8, i16, i32, i64, u8, u16, u32, u64, f32, f64, p)\
    {0, i8, i16, 0, i32, 0, i64, u8, u16, 0, u32, 0, u64, f32, f64, 0, p}
#endif

#define TY_MAKEMAP2(i8, i16, i32, i64, u8, u16, u32, u64, f32, f64, f80, \
        p32, p64, mb1, mb2, mb4, mb8) \
    {0, i8, i16, 0, i32, 0, i64, u8, u16, 0, u32, 0, u64, f32, f64, f80, \
        p32, 0, p64, mb1, mb2, mb4, mb8}

// Tuple make base type map for scalar types, indexed by base type enum

#define TY_MAKEBASEMAP(illegal, int, uint, ptr, float, str)\
    {illegal, int, uint, ptr, float, str}

// Tuple types bits used for type classification.

enum
{

#define TY_GETBIT(i) (1 << i)

#define TUPBASETYPE(ucname, type1, type2, type4, type6, type8, type10, type16, class)\
    TY_BASE ## ucname ## BIT = TY_GETBIT(TY_BASE ## ucname),
#include "tupbtype.h"
#undef TUPBASETYPE
};

// Tuple basic type field operations.

#define TY_TYPEINFO(t)       (* (TYPEINFO *) &(t))
#define TY_TYPE(t)           (TY_TYPEINFO(t).type)
#define TY_SIZE(t)           (TY_TYPEINFO(t).size)
#define TY_BITSIZE(t)        (TY_TYPEINFO(t).size * MACH_BITS)
#define TY_BASETYPE(t)       (TY_TYPEINFO(t).baseType)
#if defined(CC_TYPEINFO)
#define TY_TYPEIDENTIFIER(t) (TY_TYPEINFO(t).typeIdentifier)
#define TY_TYPEQUALIFIER(t)  (TY_TYPEINFO(t).typeQualifier)
#define TY_COPYTYPEQUALIFIER(t1,t2) (TY_TYPEQUALIFIER(t1) = TY_TYPEQUALIFIER(t2))
#define TY_ALIGN(t)          (TY_TYPEINFO(t).align)
#define TY_ALIGNBITS(t)      (MACH_BITS * (1 << TY_TYPEINFO(t).align))
#define TY_ALIGNBYTES(t)     (1 << TY_TYPEINFO(t).align)
#define TY_COPYALIGN(t1,t2)  (TY_ALIGN(t1) = TY_ALIGN(t2))
#define TY_TAGINFO(t)        (TY_TYPEINFO(t).tagInfo)
#define TY_COPYTAGINFO(t1,t2)(TY_TAGINFO(t1) = TY_TAGINFO(t2))
#define TY_EQUIVTYPE(t1,t2)  ((TY_TYPEIDENTIFIERMASK & (t1)) == (TY_TYPEIDENTIFIERMASK & (t2)))
#else
#define TY_TYPEIDENTIFIER(t) (t)
#define TY_COPYTYPEQUALIFIER(t1,t2)
#define TY_COPYALIGN(t1,t2)
#define TY_COPYTAGINFO(t1,t2)
#define TY_EQUIVTYPE(t1,t2)  ((t1) == (t2))
#endif
#define TY_INDEX(t)          (TyGetIndex(t))

#define TY_ISVALID(t)        (TyIsValid(t))
#define TY_ISINT(t)          ((TY_BASEINTBIT | TY_BASEUINTBIT | TY_BASEPTRBIT)\
                                 & TY_GETBIT(TY_BASETYPE(t)))
#define TY_ISINT64(t)        (TY_ISINT(t) && TY_SIZE(t)==8)
#define TY_ISSIGNED(t)       (TY_BASETYPE(t) == TY_BASEINT)
#define TY_ISUNSIGNED(t)     (TY_BASETYPE(t) == TY_BASEUINT)
#define TY_ISFLOAT(t)        (TY_BASETYPE(t) == TY_BASEFLOAT)
#if defined(T386)
# define TY_ISMMX(t)          (TY_BASETYPE(t) == TY_BASEMMX)
#endif
#if defined(CC_KNI)
# define TY_ISXMMX(t)         (TY_BASETYPE(t) == TY_BASEXMMX)
# define TY_ISANYXMMX(t)      (TY_ISXMMX(t))
#endif
#define TY_ISMULTIBYTE(t)    (TY_BASETYPE(t) == TY_BASEMULTIBYTE)
#define TY_ISSMB1(t)         (TY_EQUIVTYPE(t, TY_SMB1))
#define TY_ISSMB2(t)         (TY_EQUIVTYPE(t, TY_SMB2))
#define TY_ISSMB4(t)         (TY_EQUIVTYPE(t, TY_SMB4))
#define TY_ISSMB8(t)         (TY_EQUIVTYPE(t, TY_SMB8))
#if defined(TALPHA)
#define TY_ISSMALLMB(t)      ((TY_ISMULTIBYTE(t) &&\
                               TY_SIZE(t) >= BYTE_SIZE &&\
                               TY_SIZE(t) <= QWORD_SIZE) &&\
                              !FUNC_IS_WVM)
#else
#define TY_ISSMALLMB(t)      ((TY_ISSMB1(t) ||\
                               TY_ISSMB2(t) ||\
                               TY_ISSMB4(t) ||\
                               TY_ISSMB8(t))  &&\
                              !FUNC_IS_WVM)
#endif
#define TY_ISPTR(t)          (TY_BASETYPE(t) == TY_BASEPTR)
#define TY_ISFUNC(t)         (TY_EQUIVTYPE(t, TY_FUNC))
#define TY_ISCONDCODE(t)     (TY_EQUIVTYPE(t, TY_CONDCODE))
#define TY_ISFLAG(t)         (TY_EQUIVTYPE(t, TY_FLAG))
#define TY_ISVOID(t)         (TY_EQUIVTYPE(t, TY_VOID))
#if defined(TMIPS)
#define TY_ISSPILL(t)        (TY_TYPE(t) == TY_SPILL32)
#endif

#define TY_COMPATIBLE(t1,t2) (TyCompatible((t1),(t2)))
#define TY_CANENREG(t)       (TyCanEnreg(t))

#define TY_SIGNED(t)         (TY_MAKE(TY_BASEINT, TY_SIZE(t)))
#define TY_UNSIGNED(t)       (TY_MAKE(TY_BASEUINT, TY_SIZE(t)))

#if defined(CC_SYMALIGN)
// Returns the natural alignment of the given type in the BE format.  For
// sizes which are not a power of two, it rounds up (e.g. mb6 would be
// rounded to 8 byte alignment.  Returns TY_SIZEOFFLOAT64 things of
// size 0, assuming that they are mb0's (which are a hack for large MBs).
#define TY_NATALIGN(t) ((ALIGNMENT) (TY_SIZE(t) ? BYTE_ALIGN_TO_BE_ALIGN(2*TY_SIZE(t)-1) : BYTE_ALIGN_TO_BE_ALIGN(8)))
#endif

// Tuple pointer type.

extern TYPE TyPtrType;

// Tuple variant typedefs

#define TYPEDEF_TUPLE(k)\
    typedef struct tag ## k ## TUPLE k ## TUPLE, *P ## k ## TUPLE

TYPEDEF_TUPLE(BASE);
TYPEDEF_TUPLE(BASECOMMON);
TYPEDEF_TUPLE(ILLEGAL);
TYPEDEF_TUPLE(LEAFANDCODECOMMON);
TYPEDEF_TUPLE(LEAF);
TYPEDEF_TUPLE(LEAFCOMMON);
TYPEDEF_TUPLE(SYMREFCOMMON);
TYPEDEF_TUPLE(SYMREF);
TYPEDEF_TUPLE(REG);
TYPEDEF_TUPLE(SYM);
TYPEDEF_TUPLE(ADDRCOMMON);
TYPEDEF_TUPLE(ADDR);
TYPEDEF_TUPLE(CODEADDR);
TYPEDEF_TUPLE(DATAADDR);
TYPEDEF_TUPLE(MEMREFCOMMON);
TYPEDEF_TUPLE(MEMREF);
TYPEDEF_TUPLE(EA);
TYPEDEF_TUPLE(INDIR);
TYPEDEF_TUPLE(INTCONST);
TYPEDEF_TUPLE(SYMCONST);
TYPEDEF_TUPLE(FLOATCONST);
TYPEDEF_TUPLE(REGSET);
TYPEDEF_TUPLE(SYMSET);
TYPEDEF_TUPLE(CODE);
TYPEDEF_TUPLE(CODECOMMON);
TYPEDEF_TUPLE(INSTR);
TYPEDEF_TUPLE(INSTRCOMMON);
TYPEDEF_TUPLE(OP);
TYPEDEF_TUPLE(MBOP);
TYPEDEF_TUPLE(CALL);
TYPEDEF_TUPLE(RETURN);
TYPEDEF_TUPLE(INTRINSIC);
TYPEDEF_TUPLE(QUESTION);
TYPEDEF_TUPLE(BRANCH);
TYPEDEF_TUPLE(SWITCH);
TYPEDEF_TUPLE(LABEL);
TYPEDEF_TUPLE(BLOCK);
TYPEDEF_TUPLE(ENTRY);
TYPEDEF_TUPLE(EXIT);
TYPEDEF_TUPLE(PRAGMA);
TYPEDEF_TUPLE(SPLITPOINT);
TYPEDEF_TUPLE(TUPLIST);
TYPEDEF_TUPLE(EXCEPT);
TYPEDEF_TUPLE(LIST);
TYPEDEF_TUPLE(LISTCOMMON);
TYPEDEF_TUPLE(BRANCHLIST);
TYPEDEF_TUPLE(CASELIST);
TYPEDEF_TUPLE(CONDSETTERLIST);
#ifdef CC_PCODE
TYPEDEF_TUPLE(PCODE_);  // PCODETUPLE == CODETUPLE*, so make it PCODE_TUPLE
#endif
#if defined(CC_TEXTCONST)
TYPEDEF_TUPLE(TEXTCONST);
#endif
TYPEDEF_TUPLE(ILLEGAL);

// Tuple structure declarations

#define DECLARE_TUPLE(derive,base)\
    struct tag ## derive ## TUPLE { base ## COMMON;

#define DECLARE_TUPLEEND };

#if defined(CC_LRA)
#define ISHOISTEDSPILLDECL UCHAR                       isHoistedSpill:1;
#else
#define ISHOISTEDSPILLDECL UCHAR                       baseUnused1:1;
#endif

// Common base structure for all tuples.

#define BASECOMMON\
    PTUPLE                      next;\
    const OPCODE                opcode;\
    const TUPLEKIND             kind;\
    union {\
        struct {\
            UCHAR                       isInstr:1;\
            UCHAR                       isInlineAsm:1;\
            UCHAR                       isRiscified:1;\
            UCHAR                       isPersistentBranch:1;\
            UCHAR                       isDummyUse:1;\
            ISHOISTEDSPILLDECL \
            UCHAR                       baseUnused2:2; \
        };\
        struct {\
            UCHAR       /* defined above */    : 3;\
            UCHAR       /* leaf */      dontCopyProp:1;\
            UCHAR                       isRedundant:1;\
            UCHAR                       isRehashAssign:1;\
            UCHAR                       isCandidate:1;\
            UCHAR                       wasZeroTripTested:1;\
        };\
    }

DECLARE_TUPLE(BASECOMMON, BASE)
DECLARE_TUPLEEND

DECLARE_TUPLE(ILLEGAL, BASE)
DECLARE_TUPLEEND


// Common base structure for all leaf and code tuples

#ifdef CC_SSA
// 1. Note: the 2 bits of ssaDefType overlaps with the low 2 bits of OpUdLink.
//    The code assumes that if ssaDefType is 0 then OpUdLink is valid. This is
//    true as long as OpUdLink always points to 4-byte aligned data, and
//    ssaDefType is never >2 bits.
// 2. ssaDefNo is only valid if ssaDefType != 0 (i.e., is LVAL
//    or RVAL).
#define SSA_DEFNO\
    union {\
        struct {\
            unsigned int ssaDefType:2;\
            unsigned int ssaDefNo:30;\
        };\
        PTUPLE OpUdLink;\
    };
#else
#define SSA_DEFNO
#endif


#if defined(CC_PROFILE_FEEDBACK)
// Pogo does not like when condition codes are modified directly.  Make
// the TU_CONDCODE field const under Pogo.
#define CONSTCONDCODE const CONDCODE
#else
#define CONSTCONDCODE CONDCODE
#endif

#if defined(TARM) || defined(TTHUMB) || defined(CC_CNC)
// ARM needs a condcode on basically everything (since any instruction can be
// conditionally executed), so for ARM we don't put the condcode field in a
// union.  Also, ARM has 16 legal condcodes, so 4 bits isn't enough.
#define CONDCODE_UNION_BEGIN
#define CONDCODE_UNION_END
#define CONDCODE_BITSIZE 8
#else
#define CONDCODE_UNION_BEGIN  union {
#define CONDCODE_UNION_END    };
#define CONDCODE_BITSIZE 4
#endif

#ifdef CC_NAN2
#define FIELD_INVERTED  UCHAR inverted:1;
#else
#define FIELD_INVERTED
#endif

#ifdef CC_NAN
#define FIELD_ORIGCC  CONDCODE  origCC:CONDCODE_BITSIZE;
#else
#define FIELD_ORIGCC
#endif

#ifdef TP7
#define FIELD_REGMAPSCI    int regMapSci;
#else
#define FIELD_REGMAPSCI
#endif

#define LEAFANDCODECOMMON\
    BASECOMMON;\
    CONDCODE_UNION_BEGIN\
        union\
        {\
            TYPE     /* instr & leaf */ type;\
            TYPEINFO /* instr & leaf */ typeInfo;\
        };\
        struct {\
            union\
            {\
                CONSTCONDCODE /* branch  */ condCode: CONDCODE_BITSIZE;\
                CONDCODE      /* branch  */ _condCode: CONDCODE_BITSIZE;\
            };\
            FIELD_ORIGCC    /* branch  - CC_NAN ONLY */ \
            FIELD_INVERTED  /* branch -  CC_NAN2 ONLY */\
        };\
    CONDCODE_UNION_END\
    SSA_DEFNO\
    union\
    {\
        PTUPLE          /* code */               prev;\
        unsigned int    /* leaf */               defNum;\
        ULONG           /* leaf */               corToken;\
        int             /* leaf */               stackLevel;\
        unsigned int    /* instr & leaf */       optHashVal;\
        PBV             /* leaf */               stkUpRef;\
        int             /* leaf: MdValueTrack */ valNumber;\
        PTUPLE          /* leaf: SSA */          udLink;\
        FIELD_REGMAPSCI /* leaf: global scheduler */ \
    }

DECLARE_TUPLE(LEAFANDCODECOMMON, LEAFANDCODE)
DECLARE_TUPLEEND

// Common base structure for all leaf tuples.

#ifdef CC_CGIF
# define CGIF_TUPID             TUPID    tupID;
#else
# define CGIF_TUPID
#endif

#define LEAFCOMMON\
    LEAFANDCODECOMMON;\
    union {\
        struct {\
            UCHAR               scale          : 4;\
            UCHAR               inUse          : 1;\
            UCHAR               isMemRefReg    : 1;\
            UCHAR               isVolatile     : 1;\
            UCHAR               isCextr        : 1;\
            UCHAR               seg            : 3;\
            UCHAR               isWriteThru    : 1;\
            UCHAR               isDead         : 1;\
            UCHAR               isDetached     : 1;\
            UCHAR               isOverflowed   : 1;\
            UCHAR  /* !color */ unused         : 1;\
            CGIF_TUPID \
        };\
        struct /* optimize only */ {\
            UCHAR       /* defined above */    : 8;\
            UCHAR       /* defined above */    : 7;\
            UCHAR               isRegionConst  : 1;\
        };\
        struct /* color only */ {\
            UCHAR               opeqNum        : 4;\
            UCHAR       /* defined above */    : 3;\
            UCHAR /* color */   physregNotDead : 1;\
            UCHAR       /* defined above */    : 6;\
            UCHAR /* color */   reachesEnd     : 1;\
            UCHAR /* color */   affectsCost    : 1;\
        };\
        struct /* stack only */ {\
            UCHAR       /* defined above */    : 8;\
            UCHAR       /* defined above */    : 7;\
            UCHAR /* stack pack */   upUse     : 1;\
        };\
        struct /* reader only */ {\
            UCHAR               rdrinvertedCC  : 1;\
            UCHAR       /* defined above */    : 7;\
            UCHAR       /* defined above */    : 4;\
            UCHAR               readerCC       : 4;\
        };\
    }

DECLARE_TUPLE(LEAFCOMMON, LEAF)
DECLARE_TUPLEEND

// Common base structure for sym ref leafs (address, memory, or reg)

#define SYMREFCOMMON\
    LEAFCOMMON;\
    union {\
        PSYM    /* reg & sym */ sym;\
        PSYMBOL /* codeaddr */  feSym;\
    };\
    const PSYM                  reg

DECLARE_TUPLE(SYMREF, SYMREF)
DECLARE_TUPLEEND

// Leaf: Reg - symbol in register

DECLARE_TUPLE(REG, SYMREF)
DECLARE_TUPLEEND

// Leaf: Sym - symbol in memory

DECLARE_TUPLE(SYM, SYMREF)
DECLARE_TUPLEEND

// Common base structure for addr leaf tuples (code or data)

#define ADDRCOMMON\
    SYMREFCOMMON

DECLARE_TUPLE(ADDR, ADDR)
DECLARE_TUPLEEND

// Leaf: DataAddr - address of symbol

DECLARE_TUPLE(DATAADDR, ADDR)
DECLARE_TUPLEEND

// Leaf: CodeAddr - address of label or function

DECLARE_TUPLE(CODEADDR, ADDR)
DECLARE_TUPLEEND

// Common base structure for memory ref leafs (address or indir)

#if defined(TARM) || defined(TTHUMB)
struct tagSHIFTER {
    UCHAR    type;       // enum SHIFT_KIND (md.h)
    UCHAR    shift;      // immediate shift amount
    UCHAR    sub : 1;    // BOOL: subtract (U=0) if true else add (U=1)
    UCHAR    post : 1;   // BOOL: post-indexed (P=0) if true
                         //       else pre-indexed (P=1)
    UCHAR    update : 1; // BOOL: 0 (W=0) if post, else: update (W=1) if
                         //       true else no update (W=0)
    UCHAR    reserved : 5;
    UCHAR    reserved2 : 8;
};
#define DECL_SHIFTER ; SHIFTER shifter
#else
#define DECL_SHIFTER
#endif

#if defined(CC_DLP)
#define MEMREFCOMMON_DLP    DLPINFO dlpInfo;
#else
#define MEMREFCOMMON_DLP
#endif

#define MEMREFCOMMON\
    LEAFCOMMON;\
    MEMREFCOMMON_DLP\
    PSYM                        shape;\
    PASINDEX                    pasIndex;\
    ALIGNMENT                   align;\
    PSYM                        fixupSym;\
    OFFSET                      offset;\
    PTUPLE                      base;\
    PTUPLE                      index \
    DECL_SHIFTER

DECLARE_TUPLE(MEMREF, MEMREF)
DECLARE_TUPLEEND

// Leaf: Ea - memory effective address

DECLARE_TUPLE(EA, MEMREF)
DECLARE_TUPLEEND

// Leaf: Indir - memory indirection

DECLARE_TUPLE(INDIR, MEMREF)
DECLARE_TUPLEEND

// Leaf: IntConst

DECLARE_TUPLE(INTCONST, LEAF)
    IVALTYPE                    ival;
# ifdef CC_CE_FPEM
// flag to indicate whether it was a float const before
    UCHAR                         WasFloatConst:1;
# endif
DECLARE_TUPLEEND

// Leaf: SymConst

DECLARE_TUPLE(SYMCONST, LEAF)
    PSYM                        symConst;
DECLARE_TUPLEEND

// Leaf: FloatConst

DECLARE_TUPLE(FLOATCONST, LEAF)
    FVALTYPE                    fval;
DECLARE_TUPLEEND

// Leaf: RegSet

DECLARE_TUPLE(REGSET, LEAF)
   PBV                          regSet;
DECLARE_TUPLEEND

// Leaf: SymSet

DECLARE_TUPLE(SYMSET, LEAF)
    PASINDEX                    symSet;
DECLARE_TUPLEEND

#if defined(CC_TEXTCONST)
// Leaf: TextConst

DECLARE_TUPLE(TEXTCONST, LEAF)
    char                       *textval;
DECLARE_TUPLEEND
#endif

// Common base structure for all code stream (i.e. non-leaf) tuples.
// scratch is const so it's difficult to misuse - exists only to be cleared
// to detect attempts to illegally stretch lifetime of scratch info.

#if defined(TMIPS) || defined(CC_CNC)
#define CODECOMMON_INSTRSIZESIZE USHORT
#else
#define CODECOMMON_INSTRSIZESIZE UCHAR
#endif

#if defined(TP7)
#define DECLARE_GPISVALID struct { UCHAR /* instr */ GPIsValid; };
#else
#define DECLARE_GPISVALID
#endif

#define CODECOMMON\
    LEAFANDCODECOMMON;\
    LINEOFS                     lineOfs;\
    union {\
        struct {\
            UCHAR /* instr */   visited;\
            UCHAR /* instr */   visited2;\
        } vis;\
        struct /* need to change warn.c if these change from UCHAR */ {\
            const UCHAR /* instr */   autoSymUse;\
            const UCHAR /* instr */   autoSymDef;\
        } warn;\
        CODECOMMON_INSTRSIZESIZE /* instr */ instrSize;\
        USHORT /* code */       scratch;\
        USHORT /* branches */   branchType;\
        struct{\
            UCHAR /* code */    optimize;\
            UCHAR /* code */    global;\
        };\
        USHORT /* code */       number;\
        USHORT /* code */       numLiveTemps;\
        DECLARE_GPISVALID\
        CGIF_TUPID \
    }\

DECLARE_TUPLE(CODECOMMON, CODE)
DECLARE_TUPLEEND


// Common base structure for all instruction (i.e. executable) tuples.

// Setup fields that are feature- or platform-dependent.

#if defined(CC_DLP)
#define INSTRCOMMON_DLP_FIELDS    DLPINFO readerDlpInfo;  /* reader */
#else
#define INSTRCOMMON_DLP_FIELDS
#endif

#if defined(CC_GC)
#define INSTRCOMMON_GC_FIELDS     PBV liveRefs;
#else
#define INSTRCOMMON_GC_FIELDS
#endif

// IMPORTANT: If INSTRCOMMON_MD_FIELDS is not empty, it must start with
// a ';' to complete the declaration of the last explicit field (dst).

//  Note that need to preserve the field order of Cmp and FP instrs
#if defined(TP7)
#define INSTRCOMMON_MD_FIELDS   ;\
    union { \
        struct /* for BR, BRP and MOV-2-brreg */ {\
            UCHAR               codeHintWh:2; \
            UCHAR               codeHintPh:1; \
            UCHAR               codeHintDh:1; \
            UCHAR               codeHintIh:1; \
            UCHAR               codeHintPvec:3; \
        }; \
        struct /* for Compare instrs: CMP, CMP4, TBIT, TNAT */ {\
            UCHAR               cmpCrel:4; \
            UCHAR               cmpCtype:3; \
        }; \
        struct /* for FP instrs: FADD, FMA, FCMP .. */ { \
            UCHAR               fcmpCrel:4; \
            UCHAR               fcmpCtype:1; \
            UCHAR               fpSf:2; \
        }; \
        struct /* for Memory instrs: LDn, LDFm, STn .. */ {\
            UCHAR               dataHint:2; \
            UCHAR               memType:4; \
        }; \
    }; \
    struct { \
        PTUPLE                  qualifierPredicate; \
        UCHAR                   endOfGroup:1; \
        UCHAR                   beginOfBundle:1;  \
        UCHAR                   bundleTemplate:4; \
        UCHAR                   endOfBundle:1;  \
        UCHAR                   descrAttributes; \
    }
#elif defined(TALPHA)
#define INSTRCOMMON_MD_FIELDS   ;\
    struct { \
        UCHAR                   endOfCycle:1; \
        UCHAR                   trapShadowConsumer:1; \
        UCHAR                   NotUsed:6; \
    }
#elif (defined(TMIPS) && !defined(TM16)) || (defined(TSH))
#define INSTRCOMMON_MD_FIELDS   ;\
    struct { \
        UCHAR                   noPrototypeForArg:1; \
        UCHAR                   NotUsed:7; \
    }
#else
#define INSTRCOMMON_MD_FIELDS
#endif

#if defined(CC_PROFILE_FEEDBACK) || defined(CC_P7_SPE)

#define POGO_INSTRCOMMON PPROBEINFO probeInfo;
#else
#define POGO_INSTRCOMMON
#endif

#if defined(CC_WVMOPTIL)
#define INSTRCOMMON_OPTIL_FIELDS\
    REGNUM                      tmpPhysReg;
#else
#define INSTRCOMMON_OPTIL_FIELDS
#endif

#define INSTRCOMMON\
    CODECOMMON;\
    POGO_INSTRCOMMON\
    union {\
        PSYM                    hashSym;\
        PSYM                    outArgSym;\
        PBLOCK                  instrBlock;\
        EHSTATE                 ehstate;\
        INSTRCOMMON_OPTIL_FIELDS\
        INSTRCOMMON_DLP_FIELDS\
        INSTRCOMMON_GC_FIELDS\
    };\
    PTUPLE                      src;\
    PTUPLE                      dst\
    INSTRCOMMON_MD_FIELDS

DECLARE_TUPLE(INSTRCOMMON, INSTR)
DECLARE_TUPLEEND

// Instr: Op - operation, unary, binary, or n-ary

DECLARE_TUPLE(OP, INSTR)
#if defined(CC_GOPTCMP)
    CONDCODE                    opCondCode;
#endif
DECLARE_TUPLEEND

// Instr: MbOp - multi-byte operation, unary, binary, or n-ary

DECLARE_TUPLE(MBOP, INSTR)
DECLARE_TUPLEEND

// Instr: Call

DECLARE_TUPLE(CALL, INSTR)
    union
    {
#if defined(TOMNI)
        PCALLDESCR              callDescriptor;
#endif
        ULONG                   numArgBytes;
    };
#if defined(CC_GC) || defined(CC_COMIMPORT) || defined(CC_WVM)
    union
    {
        PCALLDESCR              callDescriptor; // set by lower
        PSYMBOL                 symToken;       // set by reader, used by lower
    };
#endif
#ifdef CC_INTERPROC
    PCALLGRAPHCALLEE            callSiteInfo;
#endif
#if defined(T386)
    USHORT                      numFPRegsPopped;
#endif
    CALLCONV                    callConv;

    UCHAR                       hasMbArg      : 1;

#if defined(CC_WVM)
    UCHAR                       iscorvcall    : 1;
    UCHAR                       iscornew      : 1;
#else
    UCHAR                       unused2       : 2;
#endif

    UCHAR                       isEHcall      : 1;

#if defined(TP7)
    UCHAR                       isSetjmpCall  : 1;
    UCHAR                       unused        : 1;
#elif defined(T386)
    UCHAR                       hasRegArgs    : 1;
    UCHAR                       unused        : 1;
#elif defined(TOMNI)
    UCHAR                       iscomvcall    : 1;
    UCHAR                       isvcall       : 1;
#else
    UCHAR                       unused        : 2;
#endif

#if defined(CC_WVMOPTIL)
    UCHAR                       isHoistedCall : 1;
#else
    UCHAR                       unused3       : 1;
#endif

#ifdef CC_CNC
    UCHAR                       hasThis       : 1;
#else
    UCHAR                       unused4       : 1;
#endif

#if defined(HIA64)
    // NOTICE: this is just wasted space to make sizeof(intrinsic) == sizeof(call)
    PCALLGRAPHCALLEE            placeHolder;
#endif
DECLARE_TUPLEEND

// Instr: Return

DECLARE_TUPLE(RETURN, INSTR)
DECLARE_TUPLEEND

// Instr: Intrinsic

DECLARE_TUPLE(INTRINSIC, INSTR)
    INTRINNUM                   intrinNum;
    union {
        struct {
        short blkSize; // Used to store the size of a block mov or init.
        short dontLengthen; // Used to deal with mb args of size 3.
        };
#if defined(CC_WVM) || defined(TP7) || defined(TALPHA) || defined(TPPCWIN) || defined(TRISC)
        struct tagSEHINFO *SEHInfo; // pointer to SEH info for SEH intrinsics
#endif
    };
#if defined(CC_GC) || defined(CC_COMIMPORT) || defined(CC_WVM)
    PSYMBOL                     symCall; // WVM: set by reader, used by lower
#endif
#ifdef CC_INTERPROC
// NOTICE: this is just wasted space to make sizeof(intrinsic) == sizeof(call)
    PCALLGRAPHCALLEE            placeHolder;
#endif
DECLARE_TUPLEEND

// Instr: Question

DECLARE_TUPLE(QUESTION, INSTR)
    CONDCODE                    questionCondCode;
DECLARE_TUPLEEND

// Instr: Branch

DECLARE_TUPLE(BRANCH, INSTR)
    PTUPLE                      condSetterList;
DECLARE_TUPLEEND

// Instr: Switch

DECLARE_TUPLE(SWITCH, INSTR)
    PTUPLE                      defaultLabel;
    PTUPLE                      caseList;
    PTUPLE                      twoLevLabel;
    BOOL                        isSubSwitch:1;
    BOOL                        noDefault:1;
DECLARE_TUPLEEND

// Instr: Except - exception pseudo instruction


DECLARE_TUPLE(EXCEPT, INSTR)
    union {
        PSEHINFO                    sehInfo;
        PEXCEPTINFO                 ehInfo;
        int                         scopeIndex;
        PTUPLE                      noEvalList;
#if defined(CC_GC) || defined(CC_COMIMPORT)
        PSYM                        symIV;
#endif
    };
DECLARE_TUPLEEND


// Instr: TupList - list of (out-of-line) instruction tuples

DECLARE_TUPLE(TUPLIST, INSTR)
    PTUPLE                      tupList;
DECLARE_TUPLEEND

// Code: Pcode

#ifdef CC_PCODE

DECLARE_TUPLE(PCODE_, CODE)
    PCODEINFO                   pcodeInfo;
DECLARE_TUPLEEND

#endif

// Code: Block
DECLARE_TUPLE(BLOCK, CODE)
    PBLOCK                      block;
#if defined(CC_GC) || defined(CC_COMIMPORT)
    PBV                         blockLiveRefs;
#endif
#ifdef CC_PROFILE_FEEDBACK
    USHORT                      blockInstrs;
#endif
DECLARE_TUPLEEND

// P-code needs to be able to map native labels to p-code label refs,
// so the sequence field is overloaded.  See PcodeFixupCodegen().
// WVM also needs to map labels, so it also uses this field.

// Code: Label

DECLARE_TUPLE(LABEL, CODE)
    PBLOCK                      labelBlk;
    PSYMBOL                     labelSym;
    PTUPLE                      branchList;
#if defined(CC_PROFILE_FEEDBACK) || defined(CC_P7_SPE)
    PPROBELABELINFO             probeLabelInfo;
#endif
    union
    {
        unsigned                sequence;
        PTUPLE                  labelRef;
    };
DECLARE_TUPLEEND

// Code: Entry

DECLARE_TUPLE(ENTRY, CODE)
    PFUNC                       entryFunc;
    PTUPLE                      entryParamList;
#if defined(TOMNI) || defined(CC_WVM)
    PCALLDESCR                  callDescriptor;
#endif
DECLARE_TUPLEEND

// Code: Exit

DECLARE_TUPLE(EXIT, CODE)
    PFUNC                       exitFunc;
DECLARE_TUPLEEND

// Code: Pragma

DECLARE_TUPLE(PRAGMA, CODE)
    union
    {
        struct                            // used by OPBLKSTART and OPBLKEND
        {
            SYMLIST             *symList;
            LOCBLK              *locblk;
        };
        int                     inctl;    // inline control word
        int                     alignCode; // OPALIGNCODE value
        SYMBOL                  *userLabel; // OPUSERLABEL
        PSYMBOL                 segment;  // OPSEGMENT segment symbol
        unsigned                cycles;   // OPCYCLECOUNT
    } pragScratch;
DECLARE_TUPLEEND

// Code: Split Point

DECLARE_TUPLE(SPLITPOINT, CODE)
    PBV                        splitBv;
    GLOBLIST *                 splitList;
    unsigned int               splitMask;
DECLARE_TUPLEEND

// Common base structure for all list tuples

#define LISTCOMMON\
    BASECOMMON

DECLARE_TUPLE(LISTCOMMON, LIST)
DECLARE_TUPLEEND

// Special list tuples

DECLARE_TUPLE(CASELIST, LIST)
    long                        caseLower;
    long                        caseUpper;
    PTUPLE                      caseLabel;
    PTUPLE                      caseSwitch;
#if defined(CC_PROFILE_FEEDBACK) || defined(CC_P7_SPE)
    PPROBECASEINFO              probeCaseInfo;
#endif
    CGIF_TUPID
DECLARE_TUPLEEND

DECLARE_TUPLE(BRANCHLIST, LIST)
    union
    {
    PTUPLE                      branchFrom;
    PBRANCHTUPLE                Branch;
    PSWITCHTUPLE                Switch;
    PCASELISTTUPLE              CaseList;
    };
    ULONG                       passCount;  // could be a USHORT
DECLARE_TUPLEEND

DECLARE_TUPLE(CONDSETTERLIST, LIST)
    PTUPLE                      condSetter;
DECLARE_TUPLEEND

// Leaf tuples

struct tagLEAFTUPLE
{
    union
    {
    LEAFCOMMONTUPLE             Common;
    REGTUPLE                    Reg;
    SYMTUPLE                    Sym;
    INDIRTUPLE                  Indir;
    DATAADDRTUPLE               DataAddr;
    CODEADDRTUPLE               CodeAddr;
    EATUPLE                     Ea;
    INTCONSTTUPLE               IntConst;
    SYMCONSTTUPLE               SymConst;
    FLOATCONSTTUPLE             FloatConst;
    SYMREFTUPLE                 SymRef;
    MEMREFTUPLE                 MemRef;
    REGSETTUPLE                 RegSet;
    SYMSETTUPLE                 SymSet;
#if defined(CC_TEXTCONST)
    TEXTCONSTTUPLE              TextConst;
#endif
    };
};

struct tagINSTRTUPLE
{
    union
    {
    INSTRCOMMONTUPLE            Common;
    OPTUPLE                     Op;
    MBOPTUPLE                   MbOp;
    CALLTUPLE                   Call;
    RETURNTUPLE                 Return;
    INTRINSICTUPLE              Intrinsic;
    QUESTIONTUPLE               Question;
    BRANCHTUPLE                 Branch;
    SWITCHTUPLE                 Switch;
    EXCEPTTUPLE                 Except;
    TUPLISTTUPLE                TupList;
    };
};

// Code tuples

struct tagCODETUPLE
{
    union
    {
    CODECOMMONTUPLE             Common;
    INSTRTUPLE                  Instr;
    BLOCKTUPLE                  Block;
    LABELTUPLE                  Label;
    ENTRYTUPLE                  Entry;
    EXITTUPLE                   Exit;
    PRAGMATUPLE                 Pragma;
    SPLITPOINTTUPLE             SplitPoint;
#ifdef CC_PCODE
    PCODE_TUPLE                 Pcode;
#endif
    };
};

// List tuples

struct tagLISTTUPLE
{
    union
    {
    LISTCOMMONTUPLE             Common;
    CASELISTTUPLE               CaseList;
    BRANCHLISTTUPLE             BranchList;
    CONDSETTERLISTTUPLE         CondSetterList;
    };
};

// Generic tuple

struct tagTUPLE
{
    union
    {
    LEAFANDCODECOMMONTUPLE      Common;
    INSTRTUPLE                  Instr;
    LEAFTUPLE                   Leaf;
    CODETUPLE                   Code;
    LISTTUPLE                   List;
    };
};

// Tuple Condition Code Enumeration

enum
{
#define CCDAT(name,sname,usname,revname,invname,machcode)\
    CC_ ## name,
#include "ccdat.h"
#undef CCDAT
    CC_NUMBEROFCCS
};
#if (CC_NUMBEROFCCS > (1 << CONDCODE_BITSIZE))
#error Number of tuple condition codes exceeds capacity, modify condition code bitfields
#endif

#if !defined(T386) || defined(NODEBUG)
#define InlineAsmBranch (0)
#endif

// Tuple Condition Code Tables and Conversion Macros.

extern const CONDCODE TupCCSigned[];
extern const CONDCODE TupCCUnsigned[];
extern const CONDCODE TupCCInverse[];
extern const CONDCODE TupCCReverse[];
extern const int      TupCCEncode[];
extern const ULONG    TupCCChain[];
extern const ULONG    TupCCExclude[];

#define CC_SIGNED(cc)   (TupCCSigned[cc])
#define CC_UNSIGNED(cc) (TupCCUnsigned[cc])
#define CC_INVERSE(cc)  (TupCCInverse[cc])
#define CC_REVERSE(cc)  (TupCCReverse[cc])
#define CC_ENCODE(cc)   (TupCCEncode[cc])
#define CC_ISVALID(cc)  (CC_ILLEGAL < (cc) && (cc) < CC_NUMBEROFCCS)

#define CCMASK(cc) (1U << (cc))

// Define the sets of CC's that "chain" to other CC's (ie, the first CC is
// a subset of the second CC)

#define CC1_CHAINS_TO_CC2(cc1, cc2) (TupCCChain[cc1] & CCMASK(cc2))

#define ILLEGAL_CHAIN (0)
#define EQ_CHAIN      (CCMASK(CC_EQ) | CCMASK(CC_GE) | CCMASK(CC_LE) | CCMASK(CC_UGE) | CCMASK(CC_ULE))
#define NE_CHAIN      (CCMASK(CC_NE))
#define LT_CHAIN      (CCMASK(CC_LT) | CCMASK(CC_LE) | CCMASK(CC_NE))
#define GT_CHAIN      (CCMASK(CC_GT) | CCMASK(CC_GE) | CCMASK(CC_NE))
#define LE_CHAIN      (CCMASK(CC_LE))
#define GE_CHAIN      (CCMASK(CC_GE))
#define ULT_CHAIN     (CCMASK(CC_ULT) | CCMASK(CC_ULE) | CCMASK(CC_NE))
#define UGT_CHAIN     (CCMASK(CC_UGT) | CCMASK(CC_UGE) | CCMASK(CC_NE))
#define ULE_CHAIN     (CCMASK(CC_ULE))
#define UGE_CHAIN     (CCMASK(CC_UGE))
#define O_CHAIN       (CCMASK(CC_O))
#define NO_CHAIN      (CCMASK(CC_NO))
#define S_CHAIN       (CCMASK(CC_S))
#define NS_CHAIN      (CCMASK(CC_NS))
#define P_CHAIN       (CCMASK(CC_P))
#define NP_CHAIN      (CCMASK(CC_NP))
#if defined(TC_CC_LOWBIT)
#define LBC_CHAIN     (CCMASK(CC_LBC))
#define LBS_CHAIN     (CCMASK(CC_LBS) | CCMASK(CC_NE))
#endif

// Define the sets of CC's that "exclude" other CC's (ie, the two CC's
// are mutually exclusive of each other)

#define CC1_EXCLUDES_CC2(cc1, cc2)  (TupCCExclude[cc1] & CCMASK(cc2))

#define ILLEGAL_EXCL  (0)
#define EQ_EXCL       (CCMASK(CC_NE) | CCMASK(CC_GT) | CCMASK(CC_LT) | CCMASK(CC_UGT) | CCMASK(CC_ULT))
#define NE_EXCL       (CCMASK(CC_EQ))
#define LT_EXCL       (CCMASK(CC_GE) | CCMASK(CC_GT) | CCMASK(CC_EQ))
#define GT_EXCL       (CCMASK(CC_LE) | CCMASK(CC_LT) | CCMASK(CC_EQ))
#define LE_EXCL       (CCMASK(CC_GT))
#define GE_EXCL       (CCMASK(CC_LT))
#define ULT_EXCL      (CCMASK(CC_UGE) | CCMASK(CC_UGT) | CCMASK(CC_EQ))
#define UGT_EXCL      (CCMASK(CC_ULE) | CCMASK(CC_ULT) | CCMASK(CC_EQ))
#define ULE_EXCL      (CCMASK(CC_UGT))
#define UGE_EXCL      (CCMASK(CC_ULT))
#define O_EXCL        (CCMASK(CC_NO))
#define NO_EXCL       (CCMASK(CC_O))
#define S_EXCL        (CCMASK(CC_NS))
#define NS_EXCL       (CCMASK(CC_S))
#define P_EXCL        (CCMASK(CC_NP))
#define NP_EXCL       (CCMASK(CC_P))
#if defined(TC_CC_LOWBIT)
#define LBC_EXCL      (CCMASK(CC_LBS))
#define LBS_EXCL      (CCMASK(CC_LBC) | CCMASK(CC_EQ))
#endif


// Tuple kind enumeration. Used as tag in token structure for tuple
// classification, memory manager support, and debug field access routines.

enum
{
#define TUPKIND(name, ucname, lcname, base)\
    TK_ ## ucname ## TUPLE,
#include "tupkind.h"
   TK_NUMBEROFKINDS,
   TK_FREED = TK_NUMBEROFKINDS
#undef TUPKIND
};
#if (TK_NUMBEROFKINDS > 32)
#error Number of tuple kinds exceeds 32, modify field accessor macros
#endif

// Tuple kind bits. Used for checking tuple classification.

enum
{

#define TK_GETBIT(kind) (1 << (kind))

#define TUPKIND(name, ucname, lcname, base)\
    TK_ ## ucname ## BIT = TK_GETBIT(TK_ ## ucname ## TUPLE),
#include "tupkind.h"
#undef TUPKIND

    TK_CONSTBIT          = (TK_INTCONSTBIT |
                            TK_SYMCONSTBIT |
                            TK_FLOATCONSTBIT),
    TK_ADDRBIT           = (TK_DATAADDRBIT |
                            TK_CODEADDRBIT),
    TK_REGORSYMBIT       = (TK_REGBIT |
                            TK_SYMBIT),
    TK_SYMORDATAADDRBIT  = (TK_SYMBIT |
                            TK_DATAADDRBIT),
    TK_SYMREFBIT         = (TK_SYMBIT |
                            TK_REGBIT |
                            TK_ADDRBIT),
    TK_DATASYMREFBIT     = (TK_SYMBIT |
                            TK_REGBIT |
                            TK_DATAADDRBIT),
    TK_LABREFBIT         = (TK_CODEADDRBIT),
    TK_MEMREFBIT         = (TK_EABIT |
                            TK_INDIRBIT),
    TK_SYMORMEMREFBIT    = (TK_SYMREFBIT |
                            TK_MEMREFBIT),
    TK_BRANCHTARGBIT     = (TK_SYMREFBIT | TK_MEMREFBIT | TK_LABELBIT),
    TK_GLOBALBIT         = (TK_SYMBIT |
                            TK_ADDRBIT),
    TK_LOCALBIT          = (TK_SYMBIT |
                            TK_ADDRBIT),
    TK_LEAFBIT           = (TK_SYMREFBIT |
                            TK_MEMREFBIT |
                            TK_REGSETBIT |
                            TK_SYMSETBIT |
#if defined(CC_TEXTCONST)
                            TK_TEXTCONSTBIT |
#endif
                            TK_CONSTBIT),
    TK_UNARYBIT          = (TK_OPBIT),
    TK_BINARYBIT         = (TK_OPBIT),

#ifdef CC_SSA
    TK_NARRYBIT          = (TK_OPBIT),
#endif

    TK_NONMBINSTRBIT     = (TK_OPBIT |
                            TK_UNARYBIT |
                            TK_BINARYBIT |
                            TK_QUESTIONBIT |
                            TK_CALLBIT |
                            TK_RETURNBIT |
                            TK_BRANCHBIT |
                            TK_INTRINSICBIT |
                            TK_SWITCHBIT |
                            TK_EXCEPTBIT |
                            TK_TUPLISTBIT),
    TK_MBUNARYBIT        = (TK_MBOPBIT),
    TK_MBINSTRBIT        = (TK_MBOPBIT |
                            TK_MBUNARYBIT),
    TK_INSTRBIT          = (TK_NONMBINSTRBIT |
                            TK_MBINSTRBIT),
    TK_NONBRANCHINSTRBIT = (TK_INSTRBIT & (~TK_BRANCHBIT)),
    TK_CODEBIT           = (TK_INSTRBIT |
                            TK_PRAGMABIT |
                            TK_SPLITPOINTBIT |
                            TK_ENTRYBIT |
                            TK_EXITBIT |
                            TK_BLOCKBIT |
                            TK_CASELISTBIT |
#ifdef CC_PCODE
                            TK_PCODE_BIT |
#endif
                            TK_LABELBIT),
    TK_TRANSFERBIT       = (TK_BRANCHBIT |
                            TK_SWITCHBIT),
    TK_LISTBIT           = (TK_BRANCHLISTBIT |
                            TK_CASELISTBIT |
                            TK_CONDSETTERLISTBIT),
    TK_ANYBIT            = (TK_LEAFBIT |
                            TK_CODEBIT |
                            TK_LISTBIT)
};

// Tuple kind tables.

extern const int   TupKindSize[];
#ifndef NODEBUG
extern const char * const TupKindName[];
extern const char * const TupFieldName[];
extern const long  TupFieldAccessToken[];
extern const ULONG TupOpcodeKinds[];
#endif

// Tuple kind classifications

#define TK_SIZEOF(k)             (TupKindSize[k])
#define TK_ISVALID(k)            (TK_ILLEGALTUPLE < (k) &&\
                                     (k) < TK_NUMBEROFKINDS)
#define TK_ISLEAF(k)             (TK_LEAFBIT & TK_GETBIT(k))
#define TK_ISREG(k)              ((k) == TK_REGTUPLE)
#define TK_ISSYM(k)              ((k) == TK_SYMTUPLE)
#define TK_ISREGORSYM(k)         (TK_REGORSYMBIT & TK_GETBIT(k))
#define TK_ISSYMORDATAADDR(k)    (TK_SYMORDATAADDRBIT & TK_GETBIT(k))
#define TK_ISSYMORMEMREF(k)      (TK_SYMORMEMREFBIT & TK_GETBIT(k))
#define TK_ISADDR(k)             (TK_ADDRBIT & TK_GETBIT(k))
#define TK_ISCODEADDR(k)         ((k) == TK_CODEADDRTUPLE)
#define TK_ISDATAADDR(k)         ((k) == TK_DATAADDRTUPLE)
#define TK_ISSYMREF(k)           (TK_SYMREFBIT & TK_GETBIT(k))
#define TK_ISDATASYMREF(k)       (TK_DATASYMREFBIT & TK_GETBIT(k))
#define TK_ISBRANCHTARGET(k)     (TK_BRANCHTARGBIT & TK_GETBIT(k))
#define TK_ISEA(k)               ((k) == TK_EATUPLE)
#define TK_ISINDIR(k)            ((k) == TK_INDIRTUPLE)
#define TK_ISMEMREF(k)           (TK_MEMREFBIT & TK_GETBIT(k))
#define TK_ISREGSET(k)           ((k) == TK_REGSETTUPLE)
#define TK_ISSYMSET(k)           ((k) == TK_SYMSETTUPLE)
#define TK_ISOP(k)               ((k) == TK_OPTUPLE)
#define TK_ISMBOP(k)             ((k) == TK_MBOPTUPLE)
#define TK_ISINSTR(k)            (TK_INSTRBIT & TK_GETBIT(k))
#define TK_ISMBINSTR(k)          (TK_MBINSTRBIT & TK_GETBIT(k))
#define TK_ISCODE(k)             (TK_CODEBIT & TK_GETBIT(k))
#define TK_ISLIST(k)             (TK_LISTBIT & TK_GETBIT(k))
#define TK_ISCASELIST(k)         ((k) == TK_CASELISTTUPLE)
#define TK_ISCONDSETTERLIST(k)   ((k) == TK_CONDSETTERLISTTUPLE)
#define TK_ISQUESTION(k)         ((k) == TK_QUESTIONTUPLE)
#define TK_ISBRANCH(k)           ((k) == TK_BRANCHTUPLE)
#define TK_ISTRANSFER(k)         (TK_TRANSFERBIT & TK_GETBIT(k))
#define TK_ISBLOCK(k)            ((k) == TK_BLOCKTUPLE)
#define TK_ISSWITCH(k)           ((k) == TK_SWITCHTUPLE)
#define TK_ISLABEL(k)            ((k) == TK_LABELTUPLE)
#define TK_ISINTCONST(k)         ((k) == TK_INTCONSTTUPLE)
#define TK_ISSYMCONST(k)         ((k) == TK_SYMCONSTTUPLE)
#define TK_ISFLOATCONST(k)       ((k) == TK_FLOATCONSTTUPLE)
#define TK_ISCONST(k)            (TK_CONSTBIT & TK_GETBIT(k))
#define TK_ISCALL(k)             ((k) == TK_CALLTUPLE)
#define TK_ISINTRINSIC(k)        ((k) == TK_INTRINSICTUPLE)
#define TK_ISEXCEPT(k)           ((k) == TK_EXCEPTTUPLE)
#define TK_ISRETURN(k)           ((k) == TK_RETURNTUPLE)
#define TK_ISENTRY(k)            ((k) == TK_ENTRYTUPLE)
#define TK_ISEXIT(k)             ((k) == TK_EXITTUPLE)
#define TK_ISPRAGMA(k)           ((k) == TK_PRAGMATUPLE)
#define TK_ISSPLITPOINT(k)       ((k) == TK_SPLITPOINTTUPLE)
#define TK_ISTUPLIST(k)          ((k) == TK_TUPLISTTUPLE)
#ifdef CC_PCODE
#define TK_ISPCODE(k)            ((k) == TK_PCODE_TUPLE)
#endif
#if defined(CC_TEXTCONST)
#define TK_ISTEXTCONST(k)        ((k) == TK_TEXTCONSTTUPLE)
#else
#define TK_ISTEXTCONST(k)        (FALSE)
#endif

#define CASE_SYMTUPLE            case TK_SYMTUPLE
#define CASE_REGTUPLE            case TK_REGTUPLE
#define CASE_DATAADDRTUPLE       case TK_DATAADDRTUPLE
#define CASE_CODEADDRTUPLE       case TK_CODEADDRTUPLE
#define CASE_EATUPLE             case TK_EATUPLE
#define CASE_INDIRTUPLE          case TK_INDIRTUPLE
#define CASE_INTCONSTTUPLE       case TK_INTCONSTTUPLE
#define CASE_SYMCONSTTUPLE       case TK_SYMCONSTTUPLE
#define CASE_REGSETTUPLE         case TK_REGSETTUPLE
#define CASE_SYMSETTUPLE         case TK_SYMSETTUPLE
#define CASE_FLOATCONSTTUPLE     case TK_FLOATCONSTTUPLE
#define CASE_OPTUPLE             case TK_OPTUPLE
#define CASE_MBOPTUPLE           case TK_MBOPTUPLE
#define CASE_CALLTUPLE           case TK_CALLTUPLE
#define CASE_RETURNTUPLE         case TK_RETURNTUPLE
#define CASE_QUESTIONTUPLE       case TK_QUESTIONTUPLE
#define CASE_BRANCHTUPLE         case TK_BRANCHTUPLE
#define CASE_INTRINSICTUPLE      case TK_INTRINSICTUPLE
#define CASE_SWITCHTUPLE         case TK_SWITCHTUPLE
#define CASE_EXCEPTTUPLE         case TK_EXCEPTTUPLE
#define CASE_TUPLISTTUPLE        case TK_TUPLISTTUPLE
#define CASE_PRAGMATUPLE         case TK_PRAGMATUPLE
#define CASE_SPLITPOINTTUPLE     case TK_SPLITPOINTTUPLE
#define CASE_ENTRYTUPLE          case TK_ENTRYTUPLE
#define CASE_EXITTUPLE           case TK_EXITTUPLE
#define CASE_BLOCKTUPLE          case TK_BLOCKTUPLE
#define CASE_LABELTUPLE          case TK_LABELTUPLE
#define CASE_BRANCHLISTTUPLE     case TK_BRANCHLISTTUPLE
#define CASE_CASELISTTUPLE       case TK_CASELISTTUPLE
#define CASE_CONDSETTERLISTTUPLE case TK_CONDSETTERLISTTUPLE
#if defined(CC_PCODE)
#define CASE_PCODE_TUPLE         case TK_PCODE_TUPLE
#endif
#if defined(CC_TEXTCONST)
#define CASE_TEXTCONSTTUPLE      case TK_TEXTCONSTTUPLE
#endif

#define CASE_ADDRTUPLE\
    CASE_CODEADDRTUPLE :\
    CASE_DATAADDRTUPLE

#define CASE_SYMREFTUPLE\
    CASE_REGTUPLE :\
    CASE_SYMTUPLE :\
    CASE_ADDRTUPLE

#define CASE_CONSTTUPLE\
    CASE_INTCONSTTUPLE :\
    CASE_SYMCONSTTUPLE :\
    CASE_FLOATCONSTTUPLE

#define CASE_MEMREFTUPLE\
    CASE_EATUPLE :\
    CASE_INDIRTUPLE

#define CASE_LEAFTUPLE\
    CASE_SYMREFTUPLE :\
    CASE_MEMREFTUPLE :\
    CASE_CONSTTUPLE :\
    CASE_REGSETTUPLE :\
    CASE_SYMSETTUPLE

#define CASE_INSTRTUPLE\
    CASE_OPTUPLE :\
    CASE_MBOPTUPLE :\
    CASE_CALLTUPLE :\
    CASE_RETURNTUPLE :\
    CASE_QUESTIONTUPLE :\
    CASE_BRANCHTUPLE :\
    CASE_INTRINSICTUPLE :\
    CASE_SWITCHTUPLE :\
    CASE_EXCEPTTUPLE :\
    CASE_TUPLISTTUPLE

#define CASE_NONINSTRTUPLE\
    CASE_BLOCKTUPLE :\
    CASE_LABELTUPLE :\
    CASE_ENTRYTUPLE :\
    CASE_EXITTUPLE :\
    CASE_PRAGMATUPLE :\
    CASE_SPLITPOINTTUPLE

#define CASE_CODETUPLE\
    CASE_INSTRTUPLE :\
    CASE_NONINSTRTUPLE

#define CASE_LISTTUPLE\
    CASE_BRANCHLISTTUPLE :\
    CASE_CASELISTTUPLE :\
    CASE_CONDSETTERLISTTUPLE

// General purpose query macros for tuples

#ifndef NODEBUG
// TK_FREED is only set in debug builds (see TupFree)
#define TU_ISFREED(t)         ((t)->Common.kind == TK_FREED)
#endif

#define TU_ISLEAF(t)          (TK_ISLEAF(TU_KIND(t)))
#define TU_ISSYM(t)           (TK_ISSYM(TU_KIND(t)))
#define TU_ISSYMORDATAADDR(t) (TK_ISSYMORDATAADDR(TU_KIND(t)))
#define TU_ISSYMORMEMREF(t)   (TK_ISSYMORMEMREF(TU_KIND(t)))
#define TU_ISREG(t)           (TK_ISREG(TU_KIND(t)))
#define TU_ISREGORSYM(t)      (TK_ISREGORSYM(TU_KIND(t)))
#define TU_ISADDR(t)          (TK_ISADDR(TU_KIND(t)))
#define TU_ISDATAADDR(t)      (TK_ISDATAADDR(TU_KIND(t)))
#define TU_ISCODEADDR(t)      (TK_ISCODEADDR(TU_KIND(t)))
#define TU_ISINDIR(t)         (TK_ISINDIR(TU_KIND(t)))
#define TU_ISEA(t)            (TK_ISEA(TU_KIND(t)))
#define TU_ISINTCONST(t)      (TK_ISINTCONST(TU_KIND(t)))
#define TU_ISSYMCONST(t)      (TK_ISSYMCONST(TU_KIND(t)))
#define TU_ISFLOATCONST(t)    (TK_ISFLOATCONST(TU_KIND(t)))
#define TU_ISCONST(t)         (TK_ISCONST(TU_KIND(t)))
#define TU_ISSYMSET(t)        (TK_ISSYMSET(TU_KIND(t)))
#define TU_ISREGSET(t)        (TK_ISREGSET(TU_KIND(t)))

#define TU_ISSYMREF(t)        (TK_ISSYMREF(TU_KIND(t)))
#define TU_ISDATASYMREF(t)    (TK_ISDATASYMREF(TU_KIND(t)))
#define TU_ISMEMREF(t)        (TK_ISMEMREF(TU_KIND(t)))
#define TU_ISBRANCHTARGET(t)  (TK_ISBRANCHTARGET(TU_KIND(t)))

#define TU_ISTMP(t)           (TU_ISREGORSYM(t) && SY_ISTMP(TU_SYM(t)))
#if defined(CC_COMIMPORT)
#define TU_ISVMJITTMP(t)      (TU_ISREGORSYM(t) && SY_VMJITTMP(TU_SYM(t)))
#endif
#define TU_ISFETMP(t)         (TU_ISREGORSYM(t) && SY_ISFETMP(TU_SYM(t)))
#define TU_ISSDSU(t)          (TU_ISREGORSYM(t) && SY_ISSDSUVAR(TU_SYM(t)))
#define TU_ISHASHSYM(t)       (TU_ISREGORSYM(t) && SY_ISHASHVAR(TU_SYM(t)))
#define TU_ISTMPREG(t)        (TU_ISREG(t) && SY_ISTMPREG(TU_SYM(t)))
#ifdef CC_BLT
#define TU_ISBLT(t)           (TU_ISREG(t) && SY_ISBLT(TU_SYM(t)))
#endif
#define TU_ISTMPVAR(t)        (TU_ISREGORSYM(t) && SY_ISTMPVAR(TU_SYM(t)))
#define TU_ISPHYSREGTMPREG(t) (TU_ISTMPREG(t) && SY_ISPHYSREG(TU_REG(t)))
#define TU_ISTMPINDIR(t)      (TU_ISINDIR(t) &&\
                                 (!TU_BASE(t) || TU_ISTMPREG(TU_BASE(t))) &&\
                                 (!TU_INDEX(t) || TU_ISTMPREG(TU_INDEX(t))))
#define TU_ISSDSUINDIR(t)     (TU_ISINDIR(t) &&\
                                 (!TU_BASE(t) || TU_ISSDSU(TU_BASE(t))) &&\
                                 (!TU_INDEX(t) || TU_ISSDSU(TU_INDEX(t))))
#define TU_ISTMPMEMREF(t)     (TU_ISMEMREF(t) &&\
                                 (!TU_BASE(t) || (!TU_ISREG(TU_BASE(t)) &&\
                                    TU_ISTMPREG(TU_BASE(t)))) &&\
                                 (!TU_INDEX(t) || TU_ISTMPREG(TU_INDEX(t))) &&\
                                 TU_BASE(t) != TU_INDEX(t) /* != NULL */)
#define TU_ISSDSUMEMREF(t)    (TU_ISMEMREF(t) &&\
                                 (!TU_BASE(t) || TU_ISSDSU(TU_BASE(t))) &&\
                                 (!TU_INDEX(t) || TU_ISSDSU(TU_INDEX(t))) &&\
                                 TU_BASE(t) != TU_INDEX(t) /* != NULL */)

#define TU_ISCODE(t)          (TK_ISCODE(TU_KIND(t)))
#define TU_ISOP(t)            (TK_ISOP(TU_KIND(t)))
#define TU_ISMBOP(t)          (TK_ISMBOP(TU_KIND(t)))
#define TU_ISLOWERED(t)       (OP_ISVALIDMD(TU_OPCODE(t)))
#if defined(CC_WVM)
#define TU_ISLOWEREDWVM(t)    (OP_ISVALIDWVM(TU_OPCODE(t)))
#endif
#define TU_ISMBINSTR(t)       (TK_ISMBINSTR(TU_KIND(t)))

#define TU_ISBLOCK(t)         (TK_ISBLOCK(TU_KIND(t)))
#define TU_ISLABEL(t)         (TK_ISLABEL(TU_KIND(t)))
#define TU_ISQUESTION(t)      (TK_ISQUESTION(TU_KIND(t)))
#define TU_ISBRANCH(t)        (TK_ISBRANCH(TU_KIND(t)))
#define TU_ISTRANSFER(t)      (TK_ISTRANSFER(TU_KIND(t)))
#define TU_ISSWITCH(t)        (TK_ISSWITCH(TU_KIND(t)))
#define TU_ISCALL(t)          (TK_ISCALL(TU_KIND(t)))
#define TU_ISINTRINSIC(t)     (TK_ISINTRINSIC(TU_KIND(t)))
#define TU_ISEXCEPT(t)        (TK_ISEXCEPT(TU_KIND(t)))
#ifdef CC_PROFILE_FEEDBACK
#define TU_ISPROBE(t)         (TU_ISEXCEPT(t) && (TU_OPCODE(t) == OPPROBE))
#endif
#define TU_ISRETURN(t)        (TK_ISRETURN(TU_KIND(t)))
#define TU_ISENTRY(t)         (TK_ISENTRY(TU_KIND(t)))
#define TU_ISEXIT(t)          (TK_ISEXIT(TU_KIND(t)))
#define TU_ISPRAGMA(t)        (TK_ISPRAGMA(TU_KIND(t)))
#define TU_ISSPLIT(t)         (TK_ISSPLITPOINT(TU_KIND(t)))
#define TU_ISTUPLIST(t)       (TK_ISTUPLIST(TU_KIND(t)))
#define TU_ISASM(t)           (TU_ISTUPLIST(t) && (TU_OPCODE(t) == OPASM))
#ifdef CC_PCODE
#define TU_ISPCODE(t)         (TK_ISPCODE(TU_KIND(t)))
#endif
#define TU_ISTEXTCONST(t)     (TK_ISTEXTCONST(TU_KIND(t)))

#define TU_ISLIST(t)          (TK_ISLIST(TU_KIND(t)))
#define TU_ISCASELIST(t)      (TK_ISCASELIST(TU_KIND(t)))
#define TU_ISCONDSETTERLIST(t) (TK_ISCONDSETTERLIST(TU_KIND(t)))

#define TU_SIDEEFFECT(t)      (TupQuerySideEffect(t))

#define TU_ISARG(t)           ((TU_OPCODE(t) == OPARG)\
                                  || (TU_OPCODE(t) == OPMBARG))

#define TU_ISLOCAL(t)         ((TU_OPCODE(t) == OPLOCAL)\
                                  || (TU_OPCODE(t) == OPLOCALSCALED))

#define TU_CANENREG(t)        (TY_CANENREG(TU_TYPEINFO(t)))

#if defined(CC_GOPTCMP)
#define TU_OPHASCOND(t) (TU_OPCONDCODE(t) != CC_ILLEGAL)
#endif

#if defined(TARM)
// For ARM, condcodes are always valid, so we can test this the quick way.
#define TU_HASCOND(t) (TU_CONDCODE(t) != CC_ILLEGAL)
#elif defined(TTHUMB)
// thumb todo: define this way until ARM instructions are removed
//#define TU_HASCOND(t) ((TU_CONDCODE(t) != CC_ILLEGAL) || (TU_OPCODE(t) == BC))
#define TU_HASCOND(t) (TU_CONDCODE(t) != CC_ILLEGAL)
#endif

#if defined(MD_CONDBR_CHECK)
#define AND_NOT_MD_CONDBR(t) && !MD_CONDBR_CHECK(t)
#else
#define AND_NOT_MD_CONDBR(t)
#endif

#ifdef CC_WVM

#if !defined(CC_COMIMPORT)
#define TU_ISUNCOND(t)        (TU_CONDSETTERLIST(t) == NULL \
    && TU_OPCODE(t) != OPONERROR AND_NOT_MD_CONDBR(t) \
    && (!OP_ISVALIDWVM(TU_OPCODE(t)) || TU_OPCODE(t) == CEE_BR || TU_OPCODE(t) == CEE_LEAVE || TU_OPCODE(t) == CEE_LEAVE_S))
#else // !CC_COMIMPORT
#define TU_ISUNCOND(t)        (TU_CONDSETTERLIST(t) == NULL \
    && TU_OPCODE(t) != OPONERROR AND_NOT_MD_CONDBR(t) \
    && (!OP_ISVALIDWVM(TU_OPCODE(t)) || TU_OPCODE(t) == CEE_BR || TU_OPCODE(t) == CEE_LEAVE_S)) \
    && TU_OPCODE(t) != OPFINALLYCALL)
#endif // !CC_COMIMPORT

#elif !defined(CC_COMIMPORT)
#define TU_ISUNCOND(t)        (TU_CONDSETTERLIST(t) == NULL \
    && TU_OPCODE(t) != OPONERROR AND_NOT_MD_CONDBR(t))
#else
#define TU_ISUNCOND(t)        (TU_CONDSETTERLIST(t) == NULL \
    && TU_OPCODE(t) != OPONERROR AND_NOT_MD_CONDBR(t) \
                               && TU_OPCODE(t) != OPFINALLYCALL)
#endif
#define TU_ISCOND(t)          (!TU_ISUNCOND(t))

#define TU_ISUNCOND_BRANCH(t) (TU_ISBRANCH(t) && TU_ISUNCOND(t))
#define TU_ISCOND_BRANCH(t)   (TU_ISBRANCH(t) && TU_ISCOND(t))
#if defined(MD_CONDBR_CHECK)
#define TU_ISBRANCH_ON_CC(t)  (TU_ISBRANCH(t) && (TU_CONDSETTERLIST(t) != NULL || MD_CONDBR_CHECK(t)))
#else
#define TU_ISBRANCH_ON_CC(t)  (TU_ISBRANCH(t) && TU_CONDSETTERLIST(t) != NULL)
#endif
#if defined(CC_PREDICATION)
#define TU_ISPREDICATED(t)    TupIsPredicated(t)
#endif

// Tuple type query and edit macros

#define TU_ISINT(t)          (TY_ISINT(TU_TYPEINFO(t)))
#define TU_ISSIGNED(t)       (TY_ISSIGNED(TU_TYPEINFO(t)))
#define TU_ISUNSIGNED(t)     (TY_ISUNSIGNED(TU_TYPEINFO(t)))
#define TU_ISFLOAT(t)        (TY_ISFLOAT(TU_TYPEINFO(t)))
#define TU_ISSMALLMB(t)      (TY_ISSMALLMB(TU_TYPEINFO(t)))
#define TU_ISMULTIBYTE(t)    (TY_ISMULTIBYTE(TU_TYPEINFO(t)))
#define TU_ISPTR(t)          (TY_ISPTR(TU_TYPEINFO(t)))
#define TU_ISSTRUCT(t)       (TY_ISSTRUCT(TU_TYPEINFO(t)))
#define TU_ISCONDCODE(t)     (TY_ISCONDCODE(TU_TYPEINFO(t)))
#define TU_ISFLAG(t)         (TY_ISFLAG(TU_TYPEINFO(t)))
#define TU_ISVOID(t)         (TY_ISVOID(TU_TYPEINFO(t)))
#define TU_ISSMB1(t)         (TY_EQUIVTYPE(TU_TYPE(t), TY_SMB1))
#define TU_ISSMB2(t)         (TY_EQUIVTYPE(TU_TYPE(t), TY_SMB2))
#define TU_ISSMB4(t)         (TY_EQUIVTYPE(TU_TYPE(t), TY_SMB4))
#define TU_ISSMB8(t)         (TY_EQUIVTYPE(TU_TYPE(t), TY_SMB8))

#if defined(T386)
# define TU_ISMMX(t)          (TY_ISMMX(TU_TYPEINFO(t)))
#endif
#if defined(CC_KNI)
# define TU_ISXMMX(t)         (TY_ISXMMX(TU_TYPEINFO(t)))
# define TU_ISANYXMMX(t)      (TU_ISXMMX(t))
#endif


// Tuple field access macros

#ifndef NODEBUG

#define TF_MAKEINDEX(ucname)       TF_ ## ucname

enum
{
#define TUPFIELD(ucname, tupleKindBits) TF_MAKEINDEX(ucname),
#include "tupfield.h"
    TF_NUMBEROFFIELDS
#undef TUPFIELD
};

#define TF_ACCESSTOKEN(ucname)  TF_ ## ucname ## ACCESSTOKEN

enum
{
#define TUPFIELD(ucname, tupleKindBits) TF_ACCESSTOKEN(ucname) = tupleKindBits,
#include "tupfield.h"
#undef TUPFIELD
};

extern void TupAccessFailed(PTUPLE tup, int field, char *filename, int line);

#define TK_CHECKACCESS(k, f) (TK_GETBIT(k) & TF_ACCESSTOKEN(f))
#define TU_HASFIELD(t, f)    (TK_CHECKACCESS(t->Common.kind, f))

#ifndef NOACCESSCHECK

#define TU_ASSERT(e)         ((void)((e) ? 0 : assert(__File__, __LINE__)))
#if defined(OLDCHECK) || defined(TRISC)
#define TU_ASSERTFIELD(t, f) ((void)((TU_HASFIELD(t, f)) ? 0 :\
                                 TupAccessFailed(t, TF_MAKEINDEX(f),\
                                     __File__, __LINE__)))
#else
#define TU_ASSERTFIELD(t, f) ((void)((TU_HASFIELD(t, f)) ? 0 : (*((char*)0)=0)))
#endif
#define TU_FIELD(t, f)       (*(TUPLE **)(TU_ASSERTFIELD(t, f), &(t)))

#else

#define TU_FIELD(t, f)       (t)
#define TU_ASSERT(e)         0

#endif

#else

#define TU_FIELD(t, f)       (t)
#define TU_ASSERT(e)         0

#endif

// Tuple kind setting and validity checks.

#ifndef NODEBUG
#define TupSetKind(t,k)       (TupSetKindDebug(t, k, __File__, __LINE__))
#else
#define TupSetKind(t,k)       (*((TUPLEKIND *)(&(t)->Common.kind)) = (k))
#endif

// Tuple opcode setting and validity checks.

#ifndef NODEBUG
#define TU_ISOPCODEVALID(t,o) (TupOpcodeKinds[o] & TK_GETBIT(TU_KIND(t)))
#define TupSetOpcode(t,o)     (TupSetOpcodeDebug(t, o, __File__, __LINE__))
#else
#define TupSetOpcode(t,o)     (*((OPCODE *)(&(t)->Common.opcode)) = (o))
#endif

// Tuple API to assign a register to a reg tuple.
// Debug mode

#ifndef NODEBUG
#define TupSetReg(t,r)        (TupSetRegDebug(t, r, __File__, __LINE__))
#else
#define TupSetReg(t,r)        (*((PSYM *)(&(t)->Leaf.SymRef.reg)) = (r))
#endif


// TU_CONDCODE should not be directly modified.  Pogo, in particular, is very
// dependent on condition code setting via the APIs
// (Tup{Invert,Reverse}CBranch).

#define TupSetCondCode(t,c)   ((TU_FIELD((t), CONDCODE)\
                                 ->Common._condCode) = (c))

// Tuple memory management macros.

#define TU_FREEMEMBYTE       (0xfe)
#define TU_SIZEOF(t)         (TK_SIZEOF(TU_KIND(t)))

// Base: Common Fields

#define TU_KIND(t)           (TU_FIELD((t), KIND)\
                                 ->Common.kind)
#define TU_OPCODE(t)         (TU_FIELD((t), OPCODE)\
                                 ->Common.opcode)
#define TU_NEXT(t)           (TU_FIELD((t), NEXT)\
                                 ->Common.next)
#define TU_ISINSTR(t)        ((t)->Common.isInstr)
#define TU_ISINLINEASM(t)    ((t)->Common.isInlineAsm)
#define TU_ISRISCIFIED(t)    ((t)->Common.isRiscified)
#define TU_ISPERSISTENTBRANCH(t)  ((t)->Common.isPersistentBranch)
#define TU_ISDUMMYUSE(t)     ((t)->Common.isDummyUse)
#define TU_DONTCOPYPROP(t)   ((t)->Common.dontCopyProp)
#define TU_ISREDUNDANT(t)    ((t)->Common.isRedundant)
#define TU_ISREHASHASSIGN(t) ((t)->Common.isRehashAssign)
#define TU_ISCANDIDATE(t)    ((t)->Common.isCandidate)

// Leaf & Code: Common Fields

#define TU_TYPEINFO(t)       ((t)->Common.type)

#define TU_TYPE(t)           (TY_TYPE(TU_TYPEINFO(TU_FIELD((t), TYPE))))

#define TU_TYPEIDENTIFIER(t) (TY_TYPEIDENTIFIER(TU_TYPE(t)))

#define TU_TYPEINDEX(t)      (TY_INDEX(TU_TYPE(t)))

#define TU_SIZE(t)           (TY_SIZE(TU_TYPEINFO(TU_FIELD((t), SIZE))))

#define TU_BASETYPE(t)       (TY_BASETYPE(TU_TYPEINFO(TU_FIELD((t), BASETYPE))))

#define TU_CONDCODE(t)       (TU_FIELD((t), CONDCODE)\
                                 ->Common.condCode)
#if defined(CC_NAN)
#define TU_ORIGCC(t)         (TU_FIELD((t), CONDCODE)\
                                 ->Common.origCC)
#endif

#if defined(CC_NAN2)
#define TU_INVERTED(t)       (TU_FIELD((t), INVERTED)\
                                 ->Common.inverted)
#endif
#define TU_PREV(t)           (TU_FIELD((t), PREV)\
                                 ->Common.prev)
#define TU_OPTHASHVAL(t)     (TU_FIELD((t), OPTHASHVAL)\
                                 ->Common.optHashVal)
#if defined(CC_TYPEINFO)
#define TU_EQUIVTYPE(t1,t2)  (TY_EQUIVTYPE(TU_TYPE(t1),TU_TYPE(t2)))
#define TU_TYPEQUALIFIER(t)  (TY_TYPEQUALIFIER(TU_TYPE(t)))
#define TU_ALIGN(t)          (TY_ALIGN(TU_TYPEINFO(TU_FIELD((t), ALIGNMENT))))
#define TU_ALIGNBITS(t)      (TY_ALIGNBITS(TU_TYPE(t)))
#define TU_ALIGNBYTES(t)     (TY_ALIGNBYTES(TU_TYPE(t)))
#define TU_TAGINFO(t)        (TY_TAGINFO(TU_TYPE(t)))
#define TU_ISALIGN1(t)       (TU_ALIGN(t) == 0)
#define TU_ISALIGN2(t)       (TU_ALIGN(t) == 1)
#define TU_ISALIGN4(t)       (TU_ALIGN(t) == 2)
#define TU_ISALIGN8(t)       (TU_ALIGN(t) == 3)
#define TU_ISALIGN16(t)      (TU_ALIGN(t) == 4)
#define TU_ISALIGN32(t)      (TU_ALIGN(t) == 5)
#define TU_ISALIGN64(t)      (TU_ALIGN(t) == 6)
#define TU_ISALIGN128(t)     (TU_ALIGN(t) == 7)
#define TU_COPYALIGN(t1,t2)  (TU_ALIGN(t1) = TU_ALIGN(t2))
#define TU_COPYTAGINFO(t1,t2) (TU_TAGINFO(t1) = TU_TAGINFO(t2))
#define TU_COPYTYPEQUALIFIER(t1,t2) (TU_TYPEQUALIFIER(t1) = TU_TYPEQUALIFIER(t2))
#else
#define TU_EQUIVTYPE(t1,t2)  (TU_TYPE(t1) == TU_TYPE(t2))
#define TU_COPYALIGN(t1,t2)
#define TU_COPYTAGINFO(t1,t2)
#define TU_COPYTYPEQUALIFIER(t1,t2)
#endif

// Leaf: Common Fields

#define TU_INUSE(t)          (TU_FIELD((t), INUSE)\
                                 ->Leaf.Common.inUse)
#define TU_ISMEMREFREG(t)    (TU_FIELD((t), ISMEMREFREG)\
                                 ->Leaf.Common.isMemRefReg)
#define TU_ISVOLATILE(t)     (TU_FIELD((t), ISVOLATILE)\
                                 ->Leaf.Common.isVolatile)
#define TU_ISCEXTR(t)        (TU_FIELD((t), ISCEXTR)\
                                 ->Leaf.Common.isCextr)
#define TU_ISWRITETHRU(t)    (TU_FIELD((t), ISWRITETHRU)\
                                 ->Leaf.Common.isWriteThru)
#define TU_ISDEAD(t)         (TU_FIELD((t), ISDEAD)\
                                 ->Leaf.Common.isDead)
#define TU_ISREGIONCONST(t)  (TU_FIELD((t), ISREGIONCONST)\
                                 ->Leaf.Common.isRegionConst)
#define TU_ISDETACHED(t)     (TU_FIELD((t), ISDETACHED)\
                                 ->Leaf.Common.isDetached)
#define TU_ISOVERFLOWED(t)   (TU_FIELD((t), ISOVERFLOWED)\
                                 ->Leaf.Common.isOverflowed)
#define TU_REACHESEND(t)     (TU_FIELD((t), REACHESEND)\
                                 ->Leaf.Common.reachesEnd)
#define TU_AFFECTSCOST(t)    (TU_FIELD((t), AFFECTSCOST)\
                                 ->Leaf.Common.affectsCost)
#define TU_PHYSREGNOTDEAD(t) (TU_FIELD((t), PHYSREGNOTDEAD)\
                                 ->Leaf.Common.physregNotDead)
#define TU_OPEQNUM(t)        (TU_FIELD((t), OPEQNUM)\
                                 ->Leaf.Common.opeqNum)

#define TU_UPUSE(t)          (TU_FIELD((t), UPUSE)\
                                 ->Leaf.Common.upUse)

#define TU_DEFNUM(t)         (TU_FIELD((t), DEFNUM)\
                                 ->Common.defNum)
#define TU_CORTOKEN(t)       (TU_FIELD((t), CORTOKEN)\
                                 ->Common.corToken)
#define TU_STACKLEVEL(t)     (TU_FIELD((t), STACKLEVEL)\
                                 ->Common.stackLevel)

#ifdef CC_SSA

#define TU_UD_LINK(t)        (TU_FIELD((t), SSAUDLINK)\
                                 ->Common.udLink)
#define TU_SSA_DEFNO(t)      (TU_FIELD((t), SSADEFNO)\
                                 ->Common.ssaDefNo)
#define TU_SSA_DEFTYPE(t)    (TU_FIELD((t), SSADEFTYPE)\
                                 ->Common.ssaDefType)
#define TU_INSTR_UDLINK(t)   (TU_FIELD((t), SSAINSTRUDLINK)\
                                 ->Common.OpUdLink)

#endif // CC_SSA

#ifdef MD_VALTRACKER
// Value number for leaf tuples
#define TU_VALNUMBER(t)      (TU_FIELD((t), VALNUMBER)\
                                 ->Common.valNumber)
#endif

                             // Stack packing: UpUse or UpDef for SYMSET tuples
#define TU_STKUPREF(t)       (TU_FIELD((t), STKUPREF)\
                                 ->Common.stkUpRef)

// Leaf: SymRef Fields

#define TU_SYM(t)            (TU_FIELD((t), SYM)\
                                 ->Leaf.SymRef.sym)
#define TU_FESYM(t)          (TU_FIELD((t), FESYM)\
                                 ->Leaf.SymRef.feSym)
#define TU_REG(t)            (TU_FIELD((t), REG)\
                                 ->Leaf.SymRef.reg)

#define TU_RDRINVERTEDCC(t)  (TU_FIELD((t), RDRINVERTEDCC)\
                                 ->Leaf.Reg.rdrinvertedCC)
#define TU_READERCC(t)       (TU_FIELD((t), READERCC)\
                                 ->Leaf.Reg.readerCC)

// Leaf: MemRef Fields

#define TU_SCALE(t)          (TU_FIELD((t), SCALE)\
                                 ->Leaf.MemRef.scale)
#define TU_SEG(t)            (TU_FIELD((t), SEG)\
                                 ->Leaf.MemRef.seg)
#define TU_FIXUPSYM(t)       (TU_FIELD((t), FIXUPSYM)\
                                 ->Leaf.MemRef.fixupSym)
#define TU_FEFIXUPSYM(t)     (TU_FIXUPSYM(t) ? \
                                 SY_FESYM(SY_EQUIVCLASS(TU_FIXUPSYM(t))) : NULL)
#define TU_OFFSET(t)         (TU_FIELD((t), OFFSET)\
                                 ->Leaf.MemRef.offset)
#define TU_BASE(t)           (TU_FIELD((t), BASE)\
                                 ->Leaf.MemRef.base)
#define TU_INDEX(t)          (TU_FIELD((t), INDEX)\
                                 ->Leaf.MemRef.index)
#define TU_PASINDEX(t)       (TU_FIELD((t), PASINDEX)\
                                 ->Leaf.MemRef.pasIndex)
#define TU_SHAPE(t)          (TU_FIELD((t), SHAPE)\
                                 ->Leaf.MemRef.shape)
#if defined(TARM) || defined(TTHUMB)
#define TU_SHIFTER(t)       (TU_FIELD((t), SHIFTER)\
                                 ->Leaf.MemRef.shifter)
#define TU_SHIFTER_TYPE(t)  (TU_FIELD((t), SHIFTER)\
                                 ->Leaf.MemRef.shifter.type)
#define TU_SHIFTER_SHIFT(t) (TU_FIELD((t), SHIFTER)\
                                 ->Leaf.MemRef.shifter.shift)
#define TU_SHIFTER_SUB(t)   (TU_FIELD((t), SHIFTER)\
                                 ->Leaf.MemRef.shifter.sub)
#define TU_SHIFTER_POST(t)  (TU_FIELD((t), SHIFTER)\
                                 ->Leaf.MemRef.shifter.post)
#define TU_SHIFTER_UPDATE(t) (TU_FIELD((t), SHIFTER)\
                                 ->Leaf.MemRef.shifter.update)
#endif
#ifdef CC_DLP
#define TU_DLPINFO(t)        (TU_FIELD((t), DLPINFO)\
                                 ->Leaf.MemRef.dlpInfo)
#endif

#define TU_MEMREFALIGN(t)    (TU_FIELD((t), ALIGN)\
                                 ->Leaf.MemRef.align)


// Leaf: Int and Float Const Fields

#define TU_SYMCONST(t)       (TU_FIELD((t), SYMCONST)\
                                 ->Leaf.SymConst.symConst)
#define TU_IVAL(t)           (TU_FIELD((t), IVAL)\
                                 ->Leaf.IntConst.ival)

# ifdef CC_CE_FPEM
#define TU_WASFLOATCONST(t)  (TU_FIELD((t),WASFLOATCONST)\
                                ->Leaf.IntConst.WasFloatConst)
# endif

#define TU_IVAL8(t)          ((char)(TU_IVAL(t)))
#define TU_IVAL16(t)         ((short)(TU_IVAL(t)))
#define TU_IVAL32(t)         ((long)(TU_IVAL(t)))

#define TU_IVAL_MACHREG(t)   (TU_IVAL(t) & MACH_REG_MASK)
#define TU_FVAL(t)           (TU_FIELD((t), FVAL)\
                                 ->Leaf.FloatConst.fval)
// Leaf: Reg and Sym Set Fields

#define TU_REGSET(t)         (TU_FIELD((t), REGSET)\
                                 ->Leaf.RegSet.regSet)
#define TU_SYMSET(t)         (TU_FIELD((t), SYMSET)\
                                 ->Leaf.SymSet.symSet)

#if defined(CC_TEXTCONST)
// Leaf: Text constant
#define TU_TEXTVAL(t)        (TU_FIELD((t), TEXTVAL)\
                                 ->Leaf.TextConst.textval)
#endif

// Code: Common Fields

#define TU_LINEOFS(t)        (TU_FIELD((t), LINEOFS)\
                                 ->Code.Common.lineOfs)
#define TU_VISITED(t)        (TU_FIELD((t), VISITED)\
                                 ->Code.Common.vis.visited)
#define TU_VISITED2(t)       (TU_FIELD((t), VISITED)\
                                 ->Code.Common.vis.visited2)
#define TU_AUTOSYMUSE(t)     (TU_FIELD((t), WARN)\
                                 ->Code.Common.warn.autoSymUse)
#define TU_AUTOSYMDEF(t)     (TU_FIELD((t), WARN)\
                                 ->Code.Common.warn.autoSymDef)
#define TU_SCRATCH(t)        (TU_FIELD((t), SCRATCH)\
                                 ->Code.Common.scratch)
#define TU_OPTIMIZE(t)       (TU_FIELD((t), OPTIMIZE)\
                                 ->Code.Common.optimize)
#define TU_GLOBAL(t)         (TU_FIELD((t), GLOBAL)\
                                 ->Code.Common.global)
#define TU_NUMBER(t)         (TU_FIELD((t), NUMBER)\
                                 ->Code.Common.number)
#define TU_NUMLIVETEMPS(t)   (TU_FIELD((t), NUMBER)\
                                 ->Code.Common.numLiveTemps)
#if defined(TP7)
#define TU_GPISVALID(t)      (TU_FIELD((t), GPISVALID)\
                                 ->Code.Common.GPIsValid)
#endif


// Instr: Common Fields

#define TU_INSTRSIZE(t)      (TU_FIELD((t), INSTRSIZE)\
                                 ->Code.Instr.Common.instrSize)
#define TU_DST(t)            (TU_FIELD((t), DST)\
                                 ->Code.Instr.Common.dst)
#define TU_DST1(t)           (TU_DST(t))
#define TU_DST2(t)           (TU_NEXT(TU_DST1(t)))
#define TU_SRC(t)            (TU_FIELD((t), SRC)\
                                 ->Code.Instr.Common.src)
#define TU_SRC1(t)           (TU_SRC(t))
#define TU_SRC2(t)           (TU_NEXT(TU_SRC1(t)))
#define TU_SRC3(t)           (TU_NEXT(TU_SRC2(t)))
#define TU_SRC4(t)           (TU_NEXT(TU_SRC3(t)))

#if defined (CC_PROFILE_FEEDBACK) || defined(CC_P7_SPE)
#define TU_PROBEINFO(t)      (TU_FIELD((t), PROBEINFO)\
                                 ->Code.Instr.Common.probeInfo)
#endif

#define TU_HASHSYM(t)        (TU_FIELD((t), HASHSYM)\
                                 ->Code.Instr.Common.hashSym)
#define TU_OUTARGSYM(t)      (TU_FIELD((t), OUTARGSYM)\
                                 ->Code.Instr.Common.outArgSym)

#if defined(CC_WVMOPTIL)
#define TU_TMPPHYSREG(t)     (TU_FIELD((t), TMPPHYSREG)\
                                 ->Code.Instr.Common.tmpPhysReg)
#endif

#define TU_INSTRBLOCK(t)     (TU_FIELD((t), INSTRBLOCK)\
                                 ->Code.Instr.Common.instrBlock)
#define TU_EHSTATE(t)        (TU_FIELD((t), EHSTATE)\
                                 ->Code.Instr.Common.ehstate)
#if defined(CC_GC) || defined(CC_COMIMPORT)
#define TU_LIVEREFS(t)      (TU_FIELD((t), LIVEREFS)\
                                ->Code.Instr.Common.liveRefs)
#define TU_ISGCPTRREF(t)    (TU_FIELD((t), ISGCPTRREF)\
                                 ->Code.Instr.Common.wasZeroTripTested)

#define TU_SYMISGCPTRREF(t) (TU_ISREGORSYM(t) && SY_ISGCPTRREF(TU_SYM(t)))

#endif // CC_GC || CC_COMIMPORT

#ifdef CC_DLP
#define TU_READERDLPINFO(t)  (TU_FIELD((t), READERDLPINFO)\
                                 ->Code.Instr.Common.readerDlpInfo)
#endif

#if defined(TALPHA)
#define TU_ISENDOFCYCLE(t)        (TU_FIELD((t), ISENDOFCYCLE)\
                                 ->Code.Instr.Common.endOfCycle)
#define TU_ISTRAPSHADOWCONSUMER(t)        (TU_FIELD((t), ISTRAPSHADOWCONSUMER)\
                                 ->Code.Instr.Common.trapShadowConsumer)
#endif

// ---- Use scratch field for NOPROTO flag ---
#if (defined(TMIPS) && !defined(TM16)) || (defined(TSH))
#define TU_NOPROTO_ARG(t)        (TU_FIELD((t), NOPROTOTYPEFORARG)\
                                 ->Code.Instr.Common.noPrototypeForArg)
#else
#define TU_NOPROTO_ARG(t)   TU_SCRATCH((t))
#endif

#if defined(TP7)

#if defined(CC_TYPEINFO)
#define TY_ISHFA(t)          (TY_TYPEINFO(t).isHFA)
#define TU_ISHFA(t)          (TY_ISHFA(TU_TYPE(t)))
// bit mask for isHFA within tagInfo
#define TAG_ISHFA            (1 << 2)
#endif

#define TU_CODEHINT_WH(t)     (TU_FIELD((t), CODEHINTWH)\
                                 ->Code.Instr.Common.codeHintWh)
#define TU_CODEHINT_PH(t)     (TU_FIELD((t), CODEHINTPH)\
                                 ->Code.Instr.Common.codeHintPh)
#define TU_CODEHINT_DH(t)     (TU_FIELD((t), CODEHINTDH)\
                                 ->Code.Instr.Common.codeHintDh)
#define TU_CODEHINT_IH(t)     (TU_FIELD((t), CODEHINTIH)\
                                 ->Code.Instr.Common.codeHintIh)
#define TU_CODEHINT_PVEC(t)   (TU_FIELD((t), CODEHINTPVEC)\
                                 ->Code.Instr.Common.codeHintPvec)
#define TU_CMPCREL(t)         (TU_FIELD((t), CMPCREL)\
                                 ->Code.Instr.Common.cmpCrel)
#define TU_CMPCTYPE(t)        (TU_FIELD((t), CMPCTYPE)\
                                 ->Code.Instr.Common.cmpCtype)
#define TU_DATAHINT(t)        (TU_FIELD((t), DATAHINT)\
                                 ->Code.Instr.Common.dataHint)
#define TU_MEMTYPE(t)         (TU_FIELD((t), MEMTYPE)\
                                 ->Code.Instr.Common.memType)
#define TU_FPSF(t)            (TU_FIELD((t), FPSF)\
                                 ->Code.Instr.Common.fpSf)
#define TU_FCMPCTYPE(t)       (TU_FIELD((t), FCMPCTYPEF)\
                                 ->Code.Instr.Common.fcmpCtype)
#define TU_PREDICATE(t)       (TU_FIELD((t), FCMPCTYPEF)\
                                 ->Code.Instr.Common.qualifierPredicate)
// #define TU_PREDICATE(t)       (TupFindPredicate((t)))
#define TU_ISBEGINOFBUNDLE(t) (TU_FIELD((t), ISBEGINOFBUNDLE)\
                                 ->Code.Instr.Common.beginOfBundle)
#define TU_ISENDOFBUNDLE(t)   (TU_FIELD((t), ISENDOFBUNDLE)\
                                 ->Code.Instr.Common.endOfBundle)
#define TU_BUNDLETEMPLATE(t)  (TU_FIELD((t), BUNDLETEMPLATE)\
                                 ->Code.Instr.Common.bundleTemplate)
#define TU_ISENDOFGROUP(t)        (TU_FIELD((t), ISENDOFGROUP)\
                                 ->Code.Instr.Common.endOfGroup)
#define TU_ISPREDICATE(x)     (TU_ISREG(x) && SY_ISPREDICATREG(TU_REG(x)))
#define TU_DESCRATTRIBUTES(t) (TU_FIELD((t), DESCRATTRIBUTES)\
                                 ->Code.Instr.Common.descrAttributes)
#define TU_REGMAPSCI(t)       (TU_FIELD((t), REGMAPSCI)\
                                 ->Common.regMapSci)
#else
#define TU_PREDICATE(t)       NULL
#define TU_ISPREDICATE(t)     FALSE
#endif

#if defined(CC_PREDICATION)
#define TU_ADDPREDCOND(tupInstr, tupPred) if (tupPred) { TupAddPredicate(tupInstr, tupPred); }
#if defined(CC_PREDALL)
#define TU_ADDTRUEPR(tupInstr) TupAddPredicate(tupInstr, TupMakePhysReg(TRUE_PR_REG, TY_FLAG))
#else
#define TU_ADDTRUEPR(tupInstr)
#endif
#endif

// Instr: Op Fields

#if defined(CC_GOPTCMP)
#define TU_OPCONDCODE(t)  (TU_FIELD((t), OPCONDCODE)\
                                 ->Code.Instr.Op.opCondCode)
#endif


// Instr: Multi-byte Fields

#define TU_MBSIZE(t)         (TU_IVAL32(TU_SRC2(TU_FIELD((t), MBSIZE))))

// Instr: Call Fields

#define TU_NUMARGBYTES(t)    (TU_FIELD((t), NUMARGBYTES)\
                                 ->Code.Instr.Call.numArgBytes)
#define TU_CALLCONV(t)       (TU_FIELD((t), CALLCONV)\
                                 ->Code.Instr.Call.callConv)
#define TU_CALLSYM(t)        (TU_FESYM(TU_SRC1(t)))
#define TU_HASMBARG(t)       (TU_FIELD((t), HASMBARG)\
                                 ->Code.Instr.Call.hasMbArg)
#if defined(T386)
#define TU_FLTREGSPOPPED(t)  (TU_FIELD((t), FLTREGSPOPPED)\
                                 ->Code.Instr.Call.numFPRegsPopped)
#define TU_HASREGARGS(t)     (TU_FIELD((t), HASREGARGS)\
                                 ->Code.Instr.Call.hasRegArgs)
#endif

#define TU_ISEHCALL(t)       (TU_FIELD((t), ISEHCALL)\
                                 ->Code.Instr.Call.isEHcall)

#if defined(TP7)
#define TU_ISSETJMPCALL(t)   (TU_FIELD((t), ISSETJMPCALL)\
                                 ->Code.Instr.Call.isSetjmpCall)
#endif
#if defined(CC_WVMOPTIL)
#define TU_ISHOISTEDCALL(t)  (TU_FIELD((t), ISHOISTEDCALL)\
                                 ->Code.Instr.Call.isHoistedCall)
#endif
#if defined(TOMNI) || defined(CC_WVM)
#define TU_CALLDESCR(t)      (TU_FIELD((t), CALLDESCR)\
                                 ->Code.Instr.Call.callDescriptor)
#define TU_CALLSIGNATURE(t)  (CALLDESCR_CALLSIG(TU_CALLDESCR(t)))
#define TU_CALLARGCNT(t)     (CALLSIG_ARGCNT(TU_CALLSIGNATURE(t)))
#define TU_CALLARGTYPE(t)    (CALLSIG_ARGTYPE(TU_CALLSIGNATURE(t)))
#define TU_CALLISCORVCALL(t) (TU_FIELD((t), CALLATTRIB)\
                                 ->Code.Instr.Call.iscorvcall)
#define TU_CALLISCORNEW(t)   (TU_FIELD((t), CALLATTRIB)\
                                 ->Code.Instr.Call.iscornew)
#if defined(CC_COR)
#define TU_CALLTOKENSYM(t)   (TU_FIELD((t), CALLTOKEN)\
                                 ->Code.Instr.Call.symToken)
#endif
#define TU_CALLISVCALL(t)    (TU_FIELD((t), CALLATTRIB)\
                                 ->Code.Instr.Call.isvcall)
#define TU_CALLISCOMVCALL(t) (TU_FIELD((t), CALLATTRIB)\
                                 ->Code.Instr.Call.iscomvcall)

#elif defined(CC_GC) || defined(CC_COMIMPORT)
#define TU_CALLDESCR(t)      (TU_FIELD((t), CALLDESCR)\
                                ->Code.Instr.Call.callDescriptor)
#endif  // TOMNI

#ifdef CC_CNC
#define TU_CALLHASTHIS(t)    (TU_FIELD((t), CALLATTRIB)\
                                 ->Code.Instr.Call.hasThis)
#endif

#ifdef CC_INTERPROC
#define TU_CALLSITEINFO(t)   (TU_FIELD((t), CALLSITEINFO)\
                                 ->Code.Instr.Call.callSiteInfo)
#endif

// Instr: Intrinsic Fields

#define TU_INTRINNUM(t)      (TU_FIELD((t), INTRINNUM)\
                                 ->Code.Instr.Intrinsic.intrinNum)
#define TU_BLKSIZE(t)        (TU_FIELD((t), INTRINNUM)\
                                 ->Code.Instr.Intrinsic.blkSize)
#define TU_DONTLENGTHEN(t)   (TU_FIELD((t), INTRINNUM)\
                                 ->Code.Instr.Intrinsic.dontLengthen)
#if defined(CC_WVM) || defined(TP7) || defined(TALPHA) || defined(TPPCWIN) || defined(TRISC)
#define TU_SEHINTRINFO(t)    (TU_FIELD((t), INTRINNUM)\
                                 ->Code.Instr.Intrinsic.SEHInfo)
#endif
#if defined(CC_WVM)
#define TU_INTRINCALLSYM(t)   (TU_FIELD((t), INTRINNUM)\
                                 ->Code.Instr.Intrinsic.symCall)
#endif

// REVIEW: we need a cleaner way to handle these macros below.

extern SYMBOL *AllocaSsr, *ChkStkSsr;
#define TU_CALLISALLOCA(tup) ((TU_KIND(TU_SRC(tup))==TK_CODEADDRTUPLE)&&\
                 (TU_FESYM(TU_SRC(tup)) == AllocaSsr))
#define TU_CALLISCHKSTK(tup) ((TU_KIND(TU_SRC(tup))==TK_CODEADDRTUPLE)&&\
                 (TU_FESYM(TU_SRC(tup)) == ChkStkSsr))

#ifdef CC_DLP
extern SYMBOL *DlpBufferAllocSsr;
#define TU_CALLISDLPBUFFERALLOC(tup)\
                 ((TU_KIND(TU_SRC(tup))==TK_CODEADDRTUPLE)&&\
                 (TU_FESYM(TU_SRC(tup)) == DlpBufferAllocSsr))
#endif

#ifdef CC_CAP
extern SYMBOL *CapProfilingSsr;
#define TU_CALLISCAPPROFILING(tup)\
                 ((TU_KIND(TU_SRC(tup))==TK_CODEADDRTUPLE)&&\
                 (TU_FESYM(TU_SRC(tup)) == CapProfilingSsr))
extern SYMBOL *CapStartProfilingSsr;
#define TU_CALLISCAPSTARTPROFILING(tup)\
                 ((TU_KIND(TU_SRC(tup))==TK_CODEADDRTUPLE)&&\
                 (TU_FESYM(TU_SRC(tup)) == CapStartProfilingSsr))
extern SYMBOL *CapEndProfilingSsr;
#define TU_CALLISCAPENDPROFILING(tup)\
                 ((TU_KIND(TU_SRC(tup))==TK_CODEADDRTUPLE)&&\
                 (TU_FESYM(TU_SRC(tup)) == CapEndProfilingSsr))
#endif

// Instr: Question Fields
#define TU_QUESTCONDCODE(t)  (TU_FIELD((t), QUESTCONDCODE)\
                                 ->Code.Instr.Question.questionCondCode)

// Instr: Branch Fields

#define TU_CONDSETTERLIST(t) (TU_FIELD((t), CONDSETTERLIST)\
                                 ->Code.Instr.Branch.condSetterList)

#define TU_WASZEROTRIPTESTED(t) (TU_FIELD((t), WASZEROTRIPTESTED)\
                                 ->Code.Instr.Branch.wasZeroTripTested)

#define TU_BRANCHTYPE(t)        (TU_FIELD((t), BRANCHTYPE)\
                                 ->Code.Common.branchType)

#define TU_BRANCHSYM(t)      (TU_FESYM(TU_SRC1(t)))

#define TU_BRANCHLABEL(t)    (SS_LABELTUPLE(TU_BRANCHSYM(t)))

#define TU_HASBRANCHLABEL(t) (TU_ISCODEADDR(TU_SRC1(t)) && TU_BRANCHLABEL(t))

#define TU_CCREG(t)          TU_SRC2(t)


// Instr: Switch Fields

#define TU_DEFAULTLABEL(t)   (TU_FIELD((t), DEFAULTLABEL)\
                                 ->Code.Instr.Switch.defaultLabel)
#define TU_CASELIST(t)       (TU_FIELD((t), CASELIST)\
                                 ->Code.Instr.Switch.caseList)
#define TU_2LEVLABEL(t)      (TU_FIELD((t), 2LEVLABEL)\
                                 ->Code.Instr.Switch.twoLevLabel)
#define TU_ISSUBSWITCH(t)    (TU_FIELD((t), ISSUBSWITCH)\
                                 ->Code.Instr.Switch.isSubSwitch)
#define TU_NODEFAULT(t)      (TU_FIELD((t), NODEFAULT)\
                                 ->Code.Instr.Switch.noDefault)

// Instr: Except Fields

#define TU_SEHINFO(t)        (TU_FIELD((t), SEHINFO)\
                                 ->Code.Instr.Except.sehInfo)
#define TU_EHINFO(t)         (TU_FIELD((t), EHINFO)\
                                 ->Code.Instr.Except.ehInfo)
#define TU_SCOPEINDEX(t)     (TU_FIELD((t), SCOPEINDEX)\
                                 ->Code.Instr.Except.scopeIndex)
#define TU_NOEVALLIST(t)     (TU_FIELD((t), NOEVALLIST)\
                                 ->Code.Instr.Except.noEvalList)

#if defined(CC_COMIMPORT)
#define TU_SYMIV(t)          (TU_FIELD((t), SYMIV)\
                                 ->Code.Instr.Except.symIV)
#endif

#ifdef CC_CGIF
#define TU_TUPID(t)    (*(TU_ISCASELIST(t) ? \
                            & (TU_FIELD((t), TUPID)->List.CaseList.tupID) : \
                          TU_ISLEAF(t) ? \
                            & (TU_FIELD((t), TUPID)->Leaf.Common.tupID) : \
                            & (TU_FIELD((t), TUPID)->Code.Common.tupID)))
#if 0  // obsolete
#define TU_GETTUPID(t)       (TU_ISCASELIST(t) ? \
                              (TU_FIELD((t), TUPID)->List.CaseList.tupID) : \
                              TU_ISLEAF(t) ? \
                              (TU_FIELD((t), TUPID)->Leaf.Common.tupID) : \
                              (TU_FIELD((t), TUPID)->Code.Common.tupID))

#define TU_SETTUPID(t,id)    (TU_ISCASELIST(t) ? \
                              (TU_FIELD((t), TUPID)->List.CaseList.tupID = id):\
                              TU_ISLEAF(t) ? \
                              (TU_FIELD((t), TUPID)->Leaf.Common.tupID = id ) :\
                              (TU_FIELD((t), TUPID)->Code.Common.tupID = id))
#endif
#endif

// Instr: TupList Fields

#define TU_TUPLIST(t)        (TU_FIELD((t), TUPLIST) \
                                 ->Code.Instr.TupList.tupList)


// Instr: Pcode Fields

#ifdef CC_PCODE
#define TU_PCODEINFO(t)      (TU_FIELD((t), PCODEINFO)\
                                 ->Code.Pcode.pcodeInfo)
#endif

// Code: Label Fields

#define TU_LABELBLK(t)       (TU_FIELD((t), LABELBLK)\
                                 ->Code.Label.labelBlk)
#define TU_LABELSYM(t)       (TU_FIELD((t), LABELSYM)\
                                 ->Code.Label.labelSym)
#if defined(CC_PROFILE_FEEDBACK)
#define TU_PROBELABELINFO(t) (TU_FIELD((t), PROBELABELINFO)\
                                 ->Code.Label.probeLabelInfo)
#endif
#ifdef CC_PCODE
#define TU_PCODE_LABEL(t)    (TU_FIELD((t), LABELSYM)\
                                 ->Code.Label.labelRef)
#endif
#if defined(CC_WVM)
#define TU_LABELREF(t)       (TU_FIELD((t), LABELSYM)\
                                 ->Code.Label.labelRef)
#endif
#define TU_BRANCHLIST(t)     (TU_FIELD((t), BRANCHLIST)\
                                 ->Code.Label.branchList)
#define TU_SEQUENCE(t)       (TU_FIELD((t), SEQUENCE)\
                                 ->Code.Label.sequence)

// Code: Block Fields

#define TU_BLOCK(t)          (TU_FIELD((t), BLOCK)\
                                 ->Code.Block.block)
#define TU_BLOCKNUM(t)       (FG_BLOCKNUM(TU_BLOCK(t)))
#define TU_BLOCKLIVEREFS(t)  (TU_FIELD((t), BLOCKLIVEREFS)\
                                 ->Code.Block.blockLiveRefs)
#define TU_BLOCKINSTRS(t)    (TU_FIELD((t), BLOCKINSTRS)\
                                 ->Code.Block.blockInstrs)

// Code: Entry Fields

#define TU_ENTRYFUNC(t)      (TU_FIELD((t), ENTRYFUNC)\
                                 ->Code.Entry.entryFunc)
#define TU_ENTRYSYM(t)       (FU_ENTRY(TU_ENTRYFUNC(t)))
#define TU_ENTRYPARAMLIST(t) (TU_FIELD((t), ENTRYPARAMLIST)\
                                 ->Code.Entry.entryParamList)
#if defined(TOMNI) || defined(CC_WVM)
#define TU_ENTRYCALLDESCR(t) (TU_FIELD((t), ENTRYCALLDESCR)\
                                 ->Code.Entry.callDescriptor)
#define TU_ENTRYCALLSIG(t)   (CALLDESCR_CALLSIG(TU_ENTRYCALLDESCR(t)))
#endif
#define TU_ENTRYDST(t)       (TU_ENTRYPARAMLIST(t))

// Code: Exit Fields

#define TU_EXITFUNC(t)      (TU_FIELD((t), EXITFUNC)\
                                 ->Code.Exit.exitFunc)
#define TU_EXITSYM(t)       (FU_ENTRY(TU_EXITFUNC(t)))

// Pragma: Pragma Fields

#define TU_SYMLIST(t)        (TU_FIELD((t), SYMLIST)\
                                 ->Code.Pragma.pragScratch.symList)
#define TU_LOCBLK(t)         (TU_FIELD((t), LOCBLK)\
                                 ->Code.Pragma.pragScratch.locblk)
#define TU_INLINECTL(t)      (TU_FIELD((t), INLINECTL)\
                                 ->Code.Pragma.pragScratch.inctl)
#define TU_ALIGNCODE(t)      (TU_FIELD((t), ALIGNCODE)\
                                 ->Code.Pragma.pragScratch.alignCode)
#define TU_USERLABEL(t)      (TU_FIELD((t), USERLABEL)\
                                 ->Code.Pragma.pragScratch.userLabel)
#define TU_SEGMENT(t)        (TU_FIELD((t), SEGMENT)\
                                 ->Code.Pragma.pragScratch.segment)
#define TU_CYCLES(t)         (TU_FIELD((t), CYCLES)\
                                 ->Code.Pragma.pragScratch.cycles)

// SplitPoint: Split Point Fields

#define TU_SPLITBV(t)       (TU_FIELD((t), SPLITBV)\
                                 ->Code.SplitPoint.splitBv)
#define TU_SPLITLIST(t)     (TU_FIELD((t), SPLITLIST)\
                                 ->Code.SplitPoint.splitList)
#define TU_SPLITMASK(t)     (TU_FIELD((t), SPLITMASK)\
                                 ->Code.SplitPoint.splitMask)

// List: Condition Setter List Node Fields

#define TU_CONDSETTER(t)     (TU_FIELD((t), CONDSETTER)\
                                 ->List.CondSetterList.condSetter)

// List: Case List Node Fields

#define TU_CASELABEL(t)      (TU_FIELD((t), CASELABEL)\
                                 ->List.CaseList.caseLabel)
#define TU_CASEUPPER(t)      (TU_FIELD((t), CASEUPPER)\
                                 ->List.CaseList.caseUpper)
#define TU_CASELOWER(t)      (TU_FIELD((t), CASELOWER)\
                                 ->List.CaseList.caseLower)
#define TU_CASESWITCH(t)     (TU_FIELD((t), CASESWITCH)\
                                 ->List.CaseList.caseSwitch)

#if defined(CC_PROFILE_FEEDBACK) || defined(CC_P7_SPE)
#define TU_PROBECASEINFO(t) (TU_FIELD((t), PROBECASEINFO)\
                                 ->List.CaseList.probeCaseInfo)
#endif


// List: Branch List Node Fields

#define TU_BRANCHFROM(t)     (TU_FIELD((t), BRANCHFROM)\
                                 ->List.BranchList.branchFrom)

#define TU_PASSCOUNT(t)      (TU_FIELD((t), PASSCOUNT)\
                                 ->List.BranchList.passCount)

// macro to get instruction which is the branch source
#define TU_INSTRBRANCHFROM(t) (TU_ISCASELIST(TU_BRANCHFROM(t)) ? \
                                TU_CASESWITCH(TU_BRANCHFROM(t)) : \
                                TU_BRANCHFROM(t))

// Iterators for various tuple lists.

#define FOREACH_TUPLE(tup, tupList)\
    for ((tup) = (tupList);\
    ((tup) != NULL);\
    (tup) = TU_NEXT(tup))

#define FOREACH_TUPLE_EDITING(tup, tupNext, tupList)\
    {\
    for ((tup) = (tupList);\
    ((tup) != NULL);\
    (tup) = (tupNext))\
        {\
        (tupNext) = TU_NEXT(tup);

#define FOREACH_TUPLE_IN_RANGE(tup, tupFirst, tupLast)\
    for ((tup) = (tupFirst);\
    ((tup) != TU_NEXT(tupLast));\
    (tup) = TU_NEXT(tup))

#define FOREACH_TUPLE_IN_RANGE_EDITING(tup, tupNext, tupFirst, tupLast)\
    {\
    PTUPLE _tupLast = TU_NEXT(tupLast);\
    for ((tup) = (tupFirst);\
    ((tup) != _tupLast);\
    (tup) = (tupNext))\
        {\
        ASSERTNRNM((tup) != NULL);\
        (tupNext) = TU_NEXT(tup);

#define FOREACH_TUPLE_IN_RANGE_BACKWARD_EDITING(tup, tupPrev, tupFirst, tupLast)\
    {\
    PTUPLE _tupFirst = TU_PREV(tupFirst);\
    for ((tup) = (tupLast);\
    ((tup) != _tupFirst);\
    (tup) = (tupPrev))\
        {\
        ASSERTNRNM((tup) != NULL);\
        (tupPrev) = TU_PREV(tup);

#define FOREACH_TUPLE_IN_BLOCK(tup, blk)\
    for ((tup) = TU_NEXT(FG_FIRSTTUPLE(blk));\
    ((tup) != FG_LASTTUPLE(blk));\
    (tup) = TU_NEXT(tup))

#define FOREACH_TUPLE_IN_BLOCK_BACKWARD(tup, blk)\
    for ((tup) = TU_PREV(FG_LASTTUPLE(blk));\
    ((tup) != FG_FIRSTTUPLE(blk));\
    (tup) = TU_PREV(tup))

#define FOREACH_TUPLE_IN_BLOCK_EDITING(tup, tupNext, blk)\
    {\
    PTUPLE _tupLast = FG_LASTTUPLE(blk);\
    for ((tup) = TU_NEXT(FG_FIRSTTUPLE(blk));\
    ((tup) != _tupLast);\
    (tup) = (tupNext))\
        {\
        ASSERTNRNM((tup) != NULL);\
        (tupNext) = TU_NEXT(tup);

#define FOREACH_TUPLE_IN_BLOCK_BACKWARD_EDITING(tup, tupPrev, blk)\
    {\
    PTUPLE _tupLast = FG_FIRSTTUPLE(blk);\
    for ((tup) = TU_PREV(FG_LASTTUPLE(blk));\
    ((tup) != _tupLast);\
    (tup) = (tupPrev))\
        {\
        ASSERTNRNM((tup) != NULL);\
        (tupPrev) = TU_PREV(tup);

#define FOREACH_INSTR_IN_BLOCK(tup, blk)\
    for ((tup) = TU_NEXT(FG_FIRSTTUPLE(blk));\
    ((tup) != FG_LASTTUPLE(blk));\
    (tup) = TU_NEXT(tup)) {\
        if (!TU_ISINSTR(tup)) continue;

#define FOREACH_INSTR_IN_BLOCK_BACKWARD(tup, blk)\
    for ((tup) = TU_PREV(FG_LASTTUPLE(blk));\
    ((tup) != FG_FIRSTTUPLE(blk));\
    (tup) = TU_PREV(tup)) {\
        if (!TU_ISINSTR(tup)) continue;

#define NEXT_INSTR\
    }

#define FOREACH_INSTR_IN_BLOCK_EDITING(tup, tupNext, blk)\
    {\
    PTUPLE _tupLast = FG_LASTTUPLE(blk);\
    for ((tup) = TU_NEXT(FG_FIRSTTUPLE(blk));\
    ((tup) != _tupLast);\
    (tup) = (tupNext))\
        {\
        ASSERTNRNM((tup) != NULL);\
        (tupNext) = TU_NEXT(tup);\
        if (!TU_ISINSTR(tup)) continue;

#define FOREACH_INSTR_IN_BLOCK_BACKWARD_EDITING(tup, tupPrev, blk)\
    {\
    PTUPLE _tupLast = FG_FIRSTTUPLE(blk);\
    for ((tup) = TU_PREV(FG_LASTTUPLE(blk));\
    ((tup) != _tupLast);\
    (tup) = (tupPrev))\
        {\
        ASSERTNRNM((tup) != NULL);\
        (tupPrev) = TU_PREV(tup);\
        if (!TU_ISINSTR(tup)) continue;

#define NEXT_INSTR_EDITING\
        }\
    }

#define FOREACH_TUPLE_IN_FUNC(tup, func)\
    for ((tup) = FU_HEADTUPLE(func);\
    ((tup) != NULL);\
    (tup) = TU_NEXT(tup))

#define FOREACH_TUPLE_IN_FUNC_EDITING(tup, tupNext, func)\
    {\
    PTUPLE _tupLast = FU_TAILTUPLE(func);\
    for ((tup) = TU_NEXT(FU_HEADTUPLE(func));\
    ((tup) != _tupLast);\
    (tup) = (tupNext))\
        {\
        ASSERTNRNM((tup) != NULL);\
        (tupNext) = TU_NEXT(tup);

#define FOREACH_TUPLE_IN_FUNC_BACKWARD(tup, func)\
    for ((tup) = FU_TAILTUPLE(func);\
    ((tup) != NULL);\
    (tup) = TU_PREV(tup))

#define FOREACH_INSTR_IN_FUNC(tup, func)\
    for ((tup) = FU_HEADTUPLE(func);\
    ((tup) != NULL);\
    (tup) = TU_NEXT(tup)) {\
        if (!TU_ISINSTR(tup)) continue;

#define FOREACH_INSTR_IN_FUNC_EDITING(tup, tupNext, func)\
    {\
    PTUPLE _tupLast = FU_TAILTUPLE(func);\
    for ((tup) = TU_NEXT(FU_HEADTUPLE(func));\
    ((tup) != _tupLast);\
    (tup) = (tupNext))\
        {\
        ASSERTNR((tup) != NULL);\
        (tupNext) = TU_NEXT(tup);\
        if (!TU_ISINSTR(tup)) continue;

#define FOREACH_INSTR_IN_FUNC_BACKWARD(tup, func)\
    for ((tup) = FU_TAILTUPLE(func);\
    ((tup) != NULL);\
    (tup) = TU_PREV(tup)) {\
        if (!TU_ISINSTR(tup)) continue;


#define FOREACH_DST_TUPLE_EDITING(tupLeaf, tupNext, tupInst)\
    {\
    for ((tupLeaf) = TU_DST(tupInst);\
    ((tupLeaf) != NULL);\
    (tupLeaf) = (tupNext))\
        {\
        (tupNext) = TU_NEXT(tupLeaf);

#define FOREACH_SRC_TUPLE_EDITING(tupLeaf, tupNext, tupInst)\
    {\
    for ((tupLeaf) = TU_SRC(tupInst);\
    ((tupLeaf) != NULL);\
    (tupLeaf) = (tupNext))\
        {\
        (tupNext) = TU_NEXT(tupLeaf);


#define NEXT_TUPLE\
        }\
    }

#define FOREACH_TUPLE_BACKWARD(tup, tupList)\
    for ((tup) = (tupList);\
    ((tup) != NULL);\
    (tup) = TU_PREV(tup))

#define FOREACH_TUPLE_BACKWARD_EDITING(tup, tupPrev, tupList)\
    for ((tup) = (tupList);\
         (tup) != NULL ? ((tupPrev) = TU_PREV(tup), 1) : 0;\
         (tup) = (tupPrev))\

#define FOREACH_DST_TUPLE(tupLeaf, tupInst)\
    for ((tupLeaf) = TU_DST(tupInst);\
    ((tupLeaf) != NULL);\
    (tupLeaf) = TU_NEXT(tupLeaf))

#define FOREACH_SRC_TUPLE(tupLeaf, tupInst)\
    for ((tupLeaf) = TU_SRC(tupInst);\
    ((tupLeaf) != NULL);\
    (tupLeaf) = TU_NEXT(tupLeaf))

enum SRC_DST_INDEX_ENUM {
    SDX_SRC = 0, SDX_DST = 1
};

#define FOREACH_SRC_OR_DST_TUPLE(tupLeaf, tupInst)\
    {int _srcDstIndx = SDX_SRC;\
    for ((tupLeaf) = TU_SRC(tupInst);\
    ((tupLeaf) != NULL) || ((_srcDstIndx++==SDX_SRC) && (((tupLeaf) = TU_DST(tupInst)) != NULL));\
    (tupLeaf) = TU_NEXT(tupLeaf)) {

#define NEXT_SRC_OR_DST_TUPLE\
        }\
    }

enum DST_SRC_INDEX_ENUM {
    DSX_DST = 0, DSX_SRC = 1
};

#define FOREACH_DST_OR_SRC_TUPLE(tupLeaf, tupInst)\
    {int _dstSrcIndx = DSX_DST;\
    for ((tupLeaf) = TU_DST(tupInst);\
    ((tupLeaf) != NULL) || ((_dstSrcIndx++==DSX_DST) && (((tupLeaf) = TU_SRC(tupInst)) != NULL));\
    (tupLeaf) = TU_NEXT(tupLeaf)) {

#define NEXT_DST_OR_SRC_TUPLE\
        }\
    }

#define FOREACH_SRC_OR_DST_TUPLE_EDITING(tupLeaf, tupNext, tupInst)\
    {int _srcDstIndx = SDX_SRC;\
    for ((tupLeaf) = TU_SRC(tupInst);\
    (((tupLeaf) != NULL) || ((_srcDstIndx++==SDX_SRC)\
     && (((tupLeaf) = TU_DST(tupInst)) != NULL))) ? (tupNext = TU_NEXT(tupLeaf), 1) : 0;\
    (tupLeaf) = tupNext) {

#define NEXT_SRC_OR_DST_TUPLE\
        }\
    }

#define FOREACH_DST_OR_SRC_TUPLE_EDITING(tupLeaf, tupNext, tupInst)\
    {int _dstSrcIndx = DSX_DST;\
    for ((tupLeaf) = TU_DST(tupInst);\
    (((tupLeaf) != NULL) || ((_dstSrcIndx++==DSX_DST)\
     && (((tupLeaf) = TU_SRC(tupInst)) != NULL))) ? (tupNext = TU_NEXT(tupLeaf), 1) : 0;\
    (tupLeaf) = tupNext) {

#define NEXT_DST_OR_SRC_TUPLE\
        }\
    }

#define FOREACH_CASELIST_TUPLE(tupCaseList, tupSwitch)\
    for ((tupCaseList) = TU_CASELIST(tupSwitch);\
    ((tupCaseList) != NULL);\
    (tupCaseList) = TU_NEXT(tupCaseList))

#define FOREACH_BRANCHLIST_TUPLE(tupBranchList, tupLabel)\
    for ((tupBranchList) = TU_BRANCHLIST(tupLabel);\
    ((tupBranchList) != NULL);\
    (tupBranchList) = TU_NEXT(tupBranchList))

#define FOREACH_CONDSETTERLIST_TUPLE(tupCCsetList, tupBranch)\
    for ((tupCCsetList) = TU_CONDSETTERLIST(tupBranch);\
    ((tupCCsetList) != NULL);\
    (tupCCsetList) = TU_NEXT(tupCCsetList))

// Tuple insert methods.

typedef void (TUPLEINSERTMETHOD)(PTUPLE, PTUPLE);
typedef TUPLEINSERTMETHOD *PTUPLEINSERTMETHOD;

typedef PTUPLE (TUPLEREPLACELEAFMETHOD)(PTUPLE, PTUPLE, PTUPLE);
typedef TUPLEREPLACELEAFMETHOD *PTUPLEREPLACELEAFMETHOD;

#define TU_BEFORE    TupInsertBefore
#define TU_AFTER     TupInsertAfter
#define TU_LISTAFTER TupInsertListAfter

// Line offset global used by all tuple make routines
// to set line offset field in new tuples.

#ifndef NODEBUG
#define GET_TUPLINENUM(tup, func)\
    if (TU_LINEOFS(tup) != NOT_A_LINENUMBER) {\
        LineOffset = TU_LINEOFS(tup);\
        LineNumber = TU_LINEOFS(tup) + FU_BASEVLINE(func);\
        PhysLinenum = LinVirtualToPhysical(LineNumber, &PhysFilename);\
    }
#define GET_LINENUM(offset, func)\
    if (offset != NOT_A_LINENUMBER) {\
        LineOffset = offset;\
        LineNumber = offset + FU_BASEVLINE(func);\
        PhysLinenum = LinVirtualToPhysical(LineNumber, &PhysFilename);\
    }
#else
#define GET_TUPLINENUM(tup, func)\
    if (TU_LINEOFS(tup) != NOT_A_LINENUMBER) {\
        LineOffset = TU_LINEOFS(tup);\
        LineNumber = TU_LINEOFS(tup) + FU_BASEVLINE(func);\
    }
#define GET_LINENUM(offset, func)\
    if (offset != NOT_A_LINENUMBER) {\
        LineOffset = offset;\
        LineNumber = offset + FU_BASEVLINE(func);\
    }
#endif

// Miscellaneous register reference macros.

// Is this a reference to a physical register?

#define TU_ISPHYSREG(t)         (TU_ISREG(t) && SY_ISPHYSREG(TU_REG(t)))

// Is this a reference to a global register candidate?

#define TU_ISGLOBREG(t)         (TU_ISREG(t) && SY_ISGLOBREG(TU_REG(t)))

// Get the register enumeration number of this register reference.

#define TU_REGNUM(t)            (SY_REGNUM(TU_REG(t)))

// Get the machine encoding of this register reference.

#define TU_REGENC(t)            (SY_REGENCODE(TU_REG(t)))

// Get the base class register of this reg ref.

#define TU_ECREG(t)             (SY_EQUIVCLASS(TU_REG(t)))

// Get the register number of the base class register of this reg ref.

#define TU_ECREGNUM(t)          (SY_REGNUM(SY_EQUIVCLASS(TU_REG(t))))

// Get the register symbol of the base register of this indirection.

#define TU_BSREG(t)             (TU_REG(TU_BASE(t)))

// Get the register number of the base register of this indirection.

#define TU_BSREGNUM(t)          (SY_REGNUM(TU_BSREG(t)))

// Get the register encoding of the base register of this indirection.

#define TU_BSREGENC(t)          (SY_REGENCODE(TU_BSREG(t)))

// Get the register symbol of the index register of this indirection.

#define TU_IXREG(t)             (TU_REG(TU_INDEX(t)))

// Get the register number of the index register of this indirection.

#define TU_IXREGNUM(t)          (SY_REGNUM(TU_IXREG(t)))

// Get the register encoding of the index register of this indirection.

#define TU_IXREGENC(t)          (SY_REGENCODE(TU_IXREG(t)))

// Get the defining instruction from a an sdsu symbol tuple instance.

#define TU_DEF(t)               (SY_DEF(TU_SYM(t)))

struct tagTUPLIST {
    PTUPLIST next;
    PTUPLE   tuple;
};

#define TL_TUPLE(t)             ((t)->tuple)
#define TL_NEXT(t)              ((t)->next)

#define FOREACH_TUPLIST_ELEM(tl, tupList)\
    for ((tl) = (tupList);\
    (tl) != NULL;\
    (tl) = TL_NEXT(tl))

// Return TRUE if tup doesn't fall through.

#define TU_NO_FALLTHROUGH(tup) (TU_ISINSTR(tup) && !TupHasFallThrough(tup))
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\typelist.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
#if TRACK_GC_REFS
#define GCS  EA_GCREF
#define BRS  EA_BYREF
#else
#define GCS  4
#define BRS  4
#endif

#if TGT_IA64
#define __STK_I TYP_LONG
#define ADD_I(x)    x|VTF_I
#else
#define __STK_I TYP_INT
#define ADD_I(x)    x
#endif

/*  tn  - TYP_name
    nm  - name string
    jitType - The jit compresses types that are 'equivalent', this is the jit type
    sz  - size in bytes
    sze - size in bytes for the emitter (GC types are encoded)
    asze- size in bytes for the emitter (GC types are encoded) for the genActualType()
    st  - stack slots (slots are sizeof(void*) bytes)
    al  - alignment
    tf  - flags
    howUsed - If a variable is used (referenced) as the type

DEF_TP(tn      ,nm        , jitType,    sz, sze,asze,st,al, tf,            howUsed     )
*/

DEF_TP(UNDEF   ,"<UNDEF>" , TYP_UNDEF,   0,  0,  0,  0, 0, VTF_ANY,        0           )
DEF_TP(VOID    ,"void"    , TYP_VOID,    0,  0,  0,  0, 0, VTF_ANY,        0           )

DEF_TP(BOOL    ,"boolean" , __STK_I,     1,  1,  4,  1, 1, VTF_INT,        TYPE_REF_INT)

DEF_TP(BYTE    ,"byte"    , __STK_I,     1,  1,  4,  1, 1, VTF_INT,        TYPE_REF_INT)
DEF_TP(UBYTE   ,"ubyte"   , __STK_I,     1,  1,  4,  1, 1, VTF_INT|VTF_UNS,TYPE_REF_INT)

DEF_TP(SHORT   ,"short"   , __STK_I,     2,  2,  4,  1, 2, VTF_INT,        TYPE_REF_INT)
DEF_TP(CHAR    ,"char"    , __STK_I,     2,  2,  4,  1, 2, VTF_INT|VTF_UNS,TYPE_REF_INT)

DEF_TP(INT     ,"int"     , __STK_I,     4,  4,  4,  1, 4, VTF_INT|VTF_I,  TYPE_REF_INT)
DEF_TP(LONG    ,"long"    , TYP_LONG,    8,  4,  4,  2, 8, ADD_I(VTF_INT), TYPE_REF_LNG)

DEF_TP(FLOAT   ,"float"   , TYP_FLOAT,   4,  4,  4,  1, 4, VTF_FLT,        TYPE_REF_FLT)
DEF_TP(DOUBLE  ,"double"  , TYP_DOUBLE,  8,  4,  4,  2, 8, VTF_FLT,        TYPE_REF_DBL)

DEF_TP(REF     ,"ref"     , TYP_REF,     4,GCS,GCS,  1, 4, VTF_ANY|VTF_GCR|VTF_I,TYPE_REF_PTR)
DEF_TP(BYREF   ,"byref"   , TYP_BYREF,   4,BRS,BRS,  1, 4, VTF_ANY|VTF_BYR|VTF_I,TYPE_REF_BYR)
DEF_TP(ARRAY   ,"array"   , TYP_REF,     4,GCS,GCS,  1, 4, VTF_ANY|VTF_GCR|VTF_I,TYPE_REF_PTR)
DEF_TP(STRUCT  ,"struct"  , TYP_STRUCT,  0,  0,  0,  1, 4, VTF_ANY,        TYPE_REF_STC)

DEF_TP(BLK     ,"blk"     , TYP_BLK,     0,  0,  0,  1, 4, VTF_ANY,        0           ) // blob of memory
DEF_TP(LCLBLK  ,"lclBlk"  , TYP_LCLBLK,  0,  0,  0,  1, 4, VTF_ANY,        0           ) // preallocated memory for locspace

DEF_TP(PTR     ,"pointer" , TYP_PTR,     4,  4,  4,  1, 4, VTF_ANY|VTF_I,        TYPE_REF_PTR) // (not currently used)
DEF_TP(FNC     ,"function", TYP_FNC,     0,  4,  4,  0, 0, VTF_ANY|VTF_I,        0           )

DEF_TP(UINT    ,"uint"    , __STK_I,     4,  4,  4,  1, 4, VTF_INT|VTF_UNS|VTF_I,TYPE_REF_INT) // Only used in GT_CAST nodes
DEF_TP(ULONG   ,"ulong"   , TYP_LONG,    8,  4,  4,  2, 8, ADD_I(VTF_INT|VTF_UNS),TYPE_REF_LNG) // Only used in GT_CAST nodes

DEF_TP(UNKNOWN ,"unknown" ,TYP_UNKNOWN,  0,  0,  0,  0, 0, VTF_ANY,        0           )

#undef  GCS
#undef  BRS
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\vcver.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
#ifndef _VC_VER_INC
#define _VC_VER_INC
#ifndef _VC_VER
#define _VC_VER 550
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\vartype.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef _VARTYPE_H_
#define _VARTYPE_H_
/*****************************************************************************/


enum    var_types_classification
{
    VTF_ANY = 0x0000,
    VTF_INT = 0x0001,
    VTF_UNS = 0x0002,   // type is unsigned
    VTF_FLT = 0x0004,
    VTF_GCR = 0x0008,   // type is GC ref
    VTF_BYR = 0x0010,   // type is Byref
    VTF_I   = 0x0020,   // is machine sized
};

enum    var_types
{
    #define DEF_TP(tn,nm,jitType,sz,sze,asze,st,al,tf,howUsed) TYP_##tn,
    #include "typelist.h"
    #undef  DEF_TP

    TYP_COUNT,

    TYP_lastIntrins = TYP_DOUBLE
};

#ifdef  FAST
typedef NatUns      varType_t;
#else
typedef var_types   varType_t;
#endif

/*****************************************************************************/

#if TGT_IA64
#define TYP_NAT_INT     TYP_LONG
#else
#define TYP_NAT_INT     TYP_INT
#endif

/*****************************************************************************/

extern  BYTE        varTypeClassification[TYP_COUNT];

inline  bool        varTypeIsIntegral  (varType_t vt)
{
    return  ((varTypeClassification[vt] & (VTF_INT)                ) != 0);
}

inline  bool        varTypeIsUnsigned  (varType_t vt)
{
    return  ((varTypeClassification[vt] & (VTF_UNS)                ) != 0);
}

inline  bool        varTypeIsScalar    (varType_t vt)
{
    return  ((varTypeClassification[vt] & (VTF_INT|VTF_GCR|VTF_BYR)) != 0);
}

inline  bool        varTypeIsFloating  (varType_t vt)
{
    return  ((varTypeClassification[vt] & (VTF_FLT)                ) != 0);
}

inline  bool        varTypeIsArithmetic(varType_t vt)
{
    return  ((varTypeClassification[vt] & (VTF_INT|VTF_FLT)        ) != 0);
}

inline unsigned      varTypeGCtype     (varType_t vt)
{
    return  (unsigned)(varTypeClassification[vt] & (VTF_GCR|VTF_BYR));
}

inline bool         varTypeIsGC        (varType_t vt)
{
    return  (varTypeGCtype(vt) != 0);
}

inline bool         varTypeIsI        (varType_t vt)
{
    return          ((varTypeClassification[vt] & VTF_I) != 0);
}

/*****************************************************************************/
#endif
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\__file__.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
#ifdef _DEBUG
#define VER_FILEFLAGS           VS_FF_DEBUG
#else
#define VER_FILEFLAGS           VS_FF_SPECIALBUILD
#endif

#define VER_FILETYPE            VFT_DLL
#define VER_INTERNALNAME_STR    "MSCORJIT.DLL"
#define VER_FILEDESCRIPTION_STR "Microsoft COM Runtime Just-In-Time Compiler\0"
#define VER_ORIGFILENAME_STR    "mscorjit.dll\0"
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\utils.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                                  Utils.cpp                                XX
XX                                                                           XX
XX   Has miscellaneous utility functions                                     XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/


#include "jitpch.h"
#pragma hdrstop

#include "opcode.h"

#ifndef NOT_JITC
STDAPI          CoInitializeEE(DWORD fFlags) { return(ERROR_SUCCESS); }
STDAPI_(void)   CoUninitializeEE(BOOL fFlags) {}
#endif

extern
signed char         opcodeSizes[] =
{
    #define InlineNone_size           0
    #define ShortInlineVar_size       1
    #define InlineVar_size            2
    #define ShortInlineI_size         1
    #define InlineI_size              4
    #define InlineI8_size             8
    #define ShortInlineR_size         4
    #define InlineR_size              8
    #define ShortInlineBrTarget_size  1
    #define InlineBrTarget_size       4
    #define InlineMethod_size         4
    #define InlineField_size          4
    #define InlineType_size               4
    #define InlineString_size             4
    #define InlineSig_size            4
    #define InlineRVA_size            4
    #define InlineTok_size            4
    #define InlineSwitch_size         0       // for now
    #define InlinePhi_size            0       // for now
        #define InlineVarTok_size                 0               // remove

    #define OPDEF(name,string,pop,push,oprType,opcType,l,s1,s2,ctrl) oprType ## _size ,
    #include "opcode.def"
    #undef OPDEF

    #undef InlineNone_size
    #undef ShortInlineVar_size
    #undef InlineVar_size
    #undef ShortInlineI_size
    #undef InlineI_size
    #undef InlineI8_size
    #undef ShortInlineR_size
    #undef InlineR_size
    #undef ShortInlineBrTarget_size
    #undef InlineBrTarget_size
    #undef InlineMethod_size
    #undef InlineField_size
    #undef InlineType_size
    #undef InlineString_size
    #undef InlineSig_size
    #undef InlineRVA_size
    #undef InlineTok_size
    #undef InlineSwitch_size
    #undef InlinePhi_size
};



#if COUNT_OPCODES || defined(DEBUG)

extern
const   char *      opcodeNames[] =
{
    #define OPDEF(name,string,pop,push,oprType,opcType,l,s1,s2,ctrl) string,
    #include "opcode.def"
    #undef  OPDEF
};

#endif

#ifdef DUMPER

extern
BYTE                opcodeArgKinds[] =
{
    #define OPDEF(name,string,pop,push,oprType,opcType,l,s1,s2,ctrl) (BYTE) oprType,
    #include "opcode.def"
    #undef  OPDEF
};

#endif


BYTE                varTypeClassification[] =
{
    #define DEF_TP(tn,nm,jitType,sz,sze,asze,st,al,tf,howUsed) tf,
    #include "typelist.h"
    #undef  DEF_TP
};

/*****************************************************************************/

const   char *      varTypeName(var_types vt)
{
    static
    const   char *      varTypeNames[] =
    {
        #define DEF_TP(tn,nm,jitType,sz,sze,asze,st,al,tf,howUsed) nm,
        #include "typelist.h"
        #undef  DEF_TP
    };

    assert(vt < sizeof(varTypeNames)/sizeof(varTypeNames[0]));

    return  varTypeNames[vt];
}

/*****************************************************************************/
#ifndef NOT_JITC
/*****************************************************************************
 *
 *  Skip the mangled type at 'str'.
 */

const   char *      genSkipTypeString(const char *str)
{

AGAIN:

    switch (*str++)
    {
    case '[':
        if  (*str >= '0' && *str <= '9')
        {
            assert(!"ISSUE: skip array dimension (is this ever present, anyway?)");
        }
        goto AGAIN;

    case 'L':
        while (*str != ';')
            str++;
        str++;
        break;

    default:
        break;
    }

    return  str;
}

/*****************************************************************************
 *
 *  Return the TYP_XXX value equivalent of a constant pool type string.
 */

var_types           genVtypOfTypeString(const char *str)
{
    switch (*str)
    {
    case 'B': return TYP_BYTE  ;
    case 'C': return TYP_CHAR  ;
    case 'D': return TYP_DOUBLE;
    case 'F': return TYP_FLOAT ;
    case 'I': return TYP_INT   ;
    case 'J': return TYP_LONG  ;
    case 'S': return TYP_SHORT ;
    case 'Z': return TYP_BOOL  ;
    case 'V': return TYP_VOID  ;
    case 'L': return TYP_REF   ;
    case '[': return TYP_ARRAY ;
    case '(': return TYP_FNC   ;

    default:
        assert(!"unexpected type code");
        return TYP_UNDEF;
    }
}

/*****************************************************************************/
#endif //NOT_JITC
/*****************************************************************************/
#ifdef DEBUG
/*****************************************************************************
 *
 *  Return the name of the given register.
 */

const   char *      getRegName(unsigned reg)
{
    static
    const char *    regNames[] =
    {
        #if     TGT_x86
        #define REGDEF(name, rnum, mask, byte) #name,
        #include "register.h"
        #undef  REGDEF
        #endif

        #if     TGT_SH3
        #define REGDEF(name, strn, rnum, mask)  strn,
        #include "regSH3.h"
        #undef  REGDEF
        #endif

        #if     TGT_IA64
        #define REGDEF(name, strn)              strn,
        #include "regIA64.h"
        #undef  REGDEF
        #endif
    };

    assert(reg < sizeof(regNames)/sizeof(regNames[0]));

    return  regNames[reg];
}

/*****************************************************************************
 *
 *  Displays a register set.
 */

#if!TGT_IA64

void                dspRegMask(regMaskTP regMask, size_t minSiz)
{
    const   char *  sep = "";

    printf("[");

    #define dspRegBit(reg,bit)                          \
                                                        \
        if  (isNonZeroRegMask(regMask & bit))           \
        {                                               \
            const   char *  nam = getRegName(reg);      \
            printf("%s%s", sep, nam);                   \
            minSiz -= (strlen(sep) + strlen(nam));      \
            sep = " ";                                  \
        }

#if TGT_x86

    #define dspOneReg(reg)  dspRegBit(REG_##reg, RBM_##reg)

    dspOneReg(EAX);
    dspOneReg(EDX);
    dspOneReg(ECX);
    dspOneReg(EBX);
    dspOneReg(EBP);
    dspOneReg(ESI);
    dspOneReg(EDI);

#else

    for (unsigned reg = 0; reg < REG_COUNT; reg++)
        dspRegBit(reg, genRegMask((regNumber)reg));

#endif

    printf("]");

    while ((int)minSiz > 0)
    {
        printf(" ");
        minSiz--;
    }
}

#endif

unsigned
dumpSingleILopcode(const BYTE * codeAddr, IL_OFFSET offs, const char * prefix)
{
    const BYTE  *        opcodePtr = codeAddr + offs;
    const BYTE  *   startOpcodePtr = opcodePtr;

    if( prefix!=NULL)
        printf("%s", prefix);

    OPCODE      opcode = OPCODE(getU1LittleEndian(opcodePtr));
    opcodePtr += sizeof(__int8);

DECODE_OPCODE:

    /* Get the size of additional parameters */

    size_t      sz      = opcodeSizes   [opcode];
    unsigned    argKind = opcodeArgKinds[opcode];

    /* See what kind of an opcode we have, then */

    switch (opcode)
    {
        case CEE_PREFIX1:
			opcode = OPCODE(getU1LittleEndian(opcodePtr) + 256);
            opcodePtr += sizeof(__int8);
            goto DECODE_OPCODE;

        default:
        {

            printf("%-12s ", opcodeNames[opcode]);

            __int64     iOp;
            double      dOp;
            DWORD       jOp;

            switch(argKind)
            {
            case InlineNone    :   break;

            case ShortInlineVar  :   iOp  = getU1LittleEndian(opcodePtr);  goto INT_OP;
            case ShortInlineI    :   iOp  = getI1LittleEndian(opcodePtr);  goto INT_OP;
            case InlineVar       :   iOp  = getU2LittleEndian(opcodePtr);  goto INT_OP;
            case InlineTok       :
            case InlineMethod    :
            case InlineField     :
            case InlineType      :
            case InlineString    :
            case InlineSig       :
            case InlineI                 :   iOp  = getI4LittleEndian(opcodePtr);  goto INT_OP;
            case InlineI8        :   iOp  = getU4LittleEndian(opcodePtr);
                                    iOp |= getU4LittleEndian(opcodePtr) >> 32;
                                    goto INT_OP;

        INT_OP                  :   printf("0x%X", iOp);
                                    break;

            case ShortInlineR   :   dOp  = getR4LittleEndian(opcodePtr);  goto FLT_OP;
            case InlineR   :   dOp  = getR8LittleEndian(opcodePtr);  goto FLT_OP;

        FLT_OP                  :   printf("%f", dOp);
                                    break;

            case ShortInlineBrTarget:  jOp  = getI1LittleEndian(opcodePtr);  goto JMP_OP;
            case InlineBrTarget:  jOp  = getI4LittleEndian(opcodePtr);  goto JMP_OP;

        JMP_OP                  :   printf("0x%X (abs=0x%X)", jOp,
                                            (opcodePtr - startOpcodePtr) + jOp);
                                    break;

            case InlineSwitch:
                jOp = getU4LittleEndian(opcodePtr); opcodePtr += 4;
                opcodePtr += jOp * 4; // Jump over the table
                break;

            case InlinePhi:
                jOp = getU1LittleEndian(opcodePtr); opcodePtr += 1;
                opcodePtr += jOp * 2; // Jump over the table
                break;

            default         : assert(!"Bad argKind");
            }

            opcodePtr += sz;
            break;
        }
    }

    printf("\n");
    return opcodePtr - startOpcodePtr;
}

/*****************************************************************************/
#endif // DEBUG
/*****************************************************************************
 *
 *  Display a variable set (which may be a 32-bit or 64-bit number); only
 *  one or two of these can be used at once.
 */

#ifdef  DEBUG

const   char *      genVS2str(VARSET_TP set)
{
    static
    char            num1[17];

    static
    char            num2[17];

    static
    char    *       nump = num1;

    char    *       temp = nump;

    nump = (nump == num1) ? num2
                          : num1;

#if VARSET_SZ == 32
    sprintf(temp, "%08X", set);
#else
    sprintf(temp, "%08X%08X", (int)(set >> 32), (int)set);
#endif

    return  temp;
}

#endif

/*****************************************************************************
 *
 *  Maps a variable index onto a value with the appropriate bit set.
 */

unsigned short      genVarBitToIndex(VARSET_TP bit)
{
    assert (genOneBitOnly(bit));

    /* Use a prime bigger than sizeof(VARSET_TP) and which is not of the
       form 2^n-1. modulo with this will produce a unique hash for all
       powers of 2 (which is what "bit" is).
       Entries in hashTable[] which are -1 should never be used. There
       should be HASH_NUM-8*sizeof(bit)* entries which are -1 .
     */

    const unsigned HASH_NUM = 67;

    static const char hashTable[HASH_NUM] =
    {
        -1,  0,  1, 39,  2, 15, 40, 23,  3, 12,
        16, 59, 41, 19, 24, 54,  4, -1, 13, 10,
        17, 62, 60, 28, 42, 30, 20, 51, 25, 44,
        55, 47,  5, 32, -1, 38, 14, 22, 11, 58,
        18, 53, 63,  9, 61, 27, 29, 50, 43, 46,
        31, 37, 21, 57, 52,  8, 26, 49, 45, 36,
        56,  7, 48, 35,  6, 34, 33
    };

    assert(HASH_NUM >= 8*sizeof(bit));
    assert(!genOneBitOnly(HASH_NUM+1));
    assert(sizeof(hashTable) == HASH_NUM);

    unsigned hash   = unsigned(bit % HASH_NUM);
    unsigned index  = hashTable[hash];
    assert(index != (char)-1);

    return index;
}

/*****************************************************************************
 *
 *  Given a value that has exactly one bit set, return the position of that
 *  bit, in other words return the logarithm in base 2 of the given value.
 */

unsigned            genLog2(unsigned value)
{
    unsigned        power;

    static
    BYTE            powers[16] =
    {
        0,  //  0
        1,  //  1
        2,  //  2
        0,  //  3
        3,  //  4
        0,  //  5
        0,  //  6
        0,  //  7
        4,  //  8
        0,  //  9
        0,  // 10
        0,  // 11
        0,  // 12
        0,  // 13
        0,  // 14
        0,  // 15
    };

#if 0
    int i,m;

    for (i = 1, m = 1; i <= VARSET_SZ; i++, m <<=1 )
    {
        if  (genLog2(m) != i)
            printf("Error: log(%u) returns %u instead of %u\n", m, genLog2(m), i);
    }
#endif

    assert(value && genOneBitOnly(value));

    power = 0;

    if  ((value & 0xFFFF) == 0)
    {
        value >>= 16;
        power  += 16;
    }

    if  ((value & 0xFF00) != 0)
    {
        value >>= 8;
        power  += 8;
    }

    if  ((value & 0x000F) != 0)
        return  power + powers[value];
    else
        return  power + powers[value >> 4] + 4;
}

/*****************************************************************************
 *
 *  getEERegistryDWORD - finds a value entry of type DWORD in the EE registry key.
 *  Return the value if entry exists, else return default value.
 *
 *        valueName  - Value to look up
 *        defaultVal - name says it all
 */

static const TCHAR szJITsubKey[] = TEXT(FRAMEWORK_REGISTRY_KEY);

/*****************************************************************************/

DWORD               getEERegistryDWORD(const TCHAR *valueName,
                                       DWORD        defaultVal)
{
    HKEY    hkeySubKey;
    DWORD   dwValue;
    LONG    lResult;

        TCHAR envName[64];
        TCHAR valBuff[32];
        if(strlen(valueName) > 64 - 1 - 8)
                return(0);
        strcpy(envName, "COMPlus_");
        strcpy(&envName[8], valueName);
    lResult = GetEnvironmentVariableA(envName, valBuff, 32);
        if (lResult != 0) {
                TCHAR* endPtr;
                DWORD rtn = strtol(valBuff, &endPtr, 16);               // treat it has hex
                if (endPtr != valBuff)                                                  // success
                        return(rtn);
        }

    assert(valueName  != NULL);

    // Open key.

    lResult = RegOpenKeyEx(HKEY_CURRENT_USER, szJITsubKey, 0, KEY_QUERY_VALUE,
                           &hkeySubKey);

    if (lResult == ERROR_SUCCESS)
    {
        DWORD dwType;
        DWORD dwcbValueLen = sizeof(DWORD);

        // Determine value length.

        lResult = RegQueryValueEx(hkeySubKey, valueName, NULL, &dwType,
                                  (PBYTE)&dwValue, &dwcbValueLen);

        if (lResult == ERROR_SUCCESS)
        {
            if (dwType == REG_DWORD && dwcbValueLen == sizeof(DWORD))
                defaultVal = dwValue;
        }

        RegCloseKey(hkeySubKey);
    }

    if (lResult != ERROR_SUCCESS)
    {
        lResult = RegOpenKeyEx(HKEY_LOCAL_MACHINE, szJITsubKey, 0,
                               KEY_QUERY_VALUE, &hkeySubKey);

        if (lResult == ERROR_SUCCESS)
        {
            DWORD dwType;
            DWORD dwcbValueLen = sizeof(DWORD);

            // Determine value length.

            lResult = RegQueryValueEx(hkeySubKey, valueName, NULL, &dwType,
                                      (PBYTE)&dwValue, &dwcbValueLen);

            if (lResult == ERROR_SUCCESS)
            {
                if (dwType == REG_DWORD && dwcbValueLen == sizeof(DWORD))
                    defaultVal = dwValue;
            }

            RegCloseKey(hkeySubKey);
        }
    }

    return defaultVal;
}


/*****************************************************************************/

bool                getEERegistryString(const TCHAR *   valueName,
                                        TCHAR *         buf,        /* OUT */
                                        unsigned        bufSize)
{
    HKEY    hkeySubKey;
    LONG    lResult;

    assert(valueName  != NULL);

        TCHAR envName[64];
        if(strlen(valueName) > 64 - 1 - 8)
                return(0);
        strcpy(envName, "COMPlus_");
        strcpy(&envName[8], valueName);

    lResult = GetEnvironmentVariableA(envName, buf, bufSize);
        if (lResult != 0 && *buf != 0)
                return(true);

    // Open key.
    lResult = RegOpenKeyEx(HKEY_CURRENT_USER, szJITsubKey, 0, KEY_QUERY_VALUE,
                           &hkeySubKey);

    if (lResult != ERROR_SUCCESS)
        return false;

    DWORD   dwType, dwcbValueLen = bufSize;

    // Determine value length.

    lResult = RegQueryValueEx(hkeySubKey, valueName, NULL, &dwType,
                              (PBYTE)buf, &dwcbValueLen);

    bool result = false;

    if ((lResult == ERROR_SUCCESS) && (dwType == REG_SZ))
    {
        assert(dwcbValueLen < bufSize);

        result = true;
    }
    else if (bufSize)
    {
        buf[0] = '\0';
    }

    RegCloseKey(hkeySubKey);

    return result;
}

/*****************************************************************************
 *  Parses the registry value which should be of the forms :
 *  class:method, *:method, class:*, *:*, method, *
 *  Returns true if the value is present, and the format is good
 */

bool                getEERegistryMethod(const TCHAR * valueName,
                                        TCHAR * methodBuf /*OUT*/ , size_t methodBufSize,
                                        TCHAR * classBuf  /*OUT*/ , size_t classBufSize)
{
    /* In case we bail, set these to empty strings */

    methodBuf[0] = classBuf[0] = '\0';

    /* Read the value from the registry */

    TCHAR value[200];

    if (getEERegistryString(valueName, value, sizeof(value)) == false)
        return false;

    /* Divide it using ":" as a separator */

    char * str1, * str2, * str3;

    str1 = strtok (value, ":");
    str2 = strtok (NULL,  ":");
    str3 = strtok (NULL,  ":");

    /* If we dont have a single substring, or more than 2 substrings, ignore */

    if (!str1 || str3)
        return false;

    if (str2 == NULL)
    {
        /* We have yyyy. Use this as *:yyyy */

        strcpy(classBuf,  "*" );
        strcpy(methodBuf, str1);
    }
    else
    {
        /* We have xxx:yyyyy. So className=xxx and methodName=yyyy */

        strcpy (classBuf,  str1);
        strcpy (methodBuf, str2);
    }

    return true;
}

/*****************************************************************************
 *  curClass_inc_package/curMethod is the fully qualified name of a method.
 *  regMethod and regClass are read in getEERegistryMethod()
 *
 *  Return true if curClass/curMethod fits the regular-expression defined by
 *  regClass+regMethod.
 */

bool                cmpEERegistryMethod(const TCHAR * regMethod, const TCHAR * regClass,
                                        const TCHAR * curMethod, const TCHAR * curClass)
{
    assert(regMethod && regClass && curMethod && curClass);
    assert(!regMethod[0] == !regClass[0]); // Both empty, or both non-empty

    /* There may not have been a registry value, then return false */

    if (!regMethod[0])
        return false;

    /* See if we have atleast a method name match */

    if (strcmp(regMethod, "*") != 0 && strcmp(regMethod, curMethod) != 0)
        return false;

    /* Now the class can be 1) "*",  2) an exact match, or  3) a match
       excluding the package -  to succeed */

    // 1)
    if (strcmp(regClass, "*") == 0)
        return true;

    // 2)
    if (strcmp(regClass, curClass) == 0)
        return true;

    /* 3) The class name in the registry may not include the package, so
          try to match curClass excluding the package part to "regClass" */

    const TCHAR * curNameLeft   = curClass; // chops off the package names

    for (const TCHAR * curClassIter = curClass;
         *curClassIter != '\0';
         curClassIter++)
    {
        // @Todo: this file doens't include utilcode or anything else required
        // to make the nsutilpriv.h work.  Check with jit team to see if they
        // care if it is added.
        if (*curClassIter == '.' /*NAMESPACE_SEPARATOR_CHAR*/)
            curNameLeft = curClassIter + 1;
    }

    if (strcmp(regClass, curNameLeft) == 0)
        return true;

    // Neither 1) nor 2) nor 3) means failure

    return false;
}

/*****************************************************************************/

#if defined(DEBUG) || !defined(NOT_JITC)

histo::histo(unsigned * sizeTab, unsigned sizeCnt)
{
    if  (!sizeCnt)
    {
        do
        {
            sizeCnt++;
        }
        while(sizeTab[sizeCnt]);
    }

    histoSizCnt = sizeCnt;
    histoSizTab = sizeTab;

    histoCounts = new unsigned[sizeCnt+1];

    histoClr();
}

histo::~histo()
{
    delete [] histoCounts;
}

void                histo::histoClr()
{
    memset(histoCounts, 0, (histoSizCnt+1)*sizeof(*histoCounts));
}

void                histo::histoDsp()
{
    unsigned        i;
    unsigned        c;
    unsigned        t;

    for (i = t = 0; i <= histoSizCnt; i++)
        t += histoCounts[i];

    for (i = c = 0; i <= histoSizCnt; i++)
    {
        if  (i == histoSizCnt)
        {
            if  (!histoCounts[i])
                break;

            printf("    >     %6u", histoSizTab[i-1]);
        }
        else
        {
            if (i == 0)
            {
                printf("    <=    ");
            }
            else
                printf("%6u .. ", histoSizTab[i-1]+1);

            printf("%6u", histoSizTab[i]);
        }

        c += histoCounts[i];

        printf(" ===> %6u count (%3u%% of total)\n", histoCounts[i], (int)(100.0*c/t));
    }
}

void                histo::histoRec(unsigned siz, unsigned cnt)
{
    unsigned        i;
    unsigned    *   t;

    for (i = 0, t = histoSizTab;
         i < histoSizCnt;
         i++  , t++)
    {
        if  (*t >= siz)
            break;
    }

    histoCounts[i] += cnt;
}

#endif // defined(DEBUG) || !defined(NOT_JITC)

#ifdef NOT_JITC

bool                IsNameInProfile(const TCHAR *   methodName,
                                    const TCHAR *    className,
                                    const TCHAR *    regKeyName)
{
    TCHAR   fileName[100];
    TCHAR   methBuf[1000];

    /* Get the file containing the list of methods to exclude */
    if  (!getEERegistryString(regKeyName, fileName, sizeof(fileName)))
        return false;

    /* Get the list of methods for the given class */
    if (GetPrivateProfileSection(className, methBuf, sizeof(methBuf), fileName))
    {
        char *  p = methBuf;

        while (*p)
        {
            /* Check for wild card or method name */
            if  (!strcmp(p, "*"))
                return true;

            if  (!strcmp(p, methodName))
                return true;

            /* Advance to next token */
            while (*p)
                *p++;

            /* skip zero */
            *p++;
        }
    }

    return false;
}

#endif  //NOT_JITC
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\ia64\version.c ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
const   char *      COMPILER_VERSION = "0.90.2015";
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\il\alloc.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/

#include "jitpch.h"
#pragma hdrstop

/*****************************************************************************/

#include "alloc.h"

#include "PerfAlloc.h"

#ifdef PERFALLOC
BOOL                PerfUtil::g_PerfAllocHeapInitialized = FALSE;
LONG                PerfUtil::g_PerfAllocHeapInitializing = 0;
PerfAllocVars       PerfUtil::g_PerfAllocVariables;

BOOL PerfVirtualAlloc::m_fPerfVirtualAllocInited = FALSE;
PerfBlock* PerfVirtualAlloc::m_pFirstBlock = 0;
PerfBlock* PerfVirtualAlloc::m_pLastBlock = 0;
DWORD PerfVirtualAlloc::m_dwEnableVirtualAllocStats = 0;

#endif // #if defined PERFALLOC

/*****************************************************************************/
void                allocatorCodeSizeBeg(){}
/*****************************************************************************/
#ifdef  DEBUG
/*****************************************************************************/

void    __cdecl     debugStop(const char *why, ...)
{
    va_list     args; va_start(args, why);

#ifndef _WIN32_WCE

    printf("NOTIFICATION: ");
    if  (why)
        vprintf(why, args);
    else
        printf("debugStop(0)");

    printf("\n");

#endif

    BreakIfDebuggerPresent();
}

/*****************************************************************************/

static  unsigned    blockStop    = 99999999;

/*****************************************************************************/
#endif//DEBUG
/*****************************************************************************/

bool        norls_allocator::nraInit(size_t pageSize, int preAlloc)
{
    bool    result = false;

    nraRetNull   = true;

    nraPageList  =
    nraPageLast  = 0;

    nraFreeNext  =
    nraFreeLast  = 0;

    nraPageSize  = pageSize ? pageSize
                            : 16*OS_page_size;      // anything less than 64K leaves VM holes since the OS
                                                    // allocates address space in this size.  
                                                    // Thus if we want to make this smaller, we need to do
                                                    // a reserve / commit scheme

    if  (preAlloc)
    {
        /* Grab the initial page(s) */

        setErrorTrap()  // ERROR TRAP: Start normal block
        {
            nraAllocNewPage(0);
        }
        impJitErrorTrap()  // ERROR TRAP: The following block handles errors
        {
            result = true;
        }
        endErrorTrap()  // ERROR TRAP: End
    }

    return  result;
}

bool        norls_allocator::nraStart(size_t initSize, size_t pageSize)
{
    /* Add the page descriptor overhead to the required size */

    initSize += offsetof(norls_pagdesc, nrpContents);

    /* Round the initial size to a OS page multiple */

    initSize +=  (OS_page_size - 1);
    initSize &= ~(OS_page_size - 1);

    /* Initialize the allocator by allocating one big page */

    if  (nraInit(initSize))
        return  true;

    /* Now go back to the 'true' page size */

    nraPageSize  = pageSize ? pageSize
                            : 4*OS_page_size;

    return  false;
}

/*---------------------------------------------------------------------------*/

void    *   norls_allocator::nraAllocNewPage(size_t sz)
{
    norls_pagdesc * newPage;
    size_t          sizPage;

    /* Do we have a page that's now full? */

    if  (nraPageLast)
    {
        /* Undo the "+=" done in nraAlloc() */

        nraFreeNext -= sz;

        /* Save the actual used size of the page */

        nraPageLast->nrpUsedSize = nraFreeNext - nraPageLast->nrpContents;
    }

    /* Make sure we grab enough to satisfy the allocation request */

    sizPage = nraPageSize;

    if  (sizPage < sz + sizeof(norls_pagdesc))
    {
        /* The allocation doesn't fit in a default-sized page */

#ifdef  DEBUG
//      if  (nraPageLast) printf("NOTE: wasted %u bytes in last page\n", nraPageLast->nrpPageSize - nraPageLast->nrpUsedSize);
#endif

        sizPage = sz + sizeof(norls_pagdesc);
    }

    /* Round to the nearest multiple of OS page size */

    sizPage +=  (OS_page_size - 1);
    sizPage &= ~(OS_page_size - 1);

    /* Allocate the new page */

    newPage = (norls_pagdesc *)VirtualAlloc(0, sizPage, MEM_COMMIT, PAGE_READWRITE);
    if  (!newPage)
        NOMEM();

#if 0
#ifdef DEBUG

    if  (this == &stmt_cmp::scAlloc)
        printf("StmtCmp");
    else if (this == &stmtExpr::sxAlloc)
        printf("StmtExp");
    else
        printf("Other  ");

    printf(": get  page at %08X (%u bytes)\n", newPage, nraPageSize);

#endif
#endif

#ifdef DEBUG
    newPage->nrpSelfPtr = newPage;
#endif

    /* Append the new page to the end of the list */

    newPage->nrpNextPage = 0;
    newPage->nrpPageSize = sizPage;
    newPage->nrpPrevPage = nraPageLast;

    if  (nraPageLast)
        nraPageLast->nrpNextPage = newPage;
    else
        nraPageList              = newPage;
    nraPageLast = newPage;

    /* Set up the 'next' and 'last' pointers */

    nraFreeNext = newPage->nrpContents + sz;
    nraFreeLast = newPage->nrpPageSize + (BYTE *)newPage;

    assert(nraFreeNext <= nraFreeLast);

    return  newPage->nrpContents;
}

void        norls_allocator::nraDone(void)
{
    /* Do nothing if we have no pages at all */

    if  (!nraPageList)
        return;

    /* We'll release all but the very first page */

    for (;;)
    {
        norls_pagdesc * temp;

        /* Get the next page, and stop if there aren't any more */

        temp = nraPageList->nrpNextPage;
        if  (!temp)
            break;

        /* Remove the next page from the list */

        nraPageList->nrpNextPage = temp->nrpNextPage;

#if 0
#ifdef DEBUG

        if  (this == &stmt_cmp::scAlloc)
            printf("StmtCmp");
        else if (this == &stmtExpr::sxAlloc)
            printf("StmtExp");
        else
            printf("Unknown");

        printf(": done page at %08X\n", temp);

#endif
#endif


        VirtualFree(temp, 0, MEM_RELEASE);
    }

    /* We now have exactly one page */

    nraPageLast = nraPageList;

    assert(nraPageList->nrpPrevPage == 0);
    assert(nraPageList->nrpNextPage == 0);

    /* Reset the pointers, the whole page is free now */

    nraFreeNext  = nraPageList->nrpContents;
    nraFreeLast  = nraPageList->nrpPageSize + (BYTE *)nraPageList;

#ifdef DEBUG
    memset(nraFreeNext, 0xDD, nraFreeLast - nraFreeNext);
#endif
}

void        norls_allocator::nraFree(void)
{
    /* Free all of the allocated pages */

    while   (nraPageList)
    {
        norls_pagdesc * temp;

        temp = nraPageList;
               nraPageList = temp->nrpNextPage;

#if 0
#ifdef DEBUG

        if  (this == &stmt_cmp::scAlloc)
            printf("StmtCmp");
        else if (this == &stmtExpr::sxAlloc)
            printf("StmtExp");
        else
            printf("Unknown");

        printf(": free page at %08X\n", temp);

#endif
#endif


        VirtualFree(temp, 0, MEM_RELEASE);
    }
}

#ifdef DEBUG
static
unsigned maxSize = 0;
#endif
void        norls_allocator::nraToss(nraMarkDsc &mark)
{
    void    *   last = mark.nmPage;

    if  (!last)
    {
        if  (!nraPageList)
            return;

        nraFreeNext  = nraPageList->nrpContents;
        nraFreeLast  = nraPageList->nrpPageSize + (BYTE *)nraPageList;

        return;
    }

    /* Free up all the new pages we've added at the end of the list */

    while (nraPageLast != last)
    {
        norls_pagdesc * temp;

        /* Remove the last page from the end of the list */

        temp = nraPageLast;
               nraPageLast = temp->nrpPrevPage;

        /* The new last page has no 'next' page */

        nraPageLast->nrpNextPage = 0;

#if 0
#ifdef DEBUG
        unsigned tossSize += temp->nrpPageSize;
        if (nraPageLast == last)
            printf("%4X\n", tossSize);

        if  (this == &stmt_cmp::scAlloc)
            printf("StmtCmp");
        else if (this == &stmtExpr::sxAlloc)
            printf("StmtExp");
        else
            printf("Unknown");

        printf(": toss page at %08X\n", temp);

#endif
#endif

        VirtualFree(temp, 0, MEM_RELEASE);
    }

    nraFreeNext = mark.nmNext;
    nraFreeLast = mark.nmLast;
}

/*****************************************************************************/
#ifdef DEBUG
/*****************************************************************************/

void    *           norls_allocator::nraAlloc(size_t sz)
{
    void    *   block;

    assert(sz != 0 && (sz & (sizeof(int) - 1)) == 0);

    block = nraFreeNext;
            nraFreeNext += sz;

    if  ((unsigned)block == blockStop) debugStop("Block at %08X allocated", block);

    if  (nraFreeNext > nraFreeLast)
        block = nraAllocNewPage(sz);

#ifdef DEBUG
    memset(block, 0xDD, sz);
#endif

    return  block;
}

/*****************************************************************************/
#endif
/*****************************************************************************/

size_t              norls_allocator::nraTotalSizeAlloc()
{
    norls_pagdesc * page;
    size_t          size = 0;

    for (page = nraPageList; page; page = page->nrpNextPage)
        size += page->nrpPageSize;

    return  size;
}

size_t              norls_allocator::nraTotalSizeUsed()
{
    norls_pagdesc * page;
    size_t          size = 0;

    if  (nraPageLast)
        nraPageLast->nrpUsedSize = nraFreeNext - nraPageLast->nrpContents;

    for (page = nraPageList; page; page = page->nrpNextPage)
        size += page->nrpUsedSize;

    return  size;
}

/*****************************************************************************
 * We try to use this allocator instance as much as possible. It will always
 * keep a page handy so small methods wont have to call VirtualAlloc()
 * But we may not be able to use it if another thread/reentrant call
 * is already using it
 */

static norls_allocator *nraTheAllocator;
static nraMarkDsc       nraTheAllocatorMark;
static LONG             nraTheAllocatorIsInUse = 0;

// The static instance which we try to reuse for all non-simultaneous requests

static norls_allocator  theAllocator;

/*****************************************************************************/

void                nraInitTheAllocator()
{
    bool res = theAllocator.nraInit(0, 1);

    if (res)
    {
        nraTheAllocator = NULL;
    }
    else
    {
        nraTheAllocator = &theAllocator;
    }
}

void                nraTheAllocatorDone()
{
    if (nraTheAllocator)
        nraTheAllocator->nraFree();
}

/*****************************************************************************/

norls_allocator *   nraGetTheAllocator()
{
    if (nraTheAllocator == NULL)
    {
        // If we failed to initialize nraTheAllocator in nraInitTheAllocator()
        return NULL;
    }

    if (InterlockedExchange(&nraTheAllocatorIsInUse, 1))
    {
        // Its being used by another Compiler instance
        return NULL;
    }
    else
    {
        nraTheAllocator->nraMark(nraTheAllocatorMark);
        return nraTheAllocator;
    }
}


void                nraFreeTheAllocator()
{
    if (nraTheAllocator == NULL)
    {
        // If we failed to initialize nraTheAllocator in nraInitTheAllocator()
        return;
    }

    assert(nraTheAllocatorIsInUse == 1);
    nraTheAllocator->nraRlsm(nraTheAllocatorMark);
    InterlockedExchange(&nraTheAllocatorIsInUse, 0);
}


/*****************************************************************************/
void                allocatorCodeSizeEnd(){}
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\il\delayload.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
#include "jitpch.h"
#pragma hdrstop
#include "ShimLoad.h"

ExternC PfnDliHook __pfnDliNotifyHook = ShimDelayLoadHook;
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\il\alloc.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*****************************************************************************/
#ifndef _ALLOC_H_
#define _ALLOC_H_
/*****************************************************************************/
#ifndef _HOST_H_
#ifndef BIRCH_SP2
#include"host.h"
#endif
#endif
/*****************************************************************************/

#pragma warning(disable:4200)


/*****************************************************************************/
#ifdef DEBUG

#include "DbgAlloc.h"
#include "malloc.h"

inline void* DbgNew(int size) {
    CDA_DECL_CALLSTACK();
    return DbgAlloc(size, CDA_GET_CALLSTACK());
}

inline void DbgDelete(void* ptr) {
    CDA_DECL_CALLSTACK();
    DbgFree(ptr, CDA_GET_CALLSTACK());
}

#define VirtualAlloc(addr, size, allocType, protect)                    \
    (assert(addr == 0 && allocType == MEM_COMMIT && PAGE_READWRITE),    \
    DbgNew(size))

#define VirtualFree(addr, size, freeType)          \
    (assert(size == 0 && freeType == MEM_RELEASE),  \
    DbgDelete(addr))

	// technically we can use these, we just have to insure that
	//  1) we can clean up.  2) we check out of memory conditions
	// Outlawing them is easier, if you need some memory for debug-only
	// stuff, define a special new operator with a dummy arg
		
#define __OPERATOR_NEW_INLINE 1			// indicate that I have defined these 
static inline void * __cdecl operator new(size_t n) { 
	assert(!"use JIT memory allocators");	
	return(0);
	}
static inline void * __cdecl operator new[](size_t n) { 
	assert(!"use JIT memory allocators ");	
	return(0);
	};

#endif

#include "PerfAlloc.h"
#if defined( PERFALLOC )
#pragma inline_depth( 0 )
#define VirtualAlloc(addr,size,flags,type) PerfVirtualAlloc::VirtualAlloc(addr,size,flags,type,PerfAllocCallerEIP())
#define VirtualFree(addr,size,type) PerfVirtualAlloc::VirtualFree(addr,size,type)
#pragma inline_depth( 255 )
#endif

/*****************************************************************************/

struct nraMarkDsc
{
    void    *       nmPage;
    BYTE    *       nmNext;
    BYTE    *       nmLast;
};

struct norls_allocator
{
    bool            nraInit (size_t pageSize = 0, int preAlloc = 0);
    bool            nraStart(size_t initSize,
                             size_t pageSize = 0);

    void            nraFree (void);
    void            nraDone (void);

private:

    struct norls_pagdesc
    {
        norls_pagdesc * nrpNextPage;
        norls_pagdesc * nrpPrevPage;
#ifdef DEBUG
        void    *       nrpSelfPtr;
#endif
        size_t          nrpPageSize;    // # of bytes allocated
        size_t          nrpUsedSize;    // # of bytes actually used
        BYTE            nrpContents[];
    };

    norls_pagdesc * nraPageList;
    norls_pagdesc * nraPageLast;

    bool            nraRetNull;         // OOM returns NULL (longjmp otherwise)

    BYTE    *       nraFreeNext;        // these two (when non-zero) will
    BYTE    *       nraFreeLast;        // always point into 'nraPageLast'

    size_t          nraPageSize;

    void    *       nraAllocNewPage(size_t sz);

public:

    void    *       nraAlloc(size_t sz);

    /* The following used for mark/release operation */

    void            nraMark(nraMarkDsc &mark)
    {
        mark.nmPage = nraPageLast;
        mark.nmNext = nraFreeNext;
        mark.nmLast = nraFreeLast;
    }

private:

    void            nraToss(nraMarkDsc &mark);

public:

    void            nraRlsm(nraMarkDsc &mark)
    {
        if (nraPageLast != mark.nmPage)
        {
            nraToss(mark);
        }
        else
        {
            nraFreeNext = mark.nmNext;
            nraFreeLast = mark.nmLast;
        }
    }

    size_t          nraTotalSizeAlloc();
    size_t          nraTotalSizeUsed ();

    /* The following used to visit all of the allocated pages */

    void    *       nraPageWalkerStart();
    void    *       nraPageWalkerNext (void *page);

    void    *       nraPageGetData(void *page);
    size_t          nraPageGetSize(void *page);
};

#if !defined(DEBUG) && !defined(BIRCH_SP2)

inline
void    *           norls_allocator::nraAlloc(size_t sz)
{
    void    *   block;

    block = nraFreeNext;
            nraFreeNext += sz;

    if  (nraFreeNext > nraFreeLast)
        block = nraAllocNewPage(sz);

    return  block;
}

#endif

/*****************************************************************************/
/*****************************************************************************
 * If most uses of the norls_alloctor are going to be non-simultaneous,
 * we keep a single instance handy and preallocate 1 page.
 * Then if most uses wont need to call VirtualAlloc() for the first page.
 */

void                nraInitTheAllocator();  // One-time initialization
void                nraTheAllocatorDone();  // One-time completion code

// returns NULL if the single instance is already in use. 
// User will need to allocate a new instance of the norls_allocator

norls_allocator *   nraGetTheAllocator();   

// Should be called after we are done with the current use, so that the
// next user can reuse it, instead of allocating a new instance

void                nraFreeTheAllocator();

/*****************************************************************************/
#endif
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\il\block.h ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                          BasicBlock                                       XX
XX                                                                           XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

/*****************************************************************************/
#ifndef _BLOCK_H_
#define _BLOCK_H_
/*****************************************************************************/

#include "vartype.h"    // For "var_types.h"
#include "_typeInfo.h"
/*****************************************************************************/

typedef   unsigned  __int64   VARSET_TP;
#define                       VARSET_SZ   64

#define   VARSET_NOT_ACCEPTABLE ((VARSET_TP)0-1)

/*****************************************************************************/

#if LARGE_EXPSET
typedef   unsigned  __int64   EXPSET_TP;
#define                       EXPSET_SZ   64
#else
typedef   unsigned  int       EXPSET_TP;
#define                       EXPSET_SZ   32
#endif

typedef   unsigned  int       RNGSET_TP;
#define                       RNGSET_SZ   32

/*****************************************************************************
 *
 *  Type values are stored as unsigned shorts.
 */

typedef unsigned short  verTypeVal;

/*****************************************************************************
 *
 *  The following describes a stack contents (packed version).
 */

struct stackDesc
{
    unsigned            sdDepth;    // number of values on stack
    verTypeVal       *  sdTypes;    // types  of values on stack
};

/*****************************************************************************
 *
 *  Each basic block ends with a jump which is described be a value
 *  of the following enumeration.
 */

enum _BBjumpKinds_enum
{
    BBJ_RET,        // block ends with 'endfinally' or 'endfilter'
    BBJ_THROW,      // block ends with 'throw'
    BBJ_RETURN,     // block ends with 'ret'
                    
    BBJ_NONE,       // block flows into the next one (no jump)
                    
    BBJ_ALWAYS,     // block always jumps to the target
    BBJ_LEAVE,      // block always jumps to the target, maybe out of guarded
                    // region. Used temporarily until importing
    BBJ_CALL,       // block always calls the target finallys
    BBJ_COND,       // block conditionally jumps to the target
    BBJ_SWITCH,     // block ends with a switch statement
    BBJ_COUNT
};

#ifdef DEBUG
typedef _BBjumpKinds_enum BBjumpKinds;
#else
typedef BYTE BBjumpKinds;
#endif

/*****************************************************************************
 *
 *  The following describes a switch block.
 */

struct  GenTree;
struct  BasicBlock;
class   typeInfo;

struct  BBswtDesc
{
    unsigned            bbsCount;       // count of cases (includes 'default')
    BasicBlock  *   *   bbsDstTab;      // case label table address
};

struct StackEntry
{
    struct GenTree*      val;
    typeInfo        seTypeInfo;
};
/*****************************************************************************/

struct flowList
{
    BasicBlock      *   flBlock;
    flowList        *   flNext;
};

typedef struct EntryStateStruct
{
    BYTE*           esLocVarLiveness;               // bitmap for tracking liveness of local variables
    BYTE*           esValuetypeFieldInitialized;    // bitmap for tracking init state of valuetype fields

    unsigned        thisInitialized : 8;        // used to track whether the this ptr is initialized (consider using 1 bit)
    unsigned        esStackDepth    : 24;       // size of esStack
    StackEntry *    esStack;                    // ptr to  stack

} EntryState;

/*****************************************************************************
 *
 *  The following structure describes a basic block.
 */


struct  BasicBlock
{
    BasicBlock  *       bbNext;     // next BB in ascending PC offset order

    unsigned short      bbNum;      // the block's number
#ifdef BIRCH_SP2
    short               bbRefs;     // id of the block that jumps here or negative for special flags
#else
    unsigned short      bbRefs;     // number of blocks that can jump here
#endif

    unsigned            bbFlags;    // see BBF_xxxx below

#define BBF_VISITED       0x00000001  // BB visited during optimizations
#define BBF_MARKED        0x00000002  // BB marked  during optimizations
#define BBF_CHANGED       0x00000004  // input/output of this block has changed
#define BBF_REMOVED       0x00000008  // BB has been removed from bb-list

#define BBF_DONT_REMOVE   0x00000010  // BB should not be removed during flow graph optimizations
#define BBF_IMPORTED      0x00000020  // BB byte-code has been imported
#define BBF_INTERNAL      0x00000040  // BB has been added by the compiler
#define BBF_HAS_HANDLER   0x00000080  // the BB has an exception handler

#define BBF_TRY_BEG       0x00000100  // BB starts a 'try' block
#define BBF_TRY_HND_END   0x00000200  // BB ends   a 'try' block or a handler
#define BBF_ENDFILTER     0x00000400  // BB is the end of a filter
#define BBF_ENDFINALLY    0x00000800  // BB is the end of a finally

#define BBF_RUN_RARELY    0x00001000  // BB is rarely run (catch clauses, blocks with throws etc)
#define BBF_LOOP_HEAD     0x00002000  // BB is the head of a loop
#define BBF_LOOP_CALL0    0x00004000  // BB starts a loop that sometimes won't call
#define BBF_LOOP_CALL1    0x00008000  // BB starts a loop that will always     call

#define BBF_HAS_LABEL     0x00010000  // BB needs a label
#define BBF_JMP_TARGET    0x00020000  // BB is a target of an implicit/explicit jump
#define BBF_HAS_JMP       0x00040000  // BB executes a JMP or JMPI instruction (instead of return)
#define BBF_GC_SAFE_POINT 0x00080000  // BB has a GC safe point (a call)

#define BBF_HAS_INC       0x00100000  // BB contains increment     expressions
#define BBF_HAS_INDX      0x00200000  // BB contains simple index  expressions
#define BBF_NEW_ARRAY     0x00400000  // BB contains 'new' of an array
#define BBF_FAILED_VERIFICATION  0x00800000 // BB has verification exception

#define BBF_BB_COLON      0x01000000  // _: value is an output from the block
#define BBF_BB_QMARK      0x02000000  // _? value is an input  to   the block
#define BBF_COLON         0x03000000  //  : value is an output from the block
#define BBF_QC_MASK       0x03000000
#define BBF_RETLESS_CALL  0x04000000  // BB Call that will never return (and therefore, won't need
                                      // a BBJ_ALWAYS
#define BBF_LOOP_PREHEADER 0x08000000

#define isBBF_BB_COLON(flags) (((flags) & BBF_QC_MASK) == BBF_BB_COLON)
#define isBBF_BB_QMARK(flags) (((flags) & BBF_QC_MASK) == BBF_BB_QMARK)
#define isBBF_COLON(flags)    (((flags) & BBF_QC_MASK) == BBF_COLON   )

// Flags to update when two blocks are compacted

#define BBF_COMPACT_UPD (BBF_CHANGED     |                                    \
                         BBF_TRY_HND_END | BBF_ENDFILTER | BBF_ENDFINALLY |   \
                         BBF_RUN_RARELY  |                                    \
                         BBF_GC_SAFE_POINT | BBF_HAS_JMP |                    \
                         BBF_HAS_INC     | BBF_HAS_INDX  | BBF_NEW_ARRAY  |   \
                         BBF_BB_COLON)

    IL_OFFSET           bbCodeOffs; // starting PC offset
    IL_OFFSET           bbCodeSize; // # of bytes of code

// Some non-zero value that will not colide with real tokens for bbCatchTyp
#define BBCT_FAULT              0xFFFFFFFC
#define BBCT_FINALLY            0xFFFFFFFD
#define BBCT_FILTER             0xFFFFFFFE
#define BBCT_FILTER_HANDLER     0xFFFFFFFF
#define handlerGetsXcptnObj(hndTyp)   ((hndTyp) != NULL         &&   \
                                       (hndTyp) != BBCT_FAULT   &&   \
                                       (hndTyp) != BBCT_FINALLY    )

    unsigned            bbCatchTyp; // catch type CP index if handler
    BBjumpKinds         bbJumpKind; // jump (if any) at the end

#ifdef  VERIFIER

    stackDesc           bbStackIn;  // stack descriptor for  input
    stackDesc           bbStackOut; // stack descriptor for output

    verTypeVal  *       bbTypesIn;  // list of variable types on  input
    verTypeVal  *       bbTypesOut; // list of variable types on output

#ifdef  DEF_USE_SETS
    verTypeVal  *       bbTypesUse; // table of local types    used by block
    verTypeVal  *       bbTypesDef; // table of local types defined by block
#endif

#endif

    GenTree *           bbTreeList; // the body of the block

    // @TODO: Get rid of bbStkDepth and use bbStackDepthOnEntry() instead
    union
    {
        unsigned short  bbStkDepth; // stack depth on entry
        unsigned short  bbFPinVars; // number of inner enregistered FP vars
    };

#define NO_BASE_TMP     USHRT_MAX   // base# to use when we have none

    unsigned short      bbStkTemps; // base# for input stack temps

    EntryState *        bbEntryState; // verifier tracked state of all entries in stack. 

    unsigned short      bbTryIndex; // index, into the ebd table, of innermost try clause containing the BB (used for raising exceptions)
    unsigned short      bbHndIndex; // index, into the ebd table, of innermost handler (filter, catch, fault/finally) containing the BB

    bool      hasTryIndex()             { return bbTryIndex != 0; }
    bool      hasHndIndex()             { return bbHndIndex != 0; }
    unsigned  getTryIndex()             { assert(bbTryIndex);  return bbTryIndex-1; }
    unsigned  getHndIndex()             { assert(bbHndIndex);  return bbHndIndex-1; }
    void      setTryIndex(unsigned val) { bbTryIndex = val+1;  assert(bbTryIndex);  }
    void      setHndIndex(unsigned val) { bbHndIndex = val+1;  assert(bbHndIndex);  }

    bool      isRunRarely()             { return ((bbFlags & BBF_RUN_RARELY) != 0); }
    bool      isLoopHead()              { return ((bbFlags & BBF_LOOP_HEAD)  != 0); }

    unsigned short      bbWeight;   // to give refs inside loops more weight

#define BB_UNITY_WEIGHT    2           // how much a normal execute once block 
#define BB_LOOP_WEIGHT     8           // how much more loops are weighted 
#define BB_MAX_LOOP_WEIGHT USHRT_MAX   // we're using an 'unsigned short' for the weight

    VARSET_TP           bbVarUse;   // variables used     by block (before an assignment)
    VARSET_TP           bbVarDef;   // variables assigned by block (before a use)
    VARSET_TP           bbVarTmp;   // TEMP: only used by FP enregistering code!

    VARSET_TP           bbLiveIn;   // variables live on entry
    VARSET_TP           bbLiveOut;  // variables live on exit

    union
    {
        VARSET_TP       bbFPoutVars;
#ifdef DEBUGGING_SUPPORT
        VARSET_TP       bbScope;    // variables in scope over the block
#endif
    };


    /* The following are the standard bit sets for dataflow analisys
     * We perform     CSE and range-checks at the same time
     *                and assertion propagation seperately
     * thus we can union them since the two operations are completely disjunct */

    union
    {
        EXPSET_TP       bbExpGen;        // exprs computed by block
#if ASSERTION_PROP
        EXPSET_TP       bbAssertionGen;  // value assignments computed by block
#endif
    };

    union
    {
        EXPSET_TP       bbExpKill;       // exprs killed   by block
#if ASSERTION_PROP
        EXPSET_TP       bbAssertionKill; // value assignments killed   by block
#endif
    };

    union
    {
        EXPSET_TP       bbExpIn;         // exprs available on entry
#if ASSERTION_PROP
        EXPSET_TP       bbAssertionIn;   // value assignments available on entry
#endif
    };

    union
    {
        EXPSET_TP       bbExpOut;        // exprs available on exit
#if ASSERTION_PROP
        EXPSET_TP       bbAssertionOut;  // value assignments available on exit
#endif
    };

    RNGSET_TP           bbRngGen;        // range checks computed by block
    RNGSET_TP           bbRngKill;       // range checks killed   by block
    RNGSET_TP           bbRngIn;         // range checks available on entry
    RNGSET_TP           bbRngOut;        // range checks available on exit

#define                 USZ   32         // sizeof(unsigned)

    unsigned *          bbReach;         // blocks that can reach this one
    unsigned *          bbDom;           // blocks dominating this one

    flowList *          bbPreds;         // ptr to list of predecessors

    void    *           bbEmitCookie;

    /* The following fields used for loop detection */

    unsigned char       bbLoopNum;   // set to 'n' for a loop #n header
//  unsigned short      bbLoopMask;  // set of loops this block is part of

#define MAX_LOOP_NUM    16           // we're using a 'short' for the mask
#define LOOP_MASK_TP    unsigned     // must be big enough for a mask

    /* The following union describes the jump target(s) of this block */

    union
    {
        unsigned        bbJumpOffs;         // PC offset (temporary only)
        BasicBlock  *   bbJumpDest;         // basic block
        BBswtDesc   *   bbJumpSwt;          // switch descriptor
    };

    //-------------------------------------------------------------------------

#if     MEASURE_BLOCK_SIZE
    static size_t       s_Size;
    static size_t       s_Count;
#endif

    bool                bbFallsThrough();

    BasicBlock *        bbJumpTarget();

#ifdef  DEBUG
    unsigned            bbTgtStkDepth;  // Native stack depth on entry (for throw-blocks)
    static unsigned     s_nMaxTrees;    // The max # of tree nodes in any BB
#endif

    BOOL                bbThisOnEntry();
    BOOL                bbSetThisOnEntry(BOOL val);
    void                bbSetLocVarLiveness(BYTE* bitmap);  
    BYTE*               bbLocVarLivenessBitmapOnEntry();
    void                bbSetValuetypeFieldInitialized(BYTE* bitmap);  
    BYTE*               bbValuetypeFieldBitmapOnEntry();
    unsigned            bbStackDepthOnEntry();
    void                bbSetStack(void* stackBuffer);
    StackEntry*         bbStackOnEntry();
    void                bbSetRunRarely();

protected :

};

/*****************************************************************************/

extern  BasicBlock *    __cdecl verAllocBasicBlock();

#ifdef  DEBUG
extern  void            __cdecl verDispBasicBlocks();
#endif

/*****************************************************************************
 *
 *  The following call-backs supplied by the client; it's used by the code
 *  emitter to convert a basic block to its corresponding emitter cookie.
 */

void *  FASTCALL        emitCodeGetCookie(BasicBlock *block);

/*****************************************************************************/
#endif // _BLOCK_H_
/*****************************************************************************/
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\com\netfx\src\clr\jit\il\codegen.cpp ===
// ==++==
// 
//   Copyright (c) Microsoft Corporation.  All rights reserved.
// 
// ==--==
/*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XX                                                                           XX
XX                           CodeGenerator                                   XX
XX                                                                           XX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

#include "jitpch.h"
#pragma hdrstop

#include "GCInfo.h"
#include "emit.h"

/*****************************************************************************/

const BYTE          genTypeSizes[] =
{
    #define DEF_TP(tn,nm,jitType,verType,sz,sze,asze,st,al,tf,howUsed) sz,
    #include "typelist.h"
    #undef  DEF_TP
};

const BYTE          genTypeStSzs[] =
{
    #define DEF_TP(tn,nm,jitType,verType,sz,sze,asze,st,al,tf,howUsed) st,
    #include "typelist.h"
    #undef  DEF_TP
};

const BYTE          genActualTypes[] =
{
    #define DEF_TP(tn,nm,jitType,verType,sz,sze,asze,st,al,tf,howUsed) jitType,
    #include "typelist.h"
    #undef  DEF_TP
};

/*****************************************************************************/
// Have to be defined for genTypeRegst[]

#if TGT_SH3

#define TYP_REGS_UNDEF      7
#define TYP_REGS_VOID       1

#define TYP_REGS_BOOL       1

#define TYP_REGS_BYTE       1
#define TYP_REGS_UBYTE      1

#define TYP_REGS_SHORT      1
#define TYP_REGS_CHAR       1

#define TYP_REGS_INT        1
#define TYP_REGS_LONG       2

#define TYP_REGS_FLOAT      1
#define TYP_REGS_DOUBLE     2

#define TYP_REGS_REF        1
#define TYP_REGS_BYREF      1
#define TYP_REGS_ARRAY      1
#define TYP_REGS_STRUCT     7
#define TYP_REGS_PTR        1
#define TYP_REGS_FNC        1

#define TYP_REGS_UINT       1
#define TYP_REGS_ULONG      2

#define TYP_REGS_UNKNOWN    0

#endif

/*****************************************************************************/

#if TGT_RISC

/* TYP_REGS_<type> for all the types should be defined appropriately for the
   required target */

BYTE                genTypeRegst[] =
{
    #define DEF_TP(tn,nm,jitType,sz,sze,asze,st,al,tf,howUsed) TYP_REGS_##tn,
    #include "typelist.h"
    #undef DEF_TP
};

#endif

/*****************************************************************************/

void            Compiler::genInit()
{
    rsInit  ();
    tmpInit ();
    instInit();
    gcInit  ();

#ifdef LATE_DISASM
    genDisAsm.disInit(this);
#endif

#ifdef  DEBUG
    genTempLiveChg          = true;
    genTrnslLocalVarCount   = 0;

    // Shouldnt be used before it is set in genFnProlog()
    compCalleeRegsPushed    = 0xDD;
#endif

    genFlagsEqualToNone();

#ifdef DEBUGGING_SUPPORT
    //  Initialize the IP-mapping logic.
    // if (opts.compDbgInfo)
    genIPmappingList        =
    genIPmappingLast        = 0;
#endif

    /* We have not encountered any "nested" calls */

#if TGT_RISC
    genNonLeaf         = false;
    genMaxCallArgs     = 0;
#endif

    /* Assume that we not fully interruptible */

    genInterruptible   = false;
#ifdef  DEBUG
    genIntrptibleUse   = false;
#endif
}

/*****************************************************************************
 * Should we round simple operations (assignments, arithmetic operations, etc.)
 */

inline
bool                genShouldRoundFP()
{
    RoundLevel roundLevel = getRoundFloatLevel();

    switch (roundLevel)
    {
    case ROUND_NEVER:
    case ROUND_CMP_CONST:
    case ROUND_CMP:
        return  false;

    default:
        assert(roundLevel == ROUND_ALWAYS);
        return  true;
    }
}

/*****************************************************************************
 *
 *  Initialize some global variables.
 */

void                Compiler::genPrepForCompiler()
{

    unsigned        varNum;
    LclVarDsc   *   varDsc;

    /* Figure out which non-register variables hold pointers */

    gcTrkStkPtrLcls = 0;

    /* Figure out which variables live in registers */

    genCodeCurRvm   = 0;

    for (varNum = 0, varDsc = lvaTable;
         varNum < lvaCount;
         varNum++  , varDsc++)
    {
        if  (varDsc->lvTracked)
        {
            if (varDsc->lvRegister && !isFloatRegType(varDsc->lvType))
            {
                genCodeCurRvm |= genVarIndexToBit(varDsc->lvVarIndex);
            }
            else if (varTypeIsGC(varDsc->TypeGet())             &&
                     (!varDsc->lvIsParam || varDsc->lvIsRegArg)  )
            {
                gcTrkStkPtrLcls |= genVarIndexToBit(varDsc->lvVarIndex);
            }
        }
    }

#if defined(DEBUG) && !NST_FASTCALL
    genCallInProgress = false;
#endif
}

/*****************************************************************************/

// This function should be called whenever genStackLevel is changed.

#if TGT_x86

inline
void                Compiler::genOnStackLevelChanged()
{
#ifdef DEBUGGING_SUPPORT
    if (opts.compScopeInfo && info.compLocalVarsCount>0)
        siStackLevelChanged();
#endif
}

inline
void                Compiler::genSinglePush(bool isRef)
{
    genStackLevel += sizeof(void*);
    genOnStackLevelChanged();
}

inline
void                Compiler::genSinglePop()
{
    genStackLevel -= sizeof(void*);
    genOnStackLevelChanged();
}

#else

inline
void                Compiler::genOnStackLevelChanged()  {}
inline
void                Compiler::genSinglePush(bool isRef) {}
inline
void                Compiler::genSinglePop()            {}

#endif

void                Compiler::genChangeLife(VARSET_TP newLife DEBUGARG(GenTreePtr tree))
{
    LclVarDsc   *   varDsc;

    VARSET_TP       deadMask;

    VARSET_TP       lifeMask;
    VARSET_TP        chgMask;

#ifdef  DEBUG
    if (verbose&&0) printf("[%08X] Current life %s -> %s\n", tree, genVS2str(genCodeCurLife), genVS2str(newLife));
#endif

    /* The following isn't 100% correct but it works often enough to be useful */

    assert(int(newLife) != 0xDDDDDDDD);

    /* We should only be called when the live set has actually changed */

    assert(genCodeCurLife != newLife);

    /* Figure out which variables are becoming live/dead at this point */

    deadMask = ( genCodeCurLife & ~newLife);
    lifeMask = (~genCodeCurLife &  newLife);

    /* Can't simultaneously become live and dead at the same time */

    assert((deadMask | lifeMask) != 0);
    assert((deadMask & lifeMask) == 0);

    /* Compute the new pointer stack variable mask */

    gcVarPtrSetCur = newLife & gcTrkStkPtrLcls;

    /* Compute the 'changing state' mask */

    chgMask  = (deadMask | lifeMask) & genCodeCurRvm;

    // VTUNE : This loop is a performance hot spot

    // @TODO [CONSIDER] [04/16/01] []:
    // Why not simply store the set of register variables in
    // each tree node, along with gtLiveSet. That way we can
    // change this function to a single assignment.

    for ( varDsc = lvaTable;
         (varDsc < (lvaTable + lvaCount) && chgMask);
          varDsc++ )
    {
        /* Ignore the variable if it's not (tracked and enregistered) */

        if  (!(varDsc->lvTracked & varDsc->lvRegister))
            continue;

        VARSET_TP varBit = genVarIndexToBit(varDsc->lvVarIndex);

        /* Ignore the variable if it's not changing state here */

        if  (!(chgMask & varBit))
            continue;

        assert(!isFloatRegType(varDsc->lvType));

        /* Remove this variable from the 'interesting' bit set */

        chgMask &= ~varBit;

        /* Get hold of the appropriate register bit(s) */

        regMaskTP regBit = genRegMask(varDsc->lvRegNum);

        if  (isRegPairType(varDsc->lvType) && varDsc->lvOtherReg != REG_STK)
            regBit |= genRegMask(varDsc->lvOtherReg);

        /* Is the variable becoming live or dead? */

        if  (deadMask & varBit)
        {
            assert((rsMaskVars &  regBit) != 0);
                    rsMaskVars &=~regBit;
        }
        else
        {
            assert((rsMaskVars &  regBit) == 0);
                    rsMaskVars |= regBit;
        }

#ifdef  DEBUG
        if (verbose)
        {
            printf("[%08X]: V%02u,T%02u in reg %s",
                   tree, (varDsc - lvaTable), 
                   varDsc->lvVarIndex, compRegVarName(varDsc->lvRegNum));
            if (isRegPairType(varDsc->lvType))
                printf(":%s", compRegVarName(varDsc->lvOtherReg));
            printf(" is becoming %s\n", (deadMask & varBit) ? "dead" : "live");
        }
#endif
    }

    genCodeCurLife = newLife;

#ifdef DEBUGGING_SUPPORT
    if (opts.compScopeInfo && !opts.compDbgCode && info.compLocalVarsCount>0)
        siUpdate();
#endif
}

/*****************************************************************************
 *
 *  The variable found in the deadMask are dead, update the liveness globals
 *  genCodeCurLife, gcVarPtrSetCur, rsMaskVars, gcRegGCrefSetCur, gcRegByrefSetCur
 */

void                Compiler::genDyingVars(VARSET_TP  commonMask,
                                           GenTreePtr opNext)
{
    unsigned        varNum;
    LclVarDsc   *   varDsc;
    VARSET_TP       varBit;
    unsigned        regBit;
    VARSET_TP       deadMask = commonMask & ~opNext->gtLiveSet;

    if (!deadMask)
        return;

    //
    // Consider the case in which the opNext is a GT_LCL_VAR
    // The liveness set of opNext->gtLiveSet will not include
    // this local variable, so we must remove it from deadmask
    //

    if (opNext->gtOper == GT_LCL_VAR)
    {
        varNum = opNext->gtLclVar.gtLclNum;
        varDsc = lvaTable + varNum;

        // Is this a tracked local var
        if (varDsc->lvTracked)
        {
            varBit = genVarIndexToBit(varDsc->lvVarIndex);

            /* Remove this variable from the 'deadMask' bit set */
            deadMask &= ~varBit;

            /* if deadmask is now empty then return */
            if (!deadMask)
                return;
        }
    }
#ifdef DEBUG
    else if (opNext->gtOper == GT_REG_VAR)
    {
        /* We don't expect any LCL to have been bashed into REG yet
           (except enregistered FP vars) */

        assert(isFloatRegType(opNext->gtType));

        /* However, we dont FP-enreg vars whose liveness changes inside
           GTF_COLON_COND so we dont have to worry about updating deadMask */
        varDsc = lvaTable + opNext->gtRegVar.gtRegVar;
        assert(varDsc->lvTracked);
        varBit = genVarIndexToBit(varDsc->lvVarIndex);
        assert((deadMask & varBit) == 0);
    }
#endif

    /* iterate through the variable table */

    unsigned  begNum  = 0;
    unsigned  endNum  = lvaCount;

    for (varNum = begNum, varDsc = lvaTable + begNum;
         varNum < endNum && deadMask;
         varNum++       , varDsc++)
    {
        /* Ignore the variable if it's not being tracked */

        if  (!varDsc->lvTracked)
            continue;

        /* Ignore the variable if it's not a dying var */

        varBit = genVarIndexToBit(varDsc->lvVarIndex);

        if  (!(deadMask & varBit))
            continue;

        /* Remove this variable from the 'deadMask' bit set */

        deadMask &= ~varBit;

        assert((genCodeCurLife &  varBit) != 0);

        genCodeCurLife &= ~varBit;

        assert(((gcTrkStkPtrLcls  &  varBit) == 0) ||
               ((gcVarPtrSetCur   &  varBit) != 0)    );

        gcVarPtrSetCur &= ~varBit;

        /* We are done if the variable is not enregistered */

        if (!varDsc->lvRegister)
            continue;

        // We dont do FP-enreg of vars whose liveness changes in GTF_COLON_COND

        assert(!isFloatRegType(varDsc->lvType));

        /* Get hold of the appropriate register bit(s) */

        regBit = genRegMask(varDsc->lvRegNum);

        if  (isRegPairType(varDsc->lvType) && varDsc->lvOtherReg != REG_STK)
            regBit |= genRegMask(varDsc->lvOtherReg);

#ifdef  DEBUG
        if  (verbose) printf("V%02u,T%02u in reg %s is a dyingVar\n",
                             varNum, varDsc->lvVarIndex, compRegVarName(varDsc->lvRegNum));
#endif
        assert((rsMaskVars &  regBit) != 0);

        rsMaskVars &= ~regBit;

        // Remove GC tracking if any for this register

        if ((regBit & rsMaskUsed) == 0) // The register may be multi-used
            gcMarkRegSetNpt(regBit);
     }
}

/*****************************************************************************
 *
 *  Change the given enregistered local variable node to a register variable node
 */

inline
void                Compiler::genBashLclVar(GenTreePtr tree, unsigned     varNum,
                                                             LclVarDsc *  varDsc)
{
    assert(tree->gtOper == GT_LCL_VAR);
    assert(varDsc->lvRegister);

    /* Enregistered FP variables are marked elsewhere */
    assert(!isFloatRegType(varDsc->lvType));

    if  (isRegPairType(varDsc->lvType))
    {
        /* Check for the case of a variable that was narrowed to an int */

        if  (isRegPairType(tree->gtType))
        {
            tree->gtRegPair = gen2regs2pair(varDsc->lvRegNum, varDsc->lvOtherReg);
            tree->gtFlags  |= GTF_REG_VAL;

            return;
        }

        assert(tree->gtFlags & GTF_VAR_CAST);
        assert(tree->gtType == TYP_INT);
    }
    else
    {
        assert(isRegPairType(tree->gtType) == false);
    }

    /* It's a register variable -- modify the node */

    tree->SetOper(GT_REG_VAR);
    tree->gtFlags             |= GTF_REG_VAL;
    tree->gtRegNum             =
    tree->gtRegVar.gtRegNum    = varDsc->lvRegNum;
    tree->gtRegVar.gtRegVar    = varNum;
}

/*****************************************************************************
 *
 *  Record the fact that the flags register has a value that reflects the
 *  contents of the given register.
 */

inline
void                Compiler::genFlagsEqualToReg(GenTreePtr tree,
                                                 regNumber  reg,
                                                 bool       allFlags)
{
    genFlagsEqBlk = genEmitter->emitCurBlock();
    genFlagsEqOfs = genEmitter->emitCurOffset();
    genFlagsEqAll = allFlags;
    genFlagsEqReg = reg;

    /* previous setting of flags by a var becomes invalid */

    genFlagsEqVar = 0xFFFFFFFF;

    /* Set appropritate flags on the tree */

    if (tree)
        tree->gtFlags |= (allFlags ? GTF_CC_SET : GTF_ZF_SET);
}

/*****************************************************************************
 *
 *  Record the fact that the flags register has a value that reflects the
 *  contents of the given local variable.
 */

inline
void                Compiler::genFlagsEqualToVar(GenTreePtr tree,
                                                 unsigned   var,
                                                 bool       allFlags)
{
    genFlagsEqBlk = genEmitter->emitCurBlock();
    genFlagsEqOfs = genEmitter->emitCurOffset();
    genFlagsEqAll = allFlags;
    genFlagsEqVar = var;

    /* previous setting of flags by a register becomes invalid */

    genFlagsEqReg = REG_NA;

    /* Set appropritate flags on the tree */

    if (tree)
        tree->gtFlags |= (allFlags ? GTF_CC_SET : GTF_ZF_SET);
}

/*****************************************************************************
 *
 *  Return an indication of whether the flags register is set to the current
 *  value of the given register/variable. The return value is as follows:
 *
 *      0   ..  nothing
 *      1   ..  the zero flag is  set
 *      2   ..  all the flags are set
 */

inline
int                 Compiler::genFlagsAreReg(regNumber reg)
{
    if  (genFlagsEqBlk == genEmitter->emitCurBlock () &&
         genFlagsEqOfs == genEmitter->emitCurOffset())
    {
        if  (genFlagsEqReg == reg)
            return  1 + (int)genFlagsEqAll;
    }

    return  0;
}

inline
int                 Compiler::genFlagsAreVar(unsigned  var)
{
    if  (genFlagsEqBlk == genEmitter->emitCurBlock () &&
         genFlagsEqOfs == genEmitter->emitCurOffset())
    {
        if  (genFlagsEqVar == var)
            return  1 + (int)genFlagsEqAll;
    }

    return  0;
}

/*****************************************************************************
 *
 *  Generate code that will set the given register to the integer constant.
 */

void                Compiler::genSetRegToIcon(regNumber     reg,
                                              long          val,
                                              var_types     type)
{
    assert(type != TYP_REF || val== NULL);

    /* Does the reg already hold this constant? */

    if  (!rsIconIsInReg(val, reg))
    {
#if     TGT_x86

        if  (val == 0)
            inst_RV_RV(INS_xor, reg, reg, type);
        else
        {
            /* See if a register holds the value or a close value? */
            long      delta;
            regNumber srcReg = rsIconIsInReg(val, &delta);

            if (srcReg != REG_NA)
            {
                if (delta == 0)
                {
                    inst_RV_RV(INS_mov, reg, srcReg, type);
                }
                else /* use an lea instruction to set reg */
                {
                    /* delta should fit inside a byte */
                    assert(delta  == (signed char)delta);
                    genEmitter->emitIns_R_AR (INS_lea,
                                              EA_4BYTE,
                                              (emitRegs)reg,
                                              (emitRegs)srcReg,
                                              delta);
                }
            }
            else
            {
                /* For SMALL_CODE it is smaller to push a small immediate and
                   then pop it into the dest register */
                if ((compCodeOpt() == SMALL_CODE) &&
                    val == (signed char)val)
                {
                    /* "mov" has no s(sign)-bit and so always takes 6 bytes,
                       whereas push+pop takes 2+1 bytes */

                    inst_IV(INS_push, val);
                    genSinglePush(false);

                    inst_RV(INS_pop, reg, type);
                    genSinglePop();
                }
                else
                {
                    inst_RV_IV(INS_mov, reg, val, type);
                }
            }
        }

#else

        if  (val >= IMMED_INT_MIN && val <= IMMED_INT_MAX)
        {
            genEmitter->emitIns_R_I   (INS_mov_imm,
                                       emitTypeSize(type),
                                       (emitRegs)reg,
                                       val);
        }
        else
        {
            genEmitter->emitIns_R_LP_I((emitRegs)reg,
                                        emitTypeSize(type),
                                        val);
        }

#endif

    }
    rsTrackRegIntCns(reg, val);
    gcMarkRegPtrVal(reg, type);
}

/*****************************************************************************/
#if     TGT_x86
/*****************************************************************************
 *
 *  Add the given constant to the specified register.
 *  'tree' is the resulting tree
 */

void                Compiler::genIncRegBy(regNumber     reg,
                                          long          ival,
                                          GenTreePtr    tree,
                                          var_types     dstType,
                                          bool          ovfl)
{

    /* @TODO: [CONSIDER] [04/16/01] [] For Pentium 4 don't generate inc or dec instructions */

    /* First check to see if we can generate inc or dec instruction(s) */
    if (!ovfl)
    {
        emitAttr    size = emitTypeSize(dstType);

        switch (ival)
        {
        case 2:
            inst_RV(INS_inc, reg, dstType, size);
        case 1:
            inst_RV(INS_inc, reg, dstType, size);

            genFlagsEqualToReg(tree, reg, false);
            goto UPDATE_LIVENESS;

        case -2:
            inst_RV(INS_dec, reg, dstType, size);
        case -1:
            inst_RV(INS_dec, reg, dstType, size);

            genFlagsEqualToReg(tree, reg, false);
            goto UPDATE_LIVENESS;
        }
    }

    inst_RV_IV(INS_add, reg, ival, dstType);

    genFlagsEqualToReg(tree, reg, true);

UPDATE_LIVENESS:

    rsTrackRegTrash(reg);

    gcMarkRegSetNpt(genRegMask(reg));

    if (tree)
    {
        if (!(tree->OperKind() & GTK_ASGOP))
        {
            tree->gtFlags |= GTF_REG_VAL;
            tree->gtRegNum = reg;
            if (varTypeIsGC(tree->TypeGet()))
              gcMarkRegSetByref(genRegMask(reg));
        }
    }
}

/*****************************************************************************
 *
 *  Subtract the given constant from the specified register.
 *  Should only be used for unsigned sub with overflow. Else
 *  genIncRegBy() can be used using -ival. We shouldn't use genIncRegBy()
 *  for these cases as the flags are set differently, and the following
 *  check for overflow wont work correctly.
 *  'tree' is the resulting tree.
 */

void                Compiler::genDecRegBy(regNumber     reg,
                                          long          ival,
                                          GenTreePtr    tree)
{
    assert((tree->gtFlags & GTF_OVERFLOW) && (tree->gtFlags & GTF_UNSIGNED));
    assert(tree->gtType == TYP_INT);

    rsTrackRegTrash(reg);

    assert(!varTypeIsGC(tree->TypeGet()));
    gcMarkRegSetNpt(genRegMask(reg));

    inst_RV_IV(INS_sub, reg, ival, TYP_INT);

    genFlagsEqualToReg(tree, reg, true);

    if (tree)
    {
        tree->gtFlags |= GTF_REG_VAL;
        tree->gtRegNum = reg;
    }
}

/*****************************************************************************
 *
 *  Multiply the specified register by the given value.
 *  'tree' is the resulting tree
 */

void                Compiler::genMulRegBy(regNumber     reg,
                                          long          ival,
                                          GenTreePtr    tree,
                                          var_types     dstType,
                                          bool          ovfl)
{
    assert(genActualType(dstType) == TYP_INT);

    rsTrackRegTrash(reg);

    if (tree)
    {
        tree->gtFlags |= GTF_REG_VAL;
        tree->gtRegNum = reg;
    }

    if ((dstType == TYP_INT) && !ovfl)
    {
        switch (ival)
        {
        case 1:
            return;

        case 2:
            inst_RV_SH(INS_shl, reg, 1);
            genFlagsEqualToReg(tree, reg, false);
            return;

        case 4:
            inst_RV_SH(INS_shl, reg, 2);
            genFlagsEqualToReg(tree, reg, false);
            return;

        case 8:
            inst_RV_SH(INS_shl, reg, 3);
            genFlagsEqualToReg(tree, reg, false);
            return;
        }
    }

    inst_RV_IV(inst3opImulForReg(reg), reg, ival, dstType);
}

/*****************************************************************************
 *
 *  Adjust the stack pointer by the given value; assumes that this follows
 *  a call so only callee-saved registers (and registers that may hold a
 *  return value) are used at this point.
 */

void                Compiler::genAdjustSP(int delta)
{
    if  (delta == sizeof(int))
        inst_RV   (INS_pop, REG_ECX, TYP_INT);
    else
        inst_RV_IV(INS_add, REG_ESP, delta);
}

/*****************************************************************************/
#endif//TGT_x86
/*****************************************************************************/
#if     TGT_SH3
/*****************************************************************************
 *
 *  Add the given constant to the specified register.
 */

void                Compiler::genIncRegBy(regNumber     reg,
                                          long          ival,
                                          GenTreePtr    tree,
                                          var_types     dstType,
                                          bool          ovfl)
{
    assert(dstType == TYP_INT && "only allow ints for now");

    if  (ival >= IMMED_INT_MIN && ival <= IMMED_INT_MAX)
    {
        genEmitter->emitIns_R_I(INS_add_imm,
                                emitTypeSize(dstType),
                                (emitRegs)reg,
                                ival);
    }
    else
    {
        regNumber       rgt;

#if REDUNDANT_LOAD

        /* Is the constant already in some register? */

        rgt = rsIconIsInReg(ival);

        if  (rgt == REG_NA)
#endif
        {
            rgt = rsPickReg();

            genSetRegToIcon(rgt, ival, dstType);
        }

        genEmitter->emitIns_R_R(INS_add, emitTypeSize(dstType), (emitRegs)reg,
                                                                (emitRegs)rgt);
    }

    rsTrackRegTrash(reg);
}

/*****************************************************************************/

void                Compiler::genDecRegBy(regNumber     reg,
                                          long          ival,
                                          GenTreePtr    tree)
{
    assert(!"NYI for RISC");
}

/*****************************************************************************/
#endif//TGT_SH3
/*****************************************************************************
 *
 *  Compute the value 'tree' into a register that's in 'needReg' (or any free
 *  register if 'needReg' is 0). Note that 'needReg' is just a recommendation
 *  unless mustReg==EXACT_REG. If keepReg==KEEP_REG, we mark the register the
 *  value ends up in as being used.
 *
 *  The only way to guarantee that the result will end up in a register that
 *  is trashable is to pass EXACT_REG for 'mustReg' and non-zero for 'freeOnly'.
 */

void                Compiler::genComputeReg(GenTreePtr    tree,
                                            regMaskTP     needReg,
                                            ExactReg      mustReg,
                                            KeepReg       keepReg,
                                            bool          freeOnly)
{
    assert(tree->gtType != TYP_VOID);

#if CPU_HAS_FP_SUPPORT
    assert(genActualType(tree->gtType) == TYP_INT   ||
           genActualType(tree->gtType) == TYP_REF   ||
                         tree->gtType  == TYP_BYREF);
#else
    assert(genActualType(tree->gtType) == TYP_INT   ||
           genActualType(tree->gtType) == TYP_REF   ||
                         tree->gtType  == TYP_BYREF ||
           genActualType(tree->gtType) == TYP_FLOAT);
#endif

    /* Generate the value, hopefully into the right register */

    genCodeForTr