nk->PristineRoutineAsciiName != NULL) {

                RealRoutine = (ULONG_PTR)VerifierThunk->PristineRoutine;

                if (*ImportThunk == RealRoutine) {
                    *ImportThunk = (ULONG_PTR)(VerifierThunk->NewRoutine);
                    Found = TRUE;
                    break;
                }
                VerifierThunk += 1;
            }
        }

        if (Found == FALSE) {

            NextEntry = MiVerifierDriverAddedThunkListHead.Flink;
            while (NextEntry != &MiVerifierDriverAddedThunkListHead) {

                ThunkTableBase = CONTAINING_RECORD(NextEntry,
                                                   DRIVER_SPECIFIED_VERIFIER_THUNKS,
                                                   ListEntry);

                ThunkTable = (PDRIVER_VERIFIER_THUNK_PAIRS)(ThunkTableBase + 1);

                for (j = 0; j < ThunkTableBase->NumberOfThunks; j += 1) {

                    if (*ImportThunk == (ULONG_PTR)ThunkTable->PristineRoutine) {
                        *ImportThunk = (ULONG_PTR)(ThunkTable->NewRoutine);
                        Found = TRUE;
                        break;
                    }
                    ThunkTable += 1;
                }

                if (Found == TRUE) {
                    break;
                }

                NextEntry = NextEntry->Flink;
            }
        }
    }
    return TRUE;
}

LOGICAL
MiReEnableVerifier (
    IN PKLDR_DATA_TABLE_ENTRY DataTableEntry
    )

/*++

Routine Description:

    This function thunks DLL-supplied APIs in the argument driver import table.

Arguments:

    DataTableEntry - Supplies the data table entry for the driver.

Return Value:

    TRUE if thunking was applied, FALSE if not.

Environment:

    Kernel mode, Phase 0 Initialization only.
    Non paged pool exists in Phase0, but paged pool does not.

--*/

{
    ULONG i;
    ULONG j;
    PULONG_PTR ImportThunk;
    ULONG ImportSize;
    LOGICAL Found;
    PLIST_ENTRY NextEntry;
    PMMPTE PointerPte;
    PULONG_PTR VirtualThunk;
    PFN_NUMBER PageFrameIndex;
    PFN_NUMBER VirtualPageFrameIndex;
    PDRIVER_VERIFIER_THUNK_PAIRS ThunkTable;
    PDRIVER_SPECIFIED_VERIFIER_THUNKS ThunkTableBase;
    ULONG Offset;

    ImportThunk = (PULONG_PTR)RtlImageDirectoryEntryToData(
                                               DataTableEntry->DllBase,
                                               TRUE,
                                               IMAGE_DIRECTORY_ENTRY_IAT,
                                               &ImportSize);

    if (ImportThunk == NULL) {
        return FALSE;
    }

    VirtualThunk = NULL;
    ImportSize /= sizeof(PULONG_PTR);

    //
    // Initializing VirtualPageFrameIndex is not needed for correctness, but
    // without it the compiler cannot compile this code W4 to check for use of
    // uninitialized variables.
    //

    VirtualPageFrameIndex = 0;

    for (i = 0; i < ImportSize; i += 1, ImportThunk += 1) {

        Found = FALSE;

        NextEntry = MiVerifierDriverAddedThunkListHead.Flink;
        while (NextEntry != &MiVerifierDriverAddedThunkListHead) {

            ThunkTableBase = CONTAINING_RECORD(NextEntry,
                                               DRIVER_SPECIFIED_VERIFIER_THUNKS,
                                               ListEntry);

            ThunkTable = (PDRIVER_VERIFIER_THUNK_PAIRS)(ThunkTableBase + 1);

            for (j = 0; j < ThunkTableBase->NumberOfThunks; j += 1) {

                if (*ImportThunk == (ULONG_PTR)ThunkTable->PristineRoutine) {

                    ASSERT (MI_IS_PHYSICAL_ADDRESS(ImportThunk) == 0);
                    PointerPte = MiGetPteAddress (ImportThunk);
                    ASSERT (PointerPte->u.Hard.Valid == 1);
                    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
                    Offset = (ULONG) MiGetByteOffset(ImportThunk);

                    if ((VirtualThunk != NULL) &&
                        (VirtualPageFrameIndex == PageFrameIndex)) {

                        NOTHING;
                    }
                    else {

                        VirtualThunk = MiMapSinglePage (VirtualThunk,
                                                        PageFrameIndex,
                                                        MmCached,
                                                        HighPagePriority);

                        if (VirtualThunk == NULL) {
                            return FALSE;
                        }
                        VirtualPageFrameIndex = PageFrameIndex;
                    }

                    *(PULONG_PTR)((PUCHAR)VirtualThunk + Offset) =
                        (ULONG_PTR)(ThunkTable->NewRoutine);

                    Found = TRUE;
                    break;
                }
                ThunkTable += 1;
            }

            if (Found == TRUE) {
                break;
            }

            NextEntry = NextEntry->Flink;
        }
    }

    if (VirtualThunk != NULL) {
        MiUnmapSinglePage (VirtualThunk);
    }

    return TRUE;
}

typedef struct _KERNEL_VERIFIER_THUNK_PAIRS {
    PDRIVER_VERIFIER_THUNK_ROUTINE  PristineRoutine;
    PDRIVER_VERIFIER_THUNK_ROUTINE  NewRoutine;
} KERNEL_VERIFIER_THUNK_PAIRS, *PKERNEL_VERIFIER_THUNK_PAIRS;

#if defined(_X86_)

#ifdef ALLOC_DATA_PRAGMA
#pragma const_seg("INITCONST")
#endif

const KERNEL_VERIFIER_THUNK_PAIRS MiKernelVerifierThunks[] = {

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KeRaiseIrql,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKeRaiseIrql,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KeLowerIrql,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKeLowerIrql,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KeAcquireSpinLock,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKeAcquireSpinLock,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KeReleaseSpinLock,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKeReleaseSpinLock,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KfRaiseIrql,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKfRaiseIrql,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KeRaiseIrqlToDpcLevel,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKeRaiseIrqlToDpcLevel,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KfLowerIrql,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKfLowerIrql,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KfAcquireSpinLock,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKfAcquireSpinLock,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KfReleaseSpinLock,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKfReleaseSpinLock,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)ExAcquireFastMutex,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierExAcquireFastMutex,

#if !defined(NT_UP)
    (PDRIVER_VERIFIER_THUNK_ROUTINE)KeAcquireQueuedSpinLock,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKeAcquireQueuedSpinLock,

    (PDRIVER_VERIFIER_THUNK_ROUTINE)KeReleaseQueuedSpinLock,
    (PDRIVER_VERIFIER_THUNK_ROUTINE)VerifierKeReleaseQueuedSpinLock,
#endif
};

#ifdef ALLOC_DATA_PRAGMA
#pragma const_seg()
#endif

VOID
MiEnableKernelVerifier (
    VOID
    )

/*++

Routine Description:

    This function enables the verifier for the kernel by thunking
    relevant HAL APIs in the kernel's import table.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode, Phase 1 Initialization.

--*/

{
    ULONG i;
    PULONG_PTR ImportThunk;
    ULONG ImportSize;
    KERNEL_VERIFIER_THUNK_PAIRS const *VerifierThunk;
    ULONG ThunkCount;
    ULONG_PTR RealRoutine;
    PULONG_PTR PointerRealRoutine;

    if (KernelVerifier == FALSE) {
        return;
    }

    ImportThunk = (PULONG_PTR)RtlImageDirectoryEntryToData(
                                               PsNtosImageBase,
                                               TRUE,
                                               IMAGE_DIRECTORY_ENTRY_IAT,
                                               &ImportSize);

    if (ImportThunk == NULL) {
        return;
    }

    ImportSize /= sizeof(PULONG_PTR);

    for (i = 0; i < ImportSize; i += 1, ImportThunk += 1) {

        VerifierThunk = MiKernelVerifierThunks;

        for (ThunkCount = 0; ThunkCount < sizeof (MiKernelVerifierThunks) / sizeof (KERNEL_VERIFIER_THUNK_PAIRS); ThunkCount += 1) {

            //
            // Only the x86 has/needs this oddity - take the kernel address,
            // knowing that it points at a 2 byte jmp opcode followed by
            // a 4-byte indirect pointer to a destination address.
            //

            PointerRealRoutine = (PULONG_PTR)*((PULONG_PTR)((ULONG_PTR)VerifierThunk->PristineRoutine + 2));
            RealRoutine = *PointerRealRoutine;

            if (*ImportThunk == RealRoutine) {

                //
                // Order is important here.
                //

                if (MiKernelVerifierOriginalCalls[ThunkCount] == NULL) {
                    MiKernelVerifierOriginalCalls[ThunkCount] = (PVOID)RealRoutine;
                }

                *ImportThunk = (ULONG_PTR)(VerifierThunk->NewRoutine);

                break;
            }
            VerifierThunk += 1;
        }
    }
    return;
}
#endif

//
// BEWARE: Various kernel macros were undefined above so we can pull in the
// real routines.  This is needed because the real routines are exported for
// driver compatibility.  This module has been carefully laid out so these
// macros are not referenced from that point to here and references go to the
// real routines.
//
// BE EXTREMELY CAREFUL IF YOU DECIDE TO ADD ROUTINES BELOW THIS POINT !
//
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\triage.c ===
/*++

Copyright (c) 1999  Microsoft Corporation

Module Name:

   triage.c

Abstract:

    This module contains the Phase 0 code to triage bugchecks and
    automatically enable various system tracing components until the
    guilty party is found.

Author:

    Landy Wang 13-Jan-1999

Revision History:

--*/

#include "mi.h"
#include "ntiodump.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,MiTriageSystem)
#pragma alloc_text(INIT,MiTriageAddDrivers)
#endif

//
// Always update this macro when adding triage support for additional bugchecks.
//

#define MI_CAN_TRIAGE_BUGCHECK(BugCheckCode) \
         ((BugCheckCode) == NO_MORE_SYSTEM_PTES || \
         (BugCheckCode) == BAD_POOL_HEADER || \
         (BugCheckCode) == DRIVER_CORRUPTED_SYSPTES || \
         (BugCheckCode) == DRIVER_CORRUPTED_EXPOOL || \
         (BugCheckCode) == DRIVER_CORRUPTED_MMPOOL)

//
// These are bugchecks that were presumably triggered by either autotriage or
// the admin's registry settings - so don't apply any new rules and in addition,
// keep the old ones unaltered so it can reproduce.
//

#define MI_HOLD_TRIAGE_BUGCHECK(BugCheckCode) \
        ((BugCheckCode) == DRIVER_USED_EXCESSIVE_PTES || \
         (BugCheckCode) == DRIVER_LEFT_LOCKED_PAGES_IN_PROCESS || \
         (BugCheckCode) == PAGE_FAULT_IN_FREED_SPECIAL_POOL || \
         (BugCheckCode) == DRIVER_PAGE_FAULT_IN_FREED_SPECIAL_POOL || \
         (BugCheckCode) == PAGE_FAULT_BEYOND_END_OF_ALLOCATION || \
         (BugCheckCode) == DRIVER_PAGE_FAULT_BEYOND_END_OF_ALLOCATION || \
         (BugCheckCode) == DRIVER_CAUGHT_MODIFYING_FREED_POOL || \
         (BugCheckCode) == SYSTEM_PTE_MISUSE)

#define MI_TRACKING_PTES                    0x00000002
#define MI_PROTECT_FREED_NONPAGED_POOL      0x00000004
#define MI_VERIFYING_PRENT5_DRIVERS         0x00000008
#define MI_KEEPING_PREVIOUS_SETTINGS        0x00000010

#ifdef ALLOC_DATA_PRAGMA
#pragma const_seg("INITCONST")
#pragma data_seg("INITDATA")
#endif
const PCHAR MiTriageActionStrings[] = {
    "Locked pages tracking",
    "System PTE usage tracking",
    "Making accesses to freed nonpaged pool cause bugchecks",
    "Driver Verifying Pre-Windows 2000 built drivers",
    "Keeping previous autotriage settings"
};

#if DBG
ULONG MiTriageDebug = 0;
BOOLEAN MiTriageRegardless = FALSE;
#endif

#ifdef ALLOC_DATA_PRAGMA
#pragma const_seg()
#pragma data_seg()
#endif

//
// N.B.  The debugger references this.
//

ULONG MmTriageActionTaken;

//
// The Version number must be incremented whenever the MI_TRIAGE_STORAGE
// structure is changed.  This enables usermode programs to decode the Mm
// portions of triage dumps regardless of which kernel revision created the
// dump.
//

typedef struct _MI_TRIAGE_STORAGE {
    ULONG Version;
    ULONG Size;
    ULONG MmSpecialPoolTag;
    ULONG MiTriageActionTaken;

    ULONG MmVerifyDriverLevel;
    ULONG KernelVerifier;
    ULONG_PTR MmMaximumNonPagedPool;
    ULONG_PTR MmAllocatedNonPagedPool;

    ULONG_PTR PagedPoolMaximum;
    ULONG_PTR PagedPoolAllocated;

    ULONG_PTR CommittedPages;
    ULONG_PTR CommittedPagesPeak;
    ULONG_PTR CommitLimitMaximum;

} MI_TRIAGE_STORAGE, *PMI_TRIAGE_STORAGE;

PKLDR_DATA_TABLE_ENTRY
TriageGetLoaderEntry (
    IN PVOID TriageDumpBlock,
    IN ULONG ModuleIndex
    );

LOGICAL
TriageActUpon(
    IN PVOID TriageDumpBlock
    );

PVOID
TriageGetMmInformation (
    IN PVOID TriageDumpBlock
    );


LOGICAL
MiTriageSystem (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )

/*++

Routine Description:

    This routine takes the information from the last bugcheck (if any)
    and triages it.  Various debugging options are then automatically
    enabled.

Arguments:

    LoaderBlock - Supplies a pointer to the system loader block.

Return Value:

    TRUE if triaging succeeded and options were enabled.  FALSE otherwise.

--*/

{
    PVOID TriageDumpBlock;
    ULONG_PTR BugCheckData[5];
    ULONG i;
    ULONG ModuleCount;
    NTSTATUS Status;
    PLIST_ENTRY NextEntry;
    PKLDR_DATA_TABLE_ENTRY DataTableEntry;
    PKLDR_DATA_TABLE_ENTRY DumpTableEntry;
    LOGICAL Matched;
    ULONG OldDrivers;
    ULONG OldDriversNotVerifying;
    PMI_TRIAGE_STORAGE TriageInformation;
    
    if (LoaderBlock->Extension == NULL) {
        return FALSE;
    }

    if (LoaderBlock->Extension->Size < sizeof (LOADER_PARAMETER_EXTENSION)) {
        return FALSE;
    }

    TriageDumpBlock = LoaderBlock->Extension->TriageDumpBlock;

    Status = TriageGetBugcheckData (TriageDumpBlock,
                                    (PULONG)&BugCheckData[0],
                                    (PUINT_PTR) &BugCheckData[1],
                                    (PUINT_PTR) &BugCheckData[2],
                                    (PUINT_PTR) &BugCheckData[3],
                                    (PUINT_PTR) &BugCheckData[4]);

    if (!NT_SUCCESS (Status)) {
        return FALSE;
    }

    //
    // Always display at least the bugcheck data from the previous crash.
    //

    DbgPrint ("MiTriageSystem: Previous bugcheck was %x %p %p %p %p\n",
        BugCheckData[0],
        BugCheckData[1],
        BugCheckData[2],
        BugCheckData[3],
        BugCheckData[4]);

    if (TriageActUpon (TriageDumpBlock) == FALSE) {
        DbgPrint ("MiTriageSystem: Triage disabled in registry by administrator\n");
        return FALSE;
    }

    DbgPrint ("MiTriageSystem: Triage ENABLED in registry by administrator\n");

    //
    // See if the previous bugcheck was one where action can be taken.
    // If not, bail now.  If so, then march on and verify all the loaded
    // module checksums before actually taking action on the bugcheck.
    //

    if (!MI_CAN_TRIAGE_BUGCHECK(BugCheckData[0])) {
        return FALSE;
    }

    TriageInformation = (PMI_TRIAGE_STORAGE) TriageGetMmInformation (TriageDumpBlock);

    if (TriageInformation == NULL) {
        return FALSE;
    }

    Status = TriageGetDriverCount (TriageDumpBlock, &ModuleCount);

    if (!NT_SUCCESS (Status)) {
        return FALSE;
    }

    //
    // Process module information from the triage dump.
    //

#if DBG
    if (MiTriageDebug & 0x1) {
        DbgPrint ("MiTriageSystem: printing active drivers from triage crash...\n");
    }
#endif

    OldDrivers = 0;
    OldDriversNotVerifying = 0;

    for (i = 0; i < ModuleCount; i += 1) {

        DumpTableEntry = TriageGetLoaderEntry (TriageDumpBlock, i);

        if (DumpTableEntry != NULL) {

            if ((DumpTableEntry->Flags & LDRP_ENTRY_NATIVE) == 0) {
                OldDrivers += 1;
                if ((DumpTableEntry->Flags & LDRP_IMAGE_VERIFYING) == 0) {

                    //
                    // An NT3 or NT4 driver is in the system and was not
                    // running under the verifier.
                    //

                    OldDriversNotVerifying += 1;
                }
            }
#if DBG
            if (MiTriageDebug & 0x1) {

                DbgPrint (" %wZ: base = %p, size = %lx, flags = %lx\n",
                          &DumpTableEntry->BaseDllName,
                          DumpTableEntry->DllBase,
                          DumpTableEntry->SizeOfImage,
                          DumpTableEntry->Flags);
            }
#endif
        }
    }

    //
    // Ensure that every driver that is currently loaded is identical to
    // the one in the triage dump before proceeding.
    //

    NextEntry = LoaderBlock->LoadOrderListHead.Flink;

    while (NextEntry != &LoaderBlock->LoadOrderListHead) {

        DataTableEntry = CONTAINING_RECORD(NextEntry,
                                           KLDR_DATA_TABLE_ENTRY,
                                           InLoadOrderLinks);

        Matched = FALSE;

        for (i = 0; i < ModuleCount; i += 1) {
    
            DumpTableEntry = TriageGetLoaderEntry (TriageDumpBlock, i);
    
            if (DumpTableEntry != NULL) {
    
                if (DataTableEntry->CheckSum == DumpTableEntry->CheckSum) {
                    Matched = TRUE;
                    break;
                }
            }
        }
    
        if (Matched == FALSE) {
            DbgPrint ("Matching checksum for module %wZ not found in triage dump\n",
                &DataTableEntry->BaseDllName);

#if DBG
            if (MiTriageRegardless == FALSE)
#endif
            return FALSE;
        }

        NextEntry = NextEntry->Flink;
    }

#if DBG
    if (MiTriageDebug & 0x1) {
        DbgPrint ("MiTriageSystem: OldDrivers = %u, without verification =%u\n",
            OldDrivers,
            OldDriversNotVerifying);
    }
#endif

    //
    // All boot loaded drivers matched, take action on the triage dump now.
    //

    if (MI_HOLD_TRIAGE_BUGCHECK(BugCheckData[0])) {

        //
        // The last bugcheck was presumably triggered by either autotriage or
        // the admin's registry settings - so don't apply any new rules
        // and in addition, keep the old ones unaltered so it can reproduce.
        //

        MmTriageActionTaken = TriageInformation->MiTriageActionTaken;
        MmTriageActionTaken |= MI_KEEPING_PREVIOUS_SETTINGS;
    }
    else {
    
        switch (BugCheckData[0]) {
    
            case DRIVER_CORRUPTED_SYSPTES:
    
                //
                // Turn on PTE tracking to trigger a SYSTEM_PTE_MISUSE bugcheck.
                //
    
                MmTriageActionTaken |= MI_TRACKING_PTES;
                break;
    
            case NO_MORE_SYSTEM_PTES:
    
                //
                // Turn on PTE tracking so the driver can be identified via a
                // DRIVER_USED_EXCESSIVE_PTES bugcheck.
                //
    
                if (BugCheckData[1] == SystemPteSpace) {
                    MmTriageActionTaken |= MI_TRACKING_PTES;
                }
                break;
    
            case BAD_POOL_HEADER:
            case DRIVER_CORRUPTED_EXPOOL:
    
                //
                // Turn on the driver verifier and/or special pool.
                // Start by enabling it for every driver that isn't built for NT5.
                // Override any specified driver verifier options so that only
                // special pool is enabled to minimize the performance hit.
                //
    
                if (OldDrivers != 0) {
                    if (OldDriversNotVerifying != 0) {
                        MmTriageActionTaken |= MI_VERIFYING_PRENT5_DRIVERS;
                    }
                }
    
                break;
    
            case DRIVER_CORRUPTED_MMPOOL:
    
                //
                // Protect freed nonpaged pool if the system had less than 128mb
                // of nonpaged pool anyway.  This is to trigger a
                // DRIVER_CAUGHT_MODIFYING_FREED_POOL bugcheck.
                //
    
#define MB128 ((ULONG_PTR)0x80000000 >> PAGE_SHIFT)
    
                if (TriageInformation->MmMaximumNonPagedPool < MB128) {
                    MmTriageActionTaken |= MI_PROTECT_FREED_NONPAGED_POOL;
                }
                break;
    
            case IRQL_NOT_LESS_OR_EQUAL:
            case DRIVER_IRQL_NOT_LESS_OR_EQUAL:
            default:
                break;
        }
    }

    //
    // For now always show if action was taken from the bugcheck
    // data from the crash.  This print and the space for the print strings
    // will be enabled for checked builds only prior to shipping.
    //

    if (MmTriageActionTaken != 0) {

        if (MmTriageActionTaken & MI_TRACKING_PTES) {
            MmTrackPtes |= 0x1;
        }
    
        if (MmTriageActionTaken & MI_VERIFYING_PRENT5_DRIVERS) {
            MmVerifyDriverLevel &= ~DRIVER_VERIFIER_FORCE_IRQL_CHECKING;
            MmVerifyDriverLevel |= DRIVER_VERIFIER_SPECIAL_POOLING;
        }
    
        if (MmTriageActionTaken & MI_PROTECT_FREED_NONPAGED_POOL) {
            MmProtectFreedNonPagedPool = TRUE;
        }

        DbgPrint ("MiTriageSystem: enabling options below to find who caused the last crash\n");

        for (i = 0; i < 32; i += 1) {
            if (MmTriageActionTaken & (1 << i)) {
                DbgPrint ("  %s\n", MiTriageActionStrings[i]);
            }
        }
    }

    return TRUE;
}


LOGICAL
MiTriageAddDrivers (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )

/*++

Routine Description:

    This routine moves the names of any drivers that autotriage has determined
    need verifying from the LoaderBlock into pool.

Arguments:

    LoaderBlock - Supplies a pointer to the system loader block.

Return Value:

    TRUE if any drivers were added, FALSE if not.

--*/

{
    ULONG i;
    ULONG ModuleCount;
    NTSTATUS Status;
    PKLDR_DATA_TABLE_ENTRY DumpTableEntry;
    PVOID TriageDumpBlock;
    ULONG NameLength;
    LOGICAL Added;
    PMI_VERIFIER_DRIVER_ENTRY VerifierDriverEntry;

    if ((MmTriageActionTaken & MI_VERIFYING_PRENT5_DRIVERS) == 0) {
        return FALSE;
    }

    TriageDumpBlock = LoaderBlock->Extension->TriageDumpBlock;

    Status = TriageGetDriverCount (TriageDumpBlock, &ModuleCount);

    if (!NT_SUCCESS (Status)) {
        return FALSE;
    }

    Added = FALSE;

    for (i = 0; i < ModuleCount; i += 1) {

        DumpTableEntry = TriageGetLoaderEntry (TriageDumpBlock, i);

        if (DumpTableEntry == NULL) {
            continue;
        }

        if (DumpTableEntry->Flags & LDRP_ENTRY_NATIVE) {
            continue;
        }

        DbgPrint ("MiTriageAddDrivers: Marking %wZ for verification when it is loaded\n", &DumpTableEntry->BaseDllName);

        NameLength = DumpTableEntry->BaseDllName.Length;

        VerifierDriverEntry = (PMI_VERIFIER_DRIVER_ENTRY)ExAllocatePoolWithTag (
                                    NonPagedPool,
                                    sizeof (MI_VERIFIER_DRIVER_ENTRY) +
                                                        NameLength,
                                    'dLmM');

        if (VerifierDriverEntry == NULL) {
            continue;
        }

        VerifierDriverEntry->Loads = 0;
        VerifierDriverEntry->Unloads = 0;
        VerifierDriverEntry->BaseName.Buffer = (PWSTR)((PCHAR)VerifierDriverEntry +
                            sizeof (MI_VERIFIER_DRIVER_ENTRY));

        VerifierDriverEntry->BaseName.Length = (USHORT)NameLength;
        VerifierDriverEntry->BaseName.MaximumLength = (USHORT)NameLength;

        RtlCopyMemory (VerifierDriverEntry->BaseName.Buffer,
                       DumpTableEntry->BaseDllName.Buffer,
                       NameLength);

        InsertHeadList (&MiSuspectDriverList, &VerifierDriverEntry->Links);
        Added = TRUE;
    }

    return Added;
}

#define MAX_UNLOADED_NAME_LENGTH    24

typedef struct _DUMP_UNLOADED_DRIVERS {
    UNICODE_STRING Name;
    WCHAR DriverName[MAX_UNLOADED_NAME_LENGTH / sizeof (WCHAR)];
    PVOID StartAddress;
    PVOID EndAddress;
} DUMP_UNLOADED_DRIVERS, *PDUMP_UNLOADED_DRIVERS;


ULONG
MmSizeOfUnloadedDriverInformation (
    VOID
    )

/*++

Routine Description:

    This routine returns the size of the Mm-internal unloaded driver
    information that is stored in the triage dump when (if?) the system crashes.

Arguments:

    None.

Return Value:

    Size of the Mm-internal unloaded driver information.

--*/

{
    if (MmUnloadedDrivers == NULL) {
        return sizeof (ULONG_PTR);
    }

    return sizeof(ULONG_PTR) + MI_UNLOADED_DRIVERS * sizeof(DUMP_UNLOADED_DRIVERS);
}


VOID
MmWriteUnloadedDriverInformation (
    IN PVOID Destination
    )

/*++

Routine Description:

    This routine stores the Mm-internal unloaded driver information into
    the triage dump.

Arguments:

    None.

Return Value:

    None.

--*/

{
    ULONG i;
    ULONG Index;
    PUNLOADED_DRIVERS Unloaded;
    PDUMP_UNLOADED_DRIVERS DumpUnloaded;

    if (MmUnloadedDrivers == NULL) {
        *(PULONG)Destination = 0;
    }
    else {

        DumpUnloaded = (PDUMP_UNLOADED_DRIVERS)((PULONG_PTR)Destination + 1);
        Unloaded = MmUnloadedDrivers;

        //
        // Write the list with the most recently unloaded driver first to the
        // least recently unloaded driver last.
        //

        Index = MmLastUnloadedDriver - 1;

        for (i = 0; i < MI_UNLOADED_DRIVERS; i += 1) {

            if (Index >= MI_UNLOADED_DRIVERS) {
                Index = MI_UNLOADED_DRIVERS - 1;
            }

            Unloaded = &MmUnloadedDrivers[Index];

            DumpUnloaded->Name = Unloaded->Name;

            if (Unloaded->Name.Buffer == NULL) {
                break;
            }

            DumpUnloaded->StartAddress = Unloaded->StartAddress;
            DumpUnloaded->EndAddress = Unloaded->EndAddress;

            if (DumpUnloaded->Name.Length > MAX_UNLOADED_NAME_LENGTH) {
                DumpUnloaded->Name.Length = MAX_UNLOADED_NAME_LENGTH;
            }

            if (DumpUnloaded->Name.MaximumLength > MAX_UNLOADED_NAME_LENGTH) {
                DumpUnloaded->Name.MaximumLength = MAX_UNLOADED_NAME_LENGTH;
            }

            DumpUnloaded->Name.Buffer = DumpUnloaded->DriverName;

            RtlCopyMemory ((PVOID)DumpUnloaded->Name.Buffer,
                           (PVOID)Unloaded->Name.Buffer,
                           DumpUnloaded->Name.MaximumLength);

            DumpUnloaded += 1;
            Index -= 1;
        }

        *(PULONG)Destination = i;
    }
}


ULONG
MmSizeOfTriageInformation (
    VOID
    )

/*++

Routine Description:

    This routine returns the size of the Mm-internal information that is
    stored in the triage dump when (if?) the system crashes.

Arguments:

    None.

Return Value:

    Size of the Mm-internal triage information.

--*/

{
    return sizeof (MI_TRIAGE_STORAGE);
}


VOID
MmWriteTriageInformation (
    IN PVOID Destination
    )

/*++

Routine Description:

    This routine stores the Mm-internal information into the triage dump.

Arguments:

    None.

Return Value:

    None.

--*/

{
    MI_TRIAGE_STORAGE TriageInformation;

    TriageInformation.Version = 1;
    TriageInformation.Size = sizeof (MI_TRIAGE_STORAGE);

    TriageInformation.MmSpecialPoolTag = MmSpecialPoolTag;
    TriageInformation.MiTriageActionTaken = MmTriageActionTaken;

    TriageInformation.MmVerifyDriverLevel = MmVerifierData.Level;
    TriageInformation.KernelVerifier = KernelVerifier;

    TriageInformation.MmMaximumNonPagedPool = MmMaximumNonPagedPoolInBytes >> PAGE_SHIFT;
    TriageInformation.MmAllocatedNonPagedPool = MmAllocatedNonPagedPool;

    TriageInformation.PagedPoolMaximum = MmSizeOfPagedPoolInBytes >> PAGE_SHIFT;
    TriageInformation.PagedPoolAllocated = MmPagedPoolInfo.AllocatedPagedPool;

    TriageInformation.CommittedPages = MmTotalCommittedPages;
    TriageInformation.CommittedPagesPeak = MmPeakCommitment;
    TriageInformation.CommitLimitMaximum = MmTotalCommitLimitMaximum;

    RtlCopyMemory (Destination,
                   (PVOID)&TriageInformation,
                   sizeof (MI_TRIAGE_STORAGE));
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\wrtfault.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

   wrtfault.c

Abstract:

    This module contains the copy on write routine for memory management.

Author:

    Lou Perazzoli (loup) 10-Apr-1989
    Landy Wang (landyw) 02-June-1997

Revision History:

--*/

#include "mi.h"

LOGICAL
FASTCALL
MiCopyOnWrite (
    IN PVOID FaultingAddress,
    IN PMMPTE PointerPte
    )

/*++

Routine Description:

    This routine performs a copy on write operation for the specified
    virtual address.

Arguments:

    FaultingAddress - Supplies the virtual address which caused the fault.

    PointerPte - Supplies the pointer to the PTE which caused the page fault.

Return Value:

    Returns TRUE if the page was actually split, FALSE if not.

Environment:

    Kernel mode, APCs disabled, working set mutex held.

--*/

{
    MMPTE TempPte;
    PFN_NUMBER PageFrameIndex;
    PFN_NUMBER NewPageIndex;
    PULONG CopyTo;
    PULONG CopyFrom;
    KIRQL OldIrql;
    PMMPFN Pfn1;
    PEPROCESS CurrentProcess;
    PMMCLONE_BLOCK CloneBlock;
    PMMCLONE_DESCRIPTOR CloneDescriptor;
    WSLE_NUMBER WorkingSetIndex;
    LOGICAL FakeCopyOnWrite;
    PMMWSL WorkingSetList;
    PVOID SessionSpace;
    PLIST_ENTRY NextEntry;
    PIMAGE_ENTRY_IN_SESSION Image;

    //
    // This is called from MmAccessFault, the PointerPte is valid
    // and the working set mutex ensures it cannot change state.
    //
    // Capture the PTE contents to TempPte.
    //

    TempPte = *PointerPte;
    ASSERT (TempPte.u.Hard.Valid == 1);

    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (&TempPte);
    Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

    //
    // Check to see if this is a prototype PTE with copy on write enabled.
    //

    FakeCopyOnWrite = FALSE;
    CurrentProcess = PsGetCurrentProcess ();
    CloneBlock = NULL;

    if (FaultingAddress >= (PVOID) MmSessionBase) {

        WorkingSetList = MmSessionSpace->Vm.VmWorkingSetList;
        ASSERT (Pfn1->u3.e1.PrototypePte == 1);
        SessionSpace = (PVOID) MmSessionSpace;

        MM_SESSION_SPACE_WS_LOCK_ASSERT ();

        if (MmSessionSpace->ImageLoadingCount != 0) {

            NextEntry = MmSessionSpace->ImageList.Flink;
    
            while (NextEntry != &MmSessionSpace->ImageList) {
    
                Image = CONTAINING_RECORD (NextEntry, IMAGE_ENTRY_IN_SESSION, Link);
    
                if ((FaultingAddress >= Image->Address) &&
                    (FaultingAddress <= Image->LastAddress)) {
    
                    if (Image->ImageLoading) {
    
                        ASSERT (Pfn1->u3.e1.PrototypePte == 1);
    
                        TempPte.u.Hard.CopyOnWrite = 0;
                        TempPte.u.Hard.Write = 1;
    
                        //
                        // The page is no longer copy on write, update the PTE
                        // setting both the dirty bit and the accessed bit.
                        //
                        // Even though the page's current backing is the image
                        // file, the modified writer will convert it to
                        // pagefile backing when it notices the change later.
                        //
    
                        MI_SET_PTE_DIRTY (TempPte);
                        MI_SET_ACCESSED_IN_PTE (&TempPte, 1);
    
                        MI_WRITE_VALID_PTE_NEW_PROTECTION (PointerPte, TempPte);
    
                        //
                        // The TB entry must be flushed as the valid PTE with
                        // the dirty bit clear has been fetched into the TB. If
                        // it isn't flushed, another fault is generated as the
                        // dirty bit is not set in the cached TB entry.
                        //
    
                        MI_FLUSH_SINGLE_SESSION_TB (FaultingAddress);
    
                        return FALSE;
                    }
                    break;
                }
    
                NextEntry = NextEntry->Flink;
            }
        }

#if 0

        //
        // This ASSERT is triggered if the session image came from removable
        // media (ie: a special CD install, etc) so it cannot be enabled.
        //

        ASSERT (Pfn1->u3.e1.Modified == 0);

#endif

    }
    else {
        WorkingSetList = MmWorkingSetList;
        SessionSpace = NULL;

        //
        // If a fork operation is in progress, block until the fork is
        // completed, then retry the whole operation as the state of
        // everything may have changed between when the mutexes were
        // released and reacquired.
        //

        if (CurrentProcess->ForkInProgress != NULL) {
            if (MiWaitForForkToComplete (CurrentProcess) == TRUE) {
                return FALSE;
            }
        }

        if (TempPte.u.Hard.CopyOnWrite == 0) {

            //
            // This is a fork page which is being made private in order
            // to change the protection of the page.
            // Do not make the page writable.
            //

            FakeCopyOnWrite = TRUE;
        }
    }

    WorkingSetIndex = MiLocateWsle (FaultingAddress,
                                    WorkingSetList,
                                    Pfn1->u1.WsIndex);

    //
    // The page must be copied into a new page.
    //

    LOCK_PFN (OldIrql);

    if ((MmAvailablePages < MM_HIGH_LIMIT) &&
        (MiEnsureAvailablePageOrWait (SessionSpace != NULL ? HYDRA_PROCESS : CurrentProcess, NULL, OldIrql))) {

        //
        // A wait operation was performed to obtain an available
        // page and the working set mutex and PFN lock have
        // been released and various things may have changed for
        // the worse.  Rather than examine all the conditions again,
        // return and if things are still proper, the fault will
        // be taken again.
        //

        UNLOCK_PFN (OldIrql);
        return FALSE;
    }

    //
    // This must be a prototype PTE.  Perform the copy on write.
    //

#if DBG
    if (Pfn1->u3.e1.PrototypePte == 0) {
        DbgPrint ("writefault - PTE indicates cow but not protopte\n");
        MiFormatPte (PointerPte);
        MiFormatPfn (Pfn1);
    }
#endif

    //
    // A page is being copied and made private, the global state of
    // the shared page needs to be updated at this point on certain
    // hardware.  This is done by ORing the dirty bit into the modify bit in
    // the PFN element.
    //
    // Note that a session page cannot be dirty (no POSIX-style forking is
    // supported for these drivers).
    //

    if (SessionSpace != NULL) {
        ASSERT ((TempPte.u.Hard.Valid == 1) && (TempPte.u.Hard.Write == 0));
        ASSERT (!MI_IS_PTE_DIRTY (TempPte));

        NewPageIndex = MiRemoveAnyPage (MI_GET_PAGE_COLOR_FROM_SESSION(MmSessionSpace));
    }
    else {
        MI_CAPTURE_DIRTY_BIT_TO_PFN (PointerPte, Pfn1);
        CloneBlock = (PMMCLONE_BLOCK) Pfn1->PteAddress;

        //
        // Get a new page with the same color as this page.
        //

        NewPageIndex = MiRemoveAnyPage (
                        MI_PAGE_COLOR_PTE_PROCESS(PageFrameIndex,
                                              &CurrentProcess->NextPageColor));
    }

    MiInitializeCopyOnWritePfn (NewPageIndex,
                                PointerPte,
                                WorkingSetIndex,
                                SessionSpace);

    UNLOCK_PFN (OldIrql);

    InterlockedIncrement ((PLONG) &MmInfoCounters.CopyOnWriteCount);

#if defined(_MIALT4K_)

    //
    // Avoid accessing user space as it may potentially 
    // cause a page fault on the alternate table.   
    //

    CopyFrom = KSEG_ADDRESS (PageFrameIndex);

#else

    CopyFrom = (PULONG) PAGE_ALIGN (FaultingAddress);

#endif

    CopyTo = (PULONG) MiMapPageInHyperSpace (CurrentProcess,
                                             NewPageIndex,
                                             &OldIrql);

    RtlCopyMemory (CopyTo, CopyFrom, PAGE_SIZE);

    PERFINFO_PRIVATE_COPY_ON_WRITE(CopyFrom, PAGE_SIZE);

    MiUnmapPageInHyperSpace (CurrentProcess, CopyTo, OldIrql);

    if (!FakeCopyOnWrite) {

        //
        // If the page was really a copy on write page, make it
        // accessed, dirty and writable.  Also, clear the copy-on-write
        // bit in the PTE.
        //

        MI_SET_PTE_DIRTY (TempPte);
        TempPte.u.Hard.Write = 1;
        MI_SET_ACCESSED_IN_PTE (&TempPte, 1);
        TempPte.u.Hard.CopyOnWrite = 0;
    }

    //
    // Regardless of whether the page was really a copy on write,
    // the frame field of the PTE must be updated.
    //

    TempPte.u.Hard.PageFrameNumber = NewPageIndex;

    //
    // If the modify bit is set in the PFN database for the
    // page, the data cache must be flushed.  This is due to the
    // fact that this process may have been cloned and the cache
    // still contains stale data destined for the page we are
    // going to remove.
    //

    ASSERT (TempPte.u.Hard.Valid == 1);

    MI_WRITE_VALID_PTE_NEW_PAGE (PointerPte, TempPte);

    //
    // Flush the TB entry for this page.
    //

    if (SessionSpace == NULL) {

        KeFlushSingleTb (FaultingAddress, FALSE);

        //
        // Increment the number of private pages.
        //

        CurrentProcess->NumberOfPrivatePages += 1;
    }
    else {

        MI_FLUSH_SINGLE_SESSION_TB (FaultingAddress);

        ASSERT (Pfn1->u3.e1.PrototypePte == 1);
    }

    //
    // Decrement the share count for the page which was copied
    // as this PTE no longer refers to it.
    //

    LOCK_PFN (OldIrql);

    MiDecrementShareCount (Pfn1, PageFrameIndex);

    if (SessionSpace == NULL) {

        CloneDescriptor = MiLocateCloneAddress (CurrentProcess,
                                                (PVOID)CloneBlock);

        if (CloneDescriptor != NULL) {

            //
            // Decrement the reference count for the clone block,
            // note that this could release and reacquire the mutexes.
            //

            MiDecrementCloneBlockReference (CloneDescriptor,
                                            CloneBlock,
                                            CurrentProcess,
                                            OldIrql);
        }
    }

    UNLOCK_PFN (OldIrql);
    return TRUE;
}


#if !defined(NT_UP) || defined (_IA64_)

VOID
MiSetDirtyBit (
    IN PVOID FaultingAddress,
    IN PMMPTE PointerPte,
    IN ULONG PfnHeld
    )

/*++

Routine Description:

    This routine sets dirty in the specified PTE and the modify bit in the
    corresponding PFN element.  If any page file space is allocated, it
    is deallocated.

Arguments:

    FaultingAddress - Supplies the faulting address.

    PointerPte - Supplies a pointer to the corresponding valid PTE.

    PfnHeld - Supplies TRUE if the PFN lock is already held.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, Working set mutex held.

--*/

{
    MMPTE TempPte;
    PFN_NUMBER PageFrameIndex;
    PMMPFN Pfn1;

    //
    // The page is NOT copy on write, update the PTE setting both the
    // dirty bit and the accessed bit. Note, that as this PTE is in
    // the TB, the TB must be flushed.
    //

    TempPte = *PointerPte;
    MI_SET_PTE_DIRTY (TempPte);
    MI_SET_ACCESSED_IN_PTE (&TempPte, 1);

    MI_WRITE_VALID_PTE_NEW_PROTECTION (PointerPte, TempPte);

    //
    // Check state of PFN lock and if not held, don't update PFN database.
    //

    if (PfnHeld) {

        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
        Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

        //
        // Set the modified field in the PFN database, also, if the physical
        // page is currently in a paging file, free up the page file space
        // as the contents are now worthless.
        //

        if ((Pfn1->OriginalPte.u.Soft.Prototype == 0) &&
            (Pfn1->u3.e1.WriteInProgress == 0)) {

            //
            // This page is in page file format, deallocate the page file space.
            //

            MiReleasePageFileSpace (Pfn1->OriginalPte);

            //
            // Change original PTE to indicate no page file space is reserved,
            // otherwise the space will be deallocated when the PTE is
            // deleted.
            //

            Pfn1->OriginalPte.u.Soft.PageFileHigh = 0;
        }

        MI_SET_MODIFIED (Pfn1, 1, 0x17);
    }

    //
    // The TB entry must be flushed as the valid PTE with the dirty bit clear
    // has been fetched into the TB. If it isn't flushed, another fault
    // is generated as the dirty bit is not set in the cached TB entry.
    //

    KeFillEntryTb (FaultingAddress);
    return;
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\wrtwatch.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

   wrtwatch.c

Abstract:

    This module contains the routines to support write watch.

Author:

    Landy Wang (landyw) 28-Jul-1999

Revision History:

--*/

#include "mi.h"

#define COPY_STACK_SIZE 256


NTSTATUS
NtGetWriteWatch (
    IN HANDLE ProcessHandle,
    IN ULONG Flags,
    IN PVOID BaseAddress,
    IN SIZE_T RegionSize,
    IN OUT PVOID *UserAddressArray,
    IN OUT PULONG_PTR EntriesInUserAddressArray,
    OUT PULONG Granularity
    )

/*++

Routine Description:

    This function returns the write watch status of the argument region.
    UserAddressArray is filled with the base address of each page that has
    been written to since the last NtResetWriteWatch call (or if no
    NtResetWriteWatch calls have been made, then each page written since
    this address space was created).

Arguments:

    ProcessHandle - Supplies an open handle to a process object.

    Flags - Supplies WRITE_WATCH_FLAG_RESET or nothing.

    BaseAddress - An address within a region of pages to be queried. This
                  value must lie within a private memory region with the
                  write-watch attribute already set.

    RegionSize - The size of the region in bytes beginning at the base address
                 specified.

    UserAddressArray - Supplies a pointer to user memory to store the user
                       addresses modified since the last reset.

    UserAddressArrayEntries - Supplies a pointer to how many user addresses
                              can be returned in this call.  This is then filled
                              with the exact number of addresses actually
                              returned.

    Granularity - Supplies a pointer to a variable to receive the size of
                  modified granule in bytes.
        
Return Value:

    Various NTSTATUS codes.

--*/

{
    PMMPFN Pfn1;
    LOGICAL First;
    LOGICAL UserWritten;
    PVOID EndAddress;
    PMMVAD Vad;
    KIRQL OldIrql;
    PEPROCESS Process;
    PMMPTE NextPte;
    PMMPTE PointerPte;
    PMMPTE PointerPde;
    PMMPTE PointerPpe;
    PMMPTE PointerPxe;
    PMMPTE EndPte;
    NTSTATUS Status;
    PVOID PoolArea;
    PVOID *PoolAreaPointer;
    ULONG_PTR StackArray[COPY_STACK_SIZE];
    MMPTE PteContents;
    ULONG_PTR NumberOfBytes;
    PRTL_BITMAP BitMap;
    ULONG BitMapIndex;
    ULONG NextBitMapIndex;
    PMI_PHYSICAL_VIEW PhysicalView;
    ULONG_PTR PagesWritten;
    ULONG_PTR NumberOfPages;
    LOGICAL Attached;
    KPROCESSOR_MODE PreviousMode;
    PFN_NUMBER PageFrameIndex;
    ULONG WorkingSetIndex;
    MMPTE TempPte;
    MMPTE PreviousPte;
    KAPC_STATE ApcState;
    PETHREAD CurrentThread;
    PEPROCESS CurrentProcess;
    MMPTE_FLUSH_LIST PteFlushList;
    TABLE_SEARCH_RESULT SearchResult;

    PteFlushList.Count = 0;

    ASSERT (KeGetCurrentIrql() == PASSIVE_LEVEL);

    if ((Flags & ~WRITE_WATCH_FLAG_RESET) != 0) {
        return STATUS_INVALID_PARAMETER_2;
    }

    CurrentThread = PsGetCurrentThread ();

    CurrentProcess = PsGetCurrentProcessByThread(CurrentThread);

    PreviousMode = KeGetPreviousModeByThread(&CurrentThread->Tcb);

    //
    // Establish an exception handler, probe the specified addresses
    // for write access and capture the initial values.
    //

    try {

        if (PreviousMode != KernelMode) {

            //
            // Make sure the specified starting and ending addresses are
            // within the user part of the virtual address space.
            //
        
            if (BaseAddress > MM_HIGHEST_VAD_ADDRESS) {
                return STATUS_INVALID_PARAMETER_2;
            }
        
            if ((((ULONG_PTR)MM_HIGHEST_VAD_ADDRESS + 1) - (ULONG_PTR)BaseAddress) <
                    RegionSize) {
                return STATUS_INVALID_PARAMETER_3;
            }

            //
            // Capture the number of pages.
            //

            ProbeForWritePointer (EntriesInUserAddressArray);

            NumberOfPages = *EntriesInUserAddressArray;

            if (NumberOfPages == 0) {
                return STATUS_INVALID_PARAMETER_5;
            }

            if (NumberOfPages > (MAXULONG_PTR / sizeof(ULONG_PTR))) {
                return STATUS_INVALID_PARAMETER_5;
            }

            ProbeForWrite (UserAddressArray,
                           NumberOfPages * sizeof (PVOID),
                           sizeof(PVOID));

            ProbeForWriteUlong (Granularity);
        }
        else {
            NumberOfPages = *EntriesInUserAddressArray;
            ASSERT (NumberOfPages != 0);
        }

    } except (ExSystemExceptionFilter()) {

        //
        // If an exception occurs during the probe or capture
        // of the initial values, then handle the exception and
        // return the exception code as the status value.
        //

        return GetExceptionCode();
    }

    //
    // Carefully probe and capture the user virtual address array.
    //

    PoolArea = (PVOID)&StackArray[0];

    NumberOfBytes = NumberOfPages * sizeof(ULONG_PTR);

    if (NumberOfPages > COPY_STACK_SIZE) {
        PoolArea = ExAllocatePoolWithTag (NonPagedPool,
                                                 NumberOfBytes,
                                                 'cGmM');

        if (PoolArea == NULL) {
            return STATUS_INSUFFICIENT_RESOURCES;
        }
    }

    PoolAreaPointer = (PVOID *)PoolArea;

    Attached = FALSE;

    //
    // Reference the specified process handle for VM_OPERATION access.
    //

    if (ProcessHandle == NtCurrentProcess()) {
        Process = CurrentProcess;
    }
    else {
        Status = ObReferenceObjectByHandle (ProcessHandle,
                                            PROCESS_VM_OPERATION,
                                            PsProcessType,
                                            PreviousMode,
                                            (PVOID *)&Process,
                                            NULL);

        if (!NT_SUCCESS(Status)) {
            goto ErrorReturn0;
        }
    }

    EndAddress = (PVOID)((PCHAR)BaseAddress + RegionSize - 1);

    PagesWritten = 0;

    if (BaseAddress > EndAddress) {
        Status = STATUS_INVALID_PARAMETER_4;
        goto ErrorReturn;
    }

    //
    // If the specified process is not the current process, attach
    // to the specified process.
    //

    if (CurrentProcess != Process) {
        KeStackAttachProcess (&Process->Pcb, &ApcState);
        Attached = TRUE;
    }

    Vad = NULL;

    SATISFY_OVERZEALOUS_COMPILER (PhysicalView = NULL);

    First = TRUE;

    PointerPte = MiGetPteAddress (BaseAddress);
    EndPte = MiGetPteAddress (EndAddress);

    PointerPde = MiGetPdeAddress (BaseAddress);
    PointerPpe = MiGetPpeAddress (BaseAddress);
    PointerPxe = MiGetPxeAddress (BaseAddress);

    LOCK_WS (Process);

    LOCK_PFN (OldIrql);

    if (Process->PhysicalVadRoot == NULL) {
        UNLOCK_PFN (OldIrql);
        UNLOCK_WS (Process);
        Status = STATUS_INVALID_PARAMETER_1;
        goto ErrorReturn;
    }

    //
    // Lookup the element and save the result.
    //

    SearchResult = MiFindNodeOrParent (Process->PhysicalVadRoot,
                                       MI_VA_TO_VPN (BaseAddress),
                                       (PMMADDRESS_NODE *) &PhysicalView);

    if ((SearchResult == TableFoundNode) &&
        (PhysicalView->Vad->u.VadFlags.WriteWatch == 1) &&
        (BaseAddress >= MI_VPN_TO_VA (PhysicalView->StartingVpn)) &&
        (EndAddress <= MI_VPN_TO_VA_ENDING (PhysicalView->EndingVpn))) {

        Vad = PhysicalView->Vad;
    }
    else {

        //
        // No virtual address is marked for write-watch at the specified base
        // address, return an error.
        //

        UNLOCK_PFN (OldIrql);
        UNLOCK_WS (Process);
        Status = STATUS_INVALID_PARAMETER_1;
        goto ErrorReturn;
    }

    ASSERT (Process->Flags & PS_PROCESS_FLAGS_USING_WRITE_WATCH);

    //
    // Extract the write watch status for each page in the range.
    // Note the PFN lock must be held to ensure atomicity.
    //

    BitMap = PhysicalView->u.BitMap;

    BaseAddress = MiGetVirtualAddressMappedByPte (PointerPte);

    BitMapIndex = (ULONG)(((PCHAR)BaseAddress - (PCHAR)(Vad->StartingVpn << PAGE_SHIFT)) >> PAGE_SHIFT);

    ASSERT (BitMapIndex < BitMap->SizeOfBitMap);
    ASSERT (BitMapIndex + (EndPte - PointerPte) < BitMap->SizeOfBitMap);

    while (PointerPte <= EndPte) {

        ASSERT (BitMapIndex < BitMap->SizeOfBitMap);

        UserWritten = FALSE;

        //
        // If the PTE is marked dirty (or writable) OR the BitMap says it's
        // dirtied, then let the caller know.
        //

        if (RtlCheckBit (BitMap, BitMapIndex) == 1) {
            UserWritten = TRUE;

            //
            // Note that a chunk of bits cannot be cleared at once because
            // the user array may overflow at any time.  If the user specifies
            // a bad address and the results cannot be written out, then it's
            // his own fault that he won't know which bits were cleared !
            //

            if (Flags & WRITE_WATCH_FLAG_RESET) {
                RtlClearBit (BitMap, BitMapIndex);
                goto ClearPteIfValid;
            }
        }
        else {

ClearPteIfValid:

            //
            // If the page table page is not present, then the dirty bit
            // has already been captured to the write watch bitmap.
            // Unfortunately all the entries in the page cannot be skipped
            // as the write watch bitmap must be checked for each PTE.
            //
    
#if (_MI_PAGING_LEVELS >= 4)
            if (PointerPxe->u.Hard.Valid == 0) {

                //
                // Skip the entire extended page parent if the bitmap permits.
                // The search starts at BitMapIndex (not BitMapIndex + 1) to
                // avoid wraps.
                //

                NextBitMapIndex = RtlFindSetBits (BitMap, 1, BitMapIndex);

                PointerPxe += 1;
                PointerPpe = MiGetVirtualAddressMappedByPte (PointerPxe);
                PointerPde = MiGetVirtualAddressMappedByPte (PointerPpe);
                NextPte = MiGetVirtualAddressMappedByPte (PointerPde);

                //
                // Compare the bitmap jump with the PTE jump and take
                // the lesser of the two.
                //

                if ((NextBitMapIndex == NO_BITS_FOUND) ||
                    ((ULONG)(NextPte - PointerPte) < (NextBitMapIndex - BitMapIndex))) {
                    BitMapIndex += (ULONG)(NextPte - PointerPte);
                    PointerPte = NextPte;
                }
                else {
                    PointerPte += (NextBitMapIndex - BitMapIndex);
                    BitMapIndex = NextBitMapIndex;
                }

                PointerPde = MiGetPteAddress (PointerPte);
                PointerPpe = MiGetPdeAddress (PointerPte);
                PointerPxe = MiGetPpeAddress (PointerPte);

                BaseAddress = MiGetVirtualAddressMappedByPte (PointerPte);
                continue;
            }
#endif
#if (_MI_PAGING_LEVELS >= 3)
            if (PointerPpe->u.Hard.Valid == 0) {

                //
                // Skip the entire page parent if the bitmap permits.
                // The search starts at BitMapIndex (not BitMapIndex + 1) to
                // avoid wraps.
                //

                NextBitMapIndex = RtlFindSetBits (BitMap, 1, BitMapIndex);

                PointerPpe += 1;
                PointerPde = MiGetVirtualAddressMappedByPte (PointerPpe);
                NextPte = MiGetVirtualAddressMappedByPte (PointerPde);

                //
                // Compare the bitmap jump with the PTE jump and take
                // the lesser of the two.
                //

                if ((NextBitMapIndex == NO_BITS_FOUND) ||
                    ((ULONG)(NextPte - PointerPte) < (NextBitMapIndex - BitMapIndex))) {
                    BitMapIndex += (ULONG)(NextPte - PointerPte);
                    PointerPte = NextPte;
                }
                else {
                    PointerPte += (NextBitMapIndex - BitMapIndex);
                    BitMapIndex = NextBitMapIndex;
                }

                PointerPde = MiGetPteAddress (PointerPte);
                PointerPpe = MiGetPdeAddress (PointerPte);
                PointerPxe = MiGetPpeAddress (PointerPte);

                BaseAddress = MiGetVirtualAddressMappedByPte (PointerPte);
                continue;
            }
#endif
            if (PointerPde->u.Hard.Valid == 0) {

                //
                // Skip the entire page directory if the bitmap permits.
                // The search starts at BitMapIndex (not BitMapIndex + 1) to
                // avoid wraps.
                //

                NextBitMapIndex = RtlFindSetBits (BitMap, 1, BitMapIndex);

                PointerPde += 1;
                NextPte = MiGetVirtualAddressMappedByPte (PointerPde);

                //
                // Compare the bitmap jump with the PTE jump and take
                // the lesser of the two.
                //

                if ((NextBitMapIndex == NO_BITS_FOUND) ||
                    ((ULONG)(NextPte - PointerPte) < (NextBitMapIndex - BitMapIndex))) {
                    BitMapIndex += (ULONG)(NextPte - PointerPte);
                    PointerPte = NextPte;
                }
                else {
                    PointerPte += (NextBitMapIndex - BitMapIndex);
                    BitMapIndex = NextBitMapIndex;
                }

                PointerPde = MiGetPteAddress (PointerPte);
                PointerPpe = MiGetPdeAddress (PointerPte);
                PointerPxe = MiGetPpeAddress (PointerPte);

                BaseAddress = MiGetVirtualAddressMappedByPte (PointerPte);
                continue;
            }

            PteContents = *PointerPte;

            if ((PteContents.u.Hard.Valid == 1) &&
                (MI_IS_PTE_DIRTY(PteContents))) {

                ASSERT (MI_PFN_ELEMENT(MI_GET_PAGE_FRAME_FROM_PTE(&PteContents))->u3.e1.PrototypePte == 0);

                UserWritten = TRUE;
                if (Flags & WRITE_WATCH_FLAG_RESET) {

                    //
                    // For the uniprocessor x86, just the dirty bit is
                    // cleared.  For all other platforms, the PTE writable
                    // bit must be disabled now so future writes trigger
                    // write watch updates.
                    //
        
                    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (&PteContents);
                    Pfn1 = MI_PFN_ELEMENT(PageFrameIndex);
                    ASSERT (Pfn1->u3.e1.PrototypePte == 0);
        
                    MI_MAKE_VALID_PTE (TempPte,
                                       PageFrameIndex,
                                       Pfn1->OriginalPte.u.Soft.Protection,
                                       PointerPte);
        
#if defined(_MIALT4K_)

                    //
                    // Preserve the split protections if they exist.
                    //

                    TempPte.u.Hard.Cache = PteContents.u.Hard.Cache;
#endif

                    WorkingSetIndex = MI_GET_WORKING_SET_FROM_PTE (&PteContents);
                    MI_SET_PTE_IN_WORKING_SET (&TempPte, WorkingSetIndex);
        
                    //
                    // Flush the TB as the protection of a valid PTE is
                    // being changed.
                    //
        
                    PreviousPte = *PointerPte;

                    ASSERT (PreviousPte.u.Hard.Valid == 1);

                    MI_WRITE_VALID_PTE_NEW_PROTECTION (PointerPte, TempPte);

                    if (PteFlushList.Count < MM_MAXIMUM_FLUSH_COUNT) {
                        PteFlushList.FlushVa[PteFlushList.Count] = BaseAddress;
                        PteFlushList.Count += 1;
                    }
                
                    ASSERT (PreviousPte.u.Hard.Valid == 1);
                
                    //
                    // A page's protection is being changed, on certain
                    // hardware the dirty bit should be ORed into the
                    // modify bit in the PFN element.
                    //
                    
                    MI_CAPTURE_DIRTY_BIT_TO_PFN (&PreviousPte, Pfn1);
                }
            }
        }

        if (UserWritten == TRUE) {
            *PoolAreaPointer = BaseAddress;
            PoolAreaPointer += 1;
            PagesWritten += 1;
            if (PagesWritten == NumberOfPages) {

                //
                // User array isn't big enough to take any more.  The API
                // (inherited from Win9x) is defined to return at this point.
                //

                break;
            }
        }

        PointerPte += 1;
        if (MiIsPteOnPdeBoundary(PointerPte)) {
            PointerPde = MiGetPteAddress (PointerPte);
            if (MiIsPteOnPdeBoundary(PointerPde)) {
                PointerPpe = MiGetPdeAddress (PointerPte);
#if (_MI_PAGING_LEVELS >= 4)
                if (MiIsPteOnPdeBoundary(PointerPpe)) {
                    PointerPxe = MiGetPpeAddress (PointerPte);
                }
#endif
            }
        }
        BitMapIndex += 1;
        BaseAddress = (PVOID)((PCHAR)BaseAddress + PAGE_SIZE);
    }

    if (PteFlushList.Count != 0) {
        MiFlushPteList (&PteFlushList, FALSE);
    }

    UNLOCK_PFN (OldIrql);

    UNLOCK_WS (Process);

    Status = STATUS_SUCCESS;

ErrorReturn:

    if (Attached == TRUE) {
        KeUnstackDetachProcess (&ApcState);
        Attached = FALSE;
    }

    if (ProcessHandle != NtCurrentProcess()) {
        ObDereferenceObject (Process);
    }

    if (Status == STATUS_SUCCESS) {

        //
        // Return all results to the caller.
        //
    
        try {
    
            RtlCopyMemory (UserAddressArray,
                           PoolArea,
                           PagesWritten * sizeof (PVOID));

            *EntriesInUserAddressArray = PagesWritten;

            *Granularity = PAGE_SIZE;
    
        } except (ExSystemExceptionFilter()) {
    
            Status = GetExceptionCode();
        }
    }
    
ErrorReturn0:

    if (PoolArea != (PVOID)&StackArray[0]) {
        ExFreePool (PoolArea);
    }

    return Status;
}

NTSTATUS
NtResetWriteWatch (
    IN HANDLE ProcessHandle,
    IN PVOID BaseAddress,
    IN SIZE_T RegionSize
    )

/*++

Routine Description:

    This function clears the write watch status of the argument region.
    This allows callers to "forget" old writes and only see new ones from
    this point on.

Arguments:

    ProcessHandle - Supplies an open handle to a process object.

    BaseAddress - An address within a region of pages to be reset.  This
                  value must lie within a private memory region with the
                  write-watch attribute already set.

    RegionSize - The size of the region in bytes beginning at the base address
                 specified.

Return Value:

    Various NTSTATUS codes.

--*/

{
    PVOID EndAddress;
    PMMVAD Vad;
    PMMPFN Pfn1;
    KIRQL OldIrql;
    PEPROCESS Process;
    PMMPTE PointerPte;
    PMMPTE PointerPde;
    PMMPTE PointerPpe;
    PMMPTE PointerPxe;
    PMMPTE EndPte;
    NTSTATUS Status;
    MMPTE PreviousPte;
    MMPTE PteContents;
    MMPTE TempPte;
    PRTL_BITMAP BitMap;
    ULONG BitMapIndex;
    PMI_PHYSICAL_VIEW PhysicalView;
    LOGICAL First;
    LOGICAL Attached;
    KPROCESSOR_MODE PreviousMode;
    PFN_NUMBER PageFrameIndex;
    ULONG WorkingSetIndex;
    KAPC_STATE ApcState;
    PETHREAD CurrentThread;
    PEPROCESS CurrentProcess;
    MMPTE_FLUSH_LIST PteFlushList;
    TABLE_SEARCH_RESULT SearchResult;

    PteFlushList.Count = 0;

    ASSERT (KeGetCurrentIrql() == PASSIVE_LEVEL);

    if (BaseAddress > MM_HIGHEST_VAD_ADDRESS) {
        return STATUS_INVALID_PARAMETER_2;
    }

    if ((((ULONG_PTR)MM_HIGHEST_VAD_ADDRESS + 1) - (ULONG_PTR)BaseAddress) <
            RegionSize) {
        return STATUS_INVALID_PARAMETER_3;
    }

    //
    // Reference the specified process handle for VM_OPERATION access.
    //

    CurrentThread = PsGetCurrentThread ();

    CurrentProcess = PsGetCurrentProcessByThread(CurrentThread);

    if (ProcessHandle == NtCurrentProcess()) {
        Process = CurrentProcess;
    }
    else {
        PreviousMode = KeGetPreviousModeByThread(&CurrentThread->Tcb);

        Status = ObReferenceObjectByHandle (ProcessHandle,
                                            PROCESS_VM_OPERATION,
                                            PsProcessType,
                                            PreviousMode,
                                            (PVOID *)&Process,
                                            NULL);

        if (!NT_SUCCESS(Status)) {
            return Status;
        }
    }

    Attached = FALSE;

    EndAddress = (PVOID)((PCHAR)BaseAddress + RegionSize - 1);
    
    if (BaseAddress > EndAddress) {
        Status = STATUS_INVALID_PARAMETER_3;
        goto ErrorReturn;
    }

    //
    // If the specified process is not the current process, attach
    // to the specified process.
    //

    if (CurrentProcess != Process) {
        KeStackAttachProcess (&Process->Pcb, &ApcState);
        Attached = TRUE;
    }

    Vad = NULL;
    First = TRUE;

    SATISFY_OVERZEALOUS_COMPILER (PhysicalView = NULL);

    PointerPte = MiGetPteAddress (BaseAddress);
    EndPte = MiGetPteAddress (EndAddress);

    LOCK_WS (Process);

    LOCK_PFN (OldIrql);

    if (Process->PhysicalVadRoot == NULL) {
        UNLOCK_PFN (OldIrql);
        UNLOCK_WS (Process);
        Status = STATUS_INVALID_PARAMETER_1;
        goto ErrorReturn;
    }

    //
    // Lookup the element and save the result.
    //

    SearchResult = MiFindNodeOrParent (Process->PhysicalVadRoot,
                                       MI_VA_TO_VPN (BaseAddress),
                                       (PMMADDRESS_NODE *) &PhysicalView);

    if ((SearchResult == TableFoundNode) &&
        (PhysicalView->Vad->u.VadFlags.WriteWatch == 1) &&
        (BaseAddress >= MI_VPN_TO_VA (PhysicalView->StartingVpn)) &&
        (EndAddress <= MI_VPN_TO_VA_ENDING (PhysicalView->EndingVpn))) {

        Vad = PhysicalView->Vad;
    }
    else {

        //
        // No virtual address is marked for write-watch at the specified base
        // address, return an error.
        //

        UNLOCK_PFN (OldIrql);
        UNLOCK_WS (Process);
        Status = STATUS_INVALID_PARAMETER_1;
        goto ErrorReturn;
    }

    ASSERT (Process->Flags & PS_PROCESS_FLAGS_USING_WRITE_WATCH);

    //
    // Clear the write watch status (and PTE writable/dirty bits) for each page
    // in the range.  Note if the PTE is not currently valid, then the write
    // watch bit has already been captured to the bitmap.  Hence only valid PTEs
    // need adjusting.
    //
    // The PFN lock must be held to ensure atomicity.
    //

    BitMap = PhysicalView->u.BitMap;

    BaseAddress = MiGetVirtualAddressMappedByPte (PointerPte);

    BitMapIndex = (ULONG)(((PCHAR)BaseAddress - (PCHAR)(Vad->StartingVpn << PAGE_SHIFT)) >> PAGE_SHIFT);

    ASSERT (BitMapIndex < BitMap->SizeOfBitMap);
    ASSERT (BitMapIndex + (EndPte - PointerPte) < BitMap->SizeOfBitMap);

    RtlClearBits (BitMap, BitMapIndex, (ULONG)(EndPte - PointerPte + 1));

    while (PointerPte <= EndPte) {

        //
        // If the page table page is not present, then the dirty bit
        // has already been captured to the write watch bitmap.  So skip it.
        //

        if ((First == TRUE) || MiIsPteOnPdeBoundary(PointerPte)) {
            First = FALSE;

            PointerPpe = MiGetPpeAddress (BaseAddress);
            PointerPxe = MiGetPxeAddress (BaseAddress);

#if (_MI_PAGING_LEVELS >= 4)
            if (PointerPxe->u.Hard.Valid == 0) {
                PointerPxe += 1;
                PointerPpe = MiGetVirtualAddressMappedByPte (PointerPxe);
                PointerPde = MiGetVirtualAddressMappedByPte (PointerPpe);
                PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
                BaseAddress = MiGetVirtualAddressMappedByPte (PointerPte);
                continue;
            }
#endif

#if (_MI_PAGING_LEVELS >= 3)
            if (PointerPpe->u.Hard.Valid == 0) {
                PointerPpe += 1;
                PointerPde = MiGetVirtualAddressMappedByPte (PointerPpe);
                PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
                BaseAddress = MiGetVirtualAddressMappedByPte (PointerPte);
                continue;
            }
#endif

            PointerPde = MiGetPdeAddress (BaseAddress);

            if (PointerPde->u.Hard.Valid == 0) {
                PointerPde += 1;
                PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
                BaseAddress = MiGetVirtualAddressMappedByPte (PointerPte);
                continue;
            }
        }

        //
        // If the PTE is marked dirty (or writable) OR the BitMap says it's
        // dirtied, then let the caller know.
        //

        PteContents = *PointerPte;

        if ((PteContents.u.Hard.Valid == 1) &&
            (MI_IS_PTE_DIRTY(PteContents))) {

            //
            // For the uniprocessor x86, just the dirty bit is cleared.
            // For all other platforms, the PTE writable bit must be
            // disabled now so future writes trigger write watch updates.
            //

            PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (&PteContents);
            Pfn1 = MI_PFN_ELEMENT(PageFrameIndex);
            ASSERT (Pfn1->u3.e1.PrototypePte == 0);

            MI_MAKE_VALID_PTE (TempPte,
                               PageFrameIndex,
                               Pfn1->OriginalPte.u.Soft.Protection,
                               PointerPte);

#if defined(_MIALT4K_)

            //
            // Preserve the split protections if they exist.
            //

            TempPte.u.Hard.Cache = PteContents.u.Hard.Cache;
#endif

            WorkingSetIndex = MI_GET_WORKING_SET_FROM_PTE (&PteContents);
            MI_SET_PTE_IN_WORKING_SET (&TempPte, WorkingSetIndex);

            //
            // Flush the TB as the protection of a valid PTE is being changed.
            //

            PreviousPte = *PointerPte;

            ASSERT (PreviousPte.u.Hard.Valid == 1);

            MI_WRITE_VALID_PTE_NEW_PROTECTION (PointerPte, TempPte);

            if (PteFlushList.Count < MM_MAXIMUM_FLUSH_COUNT) {
                PteFlushList.FlushVa[PteFlushList.Count] = BaseAddress;
                PteFlushList.Count += 1;
            }

            ASSERT (PreviousPte.u.Hard.Valid == 1);
        
            //
            // A page's protection is being changed, on certain
            // hardware the dirty bit should be ORed into the
            // modify bit in the PFN element.
            //
        
            MI_CAPTURE_DIRTY_BIT_TO_PFN (&PreviousPte, Pfn1);
        }

        PointerPte += 1;
        BaseAddress = (PVOID)((PCHAR)BaseAddress + PAGE_SIZE);
    }

    if (PteFlushList.Count != 0) {
        MiFlushPteList (&PteFlushList, FALSE);
    }

    UNLOCK_PFN (OldIrql);

    UNLOCK_WS (Process);

    Status = STATUS_SUCCESS;

ErrorReturn:

    if (Attached == TRUE) {
        KeUnstackDetachProcess (&ApcState);
        Attached = FALSE;
    }

    if (ProcessHandle != NtCurrentProcess()) {
        ObDereferenceObject (Process);
    }

    return Status;
}

VOID
MiCaptureWriteWatchDirtyBit (
    IN PEPROCESS Process,
    IN PVOID VirtualAddress
    )

/*++

Routine Description:

    This routine sets the write watch bit corresponding to the argument
    virtual address.

Arguments:

    Process - Supplies a pointer to an executive process structure.

    VirtualAddress - Supplies the modified virtual address.

Return Value:

    None.

Environment:

    Kernel mode, working set mutex and PFN lock held.

--*/

{
    PMMVAD Vad;
    PMI_PHYSICAL_VIEW PhysicalView;
    PRTL_BITMAP BitMap;
    ULONG BitMapIndex;
    TABLE_SEARCH_RESULT SearchResult;

    MM_PFN_LOCK_ASSERT();

    ASSERT (Process->Flags & PS_PROCESS_FLAGS_USING_WRITE_WATCH);

    //
    // This process has (or had) write watch VADs.  Search now
    // for a write watch region encapsulating the PTE being
    // invalidated.
    //

    ASSERT (Process->PhysicalVadRoot != NULL);

    SearchResult = MiFindNodeOrParent (Process->PhysicalVadRoot,
                                       MI_VA_TO_VPN (VirtualAddress),
                                       (PMMADDRESS_NODE *) &PhysicalView);

    if ((SearchResult == TableFoundNode) &&
        (PhysicalView->Vad->u.VadFlags.WriteWatch == 1) &&
        (VirtualAddress >= MI_VPN_TO_VA (PhysicalView->StartingVpn)) &&
        (VirtualAddress <= MI_VPN_TO_VA_ENDING (PhysicalView->EndingVpn))) {

        //
        // The write watch bitmap must be updated.
        //

        Vad = PhysicalView->Vad;
        BitMap = PhysicalView->u.BitMap;

        BitMapIndex = (ULONG)(((PCHAR)VirtualAddress - (PCHAR)(Vad->StartingVpn << PAGE_SHIFT)) >> PAGE_SHIFT);
    
        ASSERT (BitMapIndex < BitMap->SizeOfBitMap);

        MI_SET_BIT (BitMap->Buffer, BitMapIndex);

    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\wsmanage.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

   wsmanage.c

Abstract:

    This module contains routines which manage the set of active working
    set lists.

    Working set management is accomplished by a parallel group of actions

        1. Writing modified pages.

        2. Trimming working sets by :

            a) Aging pages by turning off access bits and incrementing age
               counts for pages which haven't been accessed.
            b) Estimating the number of unused pages in a working set and
               keeping a global count of that estimate.
            c) When getting tight on memory, replacing rather than adding
               pages in a working set when a fault occurs in a working set
               that has a significant proportion of unused pages.
            d) When memory is tight, reducing (trimming) working sets which
               are above their maximum towards their minimum.  This is done
               especially if there are a large number of available pages
               in it.

    The metrics are set such that writing modified pages is typically
    accomplished before trimming working sets, however, under certain cases
    where modified pages are being generated at a very high rate, working
    set trimming will be initiated to free up more pages.

    Once a process has had its working set raised above the minimum
    specified, the process is put on the Working Set Expanded list and
    is now eligible for trimming.  Note that at this time the FLINK field
    in the WorkingSetExpansionLink has an address value.

Author:

    Lou Perazzoli (loup) 10-Apr-1990
    Landy Wang (landyw) 02-Jun-1997

Revision History:

--*/

#include "mi.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT, MiAdjustWorkingSetManagerParameters)
#pragma alloc_text(PAGE, MmIsMemoryAvailable)
#endif

KEVENT  MiWaitForEmptyEvent;
BOOLEAN MiWaitingForWorkingSetEmpty;

LOGICAL MiReplacing = FALSE;

extern ULONG MmStandbyRePurposed;
ULONG MiLastStandbyRePurposed;

extern ULONG MiActiveVerifies;

PFN_NUMBER MmPlentyFreePages = 400;

PFN_NUMBER MmPlentyFreePagesValue;

#define MI_MAXIMUM_AGING_SHIFT 7

ULONG MiAgingShift = 4;
ULONG MiEstimationShift = 5;
PFN_NUMBER MmTotalClaim = 0;
PFN_NUMBER MmTotalEstimatedAvailable = 0;

LARGE_INTEGER MiLastAdjustmentOfClaimParams;

//
// Sixty seconds.
//

const LARGE_INTEGER MmClaimParameterAdjustUpTime = {60 * 1000 * 1000 * 10, 0};

//
// 2 seconds.
//

const LARGE_INTEGER MmClaimParameterAdjustDownTime = {2 * 1000 * 1000 * 10, 0};

LOGICAL MiHardTrim = FALSE;

WSLE_NUMBER MiMaximumWslesPerSweep = (1024 * 1024 * 1024) / PAGE_SIZE;

#define MI_MAXIMUM_SAMPLE 8192

#define MI_MINIMUM_SAMPLE 64
#define MI_MINIMUM_SAMPLE_SHIFT 7

#if DBG
PETHREAD MmWorkingSetThread;
#endif

//
// Number of times to retry when the target working set's mutex is not
// readily available.
//

ULONG MiWsRetryCount = 5;

typedef struct _MMWS_TRIM_CRITERIA {
    UCHAR NumPasses;
    UCHAR TrimAge;
    UCHAR DoAging;
    UCHAR TrimAllPasses;
    PFN_NUMBER DesiredFreeGoal;
    PFN_NUMBER NewTotalClaim;
    PFN_NUMBER NewTotalEstimatedAvailable;
} MMWS_TRIM_CRITERIA, *PMMWS_TRIM_CRITERIA;

LOGICAL
MiCheckAndSetSystemTrimCriteria (
    IN OUT PMMWS_TRIM_CRITERIA Criteria
    );

LOGICAL
MiCheckSystemTrimEndCriteria (
    IN OUT PMMWS_TRIM_CRITERIA Criteria,
    IN KIRQL OldIrql
    );

WSLE_NUMBER
MiDetermineWsTrimAmount (
    IN PMMWS_TRIM_CRITERIA Criteria,
    IN PMMSUPPORT VmSupport
    );

VOID
MiAgePagesAndEstimateClaims (
    LOGICAL EmptyIt
    );

VOID
MiAdjustClaimParameters (
    IN LOGICAL EnoughPages
    );

VOID
MiRearrangeWorkingSetExpansionList (
    VOID
    );

VOID
MiAdjustWorkingSetManagerParameters (
    IN LOGICAL WorkStation
    )

/*++

Routine Description:

    This function is called from MmInitSystem to adjust the working set manager
    trim algorithms based on system type and size.

Arguments:

    WorkStation - TRUE if this is a workstation, FALSE if not.

Return Value:

    None.

Environment:

    Kernel mode, INIT time only.

--*/
{
    if (WorkStation && MmNumberOfPhysicalPages <= 257*1024*1024/PAGE_SIZE) {
        MiAgingShift = 3;
        MiEstimationShift = 4;
    }
    else {
        MiAgingShift = 5;
        MiEstimationShift = 6;
    }

    if (MmNumberOfPhysicalPages >= 63*1024*1024/PAGE_SIZE) {
        MmPlentyFreePages *= 2;
    }

    MmPlentyFreePagesValue = MmPlentyFreePages;

    MiWaitingForWorkingSetEmpty = FALSE;
    KeInitializeEvent (&MiWaitForEmptyEvent, NotificationEvent, TRUE);
}


VOID
MiObtainFreePages (
    VOID
    )

/*++

Routine Description:

    This function examines the size of the modified list and the
    total number of pages in use because of working set increments
    and obtains pages by writing modified pages and/or reducing
    working sets.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, working set and PFN mutexes held.

--*/

{

    //
    // Check to see if there are enough modified pages to institute a
    // write.
    //

    if (MmModifiedPageListHead.Total >= MmModifiedWriteClusterSize) {

        //
        // Start the modified page writer.
        //

        KeSetEvent (&MmModifiedPageWriterEvent, 0, FALSE);
    }

    //
    // See if there are enough working sets above the minimum
    // threshold to make working set trimming worthwhile.
    //

    if ((MmPagesAboveWsMinimum > MmPagesAboveWsThreshold) ||
        (MmAvailablePages < 5)) {

        //
        // Start the working set manager to reduce working sets.
        //

        KeSetEvent (&MmWorkingSetManagerEvent, 0, FALSE);
    }
}

LOGICAL
MmIsMemoryAvailable (
    IN PFN_NUMBER PagesDesired
    )

/*++

Routine Description:

    This function checks whether there are sufficient available pages based
    on the caller's request.  If currently active pages are needed to satisfy
    this request and non-useful ones can be taken, then trimming is initiated
    here to do so.

Arguments:

    PagesRequested - Supplies the number of pages desired.

Return Value:

    TRUE if sufficient pages exist to satisfy the request.
    FALSE if not.

Environment:

    Kernel mode, PASSIVE_LEVEL.

--*/

{
    LOGICAL Status;
    PFN_NUMBER PageTarget;
    PFN_NUMBER PagePlentyTarget;
    ULONG i;
    PFN_NUMBER CurrentAvailablePages;
    PFN_NUMBER CurrentTotalClaim;

    ASSERT (KeGetCurrentIrql () == PASSIVE_LEVEL);

    CurrentAvailablePages = MmAvailablePages;

    //
    // If twice the pages that the caller asked for are available
    // without trimming anything, return TRUE.
    //

    PageTarget = PagesDesired * 2;
    if (CurrentAvailablePages >= PageTarget) {
        return TRUE;
    }

    CurrentTotalClaim = MmTotalClaim;

    //
    // If there are few pages available or claimable, we adjust to do 
    // a hard trim.
    //

    if (CurrentAvailablePages + CurrentTotalClaim < PagesDesired) {
        MiHardTrim = TRUE;
    }

    //
    // Active pages must be trimmed to satisfy this request and it is believed
    // that non-useful pages can be taken to accomplish this.
    //
    // Set the PagePlentyTarget to 125% of the readlist size and kick it off.
    // Our actual trim goal will be 150% of the PagePlentyTarget.
    //

    PagePlentyTarget = PagesDesired + (PagesDesired >> 2);
    MmPlentyFreePages = PagePlentyTarget;

    KeSetEvent (&MmWorkingSetManagerEvent, 0, FALSE);

    Status = FALSE;
    for (i = 0; i < 10; i += 1) {
        KeDelayExecutionThread (KernelMode, FALSE, (PLARGE_INTEGER)&Mm30Milliseconds);
        if (MmAvailablePages >= PagesDesired) {
            Status = TRUE;
            break;
        }
    }

    MmPlentyFreePages = MmPlentyFreePagesValue;
    MiHardTrim = FALSE;

    return Status;
}

LOGICAL
MiAttachAndLockWorkingSet (
    IN PMMSUPPORT VmSupport
    )

/*++

Routine Description:

    This function attaches to the proper address space and acquires the
    relevant working set mutex for the address space being trimmed.

    If successful, this routine returns with APCs blocked as well.

    On failure, this routine returns without any APCs blocked, no working
    set mutex acquired and no address space attached to.

Arguments:

    VmSupport - Supplies the working set to attach to and lock.

Return Value:

    TRUE if successful, FALSE if not.

Environment:

    Kernel mode, PASSIVE_LEVEL.

--*/

{
    ULONG count;
    KIRQL OldIrql;
    PEPROCESS ProcessToTrim;
    LOGICAL Attached;
    PMM_SESSION_SPACE SessionSpace;

    ASSERT (KeGetCurrentIrql () == PASSIVE_LEVEL);

    if (VmSupport == &MmSystemCacheWs) {

        ASSERT (VmSupport->Flags.SessionSpace == 0);
        ASSERT (VmSupport->Flags.TrimHard == 0);

        //
        // System cache,
        //

        if (KeTryToAcquireGuardedMutex (&VmSupport->WorkingSetMutex) == FALSE) {

            //
            // System working set mutex was not granted, don't trim
            // the system cache.
            //

            return FALSE;
        }

        MM_SYSTEM_WS_LOCK_TIMESTAMP ();

        return TRUE;
    }

    if (VmSupport->Flags.SessionSpace == 0) {

        ProcessToTrim = CONTAINING_RECORD (VmSupport, EPROCESS, Vm);

        ASSERT ((ProcessToTrim->Flags & PS_PROCESS_FLAGS_VM_DELETED) == 0);

        //
        // Attach to the process in preparation for trimming.
        //

        Attached = 0;
        if (ProcessToTrim != PsInitialSystemProcess) {

            Attached = KeForceAttachProcess (&ProcessToTrim->Pcb);

            if (Attached == 0) {
                return FALSE;
            }

            if (ProcessToTrim->Flags & PS_PROCESS_FLAGS_OUTSWAP_ENABLED) {

                //
                // We have effectively performed an inswap of the process
                // due to the force attach.  Mark the process (and session)
                // accordingly.
                //

                ASSERT ((ProcessToTrim->Flags & PS_PROCESS_FLAGS_OUTSWAPPED) == 0);

                LOCK_EXPANSION (OldIrql);

                PS_CLEAR_BITS (&ProcessToTrim->Flags,
                               PS_PROCESS_FLAGS_OUTSWAP_ENABLED);

                if ((ProcessToTrim->Flags & PS_PROCESS_FLAGS_IN_SESSION) &&
                    (VmSupport->Flags.SessionLeader == 0)) {

                    ASSERT (MmSessionSpace->ProcessOutSwapCount >= 1);
                    MmSessionSpace->ProcessOutSwapCount -= 1;
                }

                UNLOCK_EXPANSION (OldIrql);
            }
        }

        //
        // Attempt to acquire the working set mutex. If the
        // lock cannot be acquired, skip over this process.
        //

        count = 0;
        do {
            if (KeTryToAcquireGuardedMutex (&VmSupport->WorkingSetMutex) != FALSE) {
                ASSERT (VmSupport->WorkingSetExpansionLinks.Flink == MM_WS_TRIMMING);
                LOCK_WS_TIMESTAMP (ProcessToTrim);
                return TRUE;
            }

            KeDelayExecutionThread (KernelMode, FALSE, (PLARGE_INTEGER)&MmShortTime);
            count += 1;
        } while (count < MiWsRetryCount);

        //
        // Could not get the lock, skip this process.
        //

        if (Attached) {
            KeDetachProcess ();
        }

        return FALSE;
    }

    SessionSpace = CONTAINING_RECORD (VmSupport, MM_SESSION_SPACE, Vm);

    //
    // Attach directly to the session space to be trimmed.
    //

    MiAttachSession (SessionSpace);

    //
    // Try for the session working set mutex.
    //

    if (KeTryToAcquireGuardedMutex (&VmSupport->WorkingSetMutex) == FALSE) {

        //
        // This session space's working set mutex was not
        // granted, don't trim it.
        //

        MiDetachSession ();

        return FALSE;
    }

    return TRUE;
}

VOID
MiDetachAndUnlockWorkingSet (
    IN PMMSUPPORT VmSupport
    )

/*++

Routine Description:

    This function detaches from the target address space and releases the
    relevant working set mutex for the address space that was trimmed.

Arguments:

    VmSupport - Supplies the working set to detach from and unlock.

Return Value:

    None.

Environment:

    Kernel mode, APC_LEVEL.

--*/

{
    PEPROCESS ProcessToTrim;

    ASSERT (KeAreAllApcsDisabled () == TRUE);

    UNLOCK_WORKING_SET (VmSupport);

    if (VmSupport == &MmSystemCacheWs) {
        ASSERT (VmSupport->Flags.SessionSpace == 0);
    }
    else if (VmSupport->Flags.SessionSpace == 0) {

        ProcessToTrim = CONTAINING_RECORD (VmSupport, EPROCESS, Vm);

        ASSERT (KeGetCurrentIrql () == PASSIVE_LEVEL);

        if (ProcessToTrim != PsInitialSystemProcess) {
            KeDetachProcess ();
        }
    }
    else {
        MiDetachSession ();
    }

    return;
}


VOID
MmWorkingSetManager (
    VOID
    )

/*++

Routine Description:

    Implements the NT working set manager thread.  When the number
    of free pages becomes critical and ample pages can be obtained by
    reducing working sets, the working set manager's event is set, and
    this thread becomes active.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode.

--*/

{
    PLIST_ENTRY ListEntry;
    WSLE_NUMBER Trim;
    KIRQL OldIrql;
    PMMSUPPORT VmSupport;
    LARGE_INTEGER CurrentTime;
    LOGICAL DoTrimming;
    MMWS_TRIM_CRITERIA TrimCriteria;
    static ULONG Initialized = 0;

    PERFINFO_WSMANAGE_DECL();

    if (Initialized == 0) {
        PsGetCurrentThread()->MemoryMaker = 1;
        Initialized = 1;
    }

#if DBG
    MmWorkingSetThread = PsGetCurrentThread ();
#endif

    ASSERT (MmIsAddressValid (MmSessionSpace) == FALSE);

    PERFINFO_WSMANAGE_CHECK();

    //
    // Set the trim criteria: If there are plenty of pages, the existing
    // sets are aged and FALSE is returned to signify no trim is necessary.
    // Otherwise, the working set expansion list is ordered so the best
    // candidates for trimming are placed at the front and TRUE is returned.
    //

    DoTrimming = MiCheckAndSetSystemTrimCriteria (&TrimCriteria);

    if (DoTrimming) {

        //
        // Clear the deferred entry list to free up some pages.
        //

        MiDeferredUnlockPages (0);

        KeQuerySystemTime (&CurrentTime);

        ASSERT (MmIsAddressValid (MmSessionSpace) == FALSE);

        LOCK_EXPANSION (OldIrql);

        while (!IsListEmpty (&MmWorkingSetExpansionHead.ListHead)) {

            //
            // Remove the entry at the head and trim it.
            //

            ListEntry = RemoveHeadList (&MmWorkingSetExpansionHead.ListHead);

            VmSupport = CONTAINING_RECORD (ListEntry,
                                           MMSUPPORT,
                                           WorkingSetExpansionLinks);

            //
            // Note that other routines that set this bit must remove the
            // entry from the expansion list first.
            //

            ASSERT (VmSupport->WorkingSetExpansionLinks.Flink != MM_WS_TRIMMING);

            //
            // Check to see if we've been here before.
            //

            if (VmSupport->LastTrimTime.QuadPart == CurrentTime.QuadPart) {

                InsertHeadList (&MmWorkingSetExpansionHead.ListHead,
                                &VmSupport->WorkingSetExpansionLinks);

                //
                // If we aren't finished we may sleep in this call.
                //

                if (MiCheckSystemTrimEndCriteria (&TrimCriteria, OldIrql)) {

                    //
                    // No more pages are needed so we're done.
                    //

                    break;
                }

                //
                // Start a new round of trimming.
                //

                KeQuerySystemTime (&CurrentTime);

                continue;
            }

            //
            // Only attach if the working set is worth examining.  This is
            // not just an optimization, as care must be taken not to attempt
            // an attach to a process which is a candidate for being currently
            // (or already) swapped out because if we attach to a page
            // directory that is in transition it's all over.
            //

            if ((VmSupport->WorkingSetSize <= MM_PROCESS_COMMIT_CHARGE) &&
                (VmSupport != &MmSystemCacheWs) &&
                (VmSupport->Flags.SessionSpace == 0)) {

                InsertTailList (&MmWorkingSetExpansionHead.ListHead,
                                &VmSupport->WorkingSetExpansionLinks);
                continue;
            }

            VmSupport->LastTrimTime = CurrentTime;
            VmSupport->WorkingSetExpansionLinks.Flink = MM_WS_TRIMMING;
            VmSupport->WorkingSetExpansionLinks.Blink = NULL;

            UNLOCK_EXPANSION (OldIrql);

            if (MiAttachAndLockWorkingSet (VmSupport) == TRUE) {

                //
                // Determine how many pages to trim from this working set.
                //

                Trim = MiDetermineWsTrimAmount (&TrimCriteria, VmSupport);

                //
                // If there's something to trim...
                //

                if ((Trim != 0) &&
                    ((TrimCriteria.TrimAllPasses > TrimCriteria.NumPasses) ||
                     (MmAvailablePages < TrimCriteria.DesiredFreeGoal))) {

                    //
                    // We haven't reached our goal, so trim now.
                    //

                    PERFINFO_WSMANAGE_TOTRIM(Trim);

                    Trim = MiTrimWorkingSet (Trim,
                                             VmSupport,
                                             TrimCriteria.TrimAge);

                    PERFINFO_WSMANAGE_ACTUALTRIM(Trim);
                }

                //
                // Estimating the current claim is always done here by taking a
                // sample of the working set.  Aging is only done if the trim
                // pass warrants it (ie: the first pass only).
                //

                MiAgeAndEstimateAvailableInWorkingSet (
                                    VmSupport,
                                    TrimCriteria.DoAging,
                                    NULL,
                                    &TrimCriteria.NewTotalClaim,
                                    &TrimCriteria.NewTotalEstimatedAvailable);

                MiDetachAndUnlockWorkingSet (VmSupport);

                LOCK_EXPANSION (OldIrql);
            }
            else {

                //
                // Unable to attach to the working set presumably because
                // some other thread has it locked.  Set the ForceTrim flag
                // so it will be trimmed later by whoever owns it (or whoever
                // tries to insert the next entry).
                //

                LOCK_EXPANSION (OldIrql);
                VmSupport->Flags.ForceTrim = 1;
            }

            ASSERT (VmSupport->WorkingSetExpansionLinks.Flink == MM_WS_TRIMMING);
            if (VmSupport->WorkingSetExpansionLinks.Blink == NULL) {

                //
                // Reinsert this working set at the tail of the list.
                //

                InsertTailList (&MmWorkingSetExpansionHead.ListHead,
                                &VmSupport->WorkingSetExpansionLinks);
            }
            else {

                //
                // The process is terminating - the value in the blink
                // is the address of an event to set.
                //

                ASSERT (VmSupport != &MmSystemCacheWs);

                VmSupport->WorkingSetExpansionLinks.Flink = MM_WS_NOT_LISTED;

                KeSetEvent ((PKEVENT)VmSupport->WorkingSetExpansionLinks.Blink,
                            0,
                            FALSE);
            }
        }

        MmTotalClaim = TrimCriteria.NewTotalClaim;
        MmTotalEstimatedAvailable = TrimCriteria.NewTotalEstimatedAvailable;
        PERFINFO_WSMANAGE_TRIMEND_CLAIMS(&TrimCriteria);

        UNLOCK_EXPANSION (OldIrql);
    }
            
    //
    // If memory is critical and there are modified pages to be written
    // (presumably because we've just trimmed them), then signal the
    // modified page writer.
    //

    if ((MmAvailablePages < MmMinimumFreePages) ||
        (MmModifiedPageListHead.Total >= MmModifiedPageMaximum)) {

        KeSetEvent (&MmModifiedPageWriterEvent, 0, FALSE);
    }

    return;
}

LOGICAL
MiCheckAndSetSystemTrimCriteria (
    IN PMMWS_TRIM_CRITERIA Criteria
    )

/*++

Routine Description:

    Decide whether to trim, age or adjust claim estimations at this time.

Arguments:

    Criteria - Supplies a pointer to the trim criteria information.  Various
               fields in this structure are set as needed by this routine.

Return Value:

    TRUE if the caller should initiate trimming, FALSE if not.

Environment:

    Kernel mode.  No locks held.  APC level or below.

    This is called at least once per second on entry to MmWorkingSetManager.

--*/

{
    KIRQL OldIrql;
    PFN_NUMBER Available;
    ULONG StandbyRemoved;
    ULONG StandbyTemp;
    ULONG WsRetryCount;

    PERFINFO_WSMANAGE_DECL();

    PERFINFO_WSMANAGE_CHECK();

    //
    // See if an empty-all-working-sets request has been queued to us.
    //

    WsRetryCount = MiWsRetryCount;

    if (MiWaitingForWorkingSetEmpty == TRUE) {

        MiWsRetryCount = 1;

        MiAgePagesAndEstimateClaims (TRUE);

        LOCK_EXPANSION (OldIrql);

        KeSetEvent (&MiWaitForEmptyEvent, 0, FALSE);
        MiWaitingForWorkingSetEmpty = FALSE;

        UNLOCK_EXPANSION (OldIrql);

        MiReplacing = FALSE;

        MiWsRetryCount = WsRetryCount;

        return FALSE;
    }

    //
    // Check the number of pages available to see if any trimming (or aging)
    // is really required.
    //

    Available = MmAvailablePages;

    StandbyRemoved = MmStandbyRePurposed;

    //
    // If the counter wrapped, it's ok to just ignore it this time around.
    //

    if (StandbyRemoved <= MiLastStandbyRePurposed) {
        MiLastStandbyRePurposed = StandbyRemoved;
        StandbyRemoved = 0;
    }
    else {

        //
        // The value is nonzero, we need to synchronize so we get a coordinated
        // snapshot of both values.
        //

        LOCK_PFN (OldIrql);
        Available = MmAvailablePages;
        StandbyRemoved = MmStandbyRePurposed;
        UNLOCK_PFN (OldIrql);

        if (StandbyRemoved <= MiLastStandbyRePurposed) {
            MiLastStandbyRePurposed = StandbyRemoved;
            StandbyRemoved = 0;
        }
        else {
            StandbyTemp = StandbyRemoved;
            StandbyRemoved -= MiLastStandbyRePurposed;
            MiLastStandbyRePurposed = StandbyTemp;
        }
    }

    PERFINFO_WSMANAGE_STARTLOG_CLAIMS();

    //
    // If we're low on pages, or we've been replacing within a given
    // working set, or we've been cannibalizing a large number of standby
    // pages, then trim now.
    //

    if ((Available <= MmPlentyFreePages) ||
        (MiReplacing == TRUE) ||
        (StandbyRemoved >= (Available >> 2))) {

        //
        // Inform our caller to start trimming since we're below
        // plenty pages - order the list so the bigger working sets are
        // in front so our caller trims those first.
        //

        Criteria->NumPasses = 0;
        Criteria->DesiredFreeGoal = MmPlentyFreePages + (MmPlentyFreePages / 2);
        Criteria->NewTotalClaim = 0;
        Criteria->NewTotalEstimatedAvailable = 0;

        //
        // If more than 25% of the available pages were recycled standby
        // pages, then trim more aggresively in an attempt to get more of the
        // cold pages into standby for the next pass.
        //

        if (StandbyRemoved >= (Available >> 2)) {
            Criteria->TrimAllPasses = TRUE;
        }
        else {
            Criteria->TrimAllPasses = FALSE;
        }

        //
        // Start trimming the bigger working sets first.
        //

        MiRearrangeWorkingSetExpansionList ();

#if DBG
        if (MmDebug & MM_DBG_WS_EXPANSION) {
            DbgPrint("\nMM-wsmanage: Desired = %ld, Avail %ld\n",
                    Criteria->DesiredFreeGoal, MmAvailablePages);
        }
#endif

        PERFINFO_WSMANAGE_WILLTRIM_CLAIMS(Criteria);

        //
        // No need to lock synchronize the MiReplacing clearing as it
        // gets set every time a page replacement happens anyway.
        //

        MiReplacing = FALSE;

        return TRUE;
    }

    //
    // If there is an overwhelming surplus of memory and this is a big
    // server then don't even bother aging at this point.
    //

    if (Available > MM_ENORMOUS_LIMIT) {

        //
        // Note the claim and estimated available are not cleared so they
        // may contain stale values, but at this level it doesn't really
        // matter.
        //

        return FALSE;
    }

    //
    // Don't trim but do age unused pages and estimate
    // the amount available in working sets.
    //

    MiAgePagesAndEstimateClaims (FALSE);

    MiAdjustClaimParameters (TRUE);

    PERFINFO_WSMANAGE_TRIMACTION (PERFINFO_WS_ACTION_RESET_COUNTER);
    PERFINFO_WSMANAGE_DUMPENTRIES_CLAIMS ();

    return FALSE;
}

LOGICAL
MiCheckSystemTrimEndCriteria (
    IN PMMWS_TRIM_CRITERIA Criteria,
    IN KIRQL OldIrql
    )

/*++

Routine Description:

     Check the ending criteria.  If we're not done, delay for a little
     bit to let the modified writes catch up.

Arguments:

    Criteria - Supplies the trim criteria information.

    OldIrql - Supplies the old IRQL to lower to if the expansion lock needs
              to be released.

Return Value:

    TRUE if trimming can be stopped, FALSE otherwise.

Environment:

    Kernel mode.  Expansion lock held.  APC level or below.

--*/

{
    LOGICAL FinishedTrimming;

    PERFINFO_WSMANAGE_DECL();

    PERFINFO_WSMANAGE_CHECK();

    if ((MmAvailablePages > Criteria->DesiredFreeGoal) ||
        (Criteria->NumPasses >= MI_MAX_TRIM_PASSES)) {

        //
        // We have enough pages or we trimmed as many as we're going to get.
        //

        return TRUE;
    }

    //
    // Update the global claim and estimate before we wait.
    //

    MmTotalClaim = Criteria->NewTotalClaim;
    MmTotalEstimatedAvailable = Criteria->NewTotalEstimatedAvailable;

    //
    // We don't have enough pages - give the modified page writer
    // 10 milliseconds to catch up.  The wait is also important because a
    // thread may have the system cache locked but has been preempted
    // by the balance set manager due to its higher priority.  We must
    // give this thread a shot at running so it can release the system
    // cache lock (all the trimmable pages may reside in the system cache).
    //

    UNLOCK_EXPANSION (OldIrql);

    KeDelayExecutionThread (KernelMode,
                            FALSE,
                            (PLARGE_INTEGER)&MmShortTime);

    PERFINFO_WSMANAGE_WAITFORWRITER_CLAIMS();

    //
    // Check again to see if we've met the criteria to stop trimming.
    //

    if (MmAvailablePages > Criteria->DesiredFreeGoal) {

        //
        // Now we have enough pages so break out.
        //

        FinishedTrimming = TRUE;
    }
    else {

        //
        // We don't have enough pages so let's do another pass.
        // Go get the next working set list which is probably the
        // one we put back before we gave up the processor.
        //

        FinishedTrimming = FALSE;

        if (Criteria->NumPasses == 0) {
            MiAdjustClaimParameters (FALSE);
        }

        Criteria->NumPasses += 1;
        Criteria->NewTotalClaim = 0;
        Criteria->NewTotalEstimatedAvailable = 0;

        PERFINFO_WSMANAGE_TRIMACTION(PERFINFO_WS_ACTION_FORCE_TRIMMING_PROCESS);
    }

    LOCK_EXPANSION (OldIrql);

    return FinishedTrimming;
}


WSLE_NUMBER
MiDetermineWsTrimAmount (
    PMMWS_TRIM_CRITERIA Criteria,
    PMMSUPPORT VmSupport
    )

/*++

Routine Description:

     Determine whether this process should be trimmed.

Arguments:

    Criteria - Supplies the trim criteria information.

    VmSupport - Supplies the working set information for the candidate.

Return Value:

    TRUE if trimming should be done on this process, FALSE if not.

Environment:

    Kernel mode.  Expansion lock held.  APC level or below.

--*/

{
    PMMWSL WorkingSetList;
    WSLE_NUMBER MaxTrim;
    WSLE_NUMBER Trim;
    LOGICAL OutswapEnabled;
    PEPROCESS ProcessToTrim;
    PMM_SESSION_SPACE SessionSpace;

    WorkingSetList = VmSupport->VmWorkingSetList;

    MaxTrim = VmSupport->WorkingSetSize;

    if (MaxTrim <= WorkingSetList->FirstDynamic) {
        return 0;
    }

    OutswapEnabled = FALSE;

    if (VmSupport == &MmSystemCacheWs) {
        PERFINFO_WSMANAGE_TRIMWS (NULL, NULL, VmSupport);
    }
    else if (VmSupport->Flags.SessionSpace == 0) {

        ProcessToTrim = CONTAINING_RECORD (VmSupport, EPROCESS, Vm);

        if (ProcessToTrim->Flags & PS_PROCESS_FLAGS_OUTSWAP_ENABLED) {
            OutswapEnabled = TRUE;
        }

        if (VmSupport->Flags.MinimumWorkingSetHard == 1) {
            if (MaxTrim <= VmSupport->MinimumWorkingSetSize) {
                return 0;
            }
            OutswapEnabled = FALSE;
        }

        PERFINFO_WSMANAGE_TRIMWS (ProcessToTrim, NULL, VmSupport);
    }
    else {
        if (VmSupport->Flags.TrimHard == 1) {
            OutswapEnabled = TRUE;
        }

        SessionSpace = CONTAINING_RECORD(VmSupport,
                                         MM_SESSION_SPACE,
                                         Vm);

        PERFINFO_WSMANAGE_TRIMWS (NULL, SessionSpace, VmSupport);
    }

    if (OutswapEnabled == FALSE) {

        //
        // Don't trim the cache or non-swapped sessions or processes
        // below their minimum.
        //

        MaxTrim -= VmSupport->MinimumWorkingSetSize;
    }

    switch (Criteria->NumPasses) {
    case 0:
        Trim = VmSupport->Claim >>
                    ((VmSupport->Flags.MemoryPriority == MEMORY_PRIORITY_FOREGROUND)
                        ? MI_FOREGROUND_CLAIM_AVAILABLE_SHIFT
                        : MI_BACKGROUND_CLAIM_AVAILABLE_SHIFT);
        Criteria->TrimAge = MI_PASS0_TRIM_AGE;
        Criteria->DoAging = TRUE;
        break;
    case 1:
        Trim = VmSupport->Claim >>
                    ((VmSupport->Flags.MemoryPriority == MEMORY_PRIORITY_FOREGROUND)
                        ? MI_FOREGROUND_CLAIM_AVAILABLE_SHIFT
                        : MI_BACKGROUND_CLAIM_AVAILABLE_SHIFT);
        Criteria->TrimAge = MI_PASS1_TRIM_AGE;
        Criteria->DoAging = FALSE;
        break;
    case 2:
        Trim = VmSupport->Claim;
        Criteria->TrimAge = MI_PASS2_TRIM_AGE;
        Criteria->DoAging = FALSE;
        break;
    case 3:
        Trim = VmSupport->EstimatedAvailable;
        Criteria->TrimAge = MI_PASS3_TRIM_AGE;
        Criteria->DoAging = FALSE;
        break;
    default:
        Trim = VmSupport->EstimatedAvailable;
        Criteria->TrimAge = MI_PASS3_TRIM_AGE;
        Criteria->DoAging = FALSE;

        if (MiHardTrim == TRUE || MmAvailablePages < MM_HIGH_LIMIT + 64) {
            if (VmSupport->WorkingSetSize > VmSupport->MinimumWorkingSetSize) {
                Trim = (VmSupport->WorkingSetSize - VmSupport->MinimumWorkingSetSize) >> 2;
                if (Trim == 0) {
                    Trim = VmSupport->WorkingSetSize - VmSupport->MinimumWorkingSetSize;
                }
            }
            Criteria->TrimAge = MI_PASS4_TRIM_AGE;
            Criteria->DoAging = TRUE;
        }

        break;
    }

    if (Trim > MaxTrim) {
        Trim = MaxTrim;
    }

#if DBG
    if ((MmDebug & MM_DBG_WS_EXPANSION) && (Trim != 0)) {
        if (VmSupport->Flags.SessionSpace == 0) {
            ProcessToTrim = CONTAINING_RECORD (VmSupport, EPROCESS, Vm);
            DbgPrint("           Trimming        Process %16s, WS %6d, Trimming %5d ==> %5d\n",
                ProcessToTrim ? ProcessToTrim->ImageFileName : (PUCHAR)"System Cache",
                VmSupport->WorkingSetSize,
                Trim,
                VmSupport->WorkingSetSize-Trim);
        }
        else {
            SessionSpace = CONTAINING_RECORD (VmSupport,
                                              MM_SESSION_SPACE,
                                              Vm);
            DbgPrint("           Trimming        Session 0x%x (id %d), WS %6d, Trimming %5d ==> %5d\n",
                SessionSpace,
                SessionSpace->SessionId,
                VmSupport->WorkingSetSize,
                Trim,
                VmSupport->WorkingSetSize-Trim);
        }
    }
#endif

    return Trim;
}

VOID
MiAgePagesAndEstimateClaims (
    LOGICAL EmptyIt
    )

/*++

Routine Description:

    Walk through the sets on the working set expansion list.

    Either age pages and estimate the claim (number of pages they aren't using),
    or empty the working set.

Arguments:

    EmptyIt - Supplies TRUE to empty the working set,
              FALSE to just age and estimate it.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled.  PFN lock NOT held.

--*/

{
    WSLE_NUMBER WslesScanned;
    PMMSUPPORT VmSupport;
    PMMSUPPORT FirstSeen;
    LOGICAL SystemCacheSeen;
    KIRQL OldIrql;
    PLIST_ENTRY ListEntry;
    PFN_NUMBER NewTotalClaim;
    PFN_NUMBER NewTotalEstimatedAvailable;
    ULONG LoopCount;

    FirstSeen = NULL;
    SystemCacheSeen = FALSE;
    LoopCount = 0;

    WslesScanned = 0;
    NewTotalClaim = 0;
    NewTotalEstimatedAvailable = 0;

    ASSERT (MmIsAddressValid (MmSessionSpace) == FALSE);

    LOCK_EXPANSION (OldIrql);

    while (!IsListEmpty (&MmWorkingSetExpansionHead.ListHead)) {

        ASSERT (MmIsAddressValid (MmSessionSpace) == FALSE);

        //
        // Remove the entry at the head, try to lock it, if we can lock it
        // then age some pages and estimate the number of available pages.
        //

        ListEntry = RemoveHeadList (&MmWorkingSetExpansionHead.ListHead);

        VmSupport = CONTAINING_RECORD (ListEntry,
                                       MMSUPPORT,
                                       WorkingSetExpansionLinks);

        if (VmSupport == &MmSystemCacheWs) {

            if (SystemCacheSeen == TRUE) {

                //
                // Seen this one already.
                //

                FirstSeen = VmSupport;
            }
            SystemCacheSeen = TRUE;
        }

        ASSERT (VmSupport->WorkingSetExpansionLinks.Flink != MM_WS_TRIMMING);

        if (VmSupport == FirstSeen) {
            InsertHeadList (&MmWorkingSetExpansionHead.ListHead,
                            &VmSupport->WorkingSetExpansionLinks);
            break;
        }

        if ((VmSupport->WorkingSetSize <= MM_PROCESS_COMMIT_CHARGE) &&
            (VmSupport != &MmSystemCacheWs) &&
            (VmSupport->Flags.SessionSpace == 0)) {

            //
            // Only attach if the working set is worth examining.  This is
            // not just an optimization, as care must be taken not to attempt
            // an attach to a process which is a candidate for being currently
            // (or already) swapped out because if we attach to a page
            // directory that is in transition it's all over.
            //
            // Since this one is at the minimum where a racing swapout
            // thread can be processing it in parallel, just reinsert this
            // working set at the tail of the list.
            //

            InsertTailList (&MmWorkingSetExpansionHead.ListHead,
                            &VmSupport->WorkingSetExpansionLinks);
            goto skip;
        }

        VmSupport->WorkingSetExpansionLinks.Flink = MM_WS_TRIMMING;
        VmSupport->WorkingSetExpansionLinks.Blink = NULL;

        UNLOCK_EXPANSION (OldIrql);

        if (FirstSeen == NULL) {
            FirstSeen = VmSupport;
        }

        if (MiAttachAndLockWorkingSet (VmSupport) == TRUE) {

            if (EmptyIt == FALSE) {
                MiAgeAndEstimateAvailableInWorkingSet (VmSupport,
                                                       TRUE,
                                                       &WslesScanned,
                                                       &NewTotalClaim,
                                                       &NewTotalEstimatedAvailable);
            }
            else {
                MiEmptyWorkingSet (VmSupport, FALSE);
            }

            MiDetachAndUnlockWorkingSet (VmSupport);
        }

        LOCK_EXPANSION (OldIrql);

        ASSERT (VmSupport->WorkingSetExpansionLinks.Flink == MM_WS_TRIMMING);

        if (VmSupport->WorkingSetExpansionLinks.Blink == NULL) {

            //
            // Reinsert this working set at the tail of the list.
            //

            InsertTailList (&MmWorkingSetExpansionHead.ListHead,
                            &VmSupport->WorkingSetExpansionLinks);
        }
        else {

            //
            // The process is terminating - the value in the blink
            // is the address of an event to set.
            //

            ASSERT (VmSupport != &MmSystemCacheWs);

            VmSupport->WorkingSetExpansionLinks.Flink = MM_WS_NOT_LISTED;

            KeSetEvent ((PKEVENT)VmSupport->WorkingSetExpansionLinks.Blink,
                        0,
                        FALSE);
        }

skip:

        //
        // The initial working set that was chosen for FirstSeen may have
        // been trimmed down under its minimum and been removed from the
        // ExpansionHead links.  It is possible that the system cache is not
        // on the links either.  This check detects this extremely rare
        // situation so that the system does not spin forever.
        //

        LoopCount += 1;
        if (LoopCount > 200) {
            if (MmSystemCacheWs.WorkingSetExpansionLinks.Blink == NULL) {
                break;
            }
        }
    }

    UNLOCK_EXPANSION (OldIrql);

    if (EmptyIt == FALSE) {
        MmTotalClaim = NewTotalClaim;
        MmTotalEstimatedAvailable = NewTotalEstimatedAvailable;
    }
}

VOID
MiAgeAndEstimateAvailableInWorkingSet (
    IN PMMSUPPORT VmSupport,
    IN LOGICAL DoAging,
    IN PWSLE_NUMBER WslesScanned,
    IN OUT PPFN_NUMBER TotalClaim,
    IN OUT PPFN_NUMBER TotalEstimatedAvailable
    )

/*++

Routine Description:

    Age pages (clear the access bit or if the page hasn't been
    accessed, increment the age) for a portion of the working
    set.  Also, walk through a sample of the working set
    building a set of counts of how old the pages are.

    The counts are used to create a claim of the amount
    the system can steal from this process if memory
    becomes tight.

Arguments:

    VmSupport - Supplies the VM support structure to age and estimate.

    DoAging - TRUE if pages are to be aged.  Regardless, the pages will be
              added to the availability estimation.

    WslesScanned - Total numbers of WSLEs scanned on this sweep, used as a
                   control to prevent excessive aging on large systems with
                   many processes.

    TotalClaim - Supplies a pointer to system wide claim to update.

    TotalEstimatedAvailable - Supplies a pointer to system wide estimate
                              to update.

Return Value:

    None

Environment:

    Kernel mode, APCs disabled, working set mutex.  PFN lock NOT held.

--*/

{
    LOGICAL RecalculateShift;
    WSLE_NUMBER LastEntry;
    WSLE_NUMBER StartEntry;
    WSLE_NUMBER FirstDynamic;
    WSLE_NUMBER CurrentEntry;
    PMMWSL WorkingSetList;
    PMMWSLE Wsle;
    PMMPTE PointerPte;
    WSLE_NUMBER NumberToExamine;
    WSLE_NUMBER Claim;
    ULONG Estimate;
    ULONG SampledAgeCounts[MI_USE_AGE_COUNT] = {0};
    MI_NEXT_ESTIMATION_SLOT_CONST NextConst;
    WSLE_NUMBER SampleSize;
    WSLE_NUMBER AgeSize;
    ULONG CounterShift;
    WSLE_NUMBER Temp;
    ULONG i;

    WorkingSetList = VmSupport->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;
    AgeSize = 0;

    LastEntry = WorkingSetList->LastEntry;
    FirstDynamic = WorkingSetList->FirstDynamic;

    if (DoAging == TRUE) {

        //
        // Clear the used bits or increment the age of a portion of the
        // working set.
        //
        // Try to walk the entire working set every 2^MI_AGE_AGING_SHIFT
        // seconds.
        //

        if (VmSupport->WorkingSetSize > WorkingSetList->FirstDynamic) {
            NumberToExamine = (VmSupport->WorkingSetSize - WorkingSetList->FirstDynamic) >> MiAgingShift;

            //
            // Bigger machines can easily have working sets that span
            // terabytes so limit the absolute walk.
            //

            if (NumberToExamine > MI_MAXIMUM_SAMPLE) {
                NumberToExamine = MI_MAXIMUM_SAMPLE;
            }

            //
            // In addition to large working sets, bigger machines may also
            // have huge numbers of processes - checking the aggregate number
            // of working set list entries scanned prevents this situation
            // from triggering excessive scanning.
            //

            if ((WslesScanned != NULL) &&
                (*WslesScanned >= MiMaximumWslesPerSweep)) {

                NumberToExamine = 64;
            }

            AgeSize = NumberToExamine;
            CurrentEntry = VmSupport->NextAgingSlot;

            if (CurrentEntry > LastEntry || CurrentEntry < FirstDynamic) {
                CurrentEntry = FirstDynamic;
            }

            if (Wsle[CurrentEntry].u1.e1.Valid == 0) {
                MI_NEXT_VALID_AGING_SLOT(CurrentEntry, FirstDynamic, LastEntry, Wsle);
            }

            while (NumberToExamine != 0) {

                PointerPte = MiGetPteAddress (Wsle[CurrentEntry].u1.VirtualAddress);

                if (MI_GET_ACCESSED_IN_PTE(PointerPte) == 1) {
                    MI_SET_ACCESSED_IN_PTE(PointerPte, 0);
                    MI_RESET_WSLE_AGE(PointerPte, &Wsle[CurrentEntry]);
                }
                else {
                    MI_INC_WSLE_AGE(PointerPte, &Wsle[CurrentEntry]);
                }

                NumberToExamine -= 1;
                MI_NEXT_VALID_AGING_SLOT(CurrentEntry, FirstDynamic, LastEntry, Wsle);
            }

            VmSupport->NextAgingSlot = CurrentEntry + 1; // Start here next time
        }
    }

    //
    // Estimate the number of unused pages in the working set.
    //
    // The working set may have shrunk or the non-paged portion may have
    // grown since the last time.  Put the next counter at the FirstDynamic
    // if so.
    //

    CurrentEntry = VmSupport->NextEstimationSlot;

    if (CurrentEntry > LastEntry || CurrentEntry < FirstDynamic) {
        CurrentEntry = FirstDynamic;
    }

    //
    // When aging, walk the entire working set every 2^MiEstimationShift
    // seconds.
    //

    CounterShift = 0;
    SampleSize = 0;

    if (VmSupport->WorkingSetSize > WorkingSetList->FirstDynamic) {

        RecalculateShift = FALSE;
        SampleSize = VmSupport->WorkingSetSize - WorkingSetList->FirstDynamic;
        NumberToExamine = SampleSize >> MiEstimationShift;

        //
        // Bigger machines may have huge numbers of processes - checking the
        // aggregate number of working set list entries scanned prevents this
        // situation from triggering excessive scanning.
        //

        if ((WslesScanned != NULL) &&
            (*WslesScanned >= MiMaximumWslesPerSweep)) {
            RecalculateShift = TRUE;
        }
        else if (NumberToExamine > MI_MAXIMUM_SAMPLE) {

            //
            // Bigger machines can easily have working sets that span
            // terabytes so limit the absolute walk.
            //

            NumberToExamine = MI_MAXIMUM_SAMPLE;

            Temp = SampleSize >> MI_MINIMUM_SAMPLE_SHIFT;

            SampleSize = MI_MAXIMUM_SAMPLE;

            //
            // Calculate the necessary counter shift to estimate pages
            // in use.
            //

            for ( ; Temp != 0; Temp = Temp >> 1) {
                CounterShift += 1;
            }
        }
        else if (NumberToExamine >= MI_MINIMUM_SAMPLE) {

            //
            // Ensure that NumberToExamine is at least the minimum size.
            //

            SampleSize = NumberToExamine;
            CounterShift = MiEstimationShift;
        }
        else if (SampleSize > MI_MINIMUM_SAMPLE) {
            RecalculateShift = TRUE;
        }

        if (RecalculateShift == TRUE) {
            Temp = SampleSize >> MI_MINIMUM_SAMPLE_SHIFT;
            SampleSize = MI_MINIMUM_SAMPLE;

            //
            // Calculate the necessary counter shift to estimate pages
            // in use.
            //

            for ( ; Temp != 0; Temp = Temp >> 1) {
                CounterShift += 1;
            }
        }

        ASSERT (SampleSize != 0);

        MI_CALC_NEXT_ESTIMATION_SLOT_CONST(NextConst, WorkingSetList);

        StartEntry = FirstDynamic;

        if (Wsle[CurrentEntry].u1.e1.Valid == 0) {

            MI_NEXT_VALID_ESTIMATION_SLOT (CurrentEntry,
                                           StartEntry,
                                           FirstDynamic,
                                           LastEntry,
                                           NextConst,
                                           Wsle);
        }

        for (i = 0; i < SampleSize; i += 1) {

            PointerPte = MiGetPteAddress (Wsle[CurrentEntry].u1.VirtualAddress);

            if (MI_GET_ACCESSED_IN_PTE(PointerPte) == 0) {
                MI_UPDATE_USE_ESTIMATE (PointerPte,
                                        &Wsle[CurrentEntry],
                                        SampledAgeCounts);
            }

            if (i == NumberToExamine - 1) {

                //
                // Start estimation here next time.
                //

                VmSupport->NextEstimationSlot = CurrentEntry + 1;
            }

            MI_NEXT_VALID_ESTIMATION_SLOT (CurrentEntry,
                                           StartEntry,
                                           FirstDynamic,
                                           LastEntry,
                                           NextConst,
                                           Wsle);
        }
    }

    if (SampleSize < AgeSize) {
        SampleSize = AgeSize;
    }

    if (WslesScanned != NULL) {
        *WslesScanned += SampleSize;
    }

    Estimate = MI_CALCULATE_USAGE_ESTIMATE(SampledAgeCounts, CounterShift);

    Claim = VmSupport->Claim + MI_CLAIM_INCR;

    if (Claim > Estimate) {
        Claim = Estimate;
    }

    VmSupport->Claim = Claim;
    VmSupport->EstimatedAvailable = Estimate;

    PERFINFO_WSMANAGE_DUMPWS(VmSupport, SampledAgeCounts);

    VmSupport->GrowthSinceLastEstimate = 0;
    *TotalClaim += Claim >> ((VmSupport->Flags.MemoryPriority == MEMORY_PRIORITY_FOREGROUND)
                                ? MI_FOREGROUND_CLAIM_AVAILABLE_SHIFT
                                : MI_BACKGROUND_CLAIM_AVAILABLE_SHIFT);

    *TotalEstimatedAvailable += Estimate;
    return;
}

ULONG MiClaimAdjustmentThreshold[8] = { 0, 0, 4000, 8000, 12000, 24000, 32000, 32000};

VOID
MiAdjustClaimParameters (
    IN LOGICAL EnoughPages
    )

/*++

Routine Description:

    Adjust the rate at which we walk through working sets.  If we have
    enough pages (we aren't trimming pages that aren't considered young),
    then we check to see whether we should decrease the aging rate and
    vice versa.

    The limits for the aging rate are 1/8 and 1/128 of the working sets.
    This means that the finest age granularities are 8 to 128 seconds in
    these cases.  With the current 2 bit counter, at the low end we would
    start trimming pages > 16 seconds old and at the high end > 4 minutes.

Arguments:

    EnoughPages - Supplies whether to increase the rate or decrease it.

Return Value:

    None.

Environment:

    Kernel mode.

--*/

{
    LARGE_INTEGER CurrentTime;

    KeQuerySystemTime (&CurrentTime);

    if (EnoughPages == TRUE &&
        ((MmTotalClaim + MmAvailablePages) > MiClaimAdjustmentThreshold[MiAgingShift])) {

        //
        // Don't adjust the rate too frequently, don't go over the limit, and
        // make sure there are enough claimed and/or available.
        //

        if (((CurrentTime.QuadPart - MiLastAdjustmentOfClaimParams.QuadPart) >
                MmClaimParameterAdjustUpTime.QuadPart) &&
            (MiAgingShift < MI_MAXIMUM_AGING_SHIFT ) ) {

            //
            // Set the time only when we change the rate.
            //

            MiLastAdjustmentOfClaimParams.QuadPart = CurrentTime.QuadPart;

            MiAgingShift += 1;
            MiEstimationShift += 1;
        }
    }
    else if ((EnoughPages == FALSE) ||
             (MmTotalClaim + MmAvailablePages) < MiClaimAdjustmentThreshold[MiAgingShift - 1]) {

        //
        // Don't adjust the rate down too frequently.
        //

        if ((CurrentTime.QuadPart - MiLastAdjustmentOfClaimParams.QuadPart) >
                MmClaimParameterAdjustDownTime.QuadPart) {

            //
            // Always set the time so we don't adjust up too soon after
            // a 2nd pass trim.
            //

            MiLastAdjustmentOfClaimParams.QuadPart = CurrentTime.QuadPart;

            //
            // Don't go under the limit.
            //

            if (MiAgingShift > 3) {
                MiAgingShift -= 1;
                MiEstimationShift -= 1;
            }
        }
    }
}

#define MM_WS_REORG_BUCKETS_MAX 7

#if DBG
ULONG MiSessionIdleBuckets[MM_WS_REORG_BUCKETS_MAX];
#endif

VOID
MiRearrangeWorkingSetExpansionList (
    VOID
    )

/*++

Routine Description:

    This function arranges the working set list into different
    groups based upon the claim.  This is done so the working set
    trimming will take place on fat processes first.

    The working sets are sorted into buckets and then linked back up.

    Swapped out sessions and processes are put at the front.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode, no locks held.

--*/

{
    KIRQL OldIrql;
    PLIST_ENTRY ListEntry;
    PMMSUPPORT VmSupport;
    int Size;
    int PreviousNonEmpty;
    int NonEmpty;
    LIST_ENTRY ListHead[MM_WS_REORG_BUCKETS_MAX];
    LARGE_INTEGER CurrentTime;
    LARGE_INTEGER SessionIdleTime;
    ULONG IdleTime;
    PMM_SESSION_SPACE SessionGlobal;

    KeQuerySystemTime (&CurrentTime);

    if (IsListEmpty (&MmWorkingSetExpansionHead.ListHead)) {
        return;
    }

    for (Size = 0 ; Size < MM_WS_REORG_BUCKETS_MAX; Size++) {
        InitializeListHead (&ListHead[Size]);
    }

    LOCK_EXPANSION (OldIrql);

    while (!IsListEmpty (&MmWorkingSetExpansionHead.ListHead)) {
        ListEntry = RemoveHeadList (&MmWorkingSetExpansionHead.ListHead);

        VmSupport = CONTAINING_RECORD(ListEntry,
                                          MMSUPPORT,
                                          WorkingSetExpansionLinks);

        if (VmSupport->Flags.TrimHard == 1) {

            ASSERT (VmSupport->Flags.SessionSpace == 1);

            SessionGlobal = CONTAINING_RECORD (VmSupport,
                                               MM_SESSION_SPACE,
                                               Vm);

            SessionIdleTime.QuadPart = CurrentTime.QuadPart - SessionGlobal->LastProcessSwappedOutTime.QuadPart;

#if DBG
            if (MmDebug & MM_DBG_SESSIONS) {
                DbgPrint ("Mm: Session %d heavily trim/aged - all its processes (%d) swapped out %d seconds ago\n",
                    SessionGlobal->SessionId,
                    SessionGlobal->ReferenceCount,
                    (ULONG)(SessionIdleTime.QuadPart / 10000000));
            }
#endif

            if (SessionIdleTime.QuadPart < 0) {

                //
                // The administrator has moved the system time backwards.
                // Give this session a fresh start.
                //

                SessionIdleTime.QuadPart = 0;
                KeQuerySystemTime (&SessionGlobal->LastProcessSwappedOutTime);
            }

            IdleTime = (ULONG) (SessionIdleTime.QuadPart / 10000000);
        }
        else {
            IdleTime = 0;
        }

        if (VmSupport->Flags.MemoryPriority == MEMORY_PRIORITY_FOREGROUND) {

            //
            // Put the foreground processes at the end of the list,
            // to give them priority.
            //

            Size = 6;
        }
        else {

            if (VmSupport->Claim > 400) {
                Size = 0;
            }
            else if (IdleTime > 30) {
                Size = 0;
#if DBG
                MiSessionIdleBuckets[Size] += 1;
#endif
            }
            else if (VmSupport->Claim > 200) {
                Size = 1;
            }
            else if (IdleTime > 20) {
                Size = 1;
#if DBG
                MiSessionIdleBuckets[Size] += 1;
#endif
            }
            else if (VmSupport->Claim > 100) {
                Size = 2;
            }
            else if (IdleTime > 10) {
                Size = 2;
#if DBG
                MiSessionIdleBuckets[Size] += 1;
#endif
            }
            else if (VmSupport->Claim > 50) {
                Size = 3;
            }
            else if (IdleTime) {
                Size = 3;
#if DBG
                MiSessionIdleBuckets[Size] += 1;
#endif
            }
            else if (VmSupport->Claim > 25) {
                Size = 4;
            }
            else {
                Size = 5;
#if DBG
                if (VmSupport->Flags.SessionSpace == 1) {
                    MiSessionIdleBuckets[Size] += 1;
                }
#endif
            }
        }

#if DBG
        if (MmDebug & MM_DBG_WS_EXPANSION) {
            DbgPrint("MM-rearrange: TrimHard = %d, WS Size = 0x%x, Claim 0x%x, Bucket %d\n",
                    VmSupport->Flags.TrimHard,
                    VmSupport->WorkingSetSize,
                    VmSupport->Claim,
                    Size);
        }
#endif //DBG

        //
        // Note: this reverses the bucket order each time we
        // reorganize the lists.  This may be good or bad -
        // if you change it you may want to think about it.
        //

        InsertHeadList (&ListHead[Size],
                        &VmSupport->WorkingSetExpansionLinks);
    }

    //
    // Find the first non-empty list.
    //

    for (NonEmpty = 0 ; NonEmpty < MM_WS_REORG_BUCKETS_MAX ; NonEmpty += 1) {
        if (!IsListEmpty (&ListHead[NonEmpty])) {
            break;
        }
    }

    //
    // Put the head of first non-empty list at the beginning
    // of the MmWorkingSetExpansion list.
    //

    MmWorkingSetExpansionHead.ListHead.Flink = ListHead[NonEmpty].Flink;
    ListHead[NonEmpty].Flink->Blink = &MmWorkingSetExpansionHead.ListHead;

    PreviousNonEmpty = NonEmpty;

    //
    // Link the rest of the lists together.
    //

    for (NonEmpty += 1; NonEmpty < MM_WS_REORG_BUCKETS_MAX; NonEmpty += 1) {

        if (!IsListEmpty (&ListHead[NonEmpty])) {

            ListHead[PreviousNonEmpty].Blink->Flink = ListHead[NonEmpty].Flink;
            ListHead[NonEmpty].Flink->Blink = ListHead[PreviousNonEmpty].Blink;
            PreviousNonEmpty = NonEmpty;
        }
    }

    //
    // Link the tail of last non-empty to the MmWorkingSetExpansion list.
    //

    MmWorkingSetExpansionHead.ListHead.Blink = ListHead[PreviousNonEmpty].Blink;
    ListHead[PreviousNonEmpty].Blink->Flink = &MmWorkingSetExpansionHead.ListHead;

    UNLOCK_EXPANSION (OldIrql);

    return;
}


VOID
MmEmptyAllWorkingSets (
    VOID
    )

/*++

Routine Description:

    This routine attempts to empty all the working sets on the
    expansion list.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode.  No locks held.  APC level or below.

--*/

{
    KIRQL OldIrql;

    ASSERT (KeGetCurrentIrql () <= APC_LEVEL);

    ASSERT (PsGetCurrentThread () != MmWorkingSetThread);

    //
    // For session working sets, we cannot attach directly to the session
    // space to be trimmed because it would result in session space
    // references by other threads in this process to the attached session
    // instead of the (currently) correct one.  In fact, we cannot even queue
    // this to a worker thread because the working set manager
    // (who shares the same page directory) may be attaching or
    // detaching from a session (any session).  So this must be queued
    // to the working set manager.
    //

    LOCK_EXPANSION (OldIrql);

    if (MiWaitingForWorkingSetEmpty == FALSE) {
        MiWaitingForWorkingSetEmpty = TRUE;
        KeClearEvent (&MiWaitForEmptyEvent);
    }

    UNLOCK_EXPANSION (OldIrql);

    KeSetEvent (&MmWorkingSetManagerEvent, 0, FALSE);

    KeWaitForSingleObject (&MiWaitForEmptyEvent,
                           WrVirtualMemory,
                           KernelMode,
                           FALSE,
                           (PLARGE_INTEGER)0);

    return;
}

//
// This is deliberately initialized to 1 and only cleared when we have
// initialized enough of the system working set to support a trim.
//

LONG MiTrimInProgressCount = 1;

ULONG MiTrimAllPageFaultCount;


LOGICAL
MmTrimAllSystemPagableMemory (
    IN LOGICAL PurgeTransition
    )

/*++

Routine Description:

    This routine unmaps all pagable system memory.  This does not unmap user
    memory or locked down kernel memory.  Thus, the memory being unmapped
    resides in paged pool, pagable kernel/driver code & data, special pool
    and the system cache.

    Note that pages with a reference count greater than 1 are skipped (ie:
    they remain valid, as they are assumed to be locked down).  This prevents
    us from unmapping all of the system cache entries, etc.

    Non-locked down kernel stacks must be outpaged by modifying the balance
    set manager to operate in conjunction with a support routine.  This is not
    done here.

Arguments:

    PurgeTransition - Supplies whether to purge all the clean pages from the
                      transition list.

Return Value:

    TRUE if accomplished, FALSE if not.

Environment:

    Kernel mode.  APC_LEVEL or below.

--*/

{
    return MiTrimAllSystemPagableMemory (MI_SYSTEM_GLOBAL, PurgeTransition);
}
#if DBG

LOGICAL
MmTrimProcessMemory (
    IN LOGICAL PurgeTransition
    )

/*++

Routine Description:

    This routine unmaps all of the current process' user memory.

Arguments:

    PurgeTransition - Supplies whether to purge all the clean pages from the
                      transition list.

Return Value:

    TRUE if accomplished, FALSE if not.

Environment:

    Kernel mode.  APC_LEVEL or below.

--*/

{
    return MiTrimAllSystemPagableMemory (MI_USER_LOCAL, PurgeTransition);
}
#endif


LOGICAL
MiTrimAllSystemPagableMemory (
    IN ULONG MemoryType,
    IN LOGICAL PurgeTransition
    )

/*++

Routine Description:

    This routine unmaps all pagable memory of the type specified.

    Note that pages with a reference count greater than 1 are skipped (ie:
    they remain valid, as they are assumed to be locked down).  This prevents
    us from unmapping all of the system cache entries, etc.

    Non-locked down kernel stacks must be outpaged by modifying the balance
    set manager to operate in conjunction with a support routine.  This is not
    done here.

Arguments:

    MemoryType - Supplies the type of memory to unmap.

    PurgeTransition - Supplies whether to purge all the clean pages from the
                      transition list.

Return Value:

    TRUE if accomplished, FALSE if not.

Environment:

    Kernel mode.  APC_LEVEL or below.

--*/

{
    LOGICAL Status;
    KIRQL OldIrql;
    PMMSUPPORT VmSupport;
    WSLE_NUMBER PagesInUse;
    LOGICAL LockAvailable;
    PETHREAD CurrentThread;
    PEPROCESS Process;
    PMM_SESSION_SPACE SessionGlobal;

#if defined(_X86_)
    ULONG flags;
#endif

    //
    // It's ok to check this without acquiring the system WS lock.
    //

    if (MemoryType == MI_SYSTEM_GLOBAL) {
        if (MiTrimAllPageFaultCount == MmSystemCacheWs.PageFaultCount) {
            return FALSE;
        }
    }
    else if (MemoryType == MI_USER_LOCAL) {
    }
    else {
        ASSERT (MemoryType == MI_SESSION_LOCAL);
    }

    //
    // Working set mutexes will be acquired which require APC_LEVEL or below.
    //

    if (KeGetCurrentIrql () > APC_LEVEL) {
        return FALSE;
    }

    //
    // Just return if it's too early during system initialization or if
    // another thread/processor is racing here to do the work for us.
    //

    if (InterlockedIncrement (&MiTrimInProgressCount) > 1) {
        InterlockedDecrement (&MiTrimInProgressCount);
        return FALSE;
    }

#if defined(_X86_)

    _asm {
        pushfd
        pop     eax
        mov     flags, eax
    }

    if ((flags & EFLAGS_INTERRUPT_MASK) == 0) {
        InterlockedDecrement (&MiTrimInProgressCount);
        return FALSE;
    }

#endif

#if defined(_AMD64_)
    if ((GetCallersEflags () & EFLAGS_IF_MASK) == 0) {
        InterlockedDecrement (&MiTrimInProgressCount);
        return FALSE;
    }
#endif

    CurrentThread = PsGetCurrentThread ();

    //
    // Don't acquire mutexes if the thread is at priority 0 (ie: zeropage
    // thread) because this priority is not boosted - so a preemption that
    // occurs after a WS mutex is acquired can result in the thread never
    // running again and then all the other threads will be denied the mutex.
    //

    if (CurrentThread->Tcb.Priority == 0) {
        InterlockedDecrement (&MiTrimInProgressCount);
        return FALSE;
    }

    //
    // If the WS mutex is not readily available then just return.
    //

    if (MemoryType == MI_SYSTEM_GLOBAL) {

        Process = NULL;
        VmSupport = &MmSystemCacheWs;

        if (KeTryToAcquireGuardedMutex (&VmSupport->WorkingSetMutex) == FALSE) {
            InterlockedDecrement (&MiTrimInProgressCount);
            return FALSE;
        }

        MM_SYSTEM_WS_LOCK_TIMESTAMP ();
    }
    else if (MemoryType == MI_USER_LOCAL) {

        Process = PsGetCurrentProcessByThread (CurrentThread);
        VmSupport = &Process->Vm;

        if (KeTryToAcquireGuardedMutex (&VmSupport->WorkingSetMutex) == FALSE) {
            InterlockedDecrement (&MiTrimInProgressCount);
            return FALSE;
        }

        LOCK_WS_TIMESTAMP (Process);

        //
        // If the process is exiting then just return.
        //

        if (Process->Flags & PS_PROCESS_FLAGS_VM_DELETED) {
            UNLOCK_WS (Process);
            InterlockedDecrement (&MiTrimInProgressCount);
            return FALSE;
        }

        ASSERT (!MI_IS_WS_UNSAFE(Process));
    }
    else {
        ASSERT (MemoryType == MI_SESSION_LOCAL);

        Process = PsGetCurrentProcessByThread (CurrentThread);

        if (((Process->Flags & PS_PROCESS_FLAGS_IN_SESSION) == 0) ||
            (Process->Vm.Flags.SessionLeader == 1)) {

            InterlockedDecrement (&MiTrimInProgressCount);
            return FALSE;
        }

        SessionGlobal = SESSION_GLOBAL (MmSessionSpace);

        //
        // If the WS mutex is not readily available then just return.
        //

        VmSupport = &SessionGlobal->Vm;

        if (KeTryToAcquireGuardedMutex (&VmSupport->WorkingSetMutex) == FALSE) {
            InterlockedDecrement (&MiTrimInProgressCount);
            return FALSE;
        }
    }

    Status = FALSE;

    //
    // If the expansion lock is not available then just return.
    //

    LockAvailable = KeTryToAcquireSpinLock (&MmExpansionLock, &OldIrql);

    if (LockAvailable == FALSE) {
        goto Bail;
    }

    MM_SET_EXPANSION_OWNER ();

    if (VmSupport->WorkingSetExpansionLinks.Flink <= MM_WS_SWAPPED_OUT) {
        UNLOCK_EXPANSION (OldIrql);
        goto Bail;
    }

    RemoveEntryList (&VmSupport->WorkingSetExpansionLinks);

    VmSupport->WorkingSetExpansionLinks.Flink = MM_WS_TRIMMING;
    VmSupport->WorkingSetExpansionLinks.Blink = NULL;

    if (MemoryType == MI_SYSTEM_GLOBAL) {
        MiTrimAllPageFaultCount = VmSupport->PageFaultCount;
    }

    PagesInUse = VmSupport->WorkingSetSize;

    //
    // There are 2 issues here that are carefully dealt with :
    //
    // 1.  APCs must be disabled while any resources are held to prevent
    //     suspend APCs from deadlocking the system.
    //
    // 2.  Once the working set has been marked MM_WS_TRIMMING,
    //     either the thread must not be preempted or the working
    //     set mutex must be held throughout.  Otherwise a high priority thread
    //     can fault on a system code and data address and the two pages will
    //     thrash forever (at high priority) because no system working set
    //     expansion is allowed while TRIMMING is set.
    //
    // Thus, the decision was to hold the working set mutex throughout.
    //

    UNLOCK_EXPANSION (OldIrql);

    MiEmptyWorkingSet (VmSupport, FALSE);

    LOCK_EXPANSION (OldIrql);

    ASSERT (VmSupport->WorkingSetExpansionLinks.Flink == MM_WS_TRIMMING);

    if (VmSupport->WorkingSetExpansionLinks.Blink == NULL) {

        //
        // Reinsert this working set at the tail of the list.
        //

        InsertTailList (&MmWorkingSetExpansionHead.ListHead,
                        &VmSupport->WorkingSetExpansionLinks);
    }
    else {

        //
        // The process is terminating - the value in the blink
        // is the address of an event to set.
        //

        ASSERT (VmSupport != &MmSystemCacheWs);

        VmSupport->WorkingSetExpansionLinks.Flink = MM_WS_NOT_LISTED;

        KeSetEvent ((PKEVENT)VmSupport->WorkingSetExpansionLinks.Blink,
                    0,
                    FALSE);
    }

    UNLOCK_EXPANSION (OldIrql);

    Status = TRUE;

Bail:

    UNLOCK_WORKING_SET (VmSupport);

    ASSERT (KeGetCurrentIrql() <= APC_LEVEL);

    if ((PurgeTransition == TRUE) && (Status == TRUE)) {
        MiPurgeTransitionList ();
    }

    InterlockedDecrement (&MiTrimInProgressCount);

    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\wstree.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

   wstree.c

Abstract:

    This module contains the routines which manipulate the working
    set list tree.

Author:

    Lou Perazzoli (loup) 15-May-1989
    Landy Wang (landyw) 02-June-1997

Revision History:

--*/

#include "mi.h"

extern ULONG MmSystemCodePage;
extern ULONG MmSystemCachePage;
extern ULONG MmPagedPoolPage;
extern ULONG MmSystemDriverPage;

#if DBG
ULONG MmNumberOfInserts;
#endif

#if defined (_WIN64)
ULONG MiWslePteLoops = 16;
#endif

#if defined (_MI_DEBUG_WSLE)
LONG MiWsleIndex;
MI_WSLE_TRACES MiWsleTraces[MI_WSLE_TRACE_SIZE];

VOID
MiCheckWsleList (
    IN PMMSUPPORT WsInfo
    );

#endif

VOID
MiRepointWsleHashIndex (
    IN MMWSLE WsleEntry,
    IN PMMWSL WorkingSetList,
    IN WSLE_NUMBER NewWsIndex
    );

VOID
MiCheckWsleHash (
    IN PMMWSL WorkingSetList
    );


VOID
FASTCALL
MiInsertWsleHash (
    IN WSLE_NUMBER Entry,
    IN PMMSUPPORT WsInfo
    )

/*++

Routine Description:

    This routine inserts a Working Set List Entry (WSLE) into the
    hash list for the specified working set.

Arguments:

    Entry - The index number of the WSLE to insert.

    WorkingSetList - Supplies the working set list to insert into.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, Working Set Mutex held.

--*/

{
    ULONG Tries;
    PVOID VirtualAddress;
    PMMWSLE Wsle;
    WSLE_NUMBER Hash;
    PMMWSLE_HASH Table;
    WSLE_NUMBER j;
    WSLE_NUMBER Index;
    ULONG HashTableSize;
    PMMWSL WorkingSetList;

    WorkingSetList = WsInfo->VmWorkingSetList;

    Wsle = WorkingSetList->Wsle;

    ASSERT (Wsle[Entry].u1.e1.Valid == 1);
    ASSERT (Wsle[Entry].u1.e1.Direct != 1);

    Table = WorkingSetList->HashTable;

#if defined (_MI_DEBUG_WSLE)
    MiCheckWsleList (WsInfo);
#endif

    if (Table == NULL) {
        return;
    }

#if DBG
    MmNumberOfInserts += 1;
#endif

    VirtualAddress = PAGE_ALIGN (Wsle[Entry].u1.VirtualAddress);

    Hash = MI_WSLE_HASH (Wsle[Entry].u1.Long, WorkingSetList);

    HashTableSize = WorkingSetList->HashTableSize;

    //
    // Check hash table size and see if there is enough room to
    // hash or if the table should be grown.
    //

    if ((WorkingSetList->NonDirectCount + 10 + (HashTableSize >> 4)) >
                HashTableSize) {

        if ((Table + HashTableSize + ((2*PAGE_SIZE) / sizeof (MMWSLE_HASH)) <= (PMMWSLE_HASH)WorkingSetList->HighestPermittedHashAddress)) {

            WsInfo->Flags.GrowWsleHash = 1;
        }

        if ((WorkingSetList->NonDirectCount + (HashTableSize >> 4)) >
                HashTableSize) {

            //
            // No more room in the hash table, remove one and add there.
            //
            // Note the actual WSLE is not removed - just its hash entry is
            // so that we can use it for the entry now being inserted.  This
            // is nice because it preserves both entries in the working set
            // (although it is a bit more costly to remove the original
            // entry later since it won't have a hash entry).
            //

            j = Hash;

            Tries = 0;
            do {
                if (Table[j].Key != 0) {

                    Index = WorkingSetList->HashTable[j].Index;
                    ASSERT (Wsle[Index].u1.e1.Direct == 0);
                    ASSERT (Wsle[Index].u1.e1.Valid == 1);
                    ASSERT (Table[j].Key == MI_GENERATE_VALID_WSLE (&Wsle[Index]));

                    Table[j].Key = 0;
                    Hash = j;
                    break;
                }

                j += 1;

                if (j >= HashTableSize) {
                    j = 0;
                    ASSERT (Tries == 0);
                    Tries = 1;
                }

                if (j == Hash) {
                    return;
                }

            } while (TRUE);
        }
    }

    //
    // Add to the hash table if there is space.
    //

    Tries = 0;
    j = Hash;

    while (Table[Hash].Key != 0) {
        Hash += 1;
        if (Hash >= HashTableSize) {
            ASSERT (Tries == 0);
            Hash = 0;
            Tries = 1;
        }
        if (j == Hash) {
            return;
        }
    }

    ASSERT (Hash < HashTableSize);

    Table[Hash].Key = MI_GENERATE_VALID_WSLE (&Wsle[Entry]);
    Table[Hash].Index = Entry;

#if DBG
    if ((MmNumberOfInserts % 1000) == 0) {
        MiCheckWsleHash (WorkingSetList);
    }
#endif
    return;
}

#if DBG
VOID
MiCheckWsleHash (
    IN PMMWSL WorkingSetList
    )
{
    ULONG i;
    ULONG found;
    PMMWSLE Wsle;

    found = 0;
    Wsle = WorkingSetList->Wsle;

    for (i = 0; i < WorkingSetList->HashTableSize; i += 1) {
        if (WorkingSetList->HashTable[i].Key != 0) {
            found += 1;
            ASSERT (WorkingSetList->HashTable[i].Key ==
                MI_GENERATE_VALID_WSLE (&Wsle[WorkingSetList->HashTable[i].Index]));
        }
    }
    if (found > WorkingSetList->NonDirectCount) {
        DbgPrint("MMWSLE: Found %lx, nondirect %lx\n",
                    found, WorkingSetList->NonDirectCount);
        DbgBreakPoint();
    }
}
#endif

#if defined (_MI_DEBUG_WSLE)
VOID
MiCheckWsleList (
    IN PMMSUPPORT WsInfo
    )
{
    ULONG i;
    ULONG found;
    PMMWSLE Wsle;
    PMMWSL WorkingSetList;

    WorkingSetList = WsInfo->VmWorkingSetList;

    Wsle = WorkingSetList->Wsle;

    found = 0;
    for (i = 0; i <= WorkingSetList->LastInitializedWsle; i += 1) {
        if (Wsle->u1.e1.Valid == 1) {
            found += 1;
        }
        Wsle += 1;
    }
    if (found != WsInfo->WorkingSetSize) {
        DbgPrint ("MMWSLE0: Found %lx, ws size %lx\n",
                    found, WsInfo->WorkingSetSize);
        DbgBreakPoint ();
    }
}
#endif


WSLE_NUMBER
FASTCALL
MiLocateWsle (
    IN PVOID VirtualAddress,
    IN PMMWSL WorkingSetList,
    IN WSLE_NUMBER WsPfnIndex
    )

/*++

Routine Description:

    This function locates the specified virtual address within the
    working set list.

Arguments:

    VirtualAddress - Supplies the virtual to locate within the working
                     set list.

    WorkingSetList - Supplies the working set list to search.

    WsPfnIndex - Supplies a hint to try before hashing or walking linearly.

Return Value:

    Returns the index into the working set list which contains the entry.

Environment:

    Kernel mode, APCs disabled, Working Set Mutex held.

--*/

{
    PMMWSLE Wsle;
    PMMWSLE LastWsle;
    WSLE_NUMBER Hash;
    WSLE_NUMBER StartHash;
    PMMWSLE_HASH Table;
    ULONG Tries;
#if defined (_WIN64)
    ULONG LoopCount;
    WSLE_NUMBER WsPteIndex;
    PMMPTE PointerPte;
#endif

    Wsle = WorkingSetList->Wsle;
    VirtualAddress = PAGE_ALIGN (VirtualAddress);

    if (WsPfnIndex <= WorkingSetList->LastInitializedWsle) {
        if ((VirtualAddress == PAGE_ALIGN(Wsle[WsPfnIndex].u1.VirtualAddress)) &&
            (Wsle[WsPfnIndex].u1.e1.Valid == 1)) {
            return WsPfnIndex;
        }
    }

#if defined (_WIN64)
    PointerPte = MiGetPteAddress (VirtualAddress);
    WsPteIndex = MI_GET_WORKING_SET_FROM_PTE (PointerPte);

    if (WsPteIndex != 0) {

        LoopCount = MiWslePteLoops;

        while (WsPteIndex <= WorkingSetList->LastInitializedWsle) {

            if ((VirtualAddress == PAGE_ALIGN(Wsle[WsPteIndex].u1.VirtualAddress)) &&
                (Wsle[WsPteIndex].u1.e1.Valid == 1)) {
                    return WsPteIndex;
            }

            LoopCount -= 1;

            //
            // No working set index so far for this PTE.  Since the working
            // set may be very large (8TB would mean up to half a million loops)
            // just fall back to the hash instead.
            //

            if (LoopCount == 0) {
                break;
            }

            WsPteIndex += MI_MAXIMUM_PTE_WORKING_SET_INDEX;
        }
    }
#endif

    if (WorkingSetList->HashTable != NULL) {
        Tries = 0;
        Table = WorkingSetList->HashTable;

        Hash = MI_WSLE_HASH(VirtualAddress, WorkingSetList);
        StartHash = Hash;

        //
        // Or in the valid bit so virtual address 0 is handled
        // properly (instead of matching a free hash entry).
        //

        VirtualAddress = (PVOID)((ULONG_PTR)VirtualAddress | 0x1);

        while (Table[Hash].Key != VirtualAddress) {
            Hash += 1;
            if (Hash >= WorkingSetList->HashTableSize) {
                ASSERT (Tries == 0);
                Hash = 0;
                Tries = 1;
            }
            if (Hash == StartHash) {
                Tries = 2;
                break;
            }
        }
        if (Tries < 2) {
            ASSERT (WorkingSetList->Wsle[Table[Hash].Index].u1.e1.Direct == 0);
            return Table[Hash].Index;
        }
        VirtualAddress = (PVOID)((ULONG_PTR)VirtualAddress & ~0x1);
    }

    LastWsle = Wsle + WorkingSetList->LastInitializedWsle;

    do {
        if ((Wsle->u1.e1.Valid == 1) &&
            (VirtualAddress == PAGE_ALIGN(Wsle->u1.VirtualAddress))) {

            ASSERT (Wsle->u1.e1.Direct == 0);
            return (WSLE_NUMBER)(Wsle - WorkingSetList->Wsle);
        }
        Wsle += 1;

    } while (Wsle <= LastWsle);

    KeBugCheckEx (MEMORY_MANAGEMENT,
                  0x41284,
                  (ULONG_PTR)VirtualAddress,
                  WsPfnIndex,
                  (ULONG_PTR)WorkingSetList);
}


VOID
FASTCALL
MiRemoveWsle (
    IN WSLE_NUMBER Entry,
    IN PMMWSL WorkingSetList
    )

/*++

Routine Description:

    This routine removes a Working Set List Entry (WSLE) from the
    working set.

Arguments:

    Entry - The index number of the WSLE to remove.


Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, Working Set Mutex held.

--*/
{
    PMMWSLE Wsle;
    PVOID VirtualAddress;
    PMMWSLE_HASH Table;
    MMWSLE WsleContents;
    WSLE_NUMBER Hash;
    WSLE_NUMBER StartHash;
    ULONG Tries;

    Wsle = WorkingSetList->Wsle;

    //
    // Locate the entry in the tree.
    //

#if DBG
    if (MmDebug & MM_DBG_DUMP_WSL) {
        MiDumpWsl();
        DbgPrint(" \n");
    }
#endif

    if (Entry > WorkingSetList->LastInitializedWsle) {
        KeBugCheckEx (MEMORY_MANAGEMENT,
                      0x41785,
                      (ULONG_PTR)WorkingSetList,
                      Entry,
                      0);
    }

    ASSERT (Wsle[Entry].u1.e1.Valid == 1);

    VirtualAddress = PAGE_ALIGN (Wsle[Entry].u1.VirtualAddress);

    if (WorkingSetList == MmSystemCacheWorkingSetList) {

        //
        // Count system space inserts and removals.
        //

#if defined(_X86_)
        if (MI_IS_SYSTEM_CACHE_ADDRESS(VirtualAddress)) {
            MmSystemCachePage -= 1;
        }
        else
#endif
        if (VirtualAddress < MmSystemCacheStart) {
            MmSystemCodePage -= 1;
        }
        else if (VirtualAddress < MM_PAGED_POOL_START) {
            MmSystemCachePage -= 1;
        }
        else if (VirtualAddress < MmNonPagedSystemStart) {
            MmPagedPoolPage -= 1;
        }
        else {
            MmSystemDriverPage -= 1;
        }
    }

    WsleContents = Wsle[Entry];
    WsleContents.u1.e1.Valid = 0;

    MI_LOG_WSLE_CHANGE (WorkingSetList, Entry, WsleContents);

    Wsle[Entry].u1.e1.Valid = 0;

    if (Wsle[Entry].u1.e1.Direct == 0) {

        WorkingSetList->NonDirectCount -= 1;

        if (WorkingSetList->HashTable != NULL) {

            Hash = MI_WSLE_HASH (Wsle[Entry].u1.Long, WorkingSetList);
            Table = WorkingSetList->HashTable;
            Tries = 0;
            StartHash = Hash;

            //
            // Or in the valid bit so virtual address 0 is handled
            // properly (instead of matching a free hash entry).
            //

            VirtualAddress = (PVOID)((ULONG_PTR)VirtualAddress | 0x1);

            while (Table[Hash].Key != VirtualAddress) {
                Hash += 1;
                if (Hash >= WorkingSetList->HashTableSize) {
                    ASSERT (Tries == 0);
                    Hash = 0;
                    Tries = 1;
                }
                if (Hash == StartHash) {

                    //
                    // The entry could not be found in the hash, it must
                    // never have been inserted.  This is ok, we don't
                    // need to do anything more in this case.
                    //

                    return;
                }
            }
            Table[Hash].Key = 0;
        }
    }

    return;
}


VOID
MiSwapWslEntries (
    IN WSLE_NUMBER SwapEntry,
    IN WSLE_NUMBER Entry,
    IN PMMSUPPORT WsInfo,
    IN LOGICAL EntryNotInHash
    )

/*++

Routine Description:

    This routine swaps the working set list entries Entry and SwapEntry
    in the specified working set list.

Arguments:

    SwapEntry - Supplies the first entry to swap.  This entry must be
                valid, i.e. in the working set at the current time.

    Entry - Supplies the other entry to swap.  This entry may be valid
            or invalid.

    WsInfo - Supplies the working set list.

    EntryNotInHash - Supplies TRUE if the Entry cannot possibly be in the hash
                     table (ie, it is newly allocated), so the hash table
                     search can be skipped.

Return Value:

    None.

Environment:

    Kernel mode, Working set lock and PFN lock held (if system cache),
                 APCs disabled.

--*/

{
    MMWSLE WsleEntry;
    MMWSLE WsleSwap;
    PMMPTE PointerPte;
    PMMPFN Pfn1;
    PMMWSLE Wsle;
    PMMWSL WorkingSetList;
    PMMWSLE_HASH Table;
#if defined (_MI_DEBUG_WSLE)
    MMWSLE WsleContents;
#endif

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    WsleSwap = Wsle[SwapEntry];

    ASSERT (WsleSwap.u1.e1.Valid != 0);

    WsleEntry = Wsle[Entry];

    Table = WorkingSetList->HashTable;

    if (WsleEntry.u1.e1.Valid == 0) {

        //
        // Entry is not on any list. Remove it from the free list.
        //

        MiRemoveWsleFromFreeList (Entry, Wsle, WorkingSetList);

        //
        // Copy the entry to this free one.
        //

#if defined (_MI_DEBUG_WSLE)
        // Set these so the traces make more sense and no false dup hits...
        WsleContents.u1.Long = WorkingSetList->FirstFree << MM_FREE_WSLE_SHIFT;
        Wsle[Entry].u1.Long = 0x81818100;     // Clear it to avoid false dup hit
        Wsle[SwapEntry].u1.Long = 0xa1a1a100; // Clear it to avoid false dup hit

        MI_LOG_WSLE_CHANGE (WorkingSetList, SwapEntry, WsleContents);
#endif

        MI_LOG_WSLE_CHANGE (WorkingSetList, Entry, WsleSwap);

        Wsle[Entry] = WsleSwap;

        PointerPte = MiGetPteAddress (WsleSwap.u1.VirtualAddress);

        if (PointerPte->u.Hard.Valid == 0) {
#if (_MI_PAGING_LEVELS < 3)
            if (!NT_SUCCESS (MiCheckPdeForPagedPool (WsleSwap.u1.VirtualAddress))) {
#endif

                KeBugCheckEx (MEMORY_MANAGEMENT,
                              0x41289,
                              (ULONG_PTR) WsleSwap.u1.VirtualAddress,
                              (ULONG_PTR) PointerPte->u.Long,
                              (ULONG_PTR) WorkingSetList);
#if (_MI_PAGING_LEVELS < 3)
            }
#endif
        }

        ASSERT (PointerPte->u.Hard.Valid == 1);

        if (WsleSwap.u1.e1.Direct) {
            Pfn1 = MI_PFN_ELEMENT (PointerPte->u.Hard.PageFrameNumber);
            ASSERT (Pfn1->u1.WsIndex == SwapEntry);
            Pfn1->u1.WsIndex = Entry;
        }
        else {

            //
            // Update hash table.
            //

            if (Table != NULL) {
                MiRepointWsleHashIndex (WsleSwap,
                                        WorkingSetList,
                                        Entry);
            }
        }

        MI_SET_PTE_IN_WORKING_SET (PointerPte, Entry);

        //
        // Put entry on free list.
        //

        ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
                (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

        Wsle[SwapEntry].u1.Long = WorkingSetList->FirstFree << MM_FREE_WSLE_SHIFT;
        WorkingSetList->FirstFree = SwapEntry;
        ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

    }
    else {

        //
        // Both entries are valid.
        //

#if defined (_MI_DEBUG_WSLE)
        Wsle[Entry].u1.Long = 0x91919100;     // Clear it to avoid false dup hit
#endif

        MI_LOG_WSLE_CHANGE (WorkingSetList, SwapEntry, WsleEntry);
        Wsle[SwapEntry] = WsleEntry;

        PointerPte = MiGetPteAddress (WsleEntry.u1.VirtualAddress);

        if (PointerPte->u.Hard.Valid == 0) {
#if (_MI_PAGING_LEVELS < 3)
            if (!NT_SUCCESS (MiCheckPdeForPagedPool (WsleEntry.u1.VirtualAddress))) {
#endif
                KeBugCheckEx (MEMORY_MANAGEMENT,
                              0x4128A,
                              (ULONG_PTR) WsleEntry.u1.VirtualAddress,
                              (ULONG_PTR) PointerPte->u.Long,
                              (ULONG_PTR) WorkingSetList);
#if (_MI_PAGING_LEVELS < 3)
              }
#endif
        }

        ASSERT (PointerPte->u.Hard.Valid == 1);

        if (WsleEntry.u1.e1.Direct) {

            //
            // Swap the PFN WsIndex element to point to the new slot.
            //

            Pfn1 = MI_PFN_ELEMENT (PointerPte->u.Hard.PageFrameNumber);
            ASSERT (Pfn1->u1.WsIndex == Entry);
            Pfn1->u1.WsIndex = SwapEntry;
        }
        else if (Table != NULL) {

            //
            // Update hash table.
            //

            if (EntryNotInHash == TRUE) {
#if DBG
                WSLE_NUMBER Hash;
                PVOID VirtualAddress;

                VirtualAddress = MI_GENERATE_VALID_WSLE (&WsleEntry);

                for (Hash = 0; Hash < WorkingSetList->HashTableSize; Hash += 1) {
                    ASSERT (Table[Hash].Key != VirtualAddress);
                }
#endif
            }
            else {

                MiRepointWsleHashIndex (WsleEntry,
                                        WorkingSetList,
                                        SwapEntry);
            }
        }

        MI_SET_PTE_IN_WORKING_SET (PointerPte, SwapEntry);

        MI_LOG_WSLE_CHANGE (WorkingSetList, Entry, WsleSwap);
        Wsle[Entry] = WsleSwap;

        PointerPte = MiGetPteAddress (WsleSwap.u1.VirtualAddress);

        if (PointerPte->u.Hard.Valid == 0) {
#if (_MI_PAGING_LEVELS < 3)
            if (!NT_SUCCESS (MiCheckPdeForPagedPool (WsleSwap.u1.VirtualAddress))) {
#endif
                KeBugCheckEx (MEMORY_MANAGEMENT,
                              0x4128B,
                              (ULONG_PTR) WsleSwap.u1.VirtualAddress,
                              (ULONG_PTR) PointerPte->u.Long,
                              (ULONG_PTR) WorkingSetList);
#if (_MI_PAGING_LEVELS < 3)
              }
#endif
        }

        ASSERT (PointerPte->u.Hard.Valid == 1);

        if (WsleSwap.u1.e1.Direct) {

            Pfn1 = MI_PFN_ELEMENT (PointerPte->u.Hard.PageFrameNumber);
            ASSERT (Pfn1->u1.WsIndex == SwapEntry);
            Pfn1->u1.WsIndex = Entry;
        }
        else {
            if (Table != NULL) {
                MiRepointWsleHashIndex (WsleSwap,
                                        WorkingSetList,
                                        Entry);
            }
        }
        MI_SET_PTE_IN_WORKING_SET (PointerPte, Entry);
    }

    return;
}

VOID
MiRepointWsleHashIndex (
    IN MMWSLE WsleEntry,
    IN PMMWSL WorkingSetList,
    IN WSLE_NUMBER NewWsIndex
    )

/*++

Routine Description:

    This routine repoints the working set list hash entry for the supplied
    address so it points at the new working set index.

Arguments:

    WsleEntry - Supplies the virtual address to look up.

    WorkingSetList - Supplies the working set list to operate on.

    NewWsIndex - Supplies the new working set list index to use.

Return Value:

    None.

Environment:

    Kernel mode, Working set mutex held.

--*/

{
    WSLE_NUMBER Hash;
    WSLE_NUMBER StartHash;
    PVOID VirtualAddress;
    PMMWSLE_HASH Table;
    ULONG Tries;
    
    Tries = 0;
    Table = WorkingSetList->HashTable;

    VirtualAddress = MI_GENERATE_VALID_WSLE (&WsleEntry);

    Hash = MI_WSLE_HASH (WsleEntry.u1.VirtualAddress, WorkingSetList);
    StartHash = Hash;

    while (Table[Hash].Key != VirtualAddress) {

        Hash += 1;

        if (Hash >= WorkingSetList->HashTableSize) {
            ASSERT (Tries == 0);
            Hash = 0;
            Tries = 1;
        }

        if (StartHash == Hash) {

            //
            // Didn't find the hash entry, so this virtual address must
            // not have one.  That's ok, just return as nothing needs to
            // be done in this case.
            //

            return;
        }
    }

    Table[Hash].Index = NewWsIndex;

    return;
}

VOID
MiRemoveWsleFromFreeList (
    IN WSLE_NUMBER Entry,
    IN PMMWSLE Wsle,
    IN PMMWSL WorkingSetList
    )

/*++

Routine Description:

    This routine removes a working set list entry from the free list.
    It is used when the entry required is not the first element
    in the free list.

Arguments:

    Entry - Supplies the index of the entry to remove.

    Wsle - Supplies a pointer to the array of WSLEs.

    WorkingSetList - Supplies a pointer to the working set list.

Return Value:

    None.

Environment:

    Kernel mode, Working set lock and PFN lock held, APCs disabled.

--*/

{
    WSLE_NUMBER Free;
    WSLE_NUMBER ParentFree;

    Free = WorkingSetList->FirstFree;

    if (Entry == Free) {

        ASSERT (((Wsle[Entry].u1.Long >> MM_FREE_WSLE_SHIFT) <= WorkingSetList->LastInitializedWsle) ||
                ((Wsle[Entry].u1.Long >> MM_FREE_WSLE_SHIFT) == WSLE_NULL_INDEX));

        WorkingSetList->FirstFree = (WSLE_NUMBER)(Wsle[Entry].u1.Long >> MM_FREE_WSLE_SHIFT);

    }
    else {

        //
        // See if the entry is conveniently pointed to by the previous or
        // next entry to avoid walking the singly linked list when possible.
        //

        ParentFree = (WSLE_NUMBER)-1;

        if ((Entry != 0) && (Wsle[Entry - 1].u1.e1.Valid == 0)) {
            if ((Wsle[Entry - 1].u1.Long >> MM_FREE_WSLE_SHIFT) == Entry) {
                ParentFree = Entry - 1;
            }
        }
        else if ((Entry != WorkingSetList->LastInitializedWsle) && (Wsle[Entry + 1].u1.e1.Valid == 0)) {
            if ((Wsle[Entry + 1].u1.Long >> MM_FREE_WSLE_SHIFT) == Entry) {
                ParentFree = Entry + 1;
            }
        }

        if (ParentFree == (WSLE_NUMBER)-1) {
            do {
                ParentFree = Free;
                ASSERT (Wsle[Free].u1.e1.Valid == 0);
                Free = (WSLE_NUMBER)(Wsle[Free].u1.Long >> MM_FREE_WSLE_SHIFT);
            } while (Free != Entry);
        }

        Wsle[ParentFree].u1.Long = Wsle[Entry].u1.Long;
    }
    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));
    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\wslist.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

   wslist.c

Abstract:

    This module contains routines which operate on the working
    set list structure.

Author:

    Lou Perazzoli (loup) 10-Apr-1989
    Landy Wang (landyw) 02-Jun-1997

Revision History:

--*/

#include "mi.h"

#pragma alloc_text(INIT, MiInitializeSessionWsSupport)
#pragma alloc_text(PAGE, MmAssignProcessToJob)
#pragma alloc_text(PAGE, MiInitializeWorkingSetList)

extern WSLE_NUMBER MmMaximumWorkingSetSize;

ULONG MmSystemCodePage;
ULONG MmSystemCachePage;
ULONG MmPagedPoolPage;
ULONG MmSystemDriverPage;

extern LOGICAL MiReplacing;

#define MM_RETRY_COUNT 2

extern PFN_NUMBER MmTransitionSharedPages;
PFN_NUMBER MmTransitionSharedPagesPeak;

extern LOGICAL MiTrimRemovalPagesOnly;

typedef enum _WSLE_ALLOCATION_TYPE {
    WsleAllocationAny = 0,
    WsleAllocationReplace = 1,
    WsleAllocationDontTrim = 2
} WSLE_ALLOCATION_TYPE, *PWSLE_ALLOCATION_TYPE;

VOID
MiDoReplacement (
    IN PMMSUPPORT WsInfo,
    IN WSLE_ALLOCATION_TYPE Flags
    );

VOID
MiReplaceWorkingSetEntry (
    IN PMMSUPPORT WsInfo,
    IN WSLE_ALLOCATION_TYPE Flags
    );

VOID
MiUpdateWsle (
    IN OUT PWSLE_NUMBER DesiredIndex,
    IN PVOID VirtualAddress,
    IN PMMSUPPORT WsInfo,
    IN PMMPFN Pfn
    );

VOID
MiCheckWsleHash (
    IN PMMWSL WorkingSetList
    );

VOID
MiEliminateWorkingSetEntry (
    IN WSLE_NUMBER WorkingSetIndex,
    IN PMMPTE PointerPte,
    IN PMMPFN Pfn,
    IN PMMWSLE Wsle
    );

ULONG
MiAddWorkingSetPage (
    IN PMMSUPPORT WsInfo
    );

VOID
MiRemoveWorkingSetPages (
    IN PMMSUPPORT WsInfo
    );

VOID
MiCheckNullIndex (
    IN PMMWSL WorkingSetList
    );

VOID
MiDumpWsleInCacheBlock (
    IN PMMPTE CachePte
    );

ULONG
MiDumpPteInCacheBlock (
    IN PMMPTE PointerPte
    );

#if defined (_MI_DEBUG_WSLE)
VOID
MiCheckWsleList (
    IN PMMSUPPORT WsInfo
    );
#endif

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGELK, MmAdjustWorkingSetSize)
#pragma alloc_text(PAGELK, MmAdjustWorkingSetSizeEx)
#pragma alloc_text(PAGELK, MiSessionInitializeWorkingSetList)
#pragma alloc_text(PAGE, MmQueryWorkingSetInformation)
#endif

ULONG MiWsleFailures;


WSLE_NUMBER
MiAllocateWsle (
    IN PMMSUPPORT WsInfo,
    IN PMMPTE PointerPte,
    IN PMMPFN Pfn1,
    IN ULONG_PTR WsleMask
    )

/*++

Routine Description:

    This function examines the working set list for the specified
    working set and locates an entry to contain a new page.
    
    If the memory is not tight, the new page is added without removing a page.

    If memory is tight (or this working set is at its limit), a page
    is removed from the working set and the new page added in its place.

Arguments:

    WsInfo - Supplies the working set list.

    PointerPte - Supplies the PTE of the virtual address to insert.

    Pfn1 - Supplies the PFN entry of the virtual address being inserted.  If
           this pointer has the low bit set, no trimming can be done at this
           time (because it is a WSLE hash table page insertion).  Strip the
           low bit for these cases.

    WsleMask - Supplies the mask to logical OR into the new working set entry.

Return Value:

    Returns the working set index which was used to insert the specified entry,
    or 0 if no index was available.

Environment:

    Kernel mode, APCs disabled, working set lock.  PFN lock NOT held.

--*/

{
    PVOID VirtualAddress;
    PMMWSLE Wsle;
    PMMWSL WorkingSetList;
    WSLE_NUMBER WorkingSetIndex;

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    //
    // Update page fault counts.
    //

    WsInfo->PageFaultCount += 1;
    InterlockedIncrement ((PLONG) &MmInfoCounters.PageFaultCount);

    //
    // Determine if a page should be removed from the working set to make
    // room for the new page.  If so, remove it.
    //

    if ((ULONG_PTR)Pfn1 & 0x1) {
        MiDoReplacement (WsInfo, WsleAllocationDontTrim);
        if (WorkingSetList->FirstFree == WSLE_NULL_INDEX) {
            return 0;
        }
        Pfn1 = (PMMPFN)((ULONG_PTR)Pfn1 & ~0x1);
    }
    else {
        MiDoReplacement (WsInfo, WsleAllocationAny);
    
        if (WorkingSetList->FirstFree == WSLE_NULL_INDEX) {
    
            //
            // Add more pages to the working set list structure.
            //
    
            if (MiAddWorkingSetPage (WsInfo) == FALSE) {
    
                //
                // No page was added to the working set list structure.
                // We must replace a page within this working set.
                //
    
                MiDoReplacement (WsInfo, WsleAllocationReplace);
    
                if (WorkingSetList->FirstFree == WSLE_NULL_INDEX) {
                    MiWsleFailures += 1;
                    return 0;
                }
            }
        }
    }

    //
    // Get the working set entry from the free list.
    //

    ASSERT (WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle);

    ASSERT (WorkingSetList->FirstFree >= WorkingSetList->FirstDynamic);

    WorkingSetIndex = WorkingSetList->FirstFree;
    WorkingSetList->FirstFree = (WSLE_NUMBER)(Wsle[WorkingSetIndex].u1.Long >> MM_FREE_WSLE_SHIFT);

    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

    ASSERT (WsInfo->WorkingSetSize <= (WorkingSetList->LastInitializedWsle + 1));
    WsInfo->WorkingSetSize += 1;
#if defined (_MI_DEBUG_WSLE)
    WorkingSetList->Quota += 1;
    ASSERT (WsInfo->WorkingSetSize == WorkingSetList->Quota);
#endif

    if (WsInfo->WorkingSetSize > WsInfo->MinimumWorkingSetSize) {
        InterlockedExchangeAddSizeT (&MmPagesAboveWsMinimum, 1);
    }

    if (WsInfo->WorkingSetSize > WsInfo->PeakWorkingSetSize) {
        WsInfo->PeakWorkingSetSize = WsInfo->WorkingSetSize;
    }

    if (WsInfo == &MmSystemCacheWs) {
        if (WsInfo->WorkingSetSize + MmTransitionSharedPages > MmTransitionSharedPagesPeak) {
            MmTransitionSharedPagesPeak = WsInfo->WorkingSetSize + MmTransitionSharedPages;
        }
    }

    if (WorkingSetIndex > WorkingSetList->LastEntry) {
        WorkingSetList->LastEntry = WorkingSetIndex;
    }

    //
    // The returned entry is guaranteed to be available at this point.
    //

    ASSERT (Wsle[WorkingSetIndex].u1.e1.Valid == 0);

    VirtualAddress = MiGetVirtualAddressMappedByPte (PointerPte);

    MiUpdateWsle (&WorkingSetIndex, VirtualAddress, WsInfo, Pfn1);

    if (WsleMask != 0) {
        Wsle[WorkingSetIndex].u1.Long |= WsleMask;
    }

#if DBG
    if (MI_IS_SYSTEM_CACHE_ADDRESS (VirtualAddress)) {
        ASSERT (MmSystemCacheWsle[WorkingSetIndex].u1.e1.SameProtectAsProto);
    }
#endif

    MI_SET_PTE_IN_WORKING_SET (PointerPte, WorkingSetIndex);

    return WorkingSetIndex;
}

//
// Nonpaged helper routine.
//

VOID
MiSetWorkingSetForce (
    IN PMMSUPPORT WsInfo,
    IN LOGICAL ForceTrim
    )
{
    KIRQL OldIrql;

    LOCK_EXPANSION (OldIrql);

    WsInfo->Flags.ForceTrim = (UCHAR) ForceTrim;

    UNLOCK_EXPANSION (OldIrql);

    return;
}


VOID
MiDoReplacement (
    IN PMMSUPPORT WsInfo,
    IN WSLE_ALLOCATION_TYPE Flags
    )

/*++

Routine Description:

    This function determines whether the working set should be
    grown or if a page should be replaced.  Replacement is
    done here if deemed necessary.

Arguments:

    WsInfo - Supplies the working set information structure to replace within.

    Flags - Supplies 0 if replacement is not required.
            Supplies 1 if replacement is desired.
            Supplies 2 if working set trimming must not be done here - this
            is only used for inserting new WSLE hash table pages as a trim
            would not know how to interpret them.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, working set lock.  PFN lock NOT held.

--*/

{
    KIRQL OldIrql;
    WSLE_NUMBER PagesTrimmed;
    ULONG MemoryMaker;
    PMMWSL WorkingSetList;
    WSLE_NUMBER CurrentSize;
    LARGE_INTEGER CurrentTime;
    PFN_NUMBER Dummy1;
    PFN_NUMBER Dummy2;
    WSLE_NUMBER Trim;
    ULONG TrimAge;
    ULONG GrowthSinceLastEstimate;
    WSLE_ALLOCATION_TYPE TrimFlags;

    TrimFlags = Flags;
    Flags &= ~WsleAllocationDontTrim;

    WorkingSetList = WsInfo->VmWorkingSetList;
    GrowthSinceLastEstimate = 1;

    PERFINFO_BIGFOOT_REPLACEMENT_CLAIMS(WorkingSetList, WsInfo);

    PagesTrimmed = 0;

    //
    // Determine whether the working set can be grown or whether a
    // page needs to be replaced.
    //

recheck:

    if (WsInfo->WorkingSetSize >= WsInfo->MinimumWorkingSetSize) {

        if ((WsInfo->Flags.ForceTrim == 1) && (TrimFlags != WsleAllocationDontTrim)) {

            //
            // The working set manager cannot attach to this process
            // to trim it.  Force a trim now and update the working
            // set manager's fields properly to indicate a trim occurred.
            //

            Trim = WsInfo->Claim >>
                            ((WsInfo->Flags.MemoryPriority == MEMORY_PRIORITY_FOREGROUND)
                                ? MI_FOREGROUND_CLAIM_AVAILABLE_SHIFT
                                : MI_BACKGROUND_CLAIM_AVAILABLE_SHIFT);

            if (MmAvailablePages < MM_HIGH_LIMIT + 64) {
                if (WsInfo->WorkingSetSize > WsInfo->MinimumWorkingSetSize) {
                    Trim = (WsInfo->WorkingSetSize - WsInfo->MinimumWorkingSetSize) >> 2;
                }
                TrimAge = MI_PASS4_TRIM_AGE;
            }
            else {
                TrimAge = MI_PASS0_TRIM_AGE;
            }

            PagesTrimmed += MiTrimWorkingSet (Trim, WsInfo, TrimAge);

            MiAgeAndEstimateAvailableInWorkingSet (WsInfo,
                                                   TRUE,
                                                   NULL,
                                                   &Dummy1,
                                                   &Dummy2);

            KeQuerySystemTime (&CurrentTime);

            LOCK_EXPANSION (OldIrql);
            WsInfo->LastTrimTime = CurrentTime;
            WsInfo->Flags.ForceTrim = 0;
            UNLOCK_EXPANSION (OldIrql);

            goto recheck;
        }

        CurrentSize = WsInfo->WorkingSetSize;
        ASSERT (CurrentSize <= (WorkingSetList->LastInitializedWsle + 1));

        if ((WsInfo->Flags.MaximumWorkingSetHard) &&
            (CurrentSize >= WsInfo->MaximumWorkingSetSize)) {

            //
            // This is an enforced working set maximum triggering a replace.
            //

            MiReplaceWorkingSetEntry (WsInfo, Flags);

            return;
        }

        //
        // Don't grow if :
        //      - we're over the max
        //      - there aren't any pages to take
        //      - or if we are growing too much in this time interval
        //        and there isn't much memory available
        //

        MemoryMaker = PsGetCurrentThread()->MemoryMaker;

        if (((CurrentSize > MM_MAXIMUM_WORKING_SET) && (MemoryMaker == 0)) ||
            (MmAvailablePages == 0) ||
            (Flags == WsleAllocationReplace) ||
            ((MmAvailablePages < MM_VERY_HIGH_LIMIT) &&
                 (MI_WS_GROWING_TOO_FAST(WsInfo)) &&
                 (MemoryMaker == 0))) {

            //
            // Can't grow this one.
            //

            MiReplacing = TRUE;

            if ((Flags == WsleAllocationReplace) || (MemoryMaker == 0)) {

                MiReplaceWorkingSetEntry (WsInfo, Flags);

                //
                // Set the must trim flag because this could be a realtime
                // thread where the fault straddles a page boundary.  If
                // it's realtime, the balance set manager will never get to
                // run and the thread will endlessly replace one WSL entry
                // with the other half of the straddler.  Setting this flag
                // guarantees the next fault will guarantee a forced trim
                // and allow a reasonable available page threshold trim
                // calculation since GrowthSinceLastEstimate will be
                // cleared.
                //

                MiSetWorkingSetForce (WsInfo, TRUE);
                GrowthSinceLastEstimate = 0;
            }
            else {

                //
                // If we've only trimmed a single page, then don't force
                // replacement on the next fault.  This prevents a single
                // instruction causing alternating faults on the referenced
                // code & data in a (realtime) thread from looping endlessly.
                //

                if (PagesTrimmed > 1) {
                    MiSetWorkingSetForce (WsInfo, TRUE);
                }
            }
        }
    }

    //
    // If there isn't enough memory to allow growth, find a good page
    // to remove and remove it.
    //

    WsInfo->GrowthSinceLastEstimate += GrowthSinceLastEstimate;

    return;
}


NTSTATUS
MmEnforceWorkingSetLimit (
    IN PEPROCESS Process,
    IN ULONG Flags
    )

/*++

Routine Description:

    This function enables/disables hard enforcement of the working set minimums
    and maximums for the specified WsInfo.

Arguments:

    Process - Supplies the target process.

    Flags - Supplies new flags (MM_WORKING_SET_MAX_HARD_ENABLE, etc).

Return Value:

    NTSTATUS.

Environment:

    Kernel mode, APCs disabled.  The working set mutex must NOT be held.
    The caller guarantees that the target WsInfo cannot go away.

--*/

{
    KIRQL OldIrql;
    PMMSUPPORT WsInfo;
    MMSUPPORT_FLAGS PreviousBits;
    MMSUPPORT_FLAGS TempBits = {0};

    WsInfo = &Process->Vm;

    if (Flags & MM_WORKING_SET_MIN_HARD_ENABLE) {
        Flags &= ~MM_WORKING_SET_MIN_HARD_DISABLE;
        TempBits.MinimumWorkingSetHard = 1;
    }

    if (Flags & MM_WORKING_SET_MAX_HARD_ENABLE) {
        Flags &= ~MM_WORKING_SET_MAX_HARD_DISABLE;
        TempBits.MaximumWorkingSetHard = 1;
    }

    LOCK_WS (Process);

    LOCK_EXPANSION (OldIrql);

    if (Flags & MM_WORKING_SET_MIN_HARD_DISABLE) {
        WsInfo->Flags.MinimumWorkingSetHard = 0;
    }

    if (Flags & MM_WORKING_SET_MAX_HARD_DISABLE) {
        WsInfo->Flags.MaximumWorkingSetHard = 0;
    }

    PreviousBits = WsInfo->Flags;

    //
    // If the caller's request will result in hard enforcement of both limits
    // is enabled, then check whether the current minimum and maximum working
    // set values will guarantee forward progress even in pathological
    // scenarios.
    //

    if (PreviousBits.MinimumWorkingSetHard == 1) {
        TempBits.MinimumWorkingSetHard = 1;
    }

    if (PreviousBits.MaximumWorkingSetHard == 1) {
        TempBits.MaximumWorkingSetHard = 1;
    }

    if ((TempBits.MinimumWorkingSetHard == 1) &&
        (TempBits.MaximumWorkingSetHard == 1)) {

        //
        // Net result is hard enforcement on both limits so check that the
        // two limits cannot result in lack of forward progress.
        //

        if (WsInfo->MinimumWorkingSetSize + MM_FLUID_WORKING_SET >= WsInfo->MaximumWorkingSetSize) {
            UNLOCK_EXPANSION (OldIrql);
            UNLOCK_WS (Process);
            return STATUS_BAD_WORKING_SET_LIMIT;
        }
    }

    if (Flags & MM_WORKING_SET_MIN_HARD_ENABLE) {
        WsInfo->Flags.MinimumWorkingSetHard = 1;
    }

    if (Flags & MM_WORKING_SET_MAX_HARD_ENABLE) {
        WsInfo->Flags.MaximumWorkingSetHard = 1;
    }

    UNLOCK_EXPANSION (OldIrql);

    UNLOCK_WS (Process);

    return STATUS_SUCCESS;
}


VOID
MiReplaceWorkingSetEntry (
    IN PMMSUPPORT WsInfo,
    IN WSLE_ALLOCATION_TYPE Flags
    )

/*++

Routine Description:

    This function tries to find a good working set entry to replace.

Arguments:

    WsInfo - Supplies the working set info pointer.

    Flags - Supplies 0 if replacement is not required.

            Supplies 1 if replacement is desired.  Note replacement cannot
                  be guaranteed (the entire existing working set may
                  be locked down) - if no entry can be released the caller
                  can detect this because MMWSL->FirstFree will not contain
                  any free entries - and so the caller should release the
                  working set mutex and retry the operation.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, working set lock.  PFN lock NOT held.

--*/

{
    WSLE_NUMBER WorkingSetIndex;
    WSLE_NUMBER FirstDynamic;
    WSLE_NUMBER LastEntry;
    PMMWSL WorkingSetList;
    PMMWSLE Wsle;
    ULONG NumberOfCandidates;
    PMMPTE PointerPte;
    WSLE_NUMBER TheNextSlot;
    WSLE_NUMBER OldestWorkingSetIndex;
    LONG OldestAge;

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    //
    // Toss a page out of the working set.
    //

    LastEntry = WorkingSetList->LastEntry;
    FirstDynamic = WorkingSetList->FirstDynamic;
    WorkingSetIndex = WorkingSetList->NextSlot;
    if (WorkingSetIndex > LastEntry || WorkingSetIndex < FirstDynamic) {
        WorkingSetIndex = FirstDynamic;
    }
    TheNextSlot = WorkingSetIndex;
    NumberOfCandidates = 0;

    OldestWorkingSetIndex = WSLE_NULL_INDEX;
    OldestAge = -1;

    while (TRUE) {

        //
        // Keep track of the oldest page along the way in case we
        // don't find one that's >= MI_IMMEDIATE_REPLACEMENT_AGE
        // before we've looked at MM_WORKING_SET_LIST_SEARCH
        // entries.
        //

        while (Wsle[WorkingSetIndex].u1.e1.Valid == 0) {
            WorkingSetIndex += 1;
            if (WorkingSetIndex > LastEntry) {
                WorkingSetIndex = FirstDynamic;
            }

            if (WorkingSetIndex == TheNextSlot) {
                    
                if (Flags == WsleAllocationAny) {
    
                    //
                    // Entire working set list has been searched, increase
                    // the working set size.
                    //
    
                    ASSERT ((WsInfo->Flags.MaximumWorkingSetHard == 0) ||
                      (WsInfo->WorkingSetSize < WsInfo->MaximumWorkingSetSize));

                    WsInfo->GrowthSinceLastEstimate += 1;
                }
                return;
            }
        }

        if (OldestWorkingSetIndex == WSLE_NULL_INDEX) {

            //
            // First time through, so initialize the OldestWorkingSetIndex
            // to the first valid WSLE.  As we go along, this will be repointed
            // at the oldest candidate we come across.
            //

            OldestWorkingSetIndex = WorkingSetIndex;
            OldestAge = -1;
        }

        PointerPte = MiGetPteAddress(Wsle[WorkingSetIndex].u1.VirtualAddress);

        if ((Flags == WsleAllocationReplace) ||
            ((MI_GET_ACCESSED_IN_PTE(PointerPte) == 0) &&
            (OldestAge < (LONG) MI_GET_WSLE_AGE(PointerPte, &Wsle[WorkingSetIndex])))) {

            //
            // This one is not used and it's older.
            //

            OldestAge = MI_GET_WSLE_AGE(PointerPte, &Wsle[WorkingSetIndex]);
            OldestWorkingSetIndex = WorkingSetIndex;
        }

        //
        // If it's old enough or we've searched too much then use this entry.
        //

        if ((Flags == WsleAllocationReplace) ||
            OldestAge >= MI_IMMEDIATE_REPLACEMENT_AGE ||
            NumberOfCandidates > MM_WORKING_SET_LIST_SEARCH) {

            PERFINFO_PAGE_INFO_REPLACEMENT_DECL();

            if (OldestWorkingSetIndex != WorkingSetIndex) {
                WorkingSetIndex = OldestWorkingSetIndex;
                PointerPte = MiGetPteAddress(Wsle[WorkingSetIndex].u1.VirtualAddress);
            }

            PERFINFO_GET_PAGE_INFO_REPLACEMENT(PointerPte);

            if (MiFreeWsle (WorkingSetIndex, WsInfo, PointerPte)) {

                PERFINFO_LOG_WS_REPLACEMENT(WsInfo);

                //
                // This entry was removed.
                //

                WorkingSetList->NextSlot = WorkingSetIndex + 1;
                break;
            }

            //
            // We failed to remove a page, try the next one.
            //
            // Clear the OldestWorkingSetIndex so that
            // it gets set to the next valid entry above like the
            // first time around.
            //

            WorkingSetIndex = OldestWorkingSetIndex + 1;

            OldestWorkingSetIndex = WSLE_NULL_INDEX;
        }
        else {
            WorkingSetIndex += 1;
        }

        if (WorkingSetIndex > LastEntry) {
            WorkingSetIndex = FirstDynamic;
        }

        NumberOfCandidates += 1;


        if (WorkingSetIndex == TheNextSlot) {
                
            if (Flags == WsleAllocationAny) {

                //
                // Entire working set list has been searched, increase
                // the working set size.
                //

                ASSERT ((WsInfo->Flags.MaximumWorkingSetHard == 0) ||
                    (WsInfo->WorkingSetSize < WsInfo->MaximumWorkingSetSize));

                WsInfo->GrowthSinceLastEstimate += 1;
            }
            break;
        }
    }
    return;
}

ULONG
MiRemovePageFromWorkingSet (
    IN PMMPTE PointerPte,
    IN PMMPFN Pfn1,
    IN PMMSUPPORT WsInfo
    )

/*++

Routine Description:

    This function removes the page mapped by the specified PTE from
    the process's working set list.

Arguments:

    PointerPte - Supplies a pointer to the PTE mapping the page to
                 be removed from the working set list.

    Pfn1 - Supplies a pointer to the PFN database element referred to
           by the PointerPte.

Return Value:

    Returns TRUE if the specified page was locked in the working set,
    FALSE otherwise.

Environment:

    Kernel mode, APCs disabled, working set mutex held.

--*/

{
    WSLE_NUMBER WorkingSetIndex;
    PVOID VirtualAddress;
    WSLE_NUMBER Entry;
    MMWSLENTRY Locked;
    PMMWSL WorkingSetList;
    PMMWSLE Wsle;
    KIRQL OldIrql;
#if DBG
    PVOID SwapVa;
#endif

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    VirtualAddress = MiGetVirtualAddressMappedByPte (PointerPte);

    WorkingSetIndex = MiLocateWsle (VirtualAddress,
                                    WorkingSetList,
                                    Pfn1->u1.WsIndex);

    ASSERT (WorkingSetIndex != WSLE_NULL_INDEX);

    LOCK_PFN (OldIrql);

    MiEliminateWorkingSetEntry (WorkingSetIndex,
                                PointerPte,
                                Pfn1,
                                Wsle);

    UNLOCK_PFN (OldIrql);

    //
    // Check to see if this entry is locked in the working set
    // or locked in memory.
    //

    Locked = Wsle[WorkingSetIndex].u1.e1;

    MiRemoveWsle (WorkingSetIndex, WorkingSetList);

    //
    // Add this entry to the list of free working set entries
    // and adjust the working set count.
    //

    MiReleaseWsle ((WSLE_NUMBER)WorkingSetIndex, WsInfo);

    if ((Locked.LockedInWs == 1) || (Locked.LockedInMemory == 1)) {

        //
        // This entry is locked.
        //

        WorkingSetList->FirstDynamic -= 1;

        if (WorkingSetIndex != WorkingSetList->FirstDynamic) {

            Entry = WorkingSetList->FirstDynamic;

#if DBG
            SwapVa = Wsle[WorkingSetList->FirstDynamic].u1.VirtualAddress;
            SwapVa = PAGE_ALIGN (SwapVa);

            PointerPte = MiGetPteAddress (SwapVa);
            Pfn1 = MI_PFN_ELEMENT (PointerPte->u.Hard.PageFrameNumber);

            ASSERT (Entry == MiLocateWsle (SwapVa, WorkingSetList, Pfn1->u1.WsIndex));
#endif

            MiSwapWslEntries (Entry, WorkingSetIndex, WsInfo, FALSE);

        }
        return TRUE;
    }
    else {
        ASSERT (WorkingSetIndex >= WorkingSetList->FirstDynamic);
    }
    return FALSE;
}


VOID
MiReleaseWsle (
    IN WSLE_NUMBER WorkingSetIndex,
    IN PMMSUPPORT WsInfo
    )

/*++

Routine Description:

    This function releases a previously reserved working set entry to
    be reused.  A release occurs when a page fault is retried due to
    changes in PTEs and working sets during an I/O operation.

Arguments:

    WorkingSetIndex - Supplies the index of the working set entry to
                      release.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, working set lock held and PFN lock held.

--*/

{
    PMMWSL WorkingSetList;
    PMMWSLE Wsle;
    MMWSLE WsleContents;

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    MM_WS_LOCK_ASSERT (WsInfo);

    ASSERT (WorkingSetIndex <= WorkingSetList->LastInitializedWsle);

    //
    // Put the entry on the free list and decrement the current size.
    //

    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

    WsleContents.u1.Long = WorkingSetList->FirstFree << MM_FREE_WSLE_SHIFT;

    MI_LOG_WSLE_CHANGE (WorkingSetList, WorkingSetIndex, WsleContents);

    Wsle[WorkingSetIndex] = WsleContents;
    WorkingSetList->FirstFree = WorkingSetIndex;
    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));
    if (WsInfo->WorkingSetSize > WsInfo->MinimumWorkingSetSize) {
        InterlockedExchangeAddSizeT (&MmPagesAboveWsMinimum, -1);
    }
    WsInfo->WorkingSetSize -= 1;
#if defined (_MI_DEBUG_WSLE)
    WorkingSetList->Quota -= 1;
    ASSERT (WsInfo->WorkingSetSize == WorkingSetList->Quota);

    MiCheckWsleList (WsInfo);
#endif

    return;

}

VOID
MiUpdateWsle (
    IN OUT PWSLE_NUMBER DesiredIndex,
    IN PVOID VirtualAddress,
    IN PMMSUPPORT WsInfo,
    IN PMMPFN Pfn
    )

/*++

Routine Description:

    This routine updates a reserved working set entry to place it into
    the valid state.

Arguments:

    DesiredIndex - Supplies the index of the working set entry to update.

    VirtualAddress - Supplies the virtual address which the working set
                     entry maps.

    WsInfo - Supplies the relevant working set information to update.

    Pfn - Supplies a pointer to the PFN element for the page.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, working set lock held.

--*/

{
    ULONG_PTR OldValue;
    PMMWSLE Wsle;
    MMWSLE WsleContents;
    PMMWSL WorkingSetList;
    WSLE_NUMBER Index;
    WSLE_NUMBER WorkingSetIndex;

    MM_WS_LOCK_ASSERT (WsInfo);

    WorkingSetList = WsInfo->VmWorkingSetList;

    WorkingSetIndex = *DesiredIndex;

    ASSERT (WorkingSetIndex >= WorkingSetList->FirstDynamic);

    Wsle = WorkingSetList->Wsle;

    if (WorkingSetList == MmSystemCacheWorkingSetList) {

        //
        // This assert doesn't hold for NT64 as we can be adding page
        // directories and page tables for the system cache WSLE hash tables.
        //

        ASSERT32 ((VirtualAddress < (PVOID)PTE_BASE) ||
                  (VirtualAddress >= (PVOID)MM_SYSTEM_SPACE_START));

        //
        // Count system space inserts and removals.
        //

#if defined(_X86_)
        if (MI_IS_SYSTEM_CACHE_ADDRESS(VirtualAddress)) {
            MmSystemCachePage += 1;
        }
        else
#endif
        if (VirtualAddress < MmSystemCacheStart) {
            MmSystemCodePage += 1;
        }
        else if (VirtualAddress < MM_PAGED_POOL_START) {
            MmSystemCachePage += 1;
        }
        else if (VirtualAddress < MmNonPagedSystemStart) {
            MmPagedPoolPage += 1;
        }
        else {
            MmSystemDriverPage += 1;
        }
    }
    else {
        ASSERT ((VirtualAddress < (PVOID)MM_SYSTEM_SPACE_START) ||
                (MI_IS_SESSION_ADDRESS (VirtualAddress)));
    }

    //
    // Make the WSLE valid, referring to the corresponding virtual
    // page number.
    //

#if DBG
    if (Pfn->u1.WsIndex <= WorkingSetList->LastInitializedWsle) {
        ASSERT ((PAGE_ALIGN(VirtualAddress) !=
                PAGE_ALIGN(Wsle[Pfn->u1.WsIndex].u1.VirtualAddress)) ||
                (Wsle[Pfn->u1.WsIndex].u1.e1.Valid == 0));
    }
#endif

    WsleContents.u1.VirtualAddress = PAGE_ALIGN (VirtualAddress);
    WsleContents.u1.e1.Valid = 1;

    //
    // The working set mutex is a process wide mutex and two threads in
    // different processes could be adding the same physical page to
    // their working sets.  Each one could see the WsIndex field in the
    // PFN as 0 and therefore want to set the direct bit.
    //
    // To solve this, the WsIndex field is updated with an interlocked
    // operation.  Note for private pages, there can be no race so a
    // simple update is enough.
    //

    if (Pfn->u1.Event == NULL) {

        //
        // Directly index into the WSL for this entry via the PFN database
        // element.
        //
        // The entire working set index union must be zeroed on NT64.  ie:
        // The WSLE_NUMBER is currently 32 bits and the PKEVENT is 64 - we
        // must zero the top 32 bits as well.  So instead of setting the
        // WsIndex field, set the overlaid Event field with appropriate casts.
        //

        if (Pfn->u3.e1.PrototypePte == 0) {

            //
            // This is a private page so this thread is the only one that
            // can be updating the PFN, so no need to use an interlocked update.
            // Note this is true even if the process is being forked because in
            // that case, the working set mutex is held throughout the fork so
            // this thread would have blocked earlier on that mutex first.
            //

            Pfn->u1.Event = (PKEVENT) (ULONG_PTR) WorkingSetIndex;
            ASSERT (Pfn->u1.Event == (PKEVENT) (ULONG_PTR) WorkingSetIndex);
            OldValue = 0;
        }
        else {

            //
            // This is a sharable page so a thread in another process could
            // be trying to update the PFN at the same time.  Use an interlocked
            // update so only one thread gets to set the value.
            //

#if defined (_WIN64)
            OldValue = InterlockedCompareExchange64 ((PLONGLONG)&Pfn->u1.Event,
                                                     (LONGLONG) (ULONG_PTR) WorkingSetIndex,
                                                     0);
#else
            OldValue = InterlockedCompareExchange ((PLONG)&Pfn->u1.Event,
                                                   WorkingSetIndex,
                                                   0);
#endif
        }

        if (OldValue == 0) {

            WsleContents.u1.e1.Direct = 1;

            MI_LOG_WSLE_CHANGE (WorkingSetList, WorkingSetIndex, WsleContents);

            Wsle[WorkingSetIndex] = WsleContents;

            return;
        }
    }

    MI_LOG_WSLE_CHANGE (WorkingSetList, WorkingSetIndex, WsleContents);

    Wsle[WorkingSetIndex] = WsleContents;

    //
    // Try to insert at WsIndex.
    //

    Index = Pfn->u1.WsIndex;

    if ((Index < WorkingSetList->LastInitializedWsle) &&
        (Index > WorkingSetList->FirstDynamic) &&
        (Index != WorkingSetIndex)) {

        if (Wsle[Index].u1.e1.Valid) {

            if (Wsle[Index].u1.e1.Direct) {

                //
                // Only move direct indexed entries.
                //

                MiSwapWslEntries (Index, WorkingSetIndex, WsInfo, TRUE);
                WorkingSetIndex = Index;
            }
        }
        else {

            //
            // On free list, try to remove quickly without walking
            // all the free pages.
            //

            WSLE_NUMBER FreeIndex;
            MMWSLE Temp;

            FreeIndex = 0;

            ASSERT (WorkingSetList->FirstFree >= WorkingSetList->FirstDynamic);
            ASSERT (WorkingSetIndex >= WorkingSetList->FirstDynamic);

            if (WorkingSetList->FirstFree == Index) {
                WorkingSetList->FirstFree = WorkingSetIndex;
                Temp = Wsle[WorkingSetIndex];
                MI_LOG_WSLE_CHANGE (WorkingSetList, WorkingSetIndex, Wsle[Index]);
                Wsle[WorkingSetIndex] = Wsle[Index];
                MI_LOG_WSLE_CHANGE (WorkingSetList, Index, Temp);
                Wsle[Index] = Temp;
                WorkingSetIndex = Index;
                ASSERT (((Wsle[WorkingSetList->FirstFree].u1.Long >> MM_FREE_WSLE_SHIFT)
                                 <= WorkingSetList->LastInitializedWsle) ||
                        ((Wsle[WorkingSetList->FirstFree].u1.Long >> MM_FREE_WSLE_SHIFT)
                                == WSLE_NULL_INDEX));
            }
            else if (Wsle[Index - 1].u1.e1.Valid == 0) {
                if ((Wsle[Index - 1].u1.Long >> MM_FREE_WSLE_SHIFT) == Index) {
                    FreeIndex = Index - 1;
                }
            }
            else if (Wsle[Index + 1].u1.e1.Valid == 0) {
                if ((Wsle[Index + 1].u1.Long >> MM_FREE_WSLE_SHIFT) == Index) {
                    FreeIndex = Index + 1;
                }
            }
            if (FreeIndex != 0) {

                //
                // Link the WSLE into the free list.
                //

                Temp = Wsle[WorkingSetIndex];
                Wsle[FreeIndex].u1.Long = WorkingSetIndex << MM_FREE_WSLE_SHIFT;

                MI_LOG_WSLE_CHANGE (WorkingSetList, WorkingSetIndex, Wsle[Index]);
                Wsle[WorkingSetIndex] = Wsle[Index];
                MI_LOG_WSLE_CHANGE (WorkingSetList, Index, Temp);
                Wsle[Index] = Temp;
                WorkingSetIndex = Index;

                ASSERT (((Wsle[FreeIndex].u1.Long >> MM_FREE_WSLE_SHIFT)
                                 <= WorkingSetList->LastInitializedWsle) ||
                        ((Wsle[FreeIndex].u1.Long >> MM_FREE_WSLE_SHIFT)
                                == WSLE_NULL_INDEX));
            }

        }
        *DesiredIndex = WorkingSetIndex;

        if (WorkingSetIndex > WorkingSetList->LastEntry) {
            WorkingSetList->LastEntry = WorkingSetIndex;
        }
    }

    ASSERT (Wsle[WorkingSetIndex].u1.e1.Valid == 1);
    ASSERT (Wsle[WorkingSetIndex].u1.e1.Direct != 1);

    WorkingSetList->NonDirectCount += 1;

#if defined (_MI_DEBUG_WSLE)
    MiCheckWsleList (WsInfo);
#endif

    if (WorkingSetList->HashTable != NULL) {

        //
        // Insert the valid WSLE into the working set hash list.
        //

        MiInsertWsleHash (WorkingSetIndex, WsInfo);
    }

    return;
}


ULONG
MiFreeWsle (
    IN WSLE_NUMBER WorkingSetIndex,
    IN PMMSUPPORT WsInfo,
    IN PMMPTE PointerPte
    )

/*++

Routine Description:

    This routine frees the specified WSLE and decrements the share
    count for the corresponding page, putting the PTE into a transition
    state if the share count goes to 0.

Arguments:

    WorkingSetIndex - Supplies the index of the working set entry to free.

    WsInfo - Supplies a pointer to the working set structure.

    PointerPte - Supplies a pointer to the PTE for the working set entry.

Return Value:

    Returns TRUE if the WSLE was removed, FALSE if it was not removed.
        Pages with valid PTEs are not removed (i.e. page table pages
        that contain valid or transition PTEs).

Environment:

    Kernel mode, APCs disabled, working set lock.  PFN lock NOT held.

--*/

{
    PMMPFN Pfn1;
    PMMWSL WorkingSetList;
    PMMWSLE Wsle;
    KIRQL OldIrql;

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    MM_WS_LOCK_ASSERT (WsInfo);

    ASSERT (Wsle[WorkingSetIndex].u1.e1.Valid == 1);

    //
    // Check to see if the located entry is eligible for removal.
    //

    ASSERT (PointerPte->u.Hard.Valid == 1);

    ASSERT (WorkingSetIndex >= WorkingSetList->FirstDynamic);

    //
    // Check to see if this is a page table with valid PTEs.
    //
    // Note, don't clear the access bit for page table pages
    // with valid PTEs as this could cause an access trap fault which
    // would not be handled (it is only handled for PTEs not PDEs).
    //

    Pfn1 = MI_PFN_ELEMENT (PointerPte->u.Hard.PageFrameNumber);

    //
    // Perform a preliminary check without the PFN lock so that lock
    // contention is avoided for cases that cannot possibly succeed.
    //

    if (WsInfo == &MmSystemCacheWs) {
        if (Pfn1->u3.e2.ReferenceCount > 1) {
            return FALSE;
        }
    }
    else {
        if ((Pfn1->u2.ShareCount > 1) && (Pfn1->u3.e1.PrototypePte == 0)) {
            return FALSE;
        }
    }

    LOCK_PFN (OldIrql);

    //
    // If the PTE is a page table page with non-zero share count or
    // within the system cache with its reference count greater
    // than 1, don't remove it.
    //

    if (WsInfo == &MmSystemCacheWs) {
        if (Pfn1->u3.e2.ReferenceCount > 1) {
            UNLOCK_PFN (OldIrql);
            return FALSE;
        }
    }
    else {
        if ((Pfn1->u2.ShareCount > 1) && (Pfn1->u3.e1.PrototypePte == 0)) {

#if DBG
            if (WsInfo->Flags.SessionSpace == 1) {
                ASSERT (MI_IS_SESSION_ADDRESS (Wsle[WorkingSetIndex].u1.VirtualAddress));
            }
            else {
                ASSERT32 ((Wsle[WorkingSetIndex].u1.VirtualAddress >= (PVOID)PTE_BASE) &&
                 (Wsle[WorkingSetIndex].u1.VirtualAddress<= (PVOID)PTE_TOP));
            }
#endif

            //
            // Don't remove page table pages from the working set until
            // all transition pages have exited.
            //

            UNLOCK_PFN (OldIrql);
            return FALSE;
        }
    }

    //
    // Found a candidate, remove the page from the working set.
    //

    MiEliminateWorkingSetEntry (WorkingSetIndex,
                                PointerPte,
                                Pfn1,
                                Wsle);

    UNLOCK_PFN (OldIrql);

    //
    // Remove the working set entry from the working set.
    //

    MiRemoveWsle (WorkingSetIndex, WorkingSetList);

    ASSERT (WorkingSetList->FirstFree >= WorkingSetList->FirstDynamic);

    ASSERT (WorkingSetIndex >= WorkingSetList->FirstDynamic);

    //
    // Put the entry on the free list and decrement the current size.
    //

    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));
    Wsle[WorkingSetIndex].u1.Long = WorkingSetList->FirstFree << MM_FREE_WSLE_SHIFT;
    WorkingSetList->FirstFree = WorkingSetIndex;
    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

    if (WsInfo->WorkingSetSize > WsInfo->MinimumWorkingSetSize) {
        InterlockedExchangeAddSizeT (&MmPagesAboveWsMinimum, -1);
    }
    WsInfo->WorkingSetSize -= 1;
#if defined (_MI_DEBUG_WSLE)
    WorkingSetList->Quota -= 1;
    ASSERT (WsInfo->WorkingSetSize == WorkingSetList->Quota);

    MiCheckWsleList (WsInfo);
#endif

    return TRUE;
}

#define MI_INITIALIZE_WSLE(_VirtualAddress, _WslEntry) {           \
    PMMPFN _Pfn1;                                                   \
    _WslEntry->u1.VirtualAddress = (PVOID)(_VirtualAddress);        \
    _WslEntry->u1.e1.Valid = 1;                                     \
    _WslEntry->u1.e1.LockedInWs = 1;                                \
    _WslEntry->u1.e1.Direct = 1;                                    \
    _Pfn1 = MI_PFN_ELEMENT (MiGetPteAddress ((PVOID)(_VirtualAddress))->u.Hard.PageFrameNumber); \
    ASSERT (_Pfn1->u1.WsIndex == 0);                                \
    _Pfn1->u1.WsIndex = (WSLE_NUMBER)(_WslEntry - MmWsle);          \
    (_WslEntry) += 1;                                               \
}


VOID
MiInitializeWorkingSetList (
    IN PEPROCESS CurrentProcess
    )

/*++

Routine Description:

    This routine initializes a process's working set to the empty
    state.

Arguments:

    CurrentProcess - Supplies a pointer to the process to initialize.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled.

--*/

{
    PMMPFN Pfn1;
    WSLE_NUMBER i;
    PMMWSLE WslEntry;
    WSLE_NUMBER CurrentWsIndex;
    WSLE_NUMBER NumberOfEntriesMapped;
    PVOID VirtualAddress;

    WslEntry = MmWsle;

    //
    // Initialize the working set list control cells.
    //

    MmWorkingSetList->LastEntry = CurrentProcess->Vm.MinimumWorkingSetSize;
    MmWorkingSetList->HashTable = NULL;
    MmWorkingSetList->HashTableSize = 0;
    MmWorkingSetList->NumberOfImageWaiters = 0;
    MmWorkingSetList->Wsle = MmWsle;
    MmWorkingSetList->VadBitMapHint = 1;
    MmWorkingSetList->HashTableStart = 
       (PVOID)((PCHAR)PAGE_ALIGN (&MmWsle[MM_MAXIMUM_WORKING_SET]) + PAGE_SIZE);

#if defined (_X86PAE_)
    MmWorkingSetList->HighestPermittedHashAddress = (PVOID)((ULONG_PTR)MmHyperSpaceEnd + 1);
#else
    MmWorkingSetList->HighestPermittedHashAddress = (PVOID)((ULONG_PTR)HYPER_SPACE_END + 1);
#endif

    //
    // Fill in the reserved slots.
    // Start with the top level page directory page.
    //

#if (_MI_PAGING_LEVELS >= 4)
    VirtualAddress = (PVOID) PXE_BASE;
#elif (_MI_PAGING_LEVELS >= 3)
    VirtualAddress = (PVOID) PDE_TBASE;
#else
    VirtualAddress = (PVOID) PDE_BASE;
#endif

    MI_INITIALIZE_WSLE (VirtualAddress, WslEntry);

#if defined (_X86PAE_)

    //
    // Fill in the additional page directory entries.
    //

    for (i = 1; i < PD_PER_SYSTEM; i += 1) {
        MI_INITIALIZE_WSLE (PDE_BASE + i * PAGE_SIZE, WslEntry);
    }

    VirtualAddress = (PVOID)((ULONG_PTR)VirtualAddress + ((PD_PER_SYSTEM - 1) * PAGE_SIZE));
#endif

    Pfn1 = MI_PFN_ELEMENT (MiGetPteAddress ((PVOID)(VirtualAddress))->u.Hard.PageFrameNumber);
    ASSERT (Pfn1->u4.PteFrame == (ULONG_PTR)MI_PFN_ELEMENT_TO_INDEX (Pfn1));
    Pfn1->u1.Event = (PVOID) CurrentProcess;

#if (_MI_PAGING_LEVELS >= 4)

    //
    // Fill in the entry for the hyper space page directory parent page.
    //

    MI_INITIALIZE_WSLE (MiGetPpeAddress (HYPER_SPACE), WslEntry);

#endif

#if (_MI_PAGING_LEVELS >= 3)

    //
    // Fill in the entry for the hyper space page directory page.
    //

    MI_INITIALIZE_WSLE (MiGetPdeAddress (HYPER_SPACE), WslEntry);

#endif

    //
    // Fill in the entry for the page table page which maps hyper space.
    //

    MI_INITIALIZE_WSLE (MiGetPteAddress (HYPER_SPACE), WslEntry);

#if defined (_X86PAE_)

    //
    // Fill in the entry for the second page table page which maps hyper space.
    //

    MI_INITIALIZE_WSLE (MiGetPteAddress (HYPER_SPACE2), WslEntry);

#endif

    //
    // Fill in the entry for the first VAD bitmap page.
    //
    // Note when booted /3GB, the second VAD bitmap page is automatically
    // inserted as part of the working set list page as the page is shared
    // by both.
    //

    MI_INITIALIZE_WSLE (VAD_BITMAP_SPACE, WslEntry);

    //
    // Fill in the entry for the page which contains the working set list.
    //

    MI_INITIALIZE_WSLE (MmWorkingSetList, WslEntry);

    NumberOfEntriesMapped = (PAGE_SIZE - BYTE_OFFSET (MmWsle)) / sizeof (MMWSLE);

    CurrentWsIndex = (WSLE_NUMBER)(WslEntry - MmWsle);

    CurrentProcess->Vm.WorkingSetSize = CurrentWsIndex;
#if defined (_MI_DEBUG_WSLE)
    MmWorkingSetList->Quota = CurrentWsIndex;
#endif

    MmWorkingSetList->FirstFree = CurrentWsIndex;
    MmWorkingSetList->FirstDynamic = CurrentWsIndex;
    MmWorkingSetList->NextSlot = CurrentWsIndex;

    //
    //
    // Build the free list starting at the first dynamic entry.
    //

    i = CurrentWsIndex + 1;
    do {

        WslEntry->u1.Long = i << MM_FREE_WSLE_SHIFT;
        WslEntry += 1;
        i += 1;
    } while (i <= NumberOfEntriesMapped);

    //
    // Mark the end of the list.
    //

    WslEntry -= 1;
    WslEntry->u1.Long = WSLE_NULL_INDEX << MM_FREE_WSLE_SHIFT;

    MmWorkingSetList->LastInitializedWsle = NumberOfEntriesMapped - 1;

    return;
}


VOID
MiInitializeSessionWsSupport (
    VOID
    )

/*++

Routine Description:

    This routine initializes the session space working set support.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode, APC_LEVEL or below, no mutexes held.

--*/

{
    //
    // This is the list of all session spaces ordered in a working set list.
    //

    InitializeListHead (&MiSessionWsList);
}


NTSTATUS
MiSessionInitializeWorkingSetList (
    VOID
    )

/*++

Routine Description:

    This function initializes the working set for the session space and adds
    it to the list of session space working sets.

Arguments:

    None.

Return Value:

    NT_SUCCESS if success or STATUS_NO_MEMORY on failure.

Environment:

    Kernel mode, APC_LEVEL or below, no mutexes held.

--*/

{
    WSLE_NUMBER i;
    ULONG MaximumEntries;
    ULONG PageTableCost;
    KIRQL OldIrql;
    PMMPTE PointerPte;
    PMMPTE PointerPde;
    MMPTE  TempPte;
    PMMWSLE WslEntry;
    PMMPFN Pfn1;
    ULONG PageColor;
    PFN_NUMBER ResidentPages;
    PFN_NUMBER PageFrameIndex;
    WSLE_NUMBER CurrentEntry;
    WSLE_NUMBER NumberOfEntriesMapped;
    WSLE_NUMBER NumberOfEntriesMappedByFirstPage;
    ULONG WorkingSetMaximum;
    PMM_SESSION_SPACE SessionGlobal;
    LOGICAL AllocatedPageTable;
    PMMWSL WorkingSetList;
    MMPTE DemandZeroWritePte;
#if (_MI_PAGING_LEVELS < 3)
    ULONG Index;
#endif

    //
    // Use the global address for pointer references by
    // MmWorkingSetManager before it attaches to the address space.
    //

    SessionGlobal = SESSION_GLOBAL (MmSessionSpace);

    //
    // Set up the working set variables.
    //

    WorkingSetMaximum = MI_SESSION_SPACE_WORKING_SET_MAXIMUM;

    WorkingSetList = (PMMWSL) MiSessionSpaceWs;

    MmSessionSpace->Vm.VmWorkingSetList = WorkingSetList;
#if (_MI_PAGING_LEVELS >= 3)
    MmSessionSpace->Wsle = (PMMWSLE) (WorkingSetList + 1);
#else
    MmSessionSpace->Wsle = (PMMWSLE) (&WorkingSetList->UsedPageTableEntries[0]);
#endif

    ASSERT (KeGetOwnerGuardedMutex (&MmSessionSpace->Vm.WorkingSetMutex) == NULL);

    //
    // Build the PDE entry for the working set - note that the global bit
    // must be turned off.
    //

    PointerPde = MiGetPdeAddress (WorkingSetList);

    //
    // The page table page for the working set and its first data page
    // are charged against MmResidentAvailablePages and for commitment.
    //

    if (PointerPde->u.Hard.Valid == 1) {

        //
        // The page directory entry for the working set is the same
        // as for another range in the session space.  Share the PDE.
        //

#ifndef _IA64_
        ASSERT (PointerPde->u.Hard.Global == 0);
#endif
        AllocatedPageTable = FALSE;
        ResidentPages = 1;
    }
    else {
        AllocatedPageTable = TRUE;
        ResidentPages = 2;
    }


    PointerPte = MiGetPteAddress (WorkingSetList);

    //
    // The data pages needed to map up to maximum working set size are also
    // charged against MmResidentAvailablePages and for commitment.
    //

    NumberOfEntriesMappedByFirstPage = (WSLE_NUMBER)(
        ((PMMWSLE)((ULONG_PTR)WorkingSetList + PAGE_SIZE)) -
            MmSessionSpace->Wsle);

    if (MiChargeCommitment (ResidentPages, NULL) == FALSE) {
        MM_BUMP_SESSION_FAILURES (MM_SESSION_FAILURE_NO_COMMIT);
        return STATUS_NO_MEMORY;
    }

    //
    // Use the global address for mutexes since the contained event
    // must be accesible from any address space.
    //

    KeInitializeGuardedMutex (&SessionGlobal->Vm.WorkingSetMutex);

    MmLockPagableSectionByHandle (ExPageLockHandle);

    LOCK_PFN (OldIrql);

    //
    // Check to make sure the physical pages are available.
    //

    if ((SPFN_NUMBER)ResidentPages > MI_NONPAGABLE_MEMORY_AVAILABLE() - 20) {

        UNLOCK_PFN (OldIrql);

        MmUnlockPagableImageSection (ExPageLockHandle);

        MiReturnCommitment (ResidentPages);
        MM_BUMP_SESSION_FAILURES (MM_SESSION_FAILURE_NO_RESIDENT);
        return STATUS_NO_MEMORY;
    }

    MM_TRACK_COMMIT (MM_DBG_COMMIT_SESSION_WS_INIT, ResidentPages);

    MI_DECREMENT_RESIDENT_AVAILABLE (ResidentPages,
                                     MM_RESAVAIL_ALLOCATE_INIT_SESSION_WS);

    if (AllocatedPageTable == TRUE) {

        MM_BUMP_SESS_COUNTER (MM_DBG_SESSION_WS_PAGETABLE_ALLOC, 1);

        if (MmAvailablePages < MM_HIGH_LIMIT) {
            MiEnsureAvailablePageOrWait (NULL, NULL, OldIrql);
        }

        PageColor = MI_GET_PAGE_COLOR_FROM_VA (NULL);

        PageFrameIndex = MiRemoveZeroPageMayReleaseLocks (PageColor, OldIrql);

        //
        // The global bit is masked off since we need to make sure the TB entry
        // is flushed when we switch to a process in a different session space.
        //

        TempPte.u.Long = ValidKernelPdeLocal.u.Long;
        TempPte.u.Hard.PageFrameNumber = PageFrameIndex;
        MI_WRITE_VALID_PTE (PointerPde, TempPte);

#if (_MI_PAGING_LEVELS < 3)

        //
        // Add this to the session structure so other processes can fault it in.
        //

        Index = MiGetPdeSessionIndex (WorkingSetList);

        MmSessionSpace->PageTables[Index] = TempPte;

#endif

        //
        // This page frame references the session space page table page.
        //

        MiInitializePfnForOtherProcess (PageFrameIndex,
                                        PointerPde,
                                        MmSessionSpace->SessionPageDirectoryIndex);

        KeZeroPages (PointerPte, PAGE_SIZE);

        Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

        //
        // This page is never paged, ensure that its WsIndex stays clear so the
        // release of the page will be handled correctly.
        //

        ASSERT (Pfn1->u1.WsIndex == 0);
    }

    if (MmAvailablePages < MM_HIGH_LIMIT) {
        MiEnsureAvailablePageOrWait (NULL, NULL, OldIrql);
    }

    PageColor = MI_GET_PAGE_COLOR_FROM_VA (NULL);

    PageFrameIndex = MiRemoveZeroPageIfAny (PageColor);
    if (PageFrameIndex == 0) {
        PageFrameIndex = MiRemoveAnyPage (PageColor);
        UNLOCK_PFN (OldIrql);
        MiZeroPhysicalPage (PageFrameIndex, PageColor);
        LOCK_PFN (OldIrql);
    }

    MM_BUMP_SESS_COUNTER (MM_DBG_SESSION_WS_PAGE_ALLOC, (ULONG)(ResidentPages - 1));

#if DBG
    Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);
    ASSERT (Pfn1->u1.WsIndex == 0);
#endif

    //
    // The global bit is masked off since we need to make sure the TB entry
    // is flushed when we switch to a process in a different session space.
    //

    TempPte.u.Long = ValidKernelPteLocal.u.Long;
    MI_SET_PTE_DIRTY (TempPte);
    TempPte.u.Hard.PageFrameNumber = PageFrameIndex;

    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    MiInitializePfn (PageFrameIndex, PointerPte, 1);

#if DBG
    Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);
    ASSERT (Pfn1->u1.WsIndex == 0);
#endif

    UNLOCK_PFN (OldIrql);

#define MI_INITIALIZE_SESSION_WSLE(_VirtualAddress, _WslEntry) {   \
    PMMPFN _Pfn1;                                                   \
    _WslEntry->u1.VirtualAddress = (PVOID)(_VirtualAddress);        \
    _WslEntry->u1.e1.Valid = 1;                                     \
    _WslEntry->u1.e1.LockedInWs = 1;                                \
    _WslEntry->u1.e1.Direct = 1;                                    \
    _Pfn1 = MI_PFN_ELEMENT (MiGetPteAddress ((PVOID)(_VirtualAddress))->u.Hard.PageFrameNumber); \
    ASSERT (_Pfn1->u1.WsIndex == 0);                                \
    _Pfn1->u1.WsIndex = (WSLE_NUMBER)(_WslEntry - MmSessionSpace->Wsle); \
    (_WslEntry) += 1;                                               \
}

    //
    // Fill in the reserved slots starting with the 2 session data pages.
    //

    WslEntry = MmSessionSpace->Wsle;

    //
    // The first reserved slot is for the page table page mapping
    // the session data page.
    //

    MI_INITIALIZE_SESSION_WSLE (MiGetPteAddress (MmSessionSpace), WslEntry);

    //
    // The next reserved slot is for the working set page.
    //

    MI_INITIALIZE_SESSION_WSLE (WorkingSetList, WslEntry);

    if (AllocatedPageTable == TRUE) {

        //
        // The next reserved slot is for the page table page
        // mapping the working set page.
        //

        MI_INITIALIZE_SESSION_WSLE (PointerPte, WslEntry);
    }

    //
    // The next reserved slot is for the page table page
    // mapping the first session paged pool page.
    //

    MI_INITIALIZE_SESSION_WSLE (MiGetPteAddress (MmSessionSpace->PagedPoolStart), WslEntry);

    CurrentEntry = (WSLE_NUMBER)(WslEntry - MmSessionSpace->Wsle);

    MmSessionSpace->Vm.Flags.SessionSpace = 1;
    MmSessionSpace->Vm.MinimumWorkingSetSize = MI_SESSION_SPACE_WORKING_SET_MINIMUM;
    MmSessionSpace->Vm.MaximumWorkingSetSize = WorkingSetMaximum;

    WorkingSetList->LastEntry = MI_SESSION_SPACE_WORKING_SET_MINIMUM;
    WorkingSetList->HashTable = NULL;
    WorkingSetList->HashTableSize = 0;
    WorkingSetList->Wsle = MmSessionSpace->Wsle;

    //
    // Calculate the maximum number of entries dynamically as the size of
    // session space is registry configurable.  Then add in page table and
    // page directory overhead.
    //

    MaximumEntries = (ULONG)((MiSessionSpaceEnd - MmSessionBase) >> PAGE_SHIFT);
    PageTableCost = MaximumEntries / PTE_PER_PAGE + 1;
    MaximumEntries += PageTableCost;

    WorkingSetList->HashTableStart =
       (PVOID)((PCHAR)PAGE_ALIGN (&MmSessionSpace->Wsle[MaximumEntries]) + PAGE_SIZE);

#if defined (_X86PAE_)

    //
    // One less page table page is needed on PAE systems as the session
    // working set structures easily fit within 2MB.
    //

    WorkingSetList->HighestPermittedHashAddress =
        (PVOID)(MiSessionImageStart - MM_VA_MAPPED_BY_PDE);
#else
    WorkingSetList->HighestPermittedHashAddress =
        (PVOID)(MiSessionImageStart - MI_SESSION_SPACE_STRUCT_SIZE);
#endif

    DemandZeroWritePte.u.Long = MM_DEMAND_ZERO_WRITE_PTE;

    NumberOfEntriesMapped = (WSLE_NUMBER)(((PMMWSLE)((ULONG_PTR)WorkingSetList +
                                PAGE_SIZE)) - MmSessionSpace->Wsle);

    MmSessionSpace->Vm.WorkingSetSize = CurrentEntry;
#if defined (_MI_DEBUG_WSLE)
    WorkingSetList->Quota = CurrentEntry;
#endif
    WorkingSetList->FirstFree = CurrentEntry;
    WorkingSetList->FirstDynamic = CurrentEntry;
    WorkingSetList->NextSlot = CurrentEntry;

    MM_BUMP_SESS_COUNTER (MM_DBG_SESSION_NP_INIT_WS, (ULONG)ResidentPages);

    InterlockedExchangeAddSizeT (&MmSessionSpace->NonPagablePages,
                                 ResidentPages);

    InterlockedExchangeAddSizeT (&MmSessionSpace->CommittedPages,
                                 ResidentPages);

    //
    // Initialize the following slots as free.
    //

    WslEntry = MmSessionSpace->Wsle + CurrentEntry;

    for (i = CurrentEntry + 1; i < NumberOfEntriesMapped; i += 1) {

        //
        // Build the free list, note that the first working
        // set entries (CurrentEntry) are not on the free list.
        // These entries are reserved for the pages which
        // map the working set and the page which contains the PDE.
        //

        WslEntry->u1.Long = i << MM_FREE_WSLE_SHIFT;
        WslEntry += 1;
    }

    WslEntry->u1.Long = WSLE_NULL_INDEX << MM_FREE_WSLE_SHIFT;  // End of list.

    WorkingSetList->LastInitializedWsle = NumberOfEntriesMapped - 1;

    //
    // Put this session's working set in lists using its global address.
    //

    ASSERT (SessionGlobal->Vm.WorkingSetExpansionLinks.Flink == NULL);
    ASSERT (SessionGlobal->Vm.WorkingSetExpansionLinks.Blink == NULL);

    LOCK_EXPANSION (OldIrql);

    ASSERT (SessionGlobal->WsListEntry.Flink == NULL);
    ASSERT (SessionGlobal->WsListEntry.Blink == NULL);

    InsertTailList (&MiSessionWsList, &SessionGlobal->WsListEntry);

    InsertTailList (&MmWorkingSetExpansionHead.ListHead,
                    &SessionGlobal->Vm.WorkingSetExpansionLinks);

    UNLOCK_EXPANSION (OldIrql);

    MmUnlockPagableImageSection (ExPageLockHandle);

    return STATUS_SUCCESS;
}


LOGICAL
MmAssignProcessToJob (
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This routine acquires the address space mutex so a consistent snapshot of
    the argument process' commit charges can be used by Ps when adding this
    process to a job.

    Note that the working set mutex is not acquired here so the argument
    process' working set sizes cannot be reliably snapped by Ps, but since Ps
    doesn't look at that anyway, it's not a problem.

Arguments:

    Process - Supplies a pointer to the process to operate upon.

Return Value:

    TRUE if the process is allowed to join the job, FALSE otherwise.

    Note that FALSE cannot be returned without changing the code in Ps.

Environment:

    Kernel mode, IRQL APC_LEVEL or below.  The caller provides protection
    from the target process going away.

--*/

{
    LOGICAL Attached;
    LOGICAL Status;
    KAPC_STATE ApcState;

    PAGED_CODE ();

    Attached = FALSE;

    if (PsGetCurrentProcess() != Process) {
        KeStackAttachProcess (&Process->Pcb, &ApcState);
        Attached = TRUE;
    }

    LOCK_ADDRESS_SPACE (Process);

    Status = PsChangeJobMemoryUsage (PS_JOB_STATUS_REPORT_COMMIT_CHANGES, Process->CommitCharge);

    //
    // Join the job unconditionally.  If the process is over any limits, it
    // will be caught on its next request.
    //

    PS_SET_BITS (&Process->JobStatus, PS_JOB_STATUS_REPORT_COMMIT_CHANGES);

    UNLOCK_ADDRESS_SPACE (Process);

    if (Attached) {
        KeUnstackDetachProcess (&ApcState);
    }

    //
    // Note that FALSE cannot be returned without changing the code in Ps.
    //

    return TRUE;
}


NTSTATUS
MmQueryWorkingSetInformation (
    IN PSIZE_T PeakWorkingSetSize,
    IN PSIZE_T WorkingSetSize,
    IN PSIZE_T MinimumWorkingSetSize,
    IN PSIZE_T MaximumWorkingSetSize,
    IN PULONG HardEnforcementFlags
    )

/*++

Routine Description:

    This routine returns various working set information fields for the
    current process.

Arguments:

    PeakWorkingSetSize - Supplies an address to receive the peak working set
                         size in bytes.

    WorkingSetSize - Supplies an address to receive the current working set
                     size in bytes.

    MinimumWorkingSetSize - Supplies an address to receive the minimum
                            working set size in bytes.

    MaximumWorkingSetSize - Supplies an address to receive the maximum
                            working set size in bytes.

    HardEnforcementFlags - Supplies an address to receive the current
                           working set enforcement policy.

Return Value:

    NTSTATUS.

Environment:

    Kernel mode, IRQL APC_LEVEL or below.

--*/

{
    PEPROCESS Process;

    ASSERT (KeGetCurrentIrql () <= APC_LEVEL);

    *HardEnforcementFlags = 0;
    Process = PsGetCurrentProcess ();

    LOCK_WS (Process);

    *PeakWorkingSetSize = (SIZE_T) Process->Vm.PeakWorkingSetSize << PAGE_SHIFT;
    *WorkingSetSize = (SIZE_T) Process->Vm.WorkingSetSize << PAGE_SHIFT;
    *MinimumWorkingSetSize = (SIZE_T) Process->Vm.MinimumWorkingSetSize << PAGE_SHIFT;
    *MaximumWorkingSetSize = (SIZE_T) Process->Vm.MaximumWorkingSetSize << PAGE_SHIFT;

    if (Process->Vm.Flags.MinimumWorkingSetHard == 1) {
        *HardEnforcementFlags |= MM_WORKING_SET_MIN_HARD_ENABLE;
    }

    if (Process->Vm.Flags.MaximumWorkingSetHard == 1) {
        *HardEnforcementFlags |= MM_WORKING_SET_MAX_HARD_ENABLE;
    }

    UNLOCK_WS (Process);

    return STATUS_SUCCESS;
}

NTSTATUS
MmAdjustWorkingSetSizeEx (
    IN SIZE_T WorkingSetMinimumInBytes,
    IN SIZE_T WorkingSetMaximumInBytes,
    IN ULONG SystemCache,
    IN BOOLEAN IncreaseOkay,
    IN ULONG Flags
    )

/*++

Routine Description:

    This routine adjusts the current size of a process's working set
    list.  If the maximum value is above the current maximum, pages
    are removed from the working set list.

    A failure status is returned if the limit cannot be granted.  This
    could occur if too many pages were locked in the process's
    working set.

    Note: if the minimum and maximum are both (SIZE_T)-1, the working set
          is purged, but the default sizes are not changed.

Arguments:

    WorkingSetMinimumInBytes - Supplies the new minimum working set size in
                               bytes.

    WorkingSetMaximumInBytes - Supplies the new maximum working set size in
                               bytes.

    SystemCache - Supplies TRUE if the system cache working set is being
                  adjusted, FALSE for all other working sets.

    IncreaseOkay - Supplies TRUE if this routine should allow increases to
                   the working set minimum.

    Flags - Supplies flags (MM_WORKING_SET_MAX_HARD_ENABLE, etc) for
            enabling/disabling hard enforcement of the working set minimums
            and maximums for the specified WsInfo.

Return Value:

    NTSTATUS.

Environment:

    Kernel mode, IRQL APC_LEVEL or below.

--*/

{
    PETHREAD CurrentThread;
    PEPROCESS CurrentProcess;
    WSLE_NUMBER Entry;
    WSLE_NUMBER LastFreed;
    PMMWSLE Wsle;
    KIRQL OldIrql;
    SPFN_NUMBER i;
    PMMPTE PointerPte;
    NTSTATUS ReturnStatus;
    LONG PagesAbove;
    LONG NewPagesAbove;
    ULONG FreeTryCount;
    PMMSUPPORT WsInfo;
    PMMWSL WorkingSetList;
    WSLE_NUMBER WorkingSetMinimum;
    WSLE_NUMBER WorkingSetMaximum;

    PERFINFO_PAGE_INFO_DECL();

    FreeTryCount = 0;

    if (SystemCache) {

        //
        // Initializing CurrentProcess is not needed for correctness, but
        // without it the compiler cannot compile this code W4 to check
        // for use of uninitialized variables.
        //

        CurrentProcess = NULL;
        WsInfo = &MmSystemCacheWs;
    }
    else {
        CurrentProcess = PsGetCurrentProcess ();
        WsInfo = &CurrentProcess->Vm;
    }

    if ((WorkingSetMinimumInBytes == (SIZE_T)-1) &&
        (WorkingSetMaximumInBytes == (SIZE_T)-1)) {

        return MiEmptyWorkingSet (WsInfo, TRUE);
    }

    ReturnStatus = STATUS_SUCCESS;

    MmLockPagableSectionByHandle (ExPageLockHandle);

    //
    // Get the working set lock and disable APCs.
    //

    if (SystemCache) {
        CurrentThread = PsGetCurrentThread ();
        LOCK_SYSTEM_WS (CurrentThread);
    }
    else {

        LOCK_WS (CurrentProcess);

        if (CurrentProcess->Flags & PS_PROCESS_FLAGS_VM_DELETED) {
            ReturnStatus = STATUS_PROCESS_IS_TERMINATING;
            goto Returns;
        }
    }

    if (WorkingSetMinimumInBytes == 0) {
        WorkingSetMinimum = WsInfo->MinimumWorkingSetSize;
    }
    else {
        WorkingSetMinimum = (WSLE_NUMBER)(WorkingSetMinimumInBytes >> PAGE_SHIFT);
    }

    if (WorkingSetMaximumInBytes == 0) {
        WorkingSetMaximum = WsInfo->MaximumWorkingSetSize;
    }
    else {
        WorkingSetMaximum = (WSLE_NUMBER)(WorkingSetMaximumInBytes >> PAGE_SHIFT);
    }

    if (WorkingSetMinimum > WorkingSetMaximum) {
        ReturnStatus = STATUS_BAD_WORKING_SET_LIMIT;
        goto Returns;
    }

    if (WorkingSetMaximum > MmMaximumWorkingSetSize) {
        WorkingSetMaximum = MmMaximumWorkingSetSize;
        ReturnStatus = STATUS_WORKING_SET_LIMIT_RANGE;
    }

    if (WorkingSetMinimum > MmMaximumWorkingSetSize) {
        WorkingSetMinimum = MmMaximumWorkingSetSize;
        ReturnStatus = STATUS_WORKING_SET_LIMIT_RANGE;
    }

    if (WorkingSetMinimum < MmMinimumWorkingSetSize) {
        WorkingSetMinimum = (ULONG)MmMinimumWorkingSetSize;
        ReturnStatus = STATUS_WORKING_SET_LIMIT_RANGE;
    }

    //
    // Make sure that the number of locked pages will not
    // make the working set not fluid.
    //

    if ((WsInfo->VmWorkingSetList->FirstDynamic + MM_FLUID_WORKING_SET) >=
         WorkingSetMaximum) {
        ReturnStatus = STATUS_BAD_WORKING_SET_LIMIT;
        goto Returns;
    }

    //
    // If hard working set limits are being enabled (or are already enabled),
    // then make sure the minimum and maximum will not starve this process.
    //

    if ((Flags & MM_WORKING_SET_MIN_HARD_ENABLE) ||
        ((WsInfo->Flags.MinimumWorkingSetHard == 1) &&
         ((Flags & MM_WORKING_SET_MIN_HARD_DISABLE) == 0))) {

        //
        // Working set minimum is (or will be hard).  Check the maximum.
        //

        if ((Flags & MM_WORKING_SET_MAX_HARD_ENABLE) ||
            ((WsInfo->Flags.MaximumWorkingSetHard == 1) &&
            ((Flags & MM_WORKING_SET_MAX_HARD_DISABLE) == 0))) {

            //
            // Working set maximum is (or will be hard) as well.
            //
            // Check whether the requested minimum and maximum working
            // set values will guarantee forward progress even in pathological
            // scenarios.
            //

            if (WorkingSetMinimum + MM_FLUID_WORKING_SET >= WorkingSetMaximum) {
                ReturnStatus = STATUS_BAD_WORKING_SET_LIMIT;
                goto Returns;
            }
        }
    }

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    i = (SPFN_NUMBER)WorkingSetMinimum - (SPFN_NUMBER)WsInfo->MinimumWorkingSetSize;

    //
    // Check to make sure ample resident physical pages exist for
    // this operation.
    //

    LOCK_PFN (OldIrql);

    if (i > 0) {

        //
        // New minimum working set is greater than the old one.
        // Ensure that increasing is okay, and that we don't allow
        // this process' working set minimum to increase to a point
        // where subsequent nonpaged pool allocations could cause us
        // to run out of pages.  Additionally, leave 100 extra pages
        // around so the user can later bring up tlist and kill
        // processes if necessary.
        //

        if (IncreaseOkay == FALSE) {
            UNLOCK_PFN (OldIrql);
            ReturnStatus = STATUS_PRIVILEGE_NOT_HELD;
            goto Returns;
        }

        if ((SPFN_NUMBER)((i / (PAGE_SIZE / sizeof (MMWSLE)))) >
            (SPFN_NUMBER)(MmAvailablePages - MM_HIGH_LIMIT)) {

            UNLOCK_PFN (OldIrql);
            ReturnStatus = STATUS_INSUFFICIENT_RESOURCES;
            goto Returns;
        }

        if (MI_NONPAGABLE_MEMORY_AVAILABLE() - 100 < i) {
            UNLOCK_PFN (OldIrql);
            ReturnStatus = STATUS_INSUFFICIENT_RESOURCES;
            goto Returns;
        }
    }

    //
    // Adjust the number of resident pages up or down dependent on
    // the size of the new minimum working set size versus the previous
    // minimum size.
    //

    MI_DECREMENT_RESIDENT_AVAILABLE (i, MM_RESAVAIL_ALLOCATEORFREE_WS_ADJUST);

    UNLOCK_PFN (OldIrql);

    if (WorkingSetMaximum < WorkingSetList->LastInitializedWsle) {

        //
        // The new working set maximum is less than the current working set
        // maximum.
        //

        if (WsInfo->WorkingSetSize > WorkingSetMaximum) {

            //
            // Remove some pages from the working set.
            //
            // Make sure that the number of locked pages will not
            // make the working set not fluid.
            //

            if ((WorkingSetList->FirstDynamic + MM_FLUID_WORKING_SET) >=
                 WorkingSetMaximum) {

                ReturnStatus = STATUS_BAD_WORKING_SET_LIMIT;

                LOCK_PFN (OldIrql);

                MI_INCREMENT_RESIDENT_AVAILABLE (i, MM_RESAVAIL_ALLOCATEORFREE_WS_ADJUST2);

                UNLOCK_PFN (OldIrql);

                goto Returns;
            }

            //
            // Attempt to remove the pages from the Maximum downward.
            //

            LastFreed = WorkingSetList->LastEntry;

            while (LastFreed >= WorkingSetMaximum) {

                PointerPte = MiGetPteAddress(Wsle[LastFreed].u1.VirtualAddress);

                PERFINFO_GET_PAGE_INFO(PointerPte);

                if ((Wsle[LastFreed].u1.e1.Valid != 0) &&
                    (!MiFreeWsle (LastFreed, WsInfo, PointerPte))) {

                    //
                    // This LastFreed could not be removed.
                    //

                    break;
                }
                PERFINFO_LOG_WS_REMOVAL(PERFINFO_LOG_TYPE_OUTWS_ADJUSTWS, WsInfo);
                LastFreed -= 1;
            }

            WorkingSetList->LastEntry = LastFreed;

            //
            // Remove pages.
            //

            Entry = WorkingSetList->FirstDynamic;

            while (WsInfo->WorkingSetSize > WorkingSetMaximum) {
                if (Wsle[Entry].u1.e1.Valid != 0) {
                    PointerPte = MiGetPteAddress (
                                            Wsle[Entry].u1.VirtualAddress);
                    PERFINFO_GET_PAGE_INFO(PointerPte);

                    if (MiFreeWsle (Entry, WsInfo, PointerPte)) {
                        PERFINFO_LOG_WS_REMOVAL(PERFINFO_LOG_TYPE_OUTWS_ADJUSTWS,
                                              WsInfo);
                    }
                }
                Entry += 1;
                if (Entry > LastFreed) {
                    FreeTryCount += 1;
                    if (FreeTryCount > MM_RETRY_COUNT) {

                        //
                        // Page table pages are not becoming free, give up
                        // and return an error.
                        //

                        ReturnStatus = STATUS_BAD_WORKING_SET_LIMIT;

                        break;
                    }
                    Entry = WorkingSetList->FirstDynamic;
                }
            }
        }
    }

    //
    // Adjust the number of pages above the working set minimum.
    //

    PagesAbove = (LONG)WsInfo->WorkingSetSize -
                               (LONG)WsInfo->MinimumWorkingSetSize;

    NewPagesAbove = (LONG)WsInfo->WorkingSetSize - (LONG)WorkingSetMinimum;

    if (PagesAbove > 0) {
        InterlockedExchangeAddSizeT (&MmPagesAboveWsMinimum, 0 - (PFN_NUMBER)PagesAbove);
    }
    if (NewPagesAbove > 0) {
        InterlockedExchangeAddSizeT (&MmPagesAboveWsMinimum, (PFN_NUMBER)NewPagesAbove);
    }

    if (FreeTryCount <= MM_RETRY_COUNT) {
        WsInfo->MaximumWorkingSetSize = WorkingSetMaximum;
        WsInfo->MinimumWorkingSetSize = WorkingSetMinimum;

        //
        // A change in hard working set limits is being requested.
        //
        // If the caller's request will result in hard enforcement of both
        // limits, the minimum and maximum working set values must
        // guarantee forward progress even in pathological scenarios.
        // This was already checked above.
        //

        if (Flags != 0) {

            LOCK_EXPANSION (OldIrql);

            if (Flags & MM_WORKING_SET_MIN_HARD_ENABLE) {
                WsInfo->Flags.MinimumWorkingSetHard = 1;
            }
            else if (Flags & MM_WORKING_SET_MIN_HARD_DISABLE) {
                WsInfo->Flags.MinimumWorkingSetHard = 0;
            }

            if (Flags & MM_WORKING_SET_MAX_HARD_ENABLE) {
                WsInfo->Flags.MaximumWorkingSetHard = 1;
            }
            else if (Flags & MM_WORKING_SET_MAX_HARD_DISABLE) {
                WsInfo->Flags.MaximumWorkingSetHard = 0;
            }

            UNLOCK_EXPANSION (OldIrql);
        }
    }
    else {
        MI_INCREMENT_RESIDENT_AVAILABLE (i, MM_RESAVAIL_ALLOCATEORFREE_WS_ADJUST3);
    }

    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

Returns:

    if (SystemCache) {
        UNLOCK_SYSTEM_WS ();
    }
    else {
        UNLOCK_WS (CurrentProcess);
    }

    MmUnlockPagableImageSection (ExPageLockHandle);

    return ReturnStatus;
}


NTSTATUS
MmAdjustWorkingSetSize (
    IN SIZE_T WorkingSetMinimumInBytes,
    IN SIZE_T WorkingSetMaximumInBytes,
    IN ULONG SystemCache,
    IN BOOLEAN IncreaseOkay
    )

/*++

Routine Description:

    This routine adjusts the current size of a process's working set
    list.  If the maximum value is above the current maximum, pages
    are removed from the working set list.

    A failure status is returned if the limit cannot be granted.  This
    could occur if too many pages were locked in the process's
    working set.

    Note: if the minimum and maximum are both (SIZE_T)-1, the working set
          is purged, but the default sizes are not changed.

Arguments:

    WorkingSetMinimumInBytes - Supplies the new minimum working set size in
                               bytes.

    WorkingSetMaximumInBytes - Supplies the new maximum working set size in
                               bytes.

    SystemCache - Supplies TRUE if the system cache working set is being
                  adjusted, FALSE for all other working sets.

Return Value:

    NTSTATUS.

Environment:

    Kernel mode, IRQL APC_LEVEL or below.

--*/

{
    return MmAdjustWorkingSetSizeEx (WorkingSetMinimumInBytes,
                                     WorkingSetMaximumInBytes,
                                     SystemCache,
                                     IncreaseOkay,
                                     0);
}

#define MI_ALLOCATED_PAGE_TABLE     0x1
#define MI_ALLOCATED_PAGE_DIRECTORY 0x2


ULONG
MiAddWorkingSetPage (
    IN PMMSUPPORT WsInfo
    )

/*++

Routine Description:

    This function grows the working set list above working set
    maximum during working set adjustment.  At most one page
    can be added at a time.

Arguments:

    None.

Return Value:

    Returns FALSE if no working set page could be added.

Environment:

    Kernel mode, APCs disabled, working set mutex held.

--*/

{
    PETHREAD CurrentThread;
    WSLE_NUMBER SwapEntry;
    WSLE_NUMBER CurrentEntry;
    PMMWSLE WslEntry;
    WSLE_NUMBER i;
    PMMPTE PointerPte;
    PMMPTE Va;
    MMPTE TempPte;
    WSLE_NUMBER NumberOfEntriesMapped;
    PFN_NUMBER WorkingSetPage;
    WSLE_NUMBER WorkingSetIndex;
    PMMWSL WorkingSetList;
    PMMWSLE Wsle;
    PMMPFN Pfn1;
    KIRQL OldIrql;
    ULONG PageTablePageAllocated;
    LOGICAL PfnHeld;
    ULONG NumberOfPages;
    MMPTE DemandZeroWritePte;
#if (_MI_PAGING_LEVELS >= 3)
    PVOID VirtualAddress;
    PMMPTE PointerPde;
#endif
#if (_MI_PAGING_LEVELS >= 4)
    PMMPTE PointerPpe;
#endif

    //
    // Initializing OldIrql is not needed for correctness, but
    // without it the compiler cannot compile this code W4 to check
    // for use of uninitialized variables.
    //

    OldIrql = PASSIVE_LEVEL;

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    MM_WS_LOCK_ASSERT (WsInfo);

    //
    // The maximum size of the working set is being increased, check
    // to ensure the proper number of pages are mapped to cover
    // the complete working set list.
    //

    PointerPte = MiGetPteAddress (&Wsle[WorkingSetList->LastInitializedWsle]);

    ASSERT (PointerPte->u.Hard.Valid == 1);

    PointerPte += 1;

    Va = (PMMPTE)MiGetVirtualAddressMappedByPte (PointerPte);

    if ((PVOID)Va >= WorkingSetList->HashTableStart) {

        //
        // Adding this entry would overrun the hash table.  The caller
        // must replace instead.
        //

        return FALSE;
    }

    //
    // Ensure enough commitment is available prior to acquiring pages.
    // Excess is released after the pages are acquired.
    //

    if (MiChargeCommitmentCantExpand (_MI_PAGING_LEVELS - 1, FALSE) == FALSE) {
        return FALSE;
    }

    MM_TRACK_COMMIT (MM_DBG_COMMIT_SESSION_ADDITIONAL_WS_PAGES, _MI_PAGING_LEVELS - 1);
    PageTablePageAllocated = 0;
    PfnHeld = FALSE;
    NumberOfPages = 0;
    DemandZeroWritePte.u.Long = MM_DEMAND_ZERO_WRITE_PTE;

    //
    // The PPE is guaranteed to always be resident for architectures using
    // 3 level lookup.  This is because the hash table PPE immediately
    // follows the working set PPE.
    //
    // For x86 PAE the same paradigm holds in guaranteeing that the PDE is
    // always resident.
    //
    // x86 non-PAE uses the same PDE and hence it also guarantees PDE residency.
    //
    // Architectures employing 4 level lookup use a single PXE for this, but
    // each PPE must be checked.
    //
    // All architectures must check for page table page residency.
    //

#if (_MI_PAGING_LEVELS >= 4)

    //
    // Allocate a PPE if one is needed.
    //

    PointerPpe = MiGetPdeAddress (PointerPte);
    if (PointerPpe->u.Hard.Valid == 0) {

        ASSERT (WsInfo->Flags.SessionSpace == 0);

        //
        // Map in a new page directory for the working set expansion.
        // Continue holding the PFN lock until the entire hierarchy is
        // allocated.  This eliminates error recovery which would be needed
        // if the lock was released and then when reacquired it is discovered
        // that one of the pages cannot be allocated.
        //
    
        PfnHeld = TRUE;
        LOCK_PFN (OldIrql);
        if ((MmAvailablePages < MM_HIGH_LIMIT) ||
            (MI_NONPAGABLE_MEMORY_AVAILABLE() < MM_HIGH_LIMIT)) {
    
            //
            // No pages are available, the caller will have to replace.
            //
    
            UNLOCK_PFN (OldIrql);
            MiReturnCommitment (_MI_PAGING_LEVELS - 1 - NumberOfPages);
            MM_TRACK_COMMIT_REDUCTION (MM_DBG_COMMIT_SESSION_ADDITIONAL_WS_PAGES,
                            _MI_PAGING_LEVELS - 1 - NumberOfPages);
            return FALSE;
        }
    
        //
        // Apply the resident available charge for the working set page
        // directory table page now before releasing the PFN lock.
        //

        MI_DECREMENT_RESIDENT_AVAILABLE (1, MM_RESAVAIL_ALLOCATE_ADD_WS_PAGE);

        PageTablePageAllocated |= MI_ALLOCATED_PAGE_DIRECTORY;
        WorkingSetPage = MiRemoveZeroPage (MI_GET_PAGE_COLOR_FROM_PTE (PointerPpe));

        MI_WRITE_INVALID_PTE (PointerPpe, DemandZeroWritePte);

        MiInitializePfn (WorkingSetPage, PointerPpe, 1);
    
        MI_MAKE_VALID_PTE (TempPte,
                           WorkingSetPage,
                           MM_READWRITE,
                           PointerPpe);
    
        MI_SET_PTE_DIRTY (TempPte);
        MI_WRITE_VALID_PTE (PointerPpe, TempPte);
        NumberOfPages += 1;
    }

#endif

#if (_MI_PAGING_LEVELS >= 3)

    //
    // Map in a new page table (if needed) for the working set expansion.
    //

    PointerPde = MiGetPteAddress (PointerPte);

    if (PointerPde->u.Hard.Valid == 0) {
        PageTablePageAllocated |= MI_ALLOCATED_PAGE_TABLE;

        if (PfnHeld == FALSE) {
            PfnHeld = TRUE;
            LOCK_PFN (OldIrql);
            if ((MmAvailablePages < MM_HIGH_LIMIT) ||
                (MI_NONPAGABLE_MEMORY_AVAILABLE() < MM_HIGH_LIMIT)) {
    
                //
                // No pages are available, the caller will have to replace.
                //
    
                UNLOCK_PFN (OldIrql);
                MiReturnCommitment (_MI_PAGING_LEVELS - 1 - NumberOfPages);
                MM_TRACK_COMMIT_REDUCTION (MM_DBG_COMMIT_SESSION_ADDITIONAL_WS_PAGES,
                                 _MI_PAGING_LEVELS - 1 - NumberOfPages);
                return FALSE;
            }
        }

        //
        // Apply the resident available charge for the working set page table
        // page now before releasing the PFN lock.
        //

        MI_DECREMENT_RESIDENT_AVAILABLE (1, MM_RESAVAIL_ALLOCATE_ADD_WS_PAGE);

        WorkingSetPage = MiRemoveZeroPage (MI_GET_PAGE_COLOR_FROM_PTE (PointerPde));
        MI_WRITE_INVALID_PTE (PointerPde, DemandZeroWritePte);

        MiInitializePfn (WorkingSetPage, PointerPde, 1);
    
        MI_MAKE_VALID_PTE (TempPte,
                           WorkingSetPage,
                           MM_READWRITE,
                           PointerPde);
    
        MI_SET_PTE_DIRTY (TempPte);
        MI_WRITE_VALID_PTE (PointerPde, TempPte);
        NumberOfPages += 1;
    }

#endif
    
    ASSERT (PointerPte->u.Hard.Valid == 0);

    //
    // Finally allocate and map the actual working set page now.  The PFN lock
    // is only held if another page in the hierarchy needed to be allocated.
    //
    // Further down in this routine (once an actual working set page has been
    // allocated) the working set size will be increased by 1 to reflect
    // the working set size entry for the new page directory page.
    // The page directory page will be put in a working set entry which will
    // be locked into the working set.
    //

    if (PfnHeld == FALSE) {
        LOCK_PFN (OldIrql);
        if ((MmAvailablePages < MM_HIGH_LIMIT) ||
            (MI_NONPAGABLE_MEMORY_AVAILABLE() < MM_HIGH_LIMIT)) {
    
            //
            // No pages are available, the caller will have to replace.
            //
    
            UNLOCK_PFN (OldIrql);
            MiReturnCommitment (_MI_PAGING_LEVELS - 1 - NumberOfPages);
            MM_TRACK_COMMIT_REDUCTION (MM_DBG_COMMIT_SESSION_ADDITIONAL_WS_PAGES,
                                       _MI_PAGING_LEVELS - 1 - NumberOfPages);
            return FALSE;
        }
    }

    //
    // Apply the resident available charge for the working set page now
    // before releasing the PFN lock.
    //

    MI_DECREMENT_RESIDENT_AVAILABLE (1, MM_RESAVAIL_ALLOCATE_ADD_WS_PAGE);

    WorkingSetPage = MiRemoveZeroPage (MI_GET_PAGE_COLOR_FROM_PTE (PointerPte));

    MI_WRITE_INVALID_PTE (PointerPte, DemandZeroWritePte);

    MiInitializePfn (WorkingSetPage, PointerPte, 1);

    UNLOCK_PFN (OldIrql);

    NumberOfPages += 1;

    if (_MI_PAGING_LEVELS - 1 - NumberOfPages != 0) {
        MiReturnCommitment (_MI_PAGING_LEVELS - 1 - NumberOfPages);
        MM_TRACK_COMMIT_REDUCTION (MM_DBG_COMMIT_SESSION_ADDITIONAL_WS_PAGES,
                         _MI_PAGING_LEVELS - 1 - NumberOfPages);
    }

    MI_MAKE_VALID_PTE (TempPte, WorkingSetPage, MM_READWRITE, PointerPte);

    MI_SET_PTE_DIRTY (TempPte);
    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    NumberOfEntriesMapped = (WSLE_NUMBER)(((PMMWSLE)((PCHAR)Va + PAGE_SIZE)) - Wsle);

    if (WsInfo->Flags.SessionSpace == 1) {
        MM_BUMP_SESS_COUNTER (MM_DBG_SESSION_NP_WS_GROW, NumberOfPages);
        MM_BUMP_SESS_COUNTER (MM_DBG_SESSION_WS_PAGE_ALLOC_GROWTH, NumberOfPages);
        InterlockedExchangeAddSizeT (&MmSessionSpace->NonPagablePages,
                                     NumberOfPages);
        InterlockedExchangeAddSizeT (&MmSessionSpace->CommittedPages,
                                     NumberOfPages);
    }

    CurrentEntry = WorkingSetList->LastInitializedWsle + 1;

    ASSERT (NumberOfEntriesMapped > CurrentEntry);

    WslEntry = &Wsle[CurrentEntry - 1];

    for (i = CurrentEntry; i < NumberOfEntriesMapped; i += 1) {

        //
        // Build the free list, note that the first working
        // set entries (CurrentEntry) are not on the free list.
        // These entries are reserved for the pages which
        // map the working set and the page which contains the PDE.
        //

        WslEntry += 1;
        WslEntry->u1.Long = (i + 1) << MM_FREE_WSLE_SHIFT;
    }

    WslEntry->u1.Long = WorkingSetList->FirstFree << MM_FREE_WSLE_SHIFT;

    ASSERT (CurrentEntry >= WorkingSetList->FirstDynamic);

    WorkingSetList->FirstFree = CurrentEntry;

    WorkingSetList->LastInitializedWsle = (NumberOfEntriesMapped - 1);

    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

    Pfn1 = MI_PFN_ELEMENT (PointerPte->u.Hard.PageFrameNumber);

    CurrentThread = PsGetCurrentThread ();

    Pfn1->u1.Event = NULL;

    //
    // Get a working set entry.
    //

    ASSERT (WsInfo->WorkingSetSize <= (WorkingSetList->LastInitializedWsle + 1));
    WsInfo->WorkingSetSize += 1;
#if defined (_MI_DEBUG_WSLE)
    WorkingSetList->Quota += 1;
    ASSERT (WsInfo->WorkingSetSize == WorkingSetList->Quota);
#endif

    ASSERT (WorkingSetList->FirstFree != WSLE_NULL_INDEX);
    ASSERT (WorkingSetList->FirstFree >= WorkingSetList->FirstDynamic);

    WorkingSetIndex = WorkingSetList->FirstFree;
    WorkingSetList->FirstFree = (WSLE_NUMBER)(Wsle[WorkingSetIndex].u1.Long >> MM_FREE_WSLE_SHIFT);
    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

    if (WsInfo->WorkingSetSize > WsInfo->MinimumWorkingSetSize) {
        InterlockedExchangeAddSizeT (&MmPagesAboveWsMinimum, 1);
    }
    if (WorkingSetIndex > WorkingSetList->LastEntry) {
        WorkingSetList->LastEntry = WorkingSetIndex;
    }

    MiUpdateWsle (&WorkingSetIndex, Va, WsInfo, Pfn1);

    MI_SET_PTE_IN_WORKING_SET (PointerPte, WorkingSetIndex);

    //
    // Lock any created page table pages into the working set.
    //

    if (WorkingSetIndex >= WorkingSetList->FirstDynamic) {

        SwapEntry = WorkingSetList->FirstDynamic;

        if (WorkingSetIndex != WorkingSetList->FirstDynamic) {

            //
            // Swap this entry with the one at first dynamic.
            //

            MiSwapWslEntries (WorkingSetIndex, SwapEntry, WsInfo, FALSE);
        }

        WorkingSetList->FirstDynamic += 1;

        Wsle[SwapEntry].u1.e1.LockedInWs = 1;
        ASSERT (Wsle[SwapEntry].u1.e1.Valid == 1);
    }

#if (_MI_PAGING_LEVELS >= 3)
    while (PageTablePageAllocated != 0) {
    
        if (PageTablePageAllocated & MI_ALLOCATED_PAGE_TABLE) {
            PageTablePageAllocated &= ~MI_ALLOCATED_PAGE_TABLE;
            Pfn1 = MI_PFN_ELEMENT (PointerPde->u.Hard.PageFrameNumber);
            VirtualAddress = PointerPte;
        }
#if (_MI_PAGING_LEVELS >= 4)
        else if (PageTablePageAllocated & MI_ALLOCATED_PAGE_DIRECTORY) {
            PageTablePageAllocated &= ~MI_ALLOCATED_PAGE_DIRECTORY;
            Pfn1 = MI_PFN_ELEMENT (PointerPpe->u.Hard.PageFrameNumber);
            VirtualAddress = PointerPde;
        }
#endif
        else {
            ASSERT (FALSE);

            SATISFY_OVERZEALOUS_COMPILER (VirtualAddress = NULL);
        }
    
        Pfn1->u1.Event = NULL;
    
        //
        // Get a working set entry.
        //
    
        WsInfo->WorkingSetSize += 1;
#if defined (_MI_DEBUG_WSLE)
        WorkingSetList->Quota += 1;
        ASSERT (WsInfo->WorkingSetSize == WorkingSetList->Quota);
#endif
    
        ASSERT (WorkingSetList->FirstFree != WSLE_NULL_INDEX);
        ASSERT (WorkingSetList->FirstFree >= WorkingSetList->FirstDynamic);
    
        WorkingSetIndex = WorkingSetList->FirstFree;
        WorkingSetList->FirstFree = (WSLE_NUMBER)(Wsle[WorkingSetIndex].u1.Long >> MM_FREE_WSLE_SHIFT);
        ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
                (WorkingSetList->FirstFree == WSLE_NULL_INDEX));
    
        if (WsInfo->WorkingSetSize > WsInfo->MinimumWorkingSetSize) {
            InterlockedExchangeAddSizeT (&MmPagesAboveWsMinimum, 1);
        }
        if (WorkingSetIndex > WorkingSetList->LastEntry) {
            WorkingSetList->LastEntry = WorkingSetIndex;
        }
    
        MiUpdateWsle (&WorkingSetIndex, VirtualAddress, WsInfo, Pfn1);
    
        MI_SET_PTE_IN_WORKING_SET (MiGetPteAddress (VirtualAddress),
                                   WorkingSetIndex);
    
        //
        // Lock the created page table page into the working set.
        //
    
        if (WorkingSetIndex >= WorkingSetList->FirstDynamic) {
    
            SwapEntry = WorkingSetList->FirstDynamic;
    
            if (WorkingSetIndex != WorkingSetList->FirstDynamic) {
    
                //
                // Swap this entry with the one at first dynamic.
                //
    
                MiSwapWslEntries (WorkingSetIndex, SwapEntry, WsInfo, FALSE);
            }
    
            WorkingSetList->FirstDynamic += 1;
    
            Wsle[SwapEntry].u1.e1.LockedInWs = 1;
            ASSERT (Wsle[SwapEntry].u1.e1.Valid == 1);
        }
    }
#endif

    ASSERT ((MiGetPteAddress(&Wsle[WorkingSetList->LastInitializedWsle]))->u.Hard.Valid == 1);

    if ((WorkingSetList->HashTable == NULL) &&
        (MmAvailablePages > MM_HIGH_LIMIT)) {

        //
        // Add a hash table to support shared pages in the working set to
        // eliminate costly lookups.
        //

        WsInfo->Flags.GrowWsleHash = 1;
    }

    return TRUE;
}

LOGICAL
MiAddWsleHash (
    IN PMMSUPPORT WsInfo,
    IN PMMPTE PointerPte
    )

/*++

Routine Description:

    This function adds a page directory, page table or actual mapping page
    for hash table creation (or expansion) for the current process.

Arguments:

    WsInfo - Supplies a pointer to the working set info structure.

    PointerPte - Supplies a pointer to the PTE to be filled.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, working set lock held.

--*/
{
    KIRQL OldIrql;
    PMMPFN Pfn1;
    WSLE_NUMBER SwapEntry;
    MMPTE TempPte;
    PMMWSLE Wsle;
    PFN_NUMBER WorkingSetPage;
    WSLE_NUMBER WorkingSetIndex;
    PMMWSL WorkingSetList;
    MMPTE DemandZeroWritePte;

    if (MiChargeCommitmentCantExpand (1, FALSE) == FALSE) {
        return FALSE;
    }

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    ASSERT (PointerPte->u.Hard.Valid == 0);

    DemandZeroWritePte.u.Long = MM_DEMAND_ZERO_WRITE_PTE;

    LOCK_PFN (OldIrql);

    if (MmAvailablePages < MM_HIGH_LIMIT) {
        UNLOCK_PFN (OldIrql);
        MiReturnCommitment (1);
        return FALSE;
    }

    if (MI_NONPAGABLE_MEMORY_AVAILABLE() < MM_HIGH_LIMIT) {
        UNLOCK_PFN (OldIrql);
        MiReturnCommitment (1);
        return FALSE;
    }

    MI_DECREMENT_RESIDENT_AVAILABLE (1, MM_RESAVAIL_ALLOCATE_WSLE_HASH);

    MM_TRACK_COMMIT (MM_DBG_COMMIT_SESSION_ADDITIONAL_WS_HASHPAGES, 1);

    WorkingSetPage = MiRemoveZeroPage (MI_GET_PAGE_COLOR_FROM_PTE (PointerPte));

    MI_WRITE_INVALID_PTE (PointerPte, DemandZeroWritePte);

    MiInitializePfn (WorkingSetPage, PointerPte, 1);

    UNLOCK_PFN (OldIrql);

    MI_MAKE_VALID_PTE (TempPte,
                       WorkingSetPage,
                       MM_READWRITE,
                       PointerPte);

    MI_SET_PTE_DIRTY (TempPte);
    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // As we have grown the working set, take the
    // next free WSLE from the list and use it.
    //

    Pfn1 = MI_PFN_ELEMENT (WorkingSetPage);

    Pfn1->u1.Event = NULL;

    //
    // Set the low bit in the PFN pointer to indicate that the working set
    // should not be trimmed during the WSLE allocation as the PTEs for the
    // new hash pages are valid but we are still in the midst of making all
    // the associated fields valid.
    //

    WorkingSetIndex = MiAllocateWsle (WsInfo,
                                      PointerPte,
                                      (PMMPFN)((ULONG_PTR)Pfn1 | 0x1),
                                      0);

    if (WorkingSetIndex == 0) {

        //
        // No working set index was available, flush the PTE and the page,
        // and decrement the count on the containing page.
        //

        ASSERT (Pfn1->u3.e1.PrototypePte == 0);

        LOCK_PFN (OldIrql);
        MI_SET_PFN_DELETED (Pfn1);
        UNLOCK_PFN (OldIrql);

        MiTrimPte (MiGetVirtualAddressMappedByPte (PointerPte),
                   PointerPte,
                   Pfn1,
                   PsGetCurrentProcess (),
                   ZeroPte);

        MI_INCREMENT_RESIDENT_AVAILABLE (1, MM_RESAVAIL_FREE_WSLE_HASH);
        MiReturnCommitment (1);

        return FALSE;
    }

    //
    // Lock any created page table pages into the working set.
    //

    if (WorkingSetIndex >= WorkingSetList->FirstDynamic) {

        SwapEntry = WorkingSetList->FirstDynamic;

        if (WorkingSetIndex != WorkingSetList->FirstDynamic) {

            //
            // Swap this entry with the one at first dynamic.
            //

            MiSwapWslEntries (WorkingSetIndex, SwapEntry, WsInfo, FALSE);
        }

        WorkingSetList->FirstDynamic += 1;

        Wsle[SwapEntry].u1.e1.LockedInWs = 1;
        ASSERT (Wsle[SwapEntry].u1.e1.Valid == 1);
    }

    if (WsInfo->Flags.SessionSpace == 1) {
        MM_BUMP_SESS_COUNTER (MM_DBG_SESSION_NP_HASH_GROW, 1);
        InterlockedExchangeAddSizeT (&MmSessionSpace->NonPagablePages, 1);
        MM_BUMP_SESS_COUNTER (MM_DBG_SESSION_WS_HASHPAGE_ALLOC, 1);
        InterlockedExchangeAddSizeT (&MmSessionSpace->CommittedPages, 1);
    }

    return TRUE;
}

VOID
MiGrowWsleHash (
    IN PMMSUPPORT WsInfo
    )

/*++

Routine Description:

    This function grows (or adds) a hash table to the working set list
    to allow direct indexing for WSLEs than cannot be located via the
    PFN database WSINDEX field.

    The hash table is located AFTER the WSLE array and the pages are
    locked into the working set just like standard WSLEs.

    Note that the hash table is expanded by setting the hash table
    field in the working set to NULL, but leaving the size as non-zero.
    This indicates that the hash should be expanded and the initial
    portion of the table zeroed.

Arguments:

    WsInfo - Supplies a pointer to the working set info structure.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, working set lock held.

--*/
{
    ULONG Tries;
    LONG Size;
    PMMWSLE Wsle;
    PMMPTE StartPte;
    PMMPTE EndPte;
    PMMPTE PointerPte;
    ULONG First;
    WSLE_NUMBER Hash;
    ULONG NewSize;
    PMMWSLE_HASH Table;
    PMMWSLE_HASH OriginalTable;
    ULONG j;
    PMMWSL WorkingSetList;
    WSLE_NUMBER Count;
    PVOID EntryHashTableEnd;
    PVOID VirtualAddress;
#if (_MI_PAGING_LEVELS >= 3) || defined (_X86PAE_)
    KIRQL OldIrql;
    PVOID TempVa;
    PEPROCESS CurrentProcess;
    LOGICAL LoopStart;
    PMMPTE AllocatedPde;
    PMMPTE AllocatedPpe;
    PMMPTE AllocatedPxe;
    PMMPTE PointerPde;
#endif
#if (_MI_PAGING_LEVELS >= 3)
    PMMPTE PointerPpe;
    PMMPTE PointerPxe;
#endif

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    Table = WorkingSetList->HashTable;
    OriginalTable = WorkingSetList->HashTable;

    First = WorkingSetList->HashTableSize;

    if (Table == NULL) {

        NewSize = PtrToUlong(PAGE_ALIGN (((1 + WorkingSetList->NonDirectCount) *
                            2 * sizeof(MMWSLE_HASH)) + PAGE_SIZE - 1));

        //
        // Note that the Table may be NULL and the HashTableSize/PTEs nonzero
        // in the case where the hash has been contracted.
        //

        j = First * sizeof(MMWSLE_HASH);

        //
        // Don't try for additional hash pages if we already have
        // the right amount (or too many).
        //

        if ((j + PAGE_SIZE > NewSize) && (j != 0)) {
            WsInfo->Flags.GrowWsleHash = 0;
            return;
        }

        Table = (PMMWSLE_HASH)(WorkingSetList->HashTableStart);
        EntryHashTableEnd = &Table[WorkingSetList->HashTableSize];

        WorkingSetList->HashTableSize = 0;
    }
    else {

        //
        // Attempt to add 4 pages, make sure the working set list has
        // 4 free entries.
        //

        if ((WorkingSetList->LastInitializedWsle + 5) > WsInfo->WorkingSetSize) {
            NewSize = PAGE_SIZE * 4;
        }
        else {
            NewSize = PAGE_SIZE;
        }
        EntryHashTableEnd = &Table[WorkingSetList->HashTableSize];
    }

    if ((PCHAR)EntryHashTableEnd + NewSize > (PCHAR)WorkingSetList->HighestPermittedHashAddress) {
        NewSize =
            (ULONG)((PCHAR)(WorkingSetList->HighestPermittedHashAddress) -
                ((PCHAR)EntryHashTableEnd));
        if (NewSize == 0) {
            if (OriginalTable == NULL) {
                WorkingSetList->HashTableSize = First;
            }
            WsInfo->Flags.GrowWsleHash = 0;
            return;
        }
    }


#if (_MI_PAGING_LEVELS >= 4)
    ASSERT64 ((MiGetPxeAddress(EntryHashTableEnd)->u.Hard.Valid == 0) ||
              (MiGetPpeAddress(EntryHashTableEnd)->u.Hard.Valid == 0) ||
              (MiGetPdeAddress(EntryHashTableEnd)->u.Hard.Valid == 0) ||
              (MiGetPteAddress(EntryHashTableEnd)->u.Hard.Valid == 0));
#else
    ASSERT64 ((MiGetPpeAddress(EntryHashTableEnd)->u.Hard.Valid == 0) ||
              (MiGetPdeAddress(EntryHashTableEnd)->u.Hard.Valid == 0) ||
              (MiGetPteAddress(EntryHashTableEnd)->u.Hard.Valid == 0));
#endif

    //
    // Note PAE virtual address space is packed even more densely than
    // regular x86.  The working set list hash table can grow until it
    // is directly beneath the system cache data structures.  Hence the
    // assert below factors that in by checking HighestPermittedHashAddress
    // first.
    //

    ASSERT32 ((EntryHashTableEnd == WorkingSetList->HighestPermittedHashAddress) ||
              (MiGetPdeAddress(EntryHashTableEnd)->u.Hard.Valid == 0) ||
              (MiGetPteAddress(EntryHashTableEnd)->u.Hard.Valid == 0));

    Size = NewSize;
    PointerPte = MiGetPteAddress (EntryHashTableEnd);
    StartPte = PointerPte;
    EndPte = PointerPte + (NewSize >> PAGE_SHIFT);

#if (_MI_PAGING_LEVELS >= 3) || defined (_X86PAE_)
    PointerPde = NULL;
    LoopStart = TRUE;
    AllocatedPde = NULL;
#endif

#if (_MI_PAGING_LEVELS >= 3)
    AllocatedPpe = NULL;
    AllocatedPxe = NULL;
    PointerPpe = NULL;
    PointerPxe = NULL;
#endif

    do {

#if (_MI_PAGING_LEVELS >= 3) || defined (_X86PAE_)
        if (LoopStart == TRUE || MiIsPteOnPdeBoundary(PointerPte)) {

            PointerPde = MiGetPteAddress (PointerPte);

#if (_MI_PAGING_LEVELS >= 3)
            PointerPxe = MiGetPpeAddress (PointerPte);
            PointerPpe = MiGetPdeAddress (PointerPte);

#if (_MI_PAGING_LEVELS >= 4)
            if (PointerPxe->u.Hard.Valid == 0) {
                if (MiAddWsleHash (WsInfo, PointerPxe) == FALSE) {
                    break;
                }
                AllocatedPxe = PointerPxe;
            }
#endif

            if (PointerPpe->u.Hard.Valid == 0) {
                if (MiAddWsleHash (WsInfo, PointerPpe) == FALSE) {
                    break;
                }
                AllocatedPpe = PointerPpe;
            }
#endif

            if (PointerPde->u.Hard.Valid == 0) {
                if (MiAddWsleHash (WsInfo, PointerPde) == FALSE) {
                    break;
                }
                AllocatedPde = PointerPde;
            }

            LoopStart = FALSE;
        }
        else {
            AllocatedPde = NULL;
            AllocatedPpe = NULL;
            AllocatedPxe = NULL;
        }
#endif

        if (PointerPte->u.Hard.Valid == 0) {
            if (MiAddWsleHash (WsInfo, PointerPte) == FALSE) {
                break;
            }
        }

        PointerPte += 1;
        Size -= PAGE_SIZE;
    } while (Size > 0);

    //
    // If MiAddWsleHash was unable to allocate memory above, then roll back
    // any extra PPEs & PDEs that may have been created.  Note NewSize must
    // be recalculated to handle the fact that memory may have run out.
    //

#if (_MI_PAGING_LEVELS >= 3) || defined (_X86PAE_)
    if (PointerPte != EndPte) {

        CurrentProcess = PsGetCurrentProcess ();

        //
        // Clean up the last allocated PPE/PDE as they are not needed.
        // Note that the system cache and the session space working sets
        // have no current process (which MiDeletePte requires) which is
        // needed for WSLE and PrivatePages adjustments.
        //

        if (AllocatedPde != NULL) {

            ASSERT (AllocatedPde->u.Hard.Valid == 1);
            TempVa = MiGetVirtualAddressMappedByPte (AllocatedPde);

            if (WsInfo->VmWorkingSetList == MmWorkingSetList) {

                LOCK_PFN (OldIrql);
                MiDeletePte (AllocatedPde,
                             TempVa,
                             FALSE,
                             CurrentProcess,
                             NULL,
                             NULL,
                             OldIrql);
                UNLOCK_PFN (OldIrql);

                //
                // Add back in the private page MiDeletePte subtracted.
                //

                CurrentProcess->NumberOfPrivatePages += 1;
            }
            else {
                LOCK_PFN (OldIrql);
                MiDeleteValidSystemPte (AllocatedPde,
                                        TempVa,
                                        WsInfo,
                                        NULL);
                UNLOCK_PFN (OldIrql);
            }

            MiReturnCommitment (1);
            MI_INCREMENT_RESIDENT_AVAILABLE (1, MM_RESAVAIL_FREE_WSLE_HASH);
        }
    
#if (_MI_PAGING_LEVELS >= 3)
        if (AllocatedPpe != NULL) {

            ASSERT (AllocatedPpe->u.Hard.Valid == 1);
            TempVa = MiGetVirtualAddressMappedByPte (AllocatedPpe);

            if (WsInfo->VmWorkingSetList == MmWorkingSetList) {
                LOCK_PFN (OldIrql);

                MiDeletePte (AllocatedPpe,
                             TempVa,
                             FALSE,
                             CurrentProcess,
                             NULL,
                             NULL,
                             OldIrql);

                UNLOCK_PFN (OldIrql);

                //
                // Add back in the private page MiDeletePte subtracted.
                //

                CurrentProcess->NumberOfPrivatePages += 1;
            }
            else {
                LOCK_PFN (OldIrql);
                MiDeleteValidSystemPte (AllocatedPpe,
                                        TempVa,
                                        WsInfo,
                                        NULL);
                UNLOCK_PFN (OldIrql);
            }

            MiReturnCommitment (1);
            MI_INCREMENT_RESIDENT_AVAILABLE (1, MM_RESAVAIL_FREE_WSLE_HASH);
        }

        if (AllocatedPxe != NULL) {

            ASSERT (AllocatedPxe->u.Hard.Valid == 1);
            TempVa = MiGetVirtualAddressMappedByPte (AllocatedPxe);

            if (WsInfo->VmWorkingSetList == MmWorkingSetList) {
                LOCK_PFN (OldIrql);

                MiDeletePte (AllocatedPxe,
                             TempVa,
                             FALSE,
                             CurrentProcess,
                             NULL,
                             NULL,
                             OldIrql);

                UNLOCK_PFN (OldIrql);

                //
                // Add back in the private page MiDeletePte subtracted.
                //

                CurrentProcess->NumberOfPrivatePages += 1;
            }
            else {
                LOCK_PFN (OldIrql);
                MiDeleteValidSystemPte (AllocatedPxe,
                                        TempVa,
                                        WsInfo,
                                        NULL);
                UNLOCK_PFN (OldIrql);
            }

            MiReturnCommitment (1);
            MI_INCREMENT_RESIDENT_AVAILABLE (1, MM_RESAVAIL_FREE_WSLE_HASH);
        }
#endif

        if (PointerPte == StartPte) {
            if (OriginalTable == NULL) {
                WorkingSetList->HashTableSize = First;
            }
            WsInfo->Flags.GrowWsleHash = 0;
            return;
        }
    }
#else
    if (PointerPte == StartPte) {
        if (OriginalTable == NULL) {
            WorkingSetList->HashTableSize = First;
        }
        WsInfo->Flags.GrowWsleHash = 0;
        return;
    }
#endif

    NewSize = (ULONG)((PointerPte - StartPte) << PAGE_SHIFT);

    VirtualAddress = MiGetVirtualAddressMappedByPte (PointerPte);

    ASSERT ((VirtualAddress == WorkingSetList->HighestPermittedHashAddress) ||
            (MiIsAddressValid (VirtualAddress, FALSE) == FALSE));

    WorkingSetList->HashTableSize = First + NewSize / sizeof (MMWSLE_HASH);
    WorkingSetList->HashTable = Table;

    VirtualAddress = &Table[WorkingSetList->HashTableSize];

    ASSERT ((VirtualAddress == WorkingSetList->HighestPermittedHashAddress) ||
            (MiIsAddressValid (VirtualAddress, FALSE) == FALSE));

    if (First != 0) {
        RtlZeroMemory (Table, First * sizeof(MMWSLE_HASH));
    }

    //
    // Fill hash table.
    //

    j = 0;
    Count = WorkingSetList->NonDirectCount;

    Size = WorkingSetList->HashTableSize;

    do {
        if ((Wsle[j].u1.e1.Valid == 1) &&
            (Wsle[j].u1.e1.Direct == 0)) {

            //
            // Hash this.
            //

            Count -= 1;

            Hash = MI_WSLE_HASH(Wsle[j].u1.Long, WorkingSetList);

            Tries = 0;
            while (Table[Hash].Key != 0) {
                Hash += 1;
                if (Hash >= (ULONG)Size) {

                    if (Tries != 0) {

                        //
                        // Not enough space to hash everything but that's ok.
                        // Just bail out, we'll do linear walks to lookup this
                        // entry until the hash can be further expanded later.
                        //

                        WsInfo->Flags.GrowWsleHash = 0;
                        return;
                    }
                    Tries = 1;
                    Hash = 0;
                    Size = MI_WSLE_HASH(Wsle[j].u1.Long, WorkingSetList);
                }
            }

            Table[Hash].Key = MI_GENERATE_VALID_WSLE (&Wsle[j]);
            Table[Hash].Index = j;
#if DBG
            PointerPte = MiGetPteAddress(Wsle[j].u1.VirtualAddress);
            ASSERT (PointerPte->u.Hard.Valid);
#endif

        }
        ASSERT (j <= WorkingSetList->LastEntry);
        j += 1;
    } while (Count);

#if DBG
    MiCheckWsleHash (WorkingSetList);
#endif
    WsInfo->Flags.GrowWsleHash = 0;
    return;
}


WSLE_NUMBER
MiFreeWsleList (
    IN PMMSUPPORT WsInfo,
    IN PMMWSLE_FLUSH_LIST WsleFlushList
    )

/*++

Routine Description:

    This routine frees the specified list of WSLEs decrementing the share
    count for the corresponding pages, putting each PTE into a transition
    state if the share count goes to 0.

Arguments:

    WsInfo - Supplies a pointer to the working set structure.

    WsleFlushList - Supplies the list of WSLEs to flush.

Return Value:

    Returns the number of WSLEs that were NOT removed.

Environment:

    Kernel mode, APCs disabled, working set lock.  PFN lock NOT held.

--*/

{
    PMMPFN Pfn1;
    KIRQL OldIrql;
    PMMPTE PointerPte;
    WSLE_NUMBER i;
    WSLE_NUMBER WorkingSetIndex;
    WSLE_NUMBER NumberNotFlushed;
    PMMWSL WorkingSetList;
    PMMWSLE Wsle;
    PMMPTE ContainingPageTablePage;
    MMPTE TempPte;
    PFN_NUMBER PageFrameIndex;
    PFN_NUMBER PageTableFrameIndex;
    PEPROCESS Process;
    PMMPFN Pfn2;
    MMPTE_FLUSH_LIST PteFlushList;

    PteFlushList.Count = 0;

    ASSERT (WsleFlushList->Count != 0);

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    MM_WS_LOCK_ASSERT (WsInfo);

    LOCK_PFN (OldIrql);

    for (i = 0; i < WsleFlushList->Count; i += 1) {

        WorkingSetIndex = WsleFlushList->FlushIndex[i];

        ASSERT (WorkingSetIndex >= WorkingSetList->FirstDynamic);
        ASSERT (Wsle[WorkingSetIndex].u1.e1.Valid == 1);

        PointerPte = MiGetPteAddress (Wsle[WorkingSetIndex].u1.VirtualAddress);

        TempPte = *PointerPte;
        ASSERT (TempPte.u.Hard.Valid == 1);

        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (&TempPte);
        Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

        //
        // Check to see if the located entry is eligible for removal.
        //
        // Note, don't clear the access bit for page table pages
        // with valid PTEs as this could cause an access trap fault which
        // would not be handled (it is only handled for PTEs not PDEs).
        //
        // If the PTE is a page table page with non-zero share count or
        // within the system cache with its reference count greater
        // than 1, don't remove it.
        //

        if (WsInfo == &MmSystemCacheWs) {
            if (Pfn1->u3.e2.ReferenceCount > 1) {
                WsleFlushList->FlushIndex[i] = 0;
                continue;
            }
        }
        else {
            if ((Pfn1->u2.ShareCount > 1) && (Pfn1->u3.e1.PrototypePte == 0)) {

#if DBG
                if (WsInfo->Flags.SessionSpace == 1) {
                    ASSERT (MI_IS_SESSION_ADDRESS (Wsle[WorkingSetIndex].u1.VirtualAddress));
                }
                else {
                    ASSERT32 ((Wsle[WorkingSetIndex].u1.VirtualAddress >= (PVOID)PTE_BASE) &&
                     (Wsle[WorkingSetIndex].u1.VirtualAddress<= (PVOID)PTE_TOP));
                }
#endif

                //
                // Don't remove page table pages from the working set until
                // all transition pages have exited.
                //

                WsleFlushList->FlushIndex[i] = 0;
                continue;
            }
        }

        //
        // Found a candidate, remove the page from the working set.
        //

        ASSERT (MI_IS_PFN_DELETED (Pfn1) == 0);

#ifdef _X86_
#if DBG
#if !defined(NT_UP)
        if (TempPte.u.Hard.Writable == 1) {
            ASSERT (TempPte.u.Hard.Dirty == 1);
        }
#endif //NTUP
#endif //DBG
#endif //X86

        //
        // This page is being removed from the working set, the dirty
        // bit must be ORed into the modify bit in the PFN element.
        //

        MI_CAPTURE_DIRTY_BIT_TO_PFN (&TempPte, Pfn1);

        MI_MAKING_VALID_PTE_INVALID (FALSE);

        if (Pfn1->u3.e1.PrototypePte) {

            //
            // This is a prototype PTE.  The PFN database does not contain
            // the contents of this PTE it contains the contents of the
            // prototype PTE.  This PTE must be reconstructed to contain
            // a pointer to the prototype PTE.
            //
            // The working set list entry contains information about
            // how to reconstruct the PTE.
            //

            if (Wsle[WorkingSetIndex].u1.e1.SameProtectAsProto == 0) {

                //
                // The protection for the prototype PTE is in the WSLE.
                //

                ASSERT (Wsle[WorkingSetIndex].u1.e1.Protection != 0);

                TempPte.u.Long = 0;
                TempPte.u.Soft.Protection =
                    MI_GET_PROTECTION_FROM_WSLE (&Wsle[WorkingSetIndex]);
                TempPte.u.Soft.PageFileHigh = MI_PTE_LOOKUP_NEEDED;
            }
            else {

                //
                // The protection is in the prototype PTE.
                //

                TempPte.u.Long = MiProtoAddressForPte (Pfn1->PteAddress);
            }
        
            TempPte.u.Proto.Prototype = 1;

            //
            // Decrement the share count of the containing page table
            // page as the PTE for the removed page is no longer valid
            // or in transition.
            //

            ContainingPageTablePage = MiGetPteAddress (PointerPte);
#if (_MI_PAGING_LEVELS >= 3)
            ASSERT (ContainingPageTablePage->u.Hard.Valid == 1);
#else
            if (ContainingPageTablePage->u.Hard.Valid == 0) {
                if (!NT_SUCCESS(MiCheckPdeForPagedPool (PointerPte))) {
                    KeBugCheckEx (MEMORY_MANAGEMENT,
                                  0x61940, 
                                  (ULONG_PTR)PointerPte,
                                  (ULONG_PTR)ContainingPageTablePage->u.Long,
                                  (ULONG_PTR)MiGetVirtualAddressMappedByPte(PointerPte));
                }
            }
#endif
            PageTableFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (ContainingPageTablePage);
            Pfn2 = MI_PFN_ELEMENT (PageTableFrameIndex);
            MiDecrementShareCountInline (Pfn2, PageTableFrameIndex);
        }
        else {

            //
            // This is a private page, make it transition.
            //
            // If the PTE indicates the page has been modified (this is
            // different from the PFN indicating this), then ripple it
            // back to the write watch bitmap now since we are still in
            // the correct process context.
            //

            if ((MI_IS_PTE_DIRTY(TempPte)) && (Wsle == MmWsle)) {

                Process = CONTAINING_RECORD (WsInfo, EPROCESS, Vm);

                ASSERT (Process == PsGetCurrentProcess ());

                if (Process->Flags & PS_PROCESS_FLAGS_USING_WRITE_WATCH) {

                    //
                    // This process has (or had) write watch VADs.  Search now
                    // for a write watch region encapsulating the PTE being
                    // invalidated.
                    //

                    MiCaptureWriteWatchDirtyBit (Process,
                                           Wsle[WorkingSetIndex].u1.VirtualAddress);
                }
            }

            //
            // Assert that the share count is 1 for all user mode pages.
            //

            ASSERT ((Pfn1->u2.ShareCount == 1) ||
                    (Wsle[WorkingSetIndex].u1.VirtualAddress >
                            (PVOID)MM_HIGHEST_USER_ADDRESS));

            //
            // Set the working set index to zero.  This allows page table
            // pages to be brought back in with the proper WSINDEX.
            //

            ASSERT (Pfn1->u1.WsIndex != 0);
            MI_ZERO_WSINDEX (Pfn1);
            MI_MAKE_VALID_PTE_TRANSITION (TempPte,
                                          Pfn1->OriginalPte.u.Soft.Protection);
        }

        MI_WRITE_INVALID_PTE (PointerPte, TempPte);

        if (PteFlushList.Count < MM_MAXIMUM_FLUSH_COUNT) {
            PteFlushList.FlushVa[PteFlushList.Count] =
                Wsle[WorkingSetIndex].u1.VirtualAddress;
            PteFlushList.Count += 1;
        }

        //
        // Flush the translation buffer and decrement the number of valid
        // PTEs within the containing page table page.  Note that for a
        // private page, the page table page is still needed because the
        // page is in transition.
        //

        MiDecrementShareCountInline (Pfn1, PageFrameIndex);
    }

    if (PteFlushList.Count != 0) {

        if (Wsle == MmWsle) {
            MiFlushPteList (&PteFlushList, FALSE);
        }
        else if (Wsle == MmSystemCacheWsle) {

            //
            // Must be the system cache.
            //

            MiFlushPteList (&PteFlushList, TRUE);
        }
        else {

            //
            // Must be a session space.
            //

            MiFlushPteList (&PteFlushList, TRUE);

            //
            // Session space has no ASN - flush the entire TB.
            //

            MI_FLUSH_ENTIRE_SESSION_TB (TRUE, TRUE);
        }
    }

    UNLOCK_PFN (OldIrql);

    NumberNotFlushed = 0;

    //
    // Remove the working set entries (the PFN lock is not needed for this).
    //

    for (i = 0; i < WsleFlushList->Count; i += 1) {

        WorkingSetIndex = WsleFlushList->FlushIndex[i];

        if (WorkingSetIndex == 0) {
            NumberNotFlushed += 1;
            continue;
        }

        ASSERT (WorkingSetIndex >= WorkingSetList->FirstDynamic);
        ASSERT (Wsle[WorkingSetIndex].u1.e1.Valid == 1);

        MiRemoveWsle (WorkingSetIndex, WorkingSetList);

        ASSERT (WorkingSetList->FirstFree >= WorkingSetList->FirstDynamic);

        ASSERT (WorkingSetIndex >= WorkingSetList->FirstDynamic);

        //
        // Put the entry on the free list and decrement the current size.
        //

        ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
                (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

        Wsle[WorkingSetIndex].u1.Long = WorkingSetList->FirstFree << MM_FREE_WSLE_SHIFT;
        WorkingSetList->FirstFree = WorkingSetIndex;

        ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
                (WorkingSetList->FirstFree == WSLE_NULL_INDEX));

        if (WsInfo->WorkingSetSize > WsInfo->MinimumWorkingSetSize) {
            InterlockedExchangeAddSizeT (&MmPagesAboveWsMinimum, -1);
        }

        WsInfo->WorkingSetSize -= 1;
#if defined (_MI_DEBUG_WSLE)
        WorkingSetList->Quota -= 1;
        ASSERT (WsInfo->WorkingSetSize == WorkingSetList->Quota);
#endif

        PERFINFO_LOG_WS_REMOVAL(PERFINFO_LOG_TYPE_OUTWS_VOLUNTRIM, WsInfo);
    }

    return NumberNotFlushed;
}

WSLE_NUMBER
MiTrimWorkingSet (
    IN WSLE_NUMBER Reduction,
    IN PMMSUPPORT WsInfo,
    IN ULONG TrimAge
    )

/*++

Routine Description:

    This function reduces the working set by the specified amount.

Arguments:

    Reduction - Supplies the number of pages to remove from the working set.

    WsInfo - Supplies a pointer to the working set information to trim.

    TrimAge - Supplies the age value to use - ie: pages of this age or older
              will be removed.

Return Value:

    Returns the actual number of pages removed.

Environment:

    Kernel mode, APCs disabled, working set lock.  PFN lock NOT held.

--*/

{
    WSLE_NUMBER TryToFree;
    WSLE_NUMBER StartEntry;
    WSLE_NUMBER LastEntry;
    PMMWSL WorkingSetList;
    PMMWSLE Wsle;
    PMMPTE PointerPte;
    WSLE_NUMBER NumberLeftToRemove;
    WSLE_NUMBER NumberNotFlushed;
    MMWSLE_FLUSH_LIST WsleFlushList;

    WsleFlushList.Count = 0;

    NumberLeftToRemove = Reduction;
    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    MM_WS_LOCK_ASSERT (WsInfo);

    LastEntry = WorkingSetList->LastEntry;

    TryToFree = WorkingSetList->NextSlot;
    if (TryToFree > LastEntry || TryToFree < WorkingSetList->FirstDynamic) {
        TryToFree = WorkingSetList->FirstDynamic;
    }

    StartEntry = TryToFree;

TrimMore:

    while (NumberLeftToRemove != 0) {
        if (Wsle[TryToFree].u1.e1.Valid == 1) {
            PointerPte = MiGetPteAddress (Wsle[TryToFree].u1.VirtualAddress);

            if ((TrimAge == 0) ||
                ((MI_GET_ACCESSED_IN_PTE (PointerPte) == 0) &&
                (MI_GET_WSLE_AGE(PointerPte, &Wsle[TryToFree]) >= TrimAge))) {

                PERFINFO_GET_PAGE_INFO_WITH_DECL(PointerPte);

                WsleFlushList.FlushIndex[WsleFlushList.Count] = TryToFree;
                WsleFlushList.Count += 1;
                NumberLeftToRemove -= 1;

                if (WsleFlushList.Count == MM_MAXIMUM_FLUSH_COUNT) {
                    NumberNotFlushed = MiFreeWsleList (WsInfo, &WsleFlushList);
                    WsleFlushList.Count = 0;
                    NumberLeftToRemove += NumberNotFlushed;
                }
            }
        }
        TryToFree += 1;

        if (TryToFree > LastEntry) {
            TryToFree = WorkingSetList->FirstDynamic;
        }

        if (TryToFree == StartEntry) {
            break;
        }
    }

    if (WsleFlushList.Count != 0) {
        NumberNotFlushed = MiFreeWsleList (WsInfo, &WsleFlushList);
        NumberLeftToRemove += NumberNotFlushed;

        if (NumberLeftToRemove != 0) {
            if (TryToFree != StartEntry) {
                WsleFlushList.Count = 0;
                goto TrimMore;
            }
        }
    }

    WorkingSetList->NextSlot = TryToFree;

    //
    // See if the working set list can be contracted.
    //
    // Make sure we are at least a page above the working set maximum.
    //

    if (WorkingSetList->FirstDynamic == WsInfo->WorkingSetSize) {
        MiRemoveWorkingSetPages (WsInfo);
    }
    else {

        if ((WsInfo->WorkingSetSize + 15 + (PAGE_SIZE / sizeof(MMWSLE))) <
                                                WorkingSetList->LastEntry) {
            if ((WsInfo->MaximumWorkingSetSize + 15 + (PAGE_SIZE / sizeof(MMWSLE))) <
                 WorkingSetList->LastEntry ) {

                MiRemoveWorkingSetPages (WsInfo);
            }
        }
    }

    return Reduction - NumberLeftToRemove;
}

VOID
MiEliminateWorkingSetEntry (
    IN WSLE_NUMBER WorkingSetIndex,
    IN PMMPTE PointerPte,
    IN PMMPFN Pfn,
    IN PMMWSLE Wsle
    )

/*++

Routine Description:

    This routine removes the specified working set list entry
    from the working set, flushes the TB for the page, decrements
    the share count for the physical page, and, if necessary turns
    the PTE into a transition PTE.

Arguments:

    WorkingSetIndex - Supplies the working set index to remove.

    PointerPte - Supplies a pointer to the PTE corresponding to the virtual
                 address in the working set.

    Pfn - Supplies a pointer to the PFN element corresponding to the PTE.

    Wsle - Supplies a pointer to the first working set list entry for this
           working set.

Return Value:

    None.

Environment:

    Kernel mode, Working set lock and PFN lock held, APCs disabled.

--*/

{
    PMMPTE ContainingPageTablePage;
    MMPTE TempPte;
    MMPTE PreviousPte;
    PFN_NUMBER PageFrameIndex;
    PFN_NUMBER PageTableFrameIndex;
    PEPROCESS Process;
    PVOID VirtualAddress;
    PMMPFN Pfn2;

    //
    // Remove the page from the working set.
    //

    MM_PFN_LOCK_ASSERT ();

    TempPte = *PointerPte;
    ASSERT (TempPte.u.Hard.Valid == 1);
    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (&TempPte);

    ASSERT (Pfn == MI_PFN_ELEMENT(PageFrameIndex));
    ASSERT (MI_IS_PFN_DELETED (Pfn) == 0);

#ifdef _X86_
#if DBG
#if !defined(NT_UP)
    if (TempPte.u.Hard.Writable == 1) {
        ASSERT (TempPte.u.Hard.Dirty == 1);
    }
#endif //NTUP
#endif //DBG
#endif //X86

    MI_MAKING_VALID_PTE_INVALID (FALSE);

    if (Pfn->u3.e1.PrototypePte) {

        //
        // This is a prototype PTE.  The PFN database does not contain
        // the contents of this PTE it contains the contents of the
        // prototype PTE.  This PTE must be reconstructed to contain
        // a pointer to the prototype PTE.
        //
        // The working set list entry contains information about
        // how to reconstruct the PTE.
        //

        if (Wsle[WorkingSetIndex].u1.e1.SameProtectAsProto == 0) {

            //
            // The protection for the prototype PTE is in the WSLE.
            //

            ASSERT (Wsle[WorkingSetIndex].u1.e1.Protection != 0);

            TempPte.u.Long = 0;
            TempPte.u.Soft.Protection =
                MI_GET_PROTECTION_FROM_WSLE (&Wsle[WorkingSetIndex]);
            TempPte.u.Soft.PageFileHigh = MI_PTE_LOOKUP_NEEDED;
        }
        else {

            //
            // The protection is in the prototype PTE.
            //

            TempPte.u.Long = MiProtoAddressForPte (Pfn->PteAddress);
        }
    
        TempPte.u.Proto.Prototype = 1;

        //
        // Decrement the share count of the containing page table
        // page as the PTE for the removed page is no longer valid
        // or in transition.
        //

        ContainingPageTablePage = MiGetPteAddress (PointerPte);
#if (_MI_PAGING_LEVELS >= 3)
        ASSERT (ContainingPageTablePage->u.Hard.Valid == 1);
#else
        if (ContainingPageTablePage->u.Hard.Valid == 0) {
            if (!NT_SUCCESS(MiCheckPdeForPagedPool (PointerPte))) {
                KeBugCheckEx (MEMORY_MANAGEMENT,
                              0x61940, 
                              (ULONG_PTR)PointerPte,
                              (ULONG_PTR)ContainingPageTablePage->u.Long,
                              (ULONG_PTR)MiGetVirtualAddressMappedByPte(PointerPte));
            }
        }
#endif
        PageTableFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (ContainingPageTablePage);
        Pfn2 = MI_PFN_ELEMENT (PageTableFrameIndex);
        MiDecrementShareCountInline (Pfn2, PageTableFrameIndex);

    }
    else {

        //
        // This is a private page, make it transition.
        //

        //
        // Assert that the share count is 1 for all user mode pages.
        //

        ASSERT ((Pfn->u2.ShareCount == 1) ||
                (Wsle[WorkingSetIndex].u1.VirtualAddress >
                        (PVOID)MM_HIGHEST_USER_ADDRESS));

        //
        // Set the working set index to zero.  This allows page table
        // pages to be brought back in with the proper WSINDEX.
        //

        ASSERT (Pfn->u1.WsIndex != 0);
        MI_ZERO_WSINDEX (Pfn);
        MI_MAKE_VALID_PTE_TRANSITION (TempPte,
                                      Pfn->OriginalPte.u.Soft.Protection);
    }

    PreviousPte = *PointerPte;

    ASSERT (PreviousPte.u.Hard.Valid == 1);

    MI_WRITE_INVALID_PTE (PointerPte, TempPte);

    //
    // Flush the translation buffer.
    //

    if (Wsle == MmWsle) {

        KeFlushSingleTb (Wsle[WorkingSetIndex].u1.VirtualAddress, FALSE);
    }
    else if (Wsle == MmSystemCacheWsle) {

        //
        // Must be the system cache.
        //

        KeFlushSingleTb (Wsle[WorkingSetIndex].u1.VirtualAddress, TRUE);
    }
    else {

        //
        // Must be a session space.
        //

        MI_FLUSH_SINGLE_SESSION_TB (Wsle[WorkingSetIndex].u1.VirtualAddress);
    }

    ASSERT (PreviousPte.u.Hard.Valid == 1);

    //
    // A page is being removed from the working set, on certain
    // hardware the dirty bit should be ORed into the modify bit in
    // the PFN element.
    //

    MI_CAPTURE_DIRTY_BIT_TO_PFN (&PreviousPte, Pfn);

    //
    // If the PTE indicates the page has been modified (this is different
    // from the PFN indicating this), then ripple it back to the write watch
    // bitmap now since we are still in the correct process context.
    //

    if ((Pfn->u3.e1.PrototypePte == 0) && (MI_IS_PTE_DIRTY(PreviousPte))) {

        Process = PsGetCurrentProcess ();

        if (Process->Flags & PS_PROCESS_FLAGS_USING_WRITE_WATCH) {

            //
            // This process has (or had) write watch VADs.  Search now
            // for a write watch region encapsulating the PTE being
            // invalidated.
            //

            VirtualAddress = MiGetVirtualAddressMappedByPte (PointerPte);
            MiCaptureWriteWatchDirtyBit (Process, VirtualAddress);
        }
    }

    //
    // Decrement the share count on the page.  Note that for a
    // private page, the page table page is still needed because the
    // page is in transition.
    //

    MiDecrementShareCountInline (Pfn, PageFrameIndex);

    return;
}

VOID
MiRemoveWorkingSetPages (
    IN PMMSUPPORT WsInfo
    )

/*++

Routine Description:

    This routine compresses the WSLEs into the front of the working set
    and frees the pages for unneeded working set entries.

Arguments:

    WsInfo - Supplies a pointer to the working set structure to compress.

Return Value:

    None.

Environment:

    Kernel mode, Working set lock held, APCs disabled.

--*/

{
    LOGICAL MovedOne;
    PFN_NUMBER PageFrameIndex;
    PMMWSLE FreeEntry;
    PMMWSLE LastEntry;
    PMMWSLE Wsle;
    WSLE_NUMBER DynamicEntries;
    WSLE_NUMBER LockedEntries;
    WSLE_NUMBER FreeIndex;
    WSLE_NUMBER LastIndex;
    PMMPTE LastPte;
    PMMPTE PointerPte;
    PMMPFN Pfn1;
    ULONG NewSize;
    PMMWSLE_HASH Table;
    MMWSLE WsleContents;
    PMMWSL WorkingSetList;

    WorkingSetList = WsInfo->VmWorkingSetList;

#if DBG
    MiCheckNullIndex (WorkingSetList);
#endif

    //
    // Check to see if the WSLE hash table should be contracted.
    //

    if (WorkingSetList->HashTable) {

        Table = WorkingSetList->HashTable;

#if DBG
        if ((PVOID)(&Table[WorkingSetList->HashTableSize]) < WorkingSetList->HighestPermittedHashAddress) {
            ASSERT (MiIsAddressValid (&Table[WorkingSetList->HashTableSize], FALSE) == FALSE);
        }
#endif

        if (WsInfo->WorkingSetSize < 200) {
            NewSize = 0;
        }
        else {
            NewSize = PtrToUlong(PAGE_ALIGN ((WorkingSetList->NonDirectCount * 2 *
                                       sizeof(MMWSLE_HASH)) + PAGE_SIZE - 1));
    
            NewSize = NewSize / sizeof(MMWSLE_HASH);
        }

        if (NewSize < WorkingSetList->HashTableSize) {

            if (NewSize != 0) {
                WsInfo->Flags.GrowWsleHash = 1;
            }

            //
            // Remove pages from hash table.
            //

            ASSERT (((ULONG_PTR)&WorkingSetList->HashTable[NewSize] &
                                                    (PAGE_SIZE - 1)) == 0);

            PointerPte = MiGetPteAddress (&WorkingSetList->HashTable[NewSize]);

            LastPte = MiGetPteAddress (WorkingSetList->HighestPermittedHashAddress);
            //
            // Set the hash table to null indicating that no hashing
            // is going on.
            //

            WorkingSetList->HashTable = NULL;
            WorkingSetList->HashTableSize = NewSize;

            MiDeletePteRange (WsInfo, PointerPte, LastPte, FALSE);
        }
#if (_MI_PAGING_LEVELS >= 4)

        //
        // For NT64, the page tables and page directories are also
        // deleted during contraction.
        //

        ASSERT ((MiGetPxeAddress(&Table[WorkingSetList->HashTableSize])->u.Hard.Valid == 0) ||
                (MiGetPpeAddress(&Table[WorkingSetList->HashTableSize])->u.Hard.Valid == 0) ||
                (MiGetPdeAddress(&Table[WorkingSetList->HashTableSize])->u.Hard.Valid == 0) ||
                (MiGetPteAddress(&Table[WorkingSetList->HashTableSize])->u.Hard.Valid == 0));

#elif (_MI_PAGING_LEVELS >= 3)

        //
        // For NT64, the page tables and page directories are also
        // deleted during contraction.
        //

        ASSERT ((MiGetPpeAddress(&Table[WorkingSetList->HashTableSize])->u.Hard.Valid == 0) ||
                (MiGetPdeAddress(&Table[WorkingSetList->HashTableSize])->u.Hard.Valid == 0) ||
                (MiGetPteAddress(&Table[WorkingSetList->HashTableSize])->u.Hard.Valid == 0));

#else

        ASSERT ((&Table[WorkingSetList->HashTableSize] == WorkingSetList->HighestPermittedHashAddress) || (MiGetPteAddress(&Table[WorkingSetList->HashTableSize])->u.Hard.Valid == 0));

#endif
    }

    //
    // Compress all the valid working set entries to the front of the list.
    //

    Wsle = WorkingSetList->Wsle;

    LockedEntries = WorkingSetList->FirstDynamic;

    if (WsInfo == &MmSystemCacheWs) {

        //
        // The first entry of the system cache working set list is never used
        // because WSL index 0 in a PFN is treated specially by the fault
        // processing code (and trimming) to mean that the entry should be
        // inserted into the WSL by the current thread.
        //
        // This is not an issue for process or session working sets because
        // for them, entry 0 is the top level page directory which must already
        // be resident in order for the process to even get to run (ie: so
        // the process cannot fault on it).
        //

        ASSERT (WorkingSetList->FirstDynamic != 0);

        LockedEntries -= 1;
    }

    ASSERT (WsInfo->WorkingSetSize >= LockedEntries);

    MovedOne = FALSE;
    DynamicEntries = WsInfo->WorkingSetSize - LockedEntries;

    if (DynamicEntries == 0) {

        //
        // If the only pages in the working set are locked pages (that
        // is all pages are BEFORE first dynamic, just reorganize the
        // free list).
        //

        LastIndex = WorkingSetList->FirstDynamic;
        LastEntry = &Wsle[LastIndex];
    }
    else {

        //
        // Start from the first dynamic and move towards the end looking
        // for free entries.  At the same time start from the end and
        // move towards first dynamic looking for valid entries.
        //

        FreeIndex = WorkingSetList->FirstDynamic;
        FreeEntry = &Wsle[FreeIndex];
        LastIndex = WorkingSetList->LastEntry;
        LastEntry = &Wsle[LastIndex];

        while (FreeEntry < LastEntry) {
            if (FreeEntry->u1.e1.Valid == 1) {
                FreeEntry += 1;
                FreeIndex += 1;
                DynamicEntries -= 1;
            }
            else if (LastEntry->u1.e1.Valid == 0) {
                LastEntry -= 1;
                LastIndex -= 1;
            }
            else {

                //
                // Move the WSLE at LastEntry to the free slot at FreeEntry.
                //

                MovedOne = TRUE;
                WsleContents = *LastEntry;
                PointerPte = MiGetPteAddress (LastEntry->u1.VirtualAddress);
                ASSERT (PointerPte->u.Hard.Valid == 1);
                PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

#if defined (_MI_DEBUG_WSLE)
                // Set these so the traces make more sense and no false dup hits...
                LastEntry->u1.Long = 0xb1b1b100;
#endif
                MI_LOG_WSLE_CHANGE (WorkingSetList, FreeIndex, WsleContents);

                *FreeEntry = WsleContents;

                if (WsleContents.u1.e1.Direct) {
                    Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);
                    Pfn1->u1.WsIndex = FreeIndex;
#if defined (_MI_DEBUG_WSLE)
                    WsleContents.u1.Long = 0xb1b1b100;
                    MI_LOG_WSLE_CHANGE (WorkingSetList, LastIndex, WsleContents);
#endif
                }
                else {

                    //
                    // This last working set entry is not direct.
                    // Remove it from there and re-insert it in the hash at the
                    // lowest free slot.
                    //

                    MiRemoveWsle (LastIndex, WorkingSetList);
                    WorkingSetList->NonDirectCount += 1;
                    MiInsertWsleHash (FreeIndex, WsInfo);
                }

                MI_SET_PTE_IN_WORKING_SET (PointerPte, FreeIndex);
                LastEntry->u1.Long = 0;
                LastEntry -= 1;
                LastIndex -= 1;
                FreeEntry += 1;
                FreeIndex += 1;
                DynamicEntries -= 1;
            }

            if (DynamicEntries == 0) {

                //
                // The last dynamic entry has been processed, no need to look
                // at any more - the rest are all invalid.
                //

                LastEntry = FreeEntry;
                LastIndex = FreeIndex;
                break;
            }
        }
    }

    //
    // Reorganize the free list.  Make last entry the first free.
    //

    ASSERT (((LastEntry - 1)->u1.e1.Valid == 1) ||
            (WsInfo->WorkingSetSize == 0) ||
            ((WsInfo == &MmSystemCacheWs) && (LastEntry - 1 == WorkingSetList->Wsle)));

    if (LastEntry->u1.e1.Valid == 1) {
        LastEntry += 1;
        LastIndex += 1;
    }

    ASSERT (((LastEntry - 1)->u1.e1.Valid == 1) || (WsInfo->WorkingSetSize == 0));

    ASSERT ((MiIsAddressValid (LastEntry, FALSE) == FALSE) || (LastEntry->u1.e1.Valid == 0));

    //
    // If the working set valid & free entries are already compressed optimally
    // (or fit into a single page) then bail.
    //

    if ((MovedOne == FALSE) &&

        ((WorkingSetList->LastInitializedWsle + 1 == (PAGE_SIZE - BYTE_OFFSET (MmWsle)) / sizeof (MMWSLE)) ||

         ((WorkingSetList->FirstFree == LastIndex) &&
         ((WorkingSetList->LastEntry == LastIndex - 1) ||
         (WorkingSetList->LastEntry == WorkingSetList->FirstDynamic))))) {

#if DBG
        while (LastIndex < WorkingSetList->LastInitializedWsle) {
            ASSERT (LastEntry->u1.e1.Valid == 0);
            LastIndex += 1;
            LastEntry += 1;
        }
#endif

        return;
    }

    WorkingSetList->LastEntry = LastIndex - 1;
    if (WorkingSetList->FirstFree != WSLE_NULL_INDEX) {
        WorkingSetList->FirstFree = LastIndex;
    }

    //
    // Point free entry to the first invalid page.
    //

    FreeEntry = LastEntry;

    while (LastIndex < WorkingSetList->LastInitializedWsle) {

        //
        // Put the remainder of the WSLEs on the free list.
        //

        ASSERT (LastEntry->u1.e1.Valid == 0);
        LastIndex += 1;
        LastEntry->u1.Long = LastIndex << MM_FREE_WSLE_SHIFT;
        LastEntry += 1;
    }

    //
    // Calculate the start and end of the working set pages at the end
    // that we will delete shortly.  Don't delete them until after
    // LastInitializedWsle is reduced so that debug WSL validation code
    // in MiReleaseWsle (called from MiDeletePte) will see a
    // consistent snapshot.
    //

    LastPte = MiGetPteAddress (&Wsle[WorkingSetList->LastInitializedWsle]) + 1;

    PointerPte = MiGetPteAddress (FreeEntry) + 1;

    //
    // Mark the last working set entry in the list as free.  Note if the list
    // has no free entries, the marker is in FirstFree (and cannot be put into
    // the list anyway because there is no space).
    //

    if (WorkingSetList->FirstFree == WSLE_NULL_INDEX) {
        FreeEntry -= 1;
        PointerPte -= 1;
    }
    else {

        ASSERT (WorkingSetList->FirstFree >= WorkingSetList->FirstDynamic);
    
        LastEntry = (PMMWSLE)((PCHAR)(PAGE_ALIGN(FreeEntry)) + PAGE_SIZE);
        LastEntry -= 1;
    
        ASSERT (LastEntry->u1.e1.Valid == 0);
    
        //
        // Insert the end of list delimiter.
        //

        LastEntry->u1.Long = WSLE_NULL_INDEX << MM_FREE_WSLE_SHIFT;
        ASSERT (LastEntry > &Wsle[0]);
    
        ASSERT (WsInfo->WorkingSetSize <= (WSLE_NUMBER)(LastEntry - &Wsle[0] + 1));
    
        WorkingSetList->LastInitializedWsle = (WSLE_NUMBER)(LastEntry - &Wsle[0]);
    }

    WorkingSetList->NextSlot = WorkingSetList->FirstDynamic;

    ASSERT (WorkingSetList->LastEntry <= WorkingSetList->LastInitializedWsle);

    ASSERT ((MiGetPteAddress(&Wsle[WorkingSetList->LastInitializedWsle]))->u.Hard.Valid == 1);
    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));
#if DBG
    MiCheckNullIndex (WorkingSetList);
#endif

    //
    // Delete the working set pages at the end.
    //

    ASSERT (WorkingSetList->FirstFree >= WorkingSetList->FirstDynamic);

    MiDeletePteRange (WsInfo, PointerPte, LastPte, FALSE);

    ASSERT (WorkingSetList->FirstFree >= WorkingSetList->FirstDynamic);

    ASSERT (WorkingSetList->LastEntry <= WorkingSetList->LastInitializedWsle);

    ASSERT ((MiGetPteAddress(&Wsle[WorkingSetList->LastInitializedWsle]))->u.Hard.Valid == 1);
    ASSERT ((WorkingSetList->FirstFree <= WorkingSetList->LastInitializedWsle) ||
            (WorkingSetList->FirstFree == WSLE_NULL_INDEX));
#if DBG
    MiCheckNullIndex (WorkingSetList);
#endif
    return;
}


NTSTATUS
MiEmptyWorkingSet (
    IN PMMSUPPORT WsInfo,
    IN LOGICAL NeedLock
    )

/*++

Routine Description:

    This routine frees all pages from the working set.

Arguments:

    WsInfo - Supplies the working set information entry to trim.

    NeedLock - Supplies TRUE if the caller needs us to acquire mutex
               synchronization for the working set.  Supplies FALSE if the
               caller has already acquired synchronization.

Return Value:

    Status of operation.

Environment:

    Kernel mode. No locks.  For session operations, the caller is responsible
    for attaching into the proper session.

--*/

{
    PEPROCESS Process;
    PMMPTE PointerPte;
    WSLE_NUMBER Entry;
    WSLE_NUMBER FirstDynamic;
    PMMWSL WorkingSetList;
    PMMWSLE Wsle;
    PMMPFN Pfn1;
    PFN_NUMBER PageFrameIndex;
    MMWSLE_FLUSH_LIST WsleFlushList;

    WsleFlushList.Count = 0;

    WorkingSetList = WsInfo->VmWorkingSetList;
    Wsle = WorkingSetList->Wsle;

    if (NeedLock == TRUE) {
        LOCK_WORKING_SET (WsInfo);
    }
    else {
        MM_WS_LOCK_ASSERT (WsInfo);
    }

    if (WsInfo->VmWorkingSetList == MmWorkingSetList) {
        Process = PsGetCurrentProcess ();
        if (Process->Flags & PS_PROCESS_FLAGS_VM_DELETED) {
            if (NeedLock == TRUE) {
                UNLOCK_WORKING_SET (WsInfo);
            }
            return STATUS_PROCESS_IS_TERMINATING;
        }
    }

    //
    // Attempt to remove the pages starting at the top to keep the free list
    // compressed as entries are added to the freelist in FILO order.
    //

    FirstDynamic = WorkingSetList->FirstDynamic;

    for (Entry = WorkingSetList->LastEntry; Entry >= FirstDynamic; Entry -= 1) {

        if (Wsle[Entry].u1.e1.Valid != 0) {
            PERFINFO_PAGE_INFO_DECL();

            PERFINFO_GET_PAGE_INFO (PointerPte);

            if (MiTrimRemovalPagesOnly == TRUE) {

                PointerPte = MiGetPteAddress (Wsle[Entry].u1.VirtualAddress);

                ASSERT (PointerPte->u.Hard.Valid == 1);
                PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
                Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);
                if (Pfn1->u3.e1.RemovalRequested == 0) {
                    Pfn1 = MI_PFN_ELEMENT (Pfn1->u4.PteFrame);
                    if (Pfn1->u3.e1.RemovalRequested == 0) {
#if (_MI_PAGING_LEVELS >= 3)
                        Pfn1 = MI_PFN_ELEMENT (Pfn1->u4.PteFrame);
                        if (Pfn1->u3.e1.RemovalRequested == 0) {
                            continue;
                        }
#else
                        continue;
#endif
                    }
                }
            }

            WsleFlushList.FlushIndex[WsleFlushList.Count] = Entry;
            WsleFlushList.Count += 1;

            if (WsleFlushList.Count == MM_MAXIMUM_FLUSH_COUNT) {
                MiFreeWsleList (WsInfo, &WsleFlushList);
                WsleFlushList.Count = 0;
            }
        }
    }

    if (WsleFlushList.Count != 0) {
        MiFreeWsleList (WsInfo, &WsleFlushList);
    }

    MiRemoveWorkingSetPages (WsInfo);

    if (NeedLock == TRUE) {
        UNLOCK_WORKING_SET (WsInfo);
    }

    return STATUS_SUCCESS;
}


#if DBG
VOID
MiCheckNullIndex (
    IN PMMWSL WorkingSetList
    )

{
    PMMWSLE Wsle;
    ULONG j;
    ULONG Nulls = 0;

    Wsle = WorkingSetList->Wsle;
    for (j = 0;j <= WorkingSetList->LastInitializedWsle; j += 1) {
        if ((((Wsle[j].u1.Long)) >> MM_FREE_WSLE_SHIFT) == WSLE_NULL_INDEX) {
            Nulls += 1;
        }
    }
    ASSERT ((Nulls == 1) || (WorkingSetList->FirstFree == WSLE_NULL_INDEX));
    return;
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\amd64\dataamd.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    dataamd.c

Abstract:

    This module contains the private hardware specific global storage for
    the memory management subsystem.

Author:

    Landy Wang (landyw) 08-Apr-2000

Revision History:

--*/

#include "mi.h"

//
// A zero Pte.
//

const MMPTE ZeroPte = { 0 };

//
// A kernel zero PTE.
//

const MMPTE ZeroKernelPte = {0x0};

MMPTE ValidKernelPte = { MM_PTE_VALID_MASK |
                         MM_PTE_WRITE_MASK |
                         MM_PTE_GLOBAL_MASK |
                         MM_PTE_DIRTY_MASK |
                         MM_PTE_ACCESS_MASK };

const MMPTE ValidKernelPteLocal = { MM_PTE_VALID_MASK |
                                    MM_PTE_WRITE_MASK |
                                    MM_PTE_DIRTY_MASK |
                                    MM_PTE_ACCESS_MASK };


const MMPTE ValidUserPte = { MM_PTE_VALID_MASK |
                             MM_PTE_WRITE_MASK |
                             MM_PTE_OWNER_MASK |
                             MM_PTE_DIRTY_MASK |
                             MM_PTE_ACCESS_MASK };


const MMPTE ValidPtePte = { MM_PTE_VALID_MASK |
                            MM_PTE_WRITE_MASK |
                            MM_PTE_DIRTY_MASK |
                            MM_PTE_ACCESS_MASK };


const MMPTE ValidPdePde = { MM_PTE_VALID_MASK |
                            MM_PTE_WRITE_MASK |
                            MM_PTE_DIRTY_MASK |
                            MM_PTE_ACCESS_MASK };


MMPTE ValidKernelPde = { MM_PTE_VALID_MASK |
                         MM_PTE_WRITE_MASK |
                         MM_PTE_GLOBAL_MASK |
                         MM_PTE_DIRTY_MASK |
                         MM_PTE_ACCESS_MASK };

const MMPTE ValidKernelPdeLocal = { MM_PTE_VALID_MASK |
                                    MM_PTE_WRITE_MASK |
                                    MM_PTE_DIRTY_MASK |
                                    MM_PTE_ACCESS_MASK };


MMPTE DemandZeroPde = { MM_READWRITE << MM_PROTECT_FIELD_SHIFT };


const MMPTE DemandZeroPte = { MM_READWRITE << MM_PROTECT_FIELD_SHIFT };


const MMPTE TransitionPde = { MM_PTE_WRITE_MASK |
                              MM_PTE_OWNER_MASK |
                              MM_PTE_TRANSITION_MASK |
                              MM_READWRITE << MM_PROTECT_FIELD_SHIFT };

MMPTE PrototypePte = { (MI_PTE_LOOKUP_NEEDED << 32) |
                       MM_PTE_PROTOTYPE_MASK |
                       MM_READWRITE << MM_PROTECT_FIELD_SHIFT };

//
// PTE which generates an access violation when referenced.
//

const MMPTE NoAccessPte = {MM_NOACCESS << MM_PROTECT_FIELD_SHIFT };

//
// Pool start and end.
//

PVOID MmNonPagedPoolStart;

PVOID MmNonPagedPoolEnd = (PVOID)MM_NONPAGED_POOL_END;

PVOID MmPagedPoolStart =  (PVOID)MM_PAGED_POOL_START;

PVOID MmPagedPoolEnd;

//
// Color tables for free and zeroed pages.
//

PMMCOLOR_TABLES MmFreePagesByColor[2];

//
// Color tables for modified pages destined for the paging file.
//

MMPFNLIST MmModifiedPageListByColor[MM_MAXIMUM_NUMBER_OF_COLORS] = {
                            0, ModifiedPageList, MM_EMPTY_LIST, MM_EMPTY_LIST};

//
// Count of the number of modified pages destined for the paging file.
//

PFN_NUMBER MmTotalPagesForPagingFile = 0;

//
// PTE reserved for mapping pages for the debugger.
//

PMMPTE MmDebugPte;
PVOID MmDebugVa;

//
// 16 PTEs reserved for mapping MDLs (64k max).
//

PMMPTE MmCrashDumpPte;
PVOID MmCrashDumpVa;

ULONG_PTR MmBootImageSize;
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\zeropage.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    zeropage.c

Abstract:

    This module contains the zero page thread for memory management.

Author:

    Lou Perazzoli (loup) 6-Apr-1991
    Landy Wang (landyw) 02-June-1997

Revision History:

--*/

#include "mi.h"

#define MM_ZERO_PAGE_OBJECT     0
#define PO_SYS_IDLE_OBJECT      1
#define NUMBER_WAIT_OBJECTS     2

#define MACHINE_ZERO_PAGE(ZeroBase,NumberOfBytes) KeZeroPagesFromIdleThread(ZeroBase,NumberOfBytes)

LOGICAL MiZeroingDisabled = FALSE;

#if !defined(NT_UP)

LONG MiNextZeroProcessor = (LONG)-1;

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,MiStartZeroPageWorkers)
#endif

#endif

VOID
MmZeroPageThread (
    VOID
    )

/*++

Routine Description:

    Implements the NT zeroing page thread.  This thread runs
    at priority zero and removes a page from the free list,
    zeroes it, and places it on the zeroed page list.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode.

--*/

{
    KIRQL OldIrql;
    PFN_NUMBER PageFrame1;
    PFN_NUMBER PageFrame;
    PMMPFN Pfn1;
    PKTHREAD Thread;
    PVOID ZeroBase;
    PVOID WaitObjects[NUMBER_WAIT_OBJECTS];
    NTSTATUS Status;
    PVOID StartVa;
    PVOID EndVa;
    PFN_COUNT PagesToZero;
    PFN_COUNT MaximumPagesToZero;
    ULONG Color;
    ULONG StartColor;
    PMMPFN PfnAllocation;

#if defined(MI_MULTINODE)

    ULONG i;
    ULONG n;
    ULONG LastNodeZeroing;

    n = 0;
    LastNodeZeroing = 0;
#endif

    //
    // Before this becomes the zero page thread, free the kernel
    // initialization code.
    //

    MiFindInitializationCode (&StartVa, &EndVa);

    if (StartVa != NULL) {
        MiFreeInitializationCode (StartVa, EndVa);
    }

    MaximumPagesToZero = 1;

#if !defined(NT_UP)

    //
    // Zero groups of pages at once to reduce PFN lock contention.
    // Charge commitment as well as resident available up front since
    // zeroing may get starved priority-wise.
    //
    // Note using MmSecondaryColors here would be excessively wasteful
    // on NUMA systems.  MmSecondaryColorMask + 1 is correct for all platforms.
    //

    PagesToZero = MmSecondaryColorMask + 1;

    if (PagesToZero > NUMBER_OF_ZEROING_PTES) {
        PagesToZero = NUMBER_OF_ZEROING_PTES;
    }

    if (MiChargeCommitment (PagesToZero, NULL) == TRUE) {

        LOCK_PFN (OldIrql);

        //
        // Check to make sure the physical pages are available.
        //

        if (MI_NONPAGABLE_MEMORY_AVAILABLE() > (SPFN_NUMBER)(PagesToZero)) {
            MI_DECREMENT_RESIDENT_AVAILABLE (PagesToZero,
                                    MM_RESAVAIL_ALLOCATE_ZERO_PAGE_CLUSTERS);
            MaximumPagesToZero = PagesToZero;
        }

        UNLOCK_PFN (OldIrql);
    }

#endif

    //
    // The following code sets the current thread's base priority to zero
    // and then sets its current priority to zero. This ensures that the
    // thread always runs at a priority of zero.
    //

    Thread = KeGetCurrentThread ();
    Thread->BasePriority = 0;
    KeSetPriorityThread (Thread, 0);

    //
    // Initialize wait object array for multiple wait
    //

    WaitObjects[MM_ZERO_PAGE_OBJECT] = &MmZeroingPageEvent;
    WaitObjects[PO_SYS_IDLE_OBJECT] = &PoSystemIdleTimer;

    Color = 0;
    PfnAllocation = (PMMPFN) MM_EMPTY_LIST;

    //
    // Loop forever zeroing pages.
    //

    do {

        //
        // Wait until there are at least MmZeroPageMinimum pages
        // on the free list.
        //

        Status = KeWaitForMultipleObjects (NUMBER_WAIT_OBJECTS,
                                           WaitObjects,
                                           WaitAny,
                                           WrFreePage,
                                           KernelMode,
                                           FALSE,
                                           NULL,
                                           NULL);

        if (Status == PO_SYS_IDLE_OBJECT) {
            PoSystemIdleWorker (TRUE);
            continue;
        }

        PagesToZero = 0;

        LOCK_PFN (OldIrql);

        do {

            if (MmFreePageListHead.Total == 0) {

                //
                // No pages on the free list at this time, wait for
                // some more.
                //

                MmZeroingPageThreadActive = FALSE;
                UNLOCK_PFN (OldIrql);
                break;
            }

            if (MiZeroingDisabled == TRUE) {
                MmZeroingPageThreadActive = FALSE;
                UNLOCK_PFN (OldIrql);
                KeDelayExecutionThread (KernelMode,
                                        FALSE,
                                        (PLARGE_INTEGER)&MmHalfSecond);
                break;
            }

#if defined(MI_MULTINODE)

            //
            // In a multinode system, zero pages by node.  Resume on
            // the last node examined, find a node with free pages that
            // need to be zeroed.
            //

            if (KeNumberNodes > 1) {

                n = LastNodeZeroing;

                for (i = 0; i < KeNumberNodes; i += 1) {
                    if (KeNodeBlock[n]->FreeCount[FreePageList] != 0) {
                        break;
                    }
                    n = (n + 1) % KeNumberNodes;
                }

                ASSERT (i != KeNumberNodes);
                ASSERT (KeNodeBlock[n]->FreeCount[FreePageList] != 0);

                if (n != LastNodeZeroing) {
                    Color = KeNodeBlock[n]->MmShiftedColor;
                }
            }
#endif
                
            ASSERT (PagesToZero == 0);

            StartColor = Color;

            do {
                            
                PageFrame = MmFreePagesByColor[FreePageList][Color].Flink;

                if (PageFrame != MM_EMPTY_LIST) {

                    PageFrame1 = MiRemoveAnyPage (Color);

                    ASSERT (PageFrame == PageFrame1);

                    Pfn1 = MI_PFN_ELEMENT (PageFrame);

                    Pfn1->u1.Flink = (PFN_NUMBER) PfnAllocation;

                    //
                    // Temporarily mark the page as bad so that contiguous
                    // memory allocators won't steal it when we release
                    // the PFN lock below.  This also prevents the
                    // MiIdentifyPfn code from trying to identify it as
                    // we haven't filled in all the fields yet.
                    //

                    Pfn1->u3.e1.PageLocation = BadPageList;

                    PfnAllocation = Pfn1;

                    PagesToZero += 1;
                }

                //
                // March to the next color - this will be used to finish
                // filling the current chunk or to start the next one.
                //

                Color = (Color & ~MmSecondaryColorMask) |
                        ((Color + 1) & MmSecondaryColorMask);

                if (PagesToZero == MaximumPagesToZero) {
                    break;
                }

                if (Color == StartColor) {
                    break;
                }

            } while (TRUE);

            ASSERT (PfnAllocation != (PMMPFN) MM_EMPTY_LIST);

            UNLOCK_PFN (OldIrql);

            ZeroBase = MiMapPagesToZeroInHyperSpace (PfnAllocation, PagesToZero);

#if defined(MI_MULTINODE)

            //
            // If a node switch is in order, do it now that the PFN
            // lock has been released.
            //

            if ((KeNumberNodes > 1) && (n != LastNodeZeroing)) {
                LastNodeZeroing = n;
                KeFindFirstSetLeftAffinity (KeNodeBlock[n]->ProcessorMask, &i);
                KeSetIdealProcessorThread (Thread, (UCHAR)i);
            }

#endif

            MACHINE_ZERO_PAGE (ZeroBase, PagesToZero << PAGE_SHIFT);

#if 0
            ASSERT (RtlCompareMemoryUlong (ZeroBase, PagesToZero << PAGE_SHIFT, 0) == PagesToZero << PAGE_SHIFT);
#endif

            MiUnmapPagesInZeroSpace (ZeroBase, PagesToZero);

            PagesToZero = 0;

            Pfn1 = PfnAllocation;

            LOCK_PFN (OldIrql);

            do {

                PageFrame = MI_PFN_ELEMENT_TO_INDEX (Pfn1);

                Pfn1 = (PMMPFN) Pfn1->u1.Flink;

                MiInsertPageInList (&MmZeroedPageListHead, PageFrame);

            } while (Pfn1 != (PMMPFN) MM_EMPTY_LIST);

            //
            // We just finished processing a cluster of pages - briefly
            // release the PFN lock to allow other threads to make progress.
            //

            UNLOCK_PFN (OldIrql);

            PfnAllocation = (PMMPFN) MM_EMPTY_LIST;

            LOCK_PFN (OldIrql);

        } while (TRUE);

    } while (TRUE);
}

#if !defined(NT_UP)


VOID
MiZeroPageWorker (
    IN PVOID Context
    )

/*++

Routine Description:

    This routine is the worker routine executed by all processors so that
    initial page zeroing occurs in parallel.

Arguments:

    Context - Supplies a pointer to the workitem.

Return Value:

    None.

Environment:

    Kernel mode initialization time, PASSIVE_LEVEL.  Because this is INIT
    only code, don't bother charging commit for the pages.

--*/

{
    MMPTE TempPte;
    PMMPTE PointerPte;
    KAFFINITY Affinity;
    KIRQL OldIrql;
    PVOID ZeroBase;
    PKTHREAD Thread;
    CCHAR OldProcessor;
    SCHAR OldBasePriority;
    KPRIORITY OldPriority;
    PWORK_QUEUE_ITEM WorkItem;
    PMMPFN Pfn1;
    PFN_NUMBER NewPage;
    PFN_NUMBER PageFrame;
#if defined(MI_MULTINODE)
    PKNODE Node;
    ULONG Color;
    ULONG FinalColor;
#endif

    WorkItem = (PWORK_QUEUE_ITEM) Context;

    ExFreePool (WorkItem);

    TempPte = ValidKernelPte;

    //
    // The following code sets the current thread's base and current priorities
    // to one so all other code (except the zero page thread) can preempt it.
    //

    Thread = KeGetCurrentThread ();
    OldBasePriority = Thread->BasePriority;
    Thread->BasePriority = 1;
    OldPriority = KeSetPriorityThread (Thread, 1);

    //
    // Dispatch each worker thread to the next processor in line.
    //

    OldProcessor = (CCHAR) InterlockedIncrement (&MiNextZeroProcessor);

    Affinity = AFFINITY_MASK (OldProcessor);
    Affinity = KeSetAffinityThread (Thread, Affinity);

    //
    // Zero all local pages.
    //

#if defined(MI_MULTINODE)
    if (KeNumberNodes > 1) {
        Node = KeGetCurrentNode ();
        Color = Node->MmShiftedColor;
        FinalColor = Color + MmSecondaryColorMask + 1;
    }
    else {
        SATISFY_OVERZEALOUS_COMPILER (Node = NULL);
        SATISFY_OVERZEALOUS_COMPILER (Color = 0);
        SATISFY_OVERZEALOUS_COMPILER (FinalColor = 0);
    }
#endif

    LOCK_PFN (OldIrql);

    do {

#if defined(MI_MULTINODE)

        //
        // In a multinode system, zero pages by node.
        //

        if (KeNumberNodes > 1) {

            if (Node->FreeCount[FreePageList] == 0) {

                //
                // No pages on the free list at this time, bail.
                //

                UNLOCK_PFN (OldIrql);
                break;
            }

            //
            // Must start with a color MiRemoveAnyPage will
            // satisfy from the free list otherwise it will
            // return an already zeroed page.
            //

            while (MmFreePagesByColor[FreePageList][Color].Flink == MM_EMPTY_LIST) {
                //
                // No pages on this free list color, march to the next one.
                //

                Color += 1;
                if (Color == FinalColor) {
                    UNLOCK_PFN (OldIrql);
                    goto ZeroingFinished;
                }
            }

            PageFrame = MiRemoveAnyPage (Color);
        }
        else {
#endif
        if (MmFreePageListHead.Total == 0) {

            //
            // No pages on the free list at this time, bail.
            //

            UNLOCK_PFN (OldIrql);
            break;
        }

        PageFrame = MmFreePageListHead.Flink;
        ASSERT (PageFrame != MM_EMPTY_LIST);

        Pfn1 = MI_PFN_ELEMENT(PageFrame);

        NewPage = MiRemoveAnyPage (MI_GET_COLOR_FROM_LIST_ENTRY(PageFrame, Pfn1));
        if (NewPage != PageFrame) {

            //
            // Someone has removed a page from the colored lists
            // chain without updating the freelist chain.
            //

            KeBugCheckEx (PFN_LIST_CORRUPT,
                          0x8F,
                          NewPage,
                          PageFrame,
                          0);
        }
#if defined(MI_MULTINODE)
        }
#endif

        //
        // Use system PTEs instead of hyperspace to zero the page so that
        // a spinlock (ie: interrupts blocked) is not held while zeroing.
        // Since system PTE acquisition is lock free and the TB lazy flushed,
        // this is perhaps the best path regardless.
        //

        UNLOCK_PFN (OldIrql);

        PointerPte = MiReserveSystemPtes (1, SystemPteSpace);

        if (PointerPte == NULL) {

            //
            // Put this page back on the freelist.
            //

            LOCK_PFN (OldIrql);

            MiInsertPageInFreeList (PageFrame);

            UNLOCK_PFN (OldIrql);

            break;
        }

        ASSERT (PointerPte->u.Hard.Valid == 0);

        ZeroBase = MiGetVirtualAddressMappedByPte (PointerPte);

        TempPte.u.Hard.PageFrameNumber = PageFrame;
        MI_WRITE_VALID_PTE (PointerPte, TempPte);

        KeZeroPages (ZeroBase, PAGE_SIZE);

        MiReleaseSystemPtes (PointerPte, 1, SystemPteSpace);

        LOCK_PFN (OldIrql);

        MiInsertPageInList (&MmZeroedPageListHead, PageFrame);

    } while (TRUE);

#if defined(MI_MULTINODE)
ZeroingFinished:
#endif

    //
    // Restore the entry thread priority and processor affinity.
    //

    KeSetAffinityThread (Thread, Affinity);

    KeSetPriorityThread (Thread, OldPriority);
    Thread->BasePriority = OldBasePriority;
}


VOID
MiStartZeroPageWorkers (
    VOID
    )

/*++

Routine Description:

    This routine starts the zero page worker threads.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode initialization phase 1, PASSIVE_LEVEL.

--*/

{
    ULONG i;
    PWORK_QUEUE_ITEM WorkItem;

    for (i = 0; i < (ULONG) KeNumberProcessors; i += 1) {

        WorkItem = ExAllocatePoolWithTag (NonPagedPool,
                                          sizeof (WORK_QUEUE_ITEM),
                                          'wZmM');

        if (WorkItem == NULL) {
            break;
        }

        ExInitializeWorkItem (WorkItem, MiZeroPageWorker, (PVOID) WorkItem);

        ExQueueWorkItem (WorkItem, CriticalWorkQueue);
    }
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\amd64\initamd.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    initamd.c

Abstract:

    This module contains the machine dependent initialization for the
    memory management component. It is specifically tailored to the
    AMD64 architecture.

Author:

    Landy Wang (landyw) 08-Apr-2000

Revision History:

--*/

#include "mi.h"

PFN_NUMBER
MxGetNextPage (
    IN PFN_NUMBER PagesNeeded
    );

PFN_NUMBER
MxPagesAvailable (
    VOID
    );

VOID
MxConvertToLargePage (
    IN PVOID VirtualAddress,
    IN PVOID EndVirtualAddress
    );

VOID
MxPopulatePageDirectories (
    IN PMMPTE StartPde,
    IN PMMPTE EndPde
    );

VOID
MiComputeInitialLargePage (
    VOID
    );

LOGICAL
MiIsRegularMemory (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock,
    IN PFN_NUMBER PageFrameIndex
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,MiInitMachineDependent)
#pragma alloc_text(INIT,MxGetNextPage)
#pragma alloc_text(INIT,MxPagesAvailable)
#pragma alloc_text(INIT,MxConvertToLargePage)
#pragma alloc_text(INIT,MiReportPhysicalMemory)
#pragma alloc_text(INIT,MxPopulatePageDirectories)
#pragma alloc_text(INIT,MiComputeInitialLargePage)
#pragma alloc_text(INIT,MiIsRegularMemory)
#endif

#define MM_LARGE_PAGE_MINIMUM  ((255*1024*1024) >> PAGE_SHIFT)

#define _x1mb (1024*1024)
#define _x1mbnp ((1024*1024) >> PAGE_SHIFT)
#define _x16mb (1024*1024*16)
#define _x16mbnp ((1024*1024*16) >> PAGE_SHIFT)
#define _x4gb (0x100000000UI64)

extern KEVENT MiImageMappingPteEvent;

//
// Local data.
//

PFN_NUMBER MiInitialLargePage;
PFN_NUMBER MiInitialLargePageSize;

PFN_NUMBER MxPfnAllocation;

PFN_NUMBER MiSlushDescriptorBase;
PFN_NUMBER MiSlushDescriptorCount;

PMEMORY_ALLOCATION_DESCRIPTOR MxFreeDescriptor;

MEMORY_ALLOCATION_DESCRIPTOR MxOldFreeDescriptor;

typedef struct _MI_LARGE_VA_RANGES {
    PVOID VirtualAddress;
    PVOID EndVirtualAddress;
} MI_LARGE_VA_RANGES, *PMI_LARGE_VA_RANGES;

//
// There are potentially 4 large page ranges:
//
// 1. PFN database
// 2. Initial nonpaged pool
// 3. Kernel code/data
// 4. HAL code/data
//

ULONG MxMapLargePages = 1;

#define MI_MAX_LARGE_VA_RANGES 2

ULONG MiLargeVaRangeIndex;
MI_LARGE_VA_RANGES MiLargeVaRanges[MI_MAX_LARGE_VA_RANGES];

#define MM_PFN_MAPPED_BY_PDE (MM_VA_MAPPED_BY_PDE >> PAGE_SHIFT)


PFN_NUMBER
MxGetNextPage (
    IN PFN_NUMBER PagesNeeded
    )

/*++

Routine Description:

    This function returns the next physical page number from the largest
    largest free descriptor.  If there are not enough physical pages left
    to satisfy the request then a bugcheck is executed since the system
    cannot be initialized.

Arguments:

    PagesNeeded - Supplies the number of pages needed.

Return Value:

    The base of the range of physically contiguous pages.

Environment:

    Kernel mode, Phase 0 only.

--*/

{
    PFN_NUMBER PageFrameIndex;

    //
    // Examine the free descriptor to see if enough usable memory is available.
    //

    if (PagesNeeded > MxFreeDescriptor->PageCount) {

        KeBugCheckEx (INSTALL_MORE_MEMORY,
                      MmNumberOfPhysicalPages,
                      MxFreeDescriptor->PageCount,
                      MxOldFreeDescriptor.PageCount,
                      PagesNeeded);
    }

    PageFrameIndex = MxFreeDescriptor->BasePage;

    MxFreeDescriptor->BasePage += (ULONG) PagesNeeded;
    MxFreeDescriptor->PageCount -= (ULONG) PagesNeeded;

    return PageFrameIndex;
}

PFN_NUMBER
MxPagesAvailable (
    VOID
    )

/*++

Routine Description:

    This function returns the number of pages available.
    
Arguments:

    None.

Return Value:

    The number of physically contiguous pages currently available.

Environment:

    Kernel mode, Phase 0 only.

--*/

{
    return MxFreeDescriptor->PageCount;
}


VOID
MxConvertToLargePage (
    IN PVOID VirtualAddress,
    IN PVOID EndVirtualAddress
    )

/*++

Routine Description:

    This function converts the backing for the supplied virtual address range
    to a large page mapping.
    
Arguments:

    VirtualAddress - Supplies the virtual address to convert to a large page.

    EndVirtualAddress - Supplies the end virtual address to convert to a
                        large page.

Return Value:

    None.

Environment:

    Kernel mode, Phase 1 only.

--*/

{
    ULONG i;
    MMPTE TempPde;
    PMMPTE PointerPde;
    PMMPTE LastPde;
    PMMPTE PointerPte;
    KIRQL OldIrql;
    PMMPFN Pfn1;
    PFN_NUMBER PageFrameIndex;
    LOGICAL ValidPteFound;
    PFN_NUMBER LargePageBaseFrame;

    ASSERT (MxMapLargePages != 0);

    PointerPde = MiGetPdeAddress (VirtualAddress);
    LastPde = MiGetPdeAddress (EndVirtualAddress);

    TempPde = ValidKernelPde;
    TempPde.u.Hard.LargePage = 1;
    TempPde.u.Hard.Global = 1;

    LOCK_PFN (OldIrql);

    for ( ; PointerPde <= LastPde; PointerPde += 1) {

        ASSERT (PointerPde->u.Hard.Valid == 1);

        if (PointerPde->u.Hard.LargePage == 1) {
            continue;
        }

        PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);

        //
        // Here's a nasty little hack - the page table page mapping the kernel
        // and HAL (built by the loader) does not necessarily fill all the
        // page table entries (ie: any number of leading entries may be zero).
        //
        // To deal with this, walk forward until a nonzero entry is found
        // and re-index the large page based on this.
        //

        ValidPteFound = FALSE;
        LargePageBaseFrame = (ULONG)-1;
        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
    
        ASSERT ((PageFrameIndex & (MM_PFN_MAPPED_BY_PDE - 1)) == 0);

        for (i = 0; i < PTE_PER_PAGE; i += 1) {

            ASSERT ((PointerPte->u.Long == ZeroKernelPte.u.Long) ||
                    (ValidPteFound == FALSE) ||
                    (PageFrameIndex == MI_GET_PAGE_FRAME_FROM_PTE (PointerPte)));
            if (PointerPte->u.Hard.Valid == 1) {
                if (ValidPteFound == FALSE) {
                    ValidPteFound = TRUE;
                    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
                    LargePageBaseFrame = PageFrameIndex - i;
                }
            }
            PointerPte += 1;
            PageFrameIndex += 1;
        }
    
        if (ValidPteFound == FALSE) {
            continue;
        }

        TempPde.u.Hard.PageFrameNumber = LargePageBaseFrame;

        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPde);

        MI_WRITE_VALID_PTE_NEW_PAGE (PointerPde, TempPde);

        KeFlushEntireTb (TRUE, TRUE);

        Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);
        Pfn1->u2.ShareCount = 0;
        Pfn1->u3.e2.ReferenceCount = 1;
        Pfn1->u3.e1.PageLocation = StandbyPageList;
        MI_SET_PFN_DELETED (Pfn1);
        MiDecrementReferenceCount (Pfn1, PageFrameIndex);
    }

    UNLOCK_PFN (OldIrql);
}
LOGICAL
MiIsRegularMemory (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock,
    IN PFN_NUMBER PageFrameIndex
    )

/*++

Routine Description:

    This routine checks whether the argument page frame index represents
    regular memory in the loader descriptor block.  It is only used very
    early during Phase0 init because the MmPhysicalMemoryBlock is not yet
    initialized.

Arguments:

    LoaderBlock  - Supplies a pointer to the firmware setup loader block.

    PageFrameIndex  - Supplies the page frame index to check.

Return Value:

    TRUE if the frame represents regular memory, FALSE if not.

Environment:

    Kernel mode.

--*/

{
    PLIST_ENTRY NextMd;
    PMEMORY_ALLOCATION_DESCRIPTOR MemoryDescriptor;

    NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;

    while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {

        MemoryDescriptor = CONTAINING_RECORD (NextMd,
                                              MEMORY_ALLOCATION_DESCRIPTOR,
                                              ListEntry);

        if (PageFrameIndex >= MemoryDescriptor->BasePage) {

            if (PageFrameIndex < MemoryDescriptor->BasePage + MemoryDescriptor->PageCount) {

                if ((MemoryDescriptor->MemoryType == LoaderFirmwarePermanent) ||
                    (MemoryDescriptor->MemoryType == LoaderBBTMemory) ||
                    (MemoryDescriptor->MemoryType == LoaderSpecialMemory)) {

                    //
                    // This page lies in a memory descriptor for which we will
                    // never create PFN entries, hence return FALSE.
                    //

                    break;
                }

                return TRUE;
            }
        }
        else {

            //
            // Since the loader memory list is sorted in ascending order,
            // the requested page must not be in the loader list at all.
            //

            break;
        }

        NextMd = MemoryDescriptor->ListEntry.Flink;
    }

    //
    // The final check before returning FALSE is to ensure that the requested
    // page wasn't one of the ones we used to normal-map the loader mappings,
    // etc.
    //

    if ((PageFrameIndex >= MxOldFreeDescriptor.BasePage) &&
        (PageFrameIndex < MxOldFreeDescriptor.BasePage + MxOldFreeDescriptor.PageCount)) {

        return TRUE;
    }

    if ((PageFrameIndex >= MiSlushDescriptorBase) &&
        (PageFrameIndex < MiSlushDescriptorBase + MiSlushDescriptorCount)) {

        return TRUE;
    }

    return FALSE;
}

VOID
MiReportPhysicalMemory (
    VOID
    )

/*++

Routine Description:

    This routine is called during Phase 0 initialization once the
    MmPhysicalMemoryBlock has been constructed.  It's job is to decide
    which large page ranges to enable later and also to construct a
    large page comparison list so any requests which are not fully cached
    can check this list in order to refuse conflicting requests.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode.  Phase 0 only.

    This is called before any non-MmCached allocations are made.

--*/

{
    ULONG i, j;
    PMMPTE PointerPte;
    LOGICAL EntryFound;
    PFN_NUMBER count;
    PFN_NUMBER Page;
    PFN_NUMBER LastPage;
    PFN_NUMBER PageFrameIndex;
    PFN_NUMBER LastPageFrameIndex;

    //
    // Examine the physical memory block to see whether large pages should
    // be enabled.  The key point is that all the physical pages within a
    // given large page range must have the same cache attributes (MmCached)
    // in order to maintain TB coherency.  This can be done provided all
    // the pages within the large page range represent real RAM (as described
    // by the loader) so that memory management can control it.  If any
    // portion of the large page range is not RAM, it is possible that it
    // may get used as noncached or writecombined device memory and
    // therefore large pages cannot be used.
    //

    if (MxMapLargePages == 0) {
        return;
    }

    for (i = 0; i < MiLargeVaRangeIndex; i += 1) {
        PointerPte = MiGetPteAddress (MiLargeVaRanges[i].VirtualAddress);
        ASSERT (PointerPte->u.Hard.Valid == 1);
        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

        PointerPte = MiGetPteAddress (MiLargeVaRanges[i].EndVirtualAddress);
        ASSERT (PointerPte->u.Hard.Valid == 1);
        LastPageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

        //
        // Round the start down to a page directory boundary and the end to
        // the last page directory entry before the next boundary.
        //

        PageFrameIndex &= ~(MM_PFN_MAPPED_BY_PDE - 1);
        LastPageFrameIndex |= (MM_PFN_MAPPED_BY_PDE - 1);

        EntryFound = FALSE;

        j = 0;
        do {

            count = MmPhysicalMemoryBlock->Run[j].PageCount;
            Page = MmPhysicalMemoryBlock->Run[j].BasePage;

            LastPage = Page + count;

            if ((PageFrameIndex >= Page) && (LastPageFrameIndex < LastPage)) {
                EntryFound = TRUE;
                break;
            }

            j += 1;

        } while (j != MmPhysicalMemoryBlock->NumberOfRuns);

        if (EntryFound == FALSE) {

            //
            // No entry was found that completely spans this large page range.
            // Zero it so this range will not be converted into large pages
            // later.
            //

            DbgPrint ("MM: Loader/HAL memory block indicates large pages cannot be used\n");

            MiLargeVaRanges[i].VirtualAddress = NULL;

            //
            // Don't use large pages for anything if any individual range
            // could not be used.  This is because 2 separate ranges may
            // share a straddling large page.  If the first range was unable
            // to use large pages, but the second one does ... then only part
            // of the first range will get large pages if we enable large
            // pages for the second range.  This would be very bad as we use
            // the MI_IS_PHYSICAL macro everywhere and assume the entire
            // range is in or out, so disable all large pages here instead.
            //

            while (i != 0) {

                i -= 1;

                if (MiLargeVaRanges[i].VirtualAddress != NULL) {

                    PointerPte = MiGetPteAddress (MiLargeVaRanges[i].VirtualAddress);
                    ASSERT (PointerPte->u.Hard.Valid == 1);
                    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

                    PointerPte = MiGetPteAddress (MiLargeVaRanges[i].EndVirtualAddress);
                    ASSERT (PointerPte->u.Hard.Valid == 1);
                    LastPageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

                    //
                    // Round the start down to a page directory boundary and
                    // the end to the last page directory entry before the
                    // next boundary.
                    //

                    PageFrameIndex &= ~(MM_PFN_MAPPED_BY_PDE - 1);
                    LastPageFrameIndex |= (MM_PFN_MAPPED_BY_PDE - 1);

                    MiRemoveCachedRange (PageFrameIndex, LastPageFrameIndex);
                }
            }

            MiLargeVaRangeIndex = 0;
            break;
        }
        else {
            MiAddCachedRange (PageFrameIndex, LastPageFrameIndex);
        }
    }
}

VOID
MxPopulatePageDirectories (
    IN PMMPTE StartPde,
    IN PMMPTE EndPde
    )

/*++

Routine Description:

    This routine allocates page parents, directories and tables as needed.
    Note any new page tables needed to map the range get zero filled.

Arguments:

    StartPde - Supplies the PDE to begin the population at.

    EndPde - Supplies the PDE to end the population at.

Return Value:

    None.

Environment:

    Kernel mode.  Phase 0 initialization.

--*/

{
    PMMPTE StartPxe;
    PMMPTE StartPpe;
    MMPTE TempPte;
    LOGICAL First;

    First = TRUE;
    TempPte = ValidKernelPte;

    while (StartPde <= EndPde) {

        if (First == TRUE || MiIsPteOnPdeBoundary(StartPde)) {
            First = FALSE;

            StartPxe = MiGetPdeAddress(StartPde);
            if (StartPxe->u.Hard.Valid == 0) {
                TempPte.u.Hard.PageFrameNumber = MxGetNextPage (1);
                *StartPxe = TempPte;
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPxe),
                               PAGE_SIZE);
            }

            StartPpe = MiGetPteAddress(StartPde);
            if (StartPpe->u.Hard.Valid == 0) {
                TempPte.u.Hard.PageFrameNumber = MxGetNextPage (1);
                *StartPpe = TempPte;
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPpe),
                               PAGE_SIZE);
            }
        }

        if (StartPde->u.Hard.Valid == 0) {
            TempPte.u.Hard.PageFrameNumber = MxGetNextPage (1);
            *StartPde = TempPte;
        }
        StartPde += 1;
    }
}

VOID
MiComputeInitialLargePage (
    VOID
    )

/*++

Routine Description:

    This function computes the number of bytes needed to span the initial
    nonpaged pool and PFN database plus the color arrays.  It rounds this up
    to a large page boundary and carves the memory from the free descriptor.

    If the physical memory is too sparse to use large pages for this, then
    fall back to using small pages.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode, INIT only.

--*/

{
    PFN_NUMBER i;
    PFN_NUMBER BasePage;
    PFN_NUMBER LastPage;
    UCHAR Associativity;
    SIZE_T NumberOfBytes;
    SIZE_T PfnAllocation;
    SIZE_T MaximumNonPagedPoolInBytesLimit;

    MaximumNonPagedPoolInBytesLimit = 0;

    //
    // Non-paged pool comprises 2 chunks.  The initial nonpaged pool grows
    // up and the expansion nonpaged pool expands downward.
    //
    // Initial non-paged pool is constructed so virtual addresses
    // are also physically contiguous.
    //

    if ((MmSizeOfNonPagedPoolInBytes >> PAGE_SHIFT) >
                        (7 * (MmNumberOfPhysicalPages >> 3))) {

        //
        // More than 7/8 of memory allocated to nonpagedpool, reset to 0.
        //

        MmSizeOfNonPagedPoolInBytes = 0;
    }

    if (MmSizeOfNonPagedPoolInBytes < MmMinimumNonPagedPoolSize) {

        //
        // Calculate the size of nonpaged pool.
        // Use the minimum size, then for every MB above 16mb add extra pages.
        //

        MmSizeOfNonPagedPoolInBytes = MmMinimumNonPagedPoolSize;

        MmSizeOfNonPagedPoolInBytes +=
            ((MmNumberOfPhysicalPages - _x16mbnp)/_x1mbnp) *
            MmMinAdditionNonPagedPoolPerMb;
    }

    if (MmSizeOfNonPagedPoolInBytes > MM_MAX_INITIAL_NONPAGED_POOL) {
        MmSizeOfNonPagedPoolInBytes = MM_MAX_INITIAL_NONPAGED_POOL;
    }

    //
    // If the registry specifies a total nonpaged pool percentage cap, enforce
    // it here.
    //

    if (MmMaximumNonPagedPoolPercent != 0) {

        if (MmMaximumNonPagedPoolPercent < 5) {
            MmMaximumNonPagedPoolPercent = 5;
        }
        else if (MmMaximumNonPagedPoolPercent > 80) {
            MmMaximumNonPagedPoolPercent = 80;
        }

        //
        // Use the registry-expressed percentage value.
        //
    
        MaximumNonPagedPoolInBytesLimit =
            ((MmNumberOfPhysicalPages * MmMaximumNonPagedPoolPercent) / 100);

        MaximumNonPagedPoolInBytesLimit *= PAGE_SIZE;

        if (MaximumNonPagedPoolInBytesLimit < 6 * 1024 * 1024) {
            MaximumNonPagedPoolInBytesLimit = 6 * 1024 * 1024;
        }

        if (MmSizeOfNonPagedPoolInBytes > MaximumNonPagedPoolInBytesLimit) {
            MmSizeOfNonPagedPoolInBytes = MaximumNonPagedPoolInBytesLimit;
        }
    }
    
    MmSizeOfNonPagedPoolInBytes = MI_ROUND_TO_SIZE (MmSizeOfNonPagedPoolInBytes,
                                                    PAGE_SIZE);

    //
    // Don't let the initial nonpaged pool choice exceed what's actually
    // available.
    //

    if ((MmSizeOfNonPagedPoolInBytes >> PAGE_SHIFT) > MxFreeDescriptor->PageCount / 2) {
        MmSizeOfNonPagedPoolInBytes = (MxFreeDescriptor->PageCount / 2) << PAGE_SHIFT;
    }

    //
    // Compute the secondary color value, allowing overrides from the registry.
    // This is because the color arrays are going to be allocated at the end
    // of the PFN database.
    //
    // Get secondary color value from:
    //
    // (a) from the registry (already filled in) or
    // (b) from the PCR or
    // (c) default value.
    //

    if (MmSecondaryColors == 0) {

        Associativity = KeGetPcr()->SecondLevelCacheAssociativity;

        MmSecondaryColors = KeGetPcr()->SecondLevelCacheSize;

        if (Associativity != 0) {
            MmSecondaryColors /= Associativity;
        }
    }

    MmSecondaryColors = MmSecondaryColors >> PAGE_SHIFT;

    if (MmSecondaryColors == 0) {
        MmSecondaryColors = MM_SECONDARY_COLORS_DEFAULT;
    }
    else {

        //
        // Make sure the value is power of two and within limits.
        //

        if (((MmSecondaryColors & (MmSecondaryColors -1)) != 0) ||
            (MmSecondaryColors < MM_SECONDARY_COLORS_MIN) ||
            (MmSecondaryColors > MM_SECONDARY_COLORS_MAX)) {
            MmSecondaryColors = MM_SECONDARY_COLORS_DEFAULT;
        }
    }

    MmSecondaryColorMask = MmSecondaryColors - 1;

    //
    // Determine number of bits in MmSecondayColorMask. This
    // is the number of bits the Node color must be shifted
    // by before it is included in colors.
    //

    i = MmSecondaryColorMask;
    MmSecondaryColorNodeShift = 0;
    while (i) {
        i >>= 1;
        MmSecondaryColorNodeShift += 1;
    }

    //
    // Adjust the number of secondary colors by the number of nodes
    // in the machine.  The secondary color mask is NOT adjusted
    // as it is used to control coloring within a node.  The node
    // color is added to the color AFTER normal color calculations
    // are performed.
    //

    MmSecondaryColors *= KeNumberNodes;

    for (i = 0; i < KeNumberNodes; i += 1) {
        KeNodeBlock[i]->Color = (ULONG)i;
        KeNodeBlock[i]->MmShiftedColor = (ULONG)(i << MmSecondaryColorNodeShift);
        InitializeSListHead(&KeNodeBlock[i]->DeadStackList);
    }

    //
    // Add in the PFN database size and the array for tracking secondary colors.
    //

    PfnAllocation = MI_ROUND_TO_SIZE (((MmHighestPossiblePhysicalPage + 1) * sizeof(MMPFN)) +
                    (MmSecondaryColors * sizeof(MMCOLOR_TABLES)*2),
                    PAGE_SIZE);

    NumberOfBytes = MmSizeOfNonPagedPoolInBytes + PfnAllocation;

    //
    // Align to large page size boundary, donating any extra to the nonpaged
    // pool.
    //

    NumberOfBytes = MI_ROUND_TO_SIZE (NumberOfBytes, MM_MINIMUM_VA_FOR_LARGE_PAGE);

    MmSizeOfNonPagedPoolInBytes = NumberOfBytes - PfnAllocation;

    MxPfnAllocation = PfnAllocation >> PAGE_SHIFT;

    //
    // Calculate the maximum size of pool.
    //

    if (MmMaximumNonPagedPoolInBytes == 0) {

        //
        // Calculate the size of nonpaged pool, adding extra pages for
        // every MB above 16mb.
        //

        MmMaximumNonPagedPoolInBytes = MmDefaultMaximumNonPagedPool;

        ASSERT (BYTE_OFFSET (MmMaximumNonPagedPoolInBytes) == 0);

        MmMaximumNonPagedPoolInBytes +=
            ((SIZE_T)((MmNumberOfPhysicalPages - _x16mbnp)/_x1mbnp) *
            MmMaxAdditionNonPagedPoolPerMb);

        if ((MmMaximumNonPagedPoolPercent != 0) &&
            (MmMaximumNonPagedPoolInBytes > MaximumNonPagedPoolInBytesLimit)) {
                MmMaximumNonPagedPoolInBytes = MaximumNonPagedPoolInBytesLimit;
        }
    }

    MmMaximumNonPagedPoolInBytes = MI_ROUND_TO_SIZE (MmMaximumNonPagedPoolInBytes,
                                                  MM_MINIMUM_VA_FOR_LARGE_PAGE);

    MmMaximumNonPagedPoolInBytes += NumberOfBytes;

    if (MmMaximumNonPagedPoolInBytes > MM_MAX_ADDITIONAL_NONPAGED_POOL) {
        MmMaximumNonPagedPoolInBytes = MM_MAX_ADDITIONAL_NONPAGED_POOL;
    }

    MiInitialLargePageSize = NumberOfBytes >> PAGE_SHIFT;

    if (MxPfnAllocation <= MxFreeDescriptor->PageCount / 2) {

        //
        // See if the free descriptor has enough pages of large page alignment
        // to satisfy our calculation.
        //

        BasePage = MI_ROUND_TO_SIZE (MxFreeDescriptor->BasePage,
                                 MM_MINIMUM_VA_FOR_LARGE_PAGE >> PAGE_SHIFT);

        LastPage = MxFreeDescriptor->BasePage + MxFreeDescriptor->PageCount;

        if ((BasePage < MxFreeDescriptor->BasePage) ||
            (BasePage + (NumberOfBytes >> PAGE_SHIFT) > LastPage)) {

            KeBugCheckEx (INSTALL_MORE_MEMORY,
                          NumberOfBytes >> PAGE_SHIFT,
                          MxFreeDescriptor->BasePage,
                          MxFreeDescriptor->PageCount,
                          2);
        }

        if (BasePage == MxFreeDescriptor->BasePage) {

            //
            // The descriptor starts on a large page aligned boundary so
            // remove the large page span from the bottom of the free descriptor.
            //

            MiInitialLargePage = BasePage;

            MxFreeDescriptor->BasePage += (ULONG) MiInitialLargePageSize;
            MxFreeDescriptor->PageCount -= (ULONG) MiInitialLargePageSize;
        }
        else {

            if ((LastPage & ((MM_MINIMUM_VA_FOR_LARGE_PAGE >> PAGE_SHIFT) - 1)) == 0) {
                //
                // The descriptor ends on a large page aligned boundary so
                // remove the large page span from the top of the free descriptor.
                //

                MiInitialLargePage = LastPage - MiInitialLargePageSize;

                MxFreeDescriptor->PageCount -= (ULONG) MiInitialLargePageSize;
            }
            else {

                //
                // The descriptor does not start or end on a large page aligned
                // address so chop the descriptor.  The excess slush is added to
                // the freelist by our caller.
                //

                MiSlushDescriptorBase = MxFreeDescriptor->BasePage;
                MiSlushDescriptorCount = BasePage - MxFreeDescriptor->BasePage;

                MiInitialLargePage = BasePage;

                MxFreeDescriptor->PageCount -= (ULONG) (MiInitialLargePageSize + MiSlushDescriptorCount);

                MxFreeDescriptor->BasePage = (ULONG) (BasePage + MiInitialLargePageSize);
            }
        }

        MiAddCachedRange (MiInitialLargePage,
                          MiInitialLargePage + MiInitialLargePageSize - 1);
    }
    else {

        //
        // Not enough contiguous physical memory in this machine to use large
        // pages for the PFN database and color heads so fall back to small.
        //
        // Continue to march on so the virtual sizes can still be computed
        // properly.
        //
        // Note this is not large page aligned so it can never be confused with
        // a valid large page start.
        //

        MiInitialLargePage = (PFN_NUMBER) -1;
    }

    MmPfnDatabase = (PMMPFN) ((PCHAR)MmNonPagedPoolEnd - MmMaximumNonPagedPoolInBytes);

    MmNonPagedPoolStart = (PVOID)((PCHAR) MmPfnDatabase + PfnAllocation);

    ASSERT (BYTE_OFFSET (MmNonPagedPoolStart) == 0);

    MmPageAlignedPoolBase[NonPagedPool] = MmNonPagedPoolStart;

    MmNonPagedPoolExpansionStart = (PVOID)((PCHAR) MmPfnDatabase +
                                        (MiInitialLargePageSize << PAGE_SHIFT));

    MmMaximumNonPagedPoolInBytes = ((PCHAR) MmNonPagedPoolEnd - (PCHAR) MmNonPagedPoolStart);

    MmMaximumNonPagedPoolInPages = (MmMaximumNonPagedPoolInBytes >> PAGE_SHIFT);

    return;
}


VOID
MiInitMachineDependent (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )

/*++

Routine Description:

    This routine performs the necessary operations to enable virtual
    memory. This includes building the page directory parent pages and
    the page directories for the system, building page table pages to map
    the code section, the data section, the stack section and the trap handler.

    It also initializes the PFN database and populates the free list.

Arguments:

    LoaderBlock - Supplies the address of the loader block.

Return Value:

    None.

Environment:

    Kernel mode.

    N.B.  This routine uses memory from the loader block descriptors, but
    the descriptors themselves must be restored prior to return as our caller
    walks them to create the MmPhysicalMemoryBlock.

--*/

{
    PHYSICAL_ADDRESS MaxHotPlugMemoryAddress;
    PVOID va;
    PVOID SystemPteStart;
    ULONG UseGlobal;
    PFN_NUMBER BasePage;
    PFN_NUMBER PageCount;
    PFN_NUMBER NextPhysicalPage;
    PFN_NUMBER LargestFreePfnStart;
    PFN_NUMBER FreePfnCount;
    PFN_COUNT FreeNumberOfPages;
    ULONG_PTR DirBase;
    LOGICAL First;
    PMMPFN BasePfn;
    PMMPFN BottomPfn;
    PMMPFN TopPfn;
    PFN_NUMBER i;
    PFN_NUMBER j;
    PFN_NUMBER PdePageNumber;
    PFN_NUMBER PxePage;
    PFN_NUMBER PpePage;
    PFN_NUMBER PdePage;
    PFN_NUMBER PtePage;
    PEPROCESS CurrentProcess;
    PFN_NUMBER MostFreePage;
    PLIST_ENTRY NextMd;
    SIZE_T MaxPool;
    KIRQL OldIrql;
    MMPTE TempPte;
    MMPTE TempPde;
    PMMPTE PointerPde;
    PMMPTE PointerPte;
    PMMPTE LastPte;
    PMMPTE Pde;
    PMMPTE StartPxe;
    PMMPTE EndPxe;
    PMMPTE StartPpe;
    PMMPTE EndPpe;
    PMMPTE StartPde;
    PMMPTE EndPde;
    PMMPTE StartPte;
    PMMPTE EndPte;
    PMMPFN Pfn1;
    PFN_NUMBER PageFrameIndex;
    PMMPFN Pfn2;
    PMMPFN Pfn3;
    PMMPFN Pfn4;
    ULONG_PTR Range;
    PFN_NUMBER LargestFreePfnCount;
    PLDR_DATA_TABLE_ENTRY DataTableEntry;
    PLIST_ENTRY NextEntry;
    PMEMORY_ALLOCATION_DESCRIPTOR MemoryDescriptor;
    ULONG ReturnedLength;
    NTSTATUS status;

    if (InitializationPhase == 1) {

        //
        // If the number of physical pages is greater than 255mb and the
        // verifier is not enabled, then map the kernel and HAL images
        // with large pages.
        //
        // The PFN database and initial nonpaged pool are already
        // mapped with large pages.
        //

        if (MxMapLargePages != 0) {
            for (i = 0; i < MiLargeVaRangeIndex; i += 1) {
                if (MiLargeVaRanges[i].VirtualAddress != NULL) {
                    MxConvertToLargePage (MiLargeVaRanges[i].VirtualAddress,
                                          MiLargeVaRanges[i].EndVirtualAddress);
                }
            }
        }

        return;
    }

    ASSERT (InitializationPhase == 0);

    //
    // All AMD64 processors support PAT mode and global pages.
    //

    ASSERT (KeFeatureBits & KF_PAT);
    ASSERT (KeFeatureBits & KF_GLOBAL_PAGE);

    MostFreePage = 0;
    LargestFreePfnCount = 0;

    ASSERT (KeFeatureBits & KF_LARGE_PAGE);

#if 0
    //
    // Since the host processor supports global bits, then set the global
    // bit in the template kernel PTE and PDE entries.
    //

    ValidKernelPte.u.Long |= MM_PTE_GLOBAL_MASK;
#else
    ValidKernelPte.u.Long = ValidKernelPteLocal.u.Long;
    ValidKernelPde.u.Long = ValidKernelPdeLocal.u.Long;
#endif

    //
    // Note that the PAE mode of the processor does not support the
    // global bit in PDEs which map 4K page table pages.
    //

    TempPte = ValidKernelPte;
    TempPde = ValidKernelPde;

    //
    // Set the directory base for the system process.
    //

    PointerPte = MiGetPxeAddress (PXE_BASE);
    PdePageNumber = MI_GET_PAGE_FRAME_FROM_PTE(PointerPte);

    DirBase = MI_GET_PAGE_FRAME_FROM_PTE(PointerPte) << PAGE_SHIFT;

    PsGetCurrentProcess()->Pcb.DirectoryTableBase[0] = DirBase;
    KeSweepDcache (FALSE);

    //
    // Unmap the user memory space.
    //

    PointerPde = MiGetPxeAddress (0);
    LastPte = MiGetPxeAddress (MM_SYSTEM_RANGE_START);

    MiFillMemoryPte (PointerPde,
                     LastPte - PointerPde,
                     ZeroKernelPte.u.Long);

    //
    // Get the lower bound of the free physical memory and the number of
    // physical pages by walking the memory descriptor lists.
    //

    MxFreeDescriptor = NULL;
    NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;
    while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {
        MemoryDescriptor = CONTAINING_RECORD(NextMd,
                                             MEMORY_ALLOCATION_DESCRIPTOR,
                                             ListEntry);

        if ((MemoryDescriptor->MemoryType != LoaderFirmwarePermanent) &&
            (MemoryDescriptor->MemoryType != LoaderBBTMemory) &&
            (MemoryDescriptor->MemoryType != LoaderHALCachedMemory) &&
            (MemoryDescriptor->MemoryType != LoaderSpecialMemory)) {

            //
            // This check results in /BURNMEMORY chunks not being counted.
            //

            if (MemoryDescriptor->MemoryType != LoaderBad) {
                MmNumberOfPhysicalPages += MemoryDescriptor->PageCount;
            }

            if (MemoryDescriptor->BasePage < MmLowestPhysicalPage) {
                MmLowestPhysicalPage = MemoryDescriptor->BasePage;
            }

            if ((MemoryDescriptor->BasePage + MemoryDescriptor->PageCount) >
                                                             MmHighestPhysicalPage) {
                MmHighestPhysicalPage =
                        MemoryDescriptor->BasePage + MemoryDescriptor->PageCount - 1;
            }

            //
            // Locate the largest free descriptor.
            //

            if ((MemoryDescriptor->MemoryType == LoaderFree) ||
                (MemoryDescriptor->MemoryType == LoaderLoadedProgram) ||
                (MemoryDescriptor->MemoryType == LoaderFirmwareTemporary) ||
                (MemoryDescriptor->MemoryType == LoaderOsloaderStack)) {

                //
                // Deliberately use >= instead of just > to force our allocation
                // as high as physically possible.  This is to leave low pages
                // for drivers which may require them.
                //

                if (MemoryDescriptor->PageCount >= MostFreePage) {
                    MostFreePage = MemoryDescriptor->PageCount;
                    MxFreeDescriptor = MemoryDescriptor;
                }
            }
        }

        NextMd = MemoryDescriptor->ListEntry.Flink;
    }

    //
    // This flag is registry-settable so check before overriding.
    //
    // Enabling special IRQL automatically disables mapping the kernel with
    // large pages so we can catch kernel and HAL code.
    //

    if (MmVerifyDriverBufferLength != (ULONG)-1) {
        MmLargePageMinimum = (ULONG)-2;
    }
    else if (MmLargePageMinimum == 0) {
        MmLargePageMinimum = MM_LARGE_PAGE_MINIMUM;
    }

    if (MmNumberOfPhysicalPages <= MmLargePageMinimum) {
        MxMapLargePages = 0;
    }

    //
    // MmDynamicPfn may have been initialized based on the registry to
    // a value representing the highest physical address in gigabytes.
    //

    MmDynamicPfn *= ((1024 * 1024 * 1024) / PAGE_SIZE);

    //
    // Retrieve highest hot plug memory range from the HAL if
    // available and not otherwise retrieved from the registry.
    //

    if (MmDynamicPfn == 0) {

        status = HalQuerySystemInformation(
                     HalQueryMaxHotPlugMemoryAddress,
                     sizeof(PHYSICAL_ADDRESS),
                     (PPHYSICAL_ADDRESS) &MaxHotPlugMemoryAddress,
                     &ReturnedLength);

        if (NT_SUCCESS(status)) {
            ASSERT (ReturnedLength == sizeof(PHYSICAL_ADDRESS));

            MmDynamicPfn = (PFN_NUMBER) (MaxHotPlugMemoryAddress.QuadPart / PAGE_SIZE);
        }
    }

    if (MmDynamicPfn != 0) {
        MmDynamicPfn *= ((1024 * 1024 * 1024) / PAGE_SIZE);
        MmHighestPossiblePhysicalPage = MI_DTC_MAX_PAGES - 1;
        if (MmDynamicPfn - 1 < MmHighestPossiblePhysicalPage) {
            if (MmDynamicPfn - 1 < MmHighestPhysicalPage) {
                MmDynamicPfn = MmHighestPhysicalPage + 1;
            }
            MmHighestPossiblePhysicalPage = MmDynamicPfn - 1;
        }
    }
    else {
        MmHighestPossiblePhysicalPage = MmHighestPhysicalPage;
    }

    //
    // Only machines with at least 5GB of physical memory get to use this.
    //

    if (strstr(LoaderBlock->LoadOptions, "NOLOWMEM")) {
        if (MmNumberOfPhysicalPages >= ((ULONGLONG)5 * 1024 * 1024 * 1024 / PAGE_SIZE)) {
            MiNoLowMemory = (PFN_NUMBER)((ULONGLONG)_4gb / PAGE_SIZE);
        }
    }

    if (MiNoLowMemory != 0) {
        MmMakeLowMemory = TRUE;
    }

    //
    // Save the original descriptor value as everything must be restored
    // prior to this function returning.
    //

    *(PMEMORY_ALLOCATION_DESCRIPTOR)&MxOldFreeDescriptor = *MxFreeDescriptor;

    if (MmNumberOfPhysicalPages < 2048) {
        KeBugCheckEx(INSTALL_MORE_MEMORY,
                     MmNumberOfPhysicalPages,
                     MmLowestPhysicalPage,
                     MmHighestPhysicalPage,
                     0);
    }

    //
    // Initialize no-execute access permissions.
    //

    for (i = 0; i < 32; i += 1) {
        j = i & 7;
        switch (j) {
            case MM_READONLY:
            case MM_READWRITE:
            case MM_WRITECOPY:
                MmProtectToPteMask[i] |= MmPaeMask;
                break;
            default:
                break;
        }
    }

    //
    // Compute the size of the initial nonpaged pool and the PFN database.
    // This is because we will remove this amount from the free descriptor
    // first and subsequently map it with large TB entries (so it requires
    // natural alignment & size, thus take it before other allocations chip
    // away at the descriptor).
    //

    MiComputeInitialLargePage ();

    //
    // Calculate the starting address for nonpaged system space rounded
    // down to a second level PDE mapping boundary.
    //

    MmNonPagedSystemStart = (PVOID)(((ULONG_PTR)MmPfnDatabase -
                                (((ULONG_PTR)MmNumberOfSystemPtes + 1) * PAGE_SIZE)) &
                                                        (~PAGE_DIRECTORY2_MASK));

    if (MmNonPagedSystemStart < MM_LOWEST_NONPAGED_SYSTEM_START) {
        MmNonPagedSystemStart = MM_LOWEST_NONPAGED_SYSTEM_START;
        MmNumberOfSystemPtes = (ULONG)(((ULONG_PTR)MmPfnDatabase -
                                (ULONG_PTR)MmNonPagedSystemStart) >> PAGE_SHIFT)-1;
        ASSERT (MmNumberOfSystemPtes > 1000);
    }

    //
    // Snap the system PTE start address as page directories and tables
    // will be preallocated for this range.
    //

    SystemPteStart = (PVOID) MmNonPagedSystemStart;

    //
    // If special pool and/or the driver verifier is enabled, reserve
    // extra virtual address space for special pooling now.  For now,
    // arbitrarily don't let it be larger than paged pool (128gb).
    //

    if ((MmVerifyDriverBufferLength != (ULONG)-1) ||
        ((MmSpecialPoolTag != 0) && (MmSpecialPoolTag != (ULONG)-1))) {

        if (MmNonPagedSystemStart > MM_LOWEST_NONPAGED_SYSTEM_START) {
            MaxPool = (ULONG_PTR)MmNonPagedSystemStart -
                      (ULONG_PTR)MM_LOWEST_NONPAGED_SYSTEM_START;
            if (MaxPool > MM_MAX_PAGED_POOL) {
                MaxPool = MM_MAX_PAGED_POOL;
            }
            MmNonPagedSystemStart = (PVOID)((ULONG_PTR)MmNonPagedSystemStart - MaxPool);
        }
        else {

            //
            // This is a pretty large machine.  Take some of the system
            // PTEs and reuse them for special pool.
            //

            MaxPool = (4 * _x4gb);
            ASSERT ((PVOID)MmPfnDatabase > (PVOID)((PCHAR)MmNonPagedSystemStart + MaxPool));
            SystemPteStart = (PVOID)((PCHAR)MmNonPagedSystemStart + MaxPool);

            MmNumberOfSystemPtes = (ULONG)(((ULONG_PTR)MmPfnDatabase -
                            (ULONG_PTR) SystemPteStart) >> PAGE_SHIFT)-1;

        }
        MmSpecialPoolStart = MmNonPagedSystemStart;
        MmSpecialPoolEnd = (PVOID)((ULONG_PTR)MmNonPagedSystemStart + MaxPool);
    }

    //
    // Set the global bit for all PDEs in system space.
    //

    StartPde = MiGetPdeAddress (MM_SYSTEM_SPACE_START);
    EndPde = MiGetPdeAddress (MM_SYSTEM_SPACE_END);
    First = TRUE;

    while (StartPde <= EndPde) {

        if (First == TRUE || MiIsPteOnPdeBoundary(StartPde)) {
            First = FALSE;

            StartPxe = MiGetPdeAddress(StartPde);
            if (StartPxe->u.Hard.Valid == 0) {
                StartPxe += 1;
                StartPpe = MiGetVirtualAddressMappedByPte (StartPxe);
                StartPde = MiGetVirtualAddressMappedByPte (StartPpe);
                continue;
            }

            StartPpe = MiGetPteAddress(StartPde);
            if (StartPpe->u.Hard.Valid == 0) {
                StartPpe += 1;
                StartPde = MiGetVirtualAddressMappedByPte (StartPpe);
                continue;
            }
        }

        TempPte = *StartPde;
        TempPte.u.Hard.Global = 1;
        *StartPde = TempPte;
        StartPde += 1;
    }

    KeFlushCurrentTb ();

    //
    // Allocate page directory parents, directories and page table pages for
    // system PTEs and expansion nonpaged pool.
    //

    TempPte = ValidKernelPte;
    StartPde = MiGetPdeAddress (SystemPteStart);
    EndPde = MiGetPdeAddress ((PCHAR)MmPfnDatabase - 1);

    MxPopulatePageDirectories (StartPde, EndPde);

    StartPde = MiGetPdeAddress ((PVOID)((ULONG_PTR)MmPfnDatabase +
                    (MiInitialLargePageSize << PAGE_SHIFT)));
    EndPde = MiGetPdeAddress ((PCHAR)MmNonPagedPoolEnd - 1);

    MxPopulatePageDirectories (StartPde, EndPde);

    //
    // If the number of physical pages is greater than 255mb and the
    // verifier is not enabled, then map the kernel and HAL images
    // with large pages.
    //

    if (MxMapLargePages != 0) {

        //
        // Add the kernel and HAL ranges to the large page ranges.
        //

        i = 0;
        NextEntry = LoaderBlock->LoadOrderListHead.Flink;

        for ( ; NextEntry != &LoaderBlock->LoadOrderListHead; NextEntry = NextEntry->Flink) {

            DataTableEntry = CONTAINING_RECORD (NextEntry,
                                                LDR_DATA_TABLE_ENTRY,
                                                InLoadOrderLinks);
    
            MiLargeVaRanges[MiLargeVaRangeIndex].VirtualAddress = DataTableEntry->DllBase;
            MiLargeVaRanges[MiLargeVaRangeIndex].EndVirtualAddress =
(PVOID)((ULONG_PTR)DataTableEntry->DllBase + DataTableEntry->SizeOfImage - 1);
            MiLargeVaRangeIndex += 1;

            i += 1;
            if (i == 2) {
                break;
            }
        }
    }

    //
    // Allocate page directory pages for the initial large page allocation.
    // Initial nonpaged pool, the PFN database & the color arrays are placed
    // here.
    //

    TempPte = ValidKernelPte;
    TempPde = ValidKernelPde;

    PageFrameIndex = MiInitialLargePage;

    if (MiInitialLargePage != (PFN_NUMBER) -1) {

        StartPpe = MiGetPpeAddress (MmPfnDatabase);
        StartPde = MiGetPdeAddress (MmPfnDatabase);
        EndPde = MiGetPdeAddress ((PVOID)((ULONG_PTR)MmPfnDatabase +
                    (MiInitialLargePageSize << PAGE_SHIFT) - 1));

        MI_MAKE_PDE_MAP_LARGE_PAGE (&TempPde);
    }
    else {
        StartPpe = MiGetPpeAddress (MmNonPagedPoolStart);
        StartPde = MiGetPdeAddress (MmNonPagedPoolStart);
        EndPde = MiGetPdeAddress ((PVOID)((ULONG_PTR)MmNonPagedPoolStart +
                    (MmSizeOfNonPagedPoolInBytes - 1)));
    }

    First = TRUE;

    while (StartPde <= EndPde) {

        if (First == TRUE || MiIsPteOnPdeBoundary (StartPde)) {

            if (First == TRUE || MiIsPteOnPpeBoundary (StartPde)) {

                StartPxe = MiGetPdeAddress (StartPde);

                if (StartPxe->u.Hard.Valid == 0) {
                    NextPhysicalPage = MxGetNextPage (1);
                    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                    MI_WRITE_VALID_PTE (StartPxe, TempPte);
                    RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPxe),
                                   PAGE_SIZE);
                }
            }

            First = FALSE;

            StartPpe = MiGetPteAddress (StartPde);

            if (StartPpe->u.Hard.Valid == 0) {
                NextPhysicalPage = MxGetNextPage (1);
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                MI_WRITE_VALID_PTE (StartPpe, TempPte);
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPpe),
                               PAGE_SIZE);
            }
        }

        ASSERT (StartPde->u.Hard.Valid == 0);

        if (MiInitialLargePage != (PFN_NUMBER) -1) {
            TempPde.u.Hard.PageFrameNumber = PageFrameIndex;
            PageFrameIndex += (MM_VA_MAPPED_BY_PDE >> PAGE_SHIFT);
            MI_WRITE_VALID_PTE (StartPde, TempPde);
        }
        else {

            //
            // Allocate a page table page here since we're not using large
            // pages.
            //

            NextPhysicalPage = MxGetNextPage (1);
            TempPde.u.Hard.PageFrameNumber = NextPhysicalPage;
            MI_WRITE_VALID_PTE (StartPde, TempPde);
            RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPde),
                           PAGE_SIZE);

            //
            // Allocate data pages here since we're not using large pages.
            //

            PointerPte = MiGetVirtualAddressMappedByPte (StartPde);

            for (i = 0; i < PTE_PER_PAGE; i += 1) {
                NextPhysicalPage = MxGetNextPage (1);
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                MI_WRITE_VALID_PTE (PointerPte, TempPte);
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPte),
                               PAGE_SIZE);
                PointerPte += 1;
            }
        }

        StartPde += 1;
    }

    MmFreePagesByColor[0] = (PMMCOLOR_TABLES)
                              &MmPfnDatabase[MmHighestPossiblePhysicalPage + 1];

    if (MiInitialLargePage != (PFN_NUMBER) -1) {
        RtlZeroMemory (MmPfnDatabase, MiInitialLargePageSize << PAGE_SHIFT);
    }
    else {

        //
        // Large pages were not used because this machine's physical memory
        // was not contiguous enough.
        //
        // Go through the memory descriptors and for each physical page make
        // sure the PFN database has a valid PTE to map it.  This allows
        // machines with sparse physical memory to have a minimal PFN database.
        //

        NextPhysicalPage = MxFreeDescriptor->BasePage;
        FreeNumberOfPages = MxFreeDescriptor->PageCount;

        NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;

        while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {

            MemoryDescriptor = CONTAINING_RECORD(NextMd,
                                                 MEMORY_ALLOCATION_DESCRIPTOR,
                                                 ListEntry);

            if ((MemoryDescriptor->MemoryType == LoaderFirmwarePermanent) ||
                (MemoryDescriptor->MemoryType == LoaderBBTMemory) ||
                (MemoryDescriptor->MemoryType == LoaderSpecialMemory)) {

                //
                // Skip these ranges.
                //

                NextMd = MemoryDescriptor->ListEntry.Flink;
                continue;
            }

            //
            // Temporarily add back in the memory allocated since Phase 0
            // began so PFN entries for it will be created and mapped.
            //
            // Note actual PFN entry allocations must be done carefully as
            // memory from the descriptor itself could get used to map
            // the PFNs for the descriptor !
            //

            if (MemoryDescriptor == MxFreeDescriptor) {
                BasePage = MxOldFreeDescriptor.BasePage;
                PageCount = (PFN_COUNT) MxOldFreeDescriptor.PageCount;
            }
            else {
                BasePage = MemoryDescriptor->BasePage;
                PageCount = MemoryDescriptor->PageCount;
            }

            PointerPte = MiGetPteAddress (MI_PFN_ELEMENT(BasePage));

            LastPte = MiGetPteAddress (((PCHAR)(MI_PFN_ELEMENT(
                                            BasePage + PageCount))) - 1);

            while (PointerPte <= LastPte) {

                StartPxe = MiGetPpeAddress (PointerPte);

                if (StartPxe->u.Hard.Valid == 0) {
                    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                    ASSERT (FreeNumberOfPages != 0);
                    NextPhysicalPage += 1;
                    FreeNumberOfPages -= 1;
                    if (FreeNumberOfPages == 0) {
                        KeBugCheckEx (INSTALL_MORE_MEMORY,
                                      MmNumberOfPhysicalPages,
                                      FreeNumberOfPages,
                                      MxOldFreeDescriptor.PageCount,
                                      3);
                    }
                    MI_WRITE_VALID_PTE (StartPxe, TempPte);
                    RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPxe),
                                   PAGE_SIZE);
                }

                StartPpe = MiGetPdeAddress (PointerPte);

                if (StartPpe->u.Hard.Valid == 0) {
                    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                    ASSERT (FreeNumberOfPages != 0);
                    NextPhysicalPage += 1;
                    FreeNumberOfPages -= 1;
                    if (FreeNumberOfPages == 0) {
                        KeBugCheckEx (INSTALL_MORE_MEMORY,
                                      MmNumberOfPhysicalPages,
                                      FreeNumberOfPages,
                                      MxOldFreeDescriptor.PageCount,
                                      3);
                    }
                    MI_WRITE_VALID_PTE (StartPpe, TempPte);
                    RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPpe),
                                   PAGE_SIZE);
                }

                StartPde = MiGetPteAddress (PointerPte);

                if (StartPde->u.Hard.Valid == 0) {
                    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                    ASSERT (FreeNumberOfPages != 0);
                    NextPhysicalPage += 1;
                    FreeNumberOfPages -= 1;
                    if (FreeNumberOfPages == 0) {
                        KeBugCheckEx (INSTALL_MORE_MEMORY,
                                      MmNumberOfPhysicalPages,
                                      FreeNumberOfPages,
                                      MxOldFreeDescriptor.PageCount,
                                      3);
                    }
                    MI_WRITE_VALID_PTE (StartPde, TempPte);
                    RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPde),
                                   PAGE_SIZE);
                }

                if (PointerPte->u.Hard.Valid == 0) {
                    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                    ASSERT (FreeNumberOfPages != 0);
                    NextPhysicalPage += 1;
                    FreeNumberOfPages -= 1;
                    if (FreeNumberOfPages == 0) {
                        KeBugCheckEx (INSTALL_MORE_MEMORY,
                                      MmNumberOfPhysicalPages,
                                      FreeNumberOfPages,
                                      MxOldFreeDescriptor.PageCount,
                                      3);
                    }
                    MI_WRITE_VALID_PTE (PointerPte, TempPte);
                    RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPte),
                                   PAGE_SIZE);
                }
                PointerPte += 1;
            }

            NextMd = MemoryDescriptor->ListEntry.Flink;
        }

        //
        // Ensure the color arrays are mapped.
        //

        PointerPte = MiGetPteAddress (MmFreePagesByColor[0]);
        LastPte = MiGetPteAddress (&MmFreePagesByColor[StandbyPageList][MmSecondaryColors]);
        if (LastPte != PAGE_ALIGN (LastPte)) {
            LastPte += 1;
        }

        StartPxe = MiGetPdeAddress (PointerPte);
        StartPpe = MiGetPdeAddress (PointerPte);
        PointerPde = MiGetPteAddress (PointerPte);

        while (PointerPte < LastPte) {

            if (StartPxe->u.Hard.Valid == 0) {
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                ASSERT (FreeNumberOfPages != 0);
                NextPhysicalPage += 1;
                FreeNumberOfPages -= 1;
                if (FreeNumberOfPages == 0) {
                    KeBugCheckEx (INSTALL_MORE_MEMORY,
                                  MmNumberOfPhysicalPages,
                                  FreeNumberOfPages,
                                  MxOldFreeDescriptor.PageCount,
                                  3);
                }
                MI_WRITE_VALID_PTE (StartPxe, TempPte);
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPxe), PAGE_SIZE);
            }

            if (StartPpe->u.Hard.Valid == 0) {
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                ASSERT (FreeNumberOfPages != 0);
                NextPhysicalPage += 1;
                FreeNumberOfPages -= 1;
                if (FreeNumberOfPages == 0) {
                    KeBugCheckEx (INSTALL_MORE_MEMORY,
                                  MmNumberOfPhysicalPages,
                                  FreeNumberOfPages,
                                  MxOldFreeDescriptor.PageCount,
                                  3);
                }
                MI_WRITE_VALID_PTE (StartPpe, TempPte);
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPpe), PAGE_SIZE);
            }

            if (PointerPde->u.Hard.Valid == 0) {
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                ASSERT (FreeNumberOfPages != 0);
                NextPhysicalPage += 1;
                FreeNumberOfPages -= 1;
                if (FreeNumberOfPages == 0) {
                    KeBugCheckEx (INSTALL_MORE_MEMORY,
                                  MmNumberOfPhysicalPages,
                                  FreeNumberOfPages,
                                  MxOldFreeDescriptor.PageCount,
                                  3);
                }
                MI_WRITE_VALID_PTE (PointerPde, TempPte);
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPde), PAGE_SIZE);
            }

            if (PointerPte->u.Hard.Valid == 0) {
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                ASSERT (FreeNumberOfPages != 0);
                NextPhysicalPage += 1;
                FreeNumberOfPages -= 1;
                if (FreeNumberOfPages == 0) {
                    KeBugCheckEx (INSTALL_MORE_MEMORY,
                                  MmNumberOfPhysicalPages,
                                  FreeNumberOfPages,
                                  MxOldFreeDescriptor.PageCount,
                                  3);
                }
                MI_WRITE_VALID_PTE (PointerPte, TempPte);
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPte), PAGE_SIZE);
            }

            PointerPte += 1;
            if (MiIsPteOnPdeBoundary (PointerPte)) {
                PointerPde += 1;
                if (MiIsPteOnPdeBoundary (PointerPde)) {
                    StartPpe += 1;
                }
            }
        }

        //
        // Adjust the free descriptor for all the pages we just took.
        //

        MxFreeDescriptor->PageCount -= (LONG)(NextPhysicalPage - MxFreeDescriptor->BasePage);

        MxFreeDescriptor->BasePage = (PFN_COUNT) NextPhysicalPage;
    }

    //
    // Set subsection base to the address to zero as the PTE format allows the
    // complete address space to be spanned.
    //

    MmSubsectionBase = 0;

    //
    // There must be at least one page of system PTEs before the expanded
    // nonpaged pool.
    //

    ASSERT (MiGetPteAddress(SystemPteStart) < MiGetPteAddress(MmNonPagedPoolExpansionStart));

    //
    // Non-paged pages now exist, build the pool structures.
    //

    MiInitializeNonPagedPool ();
    MiInitializeNonPagedPoolThresholds ();

    //
    // Before nonpaged pool can be used, the PFN database must
    // be built.  This is due to the fact that the start and end of
    // allocation bits for nonpaged pool are maintained in the
    // PFN elements for the corresponding pages.
    //

    //
    // Initialize support for colored pages.
    //

    MmFreePagesByColor[1] = &MmFreePagesByColor[0][MmSecondaryColors];

    for (i = 0; i < MmSecondaryColors; i += 1) {
        MmFreePagesByColor[ZeroedPageList][i].Flink = MM_EMPTY_LIST;
        MmFreePagesByColor[ZeroedPageList][i].Blink = (PVOID) MM_EMPTY_LIST;
        MmFreePagesByColor[ZeroedPageList][i].Count = 0;
        MmFreePagesByColor[FreePageList][i].Flink = MM_EMPTY_LIST;
        MmFreePagesByColor[FreePageList][i].Blink = (PVOID) MM_EMPTY_LIST;
        MmFreePagesByColor[FreePageList][i].Count = 0;
    }

    //
    // Ensure the hyperspace and session spaces are not mapped so they don't
    // get made global by the loops below.
    //

    ASSERT (MiGetPxeAddress (HYPER_SPACE)->u.Hard.Valid == 0);
    ASSERT (MiGetPxeAddress (MM_SESSION_SPACE_DEFAULT)->u.Hard.Valid == 0);

    //
    // Go through the page table entries and for any page which is valid,
    // update the corresponding PFN database element.
    //

    StartPxe = MiGetPxeAddress (NULL);
    EndPxe = StartPxe + PXE_PER_PAGE;

    for ( ; StartPxe < EndPxe; StartPxe += 1) {

        if (StartPxe->u.Hard.Valid == 0) {
            continue;
        }

        va = MiGetVirtualAddressMappedByPxe (StartPxe);
        ASSERT (va >= MM_SYSTEM_RANGE_START);
        if (MI_IS_PAGE_TABLE_ADDRESS (va)) {
            UseGlobal = 0;
        }
        else {
            UseGlobal = 1;
        }

        ASSERT (StartPxe->u.Hard.LargePage == 0);
        ASSERT (StartPxe->u.Hard.Owner == 0);
        ASSERT (StartPxe->u.Hard.Global == 0);

        PxePage = MI_GET_PAGE_FRAME_FROM_PTE(StartPxe);

        if (MiIsRegularMemory (LoaderBlock, PxePage)) {

            Pfn1 = MI_PFN_ELEMENT(PxePage);

            Pfn1->u4.PteFrame = DirBase;
            Pfn1->PteAddress = StartPxe;
            Pfn1->u2.ShareCount += 1;
            Pfn1->u3.e2.ReferenceCount = 1;
            Pfn1->u3.e1.PageLocation = ActiveAndValid;
            Pfn1->u3.e1.CacheAttribute = MiCached;
            MiDetermineNode (PxePage, Pfn1);
        }
        else {
            Pfn1 = NULL;
        }

        StartPpe = MiGetVirtualAddressMappedByPte (StartPxe);
        EndPpe = StartPpe + PPE_PER_PAGE;

        for ( ; StartPpe < EndPpe; StartPpe += 1) {

            if (StartPpe->u.Hard.Valid == 0) {
                continue;
            }

            ASSERT (StartPpe->u.Hard.LargePage == 0);
            ASSERT (StartPpe->u.Hard.Owner == 0);
            ASSERT (StartPpe->u.Hard.Global == 0);

            PpePage = MI_GET_PAGE_FRAME_FROM_PTE (StartPpe);

            if (MiIsRegularMemory (LoaderBlock, PpePage)) {

                Pfn2 = MI_PFN_ELEMENT (PpePage);

                Pfn2->u4.PteFrame = PxePage;
                Pfn2->PteAddress = StartPpe;
                Pfn2->u2.ShareCount += 1;
                Pfn2->u3.e2.ReferenceCount = 1;
                Pfn2->u3.e1.PageLocation = ActiveAndValid;
                Pfn2->u3.e1.CacheAttribute = MiCached;
                MiDetermineNode (PpePage, Pfn2);
            }
            else {
                Pfn2 = NULL;
            }

            ASSERT (Pfn1 != NULL);
            Pfn1->u2.ShareCount += 1;

            StartPde = MiGetVirtualAddressMappedByPte (StartPpe);
            EndPde = StartPde + PDE_PER_PAGE;

            for ( ; StartPde < EndPde; StartPde += 1) {

                if (StartPde->u.Hard.Valid == 0) {
                    continue;
                }

                ASSERT (StartPde->u.Hard.Owner == 0);
                StartPde->u.Hard.Global = UseGlobal;

                PdePage = MI_GET_PAGE_FRAME_FROM_PTE (StartPde);

                if (MiIsRegularMemory (LoaderBlock, PdePage)) {

                    Pfn3 = MI_PFN_ELEMENT (PdePage);

                    Pfn3->u4.PteFrame = PpePage;
                    Pfn3->PteAddress = StartPde;
                    Pfn3->u2.ShareCount += 1;
                    Pfn3->u3.e2.ReferenceCount = 1;
                    Pfn3->u3.e1.PageLocation = ActiveAndValid;
                    Pfn3->u3.e1.CacheAttribute = MiCached;
                    MiDetermineNode (PdePage, Pfn3);
                }
                else {
                    Pfn3 = NULL;
                }

                ASSERT (Pfn2 != NULL);
                Pfn2->u2.ShareCount += 1;

                if (StartPde->u.Hard.LargePage == 1) {
                    if (Pfn3 != NULL) {
                        for (i = 0; i < PDE_PER_PAGE - 1; i += 1) {
                            *(Pfn3 + 1) = *Pfn3;
                            Pfn3 += 1;
                        }
                    }
                }
                else {

                    StartPte = MiGetVirtualAddressMappedByPte (StartPde);
                    EndPte = StartPte + PDE_PER_PAGE;

                    for ( ; StartPte < EndPte; StartPte += 1) {

                        if (StartPte->u.Hard.Valid == 0) {
                            continue;
                        }

                        if (StartPte->u.Hard.LargePage == 1) {
                            continue;
                        }

                        ASSERT (StartPte->u.Hard.Owner == 0);
                        StartPte->u.Hard.Global = UseGlobal;

                        PtePage = MI_GET_PAGE_FRAME_FROM_PTE(StartPte);

                        ASSERT (Pfn3 != NULL);
                        Pfn3->u2.ShareCount += 1;

                        if (!MiIsRegularMemory (LoaderBlock, PtePage)) {
                            continue;
                        }

                        Pfn4 = MI_PFN_ELEMENT (PtePage);

                        if ((MmIsAddressValid(Pfn4)) &&
                             MmIsAddressValid((PUCHAR)(Pfn4+1)-1)) {

                            Pfn4->u4.PteFrame = PdePage;
                            Pfn4->PteAddress = StartPte;
                            Pfn4->u2.ShareCount += 1;
                            Pfn4->u3.e2.ReferenceCount = 1;
                            Pfn4->u3.e1.PageLocation = ActiveAndValid;
                            Pfn4->u3.e1.CacheAttribute = MiCached;
                            MiDetermineNode (PtePage, Pfn4);
                        }
                    }
                }
            }
        }
    }

    //
    // If the lowest physical page is zero and the page is still unused, mark
    // it as in use. This is because we want to find bugs where a physical
    // page is specified as zero.
    //

    Pfn1 = &MmPfnDatabase[MmLowestPhysicalPage];

    if ((MmLowestPhysicalPage == 0) && (Pfn1->u3.e2.ReferenceCount == 0)) {

        ASSERT (Pfn1->u3.e2.ReferenceCount == 0);

        //
        // Make the reference count non-zero and point it into a
        // page directory.
        //

        Pde = MiGetPxeAddress (0xFFFFFFFFB0000000);
        PdePage = MI_GET_PAGE_FRAME_FROM_PTE (Pde);
        Pfn1->u4.PteFrame = PdePage;
        Pfn1->PteAddress = Pde;
        Pfn1->u2.ShareCount += 1;
        Pfn1->u3.e2.ReferenceCount = 0xfff0;
        Pfn1->u3.e1.PageLocation = ActiveAndValid;
        Pfn1->u3.e1.CacheAttribute = MiCached;
        MiDetermineNode (0, Pfn1);
    }

    //
    // Walk through the memory descriptors and add pages to the
    // free list in the PFN database.
    //
    // Since the LoaderBlock memory descriptors are ordered
    // from low physical memory address to high, walk it backwards so the
    // high physical pages go to the front of the freelists.  The thinking
    // is that pages initially allocated by the system are less likely to be
    // freed so don't waste memory below 16mb (or 4gb) that may be needed
    // by ISA drivers later.
    //

    NextMd = LoaderBlock->MemoryDescriptorListHead.Blink;

    while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {

        MemoryDescriptor = CONTAINING_RECORD(NextMd,
                                             MEMORY_ALLOCATION_DESCRIPTOR,
                                             ListEntry);

        i = MemoryDescriptor->PageCount;
        PageFrameIndex = MemoryDescriptor->BasePage;

        switch (MemoryDescriptor->MemoryType) {
            case LoaderBad:

                if (PageFrameIndex > MmHighestPhysicalPage) {
                    i = 0;
                }
                else if (PageFrameIndex + i > MmHighestPhysicalPage + 1) {
                    i = MmHighestPhysicalPage + 1 - PageFrameIndex;
                }

                LOCK_PFN (OldIrql);

                while (i != 0) {
                    MiInsertPageInList (&MmBadPageListHead, PageFrameIndex);
                    i -= 1;
                    PageFrameIndex += 1;
                }

                UNLOCK_PFN (OldIrql);

                break;

            case LoaderFree:
            case LoaderLoadedProgram:
            case LoaderFirmwareTemporary:
            case LoaderOsloaderStack:

                FreePfnCount = 0;
                Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

                LOCK_PFN (OldIrql);

                while (i != 0) {
                    if (Pfn1->u3.e2.ReferenceCount == 0) {

                        //
                        // Set the PTE address to the physical page for
                        // virtual address alignment checking.
                        //

                        Pfn1->PteAddress =
                                        (PMMPTE)(PageFrameIndex << PTE_SHIFT);
                        MiDetermineNode (PageFrameIndex, Pfn1);
                        MiInsertPageInFreeList (PageFrameIndex);
                        FreePfnCount += 1;
                    }
                    else {
                        if (FreePfnCount > LargestFreePfnCount) {
                            LargestFreePfnCount = FreePfnCount;
                            LargestFreePfnStart = PageFrameIndex - FreePfnCount;
                            FreePfnCount = 0;
                        }
                    }

                    Pfn1 += 1;
                    i -= 1;
                    PageFrameIndex += 1;
                }

                UNLOCK_PFN (OldIrql);

                if (FreePfnCount > LargestFreePfnCount) {
                    LargestFreePfnCount = FreePfnCount;
                    LargestFreePfnStart = PageFrameIndex - FreePfnCount;
                }

                break;

            case LoaderFirmwarePermanent:
            case LoaderSpecialMemory:
            case LoaderBBTMemory:

                //
                // Skip these ranges.
                //

                break;

            default:

                PointerPte = MiGetPteAddress (KSEG0_BASE +
                                            (PageFrameIndex << PAGE_SHIFT));

                Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

                while (i != 0) {

                    //
                    // Set page as in use.
                    //

                    PointerPde = MiGetPdeAddress (KSEG0_BASE +
                                             (PageFrameIndex << PAGE_SHIFT));

                    if (Pfn1->u3.e2.ReferenceCount == 0) {
                        Pfn1->u4.PteFrame = MI_GET_PAGE_FRAME_FROM_PTE(PointerPde);
                        Pfn1->PteAddress = PointerPte;
                        Pfn1->u2.ShareCount += 1;
                        Pfn1->u3.e2.ReferenceCount = 1;
                        Pfn1->u3.e1.PageLocation = ActiveAndValid;
                        Pfn1->u3.e1.CacheAttribute = MiCached;
                        MiDetermineNode (PageFrameIndex, Pfn1);

                        if (MemoryDescriptor->MemoryType == LoaderXIPRom) {
                            Pfn1->u1.Flink = 0;
                            Pfn1->u2.ShareCount = 0;
                            Pfn1->u3.e2.ReferenceCount = 0;
                            Pfn1->u3.e1.PageLocation = 0;
                            Pfn1->u3.e1.CacheAttribute = MiCached;
                            Pfn1->u3.e1.Rom = 1;
                            Pfn1->u4.InPageError = 0;
                            Pfn1->u3.e1.PrototypePte = 1;
                        }
                    }
                    Pfn1 += 1;
                    i -= 1;
                    PageFrameIndex += 1;
                    PointerPte += 1;
                }

                break;
        }

        NextMd = MemoryDescriptor->ListEntry.Blink;
    }

    //
    // If the large page chunk came from the middle of the free descriptor (due
    // to alignment requirements), then add the pages from the split bottom
    // portion of the free descriptor now.
    //

    i = MiSlushDescriptorCount;
    NextPhysicalPage = MiSlushDescriptorBase;
    Pfn1 = MI_PFN_ELEMENT (NextPhysicalPage);

    LOCK_PFN (OldIrql);

    while (i != 0) {
        if (Pfn1->u3.e2.ReferenceCount == 0) {

            //
            // Set the PTE address to the physical page for
            // virtual address alignment checking.
            //

            Pfn1->PteAddress = (PMMPTE)(NextPhysicalPage << PTE_SHIFT);
            Pfn1->u3.e1.CacheAttribute = MiCached;
            MiDetermineNode (NextPhysicalPage, Pfn1);
            MiInsertPageInFreeList (NextPhysicalPage);
        }
        Pfn1 += 1;
        i -= 1;
        NextPhysicalPage += 1;
    }

    UNLOCK_PFN (OldIrql);

    //
    // Mark all PFN entries for the PFN pages in use.
    //

    if (MiInitialLargePage != (PFN_NUMBER) -1) {

        //
        // All PFN entries for the PFN pages in use better be marked as such.
        //

        PointerPde = MiGetPdeAddress (MmPfnDatabase);
        ASSERT (PointerPde->u.Hard.LargePage == 1);
        PageFrameIndex = (PFN_NUMBER) PointerPde->u.Hard.PageFrameNumber;
        Pfn1 = MI_PFN_ELEMENT(PageFrameIndex);
        i = MxPfnAllocation;

        do {
            Pfn1->PteAddress = (PMMPTE)(PageFrameIndex << PTE_SHIFT);
            ASSERT (Pfn1->u3.e1.PageLocation == ActiveAndValid);
            ASSERT (Pfn1->u3.e1.CacheAttribute == MiCached);
            ASSERT (Pfn1->u3.e2.ReferenceCount == 1);
            PageFrameIndex += 1;
            Pfn1 += 1;
            i -= 1;
        } while (i != 0);

        if (MmDynamicPfn == 0) {

            //
            // Scan the PFN database backward for pages that are completely
            // zero.  These pages are unused and can be added to the free list.
            //
            // This allows machines with sparse physical memory to have a
            // minimal PFN database even when mapped with large pages.
            //

            BottomPfn = MI_PFN_ELEMENT(MmHighestPhysicalPage);

            do {

                //
                // Compute the address of the start of the page that is next
                // lower in memory and scan backwards until that page address
                // is reached or just crossed.
                //

                if (((ULONG_PTR)BottomPfn & (PAGE_SIZE - 1)) != 0) {
                    BasePfn = (PMMPFN)((ULONG_PTR)BottomPfn & ~(PAGE_SIZE - 1));
                    TopPfn = BottomPfn + 1;

                }
                else {
                    BasePfn = (PMMPFN)((ULONG_PTR)BottomPfn - PAGE_SIZE);
                    TopPfn = BottomPfn;
                }

                while (BottomPfn > BasePfn) {
                    BottomPfn -= 1;
                }

                //
                // If the entire range over which the PFN entries span is
                // completely zero and the PFN entry that maps the page is
                // not in the range, then add the page to the free list.
                //

                Range = (ULONG_PTR)TopPfn - (ULONG_PTR)BottomPfn;
                if (RtlCompareMemoryUlong ((PVOID)BottomPfn, Range, 0) == Range) {

                    //
                    // Set the PTE address to the physical page for virtual
                    // address alignment checking.
                    //

                    PointerPde = MiGetPdeAddress (BasePfn);
                    ASSERT (PointerPde->u.Hard.LargePage == 1);
                    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPde) + MiGetPteOffset (BasePfn);

                    Pfn1 = MI_PFN_ELEMENT(PageFrameIndex);

                    ASSERT (Pfn1->u3.e2.ReferenceCount == 1);
                    ASSERT (Pfn1->PteAddress == (PMMPTE)(PageFrameIndex << PTE_SHIFT));
                    Pfn1->u3.e2.ReferenceCount = 0;
                    Pfn1->PteAddress = (PMMPTE)(PageFrameIndex << PTE_SHIFT);
                    MiDetermineNode (PageFrameIndex, Pfn1);
                    LOCK_PFN (OldIrql);
                    MiInsertPageInFreeList (PageFrameIndex);
                    UNLOCK_PFN (OldIrql);
                }
            } while (BottomPfn > MmPfnDatabase);
        }
    }
    else {

        //
        // The PFN database is sparsely allocated in small pages.
        //

        PointerPte = MiGetPteAddress (MmPfnDatabase);
        LastPte = MiGetPteAddress (MmPfnDatabase + MmHighestPhysicalPage + 1);
        if (LastPte != PAGE_ALIGN (LastPte)) {
            LastPte += 1;
        }

        StartPxe = MiGetPpeAddress (PointerPte);
        StartPpe = MiGetPdeAddress (PointerPte);
        PointerPde = MiGetPteAddress (PointerPte);

        while (PointerPte < LastPte) {

            if (StartPxe->u.Hard.Valid == 0) {
                StartPxe += 1;
                StartPpe = MiGetVirtualAddressMappedByPte (StartPxe);
                PointerPde = MiGetVirtualAddressMappedByPte (StartPpe);
                PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
                continue;
            }

            if (StartPpe->u.Hard.Valid == 0) {
                StartPpe += 1;
                StartPxe = MiGetPteAddress (StartPpe);
                PointerPde = MiGetVirtualAddressMappedByPte (StartPpe);
                PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
                continue;
            }

            if (PointerPde->u.Hard.Valid == 0) {
                PointerPde += 1;
                PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
                if (MiIsPteOnPdeBoundary (PointerPde)) {
                    StartPpe += 1;
                    if (MiIsPteOnPdeBoundary (StartPpe)) {
                        StartPxe += 1;
                    }
                }
                continue;
            }

            if (PointerPte->u.Hard.Valid == 1) {

                PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
                Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

                Pfn1->PteAddress = PointerPte;
                Pfn1->u3.e1.PageColor = 0;
                Pfn1->u3.e2.ReferenceCount = 1;
                Pfn1->u3.e1.PageLocation = ActiveAndValid;
                Pfn1->u3.e1.CacheAttribute = MiCached;
            }

            PointerPte += 1;
            if (MiIsPteOnPdeBoundary (PointerPte)) {
                PointerPde += 1;
                if (MiIsPteOnPdeBoundary (PointerPde)) {
                    StartPpe += 1;
                    if (MiIsPteOnPdeBoundary (StartPpe)) {
                        StartPxe += 1;
                    }
                }
            }
        }
    }

    //
    // Initialize the nonpaged pool.
    //

    InitializePool (NonPagedPool, 0);

    //
    // Adjust the memory descriptor to indicate that free pool has
    // been used for nonpaged pool creation.
    //
    // N.B.  This is required because the descriptors are walked upon
    // return from this routine to create the MmPhysicalMemoryBlock.
    //

    *MxFreeDescriptor = *(PMEMORY_ALLOCATION_DESCRIPTOR)&MxOldFreeDescriptor;

    //
    //
    // Initialize the system PTE pool now that nonpaged pool exists.
    //

    PointerPte = MiGetPteAddress (SystemPteStart);
    ASSERT (((ULONG_PTR)PointerPte & (PAGE_SIZE - 1)) == 0);

    MmNumberOfSystemPtes = (ULONG)(MiGetPteAddress (MmPfnDatabase) - PointerPte - 1);

    MiInitializeSystemPtes (PointerPte, MmNumberOfSystemPtes, SystemPteSpace);

    //
    // Initialize the debugger PTE.
    //

    MmDebugPte = MiReserveSystemPtes (1, SystemPteSpace);

    MmDebugPte->u.Long = 0;

    MmDebugVa = MiGetVirtualAddressMappedByPte (MmDebugPte);

    MmCrashDumpPte = MiReserveSystemPtes (16, SystemPteSpace);

    MmCrashDumpVa = MiGetVirtualAddressMappedByPte (MmCrashDumpPte);

    //
    // Allocate a page directory and a pair of page table pages.
    // Map the hyper space page directory page into the top level parent
    // directory & the hyper space page table page into the page directory
    // and map an additional page that will eventually be used for the
    // working set list.  Page tables after the first two are set up later
    // on during individual process working set initialization.
    //
    // The working set list page will eventually be a part of hyper space.
    // It is mapped into the second level page directory page so it can be
    // zeroed and so it will be accounted for in the PFN database. Later
    // the page will be unmapped, and its page frame number captured in the
    // system process object.
    //

    TempPte = ValidKernelPte;
    TempPte.u.Hard.Global = 0;

    StartPxe = MiGetPxeAddress (HYPER_SPACE);
    StartPpe = MiGetPpeAddress (HYPER_SPACE);
    StartPde = MiGetPdeAddress (HYPER_SPACE);

    LOCK_PFN (OldIrql);

    if (StartPxe->u.Hard.Valid == 0) {
        ASSERT (StartPxe->u.Long == 0);
        TempPte.u.Hard.PageFrameNumber = MiRemoveAnyPage (0);
        *StartPxe = TempPte;
        RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPxe), PAGE_SIZE);
    }
    else {
        ASSERT (StartPxe->u.Hard.Global == 0);
    }

    if (StartPpe->u.Hard.Valid == 0) {
        ASSERT (StartPpe->u.Long == 0);
        TempPte.u.Hard.PageFrameNumber = MiRemoveAnyPage (0);
        *StartPpe = TempPte;
        RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPpe), PAGE_SIZE);
    }
    else {
        ASSERT (StartPpe->u.Hard.Global == 0);
    }

    TempPte.u.Hard.PageFrameNumber = MiRemoveAnyPage (0);
    *StartPde = TempPte;

    //
    // Zero the hyper space page table page.
    //

    StartPte = MiGetPteAddress (HYPER_SPACE);
    RtlZeroMemory (StartPte, PAGE_SIZE);

    PageFrameIndex = MiRemoveAnyPage (0);

    UNLOCK_PFN (OldIrql);

    //
    // Hyper space now exists, set the necessary variables.
    //

    MmFirstReservedMappingPte = MiGetPteAddress (FIRST_MAPPING_PTE);
    MmLastReservedMappingPte = MiGetPteAddress (LAST_MAPPING_PTE);

    //
    // Create zeroing PTEs for the zero page thread.
    //

    MiFirstReservedZeroingPte = MiReserveSystemPtes (NUMBER_OF_ZEROING_PTES + 1,
                                                     SystemPteSpace);

    RtlZeroMemory (MiFirstReservedZeroingPte,
                   (NUMBER_OF_ZEROING_PTES + 1) * sizeof(MMPTE));

    //
    // Use the page frame number field of the first PTE as an
    // offset into the available zeroing PTEs.
    //

    MiFirstReservedZeroingPte->u.Hard.PageFrameNumber = NUMBER_OF_ZEROING_PTES;

    //
    // Create the VAD bitmap for this process.
    //

    PointerPte = MiGetPteAddress (VAD_BITMAP_SPACE);

    //
    // Note the global bit must be off for the bitmap data.
    //

    TempPte = ValidKernelPteLocal;
    TempPte.u.Hard.PageFrameNumber = PageFrameIndex;
    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Point to the page we just created and zero it.
    //

    RtlZeroMemory (VAD_BITMAP_SPACE, PAGE_SIZE);

    MiLastVadBit = (ULONG)((((ULONG_PTR) MI_64K_ALIGN (MM_HIGHEST_VAD_ADDRESS))) / X64K);
    if (MiLastVadBit > PAGE_SIZE * 8 - 1) {
        MiLastVadBit = PAGE_SIZE * 8 - 1;
    }

    KeInitializeEvent (&MiImageMappingPteEvent,
                       NotificationEvent,
                       FALSE);

    //
    // Initialize this process's memory management structures including
    // the working set list.
    //

    CurrentProcess = PsGetCurrentProcess ();

    //
    // The PFN element for the page directory has already been initialized,
    // zero the reference count and the share count so they won't be wrong.
    //

    Pfn1 = MI_PFN_ELEMENT (PdePageNumber);

    LOCK_PFN (OldIrql);

    Pfn1->u2.ShareCount = 0;
    Pfn1->u3.e2.ReferenceCount = 0;

    //
    // Get a page for the working set list and zero it.
    //

    PageFrameIndex = MiRemoveAnyPage (0);

    UNLOCK_PFN (OldIrql);

    TempPte.u.Hard.PageFrameNumber = PageFrameIndex;

    PointerPte = MiGetPteAddress (MmWorkingSetList);
    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    CurrentProcess->WorkingSetPage = PageFrameIndex;

    CurrentProcess->Vm.MaximumWorkingSetSize = (ULONG)MmSystemProcessWorkingSetMax;
    CurrentProcess->Vm.MinimumWorkingSetSize = (ULONG)MmSystemProcessWorkingSetMin;

    MmInitializeProcessAddressSpace (CurrentProcess, NULL, NULL, NULL);

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\i386\mi386.h ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    mi386.h

Abstract:

    This module contains the private data structures and procedure
    prototypes for the hardware dependent portion of the
    memory management system.

    This module is specifically tailored for the x86.

Author:

    Lou Perazzoli (loup) 6-Jan-1990
    Landy Wang (landyw) 02-June-1997

Revision History:

--*/


/*++

    Virtual Memory Layout on x86 is:

                 +------------------------------------+
        00000000 |                                    |
                 |                                    |
                 |                                    |
                 | User Mode Addresses                |
                 |                                    |
                 |   All pages within this range      |
                 |   are potentially accessible while |
                 |   the CPU is in USER mode.         |
                 |                                    |
                 |                                    |
                 +------------------------------------+
        7ffff000 | 64k No Access Area                 |
                 +------------------------------------+
        80000000 |                                    |
                 | NTLDR loads the kernel, HAL and    |
                 | boot drivers here.  The kernel     |
                 | then relocates the drivers to the  |
                 | system PTE area.                   |
                 |                                    |
                 | Kernel mode access only.           |
                 |                                    |
                 | When possible, the PFN database &  |
                 | initial non paged pool is built    |
                 | here using large page mappings.    |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | Additional system PTEs, system     |
                 | cache or special pooling           |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | System mapped views.               |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | Session space.                     |
                 |                                    |
                 +------------------------------------+
        C0000000 | Page Table Pages mapped through    |
                 |          this 4mb region           |
                 |   Kernel mode access only.         |
                 |                                    |
                 +------------------------------------+
        C0400000 | HyperSpace - working set lists     |
                 |  and per process memory management |
                 |  structures mapped in this 4mb     |
                 |  region.                           |
                 |  Kernel mode access only.          |
                 +------------------------------------+
        C0800000 | NO ACCESS AREA (4MB)               |
                 |                                    |
                 +------------------------------------+
        C0C00000 | System Cache Structures            |
                 |   reside in this 4mb region        |
                 |   Kernel mode access only.         |
                 +------------------------------------+
        C1000000 | System cache resides here.         |
                 |   Kernel mode access only.         |
                 |                                    |
                 |                                    |
                 +------------------------------------+
        E1000000 | Start of paged system area         |
                 |   Kernel mode access only.         |
                 |                                    |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | System PTE area - for mapping      |
                 |   kernel thread stacks and MDLs    |
                 |   that require system VAs.         |
                 |   Kernel mode access only.         |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | NonPaged System area               |
                 |   Kernel mode access only.         |
                 |                                    |
                 +------------------------------------+
        FFBE0000 | Crash Dump Driver area             |
                 |   Kernel mode access only.         |
                 +------------------------------------+
        FFC00000 | Last 4mb reserved for HAL usage    |
                 +------------------------------------+

--*/

#define _MI_PAGING_LEVELS 2

#define IMAGE_FILE_MACHINE_NATIVE   IMAGE_FILE_MACHINE_I386

#if !defined(_X86PAE_)

//
// Define empty list markers.
//

#define MM_EMPTY_LIST ((ULONG)0xFFFFFFFF) //
#define MM_EMPTY_PTE_LIST ((ULONG)0xFFFFF) // N.B. tied to MMPTE definition

#define MI_PTE_BASE_FOR_LOWEST_KERNEL_ADDRESS (MiGetPteAddress (0x00000000))

#define MM_SESSION_SPACE_DEFAULT        (0xA0000000)
#define MM_SESSION_SPACE_DEFAULT_END    (0xC0000000)

//
// This is the size of the region used by the loader.
//

extern ULONG_PTR MmBootImageSize;

//
// PAGE_SIZE for x86 is 4k, virtual page is 20 bits with a PAGE_SHIFT
// byte offset.
//

#define MM_VIRTUAL_PAGE_FILLER 0
#define MM_VIRTUAL_PAGE_SIZE 20

//
// Address space layout definitions.
//

#define MM_KSEG0_BASE ((ULONG)0x80000000)

#define MM_KSEG2_BASE ((ULONG)0xA0000000)

#define MM_PAGES_IN_KSEG0 ((MM_KSEG2_BASE - MM_KSEG0_BASE) >> PAGE_SHIFT)

#define CODE_START MM_KSEG0_BASE

#define CODE_END   MM_KSEG2_BASE

#define MM_SYSTEM_SPACE_START (0xC0800000)

#define MM_SYSTEM_SPACE_END (0xFFFFFFFF)

#define HYPER_SPACE ((PVOID)0xC0400000)

#define HYPER_SPACE_END (0xC07fffff)

#define MM_SYSTEM_VIEW_START (0xA0000000)

#define MM_SYSTEM_VIEW_SIZE (16*1024*1024)

#define MM_LOWEST_4MB_START ((32*1024*1024)/PAGE_SIZE) //32mb

#define MM_DEFAULT_4MB_START (((1024*1024)/PAGE_SIZE)*4096) //4gb

#define MM_HIGHEST_4MB_START (((1024*1024)/PAGE_SIZE)*4096) //4gb

#define MM_USER_ADDRESS_RANGE_LIMIT 0xFFFFFFFF // user address range limit
#define MM_MAXIMUM_ZERO_BITS 21         // maximum number of zero bits

//
// Define the start and maximum size for the system cache.
// Maximum size is normally 512MB, but can be up to 512MB + 448MB = 960MB for
// large system cache machines.
//

#define MM_SYSTEM_CACHE_WORKING_SET (0xC0C00000)

#define MM_SYSTEM_CACHE_START (0xC1000000)

#define MM_SYSTEM_CACHE_END (0xE1000000)

//
// Various resources like additional system PTEs or system cache views, etc,
// can be allocated out of this virtual address range.
//

extern ULONG MiExtraResourceStart;

extern ULONG MiExtraResourceEnd;

extern ULONG_PTR MiUseMaximumSystemSpace;

extern ULONG_PTR MiUseMaximumSystemSpaceEnd;

extern ULONG MiNumberOfExtraSystemPdes;

extern ULONG MiNumberOfExtraSystemPdes3;

extern ULONG MiMaximumSystemExtraSystemPdes;

extern ULONG MiMaximumSystemCacheSizeExtra;

extern PVOID MiSystemCacheStartExtra;

extern PVOID MiSystemCacheEndExtra;

#define MM_SYSTEM_CACHE_END_EXTRA (0xC0000000)

#define MM_PAGED_POOL_START (MmPagedPoolStart)

#define MM_DEFAULT_PAGED_POOL_START (0xE1000000)

#define MM_LOWEST_NONPAGED_SYSTEM_START ((PVOID)(0xEB000000))

#define MmProtopte_Base ((ULONG)MmPagedPoolStart)

#define MM_NONPAGED_POOL_END ((PVOID)(0xFFBE0000))

#define MM_CRASH_DUMP_VA ((PVOID)(0xFFBE0000))

#define MM_DEBUG_VA  ((PVOID)0xFFBFF000)

#define NON_PAGED_SYSTEM_END   ((ULONG)0xFFFFFFF0)  //quadword aligned.

extern BOOLEAN MiWriteCombiningPtes;

LOGICAL
MiRecoverExtraPtes (
    VOID
    );

//
// Define absolute minimum and maximum count for system PTEs.
//

#define MM_MINIMUM_SYSTEM_PTES 7000

#define MM_MAXIMUM_SYSTEM_PTES 50000

#define MM_DEFAULT_SYSTEM_PTES 11000

//
// Pool limits
//

//
// The maximum amount of nonpaged pool that can be initially created.
//

#define MM_MAX_INITIAL_NONPAGED_POOL ((ULONG)(128*1024*1024))

//
// The total amount of nonpaged pool (initial pool + expansion).
//

#define MM_MAX_ADDITIONAL_NONPAGED_POOL ((ULONG)(128*1024*1024))

//
// The maximum amount of paged pool that can be created.
//

#define MM_MAX_PAGED_POOL ((ULONG)MM_NONPAGED_POOL_END - (ULONG)MM_PAGED_POOL_START)

#define MM_MAX_TOTAL_POOL (((ULONG)MM_NONPAGED_POOL_END) - ((ULONG)(MM_PAGED_POOL_START)))


//
// Structure layout definitions.
//

#define MM_PROTO_PTE_ALIGNMENT ((ULONG)PAGE_SIZE)

#define PAGE_DIRECTORY_MASK    ((ULONG)0x003FFFFF)

#define MM_VA_MAPPED_BY_PDE (0x400000)

#define MM_MINIMUM_VA_FOR_LARGE_PAGE MM_VA_MAPPED_BY_PDE

#define LOWEST_IO_ADDRESS 0xa0000

#define PTE_SHIFT 2

//
// The number of bits in a physical address.
//

#define PHYSICAL_ADDRESS_BITS 32

#define MM_MAXIMUM_NUMBER_OF_COLORS (1)

//
// i386 does not require support for colored pages.
//

#define MM_NUMBER_OF_COLORS (1)

//
// Mask for obtaining color from a physical page number.
//

#define MM_COLOR_MASK (0)

//
// Boundary for aligned pages of like color upon.
//

#define MM_COLOR_ALIGNMENT (0)

//
// Mask for isolating color from virtual address.
//

#define MM_COLOR_MASK_VIRTUAL (0)

//
//  Define 256k worth of secondary colors.
//

#define MM_SECONDARY_COLORS_DEFAULT (64)

#define MM_SECONDARY_COLORS_MIN (2)

#define MM_SECONDARY_COLORS_MAX (1024)

//
// Maximum number of paging files.
//

#define MAX_PAGE_FILES 16


//
// Hyper space definitions.
//

#define FIRST_MAPPING_PTE   ((ULONG)0xC0400000)

#define NUMBER_OF_MAPPING_PTES 255
#define LAST_MAPPING_PTE   \
     ((ULONG)((ULONG)FIRST_MAPPING_PTE + (NUMBER_OF_MAPPING_PTES * PAGE_SIZE)))

#define COMPRESSION_MAPPING_PTE   ((PMMPTE)((ULONG)LAST_MAPPING_PTE + PAGE_SIZE))

#define IMAGE_MAPPING_PTE   ((PMMPTE)((ULONG)COMPRESSION_MAPPING_PTE + PAGE_SIZE))

#define NUMBER_OF_ZEROING_PTES 32

//
// This bitmap consumes 4K when booted /2GB and 6K when booted /3GB, thus
// the working set list start is variable.
//

#define VAD_BITMAP_SPACE    ((PVOID)((ULONG)IMAGE_MAPPING_PTE + PAGE_SIZE))

#define WORKING_SET_LIST    MmWorkingSetList

#define MM_MAXIMUM_WORKING_SET MiMaximumWorkingSet

extern ULONG MiMaximumWorkingSet;

#define MmWsle ((PMMWSLE)((PUCHAR)WORKING_SET_LIST + sizeof(MMWSL)))

#define MM_WORKING_SET_END ((ULONG)0xC07FF000)


//
// Define masks for fields within the PTE.
///

#define MM_PTE_VALID_MASK         0x1
#if defined(NT_UP)
#define MM_PTE_WRITE_MASK         0x2
#else
#define MM_PTE_WRITE_MASK         0x800
#endif
#define MM_PTE_OWNER_MASK         0x4
#define MM_PTE_WRITE_THROUGH_MASK 0x8
#define MM_PTE_CACHE_DISABLE_MASK 0x10
#define MM_PTE_ACCESS_MASK        0x20
#if defined(NT_UP)
#define MM_PTE_DIRTY_MASK         0x40
#else
#define MM_PTE_DIRTY_MASK         0x42
#endif
#define MM_PTE_LARGE_PAGE_MASK    0x80
#define MM_PTE_GLOBAL_MASK        0x100
#define MM_PTE_COPY_ON_WRITE_MASK 0x200
#define MM_PTE_PROTOTYPE_MASK     0x400
#define MM_PTE_TRANSITION_MASK    0x800

//
// Bit fields to or into PTE to make a PTE valid based on the
// protection field of the invalid PTE.
//

#define MM_PTE_NOACCESS          0x0   // not expressable on i386
#define MM_PTE_READONLY          0x0
#define MM_PTE_READWRITE         MM_PTE_WRITE_MASK
#define MM_PTE_WRITECOPY         0x200 // read-only copy on write bit set.
#define MM_PTE_EXECUTE           0x0   // read-only on i386
#define MM_PTE_EXECUTE_READ      0x0
#define MM_PTE_EXECUTE_READWRITE MM_PTE_WRITE_MASK
#define MM_PTE_EXECUTE_WRITECOPY 0x200 // read-only copy on write bit set.
#define MM_PTE_NOCACHE           0x010
#define MM_PTE_GUARD             0x0  // not expressable on i386
#define MM_PTE_CACHE             0x0

#define MM_PROTECT_FIELD_SHIFT 5

//
// Bits available for the software working set index within the hardware PTE.
//

#define MI_MAXIMUM_PTE_WORKING_SET_INDEX 0

//
// Zero PTE
//

#define MM_ZERO_PTE 0

//
// Zero Kernel PTE
//

#define MM_ZERO_KERNEL_PTE 0

//
// A demand zero PTE with a protection or PAGE_READWRITE.
//

#define MM_DEMAND_ZERO_WRITE_PTE (MM_READWRITE << MM_PROTECT_FIELD_SHIFT)


//
// A demand zero PTE with a protection or PAGE_READWRITE for system space.
//

#define MM_KERNEL_DEMAND_ZERO_PTE (MM_READWRITE << MM_PROTECT_FIELD_SHIFT)

//
// A no access PTE for system space.
//

#define MM_KERNEL_NOACCESS_PTE (MM_NOACCESS << MM_PROTECT_FIELD_SHIFT)

//
// Kernel stack alignment requirements.
//

#define MM_STACK_ALIGNMENT 0x0

#define MM_STACK_OFFSET 0x0

//
// System process definitions
//

#define PDE_PER_PAGE ((ULONG)1024)

#define PTE_PER_PAGE ((ULONG)1024)

#define PD_PER_SYSTEM ((ULONG)1)

//
// Number of page table pages for user addresses.
//

#define MM_USER_PAGE_TABLE_PAGES (768)


//++
//VOID
//MI_MAKE_VALID_PTE (
//    OUT OUTPTE,
//    IN FRAME,
//    IN PMASK,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro makes a valid PTE from a page frame number, protection mask,
//    and owner.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the transition PTE.
//
//    FRAME - Supplies the page frame number for the PTE.
//
//    PMASK - Supplies the protection to set in the transition PTE.
//
//    PPTE - Supplies a pointer to the PTE which is being made valid.
//           For prototype PTEs NULL should be specified.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_VALID_PTE(OUTPTE,FRAME,PMASK,PPTE)                            \
       (OUTPTE).u.Long = ((FRAME << 12) |                                     \
                         (MmProtectToPteMask[PMASK]) |                        \
                          MiDetermineUserGlobalPteMask ((PMMPTE)PPTE));

//++
//VOID
//MI_MAKE_VALID_PTE_TRANSITION (
//    IN OUT OUTPTE
//    IN PROTECT
//    );
//
// Routine Description:
//
//    This macro takes a valid pte and turns it into a transition PTE.
//
// Arguments
//
//    OUTPTE - Supplies the current valid PTE.  This PTE is then
//             modified to become a transition PTE.
//
//    PROTECT - Supplies the protection to set in the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_VALID_PTE_TRANSITION(OUTPTE,PROTECT) \
                (OUTPTE).u.Soft.Transition = 1;           \
                (OUTPTE).u.Soft.Valid = 0;                \
                (OUTPTE).u.Soft.Prototype = 0;            \
                (OUTPTE).u.Soft.Protection = PROTECT;

//++
//VOID
//MI_MAKE_TRANSITION_PTE (
//    OUT OUTPTE,
//    IN PAGE,
//    IN PROTECT,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a valid pte and turns it into a transition PTE.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the transition PTE.
//
//    PAGE - Supplies the page frame number for the PTE.
//
//    PROTECT - Supplies the protection to set in the transition PTE.
//
//    PPTE - Supplies a pointer to the PTE, this is used to determine
//           the owner of the PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PTE(OUTPTE,PAGE,PROTECT,PPTE)   \
                (OUTPTE).u.Long = 0;                       \
                (OUTPTE).u.Trans.PageFrameNumber = PAGE;   \
                (OUTPTE).u.Trans.Transition = 1;           \
                (OUTPTE).u.Trans.Protection = PROTECT;     \
                (OUTPTE).u.Trans.Owner = MI_DETERMINE_OWNER(PPTE);


//++
//VOID
//MI_MAKE_TRANSITION_PTE_VALID (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a transition pte and makes it a valid PTE.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PTE_VALID(OUTPTE,PPTE)                             \
        ASSERT (((PPTE)->u.Hard.Valid == 0) &&                                \
                ((PPTE)->u.Trans.Prototype == 0) &&                           \
                ((PPTE)->u.Trans.Transition == 1));                           \
               (OUTPTE).u.Long = (((PPTE)->u.Long & ~0xFFF) |                 \
                         (MmProtectToPteMask[(PPTE)->u.Trans.Protection]) |   \
                          MiDetermineUserGlobalPteMask ((PMMPTE)PPTE));

//++
//VOID
//MI_MAKE_TRANSITION_PROTOPTE_VALID (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a transition prototype PTE (in paged pool) and
//    makes it a valid PTE.  Because we know this is a prototype PTE and
//    not a pagetable PTE, this can directly or in the global bit.  This
//    makes a measurable performance gain since every instruction counts
//    when holding the PFN lock.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PROTOPTE_VALID(OUTPTE,PPTE)                        \
        ASSERT (((PPTE)->u.Hard.Valid == 0) &&                                \
                ((PPTE)->u.Trans.Prototype == 0) &&                           \
                ((PPTE)->u.Trans.Transition == 1));                           \
               (OUTPTE).u.Long = (((PPTE)->u.Long & ~0xFFF) |                 \
                         (MmProtectToPteMask[(PPTE)->u.Trans.Protection]) |   \
                         (MmPteGlobal.u.Long));                               \
               (OUTPTE).u.Hard.Valid = 1;                                     \
               (OUTPTE).u.Hard.Accessed = 1;

#define MI_FAULT_STATUS_INDICATES_EXECUTION(_FaultStatus)   0

#define MI_FAULT_STATUS_INDICATES_WRITE(_FaultStatus)   (_FaultStatus & 0x1)

#define MI_CLEAR_FAULT_STATUS(_FaultStatus)             (_FaultStatus = 0)

#define MI_IS_PTE_EXECUTABLE(_TempPte) (1)

//++
//++
//VOID
//MI_SET_PTE_IN_WORKING_SET (
//    OUT PMMPTE PTE,
//    IN ULONG WSINDEX
//    );
//
// Routine Description:
//
//    This macro inserts the specified working set index into the argument PTE.
//    Since the i386 PTE has no free bits nothing needs to be done on this
//    architecture.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to insert the working set index.
//
//    WSINDEX - Supplies the working set index for the PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_IN_WORKING_SET(PTE, WSINDEX)

//++
//ULONG WsIndex
//MI_GET_WORKING_SET_FROM_PTE(
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro returns the working set index from the argument PTE.
//    Since the i386 PTE has no free bits nothing needs to be done on this
//    architecture.
//
// Arguments
//
//    PTE - Supplies the PTE to extract the working set index from.
//
// Return Value:
//
//    This macro returns the working set index for the argument PTE.
//
//--

#define MI_GET_WORKING_SET_FROM_PTE(PTE)  0

//++
//VOID
//MI_SET_PTE_WRITE_COMBINE (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and enables WriteCombining as the
//    caching state.  Note that the PTE bits may only be set this way
//    if the Page Attribute Table is present and the PAT has been
//    initialized to provide Write Combining.
//
//    If either of the above conditions is not satisfied, then
//    the macro enables WEAK UC (PCD = 1, PWT = 0) in the PTE.
//
// Arguments
//
//    PTE - Supplies a valid PTE.
//
// Return Value:
//
//     None.
//
//--
//

#define MI_SET_PTE_WRITE_COMBINE(PTE) \
            {                                                               \
                if (MiWriteCombiningPtes == TRUE) {                         \
                    ((PTE).u.Hard.CacheDisable = 0);                        \
                    ((PTE).u.Hard.WriteThrough = 1);                        \
                } else {                                                    \
                    ((PTE).u.Hard.CacheDisable = 1);                        \
                    ((PTE).u.Hard.WriteThrough = 0);                        \
                }                                                           \
            }

#define MI_SET_LARGE_PTE_WRITE_COMBINE(PTE) MI_SET_PTE_WRITE_COMBINE(PTE)

//++
//VOID
//MI_PREPARE_FOR_NONCACHED (
//    IN MI_PFN_CACHE_ATTRIBUTE CacheAttribute
//    );
//
// Routine Description:
//
//    This macro prepares the system prior to noncached PTEs being created.
//
//    Note the entire TB must be flushed on all processors because there may
//    be stale system PTE (or hyperspace or zeropage) mappings in the TB which
//    may refer to the same physical page but with a different cache attribute.
//
// Arguments
//
//    CacheAttribute - Supplies the cache attribute the PTEs will be filled
//                     with.
//
// Return Value:
//
//     None.
//
//--
#define MI_PREPARE_FOR_NONCACHED(_CacheAttribute)                           \
        if (_CacheAttribute != MiCached) {                                  \
            KeFlushEntireTb (FALSE, TRUE);                                  \
            KeInvalidateAllCaches ();                                       \
        }

//++
//VOID
//MI_SWEEP_CACHE (
//    IN MI_PFN_CACHE_ATTRIBUTE CacheAttribute,
//    IN PVOID StartVa,
//    IN ULONG NumberOfBytes
//    );
//
// Routine Description:
//
//    This macro prepares the system prior to noncached PTEs being created.
//    This does nothing on x86.
//
// Arguments
//
//    CacheAttribute - Supplies the cache attribute the new PTEs were filled
//                     with.
//
//    StartVa - Supplies the starting address that's been mapped.
//
//    NumberOfBytes - Supplies the number of bytes that have been mapped.
//
// Return Value:
//
//     None.
//
//--
#define MI_SWEEP_CACHE(_CacheAttribute,_StartVa,_NumberOfBytes)

//++
//VOID
//MI_SET_PTE_DIRTY (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro sets the dirty bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to set dirty.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_DIRTY(PTE) (PTE).u.Long |= HARDWARE_PTE_DIRTY_MASK


//++
//VOID
//MI_SET_PTE_CLEAN (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro clears the dirty bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to set clear.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_CLEAN(PTE) (PTE).u.Long &= ~HARDWARE_PTE_DIRTY_MASK



//++
//VOID
//MI_IS_PTE_DIRTY (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro checks the dirty bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if the page is dirty (modified), FALSE otherwise.
//
//--

#define MI_IS_PTE_DIRTY(PTE) ((PTE).u.Hard.Dirty != 0)



//++
//VOID
//MI_SET_GLOBAL_BIT_IF_SYSTEM (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro sets the global bit if the pointer PTE is within
//    system space.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the PTE becoming valid.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_GLOBAL_BIT_IF_SYSTEM(OUTPTE,PPTE)                             \
   if ((((PMMPTE)PPTE) > MiHighestUserPte) &&                                \
       ((((PMMPTE)PPTE) <= MiGetPteAddress (PTE_BASE)) ||                    \
       (((PMMPTE)PPTE) >= MiGetPteAddress (MM_SYSTEM_CACHE_WORKING_SET)))) { \
           (OUTPTE).u.Long |= MmPteGlobal.u.Long;                            \
   }                                                                         \
   else {                                                                    \
           (OUTPTE).u.Long &= ~MmPteGlobal.u.Long;                           \
   }


//++
//VOID
//MI_SET_GLOBAL_STATE (
//    IN MMPTE PTE,
//    IN ULONG STATE
//    );
//
// Routine Description:
//
//    This macro sets the global bit in the PTE. if the pointer PTE is within
//
// Arguments
//
//    PTE - Supplies the PTE to set global state into.
//
//    STATE - Supplies 1 if global, 0 if not.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_GLOBAL_STATE(PTE,STATE)                              \
           if (STATE) {                                             \
               (PTE).u.Long |= MmPteGlobal.u.Long;                  \
           }                                                        \
           else {                                                   \
               (PTE).u.Long &= ~MmPteGlobal.u.Long;                 \
           }





//++
//VOID
//MI_ENABLE_CACHING (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and sets the caching state to be
//    enabled.  This is performed by clearing the PCD and PWT bits in the PTE.
//
//    Semantics of the overlap between PCD, PWT, and the
//    USWC memory type in the MTRR are:
//
//    PCD   PWT   Mtrr Mem Type      Effective Memory Type
//     1     0    USWC               USWC
//     1     1    USWC               UC
//
// Arguments
//
//    PTE - Supplies a valid PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_ENABLE_CACHING(PTE) \
            {                                                                \
                ((PTE).u.Hard.CacheDisable = 0);                             \
                ((PTE).u.Hard.WriteThrough = 0);                             \
            }



//++
//VOID
//MI_DISABLE_CACHING (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and sets the caching state to be
//    disabled.  This is performed by setting the PCD and PWT bits in the PTE.
//
//    Semantics of the overlap between PCD, PWT, and the
//    USWC memory type in the MTRR are:
//
//    PCD   PWT   Mtrr Mem Type      Effective Memory Type
//     1     0    USWC               USWC
//     1     1    USWC               UC
//
//    Since an effective memory type of UC is desired here,
//    the WT bit is set.
//
// Arguments
//
//    PTE - Supplies a pointer to the valid PTE.
//
// Return Value:
//
//     None.
//
//--


#define MI_DISABLE_CACHING(PTE) \
            {                                                                \
                ((PTE).u.Hard.CacheDisable = 1);                             \
                ((PTE).u.Hard.WriteThrough = 1);                             \
            }

#define MI_DISABLE_LARGE_PTE_CACHING(PTE) MI_DISABLE_CACHING(PTE)



//++
//BOOLEAN
//MI_IS_CACHING_DISABLED (
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and returns TRUE if caching is
//    disabled.
//
// Arguments
//
//    PPTE - Supplies a pointer to the valid PTE.
//
// Return Value:
//
//     TRUE if caching is disabled, FALSE if it is enabled.
//
//--

#define MI_IS_CACHING_DISABLED(PPTE)   \
            ((PPTE)->u.Hard.CacheDisable == 1)



//++
//VOID
//MI_SET_PFN_DELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a PFN element and indicates that
//    the PFN is no longer in use.
//
// Arguments
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//    none.
//
//--

#define MI_SET_PFN_DELETED(PPFN) \
    PPFN->PteAddress = (PMMPTE)(((ULONG_PTR)(PPFN->PteAddress)) | 0x1);


//++
//VOID
//MI_MARK_PFN_UNDELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a deleted PFN element and mark that
//    the PFN is not deleted.
//
// Arguments
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//    none.
//
//--

#define MI_MARK_PFN_UNDELETED(PPFN) \
    PPFN->PteAddress = (PMMPTE)((ULONG_PTR)PPFN->PteAddress & ~0x1);


//++
//BOOLEAN
//MI_IS_PFN_DELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a PFN element and determines if
//    the PFN is no longer in use.
//
// Arguments
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//     TRUE if PFN is no longer used, FALSE if it is still being used.
//
//--

#define MI_IS_PFN_DELETED(PPFN)   \
            ((ULONG_PTR)(PPFN)->PteAddress & 0x1)


//++
//VOID
//MI_CHECK_PAGE_ALIGNMENT (
//    IN ULONG PAGE,
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro takes a PFN element number (Page) and checks to see
//    if the virtual alignment for the previous address of the page
//    is compatible with the new address of the page.  If they are
//    not compatible, the D cache is flushed.
//
// Arguments
//
//    PAGE - Supplies the PFN element.
//    PPTE - Supplies a pointer to the new PTE which will contain the page.
//
// Return Value:
//
//    none.
//
//--

// does nothing on i386.

#define MI_CHECK_PAGE_ALIGNMENT(PAGE,PPTE)




//++
//VOID
//MI_INITIALIZE_HYPERSPACE_MAP (
//    VOID
//    );
//
// Routine Description:
//
//    This macro initializes the PTEs reserved for double mapping within
//    hyperspace.
//
// Arguments
//
//    None.
//
// Return Value:
//
//    None.
//
//--

// does nothing on i386.

#define MI_INITIALIZE_HYPERSPACE_MAP(INDEX)


//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_PTE (
//    IN PMMPTE PTEADDRESS
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    PTEADDRESS - Supplies the PTE address the page is (or was) mapped at.
//
// Return Value:
//
//    The page's color.
//
//--

#define MI_GET_PAGE_COLOR_FROM_PTE(PTEADDRESS)  \
         ((ULONG)((MI_SYSTEM_PAGE_COLOR++) & MmSecondaryColorMask))



//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_VA (
//    IN PVOID ADDRESS
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    ADDRESS - Supplies the address the page is (or was) mapped at.
//
// Return Value:
//
//    The page's color.
//
//--


#define MI_GET_PAGE_COLOR_FROM_VA(ADDRESS)  \
         ((ULONG)((MI_SYSTEM_PAGE_COLOR++) & MmSecondaryColorMask))

//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_SESSION (
//    IN PMM_SESSION_SPACE SessionSpace
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    SessionSpace - Supplies the session space the page will be mapped into.
//
// Return Value:
//
//    The page's color.
//
//--


#define MI_GET_PAGE_COLOR_FROM_SESSION(_SessionSpace)  \
         ((ULONG)((_SessionSpace->Color++) & MmSecondaryColorMask))



//++
//ULONG
//MI_PAGE_COLOR_PTE_PROCESS (
//    IN PMMPTE PTE,
//    IN PUSHORT COLOR
//    );
//
// Routine Description:
//
//    Select page color for this process.
//
// Arguments
//
//   PTE    Not used.
//   COLOR  Value from which color is determined.   This
//          variable is incremented.
//
// Return Value:
//
//    Page color.
//
//--


#define MI_PAGE_COLOR_PTE_PROCESS(PTE,COLOR)  \
         ((ULONG)((*(COLOR))++) & MmSecondaryColorMask)


//++
//ULONG
//MI_PAGE_COLOR_VA_PROCESS (
//    IN PVOID ADDRESS,
//    IN PEPROCESS COLOR
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    ADDRESS - Supplies the address the page is (or was) mapped at.
//
// Return Value:
//
//    The page's color.
//
//--

#define MI_PAGE_COLOR_VA_PROCESS(ADDRESS,COLOR) \
         ((ULONG)((*(COLOR))++) & MmSecondaryColorMask)



//++
//ULONG
//MI_GET_NEXT_COLOR (
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the next color in the sequence.
//
// Arguments
//
//    COLOR - Supplies the color to return the next of.
//
// Return Value:
//
//    Next color in sequence.
//
//--

#define MI_GET_NEXT_COLOR(COLOR)  ((COLOR + 1) & MM_COLOR_MASK)


//++
//ULONG
//MI_GET_PREVIOUS_COLOR (
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the previous color in the sequence.
//
// Arguments
//
//    COLOR - Supplies the color to return the previous of.
//
// Return Value:
//
//    Previous color in sequence.
//
//--

#define MI_GET_PREVIOUS_COLOR(COLOR)  (0)


#define MI_GET_SECONDARY_COLOR(PAGE,PFN) (PAGE & MmSecondaryColorMask)


#define MI_GET_COLOR_FROM_SECONDARY(SECONDARY_COLOR) (0)


//++
//VOID
//MI_GET_MODIFIED_PAGE_BY_COLOR (
//    OUT ULONG PAGE,
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the first page destined for a paging
//    file with the desired color.  It does NOT remove the page
//    from its list.
//
// Arguments
//
//    PAGE - Returns the page located, the value MM_EMPTY_LIST is
//           returned if there is no page of the specified color.
//
//    COLOR - Supplies the color of page to locate.
//
// Return Value:
//
//    none.
//
//--

#define MI_GET_MODIFIED_PAGE_BY_COLOR(PAGE,COLOR) \
            PAGE = MmModifiedPageListByColor[COLOR].Flink


//++
//VOID
//MI_GET_MODIFIED_PAGE_ANY_COLOR (
//    OUT ULONG PAGE,
//    IN OUT ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the first page destined for a paging
//    file with the desired color.  If not page of the desired
//    color exists, all colored lists are searched for a page.
//    It does NOT remove the page from its list.
//
// Arguments
//
//    PAGE - Returns the page located, the value MM_EMPTY_LIST is
//           returned if there is no page of the specified color.
//
//    COLOR - Supplies the color of page to locate and returns the
//            color of the page located.
//
// Return Value:
//
//    none.
//
//--

#define MI_GET_MODIFIED_PAGE_ANY_COLOR(PAGE,COLOR) \
            {                                                                \
                if (MmTotalPagesForPagingFile == 0) {                        \
                    PAGE = MM_EMPTY_LIST;                                    \
                } else {                                                     \
                    PAGE = MmModifiedPageListByColor[COLOR].Flink;           \
                }                                                            \
            }



//++
//VOID
//MI_MAKE_VALID_PTE_WRITE_COPY (
//    IN OUT PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro checks to see if the PTE indicates that the
//    page is writable and if so it clears the write bit and
//    sets the copy-on-write bit.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     None.
//
//--

#if defined(NT_UP)
#define MI_MAKE_VALID_PTE_WRITE_COPY(PPTE) \
                    if ((PPTE)->u.Hard.Write == 1) {    \
                        (PPTE)->u.Hard.CopyOnWrite = 1; \
                        (PPTE)->u.Hard.Write = 0;       \
                    }
#else
#define MI_MAKE_VALID_PTE_WRITE_COPY(PPTE) \
                    if ((PPTE)->u.Hard.Write == 1) {    \
                        (PPTE)->u.Hard.CopyOnWrite = 1; \
                        (PPTE)->u.Hard.Write = 0;       \
                        (PPTE)->u.Hard.Writable = 0;    \
                    }
#endif


#define MI_PTE_OWNER_USER       1

#define MI_PTE_OWNER_KERNEL     0


//++
//ULONG
//MI_DETERMINE_OWNER (
//    IN MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro examines the virtual address of the PTE and determines
//    if the PTE resides in system space or user space.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     1 if the owner is USER_MODE, 0 if the owner is KERNEL_MODE.
//
//--

#define MI_DETERMINE_OWNER(PPTE)   \
    ((((PPTE) <= MiHighestUserPte) ||                                       \
      ((PPTE) >= MiGetPdeAddress(NULL) &&                                   \
      ((PPTE) <= MiHighestUserPde))) ? MI_PTE_OWNER_USER : MI_PTE_OWNER_KERNEL)



//++
//VOID
//MI_SET_ACCESSED_IN_PTE (
//    IN OUT MMPTE PPTE,
//    IN ULONG ACCESSED
//    );
//
// Routine Description:
//
//    This macro sets the ACCESSED field in the PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     None
//
//--

#define MI_SET_ACCESSED_IN_PTE(PPTE,ACCESSED) \
                    ((PPTE)->u.Hard.Accessed = ACCESSED)

//++
//ULONG
//MI_GET_ACCESSED_IN_PTE (
//    IN OUT MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro returns the state of the ACCESSED field in the PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     The state of the ACCESSED field.
//
//--

#define MI_GET_ACCESSED_IN_PTE(PPTE) ((PPTE)->u.Hard.Accessed)


//++
//VOID
//MI_SET_OWNER_IN_PTE (
//    IN PMMPTE PPTE
//    IN ULONG OWNER
//    );
//
// Routine Description:
//
//    This macro sets the owner field in the PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_OWNER_IN_PTE(PPTE,OWNER) ((PPTE)->u.Hard.Owner = OWNER)


//
// bit mask to clear out fields in a PTE to or in prototype pte offset.
//

#define CLEAR_FOR_PROTO_PTE_ADDRESS ((ULONG)0x701)

//
// bit mask to clear out fields in a PTE to or in paging file location.
//

#define CLEAR_FOR_PAGE_FILE 0x000003E0


//++
//VOID
//MI_SET_PAGING_FILE_INFO (
//    OUT MMPTE OUTPTE,
//    IN MMPTE PPTE,
//    IN ULONG FILEINFO,
//    IN ULONG OFFSET
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to store the result.
//
//    PTE - Supplies the PTE to operate upon.
//
//    FILEINFO - Supplies the number of the paging file.
//
//    OFFSET - Supplies the offset into the paging file.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_PAGING_FILE_INFO(OUTPTE,PPTE,FILEINFO,OFFSET)            \
       (OUTPTE).u.Long = (PPTE).u.Long;                                 \
       (OUTPTE).u.Long &= CLEAR_FOR_PAGE_FILE;                          \
       (OUTPTE).u.Long |= ((FILEINFO << 1) | (OFFSET << 12));


//++
//PMMPTE
//MiPteToProto (
//    IN OUT MMPTE PPTE,
//    IN ULONG FILEINFO,
//    IN ULONG OFFSET
//    );
//
// Routine Description:
//
//   This macro returns the address of the corresponding prototype which
//   was encoded earlier into the supplied PTE.
//
//    NOTE THAT A PROTOPTE CAN ONLY RESIDE IN PAGED POOL!!!!!!
//
//    MAX SIZE = 2^(2+7+21) = 2^30 = 1GB.
//
//    NOTE that the valid bit must be zero!
//
// Arguments
//
//    lpte - Supplies the PTE to operate upon.
//
// Return Value:
//
//    Pointer to the prototype PTE that backs this PTE.
//
//--

#define MiPteToProto(lpte) (PMMPTE)((PMMPTE)(((((lpte)->u.Long) >> 11) << 9) +  \
                (((((lpte)->u.Long)) << 24) >> 23) + \
                MmProtopte_Base))


//++
//ULONG
//MiProtoAddressForPte (
//    IN PMMPTE proto_va
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//    MiProtoAddressForPte returns the bit field to OR into the PTE to
//    reference a prototype PTE.  And set the protoPTE bit,
//    MM_PTE_PROTOTYPE_MASK.
//
// Arguments
//
//    proto_va - Supplies the address of the prototype PTE.
//
// Return Value:
//
//    Mask to set into the PTE.
//
//--

#define MiProtoAddressForPte(proto_va)  \
   ((((((ULONG)proto_va - MmProtopte_Base) >> 1) & (ULONG)0x000000FE)   | \
    (((((ULONG)proto_va - MmProtopte_Base) << 2) & (ULONG)0xfffff800))) | \
    MM_PTE_PROTOTYPE_MASK)




//++
//ULONG
//MiProtoAddressForKernelPte (
//    IN PMMPTE proto_va
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//    MiProtoAddressForPte returns the bit field to OR into the PTE to
//    reference a prototype PTE.  And set the protoPTE bit,
//    MM_PTE_PROTOTYPE_MASK.
//
//    This macro also sets any other information (such as global bits)
//    required for kernel mode PTEs.
//
// Arguments
//
//    proto_va - Supplies the address of the prototype PTE.
//
// Return Value:
//
//    Mask to set into the PTE.
//
//--

//  not different on x86.

#define MiProtoAddressForKernelPte(proto_va)  MiProtoAddressForPte(proto_va)


//++
//PSUBSECTION
//MiGetSubsectionAddress (
//    IN PMMPTE lpte
//    );
//
// Routine Description:
//
//   This macro takes a PTE and returns the address of the subsection that
//   the PTE refers to.  Subsections are quadword structures allocated
//   from nonpaged pool.
//
//   NOTE THIS MACRO LIMITS THE SIZE OF NONPAGED POOL!
//    MAXIMUM NONPAGED POOL = 2^(3+4+21) = 2^28 = 256mb.
//
//
// Arguments
//
//    lpte - Supplies the PTE to operate upon.
//
// Return Value:
//
//    A pointer to the subsection referred to by the supplied PTE.
//
//--

#define MiGetSubsectionAddress(lpte)                              \
    (((lpte)->u.Long & 0x80000000) ?                              \
            ((PSUBSECTION)((PCHAR)MmSubsectionBase +    \
                ((((lpte)->u.Long & 0x7ffff800) >> 4) |              \
                (((lpte)->u.Long<<2) & 0x78)))) \
      : \
            ((PSUBSECTION)((PCHAR)MmNonPagedPoolEnd -    \
                (((((lpte)->u.Long)>>11)<<7) |              \
                (((lpte)->u.Long<<2) & 0x78)))))



//++
//ULONG
//MiGetSubsectionAddressForPte (
//    IN PSUBSECTION VA
//    );
//
// Routine Description:
//
//    This macro takes the address of a subsection and encodes it for use
//    in a PTE.
//
//    NOTE - THE SUBSECTION ADDRESS MUST BE QUADWORD ALIGNED!
//
// Arguments
//
//    VA - Supplies a pointer to the subsection to encode.
//
// Return Value:
//
//     The mask to set into the PTE to make it reference the supplied
//     subsection.
//
//--


#define MiGetSubsectionAddressForPte(VA)                   \
            (((ULONG)(VA) < (ULONG)MmSubsectionBase + 128*1024*1024) ?                  \
   (((((ULONG)VA - (ULONG)MmSubsectionBase)>>2) & (ULONG)0x0000001E) |  \
   ((((((ULONG)VA - (ULONG)MmSubsectionBase)<<4) & (ULONG)0x7ffff800)))| \
   0x80000000) \
            : \
   (((((ULONG)MmNonPagedPoolEnd - (ULONG)VA)>>2) & (ULONG)0x0000001E) |  \
   ((((((ULONG)MmNonPagedPoolEnd - (ULONG)VA)<<4) & (ULONG)0x7ffff800)))))


//++
//PMMPTE
//MiGetPdeAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeAddress returns the address of the PDE which maps the
//    given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the PDE for.
//
// Return Value:
//
//    The address of the PDE.
//
//--

#define MiGetPdeAddress(va)  ((PMMPTE)(((((ULONG)(va)) >> 22) << 2) + PDE_BASE))


//++
//PMMPTE
//MiGetPteAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPteAddress returns the address of the PTE which maps the
//    given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the PTE for.
//
// Return Value:
//
//    The address of the PTE.
//
//--

#define MiGetPteAddress(va) ((PMMPTE)(((((ULONG)(va)) >> 12) << 2) + PTE_BASE))


//++
//ULONG
//MiGetPpeOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPpeOffset returns the offset into a page root
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page root table the corresponding PPE is at.
//
//--

#define MiGetPpeOffset(va) (0)

//++
//ULONG
//MiGetPdeOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeOffset returns the offset into a page directory
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page directory table the corresponding PDE is at.
//
//--

#define MiGetPdeOffset(va) (((ULONG)(va)) >> 22)

//++
//ULONG
//MiGetPdeIndex (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeIndex returns the page directory index
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The index into the page directory - ie: the virtual page table number.
//    This is different from the page directory offset because this spans
//    page directories on supported platforms.
//
//--

#define MiGetPdeIndex MiGetPdeOffset



//++
//ULONG
//MiGetPteOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPteOffset returns the offset into a page table page
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page table page table the corresponding PTE is at.
//
//--

#define MiGetPteOffset(va) ((((ULONG)(va)) << 10) >> 22)



//++
//PVOID
//MiGetVirtualAddressMappedByPpe (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPpe returns the virtual address
//    which is mapped by a given PPE address.
//
// Arguments
//
//    PPE - Supplies the PPE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PPE.
//
//--

#define MiGetVirtualAddressMappedByPpe(PPE) (NULL)

//++
//PVOID
//MiGetVirtualAddressMappedByPde (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPde returns the virtual address
//    which is mapped by a given PDE address.
//
// Arguments
//
//    PDE - Supplies the PDE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PDE.
//
//--

#define MiGetVirtualAddressMappedByPde(PDE) ((PVOID)((ULONG)(PDE) << 20))


//++
//PVOID
//MiGetVirtualAddressMappedByPte (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPte returns the virtual address
//    which is mapped by a given PTE address.
//
// Arguments
//
//    PTE - Supplies the PTE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PTE.
//
//--

#define MiGetVirtualAddressMappedByPte(PTE) ((PVOID)((ULONG)(PTE) << 10))


//++
//LOGICAL
//MiIsVirtualAddressOnPpeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsVirtualAddressOnPpeBoundary returns TRUE if the virtual address is
//    on a page directory entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on a boundary, FALSE if not.
//
//--

#define MiIsVirtualAddressOnPpeBoundary(VA) (FALSE)


//++
//LOGICAL
//MiIsVirtualAddressOnPdeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsVirtualAddressOnPdeBoundary returns TRUE if the virtual address is
//    on a page directory entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on a 4MB PDE boundary, FALSE if not.
//
//--

#define MiIsVirtualAddressOnPdeBoundary(VA) (((ULONG_PTR)(VA) & PAGE_DIRECTORY_MASK) == 0)

//++
//LOGICAL
//MiIsPteOnPdeBoundary (
//    IN PVOID PTE
//    );
//
// Routine Description:
//
//    MiIsPteOnPdeBoundary returns TRUE if the PTE is
//    on a page directory entry boundary.
//
// Arguments
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if on a 4MB PDE boundary, FALSE if not.
//
//--

#define MiIsPteOnPdeBoundary(PTE) (((ULONG_PTR)(PTE) & (PAGE_SIZE - 1)) == 0)


//++
//ULONG
//GET_PAGING_FILE_NUMBER (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro extracts the paging file number from a PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    The paging file number.
//
//--

#define GET_PAGING_FILE_NUMBER(PTE) ((((PTE).u.Long) >> 1) & 0x0000000F)



//++
//ULONG
//GET_PAGING_FILE_OFFSET (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro extracts the offset into the paging file from a PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    The paging file offset.
//
//--

#define GET_PAGING_FILE_OFFSET(PTE) ((((PTE).u.Long) >> 12) & 0x000FFFFF)




//++
//ULONG
//IS_PTE_NOT_DEMAND_ZERO (
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro checks to see if a given PTE is NOT a demand zero PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     Returns 0 if the PTE is demand zero, non-zero otherwise.
//
//--

#define IS_PTE_NOT_DEMAND_ZERO(PTE) ((PTE).u.Long & (ULONG)0xFFFFFC01)




//++
//VOID
//MI_MAKING_VALID_PTE_INVALID(
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    Prepare to make a single valid PTE invalid.
//    No action is required on x86.
//
// Arguments
//
//    SYSTEM_WIDE - Supplies TRUE if this will happen on all processors.
//
// Return Value:
//
//    None.
//
//--

#define MI_MAKING_VALID_PTE_INVALID(SYSTEM_WIDE)


//++
//VOID
//MI_MAKING_VALID_MULTIPLE_PTES_INVALID(
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    Prepare to make multiple valid PTEs invalid.
//    No action is required on x86.
//
// Arguments
//
//    SYSTEM_WIDE - Supplies TRUE if this will happen on all processors.
//
// Return Value:
//
//    None.
//
//--

#define MI_MAKING_MULTIPLE_PTES_INVALID(SYSTEM_WIDE)



//++
//VOID
//MI_MAKE_PROTECT_WRITE_COPY (
//    IN OUT MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro makes a writable PTE a writable-copy PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    NONE
//
//--

#define MI_MAKE_PROTECT_WRITE_COPY(PTE) \
        if ((PTE).u.Soft.Protection & MM_PROTECTION_WRITE_MASK) {      \
            (PTE).u.Long |= MM_PROTECTION_COPY_MASK << MM_PROTECT_FIELD_SHIFT;      \
        }


//++
//VOID
//MI_SET_PAGE_DIRTY(
//    IN PMMPTE PPTE,
//    IN PVOID VA,
//    IN PVOID PFNHELD
//    );
//
// Routine Description:
//
//    This macro sets the dirty bit (and release page file space).
//
// Arguments
//
//    TEMP - Supplies a temporary for usage.
//
//    PPTE - Supplies a pointer to the PTE that corresponds to VA.
//
//    VA - Supplies a the virtual address of the page fault.
//
//    PFNHELD - Supplies TRUE if the PFN lock is held.
//
// Return Value:
//
//    None.
//
//--

#if defined(NT_UP)
#define MI_SET_PAGE_DIRTY(PPTE,VA,PFNHELD)
#else
#define MI_SET_PAGE_DIRTY(PPTE,VA,PFNHELD)                          \
            if ((PPTE)->u.Hard.Dirty == 1) {                        \
                MiSetDirtyBit ((VA),(PPTE),(PFNHELD));              \
            }
#endif




//++
//VOID
//MI_NO_FAULT_FOUND(
//    IN FAULTSTATUS,
//    IN PMMPTE PPTE,
//    IN PVOID VA,
//    IN PVOID PFNHELD
//    );
//
// Routine Description:
//
//    This macro handles the case when a page fault is taken and no
//    PTE with the valid bit clear is found.
//
// Arguments
//
//    FAULTSTATUS - Supplies the fault status.
//
//    PPTE - Supplies a pointer to the PTE that corresponds to VA.
//
//    VA - Supplies a the virtual address of the page fault.
//
//    PFNHELD - Supplies TRUE if the PFN lock is held.
//
// Return Value:
//
//    None.
//
//--

#if defined(NT_UP)
#define MI_NO_FAULT_FOUND(FAULTSTATUS,PPTE,VA,PFNHELD)
#else
#define MI_NO_FAULT_FOUND(FAULTSTATUS,PPTE,VA,PFNHELD) \
        if ((MI_FAULT_STATUS_INDICATES_WRITE(FAULTSTATUS)) && ((PPTE)->u.Hard.Dirty == 0)) {  \
            MiSetDirtyBit ((VA),(PPTE),(PFNHELD));     \
        }
#endif




//++
//ULONG
//MI_CAPTURE_DIRTY_BIT_TO_PFN (
//    IN PMMPTE PPTE,
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro gets captures the state of the dirty bit to the PFN
//    and frees any associated page file space if the PTE has been
//    modified element.
//
//    NOTE - THE PFN LOCK MUST BE HELD!
//
// Arguments
//
//    PPTE - Supplies the PTE to operate upon.
//
//    PPFN - Supplies a pointer to the PFN database element that corresponds
//           to the page mapped by the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_CAPTURE_DIRTY_BIT_TO_PFN(PPTE,PPFN)                      \
         ASSERT (KeGetCurrentIrql() > APC_LEVEL);                   \
         if (((PPFN)->u3.e1.Modified == 0) &&                       \
            ((PPTE)->u.Hard.Dirty != 0)) {                          \
             MI_SET_MODIFIED (PPFN, 1, 0x18);                       \
             if (((PPFN)->OriginalPte.u.Soft.Prototype == 0) &&     \
                          ((PPFN)->u3.e1.WriteInProgress == 0)) {   \
                 MiReleasePageFileSpace ((PPFN)->OriginalPte);      \
                 (PPFN)->OriginalPte.u.Soft.PageFileHigh = 0;       \
             }                                                      \
         }


//++
//BOOLEAN
//MI_IS_PHYSICAL_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    physical address.
//
// Arguments
//
//    VA - Supplies the virtual address.
//
// Return Value:
//
//    FALSE if it is not a physical address, TRUE if it is.
//
//--


#define MI_IS_PHYSICAL_ADDRESS(Va) \
    ((MiGetPdeAddress(Va)->u.Long & 0x81) == 0x81)

//++
//ULONG
//MI_CONVERT_PHYSICAL_TO_PFN (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro converts a physical address (see MI_IS_PHYSICAL_ADDRESS)
//    to its corresponding physical frame number.
//
// Arguments
//
//    VA - Supplies a pointer to the physical address.
//
// Return Value:
//
//    Returns the PFN for the page.
//
//--


#define MI_CONVERT_PHYSICAL_TO_PFN(Va)     \
    ((PFN_NUMBER)(MiGetPdeAddress(Va)->u.Hard.PageFrameNumber) + (MiGetPteOffset((ULONG)Va)))


typedef struct _MMCOLOR_TABLES {
    PFN_NUMBER Flink;
    PVOID Blink;
    PFN_NUMBER Count;
} MMCOLOR_TABLES, *PMMCOLOR_TABLES;

extern PMMCOLOR_TABLES MmFreePagesByColor[2];

extern ULONG MmTotalPagesForPagingFile;


//
// A VALID Page Table Entry on the x86 has the following definition.
//

#define MI_MAXIMUM_PAGEFILE_SIZE (((UINT64)1 * 1024 * 1024 - 1) * PAGE_SIZE)

#define MI_PTE_LOOKUP_NEEDED (0xfffff)

typedef struct _MMPTE_SOFTWARE {
    ULONG Valid : 1;
    ULONG PageFileLow : 4;
    ULONG Protection : 5;
    ULONG Prototype : 1;
    ULONG Transition : 1;
    ULONG PageFileHigh : 20;
} MMPTE_SOFTWARE;

typedef struct _MMPTE_TRANSITION {
    ULONG Valid : 1;
    ULONG Write : 1;
    ULONG Owner : 1;
    ULONG WriteThrough : 1;
    ULONG CacheDisable : 1;
    ULONG Protection : 5;
    ULONG Prototype : 1;
    ULONG Transition : 1;
    ULONG PageFrameNumber : 20;
} MMPTE_TRANSITION;

typedef struct _MMPTE_PROTOTYPE {
    ULONG Valid : 1;
    ULONG ProtoAddressLow : 7;
    ULONG ReadOnly : 1;  // if set allow read only access.
    ULONG WhichPool : 1;
    ULONG Prototype : 1;
    ULONG ProtoAddressHigh : 21;
} MMPTE_PROTOTYPE;

typedef struct _MMPTE_SUBSECTION {
    ULONG Valid : 1;
    ULONG SubsectionAddressLow : 4;
    ULONG Protection : 5;
    ULONG Prototype : 1;
    ULONG SubsectionAddressHigh : 20;
    ULONG WhichPool : 1;
} MMPTE_SUBSECTION;

typedef struct _MMPTE_LIST {
    ULONG Valid : 1;
    ULONG OneEntry : 1;
    ULONG filler0 : 8;

    //
    // Note the Prototype bit must not be used for lists like freed nonpaged
    // pool because lookaside pops can legitimately reference bogus addresses
    // (since the pop is unsynchronized) and the fault handler must be able to
    // distinguish lists from protos so a retry status can be returned (vs a
    // fatal bugcheck).
    //

    ULONG Prototype : 1;            // MUST BE ZERO as per above comment.
    ULONG filler1 : 1;
    ULONG NextEntry : 20;
} MMPTE_LIST;

//
// A Page Table Entry on the x86 has the following definition.
// Note the MP version is to avoid stalls when flushing TBs across processors.
//

typedef struct _MMPTE_HARDWARE {
    ULONG Valid : 1;
#if defined(NT_UP)
    ULONG Write : 1;       // UP version
#else
    ULONG Writable : 1;    // changed for MP version
#endif
    ULONG Owner : 1;
    ULONG WriteThrough : 1;
    ULONG CacheDisable : 1;
    ULONG Accessed : 1;
    ULONG Dirty : 1;
    ULONG LargePage : 1;
    ULONG Global : 1;
    ULONG CopyOnWrite : 1; // software field
    ULONG Prototype : 1;   // software field
#if defined(NT_UP)
    ULONG reserved : 1;    // software field
#else
    ULONG Write : 1;       // software field - MP change
#endif
    ULONG PageFrameNumber : 20;
} MMPTE_HARDWARE, *PMMPTE_HARDWARE;

#if defined(NT_UP)
#define HARDWARE_PTE_DIRTY_MASK     0x40
#else
#define HARDWARE_PTE_DIRTY_MASK     0x42
#endif

#define MI_PDE_MAPS_LARGE_PAGE(PDE) ((PDE)->u.Hard.LargePage == 1)

#define MI_MAKE_PDE_MAP_LARGE_PAGE(PDE) ((PDE)->u.Hard.LargePage = 1)

#define MI_GET_PAGE_FRAME_FROM_PTE(PTE) ((PTE)->u.Hard.PageFrameNumber)
#define MI_GET_PAGE_FRAME_FROM_TRANSITION_PTE(PTE) ((PTE)->u.Trans.PageFrameNumber)
#define MI_GET_PROTECTION_FROM_SOFT_PTE(PTE) ((PTE)->u.Soft.Protection)
#define MI_GET_PROTECTION_FROM_TRANSITION_PTE(PTE) ((PTE)->u.Trans.Protection)

typedef struct _MMPTE {
    union  {
        ULONG Long;
        HARDWARE_PTE Flush;
        MMPTE_HARDWARE Hard;
        MMPTE_PROTOTYPE Proto;
        MMPTE_SOFTWARE Soft;
        MMPTE_TRANSITION Trans;
        MMPTE_SUBSECTION Subsect;
        MMPTE_LIST List;
        } u;
} MMPTE;

typedef MMPTE *PMMPTE;

extern MMPTE MmPteGlobal; // Set if processor supports Global Page, else zero.

extern PMMPTE MiFirstReservedZeroingPte;

#define InterlockedCompareExchangePte(_PointerPte, _NewContents, _OldContents) \
        InterlockedCompareExchange ((PLONG)(_PointerPte), _NewContents, _OldContents)

#define InterlockedExchangePte(_PointerPte, _NewContents) InterlockedExchange((PLONG)(_PointerPte), _NewContents)

//++
//VOID
//MI_WRITE_VALID_PTE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE fills in the specified PTE making it valid with the
//    specified contents.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 0);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MI_WRITE_INVALID_PTE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_INVALID_PTE fills in the specified PTE making it invalid with the
//    specified contents.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_INVALID_PTE(_PointerPte, _PteContents)  \
            ASSERT ((_PteContents).u.Hard.Valid == 0);  \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MI_WRITE_VALID_PTE_NEW_PROTECTION (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE_NEW_PROTECTION fills in the specified PTE (which was
//    already valid) changing only the protection or the dirty bit.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE_NEW_PROTECTION(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 1);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            ASSERT ((_PointerPte)->u.Hard.PageFrameNumber == (_PteContents).u.Hard.PageFrameNumber); \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MI_WRITE_VALID_PTE_NEW_PAGE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE_NEW_PAGE fills in the specified PTE (which was
//    already valid) changing the page and the protection.
//    Note that the contents are very carefully written.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE_NEW_PAGE(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 1);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            ASSERT ((_PointerPte)->u.Hard.PageFrameNumber != (_PteContents).u.Hard.PageFrameNumber); \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MiFillMemoryPte (
//    IN PMMPTE Destination,
//    IN ULONG  NumberOfPtes,
//    IN MMPTE  Pattern,
//    };
//
// Routine Description:
//
//    This function fills memory with the specified PTE pattern.
//
// Arguments
//
//    Destination - Supplies a pointer to the memory to fill.
//
//    NumberOfPtes - Supplies the number of PTEs (not bytes!) to be filled.
//
//    Pattern     - Supplies the PTE fill pattern.
//
// Return Value:
//
//    None.
//
//--

#define MiFillMemoryPte(Destination, Length, Pattern) \
             RtlFillMemoryUlong ((Destination), (Length) * sizeof (MMPTE), (Pattern))

#define MiZeroMemoryPte(Destination, Length) \
             RtlZeroMemory ((Destination), (Length) * sizeof (MMPTE))

ULONG
FASTCALL
MiDetermineUserGlobalPteMask (
    IN PMMPTE Pte
    );

//++
//BOOLEAN
//MI_IS_PAGE_TABLE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page table address, FALSE if not.
//
//--

#define MI_IS_PAGE_TABLE_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)PTE_BASE && (PVOID)(VA) <= (PVOID)PTE_TOP)

//++
//BOOLEAN
//MI_IS_PAGE_TABLE_OR_HYPER_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table or hyperspace address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page table or hyperspace address, FALSE if not.
//
//--

#define MI_IS_PAGE_TABLE_OR_HYPER_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)PTE_BASE && (PVOID)(VA) <= (PVOID)HYPER_SPACE_END)

//++
//BOOLEAN
//MI_IS_KERNEL_PAGE_TABLE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table address for a kernel address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a kernel page table address, FALSE if not.
//
//--

#define MI_IS_KERNEL_PAGE_TABLE_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)MiGetPteAddress(MmSystemRangeStart) && (PVOID)(VA) <= (PVOID)PTE_TOP)


//++
//BOOLEAN
//MI_IS_PAGE_DIRECTORY_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page directory address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page directory address, FALSE if not.
//
//--

#define MI_IS_PAGE_DIRECTORY_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)PDE_BASE && (PVOID)(VA) <= (PVOID)PDE_TOP)


//++
//BOOLEAN
//MI_IS_HYPER_SPACE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a hyper space address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a hyper space address, FALSE if not.
//
//--

#define MI_IS_HYPER_SPACE_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)HYPER_SPACE && (PVOID)(VA) <= (PVOID)HYPER_SPACE_END)


//++
//BOOLEAN
//MI_IS_PROCESS_SPACE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a process-specific address.  This is an address in user space
//    or page table pages or hyper space.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a process-specific address, FALSE if not.
//
//--

#define MI_IS_PROCESS_SPACE_ADDRESS(VA)   \
            (((PVOID)(VA) <= (PVOID)MM_HIGHEST_USER_ADDRESS) || \
             ((PVOID)(VA) >= (PVOID)PTE_BASE && (PVOID)(VA) <= (PVOID)HYPER_SPACE_END))


//++
//BOOLEAN
//MI_IS_PTE_PROTOTYPE (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a PTE address and determines if it is a prototype PTE.
//
// Arguments
//
//    PTE - Supplies the virtual address of the PTE to check.
//
// Return Value:
//
//    TRUE if the PTE is in a segment (ie, a prototype PTE), FALSE if not.
//
//--

#define MI_IS_PTE_PROTOTYPE(PTE)   \
            ((PTE) > (PMMPTE)PTE_TOP)

//++
//BOOLEAN
//MI_IS_SYSTEM_CACHE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a system cache address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is in the system cache, FALSE if not.
//
//--

#define MI_IS_SYSTEM_CACHE_ADDRESS(VA)                            \
         (((PVOID)(VA) >= (PVOID)MmSystemCacheStart &&            \
		     (PVOID)(VA) <= (PVOID)MmSystemCacheEnd)  ||          \
          ((PVOID)(VA) >= (PVOID)MiSystemCacheStartExtra &&       \
			  (PVOID)(VA) <= (PVOID)MiSystemCacheEndExtra))

//++
//VOID
//MI_BARRIER_SYNCHRONIZE (
//    IN ULONG TimeStamp
//    );
//
// Routine Description:
//
//    MI_BARRIER_SYNCHRONIZE compares the argument timestamp against the
//    current IPI barrier sequence stamp.  When equal, all processors will
//    issue memory barriers to ensure that newly created pages remain coherent.
//
//    When a page is put in the zeroed or free page list the current
//    barrier sequence stamp is read (interlocked - this is necessary
//    to get the correct value - memory barriers won't do the trick)
//    and stored in the pfn entry for the page. The current barrier
//    sequence stamp is maintained by the IPI send logic and is
//    incremented (interlocked) when the target set of an IPI send
//    includes all processors, but the one doing the send. When a page
//    is needed its sequence number is compared against the current
//    barrier sequence number.  If it is equal, then the contents of
//    the page may not be coherent on all processors, and an IPI must
//    be sent to all processors to ensure a memory barrier is
//    executed (generic call can be used for this). Sending the IPI
//    automatically updates the barrier sequence number. The compare
//    is for equality as this is the only value that requires the IPI
//    (i.e., the sequence number wraps, values in both directions are
//    older). When a page is removed in this fashion and either found
//    to be coherent or made coherent, it cannot be modified between
//    that time and writing the PTE. If the page is modified between
//    these times, then an IPI must be sent.
//
// Arguments
//
//    TimeStamp - Supplies the timestamp at the time when the page was zeroed.
//
// Return Value:
//
//    None.
//
//--

// does nothing on i386.

#define MI_BARRIER_SYNCHRONIZE(TimeStamp)

//++
//VOID
//MI_BARRIER_STAMP_ZEROED_PAGE (
//    IN PULONG PointerTimeStamp
//    );
//
// Routine Description:
//
//    MI_BARRIER_STAMP_ZEROED_PAGE issues an interlocked read to get the
//    current IPI barrier sequence stamp.  This is called AFTER a page is
//    zeroed.
//
// Arguments
//
//    PointerTimeStamp - Supplies a timestamp pointer to fill with the
//                       current IPI barrier sequence stamp.
//
// Return Value:
//
//    None.
//
//--

// does nothing on i386.

#define MI_BARRIER_STAMP_ZEROED_PAGE(PointerTimeStamp)

//++
//VOID
//MI_FLUSH_SINGLE_SESSION_TB (
//    IN PVOID Virtual
//    );
//
// Routine Description:
//
//    MI_FLUSH_SINGLE_SESSION_TB flushes the requested single address
//    translation from the TB.
//
//    Since there are no ASNs on the x86, this routine becomes a single
//    TB invalidate.
//
// Arguments
//
//    Virtual - Supplies the virtual address to invalidate.
//
// Return Value:
//
//    None.
//
//--

#define MI_FLUSH_SINGLE_SESSION_TB(Virtual) \
    KeFlushSingleTb (Virtual, TRUE);

//++
//VOID
//MI_FLUSH_ENTIRE_SESSION_TB (
//    IN ULONG Invalid,
//    IN LOGICAL AllProcessors
//    );
//
// Routine Description:
//
//    MI_FLUSH_ENTIRE_SESSION_TB flushes the entire TB on processors which
//    support ASNs.
//
//    Since there are no ASNs on the x86, this routine does nothing.
//
// Arguments
//
//    Invalid - TRUE if invalidating.
//
//    AllProcessors - TRUE if all processors need to be IPI'd.
//
// Return Value:
//
//    None.
//

#define MI_FLUSH_ENTIRE_SESSION_TB(Invalid, AllProcessors) \
    NOTHING;

//++
//LOGICAL
//MI_RESERVED_BITS_CANONICAL (
//    IN PVOID VirtualAddress
//    );
//
// Routine Description:
//
//    This routine checks whether all of the reserved bits are correct.
//
//    This does nothing on the x86.
//
// Arguments
//
//    VirtualAddress - Supplies the virtual address to check.
//
// Return Value:
//
//    None.
//
#define MI_RESERVED_BITS_CANONICAL(VirtualAddress)  TRUE

//++
//VOID
//MI_DISPLAY_TRAP_INFORMATION (
//    IN PVOID TrapInformation
//    );
//
// Routine Description:
//
//    Display any relevant trap information to aid debugging.
//
// Arguments
//
//    TrapInformation - Supplies a pointer to a trap frame.
//
// Return Value:
//
//    None.
//
#define MI_DISPLAY_TRAP_INFORMATION(TrapInformation)                    \
            KdPrint(("MM:***EIP %p, EFL %p\n",                          \
                     ((PKTRAP_FRAME) (TrapInformation))->Eip,           \
                     ((PKTRAP_FRAME) (TrapInformation))->EFlags));      \
            KdPrint(("MM:***EAX %p, ECX %p EDX %p\n",                   \
                     ((PKTRAP_FRAME) (TrapInformation))->Eax,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Ecx,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Edx));         \
            KdPrint(("MM:***EBX %p, ESI %p EDI %p\n",                   \
                     ((PKTRAP_FRAME) (TrapInformation))->Ebx,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Esi,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Edi));

#else
#include "i386\mipae.h"
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\amd64\miamd.h ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    miamd.h

Abstract:

    This module contains the private data structures and procedure
    prototypes for the hardware dependent portion of the
    memory management system.

    This module is specifically tailored for the AMD 64-bit processor.

Author:

    Landy Wang (landyw) 08-Apr-2000

Revision History:

--*/

/*++

    Virtual Memory Layout on the AMD64 is:

                 +------------------------------------+
0000000000000000 | User mode addresses - 8tb minus 64k|
                 |                                    |
                 |                                    |
000007FFFFFEFFFF |                                    | MM_HIGHEST_USER_ADDRESS
                 +------------------------------------+
000007FFFFFF0000 | 64k No Access Region               | MM_USER_PROBE_ADDRESS
000007FFFFFFFFFF |                                    |
                 +------------------------------------+

                                   .
                 +------------------------------------+
FFFF080000000000 | Start of System space              | MM_SYSTEM_RANGE_START
                 +------------------------------------+
FFFFF68000000000 | 512gb four level page table map.   | PTE_BASE
                 +------------------------------------+
FFFFF70000000000 | HyperSpace - working set lists     | HYPER_SPACE
                 | and per process memory management  |
                 | structures mapped in this 512gb    |
                 | region.                            | HYPER_SPACE_END
                 +------------------------------------+     MM_WORKING_SET_END
FFFFF78000000000 | Shared system page                 | KI_USER_SHARED_DATA
                 +------------------------------------+
FFFFF78000001000 | The system cache working set       | MM_SYSTEM_CACHE_WORKING_SET
                 | information resides in this        |
                 | 512gb-4k region.                   |
                 |                                    |
                 +------------------------------------+
                                   .
                                   .
Note the ranges below are sign extended for > 43 bits and therefore
can be used with interlocked slists.  The system address space above is NOT.
                                   .
                                   .
                 +------------------------------------+
FFFFF80000000000 | Start of 1tb of                    | MM_KSEG0_BASE
                 | physically addressable memory.     | MM_KSEG2_BASE
                 +------------------------------------+
FFFFF90000000000 | win32k.sys                         |
                 |                                    |
                 | Hydra configurations have session  |
                 | data structures here.              |
                 |                                    |
                 | This is a 512gb region.            |
                 +------------------------------------+
                 |                                    | MM_SYSTEM_SPACE_START
FFFFF98000000000 | System cache resides here.         | MM_SYSTEM_CACHE_START
                 |  Kernel mode access only.          |
                 |  1tb.                              |
                 |                                    | MM_SYSTEM_CACHE_END
                 +------------------------------------+
FFFFFA8000000000 | Start of paged system area.        | MM_PAGED_POOL_START
                 |  Kernel mode access only.          |
                 |  128gb.                            |
                 +------------------------------------+
                 | System mapped views start just     |
                 | after paged pool.  Default is      |
                 | 104MB, can be registry-overridden. |
                 | 8GB maximum.                       |
                 |                                    |
                 +------------------------------------+
FFFFFAA000000000 | System PTE pool.                   | MM_LOWEST_NONPAGED_SYSTEM_START
                 |  Kernel mode access only.          |
                 |  128gb.                            |
                 +------------------------------------+
FFFFFAC000000000 | NonPaged pool.                     | MM_NON_PAGED_POOL_START
                 |  Kernel mode access only.          |
                 |  128gb.                            |
                 |                                    |
FFFFFADFFFFFFFFF |  NonPaged System area              | MM_NONPAGED_POOL_END
                 +------------------------------------+
                                   .
                                   .
                                   .
                                   .
                 +------------------------------------+
FFFFFFFF80000000 |                                    |
                 | Reserved for the HAL. 2gb.         |
FFFFFFFFFFFFFFFF |                                    | MM_SYSTEM_SPACE_END
                 +------------------------------------+

--*/

#define _MI_PAGING_LEVELS 4

#define _MI_MORE_THAN_4GB_ 1

#define IMAGE_FILE_MACHINE_NATIVE   IMAGE_FILE_MACHINE_AMD64

//
// Top level PXE mapping allocations:
//
// 0x0->0xF:        0x10 user entries
// 0x1ed:           0x1 for selfmaps
// 0x1ee:           0x1 hyperspace entry
// 0x1ef:           0x1 entry for syscache WSL & shared user data
// 0x1f0->0x1ff:    0x10 kernel entries
//

//
// Define empty list markers.
//

#define MM_EMPTY_LIST ((ULONG_PTR)-1)              //
#define MM_EMPTY_PTE_LIST 0xFFFFFFFFUI64 // N.B. tied to MMPTE definition

#define MI_PTE_BASE_FOR_LOWEST_KERNEL_ADDRESS (MiGetPteAddress (MM_KSEG0_BASE))

#define MI_PTE_BASE_FOR_LOWEST_SESSION_ADDRESS (MiGetPteAddress (MM_SESSION_SPACE_DEFAULT))

//
// This is the size of the region used by the loader.
//

extern ULONG_PTR MmBootImageSize;

//
// PAGE_SIZE for AMD64 is 4k, virtual page is 36 bits with a PAGE_SHIFT
// byte offset.
//

#define MM_VIRTUAL_PAGE_FILLER 0
#define MM_VIRTUAL_PAGE_SIZE (48 - 12)

//
// Address space layout definitions.
//

#define MM_KSEG0_BASE  0xFFFFF80000000000UI64

#define MM_KSEG2_BASE  0xFFFFF90000000000UI64

#define MM_PAGES_IN_KSEG0 ((MM_KSEG2_BASE - MM_KSEG0_BASE) >> PAGE_SHIFT)

#define MM_SYSTEM_SPACE_START 0xFFFFF98000000000UI64

#define MM_SYSTEM_SPACE_END 0xFFFFFFFFFFFFFFFFUI64

#define MM_USER_ADDRESS_RANGE_LIMIT    0xFFFFFFFFFFFFFFFF // user address range limit
#define MM_MAXIMUM_ZERO_BITS 53         // maximum number of zero bits

//
// Define the start and maximum size for the system cache.
//

#define MM_SYSTEM_CACHE_START 0xFFFFF98000000000UI64

#define MM_SYSTEM_CACHE_END   0xFFFFFA8000000000UI64

#define MM_MAXIMUM_SYSTEM_CACHE_SIZE \
    ((MM_SYSTEM_CACHE_END - MM_SYSTEM_CACHE_START) >> PAGE_SHIFT)

#define MM_SYSTEM_CACHE_WORKING_SET 0xFFFFF78000001000UI64

//
// Define area for mapping views into system space.
//

#define MM_SESSION_SPACE_DEFAULT_END    0xFFFFF98000000000UI64
#define MM_SESSION_SPACE_DEFAULT        (MM_SESSION_SPACE_DEFAULT_END - MI_SESSION_SPACE_MAXIMUM_TOTAL_SIZE)

#define MM_SYSTEM_VIEW_SIZE (104 * 1024 * 1024)

//
// Various system resource locations.
//

#define MM_PAGED_POOL_START ((PVOID)0xFFFFFA8000000000)

#define MM_LOWEST_NONPAGED_SYSTEM_START ((PVOID)0xFFFFFAA000000000)

#define MM_NONPAGED_POOL_END ((PVOID)(0xFFFFFAE000000000)) 

extern PVOID MmDebugVa;
#define MM_DEBUG_VA MmDebugVa

extern PVOID MmCrashDumpVa;
#define MM_CRASH_DUMP_VA MmCrashDumpVa

#define NON_PAGED_SYSTEM_END ((PVOID)0xFFFFFFFFFFFFFFF0)

extern BOOLEAN MiWriteCombiningPtes;

//
// Define absolute minimum and maximum count for system PTEs.
//

#define MM_MINIMUM_SYSTEM_PTES 7000

#define MM_MAXIMUM_SYSTEM_PTES (16*1024*1024)

#define MM_DEFAULT_SYSTEM_PTES 11000

//
// Pool limits.
//
// The maximum amount of nonpaged pool that can be initially created.
//

#define MM_MAX_INITIAL_NONPAGED_POOL (128 * 1024 * 1024)

//
// The total amount of nonpaged pool (initial pool + expansion).
//

#define MM_MAX_ADDITIONAL_NONPAGED_POOL (((SIZE_T)128 * 1024 * 1024 * 1024))

//
// The maximum amount of paged pool that can be created.
//

#define MM_MAX_PAGED_POOL ((SIZE_T)128 * 1024 * 1024 * 1024)

#define MM_MAX_DEFAULT_NONPAGED_POOL ((SIZE_T)8 * 1024 * 1024 * 1024)


//
// Structure layout definitions.
//

#define MM_PROTO_PTE_ALIGNMENT ((ULONG)MM_MAXIMUM_NUMBER_OF_COLORS * (ULONG)PAGE_SIZE)

//
// Define the address bits mapped by one PXE/PPE/PDE/PTE entry.
//

#define MM_VA_MAPPED_BY_PTE ((ULONG_PTR)PAGE_SIZE)
#define MM_VA_MAPPED_BY_PDE (PTE_PER_PAGE * MM_VA_MAPPED_BY_PTE)
#define MM_VA_MAPPED_BY_PPE (PDE_PER_PAGE * MM_VA_MAPPED_BY_PDE)
#define MM_VA_MAPPED_BY_PXE (PPE_PER_PAGE * MM_VA_MAPPED_BY_PPE)

//
// Define the address bits mapped by PPE and PDE entries.
//
// A PXE entry maps 9+9+9+12 = 39 bits of address space.
// A PPE entry maps 9+9+12 = 30 bits of address space.
// A PDE entry maps 9+12 = 21 bits of address space.
//

#define PAGE_DIRECTORY0_MASK (MM_VA_MAPPED_BY_PXE - 1)
#define PAGE_DIRECTORY1_MASK (MM_VA_MAPPED_BY_PPE - 1)
#define PAGE_DIRECTORY2_MASK (MM_VA_MAPPED_BY_PDE - 1)

#define PTE_SHIFT 3

#define MM_MINIMUM_VA_FOR_LARGE_PAGE MM_VA_MAPPED_BY_PDE

//
// The number of bits in a virtual address.
//

#define VIRTUAL_ADDRESS_BITS 48
#define VIRTUAL_ADDRESS_MASK ((((ULONG_PTR)1) << VIRTUAL_ADDRESS_BITS) - 1)

//
// The number of bits in a physical address.
//

#define PHYSICAL_ADDRESS_BITS 40

#define MM_MAXIMUM_NUMBER_OF_COLORS (1)

//
// AMD64 does not require support for colored pages.
//

#define MM_NUMBER_OF_COLORS (1)

//
// Mask for obtaining color from a physical page number.
//

#define MM_COLOR_MASK (0)

//
// Boundary for aligned pages of like color upon.
//

#define MM_COLOR_ALIGNMENT (0)

//
// Mask for isolating color from virtual address.
//

#define MM_COLOR_MASK_VIRTUAL (0)

//
//  Define 256k worth of secondary colors.
//

#define MM_SECONDARY_COLORS_DEFAULT (64)

#define MM_SECONDARY_COLORS_MIN (2)

#define MM_SECONDARY_COLORS_MAX (1024)

//
// Maximum number of paging files.
//

#define MAX_PAGE_FILES 16


//
// Hyper space definitions.
//

#define HYPER_SPACE     ((PVOID)0xFFFFF70000000000)
#define HYPER_SPACE_END         0xFFFFF77FFFFFFFFFUI64

#define FIRST_MAPPING_PTE    0xFFFFF70000000000

#define NUMBER_OF_MAPPING_PTES 126

#define LAST_MAPPING_PTE   \
    (FIRST_MAPPING_PTE + (NUMBER_OF_MAPPING_PTES * PAGE_SIZE))

#define COMPRESSION_MAPPING_PTE   ((PMMPTE)((ULONG_PTR)LAST_MAPPING_PTE + PAGE_SIZE))

#define IMAGE_MAPPING_PTE   ((PMMPTE)((ULONG_PTR)COMPRESSION_MAPPING_PTE + PAGE_SIZE))

#define NUMBER_OF_ZEROING_PTES 256

#define VAD_BITMAP_SPACE    ((PVOID)((ULONG_PTR)IMAGE_MAPPING_PTE + PAGE_SIZE))

#define WORKING_SET_LIST   ((PVOID)((ULONG_PTR)VAD_BITMAP_SPACE + PAGE_SIZE))

#define MM_MAXIMUM_WORKING_SET \
    ((((ULONG_PTR)8 * 1024 * 1024 * 1024 * 1024) - (64 * 1024 * 1024)) >> PAGE_SHIFT) //8Tb-64Mb

#define MmWorkingSetList ((PMMWSL)WORKING_SET_LIST)

#define MmWsle ((PMMWSLE)((PUCHAR)WORKING_SET_LIST + sizeof(MMWSL)))

#define MM_WORKING_SET_END (HYPER_SPACE_END + 1)

//
// Define masks for fields within the PTE.
//

#define MM_PTE_VALID_MASK         0x1
#if defined(NT_UP)
#define MM_PTE_WRITE_MASK         0x2
#else
#define MM_PTE_WRITE_MASK         0x800
#endif
#define MM_PTE_OWNER_MASK         0x4
#define MM_PTE_WRITE_THROUGH_MASK 0x8
#define MM_PTE_CACHE_DISABLE_MASK 0x10
#define MM_PTE_ACCESS_MASK        0x20
#if defined(NT_UP)
#define MM_PTE_DIRTY_MASK         0x40
#else
#define MM_PTE_DIRTY_MASK         0x42
#endif
#define MM_PTE_LARGE_PAGE_MASK    0x80
#define MM_PTE_GLOBAL_MASK        0x100
#define MM_PTE_COPY_ON_WRITE_MASK 0x200
#define MM_PTE_PROTOTYPE_MASK     0x400
#define MM_PTE_TRANSITION_MASK    0x800

//
// Bit fields to or into PTE to make a PTE valid based on the
// protection field of the invalid PTE.
//

#define MM_PTE_NOACCESS          0x0   // not expressable on AMD64
#define MM_PTE_READONLY          0x0
#define MM_PTE_READWRITE         MM_PTE_WRITE_MASK
#define MM_PTE_WRITECOPY         0x200 // read-only copy on write bit set.
#define MM_PTE_EXECUTE           0x0   // read-only on AMD64
#define MM_PTE_EXECUTE_READ      0x0
#define MM_PTE_EXECUTE_READWRITE MM_PTE_WRITE_MASK
#define MM_PTE_EXECUTE_WRITECOPY 0x200 // read-only copy on write bit set.
#define MM_PTE_NOCACHE           0x010
#define MM_PTE_GUARD             0x0  // not expressable on AMD64
#define MM_PTE_CACHE             0x0

#define MM_PROTECT_FIELD_SHIFT 5

//
// Bits available for the software working set index within the hardware PTE.
//

#define MI_MAXIMUM_PTE_WORKING_SET_INDEX (1 << _HARDWARE_PTE_WORKING_SET_BITS)

//
// Zero PTE
//

#define MM_ZERO_PTE 0

//
// Zero Kernel PTE
//

#define MM_ZERO_KERNEL_PTE 0

//
// A demand zero PTE with a protection or PAGE_READWRITE.
//

#define MM_DEMAND_ZERO_WRITE_PTE (MM_READWRITE << MM_PROTECT_FIELD_SHIFT)


//
// A demand zero PTE with a protection or PAGE_READWRITE for system space.
//

#define MM_KERNEL_DEMAND_ZERO_PTE (MM_READWRITE << MM_PROTECT_FIELD_SHIFT)

//
// A no access PTE for system space.
//

#define MM_KERNEL_NOACCESS_PTE (MM_NOACCESS << MM_PROTECT_FIELD_SHIFT)

//
// Kernel stack alignment requirements.
//

#define MM_STACK_ALIGNMENT 0x0

#define MM_STACK_OFFSET 0x0

//
// System process definitions
//

#define PXE_PER_PAGE 512
#define PPE_PER_PAGE 512
#define PDE_PER_PAGE 512
#define PTE_PER_PAGE 512
#define PTE_PER_PAGE_BITS 10    // This handles the case where the page is full

#if PTE_PER_PAGE_BITS > 32
error - too many bits to fit into MMPTE_SOFTWARE or MMPFN.u1
#endif

//
// Number of page table pages for user addresses.
//

#define MM_USER_PXES (0x10)

#define MM_USER_PAGE_TABLE_PAGES ((ULONG_PTR)PDE_PER_PAGE * PPE_PER_PAGE * MM_USER_PXES)

#define MM_USER_PAGE_DIRECTORY_PAGES (PPE_PER_PAGE * MM_USER_PXES)

#define MM_USER_PAGE_DIRECTORY_PARENT_PAGES (MM_USER_PXES)

//++
//VOID
//MI_MAKE_VALID_PTE (
//    OUT OUTPTE,
//    IN FRAME,
//    IN PMASK,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro makes a valid PTE from a page frame number, protection mask,
//    and owner.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the transition PTE.
//
//    FRAME - Supplies the page frame number for the PTE.
//
//    PMASK - Supplies the protection to set in the transition PTE.
//
//    PPTE - Supplies a pointer to the PTE which is being made valid.
//           For prototype PTEs NULL should be specified.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_VALID_PTE(OUTPTE, FRAME, PMASK, PPTE) {             \
    (OUTPTE).u.Long = MmProtectToPteMask[PMASK] | MM_PTE_VALID_MASK; \
    (OUTPTE).u.Hard.PageFrameNumber = (FRAME);                      \
    (OUTPTE).u.Hard.Accessed = 1;                                   \
    if (((PPTE) >= (PMMPTE)PDE_BASE) && ((PPTE) <= (PMMPTE)PDE_TOP)) { \
        (OUTPTE).u.Hard.NoExecute = 0;                              \
    }                                                               \
    if (MI_DETERMINE_OWNER(PPTE)) {                                 \
        (OUTPTE).u.Long |= MM_PTE_OWNER_MASK;                       \
    }                                                               \
    if (((PMMPTE)PPTE) >= MiGetPteAddress(MM_SYSTEM_SPACE_START)) { \
        (OUTPTE).u.Hard.Global = 1;                                 \
    }                                                               \
}

//++
//VOID
//MI_MAKE_VALID_PTE_TRANSITION (
//    IN OUT OUTPTE
//    IN PROTECT
//    );
//
// Routine Description:
//
//    This macro takes a valid pte and turns it into a transition PTE.
//
// Arguments
//
//    OUTPTE - Supplies the current valid PTE.  This PTE is then
//             modified to become a transition PTE.
//
//    PROTECT - Supplies the protection to set in the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_VALID_PTE_TRANSITION(OUTPTE,PROTECT) \
                (OUTPTE).u.Soft.Transition = 1;           \
                (OUTPTE).u.Soft.Valid = 0;                \
                (OUTPTE).u.Soft.Prototype = 0;            \
                (OUTPTE).u.Soft.Protection = PROTECT;

//++
//VOID
//MI_MAKE_TRANSITION_PTE (
//    OUT OUTPTE,
//    IN PAGE,
//    IN PROTECT,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a valid pte and turns it into a transition PTE.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the transition PTE.
//
//    PAGE - Supplies the page frame number for the PTE.
//
//    PROTECT - Supplies the protection to set in the transition PTE.
//
//    PPTE - Supplies a pointer to the PTE, this is used to determine
//           the owner of the PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PTE(OUTPTE,PAGE,PROTECT,PPTE)   \
                (OUTPTE).u.Long = 0;                       \
                (OUTPTE).u.Trans.PageFrameNumber = PAGE;   \
                (OUTPTE).u.Trans.Transition = 1;           \
                (OUTPTE).u.Trans.Protection = PROTECT;     \
                (OUTPTE).u.Trans.Owner = MI_DETERMINE_OWNER(PPTE);


//++
//VOID
//MI_MAKE_TRANSITION_PTE_VALID (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a transition pte and makes it a valid PTE.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PTE_VALID(OUTPTE,PPTE)                             \
        ASSERT (((PPTE)->u.Hard.Valid == 0) &&                                \
                ((PPTE)->u.Trans.Prototype == 0) &&                           \
                ((PPTE)->u.Trans.Transition == 1));                           \
        (OUTPTE).u.Long = MmProtectToPteMask[(PPTE)->u.Trans.Protection] | MM_PTE_VALID_MASK; \
        if (((PPTE) >= (PMMPTE)PDE_BASE) && ((PPTE) <= (PMMPTE)PDE_TOP)) { \
            (OUTPTE).u.Hard.NoExecute = 0;                              \
        }                                                               \
        (OUTPTE).u.Hard.PageFrameNumber = (PPTE)->u.Hard.PageFrameNumber; \
        if (MI_DETERMINE_OWNER(PPTE)) {                                 \
            (OUTPTE).u.Long |= MM_PTE_OWNER_MASK;                       \
        }                                                               \
        if (((PMMPTE)PPTE) >= MiGetPteAddress(MM_SYSTEM_SPACE_START)) { \
            (OUTPTE).u.Hard.Global = 1;                                 \
        }                                                               \
        (OUTPTE).u.Hard.Accessed = 1;

//++
//VOID
//MI_MAKE_TRANSITION_PROTOPTE_VALID (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a transition prototype PTE (in paged pool) and
//    makes it a valid PTE.  Because we know this is a prototype PTE and
//    not a pagetable PTE, this can directly or in the global bit.  This
//    makes a measurable performance gain since every instruction counts
//    when holding the PFN lock.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PROTOPTE_VALID(OUTPTE,PPTE)                        \
        ASSERT (((PPTE)->u.Hard.Valid == 0) &&                                \
                ((PPTE)->u.Trans.Prototype == 0) &&                           \
                ((PPTE)->u.Trans.Transition == 1));                           \
        (OUTPTE).u.Long = MmProtectToPteMask[(PPTE)->u.Trans.Protection] | MM_PTE_VALID_MASK; \
        (OUTPTE).u.Hard.PageFrameNumber = (PPTE)->u.Hard.PageFrameNumber; \
        (OUTPTE).u.Hard.Global = 1;                                     \
        (OUTPTE).u.Hard.Accessed = 1;

#define MI_FAULT_STATUS_INDICATES_EXECUTION(_FaultStatus)   (_FaultStatus & 0x8)

#define MI_FAULT_STATUS_INDICATES_WRITE(_FaultStatus)   (_FaultStatus & 0x1)

#define MI_CLEAR_FAULT_STATUS(_FaultStatus)             (_FaultStatus = 0)

#define MI_IS_PTE_EXECUTABLE(_TempPte) ((_TempPte)->u.Hard.NoExecute == 0)

//++
//VOID
//MI_SET_PTE_IN_WORKING_SET (
//    OUT PMMPTE PTE,
//    IN ULONG WSINDEX
//    );
//
// Routine Description:
//
//    This macro inserts the specified working set index into the argument PTE.
//
//    No TB invalidation is needed for other processors (or this one) even
//    though the entry may already be in a TB - it's just a software field
//    update and doesn't affect miss resolution.
//
// Arguments
//
//    PTE - Supplies the PTE in which to insert the working set index.
//
//    WSINDEX - Supplies the working set index for the PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_IN_WORKING_SET(PTE, WSINDEX) {             \
    MMPTE _TempPte;                                           \
    _TempPte = *(PTE);                                        \
    _TempPte.u.Hard.SoftwareWsIndex = (WSINDEX);              \
    ASSERT (_TempPte.u.Long != 0);                            \
    *(PTE) = _TempPte;                                        \
}

//++
//ULONG WsIndex
//MI_GET_WORKING_SET_FROM_PTE(
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro returns the working set index from the argument PTE.
//    Since the AMD64 PTE has no free bits nothing needs to be done on this
//    architecture.
//
// Arguments
//
//    PTE - Supplies the PTE to extract the working set index from.
//
// Return Value:
//
//    This macro returns the working set index for the argument PTE.
//
//--

#define MI_GET_WORKING_SET_FROM_PTE(PTE)  (ULONG)(PTE)->u.Hard.SoftwareWsIndex

//++
//VOID
//MI_SET_PTE_WRITE_COMBINE (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and enables WriteCombining as the
//    caching state.  Note that the PTE bits may only be set this way
//    if the Page Attribute Table is present and the PAT has been
//    initialized to provide Write Combining.
//
//    If either of the above conditions is not satisfied, then
//    the macro enables WEAK UC (PCD = 1, PWT = 0) in the PTE.
//
// Arguments
//
//    PTE - Supplies a valid PTE.
//
// Return Value:
//
//     None.
//
//--
//

#define MI_SET_PTE_WRITE_COMBINE(PTE) \
            {                                                               \
                if (MiWriteCombiningPtes == TRUE) {                         \
                    ((PTE).u.Hard.CacheDisable = 0);                        \
                    ((PTE).u.Hard.WriteThrough = 1);                        \
                } else {                                                    \
                    ((PTE).u.Hard.CacheDisable = 1);                        \
                    ((PTE).u.Hard.WriteThrough = 0);                        \
                }                                                           \
            }

#define MI_SET_LARGE_PTE_WRITE_COMBINE(PTE) MI_SET_PTE_WRITE_COMBINE(PTE)

//++
//VOID
//MI_PREPARE_FOR_NONCACHED (
//    IN MI_PFN_CACHE_ATTRIBUTE CacheAttribute
//    );
//
// Routine Description:
//
//    This macro prepares the system prior to noncached PTEs being created.
//
// Arguments
//
//    CacheAttribute - Supplies the cache attribute the PTEs will be filled
//                     with.
//
// Return Value:
//
//     None.
//
//--
#define MI_PREPARE_FOR_NONCACHED(_CacheAttribute)                           \
        if (_CacheAttribute != MiCached) {                                  \
            KeFlushEntireTb (FALSE, TRUE);                                  \
            KeInvalidateAllCaches ();                                       \
        }

//++
//VOID
//MI_SWEEP_CACHE (
//    IN MI_PFN_CACHE_ATTRIBUTE CacheAttribute,
//    IN PVOID StartVa,
//    IN ULONG NumberOfBytes
//    );
//
// Routine Description:
//
//    This macro prepares the system prior to noncached PTEs being created.
//    This does nothing on AMD64.
//
// Arguments
//
//    CacheAttribute - Supplies the cache attribute the PTEs were filled with.
//
//    StartVa - Supplies the starting address that's been mapped.
//
//    NumberOfBytes - Supplies the number of bytes that have been mapped.
//
// Return Value:
//
//     None.
//
//--
#define MI_SWEEP_CACHE(_CacheType,_StartVa,_NumberOfBytes)

//++
//VOID
//MI_SET_PTE_DIRTY (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro sets the dirty bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to set dirty.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_DIRTY(PTE) (PTE).u.Long |= HARDWARE_PTE_DIRTY_MASK


//++
//VOID
//MI_SET_PTE_CLEAN (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro clears the dirty bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to set clear.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_CLEAN(PTE) (PTE).u.Long &= ~HARDWARE_PTE_DIRTY_MASK



//++
//VOID
//MI_IS_PTE_DIRTY (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro checks the dirty bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if the page is dirty (modified), FALSE otherwise.
//
//--

#define MI_IS_PTE_DIRTY(PTE) ((PTE).u.Hard.Dirty != 0)


//++
//VOID
//MI_SET_GLOBAL_STATE (
//    IN MMPTE PTE,
//    IN ULONG STATE
//    );
//
// Routine Description:
//
//    This macro sets the global bit in the PTE. if the pointer PTE is within
//
// Arguments
//
//    PTE - Supplies the PTE to set global state into.
//
//    STATE - Supplies 1 if global, 0 if not.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_GLOBAL_STATE(PTE, STATE) (PTE).u.Hard.Global = STATE;


//++
//VOID
//MI_ENABLE_CACHING (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and sets the caching state to be
//    enabled.  This is performed by clearing the PCD and PWT bits in the PTE.
//
//    Semantics of the overlap between PCD, PWT, and the
//    USWC memory type in the MTRR are:
//
//    PCD   PWT   Mtrr Mem Type      Effective Memory Type
//     1     0    USWC               USWC
//     1     1    USWC               UC
//
// Arguments
//
//    PTE - Supplies a valid PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_ENABLE_CACHING(PTE) \
            {                                                                \
                ((PTE).u.Hard.CacheDisable = 0);                             \
                ((PTE).u.Hard.WriteThrough = 0);                             \
            }



//++
//VOID
//MI_DISABLE_CACHING (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and sets the caching state to be
//    disabled.  This is performed by setting the PCD and PWT bits in the PTE.
//
//    Semantics of the overlap between PCD, PWT, and the
//    USWC memory type in the MTRR are:
//
//    PCD   PWT   Mtrr Mem Type      Effective Memory Type
//     1     0    USWC               USWC
//     1     1    USWC               UC
//
//    Since an effective memory type of UC is desired here,
//    the WT bit is set.
//
// Arguments
//
//    PTE - Supplies a pointer to the valid PTE.
//
// Return Value:
//
//     None.
//
//--


#define MI_DISABLE_CACHING(PTE) \
            {                                                                \
                ((PTE).u.Hard.CacheDisable = 1);                             \
                ((PTE).u.Hard.WriteThrough = 1);                             \
            }


#define MI_DISABLE_LARGE_PTE_CACHING(PTE) MI_DISABLE_CACHING(PTE)


//++
//BOOLEAN
//MI_IS_CACHING_DISABLED (
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and returns TRUE if caching is
//    disabled.
//
// Arguments
//
//    PPTE - Supplies a pointer to the valid PTE.
//
// Return Value:
//
//     TRUE if caching is disabled, FALSE if it is enabled.
//
//--

#define MI_IS_CACHING_DISABLED(PPTE)   \
            ((PPTE)->u.Hard.CacheDisable == 1)



//++
//VOID
//MI_SET_PFN_DELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a PFN element and indicates that
//    the PFN is no longer in use.
//
// Arguments
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//    none.
//
//--

#define MI_SET_PFN_DELETED(PPFN) \
    (PPFN)->PteAddress = (PMMPTE)((ULONG_PTR)PPFN->PteAddress | 0x1);


//++
//VOID
//MI_MARK_PFN_UNDELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a deleted PFN element and mark that
//    the PFN is not deleted.
//
// Arguments
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//    none.
//
//--

#define MI_MARK_PFN_UNDELETED(PPFN) \
    PPFN->PteAddress = (PMMPTE)((ULONG_PTR)PPFN->PteAddress & ~0x1);



//++
//BOOLEAN
//MI_IS_PFN_DELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a PFN element and determines if
//    the PFN is no longer in use.
//
// Arguments
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//     TRUE if PFN is no longer used, FALSE if it is still being used.
//
//--

#define MI_IS_PFN_DELETED(PPFN)   \
            ((ULONG_PTR)(PPFN)->PteAddress & 0x1)


//++
//VOID
//MI_CHECK_PAGE_ALIGNMENT (
//    IN ULONG PAGE,
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro takes a PFN element number (Page) and checks to see
//    if the virtual alignment for the previous address of the page
//    is compatible with the new address of the page.  If they are
//    not compatible, the D cache is flushed.
//
// Arguments
//
//    PAGE - Supplies the PFN element.
//    PPTE - Supplies a pointer to the new PTE which will contain the page.
//
// Return Value:
//
//    none.
//
//--

// does nothing on AMD64.

#define MI_CHECK_PAGE_ALIGNMENT(PAGE,PPTE)




//++
//VOID
//MI_INITIALIZE_HYPERSPACE_MAP (
//    VOID
//    );
//
// Routine Description:
//
//    This macro initializes the PTEs reserved for double mapping within
//    hyperspace.
//
// Arguments
//
//    None.
//
// Return Value:
//
//    None.
//
//--

// does nothing on AMD64.

#define MI_INITIALIZE_HYPERSPACE_MAP(INDEX)


//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_PTE (
//    IN PMMPTE PTEADDRESS
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    PTEADDRESS - Supplies the PTE address the page is (or was) mapped at.
//
// Return Value:
//
//    The page's color.
//
//--

#define MI_GET_PAGE_COLOR_FROM_PTE(PTEADDRESS)  \
         (((ULONG)((MI_SYSTEM_PAGE_COLOR++) & MmSecondaryColorMask)) | MI_CURRENT_NODE_COLOR)



//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_VA (
//    IN PVOID ADDRESS
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    ADDRESS - Supplies the address the page is (or was) mapped at.
//
// Return Value:
//
//    The page's color.
//
//--


#define MI_GET_PAGE_COLOR_FROM_VA(ADDRESS)  \
         (((ULONG)((MI_SYSTEM_PAGE_COLOR++) & MmSecondaryColorMask)) | MI_CURRENT_NODE_COLOR)

//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_SESSION (
//    IN PMM_SESSION_SPACE SessionSpace
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    SessionSpace - Supplies the session space the page will be mapped into.
//
// Return Value:
//
//    The page's color.
//
//--


#define MI_GET_PAGE_COLOR_FROM_SESSION(_SessionSpace)  \
         (((ULONG)((_SessionSpace->Color++) & MmSecondaryColorMask)) | MI_CURRENT_NODE_COLOR)



//++
//ULONG
//MI_PAGE_COLOR_PTE_PROCESS (
//    IN PCHAR COLOR,
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//
// Return Value:
//
//    The page's color.
//
//--


#define MI_PAGE_COLOR_PTE_PROCESS(PTE,COLOR)  \
         (((ULONG)((*(COLOR))++) & MmSecondaryColorMask) | MI_CURRENT_NODE_COLOR)


//++
//ULONG
//MI_PAGE_COLOR_VA_PROCESS (
//    IN PVOID ADDRESS,
//    IN PEPROCESS COLOR
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    ADDRESS - Supplies the address the page is (or was) mapped at.
//
// Return Value:
//
//    The page's color.
//
//--

#define MI_PAGE_COLOR_VA_PROCESS(ADDRESS,COLOR) \
         (((ULONG)((*(COLOR))++) & MmSecondaryColorMask) | MI_CURRENT_NODE_COLOR)



//++
//ULONG
//MI_GET_NEXT_COLOR (
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the next color in the sequence.
//
// Arguments
//
//    COLOR - Supplies the color to return the next of.
//
// Return Value:
//
//    Next color in sequence.
//
//--

#define MI_GET_NEXT_COLOR(COLOR)  ((COLOR + 1) & MM_COLOR_MASK)


//++
//ULONG
//MI_GET_PREVIOUS_COLOR (
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the previous color in the sequence.
//
// Arguments
//
//    COLOR - Supplies the color to return the previous of.
//
// Return Value:
//
//    Previous color in sequence.
//
//--

#define MI_GET_PREVIOUS_COLOR(COLOR) (0)

#define MI_GET_SECONDARY_COLOR(PAGE,PFN) ((ULONG)(PAGE & MmSecondaryColorMask))

#define MI_GET_COLOR_FROM_SECONDARY(SECONDARY_COLOR) (0)


//++
//VOID
//MI_GET_MODIFIED_PAGE_BY_COLOR (
//    OUT ULONG PAGE,
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the first page destined for a paging
//    file with the desired color.  It does NOT remove the page
//    from its list.
//
// Arguments
//
//    PAGE - Returns the page located, the value MM_EMPTY_LIST is
//           returned if there is no page of the specified color.
//
//    COLOR - Supplies the color of page to locate.
//
// Return Value:
//
//    none.
//
//--

#define MI_GET_MODIFIED_PAGE_BY_COLOR(PAGE,COLOR) \
            PAGE = MmModifiedPageListByColor[COLOR].Flink


//++
//VOID
//MI_GET_MODIFIED_PAGE_ANY_COLOR (
//    OUT ULONG PAGE,
//    IN OUT ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the first page destined for a paging
//    file with the desired color.  If not page of the desired
//    color exists, all colored lists are searched for a page.
//    It does NOT remove the page from its list.
//
// Arguments
//
//    PAGE - Returns the page located, the value MM_EMPTY_LIST is
//           returned if there is no page of the specified color.
//
//    COLOR - Supplies the color of page to locate and returns the
//            color of the page located.
//
// Return Value:
//
//    none.
//
//--

#define MI_GET_MODIFIED_PAGE_ANY_COLOR(PAGE,COLOR) \
            {                                                                \
                if (MmTotalPagesForPagingFile == 0) {                        \
                    PAGE = MM_EMPTY_LIST;                                    \
                } else {                                                     \
                    PAGE = MmModifiedPageListByColor[COLOR].Flink;           \
                }                                                            \
            }



//++
//VOID
//MI_MAKE_VALID_PTE_WRITE_COPY (
//    IN OUT PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro checks to see if the PTE indicates that the
//    page is writable and if so it clears the write bit and
//    sets the copy-on-write bit.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     None.
//
//--

#if defined(NT_UP)
#define MI_MAKE_VALID_PTE_WRITE_COPY(PPTE) \
                    if ((PPTE)->u.Hard.Write == 1) {    \
                        (PPTE)->u.Hard.CopyOnWrite = 1; \
                        (PPTE)->u.Hard.Write = 0;       \
                    }
#else
#define MI_MAKE_VALID_PTE_WRITE_COPY(PPTE) \
                    if ((PPTE)->u.Hard.Write == 1) {    \
                        (PPTE)->u.Hard.CopyOnWrite = 1; \
                        (PPTE)->u.Hard.Write = 0;       \
                        (PPTE)->u.Hard.Writable = 0;    \
                    }
#endif


#define MI_PTE_OWNER_USER       1

#define MI_PTE_OWNER_KERNEL     0


//++
//ULONG
//MI_DETERMINE_OWNER (
//    IN MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro examines the virtual address of the PTE and determines
//    if the PTE resides in system space or user space.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     1 if the owner is USER_MODE, 0 if the owner is KERNEL_MODE.
//
//--

#define MI_DETERMINE_OWNER(PPTE)   \
    ((((PPTE) <= MiHighestUserPte) ||                                       \
      ((PPTE) >= MiGetPdeAddress(NULL) && ((PPTE) <= MiHighestUserPde)) ||  \
      ((PPTE) >= MiGetPpeAddress(NULL) && ((PPTE) <= MiHighestUserPpe)) ||  \
      ((PPTE) >= MiGetPxeAddress(NULL) && ((PPTE) <= MiHighestUserPxe)))    \
      ? MI_PTE_OWNER_USER : MI_PTE_OWNER_KERNEL)



//++
//VOID
//MI_SET_ACCESSED_IN_PTE (
//    IN OUT MMPTE PPTE,
//    IN ULONG ACCESSED
//    );
//
// Routine Description:
//
//    This macro sets the ACCESSED field in the PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     None
//
//--

#define MI_SET_ACCESSED_IN_PTE(PPTE,ACCESSED) \
                    ((PPTE)->u.Hard.Accessed = ACCESSED)

//++
//ULONG
//MI_GET_ACCESSED_IN_PTE (
//    IN OUT MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro returns the state of the ACCESSED field in the PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     The state of the ACCESSED field.
//
//--

#define MI_GET_ACCESSED_IN_PTE(PPTE) ((PPTE)->u.Hard.Accessed)


//++
//VOID
//MI_SET_OWNER_IN_PTE (
//    IN PMMPTE PPTE
//    IN ULONG OWNER
//    );
//
// Routine Description:
//
//    This macro sets the owner field in the PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_OWNER_IN_PTE(PPTE,OWNER) ((PPTE)->u.Hard.Owner = OWNER)


//
// Mask to clear all fields but protection in a PTE to or in paging file
// location.
//

#define CLEAR_FOR_PAGE_FILE 0x000003E0

//++
//VOID
//MI_SET_PAGING_FILE_INFO (
//    OUT MMPTE OUTPTE,
//    IN MMPTE PPTE,
//    IN ULONG FILEINFO,
//    IN ULONG OFFSET
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to store the result.
//
//    PTE - Supplies the PTE to operate upon.
//
//    FILEINFO - Supplies the number of the paging file.
//
//    OFFSET - Supplies the offset into the paging file.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_PAGING_FILE_INFO(OUTPTE,PPTE,FILEINFO,OFFSET)            \
       (OUTPTE).u.Long = (PPTE).u.Long;                             \
       (OUTPTE).u.Long &= CLEAR_FOR_PAGE_FILE;                       \
       (OUTPTE).u.Long |= (FILEINFO << 1);                           \
       (OUTPTE).u.Soft.PageFileHigh = (OFFSET);


//++
//PMMPTE
//MiPteToProto (
//    IN OUT MMPTE PPTE,
//    IN ULONG FILEINFO,
//    IN ULONG OFFSET
//    );
//
// Routine Description:
//
//   This macro returns the address of the corresponding prototype which
//   was encoded earlier into the supplied PTE.
//
// Arguments
//
//    lpte - Supplies the PTE to operate upon.
//
// Return Value:
//
//    Pointer to the prototype PTE that backs this PTE.
//
//--

#define MiPteToProto(lpte) \
            ((PMMPTE)((lpte)->u.Proto.ProtoAddress))


//++
//ULONG
//MiProtoAddressForPte (
//    IN PMMPTE proto_va
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//    MiProtoAddressForPte returns the bit field to OR into the PTE to
//    reference a prototype PTE.  And set the protoPTE bit,
//    MM_PTE_PROTOTYPE_MASK.
//
// Arguments
//
//    proto_va - Supplies the address of the prototype PTE.
//
// Return Value:
//
//    Mask to set into the PTE.
//
//--

#define MiProtoAddressForPte(proto_va)  \
    (((ULONG_PTR)proto_va << 16) | MM_PTE_PROTOTYPE_MASK)



//++
//ULONG
//MiProtoAddressForKernelPte (
//    IN PMMPTE proto_va
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//    MiProtoAddressForPte returns the bit field to OR into the PTE to
//    reference a prototype PTE.  And set the protoPTE bit,
//    MM_PTE_PROTOTYPE_MASK.
//
//    This macro also sets any other information (such as global bits)
//    required for kernel mode PTEs.
//
// Arguments
//
//    proto_va - Supplies the address of the prototype PTE.
//
// Return Value:
//
//    Mask to set into the PTE.
//
//--

//  not different on AMD64.

#define MiProtoAddressForKernelPte(proto_va)  MiProtoAddressForPte(proto_va)

//++
//PSUBSECTION
//MiGetSubsectionAddress (
//    IN PMMPTE lpte
//    );
//
// Routine Description:
//
//   This macro takes a PTE and returns the address of the subsection that
//   the PTE refers to.  Subsections are quadword structures allocated
//   from nonpaged pool.
//
// Arguments
//
//    lpte - Supplies the PTE to operate upon.
//
// Return Value:
//
//    A pointer to the subsection referred to by the supplied PTE.
//
//--

#define MiGetSubsectionAddress(lpte)                              \
    ((PSUBSECTION)((lpte)->u.Subsect.SubsectionAddress))


//++
//ULONG
//MiGetSubsectionAddressForPte (
//    IN PSUBSECTION VA
//    );
//
// Routine Description:
//
//    This macro takes the address of a subsection and encodes it for use
//    in a PTE.
//
// Arguments
//
//    VA - Supplies a pointer to the subsection to encode.
//
// Return Value:
//
//     The mask to set into the PTE to make it reference the supplied
//     subsection.
//
//--

#define MiGetSubsectionAddressForPte(VA) ((ULONGLONG)VA << 16)

//++
//PMMPTE
//MiGetPxeAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPxeAddress returns the address of the extended page directory parent
//    entry which maps the given virtual address.  This is one level above the
//    page parent directory.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the PXE for.
//
// Return Value:
//
//    The address of the PXE.
//
//--

#define MiGetPxeAddress(va)   ((PMMPTE)PXE_BASE + MiGetPxeOffset(va))

//++
//PMMPTE
//MiGetPpeAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPpeAddress returns the address of the page directory parent entry
//    which maps the given virtual address.  This is one level above the
//    page directory.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the PPE for.
//
// Return Value:
//
//    The address of the PPE.
//
//--

#define MiGetPpeAddress(va)   \
    ((PMMPTE)(((((ULONG_PTR)(va) & VIRTUAL_ADDRESS_MASK) >> PPI_SHIFT) << PTE_SHIFT) + PPE_BASE))

//++
//PMMPTE
//MiGetPdeAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeAddress returns the address of the PDE which maps the
//    given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the PDE for.
//
// Return Value:
//
//    The address of the PDE.
//
//--

#define MiGetPdeAddress(va)  \
    ((PMMPTE)(((((ULONG_PTR)(va) & VIRTUAL_ADDRESS_MASK) >> PDI_SHIFT) << PTE_SHIFT) + PDE_BASE))


//++
//PMMPTE
//MiGetPteAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPteAddress returns the address of the PTE which maps the
//    given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the PTE for.
//
// Return Value:
//
//    The address of the PTE.
//
//--

#define MiGetPteAddress(va) \
    ((PMMPTE)(((((ULONG_PTR)(va) & VIRTUAL_ADDRESS_MASK) >> PTI_SHIFT) << PTE_SHIFT) + PTE_BASE))


//++
//ULONG
//MiGetPxeOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPxeOffset returns the offset into an extended page directory parent
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the extended parent page directory table the corresponding
//    PXE is at.
//
//--

#define MiGetPxeOffset(va) ((ULONG)(((ULONG_PTR)(va) >> PXI_SHIFT) & PXI_MASK))

//++
//ULONG
//MiGetPxeIndex (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPxeIndex returns the extended page directory parent index
//    for a given virtual address.
//
//    N.B. This does not mask off PXE bits.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the index for.
//
// Return Value:
//
//    The index into the extended page directory parent - ie: the virtual page
//    directory parent number.  This is different from the extended page
//    directory parent offset because this spans extended page directory
//    parents on supported platforms.
//
//--

#define MiGetPxeIndex(va) ((ULONG)((ULONG_PTR)(va) >> PXI_SHIFT))

//++
//ULONG
//MiGetPpeOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPpeOffset returns the offset into a page directory parent for a
//    given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the parent page directory table the corresponding
//    PPE is at.
//
//--

#define MiGetPpeOffset(va) ((ULONG)(((ULONG_PTR)(va) >> PPI_SHIFT) & PPI_MASK))

//++
//ULONG
//MiGetPpeIndex (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPpeIndex returns the page directory parent index
//    for a given virtual address.
//
//    N.B. This does not mask off PXE bits.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the index for.
//
// Return Value:
//
//    The index into the page directory parent - ie: the virtual page directory
//    number.  This is different from the page directory parent offset because
//    this spans page directory parents on supported platforms.
//
//--

#define MiGetPpeIndex(va) ((ULONG)((ULONG_PTR)(va) >> PPI_SHIFT))

//++
//ULONG
//MiGetPdeOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeOffset returns the offset into a page directory
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page directory table the corresponding PDE is at.
//
//--

#define MiGetPdeOffset(va) ((ULONG)(((ULONG_PTR)(va) >> PDI_SHIFT) & PDI_MASK))

//++
//ULONG
//MiGetPdeIndex (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeIndex returns the page directory index
//    for a given virtual address.
//
//    N.B. This does not mask off PPE or PXE bits.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the index for.
//
// Return Value:
//
//    The index into the page directory - ie: the virtual page table number.
//    This is different from the page directory offset because this spans
//    page directories on supported platforms.
//
//--

#define MiGetPdeIndex(va) ((ULONG)((ULONG_PTR)(va) >> PDI_SHIFT))

//++
//ULONG
//MiGetPteOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPteOffset returns the offset into a page table page
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page table page table the corresponding PTE is at.
//
//--

#define MiGetPteOffset(va) ((ULONG)(((ULONG_PTR)(va) >> PTI_SHIFT) & PTI_MASK))

//++
//PVOID
//MiGetVirtualAddressMappedByPxe (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPxe returns the virtual address
//    which is mapped by a given PXE address.
//
// Arguments
//
//    PXE - Supplies the PXE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PXE.
//
//--

#define MiGetVirtualAddressMappedByPxe(PXE) \
    MiGetVirtualAddressMappedByPde(MiGetVirtualAddressMappedByPde(PXE))

//++
//PVOID
//MiGetVirtualAddressMappedByPpe (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPpe returns the virtual address
//    which is mapped by a given PPE address.
//
// Arguments
//
//    PPE - Supplies the PPE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PPE.
//
//--

#define MiGetVirtualAddressMappedByPpe(PPE) \
    MiGetVirtualAddressMappedByPte(MiGetVirtualAddressMappedByPde(PPE))

//++
//PVOID
//MiGetVirtualAddressMappedByPde (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPde returns the virtual address
//    which is mapped by a given PDE address.
//
// Arguments
//
//    PDE - Supplies the PDE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PDE.
//
//--

#define MiGetVirtualAddressMappedByPde(PDE) \
    MiGetVirtualAddressMappedByPte(MiGetVirtualAddressMappedByPte(PDE))

//++
//PVOID
//MiGetVirtualAddressMappedByPte (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPte returns the virtual address
//    which is mapped by a given PTE address.
//
// Arguments
//
//    PTE - Supplies the PTE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PTE.
//
//--

#define VA_SHIFT (63 - 47)              // address sign extend shift count

#define MiGetVirtualAddressMappedByPte(PTE) \
    ((PVOID)((LONG_PTR)(((LONG_PTR)(PTE) - PTE_BASE) << (PAGE_SHIFT + VA_SHIFT - PTE_SHIFT)) >> VA_SHIFT))

//++
//LOGICAL
//MiIsVirtualAddressOnPxeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsVirtualAddressOnPxeBoundary returns TRUE if the virtual address is
//    on an extended page directory parent entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on a boundary, FALSE if not.
//
//--

#define MiIsVirtualAddressOnPxeBoundary(VA) (((ULONG_PTR)(VA) & PAGE_DIRECTORY0_MASK) == 0)

//++
//LOGICAL
//MiIsVirtualAddressOnPpeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsVirtualAddressOnPpeBoundary returns TRUE if the virtual address is
//    on a page directory entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on a boundary, FALSE if not.
//
//--

#define MiIsVirtualAddressOnPpeBoundary(VA) (((ULONG_PTR)(VA) & PAGE_DIRECTORY1_MASK) == 0)


//++
//LOGICAL
//MiIsVirtualAddressOnPdeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsVirtualAddressOnPdeBoundary returns TRUE if the virtual address is
//    on a page directory entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on a 2MB PDE boundary, FALSE if not.
//
//--

#define MiIsVirtualAddressOnPdeBoundary(VA) (((ULONG_PTR)(VA) & PAGE_DIRECTORY2_MASK) == 0)


//++
//LOGICAL
//MiIsPteOnPxeBoundary (
//    IN PVOID PTE
//    );
//
// Routine Description:
//
//    MiIsPteOnPxeBoundary returns TRUE if the PTE is
//    on an extended page directory parent entry boundary.
//
// Arguments
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if on a boundary, FALSE if not.
//
//--

#define MiIsPteOnPxeBoundary(PTE) (((ULONG_PTR)(PTE) & (PAGE_DIRECTORY1_MASK)) == 0)

//++
//LOGICAL
//MiIsPteOnPpeBoundary (
//    IN PVOID PTE
//    );
//
// Routine Description:
//
//    MiIsPteOnPpeBoundary returns TRUE if the PTE is
//    on a page directory parent entry boundary.
//
// Arguments
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if on a boundary, FALSE if not.
//
//--

#define MiIsPteOnPpeBoundary(PTE) (((ULONG_PTR)(PTE) & (PAGE_DIRECTORY2_MASK)) == 0)


//++
//LOGICAL
//MiIsPteOnPdeBoundary (
//    IN PVOID PTE
//    );
//
// Routine Description:
//
//    MiIsPteOnPdeBoundary returns TRUE if the PTE is
//    on a page directory entry boundary.
//
// Arguments
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if on a 2MB PDE boundary, FALSE if not.
//
//--

#define MiIsPteOnPdeBoundary(PTE) (((ULONG_PTR)(PTE) & (PAGE_SIZE - 1)) == 0)

//++
//ULONG
//GET_PAGING_FILE_NUMBER (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro extracts the paging file number from a PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    The paging file number.
//
//--

#define GET_PAGING_FILE_NUMBER(PTE) ((ULONG)(((PTE).u.Soft.PageFileLow)))

//++
//ULONG
//GET_PAGING_FILE_OFFSET (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro extracts the offset into the paging file from a PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    The paging file offset.
//
//--

#define GET_PAGING_FILE_OFFSET(PTE) ((ULONG)((PTE).u.Soft.PageFileHigh))


//++
//ULONG
//IS_PTE_NOT_DEMAND_ZERO (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro checks to see if a given PTE is NOT a demand zero PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    Returns 0 if the PTE is demand zero, non-zero otherwise.
//
//--

#define IS_PTE_NOT_DEMAND_ZERO(PTE) \
                 ((PTE).u.Long & ((ULONG_PTR)0xFFFFFFFFFFFFF000 |  \
                                  MM_PTE_VALID_MASK |       \
                                  MM_PTE_PROTOTYPE_MASK |   \
                                  MM_PTE_TRANSITION_MASK))

//++
//VOID
//MI_MAKING_VALID_PTE_INVALID(
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    Prepare to make a single valid PTE invalid.
//    No action is required on AMD64.
//
// Arguments
//
//    SYSTEM_WIDE - Supplies TRUE if this will happen on all processors.
//
// Return Value:
//
//    None.
//
//--

#define MI_MAKING_VALID_PTE_INVALID(SYSTEM_WIDE)


//++
//VOID
//MI_MAKING_VALID_MULTIPLE_PTES_INVALID(
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    Prepare to make multiple valid PTEs invalid.
//    No action is required on AMD64.
//
// Arguments
//
//    SYSTEM_WIDE - Supplies TRUE if this will happen on all processors.
//
// Return Value:
//
//    None.
//
//--

#define MI_MAKING_MULTIPLE_PTES_INVALID(SYSTEM_WIDE)



//++
//VOID
//MI_MAKE_PROTECT_WRITE_COPY (
//    IN OUT MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro makes a writable PTE a writable-copy PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    NONE
//
//--

#define MI_MAKE_PROTECT_WRITE_COPY(PTE) \
        if ((PTE).u.Soft.Protection & MM_PROTECTION_WRITE_MASK) {      \
            (PTE).u.Long |= MM_PROTECTION_COPY_MASK << MM_PROTECT_FIELD_SHIFT;      \
        }


//++
//VOID
//MI_SET_PAGE_DIRTY(
//    IN PMMPTE PPTE,
//    IN PVOID VA,
//    IN PVOID PFNHELD
//    );
//
// Routine Description:
//
//    This macro sets the dirty bit (and release page file space).
//
// Arguments
//
//    TEMP - Supplies a temporary for usage.
//
//    PPTE - Supplies a pointer to the PTE that corresponds to VA.
//
//    VA - Supplies a the virtual address of the page fault.
//
//    PFNHELD - Supplies TRUE if the PFN lock is held.
//
// Return Value:
//
//    None.
//
//--

#if defined(NT_UP)
#define MI_SET_PAGE_DIRTY(PPTE,VA,PFNHELD)
#else
#define MI_SET_PAGE_DIRTY(PPTE,VA,PFNHELD)                          \
            if ((PPTE)->u.Hard.Dirty == 1) {                        \
                MiSetDirtyBit ((VA),(PPTE),(PFNHELD));              \
            }
#endif




//++
//VOID
//MI_NO_FAULT_FOUND(
//    IN FAULTSTATUS,
//    IN PMMPTE PPTE,
//    IN PVOID VA,
//    IN PVOID PFNHELD
//    );
//
// Routine Description:
//
//    This macro handles the case when a page fault is taken and no
//    PTE with the valid bit clear is found.
//
// Arguments
//
//    FAULTSTATUS - Supplies the fault status.
//
//    PPTE - Supplies a pointer to the PTE that corresponds to VA.
//
//    VA - Supplies a the virtual address of the page fault.
//
//    PFNHELD - Supplies TRUE if the PFN lock is held.
//
// Return Value:
//
//    None.
//
//--

#if defined(NT_UP)
#define MI_NO_FAULT_FOUND(FAULTSTATUS,PPTE,VA,PFNHELD)
#else
#define MI_NO_FAULT_FOUND(FAULTSTATUS,PPTE,VA,PFNHELD) \
        if ((MI_FAULT_STATUS_INDICATES_WRITE(FAULTSTATUS)) && ((PPTE)->u.Hard.Dirty == 0)) {  \
            MiSetDirtyBit ((VA),(PPTE),(PFNHELD));     \
        }
#endif




//++
//ULONG
//MI_CAPTURE_DIRTY_BIT_TO_PFN (
//    IN PMMPTE PPTE,
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro gets captures the state of the dirty bit to the PFN
//    and frees any associated page file space if the PTE has been
//    modified element.
//
//    NOTE - THE PFN LOCK MUST BE HELD!
//
// Arguments
//
//    PPTE - Supplies the PTE to operate upon.
//
//    PPFN - Supplies a pointer to the PFN database element that corresponds
//           to the page mapped by the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_CAPTURE_DIRTY_BIT_TO_PFN(PPTE,PPFN)                      \
         ASSERT (KeGetCurrentIrql() > APC_LEVEL);                   \
         if (((PPFN)->u3.e1.Modified == 0) &&                       \
            ((PPTE)->u.Hard.Dirty != 0)) {                          \
             MI_SET_MODIFIED (PPFN, 1, 0x18);                       \
             if (((PPFN)->OriginalPte.u.Soft.Prototype == 0) &&     \
                          ((PPFN)->u3.e1.WriteInProgress == 0)) {   \
                 MiReleasePageFileSpace ((PPFN)->OriginalPte);      \
                 (PPFN)->OriginalPte.u.Soft.PageFileHigh = 0;       \
             }                                                      \
         }


//++
//BOOLEAN
//MI_IS_PHYSICAL_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    physical address.
//
// Arguments
//
//    VA - Supplies the virtual address.
//
// Return Value:
//
//    FALSE if it is not a physical address, TRUE if it is.
//
//--

#define MI_IS_PHYSICAL_ADDRESS(Va) \
    ((MiGetPxeAddress(Va)->u.Hard.Valid == 1) && \
     (MiGetPpeAddress(Va)->u.Hard.Valid == 1) && \
     ((MiGetPdeAddress(Va)->u.Long & 0x81) == 0x81))


//++
//ULONG
//MI_CONVERT_PHYSICAL_TO_PFN (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro converts a physical address (see MI_IS_PHYSICAL_ADDRESS)
//    to its corresponding physical frame number.
//
// Arguments
//
//    VA - Supplies a pointer to the physical address.
//
// Return Value:
//
//    Returns the PFN for the page.
//
//--

#define MI_CONVERT_PHYSICAL_TO_PFN(Va)     \
    ((PFN_NUMBER)(MiGetPdeAddress(Va)->u.Hard.PageFrameNumber) + (MiGetPteOffset((ULONG_PTR)Va)))


typedef struct _MMCOLOR_TABLES {
    PFN_NUMBER Flink;
    PVOID Blink;
    PFN_NUMBER Count;
} MMCOLOR_TABLES, *PMMCOLOR_TABLES;

extern PMMCOLOR_TABLES MmFreePagesByColor[2];

extern PFN_NUMBER MmTotalPagesForPagingFile;


//
// A VALID Page Table Entry on an AMD64 has the following definition.
//

#define MI_MAXIMUM_PAGEFILE_SIZE (((UINT64)4 * 1024 * 1024 * 1024 - 1) * PAGE_SIZE)

#define MI_PTE_LOOKUP_NEEDED ((ULONG64)0xffffffff)

typedef struct _MMPTE_SOFTWARE {
    ULONGLONG Valid : 1;
    ULONGLONG PageFileLow : 4;
    ULONGLONG Protection : 5;
    ULONGLONG Prototype : 1;
    ULONGLONG Transition : 1;
    ULONGLONG UsedPageTableEntries : PTE_PER_PAGE_BITS;
    ULONGLONG Reserved : 20 - PTE_PER_PAGE_BITS;
    ULONGLONG PageFileHigh : 32;
} MMPTE_SOFTWARE;

typedef struct _MMPTE_TRANSITION {
    ULONGLONG Valid : 1;
    ULONGLONG Write : 1;
    ULONGLONG Owner : 1;
    ULONGLONG WriteThrough : 1;
    ULONGLONG CacheDisable : 1;
    ULONGLONG Protection : 5;
    ULONGLONG Prototype : 1;
    ULONGLONG Transition : 1;
    ULONGLONG PageFrameNumber : 28;
    ULONGLONG Unused : 24;
} MMPTE_TRANSITION;

typedef struct _MMPTE_PROTOTYPE {
    ULONGLONG Valid : 1;
    ULONGLONG Unused0: 7;
    ULONGLONG ReadOnly : 1;
    ULONGLONG Unused1: 1;
    ULONGLONG Prototype : 1;
    ULONGLONG Protection : 5;
    LONGLONG ProtoAddress: 48;
} MMPTE_PROTOTYPE;

typedef struct _MMPTE_SUBSECTION {
    ULONGLONG Valid : 1;
    ULONGLONG Unused0 : 4;
    ULONGLONG Protection : 5;
    ULONGLONG Prototype : 1;
    ULONGLONG Unused1 : 5;
    LONGLONG SubsectionAddress : 48;
} MMPTE_SUBSECTION;

typedef struct _MMPTE_LIST {
    ULONGLONG Valid : 1;
    ULONGLONG OneEntry : 1;
    ULONGLONG filler0 : 3;

    //
    // Note the Prototype bit must not be used for lists like freed nonpaged
    // pool because lookaside pops can legitimately reference bogus addresses
    // (since the pop is unsynchronized) and the fault handler must be able to
    // distinguish lists from protos so a retry status can be returned (vs a
    // fatal bugcheck).
    //
    // The same caveat applies to both the Transition and the Protection
    // fields as they are similarly examined in the fault handler and would
    // be misinterpreted if ever nonzero in the freed nonpaged pool chains.
    //

    ULONGLONG Protection : 5;
    ULONGLONG Prototype : 1;        // MUST BE ZERO as per above comment.
    ULONGLONG Transition : 1;

    ULONGLONG filler1 : 20;
    ULONGLONG NextEntry : 32;
} MMPTE_LIST;

typedef struct _MMPTE_HIGHLOW {
    ULONG LowPart;
    ULONG HighPart;
} MMPTE_HIGHLOW;


typedef struct _MMPTE_HARDWARE_LARGEPAGE {
    ULONGLONG Valid : 1;
    ULONGLONG Write : 1;
    ULONGLONG Owner : 1;
    ULONGLONG WriteThrough : 1;
    ULONGLONG CacheDisable : 1;
    ULONGLONG Accessed : 1;
    ULONGLONG Dirty : 1;
    ULONGLONG LargePage : 1;
    ULONGLONG Global : 1;
    ULONGLONG CopyOnWrite : 1; // software field
    ULONGLONG Prototype : 1;   // software field
    ULONGLONG reserved0 : 1;   // software field
    ULONGLONG PAT : 1;
    ULONGLONG reserved1 : 8;   // software field
    ULONGLONG PageFrameNumber : 19;
    ULONGLONG reserved2 : 24;   // software field
} MMPTE_HARDWARE_LARGEPAGE, *PMMPTE_HARDWARE_LARGEPAGE;

//
// A Page Table Entry on AMD64 has the following definition.
// Note the MP version is to avoid stalls when flushing TBs across processors.
//

//
// Uniprocessor version.
//

typedef struct _MMPTE_HARDWARE {
    ULONGLONG Valid : 1;
#if defined(NT_UP)
    ULONGLONG Write : 1;        // UP version
#else
    ULONGLONG Writable : 1;        // changed for MP version
#endif
    ULONGLONG Owner : 1;
    ULONGLONG WriteThrough : 1;
    ULONGLONG CacheDisable : 1;
    ULONGLONG Accessed : 1;
    ULONGLONG Dirty : 1;
    ULONGLONG LargePage : 1;
    ULONGLONG Global : 1;
    ULONGLONG CopyOnWrite : 1; // software field
    ULONGLONG Prototype : 1;   // software field
#if defined(NT_UP)
    ULONGLONG reserved0 : 1;  // software field
#else
    ULONGLONG Write : 1;       // software field - MP change
#endif
    ULONGLONG PageFrameNumber : 28;
    ULONG64 reserved1 : 24 - (_HARDWARE_PTE_WORKING_SET_BITS+1);
    ULONGLONG SoftwareWsIndex : _HARDWARE_PTE_WORKING_SET_BITS;
    ULONG64 NoExecute : 1;
} MMPTE_HARDWARE, *PMMPTE_HARDWARE;

#if defined(NT_UP)
#define HARDWARE_PTE_DIRTY_MASK     0x40
#else
#define HARDWARE_PTE_DIRTY_MASK     0x42
#endif

#define MI_PDE_MAPS_LARGE_PAGE(PDE) ((PDE)->u.Hard.LargePage == 1)

#define MI_MAKE_PDE_MAP_LARGE_PAGE(PDE) ((PDE)->u.Hard.LargePage = 1)

#define MI_GET_PAGE_FRAME_FROM_PTE(PTE) ((PTE)->u.Hard.PageFrameNumber)
#define MI_GET_PAGE_FRAME_FROM_TRANSITION_PTE(PTE) ((PTE)->u.Trans.PageFrameNumber)
#define MI_GET_PROTECTION_FROM_SOFT_PTE(PTE) ((ULONG)(PTE)->u.Soft.Protection)
#define MI_GET_PROTECTION_FROM_TRANSITION_PTE(PTE) ((ULONG)(PTE)->u.Trans.Protection)

typedef struct _MMPTE {
    union  {
        ULONG_PTR Long;
        MMPTE_HARDWARE Hard;
        MMPTE_HARDWARE_LARGEPAGE HardLarge;
        HARDWARE_PTE Flush;
        MMPTE_PROTOTYPE Proto;
        MMPTE_SOFTWARE Soft;
        MMPTE_TRANSITION Trans;
        MMPTE_SUBSECTION Subsect;
        MMPTE_LIST List;
        } u;
} MMPTE;

typedef MMPTE *PMMPTE;

extern PMMPTE MiFirstReservedZeroingPte;

#define InterlockedCompareExchangePte(_PointerPte, _NewContents, _OldContents) \
        InterlockedCompareExchange64 ((PLONGLONG)(_PointerPte), (LONGLONG)(_NewContents), (LONGLONG)(_OldContents))

#define InterlockedExchangePte(_PointerPte, _NewContents) InterlockedExchange64((PLONG64)(_PointerPte), _NewContents)

//++
//VOID
//MI_WRITE_VALID_PTE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE fills in the specified PTE making it valid with the
//    specified contents.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 0);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MI_WRITE_INVALID_PTE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_INVALID_PTE fills in the specified PTE making it invalid with the
//    specified contents.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_INVALID_PTE(_PointerPte, _PteContents)  \
            ASSERT ((_PteContents).u.Hard.Valid == 0);  \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MI_WRITE_VALID_PTE_NEW_PROTECTION (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE_NEW_PROTECTION fills in the specified PTE (which was
//    already valid) changing only the protection or the dirty bit.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE_NEW_PROTECTION(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 1);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            ASSERT ((_PointerPte)->u.Hard.PageFrameNumber == (_PteContents).u.Hard.PageFrameNumber); \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MI_WRITE_VALID_PTE_NEW_PAGE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE_NEW_PAGE fills in the specified PTE (which was
//    already valid) changing the page and the protection.
//    Note that the contents are very carefully written.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE_NEW_PAGE(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 1);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            ASSERT ((_PointerPte)->u.Hard.PageFrameNumber != (_PteContents).u.Hard.PageFrameNumber); \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MiFillMemoryPte (
//    IN PMMPTE Destination,
//    IN ULONG  NumberOfPtes,
//    IN MMPTE  Pattern,
//    };
//
// Routine Description:
//
//    This function fills memory with the specified PTE pattern.
//
// Arguments
//
//    Destination - Supplies a pointer to the memory to fill.
//
//    NumberOfPtes - Supplies the number of PTEs (not bytes!) to be filled.
//
//    Pattern     - Supplies the PTE fill pattern.
//
// Return Value:
//
//    None.
//
//--

#define MiFillMemoryPte(Destination, Length, Pattern) \
             __stosq((PULONG64)(Destination), Pattern, Length)

#define MiZeroMemoryPte(Destination, Length) \
             __stosq((PULONG64)(Destination), 0, Length)

ULONG
FASTCALL
MiDetermineUserGlobalPteMask (
    IN PMMPTE Pte
    );

//++
//BOOLEAN
//MI_IS_PAGE_TABLE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page table address, FALSE if not.
//
//--

#define MI_IS_PAGE_TABLE_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)PTE_BASE && (PVOID)(VA) <= (PVOID)PTE_TOP)

//++
//BOOLEAN
//MI_IS_PAGE_TABLE_OR_HYPER_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table or hyperspace address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page table or hyperspace address, FALSE if not.
//
//--

#define MI_IS_PAGE_TABLE_OR_HYPER_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)PTE_BASE && (PVOID)(VA) <= (PVOID)HYPER_SPACE_END)

//++
//BOOLEAN
//MI_IS_KERNEL_PAGE_TABLE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table address for a kernel address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a kernel page table address, FALSE if not.
//
//--

#define MI_IS_KERNEL_PAGE_TABLE_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)MiGetPteAddress(MM_SYSTEM_RANGE_START) && (PVOID)(VA) <= (PVOID)PTE_TOP)


//++
//BOOLEAN
//MI_IS_PAGE_DIRECTORY_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page directory address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page directory address, FALSE if not.
//
//--

#define MI_IS_PAGE_DIRECTORY_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)PDE_BASE && (PVOID)(VA) <= (PVOID)PDE_TOP)


//++
//BOOLEAN
//MI_IS_HYPER_SPACE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a hyper space address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a hyper space address, FALSE if not.
//
//--

#define MI_IS_HYPER_SPACE_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)HYPER_SPACE && (PVOID)(VA) <= (PVOID)HYPER_SPACE_END)


//++
//BOOLEAN
//MI_IS_PROCESS_SPACE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a process-specific address.  This is an address in user space
//    or page table pages or hyper space.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a process-specific address, FALSE if not.
//
//--

#define MI_IS_PROCESS_SPACE_ADDRESS(VA)   \
            (((PVOID)(VA) <= (PVOID)MM_HIGHEST_USER_ADDRESS) || \
             ((PVOID)(VA) >= (PVOID)PTE_BASE && (PVOID)(VA) <= (PVOID)HYPER_SPACE_END))


//++
//BOOLEAN
//MI_IS_PTE_PROTOTYPE (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a PTE address and determines if it is a prototype PTE.
//
// Arguments
//
//    PTE - Supplies the virtual address of the PTE to check.
//
// Return Value:
//
//    TRUE if the PTE is in a segment (ie, a prototype PTE), FALSE if not.
//
//--

#define MI_IS_PTE_PROTOTYPE(PTE)   \
            ((PTE) > (PMMPTE)PTE_TOP)

//++
//BOOLEAN
//MI_IS_SYSTEM_CACHE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a system cache address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is in the system cache, FALSE if not.
//
//--

#define MI_IS_SYSTEM_CACHE_ADDRESS(VA)                            \
         ((PVOID)(VA) >= (PVOID)MmSystemCacheStart &&            \
		     (PVOID)(VA) <= (PVOID)MmSystemCacheEnd)

//++
//VOID
//MI_BARRIER_SYNCHRONIZE (
//    IN ULONG TimeStamp
//    );
//
// Routine Description:
//
//    MI_BARRIER_SYNCHRONIZE compares the argument timestamp against the
//    current IPI barrier sequence stamp.  When equal, all processors will
//    issue memory barriers to ensure that newly created pages remain coherent.
//
//    When a page is put in the zeroed or free page list the current
//    barrier sequence stamp is read (interlocked - this is necessary
//    to get the correct value - memory barriers won't do the trick)
//    and stored in the pfn entry for the page. The current barrier
//    sequence stamp is maintained by the IPI send logic and is
//    incremented (interlocked) when the target set of an IPI send
//    includes all processors, but the one doing the send. When a page
//    is needed its sequence number is compared against the current
//    barrier sequence number.  If it is equal, then the contents of
//    the page may not be coherent on all processors, and an IPI must
//    be sent to all processors to ensure a memory barrier is
//    executed (generic call can be used for this). Sending the IPI
//    automatically updates the barrier sequence number. The compare
//    is for equality as this is the only value that requires the IPI
//    (i.e., the sequence number wraps, values in both directions are
//    older). When a page is removed in this fashion and either found
//    to be coherent or made coherent, it cannot be modified between
//    that time and writing the PTE. If the page is modified between
//    these times, then an IPI must be sent.
//
// Arguments
//
//    TimeStamp - Supplies the timestamp at the time when the page was zeroed.
//
// Return Value:
//
//    None.
//
//--

// does nothing on AMD64.

#define MI_BARRIER_SYNCHRONIZE(TimeStamp)

//++
//VOID
//MI_BARRIER_STAMP_ZEROED_PAGE (
//    IN PULONG PointerTimeStamp
//    );
//
// Routine Description:
//
//    MI_BARRIER_STAMP_ZEROED_PAGE issues an interlocked read to get the
//    current IPI barrier sequence stamp.  This is called AFTER a page is
//    zeroed.
//
// Arguments
//
//    PointerTimeStamp - Supplies a timestamp pointer to fill with the
//                       current IPI barrier sequence stamp.
//
// Return Value:
//
//    None.
//
//--

// does nothing on AMD64.

#define MI_BARRIER_STAMP_ZEROED_PAGE(PointerTimeStamp)

//++
//VOID
//MI_FLUSH_SINGLE_SESSION_TB (
//    IN PVOID Virtual
//    );
//
// Routine Description:
//
//    MI_FLUSH_SINGLE_SESSION_TB flushes the requested single address
//    translation from the TB.
//
//    Since there are no ASNs on the AMD64, this routine becomes a single
//    TB invalidate.
//
// Arguments
//
//    Virtual - Supplies the virtual address to invalidate.
//
// Return Value:
//
//    None.
//
//--

#define MI_FLUSH_SINGLE_SESSION_TB(Virtual) \
    KeFlushSingleTb (Virtual, TRUE);

//++
//VOID
//MI_FLUSH_ENTIRE_SESSION_TB (
//    IN ULONG Invalid,
//    IN LOGICAL AllProcessors
//    );
//
// Routine Description:
//
//    MI_FLUSH_ENTIRE_SESSION_TB flushes the entire TB on processors which
//    support ASNs.
//
//    Since there are no ASNs on the AMD64, this routine does nothing.
//
// Arguments
//
//    Invalid - TRUE if invalidating.
//
//    AllProcessors - TRUE if all processors need to be IPI'd.
//
// Return Value:
//
//    None.
//

#define MI_FLUSH_ENTIRE_SESSION_TB(Invalid, AllProcessors) \
    NOTHING;

//
//++
//LOGICAL
//MI_RESERVED_BITS_CANONICAL (
//    IN PVOID VirtualAddress
//    );
//
// Routine Description:
//
//    This routine checks whether all of the reserved bits are correct.
//
//    The processor implements at 48 bits of VA and memory management
//    uses them all so the VA is checked against 48 bits to prevent
//    reserved bit faults as our caller is not going to be expecting them.
//
// Arguments
//
//    VirtualAddress - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if the address is ok, FALSE if not.
//

LOGICAL
__inline
MI_RESERVED_BITS_CANONICAL (
    IN PVOID VirtualAddress
    )
{
    LONG_PTR ReservedBits;
    ULONG_PTR ImplVirtualMsb;

    ImplVirtualMsb = 48;

    ReservedBits = (LONG_PTR) VirtualAddress;
    ReservedBits >>= (ImplVirtualMsb + 1);

    if ((ULONG_PTR)VirtualAddress & ((ULONG_PTR)1 << ImplVirtualMsb)) {

        //
        // All the reserved bits (not including the VRN) must also be set.
        //

        if (ReservedBits != (LONG_PTR)-1) {
        }
    }
    else {

        //
        // All the reserved bits (not including the VRN) must also be clear.
        //

        if (ReservedBits != 0) {
            return FALSE;
        }
    }
    return TRUE;
}

//++
//VOID
//MI_DISPLAY_TRAP_INFORMATION (
//    IN PVOID TrapInformation
//    );
//
// Routine Description:
//
//    Display any relevant trap information to aid debugging.
//
// Arguments
//
//    TrapInformation - Supplies a pointer to a trap frame.
//
// Return Value:
//
//    None.
//
#define MI_DISPLAY_TRAP_INFORMATION(TrapInformation)                    \
            KdPrint(("MM:***RIP %p, EFL %p\n",                          \
                     ((PKTRAP_FRAME) (TrapInformation))->Rip,           \
                     ((PKTRAP_FRAME) (TrapInformation))->EFlags));      \
            KdPrint(("MM:***RAX %p, RCX %p RDX %p\n",                   \
                     ((PKTRAP_FRAME) (TrapInformation))->Rax,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Rcx,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Rdx));         \
            KdPrint(("MM:***RBX %p, RSI %p RDI %p\n",                   \
                     ((PKTRAP_FRAME) (TrapInformation))->Rbx,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Rsi,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Rdi));
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\i386\data386.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

   data386.c

Abstract:

    This module contains the private hardware specific global storage for
    the memory management subsystem.

Author:

    Lou Perazzoli (loup) 22-Jan-1990

Revision History:

--*/

#include "mi.h"

//
// A zero Pte.
//

const MMPTE ZeroPte = { 0 };

//
// A kernel zero PTE.
//

const MMPTE ZeroKernelPte = {0x0};

MMPTE MmPteGlobal = {0x0}; // Set global bit later if processor supports Global Page

//
// Note - MM_PTE_GLOBAL_MASK is or'ed into ValidKernelPte during
// initialization if the processor supports Global Page.  Use
// ValidKernelPteLocal if you don't want the global bit (ie: for session
// space).
//

MMPTE ValidKernelPte = { MM_PTE_VALID_MASK |
                         MM_PTE_WRITE_MASK |
                         MM_PTE_DIRTY_MASK |
                         MM_PTE_ACCESS_MASK };

const MMPTE ValidKernelPteLocal = { MM_PTE_VALID_MASK |
                                    MM_PTE_WRITE_MASK |
                                    MM_PTE_DIRTY_MASK |
                                    MM_PTE_ACCESS_MASK };


const MMPTE ValidUserPte = { MM_PTE_VALID_MASK |
                             MM_PTE_WRITE_MASK |
                             MM_PTE_OWNER_MASK |
                             MM_PTE_DIRTY_MASK |
                             MM_PTE_ACCESS_MASK };


const MMPTE ValidPtePte = { MM_PTE_VALID_MASK |
                            MM_PTE_WRITE_MASK |
                            MM_PTE_DIRTY_MASK |
                            MM_PTE_ACCESS_MASK };


const MMPTE ValidPdePde = { MM_PTE_VALID_MASK |
                            MM_PTE_WRITE_MASK |
                            MM_PTE_DIRTY_MASK |
                            MM_PTE_ACCESS_MASK };


MMPTE ValidKernelPde = { MM_PTE_VALID_MASK |
                         MM_PTE_WRITE_MASK |
                         MM_PTE_DIRTY_MASK |
                         MM_PTE_ACCESS_MASK };

const MMPTE ValidKernelPdeLocal = { MM_PTE_VALID_MASK |
                                    MM_PTE_WRITE_MASK |
                                    MM_PTE_DIRTY_MASK |
                                    MM_PTE_ACCESS_MASK };

// NOTE - MM_PTE_GLOBAL_MASK  or'ed in later if processor supports Global Page


MMPTE DemandZeroPde = { MM_READWRITE << 5 };


const MMPTE DemandZeroPte = { MM_READWRITE << 5 };


const MMPTE TransitionPde = { MM_PTE_WRITE_MASK |
                              MM_PTE_OWNER_MASK |
                              MM_PTE_TRANSITION_MASK |
                              MM_READWRITE << 5 };

#if !defined (_X86PAE_)
MMPTE PrototypePte = { 0xFFFFF000 |
                       MM_PTE_PROTOTYPE_MASK |
                       MM_READWRITE << 5 };
#else
MMPTE PrototypePte = { (MI_PTE_LOOKUP_NEEDED << 32) |
                       MM_PTE_PROTOTYPE_MASK |
                       MM_READWRITE << 5 };
#endif


//
// PTE which generates an access violation when referenced.
//

const MMPTE NoAccessPte = {MM_NOACCESS << 5};

//
// Pool start and end.
//

PVOID MmNonPagedPoolStart;

PVOID MmNonPagedPoolEnd = (PVOID) MM_NONPAGED_POOL_END;

PVOID MmPagedPoolStart = (PVOID) MM_DEFAULT_PAGED_POOL_START;

PVOID MmPagedPoolEnd;

PMMWSL MmWorkingSetList;

ULONG MiMaximumWorkingSet =
       ((ULONG)((ULONG)2*1024*1024*1024 - 64*1024*1024) >> PAGE_SHIFT); //2Gb-64Mb

//
// Color tables for free and zeroed pages.
//

PMMCOLOR_TABLES MmFreePagesByColor[2];

//
// Color tables for modified pages destined for the paging file.
//

MMPFNLIST MmModifiedPageListByColor[MM_MAXIMUM_NUMBER_OF_COLORS] = {
                            0, ModifiedPageList, MM_EMPTY_LIST, MM_EMPTY_LIST};


//
// Count of the number of modified pages destined for the paging file.
//

ULONG MmTotalPagesForPagingFile = 0;

//
// Pte reserved for mapping pages for the debugger.
//

PMMPTE MmDebugPte = (MiGetPteAddress(MM_DEBUG_VA));

//
// 16 PTEs reserved for mapping MDLs (64k max).
//

PMMPTE MmCrashDumpPte = (MiGetPteAddress(MM_CRASH_DUMP_VA));

//
// Number of additional system PTEs present.
//

ULONG MiNumberOfExtraSystemPdes;
ULONG MiMaximumSystemExtraSystemPdes;

ULONG_PTR MiUseMaximumSystemSpace;
ULONG_PTR MiUseMaximumSystemSpaceEnd;

//
// Size of extended system cache.
//

#if defined (_X86PAE_)
PMMPTE MmSystemCacheWorkingSetListPte;
#endif

ULONG MiMaximumSystemCacheSizeExtra;

PVOID MiSystemCacheStartExtra;

PVOID MiSystemCacheEndExtra;

ULONG MiExtraResourceStart;

ULONG MiExtraResourceEnd;

ULONG_PTR MmBootImageSize;
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\i386\init386.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    init386.c

Abstract:

    This module contains the machine dependent initialization for the
    memory management component.  It is specifically tailored to the
    INTEL x86 and PAE machines.

Author:

    Lou Perazzoli (loup) 6-Jan-1990
    Landy Wang (landyw)  2-Jun-1997

Revision History:

--*/

#include "mi.h"

PFN_NUMBER
MxGetNextPage (
    IN PFN_NUMBER PagesNeeded
    );

PFN_NUMBER
MxPagesAvailable (
    VOID
    );

VOID
MxConvertToLargePage (
    IN PVOID VirtualAddress,
    IN PVOID EndVirtualAddress
    );

LOGICAL
MiIsRegularMemory (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock,
    IN PFN_NUMBER PageFrameIndex
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,MiInitMachineDependent)
#pragma alloc_text(INIT,MxGetNextPage)
#pragma alloc_text(INIT,MxPagesAvailable)
#pragma alloc_text(INIT,MxConvertToLargePage)
#pragma alloc_text(INIT,MiReportPhysicalMemory)
#pragma alloc_text(INIT,MiIsRegularMemory)
#endif

#define MM_LARGE_PAGE_MINIMUM  ((255*1024*1024) >> PAGE_SHIFT)

extern ULONG MmLargeSystemCache;
extern ULONG MmLargeStackSize;
extern LOGICAL MmMakeLowMemory;
extern LOGICAL MmPagedPoolMaximumDesired;

#if defined(_X86PAE_)
LOGICAL MiUseGlobalBitInLargePdes;
PVOID MmHyperSpaceEnd;
#endif

extern KEVENT MiImageMappingPteEvent;

//
// Local data.
//

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("INITDATA")
#endif

ULONG MxPfnAllocation;

PMEMORY_ALLOCATION_DESCRIPTOR MxFreeDescriptor;

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg()
#endif

MEMORY_ALLOCATION_DESCRIPTOR MxOldFreeDescriptor;

typedef struct _MI_LARGE_VA_RANGES {
    PVOID VirtualAddress;
    PVOID EndVirtualAddress;
} MI_LARGE_VA_RANGES, *PMI_LARGE_VA_RANGES;

//
// There are potentially 4 large page ranges:
//
// 1. PFN database
// 2. Initial nonpaged pool
// 3. Kernel code/data
// 4. HAL code/data
//

#define MI_LARGE_PFN_DATABASE   0x1
#define MI_LARGE_NONPAGED_POOL  0x2
#define MI_LARGE_KERNEL_HAL     0x4

#define MI_LARGE_ALL            0x7

ULONG MxMapLargePages = MI_LARGE_ALL;

#define MI_MAX_LARGE_VA_RANGES 4

ULONG MiLargeVaRangeIndex;
MI_LARGE_VA_RANGES MiLargeVaRanges[MI_MAX_LARGE_VA_RANGES];

#define MM_PFN_MAPPED_BY_PDE (MM_VA_MAPPED_BY_PDE >> PAGE_SHIFT)


PFN_NUMBER
MxGetNextPage (
    IN PFN_NUMBER PagesNeeded
    )

/*++

Routine Description:

    This function returns the next physical page number from the largest
    largest free descriptor.  If there are not enough physical pages left
    to satisfy the request then a bugcheck is executed since the system
    cannot be initialized.

Arguments:

    PagesNeeded - Supplies the number of pages needed.

Return Value:

    The base of the range of physically contiguous pages.

Environment:

    Kernel mode, Phase 0 only.

--*/

{
    PFN_NUMBER PageFrameIndex;

    //
    // Examine the free descriptor to see if enough usable memory is available.
    //

    if (PagesNeeded > MxFreeDescriptor->PageCount) {

        KeBugCheckEx (INSTALL_MORE_MEMORY,
                      MmNumberOfPhysicalPages,
                      MxFreeDescriptor->PageCount,
                      MxOldFreeDescriptor.PageCount,
                      PagesNeeded);
    }

    PageFrameIndex = MxFreeDescriptor->BasePage;

    MxFreeDescriptor->BasePage += PagesNeeded;
    MxFreeDescriptor->PageCount -= PagesNeeded;

    return PageFrameIndex;
}

PFN_NUMBER
MxPagesAvailable (
    VOID
    )

/*++

Routine Description:

    This function returns the number of pages available.
    
Arguments:

    None.

Return Value:

    The number of physically contiguous pages currently available.

Environment:

    Kernel mode, Phase 0 only.

--*/

{
    return MxFreeDescriptor->PageCount;
}


VOID
MxConvertToLargePage (
    IN PVOID VirtualAddress,
    IN PVOID EndVirtualAddress
    )

/*++

Routine Description:

    This function converts the backing for the supplied virtual address range
    to a large page mapping.
    
Arguments:

    VirtualAddress - Supplies the virtual address to convert to a large page.

    EndVirtualAddress - Supplies the end virtual address to convert to a
                        large page.

Return Value:

    None.

Environment:

    Kernel mode, Phase 1 only.

--*/

{
    ULONG i;
    MMPTE TempPde;
    PMMPTE PointerPde;
    PMMPTE LastPde;
    PMMPTE PointerPte;
    KIRQL OldIrql;
    PMMPFN Pfn1;
    PFN_NUMBER PageFrameIndex;
    LOGICAL ValidPteFound;
    PFN_NUMBER LargePageBaseFrame;

    ASSERT (MxMapLargePages != 0);

    PointerPde = MiGetPdeAddress (VirtualAddress);
    LastPde = MiGetPdeAddress (EndVirtualAddress);

    TempPde = ValidKernelPde;
    TempPde.u.Hard.LargePage = 1;

#if defined(_X86PAE_)
    if (MiUseGlobalBitInLargePdes == TRUE) {
        TempPde.u.Hard.Global = 1;
    }
#endif

    LOCK_PFN (OldIrql);

    do {
        ASSERT (PointerPde->u.Hard.Valid == 1);

        if (PointerPde->u.Hard.LargePage == 1) {
            goto skip;
        }

        PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);

        //
        // Here's a nasty little hack - the page table page mapping the kernel
        // and HAL (built by the loader) does not necessarily fill all the
        // page table entries (ie: any number of leading entries may be zero).
        //
        // To deal with this, walk forward until a nonzero entry is found
        // and re-index the large page based on this.
        //

        ValidPteFound = FALSE;
        LargePageBaseFrame = (ULONG)-1;
        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
    
        ASSERT ((PageFrameIndex & (MM_PFN_MAPPED_BY_PDE - 1)) == 0);

        for (i = 0; i < PTE_PER_PAGE; i += 1) {

            ASSERT ((PointerPte->u.Long == ZeroKernelPte.u.Long) ||
                    (ValidPteFound == FALSE) ||
                    (PageFrameIndex == MI_GET_PAGE_FRAME_FROM_PTE (PointerPte)));
            if (PointerPte->u.Hard.Valid == 1) {
                if (ValidPteFound == FALSE) {
                    ValidPteFound = TRUE;
                    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
                    LargePageBaseFrame = PageFrameIndex - i;
                }
            }
            PointerPte += 1;
            PageFrameIndex += 1;
        }
    
        if (ValidPteFound == FALSE) {
            goto skip;
        }

        TempPde.u.Hard.PageFrameNumber = LargePageBaseFrame;

        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPde);

        MI_WRITE_VALID_PTE_NEW_PAGE (PointerPde, TempPde);

        //
        // Update the idle process to use the large page mapping also as
        // the page table page is going to be freed.
        //

        MmSystemPagePtes [((ULONG_PTR)PointerPde &
            (PD_PER_SYSTEM * (sizeof(MMPTE) * PDE_PER_PAGE) - 1)) / sizeof(MMPTE)] = TempPde;

        KeFlushEntireTb (TRUE, TRUE);

        Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);
        Pfn1->u2.ShareCount = 0;
        Pfn1->u3.e2.ReferenceCount = 1;
        Pfn1->u3.e1.PageLocation = StandbyPageList;
        MI_SET_PFN_DELETED (Pfn1);
        MiDecrementReferenceCount (Pfn1, PageFrameIndex);

skip:
        PointerPde += 1;
    } while (PointerPde <= LastPde);

    UNLOCK_PFN (OldIrql);
}

VOID
MiReportPhysicalMemory (
    VOID
    )

/*++

Routine Description:

    This routine is called during Phase 0 initialization once the
    MmPhysicalMemoryBlock has been constructed.  It's job is to decide
    which large page ranges to enable later and also to construct a
    large page comparison list so any requests which are not fully cached
    can check this list in order to refuse conflicting requests.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode.  Phase 0 only.

    This is called before any non-MmCached allocations are made.

--*/

{
    ULONG i, j;
    PMMPTE PointerPte;
    LOGICAL EntryFound;
    PFN_NUMBER count;
    PFN_NUMBER Page;
    PFN_NUMBER LastPage;
    PFN_NUMBER PageFrameIndex;
    PFN_NUMBER LastPageFrameIndex;
    PFN_NUMBER PageFrameIndex2;

    //
    // Examine the physical memory block to see whether large pages should
    // be enabled.  The key point is that all the physical pages within a
    // given large page range must have the same cache attributes (MmCached)
    // in order to maintain TB coherency.  This can be done provided all
    // the pages within the large page range represent real RAM (as described
    // by the loader) so that memory management can control it.  If any
    // portion of the large page range is not RAM, it is possible that it
    // may get used as noncached or writecombined device memory and
    // therefore large pages cannot be used.
    //

    if (MxMapLargePages == 0) {
        return;
    }

    for (i = 0; i < MiLargeVaRangeIndex; i += 1) {
        PointerPte = MiGetPteAddress (MiLargeVaRanges[i].VirtualAddress);
        ASSERT (PointerPte->u.Hard.Valid == 1);
        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

        PointerPte = MiGetPteAddress (MiLargeVaRanges[i].EndVirtualAddress);
        ASSERT (PointerPte->u.Hard.Valid == 1);
        LastPageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

        //
        // Round the start down to a page directory boundary and the end to
        // the last page directory entry before the next boundary.
        //

        PageFrameIndex &= ~(MM_PFN_MAPPED_BY_PDE - 1);
        LastPageFrameIndex |= (MM_PFN_MAPPED_BY_PDE - 1);

        EntryFound = FALSE;

        j = 0;
        do {

            count = MmPhysicalMemoryBlock->Run[j].PageCount;
            Page = MmPhysicalMemoryBlock->Run[j].BasePage;

            LastPage = Page + count;

            if ((PageFrameIndex >= Page) && (LastPageFrameIndex < LastPage)) {
                EntryFound = TRUE;
                break;
            }

            j += 1;

        } while (j != MmPhysicalMemoryBlock->NumberOfRuns);

        if (EntryFound == FALSE) {

            //
            // No entry was found that completely spans this large page range.
            // Zero it so this range will not be converted into large pages
            // later.
            //

            DbgPrint ("MM: Loader/HAL memory block indicates large pages cannot be used for %p->%p\n",
                MiLargeVaRanges[i].VirtualAddress,
                MiLargeVaRanges[i].EndVirtualAddress);

            MiLargeVaRanges[i].VirtualAddress = NULL;

            //
            // Don't use large pages for anything if this chunk overlaps any
            // others in the request list.  This is because 2 separate ranges
            // may share a straddling large page.  If the first range was unable
            // to use large pages, but the second one does ... then only part
            // of the first range will get large pages if we enable large
            // pages for the second range.  This would be vey bad as we use
            // the MI_IS_PHYSICAL macro everywhere and assume the entire
            // range is in or out, so disable all large pages here instead.
            //

            for (j = 0; j < MiLargeVaRangeIndex; j += 1) {

                //
                // Skip the range that is already being rejected.
                //

                if (i == j) {
                    continue;
                }

                //
                // Skip any range which has already been removed.
                //

                if (MiLargeVaRanges[j].VirtualAddress == NULL) {
                    continue;
                }

                PointerPte = MiGetPteAddress (MiLargeVaRanges[j].VirtualAddress);
                ASSERT (PointerPte->u.Hard.Valid == 1);
                PageFrameIndex2 = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

                if ((PageFrameIndex2 >= PageFrameIndex) &&
                    (PageFrameIndex2 <= LastPageFrameIndex)) {

                    DbgPrint ("MM: Disabling large pages for all ranges due to overlap\n");

                    goto RemoveAllRanges;
                }

                //
                // Since it is not possible for any request chunk to completely
                // encompass another one, checking only the start and end
                // addresses is sufficient.
                //

                PointerPte = MiGetPteAddress (MiLargeVaRanges[j].EndVirtualAddress);
                ASSERT (PointerPte->u.Hard.Valid == 1);
                PageFrameIndex2 = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

                if ((PageFrameIndex2 >= PageFrameIndex) &&
                    (PageFrameIndex2 <= LastPageFrameIndex)) {

                    DbgPrint ("MM: Disabling large pages for all ranges due to overlap\n");

                    goto RemoveAllRanges;
                }
            }

            //
            // No other ranges overlapped with this one, it is sufficient to
            // just disable this range and continue to attempt to use large
            // pages for any others.
            //

            continue;
        }

        MiAddCachedRange (PageFrameIndex, LastPageFrameIndex);
    }

    return;

RemoveAllRanges:

    while (i != 0) {

        i -= 1;

        if (MiLargeVaRanges[i].VirtualAddress != NULL) {

            PointerPte = MiGetPteAddress (MiLargeVaRanges[i].VirtualAddress);
            ASSERT (PointerPte->u.Hard.Valid == 1);
            PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

            PointerPte = MiGetPteAddress (MiLargeVaRanges[i].EndVirtualAddress);
            ASSERT (PointerPte->u.Hard.Valid == 1);
            LastPageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

            //
            // Round the start down to a page directory boundary and the end to
            // the last page directory entry before the next boundary.
            //

            PageFrameIndex &= ~(MM_PFN_MAPPED_BY_PDE - 1);
            LastPageFrameIndex |= (MM_PFN_MAPPED_BY_PDE - 1);

            MiRemoveCachedRange (PageFrameIndex, LastPageFrameIndex);
        }
    }

    MiLargeVaRangeIndex = 0;

    return;
}

LONG MiAddPtesCount;

PMMPTE MiExtraPtes1Pointer;
ULONG MiExtraPtes1;
ULONG MiExtraPtes2;


LOGICAL
MiRecoverExtraPtes (
    VOID
    )

/*++

Routine Description:

    This routine is called to recover extra PTEs for the system PTE pool.
    These are not just added in earlier in Phase 0 because the system PTE
    allocator uses the low addresses first which would fragment these
    bigger ranges.

Arguments:

    None.

Return Value:

    TRUE if any PTEs were added, FALSE if not.

Environment:

    Kernel mode.

--*/

{
    LOGICAL PtesAdded;
    PMMPTE PointerPte;
    ULONG OriginalAddPtesCount;

    //
    // Make sure the add is only done once as this is called multiple times.
    //

    OriginalAddPtesCount = InterlockedCompareExchange (&MiAddPtesCount, 1, 0);

    if (OriginalAddPtesCount != 0) {
        return FALSE;
    }

    PtesAdded = FALSE;

    if (MiExtraPtes1 != 0) {

        //
        // Add extra system PTEs to the pool.
        //

        MiAddSystemPtes (MiExtraPtes1Pointer, MiExtraPtes1, SystemPteSpace);
        PtesAdded = TRUE;
    }

    if (MiExtraPtes2 != 0) {

        //
        // Add extra system PTEs to the pool.
        //

        if (MM_SHARED_USER_DATA_VA > MiUseMaximumSystemSpace) {
            if (MiUseMaximumSystemSpaceEnd > MM_SHARED_USER_DATA_VA) {
                MiExtraPtes2 = BYTES_TO_PAGES(MM_SHARED_USER_DATA_VA - MiUseMaximumSystemSpace);
            }
        }

        if (MiExtraPtes2 != 0) {
            PointerPte = MiGetPteAddress (MiUseMaximumSystemSpace);
            MiAddSystemPtes (PointerPte, MiExtraPtes2, SystemPteSpace);
        }
        PtesAdded = TRUE;
    }

    return PtesAdded;
}
LOGICAL
MiIsRegularMemory (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock,
    IN PFN_NUMBER PageFrameIndex
    )

/*++

Routine Description:

    This routine checks whether the argument page frame index represents
    regular memory in the loader descriptor block.  It is only used very
    early during Phase0 init because the MmPhysicalMemoryBlock is not yet
    initialized.

Arguments:

    LoaderBlock  - Supplies a pointer to the firmware setup loader block.

    PageFrameIndex  - Supplies the page frame index to check.

Return Value:

    TRUE if the frame represents regular memory, FALSE if not.

Environment:

    Kernel mode.

--*/

{
    PLIST_ENTRY NextMd;
    PMEMORY_ALLOCATION_DESCRIPTOR MemoryDescriptor;

    NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;

    while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {

        MemoryDescriptor = CONTAINING_RECORD (NextMd,
                                              MEMORY_ALLOCATION_DESCRIPTOR,
                                              ListEntry);

        if (PageFrameIndex >= MemoryDescriptor->BasePage) {

            if (PageFrameIndex < MemoryDescriptor->BasePage + MemoryDescriptor->PageCount) {

                if ((MemoryDescriptor->MemoryType == LoaderFirmwarePermanent) ||
                    (MemoryDescriptor->MemoryType == LoaderBBTMemory) ||
                    (MemoryDescriptor->MemoryType == LoaderSpecialMemory)) {

                    //
                    // This page lies in a memory descriptor for which we will
                    // never create PFN entries, hence return FALSE.
                    //

                    break;
                }

                return TRUE;
            }
        }
        else {

            //
            // Since the loader memory list is sorted in ascending order,
            // the requested page must not be in the loader list at all.
            //

            break;
        }

        NextMd = MemoryDescriptor->ListEntry.Flink;
    }

    //
    // The final check before returning FALSE is to ensure that the requested
    // page wasn't one of the ones we used to normal-map the loader mappings,
    // etc.
    //

    if ((PageFrameIndex >= MxOldFreeDescriptor.BasePage) &&
        (PageFrameIndex < MxOldFreeDescriptor.BasePage + MxOldFreeDescriptor.PageCount)) {

        return TRUE;
    }

    return FALSE;
}

VOID
MiInitMachineDependent (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )

/*++

Routine Description:

    This routine performs the necessary operations to enable virtual
    memory.  This includes building the page directory page, building
    page table pages to map the code section, the data section, the
    stack section and the trap handler.

    It also initializes the PFN database and populates the free list.

Arguments:

    LoaderBlock  - Supplies a pointer to the firmware setup loader block.

Return Value:

    None.

Environment:

    Kernel mode.

    N.B.  This routine uses memory from the loader block descriptors, but
    the descriptors themselves must be restored prior to return as our caller
    walks them to create the MmPhysicalMemoryBlock.

--*/

{
    LOGICAL InitialNonPagedPoolSetViaRegistry;
    PHYSICAL_ADDRESS MaxHotPlugMemoryAddress;
    ULONG Bias;
    PMMPTE BasePte;
    PMMPFN BasePfn;
    PMMPFN BottomPfn;
    PMMPFN TopPfn;
    PFN_NUMBER FirstNonPagedPoolPage;
    PFN_NUMBER FirstPfnDatabasePage;
    LOGICAL PfnInLargePages;
    ULONG BasePage;
    ULONG PagesLeft;
    ULONG Range;
    ULONG PageCount;
    ULONG i, j;
    ULONG PdePageNumber;
    ULONG PdePage;
    ULONG PageFrameIndex;
    ULONG MaxPool;
    PEPROCESS CurrentProcess;
    ULONG DirBase;
    ULONG MostFreePage;
    ULONG MostFreeLowMem;
    PFN_NUMBER PagesNeeded;
    PLIST_ENTRY NextMd;
    PMEMORY_ALLOCATION_DESCRIPTOR MemoryDescriptor;
    MMPTE TempPde;
    MMPTE TempPte;
    PMMPTE PointerPde;
    PMMPTE PointerPte;
    PMMPTE LastPte;
    PMMPTE Pde;
    PMMPTE StartPde;
    PMMPTE EndPde;
    PMMPFN Pfn1;
    PMMPFN Pfn2;
    ULONG PdeCount;
    ULONG va;
    KIRQL OldIrql;
    PVOID VirtualAddress;
    PVOID NonPagedPoolStartVirtual;
    ULONG LargestFreePfnCount;
    ULONG LargestFreePfnStart;
    ULONG FreePfnCount;
    PVOID NonPagedPoolStartLow;
    LOGICAL ExtraSystemCacheViews;
    SIZE_T MaximumNonPagedPoolInBytesLimit;
    PKLDR_DATA_TABLE_ENTRY DataTableEntry;
    PLIST_ENTRY NextEntry;
    ULONG ReturnedLength;
    NTSTATUS status;
    UCHAR Associativity;
    ULONG NonPagedSystemStart;
    LOGICAL PagedPoolMaximumDesired;
    SIZE_T NumberOfBytes;

    if (InitializationPhase == 1) {

        //
        // If the kernel image has not been biased to allow for 3gb of user
        // space, *ALL* the booted processors support large pages, and the
        // number of physical pages is greater than the threshold, then map
        // the kernel image, HAL, PFN database and initial nonpaged pool
        // with large pages.
        //

        if ((KeFeatureBits & KF_LARGE_PAGE) && (MxMapLargePages != 0)) {
            for (i = 0; i < MiLargeVaRangeIndex; i += 1) {
                if (MiLargeVaRanges[i].VirtualAddress != NULL) {
                    MxConvertToLargePage (MiLargeVaRanges[i].VirtualAddress,
                                          MiLargeVaRanges[i].EndVirtualAddress);
                }
            }
        }

        return;
    }

    ASSERT (InitializationPhase == 0);
    ASSERT (MxMapLargePages == MI_LARGE_ALL);

    PfnInLargePages = FALSE;
    ExtraSystemCacheViews = FALSE;
    MostFreePage = 0;
    MostFreeLowMem = 0;
    LargestFreePfnCount = 0;
    NonPagedPoolStartLow = NULL;
    PagedPoolMaximumDesired = FALSE;

    //
    // Initializing these is not needed for correctness, but without it
    // the compiler cannot compile this code W4 to check for use of
    // uninitialized variables.
    //

    LargestFreePfnStart = 0;
    FirstPfnDatabasePage = 0;
    MaximumNonPagedPoolInBytesLimit = 0;

    //
    // If the chip doesn't support large pages or the system is booted /3GB,
    // then disable large page support.
    //

    if (((KeFeatureBits & KF_LARGE_PAGE) == 0) || (MmVirtualBias != 0)) {
        MxMapLargePages = 0;
    }

    //
    // This flag is registry-settable so check before overriding.
    //

    if (MmProtectFreedNonPagedPool == TRUE) {
        MxMapLargePages &= ~(MI_LARGE_PFN_DATABASE | MI_LARGE_NONPAGED_POOL);
    }

    //
    // Sanitize this registry-specifiable large stack size.  Note the registry
    // size is in 1K chunks, ie: 32 means 32k.  Note also that the registry
    // setting does not include the guard page and we don't want to burden
    // administrators with knowing about it so we automatically subtract one
    // page from their request.
    //

    if (MmLargeStackSize > (KERNEL_LARGE_STACK_SIZE / 1024)) {

        //
        // No registry override or the override is too high.
        // Set it to the default.
        //

        MmLargeStackSize = KERNEL_LARGE_STACK_SIZE;
    }
    else {

        //
        // Convert registry override from 1K units to bytes.  Note intelligent
        // choices are 16k or 32k because we bin those sizes in sysptes.
        //

        MmLargeStackSize *= 1024;
        MmLargeStackSize = MI_ROUND_TO_SIZE (MmLargeStackSize, PAGE_SIZE);
        MmLargeStackSize -= PAGE_SIZE;
        ASSERT (MmLargeStackSize <= KERNEL_LARGE_STACK_SIZE);
        ASSERT ((MmLargeStackSize & (PAGE_SIZE-1)) == 0);

        //
        // Don't allow a value that is too low either.
        //

        if (MmLargeStackSize < KERNEL_STACK_SIZE) {
            MmLargeStackSize = KERNEL_STACK_SIZE;
        }
    }

    //
    // If the host processor supports global bits, then set the global
    // bit in the template kernel PTE and PDE entries.
    //

    if (KeFeatureBits & KF_GLOBAL_PAGE) {
        ValidKernelPte.u.Long |= MM_PTE_GLOBAL_MASK;

#if defined(_X86PAE_)

        //
        // Note that the PAE mode of the processor does not support the
        // global bit in PDEs which map 4K page table pages.
        //

        MiUseGlobalBitInLargePdes = TRUE;
#else
        ValidKernelPde.u.Long |= MM_PTE_GLOBAL_MASK;
#endif
        MmPteGlobal.u.Long = MM_PTE_GLOBAL_MASK;
    }

    TempPte = ValidKernelPte;
    TempPde = ValidKernelPde;

    //
    // Set the directory base for the system process.
    //

    PointerPte = MiGetPdeAddress (PDE_BASE);
    PdePageNumber = MI_GET_PAGE_FRAME_FROM_PTE(PointerPte);

    CurrentProcess = PsGetCurrentProcess ();

#if defined(_X86PAE_)

    PrototypePte.u.Soft.PageFileHigh = MI_PTE_LOOKUP_NEEDED;

    _asm {
        mov     eax, cr3
        mov     DirBase, eax
    }

    //
    // Note cr3 must be 32-byte aligned.
    //

    ASSERT ((DirBase & 0x1f) == 0);

    //
    // Initialize the PaeTop for this process right away.
    //

    RtlCopyMemory ((PVOID) &MiSystemPaeVa,
                   (PVOID) (KSEG0_BASE | DirBase),
                   sizeof (MiSystemPaeVa));

    CurrentProcess->PaeTop = &MiSystemPaeVa;

#else

    DirBase = MI_GET_PAGE_FRAME_FROM_PTE(PointerPte) << PAGE_SHIFT;

#endif

    CurrentProcess->Pcb.DirectoryTableBase[0] = DirBase;
    KeSweepDcache (FALSE);

    //
    // Unmap the low 2Gb of memory.
    //

    PointerPde = MiGetPdeAddress (0);
    LastPte = MiGetPdeAddress (KSEG0_BASE);

    MiFillMemoryPte (PointerPde,
                     LastPte - PointerPde,
                     ZeroKernelPte.u.Long);

    //
    // Get the lower bound of the free physical memory and the
    // number of physical pages by walking the memory descriptor lists.
    //

    MxFreeDescriptor = NULL;
    NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;
    while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {
        MemoryDescriptor = CONTAINING_RECORD(NextMd,
                                             MEMORY_ALLOCATION_DESCRIPTOR,
                                             ListEntry);

        if ((MemoryDescriptor->MemoryType != LoaderFirmwarePermanent) &&
            (MemoryDescriptor->MemoryType != LoaderBBTMemory) &&
            (MemoryDescriptor->MemoryType != LoaderHALCachedMemory) &&
            (MemoryDescriptor->MemoryType != LoaderSpecialMemory)) {

            //
            // This check results in /BURNMEMORY chunks not being counted.
            //

            if (MemoryDescriptor->MemoryType != LoaderBad) {
                MmNumberOfPhysicalPages += MemoryDescriptor->PageCount;
            }

            if (MemoryDescriptor->BasePage < MmLowestPhysicalPage) {
                MmLowestPhysicalPage = MemoryDescriptor->BasePage;
            }

            if ((MemoryDescriptor->BasePage + MemoryDescriptor->PageCount) >
                                                             MmHighestPhysicalPage) {
                MmHighestPhysicalPage =
                        MemoryDescriptor->BasePage + MemoryDescriptor->PageCount - 1;
            }

            //
            // Locate the largest free descriptor.
            //

            if ((MemoryDescriptor->MemoryType == LoaderFree) ||
                (MemoryDescriptor->MemoryType == LoaderLoadedProgram) ||
                (MemoryDescriptor->MemoryType == LoaderFirmwareTemporary) ||
                (MemoryDescriptor->MemoryType == LoaderOsloaderStack)) {

                if (MemoryDescriptor->PageCount > MostFreePage) {
                    MostFreePage = MemoryDescriptor->PageCount;
                    MxFreeDescriptor = MemoryDescriptor;
                }
            }
        }

        NextMd = MemoryDescriptor->ListEntry.Flink;
    }

    if (MmLargeSystemCache != 0) {
        ExtraSystemCacheViews = TRUE;
    }

    //
    // This flag is registry-settable so check before overriding.
    //
    // Enabling special IRQL automatically disables mapping the kernel with
    // large pages so we can catch kernel and HAL code.
    //

    if (MmVerifyDriverBufferLength != (ULONG)-1) {
        MmLargePageMinimum = (ULONG)-2;
    }
    else if (MmLargePageMinimum == 0) {
        MmLargePageMinimum = MM_LARGE_PAGE_MINIMUM;
    }

    //
    // Capture the registry-specified initial nonpaged pool setting as we
    // will modify the variable later.
    //

    if ((MmSizeOfNonPagedPoolInBytes != 0) ||
        (MmMaximumNonPagedPoolPercent != 0)) {

        InitialNonPagedPoolSetViaRegistry = TRUE;
    }
    else {
        InitialNonPagedPoolSetViaRegistry = FALSE;
    }

    if (MmNumberOfPhysicalPages <= MmLargePageMinimum) {

        MxMapLargePages = 0;

        //
        // Reduce the size of the initial nonpaged pool on small configurations
        // as RAM is precious (unless the registry has overridden it).
        //

        if ((MmNumberOfPhysicalPages <= MM_LARGE_PAGE_MINIMUM) &&
            (MmSizeOfNonPagedPoolInBytes == 0)) {

            MmSizeOfNonPagedPoolInBytes = 2*1024*1024;
        }
    }

    //
    // MmDynamicPfn may have been initialized based on the registry to
    // a value representing the highest physical address in gigabytes.
    //

    MmDynamicPfn *= ((1024 * 1024 * 1024) / PAGE_SIZE);

    //
    // Retrieve highest hot plug memory range from the HAL if
    // available and not otherwise retrieved from the registry.
    //

    if (MmDynamicPfn == 0) {

        status = HalQuerySystemInformation (HalQueryMaxHotPlugMemoryAddress,
                                            sizeof(PHYSICAL_ADDRESS),
                                            (PPHYSICAL_ADDRESS) &MaxHotPlugMemoryAddress,
                                            &ReturnedLength);

        if (NT_SUCCESS (status)) {
            ASSERT (ReturnedLength == sizeof(PHYSICAL_ADDRESS));

            MmDynamicPfn = (PFN_NUMBER) (MaxHotPlugMemoryAddress.QuadPart / PAGE_SIZE);
        }
    }

    if (MmDynamicPfn != 0) {
        if (MmVirtualBias != 0) {
            MmDynamicPfn = 0;
        }
    }

    if (MmDynamicPfn != 0) {
#if defined(_X86PAE_)
        MmHighestPossiblePhysicalPage = MI_DTC_MAX_PAGES - 1;
#else
        MmHighestPossiblePhysicalPage = MI_DEFAULT_MAX_PAGES - 1;
#endif
        if (MmDynamicPfn - 1 < MmHighestPossiblePhysicalPage) {
            if (MmDynamicPfn - 1 < MmHighestPhysicalPage) {
                MmDynamicPfn = MmHighestPhysicalPage + 1;
            }
            MmHighestPossiblePhysicalPage = MmDynamicPfn - 1;
        }
    }
    else {
        MmHighestPossiblePhysicalPage = MmHighestPhysicalPage;
    }

    if (MmHighestPossiblePhysicalPage > 0x400000 - 1) {

        //
        // The PFN database is more than 112mb.  Force it to come from the
        // 2GB->3GB virtual address range.  Note the administrator cannot be
        // booting /3GB as when he does, the loader throws away memory
        // above the physical 16GB line, so this must be a hot-add
        // configuration.  Since the loader has already put the system at
        // 3GB, the highest possible hot add page must be reduced now.
        //

        if (MmVirtualBias != 0) {
            MmHighestPossiblePhysicalPage = 0x400000 - 1;

            if (MmHighestPhysicalPage > MmHighestPossiblePhysicalPage) {
                MmHighestPhysicalPage = MmHighestPossiblePhysicalPage;
            }
        }
        else {

            //
            // The virtual space between 2 and 3GB virtual is best used
            // for system PTEs when this much physical memory is present.
            //

            ExtraSystemCacheViews = FALSE;
        }
    }

    //
    // Don't enable extra system cache views as virtual addresses are limited.
    // Only a kernel-verifier special case can trigger this.
    //

    if ((KernelVerifier == TRUE) &&
        (MmVirtualBias == 0) &&
        (MmNumberOfPhysicalPages <= MmLargePageMinimum) &&
        (MmHighestPossiblePhysicalPage > 0x100000)) {

        ExtraSystemCacheViews = FALSE;
    }

#if defined(_X86PAE_)

    if (MmVirtualBias != 0) {

        //
        // User space is larger than 2GB, make extra room for the user space
        // working set list & associated hash tables.
        //

        MmSystemCacheWorkingSetList = (PMMWSL) ((ULONG_PTR) 
            MmSystemCacheWorkingSetList + MM_SYSTEM_CACHE_WORKING_SET_3GB_DELTA);
    }

    MmHyperSpaceEnd = (PVOID)((ULONG_PTR)MmSystemCacheWorkingSetList - 1);

    MmSystemCacheWorkingSetListPte = MiGetPteAddress (MmSystemCacheWorkingSetList);

    //
    // Only PAE machines with at least 5GB of physical memory get to use this
    // and then only if they are NOT booted /3GB.
    //

    if (strstr(LoaderBlock->LoadOptions, "NOLOWMEM")) {
        if ((MmVirtualBias == 0) &&
            (MmNumberOfPhysicalPages >= 5 * 1024 * 1024 / 4)) {
                MiNoLowMemory = (PFN_NUMBER)((ULONGLONG)_4gb / PAGE_SIZE);
        }
    }

    if (MiNoLowMemory != 0) {
        MmMakeLowMemory = TRUE;
    }

#endif

    //
    // Save the original descriptor value as everything must be restored
    // prior to this function returning.
    //

    *(PMEMORY_ALLOCATION_DESCRIPTOR)&MxOldFreeDescriptor = *MxFreeDescriptor;

    if (MmNumberOfPhysicalPages < 1100) {
        KeBugCheckEx (INSTALL_MORE_MEMORY,
                      MmNumberOfPhysicalPages,
                      MmLowestPhysicalPage,
                      MmHighestPhysicalPage,
                      0);
    }

    //
    // Build non-paged pool using the physical pages following the
    // data page in which to build the pool from.  Non-paged pool grows
    // from the high range of the virtual address space and expands
    // downward.
    //
    // At this time non-paged pool is constructed so virtual addresses
    // are also physically contiguous.
    //

    if ((MmSizeOfNonPagedPoolInBytes >> PAGE_SHIFT) >
                        (7 * (MmNumberOfPhysicalPages >> 3))) {

        //
        // More than 7/8 of memory is allocated to nonpagedpool, reset to 0.
        //

        MmSizeOfNonPagedPoolInBytes = 0;
        if (MmMaximumNonPagedPoolPercent == 0) {
            InitialNonPagedPoolSetViaRegistry = FALSE;
        }
    }

    if (MmSizeOfNonPagedPoolInBytes < MmMinimumNonPagedPoolSize) {

        //
        // Calculate the size of nonpaged pool.
        // Use the minimum size, then for every MB above 4mb add extra
        // pages.
        //

        MmSizeOfNonPagedPoolInBytes = MmMinimumNonPagedPoolSize;

        MmSizeOfNonPagedPoolInBytes +=
                            ((MmNumberOfPhysicalPages - 1024)/256) *
                            MmMinAdditionNonPagedPoolPerMb;
    }

    if (MmSizeOfNonPagedPoolInBytes > MM_MAX_INITIAL_NONPAGED_POOL) {
        MmSizeOfNonPagedPoolInBytes = MM_MAX_INITIAL_NONPAGED_POOL;
    }

    //
    // If the registry specifies a total nonpaged pool percentage cap, enforce
    // it here.
    //

    if (MmMaximumNonPagedPoolPercent != 0) {

        if (MmMaximumNonPagedPoolPercent < 5) {
            MmMaximumNonPagedPoolPercent = 5;
        }
        else if (MmMaximumNonPagedPoolPercent > 80) {
            MmMaximumNonPagedPoolPercent = 80;
        }

        //
        // Use the registry-expressed percentage value.
        //
    
        MaximumNonPagedPoolInBytesLimit =
            ((MmNumberOfPhysicalPages * MmMaximumNonPagedPoolPercent) / 100);

        //
        // Carefully set the maximum keeping in mind that maximum PAE
        // machines can have 16*1024*1024 pages so care must be taken
        // that multiplying by PAGE_SIZE doesn't overflow here.
        //

        if (MaximumNonPagedPoolInBytesLimit > ((MM_MAX_INITIAL_NONPAGED_POOL + MM_MAX_ADDITIONAL_NONPAGED_POOL) / PAGE_SIZE)) {
            MaximumNonPagedPoolInBytesLimit = MM_MAX_INITIAL_NONPAGED_POOL + MM_MAX_ADDITIONAL_NONPAGED_POOL;
        }
        else {
            MaximumNonPagedPoolInBytesLimit *= PAGE_SIZE;
        }

        if (MaximumNonPagedPoolInBytesLimit < 6 * 1024 * 1024) {
            MaximumNonPagedPoolInBytesLimit = 6 * 1024 * 1024;
        }

        if (MmSizeOfNonPagedPoolInBytes > MaximumNonPagedPoolInBytesLimit) {
            MmSizeOfNonPagedPoolInBytes = MaximumNonPagedPoolInBytesLimit;
        }
    }
    
    //
    // Align to page size boundary.
    //

    MmSizeOfNonPagedPoolInBytes &= ~(PAGE_SIZE - 1);

    //
    // Calculate the maximum size of pool.
    //

    if (MmMaximumNonPagedPoolInBytes == 0) {

        //
        // Calculate the size of nonpaged pool.  If 4mb or less use
        // the minimum size, then for every MB above 4mb add extra
        // pages.
        //

        MmMaximumNonPagedPoolInBytes = MmDefaultMaximumNonPagedPool;

        //
        // Make sure enough expansion for the PFN database exists.
        //

        MmMaximumNonPagedPoolInBytes += (ULONG)PAGE_ALIGN (
                                      (MmHighestPossiblePhysicalPage + 1) * sizeof(MMPFN));

        //
        // Only use the new formula for autosizing nonpaged pool on machines
        // with at least 512MB.  The new formula allocates 1/2 as much nonpaged
        // pool per MB but scales much higher - machines with ~1.2GB or more
        // get 256MB of nonpaged pool.  Note that the old formula gave machines
        // with 512MB of RAM 128MB of nonpaged pool so this behavior is
        // preserved with the new formula as well.
        //

        if (MmNumberOfPhysicalPages >= 0x1f000) {
            MmMaximumNonPagedPoolInBytes +=
                            ((MmNumberOfPhysicalPages - 1024)/256) *
                            (MmMaxAdditionNonPagedPoolPerMb / 2);

            if (MmMaximumNonPagedPoolInBytes < MM_MAX_ADDITIONAL_NONPAGED_POOL) {
                MmMaximumNonPagedPoolInBytes = MM_MAX_ADDITIONAL_NONPAGED_POOL;
            }
        }
        else {
            MmMaximumNonPagedPoolInBytes +=
                            ((MmNumberOfPhysicalPages - 1024)/256) *
                            MmMaxAdditionNonPagedPoolPerMb;
        }
        if ((MmMaximumNonPagedPoolPercent != 0) &&
            (MmMaximumNonPagedPoolInBytes > MaximumNonPagedPoolInBytesLimit)) {
                MmMaximumNonPagedPoolInBytes = MaximumNonPagedPoolInBytesLimit;
        }
    }

    MaxPool = MmSizeOfNonPagedPoolInBytes + PAGE_SIZE * 16 +
                                   (ULONG)PAGE_ALIGN (
                                        (MmHighestPossiblePhysicalPage + 1) * sizeof(MMPFN));

    if (MmMaximumNonPagedPoolInBytes < MaxPool) {
        MmMaximumNonPagedPoolInBytes = MaxPool;
    }

    //
    // Systems that are booted /3GB have a 128MB nonpaged pool maximum,
    //
    // Systems that have a full 2GB system virtual address space can enjoy an
    // extra 128MB of nonpaged pool in the upper GB of the address space.
    //

    MaxPool = MM_MAX_INITIAL_NONPAGED_POOL;

    if (MmVirtualBias == 0) {
        MaxPool += MM_MAX_ADDITIONAL_NONPAGED_POOL;
    }

    if (InitialNonPagedPoolSetViaRegistry == TRUE) {
        MaxPool = MmSizeOfNonPagedPoolInBytes + MM_MAX_ADDITIONAL_NONPAGED_POOL;
    }

    if (MmMaximumNonPagedPoolInBytes > MaxPool) {
        MmMaximumNonPagedPoolInBytes = MaxPool;
    }

    //
    // Grow the initial nonpaged pool if necessary so that the overall pool
    // will aggregate to the right size.
    //

    if ((MmMaximumNonPagedPoolInBytes > MM_MAX_INITIAL_NONPAGED_POOL) &&
        (InitialNonPagedPoolSetViaRegistry == FALSE)) {

        if (MmSizeOfNonPagedPoolInBytes < MmMaximumNonPagedPoolInBytes - MM_MAX_ADDITIONAL_NONPAGED_POOL) {

            //
            // Note the initial nonpaged pool can only be grown if there
            // is a sufficient contiguous physical memory chunk it can
            // be carved from immediately.
            //

            PagesLeft = MxPagesAvailable ();

            if (((MmMaximumNonPagedPoolInBytes - MM_MAX_ADDITIONAL_NONPAGED_POOL) >> PAGE_SHIFT) + ((32 * 1024 * 1024) >> PAGE_SHIFT) < PagesLeft) {

                MmSizeOfNonPagedPoolInBytes = MmMaximumNonPagedPoolInBytes - MM_MAX_ADDITIONAL_NONPAGED_POOL;
            }
            else {

                //
                // Since the initial nonpaged pool could not be grown, don't
                // leave any excess in the expansion nonpaged pool as we
                // cannot encode it into subsection format on non-pae
                // machines.
                //

                if (MmMaximumNonPagedPoolInBytes > MmSizeOfNonPagedPoolInBytes + MM_MAX_ADDITIONAL_NONPAGED_POOL) {
                    MmMaximumNonPagedPoolInBytes = MmSizeOfNonPagedPoolInBytes + MM_MAX_ADDITIONAL_NONPAGED_POOL;
                }
            }
        }
    }

    //
    // Get secondary color value from:
    //
    // (a) from the registry (already filled in) or
    // (b) from the PCR or
    // (c) default value.
    //

    if (MmSecondaryColors == 0) {

        Associativity = KeGetPcr()->SecondLevelCacheAssociativity;

        MmSecondaryColors = KeGetPcr()->SecondLevelCacheSize;

        if (Associativity != 0) {
            MmSecondaryColors /= Associativity;
        }
    }

    MmSecondaryColors = MmSecondaryColors >> PAGE_SHIFT;

    if (MmSecondaryColors == 0) {
        MmSecondaryColors = MM_SECONDARY_COLORS_DEFAULT;
    }
    else {

        //
        // Make sure the value is a power of two and within limits.
        //

        if (((MmSecondaryColors & (MmSecondaryColors - 1)) != 0) ||
            (MmSecondaryColors < MM_SECONDARY_COLORS_MIN) ||
            (MmSecondaryColors > MM_SECONDARY_COLORS_MAX)) {
            MmSecondaryColors = MM_SECONDARY_COLORS_DEFAULT;
        }
    }

    MmSecondaryColorMask = MmSecondaryColors - 1;

#if defined(MI_MULTINODE)

    //
    // Determine the number of bits in MmSecondaryColorMask. This
    // is the number of bits the Node color must be shifted
    // by before it is included in colors.
    //

    i = MmSecondaryColorMask;
    MmSecondaryColorNodeShift = 0;
    while (i != 0) {
        i >>= 1;
        MmSecondaryColorNodeShift += 1;
    }

    //
    // Adjust the number of secondary colors by the number of nodes
    // in the machine.   The secondary color mask is NOT adjusted
    // as it is used to control coloring within a node.  The node
    // color is added to the color AFTER normal color calculations
    // are performed.
    //

    MmSecondaryColors *= KeNumberNodes;

    for (i = 0; i < KeNumberNodes; i += 1) {
        KeNodeBlock[i]->Color = i;
        KeNodeBlock[i]->MmShiftedColor = i << MmSecondaryColorNodeShift;
        InitializeSListHead(&KeNodeBlock[i]->DeadStackList);
    }

#endif

    MiMaximumSystemCacheSizeExtra = 0;

    //
    // Add in the PFN database size (based on the number of pages required
    // from page zero to the highest page).
    //
    // Get the number of secondary colors and add the array for tracking
    // secondary colors to the end of the PFN database.
    //

    MxPfnAllocation = 1 + ((((MmHighestPossiblePhysicalPage + 1) * sizeof(MMPFN)) +
                        (MmSecondaryColors * sizeof(MMCOLOR_TABLES)*2))
                            >> PAGE_SHIFT);

    if (MmVirtualBias == 0) {

        MmNonPagedPoolStart = (PVOID)((ULONG)MmNonPagedPoolEnd
                                      - MmMaximumNonPagedPoolInBytes
                                      + MmSizeOfNonPagedPoolInBytes);
    }
    else {

        MmNonPagedPoolStart = (PVOID)((ULONG) MmNonPagedPoolEnd -
                                      (MmMaximumNonPagedPoolInBytes +
                                       (MxPfnAllocation << PAGE_SHIFT)));
    }

    MmNonPagedPoolStart = (PVOID) PAGE_ALIGN (MmNonPagedPoolStart);

    NonPagedPoolStartVirtual = MmNonPagedPoolStart;

    //
    // Allocate additional paged pool provided it can fit and either the
    // user asked for it or we decide 460MB of PTE space is sufficient.
    //
    // Note at 64GB of RAM, the PFN database spans 464mb.  Given that plus
    // initial nonpaged pool at 128mb and space for the loader's highest
    // page and session space, there may not be any room left to guarantee
    // we will be able to allocate system PTEs out of the virtual address
    // space below 3gb.  So don't crimp for more than 64GB.
    //

    if ((MmVirtualBias == 0) &&
        (MmHighestPossiblePhysicalPage <= 0x1000000)) {

        if (((MmLargeStackSize <= (32 * 1024 - PAGE_SIZE)) && (MiUseMaximumSystemSpace != 0)) ||
        ((MmSizeOfPagedPoolInBytes == (SIZE_T)-1) ||
         ((MmSizeOfPagedPoolInBytes == 0) &&
         (MmNumberOfPhysicalPages >= (1 * 1024 * 1024 * 1024 / PAGE_SIZE)) &&
         (MiRequestedSystemPtes != (ULONG)-1)))) {

            if ((ExpMultiUserTS == FALSE) || (MmSizeOfPagedPoolInBytes != 0)) {

                PagedPoolMaximumDesired = TRUE;
                MmPagedPoolMaximumDesired = TRUE;
            }
            else {

                //
                // This is a multiuser TS machine defaulting to
                // autoconfiguration.  These machines use approximately
                // 3.25x PTEs compared to paged pool per session.
                // If the stack size is halved, then 1.6x becomes the ratio.
                //
                // Estimate how many PTEs and paged pool virtual space
                // will be available and divide it up now.
                //

                ULONG LowVa;
                ULONG TotalVirtualSpace;
                ULONG PagedPoolPortion;
                ULONG PtePortion;

                TotalVirtualSpace = (ULONG) NonPagedPoolStartVirtual - (ULONG) MM_PAGED_POOL_START;
                LowVa = (MM_KSEG0_BASE | MmBootImageSize) + MxPfnAllocation * PAGE_SIZE + MmSizeOfNonPagedPoolInBytes;

                if (LowVa < MiSystemViewStart) {
                    TotalVirtualSpace += (MiSystemViewStart - LowVa);
                }

                PtePortion = 77;
                PagedPoolPortion = 100 - PtePortion;

                //
                // If the large stack size has been reduced, then adjust the
                // ratio automatically as well.
                //

                if (MmLargeStackSize != KERNEL_LARGE_STACK_SIZE) {
                    PtePortion = (PtePortion * MmLargeStackSize) / KERNEL_LARGE_STACK_SIZE;
                }

                MmSizeOfPagedPoolInBytes = (TotalVirtualSpace / (PagedPoolPortion + PtePortion)) * PagedPoolPortion;
            }
    
            //
            // Make sure we always allocate extra PTEs later as we have crimped
            // the initial allocation here.
            //
    
            ExtraSystemCacheViews = FALSE;
            MmNumberOfSystemPtes = 3000;
            MiRequestedSystemPtes = (ULONG)-1;
        }
    }

    //
    // Calculate the starting PDE for the system PTE pool which is
    // right below the nonpaged pool.
    //

    MmNonPagedSystemStart = (PVOID)(((ULONG)NonPagedPoolStartVirtual -
                                ((MmNumberOfSystemPtes + 1) * PAGE_SIZE)) &
                                 (~PAGE_DIRECTORY_MASK));

    if (MmNonPagedSystemStart < MM_LOWEST_NONPAGED_SYSTEM_START) {

        MmNonPagedSystemStart = MM_LOWEST_NONPAGED_SYSTEM_START;

        MmNumberOfSystemPtes = (((ULONG)NonPagedPoolStartVirtual -
                                 (ULONG)MmNonPagedSystemStart) >> PAGE_SHIFT)-1;

        ASSERT (MmNumberOfSystemPtes > 1000);
    }

    if (MmVirtualBias == 0) {

        if ((MmSizeOfPagedPoolInBytes > ((ULONG) MmNonPagedSystemStart - (ULONG) MM_PAGED_POOL_START)) &&
            (MmPagedPoolMaximumDesired == FALSE)) {
    
            ULONG OldNonPagedSystemStart;
            ULONG ExtraPtesNeeded;
            ULONG InitialPagedPoolSize;
    
            MmSizeOfPagedPoolInBytes = MI_ROUND_TO_SIZE (MmSizeOfPagedPoolInBytes, MM_VA_MAPPED_BY_PDE);
    
            //
            // Recalculate the starting PDE for the system PTE pool which is
            // right below the nonpaged pool.  Leave at least 3000 high
            // system PTEs.
            //
    
            OldNonPagedSystemStart = (ULONG) MmNonPagedSystemStart;
    
            NonPagedSystemStart = ((ULONG)NonPagedPoolStartVirtual -
                                        ((3000 + 1) * PAGE_SIZE)) &
                                         ~PAGE_DIRECTORY_MASK;
    
            if (NonPagedSystemStart < (ULONG) MM_LOWEST_NONPAGED_SYSTEM_START) {
                NonPagedSystemStart = (ULONG) MM_LOWEST_NONPAGED_SYSTEM_START;
            }
    
            InitialPagedPoolSize = NonPagedSystemStart - (ULONG) MM_PAGED_POOL_START;
    
            if (MmSizeOfPagedPoolInBytes > InitialPagedPoolSize) {
                MmSizeOfPagedPoolInBytes = InitialPagedPoolSize;
            }
            else {
                NonPagedSystemStart = ((ULONG) MM_PAGED_POOL_START +
                                            MmSizeOfPagedPoolInBytes);
    
                ASSERT ((NonPagedSystemStart & PAGE_DIRECTORY_MASK) == 0);
    
                ASSERT (NonPagedSystemStart >= (ULONG) MM_LOWEST_NONPAGED_SYSTEM_START);
            }
            
            ASSERT (NonPagedSystemStart >= OldNonPagedSystemStart);
            ExtraPtesNeeded = (NonPagedSystemStart - OldNonPagedSystemStart) >> PAGE_SHIFT;
    
            //
            // Note the PagedPoolMaximumDesired local is deliberately not set
            // because we don't want or need to delete PDEs later in this
            // routine.  The exact amount has been allocated here.
            // The global MmPagedPoolMaximumDesired is set because other parts
            // of memory management use it to finish sizing properly.
            //
    
            MmPagedPoolMaximumDesired = TRUE;
    
            MmNonPagedSystemStart = (PVOID) NonPagedSystemStart;
            MmNumberOfSystemPtes = (((ULONG)NonPagedPoolStartVirtual -
                                     (ULONG)NonPagedSystemStart) >> PAGE_SHIFT)-1;
        }
    
        //
        // If the kernel image has not been biased to allow for 3gb of user
        // space, the host processor supports large pages, and the number of
        // physical pages is greater than the threshold, then map the kernel
        // image and HAL into a large page.
        //

        if (MxMapLargePages & MI_LARGE_KERNEL_HAL) {

            //
            // Add the kernel and HAL ranges to the large page ranges.
            //

            i = 0;
            NextEntry = LoaderBlock->LoadOrderListHead.Flink;

            for ( ; NextEntry != &LoaderBlock->LoadOrderListHead; NextEntry = NextEntry->Flink) {

                DataTableEntry = CONTAINING_RECORD (NextEntry,
                                                    KLDR_DATA_TABLE_ENTRY,
                                                    InLoadOrderLinks);
    
                MiLargeVaRanges[MiLargeVaRangeIndex].VirtualAddress = DataTableEntry->DllBase;
                MiLargeVaRanges[MiLargeVaRangeIndex].EndVirtualAddress =
(PVOID)((ULONG_PTR)DataTableEntry->DllBase + DataTableEntry->SizeOfImage - 1);
                MiLargeVaRangeIndex += 1;

                i += 1;
                if (i == 2) {
                    break;
                }
            }
        }
        //
        // If the processor supports large pages and the descriptor has
        // enough contiguous pages for the entire PFN database then use
        // large pages to map it.  Regardless of large page support, put
        // the PFN database in low virtual memory just above the loaded images.
        //

        PagesLeft = MxPagesAvailable ();
    
        if ((MxMapLargePages & (MI_LARGE_PFN_DATABASE | MI_LARGE_NONPAGED_POOL))&&
            (PagesLeft > MxPfnAllocation + (MmSizeOfNonPagedPoolInBytes >> PAGE_SHIFT) + ((32 * 1024 * 1024) >> PAGE_SHIFT))) {
    
            //
            // Allocate the PFN database using large pages as there is enough
            // physically contiguous and decently aligned memory available.
            //
    
            PfnInLargePages = TRUE;
    
            FirstPfnDatabasePage = MxGetNextPage (MxPfnAllocation);

            MmPfnDatabase = (PMMPFN)(MM_KSEG0_BASE | MmBootImageSize);

            ASSERT (((ULONG_PTR)MmPfnDatabase & (MM_VA_MAPPED_BY_PDE - 1)) == 0);

            MmPfnDatabase = (PMMPFN) ((ULONG_PTR)MmPfnDatabase + (((FirstPfnDatabasePage & (MM_PFN_MAPPED_BY_PDE - 1))) << PAGE_SHIFT));

            //
            // Add the PFN database range to the large page ranges.
            //

            MiLargeVaRanges[MiLargeVaRangeIndex].VirtualAddress = MmPfnDatabase;
            MiLargeVaRanges[MiLargeVaRangeIndex].EndVirtualAddress =
                                  (PVOID) (((ULONG_PTR)MmPfnDatabase + (MxPfnAllocation << PAGE_SHIFT)) - 1);
            MiLargeVaRangeIndex += 1;
        }
        else {
            MxMapLargePages &= ~(MI_LARGE_PFN_DATABASE | MI_LARGE_NONPAGED_POOL);
            MmPfnDatabase = (PMMPFN)(MM_KSEG0_BASE | MmBootImageSize);
        }

        //
        // The system is booted 2GB, initial nonpaged pool immediately
        // follows the PFN database.
        //
        // Since the PFN database and the initial nonpaged pool are physically
        // adjacent, a single PDE is shared, thus reducing the number of pages
        // that otherwise might need to be marked as must-be-cachable.
        //
        // Calculate the correct initial nonpaged pool virtual address and
        // maximum size now.  Don't allocate pages for any other use at this
        // point to guarantee that the PFN database and nonpaged pool are
        // physically contiguous so large pages can be enabled.
        //

        MmNonPagedPoolStart = (PVOID)((ULONG_PTR)MmPfnDatabase + (MxPfnAllocation << PAGE_SHIFT));

        //
        // Systems with extremely large PFN databases (ie: spanning 64GB of RAM)
        // and bumped session space sizes may require a reduction in the initial
        // nonpaged pool size in order to fit.
        //

        NumberOfBytes = MiSystemViewStart - (ULONG_PTR) MmNonPagedPoolStart;

        if (MmSizeOfNonPagedPoolInBytes > NumberOfBytes) {

            MmMaximumNonPagedPoolInBytes -= (MmSizeOfNonPagedPoolInBytes - NumberOfBytes);

            MmSizeOfNonPagedPoolInBytes = NumberOfBytes;
        }

        if (PagedPoolMaximumDesired == TRUE) {
    
            //
            // Maximum paged pool was requested.  This means slice away most of
            // the system PTEs being used at the high end of the virtual address
            // space and use that address range for more paged pool instead.
            //
    
            ASSERT (MiIsVirtualAddressOnPdeBoundary (MmNonPagedSystemStart));
    
            PointerPde = MiGetPdeAddress (NonPagedPoolStartVirtual);
            PointerPde -= 2;

            MmNonPagedSystemStart = MiGetVirtualAddressMappedByPde (PointerPde);
            MmNumberOfSystemPtes = (((ULONG)MmNonPagedPoolStart -
                                     (ULONG)MmNonPagedSystemStart) >> PAGE_SHIFT)-1;
        }
    }
    else {

        if ((MxPfnAllocation + 500) * PAGE_SIZE > MmMaximumNonPagedPoolInBytes - MmSizeOfNonPagedPoolInBytes) {

            //
            // Recarve portions of the initial and expansion nonpaged pools
            // so enough expansion PTEs will be available to map the PFN
            // database on large memory systems that are booted /3GB.
            //

            if ((MxPfnAllocation + 500) * PAGE_SIZE < MmSizeOfNonPagedPoolInBytes) {
                MmSizeOfNonPagedPoolInBytes -= ((MxPfnAllocation + 500) * PAGE_SIZE);
            }
        }
    }

    //
    // Allocate pages and fill in the PTEs for the initial nonpaged pool.
    //

    PagesNeeded = MmSizeOfNonPagedPoolInBytes >> PAGE_SHIFT;

    //
    // Don't ask for more than is reasonable both in terms of physical pages
    // left and virtual space available.
    //

    PagesLeft = MxPagesAvailable ();

    if (PagesNeeded > PagesLeft) {
        PagesNeeded = PagesLeft;
    }

    if (MxMapLargePages & MI_LARGE_NONPAGED_POOL) {

        ASSERT (MmVirtualBias == 0);

        //
        // The PFN database has already been allocated (but not mapped).
        // Shortly we will transition from the descriptors to the real PFN
        // database so eat up the slush now.
        //

        VirtualAddress = (PVOID) ((ULONG_PTR)NonPagedPoolStartLow + (PagesNeeded << PAGE_SHIFT));

        if (((ULONG_PTR)VirtualAddress & (MM_VA_MAPPED_BY_PDE - 1)) &&
            (PagesLeft - PagesNeeded > MM_PFN_MAPPED_BY_PDE) &&
            (MmSizeOfNonPagedPoolInBytes + MM_VA_MAPPED_BY_PDE < MM_MAX_INITIAL_NONPAGED_POOL)) {

            //
            // Expand the initial nonpaged pool to use the slush efficiently.
            //

            VirtualAddress = (PVOID) MI_ROUND_TO_SIZE ((ULONG_PTR)VirtualAddress, MM_VA_MAPPED_BY_PDE);
            PagesNeeded = ((ULONG_PTR)VirtualAddress - (ULONG_PTR)NonPagedPoolStartLow) >> PAGE_SHIFT;
        }
    }

    //
    // Update various globals since the size of initial pool may have
    // changed.
    //

    if (MmSizeOfNonPagedPoolInBytes != (PagesNeeded << PAGE_SHIFT)) {
        MmMaximumNonPagedPoolInBytes -= (MmSizeOfNonPagedPoolInBytes - (PagesNeeded << PAGE_SHIFT));
        MmSizeOfNonPagedPoolInBytes = PagesNeeded << PAGE_SHIFT;
    }

    MmMaximumNonPagedPoolInPages = (MmMaximumNonPagedPoolInBytes >> PAGE_SHIFT);

    //
    // Allocate the actual pages for the initial nonpaged pool before
    // any other Mx allocations as these will be sharing the large page
    // with the PFN database when large pages are enabled.
    //

    PageFrameIndex = MxGetNextPage (PagesNeeded);
    FirstNonPagedPoolPage = PageFrameIndex;

    //
    // Set up page table pages to map system PTEs and the expansion nonpaged
    // pool.  If the system was booted /3GB, then the initial nonpaged pool
    // is mapped here as well.
    //

    StartPde = MiGetPdeAddress (MmNonPagedSystemStart);
    EndPde = MiGetPdeAddress ((PVOID)((PCHAR)MmNonPagedPoolEnd - 1));

    while (StartPde <= EndPde) {

        ASSERT (StartPde->u.Hard.Valid == 0);

        //
        // Map in a page table page.
        //

        TempPde.u.Hard.PageFrameNumber = MxGetNextPage (1);

        *StartPde = TempPde;
        PointerPte = MiGetVirtualAddressMappedByPte (StartPde);
        RtlZeroMemory (PointerPte, PAGE_SIZE);
        StartPde += 1;
    }

    if (MmVirtualBias == 0) {

        if (MxMapLargePages & MI_LARGE_PFN_DATABASE) {
            ASSERT (FirstNonPagedPoolPage == FirstPfnDatabasePage + MxPfnAllocation);
        }

        //
        // Allocate the page table pages to map the PFN database and the
        // initial nonpaged pool now.  If the system switches to large
        // pages in Phase 1, these pages will be discarded then.
        //

        StartPde = MiGetPdeAddress (MmPfnDatabase);

        VirtualAddress = (PVOID) ((ULONG_PTR)MmNonPagedPoolStart + MmSizeOfNonPagedPoolInBytes - 1);

        EndPde = MiGetPdeAddress (VirtualAddress);

        //
        // Use any extra virtual address space between the top of initial
        // nonpaged pool and session space for additional system PTEs or
        // caching.
        //

        PointerPde = EndPde + 1;
        EndPde = MiGetPdeAddress (MiSystemViewStart - 1);

        if (PointerPde <= EndPde) {

            //
            // There is available virtual space - consume everything up
            // to the system view area (which is always rounded to a page
            // directory boundary to avoid wasting valuable virtual
            // address space.
            //

            MiExtraResourceStart = (ULONG) MiGetVirtualAddressMappedByPde (PointerPde);
            MiExtraResourceEnd = MiSystemViewStart;
            MiNumberOfExtraSystemPdes = EndPde - PointerPde + 1;

            //
            // Mark the new range as PTEs iff maximum PTEs are requested,
            // TS in app server mode is selected or special pooling is
            // enabled.  Otherwise if large system caching was selected
            // then use it for that.  Finally default to PTEs if neither
            // of the above.
            //

            if ((MiRequestedSystemPtes == (ULONG)-1) ||
                (ExpMultiUserTS == TRUE) ||
                (MmVerifyDriverBufferLength != (ULONG)-1) ||
                ((MmSpecialPoolTag != 0) && (MmSpecialPoolTag != (ULONG)-1))) {

                ExtraSystemCacheViews = FALSE;
            }

            if (ExtraSystemCacheViews == TRUE) {

                //
                // The system is configured to favor large system caching,
                // so share the remaining virtual address space between the
                // system cache and system PTEs.
                //

                MiMaximumSystemCacheSizeExtra =
                                    (MiNumberOfExtraSystemPdes * 5) / 6;

                MiExtraPtes1 = MiNumberOfExtraSystemPdes -
                                    MiMaximumSystemCacheSizeExtra;

                MiExtraPtes1 *= (MM_VA_MAPPED_BY_PDE / PAGE_SIZE);

                MiMaximumSystemCacheSizeExtra *= MM_VA_MAPPED_BY_PDE;

                MiExtraPtes1Pointer = MiGetPteAddress (MiExtraResourceStart + 
                                            MiMaximumSystemCacheSizeExtra);

                MiMaximumSystemCacheSizeExtra >>= PAGE_SHIFT;
            }
            else {
                MiExtraPtes1 = BYTES_TO_PAGES(MiExtraResourceEnd - MiExtraResourceStart);
                MiExtraPtes1Pointer = MiGetPteAddress (MiExtraResourceStart);
            }
        }

        //
        // Allocate and initialize the page table pages.
        //

        while (StartPde <= EndPde) {

            ASSERT (StartPde->u.Hard.Valid == 0);
            if (StartPde->u.Hard.Valid == 0) {

                //
                // Map in a page directory page.
                //

                TempPde.u.Hard.PageFrameNumber = MxGetNextPage (1);

                *StartPde = TempPde;
                PointerPte = MiGetVirtualAddressMappedByPte (StartPde);
                RtlZeroMemory (PointerPte, PAGE_SIZE);
            }
            StartPde += 1;
        }

        if (MiUseMaximumSystemSpace != 0) {

            //
            // Use the 1GB->2GB virtual range for even more system PTEs.
            // Note the shared user data PTE (and PDE) must be left user
            // accessible, but everything else is kernelmode only.
            //

            MiExtraPtes2 = BYTES_TO_PAGES(MiUseMaximumSystemSpaceEnd - MiUseMaximumSystemSpace);

            StartPde = MiGetPdeAddress (MiUseMaximumSystemSpace);
            EndPde = MiGetPdeAddress (MiUseMaximumSystemSpaceEnd);

            while (StartPde < EndPde) {

                ASSERT (StartPde->u.Hard.Valid == 0);

                //
                // Map in a page directory page.
                //

                TempPde.u.Hard.PageFrameNumber = MxGetNextPage (1);

                *StartPde = TempPde;
                PointerPte = MiGetVirtualAddressMappedByPte (StartPde);
                RtlZeroMemory (PointerPte, PAGE_SIZE);
                StartPde += 1;
                MiMaximumSystemExtraSystemPdes += 1;
            }

            ASSERT (MiExtraPtes2 == MiMaximumSystemExtraSystemPdes * PTE_PER_PAGE);
        }

        //
        // The virtual address, length and page tables to map the initial
        // nonpaged pool are already allocated - just fill in the mappings.
        //

        MmSubsectionBase = (ULONG)MmNonPagedPoolStart;

        PointerPte = MiGetPteAddress (MmNonPagedPoolStart);

        LastPte = MiGetPteAddress ((ULONG)MmNonPagedPoolStart +
                                          MmSizeOfNonPagedPoolInBytes);

        if (MxMapLargePages & (MI_LARGE_PFN_DATABASE | MI_LARGE_NONPAGED_POOL)) {
            //
            // Since every page table page needs to be filled, ensure PointerPte
            // and LastPte span entire page table pages, and adjust
            // PageFrameIndex to account for this.
            //

            if (!MiIsPteOnPdeBoundary(PointerPte)) {
                PageFrameIndex -= (BYTE_OFFSET (PointerPte) / sizeof (MMPTE));
                PointerPte = PAGE_ALIGN (PointerPte);
            }

            if (!MiIsPteOnPdeBoundary(LastPte)) {
                LastPte = (PMMPTE) (PAGE_ALIGN (LastPte)) + PTE_PER_PAGE;
            }

            //
            // Add the initial nonpaged pool range to the large page ranges.
            //

            MiLargeVaRanges[MiLargeVaRangeIndex].VirtualAddress = MmNonPagedPoolStart;
            MiLargeVaRanges[MiLargeVaRangeIndex].EndVirtualAddress =
                                  (PVOID) ((ULONG_PTR)MmNonPagedPoolStart + MmSizeOfNonPagedPoolInBytes - 1);
            MiLargeVaRangeIndex += 1;
        }

        MI_ADD_EXECUTE_TO_VALID_PTE_IF_PAE (TempPte);

        while (PointerPte < LastPte) {
            ASSERT (PointerPte->u.Hard.Valid == 0);
            TempPte.u.Hard.PageFrameNumber = PageFrameIndex;
            MI_WRITE_VALID_PTE (PointerPte, TempPte);
            PointerPte += 1;
            PageFrameIndex += 1;
        }

        TempPte = ValidKernelPte;

        MmNonPagedPoolExpansionStart = NonPagedPoolStartVirtual;
    }
    else {

        PointerPte = MiGetPteAddress (MmNonPagedPoolStart);

        LastPte = MiGetPteAddress((ULONG)MmNonPagedPoolStart +
                                            MmSizeOfNonPagedPoolInBytes - 1);

        ASSERT (PagesNeeded == (PFN_NUMBER)(LastPte - PointerPte + 1));

        MI_ADD_EXECUTE_TO_VALID_PTE_IF_PAE (TempPte);

        while (PointerPte <= LastPte) {
            TempPte.u.Hard.PageFrameNumber = PageFrameIndex;
            MI_WRITE_VALID_PTE (PointerPte, TempPte);
            PointerPte += 1;
            PageFrameIndex += 1;
        }

        TempPte = ValidKernelPte;

        MmNonPagedPoolExpansionStart = (PVOID)((PCHAR)NonPagedPoolStartVirtual +
                    MmSizeOfNonPagedPoolInBytes);

        //
        // When booted /3GB, if /USERVA was specified then use any leftover
        // virtual space between 2 and 3gb for extra system PTEs.
        //

        if (MiUseMaximumSystemSpace != 0) {

            MiExtraPtes2 = BYTES_TO_PAGES(MiUseMaximumSystemSpaceEnd - MiUseMaximumSystemSpace);

            StartPde = MiGetPdeAddress (MiUseMaximumSystemSpace);
            EndPde = MiGetPdeAddress (MiUseMaximumSystemSpaceEnd);

            while (StartPde < EndPde) {

                ASSERT (StartPde->u.Hard.Valid == 0);

                //
                // Map in a page directory page.
                //

                TempPde.u.Hard.PageFrameNumber = MxGetNextPage (1);

                *StartPde = TempPde;
                PointerPte = MiGetVirtualAddressMappedByPte (StartPde);
                RtlZeroMemory (PointerPte, PAGE_SIZE);
                StartPde += 1;
                MiMaximumSystemExtraSystemPdes += 1;
            }

            ASSERT (MiExtraPtes2 == MiMaximumSystemExtraSystemPdes * PTE_PER_PAGE);
        }
    }

    //
    // There must be at least one page of system PTEs before the expanded
    // nonpaged pool.
    //

    ASSERT (MiGetPteAddress(MmNonPagedSystemStart) < MiGetPteAddress(MmNonPagedPoolExpansionStart));

    //
    // Non-paged pages now exist, build the pool structures.
    //

    MmPageAlignedPoolBase[NonPagedPool] = MmNonPagedPoolStart;

    if (MmVirtualBias != 0) {

        ULONG NonPagedVa;

        NonPagedVa = (ULONG) MmNonPagedPoolEnd - (ULONG) MmNonPagedPoolExpansionStart;

        ASSERT (NonPagedVa >= (MxPfnAllocation << PAGE_SHIFT));

        //
        // Add one to account for the system PTE top guard page VA.
        //

        NonPagedVa -= ((MxPfnAllocation + 1) << PAGE_SHIFT);

        if (NonPagedVa > MM_MAX_ADDITIONAL_NONPAGED_POOL) {
            NonPagedVa = MM_MAX_ADDITIONAL_NONPAGED_POOL;
        }

        MmMaximumNonPagedPoolInBytes = NonPagedVa + (MxPfnAllocation << PAGE_SHIFT) + MmSizeOfNonPagedPoolInBytes;
        MmMaximumNonPagedPoolInPages = (MmMaximumNonPagedPoolInBytes >> PAGE_SHIFT);
    }

    MiInitializeNonPagedPool ();

    MiInitializeNonPagedPoolThresholds ();

    //
    // Before nonpaged pool can be used, the PFN database must
    // be built.  This is due to the fact that the start and end of
    // allocation bits for nonpaged pool are maintained in the
    // PFN elements for the corresponding pages.
    //

    if (MxMapLargePages & MI_LARGE_PFN_DATABASE) {

        //
        // The physical pages to be used for the PFN database have already
        // been allocated.  Initialize their mappings now.
        //

        //
        // Initialize the page table mappings (the directory mappings are
        // already initialized) for the PFN database until the switch to large
        // pages occurs in Phase 1.
        //

        PointerPte = MiGetPteAddress (MmPfnDatabase);
        BasePte = MiGetVirtualAddressMappedByPte (MiGetPdeAddress (MmPfnDatabase));

        LastPte = MiGetPteAddress ((ULONG_PTR)MmPfnDatabase + (MxPfnAllocation << PAGE_SHIFT));
        if (!MiIsPteOnPdeBoundary(LastPte)) {
            LastPte = MiGetVirtualAddressMappedByPte (MiGetPteAddress (LastPte) + 1);
        }

        PageFrameIndex = FirstPfnDatabasePage - (PointerPte - BasePte);
        PointerPte = BasePte;

        while (PointerPte < LastPte) {
            ASSERT ((PointerPte->u.Hard.Valid == 0) ||
                    (PointerPte->u.Hard.PageFrameNumber == PageFrameIndex));
            if (MiIsPteOnPdeBoundary(PointerPte)) {
                ASSERT ((PageFrameIndex & (MM_PFN_MAPPED_BY_PDE - 1)) == 0);
            }
            TempPte.u.Hard.PageFrameNumber = PageFrameIndex;
            if (PointerPte->u.Hard.Valid == 0) {
                MI_WRITE_VALID_PTE (PointerPte, TempPte);
            }
            else {
                MI_WRITE_VALID_PTE_NEW_PROTECTION (PointerPte, TempPte);
            }
            PointerPte += 1;
            PageFrameIndex += 1;
        }

        RtlZeroMemory (MmPfnDatabase, MxPfnAllocation << PAGE_SHIFT);

        //
        // The PFN database was allocated in large pages.  Since space was left
        // for it virtually (in the nonpaged pool expansion PTEs), remove this
        // now unused space if it can cause PTE encoding to exceed the 27 bits.
        //

        if (MmTotalFreeSystemPtes[NonPagedPoolExpansion] >
                        (MM_MAX_ADDITIONAL_NONPAGED_POOL >> PAGE_SHIFT)) {
            //
            // Reserve the expanded pool PTEs so they cannot be used.
            //

            ULONG PfnDatabaseSpace;

            PfnDatabaseSpace = MmTotalFreeSystemPtes[NonPagedPoolExpansion] -
                        (MM_MAX_ADDITIONAL_NONPAGED_POOL >> PAGE_SHIFT);

            if (MiReserveSystemPtes (PfnDatabaseSpace, NonPagedPoolExpansion) == NULL) {
                MiIssueNoPtesBugcheck (PfnDatabaseSpace, NonPagedPoolExpansion);
            }

            //
            // Adjust the end of nonpaged pool to reflect this reservation.
            // This is so the entire nonpaged pool expansion space is available
            // not just for general purpose consumption, but also for subsection
            // encoding into protoptes when subsections are allocated from the
            // very end of the expansion range.
            //

            MmNonPagedPoolEnd = (PVOID)((PCHAR)MmNonPagedPoolEnd - PfnDatabaseSpace * PAGE_SIZE);
        }
        else {

            //
            // Allocate one more PTE just below the PFN database.  This provides
            // protection against the caller of the first real nonpaged
            // expansion allocation in case he accidentally overruns his pool
            // block.  (We'll trap instead of corrupting the PFN database).
            // This also allows us to freely increment in MiFreePoolPages
            // without having to worry about a valid PTE just after the end of
            // the highest nonpaged pool allocation.
            //

            if (MiReserveSystemPtes (1, NonPagedPoolExpansion) == NULL) {
                MiIssueNoPtesBugcheck (1, NonPagedPoolExpansion);
            }
        }
    }
    else {

        ULONG FreeNextPhysicalPage;
        ULONG FreeNumberOfPages;

        //
        // Calculate the start of the PFN database (it starts at physical
        // page zero, even if the lowest physical page is not zero).
        //

        if (MmVirtualBias == 0) {
            ASSERT (MmPfnDatabase != NULL);
            PointerPte = MiGetPteAddress (MmPfnDatabase);
        }
        else {
            ASSERT (MxPagesAvailable () >= MxPfnAllocation);

            PointerPte = MiReserveSystemPtes (MxPfnAllocation,
                                              NonPagedPoolExpansion);

            if (PointerPte == NULL) {
                MiIssueNoPtesBugcheck (MxPfnAllocation, NonPagedPoolExpansion);
            }

            MmPfnDatabase = (PMMPFN)(MiGetVirtualAddressMappedByPte (PointerPte));

            //
            // Adjust the end of nonpaged pool to reflect the PFN database
            // allocation.  This is so the entire nonpaged pool expansion space
            // is available not just for general purpose consumption, but also
            // for subsection encoding into protoptes when subsections are
            // allocated from the very beginning of the initial nonpaged pool
            // range.
            //

            MmMaximumNonPagedPoolInBytes -= (MxPfnAllocation << PAGE_SHIFT);
            MmMaximumNonPagedPoolInPages = (MmMaximumNonPagedPoolInBytes >> PAGE_SHIFT);

            MmNonPagedPoolEnd = (PVOID)MmPfnDatabase;

            //
            // Allocate one more PTE just below the PFN database.  This provides
            // protection against the caller of the first real nonpaged
            // expansion allocation in case he accidentally overruns his pool
            // block.  (We'll trap instead of corrupting the PFN database).
            // This also allows us to freely increment in MiFreePoolPages
            // without having to worry about a valid PTE just after the end of
            // the highest nonpaged pool allocation.
            //

            if (MiReserveSystemPtes (1, NonPagedPoolExpansion) == NULL) {
                MiIssueNoPtesBugcheck (1, NonPagedPoolExpansion);
            }
        }

        //
        // Go through the memory descriptors and for each physical page make
        // sure the PFN database has a valid PTE to map it.  This allows
        // machines with sparse physical memory to have a minimal PFN database.
        //

        FreeNextPhysicalPage = MxFreeDescriptor->BasePage;
        FreeNumberOfPages = MxFreeDescriptor->PageCount;

        PagesLeft = 0;
        NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;
        while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {
            MemoryDescriptor = CONTAINING_RECORD(NextMd,
                                                 MEMORY_ALLOCATION_DESCRIPTOR,
                                                 ListEntry);

            if ((MemoryDescriptor->MemoryType == LoaderFirmwarePermanent) ||
                (MemoryDescriptor->MemoryType == LoaderBBTMemory) ||
                (MemoryDescriptor->MemoryType == LoaderSpecialMemory)) {

                //
                // Skip these ranges.
                //

                NextMd = MemoryDescriptor->ListEntry.Flink;
                continue;
            }

            //
            // Temporarily add back in the memory allocated since Phase 0
            // began so PFN entries for it will be created and mapped.
            //
            // Note actual PFN entry allocations must be done carefully as
            // memory from the descriptor itself could get used to map
            // the PFNs for the descriptor !
            //

            if (MemoryDescriptor == MxFreeDescriptor) {
                BasePage = MxOldFreeDescriptor.BasePage;
                PageCount = MxOldFreeDescriptor.PageCount;
            }
            else {
                BasePage = MemoryDescriptor->BasePage;
                PageCount = MemoryDescriptor->PageCount;
            }

            PointerPte = MiGetPteAddress (MI_PFN_ELEMENT(BasePage));

            LastPte = MiGetPteAddress (((PCHAR)(MI_PFN_ELEMENT(
                                            BasePage + PageCount))) - 1);

            while (PointerPte <= LastPte) {
                if (PointerPte->u.Hard.Valid == 0) {
                    TempPte.u.Hard.PageFrameNumber = FreeNextPhysicalPage;
                    ASSERT (FreeNumberOfPages != 0);
                    FreeNextPhysicalPage += 1;
                    FreeNumberOfPages -= 1;
                    if (FreeNumberOfPages == 0) {
                        KeBugCheckEx (INSTALL_MORE_MEMORY,
                                      MmNumberOfPhysicalPages,
                                      FreeNumberOfPages,
                                      MxOldFreeDescriptor.PageCount,
                                      1);
                    }
                    PagesLeft += 1;
                    MI_WRITE_VALID_PTE (PointerPte, TempPte);
                    RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPte),
                                   PAGE_SIZE);
                }
                PointerPte += 1;
            }

            NextMd = MemoryDescriptor->ListEntry.Flink;
        }

        //
        // Update the global counts - this would have been tricky to do while
        // removing pages from them as we looped above.
        //
        // Later we will walk the memory descriptors and add pages to the free
        // list in the PFN database.
        //
        // To do this correctly:
        //
        // The FreeDescriptor fields must be updated so the PFN database
        // consumption isn't added to the freelist.
        //

        MxFreeDescriptor->BasePage = FreeNextPhysicalPage;
        MxFreeDescriptor->PageCount = FreeNumberOfPages;
    }

#if defined (_X86PAE_)

    for (i = 0; i < 32; i += 1) {
        j = i & 7;
        switch (j) {
            case MM_READONLY:
            case MM_READWRITE:
            case MM_WRITECOPY:
                MmProtectToPteMask[i] |= MmPaeMask;
                break;
            default:
                break;
        }
    }

#endif

    //
    // Initialize support for colored pages.
    //

    MmFreePagesByColor[0] = (PMMCOLOR_TABLES)
                              &MmPfnDatabase[MmHighestPossiblePhysicalPage + 1];

    MmFreePagesByColor[1] = &MmFreePagesByColor[0][MmSecondaryColors];

    //
    // Make sure the PTEs are mapped.
    //

    PointerPte = MiGetPteAddress (&MmFreePagesByColor[0][0]);

    LastPte = MiGetPteAddress (
              (PVOID)((PCHAR)&MmFreePagesByColor[1][MmSecondaryColors] - 1));

    while (PointerPte <= LastPte) {
        if (PointerPte->u.Hard.Valid == 0) {
            TempPte.u.Hard.PageFrameNumber = MxGetNextPage (1);
            MI_WRITE_VALID_PTE (PointerPte, TempPte);
            RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPte),
                           PAGE_SIZE);
        }

        PointerPte += 1;
    }

    for (i = 0; i < MmSecondaryColors; i += 1) {
        MmFreePagesByColor[ZeroedPageList][i].Flink = MM_EMPTY_LIST;
        MmFreePagesByColor[ZeroedPageList][i].Blink = (PVOID) MM_EMPTY_LIST;
        MmFreePagesByColor[ZeroedPageList][i].Count = 0;
        MmFreePagesByColor[FreePageList][i].Flink = MM_EMPTY_LIST;
        MmFreePagesByColor[FreePageList][i].Blink = (PVOID) MM_EMPTY_LIST;
        MmFreePagesByColor[FreePageList][i].Count = 0;
    }

    //
    // Add nonpaged pool to PFN database if mapped via large pages.
    //

    PointerPde = MiGetPdeAddress (PTE_BASE);

    if ((MmNonPagedPoolStart < (PVOID)MM_SYSTEM_CACHE_END_EXTRA) &&
        (MxMapLargePages & MI_LARGE_NONPAGED_POOL)) {

        j = FirstNonPagedPoolPage;
        Pfn1 = MI_PFN_ELEMENT (j);
        i = MmSizeOfNonPagedPoolInBytes >> PAGE_SHIFT;

        do {
            PointerPde = MiGetPdeAddress ((ULONG_PTR)MmNonPagedPoolStart + ((j - FirstNonPagedPoolPage) << PAGE_SHIFT));
            Pfn1->u4.PteFrame = MI_GET_PAGE_FRAME_FROM_PTE(PointerPde);
            Pfn1->PteAddress = (PMMPTE)(j << PAGE_SHIFT);
            Pfn1->u2.ShareCount += 1;
            Pfn1->u3.e2.ReferenceCount = 1;
            Pfn1->u3.e1.PageLocation = ActiveAndValid;
            Pfn1->u3.e1.CacheAttribute = MiCached;
            MiDetermineNode (j, Pfn1);
            j += 1;
            Pfn1 += 1;
            i -= 1;
        } while (i != 0);
    }

    //
    // Go through the page table entries and for any page which is valid,
    // update the corresponding PFN database element.
    //

    Pde = MiGetPdeAddress (NULL);
    va = 0;
    PdeCount = PD_PER_SYSTEM * PDE_PER_PAGE;

    for (i = 0; i < PdeCount; i += 1) {

        //
        // If the kernel image has been biased to allow for 3gb of user
        // address space, then the first several mb of memory is
        // double mapped to KSEG0_BASE and to ALTERNATE_BASE. Therefore,
        // the KSEG0_BASE entries must be skipped.
        //

        if (MmVirtualBias != 0) {
            if ((Pde >= MiGetPdeAddress(KSEG0_BASE)) &&
                (Pde < MiGetPdeAddress(KSEG0_BASE + MmBootImageSize))) {
                Pde += 1;
                va += (ULONG)PDE_PER_PAGE * (ULONG)PAGE_SIZE;
                continue;
            }
        }

        if ((Pde->u.Hard.Valid == 1) && (Pde->u.Hard.LargePage == 0)) {

            PdePage = MI_GET_PAGE_FRAME_FROM_PTE(Pde);

            if (MiIsRegularMemory (LoaderBlock, PdePage)) {

                Pfn1 = MI_PFN_ELEMENT(PdePage);
                Pfn1->u4.PteFrame = PdePageNumber;
                Pfn1->PteAddress = Pde;
                Pfn1->u2.ShareCount += 1;
                Pfn1->u3.e2.ReferenceCount = 1;
                Pfn1->u3.e1.PageLocation = ActiveAndValid;
                Pfn1->u3.e1.CacheAttribute = MiCached;
                MiDetermineNode (PdePage, Pfn1);
            }
            else {
                Pfn1 = NULL;
            }

            PointerPte = MiGetPteAddress (va);

            //
            // Set global bit.
            //

            TempPde.u.Long = MiDetermineUserGlobalPteMask (PointerPte) &
                                                           ~MM_PTE_ACCESS_MASK;

#if defined(_X86PAE_)

            //
            // Note that the PAE mode of the processor does not support the
            // global bit in PDEs which map 4K page table pages.
            //

            TempPde.u.Hard.Global = 0;
#endif

            Pde->u.Long |= TempPde.u.Long;

            for (j = 0 ; j < PTE_PER_PAGE; j += 1) {
                if (PointerPte->u.Hard.Valid == 1) {

                    PointerPte->u.Long |= MiDetermineUserGlobalPteMask (PointerPte) &
                                                            ~MM_PTE_ACCESS_MASK;

                    ASSERT (Pfn1 != NULL);
                    Pfn1->u2.ShareCount += 1;

                    if ((MiIsRegularMemory (LoaderBlock, (PFN_NUMBER) PointerPte->u.Hard.PageFrameNumber)) &&

                        ((va >= MM_KSEG2_BASE) &&
                         ((va < KSEG0_BASE + MmVirtualBias) ||
                          (va >= (KSEG0_BASE + MmVirtualBias + MmBootImageSize)))) ||
                        ((MmVirtualBias == 0) &&
                         (va >= (ULONG)MmNonPagedPoolStart) &&
                         (va < (ULONG)MmNonPagedPoolStart + MmSizeOfNonPagedPoolInBytes))) {

                        Pfn2 = MI_PFN_ELEMENT(PointerPte->u.Hard.PageFrameNumber);

                        if (MmIsAddressValid(Pfn2) &&
                             MmIsAddressValid((PUCHAR)(Pfn2+1)-1)) {

                            Pfn2->u4.PteFrame = PdePage;
                            Pfn2->PteAddress = PointerPte;
                            Pfn2->u2.ShareCount += 1;
                            Pfn2->u3.e2.ReferenceCount = 1;
                            Pfn2->u3.e1.PageLocation = ActiveAndValid;
                            Pfn2->u3.e1.CacheAttribute = MiCached;
                            MiDetermineNode(
                                (PFN_NUMBER)PointerPte->u.Hard.PageFrameNumber,
                                Pfn2);
                        }
                    }
                }

                va += PAGE_SIZE;
                PointerPte += 1;
            }

        }
        else {
            va += (ULONG)PDE_PER_PAGE * (ULONG)PAGE_SIZE;
        }

        Pde += 1;
    }

    KeFlushCurrentTb ();

    //
    // If the lowest physical page is zero and the page is still unused, mark
    // it as in use. This is because we want to find bugs where a physical
    // page is specified as zero.
    //

    Pfn1 = &MmPfnDatabase[MmLowestPhysicalPage];

    if ((MmLowestPhysicalPage == 0) && (Pfn1->u3.e2.ReferenceCount == 0)) {

        ASSERT (Pfn1->u3.e2.ReferenceCount == 0);

        //
        // Make the reference count non-zero and point it into a
        // page directory.
        //

        Pde = MiGetPdeAddress (0xffffffff);
        PdePage = MI_GET_PAGE_FRAME_FROM_PTE(Pde);
        Pfn1->u4.PteFrame = PdePageNumber;
        Pfn1->PteAddress = Pde;
        Pfn1->u2.ShareCount += 1;
        Pfn1->u3.e2.ReferenceCount = 0xfff0;
        Pfn1->u3.e1.PageLocation = ActiveAndValid;
        Pfn1->u3.e1.CacheAttribute = MiCached;
        MiDetermineNode (0, Pfn1);
    }

    //
    // Walk through the memory descriptors and add pages to the
    // free list in the PFN database.  Before doing this, adjust the
    // two descriptors we used so they only contain memory that can be
    // freed now (ie: any memory we removed from them earlier in this routine
    // without updating the descriptor for must be updated now).
    //

    //
    // We may have taken memory out of the MxFreeDescriptor - but
    // that's ok because we wouldn't want to free that memory right now
    // (or ever) anyway.
    //

    //
    // Since the LoaderBlock memory descriptors are ordered
    // from low physical memory address to high, walk it backwards so the
    // high physical pages go to the front of the freelists.  The thinking
    // is that pages initially allocated by the system are less likely to be
    // freed so don't waste memory below 16mb (or 4gb) that may be needed
    // by ISA drivers later.
    //

    NextMd = LoaderBlock->MemoryDescriptorListHead.Blink;

    Bias = 0;
    if (MmVirtualBias != 0) {

        //
        // This is nasty.  You don't want to know.  Cleanup needed.
        //

        Bias = ALTERNATE_BASE - KSEG0_BASE;
    }

    while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {

        MemoryDescriptor = CONTAINING_RECORD(NextMd,
                                             MEMORY_ALLOCATION_DESCRIPTOR,
                                             ListEntry);

        i = MemoryDescriptor->PageCount;
        PageFrameIndex = MemoryDescriptor->BasePage;

        //
        // Ensure no frames are inserted beyond the end of the PFN
        // database.  This can happen for example if the system
        // has > 16GB of RAM and is booted /3GB - the top of this
        // routine reduces the highest physical page and then
        // creates the PFN database.  But the loader block still
        // contains descriptions of the pages above 16GB.
        //

        if (PageFrameIndex > MmHighestPhysicalPage) {
            NextMd = MemoryDescriptor->ListEntry.Blink;
            continue;
        }

        if (PageFrameIndex + i > MmHighestPhysicalPage + 1) {
            i = MmHighestPhysicalPage + 1 - PageFrameIndex;
            MemoryDescriptor->PageCount = i;
            if (i == 0) {
                NextMd = MemoryDescriptor->ListEntry.Blink;
                continue;
            }
        }

        switch (MemoryDescriptor->MemoryType) {
            case LoaderBad:
                while (i != 0) {
                    MiInsertPageInList (&MmBadPageListHead, PageFrameIndex);
                    i -= 1;
                    PageFrameIndex += 1;
                }
                break;

            case LoaderFree:
            case LoaderLoadedProgram:
            case LoaderFirmwareTemporary:
            case LoaderOsloaderStack:

                FreePfnCount = 0;
                Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);
                LOCK_PFN (OldIrql);
                while (i != 0) {
                    if (Pfn1->u3.e2.ReferenceCount == 0) {

                        //
                        // Set the PTE address to the physical page for
                        // virtual address alignment checking.
                        //

                        Pfn1->PteAddress =
                                        (PMMPTE)(PageFrameIndex << PTE_SHIFT);

                        //
                        // No need to initialize Pfn1->u3.e1.CacheAttribute
                        // here as the freelist insertion will mark it as
                        // not-mapped.
                        //

                        MiDetermineNode (PageFrameIndex, Pfn1);
                        MiInsertPageInFreeList (PageFrameIndex);
                        FreePfnCount += 1;
                    }
                    else {
                        if (FreePfnCount > LargestFreePfnCount) {
                            LargestFreePfnCount = FreePfnCount;
                            LargestFreePfnStart = PageFrameIndex - FreePfnCount;
                            FreePfnCount = 0;
                        }
                    }

                    Pfn1 += 1;
                    i -= 1;
                    PageFrameIndex += 1;
                }
                UNLOCK_PFN (OldIrql);

                if (FreePfnCount > LargestFreePfnCount) {
                    LargestFreePfnCount = FreePfnCount;
                    LargestFreePfnStart = PageFrameIndex - FreePfnCount;
                }

                break;

            case LoaderFirmwarePermanent:
            case LoaderSpecialMemory:
            case LoaderBBTMemory:

                //
                // Skip these ranges.
                //

                break;

            default:

                PointerPte = MiGetPteAddress (KSEG0_BASE + Bias +
                                            (PageFrameIndex << PAGE_SHIFT));

                Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);
                while (i != 0) {

                    //
                    // Set page as in use.
                    //

                    PointerPde = MiGetPdeAddress (KSEG0_BASE + Bias +
                                             (PageFrameIndex << PAGE_SHIFT));

                    if (Pfn1->u3.e2.ReferenceCount == 0) {
                        Pfn1->u4.PteFrame = MI_GET_PAGE_FRAME_FROM_PTE(PointerPde);
                        Pfn1->PteAddress = PointerPte;
                        Pfn1->u2.ShareCount += 1;
                        Pfn1->u3.e2.ReferenceCount = 1;
                        Pfn1->u3.e1.PageLocation = ActiveAndValid;
                        MiDetermineNode (PageFrameIndex, Pfn1);

                        if (MemoryDescriptor->MemoryType == LoaderXIPRom) {
                            Pfn1->u1.Flink = 0;
                            Pfn1->u2.ShareCount = 0;
                            Pfn1->u3.e2.ReferenceCount = 0;
                            Pfn1->u3.e1.PageLocation = 0;
                            Pfn1->u3.e1.Rom = 1;
                            Pfn1->u4.InPageError = 0;
                            Pfn1->u3.e1.PrototypePte = 1;
                        }
                        Pfn1->u3.e1.CacheAttribute = MiCached;
                    }
                    Pfn1 += 1;
                    i -= 1;
                    PageFrameIndex += 1;
                    PointerPte += 1;
                }
                break;
        }

        NextMd = MemoryDescriptor->ListEntry.Blink;
    }

    if (PfnInLargePages == FALSE) {

        //
        // Indicate that the PFN database is allocated in nonpaged pool.
        //

        PointerPte = MiGetPteAddress (&MmPfnDatabase[MmLowestPhysicalPage]);
        Pfn1 = MI_PFN_ELEMENT(PointerPte->u.Hard.PageFrameNumber);
        Pfn1->u3.e1.StartOfAllocation = 1;

        if (MmVirtualBias == 0) {
            LastPte = MiGetPteAddress (&MmPfnDatabase[MmHighestPossiblePhysicalPage]);
            while (PointerPte <= LastPte) {
                Pfn1 = MI_PFN_ELEMENT(PointerPte->u.Hard.PageFrameNumber);
                Pfn1->u2.ShareCount = 1;
                Pfn1->u3.e2.ReferenceCount = 1;
                PointerPte += 1;
            }
        }

        //
        // Set the end of the allocation.
        //

        PointerPte = MiGetPteAddress (&MmPfnDatabase[MmHighestPossiblePhysicalPage]);
        Pfn1 = MI_PFN_ELEMENT(PointerPte->u.Hard.PageFrameNumber);
        Pfn1->u3.e1.EndOfAllocation = 1;
    }
    else {

        //
        // The PFN database is allocated using large pages.
        //
        // Mark all PFN entries for the PFN pages in use.
        //

        PointerPte = MiGetPteAddress (MmPfnDatabase);
        PageFrameIndex = (PFN_NUMBER)PointerPte->u.Hard.PageFrameNumber;
        Pfn1 = MI_PFN_ELEMENT(PageFrameIndex);
        i = MxPfnAllocation;

        do {
            Pfn1->PteAddress = (PMMPTE)(PageFrameIndex << PTE_SHIFT);
            Pfn1->u3.e1.CacheAttribute = MiCached;
            MiDetermineNode (PageFrameIndex, Pfn1);
            Pfn1->u3.e2.ReferenceCount += 1;
            PageFrameIndex += 1;
            Pfn1 += 1;
            i -= 1;
        } while (i != 0);

        if (MmDynamicPfn == 0) {

            //
            // Scan the PFN database backward for pages that are completely
            // zero.  These pages are unused and can be added to the free list.
            //

            BottomPfn = MI_PFN_ELEMENT(MmHighestPhysicalPage);
            do {

                //
                // Compute the address of the start of the page that is next
                // lower in memory and scan backwards until that page address
                // is reached or just crossed.
                //

                if (((ULONG)BottomPfn & (PAGE_SIZE - 1)) != 0) {
                    BasePfn = (PMMPFN)((ULONG)BottomPfn & ~(PAGE_SIZE - 1));
                    TopPfn = BottomPfn + 1;

                }
                else {
                    BasePfn = (PMMPFN)((ULONG)BottomPfn - PAGE_SIZE);
                    TopPfn = BottomPfn;
                }

                while (BottomPfn > BasePfn) {
                    BottomPfn -= 1;
                }

                //
                // If the entire range over which the PFN entries span is
                // completely zero and the PFN entry that maps the page is
                // not in the range, then add the page to the appropriate
                // free list.
                //

                Range = (ULONG)TopPfn - (ULONG)BottomPfn;
                if (RtlCompareMemoryUlong((PVOID)BottomPfn, Range, 0) == Range) {

                    //
                    // Set the PTE address to the physical page for virtual
                    // address alignment checking.
                    //

                    PointerPte = MiGetPteAddress (BasePfn);
                    PageFrameIndex = (PFN_NUMBER)PointerPte->u.Hard.PageFrameNumber;
                    Pfn1 = MI_PFN_ELEMENT(PageFrameIndex);

                    ASSERT (Pfn1->u3.e2.ReferenceCount == 1);
                    ASSERT (Pfn1->PteAddress == (PMMPTE)(PageFrameIndex << PTE_SHIFT));
                    Pfn1->u3.e2.ReferenceCount = 0;
                    Pfn1->PteAddress = (PMMPTE)(PageFrameIndex << PTE_SHIFT);

                    //
                    // No need to initialize Pfn1->u3.e1.CacheAttribute
                    // here as the freelist insertion will mark it as
                    // not-mapped.
                    //

                    MiDetermineNode (PageFrameIndex, Pfn1);
                    LOCK_PFN (OldIrql);
                    MiInsertPageInFreeList (PageFrameIndex);
                    UNLOCK_PFN (OldIrql);
                }
            } while (BottomPfn > MmPfnDatabase);
        }
    }

    //
    // Adjust the memory descriptor to indicate that free pool has
    // been used for nonpaged pool creation.
    //
    // N.B.  This is required because the descriptors are walked upon
    // return from this routine to create the MmPhysicalMemoryBlock.
    //

    *MxFreeDescriptor = *(PMEMORY_ALLOCATION_DESCRIPTOR)&MxOldFreeDescriptor;

    //
    // Initialize the nonpaged pool.
    //

    InitializePool (NonPagedPool, 0);

    //
    // Initialize the system PTE pool now that nonpaged pool exists.
    // This is used for mapping I/O space, driver images and kernel stacks.
    // Note this expands the initial PTE allocation to use all possible
    // available virtual space by reclaiming the initial nonpaged
    // pool range (in non /3GB systems) because that range has already been
    // moved into the 2GB virtual range.
    //

    PointerPte = MiGetPteAddress (MmNonPagedSystemStart);
    ASSERT (((ULONG)PointerPte & (PAGE_SIZE - 1)) == 0);

    MmNumberOfSystemPtes = MiGetPteAddress (NonPagedPoolStartVirtual) - PointerPte - 1;

    MiInitializeSystemPtes (PointerPte, MmNumberOfSystemPtes, SystemPteSpace);

    if (MiExtraPtes1 != 0) {

        //
        // Increment the system PTEs (for autoconfiguration purposes) but
        // don't actually add the PTEs till later (to prevent fragmentation).
        //

        MiIncrementSystemPtes (MiExtraPtes1);
    }

    if (MiExtraPtes2 != 0) {

        //
        // Add extra system PTEs to the pool.
        //

        if (MM_SHARED_USER_DATA_VA > MiUseMaximumSystemSpace) {
            if (MiUseMaximumSystemSpaceEnd > MM_SHARED_USER_DATA_VA) {
                MiExtraPtes2 = BYTES_TO_PAGES(MM_SHARED_USER_DATA_VA - MiUseMaximumSystemSpace);
            }
        }
        else {
            ASSERT (MmVirtualBias != 0);
        }

        if (MiExtraPtes2 != 0) {

            //
            // Increment the system PTEs (for autoconfiguration purposes) but
            // don't actually add the PTEs till later (to prevent
            // fragmentation).
            //

            MiIncrementSystemPtes (MiExtraPtes2);
        }
    }

    //
    // Recover the extra PTE ranges immediately if special pool is enabled
    // so the special pool range can be made as large as possible by consuming
    // these.
    //

    if ((MmVerifyDriverBufferLength != (ULONG)-1) ||
        ((MmSpecialPoolTag != 0) && (MmSpecialPoolTag != (ULONG)-1))) {
        MiRecoverExtraPtes ();
    }

    //
    // Initialize memory management structures for this process.
    //
    // Build the working set list.  This requires the creation of a PDE
    // to map hyperspace and the page table page pointed to
    // by the PDE must be initialized.
    //
    // Note we can't remove a zeroed page as hyperspace does not
    // exist and we map non-zeroed pages into hyperspace to zero them.
    //

    TempPde = ValidKernelPdeLocal;

    PointerPde = MiGetPdeAddress (HYPER_SPACE);

    LOCK_PFN (OldIrql);

    PageFrameIndex = MiRemoveAnyPage (0);
    TempPde.u.Hard.PageFrameNumber = PageFrameIndex;

    MI_WRITE_VALID_PTE (PointerPde, TempPde);

#if defined (_X86PAE_)
    PointerPde = MiGetPdeAddress((PVOID)((PCHAR)HYPER_SPACE + MM_VA_MAPPED_BY_PDE));

    PageFrameIndex = MiRemoveAnyPage (0);
    TempPde.u.Hard.PageFrameNumber = PageFrameIndex;

    MI_WRITE_VALID_PTE (PointerPde, TempPde);

    //
    // Point to the page table page we just created and zero it.
    //

    PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
    RtlZeroMemory (PointerPte, PAGE_SIZE);
#endif

    KeFlushCurrentTb();

    UNLOCK_PFN (OldIrql);

    //
    // Point to the page table page we just created and zero it.
    //

    PointerPte = MiGetPteAddress(HYPER_SPACE);
    RtlZeroMemory ((PVOID)PointerPte, PAGE_SIZE);

    //
    // Hyper space now exists, set the necessary variables.
    //

    MmFirstReservedMappingPte = MiGetPteAddress (FIRST_MAPPING_PTE);
    MmLastReservedMappingPte = MiGetPteAddress (LAST_MAPPING_PTE);

    MmFirstReservedMappingPte->u.Hard.PageFrameNumber = NUMBER_OF_MAPPING_PTES;

    MmWorkingSetList = (PMMWSL) ((ULONG_PTR)VAD_BITMAP_SPACE + PAGE_SIZE);

    //
    // Create zeroing PTEs for the zero page thread.
    //

    MiFirstReservedZeroingPte = MiReserveSystemPtes (NUMBER_OF_ZEROING_PTES + 1,
                                                     SystemPteSpace);

    RtlZeroMemory (MiFirstReservedZeroingPte,
                   (NUMBER_OF_ZEROING_PTES + 1) * sizeof(MMPTE));

    //
    // Use the page frame number field of the first PTE as an
    // offset into the available zeroing PTEs.
    //

    MiFirstReservedZeroingPte->u.Hard.PageFrameNumber = NUMBER_OF_ZEROING_PTES;

    //
    // Create the VAD bitmap for this process.
    //

    PointerPte = MiGetPteAddress (VAD_BITMAP_SPACE);

    LOCK_PFN (OldIrql);
    PageFrameIndex = MiRemoveAnyPage (0);
    UNLOCK_PFN (OldIrql);

    //
    // Note the global bit must be off for the bitmap data.
    //

    TempPte = ValidKernelPteLocal;
    TempPte.u.Hard.PageFrameNumber = PageFrameIndex;
    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Point to the page we just created and zero it.
    //

    RtlZeroMemory (VAD_BITMAP_SPACE, PAGE_SIZE);

    //
    // If booted /3GB, then the bitmap needs to be 2K bigger, shift
    // the working set accordingly as well.
    //
    // Note the 2K expansion portion of the bitmap is automatically
    // carved out of the working set page allocated below.
    //

    if (MmVirtualBias != 0) {
        MmWorkingSetList = (PMMWSL) ((ULONG_PTR)MmWorkingSetList + PAGE_SIZE / 2);
    }

    MiLastVadBit = (((ULONG_PTR) MI_64K_ALIGN (MM_HIGHEST_VAD_ADDRESS))) / X64K;

#if defined (_X86PAE_)

    //
    // Only bitmap the first 2GB of the PAE address space when booted /3GB.
    // This is because PAE has twice as many pagetable pages as non-PAE which
    // causes the MMWSL structure to be larger than 2K.  If we bitmapped the
    // entire user address space in this configuration then we'd need a 6K
    // bitmap and this would cause the initial MMWSL structure to overflow
    // into a second page.  This would require a bunch of extra code throughout
    // process support and other areas so just limit the bitmap for now.
    //

    if (MiLastVadBit > PAGE_SIZE * 8 - 1) {
        ASSERT (MmVirtualBias != 0);
        MiLastVadBit = PAGE_SIZE * 8 - 1;
        MmWorkingSetList = (PMMWSL) ((ULONG_PTR)VAD_BITMAP_SPACE + PAGE_SIZE);
    }

#endif

    KeInitializeEvent (&MiImageMappingPteEvent,
                       NotificationEvent,
                       FALSE);

    //
    // Initialize this process's memory management structures including
    // the working set list.
    //
    // The PFN element for the page directory has already been initialized,
    // zero the reference count and the share count so they won't be
    // wrong.
    //

    Pfn1 = MI_PFN_ELEMENT (PdePageNumber);

    LOCK_PFN (OldIrql);

    Pfn1->u2.ShareCount = 0;
    Pfn1->u3.e2.ReferenceCount = 0;

#if defined (_X86PAE_)
    PointerPte = MiGetPteAddress (PDE_BASE);
    for (i = 0; i < PD_PER_SYSTEM; i += 1) {

        PdePageNumber = MI_GET_PAGE_FRAME_FROM_PTE(PointerPte);

        Pfn1 = MI_PFN_ELEMENT (PdePageNumber);
        Pfn1->u2.ShareCount = 0;
        Pfn1->u3.e2.ReferenceCount = 0;

        PointerPte += 1;
    }
#endif

    //
    // Get a page for the working set list and zero it.
    //

    TempPte = ValidKernelPteLocal;
    PageFrameIndex = MiRemoveAnyPage (0);
    TempPte.u.Hard.PageFrameNumber = PageFrameIndex;

    PointerPte = MiGetPteAddress (MmWorkingSetList);
    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Note that when booted /3GB, MmWorkingSetList is not page aligned, so
    // always start zeroing from the start of the page regardless.
    //

    RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPte), PAGE_SIZE);

    CurrentProcess->WorkingSetPage = PageFrameIndex;

#if defined (_X86PAE_)
    MiPaeInitialize ();
#endif

    KeFlushCurrentTb();

    UNLOCK_PFN (OldIrql);

    CurrentProcess->Vm.MaximumWorkingSetSize = MmSystemProcessWorkingSetMax;
    CurrentProcess->Vm.MinimumWorkingSetSize = MmSystemProcessWorkingSetMin;

    MmInitializeProcessAddressSpace (CurrentProcess, NULL, NULL, NULL);

    //
    // Ensure the secondary page structures are marked as in use.
    //

    if (MmVirtualBias == 0) {

        ASSERT (MmFreePagesByColor[0] < (PMMCOLOR_TABLES)MM_SYSTEM_CACHE_END_EXTRA);

        PointerPde = MiGetPdeAddress(MmFreePagesByColor[0]);
        ASSERT (PointerPde->u.Hard.Valid == 1);

        PointerPte = MiGetPteAddress(MmFreePagesByColor[0]);
        ASSERT (PointerPte->u.Hard.Valid == 1);

        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE(PointerPte);
        Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

        LOCK_PFN (OldIrql);

        if (Pfn1->u3.e2.ReferenceCount == 0) {
            Pfn1->u4.PteFrame = MI_GET_PAGE_FRAME_FROM_PTE(PointerPde);
            Pfn1->PteAddress = PointerPte;
            Pfn1->u2.ShareCount += 1;
            Pfn1->u3.e2.ReferenceCount = 1;
            Pfn1->u3.e1.PageLocation = ActiveAndValid;
            Pfn1->u3.e1.CacheAttribute = MiCached;
            MiDetermineNode (PageFrameIndex, Pfn1);
        }
        UNLOCK_PFN (OldIrql);
    }
    else if ((((ULONG)MmFreePagesByColor[0] & (PAGE_SIZE - 1)) == 0) &&
        ((MmSecondaryColors * 2 * sizeof(MMCOLOR_TABLES)) < PAGE_SIZE)) {

        PMMCOLOR_TABLES c;

        c = MmFreePagesByColor[0];

        MmFreePagesByColor[0] = ExAllocatePoolWithTag (NonPagedPool,
                               MmSecondaryColors * 2 * sizeof(MMCOLOR_TABLES),
                               '  mM');

        if (MmFreePagesByColor[0] != NULL) {

            MmFreePagesByColor[1] = &MmFreePagesByColor[0][MmSecondaryColors];

            RtlCopyMemory (MmFreePagesByColor[0],
                           c,
                           MmSecondaryColors * 2 * sizeof(MMCOLOR_TABLES));

            //
            // Free the page.
            //

            PointerPte = MiGetPteAddress (c);
            PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

            ASSERT (c > (PMMCOLOR_TABLES)MM_SYSTEM_CACHE_END_EXTRA);
            MI_WRITE_INVALID_PTE (PointerPte, ZeroKernelPte);

            Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

            LOCK_PFN (OldIrql);

            ASSERT ((Pfn1->u2.ShareCount <= 1) && (Pfn1->u3.e2.ReferenceCount <= 1));
            Pfn1->u2.ShareCount = 0;
            Pfn1->u3.e2.ReferenceCount = 1;
            MI_SET_PFN_DELETED (Pfn1);
#if DBG
            Pfn1->u3.e1.PageLocation = StandbyPageList;
#endif
            MiDecrementReferenceCount (Pfn1, PageFrameIndex);

            UNLOCK_PFN (OldIrql);

            KeFlushSingleTb (c, FALSE);
        }
        else {
            MmFreePagesByColor[0] = c;
        }
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\i386\pae.asm ===
title  "pae"
;++
;
; Copyright (c) 1989, 2000  Microsoft Corporation
;
; Module Name:
;
;    pae.asm
;
; Abstract:
;
;    This module implements the code necessary to swap PTEs on a PAE system.
;
; Author:
;
;    Landy Wang (landyw)  15-Nov-1998
;
; Environment:
;
;    Kernel mode only.
;
; Revision History:
;
;--

.586p
        .xlist
include callconv.inc
FPOFRAME macro a, b
.FPO ( a, b, 0, 0, 0, 0 )
endm
        .list

_TEXT$00   SEGMENT PARA PUBLIC 'CODE'
        ASSUME  DS:FLAT, ES:FLAT, SS:NOTHING, FS:NOTHING, GS:NOTHING

        page , 132
        subttl "Interlocked Swap PTE"

;++
;
; VOID
; InterlockedExchangePte (
;     IN OUT PMMPTE Destination,
;     IN ULONGLONG Exchange
;     )
;
; Routine Description:
;
;     This function performs an interlocked swap of a PTE.  This is only needed
;     for the PAE architecture where the PTE width is larger than the register
;     width.
;
;     Both PTEs must be valid or a careful write would have been done instead.
;
; Arguments:
;
;     PtePointer - Address of PTE to update with new value.
;
;     NewPteContents - The new value to put in the PTE.
;
; Return Value:
;
;     None.
;
;--

cPublicProc _InterlockedExchangePte ,3

    push    ebx
    push    esi

    mov     ebx, [esp] + 16         ; ebx = NewPteContents lowpart
    mov     ecx, [esp] + 20         ; ebx = NewPteContents highpart

    mov     esi, [esp] + 12         ; esi = PtePointer

    mov     edx, [esi] + 4
    mov     eax, [esi]              ; edx:eax = target pte contents

swapagain:

    ;
    ; cmpxchg loads edx:eax with the new contents of the target quadword
    ; in the event of failure
    ;

    lock cmpxchg8b qword ptr [esi]  ; compare and exchange

    jnz     short swapagain         ; if z clear, exchange failed

    pop     esi
    pop     ebx

    stdRET   _InterlockedExchangePte
stdENDP _InterlockedExchangePte

_TEXT$00   ends

        end
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\i386\mipae.h ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    mipae.h

Abstract:

    This module contains the private data structures and procedure
    prototypes for the hardware dependent portion of the
    memory management system.

    This module is specifically tailored for the PAE x86,

Author:

    Landy Wang (landyw) 30-Nov-1998

Revision History:

--*/

#if defined(_X86PAE_)

/*++

    Virtual Memory Layout on the PAE x86 is:

                 +------------------------------------+
        00000000 |                                    |
                 |                                    |
                 |                                    |
                 | User Mode Addresses                |
                 |                                    |
                 |   All pages within this range      |
                 |   are potentially accessible while |
                 |   the CPU is in USER mode.         |
                 |                                    |
                 |                                    |
                 +------------------------------------+
        7ffff000 | 64k No Access Area                 |
                 +------------------------------------+
        80000000 |                                    |
                 | NTLDR loads the kernel, HAL and    |
                 | boot drivers here.  The kernel     |
                 | then relocates the drivers to the  |
                 | system PTE area.                   |
                 |                                    |
                 | Kernel mode access only.           |
                 |                                    |
                 | When possible, the PFN database &  |
                 | initial non paged pool is built    |
                 | here using large page mappings.    |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | Additional system PTEs, system     |
                 | cache or special pooling           |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | System mapped views.               |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | Session space.                     |
                 |                                    |
                 +------------------------------------+
        C0000000 | Page Table Pages mapped through    |
                 |   this 8mb region                  |
                 |   Kernel mode access only.         |
                 |                                    |
                 +------------------------------------+
        C0800000 | HyperSpace - working set lists     |
                 |  and per process memory management |
                 |  structures mapped in this 4mb     |
                 |  region.                           |
                 |  Kernel mode access only.          |
                 +------------------------------------+
                 | System Cache Structures            |
                 |   reside in this 4mb region        |
                 |   Kernel mode access only.         |
                 +------------------------------------+
       ~C1000000 | System cache resides in this area  |
                 | Note the exact address is computed |
                 | dynamically depending on whether   |
                 | the system was booted with /3GB or |
                 | other various options.             |
                 |   Kernel mode access only.         |
                 |                                    |
                 |                                    |
                 +------------------------------------+
        E1000000 | Start of paged system area         |
                 |   Kernel mode access only.         |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | System PTE area - for mapping      |
                 |   kernel thread stacks and MDLs    |
                 |   that require system VAs.         |
                 |   Kernel mode access only.         |
                 |                                    |
                 +------------------------------------+
                 |                                    |
                 | NonPaged System area               |
                 |   Kernel mode access only.         |
                 |                                    |
                 +------------------------------------+
        FFBE0000 | Crash Dump Driver area             |
                 |   Kernel mode access only.         |
                 +------------------------------------+
        FFC00000 | Last 4mb reserved for HAL usage    |
                 +------------------------------------+

--*/

#define _MI_PAGING_LEVELS 2

#define _MI_MORE_THAN_4GB_ 1

//
// Define empty list markers.
//

#define MM_EMPTY_LIST ((ULONG)0xFFFFFFFF) //
#define MM_EMPTY_PTE_LIST ((ULONG)0xFFFFFFFF) // N.B. tied to MMPTE definition

#define MI_PTE_BASE_FOR_LOWEST_KERNEL_ADDRESS (MiGetPteAddress (0x00000000))

#define MM_SESSION_SPACE_DEFAULT        (0xA0000000)
#define MM_SESSION_SPACE_DEFAULT_END    (0xC0000000)

extern ULONG_PTR MmBootImageSize;

//
// PAGE_SIZE for PAE x86 is 4k, virtual page is 20 bits with a PAGE_SHIFT
// byte offset.
//

#define MM_VIRTUAL_PAGE_FILLER 0
#define MM_VIRTUAL_PAGE_SIZE 20

//
// Address space layout definitions.
//

#define MM_KSEG0_BASE ((ULONG)0x80000000)

#define MM_KSEG2_BASE ((ULONG)0xA0000000)

#define MM_PAGES_IN_KSEG0 ((MM_KSEG2_BASE - MM_KSEG0_BASE) >> PAGE_SHIFT)

#define CODE_START MM_KSEG0_BASE

#define CODE_END   MM_KSEG2_BASE

#define MM_SYSTEM_SPACE_START ((ULONG_PTR)MmSystemCacheWorkingSetList)

#define MM_SYSTEM_SPACE_END (0xFFFFFFFF)

#define HYPER_SPACE ((PVOID)0xC0800000)

#define HYPER_SPACE2 ((PVOID)0xC0A00000)

extern PVOID MmHyperSpaceEnd;

#define MM_SYSTEM_VIEW_START (0xA0000000)

#define MM_SYSTEM_VIEW_SIZE (16*1024*1024)

#define MM_USER_ADDRESS_RANGE_LIMIT 0xFFFFFFFF // user address range limit
#define MM_MAXIMUM_ZERO_BITS 21         // maximum number of zero bits

//
// Define the start and maximum size for the system cache.
// Maximum size is normally 512MB, but can be up to 512MB + 448MB = 960MB for
// large system cache machines.
//

#define MM_SYSTEM_CACHE_WORKING_SET (0xC0E00000)

#define MM_SYSTEM_CACHE_START (0xC1200000)

#define MM_SYSTEM_CACHE_WORKING_SET_3GB_DELTA (0x400000)

#define MM_SYSTEM_CACHE_END (0xE1000000)
//
//
// Various resources like additional system PTEs or system cache views, etc,
// can be allocated out of this virtual address range.
//

extern ULONG MiExtraResourceStart;

extern ULONG MiExtraResourceEnd;

extern ULONG_PTR MiUseMaximumSystemSpace;

extern ULONG_PTR MiUseMaximumSystemSpaceEnd;

extern ULONG MiNumberOfExtraSystemPdes;

extern ULONG MiMaximumSystemExtraSystemPdes;

extern ULONG MiMaximumSystemCacheSizeExtra;

extern PVOID MiSystemCacheStartExtra;

extern PVOID MiSystemCacheEndExtra;

#define MM_SYSTEM_CACHE_END_EXTRA (0xC0000000)

#define MM_PAGED_POOL_START (MmPagedPoolStart)

#define MM_DEFAULT_PAGED_POOL_START (0xE1000000)

#define MM_LOWEST_NONPAGED_SYSTEM_START ((PVOID)(0xEB000000))

#define MmProtopte_Base ((ULONG)MmPagedPoolStart)

#define MM_NONPAGED_POOL_END ((PVOID)(0xFFBE0000))

#define MM_CRASH_DUMP_VA ((PVOID)(0xFFBE0000))

#define MM_DEBUG_VA  ((PVOID)0xFFBFF000)

#define NON_PAGED_SYSTEM_END   ((ULONG)0xFFFFFFF0)  //quadword aligned.

extern BOOLEAN MiWriteCombiningPtes;

LOGICAL
MiRecoverExtraPtes (
    VOID
    );

//
// Define absolute minimum and maximum count for system PTEs.
//

#define MM_MINIMUM_SYSTEM_PTES 7000

#define MM_MAXIMUM_SYSTEM_PTES 50000

#define MM_DEFAULT_SYSTEM_PTES 11000

//
// Pool limits
//

//
// The maximum amount of nonpaged pool that can be initially created.
//

#define MM_MAX_INITIAL_NONPAGED_POOL ((ULONG)(128*1024*1024))

//
// The total amount of nonpaged pool (initial pool + expansion).
//

#define MM_MAX_ADDITIONAL_NONPAGED_POOL ((ULONG)(128*1024*1024))

//
// The maximum amount of paged pool that can be created.
//

#define MM_MAX_PAGED_POOL ((ULONG)MM_NONPAGED_POOL_END - (ULONG)MM_PAGED_POOL_START)

#define MM_MAX_TOTAL_POOL (((ULONG)MM_NONPAGED_POOL_END) - ((ULONG)(MM_PAGED_POOL_START)))


//
// Structure layout definitions.
//

#define MM_PROTO_PTE_ALIGNMENT ((ULONG)PAGE_SIZE)

#define PAGE_DIRECTORY_MASK    ((ULONG)0x001FFFFF)

#define MM_VA_MAPPED_BY_PDE (0x200000)

#define MM_MINIMUM_VA_FOR_LARGE_PAGE MM_VA_MAPPED_BY_PDE

#define LOWEST_IO_ADDRESS 0xa0000

#define PTE_SHIFT 3

//
// The number of bits in a physical address.
//

#define PHYSICAL_ADDRESS_BITS 36

#define MM_MAXIMUM_NUMBER_OF_COLORS (1)

//
// x86 does not require support for colored pages.
//

#define MM_NUMBER_OF_COLORS (1)

//
// Mask for obtaining color from a physical page number.
//

#define MM_COLOR_MASK (0)

//
// Boundary for aligned pages of like color upon.
//

#define MM_COLOR_ALIGNMENT (0)

//
// Mask for isolating color from virtual address.
//

#define MM_COLOR_MASK_VIRTUAL (0)

//
//  Define 256k worth of secondary colors.
//

#define MM_SECONDARY_COLORS_DEFAULT (64)

#define MM_SECONDARY_COLORS_MIN (2)

#define MM_SECONDARY_COLORS_MAX (1024)

//
// Maximum number of paging files.
//

#define MAX_PAGE_FILES 16


//
// Hyper space definitions.
//

#define FIRST_MAPPING_PTE   ((ULONG)0xC0801000)

#define NUMBER_OF_MAPPING_PTES 126
#define LAST_MAPPING_PTE   \
     ((ULONG)((ULONG)FIRST_MAPPING_PTE + (NUMBER_OF_MAPPING_PTES * PAGE_SIZE)))

#define COMPRESSION_MAPPING_PTE   ((PMMPTE)((ULONG)LAST_MAPPING_PTE + PAGE_SIZE))

#define IMAGE_MAPPING_PTE   ((PMMPTE)((ULONG)COMPRESSION_MAPPING_PTE + PAGE_SIZE))

#define NUMBER_OF_ZEROING_PTES 256

//
// This bitmap consumes 4K when booted /2GB and 6K when booted /3GB, thus
// the working set list start is variable.
//

#define VAD_BITMAP_SPACE    ((PVOID)((ULONG)IMAGE_MAPPING_PTE + PAGE_SIZE))

#define WORKING_SET_LIST    MmWorkingSetList

#define MM_MAXIMUM_WORKING_SET MiMaximumWorkingSet

#define MmWsle ((PMMWSLE)((PUCHAR)WORKING_SET_LIST + sizeof(MMWSL)))

extern ULONG MiMaximumWorkingSet;


#define MM_WORKING_SET_END ((ULONG)0xC0BFF000)


//
// Define masks for fields within the PTE.
///

#define MM_PTE_VALID_MASK         0x1
#if defined(NT_UP)
#define MM_PTE_WRITE_MASK         0x2
#else
#define MM_PTE_WRITE_MASK         0x800
#endif
#define MM_PTE_OWNER_MASK         0x4
#define MM_PTE_WRITE_THROUGH_MASK 0x8
#define MM_PTE_CACHE_DISABLE_MASK 0x10
#define MM_PTE_ACCESS_MASK        0x20
#if defined(NT_UP)
#define MM_PTE_DIRTY_MASK         0x40
#else
#define MM_PTE_DIRTY_MASK         0x42
#endif
#define MM_PTE_LARGE_PAGE_MASK    0x80
#define MM_PTE_GLOBAL_MASK        0x100
#define MM_PTE_COPY_ON_WRITE_MASK 0x200
#define MM_PTE_PROTOTYPE_MASK     0x400
#define MM_PTE_TRANSITION_MASK    0x800

//
// Bit fields to or into PTE to make a PTE valid based on the
// protection field of the invalid PTE.
//

#define MM_PTE_NOACCESS          0x0   // not expressable on x86
#define MM_PTE_READONLY          0x0
#define MM_PTE_READWRITE         MM_PTE_WRITE_MASK
#define MM_PTE_WRITECOPY         0x200 // read-only copy on write bit set.
#define MM_PTE_EXECUTE           0x0   // read-only on x86
#define MM_PTE_EXECUTE_READ      0x0
#define MM_PTE_EXECUTE_READWRITE MM_PTE_WRITE_MASK
#define MM_PTE_EXECUTE_WRITECOPY 0x200 // read-only copy on write bit set.
#define MM_PTE_NOCACHE           0x010
#define MM_PTE_GUARD             0x0  // not expressable on x86
#define MM_PTE_CACHE             0x0

#define MM_PROTECT_FIELD_SHIFT 5

//
// Bits available for the software working set index within the hardware PTE.
//

#define MI_MAXIMUM_PTE_WORKING_SET_INDEX 0

//
// Zero PTE
//

#define MM_ZERO_PTE 0

//
// Zero Kernel PTE
//

#define MM_ZERO_KERNEL_PTE 0

//
// A demand zero PTE with a protection of PAGE_READWRITE.
//

#define MM_DEMAND_ZERO_WRITE_PTE ((ULONGLONG)MM_READWRITE << MM_PROTECT_FIELD_SHIFT)


//
// A demand zero PTE with a protection of PAGE_READWRITE for system space.
//

#define MM_KERNEL_DEMAND_ZERO_PTE ((ULONGLONG)MM_READWRITE << MM_PROTECT_FIELD_SHIFT)

//
// A no access PTE for system space.
//

#define MM_KERNEL_NOACCESS_PTE ((ULONGLONG)MM_NOACCESS << MM_PROTECT_FIELD_SHIFT)

//
// Kernel stack alignment requirements.
//

#define MM_STACK_ALIGNMENT 0x0

#define MM_STACK_OFFSET 0x0

//
// System process definitions
//

#define PDE_PER_PAGE ((ULONG)512)

#define PTE_PER_PAGE ((ULONG)512)

#define PD_PER_SYSTEM ((ULONG)4)

//
// Number of page table pages for user addresses.
//

#define MM_USER_PAGE_TABLE_PAGES (1536)

VOID
MiPaeInitialize (
    VOID
    );

//++
//VOID
//MI_MAKE_VALID_PTE (
//    OUT OUTPTE,
//    IN FRAME,
//    IN PMASK,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro makes a valid PTE from a page frame number, protection mask,
//    and owner.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the transition PTE.
//
//    FRAME - Supplies the page frame number for the PTE.
//
//    PMASK - Supplies the protection to set in the transition PTE.
//
//    PPTE - Supplies a pointer to the PTE which is being made valid.
//           For prototype PTEs NULL should be specified.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_VALID_PTE(OUTPTE,FRAME,PMASK,PPTE)                            \
       (OUTPTE).u.Long = (((ULONGLONG)FRAME << 12) |                          \
                         (MmProtectToPteMask[PMASK]) |                        \
                          MiDetermineUserGlobalPteMask ((PMMPTE)PPTE));       \
                         if (MmPaeMask != 0) {                                \
                            if (((PPTE) >= (PMMPTE)PDE_BASE) && ((PPTE) < (PMMPTE)PDE_TOP)) {  \
                               (OUTPTE).u.Long &= ~MmPaeMask; \
                            } \
                         }

//++
//VOID
//MI_MAKE_VALID_PTE_TRANSITION (
//    IN OUT OUTPTE
//    IN PROTECT
//    );
//
// Routine Description:
//
//    This macro takes a valid pte and turns it into a transition PTE.
//
// Arguments
//
//    OUTPTE - Supplies the current valid PTE.  This PTE is then
//             modified to become a transition PTE.
//
//    PROTECT - Supplies the protection to set in the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_VALID_PTE_TRANSITION(OUTPTE,PROTECT) \
                (OUTPTE).u.Soft.Transition = 1;           \
                (OUTPTE).u.Soft.Valid = 0;                \
                (OUTPTE).u.Soft.Prototype = 0;            \
                (OUTPTE).u.Soft.Protection = PROTECT;

//++
//VOID
//MI_MAKE_TRANSITION_PTE (
//    OUT OUTPTE,
//    IN PAGE,
//    IN PROTECT,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a valid pte and turns it into a transition PTE.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the transition PTE.
//
//    PAGE - Supplies the page frame number for the PTE.
//
//    PROTECT - Supplies the protection to set in the transition PTE.
//
//    PPTE - Supplies a pointer to the PTE, this is used to determine
//           the owner of the PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PTE(OUTPTE,PAGE,PROTECT,PPTE)   \
                (OUTPTE).u.Long = 0;                  \
                (OUTPTE).u.Trans.PageFrameNumber = PAGE;   \
                (OUTPTE).u.Trans.Transition = 1;           \
                (OUTPTE).u.Trans.Protection = PROTECT;     \
                (OUTPTE).u.Trans.Owner = MI_DETERMINE_OWNER(PPTE);


//++
//VOID
//MI_MAKE_TRANSITION_PTE_VALID (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a transition pte and makes it a valid PTE.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PTE_VALID(OUTPTE,PPTE)                             \
        ASSERT (((PPTE)->u.Hard.Valid == 0) &&                                \
                ((PPTE)->u.Trans.Prototype == 0) &&                           \
                ((PPTE)->u.Trans.Transition == 1));                           \
               (OUTPTE).u.Long = (((PPTE)->u.Long & ~0xFFF) |                 \
                         (MmProtectToPteMask[(PPTE)->u.Trans.Protection]) |   \
                          MiDetermineUserGlobalPteMask ((PMMPTE)PPTE));       \
                         if (MmPaeMask != 0) {                                \
                            if (((PPTE) >= (PMMPTE)PDE_BASE) && ((PPTE) < (PMMPTE)PDE_TOP)) {  \
                               (OUTPTE).u.Long &= ~MmPaeMask; \
                            } \
                         }

//++
//VOID
//MI_MAKE_TRANSITION_PROTOPTE_VALID (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a transition prototype PTE (in paged pool) and
//    makes it a valid PTE.  Because we know this is a prototype PTE and
//    not a pagetable PTE, this can directly or in the global bit.  This
//    makes a measurable performance gain since every instruction counts
//    when holding the PFN lock.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PROTOPTE_VALID(OUTPTE,PPTE)                        \
        ASSERT (((PPTE)->u.Hard.Valid == 0) &&                                \
                ((PPTE)->u.Trans.Prototype == 0) &&                           \
                ((PPTE)->u.Trans.Transition == 1));                           \
               (OUTPTE).u.Long = (((PPTE)->u.Long & ~0xFFF) |                 \
                         (MmProtectToPteMask[(PPTE)->u.Trans.Protection]) |   \
                         (MmPteGlobal.u.Long));                               \
               (OUTPTE).u.Hard.Valid = 1;                                     \
               (OUTPTE).u.Hard.Accessed = 1;

#define MI_FAULT_STATUS_INDICATES_EXECUTION(_FaultStatus)   (_FaultStatus & MmPaeErrMask)

#define MI_FAULT_STATUS_INDICATES_WRITE(_FaultStatus)   (_FaultStatus & 0x1)

#define MI_CLEAR_FAULT_STATUS(_FaultStatus)             (_FaultStatus = 0)

#define MI_IS_PTE_EXECUTABLE(_TempPte) (((_TempPte)->u.Long & MmPaeMask) == 0)

//++
//VOID
//MI_SET_PTE_IN_WORKING_SET (
//    OUT PMMPTE PTE,
//    IN ULONG WSINDEX
//    );
//
// Routine Description:
//
//    This macro inserts the specified working set index into the argument PTE.
//    Since the x86 PTE has no free bits in the valid PTE, nothing needs to
//    be done on this architecture.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to insert the working set index.
//
//    WSINDEX - Supplies the working set index for the PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_IN_WORKING_SET(PTE, WSINDEX)

//++
//ULONG WsIndex
//MI_GET_WORKING_SET_FROM_PTE(
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro returns the working set index from the argument PTE.
//    Since the x86 PTE has no free bits in the valid PTE, nothing needs to
//    be done on this architecture.
//
// Arguments
//
//    PTE - Supplies the PTE to extract the working set index from.
//
// Return Value:
//
//    This macro returns the working set index for the argument PTE.
//
//--

#define MI_GET_WORKING_SET_FROM_PTE(PTE)  0

//++
//VOID
//MI_SET_PTE_WRITE_COMBINE (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and enables WriteCombining as the
//    caching state.  Note that the PTE bits may only be set this way
//    if the Page Attribute Table is present and the PAT has been
//    initialized to provide Write Combining.
//
//    If either of the above conditions is not satisfied, then
//    the macro enables WEAK UC (PCD = 1, PWT = 0) in the PTE.
//
// Arguments
//
//    PTE - Supplies a valid PTE.
//
// Return Value:
//
//     None.
//
//--
//

#define MI_SET_PTE_WRITE_COMBINE(PTE) \
            {                                                               \
                if (MiWriteCombiningPtes == TRUE) {                         \
                    ((PTE).u.Hard.CacheDisable = 0);                        \
                    ((PTE).u.Hard.WriteThrough = 1);                        \
                } else {                                                    \
                    ((PTE).u.Hard.CacheDisable = 1);                        \
                    ((PTE).u.Hard.WriteThrough = 0);                        \
                }                                                           \
            }

#define MI_SET_LARGE_PTE_WRITE_COMBINE(PTE) MI_SET_PTE_WRITE_COMBINE(PTE)

//++
//VOID
//MI_PREPARE_FOR_NONCACHED (
//    IN MI_PFN_CACHE_ATTRIBUTE CacheAttribute
//    );
//
// Routine Description:
//
//    This macro prepares the system prior to noncached PTEs being created.
//
//    Note the entire TB must be flushed on all processors because there may
//    be stale system PTE (or hyperspace or zeropage) mappings in the TB which
//    may refer to the same physical page but with a different cache attribute.
//
// Arguments
//
//    CacheAttribute - Supplies the cache attribute the PTEs will be filled
//                     with.
//
// Return Value:
//
//     None.
//
//--
#define MI_PREPARE_FOR_NONCACHED(_CacheAttribute)                           \
        if (_CacheAttribute != MiCached) {                                  \
            KeFlushEntireTb (FALSE, TRUE);                                  \
            KeInvalidateAllCaches ();                                       \
        }

//++
//VOID
//MI_SWEEP_CACHE (
//    IN MI_PFN_CACHE_ATTRIBUTE CacheAttribute,
//    IN PVOID StartVa,
//    IN ULONG NumberOfBytes
//    );
//
// Routine Description:
//
//    This macro prepares the system prior to noncached PTEs being created.
//    This does nothing on x86.
//
// Arguments
//
//    CacheAttribute - Supplies the cache attribute the PTEs were filled with.
//
//    StartVa - Supplies the starting address that's been mapped.
//
//    NumberOfBytes - Supplies the number of bytes that have been mapped.
//
// Return Value:
//
//     None.
//
//--
#define MI_SWEEP_CACHE(_CacheType,_StartVa,_NumberOfBytes)

//++
//VOID
//MI_SET_PTE_DIRTY (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro sets the dirty bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to set dirty.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_DIRTY(PTE) (PTE).u.Long |= HARDWARE_PTE_DIRTY_MASK


//++
//VOID
//MI_SET_PTE_CLEAN (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro clears the dirty bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to set clear.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_CLEAN(PTE) (PTE).u.Long &= ~HARDWARE_PTE_DIRTY_MASK



//++
//VOID
//MI_IS_PTE_DIRTY (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro checks the dirty bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if the page is dirty (modified), FALSE otherwise.
//
//--

#define MI_IS_PTE_DIRTY(PTE) ((PTE).u.Hard.Dirty != 0)



//++
//VOID
//MI_SET_GLOBAL_BIT_IF_SYSTEM (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro sets the global bit if the pointer PTE is within
//    system space.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the PTE becoming valid.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_GLOBAL_BIT_IF_SYSTEM(OUTPTE,PPTE)                             \
   if ((((PMMPTE)PPTE) > MiHighestUserPte) &&                                \
       ((((PMMPTE)PPTE) <= MiGetPteAddress (PTE_BASE)) ||                    \
       (((PMMPTE)PPTE) >= MmSystemCacheWorkingSetListPte))) {                \
           (OUTPTE).u.Long |= MmPteGlobal.u.Long;                            \
   }                                                                         \
   else {                                                                    \
           (OUTPTE).u.Long &= ~MmPteGlobal.u.Long;                           \
   }


//++
//VOID
//MI_SET_GLOBAL_STATE (
//    IN MMPTE PTE,
//    IN ULONG STATE
//    );
//
// Routine Description:
//
//    This macro sets the global bit in the PTE based on the state argument.
//
// Arguments
//
//    PTE - Supplies the PTE to set global state into.
//
//    STATE - Supplies 1 if global, 0 if not.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_GLOBAL_STATE(PTE,STATE)                              \
           if (STATE) {                                             \
               (PTE).u.Long |= MmPteGlobal.u.Long;                  \
           }                                                        \
           else {                                                   \
               (PTE).u.Long &= ~MmPteGlobal.u.Long;                 \
           }





//++
//VOID
//MI_ENABLE_CACHING (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and sets the caching state to be
//    enabled.  This is performed by clearing the PCD and PWT bits in the PTE.
//
//    Semantics of the overlap between PCD, PWT, and the
//    USWC memory type in the MTRR are:
//
//    PCD   PWT   Mtrr Mem Type      Effective Memory Type
//     1     0    USWC               USWC
//     1     1    USWC               UC
//
// Arguments
//
//    PTE - Supplies a valid PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_ENABLE_CACHING(PTE) \
            {                                                                \
                ((PTE).u.Hard.CacheDisable = 0);                             \
                ((PTE).u.Hard.WriteThrough = 0);                             \
            }



//++
//VOID
//MI_DISABLE_CACHING (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and sets the caching state to be
//    disabled.  This is performed by setting the PCD and PWT bits in the PTE.
//
//    Semantics of the overlap between PCD, PWT, and the
//    USWC memory type in the MTRR are:
//
//    PCD   PWT   Mtrr Mem Type      Effective Memory Type
//     1     0    USWC               USWC
//     1     1    USWC               UC
//
//    Since an effective memory type of UC is desired here,
//    the WT bit is set.
//
// Arguments
//
//    PTE - Supplies a pointer to the valid PTE.
//
// Return Value:
//
//     None.
//
//--


#define MI_DISABLE_CACHING(PTE) \
            {                                                                \
                ((PTE).u.Hard.CacheDisable = 1);                             \
                ((PTE).u.Hard.WriteThrough = 1);                             \
            }

#define MI_DISABLE_LARGE_PTE_CACHING(PTE) MI_DISABLE_CACHING(PTE)



//++
//BOOLEAN
//MI_IS_CACHING_DISABLED (
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and returns TRUE if caching is
//    disabled.
//
// Arguments
//
//    PPTE - Supplies a pointer to the valid PTE.
//
// Return Value:
//
//     TRUE if caching is disabled, FALSE if it is enabled.
//
//--

#define MI_IS_CACHING_DISABLED(PPTE)   \
            ((PPTE)->u.Hard.CacheDisable == 1)



//++
//VOID
//MI_SET_PFN_DELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a PFN element and indicates that
//    the PFN is no longer in use.
//
// Arguments
//
//    PPFN - Supplies a pointer to the PFN element.
//
// Return Value:
//
//    none.
//
//--

#define MI_SET_PFN_DELETED(PPFN) \
    PPFN->PteAddress = (PMMPTE)(((ULONG_PTR)(PPFN->PteAddress)) | 0x1);


//++
//VOID
//MI_MARK_PFN_UNDELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a deleted PFN element and mark that
//    the PFN is not deleted.
//
// Arguments
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//    none.
//
//--

#define MI_MARK_PFN_UNDELETED(PPFN) \
    PPFN->PteAddress = (PMMPTE)((ULONG_PTR)PPFN->PteAddress & ~0x1);



//++
//BOOLEAN
//MI_IS_PFN_DELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a PFN element and determines if
//    the PFN is no longer in use.
//
// Arguments
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//    TRUE if PFN is no longer used, FALSE if it is still being used.
//
//--

#define MI_IS_PFN_DELETED(PPFN)   \
            ((ULONG_PTR)(PPFN)->PteAddress & 0x1)


//++
//VOID
//MI_CHECK_PAGE_ALIGNMENT (
//    IN ULONG PAGE,
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro takes a PFN element number (Page) and checks to see
//    if the virtual alignment for the previous address of the page
//    is compatible with the new address of the page.  If they are
//    not compatible, the D cache is flushed.
//
// Arguments
//
//    PAGE - Supplies the PFN element.
//    PPTE - Supplies a pointer to the new PTE which will contain the page.
//
// Return Value:
//
//    none.
//
//--

// does nothing on x86.

#define MI_CHECK_PAGE_ALIGNMENT(PAGE,PPTE)


//++
//VOID
//MI_INITIALIZE_HYPERSPACE_MAP (
//    VOID
//    );
//
// Routine Description:
//
//    This macro initializes the PTEs reserved for double mapping within
//    hyperspace.
//
// Arguments
//
//    None.
//
// Return Value:
//
//    None.
//
//--

// does nothing on x86.

#define MI_INITIALIZE_HYPERSPACE_MAP(INDEX)


//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_PTE (
//    IN PMMPTE PTEADDRESS
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    PTEADDRESS - Supplies the PTE address the page is (or was) mapped at.
//
// Return Value:
//
//    The page's color.
//
//--

#define MI_GET_PAGE_COLOR_FROM_PTE(PTEADDRESS)  \
         ((ULONG)((MI_SYSTEM_PAGE_COLOR++) & MmSecondaryColorMask) | MI_CURRENT_NODE_COLOR)



//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_VA (
//    IN PVOID ADDRESS
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    ADDRESS - Supplies the address the page is (or was) mapped at.
//
// Return Value:
//
//    The page's color.
//
//--


#define MI_GET_PAGE_COLOR_FROM_VA(ADDRESS)  \
         ((ULONG)((MI_SYSTEM_PAGE_COLOR++) & MmSecondaryColorMask) | MI_CURRENT_NODE_COLOR)

//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_SESSION (
//    IN PMM_SESSION_SPACE SessionSpace
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    SessionSpace - Supplies the session space the page will be mapped into.
//
// Return Value:
//
//    The page's color.
//
//--


#define MI_GET_PAGE_COLOR_FROM_SESSION(_SessionSpace)  \
         ((ULONG)((_SessionSpace->Color++) & MmSecondaryColorMask) | MI_CURRENT_NODE_COLOR)



//++
//ULONG
//MI_PAGE_COLOR_PTE_PROCESS (
//    IN PMMPTE PTE,
//    IN PUSHORT COLOR
//    );
//
// Routine Description:
//
//    Select page color for this process.
//
// Arguments
//
//   PTE    Not used.
//   COLOR  Value from which color is determined.   This
//          variable is incremented.
//
// Return Value:
//
//    Page color.
//
//--


#define MI_PAGE_COLOR_PTE_PROCESS(PTE,COLOR)  \
         (((ULONG)((*(COLOR))++) & MmSecondaryColorMask) | MI_CURRENT_NODE_COLOR)


//++
//ULONG
//MI_PAGE_COLOR_VA_PROCESS (
//    IN PVOID ADDRESS,
//    IN PEPROCESS COLOR
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    ADDRESS - Supplies the address the page is (or was) mapped at.
//
// Return Value:
//
//    The page's color.
//
//--

#define MI_PAGE_COLOR_VA_PROCESS(ADDRESS,COLOR) \
         (((ULONG)((*(COLOR))++) & MmSecondaryColorMask) | MI_CURRENT_NODE_COLOR)



//++
//ULONG
//MI_GET_NEXT_COLOR (
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the next color in the sequence.
//
// Arguments
//
//    COLOR - Supplies the color to return the next of.
//
// Return Value:
//
//    Next color in sequence.
//
//--

#define MI_GET_NEXT_COLOR(COLOR)  ((COLOR + 1) & MM_COLOR_MASK)


//++
//ULONG
//MI_GET_PREVIOUS_COLOR (
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the previous color in the sequence.
//
// Arguments
//
//    COLOR - Supplies the color to return the previous of.
//
// Return Value:
//
//    Previous color in sequence.
//
//--

#define MI_GET_PREVIOUS_COLOR(COLOR)  (0)

#define MI_GET_SECONDARY_COLOR(PAGE,PFN) (PAGE & MmSecondaryColorMask)

#define MI_GET_COLOR_FROM_SECONDARY(SECONDARY_COLOR) (0)


//++
//VOID
//MI_GET_MODIFIED_PAGE_BY_COLOR (
//    OUT ULONG PAGE,
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the first page destined for a paging
//    file with the desired color.  It does NOT remove the page
//    from its list.
//
// Arguments
//
//    PAGE - Returns the page located, the value MM_EMPTY_LIST is
//           returned if there is no page of the specified color.
//
//    COLOR - Supplies the color of page to locate.
//
// Return Value:
//
//    none.
//
//--

#define MI_GET_MODIFIED_PAGE_BY_COLOR(PAGE,COLOR) \
            PAGE = MmModifiedPageListByColor[COLOR].Flink


//++
//VOID
//MI_GET_MODIFIED_PAGE_ANY_COLOR (
//    OUT ULONG PAGE,
//    IN OUT ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the first page destined for a paging
//    file with the desired color.  If not page of the desired
//    color exists, all colored lists are searched for a page.
//    It does NOT remove the page from its list.
//
// Arguments
//
//    PAGE - Returns the page located, the value MM_EMPTY_LIST is
//           returned if there is no page of the specified color.
//
//    COLOR - Supplies the color of page to locate and returns the
//            color of the page located.
//
// Return Value:
//
//    none.
//
//--

#define MI_GET_MODIFIED_PAGE_ANY_COLOR(PAGE,COLOR) \
            {                                                                \
                if (MmTotalPagesForPagingFile == 0) {                        \
                    PAGE = MM_EMPTY_LIST;                                    \
                } else {                                                     \
                    PAGE = MmModifiedPageListByColor[COLOR].Flink;           \
                }                                                            \
            }



//++
//VOID
//MI_MAKE_VALID_PTE_WRITE_COPY (
//    IN OUT PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro checks to see if the PTE indicates that the
//    page is writable and if so it clears the write bit and
//    sets the copy-on-write bit.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     None.
//
//--

#if defined(NT_UP)
#define MI_MAKE_VALID_PTE_WRITE_COPY(PPTE) \
                    if ((PPTE)->u.Hard.Write == 1) {    \
                        (PPTE)->u.Hard.CopyOnWrite = 1; \
                        (PPTE)->u.Hard.Write = 0;       \
                    }
#else
#define MI_MAKE_VALID_PTE_WRITE_COPY(PPTE) \
                    if ((PPTE)->u.Hard.Write == 1) {    \
                        (PPTE)->u.Hard.CopyOnWrite = 1; \
                        (PPTE)->u.Hard.Write = 0;       \
                        (PPTE)->u.Hard.Writable = 0;    \
                    }
#endif


#define MI_PTE_OWNER_USER       1

#define MI_PTE_OWNER_KERNEL     0


//++
//ULONG
//MI_DETERMINE_OWNER (
//    IN MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro examines the virtual address of the PTE and determines
//    if the PTE resides in system space or user space.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     1 if the owner is USER_MODE, 0 if the owner is KERNEL_MODE.
//
//--

#define MI_DETERMINE_OWNER(PPTE)   \
    ((((PPTE) <= MiHighestUserPte) ||                                       \
      ((PPTE) >= MiGetPdeAddress(NULL) &&                                   \
      ((PPTE) <= MiHighestUserPde))) ? MI_PTE_OWNER_USER : MI_PTE_OWNER_KERNEL)



//++
//VOID
//MI_SET_ACCESSED_IN_PTE (
//    IN OUT MMPTE PPTE,
//    IN ULONG ACCESSED
//    );
//
// Routine Description:
//
//    This macro sets the ACCESSED field in the PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     None
//
//--

#define MI_SET_ACCESSED_IN_PTE(PPTE,ACCESSED) \
                    ((PPTE)->u.Hard.Accessed = ACCESSED)

//++
//ULONG
//MI_GET_ACCESSED_IN_PTE (
//    IN OUT MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro returns the state of the ACCESSED field in the PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     The state of the ACCESSED field.
//
//--

#define MI_GET_ACCESSED_IN_PTE(PPTE) ((PPTE)->u.Hard.Accessed)


//++
//VOID
//MI_SET_OWNER_IN_PTE (
//    IN PMMPTE PPTE
//    IN ULONG OWNER
//    );
//
// Routine Description:
//
//    This macro sets the owner field in the PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_OWNER_IN_PTE(PPTE,OWNER) ((PPTE)->u.Hard.Owner = OWNER)


//
// bit mask to clear out fields in a PTE to or in paging file location.
//

#define CLEAR_FOR_PAGE_FILE 0x000003E0


//++
//VOID
//MI_SET_PAGING_FILE_INFO (
//    OUT MMPTE OUTPTE,
//    IN MMPTE PPTE,
//    IN ULONG FILEINFO,
//    IN ULONG OFFSET
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to store the result.
//
//    PTE - Supplies the PTE to operate upon.
//
//    FILEINFO - Supplies the number of the paging file.
//
//    OFFSET - Supplies the offset into the paging file.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_PAGING_FILE_INFO(OUTPTE,PPTE,FILEINFO,OFFSET)        \
       (OUTPTE).u.Long = (PPTE).u.Long;                             \
       (OUTPTE).u.Long &= CLEAR_FOR_PAGE_FILE;                      \
       (OUTPTE).u.Long |= ((ULONGLONG)FILEINFO << 1);               \
       (OUTPTE).u.Soft.PageFileHigh = (OFFSET);


//++
//PMMPTE
//MiPteToProto (
//    IN OUT MMPTE PPTE,
//    IN ULONG FILEINFO,
//    IN ULONG OFFSET
//    );
//
// Routine Description:
//
//   This macro returns the address of the corresponding prototype which
//   was encoded earlier into the supplied PTE.
//
// Arguments
//
//    lpte - Supplies the PTE to operate upon.
//
// Return Value:
//
//    Pointer to the prototype PTE that backs this PTE.
//
//--


#define MiPteToProto(lpte) \
            ((PMMPTE)(ULONG_PTR)((lpte)->u.Proto.ProtoAddress))


//++
//MMPTE
//MiProtoAddressForPte (
//    IN PMMPTE proto_va
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//    MiProtoAddressForPte returns the bit field to OR into the PTE to
//    reference a prototype PTE.  And set the protoPTE bit,
//
//    N.B. This macro is dependent on the layout of the prototype PTE.
//
// Arguments
//
//    proto_va - Supplies the address of the prototype PTE.
//
// Return Value:
//
//    Mask to set into the PTE.
//
//--

#define MiProtoAddressForPte(proto_va)  \
    (((ULONGLONG)proto_va << 32) | MM_PTE_PROTOTYPE_MASK)


//++
//ULONG
//MiProtoAddressForKernelPte (
//    IN PMMPTE proto_va
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//    MiProtoAddressForPte returns the bit field to OR into the PTE to
//    reference a prototype PTE.  And set the protoPTE bit,
//    MM_PTE_PROTOTYPE_MASK.
//
//    This macro also sets any other information (such as global bits)
//    required for kernel mode PTEs.
//
// Arguments
//
//    proto_va - Supplies the address of the prototype PTE.
//
// Return Value:
//
//    Mask to set into the PTE.
//
//--

//  not different on x86.

#define MiProtoAddressForKernelPte(proto_va)  MiProtoAddressForPte(proto_va)


//++
//PSUBSECTION
//MiGetSubsectionAddress (
//    IN PMMPTE lpte
//    );
//
// Routine Description:
//
//   This macro takes a PTE and returns the address of the subsection that
//   the PTE refers to.  Subsections are quadword structures allocated
//   from nonpaged pool.
//
// Arguments
//
//    lpte - Supplies the PTE to operate upon.
//
// Return Value:
//
//    A pointer to the subsection referred to by the supplied PTE.
//
//--

#define MiGetSubsectionAddress(lpte)                              \
    ((PSUBSECTION)(ULONG_PTR)((lpte)->u.Subsect.SubsectionAddress))



//++
//ULONG
//MiGetSubsectionAddressForPte (
//    IN PSUBSECTION VA
//    );
//
// Routine Description:
//
//    This macro takes the address of a subsection and encodes it for use
//    in a PTE.
//
// Arguments
//
//    VA - Supplies a pointer to the subsection to encode.
//
// Return Value:
//
//     The mask to set into the PTE to make it reference the supplied
//     subsection.
//
//--

#define MiGetSubsectionAddressForPte(VA) ((ULONGLONG)VA << 32)


//++
//PMMPTE
//MiGetPdeAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeAddress returns the address of the PDE which maps the
//    given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the PDE for.
//
// Return Value:
//
//    The address of the PDE.
//
//--

#define MiGetPdeAddress(va)   ((PMMPTE)(PDE_BASE + ((((ULONG)(va)) >> 21) << 3)))


//++
//PMMPTE
//MiGetPteAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPteAddress returns the address of the PTE which maps the
//    given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the PTE for.
//
// Return Value:
//
//    The address of the PTE.
//
//--

#define MiGetPteAddress(va)   ((PMMPTE)(PTE_BASE + ((((ULONG)(va)) >> 12) << 3)))


//++
//ULONG
//MiGetPpeOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPpeOffset returns the offset into a page root
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page root table the corresponding PPE is at.
//
//--

#define MiGetPpeOffset(va) (0)

//++
//ULONG
//MiGetPdPteOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdPteOffset returns the offset into a page directory
//    pointer PTE table for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page directory pointer PTE table the corresponding
//    PDE is at.
//
//--

#define MiGetPdPteOffset(va) (((ULONG)(va)) >> 30)

//++
//ULONG
//MiGetPdeOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeOffset returns the offset into a page directory
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page directory table the corresponding PDE is at.
//
//--

#define MiGetPdeOffset(va) ((((ULONG)(va)) >> 21) & 0x1FF)

//++
//ULONG
//MiGetPdeIndex (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeIndex returns the page directory index
//    for a given virtual address.
//
//    N.B. This does not mask off PPE bits.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The index into the page directory - ie: the virtual page table number.
//    This is different from the page directory offset because this spans
//    page directories on supported platforms.
//
//--

#define MiGetPdeIndex(va) (((ULONG)(va)) >> 21)

//++
//ULONG
//MiGetPteOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPteOffset returns the offset into a page table page
//    for a given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page table page table the corresponding PTE is at.
//
//--

#define MiGetPteOffset(va) ((((ULONG)(va)) << 11) >> 23)



//++
//PVOID
//MiGetVirtualAddressMappedByPpe (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPpe returns the virtual address
//    which is mapped by a given PPE address.
//
// Arguments
//
//    PPE - Supplies the PPE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PPE.
//
//--

#define MiGetVirtualAddressMappedByPpe(PPE) (NULL)

//++
//PVOID
//MiGetVirtualAddressMappedByPde (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPde returns the virtual address
//    which is mapped by a given PDE address.
//
// Arguments
//
//    PDE - Supplies the PDE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PDE.
//
//--

#define MiGetVirtualAddressMappedByPde(PDE) ((PVOID)((ULONG)(PDE) << 18))


//++
//PVOID
//MiGetVirtualAddressMappedByPte (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPte returns the virtual address
//    which is mapped by a given PTE address.
//
// Arguments
//
//    PTE - Supplies the PTE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PTE.
//
//--

#define MiGetVirtualAddressMappedByPte(PTE) ((PVOID)((ULONG)(PTE) << 9))


//++
//LOGICAL
//MiIsVirtualAddressOnPpeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsVirtualAddressOnPpeBoundary returns TRUE if the virtual address is
//    on a page directory entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on a boundary, FALSE if not.
//
//--

#define MiIsVirtualAddressOnPpeBoundary(VA) (FALSE)


//++
//LOGICAL
//MiIsVirtualAddressOnPdeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsVirtualAddressOnPdeBoundary returns TRUE if the virtual address is
//    on a page directory entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on a 4MB PDE boundary, FALSE if not.
//
//--

#define MiIsVirtualAddressOnPdeBoundary(VA) (((ULONG_PTR)(VA) & PAGE_DIRECTORY_MASK) == 0)

//++
//LOGICAL
//MiIsPteOnPdeBoundary (
//    IN PVOID PTE
//    );
//
// Routine Description:
//
//    MiIsPteOnPdeBoundary returns TRUE if the PTE is
//    on a page directory entry boundary.
//
// Arguments
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if on a 4MB PDE boundary, FALSE if not.
//
//--

#define MiIsPteOnPdeBoundary(PTE) (((ULONG_PTR)(PTE) & (PAGE_SIZE - 1)) == 0)


//++
//ULONG
//GET_PAGING_FILE_NUMBER (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro extracts the paging file number from a PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    The paging file number.
//
//--

#define GET_PAGING_FILE_NUMBER(PTE) ((ULONG)((((PTE).u.Long) >> 1) & 0x0000000F))



//++
//ULONG
//GET_PAGING_FILE_OFFSET (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro extracts the offset into the paging file from a PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    The paging file offset.
//
//--

#define GET_PAGING_FILE_OFFSET(PTE) ((ULONG)((PTE).u.Soft.PageFileHigh))




//++
//ULONG
//IS_PTE_NOT_DEMAND_ZERO (
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro checks to see if a given PTE is NOT a demand zero PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     Returns 0 if the PTE is demand zero, non-zero otherwise.
//
//--

#define IS_PTE_NOT_DEMAND_ZERO(PTE) ((PTE).u.Long & ~0x3FE)


//++
//VOID
//MI_MAKING_VALID_PTE_INVALID(
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    Prepare to make a single valid PTE invalid.
//    No action is required on x86.
//
// Arguments
//
//    SYSTEM_WIDE - Supplies TRUE if this will happen on all processors.
//
// Return Value:
//
//    None.
//
//--

#define MI_MAKING_VALID_PTE_INVALID(SYSTEM_WIDE)


//++
//VOID
//MI_MAKING_VALID_MULTIPLE_PTES_INVALID(
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    Prepare to make multiple valid PTEs invalid.
//    No action is required on x86.
//
// Arguments
//
//    SYSTEM_WIDE - Supplies TRUE if this will happen on all processors.
//
// Return Value:
//
//    None.
//
//--

#define MI_MAKING_MULTIPLE_PTES_INVALID(SYSTEM_WIDE)



//++
//VOID
//MI_MAKE_PROTECT_WRITE_COPY (
//    IN OUT MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro makes a writable PTE a writable-copy PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    NONE
//
//--

#define MI_MAKE_PROTECT_WRITE_COPY(PTE) \
        if ((PTE).u.Soft.Protection & MM_PROTECTION_WRITE_MASK) {      \
            (PTE).u.Long |= (ULONGLONG)MM_PROTECTION_COPY_MASK << MM_PROTECT_FIELD_SHIFT;      \
        }


//++
//VOID
//MI_SET_PAGE_DIRTY(
//    IN PMMPTE PPTE,
//    IN PVOID VA,
//    IN PVOID PFNHELD
//    );
//
// Routine Description:
//
//    This macro sets the dirty bit (and release page file space).
//
// Arguments
//
//    PPTE - Supplies a pointer to the PTE that corresponds to VA.
//
//    VA - Supplies a the virtual address of the page fault.
//
//    PFNHELD - Supplies TRUE if the PFN lock is held.
//
// Return Value:
//
//    None.
//
//--

#if defined(NT_UP)
#define MI_SET_PAGE_DIRTY(PPTE,VA,PFNHELD)
#else
#define MI_SET_PAGE_DIRTY(PPTE,VA,PFNHELD)                          \
            if ((PPTE)->u.Hard.Dirty == 1) {                        \
                MiSetDirtyBit ((VA),(PPTE),(PFNHELD));              \
            }
#endif




//++
//VOID
//MI_NO_FAULT_FOUND(
//    IN FAULTSTATUS,
//    IN PMMPTE PPTE,
//    IN PVOID VA,
//    IN PVOID PFNHELD
//    );
//
// Routine Description:
//
//    This macro handles the case when a page fault is taken and no
//    PTE with the valid bit clear is found.
//
// Arguments
//
//    FAULTSTATUS - Supplies the fault status.
//
//    PPTE - Supplies a pointer to the PTE that corresponds to VA.
//
//    VA - Supplies a the virtual address of the page fault.
//
//    PFNHELD - Supplies TRUE if the PFN lock is held.
//
// Return Value:
//
//    None.
//
//--

#if defined(NT_UP)
#define MI_NO_FAULT_FOUND(FAULTSTATUS,PPTE,VA,PFNHELD)
#else
#define MI_NO_FAULT_FOUND(FAULTSTATUS,PPTE,VA,PFNHELD) \
        if ((MI_FAULT_STATUS_INDICATES_WRITE(FAULTSTATUS)) && ((PPTE)->u.Hard.Dirty == 0)) {  \
            MiSetDirtyBit ((VA),(PPTE),(PFNHELD));     \
        }
#endif




//++
//ULONG
//MI_CAPTURE_DIRTY_BIT_TO_PFN (
//    IN PMMPTE PPTE,
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro gets captures the state of the dirty bit to the PFN
//    and frees any associated page file space if the PTE has been
//    modified element.
//
//    NOTE - THE PFN LOCK MUST BE HELD!
//
// Arguments
//
//    PPTE - Supplies the PTE to operate upon.
//
//    PPFN - Supplies a pointer to the PFN database element that corresponds
//           to the page mapped by the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_CAPTURE_DIRTY_BIT_TO_PFN(PPTE,PPFN)                      \
         ASSERT (KeGetCurrentIrql() > APC_LEVEL);                   \
         if (((PPFN)->u3.e1.Modified == 0) &&                       \
            ((PPTE)->u.Hard.Dirty != 0)) {                          \
             MI_SET_MODIFIED (PPFN, 1, 0x18);                       \
             if (((PPFN)->OriginalPte.u.Soft.Prototype == 0) &&     \
                          ((PPFN)->u3.e1.WriteInProgress == 0)) {   \
                 MiReleasePageFileSpace ((PPFN)->OriginalPte);      \
                 (PPFN)->OriginalPte.u.Soft.PageFileHigh = 0;       \
             }                                                      \
         }


//++
//BOOLEAN
//MI_IS_PHYSICAL_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    physical address.
//
// Arguments
//
//    VA - Supplies the virtual address.
//
// Return Value:
//
//    FALSE if it is not a physical address, TRUE if it is.
//
//--


#define MI_IS_PHYSICAL_ADDRESS(Va) \
    ((MiGetPdeAddress(Va)->u.Long & 0x81) == 0x81)


//++
//ULONG
//MI_CONVERT_PHYSICAL_TO_PFN (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro converts a physical address (see MI_IS_PHYSICAL_ADDRESS)
//    to its corresponding physical frame number.
//
// Arguments
//
//    VA - Supplies a pointer to the physical address.
//
// Return Value:
//
//    Returns the PFN for the page.
//
//--


#define MI_CONVERT_PHYSICAL_TO_PFN(Va)     \
    ((PFN_NUMBER)(MiGetPdeAddress(Va)->u.Hard.PageFrameNumber) + (MiGetPteOffset((ULONG)Va)))


typedef struct _MMCOLOR_TABLES {
    PFN_NUMBER Flink;
    PVOID Blink;
    PFN_NUMBER Count;
} MMCOLOR_TABLES, *PMMCOLOR_TABLES;

extern PMMCOLOR_TABLES MmFreePagesByColor[2];

extern ULONG MmTotalPagesForPagingFile;


//
// A VALID Page Table Entry on PAE x86 has the following definition.
//

#define MI_MAXIMUM_PAGEFILE_SIZE (((UINT64)4 * 1024 * 1024 * 1024 - 1) * PAGE_SIZE)

#define MI_PTE_LOOKUP_NEEDED (0xffffffff)

typedef struct _MMPTE_SOFTWARE {
    ULONGLONG Valid : 1;
    ULONGLONG PageFileLow : 4;
    ULONGLONG Protection : 5;
    ULONGLONG Prototype : 1;
    ULONGLONG Transition : 1;
    ULONGLONG Unused : 20;
    ULONGLONG PageFileHigh : 32;
} MMPTE_SOFTWARE;

typedef struct _MMPTE_TRANSITION {
    ULONGLONG Valid : 1;
    ULONGLONG Write : 1;
    ULONGLONG Owner : 1;
    ULONGLONG WriteThrough : 1;
    ULONGLONG CacheDisable : 1;
    ULONGLONG Protection : 5;
    ULONGLONG Prototype : 1;
    ULONGLONG Transition : 1;
    ULONGLONG PageFrameNumber : 26;
    ULONGLONG Unused : 26;
} MMPTE_TRANSITION;

typedef struct _MMPTE_PROTOTYPE {
    ULONGLONG Valid : 1;
    ULONGLONG Unused0: 7;
    ULONGLONG ReadOnly : 1;  // if set allow read only access.
    ULONGLONG Unused1: 1;
    ULONGLONG Prototype : 1;
    ULONGLONG Protection : 5;
    ULONGLONG Unused: 16;
    ULONGLONG ProtoAddress: 32;
} MMPTE_PROTOTYPE;

typedef struct _MMPTE_SUBSECTION {
    ULONGLONG Valid : 1;
    ULONGLONG Unused0 : 4;
    ULONGLONG Protection : 5;
    ULONGLONG Prototype : 1;
    ULONGLONG Unused1 : 21;
    ULONGLONG SubsectionAddress : 32;
} MMPTE_SUBSECTION;

typedef struct _MMPTE_LIST {
    ULONGLONG Valid : 1;
    ULONGLONG OneEntry : 1;
    ULONGLONG filler0 : 8;

    //
    // Note the Prototype bit must not be used for lists like freed nonpaged
    // pool because lookaside pops can legitimately reference bogus addresses
    // (since the pop is unsynchronized) and the fault handler must be able to
    // distinguish lists from protos so a retry status can be returned (vs a
    // fatal bugcheck).
    //

    ULONGLONG Prototype : 1;            // MUST BE ZERO as per above comment.
    ULONGLONG filler1 : 21;

    ULONGLONG NextEntry : 32;
} MMPTE_LIST;

typedef struct _MMPTE_HIGHLOW {
    ULONG LowPart;
    ULONG HighPart;
} MMPTE_HIGHLOW;

//
// A Page Table Entry on PAE has the following definition.
// Note the MP version is to avoid stalls when flushing TBs across processors.
//

//
// Uniprocessor version.
//

typedef struct _MMPTE_HARDWARE {
    ULONGLONG Valid : 1;
#if defined(NT_UP)
    ULONGLONG Write : 1;        // UP version
#else
    ULONGLONG Writable : 1;        // changed for MP version
#endif
    ULONGLONG Owner : 1;
    ULONGLONG WriteThrough : 1;
    ULONGLONG CacheDisable : 1;
    ULONGLONG Accessed : 1;
    ULONGLONG Dirty : 1;
    ULONGLONG LargePage : 1;
    ULONGLONG Global : 1;
    ULONGLONG CopyOnWrite : 1; // software field
    ULONGLONG Prototype : 1;   // software field
#if defined(NT_UP)
    ULONGLONG reserved0 : 1;  // software field
#else
    ULONGLONG Write : 1;       // software field - MP change
#endif
    ULONGLONG PageFrameNumber : 26;
    ULONGLONG reserved1 : 26;  // software field
} MMPTE_HARDWARE, *PMMPTE_HARDWARE;

#if defined(NT_UP)
#define HARDWARE_PTE_DIRTY_MASK     0x40
#else
#define HARDWARE_PTE_DIRTY_MASK     0x42
#endif

#define MI_PDE_MAPS_LARGE_PAGE(PDE) ((PDE)->u.Hard.LargePage == 1)

#define MI_MAKE_PDE_MAP_LARGE_PAGE(PDE) ((PDE)->u.Hard.LargePage = 1)

#define MI_GET_PAGE_FRAME_FROM_PTE(PTE) ((PFN_NUMBER)(PTE)->u.Hard.PageFrameNumber)
#define MI_GET_PAGE_FRAME_FROM_TRANSITION_PTE(PTE) ((PFN_NUMBER)(PTE)->u.Trans.PageFrameNumber)
#define MI_GET_PROTECTION_FROM_SOFT_PTE(PTE) ((ULONG)(PTE)->u.Soft.Protection)
#define MI_GET_PROTECTION_FROM_TRANSITION_PTE(PTE) ((ULONG)(PTE)->u.Trans.Protection)

typedef struct _MMPTE {
    union  {
        ULONGLONG Long;
        MMPTE_HIGHLOW HighLow;
        MMPTE_HARDWARE Hard;
        HARDWARE_PTE Flush;
        MMPTE_PROTOTYPE Proto;
        MMPTE_SOFTWARE Soft;
        MMPTE_TRANSITION Trans;
        MMPTE_SUBSECTION Subsect;
        MMPTE_LIST List;
        } u;
} MMPTE;

typedef MMPTE *PMMPTE;

extern LOGICAL MiUseGlobalBitInLargePdes;

extern MMPTE MmPteGlobal; // Set if processor supports Global Page, else zero.

extern PMMPTE MiFirstReservedZeroingPte;

//
// A compiler intrinsic for InterlockedCompareExchange64I would be much better
// but since there isn't, make it an inline.
//

FORCEINLINE
LONG64
FASTCALL
InterlockedCompareExchange64I (
    IN OUT LONG64 volatile *Destination,
    IN PLONG64 Exchange,
    IN PLONG64 Comperand
    )
{
    __asm {
        push    ebx
        push    esi

        mov     esi, Destination        ; set destination address
        mov     edx, Exchange
        mov     ebx, [edx]              ; get exchange value
        mov     ecx, [edx] + 4          ;
        mov     edx, Comperand          ; get comperand address
        mov     eax, [edx]              ; get comperand value
        mov     edx, [edx] + 4          ;

        lock cmpxchg8b qword ptr [esi]  ; compare and exchange

        pop     esi                     ; restore nonvolatile registers
        pop     ebx                     ;
    }
}

#define InterlockedCompareExchangePte(Destination, ExChange, Comperand) \
    InterlockedCompareExchange64I((LONG64 volatile *)(Destination), (PLONG64)&(ExChange), (PLONG64)&(Comperand))

VOID
InterlockedExchangePte (
    IN OUT PMMPTE Destination,
    IN ULONGLONG Exchange
    );

//++
//VOID
//MI_WRITE_VALID_PTE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE fills in the specified PTE making it valid with the
//    specified contents.  Note that the contents are very carefully written.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 0);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            ((_PointerPte)->u.HighLow.HighPart = ((_PteContents).u.HighLow.HighPart)); \
            ((_PointerPte)->u.HighLow.LowPart = ((_PteContents).u.HighLow.LowPart))

//++
//VOID
//MI_WRITE_INVALID_PTE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_INVALID_PTE fills in the specified PTE making it invalid with the
//    specified contents.  Note that the contents are very carefully written.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_INVALID_PTE(_PointerPte, _PteContents)  \
            ASSERT ((_PteContents).u.Hard.Valid == 0);  \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            ((_PointerPte)->u.HighLow.LowPart = ((_PteContents).u.HighLow.LowPart)); \
            ((_PointerPte)->u.HighLow.HighPart = ((_PteContents).u.HighLow.HighPart))

//++
//VOID
//MI_WRITE_VALID_PTE_NEW_PROTECTION (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE_NEW_PROTECTION fills in the specified PTE (which was
//    already valid) changing only the protection, dirty or execute bit.
//    Note that the contents are very carefully written.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE_NEW_PROTECTION(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 1);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            ASSERT ((_PointerPte)->u.Hard.PageFrameNumber == (_PteContents).u.Hard.PageFrameNumber); \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            ((_PointerPte)->u.HighLow.LowPart = ((_PteContents).u.HighLow.LowPart)); \
            ((_PointerPte)->u.HighLow.HighPart = ((_PteContents).u.HighLow.HighPart));

//++
//VOID
//MI_WRITE_VALID_PTE_NEW_PAGE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE_NEW_PAGE fills in the specified PTE (which was
//    already valid) changing the page and the protection.
//    Note that the contents are very carefully written.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE_NEW_PAGE(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 1);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            ASSERT ((_PointerPte)->u.Hard.PageFrameNumber != (_PteContents).u.Hard.PageFrameNumber); \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            InterlockedExchangePte (_PointerPte, (_PteContents).u.Long);

//++
//VOID
//MiFillMemoryPte (
//    IN PMMPTE Destination,
//    IN ULONG  NumberOfPtes,
//    IN MMPTE  Pattern,
//    };
//
// Routine Description:
//
//    This function fills memory with the specified PTE pattern.
//
// Arguments
//
//    Destination - Supplies a pointer to the memory to fill.
//
//    NumberOfPtes - Supplies the number of PTEs (not bytes!) to be filled.
//
//    Pattern     - Supplies the PTE fill pattern.
//
// Return Value:
//
//    None.
//
//--

#define MiFillMemoryPte(Destination, Length, Pattern) \
             RtlFillMemoryUlonglong ((Destination), (Length) * sizeof (MMPTE), (Pattern))

#define MiZeroMemoryPte(Destination, Length) \
             RtlZeroMemory ((Destination), (Length) * sizeof (MMPTE))

ULONG
FASTCALL
MiDetermineUserGlobalPteMask (
    IN PMMPTE Pte
    );

//++
//BOOLEAN
//MI_IS_PAGE_TABLE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page table address, FALSE if not.
//
//--

#define MI_IS_PAGE_TABLE_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)PTE_BASE && (PVOID)(VA) <= (PVOID)PTE_TOP)

//++
//BOOLEAN
//MI_IS_PAGE_TABLE_OR_HYPER_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table or hyperspace address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page table or hyperspace address, FALSE if not.
//
//--

#define MI_IS_PAGE_TABLE_OR_HYPER_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)PTE_BASE && (PVOID)(VA) <= (PVOID)MmHyperSpaceEnd)

//++
//BOOLEAN
//MI_IS_KERNEL_PAGE_TABLE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table address for a kernel address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a kernel page table address, FALSE if not.
//
//--

#define MI_IS_KERNEL_PAGE_TABLE_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)MiGetPteAddress(MmSystemRangeStart) && (PVOID)(VA) <= (PVOID)PTE_TOP)


//++
//BOOLEAN
//MI_IS_PAGE_DIRECTORY_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page directory address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page directory address, FALSE if not.
//
//--

#define MI_IS_PAGE_DIRECTORY_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)PDE_BASE && (PVOID)(VA) <= (PVOID)PDE_TOP)


//++
//BOOLEAN
//MI_IS_HYPER_SPACE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a hyper space address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a hyper space address, FALSE if not.
//
//--

#define MI_IS_HYPER_SPACE_ADDRESS(VA)   \
            ((PVOID)(VA) >= (PVOID)HYPER_SPACE && (PVOID)(VA) <= (PVOID)MmHyperSpaceEnd)


//++
//BOOLEAN
//MI_IS_PROCESS_SPACE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a process-specific address.  This is an address in user space
//    or page table pages or hyper space.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a process-specific address, FALSE if not.
//
//--

#define MI_IS_PROCESS_SPACE_ADDRESS(VA)   \
            (((PVOID)(VA) <= (PVOID)MM_HIGHEST_USER_ADDRESS) || \
             ((PVOID)(VA) >= (PVOID)PTE_BASE && (PVOID)(VA) <= (PVOID)MmHyperSpaceEnd))


//++
//BOOLEAN
//MI_IS_PTE_PROTOTYPE (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a PTE address and determines if it is a prototype PTE.
//
// Arguments
//
//    PTE - Supplies the virtual address of the PTE to check.
//
// Return Value:
//
//    TRUE if the PTE is in a segment (ie, a prototype PTE), FALSE if not.
//
//--

#define MI_IS_PTE_PROTOTYPE(PTE)   \
            ((PTE) > (PMMPTE)PTE_TOP)

//++
//BOOLEAN
//MI_IS_SYSTEM_CACHE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a system cache address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is in the system cache, FALSE if not.
//
//--

#define MI_IS_SYSTEM_CACHE_ADDRESS(VA)                            \
         (((PVOID)(VA) >= (PVOID)MmSystemCacheStart &&            \
		     (PVOID)(VA) <= (PVOID)MmSystemCacheEnd)  ||          \
          ((PVOID)(VA) >= (PVOID)MiSystemCacheStartExtra &&       \
			  (PVOID)(VA) <= (PVOID)MiSystemCacheEndExtra))

extern PMMPTE MmSystemCacheWorkingSetListPte;

//++
//VOID
//MI_BARRIER_SYNCHRONIZE (
//    IN ULONG TimeStamp
//    );
//
// Routine Description:
//
//    MI_BARRIER_SYNCHRONIZE compares the argument timestamp against the
//    current IPI barrier sequence stamp.  When equal, all processors will
//    issue memory barriers to ensure that newly created pages remain coherent.
//
//    When a page is put in the zeroed or free page list the current
//    barrier sequence stamp is read (interlocked - this is necessary
//    to get the correct value - memory barriers won't do the trick)
//    and stored in the pfn entry for the page. The current barrier
//    sequence stamp is maintained by the IPI send logic and is
//    incremented (interlocked) when the target set of an IPI send
//    includes all processors, but the one doing the send. When a page
//    is needed its sequence number is compared against the current
//    barrier sequence number.  If it is equal, then the contents of
//    the page may not be coherent on all processors, and an IPI must
//    be sent to all processors to ensure a memory barrier is
//    executed (generic call can be used for this). Sending the IPI
//    automatically updates the barrier sequence number. The compare
//    is for equality as this is the only value that requires the IPI
//    (i.e., the sequence number wraps, values in both directions are
//    older). When a page is removed in this fashion and either found
//    to be coherent or made coherent, it cannot be modified between
//    that time and writing the PTE. If the page is modified between
//    these times, then an IPI must be sent.
//
// Arguments
//
//    TimeStamp - Supplies the timestamp at the time when the page was zeroed.
//
// Return Value:
//
//    None.
//
//--

// does nothing on PAE.

#define MI_BARRIER_SYNCHRONIZE(TimeStamp)

//++
//VOID
//MI_BARRIER_STAMP_ZEROED_PAGE (
//    IN PULONG PointerTimeStamp
//    );
//
// Routine Description:
//
//    MI_BARRIER_STAMP_ZEROED_PAGE issues an interlocked read to get the
//    current IPI barrier sequence stamp.  This is called AFTER a page is
//    zeroed.
//
// Arguments
//
//    PointerTimeStamp - Supplies a timestamp pointer to fill with the
//                       current IPI barrier sequence stamp.
//
// Return Value:
//
//    None.
//
//--

// does nothing on PAE.

#define MI_BARRIER_STAMP_ZEROED_PAGE(PointerTimeStamp)

typedef struct _PAE_PAGEINFO {
    LIST_ENTRY ListHead;
    PFN_NUMBER PageFrameNumber;
    ULONG EntriesInUse;
} PAE_PAGEINFO, *PPAE_PAGEINFO;

typedef struct _PAE_ENTRY {
    union {
        MMPTE PteEntry[PD_PER_SYSTEM];
        PAE_PAGEINFO PaeEntry;
        SLIST_ENTRY NextPae;
    };
} PAE_ENTRY, *PPAE_ENTRY;

extern PAE_ENTRY MiSystemPaeVa;

//++
//VOID
//MI_FLUSH_SINGLE_SESSION_TB (
//    IN PVOID Virtual
//    );
//
// Routine Description:
//
//    MI_FLUSH_SINGLE_SESSION_TB flushes the requested single address
//    translation from the TB.
//
//    Since there are no ASNs on the x86, this routine becomes a single
//    TB invalidate.
//
// Arguments
//
//    Virtual - Supplies the virtual address to invalidate.
//
// Return Value:
//
//    None.
//
//--

#define MI_FLUSH_SINGLE_SESSION_TB(Virtual) \
    KeFlushSingleTb (Virtual, TRUE);

//++
//VOID
//MI_FLUSH_ENTIRE_SESSION_TB (
//    IN ULONG Invalid,
//    IN LOGICAL AllProcessors
//    );
//
// Routine Description:
//
//    MI_FLUSH_ENTIRE_SESSION_TB flushes the entire TB on processors which
//    support ASNs.
//
//    Since there are no ASNs on the x86, this routine does nothing.
//
// Arguments
//
//    Invalid - TRUE if invalidating.
//
//    AllProcessors - TRUE if all processors need to be IPI'd.
//
// Return Value:
//
//    None.
//

#define MI_FLUSH_ENTIRE_SESSION_TB(Invalid, AllProcessors) \
    NOTHING;

//++
//LOGICAL
//MI_RESERVED_BITS_CANONICAL (
//    IN PVOID VirtualAddress
//    );
//
// Routine Description:
//
//    This routine checks whether all of the reserved bits are correct.
//
//    This does nothing on PAE x86.
//
// Arguments
//
//    VirtualAddress - Supplies the virtual address to check.
//
// Return Value:
//
//    None.
//
#define MI_RESERVED_BITS_CANONICAL(VirtualAddress)  TRUE

//++
//VOID
//MI_DISPLAY_TRAP_INFORMATION (
//    IN PVOID TrapInformation
//    );
//
// Routine Description:
//
//    Display any relevant trap information to aid debugging.
//
// Arguments
//
//    TrapInformation - Supplies a pointer to a trap frame.
//
// Return Value:
//
//    None.
//
#define MI_DISPLAY_TRAP_INFORMATION(TrapInformation)                    \
            KdPrint(("MM:***EIP %p, EFL %p\n",                          \
                     ((PKTRAP_FRAME) (TrapInformation))->Eip,           \
                     ((PKTRAP_FRAME) (TrapInformation))->EFlags));      \
            KdPrint(("MM:***EAX %p, ECX %p EDX %p\n",                   \
                     ((PKTRAP_FRAME) (TrapInformation))->Eax,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Ecx,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Edx));         \
            KdPrint(("MM:***EBX %p, ESI %p EDI %p\n",                   \
                     ((PKTRAP_FRAME) (TrapInformation))->Ebx,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Esi,           \
                     ((PKTRAP_FRAME) (TrapInformation))->Edi));

//
// Turn off U/S, R/W and any other appropriate bits required by the processor.
//

#define MM_PAE_PDPTE_MASK         0x1e6

ULONG
MiPaeAllocate (
    PPAE_ENTRY *
    );

VOID
MiPaeFree (
    PPAE_ENTRY Pae
    );

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\i386\paesup.c ===
/*++

Copyright (c) 1998  Microsoft Corporation

Module Name:

    paesup.c

Abstract:

    This module contains the machine dependent support for the x86 PAE
    architecture.

Author:

    Landy Wang (landyw)  15-Nov-1998

Revision History:

--*/

#include "mi.h"

#if defined (_X86PAE_)

#define PAES_PER_PAGE  (PAGE_SIZE / sizeof(PAE_ENTRY))

#define MINIMUM_PAE_SLIST_THRESHOLD (PAES_PER_PAGE * 1)
#define MINIMUM_PAE_THRESHOLD       (PAES_PER_PAGE * 4)
#define REPLENISH_PAE_SIZE          (PAES_PER_PAGE * 16)
#define EXCESS_PAE_THRESHOLD        (PAES_PER_PAGE * 20)

#define MM_HIGHEST_PAE_PAGE      0xFFFFF

ULONG MiFreePaeEntries;
PAE_ENTRY MiFirstFreePae;

LONG MmAllocatedPaePages;
KSPIN_LOCK MiPaeLock;

SLIST_HEADER MiPaeEntrySList;

PAE_ENTRY MiSystemPaeVa;

LONG
MiPaeAllocatePages (
    VOID
    );

VOID
MiPaeFreePages (
    PVOID VirtualAddress
    );

#pragma alloc_text(INIT,MiPaeInitialize)
#pragma alloc_text(PAGE,MiPaeFreePages)

VOID
MiMarkMdlPageAttributes (
    IN PMDL Mdl,
    IN PFN_NUMBER NumberOfPages,
    IN MI_PFN_CACHE_ATTRIBUTE CacheAttribute
    );

VOID
MiPaeInitialize (
    VOID
    )
{
    InitializeSListHead (&MiPaeEntrySList);
    KeInitializeSpinLock (&MiPaeLock);
    InitializeListHead (&MiFirstFreePae.PaeEntry.ListHead);
}

ULONG
MiPaeAllocate (
    OUT PPAE_ENTRY *Va
    )

/*++

Routine Description:

    This routine allocates the top level page directory pointer structure.
    This structure will contain 4 PDPTEs.

Arguments:

    Va - Supplies a place to put the virtual address this page can be accessed
         at.

Return Value:

    Returns a virtual and physical address suitable for use as a top
    level page directory pointer page.  The page returned must be below
    physical 4GB as required by the processor.

    Returns 0 if no page was allocated.

Environment:

    Kernel mode.  No locks may be held.

--*/

{
    LOGICAL FlushedOnce;
    PPAE_ENTRY Pae2;
    PPAE_ENTRY Pae3;
    PPAE_ENTRY Pae3Base;
    PPAE_ENTRY Pae;
    PPAE_ENTRY PaeBase;
    PFN_NUMBER PageFrameIndex;
    PSLIST_ENTRY SingleListEntry;
    ULONG j;
    ULONG Entries;
    KLOCK_QUEUE_HANDLE LockHandle;
#if DBG
    PMMPFN Pfn1;
#endif

    FlushedOnce = FALSE;

    ASSERT (KeGetCurrentIrql() <= APC_LEVEL);

    do {

        //
        // Pop an entry from the freelist.
        //

        SingleListEntry = InterlockedPopEntrySList (&MiPaeEntrySList);

        if (SingleListEntry != NULL) {
            Pae = CONTAINING_RECORD (SingleListEntry,
                                    PAE_ENTRY,
                                    NextPae);

            PaeBase = (PPAE_ENTRY)PAGE_ALIGN(Pae);

            *Va = Pae;

            PageFrameIndex = PaeBase->PaeEntry.PageFrameNumber;
            ASSERT (PageFrameIndex <= MM_HIGHEST_PAE_PAGE);

            return (PageFrameIndex << PAGE_SHIFT) + BYTE_OFFSET (Pae);
        }

        KeAcquireInStackQueuedSpinLock (&MiPaeLock, &LockHandle);

        if (MiFreePaeEntries != 0) {

            ASSERT (IsListEmpty (&MiFirstFreePae.PaeEntry.ListHead) == 0);

            Pae = (PPAE_ENTRY) RemoveHeadList (&MiFirstFreePae.PaeEntry.ListHead);

            PaeBase = (PPAE_ENTRY)PAGE_ALIGN(Pae);
            PaeBase->PaeEntry.EntriesInUse += 1;
#if DBG
            RtlZeroMemory ((PVOID)Pae, sizeof(PAE_ENTRY));

            Pfn1 = MI_PFN_ELEMENT (PaeBase->PaeEntry.PageFrameNumber);
            ASSERT (Pfn1->u2.ShareCount == 1);
            ASSERT (Pfn1->u3.e2.ReferenceCount == 1);
            ASSERT (Pfn1->u3.e1.PageLocation == ActiveAndValid);
            ASSERT (Pfn1->u3.e1.CacheAttribute == MiCached);
#endif

            MiFreePaeEntries -= 1;

            //
            // Since we're holding the spinlock, dequeue a chain of entries
            // for the SLIST.
            //

            Entries = MiFreePaeEntries;

            if (Entries != 0) {
                if (Entries > MINIMUM_PAE_SLIST_THRESHOLD) {
                    Entries = MINIMUM_PAE_SLIST_THRESHOLD;
                }

                ASSERT (IsListEmpty (&MiFirstFreePae.PaeEntry.ListHead) == 0);

                Pae2 = (PPAE_ENTRY) RemoveHeadList (&MiFirstFreePae.PaeEntry.ListHead);
                Pae2->NextPae.Next = NULL;
                Pae3 = Pae2;
                Pae3Base = (PPAE_ENTRY)PAGE_ALIGN(Pae3);
                Pae3Base->PaeEntry.EntriesInUse += 1;

                for (j = 1; j < Entries; j += 1) {
                    ASSERT (IsListEmpty (&MiFirstFreePae.PaeEntry.ListHead) == 0);

                    Pae3->NextPae.Next = (PSLIST_ENTRY) RemoveHeadList (&MiFirstFreePae.PaeEntry.ListHead);

                    Pae3 = (PPAE_ENTRY) Pae3->NextPae.Next;
                    Pae3Base = (PPAE_ENTRY)PAGE_ALIGN(Pae3);
                    Pae3Base->PaeEntry.EntriesInUse += 1;
                }

                MiFreePaeEntries -= Entries;

                KeReleaseInStackQueuedSpinLock (&LockHandle);

                Pae3->NextPae.Next = NULL;

                InterlockedPushListSList (&MiPaeEntrySList,
                                          (PSLIST_ENTRY) Pae2,
                                          (PSLIST_ENTRY) Pae3,
                                          Entries);
            }
            else {
                KeReleaseInStackQueuedSpinLock (&LockHandle);
            }

            ASSERT (KeGetCurrentIrql() <= APC_LEVEL);
            *Va = Pae;

            PageFrameIndex = PaeBase->PaeEntry.PageFrameNumber;
            ASSERT (PageFrameIndex <= MM_HIGHEST_PAE_PAGE);

            return (PageFrameIndex << PAGE_SHIFT) + BYTE_OFFSET (Pae);
        }

        KeReleaseInStackQueuedSpinLock (&LockHandle);

        if (FlushedOnce == TRUE) {
            break;
        }

        //
        // No free pages in the cachelist, replenish the list now.
        //

        if (MiPaeAllocatePages () == 0) {

            InterlockedIncrement (&MiDelayPageFaults);

            //
            // Attempt to move pages to the standby list.
            //

            MmEmptyAllWorkingSets ();
            MiFlushAllPages();

            KeDelayExecutionThread (KernelMode,
                                    FALSE,
                                    (PLARGE_INTEGER)&MmHalfSecond);

            InterlockedDecrement (&MiDelayPageFaults);

            FlushedOnce = TRUE;

            //
            // Since all the working sets have been trimmed, check whether
            // another thread has replenished our list.  If not, then attempt
            // to do so since the working set pain has already been absorbed.
            //

            if (MiFreePaeEntries < MINIMUM_PAE_THRESHOLD) {
                MiPaeAllocatePages ();
            }
        }

    } while (TRUE);

    ASSERT (KeGetCurrentIrql() <= APC_LEVEL);

    return 0;
}

VOID
MiPaeFree (
    PPAE_ENTRY Pae
    )

/*++

Routine Description:

    This routine releases the top level page directory pointer page.

Arguments:

    PageFrameIndex - Supplies the top level page directory pointer page.

Return Value:

    None.

Environment:

    Kernel mode.  No locks may be held.

--*/

{
    ULONG i;
    PLIST_ENTRY NextEntry;
    PPAE_ENTRY PaeBase;
    KLOCK_QUEUE_HANDLE LockHandle;

#if DBG
    PMMPTE PointerPte;
    PFN_NUMBER PageFrameIndex;
    PMMPFN Pfn1;

    PointerPte = MiGetPteAddress (Pae);
    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);

    //
    // This page must be in the first 4GB of RAM.
    //

    ASSERT (PageFrameIndex <= MM_HIGHEST_PAE_PAGE);

    Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

    ASSERT (Pfn1->u2.ShareCount == 1);
    ASSERT (Pfn1->u3.e2.ReferenceCount == 1);
    ASSERT (Pfn1->u3.e1.PageLocation == ActiveAndValid);
    ASSERT (Pfn1->u3.e1.CacheAttribute == MiCached);
#endif

    if (ExQueryDepthSList (&MiPaeEntrySList) < MINIMUM_PAE_SLIST_THRESHOLD) {
        InterlockedPushEntrySList (&MiPaeEntrySList, &Pae->NextPae);
        return;
    }

    PaeBase = (PPAE_ENTRY)PAGE_ALIGN(Pae);

    KeAcquireInStackQueuedSpinLock (&MiPaeLock, &LockHandle);

    PaeBase->PaeEntry.EntriesInUse -= 1;

    if ((PaeBase->PaeEntry.EntriesInUse == 0) &&
        (MiFreePaeEntries > EXCESS_PAE_THRESHOLD)) {

        //
        // Free the entire page.
        //

        i = 1;
        NextEntry = MiFirstFreePae.PaeEntry.ListHead.Flink;
        while (NextEntry != &MiFirstFreePae.PaeEntry.ListHead) {

            Pae = CONTAINING_RECORD (NextEntry,
                                     PAE_ENTRY,
                                     PaeEntry.ListHead);

            if (PAGE_ALIGN(Pae) == PaeBase) {
                RemoveEntryList (NextEntry);
                i += 1;
            }
            NextEntry = Pae->PaeEntry.ListHead.Flink;
        }
        ASSERT (i == PAES_PER_PAGE - 1);
        MiFreePaeEntries -= (PAES_PER_PAGE - 1);
        KeReleaseInStackQueuedSpinLock (&LockHandle);

        MiPaeFreePages (PaeBase);
    }
    else {

        InsertTailList (&MiFirstFreePae.PaeEntry.ListHead,
                        &Pae->PaeEntry.ListHead);
        MiFreePaeEntries += 1;
        KeReleaseInStackQueuedSpinLock (&LockHandle);
    }

    return;
}

LONG
MiPaeAllocatePages (
    VOID
    )

/*++

Routine Description:

    This routine replenishes the PAE top level mapping list.

Arguments:

    None.

Return Value:

    The number of pages allocated.

Environment:

    Kernel mode, IRQL of APC_LEVEL or below.

--*/
{
    PMDL MemoryDescriptorList;
    LONG AllocatedPaePages;
    ULONG i;
    ULONG j;
    PPFN_NUMBER SlidePage;
    PPFN_NUMBER Page;
    PFN_NUMBER PageFrameIndex;
    ULONG_PTR ActualPages;
    PMMPTE PointerPte;
    PVOID BaseAddress;
    PPAE_ENTRY Pae;
    ULONG NumberOfPages;
    MMPTE TempPte;
    PHYSICAL_ADDRESS HighAddress;
    PHYSICAL_ADDRESS LowAddress;
    PHYSICAL_ADDRESS SkipBytes;
    KLOCK_QUEUE_HANDLE LockHandle;

#if defined (_MI_MORE_THAN_4GB_)
    if (MiNoLowMemory != 0) {
        BaseAddress = MiAllocateLowMemory (PAGE_SIZE,
                                           0,
                                           MiNoLowMemory - 1,
                                           0,
                                           (PVOID)0x123,
                                           MmCached,
                                           'DeaP');
        if (BaseAddress == NULL) {
            return 0;
        }

        PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (MiGetPteAddress(BaseAddress));

        Pae = (PPAE_ENTRY) BaseAddress;
        Pae->PaeEntry.EntriesInUse = 0;
        Pae->PaeEntry.PageFrameNumber = PageFrameIndex;
        Pae += 1;

        KeAcquireInStackQueuedSpinLock (&MiPaeLock, &LockHandle);

        for (i = 1; i < PAES_PER_PAGE; i += 1) {
            InsertTailList (&MiFirstFreePae.PaeEntry.ListHead,
                            &Pae->PaeEntry.ListHead);
            Pae += 1;
        }
        MiFreePaeEntries += (PAES_PER_PAGE - 1);

        KeReleaseInStackQueuedSpinLock (&LockHandle);

        InterlockedIncrement (&MmAllocatedPaePages);
        return 1;
    }
#endif

    NumberOfPages = REPLENISH_PAE_SIZE / PAES_PER_PAGE;
    AllocatedPaePages = 0;

    HighAddress.QuadPart = (ULONGLONG)_4gb - 1;
    LowAddress.QuadPart = 0;
    SkipBytes.QuadPart = 0;

    //
    // This is a potentially expensive call so pick up a chunk of pages
    // at once to amortize the cost.
    //

    MemoryDescriptorList = MmAllocatePagesForMdl (LowAddress,
                                                  HighAddress,
                                                  SkipBytes,
                                                  NumberOfPages << PAGE_SHIFT);

    if (MemoryDescriptorList == NULL) {
        return 0;
    }

    ActualPages = MemoryDescriptorList->ByteCount >> PAGE_SHIFT;

    MiMarkMdlPageAttributes (MemoryDescriptorList, ActualPages, MiCached);

    TempPte = ValidKernelPte;
    Page = (PPFN_NUMBER)(MemoryDescriptorList + 1);

    //
    // Map each page individually as they may need to be freed individually
    // later.
    //

    for (i = 0; i < ActualPages; i += 1) {
        PageFrameIndex = *Page;

        PointerPte = MiReserveSystemPtes (1, SystemPteSpace);

        if (PointerPte == NULL) {

            //
            // Free any remaining pages in the MDL as they are not mapped.
            // Slide the MDL pages forward so the mapped ones are kept.
            //

            MmInitializeMdl (MemoryDescriptorList,
                             0,
                             (ActualPages - i) << PAGE_SHIFT);

            SlidePage = (PPFN_NUMBER)(MemoryDescriptorList + 1);

            while (i < ActualPages) {
                i += 1;
                *SlidePage = *Page;
                SlidePage += 1;
                Page += 1;
            }

            MmFreePagesFromMdl (MemoryDescriptorList);

            break;
        }

        TempPte.u.Hard.PageFrameNumber = PageFrameIndex;
        MI_WRITE_VALID_PTE (PointerPte, TempPte);

        BaseAddress = MiGetVirtualAddressMappedByPte (PointerPte);

        Pae = (PPAE_ENTRY) BaseAddress;

        Pae->PaeEntry.EntriesInUse = 0;
        Pae->PaeEntry.PageFrameNumber = PageFrameIndex;
        Pae += 1;

        //
        // Put the first chunk into the SLIST if it's still low, and just
        // enqueue all the other entries normally.
        //

        if ((i == 0) &&
            (ExQueryDepthSList (&MiPaeEntrySList) < MINIMUM_PAE_SLIST_THRESHOLD)) {

            (Pae - 1)->PaeEntry.EntriesInUse = PAES_PER_PAGE - 1;

            for (j = 1; j < PAES_PER_PAGE - 1; j += 1) {
                Pae->NextPae.Next = (PSLIST_ENTRY) (Pae + 1);
                Pae += 1;
            }

            Pae->NextPae.Next = NULL;

            InterlockedPushListSList (&MiPaeEntrySList,
                                      (PSLIST_ENTRY)((PPAE_ENTRY) BaseAddress + 1),
                                      (PSLIST_ENTRY) Pae,
                                      PAES_PER_PAGE - 1);
        }
        else {

            KeAcquireInStackQueuedSpinLock (&MiPaeLock, &LockHandle);

            for (j = 1; j < PAES_PER_PAGE; j += 1) {
                InsertTailList (&MiFirstFreePae.PaeEntry.ListHead,
                                &Pae->PaeEntry.ListHead);
                Pae += 1;
            }

            MiFreePaeEntries += (PAES_PER_PAGE - 1);

            KeReleaseInStackQueuedSpinLock (&LockHandle);
        }

        AllocatedPaePages += 1;

        Page += 1;
    }

    ExFreePool (MemoryDescriptorList);

    InterlockedExchangeAdd (&MmAllocatedPaePages, AllocatedPaePages);

    return AllocatedPaePages;
}

VOID
MiPaeFreePages (
    PVOID VirtualAddress
    )

/*++

Routine Description:

    This routine releases a single page that previously contained top level
    page directory pointer pages.

Arguments:

    VirtualAddress - Supplies the virtual address of the page that contained
                     top level page directory pointer pages.

Return Value:

    None.

Environment:

    Kernel mode.  No locks held.

--*/

{
    ULONG MdlPages;
    PFN_NUMBER PageFrameIndex;
    PMMPTE PointerPte;
    PFN_NUMBER MdlHack[(sizeof(MDL) / sizeof(PFN_NUMBER)) + 1];
    PPFN_NUMBER MdlPage;
    PMDL MemoryDescriptorList;

#if defined (_MI_MORE_THAN_4GB_)
    if (MiNoLowMemory != 0) {
        if (MiFreeLowMemory (VirtualAddress, 'DeaP') == TRUE) {
            InterlockedDecrement (&MmAllocatedPaePages);
            return;
        }
    }
#endif

    MemoryDescriptorList = (PMDL)&MdlHack[0];
    MdlPages = 1;
    MmInitializeMdl (MemoryDescriptorList, 0, MdlPages << PAGE_SHIFT);

    MdlPage = (PPFN_NUMBER)(MemoryDescriptorList + 1);

    PointerPte = MiGetPteAddress (VirtualAddress);
    PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
    *MdlPage = PageFrameIndex;

    ASSERT ((MI_PFN_ELEMENT(PageFrameIndex))->u3.e1.CacheAttribute == MiCached);

    MiReleaseSystemPtes (PointerPte, 1, SystemPteSpace);

    MmFreePagesFromMdl (MemoryDescriptorList);

    InterlockedDecrement (&MmAllocatedPaePages);
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\up\makefile.inc ===
$O\pooltag.txt : pooltags.pl $(PROJECT_ROOT)\ntos\inc\pooltag.w
        perl pooltags.pl -o $O\pooltag.txt -i $(PROJECT_ROOT)\ntos\inc\pooltag.w
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\ia64\dataia64.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

   dataia64.c

Abstract:

    This module contains the private hardware specific global storage for
    the memory management subsystem.

Author:

    Lou Perazzoli (loup) 22-Jan-1990

Revision History:

    Koichi Yamada (kyamada) 9-Jan-1996 : IA64 version based on i386 version

--*/

#include "mi.h"


//
// A zero Pte.
//

const MMPTE ZeroPte = { 0 };


//
// A kernel zero PTE.
//

const MMPTE ZeroKernelPte = {0x0};


MMPTE ValidKernelPte = { MM_PTE_VALID_MASK |
                         MM_PTE_CACHE |
                         MM_PTE_WRITE_MASK |
                         MM_PTE_EXECUTE_MASK |
                         MM_PTE_ACCESS_MASK |
                         MM_PTE_DIRTY_MASK |
                         MM_PTE_EXC_DEFER};

const MMPTE ValidKernelPteLocal = { MM_PTE_VALID_MASK |
                                    MM_PTE_CACHE |
                                    MM_PTE_WRITE_MASK |
                                    MM_PTE_ACCESS_MASK |
                                    MM_PTE_DIRTY_MASK |
                                    MM_PTE_EXC_DEFER};


const MMPTE ValidUserPte = { MM_PTE_VALID_MASK |
                       MM_PTE_CACHE |
                       MM_PTE_WRITE_MASK |
                       MM_PTE_OWNER_MASK |
                       MM_PTE_ACCESS_MASK |
                       MM_PTE_DIRTY_MASK |
                       MM_PTE_EXC_DEFER};


const MMPTE ValidPtePte = { MM_PTE_VALID_MASK |
                            MM_PTE_CACHE |
                            MM_PTE_WRITE_MASK |
                            MM_PTE_ACCESS_MASK |
                            MM_PTE_DIRTY_MASK  };


const MMPTE ValidPdePde = { MM_PTE_VALID_MASK |
                            MM_PTE_CACHE |
                            MM_PTE_WRITE_MASK |
                            MM_PTE_ACCESS_MASK |
                            MM_PTE_DIRTY_MASK };


MMPTE ValidKernelPde = { MM_PTE_VALID_MASK |
                         MM_PTE_CACHE |
                         MM_PTE_WRITE_MASK |
                         MM_PTE_ACCESS_MASK |
                         MM_PTE_DIRTY_MASK };

const MMPTE ValidKernelPdeLocal = { MM_PTE_VALID_MASK |
                                    MM_PTE_CACHE |
                                    MM_PTE_WRITE_MASK |
                                    MM_PTE_ACCESS_MASK |
                                    MM_PTE_DIRTY_MASK };

MMPTE ValidPpePte = { MM_PTE_VALID_MASK |
                      MM_PTE_CACHE |
                      MM_PTE_WRITE_MASK |
                      MM_PTE_ACCESS_MASK |
                      MM_PTE_DIRTY_MASK };


MMPTE DemandZeroPde = { MM_READWRITE << MM_PROTECT_FIELD_SHIFT };


const MMPTE DemandZeroPte = { MM_READWRITE << MM_PROTECT_FIELD_SHIFT };


const MMPTE TransitionPde = { MM_PTE_TRANSITION_MASK |
                              MM_READWRITE << MM_PROTECT_FIELD_SHIFT };


MMPTE PrototypePte = { MI_PTE_LOOKUP_NEEDED << 32 |
                       MM_PTE_PROTOTYPE_MASK |
                       MM_READWRITE << MM_PROTECT_FIELD_SHIFT };

//
// PTE which generates an access violation when referenced.
//

const MMPTE NoAccessPte = {MM_NOACCESS << MM_PROTECT_FIELD_SHIFT};

//
// Pool start and end.
//

PVOID MmNonPagedPoolStart;

PVOID MmNonPagedPoolEnd = (PVOID)MM_NONPAGED_POOL_END;

PVOID MmPagedPoolStart =  (PVOID)MM_PAGED_POOL_START;

PVOID MmPagedPoolEnd;

//
// Color tables for free and zeroed pages.
//

#if MM_MAXIMUM_NUMBER_OF_COLORS > 1
MMPFNLIST MmFreePagesByPrimaryColor[2][MM_MAXIMUM_NUMBER_OF_COLORS];
#endif

PMMCOLOR_TABLES MmFreePagesByColor[2];

//
// Color tables for modified pages destined for the paging file.
//

MMPFNLIST MmModifiedPageListByColor[MM_MAXIMUM_NUMBER_OF_COLORS] = {
                            0, ModifiedPageList, MM_EMPTY_LIST, MM_EMPTY_LIST};


//
// Count of the number of modified pages destined for the paging file.
//

PFN_NUMBER MmTotalPagesForPagingFile = 0;

//
// Pte reserved for mapping pages for the debugger.
//

PMMPTE MmDebugPte;

//
// 16 PTEs reserved for mapping MDLs (64k max).
//

PMMPTE MmCrashDumpPte;

//
// Maximum size of system cache
//

ULONG MiMaximumSystemCacheSize;

#if defined(_MIALT4K_)

//
// Map a IA32 compatible PTE protection from Pte.Protect field
//

ULONG MmProtectToPteMaskForIA32[32] = {
                       MM_PTE_NOACCESS,
                       MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_READWRITE | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_WRITECOPY | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_READWRITE | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_WRITECOPY | MM_PTE_CACHE,
                       MM_PTE_NOACCESS,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READWRITE,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_WRITECOPY,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READWRITE,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_WRITECOPY,
                       MM_PTE_NOACCESS,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READWRITE | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_WRITECOPY | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READWRITE | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_WRITECOPY | MM_PTE_CACHE,
                       MM_PTE_NOACCESS,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READWRITE,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_WRITECOPY,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READWRITE,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_WRITECOPY
                    };

ULONG MmProtectToPteMaskForSplit[32] = {
                       MM_PTE_NOACCESS,
                       MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_WRITECOPY | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_EXECUTE_WRITECOPY | MM_PTE_CACHE,
                       MM_PTE_NOACCESS,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_WRITECOPY,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_READWRITE,
                       MM_PTE_NOCACHE | MM_PTE_EXECUTE_WRITECOPY,
                       MM_PTE_NOACCESS,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_WRITECOPY | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_READ | MM_PTE_CACHE,
                       MM_PTE_GUARD | MM_PTE_EXECUTE_WRITECOPY | MM_PTE_CACHE,
                       MM_PTE_NOACCESS,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_WRITECOPY,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_READ,
                       MM_PTE_NOCACHE | MM_PTE_GUARD | MM_PTE_EXECUTE_WRITECOPY
                    };

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\ia64\initia64.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    initia64.c

Abstract:

    This module contains the machine dependent initialization for the
    memory management component.  It is specifically tailored to the
    IA64 architecture.

Author:

    Koichi Yamada (kyamada) 9-Jan-1996
    Landy Wang (landyw) 2-June-1997

Revision History:

--*/

#include "mi.h"

VOID
MiBuildPageTableForLoaderMemory (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    );

PVOID
MiConvertToLoaderVirtual (
    IN PFN_NUMBER Page,
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    );

VOID
MiRemoveLoaderSuperPages (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    );

VOID
MiCompactMemoryDescriptorList (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    );

VOID
MiInitializeTbImage (
    VOID
    );

VOID
MiAddTrEntry (
    ULONG_PTR BaseAddress,
    ULONG_PTR EndAddress
    );

VOID
MiComputeInitialLargePage (
    VOID
    );

PVOID MiMaxWow64Pte;

//
// This is enabled once the memory management page table structures and TB
// entries have been initialized and can be safely referenced.
//

LOGICAL MiMappingsInitialized = FALSE;

PFN_NUMBER MmSystemParentTablePage;

PFN_NUMBER MmSessionParentTablePage;
REGION_MAP_INFO MmSessionMapInfo;

MMPTE MiSystemSelfMappedPte;
MMPTE MiUserSelfMappedPte;

PFN_NUMBER MiNtoskrnlPhysicalBase;
ULONG_PTR MiNtoskrnlVirtualBase;
ULONG MiNtoskrnlPageShift;
MMPTE MiDefaultPpe;
MMPTE MiNatPte;

#define _x1mb (1024*1024)
#define _x1mbnp ((1024*1024) >> PAGE_SHIFT)
#define _x4mb (1024*1024*4)
#define _x4mbnp ((1024*1024*4) >> PAGE_SHIFT)
#define _x16mb (1024*1024*16)
#define _x16mbnp ((1024*1024*16) >> PAGE_SHIFT)
#define _x64mb (1024*1024*64)
#define _x64mbnp ((1024*1024*64) >> PAGE_SHIFT)
#define _x256mb (1024*1024*256)
#define _x256mbnp ((1024*1024*256) >> PAGE_SHIFT)
#define _x4gb (0x100000000UI64)
#define _x4gbnp (0x100000000UI64 >> PAGE_SHIFT)

PMEMORY_ALLOCATION_DESCRIPTOR MiFreeDescriptor;

PFN_NUMBER MiOldFreeDescriptorBase;
PFN_NUMBER MiOldFreeDescriptorCount;

PFN_NUMBER MiSlushDescriptorBase;
PFN_NUMBER MiSlushDescriptorCount;

PFN_NUMBER MiInitialLargePage;
PFN_NUMBER MiInitialLargePageSize;

PFN_NUMBER MxPfnAllocation;

extern KEVENT MiImageMappingPteEvent;

//
// Examine the 8 icache & dcache TR entries looking for a match.
// It is too bad the number of entries is hardcoded into the
// loader block.  Since it is this way, declare our own static array
// and also assume also that the ITR and DTR entries are contiguous
// and just keep walking into the DTR if a match cannot be found in the ITR.
//

#define NUMBER_OF_LOADER_TR_ENTRIES 8

TR_INFO MiTrInfo[2 * NUMBER_OF_LOADER_TR_ENTRIES];

TR_INFO MiBootedTrInfo[2 * NUMBER_OF_LOADER_TR_ENTRIES];

PTR_INFO MiLastTrEntry;

//
// These variables are purely for use by the debugger.
//

PVOID MiKseg0Start;
PVOID MiKseg0End;
PFN_NUMBER MiKseg0StartFrame;
PFN_NUMBER MiKseg0EndFrame;
BOOLEAN MiKseg0Mapping;

PFN_NUMBER
MiGetNextPhysicalPage (
    VOID
    );

VOID
MiCompactMemoryDescriptorList (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    );

LOGICAL
MiIsRegularMemory (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock,
    IN PFN_NUMBER PageFrameIndex
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,MiInitMachineDependent)
#pragma alloc_text(INIT,MiGetNextPhysicalPage)
#pragma alloc_text(INIT,MiBuildPageTableForLoaderMemory)
#pragma alloc_text(INIT,MiConvertToLoaderVirtual)
#pragma alloc_text(INIT,MiInitializeTbImage)
#pragma alloc_text(INIT,MiAddTrEntry)
#pragma alloc_text(INIT,MiCompactMemoryDescriptorList)
#pragma alloc_text(INIT,MiRemoveLoaderSuperPages)
#pragma alloc_text(INIT,MiComputeInitialLargePage)
#pragma alloc_text(INIT,MiIsRegularMemory)
#endif


PFN_NUMBER
MiGetNextPhysicalPage (
    VOID
    )

/*++

Routine Description:

    This function returns the next physical page number from the
    free descriptor.  If there are no physical pages left, then a
    bugcheck is executed since the system cannot be initialized.

Arguments:

    None.

Return Value:

    The next physical page number.

Environment:

    Kernel mode.

--*/

{
    PFN_NUMBER FreePage;

    if (MiFreeDescriptor->PageCount == 0) {
        KeBugCheckEx (INSTALL_MORE_MEMORY,
                      MmNumberOfPhysicalPages,
                      MmLowestPhysicalPage,
                      MmHighestPhysicalPage,
                      0);
    }

    FreePage = MiFreeDescriptor->BasePage;

    MiFreeDescriptor->PageCount -= 1;

    MiFreeDescriptor->BasePage += 1;

    return FreePage;
}

VOID
MiComputeInitialLargePage (
    VOID
    )

/*++

Routine Description:

    This function computes the number of bytes needed to span the initial
    nonpaged pool and PFN database plus the color arrays.  It rounds this up
    to a large page boundary and carves the memory from the free descriptor.

    If the physical memory is too sparse to use large pages for this, then
    fall back to using small pages.  ie: we have seen an OEM machine
    with only 2 1gb chunks of RAM and a 275gb gap between them !

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode, INIT only.

--*/

{
    PFN_NUMBER BasePage;
    PFN_NUMBER LastPage;
    SIZE_T NumberOfBytes;
    SIZE_T PfnAllocation;
    SIZE_T MaximumNonPagedPoolInBytesLimit;
#if defined(MI_MULTINODE)
    PFN_NUMBER i;
#endif

    MaximumNonPagedPoolInBytesLimit = 0;

    //
    // Non-paged pool comprises 2 chunks.  The initial nonpaged pool grows
    // up and the expansion nonpaged pool expands downward.
    //
    // Initial non-paged pool is constructed so virtual addresses
    // are also physically contiguous.
    //

    if ((MmSizeOfNonPagedPoolInBytes >> PAGE_SHIFT) >
                        (7 * (MmNumberOfPhysicalPages >> 3))) {

        //
        // More than 7/8 of memory allocated to nonpagedpool, reset to 0.
        //

        MmSizeOfNonPagedPoolInBytes = 0;
    }

    if (MmSizeOfNonPagedPoolInBytes < MmMinimumNonPagedPoolSize) {

        //
        // Calculate the size of nonpaged pool.
        // Use the minimum size, then for every MB above 16mb add extra pages.
        //

        MmSizeOfNonPagedPoolInBytes = MmMinimumNonPagedPoolSize;

        MmSizeOfNonPagedPoolInBytes +=
            ((MmNumberOfPhysicalPages - _x16mbnp)/_x1mbnp) *
            MmMinAdditionNonPagedPoolPerMb;
    }

    if (MmSizeOfNonPagedPoolInBytes > MM_MAX_INITIAL_NONPAGED_POOL) {
        MmSizeOfNonPagedPoolInBytes = MM_MAX_INITIAL_NONPAGED_POOL;
    }

    //
    // If the registry specifies a total nonpaged pool percentage cap, enforce
    // it here.
    //

    if (MmMaximumNonPagedPoolPercent != 0) {

        if (MmMaximumNonPagedPoolPercent < 5) {
            MmMaximumNonPagedPoolPercent = 5;
        }
        else if (MmMaximumNonPagedPoolPercent > 80) {
            MmMaximumNonPagedPoolPercent = 80;
        }

        //
        // Use the registry-expressed percentage value.
        //
    
        MaximumNonPagedPoolInBytesLimit =
            ((MmNumberOfPhysicalPages * MmMaximumNonPagedPoolPercent) / 100);

        MaximumNonPagedPoolInBytesLimit *= PAGE_SIZE;

        if (MaximumNonPagedPoolInBytesLimit < 6 * 1024 * 1024) {
            MaximumNonPagedPoolInBytesLimit = 6 * 1024 * 1024;
        }

        if (MmSizeOfNonPagedPoolInBytes > MaximumNonPagedPoolInBytesLimit) {
            MmSizeOfNonPagedPoolInBytes = MaximumNonPagedPoolInBytesLimit;
        }
    }
    
    MmSizeOfNonPagedPoolInBytes = MI_ROUND_TO_SIZE (MmSizeOfNonPagedPoolInBytes,
                                                    PAGE_SIZE);

    //
    // Don't let the initial nonpaged pool choice exceed what's actually
    // available.
    //

    if ((MmSizeOfNonPagedPoolInBytes >> PAGE_SHIFT) > MiFreeDescriptor->PageCount / 2) {
        MmSizeOfNonPagedPoolInBytes = (MiFreeDescriptor->PageCount / 2) << PAGE_SHIFT;
    }

    //
    // Compute the secondary color value, allowing overrides from the registry.
    // This is because the color arrays are going to be allocated at the end
    // of the PFN database.
    //

    MmSecondaryColors = MmSecondaryColors >> PAGE_SHIFT;

    if (MmSecondaryColors == 0) {
        MmSecondaryColors = MM_SECONDARY_COLORS_DEFAULT;
    }
    else {

        //
        // Make sure the value is power of two and within limits.
        //

        if (((MmSecondaryColors & (MmSecondaryColors -1)) != 0) ||
            (MmSecondaryColors < MM_SECONDARY_COLORS_MIN) ||
            (MmSecondaryColors > MM_SECONDARY_COLORS_MAX)) {
            MmSecondaryColors = MM_SECONDARY_COLORS_DEFAULT;
        }
    }

    MmSecondaryColorMask = MmSecondaryColors - 1;

#if defined(MI_MULTINODE)

    //
    // Determine number of bits in MmSecondayColorMask. This
    // is the number of bits the Node color must be shifted
    // by before it is included in colors.
    //

    i = MmSecondaryColorMask;
    MmSecondaryColorNodeShift = 0;
    while (i) {
        i >>= 1;
        MmSecondaryColorNodeShift += 1;
    }

    //
    // Adjust the number of secondary colors by the number of nodes
    // in the machine.  The secondary color mask is NOT adjusted
    // as it is used to control coloring within a node.  The node
    // color is added to the color AFTER normal color calculations
    // are performed.
    //

    MmSecondaryColors *= KeNumberNodes;

    for (i = 0; i < KeNumberNodes; i += 1) {
        KeNodeBlock[i]->Color = (ULONG)i;
        KeNodeBlock[i]->MmShiftedColor = (ULONG)(i << MmSecondaryColorNodeShift);
        InitializeSListHead(&KeNodeBlock[i]->DeadStackList);
    }

#endif

    //
    // Add in the PFN database size and the array for tracking secondary colors.
    //

    PfnAllocation = MI_ROUND_TO_SIZE (((MmHighestPossiblePhysicalPage + 1) * sizeof(MMPFN)) +
                    (MmSecondaryColors * sizeof(MMCOLOR_TABLES)*2),
                    PAGE_SIZE);


    NumberOfBytes = MmSizeOfNonPagedPoolInBytes + PfnAllocation;

    //
    // Align to large page size boundary, donating any extra to the nonpaged
    // pool.
    //

    NumberOfBytes = MI_ROUND_TO_SIZE (NumberOfBytes, MM_MINIMUM_VA_FOR_LARGE_PAGE);

    MmSizeOfNonPagedPoolInBytes = NumberOfBytes - PfnAllocation;

    MxPfnAllocation = PfnAllocation >> PAGE_SHIFT;

    //
    // Calculate the maximum size of pool.
    //

    if (MmMaximumNonPagedPoolInBytes == 0) {

        //
        // Calculate the size of nonpaged pool, adding extra pages for
        // every MB above 16mb.
        //

        MmMaximumNonPagedPoolInBytes = MmDefaultMaximumNonPagedPool;

        ASSERT (BYTE_OFFSET (MmMaximumNonPagedPoolInBytes) == 0);

        MmMaximumNonPagedPoolInBytes +=
            ((SIZE_T)((MmNumberOfPhysicalPages - _x16mbnp)/_x1mbnp) *
            MmMaxAdditionNonPagedPoolPerMb);

        if ((MmMaximumNonPagedPoolPercent != 0) &&
            (MmMaximumNonPagedPoolInBytes > MaximumNonPagedPoolInBytesLimit)) {

            MmMaximumNonPagedPoolInBytes = MaximumNonPagedPoolInBytesLimit;
        }
    }

    MmMaximumNonPagedPoolInBytes = MI_ROUND_TO_SIZE (MmMaximumNonPagedPoolInBytes,
                                                  MM_MINIMUM_VA_FOR_LARGE_PAGE);

    MmMaximumNonPagedPoolInBytes += NumberOfBytes;

    if (MmMaximumNonPagedPoolInBytes > MM_MAX_ADDITIONAL_NONPAGED_POOL) {
        MmMaximumNonPagedPoolInBytes = MM_MAX_ADDITIONAL_NONPAGED_POOL;
    }

    MiInitialLargePageSize = NumberOfBytes >> PAGE_SHIFT;

    if (MxPfnAllocation <= MiFreeDescriptor->PageCount / 2) {

        //
        // See if the free descriptor has enough pages of large page alignment
        // to satisfy our calculation.
        //

        BasePage = MI_ROUND_TO_SIZE (MiFreeDescriptor->BasePage,
                                     MM_MINIMUM_VA_FOR_LARGE_PAGE >> PAGE_SHIFT);

        LastPage = MiFreeDescriptor->BasePage + MiFreeDescriptor->PageCount;

        if ((BasePage < MiFreeDescriptor->BasePage) ||
            (BasePage + (NumberOfBytes >> PAGE_SHIFT) > LastPage)) {

            KeBugCheckEx (INSTALL_MORE_MEMORY,
                          NumberOfBytes >> PAGE_SHIFT,
                          MiFreeDescriptor->BasePage,
                          MiFreeDescriptor->PageCount,
                          2);
        }

        if (BasePage == MiFreeDescriptor->BasePage) {

            //
            // The descriptor starts on a large page aligned boundary so
            // remove the large page span from the bottom of the free descriptor.
            //

            MiInitialLargePage = BasePage;

            MiFreeDescriptor->BasePage += (ULONG) MiInitialLargePageSize;
            MiFreeDescriptor->PageCount -= (ULONG) MiInitialLargePageSize;
        }
        else {

            if ((LastPage & ((MM_MINIMUM_VA_FOR_LARGE_PAGE >> PAGE_SHIFT) - 1)) == 0) {
                //
                // The descriptor ends on a large page aligned boundary so
                // remove the large page span from the top of the free descriptor.
                //

                MiInitialLargePage = LastPage - MiInitialLargePageSize;

                MiFreeDescriptor->PageCount -= (ULONG) MiInitialLargePageSize;
            }
            else {

                //
                // The descriptor does not start or end on a large page aligned
                // address so chop the descriptor.  The excess slush is added to
                // the freelist by our caller.
                //

                MiSlushDescriptorBase = MiFreeDescriptor->BasePage;
                MiSlushDescriptorCount = BasePage - MiFreeDescriptor->BasePage;

                MiInitialLargePage = BasePage;

                MiFreeDescriptor->PageCount -= (ULONG) (MiInitialLargePageSize + MiSlushDescriptorCount);

                MiFreeDescriptor->BasePage = (ULONG) (BasePage + MiInitialLargePageSize);
            }
        }
    }
    else {

        //
        // Not enough contiguous physical memory in this machine to use large
        // pages for the PFN database and color heads so fall back to small.
        //
        // Continue to march on so the virtual sizes can still be computed
        // properly.
        //
        // Note this is not large page aligned so it can never be confused with
        // a valid large page start.
        //

        MiInitialLargePage = (PFN_NUMBER) -1;
    }

    MmPfnDatabase = (PMMPFN) ((PCHAR)MmNonPagedPoolEnd - MmMaximumNonPagedPoolInBytes);
    MmNonPagedPoolStart = (PVOID)((PCHAR) MmPfnDatabase + PfnAllocation);
    MmNonPagedPoolExpansionStart = (PVOID)((PCHAR) MmPfnDatabase +
                                    (MiInitialLargePageSize << PAGE_SHIFT));

    ASSERT (BYTE_OFFSET (MmNonPagedPoolStart) == 0);

    MmPageAlignedPoolBase[NonPagedPool] = MmNonPagedPoolStart;

    MmMaximumNonPagedPoolInBytes = ((PCHAR) MmNonPagedPoolEnd - (PCHAR) MmNonPagedPoolStart);

    MmMaximumNonPagedPoolInPages = (MmMaximumNonPagedPoolInBytes >> PAGE_SHIFT);

    return;
}

LOGICAL
MiIsRegularMemory (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock,
    IN PFN_NUMBER PageFrameIndex
    )

/*++

Routine Description:

    This routine checks whether the argument page frame index represents
    regular memory in the loader descriptor block.  It is only used very
    early during Phase0 init because the MmPhysicalMemoryBlock is not yet
    initialized.

Arguments:

    LoaderBlock  - Supplies a pointer to the firmware setup loader block.

    PageFrameIndex  - Supplies the page frame index to check.

Return Value:

    TRUE if the frame represents regular memory, FALSE if not.

Environment:

    Kernel mode.

--*/

{
    PLIST_ENTRY NextMd;
    PMEMORY_ALLOCATION_DESCRIPTOR MemoryDescriptor;

    NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;

    while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {

        MemoryDescriptor = CONTAINING_RECORD (NextMd,
                                              MEMORY_ALLOCATION_DESCRIPTOR,
                                              ListEntry);

        if (PageFrameIndex >= MemoryDescriptor->BasePage) {

            if (PageFrameIndex < MemoryDescriptor->BasePage + MemoryDescriptor->PageCount) {

                if ((MemoryDescriptor->MemoryType == LoaderFirmwarePermanent) ||
                    (MemoryDescriptor->MemoryType == LoaderBBTMemory) ||
                    (MemoryDescriptor->MemoryType == LoaderSpecialMemory)) {

                    //
                    // This page lies in a memory descriptor for which we will
                    // never create PFN entries, hence return FALSE.
                    //

                    break;
                }

                return TRUE;
            }
        }
        else {

            //
            // Since the loader memory list is sorted in ascending order,
            // the requested page must not be in the loader list at all.
            //

            break;
        }

        NextMd = MemoryDescriptor->ListEntry.Flink;
    }

    //
    // The final check before returning FALSE is to ensure that the requested
    // page wasn't one of the ones we used to normal-map the loader mappings,
    // etc.
    //

    if ((PageFrameIndex >= MiOldFreeDescriptorBase) &&
        (PageFrameIndex < MiOldFreeDescriptorBase + MiOldFreeDescriptorCount)) {

        return TRUE;
    }

    if ((PageFrameIndex >= MiSlushDescriptorBase) &&
        (PageFrameIndex < MiSlushDescriptorBase + MiSlushDescriptorCount)) {

        return TRUE;
    }

    return FALSE;
}


VOID
MiInitMachineDependent (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )

/*++

Routine Description:

    This routine performs the necessary operations to enable virtual
    memory.  This includes building the page directory page, building
    page table pages to map the code section, the data section, the
    stack section and the trap handler.

    It also initializes the PFN database and populates the free list.

Arguments:

    LoaderBlock  - Supplies a pointer to the firmware setup loader block.

Return Value:

    None.

Environment:

    Kernel mode.

    N.B.  This routine uses memory from the loader block descriptors, but
    the descriptors themselves must be restored prior to return as our caller
    walks them to create the MmPhysicalMemoryBlock.

--*/

{
    PMMPFN BasePfn;
    PMMPFN TopPfn;
    PMMPFN BottomPfn;
    SIZE_T Range;
    PFN_NUMBER BasePage;
    PFN_COUNT PageCount;
    PHYSICAL_ADDRESS MaxHotPlugMemoryAddress;
    PFN_COUNT FreeNextPhysicalPage;
    PFN_COUNT FreeNumberOfPages;
    PFN_NUMBER i;
    ULONG j;
    PFN_NUMBER PdePageNumber;
    PFN_NUMBER PdePage;
    PFN_NUMBER PpePage;
    PFN_NUMBER PageFrameIndex;
    PFN_NUMBER NextPhysicalPage;
    SPFN_NUMBER PfnAllocation;
    SIZE_T MaxPool;
    PEPROCESS CurrentProcess;
    PFN_NUMBER MostFreePage;
    PLIST_ENTRY NextMd;
    PMEMORY_ALLOCATION_DESCRIPTOR MemoryDescriptor;
    MMPTE TempPde;
    MMPTE TempPte;
    PMMPTE PointerPde;
    PMMPTE PointerPte;
    PMMPTE LastPte;
    PMMPTE Pde;
    PMMPTE StartPde;
    PMMPTE StartPpe;
    PMMPTE EndPde;
    PMMPFN Pfn1;
    PMMPFN Pfn2;
    PMMPFN Pfn3;
    ULONG First;
    PVOID SystemPteStart;
    ULONG ReturnedLength;
    NTSTATUS status;
    PTR_INFO ItrInfo;

    MostFreePage = 0;

    //
    // Initialize some variables so they do not need to be constantly
    // recalculated throughout the life of the system.
    //

    MiMaxWow64Pte = (PVOID) MiGetPteAddress ((PVOID)_4gb);

    //
    // Initialize the kernel mapping info.
    //

    ItrInfo = &LoaderBlock->u.Ia64.ItrInfo[ITR_KERNEL_INDEX];

    MiNtoskrnlPhysicalBase = ItrInfo->PhysicalAddress;
    MiNtoskrnlVirtualBase = ItrInfo->VirtualAddress;
    MiNtoskrnlPageShift = ItrInfo->PageSize;

    //
    // Initialize MmDebugPte and MmCrashDumpPte.
    //

    MmDebugPte = MiGetPteAddress (MM_DEBUG_VA);

    MmCrashDumpPte = MiGetPteAddress (MM_CRASH_DUMP_VA);

    //
    // Set TempPte to ValidKernelPte for future use.
    //

    TempPte = ValidKernelPte;

    //
    // Compact the memory descriptor list from the loader.
    //

    MiCompactMemoryDescriptorList (LoaderBlock);

    //
    // Get the lower bound of the free physical memory and the
    // number of physical pages by walking the memory descriptor lists.
    //

    NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;

    while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {

        MemoryDescriptor = CONTAINING_RECORD (NextMd,
                                              MEMORY_ALLOCATION_DESCRIPTOR,
                                              ListEntry);

        if ((MemoryDescriptor->MemoryType != LoaderBBTMemory) &&
            (MemoryDescriptor->MemoryType != LoaderFirmwarePermanent) &&
            (MemoryDescriptor->MemoryType != LoaderSpecialMemory)) {

            BasePage = MemoryDescriptor->BasePage;
            PageCount = MemoryDescriptor->PageCount;

            //
            // This check results in /BURNMEMORY chunks not being counted.
            //

            if (MemoryDescriptor->MemoryType != LoaderBad) {
                MmNumberOfPhysicalPages += PageCount;
            }

            if (BasePage < MmLowestPhysicalPage) {
                MmLowestPhysicalPage = BasePage;
            }

            if (MemoryDescriptor->MemoryType != LoaderBad) {
                if ((BasePage + PageCount) > MmHighestPhysicalPage) {
                    MmHighestPhysicalPage = BasePage + PageCount -1;
                }
            }

            if ((MemoryDescriptor->MemoryType == LoaderFree) ||
                (MemoryDescriptor->MemoryType == LoaderLoadedProgram) ||
                (MemoryDescriptor->MemoryType == LoaderFirmwareTemporary) ||
                (MemoryDescriptor->MemoryType == LoaderOsloaderStack)) {

                //
                // Deliberately use >= instead of just > to force our allocation
                // as high as physically possible.  This is to leave low pages
                // for drivers which may require them.
                //

                if (PageCount >= MostFreePage) {
                    MostFreePage = PageCount;
                    MiFreeDescriptor = MemoryDescriptor;
                }
            }
        }

        NextMd = MemoryDescriptor->ListEntry.Flink;
    }

    if (MiFreeDescriptor == NULL) {
        KeBugCheckEx (INSTALL_MORE_MEMORY,
                      MmNumberOfPhysicalPages,
                      MmLowestPhysicalPage,
                      MmHighestPhysicalPage,
                      1);
    }

    //
    // MmDynamicPfn may have been initialized based on the registry to
    // a value representing the highest physical address in gigabytes.
    //

    MmDynamicPfn *= ((1024 * 1024 * 1024) / PAGE_SIZE);

    //
    // Retrieve highest hot plug memory range from the HAL if
    // available and not otherwise retrieved from the registry.
    //

    if (MmDynamicPfn == 0) {

        status = HalQuerySystemInformation (HalQueryMaxHotPlugMemoryAddress,
                                            sizeof(PHYSICAL_ADDRESS),
                                            (PPHYSICAL_ADDRESS) &MaxHotPlugMemoryAddress,
                                            &ReturnedLength);

        if (NT_SUCCESS(status)) {
            ASSERT (ReturnedLength == sizeof(PHYSICAL_ADDRESS));

            MmDynamicPfn = (PFN_NUMBER) (MaxHotPlugMemoryAddress.QuadPart / PAGE_SIZE);
        }
    }

    if (MmDynamicPfn != 0) {
        MmHighestPossiblePhysicalPage = MI_DTC_MAX_PAGES - 1;
        if (MmDynamicPfn - 1 < MmHighestPossiblePhysicalPage) {
            if (MmDynamicPfn - 1 < MmHighestPhysicalPage) {
                MmDynamicPfn = MmHighestPhysicalPage + 1;
            }
            MmHighestPossiblePhysicalPage = MmDynamicPfn - 1;
        }
    }
    else {
        MmHighestPossiblePhysicalPage = MmHighestPhysicalPage;
    }

    //
    // Only machines with at least 5GB of physical memory get to use this.
    //

    if (strstr(LoaderBlock->LoadOptions, "NOLOWMEM")) {
        if (MmNumberOfPhysicalPages >= ((ULONGLONG)5 * 1024 * 1024 * 1024 / PAGE_SIZE)) {
            MiNoLowMemory = (PFN_NUMBER)((ULONGLONG)_4gb / PAGE_SIZE);
        }
    }

    if (MiNoLowMemory != 0) {
        MmMakeLowMemory = TRUE;
    }

    // 
    // Initialize the Phase0 page allocation structures.
    //

    MiOldFreeDescriptorCount = MiFreeDescriptor->PageCount;
    MiOldFreeDescriptorBase = MiFreeDescriptor->BasePage;

    //
    // Compute the size of the initial nonpaged pool and the PFN database.
    // This is because we will remove this amount from the free descriptor
    // first and subsequently map it with large TB entries (so it requires
    // natural alignment & size, thus take it before other allocations chip
    // away at the descriptor).
    //

    MiComputeInitialLargePage ();

    //
    // Build the parent directory page table for kernel space.
    //

    PdePageNumber = (PFN_NUMBER)LoaderBlock->u.Ia64.PdrPage;

    MmSystemParentTablePage = MiGetNextPhysicalPage ();

    RtlZeroMemory (KSEG_ADDRESS(MmSystemParentTablePage), PAGE_SIZE);

    TempPte.u.Hard.PageFrameNumber = MmSystemParentTablePage;

    MiSystemSelfMappedPte = TempPte;

    KeFillFixedEntryTb ((PHARDWARE_PTE)&TempPte,
                        (PVOID)PDE_KTBASE,
                        PAGE_SHIFT,
                        DTR_KTBASE_INDEX_TMP);

    //
    // Initialize the selfmap PPE entry in the kernel parent directory table.
    //

    PointerPte = MiGetPteAddress ((PVOID)PDE_KTBASE);

    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Initialize the kernel image PPE entry in the parent directory table.
    //

    PointerPte = MiGetPteAddress ((PVOID)PDE_KBASE);

    TempPte.u.Hard.PageFrameNumber = PdePageNumber;

    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Build the parent directory page table for user space.
    //

    NextPhysicalPage = MiGetNextPhysicalPage ();

    RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);

    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;

    CurrentProcess = PsGetCurrentProcess ();

    INITIALIZE_DIRECTORY_TABLE_BASE (&CurrentProcess->Pcb.DirectoryTableBase[0],
                                     NextPhysicalPage);

    MiUserSelfMappedPte = TempPte;

    KeFillFixedEntryTb ((PHARDWARE_PTE)&TempPte,
                        (PVOID)PDE_UTBASE,
                        PAGE_SHIFT,
                        DTR_UTBASE_INDEX_TMP);

    //
    // Initialize the selfmap PPE entry in the user parent directory table.
    //

    PointerPte = MiGetPteAddress ((PVOID)PDE_UTBASE);

    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Build the parent directory page table for win32k (session) space.
    //
    // TS will only allocate a map for session space when each one is
    // actually created by smss.
    //
    // Note TS never maps session space into the system process.
    // The system process is kept Hydra-free so that trims can happen
    // properly and also so that renegade worker items are caught.
    //

    NextPhysicalPage = MiGetNextPhysicalPage ();

    RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);

    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;

    MmSessionParentTablePage = NextPhysicalPage;

    INITIALIZE_DIRECTORY_TABLE_BASE (&CurrentProcess->Pcb.SessionParentBase,
                                     NextPhysicalPage);

    KeFillFixedEntryTb ((PHARDWARE_PTE)&TempPte,
                        (PVOID)PDE_STBASE,
                        PAGE_SHIFT,
                        DTR_STBASE_INDEX);

    //
    // Initialize the selfmap PPE entry in the Hydra parent directory table.
    //

    PointerPte = MiGetPteAddress ((PVOID)PDE_STBASE);

    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Initialize the default PPE for the unused regions.
    //

    NextPhysicalPage = MiGetNextPhysicalPage ();

    PointerPte = KSEG_ADDRESS(NextPhysicalPage);

    RtlZeroMemory ((PVOID)PointerPte, PAGE_SIZE);

    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
    
    MiDefaultPpe = TempPte;

    PointerPte[MiGetPpeOffset(PDE_TBASE)] = TempPte;

    //
    // Build a PTE for the EPC page so an accidental ITR purge doesn't
    // render things undebuggable.
    //

    PointerPte = MiGetPteAddress((PVOID)MM_EPC_VA);

    TempPte.u.Hard.PageFrameNumber = 
        MI_CONVERT_PHYSICAL_TO_PFN((PVOID)((PPLABEL_DESCRIPTOR)(ULONG_PTR)KiNormalSystemCall)->EntryPoint);
    
    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Build a PTE for the PCR page so an accidental ITR purge doesn't
    // render things undebuggable.  
    //

    PointerPte = MiGetPteAddress ((PVOID)KIPCR);
    
    TempPte.u.Hard.PageFrameNumber = MI_CONVERT_PHYSICAL_TO_PFN (KiProcessorBlock[0]);

    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Initialize the NAT Page entry for null address references.
    //

    TempPte.u.Hard.PageFrameNumber = MiGetNextPhysicalPage ();

    TempPte.u.Hard.Cache = MM_PTE_CACHE_NATPAGE;

    MiNatPte = TempPte;

    //
    // Calculate the starting address for the system PTE pool which is
    // right below the nonpaged pool.
    //

    MmNonPagedSystemStart = (PVOID)(((ULONG_PTR)MmPfnDatabase -
                            (((ULONG_PTR)MmNumberOfSystemPtes + 1) * PAGE_SIZE)) &
                             (~PAGE_DIRECTORY2_MASK));

    if (MmNonPagedSystemStart < MM_LOWEST_NONPAGED_SYSTEM_START) {
        MmNonPagedSystemStart = MM_LOWEST_NONPAGED_SYSTEM_START;

        MmNumberOfSystemPtes = (ULONG)(((ULONG_PTR)MmPfnDatabase -
                            (ULONG_PTR)MmNonPagedSystemStart) >> PAGE_SHIFT)-1;

        ASSERT (MmNumberOfSystemPtes > 1000);
    }

    //
    // Snap the system PTE start address as page directories and tables
    // will be preallocated for this range.
    //

    SystemPteStart = (PVOID) MmNonPagedSystemStart;

    //
    // If special pool and/or the driver verifier is enabled, reserve
    // extra virtual address space for special pooling now.  For now,
    // arbitrarily don't let it be larger than paged pool (128gb).
    //

    if ((MmVerifyDriverBufferLength != (ULONG)-1) ||
        ((MmSpecialPoolTag != 0) && (MmSpecialPoolTag != (ULONG)-1))) {

        if (MmNonPagedSystemStart > MM_LOWEST_NONPAGED_SYSTEM_START) {

            MaxPool = (ULONG_PTR)MmNonPagedSystemStart -
                      (ULONG_PTR)MM_LOWEST_NONPAGED_SYSTEM_START;
            if (MaxPool > MM_MAX_PAGED_POOL) {
                MaxPool = MM_MAX_PAGED_POOL;
            }
            MmNonPagedSystemStart = (PVOID)((ULONG_PTR)MmNonPagedSystemStart - MaxPool);
        }
        else {

            //
            // This is a pretty large machine.  Take some of the system
            // PTEs and reuse them for special pool.
            //

            MaxPool = (4 * _x4gb);
            ASSERT ((PVOID)MmPfnDatabase > (PVOID)((PCHAR)MmNonPagedSystemStart + MaxPool));
            SystemPteStart = (PVOID)((PCHAR)MmNonPagedSystemStart + MaxPool);

            MmNumberOfSystemPtes = (ULONG)(((ULONG_PTR)MmPfnDatabase -
                            (ULONG_PTR) SystemPteStart) >> PAGE_SHIFT)-1;

        }
        MmSpecialPoolStart = MmNonPagedSystemStart;
        MmSpecialPoolEnd = (PVOID)((ULONG_PTR)MmNonPagedSystemStart + MaxPool);
    }

    //
    // Map the hyper space page directory page into the top level parent
    // directory & the hyper space page table page into the page directory.
    // Additional page parents, directories & tables are set up later
    // on during individual process working set initialization.
    //

    TempPte = ValidPdePde;
    StartPpe = MiGetPpeAddress (HYPER_SPACE);

    if (StartPpe->u.Hard.Valid == 0) {
        ASSERT (StartPpe->u.Long == 0);
        NextPhysicalPage = MiGetNextPhysicalPage ();
        RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
        TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
        MI_WRITE_VALID_PTE (StartPpe, TempPte);
    }

    StartPde = MiGetPdeAddress (HYPER_SPACE);
    NextPhysicalPage = MiGetNextPhysicalPage ();
    RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
    MI_WRITE_VALID_PTE (StartPde, TempPte);

    //
    // Allocate page directory pages for the initial large page allocation.
    // Initial nonpaged pool, the PFN database & the color arrays will be put
    // here.
    //

    TempPte = ValidKernelPte;
    TempPde = ValidKernelPde;

    PageFrameIndex = MiInitialLargePage;

    if (MiInitialLargePage != (PFN_NUMBER) -1) {
        StartPpe = MiGetPpeAddress (MmPfnDatabase);
        StartPde = MiGetPdeAddress (MmPfnDatabase);
        EndPde = MiGetPdeAddress ((PVOID)((ULONG_PTR)MmPfnDatabase +
                    (MiInitialLargePageSize << PAGE_SHIFT) - 1));

        MI_MAKE_PDE_MAP_LARGE_PAGE (&TempPde);

        RtlZeroMemory (KSEG_ADDRESS(PageFrameIndex),
                       MiInitialLargePageSize << PAGE_SHIFT);
    }
    else {
        StartPpe = MiGetPpeAddress (MmNonPagedPoolStart);
        StartPde = MiGetPdeAddress (MmNonPagedPoolStart);
        EndPde = MiGetPdeAddress ((PVOID)((ULONG_PTR)MmNonPagedPoolStart +
                    (MmSizeOfNonPagedPoolInBytes - 1)));
    }

    First = (StartPpe->u.Hard.Valid == 0) ? TRUE : FALSE;

    while (StartPde <= EndPde) {

        if (First == TRUE || MiIsPteOnPdeBoundary(StartPde)) {
            First = FALSE;
            StartPpe = MiGetPteAddress(StartPde);
            if (StartPpe->u.Hard.Valid == 0) {
                NextPhysicalPage = MiGetNextPhysicalPage ();
                RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                MI_WRITE_VALID_PTE (StartPpe, TempPte);
            }
        }

        ASSERT (StartPde->u.Hard.Valid == 0);

        if (MiInitialLargePage != (PFN_NUMBER) -1) {
            TempPde.u.Hard.PageFrameNumber = PageFrameIndex;
            PageFrameIndex += (MM_VA_MAPPED_BY_PDE >> PAGE_SHIFT);
            MI_WRITE_VALID_PTE (StartPde, TempPde);
        }
        else {

            //
            // Allocate a page table page here since we're not using large
            // pages.
            //

            NextPhysicalPage = MiGetNextPhysicalPage ();
            RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
            TempPde.u.Hard.PageFrameNumber = NextPhysicalPage;
            MI_WRITE_VALID_PTE (StartPde, TempPde);

            //
            // Allocate data pages here since we're not using large pages.
            //

            PointerPte = MiGetVirtualAddressMappedByPte (StartPde);

            for (i = 0; i < PTE_PER_PAGE; i += 1) {
                NextPhysicalPage = MiGetNextPhysicalPage ();
                RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                MI_WRITE_VALID_PTE (PointerPte, TempPte);
                PointerPte += 1;
            }
        }

        StartPde += 1;
    }

    //
    // Allocate page directory and page table pages for system PTEs and
    // expansion nonpaged pool (but not the special pool area).  Note
    // the initial nonpaged pool, PFN database & color arrays initialized
    // above are skipped here by virtue of their PPE/PDEs being valid.
    //

    TempPte = ValidKernelPte;
    StartPpe = MiGetPpeAddress (SystemPteStart);
    StartPde = MiGetPdeAddress (SystemPteStart);
    EndPde = MiGetPdeAddress ((PVOID)((ULONG_PTR)MmNonPagedPoolEnd - 1));
    First = (StartPpe->u.Hard.Valid == 0) ? TRUE : FALSE;

    while (StartPde <= EndPde) {

        if (First == TRUE || MiIsPteOnPdeBoundary(StartPde)) {
            First = FALSE;
            StartPpe = MiGetPteAddress(StartPde);
            if (StartPpe->u.Hard.Valid == 0) {
                NextPhysicalPage = MiGetNextPhysicalPage ();
                RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                MI_WRITE_VALID_PTE (StartPpe, TempPte);
            }
        }

        if (StartPde->u.Hard.Valid == 0) {
            NextPhysicalPage = MiGetNextPhysicalPage ();
            RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
            TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
            MI_WRITE_VALID_PTE (StartPde, TempPte);
        }
        StartPde += 1;
    }

    MiBuildPageTableForLoaderMemory (LoaderBlock);

    MiRemoveLoaderSuperPages (LoaderBlock);

    //
    // Remove the temporary super pages for the root page table pages,
    // and remap them with DTR_KTBASE_INDEX and DTR_UTBASE_INDEX.
    //

    KiFlushFixedDataTb (FALSE, (PVOID)PDE_KTBASE);

    KiFlushFixedDataTb (FALSE, (PVOID)PDE_UTBASE);

    KeFillFixedEntryTb ((PHARDWARE_PTE)&MiSystemSelfMappedPte,
                        (PVOID)PDE_KTBASE,
                        PAGE_SHIFT,
                        DTR_KTBASE_INDEX);

    KeFillFixedEntryTb ((PHARDWARE_PTE)&MiUserSelfMappedPte,
                        (PVOID)PDE_UTBASE,
                        PAGE_SHIFT,
                        DTR_UTBASE_INDEX);

    MiInitializeTbImage ();
    MiMappingsInitialized = TRUE;

    //
    // As only the initial nonpaged pool is mapped through superpages,
    // MmSubsectionTopPage is always set to zero.
    //

    MmSubsectionBase = (ULONG_PTR) MmNonPagedPoolStart;
    MmSubsectionTopPage = 0;

    //
    // Add the array for tracking secondary colors to the end of
    // the PFN database.
    //

    MmFreePagesByColor[0] = (PMMCOLOR_TABLES)
                            &MmPfnDatabase[MmHighestPossiblePhysicalPage + 1];

    if (MiInitialLargePage == (PFN_NUMBER) -1) {

        //
        // Large pages were not used because this machine's physical memory
        // was not contiguous enough.
        //
        // Go through the memory descriptors and for each physical page make
        // sure the PFN database has a valid PTE to map it.  This allows
        // machines with sparse physical memory to have a minimal PFN database.
        //

        FreeNextPhysicalPage = MiFreeDescriptor->BasePage;
        FreeNumberOfPages = MiFreeDescriptor->PageCount;

        NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;

        while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {

            MemoryDescriptor = CONTAINING_RECORD(NextMd,
                                                 MEMORY_ALLOCATION_DESCRIPTOR,
                                                 ListEntry);

            if ((MemoryDescriptor->MemoryType == LoaderFirmwarePermanent) ||
                (MemoryDescriptor->MemoryType == LoaderBBTMemory) ||
                (MemoryDescriptor->MemoryType == LoaderSpecialMemory)) {

                //
                // Skip these ranges.
                //

                NextMd = MemoryDescriptor->ListEntry.Flink;
                continue;
            }

            //
            // Temporarily add back in the memory allocated since Phase 0
            // began so PFN entries for it will be created and mapped.
            //
            // Note actual PFN entry allocations must be done carefully as
            // memory from the descriptor itself could get used to map
            // the PFNs for the descriptor !
            //

            if (MemoryDescriptor == MiFreeDescriptor) {
                BasePage = MiOldFreeDescriptorBase;
                PageCount = (PFN_COUNT) MiOldFreeDescriptorCount;
            }
            else {
                BasePage = MemoryDescriptor->BasePage;
                PageCount = MemoryDescriptor->PageCount;
            }

            PointerPte = MiGetPteAddress (MI_PFN_ELEMENT(BasePage));

            LastPte = MiGetPteAddress (((PCHAR)(MI_PFN_ELEMENT(
                                            BasePage + PageCount))) - 1);

            while (PointerPte <= LastPte) {

                StartPpe = MiGetPdeAddress (PointerPte);

                if (StartPpe->u.Hard.Valid == 0) {
                    TempPte.u.Hard.PageFrameNumber = FreeNextPhysicalPage;
                    ASSERT (FreeNumberOfPages != 0);
                    FreeNextPhysicalPage += 1;
                    FreeNumberOfPages -= 1;
                    if (FreeNumberOfPages == 0) {
                        KeBugCheckEx (INSTALL_MORE_MEMORY,
                                      MmNumberOfPhysicalPages,
                                      FreeNumberOfPages,
                                      MiOldFreeDescriptorCount,
                                      3);
                    }
                    MI_WRITE_VALID_PTE (StartPpe, TempPte);
                    RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPpe),
                                   PAGE_SIZE);
                }

                StartPde = MiGetPteAddress (PointerPte);

                if (StartPde->u.Hard.Valid == 0) {
                    TempPte.u.Hard.PageFrameNumber = FreeNextPhysicalPage;
                    ASSERT (FreeNumberOfPages != 0);
                    FreeNextPhysicalPage += 1;
                    FreeNumberOfPages -= 1;
                    if (FreeNumberOfPages == 0) {
                        KeBugCheckEx (INSTALL_MORE_MEMORY,
                                      MmNumberOfPhysicalPages,
                                      FreeNumberOfPages,
                                      MiOldFreeDescriptorCount,
                                      3);
                    }
                    MI_WRITE_VALID_PTE (StartPde, TempPte);
                    RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPde),
                                   PAGE_SIZE);
                }

                if (PointerPte->u.Hard.Valid == 0) {
                    TempPte.u.Hard.PageFrameNumber = FreeNextPhysicalPage;
                    ASSERT (FreeNumberOfPages != 0);
                    FreeNextPhysicalPage += 1;
                    FreeNumberOfPages -= 1;
                    if (FreeNumberOfPages == 0) {
                        KeBugCheckEx (INSTALL_MORE_MEMORY,
                                      MmNumberOfPhysicalPages,
                                      FreeNumberOfPages,
                                      MiOldFreeDescriptorCount,
                                      3);
                    }
                    MI_WRITE_VALID_PTE (PointerPte, TempPte);
                    RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPte),
                                   PAGE_SIZE);
                }
                PointerPte += 1;
            }

            NextMd = MemoryDescriptor->ListEntry.Flink;
        }

        //
        // Ensure the color arrays are mapped.
        //

        PointerPte = MiGetPteAddress (MmFreePagesByColor[0]);
        LastPte = MiGetPteAddress (&MmFreePagesByColor[StandbyPageList][MmSecondaryColors]);
        if (LastPte != PAGE_ALIGN (LastPte)) {
            LastPte += 1;
        }

        StartPpe = MiGetPdeAddress (PointerPte);
        PointerPde = MiGetPteAddress (PointerPte);

        while (PointerPte < LastPte) {

            if (StartPpe->u.Hard.Valid == 0) {
                TempPte.u.Hard.PageFrameNumber = FreeNextPhysicalPage;
                ASSERT (FreeNumberOfPages != 0);
                FreeNextPhysicalPage += 1;
                FreeNumberOfPages -= 1;
                if (FreeNumberOfPages == 0) {
                    KeBugCheckEx (INSTALL_MORE_MEMORY,
                                  MmNumberOfPhysicalPages,
                                  FreeNumberOfPages,
                                  MiOldFreeDescriptorCount,
                                  3);
                }
                MI_WRITE_VALID_PTE (StartPpe, TempPte);
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (StartPpe), PAGE_SIZE);
            }

            if (PointerPde->u.Hard.Valid == 0) {
                TempPte.u.Hard.PageFrameNumber = FreeNextPhysicalPage;
                ASSERT (FreeNumberOfPages != 0);
                FreeNextPhysicalPage += 1;
                FreeNumberOfPages -= 1;
                if (FreeNumberOfPages == 0) {
                    KeBugCheckEx (INSTALL_MORE_MEMORY,
                                  MmNumberOfPhysicalPages,
                                  FreeNumberOfPages,
                                  MiOldFreeDescriptorCount,
                                  3);
                }
                MI_WRITE_VALID_PTE (PointerPde, TempPte);
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPde), PAGE_SIZE);
            }

            if (PointerPte->u.Hard.Valid == 0) {
                TempPte.u.Hard.PageFrameNumber = FreeNextPhysicalPage;
                ASSERT (FreeNumberOfPages != 0);
                FreeNextPhysicalPage += 1;
                FreeNumberOfPages -= 1;
                if (FreeNumberOfPages == 0) {
                    KeBugCheckEx (INSTALL_MORE_MEMORY,
                                  MmNumberOfPhysicalPages,
                                  FreeNumberOfPages,
                                  MiOldFreeDescriptorCount,
                                  3);
                }
                MI_WRITE_VALID_PTE (PointerPte, TempPte);
                RtlZeroMemory (MiGetVirtualAddressMappedByPte (PointerPte), PAGE_SIZE);
            }

            PointerPte += 1;
            if (MiIsPteOnPdeBoundary (PointerPte)) {
                PointerPde += 1;
                if (MiIsPteOnPdeBoundary (PointerPde)) {
                    StartPpe += 1;
                }
            }
        }

        //
        // Adjust the free descriptor for all the pages we just took.
        //

        MiFreeDescriptor->PageCount -= (FreeNextPhysicalPage - MiFreeDescriptor->BasePage);

        MiFreeDescriptor->BasePage = FreeNextPhysicalPage;
    }

    //
    // Non-paged pages now exist, build the pool structures.
    //
    // Before nonpaged pool can be used, the PFN database must
    // be built.  This is due to the fact that the start and end of
    // allocation bits for nonpaged pool are maintained in the
    // PFN elements for the corresponding pages.
    //

    MiInitializeNonPagedPool ();
    MiInitializeNonPagedPoolThresholds ();

    if (MiInitialLargePage != (PFN_NUMBER) -1) {

        //
        // Add the initial large page range to the translation register list.
        //

        MiAddTrEntry ((ULONG_PTR)MmPfnDatabase,
                      (ULONG_PTR)MmPfnDatabase + (MiInitialLargePageSize << PAGE_SHIFT));

        MiAddCachedRange (MiInitialLargePage,
                          MiInitialLargePage + MiInitialLargePageSize - 1);
    }

    MmFreePagesByColor[1] = &MmFreePagesByColor[0][MmSecondaryColors];

    //
    // Initialize support for colored pages.
    //

    for (i = 0; i < MmSecondaryColors; i += 1) {
        MmFreePagesByColor[ZeroedPageList][i].Flink = MM_EMPTY_LIST;
        MmFreePagesByColor[ZeroedPageList][i].Blink = (PVOID) MM_EMPTY_LIST;
        MmFreePagesByColor[ZeroedPageList][i].Count = 0;
        MmFreePagesByColor[FreePageList][i].Flink = MM_EMPTY_LIST;
        MmFreePagesByColor[FreePageList][i].Blink = (PVOID) MM_EMPTY_LIST;
        MmFreePagesByColor[FreePageList][i].Count = 0;
    }

#if MM_MAXIMUM_NUMBER_OF_COLORS > 1
    for (i = 0; i < MM_MAXIMUM_NUMBER_OF_COLORS; i += 1) {
        MmFreePagesByPrimaryColor[ZeroedPageList][i].ListName = ZeroedPageList;
        MmFreePagesByPrimaryColor[FreePageList][i].ListName = FreePageList;
        MmFreePagesByPrimaryColor[ZeroedPageList][i].Flink = MM_EMPTY_LIST;
        MmFreePagesByPrimaryColor[FreePageList][i].Flink = MM_EMPTY_LIST;
        MmFreePagesByPrimaryColor[ZeroedPageList][i].Blink = MM_EMPTY_LIST;
        MmFreePagesByPrimaryColor[FreePageList][i].Blink = MM_EMPTY_LIST;
    }
#endif

    //
    // Go through the page table entries for hyper space and for any page
    // which is valid, update the corresponding PFN database element.
    //

    StartPde = MiGetPdeAddress (HYPER_SPACE);
    StartPpe = MiGetPpeAddress (HYPER_SPACE);
    EndPde = MiGetPdeAddress(HYPER_SPACE_END);

    if (StartPpe->u.Hard.Valid == 0) {
        First = TRUE;
        PdePage = 0;
        Pfn1 = NULL;
    }
    else {
        First = FALSE;
        PdePage = MI_GET_PAGE_FRAME_FROM_PTE (StartPpe);
        if (MiIsRegularMemory (LoaderBlock, PdePage)) {
            Pfn1 = MI_PFN_ELEMENT(PdePage);
        }
        else {
            Pfn1 = NULL;
        }
    }

    while (StartPde <= EndPde) {

        if (First == TRUE || MiIsPteOnPdeBoundary(StartPde)) {
            First = FALSE;
            StartPpe = MiGetPteAddress(StartPde);
            if (StartPpe->u.Hard.Valid == 0) {
                StartPpe += 1;
                StartPde = MiGetVirtualAddressMappedByPte (StartPpe);
                continue;
            }

            PdePage = MI_GET_PAGE_FRAME_FROM_PTE(StartPpe);

            if (MiIsRegularMemory (LoaderBlock, PdePage)) {

                Pfn1 = MI_PFN_ELEMENT(PdePage);
                Pfn1->u4.PteFrame = MmSystemParentTablePage;
                Pfn1->PteAddress = StartPde;
                Pfn1->u2.ShareCount += 1;
                Pfn1->u3.e2.ReferenceCount = 1;
                Pfn1->u3.e1.PageLocation = ActiveAndValid;
                Pfn1->u3.e1.CacheAttribute = MiCached;
                Pfn1->u3.e1.PageColor =
                 MI_GET_COLOR_FROM_SECONDARY(GET_PAGE_COLOR_FROM_PTE(StartPpe));
            }
        }


        if (StartPde->u.Hard.Valid == 1) {
            PdePage = MI_GET_PAGE_FRAME_FROM_PTE(StartPde);
            PointerPde = MiGetPteAddress(StartPde);
            Pfn2 = MI_PFN_ELEMENT(PdePage);

            if (MiIsRegularMemory (LoaderBlock, PdePage)) {

                Pfn2->u4.PteFrame = MI_GET_PAGE_FRAME_FROM_PTE(PointerPde);
                ASSERT (MiIsRegularMemory (LoaderBlock, Pfn2->u4.PteFrame));
                Pfn2->PteAddress = StartPde;
                Pfn2->u2.ShareCount += 1;
                Pfn2->u3.e2.ReferenceCount = 1;
                Pfn2->u3.e1.PageLocation = ActiveAndValid;
                Pfn2->u3.e1.CacheAttribute = MiCached;
                Pfn2->u3.e1.PageColor =
                MI_GET_COLOR_FROM_SECONDARY(GET_PAGE_COLOR_FROM_PTE (StartPde));
            }

            PointerPte = MiGetVirtualAddressMappedByPte(StartPde);
            for (j = 0 ; j < PTE_PER_PAGE; j += 1) {
                if (PointerPte->u.Hard.Valid == 1) {

                    ASSERT (MiIsRegularMemory (LoaderBlock, PdePage));

                    Pfn2->u2.ShareCount += 1;

                    if (MiIsRegularMemory (LoaderBlock, PointerPte->u.Hard.PageFrameNumber)) {
                        Pfn3 = MI_PFN_ELEMENT(PointerPte->u.Hard.PageFrameNumber);
                        Pfn3->u4.PteFrame = PdePage;
                        Pfn3->PteAddress = PointerPte;
                        Pfn3->u2.ShareCount += 1;
                        Pfn3->u3.e2.ReferenceCount = 1;
                        Pfn3->u3.e1.PageLocation = ActiveAndValid;
                        Pfn3->u3.e1.CacheAttribute = MiCached;
                        Pfn3->u3.e1.PageColor =
                            MI_GET_COLOR_FROM_SECONDARY(
                                                  MI_GET_PAGE_COLOR_FROM_PTE (
                                                        PointerPte));
                    }
                }
                PointerPte += 1;
            }
        }

        StartPde += 1;
    }

    //
    // Go through the page table entries for kernel space and for any page
    // which is valid, update the corresponding PFN database element.
    //

    StartPde = MiGetPdeAddress ((PVOID)KADDRESS_BASE);
    StartPpe = MiGetPpeAddress ((PVOID)KADDRESS_BASE);
    EndPde = MiGetPdeAddress((PVOID)MM_SYSTEM_SPACE_END);
    if (StartPpe->u.Hard.Valid == 0) {
        First = TRUE;
        PpePage = 0;
        Pfn1 = NULL;
    }
    else {
        First = FALSE;
        PpePage = MI_GET_PAGE_FRAME_FROM_PTE (StartPpe);
        if (MiIsRegularMemory (LoaderBlock, PpePage)) {
            Pfn1 = MI_PFN_ELEMENT(PpePage);
        }
        else {
            Pfn1 = NULL;
        }
    }

    while (StartPde <= EndPde) {

        if (First == TRUE || MiIsPteOnPdeBoundary(StartPde)) {
            First = FALSE;
            StartPpe = MiGetPteAddress(StartPde);
            if (StartPpe->u.Hard.Valid == 0) {
                StartPpe += 1;
                StartPde = MiGetVirtualAddressMappedByPte (StartPpe);
                continue;
            }

            PpePage = MI_GET_PAGE_FRAME_FROM_PTE(StartPpe);

            if (MiIsRegularMemory (LoaderBlock, PpePage)) {

                Pfn1 = MI_PFN_ELEMENT(PpePage);
                Pfn1->u4.PteFrame = MmSystemParentTablePage;
                Pfn1->PteAddress = StartPpe;
                Pfn1->u2.ShareCount += 1;
                Pfn1->u3.e2.ReferenceCount = 1;
                Pfn1->u3.e1.PageLocation = ActiveAndValid;
                Pfn1->u3.e1.CacheAttribute = MiCached;
                Pfn1->u3.e1.PageColor =
                  MI_GET_COLOR_FROM_SECONDARY(GET_PAGE_COLOR_FROM_PTE(StartPpe));
            }
            else {
                Pfn1 = NULL;
            }
        }

        if (StartPde->u.Hard.Valid == 1) {

            if (MI_PDE_MAPS_LARGE_PAGE (StartPde)) {

                PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (StartPde);

                ASSERT (Pfn1 != NULL);
                Pfn1->u2.ShareCount += PTE_PER_PAGE;

                for (j = 0 ; j < PTE_PER_PAGE; j += 1) {

                    if (MiIsRegularMemory (LoaderBlock, PageFrameIndex + j)) {

                        Pfn3 = MI_PFN_ELEMENT (PageFrameIndex + j);
                        Pfn3->u4.PteFrame = PpePage;
                        Pfn3->PteAddress = StartPde;
                        Pfn3->u2.ShareCount += 1;
                        Pfn3->u3.e2.ReferenceCount = 1;
                        Pfn3->u3.e1.PageLocation = ActiveAndValid;
                        Pfn3->u3.e1.CacheAttribute = MiCached;
                        Pfn3->u3.e1.PageColor =
                            MI_GET_COLOR_FROM_SECONDARY(
                                                  MI_GET_PAGE_COLOR_FROM_PTE (
                                                        StartPde));
                    }
                }
            }
            else {

                PdePage = MI_GET_PAGE_FRAME_FROM_PTE(StartPde);

                if (MiIsRegularMemory (LoaderBlock, PdePage)) {
                    Pfn2 = MI_PFN_ELEMENT(PdePage);
                    Pfn2->u4.PteFrame = PpePage;
                    Pfn2->PteAddress = StartPde;
                    Pfn2->u2.ShareCount += 1;
                    Pfn2->u3.e2.ReferenceCount = 1;
                    Pfn2->u3.e1.PageLocation = ActiveAndValid;
                    Pfn2->u3.e1.CacheAttribute = MiCached;
                    Pfn2->u3.e1.PageColor =
                        MI_GET_COLOR_FROM_SECONDARY(GET_PAGE_COLOR_FROM_PTE (StartPde));
                }
                else {
                    Pfn2 = NULL;
                }

                PointerPte = MiGetVirtualAddressMappedByPte(StartPde);

                for (j = 0 ; j < PTE_PER_PAGE; j += 1) {

                    if (PointerPte->u.Hard.Valid == 1) {

                        ASSERT (Pfn2 != NULL);
                        Pfn2->u2.ShareCount += 1;

                        if (MiIsRegularMemory (LoaderBlock, PointerPte->u.Hard.PageFrameNumber)) {

                            Pfn3 = MI_PFN_ELEMENT(PointerPte->u.Hard.PageFrameNumber);
                            Pfn3->u4.PteFrame = PdePage;
                            Pfn3->PteAddress = PointerPte;
                            Pfn3->u2.ShareCount += 1;
                            Pfn3->u3.e2.ReferenceCount = 1;
                            Pfn3->u3.e1.PageLocation = ActiveAndValid;
                            Pfn3->u3.e1.CacheAttribute = MiCached;
                            Pfn3->u3.e1.PageColor =
                                MI_GET_COLOR_FROM_SECONDARY(
                                                      MI_GET_PAGE_COLOR_FROM_PTE (
                                                            PointerPte));
                        }
                    }
                    PointerPte += 1;
                }
            }
        }

        StartPde += 1;
    }

    //
    // Mark the system top level page directory parent page as in use.
    //

    PointerPte = MiGetPteAddress((PVOID)PDE_KTBASE);
    Pfn2 = MI_PFN_ELEMENT(MmSystemParentTablePage);

    Pfn2->u4.PteFrame = MmSystemParentTablePage;
    Pfn2->PteAddress = PointerPte;
    Pfn2->u1.Event = (PVOID) CurrentProcess;
    Pfn2->u2.ShareCount += 1;
    Pfn2->u3.e2.ReferenceCount = 1;
    Pfn2->u3.e1.PageLocation = ActiveAndValid;
    Pfn2->u3.e1.CacheAttribute = MiCached;
    Pfn2->u3.e1.PageColor =
        MI_GET_COLOR_FROM_SECONDARY(MI_GET_PAGE_COLOR_FROM_PTE (PointerPte));

    // 
    // Temporarily mark the user top level page directory parent page as in use 
    // so this page will not be put in the free list.
    //
    
    PointerPte = MiGetPteAddress((PVOID)PDE_UTBASE);
    Pfn2 = MI_PFN_ELEMENT(PointerPte->u.Hard.PageFrameNumber);
    Pfn2->u4.PteFrame = PointerPte->u.Hard.PageFrameNumber;
    Pfn2->PteAddress = PointerPte;
    Pfn2->u1.Event = NULL;
    Pfn2->u2.ShareCount += 1;
    Pfn2->u3.e2.ReferenceCount = 1;
    Pfn2->u3.e1.PageLocation = ActiveAndValid;
    Pfn2->u3.e1.CacheAttribute = MiCached;
    Pfn2->u3.e1.PageColor =
        MI_GET_COLOR_FROM_SECONDARY(MI_GET_PAGE_COLOR_FROM_PTE (PointerPte));

    //
    // Mark the region 1 session top level page directory parent page as in use.
    // This page will never be freed.
    //

    PointerPte = MiGetPteAddress((PVOID)PDE_STBASE);
    Pfn2 = MI_PFN_ELEMENT(MmSessionParentTablePage);

    Pfn2->u4.PteFrame = MmSessionParentTablePage;
    Pfn2->PteAddress = PointerPte;
    Pfn2->u2.ShareCount += 1;
    Pfn2->u3.e2.ReferenceCount = 1;
    Pfn2->u3.e1.PageLocation = ActiveAndValid;
    Pfn2->u3.e1.CacheAttribute = MiCached;
    Pfn2->u3.e1.PageColor =
        MI_GET_COLOR_FROM_SECONDARY(MI_GET_PAGE_COLOR_FROM_PTE (PointerPte));

    //
    // Mark the default PPE table page as in use so that this page will never
    // be used.
    //

    PageFrameIndex = MiDefaultPpe.u.Hard.PageFrameNumber;
    PointerPte = KSEG_ADDRESS(PageFrameIndex);
    Pfn2 = MI_PFN_ELEMENT(PageFrameIndex);
    Pfn2->u4.PteFrame = PageFrameIndex;
    Pfn2->PteAddress = PointerPte;
    Pfn2->u1.Event = (PVOID) CurrentProcess;
    Pfn2->u2.ShareCount += 1;
    Pfn2->u3.e2.ReferenceCount = 1;
    Pfn2->u3.e1.PageLocation = ActiveAndValid;
    Pfn2->u3.e1.CacheAttribute = MiCached;
    Pfn2->u3.e1.PageColor =
        MI_GET_COLOR_FROM_SECONDARY(MI_GET_PAGE_COLOR_FROM_PTE (PointerPte));

    //
    // If page zero is still unused, mark it as in use. This is
    // because we want to find bugs where a physical page
    // is specified as zero.
    //

    Pfn1 = &MmPfnDatabase[MmLowestPhysicalPage];
    if (Pfn1->u3.e2.ReferenceCount == 0) {

        //
        // Make the reference count non-zero and point it into a
        // page directory.
        //

        Pde = MiGetPdeAddress ((PVOID)(KADDRESS_BASE + 0xb0000000));
        PdePage = MI_GET_PAGE_FRAME_FROM_PTE(Pde);
        Pfn1->u4.PteFrame = PdePageNumber;
        Pfn1->PteAddress = Pde;
        Pfn1->u2.ShareCount += 1;
        Pfn1->u3.e2.ReferenceCount = 1;
        Pfn1->u3.e1.PageLocation = ActiveAndValid;
        Pfn1->u3.e1.CacheAttribute = MiCached;
        Pfn1->u3.e1.PageColor = MI_GET_COLOR_FROM_SECONDARY(
                                            MI_GET_PAGE_COLOR_FROM_PTE (Pde));
    }

    //
    // Walk through the memory descriptors and add pages to the
    // free list in the PFN database.
    //

    NextMd = LoaderBlock->MemoryDescriptorListHead.Flink;

    while (NextMd != &LoaderBlock->MemoryDescriptorListHead) {

        MemoryDescriptor = CONTAINING_RECORD(NextMd,
                                             MEMORY_ALLOCATION_DESCRIPTOR,
                                             ListEntry);

        i = MemoryDescriptor->PageCount;
        NextPhysicalPage = MemoryDescriptor->BasePage;

        switch (MemoryDescriptor->MemoryType) {
            case LoaderBad:

                if (NextPhysicalPage > MmHighestPhysicalPage) {
                    i = 0;
                }
                else if (NextPhysicalPage + i > MmHighestPhysicalPage + 1) {
                    i = MmHighestPhysicalPage + 1 - NextPhysicalPage;
                }

                while (i != 0) {
                    MiInsertPageInList (&MmBadPageListHead, NextPhysicalPage);
                    i -= 1;
                    NextPhysicalPage += 1;
                }
                break;

            case LoaderFree:
            case LoaderLoadedProgram:
            case LoaderFirmwareTemporary:
            case LoaderOsloaderStack:

                Pfn1 = MI_PFN_ELEMENT (NextPhysicalPage);
                while (i != 0) {
                    if (Pfn1->u3.e2.ReferenceCount == 0) {

                        //
                        // Set the PTE address to the physical page for
                        // virtual address alignment checking.
                        //

                        Pfn1->PteAddress = KSEG_ADDRESS (NextPhysicalPage);
                        Pfn1->u3.e1.CacheAttribute = MiCached;
                        MiDetermineNode(NextPhysicalPage, Pfn1);
                        MiInsertPageInFreeList (NextPhysicalPage);
                    }
                    Pfn1 += 1;
                    i -= 1;
                    NextPhysicalPage += 1;
                }
                break;

            case LoaderSpecialMemory:
            case LoaderBBTMemory:
            case LoaderFirmwarePermanent:

                //
                // Skip this range.
                //

                break;

            default:

                PointerPte = KSEG_ADDRESS(NextPhysicalPage);
                Pfn1 = MI_PFN_ELEMENT (NextPhysicalPage);
                while (i != 0) {

                    //
                    // Set page as in use.
                    //

                    if (Pfn1->u3.e2.ReferenceCount == 0) {
                        Pfn1->u4.PteFrame = PdePageNumber;
                        Pfn1->PteAddress = PointerPte;
                        Pfn1->u2.ShareCount += 1;
                        Pfn1->u3.e2.ReferenceCount = 1;
                        Pfn1->u3.e1.PageLocation = ActiveAndValid;
                        Pfn1->u3.e1.CacheAttribute = MiCached;
                        Pfn1->u3.e1.PageColor = MI_GET_COLOR_FROM_SECONDARY(
                                        MI_GET_PAGE_COLOR_FROM_PTE (
                                                        PointerPte));

                        if (MemoryDescriptor->MemoryType == LoaderXIPRom) {
                            Pfn1->u1.Flink = 0;
                            Pfn1->u2.ShareCount = 0;
                            Pfn1->u3.e2.ReferenceCount = 0;
                            Pfn1->u3.e1.PageLocation = 0;
                            Pfn1->u3.e1.Rom = 1;
                            Pfn1->u4.InPageError = 0;
                            Pfn1->u3.e1.PrototypePte = 1;
                        }
                    }
                    Pfn1 += 1;
                    i -= 1;
                    NextPhysicalPage += 1;
                    PointerPte += 1;
                }
                break;
        }

        NextMd = MemoryDescriptor->ListEntry.Flink;
    }

    //
    // If the large page chunk came from the middle of the free descriptor (due
    // to alignment requirements), then add the pages from the split bottom
    // portion of the free descriptor now.
    //

    i = MiSlushDescriptorCount;
    NextPhysicalPage = MiSlushDescriptorBase;
    Pfn1 = MI_PFN_ELEMENT (NextPhysicalPage);

    while (i != 0) {
        if (Pfn1->u3.e2.ReferenceCount == 0) {

            //
            // Set the PTE address to the physical page for
            // virtual address alignment checking.
            //

            Pfn1->PteAddress = KSEG_ADDRESS (NextPhysicalPage);
            Pfn1->u3.e1.CacheAttribute = MiCached;
            MiDetermineNode(NextPhysicalPage, Pfn1);
            MiInsertPageInFreeList (NextPhysicalPage);
        }
        Pfn1 += 1;
        i -= 1;
        NextPhysicalPage += 1;
    }

    //
    // Mark all PFN entries for the PFN pages in use.
    //

    if (MiInitialLargePage != (PFN_NUMBER) -1) {

        //
        // The PFN database is allocated in large pages.
        //

        PfnAllocation = MxPfnAllocation;

        PageFrameIndex = MI_CONVERT_PHYSICAL_TO_PFN (MmPfnDatabase);
        Pfn1 = MI_PFN_ELEMENT(PageFrameIndex);

        do {
            Pfn1->PteAddress = KSEG_ADDRESS(PageFrameIndex);
            Pfn1->u3.e1.PageColor = 0;
            Pfn1->u3.e2.ReferenceCount = 1;
            Pfn1->u3.e1.PageLocation = ActiveAndValid;
            Pfn1->u3.e1.CacheAttribute = MiCached;
            PageFrameIndex += 1;
            Pfn1 += 1;
            PfnAllocation -= 1;
        } while (PfnAllocation != 0);

        if (MmDynamicPfn == 0) {

            //
            // Scan the PFN database backward for pages that are completely
            // zero.  These pages are unused and can be added to the free list.
            //
            // This allows machines with sparse physical memory to have a
            // minimal PFN database even when mapped with large pages.
            //

            BottomPfn = MI_PFN_ELEMENT (MmHighestPhysicalPage);

            do {

                //
                // Compute the address of the start of the page that is next
                // lower in memory and scan backwards until that page address
                // is reached or just crossed.
                //

                if (((ULONG_PTR)BottomPfn & (PAGE_SIZE - 1)) != 0) {
                    BasePfn = (PMMPFN)((ULONG_PTR)BottomPfn & ~(PAGE_SIZE - 1));
                    TopPfn = BottomPfn + 1;

                }
                else {
                    BasePfn = (PMMPFN)((ULONG_PTR)BottomPfn - PAGE_SIZE);
                    TopPfn = BottomPfn;
                }

                while (BottomPfn > BasePfn) {
                    BottomPfn -= 1;
                }

                //
                // If the entire range over which the PFN entries span is
                // completely zero and the PFN entry that maps the page is
                // not in the range, then add the page to the appropriate
                // free list.
                //

                Range = (ULONG_PTR)TopPfn - (ULONG_PTR)BottomPfn;
                if (RtlCompareMemoryUlong((PVOID)BottomPfn, Range, 0) == Range) {

                    //
                    // Set the PTE address to the physical page for virtual
                    // address alignment checking.
                    //

                    PageFrameIndex = MI_CONVERT_PHYSICAL_TO_PFN (BasePfn);
                    Pfn1 = MI_PFN_ELEMENT(PageFrameIndex);

                    ASSERT (Pfn1->u3.e2.ReferenceCount == 1);
                    ASSERT (Pfn1->PteAddress == KSEG_ADDRESS(PageFrameIndex));
                    Pfn1->u3.e2.ReferenceCount = 0;
                    Pfn1->PteAddress = (PMMPTE)((ULONG_PTR)PageFrameIndex << PTE_SHIFT);
                    Pfn1->u3.e1.PageColor = 0;
                    MiInsertPageInFreeList (PageFrameIndex);
                }

            } while (BottomPfn > MmPfnDatabase);
        }
    }
    else {

        //
        // The PFN database is sparsely allocated in small pages.
        //

        PointerPte = MiGetPteAddress (MmPfnDatabase);
        LastPte = MiGetPteAddress (MmPfnDatabase + MmHighestPhysicalPage + 1);
        if (LastPte != PAGE_ALIGN (LastPte)) {
            LastPte += 1;
        }

        StartPpe = MiGetPdeAddress (PointerPte);
        PointerPde = MiGetPteAddress (PointerPte);

        while (PointerPte < LastPte) {

            if (StartPpe->u.Hard.Valid == 0) {
                StartPpe += 1;
                PointerPde = MiGetVirtualAddressMappedByPte (StartPpe);
                PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
                continue;
            }

            if (PointerPde->u.Hard.Valid == 0) {
                PointerPde += 1;
                PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
                if (MiIsPteOnPdeBoundary (PointerPde)) {
                    StartPpe += 1;
                }
                continue;
            }

            if (PointerPte->u.Hard.Valid == 1) {

                PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
                Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);

                Pfn1->PteAddress = PointerPte;
                Pfn1->u3.e1.PageColor = 0;
                Pfn1->u3.e2.ReferenceCount = 1;
                Pfn1->u3.e1.PageLocation = ActiveAndValid;
                Pfn1->u3.e1.CacheAttribute = MiCached;
            }

            PointerPte += 1;
            if (MiIsPteOnPdeBoundary (PointerPte)) {
                PointerPde += 1;
                if (MiIsPteOnPdeBoundary (PointerPde)) {
                    StartPpe += 1;
                }
            }
        }
    }

    //
    // Initialize the nonpaged pool.
    //

    InitializePool (NonPagedPool, 0);

    //
    // Initialize the nonpaged available PTEs for mapping I/O space
    // and kernel stacks.
    //

    PointerPte = MiGetPteAddress (SystemPteStart);
    ASSERT (((ULONG_PTR)PointerPte & (PAGE_SIZE - 1)) == 0);

    MmNumberOfSystemPtes = (ULONG)(MiGetPteAddress(MmPfnDatabase) - PointerPte - 1);

    MiInitializeSystemPtes (PointerPte, MmNumberOfSystemPtes, SystemPteSpace);

    //
    // Initialize memory management structures for the system process.
    //
    // Set the address of the first and last reserved PTE in hyper space.
    //

    MmFirstReservedMappingPte = MiGetPteAddress (FIRST_MAPPING_PTE);
    MmLastReservedMappingPte = MiGetPteAddress (LAST_MAPPING_PTE);

    //
    // Create zeroing PTEs for the zero page thread.
    //

    MiFirstReservedZeroingPte = MiReserveSystemPtes (NUMBER_OF_ZEROING_PTES + 1,
                                                     SystemPteSpace);

    RtlZeroMemory (MiFirstReservedZeroingPte,
                   (NUMBER_OF_ZEROING_PTES + 1) * sizeof(MMPTE));

    //
    // Use the page frame number field of the first PTE as an
    // offset into the available zeroing PTEs.
    //

    MiFirstReservedZeroingPte->u.Hard.PageFrameNumber = NUMBER_OF_ZEROING_PTES;

    //
    // Create the VAD bitmap for this process.
    //

    PointerPte = MiGetPteAddress (VAD_BITMAP_SPACE);

    PageFrameIndex = MiRemoveAnyPage (0);

    //
    // Note the global bit must be off for the bitmap data.
    //

    TempPte = ValidPdePde;
    TempPte.u.Hard.PageFrameNumber = PageFrameIndex;
    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    //
    // Point to the page we just created and zero it.
    //

    RtlZeroMemory (VAD_BITMAP_SPACE, PAGE_SIZE);

    MiLastVadBit = (ULONG)((((ULONG_PTR) MI_64K_ALIGN (MM_HIGHEST_VAD_ADDRESS))) / X64K);
    if (MiLastVadBit > PAGE_SIZE * 8 - 1) {
        MiLastVadBit = PAGE_SIZE * 8 - 1;
    }

    //
    // The PFN element for the page directory parent will be initialized
    // a second time when the process address space is initialized. Therefore,
    // the share count and the reference count must be set to zero.
    //

    Pfn1 = MI_PFN_ELEMENT(MI_GET_PAGE_FRAME_FROM_PTE((PMMPTE)PDE_SELFMAP));
    Pfn1->u2.ShareCount = 0;
    Pfn1->u3.e2.ReferenceCount = 0;

    //
    // The PFN element for the hyper space page directory page will be
    // initialized a second time when the process address space is initialized.
    // Therefore, the share count and the reference count must be set to zero.
    //

    PointerPte = MiGetPpeAddress(HYPER_SPACE);
    Pfn1 = MI_PFN_ELEMENT(MI_GET_PAGE_FRAME_FROM_PTE(PointerPte));
    Pfn1->u2.ShareCount = 0;
    Pfn1->u3.e2.ReferenceCount = 0;

    //
    // The PFN elements for the hyper space page table page and working set list
    // page will be initialized a second time when the process address space
    // is initialized. Therefore, the share count and the reference must be
    // set to zero.
    //

    StartPde = MiGetPdeAddress(HYPER_SPACE);

    Pfn1 = MI_PFN_ELEMENT(MI_GET_PAGE_FRAME_FROM_PTE(StartPde));
    Pfn1->u2.ShareCount = 0;
    Pfn1->u3.e2.ReferenceCount = 0;

    KeInitializeEvent (&MiImageMappingPteEvent,
                       NotificationEvent,
                       FALSE);

    //
    // Initialize this process's memory management structures including
    // the working set list.
    //

    //
    // The PFN element for the page directory has already been initialized,
    // zero the reference count and the share count so they won't be
    // wrong.
    //

    Pfn1 = MI_PFN_ELEMENT (PdePageNumber);
    Pfn1->u2.ShareCount = 0;
    Pfn1->u3.e2.ReferenceCount = 0;

    //
    // Get a page for the working set list and map it into the page
    // directory at the page after hyperspace.
    //

    PageFrameIndex = MiRemoveAnyPage (0);

    CurrentProcess->WorkingSetPage = PageFrameIndex;

    TempPte = ValidPdePde;
    TempPte.u.Hard.PageFrameNumber = PageFrameIndex;
    PointerPte = MiGetPteAddress (MmWorkingSetList);

    MI_WRITE_VALID_PTE (PointerPte, TempPte);

    RtlZeroMemory (KSEG_ADDRESS(PageFrameIndex), PAGE_SIZE);

    CurrentProcess->Vm.MaximumWorkingSetSize = (ULONG)MmSystemProcessWorkingSetMax;
    CurrentProcess->Vm.MinimumWorkingSetSize = (ULONG)MmSystemProcessWorkingSetMin;

    MmSessionMapInfo.RegionId = START_SESSION_RID;
    MmSessionMapInfo.SequenceNumber = START_SEQUENCE;

    KeAttachSessionSpace (&MmSessionMapInfo, MmSessionParentTablePage);

    MmInitializeProcessAddressSpace (CurrentProcess, NULL, NULL, NULL);

    KeFlushCurrentTb ();

#if defined (_MI_DEBUG_ALTPTE)
    MmDebug |= MM_DBG_STOP_ON_WOW64_ACCVIO;
#endif

    //
    // Restore the loader block memory descriptor to its original contents
    // as our caller relies on it.
    //

    MiFreeDescriptor->BasePage = (ULONG) MiOldFreeDescriptorBase;
    MiFreeDescriptor->PageCount = (ULONG) MiOldFreeDescriptorCount;

    return;
}
VOID
MiSweepCacheMachineDependent (
    IN PVOID VirtualAddress,
    IN SIZE_T Size,
    IN ULONG InputAttribute
    )
/*++

Routine Description:

    This function checks and performs appropriate cache flushing operations.

Arguments:

    StartVirtual - Supplies the start address of the region of pages.

    Size - Supplies the size of the region in pages.

    CacheAttribute - Supplies the new cache attribute.

Return Value:

    None.

--*/
{
    SIZE_T Size2;
    PFN_NUMBER i;
    PFN_NUMBER PageFrameIndex;
    PFN_NUMBER NumberOfPages;
    PVOID BaseAddress;
    PVOID Va;
    PMMPTE PointerPde;
    PMMPTE PointerPte;
    PMMPTE EndPte;
    MMPTE TempPte;
    MI_PFN_CACHE_ATTRIBUTE CacheAttribute;
    MMPTE_FLUSH_LIST PteFlushList;

    CacheAttribute = (MI_PFN_CACHE_ATTRIBUTE) InputAttribute;

    NumberOfPages = ADDRESS_AND_SIZE_TO_SPAN_PAGES (VirtualAddress, Size);
    VirtualAddress = PAGE_ALIGN(VirtualAddress);
    Size = NumberOfPages * PAGE_SIZE;

    //
    // Unfortunately some IA64 machines have hardware problems when sweeping
    // address ranges that are backed by I/O space instead of system DRAM.
    //
    // So we have to check for that here and chop up the request if need be
    // so that only system DRAM addresses get swept.
    //

    i = 0;
    Size2 = 0;
    BaseAddress = NULL;

    PointerPte = MiGetPteAddress (VirtualAddress);
    EndPte = PointerPte + NumberOfPages;

    PointerPde = MiGetPdeAddress (VirtualAddress);

    for (i = 0; i < NumberOfPages; ) {

        if (MI_PDE_MAPS_LARGE_PAGE (PointerPde)) {

            Va = MiGetVirtualAddressMappedByPde (PointerPde);
            ASSERT (MiGetPteOffset (Va) == 0);

            PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPde);
        }
        else {
            PageFrameIndex = MI_GET_PAGE_FRAME_FROM_PTE (PointerPte);
        }

        if (!MI_IS_PFN (PageFrameIndex)) {

            //
            // Sweep the partial range if one exists.
            //

            if (Size2 != 0) {

                KeSweepCacheRangeWithDrain (TRUE, BaseAddress, (ULONG)Size2);
                Size2 = 0;
            }
        }
        else {
            if (Size2 == 0) {
                BaseAddress = (PVOID)((PCHAR)VirtualAddress + i * PAGE_SIZE);
            }
            if (MI_PDE_MAPS_LARGE_PAGE (PointerPde)) {
                Size2 += PTE_PER_PAGE * PAGE_SIZE;
            }
            else {
                Size2 += PAGE_SIZE;
            }
        }

        if (MI_PDE_MAPS_LARGE_PAGE (PointerPde)) {
            i += PTE_PER_PAGE;
            PointerPte += PTE_PER_PAGE;
            PointerPde += 1;
        }
        else {
            i += 1;
            PointerPte += 1;
            if (MiIsPteOnPdeBoundary (PointerPte)) {
                PointerPde += 1;
            }
        }
    }

    //
    // Sweep any remainder.
    //

    if (Size2 != 0) {
        KeSweepCacheRangeWithDrain (TRUE, BaseAddress, (ULONG)Size2);
    }

    PointerPde = MiGetPdeAddress (VirtualAddress);

    if ((CacheAttribute == MiWriteCombined) &&
        ((MI_PDE_MAPS_LARGE_PAGE (PointerPde)) == 0)) {

        PointerPte = MiGetPteAddress (VirtualAddress);

        PteFlushList.Count = 0;

        while (NumberOfPages != 0) {
            TempPte = *PointerPte;
            MI_SET_PTE_WRITE_COMBINE2 (TempPte);
            MI_WRITE_VALID_PTE_NEW_PROTECTION (PointerPte, TempPte);

            if (PteFlushList.Count != MM_MAXIMUM_FLUSH_COUNT) {
                PteFlushList.FlushVa[PteFlushList.Count] = VirtualAddress;
                PteFlushList.Count += 1;
                VirtualAddress = (PVOID) ((PCHAR)VirtualAddress + PAGE_SIZE);
            }

            PointerPte += 1;
            NumberOfPages -= 1;
        }

        MiFlushPteList (&PteFlushList, TRUE);
    }
}

PVOID
MiConvertToLoaderVirtual (
    IN PFN_NUMBER Page,
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )
{
    ULONG_PTR PageAddress;
    PTR_INFO ItrInfo;

    PageAddress = Page << PAGE_SHIFT;
    ItrInfo = &LoaderBlock->u.Ia64.ItrInfo[0];

    if ((ItrInfo[ITR_KERNEL_INDEX].Valid == TRUE) &&
        (PageAddress >= ItrInfo[ITR_KERNEL_INDEX].PhysicalAddress) &&
        (PageAddress <= ItrInfo[ITR_KERNEL_INDEX].PhysicalAddress +
         ((ULONG_PTR)1 << ItrInfo[ITR_KERNEL_INDEX].PageSize))) {

        return (PVOID)(ItrInfo[ITR_KERNEL_INDEX].VirtualAddress +
                       (PageAddress - ItrInfo[ITR_KERNEL_INDEX].PhysicalAddress));

    }
    else if ((ItrInfo[ITR_DRIVER0_INDEX].Valid == TRUE) &&
        (PageAddress >= ItrInfo[ITR_DRIVER0_INDEX].PhysicalAddress) &&
        (PageAddress <= ItrInfo[ITR_DRIVER0_INDEX].PhysicalAddress +
         ((ULONG_PTR)1 << ItrInfo[ITR_DRIVER0_INDEX].PageSize))) {

        return (PVOID)(ItrInfo[ITR_DRIVER0_INDEX].VirtualAddress +
                       (PageAddress - ItrInfo[ITR_DRIVER0_INDEX].PhysicalAddress));

    }
    else if ((ItrInfo[ITR_DRIVER1_INDEX].Valid == TRUE) &&
        (PageAddress >= ItrInfo[ITR_DRIVER1_INDEX].PhysicalAddress) &&
        (PageAddress <= ItrInfo[ITR_DRIVER1_INDEX].PhysicalAddress +
         ((ULONG_PTR)1 << ItrInfo[ITR_DRIVER1_INDEX].PageSize))) {

        return (PVOID)(ItrInfo[ITR_DRIVER1_INDEX].VirtualAddress +
                       (PageAddress - ItrInfo[ITR_DRIVER1_INDEX].PhysicalAddress));

    }
    else {

        KeBugCheckEx (MEMORY_MANAGEMENT,
                      0x01010101,
                      PageAddress,
                      (ULONG_PTR)&ItrInfo[0],
                      (ULONG_PTR)LoaderBlock);
    }
}


VOID
MiBuildPageTableForLoaderMemory (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )
/*++

Routine Description:

    This function builds page tables for loader loaded drivers and loader
    allocated memory.

Arguments:

    LoaderBlock - Supplies the address of the loader block.

Return Value:

    None.

--*/
{
    PMMPTE StartPte;
    PMMPTE EndPte;
    PMMPTE StartPde;
    PMMPTE StartPpe;
    MMPTE TempPte;
    MMPTE TempPte2;
    ULONG First;
    PLIST_ENTRY NextEntry;
    PFN_NUMBER NextPhysicalPage;
    PVOID Va;
    PFN_NUMBER PfnNumber;
    PTR_INFO DtrInfo;
    PMEMORY_ALLOCATION_DESCRIPTOR MemoryDescriptor;

    TempPte = ValidKernelPte;
    NextEntry = LoaderBlock->MemoryDescriptorListHead.Flink;

    for ( ; NextEntry != &LoaderBlock->MemoryDescriptorListHead; NextEntry = NextEntry->Flink) {

        MemoryDescriptor = CONTAINING_RECORD(NextEntry,
                                             MEMORY_ALLOCATION_DESCRIPTOR,
                                             ListEntry);

        if ((MemoryDescriptor->MemoryType == LoaderOsloaderHeap) ||
            (MemoryDescriptor->MemoryType == LoaderRegistryData) ||
            (MemoryDescriptor->MemoryType == LoaderNlsData) ||
            (MemoryDescriptor->MemoryType == LoaderStartupDpcStack) ||
            (MemoryDescriptor->MemoryType == LoaderStartupKernelStack) ||
            (MemoryDescriptor->MemoryType == LoaderStartupPanicStack) ||
            (MemoryDescriptor->MemoryType == LoaderStartupPdrPage) ||
            (MemoryDescriptor->MemoryType == LoaderMemoryData)) {

            TempPte.u.Hard.Execute = 0;

        }
        else if ((MemoryDescriptor->MemoryType == LoaderSystemCode) ||
                   (MemoryDescriptor->MemoryType == LoaderHalCode) ||
                   (MemoryDescriptor->MemoryType == LoaderBootDriver) ||
                   (MemoryDescriptor->MemoryType == LoaderStartupDpcStack)) {

            TempPte.u.Hard.Execute = 1;

        }
        else {

            continue;

        }

        PfnNumber = MemoryDescriptor->BasePage;
        Va = MiConvertToLoaderVirtual (MemoryDescriptor->BasePage, LoaderBlock);

        StartPte = MiGetPteAddress (Va);
        EndPte = StartPte + MemoryDescriptor->PageCount;

        First = TRUE;

        while (StartPte < EndPte) {

            if (First == TRUE || MiIsPteOnPpeBoundary(StartPte)) {
                StartPpe = MiGetPdeAddress(StartPte);
                if (StartPpe->u.Hard.Valid == 0) {
                    ASSERT (StartPpe->u.Long == 0);
                    NextPhysicalPage = MiGetNextPhysicalPage ();
                    RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
                    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                    MI_WRITE_VALID_PTE (StartPpe, TempPte);
                }
            }

            if ((First == TRUE) || MiIsPteOnPdeBoundary(StartPte)) {
                First = FALSE;
                StartPde = MiGetPteAddress (StartPte);
                if (StartPde->u.Hard.Valid == 0) {
                    NextPhysicalPage = MiGetNextPhysicalPage ();
                    RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
                    TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                    MI_WRITE_VALID_PTE (StartPde, TempPte);
                }
            }

            TempPte.u.Hard.PageFrameNumber = PfnNumber;
            MI_WRITE_VALID_PTE (StartPte, TempPte);
            StartPte += 1;
            PfnNumber += 1;
            Va = (PVOID)((ULONG_PTR)Va + PAGE_SIZE);
        }
    }

    //
    // Build a mapping for the I/O port space with caching disabled.
    //

    DtrInfo = &LoaderBlock->u.Ia64.DtrInfo[DTR_IO_PORT_INDEX];
    Va = (PVOID) DtrInfo->VirtualAddress;

    PfnNumber = (DtrInfo->PhysicalAddress >> PAGE_SHIFT);

    StartPte = MiGetPteAddress (Va);
    EndPte = MiGetPteAddress (
            (PVOID) ((ULONG_PTR)Va + ((ULONG_PTR)1 << DtrInfo->PageSize) - 1));

    TempPte2 = ValidKernelPte;

    MI_DISABLE_CACHING (TempPte2);

    First = TRUE;

    while (StartPte <= EndPte) {

        if (First == TRUE || MiIsPteOnPpeBoundary (StartPte)) {
            StartPpe = MiGetPdeAddress(StartPte);
            if (StartPpe->u.Hard.Valid == 0) {
                ASSERT (StartPpe->u.Long == 0);
                NextPhysicalPage = MiGetNextPhysicalPage ();
                RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                MI_WRITE_VALID_PTE (StartPpe, TempPte);
            }
        }

        if ((First == TRUE) || MiIsPteOnPdeBoundary (StartPte)) {
            First = FALSE;
            StartPde = MiGetPteAddress (StartPte);
            if (StartPde->u.Hard.Valid == 0) {
                NextPhysicalPage = MiGetNextPhysicalPage ();
                RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                MI_WRITE_VALID_PTE (StartPde, TempPte);
            }
        }

        TempPte2.u.Hard.PageFrameNumber = PfnNumber;
        MI_WRITE_VALID_PTE (StartPte, TempPte2);
        StartPte += 1;
        PfnNumber += 1;
    }

    //
    // Build a mapping for the PAL with caching enabled.
    //

    DtrInfo = &LoaderBlock->u.Ia64.DtrInfo[DTR_PAL_INDEX];
    Va = (PVOID) HAL_PAL_VIRTUAL_ADDRESS;

    PfnNumber = (DtrInfo->PhysicalAddress >> PAGE_SHIFT);

    StartPte = MiGetPteAddress (Va);
    EndPte = MiGetPteAddress (
            (PVOID) ((ULONG_PTR)Va + ((ULONG_PTR)1 << DtrInfo->PageSize) - 1));

    TempPte2 = ValidKernelPte;

    First = TRUE;

    while (StartPte <= EndPte) {

        if (First == TRUE || MiIsPteOnPpeBoundary (StartPte)) {
            StartPpe = MiGetPdeAddress(StartPte);
            if (StartPpe->u.Hard.Valid == 0) {
                ASSERT (StartPpe->u.Long == 0);
                NextPhysicalPage = MiGetNextPhysicalPage ();
                RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                MI_WRITE_VALID_PTE (StartPpe, TempPte);
            }
        }

        if ((First == TRUE) || MiIsPteOnPdeBoundary (StartPte)) {
            First = FALSE;
            StartPde = MiGetPteAddress (StartPte);
            if (StartPde->u.Hard.Valid == 0) {
                NextPhysicalPage = MiGetNextPhysicalPage ();
                RtlZeroMemory (KSEG_ADDRESS(NextPhysicalPage), PAGE_SIZE);
                TempPte.u.Hard.PageFrameNumber = NextPhysicalPage;
                MI_WRITE_VALID_PTE (StartPde, TempPte);
            }
        }

        TempPte2.u.Hard.PageFrameNumber = PfnNumber;
        MI_WRITE_VALID_PTE (StartPte, TempPte2);
        StartPte += 1;
        PfnNumber += 1;
    }
}

VOID
MiRemoveLoaderSuperPages (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )
{

    //
    // Remove the super page fixed TB entries used for the boot drivers.
    //
    if (LoaderBlock->u.Ia64.ItrInfo[ITR_DRIVER0_INDEX].Valid) {
        KiFlushFixedInstTb(FALSE, LoaderBlock->u.Ia64.ItrInfo[ITR_DRIVER0_INDEX].VirtualAddress);
    }
    if (LoaderBlock->u.Ia64.ItrInfo[ITR_DRIVER1_INDEX].Valid) {
        KiFlushFixedInstTb(FALSE, LoaderBlock->u.Ia64.ItrInfo[ITR_DRIVER1_INDEX].VirtualAddress);
    }
    if (LoaderBlock->u.Ia64.DtrInfo[DTR_DRIVER0_INDEX].Valid) {
        KiFlushFixedDataTb(FALSE, LoaderBlock->u.Ia64.DtrInfo[DTR_DRIVER0_INDEX].VirtualAddress);
    }
    if (LoaderBlock->u.Ia64.DtrInfo[DTR_DRIVER1_INDEX].Valid) {
        KiFlushFixedDataTb(FALSE, LoaderBlock->u.Ia64.DtrInfo[DTR_DRIVER1_INDEX].VirtualAddress);
    }

    if (LoaderBlock->u.Ia64.DtrInfo[DTR_IO_PORT_INDEX].Valid) {
        KiFlushFixedDataTb(FALSE, LoaderBlock->u.Ia64.DtrInfo[DTR_IO_PORT_INDEX].VirtualAddress);
    }
    
}

VOID
MiCompactMemoryDescriptorList (
    IN PLOADER_PARAMETER_BLOCK LoaderBlock
    )
{
    PFN_NUMBER KernelStart;
    PFN_NUMBER KernelEnd;
    ULONG_PTR PageSize;
    PLIST_ENTRY NextEntry;
    PLIST_ENTRY PreviousEntry;
    PMEMORY_ALLOCATION_DESCRIPTOR MemoryDescriptor;
    PMEMORY_ALLOCATION_DESCRIPTOR PreviousMemoryDescriptor;

    KernelStart = MiNtoskrnlPhysicalBase >> PAGE_SHIFT;
    PageSize = (ULONG_PTR)1 << MiNtoskrnlPageShift;
    KernelEnd = KernelStart + (PageSize >> PAGE_SHIFT);

    PreviousMemoryDescriptor = NULL;
    PreviousEntry = NULL;

    NextEntry = LoaderBlock->MemoryDescriptorListHead.Flink;

    for ( ; NextEntry != &LoaderBlock->MemoryDescriptorListHead; NextEntry = NextEntry->Flink) {

        MemoryDescriptor = CONTAINING_RECORD(NextEntry,
                                             MEMORY_ALLOCATION_DESCRIPTOR,
                                             ListEntry);

        if ((MemoryDescriptor->BasePage >= KernelStart) &&
            (MemoryDescriptor->BasePage + MemoryDescriptor->PageCount <= KernelEnd)) {

            if (MemoryDescriptor->MemoryType == LoaderSystemBlock) {

                MemoryDescriptor->MemoryType = LoaderFirmwareTemporary;
            }
            else if (MemoryDescriptor->MemoryType == LoaderSpecialMemory) {

                MemoryDescriptor->MemoryType = LoaderFirmwareTemporary;
            }
        }

        if ((PreviousMemoryDescriptor != NULL) &&
            (MemoryDescriptor->MemoryType == PreviousMemoryDescriptor->MemoryType) &&
            (MemoryDescriptor->BasePage ==
             (PreviousMemoryDescriptor->BasePage + PreviousMemoryDescriptor->PageCount))) {

            PreviousMemoryDescriptor->PageCount += MemoryDescriptor->PageCount;
            RemoveEntryList (NextEntry);
        }
        else {
            PreviousMemoryDescriptor = MemoryDescriptor;
            PreviousEntry = NextEntry;
        }
    }
}

VOID
MiInitializeTbImage (
    VOID
    )

/*++

Routine Description:

    Initialize the software map of the translation register mappings wired
    into the TB by the loader.

Arguments:

    None.

Return Value:

    None.

Environment:

    Kernel mode, Phase 0 INIT only so no locks needed.

--*/

{
    ULONG PageSize;
    PFN_NUMBER BasePage;
    ULONG_PTR TranslationLength;
    ULONG_PTR BaseAddress;
    ULONG_PTR EndAddress;
    PTR_INFO TranslationRegisterEntry;
    PTR_INFO AliasTranslationRegisterEntry;
    PTR_INFO LastTranslationRegisterEntry;

    //
    // Snap the boot TRs.
    //

    RtlCopyMemory (&MiBootedTrInfo[0],
                   &KeLoaderBlock->u.Ia64.ItrInfo[0],
                   NUMBER_OF_LOADER_TR_ENTRIES * sizeof (TR_INFO));

    RtlCopyMemory (&MiBootedTrInfo[NUMBER_OF_LOADER_TR_ENTRIES],
                   &KeLoaderBlock->u.Ia64.DtrInfo[0],
                   NUMBER_OF_LOADER_TR_ENTRIES * sizeof (TR_INFO));

    //
    // Capture information regarding the translation register entry that
    // maps the kernel.
    //

    LastTranslationRegisterEntry = MiTrInfo;

    TranslationRegisterEntry = &KeLoaderBlock->u.Ia64.ItrInfo[ITR_KERNEL_INDEX];
    AliasTranslationRegisterEntry = TranslationRegisterEntry + NUMBER_OF_LOADER_TR_ENTRIES;

    ASSERT (TranslationRegisterEntry->PageSize != 0);
    ASSERT (TranslationRegisterEntry->PageSize == AliasTranslationRegisterEntry->PageSize);
    ASSERT (TranslationRegisterEntry->VirtualAddress == AliasTranslationRegisterEntry->VirtualAddress);
    ASSERT (TranslationRegisterEntry->PhysicalAddress == AliasTranslationRegisterEntry->PhysicalAddress);

    *LastTranslationRegisterEntry = *TranslationRegisterEntry;

    //
    // Calculate the ending address for each range to speed up
    // subsequent searches.
    //

    PageSize = TranslationRegisterEntry->PageSize;
    ASSERT (PageSize != 0);
    BaseAddress = TranslationRegisterEntry->VirtualAddress;
    TranslationLength = 1 << PageSize;

    BasePage = MI_VA_TO_PAGE (TranslationRegisterEntry->PhysicalAddress);

    MiAddCachedRange (BasePage,
                      BasePage + BYTES_TO_PAGES (TranslationLength) - 1);

    //
    // Initialize the kseg0 variables purely for the debugger.
    //

    MiKseg0Start = (PVOID) TranslationRegisterEntry->VirtualAddress;
    MiKseg0End = (PVOID) ((PCHAR) MiKseg0Start + TranslationLength);
    MiKseg0Mapping = TRUE;
    MiKseg0StartFrame = BasePage;
    MiKseg0EndFrame = BasePage + BYTES_TO_PAGES (TranslationLength) - 1;

    EndAddress = BaseAddress + TranslationLength;
    LastTranslationRegisterEntry->PhysicalAddress = EndAddress;

    MiLastTrEntry = LastTranslationRegisterEntry + 1;

    //
    // Add in the KSEG3 range.
    //

    MiAddTrEntry (KSEG3_BASE, KSEG3_LIMIT);

    //
    // Add in the PCR range.
    //

    MiAddTrEntry ((ULONG_PTR)PCR, (ULONG_PTR)PCR + PAGE_SIZE);

    return;
}

VOID
MiAddTrEntry (
    ULONG_PTR BaseAddress,
    ULONG_PTR EndAddress
    )

/*++

Routine Description:

    Add a translation cache entry to our software table.

Arguments:

    BaseAddress - Supplies the starting virtual address of the range.

    EndAddress - Supplies the ending virtual address of the range.

Return Value:

    None.

Environment:

    Kernel mode, Phase 0 INIT only so no locks needed.

--*/

{
    PTR_INFO TranslationRegisterEntry;

    if ((MiLastTrEntry == NULL) ||
        (MiLastTrEntry == MiTrInfo + NUMBER_OF_LOADER_TR_ENTRIES)) {

        //
        // This should never happen.
        //

        KeBugCheckEx (MEMORY_MANAGEMENT,
                      0x02020202,
                      (ULONG_PTR) MiTrInfo,
                      (ULONG_PTR) MiLastTrEntry,
                      NUMBER_OF_LOADER_TR_ENTRIES);
    }

    TranslationRegisterEntry = MiLastTrEntry;
    TranslationRegisterEntry->VirtualAddress = (ULONGLONG) BaseAddress;
    TranslationRegisterEntry->PhysicalAddress = (ULONGLONG) EndAddress;
    TranslationRegisterEntry->PageSize = 1;

    MiLastTrEntry += 1;

    return;
}

LOGICAL
MiIsVirtualAddressMappedByTr (
    IN PVOID VirtualAddress
    )

/*++

Routine Description:

    For a given virtual address this function returns TRUE if no page fault
    will occur for a read operation on the address, FALSE otherwise.

    Note that after this routine was called, if appropriate locks are not
    held, a non-faulting address could fault.

Arguments:

    VirtualAddress - Supplies the virtual address to check.

Return Value:

    TRUE if no page fault would be generated reading the virtual address,
    FALSE otherwise.

Environment:

    Kernel mode.

--*/

{
    ULONG i;
    ULONG PageSize;
    PMMPFN Pfn1;
    PFN_NUMBER BasePage;
    PFN_NUMBER PageCount;
    PTR_INFO TranslationRegisterEntry;
    ULONG_PTR TranslationLength;
    ULONG_PTR BaseAddress;
    ULONG_PTR EndAddress;
    PFN_NUMBER PageFrameIndex;
    PLIST_ENTRY NextMd;
    PMEMORY_ALLOCATION_DESCRIPTOR MemoryDescriptor;

    if ((VirtualAddress >= (PVOID)KSEG3_BASE) && (VirtualAddress < (PVOID)KSEG3_LIMIT)) {

        //
        // Bound this with the actual physical pages so that a busted
        // debugger access can't tube the machine.  Note only pages
        // with attributes of fully cached should be accessed this way
        // to avoid corrupting the TB.
        //
        // N.B.  You cannot use the line below as on IA64 this translates
        // into a direct TB query (tpa) and this address has not been
        // validated against the actual PFNs.  Instead, convert it manually
        // and then validate it.
        //
        // PageFrameIndex = MI_CONVERT_PHYSICAL_TO_PFN (VirtualAddress);
        //

        PageFrameIndex = (ULONG_PTR)VirtualAddress - KSEG3_BASE;
        PageFrameIndex = MI_VA_TO_PAGE (PageFrameIndex);

        if (MmPhysicalMemoryBlock != NULL) {

            if (MI_IS_PFN (PageFrameIndex)) {
                Pfn1 = MI_PFN_ELEMENT (PageFrameIndex);
                if ((Pfn1->u3.e1.CacheAttribute == MiCached) ||
                    (Pfn1->u3.e1.CacheAttribute == MiNotMapped)) {

                    return TRUE;
                }
            }

            return FALSE;
        }

        //
        // Walk loader blocks as it's all we have.
        //

        NextMd = KeLoaderBlock->MemoryDescriptorListHead.Flink;
        while (NextMd != &KeLoaderBlock->MemoryDescriptorListHead) {

            MemoryDescriptor = CONTAINING_RECORD (NextMd,
                                                  MEMORY_ALLOCATION_DESCRIPTOR,
                                                  ListEntry);

            BasePage = MemoryDescriptor->BasePage;
            PageCount = MemoryDescriptor->PageCount;

            if ((PageFrameIndex >= BasePage) &&
                (PageFrameIndex < BasePage + PageCount)) {

                //
                // Changes to the memory type requirements below need
                // to be done carefully as the debugger may not only
                // accidentally try to read this range, it may try
                // to write it !
                //

                switch (MemoryDescriptor->MemoryType) {
                    case LoaderFree:
                    case LoaderLoadedProgram:
                    case LoaderFirmwareTemporary:
                    case LoaderOsloaderStack:
                            return TRUE;
                }
                return FALSE;
            }

            NextMd = MemoryDescriptor->ListEntry.Flink;
        }

        return FALSE;
    }

    if (MiMappingsInitialized == FALSE) {
        TranslationRegisterEntry = &KeLoaderBlock->u.Ia64.ItrInfo[0];
    }
    else {
        TranslationRegisterEntry = &MiTrInfo[0];
    }

    //
    // Examine the 8 icache & dcache TR entries looking for a match.
    // It is too bad this the number of entries is hardcoded into the
    // loader block.  Since it is this way, assume also that the ITR
    // and DTR entries are contiguous and just keep walking into the DTR
    // if a match cannot be found in the ITR.
    //

    for (i = 0; i < 2 * NUMBER_OF_LOADER_TR_ENTRIES; i += 1) {

        PageSize = TranslationRegisterEntry->PageSize;

        if (PageSize != 0) {

            BaseAddress = TranslationRegisterEntry->VirtualAddress;

            //
            // Convert PageSize (really the power of 2 to use) into the
            // correct byte length the translation maps.  Note that the MiTrInfo
            // is already converted.
            //

            if (MiMappingsInitialized == FALSE) {
                TranslationLength = 1;
                while (PageSize != 0) {
                    TranslationLength = TranslationLength << 1;
                    PageSize -= 1;
                }
                EndAddress = BaseAddress + TranslationLength;
            }
            else {
                EndAddress = TranslationRegisterEntry->PhysicalAddress;
            }

            if ((VirtualAddress >= (PVOID) BaseAddress) &&
                (VirtualAddress < (PVOID) EndAddress)) {

                return TRUE;
            }
        }
        TranslationRegisterEntry += 1;
        if (TranslationRegisterEntry == MiLastTrEntry) {
            break;
        }
    }

    return FALSE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\i386\setmodfy.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

   setmodfy.c

Abstract:

    This module contains the setting modify bit routine for memory management.
    x86 specific.

Author:

    Lou Perazzoli (loup) 6-Jan-1990
    Landy Wang (landyw)  2-Jun-1997

Revision History:

--*/

#include "mi.h"

#if defined (_X86PAE_)
extern PMMPTE MmSystemCacheWorkingSetListPte;
#endif

VOID
MiSetModifyBit (
    IN PMMPFN Pfn
    )

/*++

Routine Description:

    This routine sets the modify bit in the specified PFN element
    and deallocates any allocated page file space.

Arguments:

    Pfn - Supplies the pointer to the PFN element to update.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, Working set mutex held and PFN lock held.

--*/

{

    //
    // Set the modified field in the PFN database, also, if the physical
    // page is currently in a paging file, free up the page file space
    // as the contents are now worthless.
    //

    MI_SET_MODIFIED (Pfn, 1, 0x16);

    if (Pfn->OriginalPte.u.Soft.Prototype == 0) {

        //
        // This page is in page file format, deallocate the page file space.
        //

        MiReleasePageFileSpace (Pfn->OriginalPte);

        //
        // Change original PTE to indicate no page file space is reserved,
        // otherwise the space will be deallocated when the PTE is
        // deleted.
        //

        Pfn->OriginalPte.u.Soft.PageFileHigh = 0;
    }


    return;
}

ULONG
FASTCALL
MiDetermineUserGlobalPteMask (
    IN PMMPTE Pte
    )

/*++

Routine Description:

    Builds a mask to OR with the PTE frame field.
    This mask has the valid and access bits set and
    has the global and owner bits set based on the
    address of the PTE.

    *******************  NOTE *********************************************
        THIS ROUTINE DOES NOT CHECK FOR PDEs WHICH NEED TO BE
        SET GLOBAL AS IT ASSUMES PDEs FOR SYSTEM SPACE ARE
        PROPERLY SET AT INITIALIZATION TIME!

Arguments:

    Pte - Supplies a pointer to the PTE in which to fill.

Return Value:

    Mask to OR into the frame to make a valid PTE.

Environment:

    Kernel mode, 386 specific.

--*/


{
    MMPTE Mask;

    Mask.u.Long = 0;
    Mask.u.Hard.Valid = 1;
    Mask.u.Hard.Accessed = 1;

#if defined (_X86PAE_)
    ASSERT (MmSystemCacheWorkingSetListPte != NULL);
#endif

    if (Pte <= MiHighestUserPte) {
        Mask.u.Hard.Owner = 1;
    }
    else if ((Pte < MiGetPteAddress (PTE_BASE)) ||
#if defined (_X86PAE_)
             (Pte >= MmSystemCacheWorkingSetListPte)
#else
             (Pte >= MiGetPteAddress (MM_SYSTEM_CACHE_WORKING_SET))
#endif
    ) {

        if (MI_IS_SESSION_PTE (Pte) == FALSE) {
#if defined (_X86PAE_)
          if ((Pte < (PMMPTE)PDE_BASE) || (Pte > (PMMPTE)PDE_TOP))
#endif
            Mask.u.Long |= MmPteGlobal.u.Long;
        }
    }
    else if ((Pte >= MiGetPdeAddress (NULL)) && (Pte <= MiHighestUserPde)) {
        Mask.u.Hard.Owner = 1;
    }

    //
    // Since the valid, accessed, global and owner bits are always in the
    // low dword of the PTE, returning a ULONG is ok.
    //

    return (ULONG)Mask.u.Long;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\ia64\altperm.c ===
/*++

Copyright (c) 1999  Microsoft Corporation

Module Name:

    altperm.c

Abstract:

    This module contains the routines to support 4K pages on IA64.

    An alternate set of permissions is kept that are on 4K boundaries.
    Permissions are kept for all memory, not just split pages
    and the information is updated on any call to NtVirtualProtect()
    and NtAllocateVirtualMemory().

Author:

    Koichi Yamada 18-Aug-1998
    Landy Wang (landyw) 02-June-1997

Revision History:

--*/

#include "mi.h"

#if defined(_MIALT4K_)

ULONG
MiFindProtectionForNativePte ( 
    PVOID VirtualAddress
    );

VOID
MiResetAccessBitForNativePtes (
    IN PVOID StartVirtual,
    IN PVOID EndVirtual,
    IN PEPROCESS Process
    );

LOGICAL
MiIsSplitPage (
    IN PVOID Virtual
    );

VOID
MiCheckDemandZeroCopyOnWriteFor4kPage (
    PVOID VirtualAddress,
    PEPROCESS Process
    );

LOGICAL
MiIsNativeGuardPage (
    IN PVOID VirtualAddress
    );

VOID
MiSetNativePteProtection (
    IN PVOID VirtualAddress,
    IN ULONGLONG NewPteProtection,
    IN LOGICAL PageIsSplit,
    IN PEPROCESS CurrentProcess
    );

VOID
MiSyncAltPte (
    IN PVOID VirtualAddress
    );

extern PMMPTE MmPteHit;

#if defined (_MI_DEBUG_ALTPTE)

typedef struct _MI_ALTPTE_TRACES {

    PETHREAD Thread;
    PMMPTE PointerPte;
    MMPTE PteContents;
    MMPTE NewPteContents;
    PVOID Caller;
    PVOID CallersCaller;
    PVOID Temp[2];

} MI_ALTPTE_TRACES, *PMI_ALTPTE_TRACES;

#define MI_ALTPTE_TRACE_SIZE   0x1000

VOID
FORCEINLINE
MiSnapAltPte (
    IN PMMPTE PointerPte,
    IN MMPTE NewValue,
    IN ULONG Id
    )
{
    ULONG Index;
    SIZE_T NumberOfBytes;
    PMI_ALTPTE_TRACES Information;
    PVOID HighestUserAddress;
    PLONG IndexPointer;
    PMI_ALTPTE_TRACES TablePointer;
    PWOW64_PROCESS Wow64Process;

    HighestUserAddress = MiGetVirtualAddressMappedByPte (MmWorkingSetList->HighestUserPte);
    ASSERT (HighestUserAddress <= (PVOID) _4gb);

    NumberOfBytes = ((ULONG_PTR)HighestUserAddress >> PTI_SHIFT) / 8;

    Wow64Process = PsGetCurrentProcess()->Wow64Process;
    ASSERT (Wow64Process != NULL);

    IndexPointer = (PLONG) ((PCHAR) Wow64Process->AltPermBitmap + NumberOfBytes);
    TablePointer = (PMI_ALTPTE_TRACES)IndexPointer + 1;

    Index = InterlockedIncrement (IndexPointer);

    Index &= (MI_ALTPTE_TRACE_SIZE - 1);

    Information = &TablePointer[Index];

    Information->Thread = PsGetCurrentThread ();
    Information->PteContents = *PointerPte;
    Information->NewPteContents = NewValue;
    Information->PointerPte = PointerPte;

#if 1
    Information->Caller = MiGetInstructionPointer ();
#else
    // Ip generates link (not compile) errors
    Information->Caller = (PVOID) __getReg (CV_IA64_Ip);

    // StIIp generates no compiler or link errors, but bugcheck 3Bs on the
    // execution of the actual generated mov r19=cr.iip instruction.
    Information->Caller = (PVOID) __getReg (CV_IA64_StIIP);
#endif

    Information->Temp[0] = (PVOID) (ULONG_PTR) Id;

    Information->CallersCaller = (PVOID) _ReturnAddress ();
}

#define MI_ALTPTE_TRACKING_BYTES    ((MI_ALTPTE_TRACE_SIZE + 1) * sizeof (MI_ALTPTE_TRACES))

#define MI_LOG_ALTPTE_CHANGE(_PointerPte, _PteContents, Id)    MiSnapAltPte(_PointerPte, _PteContents, Id)

#else

#define MI_ALTPTE_TRACKING_BYTES    0

#define MI_LOG_ALTPTE_CHANGE(_PointerPte, _PteContents, Id)

#endif


#define MI_WRITE_ALTPTE(PointerAltPte, AltPteContents, Id) {               \
                MI_LOG_ALTPTE_CHANGE (PointerAltPte, AltPteContents, Id);  \
                (PointerAltPte)->u.Long = AltPteContents.u.Long;           \
        }

#if defined (_MI_DEBUG_PTE) && defined (_MI_DEBUG_ALTPTE)
VOID
MiLogPteInAltTrace (
    IN PVOID InputNativeInformation
    )
{
    ULONG Index;
    SIZE_T NumberOfBytes;
    PMI_ALTPTE_TRACES Information;
    PVOID HighestUserAddress;
    PLONG IndexPointer;
    PMI_ALTPTE_TRACES TablePointer;
    PWOW64_PROCESS Wow64Process;
    PMI_PTE_TRACES NativeInformation;

    NativeInformation = (PMI_PTE_TRACES) InputNativeInformation;

    if (PsGetCurrentProcess()->Peb == NULL) {

        //
        // Don't log PTE traces during process creation if the altperm
        // bitmap pool allocation hasn't been done yet (the EPROCESS
        // Wow64Process pointer is already initialized) !
        //

        return;
    }

    if (PsGetCurrentProcess()->VmDeleted == 1) {

        //
        // Don't log PTE traces during process deletion as the altperm
        // bitmap pool allocation may have already been freed !
        //

        return;
    }

    HighestUserAddress = MiGetVirtualAddressMappedByPte (MmWorkingSetList->HighestUserPte);
    ASSERT (HighestUserAddress <= (PVOID) _4gb);

    NumberOfBytes = ((ULONG_PTR)HighestUserAddress >> PTI_SHIFT) / 8;

    Wow64Process = PsGetCurrentProcess()->Wow64Process;
    ASSERT (Wow64Process != NULL);

    IndexPointer = (PLONG) ((PCHAR) Wow64Process->AltPermBitmap + NumberOfBytes);
    TablePointer = (PMI_ALTPTE_TRACES)IndexPointer + 1;

    Index = InterlockedIncrement (IndexPointer);

    Index &= (MI_ALTPTE_TRACE_SIZE - 1);

    Information = &TablePointer[Index];

    Information->Thread = NativeInformation->Thread;
    Information->PteContents = NativeInformation->PteContents;
    Information->NewPteContents = NativeInformation->NewPteContents;
    Information->PointerPte = NativeInformation->PointerPte;

    Information->Caller = NativeInformation->StackTrace[0];
    Information->CallersCaller = NativeInformation->StackTrace[1];

    Information->Temp[0] = (PVOID) (ULONG_PTR) -1;
}
#endif

NTSTATUS
MmX86Fault (
    IN ULONG_PTR FaultStatus,
    IN PVOID VirtualAddress, 
    IN KPROCESSOR_MODE PreviousMode,
    IN PVOID TrapInformation
    )

/*++

Routine Description:

    This function is called by the kernel on data or instruction
    access faults if CurrentProcess->Wow64Process is non-NULL and the
    faulting address is within the 32-bit user address space.

    This routine determines the type of fault by checking the alternate
    4Kb granular page table and calls MmAccessFault() if necessary to 
    handle the page fault or the write fault.

Arguments:

    FaultStatus - Supplies fault status information bits.

    VirtualAddress - Supplies the virtual address which caused the fault.

    PreviousMode - Supplies the mode (kernel or user) in which the fault
                   occurred.

    TrapInformation - Opaque information about the trap, interpreted by the
                      kernel, not Mm.  Needed to allow fast interlocked access
                      to operate correctly.

Return Value:

    Returns the status of the fault handling operation.  Can be one of:
        - Success.
        - Access Violation.
        - Guard Page Violation.
        - In-page Error.

Environment:

    Kernel mode.

--*/

{
    ULONG i;
    ULONG Waited;
    PMMVAD TempVad;
    MMPTE PteContents;
    PMMPTE PointerAltPte;
    PMMPTE PointerAltPte2;
    PMMPTE PointerAltPteForNativePage;
    MMPTE AltPteContents;
    PMMPTE PointerPte;
    PMMPTE PointerPde;
    ULONGLONG NewPteProtection;
    LOGICAL FillZero;
    LOGICAL PageIsSplit;
    LOGICAL SharedPageFault;
    LOGICAL NativeGuardPage;
    PEPROCESS CurrentProcess;
    PWOW64_PROCESS Wow64Process;
    KIRQL OldIrql;
    NTSTATUS status;
    ULONGLONG ProtectionMaskOriginal;
    PMMPTE ProtoPte;
    PMMPFN Pfn1;
    PVOID OriginalVirtualAddress;
    ULONG_PTR Vpn;
    PVOID ZeroAddress;
    PMMPTE PointerPpe;
    ULONG FirstProtect;

    ASSERT (VirtualAddress < MmWorkingSetList->HighestUserAddress);

    if (KeGetCurrentIrql () > APC_LEVEL) {
        return MmAccessFault (FaultStatus,
                              VirtualAddress,
                              PreviousMode,
                              TrapInformation);
    }

    NewPteProtection = 0;
    FillZero = FALSE;
    PageIsSplit = FALSE;
    SharedPageFault = FALSE;
    NativeGuardPage = FALSE;
    OriginalVirtualAddress = VirtualAddress;

    CurrentProcess = PsGetCurrentProcess ();

    Wow64Process = CurrentProcess->Wow64Process;

    PointerPte = MiGetPteAddress (VirtualAddress);
    PointerAltPte = MiGetAltPteAddress (VirtualAddress);

    Vpn = MI_VA_TO_VPN (VirtualAddress);

#if DBG
    if (PointerPte == MmPteHit) {
        DbgPrint ("MM: PTE hit at %p\n", MmPteHit);
        DbgBreakPoint ();
    }
#endif

    //
    // Acquire the alternate table mutex, also blocking APCs.
    //

    LOCK_ALTERNATE_TABLE (Wow64Process);

    //
    // If a fork operation is in progress and the faulting thread
    // is not the thread performing the fork operation, block until
    // the fork is completed.
    //

    if (CurrentProcess->ForkInProgress != NULL) {

        UNLOCK_ALTERNATE_TABLE (Wow64Process);

        LOCK_WS (CurrentProcess);

        if (MiWaitForForkToComplete (CurrentProcess) == FALSE) {
            ASSERT (FALSE);
        }

        UNLOCK_WS (CurrentProcess);

        return STATUS_SUCCESS;
    }

    //
    // Check to see if the protection is registered in the alternate entry.
    //

    if (MI_CHECK_BIT (Wow64Process->AltPermBitmap, Vpn) == 0) {
        MiSyncAltPte (VirtualAddress);
    }

    //
    // Read the alternate PTE contents.
    //

    AltPteContents = *PointerAltPte;

    //
    // If the alternate PTE indicates no access for this 4K page
    // then deliver an access violation.
    //

    if (AltPteContents.u.Alt.NoAccess != 0) {
        status = STATUS_ACCESS_VIOLATION;
        MI_BREAK_ON_AV (VirtualAddress, 0x20);
        goto return_status;
    }
    
    //
    // Since we release the AltTable lock before calling MmAccessFault,
    // there is a chance that two threads may execute concurrently inside
    // MmAccessFault, which would yield bad results since the initial native
    // PTE for the page has only READ protection on it.  So if two threads
    // fault on the same address, one of them will execute through all of
    // this routine, however the other one will just return STATUS_SUCCESS
    // which will cause another fault to happen in which the protections
    // will be fixed on the native page.
    //
    // Note that in addition to the dual thread case there is also the case
    // of a single thread which also has an overlapped I/O pending (for example)
    // which can trigger an APC completion memory copy to the same page.
    // Protect against this by remaining at APC_LEVEL until clearing the
    // inpage in progress in the alternate PTE.
    //

    if (AltPteContents.u.Alt.InPageInProgress == 1) {

        //
        // Release the Alt PTE lock
        //

        UNLOCK_ALTERNATE_TABLE (Wow64Process);

        //
        // Flush the TB as MiSetNativePteProtection may have edited the PTE.
        //

        KiFlushSingleTb (OriginalVirtualAddress);

        //
        // Delay execution so that if this is a high priority thread,
        // it won't starve the other thread (that's doing the actual inpage)
        // as it may be running at a lower priority.
        //

        KeDelayExecutionThread (KernelMode, FALSE, (PLARGE_INTEGER)&MmShortTime);

        return STATUS_SUCCESS;
    }

    //
    // Check to see if the alternate entry is empty or if anyone has made any
    // commitments for the shared pages.
    //

    if ((AltPteContents.u.Long == 0) || 
        ((AltPteContents.u.Alt.Commit == 0) && (AltPteContents.u.Alt.Private == 0))) {
        //
        // If empty, get the protection information and fill the entry.
        //

        LOCK_WS (CurrentProcess);
        
        ProtoPte = MiCheckVirtualAddress (VirtualAddress,
                                          &FirstProtect,
                                          &TempVad);

        if (ProtoPte != NULL) {

            if (FirstProtect == MM_UNKNOWN_PROTECTION) {

                //
                // Ultimately this must be an address backed by a prototype
                // PTE in an image section (and the real PTE is currently
                // zero).  Therefore we are guaranteed that the protection
                // in the prototype PTE is the correct one to use (ie: there
                // is no WSLE overriding it).
                //
    
                ASSERT (!MI_IS_PHYSICAL_ADDRESS(ProtoPte));
    
                PointerPde = MiGetPteAddress (ProtoPte);
                LOCK_PFN (OldIrql);
                if (PointerPde->u.Hard.Valid == 0) {
                    MiMakeSystemAddressValidPfn (ProtoPte, OldIrql);
                }
    
                PteContents = *ProtoPte;
    
                if (PteContents.u.Long == 0) {
                    FirstProtect = MM_NOACCESS;
                }
                else if (PteContents.u.Hard.Valid == 1) {
    
                    //
                    // The prototype PTE is valid, get the protection from
                    // the PFN database.
                    //
    
                    Pfn1 = MI_PFN_ELEMENT (PteContents.u.Hard.PageFrameNumber);
    
                    FirstProtect = (ULONG) Pfn1->OriginalPte.u.Soft.Protection;
                }
                else {
    
                    //
                    // The prototype PTE is not valid, ie: subsection format,
                    // demand zero, pagefile or in transition - in all cases,
                    // the protection is in the PTE.
                    //
    
                    FirstProtect = (ULONG) PteContents.u.Soft.Protection;
                }
    
                UNLOCK_PFN (OldIrql);
    
                ASSERT (FirstProtect != MM_INVALID_PROTECTION);
            }
        
            UNLOCK_WS (CurrentProcess);
        
            if (FirstProtect == MM_INVALID_PROTECTION) {
                status = STATUS_ACCESS_VIOLATION;
                MI_BREAK_ON_AV (VirtualAddress, 0x21);
                goto return_status;
            }

            if (FirstProtect != MM_NOACCESS) {

                ProtectionMaskOriginal = MiMakeProtectionAteMask (FirstProtect);
            
                SharedPageFault = TRUE;
                ProtectionMaskOriginal |= MM_ATE_COMMIT;

                AltPteContents.u.Long = ProtectionMaskOriginal;
                AltPteContents.u.Alt.Protection = FirstProtect;

                //
                // Atomically update the PTE.
                //

                MI_WRITE_ALTPTE (PointerAltPte, AltPteContents, 1);
            }
        } 
        else {
            UNLOCK_WS (CurrentProcess);
        }
    } 

    if (AltPteContents.u.Alt.Commit == 0) {
        
        //
        // If the page is not committed, return an access violation.
        //

        status = STATUS_ACCESS_VIOLATION;
        MI_BREAK_ON_AV (VirtualAddress, 0x22);
        goto return_status;
    }

    //
    // Check whether the faulting page is split into 4k pages.
    //

    PointerAltPte2 = MiGetAltPteAddress (PAGE_ALIGN (VirtualAddress));
    PteContents = *PointerAltPte2;

    PageIsSplit = FALSE;

    for (i = 0; i < SPLITS_PER_PAGE; i += 1) {

        if ((PointerAltPte2->u.Long != 0) && 
            ((PointerAltPte2->u.Alt.Commit == 0) || 
             (PointerAltPte2->u.Alt.Accessed == 0) ||
             (PointerAltPte2->u.Alt.CopyOnWrite != 0) || 
             (PointerAltPte2->u.Alt.PteIndirect != 0) ||
             (PointerAltPte2->u.Alt.FillZero != 0))) {

            //
            // If it is a NoAccess, FillZero or Guard page, CopyOnWrite,
            // mark it as a split page.
            //

            PageIsSplit = TRUE;
            break;
        }

        if (PteContents.u.Long != PointerAltPte2->u.Long) {

            //
            // If the next 4kb page is different from the 1st 4k page
            // the page is split.
            //

            PageIsSplit = TRUE;
            break;
        }

        PointerAltPte2 += 1;
    }

    //
    // Get the real protection for the native PTE.
    //

    NewPteProtection = 0;

    PointerAltPte2 -= i;
    
    for (i = 0; i < SPLITS_PER_PAGE; i += 1) {

        PteContents.u.Long = PointerAltPte2->u.Long;

        if (PteContents.u.Alt.PteIndirect == 0) {
            NewPteProtection |= (PointerAltPte2->u.Long & ALT_PROTECTION_MASK);
        }

        PointerAltPte2 += 1;
    }

    PointerAltPte2 -= SPLITS_PER_PAGE;

    //
    // Set the protection for the native PTE.
    //

    MiSetNativePteProtection (VirtualAddress,
                              NewPteProtection,
                              PageIsSplit,
                              CurrentProcess);

    
    //
    // Check the indirect PTE reference case. If so, set the protection for  
    // the indirect PTE too.
    //

    if (AltPteContents.u.Alt.PteIndirect != 0) {

        PointerPte = (PMMPTE)(AltPteContents.u.Alt.PteOffset + PTE_UBASE);

        VirtualAddress = MiGetVirtualAddressMappedByPte (PointerPte);

        NewPteProtection = AltPteContents.u.Long & ALT_PROTECTION_MASK;

        if (AltPteContents.u.Alt.CopyOnWrite != 0) {
            NewPteProtection |= MM_PTE_COPY_ON_WRITE_MASK;
        }

        MiSetNativePteProtection (VirtualAddress,
                                  NewPteProtection,
                                  FALSE,
                                  CurrentProcess);
    }
        
    //
    // The faulting 4kb page must be a valid page, but we need to resolve it 
    // on a case by case basis.
    //

    ASSERT (AltPteContents.u.Long != 0);
    ASSERT (AltPteContents.u.Alt.Commit != 0);
        
    if (AltPteContents.u.Alt.Accessed == 0) {

        //
        // When PointerAte->u.Hard.Accessed is zero, there are 4 possibilities:
        // 
        //  1. Lowest Protection
        //  2. 4kb Demand Zero
        //  3. GUARD page fault
        //  4. This 4kb page is no access, but the other 4K page(s) within
        //     the native page has accessible permissions.
        //

        if (AltPteContents.u.Alt.FillZero != 0) {

            //
            // Schedule it later.
            //

            FillZero = TRUE;
        } 

        if ((AltPteContents.u.Alt.Protection & MM_GUARD_PAGE) != 0) {
            goto CheckGuardPage;
        }

        if (FillZero == FALSE) {

            //
            // This 4kb page has permission set to no access.
            //

            status = STATUS_ACCESS_VIOLATION;
            MI_BREAK_ON_AV (OriginalVirtualAddress, 0x23);
            goto return_status;
        }
    }

    if (MI_FAULT_STATUS_INDICATES_EXECUTION (FaultStatus)) {
        
        //
        // Execute permission is already given to IA32 by setting it in 
        // MI_MAKE_VALID_PTE().
        //

    }
    else if (MI_FAULT_STATUS_INDICATES_WRITE(FaultStatus)) {
        
        //
        // Check to see if this is a copy-on-write page.
        //

        if (AltPteContents.u.Alt.CopyOnWrite != 0) {

            //
            // Let MmAccessFault() perform the copy-on-write.
            //

            status = MmAccessFault (FaultStatus,
                                    VirtualAddress,
                                    PreviousMode,
                                    TrapInformation);

            if (NT_SUCCESS(status)) {

                //
                // Change the protection of the alternate pages for this
                // copy on write native page. 
                //

                ASSERT (PointerAltPte2 == MiGetAltPteAddress (PAGE_ALIGN(OriginalVirtualAddress)));
                
                for (i = 0; i < SPLITS_PER_PAGE; i += 1) {
                 
                    AltPteContents.u.Long = PointerAltPte2->u.Long;

                    if (AltPteContents.u.Alt.Commit != 0) {
                        
                        //
                        // When a copy-on-write page is touched, the native
                        // page will be made private by MM, so all the sub-4k
                        // pages within the native page should be made
                        // private (if they are committed/mapped).
                        //

                        AltPteContents.u.Alt.Private = 1;

                        if (AltPteContents.u.Alt.CopyOnWrite != 0) {

                            AltPteContents.u.Alt.CopyOnWrite = 0;
                            AltPteContents.u.Hard.Write = 1;
                
                            AltPteContents.u.Alt.Protection = 
                                    MI_MAKE_PROTECT_NOT_WRITE_COPY(AltPteContents.u.Alt.Protection);
                        }

                        //
                        // Atomically update the PTE.
                        //

                        MI_WRITE_ALTPTE (PointerAltPte2, AltPteContents, 2);
                    }

                    PointerAltPte2 += 1;
                }
            }

            goto return_status;
        }
            
        if (AltPteContents.u.Hard.Write == 0) {
            status = STATUS_ACCESS_VIOLATION;
            MI_BREAK_ON_AV (OriginalVirtualAddress, 0x24);
            goto return_status;
        }
    }

CheckGuardPage:

    //
    // Indicate that we have begun updating the PTE for this page.
    // Subsequent faults on this native page will be restarted.
    // This should happen only if the PTE isn't valid.
    //
    
    PointerAltPteForNativePage = MiGetAltPteAddress (PAGE_ALIGN (VirtualAddress));
    
    for (i = 0; i < SPLITS_PER_PAGE; i += 1) {

        AltPteContents = *PointerAltPteForNativePage;
        AltPteContents.u.Alt.InPageInProgress = TRUE;

        MI_WRITE_ALTPTE (PointerAltPteForNativePage, AltPteContents, 3);

        PointerAltPteForNativePage += 1;
    }
    
    //
    // Let MmAccessFault() perform an inpage, dirty-bit setting, etc.
    //
    // Release the alternate table mutex but block APCs to prevent an
    // incoming APC that references the same page from deadlocking this thread.
    // It is safe to drop allow APCs only after the in progress bit in
    // the alternate PTE has been cleared.
    //

    KeRaiseIrql (APC_LEVEL, &OldIrql);

    UNLOCK_ALTERNATE_TABLE (Wow64Process);
    
    status = MmAccessFault (FaultStatus,
                            VirtualAddress,
                            PreviousMode,
                            TrapInformation);

    LOCK_ALTERNATE_TABLE (Wow64Process);

    //
    // This IRQL lower will have no effect since the alternate table guarded
    // mutex is now held again.
    //

    KeLowerIrql (OldIrql);

    for (i = 0; i < SPLITS_PER_PAGE; i += 1) {

        PointerAltPteForNativePage -= 1;

        AltPteContents = *PointerAltPteForNativePage;
        AltPteContents.u.Alt.InPageInProgress = FALSE;

        MI_WRITE_ALTPTE (PointerAltPteForNativePage, AltPteContents, 4);
    }

    AltPteContents = *PointerAltPte;

    if ((AltPteContents.u.Alt.Protection & MM_GUARD_PAGE) != 0) {
                    
        AltPteContents = *PointerAltPte;
        AltPteContents.u.Alt.Protection &= ~MM_GUARD_PAGE;
        AltPteContents.u.Alt.Accessed = 1;
        
        MI_WRITE_ALTPTE (PointerAltPte, AltPteContents, 5);

        if ((status != STATUS_PAGE_FAULT_GUARD_PAGE) &&
            (status != STATUS_STACK_OVERFLOW)) {
        
            UNLOCK_ALTERNATE_TABLE (Wow64Process);

            status = MiCheckForUserStackOverflow (VirtualAddress);

            LOCK_ALTERNATE_TABLE (Wow64Process);
        }
    }
    else if (status == STATUS_GUARD_PAGE_VIOLATION) {

        //
        // Native PTE has the guard bit set, but the AltPte
        // doesn't have it.
        //
        // See if any of the AltPtes has the guard bit set.
        //

        ASSERT (PointerAltPteForNativePage == MiGetAltPteAddress (PAGE_ALIGN (VirtualAddress)));
            
        for (i = 0; i < SPLITS_PER_PAGE; i += 1) {

            if (PointerAltPteForNativePage->u.Alt.Protection & MM_GUARD_PAGE) {
                status = STATUS_SUCCESS;
                break;
            }

            PointerAltPteForNativePage += 1;
        }
    }
    else if ((SharedPageFault == TRUE) && (status == STATUS_ACCESS_VIOLATION)) {
        
        AltPteContents.u.Long = PointerAltPte->u.Long;

        AltPteContents.u.Alt.Commit = 0;

        MI_WRITE_ALTPTE (PointerAltPte, AltPteContents, 6);
    }

return_status:

    KiFlushSingleTb (OriginalVirtualAddress);

    if (FillZero == TRUE) {

        //
        // Zero the specified 4k page.
        //

        PointerAltPte = MiGetAltPteAddress (VirtualAddress);

        PointerPte = MiGetPteAddress (VirtualAddress);
        PointerPde = MiGetPdeAddress (VirtualAddress);
        PointerPpe = MiGetPpeAddress (VirtualAddress);

        do {

            if (PointerAltPte->u.Alt.FillZero == 0) {

                //
                // Another thread has already completed the zero operation.
                //

                goto Finished;
            }

            //
            // Make the PPE and PDE valid as well as the
            // page table for the original PTE.  This guarantees
            // TB forward progress for the TB indirect fault.
            // 

            LOCK_WS_UNSAFE (CurrentProcess);

            if (MiDoesPpeExistAndMakeValid (PointerPpe,
                                            CurrentProcess,
                                            MM_NOIRQL,
                                            &Waited) == FALSE) {
                PteContents.u.Long = 0;
            }
            else if (MiDoesPdeExistAndMakeValid (PointerPde,
                                                 CurrentProcess,
                                                 MM_NOIRQL,
                                                 &Waited) == FALSE) {

                PteContents.u.Long = 0;
            }
            else {

                //
                // Now it is safe to read PointerPte.
                //

                PteContents = *PointerPte;
            }

            //
            // The alternate PTE may have been trimmed during the period
            // prior to the working set mutex being acquired or when it
            // was released prior to being reacquired.
            //

            if (MiIsAddressValid (PointerAltPte, TRUE) == TRUE) {
                break;
            }

            UNLOCK_WS_UNSAFE (CurrentProcess);

        } while (TRUE);

        AltPteContents.u.Long = PointerAltPte->u.Long;

        if (PteContents.u.Hard.Valid != 0) { 

            ZeroAddress = KSEG_ADDRESS (PteContents.u.Hard.PageFrameNumber);

            ZeroAddress = 
                (PVOID)((ULONG_PTR)ZeroAddress + 
                        ((ULONG_PTR)PAGE_4K_ALIGN(VirtualAddress) & (PAGE_SIZE-1)));

            RtlZeroMemory (ZeroAddress, PAGE_4K);

            UNLOCK_WS_UNSAFE (CurrentProcess);

            AltPteContents.u.Alt.FillZero = 0;
            AltPteContents.u.Alt.Accessed = 1;
        }
        else {

            UNLOCK_WS_UNSAFE (CurrentProcess);

            AltPteContents.u.Alt.Accessed = 0;
        }

        MI_WRITE_ALTPTE (PointerAltPte, AltPteContents, 7);
    }

Finished:

    UNLOCK_ALTERNATE_TABLE (Wow64Process);

    return status;
}

VOID
MiSyncAltPte (
    IN PVOID VirtualAddress
    )

/*++

Routine Description:

    This function is called to compute the alternate PTE entries for the
    given virtual address.  It is called with the alternate table mutex held
    and updates the alternate table bitmap before returning.

Arguments:

    VirtualAddress - Supplies the virtual address to evaluate.

Return Value:

    None.

Environment:

    Kernel mode, alternate table mutex held.

--*/

{
    PMMVAD TempVad;
    MMPTE PteContents;
    PMMPTE PointerAltPte;
    MMPTE AltPteContents;
    PMMPTE PointerPde;
    PEPROCESS CurrentProcess;
    PWOW64_PROCESS Wow64Process;
    KIRQL OldIrql;
    PMMPTE ProtoPte;
    PMMPFN Pfn1;
    ULONG_PTR Vpn;
    ULONG FirstProtect;
    ULONG SecondProtect;
    PSUBSECTION Subsection;
    PSUBSECTION FirstSubsection;
    PCONTROL_AREA ControlArea;
    PMMVAD Vad;

    Vpn = MI_VA_TO_VPN (VirtualAddress);

    CurrentProcess = PsGetCurrentProcess ();

    Wow64Process = CurrentProcess->Wow64Process;

    LOCK_WS_UNSAFE (CurrentProcess);

    ASSERT ((MiGetPpeAddress (VirtualAddress)->u.Hard.Valid == 0) ||
            (MiGetPdeAddress (VirtualAddress)->u.Hard.Valid == 0) ||
            (MiGetPteAddress (VirtualAddress)->u.Long == 0));

    ProtoPte = MiCheckVirtualAddress (VirtualAddress,
                                      &FirstProtect,
                                      &TempVad);

    if (FirstProtect == MM_UNKNOWN_PROTECTION) {

        //
        // Ultimately this must be an address backed by a prototype PTE in
        // an image section (and the real PTE is currently zero).  Therefore
        // we are guaranteed that the protection in the prototype PTE 
        // is the correct one to use (ie: there is no WSLE overriding it).
        //

        Vad = MiLocateAddress (VirtualAddress);

        ASSERT (Vad != NULL);

        ControlArea = Vad->ControlArea;
        ASSERT (ControlArea->u.Flags.Image == 1);

        if ((ControlArea->u.Flags.Rom == 1) ||
            (ControlArea->u.Flags.GlobalOnlyPerSession == 1)) {

            FirstSubsection = (PSUBSECTION)((PLARGE_CONTROL_AREA)ControlArea + 1);
        }
        else {
            FirstSubsection = (PSUBSECTION)(ControlArea + 1);
        }

        ASSERT (!MI_IS_PHYSICAL_ADDRESS (ProtoPte));

        //
        // Get the original protection information from the prototype PTE.
        //
        // A non-NULL subsection indicates split permissions need to be
        // applied on the ALT PTEs for this native PTE.
        //

        Subsection = NULL;

        //
        // Read the prototype PTE contents without the PFN lock - the PFN
        // lock is only needed if the prototype PTE is valid so that the
        // PFN's original PTE field can be fetched.
        //

        PteContents = *ProtoPte;

DecodeProto:

        if (PteContents.u.Hard.Valid == 0) {

            if (PteContents.u.Long == 0) {
                FirstProtect = MM_NOACCESS;
            }
            else {

                //
                // The prototype PTE is not valid, ie: subsection format,
                // demand zero, pagefile or in transition - in all cases,
                // the protection is in the PTE.
                //

                FirstProtect = (ULONG) PteContents.u.Soft.Protection;

                if (PteContents.u.Soft.SplitPermissions == 1) {
                    Subsection = (PSUBSECTION) 1;
                }
            }
        }
        else {

            PointerPde = MiGetPteAddress (ProtoPte);
            LOCK_PFN (OldIrql);
            if (PointerPde->u.Hard.Valid == 0) {
                MiMakeSystemAddressValidPfn (ProtoPte, OldIrql);
            }

            PteContents = *ProtoPte;

            if (PteContents.u.Hard.Valid == 0) {
                UNLOCK_PFN (OldIrql);
                goto DecodeProto;
            }

            //
            // The prototype PTE is valid, get the protection from
            // the PFN database.  Unless the protection is split, in
            // which case it must be retrieved from the subsection.
            // Note that if the page has been trimmed already then
            // the original PTE is no longer in subsection format.
            //

            Pfn1 = MI_PFN_ELEMENT (PteContents.u.Hard.PageFrameNumber);

            FirstProtect = (ULONG) Pfn1->OriginalPte.u.Soft.Protection;

            UNLOCK_PFN (OldIrql);

            if (PteContents.u.Hard.Cache == MM_PTE_CACHE_RESERVED) {
                Subsection = (PSUBSECTION) 1;
            }
        }

        ASSERT (FirstProtect != MM_INVALID_PROTECTION);

        if (Subsection != NULL) {

            //
            // Compute the subsection address as the split permissions are
            // stored there.  Note to reduce lock contention this was
            // deferred until after the PFN lock was released.
            //

            Subsection = FirstSubsection;

            do {
                ASSERT (Subsection->SubsectionBase != NULL);

                if ((ProtoPte >= Subsection->SubsectionBase) &&
                    (ProtoPte < Subsection->SubsectionBase + Subsection->PtesInSubsection)) {
                    break;
                }

                Subsection = Subsection->NextSubsection;

            } while (TRUE);

            ASSERT (Subsection != NULL);

            //
            // Get the protection for each 4K page from the subsection.
            //

            FirstProtect = Subsection->u.SubsectionFlags.Protection;
            SecondProtect = Subsection->LastSplitPageProtection;
        }
        else {

            //
            // If demand-zero and copy-on-write, remove copy-on-write.
            // Note this cannot happen for images with native (ie: multiple
            // subsection) support.
            //

            if ((!IS_PTE_NOT_DEMAND_ZERO (PteContents)) && 
                (PteContents.u.Soft.Protection & MM_COPY_ON_WRITE_MASK)) {

                FirstProtect = FirstProtect & ~MM_PROTECTION_COPY_MASK;
            }

            SecondProtect = FirstProtect;
        }

        ASSERT ((FirstProtect != MM_INVALID_PROTECTION) &&
                (SecondProtect != MM_INVALID_PROTECTION));

        UNLOCK_WS_UNSAFE (CurrentProcess);

        PointerAltPte = MiGetAltPteAddress (PAGE_ALIGN (VirtualAddress));

        //
        // Update the first alternate PTE.
        //

        AltPteContents.u.Long = MiMakeProtectionAteMask (FirstProtect) | MM_ATE_COMMIT;
        AltPteContents.u.Alt.Protection = FirstProtect;

        if ((FirstProtect & MM_PROTECTION_COPY_MASK) == 0) {

            //
            // If copy-on-write is removed, make it private.
            //

            AltPteContents.u.Alt.Private = 1;
        }

        MI_WRITE_ALTPTE (PointerAltPte, AltPteContents, 8);

        //
        // Update the second alternate PTE, computing it
        // only if it is different from the first.
        //

        if (Subsection != NULL) {

            AltPteContents.u.Long = MiMakeProtectionAteMask (SecondProtect) | MM_ATE_COMMIT;
            AltPteContents.u.Alt.Protection = SecondProtect;

            if ((SecondProtect & MM_PROTECTION_COPY_MASK) == 0) {

                //
                // If copy-on-write is removed, make it private.
                //

                AltPteContents.u.Alt.Private = 1;
            }
        }
    }
    else {
        UNLOCK_WS_UNSAFE (CurrentProcess);

        AltPteContents.u.Long = MiMakeProtectionAteMask (FirstProtect);
        AltPteContents.u.Alt.Protection = FirstProtect;
        AltPteContents.u.Alt.Commit = 1;

        PointerAltPte = MiGetAltPteAddress (PAGE_ALIGN (VirtualAddress));

        //
        // Update the alternate PTEs.
        //

        MI_WRITE_ALTPTE (PointerAltPte, AltPteContents, 9);
    }

    MI_WRITE_ALTPTE (PointerAltPte + 1, AltPteContents, 0xA);

    //
    // Update the bitmap.
    //

    MI_SET_BIT (Wow64Process->AltPermBitmap, Vpn);

    return;
}

VOID
MiProtectImageFileFor4kPage (
    IN PVOID VirtualAddress,
    IN SIZE_T ViewSize
    )
{
    ULONG Vpn;
    PVOID EndAddress;
    PULONG Bitmap;
    PWOW64_PROCESS Wow64Process;

    ASSERT (BYTE_OFFSET (VirtualAddress) == 0);

    Vpn = (ULONG) MI_VA_TO_VPN (VirtualAddress);

    EndAddress = (PVOID)((PCHAR) VirtualAddress + ViewSize - 1);

    Wow64Process = PsGetCurrentProcess()->Wow64Process;

    Bitmap = Wow64Process->AltPermBitmap;

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    do {

        if (MI_CHECK_BIT (Bitmap, Vpn) == 0) {
            MiSyncAltPte (VirtualAddress);
        }

        VirtualAddress = (PVOID)((PCHAR) VirtualAddress + PAGE_SIZE);

        Vpn += 1;

    } while (VirtualAddress <= EndAddress);

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    return;
}


//
// Define and initialize the protection conversion table for the
// Alternate Permission Table Entries.
//

ULONGLONG MmProtectToAteMask[32] = {
                       MM_PTE_NOACCESS | MM_ATE_NOACCESS,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READWRITE | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK | MM_ATE_COPY_ON_WRITE,
                       MM_PTE_EXECUTE_READWRITE | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK | MM_ATE_COPY_ON_WRITE,
                       MM_PTE_NOACCESS | MM_ATE_NOACCESS,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READWRITE | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK | MM_ATE_COPY_ON_WRITE,
                       MM_PTE_EXECUTE_READWRITE | MM_PTE_ACCESS_MASK,
                       MM_PTE_EXECUTE_READ | MM_PTE_ACCESS_MASK | MM_ATE_COPY_ON_WRITE,
                       MM_PTE_NOACCESS | MM_ATE_NOACCESS,
                       MM_PTE_EXECUTE_READ,
                       MM_PTE_EXECUTE_READ,
                       MM_PTE_EXECUTE_READ,
                       MM_PTE_EXECUTE_READWRITE,
                       MM_PTE_EXECUTE_READ | MM_ATE_COPY_ON_WRITE,
                       MM_PTE_EXECUTE_READWRITE,
                       MM_PTE_EXECUTE_READ | MM_ATE_COPY_ON_WRITE,
                       MM_PTE_NOACCESS | MM_ATE_NOACCESS,
                       MM_PTE_EXECUTE_READ,
                       MM_PTE_EXECUTE_READ,
                       MM_PTE_EXECUTE_READ,
                       MM_PTE_EXECUTE_READWRITE,
                       MM_PTE_EXECUTE_READ | MM_ATE_COPY_ON_WRITE,
                       MM_PTE_EXECUTE_READWRITE,
                       MM_PTE_EXECUTE_READ | MM_ATE_COPY_ON_WRITE
                    };

#define MiMakeProtectionAteMask(NewProtect) MmProtectToAteMask[NewProtect]

VOID
MiProtectFor4kPage (
    IN PVOID Starting4KAddress,
    IN SIZE_T Size,
    IN ULONG NewProtect,
    IN ULONG Flags,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This routine sets the permissions on the alternate bitmap (based on
    4K page sizes).  The base and size are assumed to be aligned for
    4K pages already.

Arguments:

    Starting4KAddress - Supplies the base address (assumed to be 4K aligned already).

    Size - Supplies the size to be protected (assumed to be 4K aligned already).

    NewProtect - Supplies the protection for the new pages.

    Flags - Supplies the alternate table entry request flags.

    Process - Supplies a pointer to the process in which to create the 
              protections on the alternate table.

Return Value:
 
    None.

Environment:

    Kernel mode.  Address creation mutex held at APC_LEVEL.

--*/

{
    RTL_BITMAP BitMap;
    ULONG NumberOfPtes;
    ULONG StartingNativeVpn;
    PVOID Ending4KAddress;
    ULONG NewProtectNotCopy;
    ULONGLONG ProtectionMask;
    ULONGLONG ProtectionMaskNotCopy;
    PMMPTE StartAltPte;
    PMMPTE EndAltPte;
    PMMPTE StartAltPte0;
    PMMPTE EndAltPte0;
    PWOW64_PROCESS Wow64Process;
    MMPTE AltPteContents;
    MMPTE TempAltPte;

    Ending4KAddress = (PCHAR)Starting4KAddress + Size - 1;

    //
    // If the addresses are not WOW64 then nothing needs to be done here.
    //

    if ((Starting4KAddress >= MmWorkingSetList->HighestUserAddress) ||
        (Ending4KAddress >= MmWorkingSetList->HighestUserAddress)) {

        return;
    }

    //
    // Set up the protection to be used for this range of addresses.
    //

    ProtectionMask = MiMakeProtectionAteMask (NewProtect);

    if ((NewProtect & MM_COPY_ON_WRITE_MASK) == MM_COPY_ON_WRITE_MASK) {
        NewProtectNotCopy = NewProtect & ~MM_PROTECTION_COPY_MASK;
        ProtectionMaskNotCopy = MiMakeProtectionAteMask (NewProtectNotCopy);
    }
    else {
        NewProtectNotCopy = NewProtect;
        ProtectionMaskNotCopy = ProtectionMask;
    }    

    if (Flags & ALT_COMMIT) {
        ProtectionMask |= MM_ATE_COMMIT;
        ProtectionMaskNotCopy |= MM_ATE_COMMIT; 
    }

    //
    // Get the entry in the table for each of these addresses.
    //

    StartAltPte = MiGetAltPteAddress (Starting4KAddress);
    EndAltPte = MiGetAltPteAddress (Ending4KAddress);

    NumberOfPtes = (ULONG) ADDRESS_AND_SIZE_TO_SPAN_PAGES (Starting4KAddress,
                                           (ULONG_PTR)Ending4KAddress -
                                           (ULONG_PTR)Starting4KAddress);
    ASSERT (NumberOfPtes != 0);

    StartAltPte0 = MiGetAltPteAddress (PAGE_ALIGN (Starting4KAddress));
    EndAltPte0 = MiGetAltPteAddress ((ULONG_PTR)PAGE_ALIGN(Ending4KAddress)+PAGE_SIZE-1);

    Wow64Process = Process->Wow64Process;

    StartingNativeVpn = (ULONG) MI_VA_TO_VPN (Starting4KAddress);

    TempAltPte.u.Long = 0;

    //
    // Acquire the mutex guarding the alternate page table.
    //

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    if (!(Flags & ALT_ALLOCATE) && 
        (MI_CHECK_BIT(Wow64Process->AltPermBitmap, StartingNativeVpn) == 0)) {

        UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
        return;
    }

    //
    // Change all of the protections.
    //

    while (StartAltPte <= EndAltPte) {

        AltPteContents.u.Long = StartAltPte->u.Long;

        TempAltPte.u.Long = ProtectionMask;
        TempAltPte.u.Alt.Protection = NewProtect;

        if (!(Flags & ALT_ALLOCATE)) {
            
            if (AltPteContents.u.Alt.Private != 0) {

                //
                // If it is already private, don't make it writecopy.
                //
                
                TempAltPte.u.Long = ProtectionMaskNotCopy;
                TempAltPte.u.Alt.Protection = NewProtectNotCopy;

                //
                // Private is sticky bit.
                //

                TempAltPte.u.Alt.Private = 1;
            } 

            if (AltPteContents.u.Alt.FillZero != 0) {

                TempAltPte.u.Alt.Accessed = 0;
                TempAltPte.u.Alt.FillZero = 1;
            }

            //
            // Leave the other sticky attribute bits.
            //

            TempAltPte.u.Alt.Lock = AltPteContents.u.Alt.Lock;
            TempAltPte.u.Alt.PteIndirect = AltPteContents.u.Alt.PteIndirect;
            TempAltPte.u.Alt.PteOffset = AltPteContents.u.Alt.PteOffset;
        }

        if (Flags & ALT_CHANGE) {

            //
            // If it is a change request, make commit sticky.
            //

            TempAltPte.u.Alt.Commit = AltPteContents.u.Alt.Commit;
        }

        //
        // Atomic PTE update.
        //

        MI_WRITE_ALTPTE (StartAltPte, TempAltPte, 0xB);

        StartAltPte += 1;
    }

    ASSERT (TempAltPte.u.Long != 0);

    if (Flags & ALT_ALLOCATE) {

        //
        // Fill the empty Alt PTE as NoAccess ATE at the end.
        //

        EndAltPte += 1;

        while (EndAltPte <= EndAltPte0) {

            if (EndAltPte->u.Long == 0) {

                TempAltPte.u.Long = EndAltPte->u.Long;
                TempAltPte.u.Alt.NoAccess = 1;

                //
                // Atomic PTE update.
                //

                MI_WRITE_ALTPTE (EndAltPte, TempAltPte, 0xC);
            }

            EndAltPte += 1;
        }

        //
        // Update the permission bitmap.
        //
        // Initialize the bitmap inline for speed.
        //

        BitMap.SizeOfBitMap = (ULONG)((ULONG_PTR)MmWorkingSetList->HighestUserAddress >> PTI_SHIFT);
        BitMap.Buffer = Wow64Process->AltPermBitmap;

        RtlSetBits (&BitMap, StartingNativeVpn, NumberOfPtes);
    }

    MiResetAccessBitForNativePtes (Starting4KAddress, Ending4KAddress, Process);

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
}

VOID
MiProtectMapFileFor4kPage (
    IN PVOID Base,
    IN SIZE_T Size,
    IN ULONG NewProtect,
    IN SIZE_T CommitSize,
    IN PMMPTE PointerPte,
    IN PMMPTE LastPte,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This routine sets the permissions on the alternate bitmap (based on
    4K page sizes).  The base and size are assumed to be aligned for
    4K pages already.

Arguments:

    Base - Supplies the base address (assumed to be 4K aligned already).

    Size - Supplies the size to be protected (assumed to be 4K aligned already).

    NewProtect - Supplies the protection for the new pages.

    CommitSize - Supplies the commit size.

    PointerPte - Supplies the starting PTE.

    LastPte - Supplies the last PTE.

    Process - Supplies a pointer to the process in which to create the 
              protections on the alternate table.

Return Value:
 
    None.

Environment:

    Kernel mode.  Address creation mutex held at APC_LEVEL.

--*/

{
    RTL_BITMAP BitMap;
    PVOID Starting4KAddress;
    PVOID Ending4KAddress;
    ULONGLONG ProtectionMask;
    PMMPTE StartAltPte;
    PMMPTE EndAltPte;
    PMMPTE EndAltPte0;
    PWOW64_PROCESS Wow64Process;
    MMPTE TempAltPte;
    PMMPTE LastCommitPte;
    ULONG Vpn;
    ULONG VpnRange;

    Wow64Process = Process->Wow64Process;
    Starting4KAddress = Base;
    Ending4KAddress = (PCHAR)Base + Size - 1;

    //
    // If the addresses are not WOW64 then nothing needs to be done here.
    //

    if ((Starting4KAddress >= MmWorkingSetList->HighestUserAddress) ||
        (Ending4KAddress >= MmWorkingSetList->HighestUserAddress)) {

        return;
    }

    Vpn = (ULONG) MI_VA_TO_VPN (Base);
    VpnRange = (ULONG) (MI_VA_TO_VPN (Ending4KAddress) - Vpn + 1);

    //
    // Set up the protection to be used for this range of addresses.
    //

    ProtectionMask = MiMakeProtectionAteMask (NewProtect);

    //
    // Get the entry in the table for each of these addresses.
    //

    StartAltPte = MiGetAltPteAddress (Starting4KAddress);
    EndAltPte = MiGetAltPteAddress (Ending4KAddress);
    EndAltPte0 = MiGetAltPteAddress ((ULONG_PTR)PAGE_ALIGN(Ending4KAddress)+PAGE_SIZE-1);

    LastCommitPte = PointerPte + BYTES_TO_PAGES (CommitSize);

    TempAltPte.u.Long = ProtectionMask;
    TempAltPte.u.Alt.Protection = NewProtect;

    //
    // Initialize the bitmap inline for speed.
    //

    BitMap.SizeOfBitMap = (ULONG)((ULONG_PTR)MmWorkingSetList->HighestUserAddress >> PTI_SHIFT);
    BitMap.Buffer = Wow64Process->AltPermBitmap;


    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    KeAcquireGuardedMutexUnsafe (&MmSectionCommitMutex);

    //
    // And then change all of the protections.
    //

    while (StartAltPte <= EndAltPte) {

        if (PointerPte < LastCommitPte) {
            TempAltPte.u.Alt.Commit = 1;
        }
        else if ((PointerPte <= LastPte) && (PointerPte->u.Long != 0)) {
            TempAltPte.u.Alt.Commit = 1;
        }
        else {
            TempAltPte.u.Alt.Commit = 0;
        }

        //
        // Atomic PTE update.
        //

        MI_WRITE_ALTPTE (StartAltPte, TempAltPte, 0xD);

        StartAltPte += 1;

        if (((ULONG_PTR)StartAltPte & ((SPLITS_PER_PAGE * sizeof(MMPTE))-1)) == 0) {
            PointerPte += 1;
        }
    }

    ASSERT (TempAltPte.u.Long != 0);

    KeReleaseGuardedMutexUnsafe (&MmSectionCommitMutex);

    //
    // Fill the empty Alt PTE as NoAccess ATE at the end.
    //

    EndAltPte += 1;

    while (EndAltPte <= EndAltPte0) {

        if (EndAltPte->u.Long == 0) {

            TempAltPte.u.Long = EndAltPte->u.Long;
            TempAltPte.u.Alt.NoAccess = 1;

            //
            // Atomic PTE size update.
            //

            MI_WRITE_ALTPTE (EndAltPte, TempAltPte, 0xE);
        }

        EndAltPte += 1;
    }
    
    RtlSetBits (&BitMap, Vpn, VpnRange);

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
}

VOID
MiReleaseFor4kPage (
    IN PVOID StartVirtual,
    IN PVOID EndVirtual,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function releases a region of pages within the virtual address
    space of the subject process.

Arguments:

    StartVirtual - Supplies the start address of the region of pages
                   to be released.

    EndVirtual - Supplies the end address of the region of pages to be released.

    Process - Supplies a pointer to the process in which to release the 
              region of pages.

Return Value:

    None.

Environment:

    Kernel mode.  Address creation mutex held at APC_LEVEL.

--*/

{
    RTL_BITMAP BitMap;
    PMMPTE StartAltPte;
    PMMPTE EndAltPte;
    MMPTE TempAltPte;
    PVOID VirtualAddress; 
    PVOID OriginalStartVa;
    PVOID OriginalEndVa;
    ULONG i;
    PWOW64_PROCESS Wow64Process;
    PFN_NUMBER NumberOfAltPtes;

    ASSERT (StartVirtual <= EndVirtual);

    OriginalStartVa = StartVirtual;
    OriginalEndVa = EndVirtual;
    Wow64Process = Process->Wow64Process;

    StartAltPte = MiGetAltPteAddress (StartVirtual);
    EndAltPte = MiGetAltPteAddress (EndVirtual);
    NumberOfAltPtes = EndAltPte - StartAltPte + 1;

    TempAltPte.u.Long = 0;
    TempAltPte.u.Alt.NoAccess = 1;
    TempAltPte.u.Alt.FillZero = 1;

    StartVirtual = PAGE_ALIGN (StartVirtual);

    VirtualAddress = StartVirtual;

    ASSERT ((ULONG) ADDRESS_AND_SIZE_TO_SPAN_PAGES (StartVirtual,
                                           (ULONG_PTR)EndVirtual -
                                           (ULONG_PTR)StartVirtual) != 0);

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    do {
        MI_WRITE_ALTPTE (StartAltPte, TempAltPte, 0xF);

        NumberOfAltPtes -= 1;
        StartAltPte += 1;

    } while (NumberOfAltPtes != 0);

    while (VirtualAddress <= EndVirtual) {

        StartAltPte = MiGetAltPteAddress (VirtualAddress);
        TempAltPte = *StartAltPte;

        i = 0;

        //
        // Note that this check must be made as the ATE fill above may not
        // have begun on a native page boundary and this scan always does.
        //

        while (TempAltPte.u.Long == StartAltPte->u.Long) {
            i += 1;
            if (i == SPLITS_PER_PAGE) {
                while (i != 0) {
                    MI_WRITE_ALTPTE (StartAltPte, ZeroPte, 0x10);
                    StartAltPte -= 1;
                    i -= 1;
                }
                break;
            }
            StartAltPte += 1;
        }
        
        VirtualAddress = (PVOID)((PCHAR) VirtualAddress + PAGE_SIZE);
    }

    MiResetAccessBitForNativePtes (StartVirtual, EndVirtual, Process);

    //
    // Mark the native released pages as non-split so they get re-synced
    // at MmX86Fault() time.  NOTE: StartVirtual should be aligned on
    // the native page size before executing this code.
    //
    
    if (BYTE_OFFSET (OriginalStartVa) != 0) {
        
        if (MiArePreceding4kPagesAllocated (OriginalStartVa) != FALSE) {

            StartVirtual = PAGE_ALIGN ((ULONG_PTR)StartVirtual + PAGE_SIZE);
        }
    }

    EndVirtual = (PVOID) ((ULONG_PTR)EndVirtual | (PAGE_SIZE - 1));

    if (BYTE_OFFSET (OriginalEndVa) != (PAGE_SIZE - 1)) {
        
        if (MiAreFollowing4kPagesAllocated (OriginalEndVa) != FALSE) {

            EndVirtual = (PVOID) ((ULONG_PTR)EndVirtual - PAGE_SIZE);
        }
    }

    if (StartVirtual < EndVirtual) {

        //
        // Initialize the bitmap inline for speed.
        //

        BitMap.SizeOfBitMap = (ULONG)((ULONG_PTR)MmWorkingSetList->HighestUserAddress >> PTI_SHIFT);
        BitMap.Buffer = Wow64Process->AltPermBitmap;

        RtlClearBits (&BitMap,
                      (ULONG) MI_VA_TO_VPN (StartVirtual),
                      (ULONG) (MI_VA_TO_VPN (EndVirtual) - MI_VA_TO_VPN (StartVirtual) + 1));
    }

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
}

VOID
MiDecommitFor4kPage (
    IN PVOID StartVirtual,
    IN PVOID EndVirtual,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function decommits a region of pages within the virtual address
    space of a subject process.

Arguments:

    StartVirtual - Supplies the start address of the region of pages
                   to be decommitted.

    EndVirtual - Supplies the end address of the region of the pages 
                 to be decommitted.

    Process - Supplies a pointer to the process in which to decommit a
              a region of pages.

Return Value:

    None.

Environment:

    Address space mutex held at APC_LEVEL.

--*/

{
    PMMPTE StartAltPte;
    PMMPTE EndAltPte;
    MMPTE TempAltPte;
    PWOW64_PROCESS Wow64Process;

    Wow64Process = Process->Wow64Process;

    ASSERT (StartVirtual <= EndVirtual);

    StartAltPte = MiGetAltPteAddress (StartVirtual);
    EndAltPte = MiGetAltPteAddress (EndVirtual);

    ASSERT ((ULONG) ADDRESS_AND_SIZE_TO_SPAN_PAGES (StartVirtual,
                                           (ULONG_PTR)EndVirtual -
                                           (ULONG_PTR)StartVirtual) != 0);

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    while (StartAltPte <= EndAltPte) {

        TempAltPte.u.Long = StartAltPte->u.Long;
        TempAltPte.u.Alt.Commit = 0;
        TempAltPte.u.Alt.Accessed = 0;
        TempAltPte.u.Alt.FillZero = 1;

        //
        // Atomic PTE update.
        //

        MI_WRITE_ALTPTE (StartAltPte, TempAltPte, 0x11);

        StartAltPte += 1;
    }

    //
    // Update the native PTEs and flush the relevant native TB entries.
    //

    MiResetAccessBitForNativePtes (StartVirtual, EndVirtual, Process);

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
}


VOID
MiDeleteFor4kPage (
    IN PVOID VirtualAddress,
    IN PVOID EndVirtual,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function deletes a region of pages within the virtual address
    space of the subject process.

Arguments:

    VirtualAddress - Supplies the start address of the region of pages
                   to be deleted.

    EndVirtual - Supplies the end address of the region of pages 
                 to be deleted.

    Process - Supplies a pointer to the process in which to delete
              the region of pages.

Return Value:

    None.

Environment:

    Kernel mode.  Address creation mutex held at APC_LEVEL.

--*/

{
    RTL_BITMAP BitMap;
    PMMPTE EndAltPte;
    PMMPTE StartAltPte;
    PWOW64_PROCESS Wow64Process;
    PFN_NUMBER NumberOfAltPtes;
    ULONG Vpn;
    ULONG VpnRange;

    ASSERT (VirtualAddress <= EndVirtual);

    StartAltPte = MiGetAltPteAddress (VirtualAddress);
    EndAltPte = MiGetAltPteAddress (EndVirtual);

    NumberOfAltPtes = EndAltPte - StartAltPte + 1;

    ASSERT (ADDRESS_AND_SIZE_TO_SPAN_PAGES (VirtualAddress,
                                           (ULONG_PTR)EndVirtual -
                                           (ULONG_PTR)VirtualAddress) != 0);

    Wow64Process = Process->Wow64Process;

    Vpn = (ULONG) MI_VA_TO_VPN (VirtualAddress);
    VpnRange = (ULONG) (MI_VA_TO_VPN (EndVirtual) - Vpn + 1);

    //
    // Initialize the bitmap inline for speed.
    //

    BitMap.SizeOfBitMap = (ULONG)((ULONG_PTR)MmWorkingSetList->HighestUserAddress >> PTI_SHIFT);

    BitMap.Buffer = Wow64Process->AltPermBitmap;

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    do {

        MI_WRITE_ALTPTE (StartAltPte, ZeroPte, 0x12);

        NumberOfAltPtes -= 1;
        StartAltPte += 1;

    } while (NumberOfAltPtes != 0);

    RtlClearBits (&BitMap, Vpn, VpnRange);

    //
    // VirtualAddress and EndVirtual are already aligned to the native
    // PAGE_SIZE so no need to readjust them before removing the split markers.
    //

    MiResetAccessBitForNativePtes (VirtualAddress, EndVirtual, Process);

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
}

LOGICAL
MiArePreceding4kPagesAllocated (
    IN PVOID VirtualAddress
    )
/*++

Routine Description:

    This function checks to see if the specified virtual address contains any
    preceding 4k allocations within the native page.

Arguments:

    VirtualAddress - Supplies the virtual address to check.
    
Return Value:

    TRUE if the address has preceding 4k pages, FALSE if not.

Environment:

    Kernel mode, address creation mutex held, APCs disabled.

--*/

{
    PMMPTE AltPte;
    PMMPTE AltPteEnd;

    ASSERT (BYTE_OFFSET (VirtualAddress) != 0);

    AltPte = MiGetAltPteAddress (PAGE_ALIGN(VirtualAddress));
    AltPteEnd = MiGetAltPteAddress (VirtualAddress);

    //
    // No need to hold the AltPte mutex as the address space mutex
    // is held which prevents allocation or deletion of the AltPte entries
    // inside the table.
    //

    while (AltPte != AltPteEnd) {

        if ((AltPte->u.Long == 0) || 
            ((AltPte->u.Alt.NoAccess == 1) && (AltPte->u.Alt.Protection != MM_NOACCESS))) {
    
            //
            // The page's alternate PTE hasn't been allocated yet to the process
            // or it's marked no access.
            //

            NOTHING;
        }
        else {
            return TRUE;
        }

        AltPte += 1;
    }

    return FALSE;
}


LOGICAL
MiAreFollowing4kPagesAllocated (
    IN PVOID VirtualAddress
    )
/*++

Routine Description:

    This function checks to see if the specified virtual address contains any
    following 4k allocations within the native page.

Arguments:

    VirtualAddress - Supplies the virtual address to check.
    
Return Value:

    TRUE if the address has following 4k pages, FALSE if not.

Environment:

    Kernel mode, address creation mutex held, APCs disabled.

--*/

{
    PMMPTE AltPte;
    PMMPTE AltPteEnd;

    ASSERT (BYTE_OFFSET (VirtualAddress) != 0);

    AltPteEnd = MiGetAltPteAddress (PAGE_ALIGN ((ULONG_PTR)VirtualAddress + PAGE_SIZE));

    AltPte = MiGetAltPteAddress (VirtualAddress) + 1;

    ASSERT (AltPte < AltPteEnd);

    //
    // No need to hold the AltPte mutex as the address space mutex
    // is held which prevents allocation or deletion of the AltPte entries
    // inside the table.
    //

    while (AltPte != AltPteEnd) {

        if ((AltPte->u.Long == 0) || 
            ((AltPte->u.Alt.NoAccess == 1) && (AltPte->u.Alt.Protection != MM_NOACCESS))) {
    
            //
            // The page's alternate PTE hasn't been allocated yet to the process
            // or it's marked no access.
            //

            NOTHING;
        }
        else {
            return TRUE;
        }

        AltPte += 1;
    }

    return FALSE;
}

VOID
MiResetAccessBitForNativePtes (
    IN PVOID VirtualAddress,
    IN PVOID EndVirtual,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function resets the access bit of the native PTEs which have
    corresponding initialized alternate PTEs.
    
    This results in the next access to these VAs incurring a TB miss.

    The miss will then be processed by the 4k TB miss handler (if the
    cache reserved bit is set in the native PTE) and either handled
    inline (if the alternate PTE allows it) or via a call to MmX86Fault.

    If the cache reserved bit is *NOT* set in the native PTE (ie: the
    native page does not contain split permissions), then the access
    will still go to KiPageFault and then to MmX86Fault and then to
    MmAccessFault for general processing to set the access bit.

Arguments:

    VirtualAddress - Supplies the start address of the region of pages
                     to be inspected. 

    EndVirtual - Supplies the end address of the region of the pages 
                 to be inspected.

    Process - Supplies the pointer to the process.

Return Value:

    None.

Environment:

    Alternate table mutex held at APC_LEVEL.

--*/

{
    ULONG NumberOfPtes;
    MMPTE PteContents;
    PMMPTE PointerPte;
    PMMPTE PointerPde;
    PMMPTE PointerPpe;
    LOGICAL FirstTime;
    ULONG Waited;
    PULONG Bitmap;
    PVOID Virtual[MM_MAXIMUM_FLUSH_COUNT];

    NumberOfPtes = 0;
    Bitmap = Process->Wow64Process->AltPermBitmap;

    VirtualAddress = PAGE_ALIGN (VirtualAddress);

    PointerPte = MiGetPteAddress (VirtualAddress);

    FirstTime = TRUE;

    LOCK_WS_UNSAFE (Process);

    while (VirtualAddress <= EndVirtual) {

        if ((FirstTime == TRUE) || MiIsPteOnPdeBoundary (PointerPte)) {

            PointerPde = MiGetPteAddress (PointerPte);
            PointerPpe = MiGetPdeAddress (PointerPte);

            if (MiDoesPpeExistAndMakeValid (PointerPpe, 
                                            Process, 
                                            MM_NOIRQL,
                                            &Waited) == FALSE) {

                //
                // This page directory parent entry is empty,
                // go to the next one.
                //

                PointerPpe += 1;
                PointerPde = MiGetVirtualAddressMappedByPte (PointerPpe);
                PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
                VirtualAddress = MiGetVirtualAddressMappedByPte (PointerPte);
                continue;
            }

            if (MiDoesPdeExistAndMakeValid (PointerPde, 
                                            Process,
                                            MM_NOIRQL,
                                            &Waited) == FALSE) {


                //
                // This page directory entry is empty,
                // go to the next one.
                //

                PointerPde += 1;
                PointerPte = MiGetVirtualAddressMappedByPte(PointerPde);
                VirtualAddress = MiGetVirtualAddressMappedByPte(PointerPte);
                continue;
            }
                    
            FirstTime = FALSE;

        }
            
        PteContents = *PointerPte;

        if (PteContents.u.Hard.Valid != 0) {

            if ((PteContents.u.Hard.Accessed != 0) &&
                (MI_CHECK_BIT (Bitmap, MI_VA_TO_VPN (VirtualAddress)))) {

                PteContents.u.Hard.Accessed = 0;

                MI_WRITE_VALID_PTE_NEW_PROTECTION (PointerPte, PteContents);
            }

            //
            // Flush this valid native TB entry.  Note this is done even if no
            // changes were made to it above because our caller may not
            // have flushed the native PTE if the starting 4k address was
            // preceded by another valid 4k page within the same native page,
            // or if the ending 4k address was followed by another valid 4k
            // page within the same native page.
            //

            if (NumberOfPtes < MM_MAXIMUM_FLUSH_COUNT) {
                Virtual[NumberOfPtes] = VirtualAddress;
                NumberOfPtes += 1;
            }
        }

        PointerPte += 1;
        VirtualAddress = (PVOID)((ULONG_PTR)VirtualAddress + PAGE_SIZE); 
    }

    UNLOCK_WS_UNSAFE (Process);

    if (NumberOfPtes == 0) {
        NOTHING;
    }
    else if (NumberOfPtes < MM_MAXIMUM_FLUSH_COUNT) {
        KeFlushMultipleTb (NumberOfPtes, &Virtual[0], FALSE);
    }
    else {
        KeFlushProcessTb (FALSE);
    }

    return;
}

VOID
MiQueryRegionFor4kPage (
    IN PVOID BaseAddress,
    IN PVOID EndAddress,
    IN OUT PSIZE_T RegionSize,
    IN OUT PULONG RegionState,
    IN OUT PULONG RegionProtect,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function checks the size of the region which has the same memory 
    state.

Arguments:

    BaseAddress - Supplies the base address of the region of pages
                  to be queried.
 
    EndAddress - Supplies the end of address of the region of pages
                 to be queried.

    RegionSize - Supplies the original region size.  Returns a region
                 size for 4k pages if different.

    RegionState - Supplies the original region state.  Returns a region
                  state for 4k pages if different.

    RegionProtect - Supplies the original protection.  Returns a protection
                    for 4k pages if different.

    Process - Supplies a pointer to the process to be queried.

Return Value:

    Returns the size of the region.

Environment:

    Kernel mode.  Address creation mutex held at APC_LEVEL.

--*/

{
   PMMPTE AltPte;
   PMMPTE LastAltPte;
   MMPTE AltContents;
   PWOW64_PROCESS Wow64Process;
   SIZE_T RegionSize4k;

   //
   // If above the Wow64 max address, just return.
   //

   if ((BaseAddress >= MmWorkingSetList->HighestUserAddress) ||
       (EndAddress >= MmWorkingSetList->HighestUserAddress)) {

        return;
   }

   AltPte = MiGetAltPteAddress (BaseAddress);
   LastAltPte = MiGetAltPteAddress (EndAddress);

   Wow64Process = Process->Wow64Process;

   LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

   if (MI_CHECK_BIT (Wow64Process->AltPermBitmap, 
                     MI_VA_TO_VPN(BaseAddress)) == 0) {

       UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
       return;
   }

   AltContents.u.Long = AltPte->u.Long;

   if (AltContents.u.Long == 0) {
       UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
       return;
   }

   *RegionProtect = MI_CONVERT_FROM_PTE_PROTECTION(AltContents.u.Alt.Protection);

   if (AltContents.u.Alt.Commit != 0) {

       *RegionState = MEM_COMMIT;
   }
   else {

       if ((AltPte->u.Long == 0) || 
           ((AltPte->u.Alt.NoAccess == 1) && (AltPte->u.Alt.Protection != MM_NOACCESS))) {
           *RegionState   = MEM_FREE;
           *RegionProtect = PAGE_NOACCESS;
       }
       else {
           *RegionState = MEM_RESERVE;
           *RegionProtect = 0;
       }
   }

   AltPte += 1;
   RegionSize4k = PAGE_4K;

   while (AltPte <= LastAltPte) {

       if ((AltPte->u.Alt.Protection != AltContents.u.Alt.Protection) ||
           (AltPte->u.Alt.Commit != AltContents.u.Alt.Commit)) {

            //
            // The state for this address does not match, bail.
            //

            break;
       }

       RegionSize4k += PAGE_4K;
       AltPte += 1;
   }

   UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

   *RegionSize = RegionSize4k;
}

ULONG
MiQueryProtectionFor4kPage (
    IN PVOID BaseAddress,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function queries the protection for a specified 4k page.

Arguments:

    BaseAddress - Supplies a base address of the 4k page. 

    Process - Supplies a pointer to the relevant process.

Return Value:

    Returns the protection of the 4k page.

Environment:

    Kernel mode.  Address creation mutex held at APC_LEVEL.

--*/

{
    ULONG Protection;
    PMMPTE PointerAltPte;
    PWOW64_PROCESS Wow64Process;

    Wow64Process = Process->Wow64Process;

    PointerAltPte = MiGetAltPteAddress (BaseAddress);

    Protection = 0;

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
    
    if (MI_CHECK_BIT(Wow64Process->AltPermBitmap, 
                     MI_VA_TO_VPN(BaseAddress)) != 0) {

        Protection = (ULONG)PointerAltPte->u.Alt.Protection;
    }

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
    
    return Protection;
}

//
// Note 1 is added to the charge to account for the page table page. 
//

#define MI_ALTERNATE_PAGE_TABLE_CHARGE(HighestUserAddress) \
((((((ULONG_PTR)HighestUserAddress) >> PAGE_4K_SHIFT) * sizeof (MMPTE)) >> PAGE_SHIFT) + 1)


NTSTATUS
MiInitializeAlternateTable (
    IN PEPROCESS Process,
    IN PVOID HighestUserAddress
    )

/*++

Routine Description:

    This function initializes the alternate table for the specified process.

Arguments:

    Process - Supplies a pointer to the process to initialize the alternate 
              table for.

    HighestUserAddress - Supplies the highest 32-bit user address for this
                         process.

Return Value:

    NTSTATUS.

Environment:

--*/

{
    PULONG AltTablePointer; 
    PWOW64_PROCESS Wow64Process;
    SIZE_T AltPteCharge;
    SIZE_T NumberOfBytes;

    //
    // Charge commitment now for the alternate PTE table pages as they will
    // need to be dynamically created later at fault time.
    //
    // Add X64K to include alternate PTEs for the guard region.
    //

    HighestUserAddress = (PVOID)((PCHAR)HighestUserAddress + X64K);

    AltPteCharge = MI_ALTERNATE_PAGE_TABLE_CHARGE (HighestUserAddress);

    if (MiChargeCommitment (AltPteCharge, NULL) == FALSE) {
        return STATUS_COMMITMENT_LIMIT;
    }

    NumberOfBytes = ((ULONG_PTR)HighestUserAddress >> PTI_SHIFT) / 8;

    NumberOfBytes += MI_ALTPTE_TRACKING_BYTES;

    AltTablePointer = (PULONG) ExAllocatePoolWithTag (NonPagedPool,
                                                      NumberOfBytes,
                                                      'AlmM');

    if (AltTablePointer == NULL) {
        MiReturnCommitment (AltPteCharge);
        return STATUS_NO_MEMORY;
    }

    RtlZeroMemory (AltTablePointer, NumberOfBytes);

    Wow64Process = Process->Wow64Process;

    Wow64Process->AltPermBitmap = AltTablePointer;

    KeInitializeGuardedMutex (&Wow64Process->AlternateTableLock);

    MmWorkingSetList->HighestUserPte = MiGetPteAddress (HighestUserAddress);
    MmWorkingSetList->HighestAltPte = MiGetAltPteAddress (HighestUserAddress);

    return STATUS_SUCCESS;
}

VOID
MiDuplicateAlternateTable (
    IN PEPROCESS CurrentProcess,
    IN PEPROCESS ProcessToInitialize
    )

/*++

Routine Description:

    This function duplicates the alternate table bitmap and the alternate PTEs
    themselves for the specified process.

Arguments:

    Process - Supplies a pointer to the process whose alternate information
              should be copied.

    ProcessToInitialize - Supplies a pointer to the target process who should
                          receive the new alternate information.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, working set and address space mutex
    and ForkInProgress flag held.

--*/

{
    PVOID Source;
    KAPC_STATE ApcState;
    PMMPTE PointerPte;
    PMMPTE PointerAltPte;
    PMMPTE PointerPde;
    PVOID Va;
    ULONG i;
    ULONG j;
    ULONG Waited;

    //
    // It's not necessary to acquire the alternate table mutex since both the
    // address space and ForkInProgress resources are held on entry.
    //

    RtlCopyMemory (ProcessToInitialize->Wow64Process->AltPermBitmap,
                   CurrentProcess->Wow64Process->AltPermBitmap,
                   ((ULONG_PTR)MmWorkingSetList->HighestUserAddress >> PTI_SHIFT)/8);

    //
    // Since the PPE for the Alternate Table is shared with hyperspace,
    // we can assume it is always present without performing 
    // MiDoesPpeExistAndMakeValid().
    //

    PointerPde = MiGetPdeAddress (ALT4KB_PERMISSION_TABLE_START);
    PointerPte = MiGetPteAddress (ALT4KB_PERMISSION_TABLE_START);

    Va = ALT4KB_PERMISSION_TABLE_START;

    do {

        if (MiDoesPdeExistAndMakeValid (PointerPde,
                                        CurrentProcess,
                                        MM_NOIRQL,
                                        &Waited) == TRUE) {

            //
            // Duplicate any addresses that exist in the parent, bringing them
            // in from disk or materializing them as necessary.  Note the
            // KSEG address is used for each parent address to avoid allocating
            // a system PTE for this mapping as this routine cannot fail (the
            // overall fork is too far along to tolerate a failure).
            //
    
            for (i = 0; i < PTE_PER_PAGE; i += 1) {
    
                if (PointerPte->u.Long != 0) {
    
                    if (MiDoesPdeExistAndMakeValid (PointerPte,
                                                    CurrentProcess,
                                                    MM_NOIRQL,
                                                    &Waited) == TRUE) {
    
                        ASSERT (PointerPte->u.Hard.Valid == 1);
    
                        Source = KSEG_ADDRESS (PointerPte->u.Hard.PageFrameNumber);
    
                        KeStackAttachProcess (&ProcessToInitialize->Pcb,
                                              &ApcState);
    
                        RtlCopyMemory (Va, Source, PAGE_SIZE);
    
                        //
                        // Eliminate any bits that should NOT be copied.
                        //
    
                        PointerAltPte = (PMMPTE) Va;
    
                        for (j = 0; j < PTE_PER_PAGE; j += 1) {
                            if (PointerAltPte->u.Alt.InPageInProgress == 1) {
                                PointerAltPte->u.Alt.InPageInProgress = 0;
                            }
                            PointerAltPte += 1;
                        }
    
                        KeUnstackDetachProcess (&ApcState);
                    }
                }
                
                Va = (PVOID)((PCHAR) Va + PAGE_SIZE);
                PointerPte += 1;
            }
        }

        PointerPde += 1;
        PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
        Va = MiGetVirtualAddressMappedByPte (PointerPte);

    } while (Va < ALT4KB_PERMISSION_TABLE_END);

    //
    // Initialize the child's 32-bit PEB to be the same as the parent's.
    //

    ProcessToInitialize->Wow64Process->Wow64 = CurrentProcess->Wow64Process->Wow64;

    return;
}


VOID
MiDeleteAlternateTable (
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function deletes the alternate table for the specified process.

Arguments:

    Process - Supplies a pointer to the process to delete the alternate 
              table for.

Return Value:

    None.

Environment:

    Kernel mode, APCs disabled, working set mutex held.

--*/

{
    PVOID HighestUserAddress;
    PMMPTE PointerPte;
    PMMPTE PointerPde;
    PVOID Va;
    PVOID TempVa;
    ULONG i;
    ULONG Waited;
    MMPTE_FLUSH_LIST PteFlushList;
    PWOW64_PROCESS Wow64Process;
    KIRQL OldIrql;

    Wow64Process = Process->Wow64Process;

    if (Wow64Process->AltPermBitmap == NULL) {

        //
        // This is only NULL (and Wow64Process non-NULL) if a memory allocation
        // failed during process creation.
        //

        return;
    }
    
    //
    // Since the PPE for the Alternate Table is shared with hyperspace,
    // we can assume it is always present without performing 
    // MiDoesPpeExistAndMakeValid().
    //

    Va = ALT4KB_PERMISSION_TABLE_START;
    PointerPte = MiGetPteAddress (ALT4KB_PERMISSION_TABLE_START);
    PointerPde = MiGetPdeAddress (ALT4KB_PERMISSION_TABLE_START);

    PteFlushList.Count = 0;

    do {

        if (MiDoesPdeExistAndMakeValid (PointerPde,
                                        Process,
                                        MM_NOIRQL,
                                        &Waited) == TRUE) {

            //
            // Delete the PTE entries mapping the Alternate Table.
            //
    
            TempVa = Va;
    
            LOCK_PFN (OldIrql);
    
            for (i = 0; i < PTE_PER_PAGE; i += 1) {
    
                if (PointerPte->u.Long != 0) {
    
                    if (IS_PTE_NOT_DEMAND_ZERO (*PointerPte)) {
    
                        MiDeletePte (PointerPte,
                                     TempVa,
                                     TRUE,
                                     Process,
                                     NULL,
                                     &PteFlushList,
                                     OldIrql);
                    }
                    else {
    
                        MI_WRITE_INVALID_PTE (PointerPte, ZeroPte);
                    }
                                        
                }
                
                TempVa = (PVOID)((PCHAR)TempVa + PAGE_SIZE);
                PointerPte += 1;
            }
    
            //
            // Delete the PDE entry mapping the Alternate Table.
            //
    
            TempVa = MiGetVirtualAddressMappedByPte (PointerPde);
    
            MiDeletePte (PointerPde,
                         TempVa,
                         TRUE,
                         Process,
                         NULL,
                         &PteFlushList,
                         OldIrql);
            
            MiFlushPteList (&PteFlushList, FALSE);
    
            UNLOCK_PFN (OldIrql);
        }

        PointerPde += 1;
        PointerPte = MiGetVirtualAddressMappedByPte (PointerPde);
        Va = MiGetVirtualAddressMappedByPte (PointerPte);

    } while (Va < ALT4KB_PERMISSION_TABLE_END);

    HighestUserAddress = MmWorkingSetList->HighestUserAddress;

    ASSERT (HighestUserAddress != NULL);

    //
    // Add X64K to include alternate PTEs for the guard region.
    //

    HighestUserAddress = (PVOID)((PCHAR)HighestUserAddress + X64K);

    MiReturnCommitment (MI_ALTERNATE_PAGE_TABLE_CHARGE (HighestUserAddress));

    ExFreePool (Wow64Process->AltPermBitmap);

    Wow64Process->AltPermBitmap = NULL;

    return;
}

VOID
MiRemoveAliasedVadsApc (
    IN PKAPC Apc,
    OUT PKNORMAL_ROUTINE *NormalRoutine,
    IN OUT PVOID NormalContext,
    IN OUT PVOID *SystemArgument1,
    IN OUT PVOID *SystemArgument2
    )
{
    ULONG i;
    PALIAS_VAD_INFO2 AliasBase;
    PEPROCESS Process;
    PALIAS_VAD_INFO AliasInformation;

    UNREFERENCED_PARAMETER (Apc);
    UNREFERENCED_PARAMETER (NormalContext);
    UNREFERENCED_PARAMETER (SystemArgument2);

    Process = PsGetCurrentProcess ();

    AliasInformation = (PALIAS_VAD_INFO) *SystemArgument1;
    AliasBase = (PALIAS_VAD_INFO2)(AliasInformation + 1);

    LOCK_ADDRESS_SPACE (Process);

    for (i = 0; i < AliasInformation->NumberOfEntries; i += 1) {

        ASSERT (AliasBase->BaseAddress < _2gb);

        MiUnsecureVirtualMemory (AliasBase->SecureHandle, TRUE);

        MiUnmapViewOfSection (Process,
                              (PVOID) (ULONG_PTR)AliasBase->BaseAddress,
                              TRUE);

        AliasBase += 1;
    }

    UNLOCK_ADDRESS_SPACE (Process);

    ExFreePool (AliasInformation);

    //
    // Clear the normal routine so this routine doesn't get called again
    // for the same request.
    //

    *NormalRoutine = NULL;
}

VOID
MiRemoveAliasedVads (
    IN PEPROCESS Process,
    IN PMMVAD Vad
    )
/*++

Routine Description:

    This function removes all aliased VADs spawned earlier from the
    argument VAD.

Arguments:

    Process - Supplies the EPROCESS pointer to the current process.

    Vad - Supplies a pointer to the VAD describing the range being removed.

Return Value:

    None.

Environment:

    Kernel mode, address creation and working set mutexes held, APCs disabled.

--*/

{
    PALIAS_VAD_INFO AliasInformation;

    ASSERT (Process->Wow64Process != NULL);

    AliasInformation = ((PMMVAD_LONG)Vad)->AliasInformation;

    ASSERT (AliasInformation != NULL);

    if ((Process->Flags & PS_PROCESS_FLAGS_VM_DELETED) == 0) {

        //
        // This process is still alive so queue an APC to delete each aliased
        // VAD.  This is because the deletion must also get rid of page table
        // commitment which requires that it search (and modify) VAD trees,
        // etc - but the address space mutex is already held and the caller
        // is not generally prepared for all this to change at this point.
        //

        KeInitializeApc (&AliasInformation->Apc,
                         &PsGetCurrentThread()->Tcb,
                         OriginalApcEnvironment,
                         (PKKERNEL_ROUTINE) MiRemoveAliasedVadsApc,
                         NULL,
                         (PKNORMAL_ROUTINE) MiRemoveAliasedVadsApc,
                         KernelMode,
                         (PVOID) AliasInformation);

        KeInsertQueueApc (&AliasInformation->Apc, AliasInformation, NULL, 0);
    }
    else {

        //
        // This process is exiting so all the VADs are being rundown anyway.
        // Just free the pool and let normal rundown handle the aliases.
        //

        ExFreePool (AliasInformation);
    }
}

PVOID
MiDuplicateAliasVadList (
    IN PMMVAD Vad
    )
{
    SIZE_T AliasInfoSize;
    PALIAS_VAD_INFO AliasInfo;
    PALIAS_VAD_INFO NewAliasInfo;

    AliasInfo = ((PMMVAD_LONG)Vad)->AliasInformation;

    ASSERT (AliasInfo != NULL);

    AliasInfoSize = sizeof (ALIAS_VAD_INFO) + AliasInfo->MaximumEntries * sizeof (ALIAS_VAD_INFO2);

    NewAliasInfo = ExAllocatePoolWithTag (NonPagedPool,
                                          AliasInfoSize,
                                          'AdaV');

    if (NewAliasInfo != NULL) {
        RtlCopyMemory (NewAliasInfo, AliasInfo, AliasInfoSize);
    }

    return NewAliasInfo;
}

#define ALIAS_VAD_INCREMENT 4

NTSTATUS
MiSetCopyPagesFor4kPage (
    IN PEPROCESS Process,
    IN PMMVAD Vad,
    IN OUT PVOID StartingAddress,
    IN OUT PVOID EndingAddress,
    IN ULONG NewProtection,
    OUT PMMVAD *CallerNewVad
    )
/*++

Routine Description:

    This function creates another map for the existing mapped view space
    and gives it copy-on-write protection.  This is called when
    SetProtectionOnSection() tries to change the protection from
    non-copy-on-write to copy-on-write.  Since a large native page cannot be
    split to shared and copy-on-write 4kb pages, references to the
    copy-on-write page(s) need to be fixed to reference the
    new mapped view space and this is done through the smart TB handler
    and the alternate page table entries.

Arguments:

    Process - Supplies the EPROCESS pointer to the current process.

    Vad - Supplies a pointer to the VAD describing the range to protect.
   
    StartingAddress - Supplies a pointer to the starting address to protect.

    EndingAddress - Supplies a pointer to the ending address to the protect.

    NewProtect - Supplies the new protection to set.

    CallerNewVad - Returns the new VAD the caller should use for this range.

Return Value:

    NTSTATUS.

Environment:

    Kernel mode, address creation mutex held, APCs disabled.

--*/

{
    ULONG_PTR Vpn;
    PALIAS_VAD_INFO2 AliasBase;
    HANDLE Handle;
    PMMVAD VadParent;
    PMMVAD_LONG NewVad;
    SIZE_T AliasInfoSize;
    PALIAS_VAD_INFO AliasInfo;
    PALIAS_VAD_INFO NewAliasInfo;
    LARGE_INTEGER SectionOffset;
    SIZE_T CapturedViewSize;
    PVOID CapturedBase;
    PVOID Va;
    PVOID VaEnd;
    PVOID Alias;
    PMMPTE PointerPte;
    PMMPTE AltPte;
    MMPTE AltPteContents;
    LOGICAL AliasReferenced;
    SECTION Section;
    PCONTROL_AREA ControlArea;
    NTSTATUS status;
    PWOW64_PROCESS Wow64Process;
    ULONGLONG ProtectionMask;
    ULONGLONG ProtectionMaskNotCopy;
    ULONG NewProtectNotCopy;

    AliasReferenced = FALSE;
    StartingAddress = PAGE_ALIGN(StartingAddress);
    EndingAddress =  (PVOID)((ULONG_PTR)PAGE_ALIGN(EndingAddress) + PAGE_SIZE - 1);
    
    SectionOffset.QuadPart = (ULONG_PTR)MI_64K_ALIGN((ULONG_PTR)StartingAddress - 
                                                     (ULONG_PTR)(Vad->StartingVpn << PAGE_SHIFT));

    CapturedBase = NULL;

    Va = MI_VPN_TO_VA (Vad->StartingVpn);
    VaEnd = MI_VPN_TO_VA_ENDING (Vad->EndingVpn);

    CapturedViewSize = (ULONG_PTR)VaEnd - (ULONG_PTR)Va + 1L;

    ControlArea = Vad->ControlArea;

    RtlZeroMemory ((PVOID)&Section, sizeof(Section));

    status = MiMapViewOfDataSection (ControlArea,
                                     Process,
                                     &CapturedBase,
                                     &SectionOffset,
                                     &CapturedViewSize,
                                     &Section,
                                     ViewShare,
                                     (ULONG)Vad->u.VadFlags.Protection,
                                     0,
                                     0,
                                     0);
        
    if (!NT_SUCCESS (status)) {
        return status;
    }    

    Handle = MiSecureVirtualMemory (CapturedBase,
                                    CapturedViewSize,
                                    PAGE_READONLY,
                                    TRUE);

    if (Handle == NULL) {
        MiUnmapViewOfSection (Process, CapturedBase, TRUE);
        return STATUS_INSUFFICIENT_RESOURCES;
    }    

    //
    // If the original VAD is a short or regular VAD, it needs to be
    // reallocated as a large VAD.  Note that a short VAD that was
    // previously converted to a long VAD here will still be marked
    // as private memory, thus to handle this case the NoChange bit
    // must also be tested.
    //

    if (((Vad->u.VadFlags.PrivateMemory) && (Vad->u.VadFlags.NoChange == 0)) 
        ||
        (Vad->u2.VadFlags2.LongVad == 0)) {

        if (Vad->u.VadFlags.PrivateMemory == 0) {
            ASSERT (Vad->u2.VadFlags2.OneSecured == 0);
            ASSERT (Vad->u2.VadFlags2.MultipleSecured == 0);
        }

        AliasInfoSize = sizeof (ALIAS_VAD_INFO) + ALIAS_VAD_INCREMENT * sizeof (ALIAS_VAD_INFO2);

        AliasInfo = ExAllocatePoolWithTag (NonPagedPool,
                                           AliasInfoSize,
                                           'AdaV');

        if (AliasInfo == NULL) {
            MiUnsecureVirtualMemory (Handle, TRUE);
            MiUnmapViewOfSection (Process, CapturedBase, TRUE);
            return STATUS_INSUFFICIENT_RESOURCES;
        }

        AliasInfo->NumberOfEntries = 0;
        AliasInfo->MaximumEntries = ALIAS_VAD_INCREMENT;

        NewVad = ExAllocatePoolWithTag (NonPagedPool,
                                        sizeof(MMVAD_LONG),
                                        'ldaV');

        if (NewVad == NULL) {
            ExFreePool (AliasInfo);
            MiUnsecureVirtualMemory (Handle, TRUE);
            MiUnmapViewOfSection (Process, CapturedBase, TRUE);
            return STATUS_INSUFFICIENT_RESOURCES;
        }

        RtlZeroMemory (NewVad, sizeof(MMVAD_LONG));

        if (Vad->u.VadFlags.PrivateMemory) {
            RtlCopyMemory (NewVad, Vad, sizeof(MMVAD_SHORT));
        }
        else {
            RtlCopyMemory (NewVad, Vad, sizeof(MMVAD));
        }

        NewVad->u2.VadFlags2.LongVad = 1;
        NewVad->AliasInformation = AliasInfo;

        //
        // Replace the current VAD with this expanded VAD.
        //

        LOCK_WS_UNSAFE (Process);

        VadParent = (PMMVAD) SANITIZE_PARENT_NODE (Vad->u1.Parent);
        ASSERT (VadParent != NULL);

        if (VadParent != Vad) {
            if (VadParent->RightChild == Vad) {
                VadParent->RightChild = (PMMVAD) NewVad;
            }
            else {
                ASSERT (VadParent->LeftChild == Vad);
                VadParent->LeftChild = (PMMVAD) NewVad;
            }
        }
        else {
            Process->VadRoot.BalancedRoot.RightChild = (PMMADDRESS_NODE) NewVad;
        }
        if (Vad->LeftChild) {
            Vad->LeftChild->u1.Parent = (PMMVAD) MI_MAKE_PARENT (NewVad, Vad->LeftChild->u1.Balance);
        }
        if (Vad->RightChild) {
            Vad->RightChild->u1.Parent = (PMMVAD) MI_MAKE_PARENT (NewVad, Vad->RightChild->u1.Balance);
        }
        if (Process->VadRoot.NodeHint == Vad) {
            Process->VadRoot.NodeHint = (PMMVAD) NewVad;
        }
        if (Process->VadFreeHint == Vad) {
            Process->VadFreeHint = (PMMVAD) NewVad;
        }

        if ((Vad->u.VadFlags.PhysicalMapping == 1) ||
            (Vad->u.VadFlags.WriteWatch == 1)) {

            MiPhysicalViewAdjuster (Process, Vad, (PMMVAD) NewVad);
        }

        UNLOCK_WS_UNSAFE (Process);

        ExFreePool (Vad);

        Vad = (PMMVAD) NewVad;
    }
    else {
        AliasInfo = (PALIAS_VAD_INFO) ((PMMVAD_LONG)Vad)->AliasInformation;

        if (AliasInfo == NULL) {
            AliasInfoSize = sizeof (ALIAS_VAD_INFO) + ALIAS_VAD_INCREMENT * sizeof (ALIAS_VAD_INFO2);
        }
        else if (AliasInfo->NumberOfEntries >= AliasInfo->MaximumEntries) {

            AliasInfoSize = sizeof (ALIAS_VAD_INFO) + (AliasInfo->MaximumEntries + ALIAS_VAD_INCREMENT) * sizeof (ALIAS_VAD_INFO2);
        }
        else {
            AliasInfoSize = 0;
        }

        if (AliasInfoSize != 0) {
            NewAliasInfo = ExAllocatePoolWithTag (NonPagedPool,
                                                  AliasInfoSize,
                                                  'AdaV');

            if (NewAliasInfo == NULL) {
                MiUnsecureVirtualMemory (Handle, TRUE);
                MiUnmapViewOfSection (Process, CapturedBase, TRUE);
                return STATUS_INSUFFICIENT_RESOURCES;
            }

            if (AliasInfo != NULL) {
                RtlCopyMemory (NewAliasInfo, AliasInfo, AliasInfoSize - ALIAS_VAD_INCREMENT * sizeof (ALIAS_VAD_INFO2));
                NewAliasInfo->MaximumEntries += ALIAS_VAD_INCREMENT;
                ExFreePool (AliasInfo);
            }
            else {
                NewAliasInfo->NumberOfEntries = 0;
                NewAliasInfo->MaximumEntries = ALIAS_VAD_INCREMENT;
            }

            AliasInfo = NewAliasInfo;
        }
    }

    *CallerNewVad = Vad;

    Va = StartingAddress;
    VaEnd = EndingAddress;
    Alias = (PVOID)((ULONG_PTR)CapturedBase + ((ULONG_PTR)StartingAddress & (X64K - 1)));

    ProtectionMask = MiMakeProtectionAteMask (NewProtection);

    NewProtectNotCopy = NewProtection & ~MM_PROTECTION_COPY_MASK;
    ProtectionMaskNotCopy = MiMakeProtectionAteMask (NewProtectNotCopy);

    Wow64Process = Process->Wow64Process;
    AltPte = MiGetAltPteAddress (Va);

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
        
    while (Va <= VaEnd) {

        //
        // Check to see if the protection is registered in the alternate entry.
        //

        Vpn = (ULONG) MI_VA_TO_VPN (Va);

        if (MI_CHECK_BIT (Wow64Process->AltPermBitmap, Vpn) == 0) {
            MiSyncAltPte (Va);
        }

        PointerPte = MiGetPteAddress (Alias);

        AltPteContents.u.Long = AltPte->u.Long;

        //
        // If this address is NOT copy-on-write, AND it is not already
        // redirected through an indirect entry, then redirect it now to
        // the alias VAD which points at the original section.
        //

        if ((AltPteContents.u.Alt.CopyOnWrite == 0) &&
            (AltPteContents.u.Alt.PteIndirect == 0)) {

            AltPteContents.u.Alt.PteOffset = (ULONG_PTR)PointerPte - PTE_UBASE;
            AltPteContents.u.Alt.PteIndirect = 1;
            
            MI_WRITE_ALTPTE (AltPte, AltPteContents, 0x13);

            AliasReferenced = TRUE;
        }
        
        Va = (PVOID)((ULONG_PTR)Va + PAGE_4K);
        Alias = (PVOID)((ULONG_PTR)Alias + PAGE_4K);
        AltPte += 1;
    }
        
    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    ASSERT (AliasInfo->NumberOfEntries < AliasInfo->MaximumEntries);

    if (AliasReferenced == TRUE) {

        //
        // The alias view of the shared section was referenced so chain it so
        // the alias view can be :
        //
        // a) easily duplicated if the process subsequently forks.
        //
        // AND
        //
        // b) deleted when/if the original VAD is deleted later.
        //

        AliasBase = (PALIAS_VAD_INFO2)(AliasInfo + 1);
        AliasBase += AliasInfo->NumberOfEntries;
        ASSERT (CapturedBase < (PVOID)(ULONG_PTR)_2gb);
        AliasBase->BaseAddress = (ULONG)(ULONG_PTR)CapturedBase;
        AliasBase->SecureHandle = Handle;
        AliasInfo->NumberOfEntries += 1;
    }
    else {

        //
        // The alias view of the shared section wasn't referenced, delete it.
        //

        MiUnsecureVirtualMemory (Handle, TRUE);
        MiUnmapViewOfSection (Process, CapturedBase, TRUE);
    }    

    PS_SET_BITS (&Process->Flags, PS_PROCESS_FLAGS_WOW64_SPLIT_PAGES);

    return STATUS_SUCCESS;
}    

VOID
MiLockFor4kPage (
    IN PVOID CapturedBase,
    IN SIZE_T CapturedRegionSize,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function adds the page locked attribute to the alternate table entries.

Arguments:

    CapturedBase - Supplies the base address to be locked.

    CapturedRegionSize - Supplies the size of the region to be locked.

    Process - Supplies a pointer to the process object.
    
Return Value:

    None.

Environment:

    Kernel mode, address creation mutex held.

--*/
{
    PWOW64_PROCESS Wow64Process;
    PVOID EndingAddress;
    PMMPTE StartAltPte;
    PMMPTE EndAltPte;
    MMPTE AltPteContents;

    Wow64Process = Process->Wow64Process;

    EndingAddress = (PVOID)((ULONG_PTR)CapturedBase + CapturedRegionSize - 1);

    StartAltPte = MiGetAltPteAddress(CapturedBase);
    EndAltPte = MiGetAltPteAddress(EndingAddress);

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
    
    while (StartAltPte <= EndAltPte) {

        AltPteContents = *StartAltPte;
        AltPteContents.u.Alt.Lock = 1;

        MI_WRITE_ALTPTE (StartAltPte, AltPteContents, 0x14);

        StartAltPte += 1;
    }

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
}

NTSTATUS
MiUnlockFor4kPage (
    IN PVOID CapturedBase,
    IN SIZE_T CapturedRegionSize,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function removes the page locked attribute from the
    alternate table entries.

Arguments:

    CapturedBase - Supplies the base address to be unlocked.

    CapturedRegionSize - Supplies the size of the region to be unlocked.

    Process - Supplies a pointer to the process object.
   
Return Value:

    NTSTATUS.

Environment:

    Kernel mode, address creation and working set mutexes held.

    Note this routine releases and reacquires the working set mutex !!!

--*/

{
    PMMPTE PointerAltPte;
    PMMPTE StartAltPte;
    PMMPTE EndAltPte;
    PWOW64_PROCESS Wow64Process;
    PVOID EndingAddress;
    NTSTATUS Status;
    MMPTE AltPteContents;

    UNLOCK_WS_UNSAFE (Process);

    Status = STATUS_SUCCESS;

    Wow64Process = Process->Wow64Process;

    EndingAddress = (PVOID)((ULONG_PTR)CapturedBase + CapturedRegionSize - 1);

    StartAltPte = MiGetAltPteAddress (CapturedBase);
    EndAltPte = MiGetAltPteAddress (EndingAddress);

    PointerAltPte = StartAltPte;

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);
    
    do {

        if (PointerAltPte->u.Alt.Lock == 0) {
            Status = STATUS_NOT_LOCKED;
            goto StatusReturn;

        }

        PointerAltPte += 1;

    } while (PointerAltPte <= EndAltPte);

    PointerAltPte = StartAltPte;

    do {
        AltPteContents = *PointerAltPte;
        AltPteContents.u.Alt.Lock = 0;

        MI_WRITE_ALTPTE (PointerAltPte, AltPteContents, 0x15);

        PointerAltPte += 1;

    } while (PointerAltPte <= EndAltPte);

StatusReturn:

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    LOCK_WS_UNSAFE (Process);

    return Status;
}

LOGICAL
MiShouldBeUnlockedFor4kPage (
    IN PVOID VirtualAddress,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function examines whether the page should be unlocked.

Arguments:

    VirtualAddress - Supplies the virtual address to be examined.

    Process - Supplies a pointer to the process object.
   
Return Value:

    None.

Environment:

    Kernel mode, address creation and working set mutexes held.

    Note this routine releases and reacquires the working set mutex !!!

--*/

{
    PMMPTE StartAltPte;
    PMMPTE EndAltPte;
    PWOW64_PROCESS Wow64Process;
    PVOID VirtualAligned;
    PVOID EndingAddress;
    LOGICAL PageUnlocked;

    UNLOCK_WS_UNSAFE (Process);

    PageUnlocked = TRUE;
    Wow64Process = Process->Wow64Process;

    VirtualAligned = PAGE_ALIGN(VirtualAddress);
    EndingAddress = (PVOID)((ULONG_PTR)VirtualAligned + PAGE_SIZE - 1);

    StartAltPte = MiGetAltPteAddress (VirtualAligned);
    EndAltPte = MiGetAltPteAddress (EndingAddress);

    LOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    while (StartAltPte <= EndAltPte) {

        if (StartAltPte->u.Alt.Lock != 0) {
            PageUnlocked = FALSE;
        }

        StartAltPte += 1;
    }

    UNLOCK_ALTERNATE_TABLE_UNSAFE (Wow64Process);

    LOCK_WS_UNSAFE (Process);

    return PageUnlocked;
}

ULONG
MiMakeProtectForNativePage (
    IN PVOID VirtualAddress,
    IN ULONG NewProtect,
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function makes a page protection mask for native pages. 

Arguments:

    VirtualAddress - Supplies the virtual address for the protection mask.

    NewProtect - Supplies the original protection.

    Process - Supplies a pointer to the process object.

Return Value: 

    None.

Environment:

    Kernel mode.

--*/

{
    PWOW64_PROCESS Wow64Process;

    Wow64Process = Process->Wow64Process;

    if (MI_CHECK_BIT(Wow64Process->AltPermBitmap, 
                     MI_VA_TO_VPN(VirtualAddress)) != 0) {

        if (NewProtect & PAGE_NOACCESS) {
            NewProtect &= ~PAGE_NOACCESS;
            NewProtect |= PAGE_EXECUTE_READWRITE;
        }

        if (NewProtect & PAGE_READONLY) {
            NewProtect &= ~PAGE_READONLY;
            NewProtect |= PAGE_EXECUTE_READWRITE;
        }

        if (NewProtect & PAGE_EXECUTE) {
            NewProtect &= ~PAGE_EXECUTE;
            NewProtect |= PAGE_EXECUTE_READWRITE;
        }

        if (NewProtect & PAGE_EXECUTE_READ) {
            NewProtect &= ~PAGE_EXECUTE_READ;
            NewProtect |= PAGE_EXECUTE_READWRITE;
        }

        //
        // Remove PAGE_GUARD as it is emulated by the Alternate Table.
        //

        if (NewProtect & PAGE_GUARD) {
            NewProtect &= ~PAGE_GUARD;
        }
    }

    return NewProtect;
}

VOID
MiSetNativePteProtection (
    PVOID VirtualAddress,
    ULONGLONG NewPteProtection,
    LOGICAL PageIsSplit,
    PEPROCESS CurrentProcess
    )
{
    MMPTE PteContents;
    MMPTE TempPte;
    PMMPTE PointerPte;
    PMMPTE PointerPde;
    PMMPTE PointerPpe;
    ULONG Waited;

    PointerPte = MiGetPteAddress (VirtualAddress);
    PointerPde = MiGetPdeAddress (VirtualAddress);
    PointerPpe = MiGetPpeAddress (VirtualAddress);

    //
    // Block APCs and acquire the working set lock.
    //

    LOCK_WS (CurrentProcess);

    //
    // Make the PPE and PDE exist and valid.
    //

    if (MiDoesPpeExistAndMakeValid (PointerPpe,
                                    CurrentProcess,
                                    MM_NOIRQL,
                                    &Waited) == FALSE) {

        UNLOCK_WS (CurrentProcess);
        return;
    }

    if (MiDoesPdeExistAndMakeValid (PointerPde,
                                    CurrentProcess,
                                    MM_NOIRQL,
                                    &Waited) == FALSE) {

        UNLOCK_WS (CurrentProcess);
        return;
    }

    //
    // Now it is safe to read PointerPte.
    //

    PteContents = *PointerPte;

    //
    // Check to see if the protection for the native page should be set
    // and if the access bit of the PTE should be set.
    //

    if (PteContents.u.Hard.Valid != 0) { 

        TempPte = PteContents;

        //
        // Perform PTE protection mask corrections.
        //

        TempPte.u.Long |= NewPteProtection;

        if (PteContents.u.Hard.Accessed == 0) {

            TempPte.u.Hard.Accessed = 1;

            if (PageIsSplit == TRUE) {
                TempPte.u.Hard.Cache = MM_PTE_CACHE_RESERVED;
            } 
        }

        MI_WRITE_VALID_PTE_NEW_PROTECTION (PointerPte, TempPte); 
    }

    UNLOCK_WS (CurrentProcess);
}

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\nls\makefile.inc ===
$O\bugcodes.txt : gnbugcds.pl bugcodes.w
           perl gnbugcds.pl -o $O\bugcodes.txt -i bugcodes.w
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\mm\ia64\miia64.h ===
/*++

Copyright (c) 1990  Microsoft Corporation
Copyright (c) 1995  Intel Corporation

Module Name:

    miia64.h

Abstract:

    This module contains the private data structures and procedure
    prototypes for the hardware dependent portion of the
    memory management system.

    This module is specifically tailored for the IA64.

Author:

    Lou Perazzoli (loup) 6-Jan-1990
    Landy Wang (landyw) 2-June-1997
    Koichi Yamada (kyamada) 9-Jan-1996

Revision History:

--*/

/*++

    Virtual Memory Layout on IA64 is:

                 +------------------------------------+
0000000000000000 | User mode addresses - 7tb - 16gb   | UADDRESS_BASE
                 |                                    |
                 |                                    |
000006FBFFFEFFFF |                                    | MM_HIGHEST_USER_ADDRESS
                 +------------------------------------+
000006FBFFFF0000 | 64k No Access Region               | MM_USER_PROBE_ADDRESS
                 +------------------------------------+
000006FC00000000 | Alternate 4K-page mappings         | ALT4KB_BASE
                 |  for x86 process emulation         |
                 | Alternate 4K-page mappings         | ALT4KB_END
                 | Spans 8mb to allow for 4gb VA space| ALT4KB_END
                 +------------------------------------+
000006FC00800000 | HyperSpace - working set lists     | HYPER_SPACE
                 |  and per process memory management |
                 |  structures mapped in this 16gb    |
000006FFFFFFFFFF |  region.                           | HYPER_SPACE_END
                 +------------------------------------+
0000070000000000 |                                    |
                 | Page table selfmapping structures  |
000007FFFFFFFFFF |                                    |
                 +------------------------------------+
                                   .
                                   .
                 +------------------------------------+
1FFFFF0000000000 | 8gb leaf level page table map      | PTE_UBASE
                 |        for user space              |
1FFFFF01FFFFFFFF |                                    | PTE_UTOP
                 +------------------------------------+
                 +------------------------------------+
1FFFFFFFC0000000 | 8mb page directory (2nd level)     | PDE_UBASE
                 | table map for user space           |
1FFFFFFFC07FFFFF |                                    | PDE_UTOP
                 +------------------------------------+
                 +------------------------------------+
1FFFFFFFFFF00000 | 8KB parent directory (1st level)   | PDE_UTBASE
                 +------------------------------------+
                                   .
                                   .
                 +------------------------------------+
2000000000000000 | 1. Win32k.sys                      | MM_SESSION_SPACE_DEFAULT
                 | 2. Hydra - 8gb                     |
                 |  and per session memory management |
                 |  structures mapped in this 8gb     |
                 |  region.                           |
                 +------------------------------------+
                                   .
                 +------------------------------------+
3FFFFF0000000000 | 8gb leaf level page table map      | PTE_SBASE
                 |        for session space           |
3FFFFF01FFFFFFFF |                                    | PTE_STOP
                 +------------------------------------+
                 +------------------------------------+
3FFFFFFFC0000000 | 8mb page directory (2nd level)     | PDE_SBASE
                 | table map for session space        |
3FFFFFFFC07FFFFF |                                    | PDE_STOP
                 +------------------------------------+
                 +------------------------------------+
3FFFFFFFFFF00000 | 8KB parent directory (1st level)   | PDE_STBASE
                 +------------------------------------+
                                   .
                 +------------------------------------+
8000000000000000 |   physical addressable memory      | KSEG3_BASE
                 |   for 44-bit of address space      |
80000FFFFFFFFFFF |   mapped by VHPT 64KB page         | KSEG3_LIMIT
                 +------------------------------------+
                                   .
                 +------------------------------------+
9FFFFF00000000000| vhpt 64kb page for KSEG3 space     |
                 |            (not used)              |
                 +------------------------------------+
                                   .
                                   .
                 +------------------------------------+ MM_SYSTEM_RANGE_START
E000000000000000 |                                    | KADDRESS_BASE
                 +------------------------------------+
E000000080000000 | The HAL, kernel, initial drivers,  | KSEG0_BASE
                 | NLS data, and registry load in the |
                 | first 16mb of this region which    |
                 | physically addresses memory.       |
                 |                                    |
                 | Kernel mode access only.           |
                 |                                    |
                 | Initial NonPaged Pool is within    |
                 | KSEG0                              |
                 |                                    | KSEG2_BASE
                 +------------------------------------+
E0000000FF000000 | Shared system page                 | KI_USER_SHARED_DATA
                 +------------------------------------+
E0000000FF002000 |   Reserved for the HAL.            |
                 |                                    |
                 |                                    |
E0000000FFFFFFFF |                                    |
                 +------------------------------------+
                                   .
                                   .
                 +------------------------------------+
E000000200000000 |                                    |
                 |                                    |
                 |                                    |
                 |                                    |
                 +------------------------------------+
E000000400000000 |   The system cache working set     | MM_SYSTEM_CACHE_WORKING_SET
                 |                                    | MM_SYSTEM_SPACE_START
                 |   information resides in this 8gb  |
                 |   region.                          |
                 +------------------------------------+
E000000600000000 | System cache resides here.         | MM_SYSTEM_CACHE_START
                 |  Kernel mode access only.          |
                 |  1tb.                              |
                 +------------------------------------+
E000010600000000 | Start of paged system area.        | MM_PAGED_POOL_START
                 |  Kernel mode access only.          |
                 |  128gb.                            |
                 +------------------------------------+
                 | System mapped views start just     |
                 | after paged pool.  Default is      |
                 | 104MB, can be registry-overridden. |
                 | 8GB maximum.                       |
                 +------------------------------------+
                 |                                    |
                                   .
                                   .

In general, the next two areas (system PTE pool and nonpaged pool) will both
be shifted upwards to conserve a PPE...

                                   .
                                   .
                 +------------------------------------+
E000012600000000 | System PTE pool.                   | MM_LOWEST_NONPAGED_SYSTEM_START
                 |  Kernel mode access only.          |
                 |  128gb.                            |
                 +------------------------------------+
                 | PFN Database.                      |
                 +------------------------------------+
E000014600000000 | NonPaged pool.                     | MM_NON_PAGED_POOL_START
                 |  Kernel mode access only.          |
                 |  128gb.                            |
                 |                                    |
E0000165FFFFFFFF |  NonPaged System area              | MM_NONPAGED_POOL_END
                 +------------------------------------+
                                   .
                                   .
E000060000000000 +------------------------------------+ MM_SYSTEM_SPACE_END
                                   .
                                   .
                 +------------------------------------+
FFFFFF0000000000 | 8gb leaf level page table map      | PTE_KBASE
                 |       for kernel space             |
FFFFFF01FFFFFFFF |                                    | PTE_KTOP
                 +------------------------------------+
                 +------------------------------------+
FFFFFFFFC0000000 | 8mb page directory (2nd level)     | PDE_KBASE
                 | table map for kernel space         |
FFFFFFFFC07FFFFF |                                    | PDE_KTOP
                 +------------------------------------+
                 +------------------------------------+
FFFFFFFFFFF00000 | 8KB parent directory (1st level)   | PDE_KTBASE
                 +------------------------------------+

--*/

#define _MI_PAGING_LEVELS 3

#define _MI_MORE_THAN_4GB_ 1

#define IMAGE_FILE_MACHINE_NATIVE   IMAGE_FILE_MACHINE_IA64

#define _MIALT4K_ 1

//
// Define empty list markers.
//

#define MM_EMPTY_LIST ((ULONG_PTR)-1)              //
#define MM_EMPTY_PTE_LIST ((ULONG)0xFFFFFFFF) // N.B. tied to MMPTE definition

#define MI_PTE_BASE_FOR_LOWEST_KERNEL_ADDRESS ((PMMPTE)PTE_KBASE)

//
// Define the session PTE base.
//

#define MI_PTE_BASE_FOR_LOWEST_SESSION_ADDRESS ((PMMPTE)PTE_SBASE)

//
// 43-Bit virtual address mask.
//

#define MASK_43 0x7FFFFFFFFFFUI64       //

//
// 44-Bit Physical address mask.
//

#define MASK_44 0xFFFFFFFFFFFUI64

#define MM_PAGES_IN_KSEG0 ((ULONG)((KSEG2_BASE - KSEG0_BASE) >> PAGE_SHIFT))

#define MM_USER_ADDRESS_RANGE_LIMIT (0xFFFFFFFFFFFFFFFFUI64) // user address range limit
#define MM_MAXIMUM_ZERO_BITS 53         // maximum number of zero bits

//
// PAGE_SIZE for IA64 is 8k, virtual page is 20 bits with a PAGE_SHIFT
// byte offset.
//

#define MM_VIRTUAL_PAGE_FILLER (PAGE_SHIFT - 12)
#define MM_VIRTUAL_PAGE_SIZE (64-PAGE_SHIFT)

//
// Address space layout definitions.
//

#define CODE_START KSEG0_BASE

#define CODE_END   KSEG2_BASE

#define MM_SYSTEM_SPACE_START (KADDRESS_BASE + 0x400000000UI64)

#define MM_SYSTEM_SPACE_END (KADDRESS_BASE + 0x60000000000UI64)

#define PDE_TOP PDE_UTOP

#define PTE_TOP PTE_UTOP

//
// Define Alternate 4KB permission table space for X86 emulation mappings.
//

#define ALT4KB_PERMISSION_TABLE_START ((PVOID)(UADDRESS_BASE + 0x6FC00000000))

#define ALT4KB_PERMISSION_TABLE_END   ((PVOID)(UADDRESS_BASE + 0x6FC00800000))

// #define _MI_DEBUG_ALTPTE 1       // Enable this to get ALTPTE logging

VOID
MiLogPteInAltTrace (
    IN PVOID NativeInformation
    );

//
// Define hyper space.
//

#define HYPER_SPACE ((PVOID)(UADDRESS_BASE + 0x6FC00800000))

#define HYPER_SPACE_END ((PVOID)(UADDRESS_BASE + 0x6FFFFFFFFFF))

//
// Define area for mapping views into system space.
//

#define MM_SYSTEM_VIEW_SIZE (104*1024*1024)

//
// Hydra lives in region 1.
//

#define MM_SESSION_SPACE_DEFAULT        (0x2000000000000000UI64)
#define MM_SESSION_SPACE_DEFAULT_END    (0x2000000200000000UI64)

//
// Define the start and maximum size for the system cache.
//

#define MM_SYSTEM_CACHE_WORKING_SET (KADDRESS_BASE + 0x400000000UI64)

#define MM_SYSTEM_CACHE_START (KADDRESS_BASE + 0x600000000UI64)

#define MM_SYSTEM_CACHE_END (KADDRESS_BASE + 0x10600000000UI64)

#define MM_MAXIMUM_SYSTEM_CACHE_SIZE     \
   (((ULONG_PTR)MM_SYSTEM_CACHE_END - (ULONG_PTR)MM_SYSTEM_CACHE_START) >> PAGE_SHIFT)

#define MM_PAGED_POOL_START ((PVOID) MM_SYSTEM_CACHE_END)

#define MM_LOWEST_NONPAGED_SYSTEM_START ((PVOID)(KADDRESS_BASE + 0x12600000000UI64))

#define MmProtopte_Base (KADDRESS_BASE)

#define MM_NONPAGED_POOL_END ((PVOID)(KADDRESS_BASE + 0x16600000000UI64)) // 16mb aligned.

#define MM_CRASH_DUMP_VA ((PVOID)(KADDRESS_BASE + 0xFF800000))

// EPC VA at 0xFFA00000 (see ntia64.h)

#define MM_DEBUG_VA  ((PVOID)(KADDRESS_BASE + 0xFF900000))

#define NON_PAGED_SYSTEM_END   (KADDRESS_BASE + 0x16600000000UI64)  //quadword aligned.

extern ULONG MiMaximumSystemCacheSize;

//
// Define absolute minimum and maximum count for system ptes.
//

#define MM_MINIMUM_SYSTEM_PTES 7000

#define MM_MAXIMUM_SYSTEM_PTES (16*1024*1024)

#define MM_DEFAULT_SYSTEM_PTES 11000

//
// Pool limits
//

//
// The maximum amount of nonpaged pool that can be initially created.
//

#define MM_MAX_INITIAL_NONPAGED_POOL ((SIZE_T)(128 * 1024 * 1024))

//
// The total amount of nonpaged pool (initial pool + expansion + system PTEs).
//

#define MM_MAX_ADDITIONAL_NONPAGED_POOL (((SIZE_T)128 * 1024 * 1024 * 1024))

//
// The maximum amount of paged pool that can be created.
//

#define MM_MAX_PAGED_POOL ((SIZE_T)128 * 1024 * 1024 * 1024)

//
// Define the maximum default for pool (user specified 0 in registry).
//

#define MM_MAX_DEFAULT_NONPAGED_POOL ((SIZE_T)8 * 1024 * 1024 * 1024)

//
// Structure layout defintions.
//

#define MM_PROTO_PTE_ALIGNMENT ((ULONG)PAGE_SIZE)

//
// Define the address bits mapped by PPE and PDE entries.
//
// A PPE entry maps 10+10+13 = 33 bits of address space.
// A PDE entry maps 10+13 = 23 bits of address space.
//

#define PAGE_DIRECTORY1_MASK (((ULONG_PTR)1 << PDI1_SHIFT) - 1)
#define PAGE_DIRECTORY2_MASK (((ULONG_PTR)1 << PDI_SHIFT) -1)

#define MM_VA_MAPPED_BY_PDE ((ULONG_PTR)1 << PDI_SHIFT)

#define MM_VA_MAPPED_BY_PPE ((ULONG_PTR)1 << PDI1_SHIFT)

#define LOWEST_IO_ADDRESS 0xa0000

//
// IA64 supports page sizes of 4k, 8k, 16k, 64k, 256k,
// 1mb, 4mb, 16mb, 64mb & 256mb.
//

#define MM_MINIMUM_VA_FOR_LARGE_PAGE (2 * MM_VA_MAPPED_BY_PDE)

//
// The number of bits in a physical address.
//

#define PHYSICAL_ADDRESS_BITS 44

#define MM_MAXIMUM_NUMBER_OF_COLORS (1)

//
// IA64 does not require support for colored pages.
//

#define MM_NUMBER_OF_COLORS (1)

//
// Mask for obtaining color from a physical page number.
//

#define MM_COLOR_MASK (0)

//
// Boundary for aligned pages of like color upon.
//

#define MM_COLOR_ALIGNMENT (0)

//
// Mask for isolating color from virtual address.
//

#define MM_COLOR_MASK_VIRTUAL (0)

//
//  Define 256k worth of secondary colors.
//

#define MM_SECONDARY_COLORS_DEFAULT (64)

#define MM_SECONDARY_COLORS_MIN (2)

#define MM_SECONDARY_COLORS_MAX (1024)

//
// Maximum number of paging files.
//

#define MAX_PAGE_FILES 16

//
// Hyper space definitions.
//

#define FIRST_MAPPING_PTE   ((PMMPTE)HYPER_SPACE)

#define NUMBER_OF_MAPPING_PTES 253
#define LAST_MAPPING_PTE   \
     ((PVOID)((ULONG_PTR)FIRST_MAPPING_PTE + (NUMBER_OF_MAPPING_PTES * PAGE_SIZE)))

#define COMPRESSION_MAPPING_PTE   ((PMMPTE)((ULONG_PTR)LAST_MAPPING_PTE + PAGE_SIZE))

#define IMAGE_MAPPING_PTE   ((PMMPTE)((ULONG_PTR)COMPRESSION_MAPPING_PTE + PAGE_SIZE))

#define NUMBER_OF_ZEROING_PTES 32

#define VAD_BITMAP_SPACE    ((PVOID)((ULONG_PTR)IMAGE_MAPPING_PTE + PAGE_SIZE))

#define WORKING_SET_LIST   ((PVOID)((ULONG_PTR)VAD_BITMAP_SPACE + PAGE_SIZE))

#define MM_MAXIMUM_WORKING_SET (((ULONG_PTR)(HYPER_SPACE)) >> PAGE_SHIFT)

#define MmWorkingSetList ((PMMWSL)WORKING_SET_LIST)

#define MmWsle ((PMMWSLE)((PUCHAR)WORKING_SET_LIST + sizeof(MMWSL)))

#define MM_WORKING_SET_END (UADDRESS_BASE + 0x3FFFFFFFFFFUI64)

//
// Define memory attributes fields within PTE.
//

#define MM_PTE_TB_MA_WB         (0x0 << 2) // cacheable, write-back
#define MM_PTE_TB_MA_UC         (0x4 << 2) // uncacheable
#define MM_PTE_TB_MA_UCE        (0x5 << 2) // uncacheable, exporting fetchadd
#define MM_PTE_TB_MA_WC         (0x6 << 2) // uncacheable, coalescing
#define MM_PTE_TB_MA_NATPAGE    (0x7 << 2) // Nat Page

//
// Define masks for the PTE cache attributes.
//

#define MM_PTE_CACHE_ENABLED     0     // WB
#define MM_PTE_CACHE_RESERVED    1     // special encoding to cause a TLB miss
#define MM_PTE_CACHE_DISABLED    4     // UC
#define MM_PTE_CACHE_DISPLAY     6     // WC
#define MM_PTE_CACHE_NATPAGE     7     // Nat Page

//
// Define masks for fields within the PTE.
//

#define MM_PTE_OWNER_MASK         0x0180
#define MM_PTE_VALID_MASK         1
#define MM_PTE_CACHE_DISABLE_MASK MM_PTE_TB_MA_UC
#define MM_PTE_ACCESS_MASK        0x0020
#define MM_PTE_DIRTY_MASK         0x0040
#define MM_PTE_EXECUTE_MASK       0x0200
#define MM_PTE_WRITE_MASK         0x0400
#define MM_PTE_LARGE_PAGE_MASK    0
#define MM_PTE_COPY_ON_WRITE_MASK ((ULONG)1 << (PAGE_SHIFT-1))

#define MM_PTE_PROTOTYPE_MASK     0x0002
#define MM_PTE_TRANSITION_MASK    0x0080

//
// Bit fields to or into PTE to make a PTE valid based on the
// protection field of the invalid PTE.
//

#define MM_PTE_NOACCESS          0x0
#define MM_PTE_READONLY          0x0
#define MM_PTE_READWRITE         MM_PTE_WRITE_MASK
#define MM_PTE_WRITECOPY         MM_PTE_COPY_ON_WRITE_MASK
#define MM_PTE_EXECUTE           MM_PTE_EXECUTE_MASK
#define MM_PTE_EXECUTE_READ      MM_PTE_EXECUTE_MASK
#define MM_PTE_EXECUTE_READWRITE MM_PTE_EXECUTE_MASK | MM_PTE_WRITE_MASK
#define MM_PTE_EXECUTE_WRITECOPY MM_PTE_EXECUTE_MASK | MM_PTE_COPY_ON_WRITE_MASK
#define MM_PTE_GUARD             0x0
#define MM_PTE_CACHE             MM_PTE_TB_MA_WB
#define MM_PTE_NOCACHE           MM_PTE_CACHE     // PAGE_NOCACHE is cached
#define MM_PTE_EXC_DEFER         0x10000000000000 // defer exception


#define MM_PROTECT_FIELD_SHIFT 2

//
// Define masks for fields within the IA64 TB entry.
//

#define MM_PTE_TB_VALID          0x0001
#define MM_PTE_TB_ACCESSED       0x0020
#define MM_PTE_TB_MODIFIED       0x0040
#define MM_PTE_TB_WRITE          0x0400
#define MM_PTE_TB_EXECUTE        0x0200             // read/execute
#define MM_PTE_TB_EXC_DEFER      0x10000000000000   // defer exception

//
// Define the number of VHPT pages.
//

#define MM_VHPT_PAGES           32

//
// Bits available for the software working set index within the hardware PTE.
//

#define MI_MAXIMUM_PTE_WORKING_SET_INDEX (1 << _HARDWARE_PTE_WORKING_SET_BITS)

//
// Zero PTE.
//

#define MM_ZERO_PTE 0

//
// Zero Kernel PTE.
//

#define MM_ZERO_KERNEL_PTE 0

//
// A demand zero PTE with a protection of PAGE_READWRITE.
//

#define MM_DEMAND_ZERO_WRITE_PTE ((ULONGLONG)MM_READWRITE << MM_PROTECT_FIELD_SHIFT)


//
// A demand zero PTE with a protection of PAGE_READWRITE for system space.
//

#define MM_KERNEL_DEMAND_ZERO_PTE ((ULONGLONG)MM_READWRITE << MM_PROTECT_FIELD_SHIFT)

//
// A no access PTE for system space.
//

#define MM_KERNEL_NOACCESS_PTE ((ULONGLONG)MM_NOACCESS << MM_PROTECT_FIELD_SHIFT)

//
// Kernel stack alignment requirements.
//

#define MM_STACK_ALIGNMENT 0x0

#define MM_STACK_OFFSET 0x0

#define PDE_PER_PAGE ((ULONG)(PAGE_SIZE/(1 << PTE_SHIFT)))

#define PTE_PER_PAGE ((ULONG)(PAGE_SIZE/(1 << PTE_SHIFT)))

#define PTE_PER_PAGE_BITS 11    // This handles the case where the page is full

#if PTE_PER_PAGE_BITS > 32
error - too many bits to fit into MMPTE_SOFTWARE or MMPFN.u1
#endif

//
// Number of page table pages for user addresses.
//

#define MM_USER_PAGE_TABLE_PAGES ((ULONG_PTR)MI_SYSTEM_RANGE_START / (PTE_PER_PAGE * PAGE_SIZE))

#define MM_USER_PAGE_DIRECTORY_PAGES ((ULONG_PTR)MI_SYSTEM_RANGE_START / ((ULONG_PTR)PDE_PER_PAGE * PTE_PER_PAGE * PAGE_SIZE))

//++
//VOID
//MI_MAKE_VALID_PTE (
//    OUT OUTPTE,
//    IN FRAME,
//    IN PMASK,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro makes a valid PTE from a page frame number, protection mask,
//    and owner.
//
// Arguments:
//
//    OUTPTE - Supplies the PTE in which to build the transition PTE.
//
//    FRAME - Supplies the page frame number for the PTE.
//
//    PMASK - Supplies the protection to set in the transition PTE.
//
//    PPTE - Supplies a pointer to the PTE which is being made valid.
//           For prototype PTEs NULL should be specified.
//
// Return Value:
//
//     None.
//
//--


#define _ALTPERM_BITMAP_MASK ((_4gb - 1) >> PTI_SHIFT)

#if defined(_MIALT4K_)

extern PVOID MiMaxWow64Pte;

#define MI_SET_VALID_PTE_BITS(OUTPTE,PMASK,PPTE) {                           \
        PWOW64_PROCESS _Wow64Process;                                        \
        if ((PPTE >= (PMMPTE)PTE_UBASE) && (PPTE < (PMMPTE)MiMaxWow64Pte)) { \
            _Wow64Process = PsGetCurrentProcess()->Wow64Process;             \
            if ((_Wow64Process != NULL) && (PPTE < MmWorkingSetList->HighestUserPte)) {                                     \
                if (MI_CHECK_BIT(_Wow64Process->AltPermBitmap,               \
                ((ULONG_PTR)PPTE >> PTE_SHIFT) & _ALTPERM_BITMAP_MASK) != 0) { \
                    (OUTPTE).u.Long |= (MmProtectToPteMaskForSplit[PMASK]);  \
                }                                                            \
                else {                                                       \
                    (OUTPTE).u.Long |= (MmProtectToPteMaskForIA32[PMASK]);   \
                    (OUTPTE).u.Hard.Accessed = 1;                            \
                }                                                            \
            }                                                                \
            else {                                                           \
                (OUTPTE).u.Hard.Accessed = 1;                                \
                (OUTPTE).u.Long |= (MmProtectToPteMask[PMASK]);              \
            }                                                                \
        }                                                                    \
        else {                                                               \
            (OUTPTE).u.Hard.Accessed = 1;                                    \
            (OUTPTE).u.Long |= (MmProtectToPteMask[PMASK]);                  \
        }                                                                    \
}

#else

#define MI_SET_VALID_PTE_BITS(OUTPTE,PMASK,PPTE) {                           \
       (OUTPTE).u.Hard.Accessed = 1;                                         \
       (OUTPTE).u.Long |= (MmProtectToPteMask[PMASK]);
}

#endif

#define MI_MAKE_VALID_PTE(OUTPTE,FRAME,PMASK,PPTE)                           \
       (OUTPTE).u.Long = 0;                                                  \
       (OUTPTE).u.Hard.Valid = 1;                                            \
       (OUTPTE).u.Hard.Cache = MM_PTE_CACHE_ENABLED;                         \
       (OUTPTE).u.Hard.Exception = 1;                                        \
       (OUTPTE).u.Hard.PageFrameNumber = FRAME;                              \
       (OUTPTE).u.Hard.Owner = MI_DETERMINE_OWNER(PPTE);                     \
       MI_SET_VALID_PTE_BITS(OUTPTE,PMASK,PPTE)

//++
//VOID
//MI_MAKE_VALID_PTE_TRANSITION (
//    IN OUT OUTPTE
//    IN PROTECT
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and turns it into a transition PTE.
//
// Arguments:
//
//    OUTPTE - Supplies the current valid PTE.  This PTE is then
//             modified into a transition PTE.
//
//    PROTECT - Supplies the protection to set in the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#if defined(_MIALT4K_)
#define MI_MAKE_VALID_PTE_TRANSITION(OUTPTE,PROTECT)                    \
                if ((OUTPTE).u.Hard.Cache == MM_PTE_CACHE_RESERVED) {   \
                    (OUTPTE).u.Trans.SplitPermissions = 1;              \
                }                                                       \
                else {                                                  \
                    (OUTPTE).u.Trans.SplitPermissions = 0;              \
                }                                                       \
                (OUTPTE).u.Soft.Transition = 1;                         \
                (OUTPTE).u.Soft.Valid = 0;                              \
                (OUTPTE).u.Soft.Prototype = 0;                          \
                (OUTPTE).u.Soft.Protection = PROTECT;
#else
#define MI_MAKE_VALID_PTE_TRANSITION(OUTPTE,PROTECT)                    \
                (OUTPTE).u.Soft.Transition = 1;                         \
                (OUTPTE).u.Soft.Valid = 0;                              \
                (OUTPTE).u.Soft.Prototype = 0;                          \
                (OUTPTE).u.Soft.Protection = PROTECT;
#endif

//++
//VOID
//MI_MAKE_TRANSITION_PTE (
//    OUT OUTPTE,
//    IN PAGE,
//    IN PROTECT,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro constructs a transition PTE.
//
// Arguments:
//
//    OUTPTE - Supplies the PTE in which to build the transition PTE.
//
//    PAGE - Supplies the page frame number for the PTE.
//
//    PROTECT - Supplies the protection to set in the transition PTE.
//
//    PPTE - Supplies a pointer to the PTE, this is used to determine
//           the split permissions (if any) of the PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PTE(OUTPTE,PAGE,PROTECT,PPTE)   \
                (OUTPTE).u.Long = 0;                       \
                (OUTPTE).u.Trans.PageFrameNumber = PAGE;   \
                (OUTPTE).u.Trans.Transition = 1;           \
                ASSERT (PPTE->u.Hard.Valid == 0);          \
                (OUTPTE).u.Trans.SplitPermissions = PPTE->u.Soft.SplitPermissions; \
                (OUTPTE).u.Trans.Protection = PROTECT;


//++
//VOID
//MI_MAKE_TRANSITION_PTE_VALID (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro takes a transition PTE and makes it a valid PTE.
//
// Arguments:
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the transition PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_TRANSITION_PTE_VALID(OUTPTE,PPTE) {                      \
        ASSERT (((PPTE)->u.Hard.Valid == 0) &&                           \
                ((PPTE)->u.Trans.Prototype == 0) &&                      \
                ((PPTE)->u.Trans.Transition == 1));                      \
       (OUTPTE).u.Long = (PPTE)->u.Long & 0x1FFFFFFFE000;                \
       (OUTPTE).u.Hard.Valid = 1;                                        \
       ASSERT (PPTE->u.Hard.Valid == 0);                                 \
       if (PPTE->u.Trans.SplitPermissions == 0) {                        \
            (OUTPTE).u.Hard.Cache = MM_PTE_CACHE_ENABLED;                \
       }                                                                 \
       else {                                                            \
            (OUTPTE).u.Hard.Cache = MM_PTE_CACHE_RESERVED;               \
       }                                                                 \
       (OUTPTE).u.Hard.Exception = 1;                                    \
       (OUTPTE).u.Hard.Owner = MI_DETERMINE_OWNER(PPTE);                 \
       MI_SET_VALID_PTE_BITS(OUTPTE,(PPTE)->u.Trans.Protection,PPTE)     \
}

#define MI_MAKE_TRANSITION_PROTOPTE_VALID(OUTPTE,PPTE) \
            MI_MAKE_TRANSITION_PTE_VALID(OUTPTE,PPTE)

#define MI_FAULT_STATUS_INDICATES_EXECUTION(_FaultStatus)   (_FaultStatus & 0x2)

#define MI_FAULT_STATUS_INDICATES_WRITE(_FaultStatus)   (_FaultStatus & 0x1)

#define MI_CLEAR_FAULT_STATUS(_FaultStatus)             (_FaultStatus = 0)

#define MI_IS_PTE_EXECUTABLE(_TempPte) ((_TempPte)->u.Hard.Execute != 0)

//++
//VOID
//MI_SET_PTE_IN_WORKING_SET (
//    OUT PMMPTE PTE,
//    IN ULONG WSINDEX
//    );
//
// Routine Description:
//
//    This macro inserts the specified working set index into the argument PTE.
//
//    No TB invalidation is needed for other processors (or this one) even
//    though the entry may already be in a TB - it's just a software field
//    update and doesn't affect miss resolution.
//
// Arguments
//
//    OUTPTE - Supplies the PTE in which to insert the working set index.
//
//    WSINDEX - Supplies the working set index for the PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_IN_WORKING_SET(PTE, WSINDEX) {             \
    MMPTE _TempPte;                                           \
    _TempPte = *(PTE);                                        \
    _TempPte.u.Hard.SoftwareWsIndex = (WSINDEX);              \
    *(PTE) = _TempPte;                                        \
}

//++
//ULONG WsIndex
//MI_GET_WORKING_SET_FROM_PTE(
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro returns the working set index from the argument PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to extract the working set index from.
//
// Return Value:
//
//    This macro returns the working set index for the argument PTE.
//
//--

#define MI_GET_WORKING_SET_FROM_PTE(PTE)  (ULONG)(PTE)->u.Hard.SoftwareWsIndex

extern BOOLEAN MiWriteCombiningPtes;

//++
//VOID
//MI_SET_PTE_WRITE_COMBINE (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro sets the write combined bit(s) in the specified PTE.
//
// Arguments
//
//    PTE - Supplies the PTE to set dirty.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_WRITE_COMBINE(PTE)  \
    ((PTE).u.Hard.Cache = MM_PTE_CACHE_DISABLED)

#define MI_SET_PTE_WRITE_COMBINE2(PTE)                          \
            if (MiWriteCombiningPtes == TRUE) {                 \
                (PTE).u.Hard.Cache = MM_PTE_CACHE_DISPLAY;      \
            }                                                   \
            else {                                              \
                (PTE).u.Hard.Cache = MM_PTE_CACHE_DISABLED;     \
            }

#define MI_SET_LARGE_PTE_WRITE_COMBINE(PTE)                     \
    ASSERT ((PTE).u.Hard.Cache == MM_PTE_CACHE_RESERVED);       \
    ((PTE).u.Hard.SoftwareWsIndex = MM_PTE_CACHE_DISPLAY);

//++
//VOID
//MI_PREPARE_FOR_NONCACHED (
//    IN MI_PFN_CACHE_ATTRIBUTE CacheAttribute
//    );
//
// Routine Description:
//
//    This macro prepares the system prior to noncached PTEs being created.
//
//    Note the entire TB must be flushed on all processors because there may
//    be stale system PTE (or hyperspace or zeropage) mappings in the TB which
//    may refer to the same physical page but with a different cache attribute.
//
// Arguments
//
//    CacheAttribute - Supplies the cache attribute the PTEs will be filled
//                     with.
//
// Return Value:
//
//     None.
//
//--
#define MI_PREPARE_FOR_NONCACHED(_CacheAttribute)               \
        if (_CacheAttribute != MiCached) {                      \
            KeFlushEntireTb (FALSE, TRUE);                      \
        }

//++
//VOID
//MI_SWEEP_CACHE (
//    IN MI_PFN_CACHE_ATTRIBUTE CacheAttribute,
//    IN PVOID StartVa,
//    IN ULONG NumberOfBytes
//    );
//
// Routine Description:
//
//    This macro prepares the system prior to noncached PTEs being created.
//
// Arguments
//
//    CacheAttribute - Supplies the cache attribute the PTEs were filled with.
//
//    StartVa - Supplies the starting address that's been mapped.
//
//    NumberOfBytes - Supplies the number of bytes that have been mapped.
//
// Return Value:
//
//     None.
//
//--
#define MI_SWEEP_CACHE(_CacheAttribute,_StartVa,_NumberOfBytes)         \
        if (_CacheAttribute != MiCached) {                              \
            MiSweepCacheMachineDependent (_StartVa,                     \
                                          _NumberOfBytes,               \
                                          (ULONG)(_CacheAttribute));    \
        }

//++
//VOID
//MI_SET_PTE_DIRTY (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro sets the dirty bit(s) in the specified PTE.
//
// Arguments:
//
//    PTE - Supplies the PTE to set dirty.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_DIRTY(PTE) (PTE).u.Hard.Dirty = 1


//++
//VOID
//MI_SET_PTE_CLEAN (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro clears the dirty bit(s) in the specified PTE.
//
// Arguments:
//
//    PTE - Supplies the PTE to set clear.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_PTE_CLEAN(PTE) (PTE).u.Hard.Dirty = 0



//++
//VOID
//MI_IS_PTE_DIRTY (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro checks the dirty bit(s) in the specified PTE.
//
// Arguments:
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if the page is dirty (modified), FALSE otherwise.
//
//--

#define MI_IS_PTE_DIRTY(PTE) ((PTE).u.Hard.Dirty != 0)



//++
//VOID
//MI_SET_GLOBAL_BIT_IF_SYSTEM (
//    OUT OUTPTE,
//    IN PPTE
//    );
//
// Routine Description:
//
//    This macro sets the global bit if the pointer PTE is within
//    system space.
//
// Arguments:
//
//    OUTPTE - Supplies the PTE in which to build the valid PTE.
//
//    PPTE - Supplies a pointer to the PTE becoming valid.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_GLOBAL_BIT_IF_SYSTEM(OUTPTE,PPTE)



//++
//VOID
//MI_SET_GLOBAL_STATE (
//    IN MMPTE PTE,
//    IN ULONG STATE
//    );
//
// Routine Description:
//
//    This macro sets the global bit in the PTE. if the pointer PTE is within
//
// Arguments:
//
//    PTE - Supplies the PTE to set global state into.
//
//    STATE - Supplies 1 if global, 0 if not.
//
// Return Value:
//
//     None.
//
//--

#define MI_SET_GLOBAL_STATE(PTE,STATE)



//++
//VOID
//MI_ENABLE_CACHING (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and sets the caching state to be
//    enabled.
//
// Arguments:
//
//    PTE - Supplies a valid PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_ENABLE_CACHING(PTE) ((PTE).u.Hard.Cache = MM_PTE_CACHE_ENABLED)



//++
//VOID
//MI_DISABLE_CACHING (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and sets the caching state to be
//    disabled.
//
// Arguments:
//
//    PTE - Supplies a pointer to the valid PTE.
//
// Return Value:
//
//     None.
//
//--

#define MI_DISABLE_CACHING(PTE) ((PTE).u.Hard.Cache = MM_PTE_CACHE_DISABLED)

#define MI_DISABLE_LARGE_PTE_CACHING(PTE)                           \
        ASSERT ((PTE).u.Hard.Cache == MM_PTE_CACHE_RESERVED);       \
        ((PTE).u.Hard.SoftwareWsIndex = MM_PTE_CACHE_DISABLED);     \




//++
//BOOLEAN
//MI_IS_CACHING_DISABLED (
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro takes a valid PTE and returns TRUE if caching is
//    disabled.
//
// Arguments:
//
//    PPTE - Supplies a pointer to the valid PTE.
//
// Return Value:
//
//     TRUE if caching is disabled, FALSE if it is enabled.
//
//--

#define MI_IS_CACHING_DISABLED(PPTE) \
            ((PPTE)->u.Hard.Cache == MM_PTE_CACHE_DISABLED)



//++
//VOID
//MI_SET_PFN_DELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a PFN element and indicates that
//    the PFN is no longer in use.
//
// Arguments:
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//    none.
//
//--

#define MI_SET_PFN_DELETED(PPFN) \
    (PPFN)->PteAddress = (PMMPTE)((ULONG_PTR)PPFN->PteAddress | 0x1);


//++
//VOID
//MI_MARK_PFN_UNDELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a deleted PFN element and mark that
//    the PFN is not deleted.
//
// Arguments
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//    none.
//
//--

#define MI_MARK_PFN_UNDELETED(PPFN) \
    PPFN->PteAddress = (PMMPTE)((ULONG_PTR)PPFN->PteAddress & ~0x1);



//++
//BOOLEAN
//MI_IS_PFN_DELETED (
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro takes a pointer to a PFN element and determines if
//    the PFN is no longer in use.
//
// Arguments:
//
//    PPTE - Supplies a pointer to the PFN element.
//
// Return Value:
//
//     TRUE if PFN is no longer used, FALSE if it is still being used.
//
//--

#define MI_IS_PFN_DELETED(PPFN)   \
            ((ULONG_PTR)(PPFN)->PteAddress & 0x1)


//++
//VOID
//MI_CHECK_PAGE_ALIGNMENT (
//    IN ULONG PAGE,
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro takes a PFN element number (Page) and checks to see
//    if the virtual alignment for the previous address of the page
//    is compatable with the new address of the page.  If they are
//    not compatible, the D cache is flushed.
//
// Arguments:
//
//    PAGE - Supplies the PFN element.
//    PPTE - Supplies a pointer to the new PTE which will contain the page.
//
// Return Value:
//
//    none.
//
//--

// does nothing on IA64.

#define MI_CHECK_PAGE_ALIGNMENT(PAGE,PPTE)




//++
//VOID
//MI_INITIALIZE_HYPERSPACE_MAP (
//    VOID
//    );
//
// Routine Description:
//
//    This macro initializes the PTEs reserved for double mapping within
//    hyperspace.
//
// Arguments:
//
//    None.
//
// Return Value:
//
//    None.
//
//--

// does nothing on IA64.

#define MI_INITIALIZE_HYPERSPACE_MAP(INDEX)


//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_PTE (
//    IN PMMPTE PTEADDRESS
//    );
//
// Routine Description:
//
//    This macro determines the pages color based on the PTE address
//    that maps the page.
//
// Arguments:
//
//    PTEADDRESS - Supplies the PTE address the page is (or was) mapped at.
//
// Return Value:
//
//    The pages color.
//
//--

#define MI_GET_PAGE_COLOR_FROM_PTE(PTEADDRESS)  \
         (((ULONG)((MI_SYSTEM_PAGE_COLOR++) & MmSecondaryColorMask)) | MI_CURRENT_NODE_COLOR)



//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_VA (
//    IN PVOID ADDRESS
//    );
//
// Routine Description:
//
//    This macro determines the pages color based on the PTE address
//    that maps the page.
//
// Arguments:
//
//    ADDRESS - Supplies the address the page is (or was) mapped at.
//
// Return Value:
//
//    The pages color.
//
//--


#define MI_GET_PAGE_COLOR_FROM_VA(ADDRESS)  \
         (((ULONG)((MI_SYSTEM_PAGE_COLOR++) & MmSecondaryColorMask)) | MI_CURRENT_NODE_COLOR)


//++
//ULONG
//MI_GET_PAGE_COLOR_FROM_SESSION (
//    IN PMM_SESSION_SPACE SessionSpace
//    );
//
// Routine Description:
//
//    This macro determines the page's color based on the PTE address
//    that maps the page.
//
// Arguments
//
//    SessionSpace - Supplies the session space the page will be mapped into.
//
// Return Value:
//
//    The page's color.
//
//--


#define MI_GET_PAGE_COLOR_FROM_SESSION(_SessionSpace)  \
         (((ULONG)((_SessionSpace->Color++) & MmSecondaryColorMask)) | MI_CURRENT_NODE_COLOR)


//++
//ULONG
//MI_PAGE_COLOR_PTE_PROCESS (
//    IN PMMPTE PTE,
//    IN PUSHORT COLOR
//    );
//
// Routine Description:
//
//    Select page color for this process.
//
// Arguments
//
//   PTE    Not used.
//   COLOR  Value from which color is determined.   This
//          variable is incremented.
//
// Return Value:
//
//    Page color.
//
//--


#define MI_PAGE_COLOR_PTE_PROCESS(PTE,COLOR)  \
         (((ULONG)((*(COLOR))++) & MmSecondaryColorMask) | MI_CURRENT_NODE_COLOR)


//++
//ULONG
//MI_PAGE_COLOR_VA_PROCESS (
//    IN PVOID ADDRESS,
//    IN PEPROCESS COLOR
//    );
//
// Routine Description:
//
//    This macro determines the pages color based on the PTE address
//    that maps the page.
//
// Arguments:
//
//    ADDRESS - Supplies the address the page is (or was) mapped at.
//
// Return Value:
//
//    The pages color.
//
//--

#define MI_PAGE_COLOR_VA_PROCESS(ADDRESS,COLOR) \
         (((ULONG)((*(COLOR))++) & MmSecondaryColorMask) | MI_CURRENT_NODE_COLOR)



//++
//ULONG
//MI_GET_NEXT_COLOR (
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the next color in the sequence.
//
// Arguments:
//
//    COLOR - Supplies the color to return the next of.
//
// Return Value:
//
//    Next color in sequence.
//
//--

#define MI_GET_NEXT_COLOR(COLOR)  ((COLOR + 1) & MM_COLOR_MASK)


//++
//ULONG
//MI_GET_PREVIOUS_COLOR (
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the previous color in the sequence.
//
// Arguments:
//
//    COLOR - Supplies the color to return the previous of.
//
// Return Value:
//
//    Previous color in sequence.
//
//--

#define MI_GET_PREVIOUS_COLOR(COLOR)  (0)

#define MI_GET_SECONDARY_COLOR(PAGE,PFN) (PAGE & MmSecondaryColorMask)

#define MI_GET_COLOR_FROM_SECONDARY(SECONDARY_COLOR) (0)


//++
//VOID
//MI_GET_MODIFIED_PAGE_BY_COLOR (
//    OUT ULONG PAGE,
//    IN ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the first page destined for a paging
//    file with the desired color.  It does NOT remove the page
//    from its list.
//
// Arguments:
//
//    PAGE - Returns the page located, the value MM_EMPTY_LIST is
//           returned if there is no page of the specified color.
//
//    COLOR - Supplies the color of page to locate.
//
// Return Value:
//
//    none.
//
//--

#define MI_GET_MODIFIED_PAGE_BY_COLOR(PAGE,COLOR) \
            PAGE = MmModifiedPageListByColor[COLOR].Flink


//++
//VOID
//MI_GET_MODIFIED_PAGE_ANY_COLOR (
//    OUT ULONG PAGE,
//    IN OUT ULONG COLOR
//    );
//
// Routine Description:
//
//    This macro returns the first page destined for a paging
//    file with the desired color.  If not page of the desired
//    color exists, all colored lists are searched for a page.
//    It does NOT remove the page from its list.
//
// Arguments:
//
//    PAGE - Returns the page located, the value MM_EMPTY_LIST is
//           returned if there is no page of the specified color.
//
//    COLOR - Supplies the color of page to locate and returns the
//            color of the page located.
//
// Return Value:
//
//    none.
//
//--

#define MI_GET_MODIFIED_PAGE_ANY_COLOR(PAGE,COLOR) \
            {                                                                \
                if (MmTotalPagesForPagingFile == 0) {                        \
                    PAGE = MM_EMPTY_LIST;                                    \
                } else {                                                     \
                    PAGE = MmModifiedPageListByColor[COLOR].Flink;           \
                }                                                            \
            }



//++
//VOID
//MI_MAKE_VALID_PTE_WRITE_COPY (
//    IN OUT PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro checks to see if the PTE indicates that the
//    page is writable and if so it clears the write bit and
//    sets the copy-on-write bit.
//
// Arguments:
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     None.
//
//--

#define MI_MAKE_VALID_PTE_WRITE_COPY(PPTE) \
                    if ((PPTE)->u.Hard.Write == 1) {    \
                        (PPTE)->u.Hard.CopyOnWrite = 1; \
                        (PPTE)->u.Hard.Write = 0;       \
                    }

#define MI_PTE_OWNER_USER       3

#define MI_PTE_OWNER_KERNEL     0

#if defined(_MIALT4K_)
#define MI_IS_ALT_PAGE_TABLE_ADDRESS(PPTE) \
            (((PPTE) >= (PMMPTE)ALT4KB_PERMISSION_TABLE_START) && \
             ((PPTE) < (PMMPTE)ALT4KB_PERMISSION_TABLE_END))
#else
#define MI_IS_ALT_PAGE_TABLE_ADDRESS(PPTE) 0
#endif

//++
//ULONG
//MI_DETERMINE_OWNER (
//    IN MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro examines the virtual address of the PTE and determines
//    if the PTE resides in system space or user space.
//
// Arguments:
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     3 if the owner is USER_MODE, 0 if the owner is KERNEL_MODE.
//
//--

#define MI_DETERMINE_OWNER(PPTE)   \
     ((((((PPTE) >= (PMMPTE)PTE_UBASE) && ((PPTE) <= MiHighestUserPte))) || \
       (MI_IS_ALT_PAGE_TABLE_ADDRESS(PPTE))) ? MI_PTE_OWNER_USER : MI_PTE_OWNER_KERNEL)


//++
//VOID
//MI_SET_ACCESSED_IN_PTE (
//    IN OUT MMPTE PPTE,
//    IN ULONG ACCESSED
//    );
//
// Routine Description:
//
//    This macro sets the ACCESSED field in the PTE.  Note that this must
//    not be cleared in PPEs or PDEs as they are not checked for this in
//    memory management before referencing the hierarchy beneath them.
//
// Arguments:
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_ACCESSED_IN_PTE(PPTE,ACCESSED) {                              \
        PWOW64_PROCESS _Wow64Process;                                        \
        if (ACCESSED == 0) {                                                 \
            if (MI_IS_PTE_ADDRESS(PPTE)) {                                   \
                (PPTE)->u.Hard.Accessed = 0;                                 \
            }                                                                \
        }                                                                    \
        else if ((PPTE >= (PMMPTE)PTE_UBASE) && (PPTE < (PMMPTE)MiMaxWow64Pte)) {    \
            _Wow64Process = PsGetCurrentProcess()->Wow64Process;             \
            if ((_Wow64Process != NULL) && (PPTE < MmWorkingSetList->HighestUserPte)) {                                     \
                if (MI_CHECK_BIT(_Wow64Process->AltPermBitmap,               \
                ((ULONG_PTR)PPTE >> PTE_SHIFT) & _ALTPERM_BITMAP_MASK) != 0) { \
                    NOTHING;                                                 \
                }                                                            \
                else {                                                       \
                    (PPTE)->u.Hard.Accessed = 1;                             \
                }                                                            \
            }                                                                \
            else {                                                           \
                (PPTE)->u.Hard.Accessed = 1;                                 \
            }                                                                \
        }                                                                    \
        else {                                                               \
            (PPTE)->u.Hard.Accessed = 1;                                     \
        }                                                                    \
}



//++
//ULONG
//MI_GET_ACCESSED_IN_PTE (
//    IN OUT MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro returns the state of the ACCESSED field in the PTE.
//
// Arguments:
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     The state of the ACCESSED field.
//
//--

#define MI_GET_ACCESSED_IN_PTE(PPTE) ((PPTE)->u.Hard.Accessed)



//++
//VOID
//MI_SET_OWNER_IN_PTE (
//    IN PMMPTE PPTE
//    IN ULONG OWNER
//    );
//
// Routine Description:
//
//    This macro sets the owner field in the PTE.
//
// Arguments:
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_OWNER_IN_PTE(PPTE,OWNER)



//++
//VOID
//MI_SET_PAGING_FILE_INFO (
//    OUT MMPTE OUTPTE,
//    IN MMPTE PPTE,
//    IN ULONG FILEINFO,
//    IN ULONG OFFSET
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//
// Arguments:
//
//    OUTPTE - Supplies the PTE in which to store the result.
//
//    PTE - Supplies the PTE to operate upon.
//
//    FILEINFO - Supplies the number of the paging file.
//
//    OFFSET - Supplies the offset into the paging file.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_PAGING_FILE_INFO(OUTPTE,PTE,FILEINFO,OFFSET) \
        (OUTPTE).u.Long = (((PTE).u.Soft.Protection << MM_PROTECT_FIELD_SHIFT) | \
         ((ULONGLONG)(FILEINFO) << _MM_PAGING_FILE_LOW_SHIFT) | \
         ((ULONGLONG)(OFFSET) << _MM_PAGING_FILE_HIGH_SHIFT));


//++
//PMMPTE
//MiPteToProto (
//    IN OUT MMPTE PPTE,
//    IN ULONG FILEINFO,
//    IN ULONG OFFSET
//    );
//
// Routine Description:
//
//    This macro returns the address of the corresponding prototype which
//    was encoded earlier into the supplied PTE.
//
// Arguments:
//
//    lpte - Supplies the PTE to operate upon.
//
// Return Value:
//
//    Pointer to the prototype PTE that backs this PTE.
//
//--


#define MiPteToProto(lpte) \
            ((PMMPTE) ((ULONG_PTR)((lpte)->u.Proto.ProtoAddress) + MmProtopte_Base))

//++
//ULONG_PTR
//MiProtoAddressForPte (
//    IN PMMPTE proto_va
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//    MiProtoAddressForPte returns the bit field to OR into the PTE to
//    reference a prototype PTE.
//
//    And set the protoPTE MM_PTE_PROTOTYPE_MASK bit.
//
// Arguments:
//
//    proto_va - Supplies the address of the prototype PTE.
//
// Return Value:
//
//    Mask to set into the PTE.
//
//--

#define MiProtoAddressForPte(proto_va)  \
        (( (ULONGLONG)((ULONG_PTR)proto_va - MmProtopte_Base) <<  \
          (_MM_PROTO_ADDRESS_SHIFT)) | MM_PTE_PROTOTYPE_MASK)

#define MISetProtoAddressForPte(PTE, proto_va) \
        (PTE).u.Long = 0;                      \
        (PTE).u.Proto.Prototype = 1;           \
        (PTE).u.Proto.ProtoAddress = (ULONG_PTR)proto_va - MmProtopte_Base;


//++
//ULONG_PTR
//MiProtoAddressForKernelPte (
//    IN PMMPTE proto_va
//    );
//
// Routine Description:
//
//    This macro sets into the specified PTE the supplied information
//    to indicate where the backing store for the page is located.
//    MiProtoAddressForPte returns the bit field to OR into the PTE to
//    reference a prototype PTE.  And set the protoPTE bit,
//    MM_PTE_PROTOTYPE_MASK.
//
//    This macro also sets any other information (such as global bits)
//    required for kernel mode PTEs.
//
// Arguments:
//
//    proto_va - Supplies the address of the prototype PTE.
//
// Return Value:
//
//    Mask to set into the PTE.
//
//--

//  not different on IA64.

#define MiProtoAddressForKernelPte(proto_va)  MiProtoAddressForPte(proto_va)


#define MM_SUBSECTION_MAP (128*1024*1024)

//++
//PSUBSECTION
//MiGetSubsectionAddress (
//    IN PMMPTE lpte
//    );
//
// Routine Description:
//
//   This macro takes a PTE and returns the address of the subsection that
//   the PTE refers to.  Subsections are quadword structures allocated
//   from nonpaged pool.
//
// Arguments:
//
//   lpte - Supplies the PTE to operate upon.
//
// Return Value:
//
//   A pointer to the subsection referred to by the supplied PTE.
//
//--

#define MiGetSubsectionAddress(lpte)                              \
    (((lpte)->u.Subsect.WhichPool == 1) ?                              \
     ((PSUBSECTION)((ULONG_PTR)MmSubsectionBase +    \
                    ((ULONG_PTR)(lpte)->u.Subsect.SubsectionAddress))) \
     : \
     ((PSUBSECTION)((ULONG_PTR)MM_NONPAGED_POOL_END -    \
                    ((ULONG_PTR)(lpte)->u.Subsect.SubsectionAddress))))

//++
//ULONGLONG
//MiGetSubsectionAddressForPte (
//    IN PSUBSECTION VA
//    );
//
// Routine Description:
//
//    This macro takes the address of a subsection and encodes it for use
//    in a PTE.
//
//    NOTE - THE SUBSECTION ADDRESS MUST BE QUADWORD ALIGNED!
//
// Arguments:
//
//    VA - Supplies a pointer to the subsection to encode.
//
// Return Value:
//
//     The mask to set into the PTE to make it reference the supplied
//     subsetion.
//
//--

#define MiGetSubsectionAddressForPte(VA)                   \
   ( ((ULONG_PTR)(VA) < (ULONG_PTR)KSEG2_BASE) ?                  \
     ( ((ULONGLONG)((ULONG_PTR)VA - (ULONG_PTR)MmSubsectionBase) \
          << (_MM_PTE_SUBSECTION_ADDRESS_SHIFT)) | 0x80) \
     : \
       ((ULONGLONG)((ULONG_PTR)MM_NONPAGED_POOL_END - (ULONG_PTR)VA) \
          << (_MM_PTE_SUBSECTION_ADDRESS_SHIFT)) )

//++
//ULONG
//MiGetPpeOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPpeOffset returns the offset into a page directory parent for a
//    given virtual address.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page root table the corresponding PPE is at.
//
//--

#define MiGetPpeOffset(va) \
     ((((ULONG_PTR)(va) & PDE_TBASE) == PDE_TBASE) ? \
      ((PDE_SELFMAP & ((sizeof(MMPTE)*PTE_PER_PAGE) - 1))/sizeof(MMPTE)) : \
      ((ULONG)(((ULONG_PTR)(va) >> PDI1_SHIFT) & PDI_MASK)))

//++
//ULONG
//MiGetPpeIndex (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPpeIndex returns the page directory parent index
//    for a given virtual address.
//
//    N.B. This does not mask off PXE bits.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the index for.
//
// Return Value:
//
//    The index into the page directory parent - ie: the virtual page directory
//    number.  This is different from the page directory parent offset because
//    this spans page directory parents on supported platforms.
//
//    N.B.  This macro only works on user addresses - the region ID bits
//    are not masked off !
//--

#define MiGetPpeIndex(va) ((ULONG)((ULONG_PTR)(va) >> PDI1_SHIFT))

//++
//ULONG_PTR
//MiGetPdeOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeOffset returns the offset into a page directory
//    for a given virtual address.
//
// Arguments:
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page directory table the corresponding PDE is at.
//
//--

#define MiGetPdeOffset(va) ((ULONG) (((ULONG_PTR)(va) >> PDI_SHIFT) & PDI_MASK))

//++
//ULONG
//MiGetPdeIndex (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeIndex returns the page directory index
//    for a given virtual address.
//
//    N.B. This does not mask off PPE bits.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the index for.
//
// Return Value:
//
//    The index into the page directory - ie: the virtual page table number.
//    This is different from the page directory offset because this spans
//    page directories on supported platforms.
//
//    N.B.  This macro only works on user addresses - the region ID bits
//    are not masked off !
//
//--

#define MiGetPdeIndex(va) ((ULONG) ((ULONG_PTR)(va) >> PDI_SHIFT))

//++
//ULONG_PTR
//MiGetPteOffset (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPteOffset returns the offset into a page table page
//    for a given virtual address.
//
// Arguments:
//
//    Va - Supplies the virtual address to locate the offset for.
//
// Return Value:
//
//    The offset into the page table page table the corresponding PTE is at.
//
//--

#define MiGetPteOffset(va) ((ULONG) (((ULONG_PTR)(va) >> PTI_SHIFT) & PDI_MASK))


//++
//++
//PVOID
//MiGetVirtualAddressMappedByPpe (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPpe returns the virtual address
//    which is mapped by a given PPE address.
//
// Arguments
//
//    PPE - Supplies the PPE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PPE.
//
//--

#define MiGetVirtualAddressMappedByPpe(PPE) \
    MiGetVirtualAddressMappedByPte(MiGetVirtualAddressMappedByPde(PPE))

//++
//PVOID
//MiGetVirtualAddressMappedByPde (
//    IN PMMPTE PDE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPde returns the virtual address
//    which is mapped by a given PDE address.
//
// Arguments
//
//    PDE - Supplies the PDE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PDE.
//
//--

#define MiGetVirtualAddressMappedByPde(Pde) \
    MiGetVirtualAddressMappedByPte(MiGetVirtualAddressMappedByPte(Pde))

//++
//PVOID
//MiGetVirtualAddressMappedByPte (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    MiGetVirtualAddressMappedByPte returns the virtual address
//    which is mapped by a given PTE address.
//
// Arguments:
//
//    PTE - Supplies the PTE to get the virtual address for.
//
// Return Value:
//
//    Virtual address mapped by the PTE.
//
//--

#define MiGetVirtualAddressMappedByPte(PTE) \
  (((ULONG_PTR)(PTE) & PTA_SIGN) ? \
   (PVOID)(((ULONG_PTR)(PTE) & VRN_MASK) | VA_FILL | \
           (((ULONG_PTR)(PTE)-PTE_BASE) << (PAGE_SHIFT - PTE_SHIFT))) : \
   (PVOID)(((ULONG_PTR)(PTE) & VRN_MASK) | (((ULONG_PTR)(PTE)-PTE_BASE) << (PAGE_SHIFT - PTE_SHIFT))))


//++
//LOGICAL
//MiIsVirtualAddressOnPpeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsVirtualAddressOnPpeBoundary returns TRUE if the virtual address is
//    on a page directory entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on a boundary, FALSE if not.
//
//--

#define MiIsVirtualAddressOnPpeBoundary(VA) (((ULONG_PTR)(VA) & PAGE_DIRECTORY1_MASK) == 0)


//++
//LOGICAL
//MiIsVirtualAddressOnPdeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsVirtualAddressOnPdeBoundary returns TRUE if the virtual address is
//    on a page directory entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on an 8MB PDE boundary, FALSE if not.
//
//--

#define MiIsVirtualAddressOnPdeBoundary(VA) (((ULONG_PTR)(VA) & PAGE_DIRECTORY2_MASK) == 0)

//++
//LOGICAL
//MiIsPteOnPpeBoundary (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    MiIsPteOnPpeBoundary returns TRUE if the PTE is
//    on a page directory parent entry boundary.
//
// Arguments
//
//    VA - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if on a boundary, FALSE if not.
//
//--

#define MiIsPteOnPpeBoundary(PTE) (((ULONG_PTR)(PTE) & (MM_VA_MAPPED_BY_PDE - 1)) == 0)



//++
//LOGICAL
//MiIsPteOnPdeBoundary (
//    IN PVOID PTE
//    );
//
// Routine Description:
//
//    MiIsPteOnPdeBoundary returns TRUE if the PTE is
//    on a page directory entry boundary.
//
// Arguments
//
//    PTE - Supplies the PTE to check.
//
// Return Value:
//
//    TRUE if on a 8MB PDE boundary, FALSE if not.
//
//--

#define MiIsPteOnPdeBoundary(PTE) (((ULONG_PTR)(PTE) & (PAGE_SIZE - 1)) == 0)


//++
//ULONG
//GET_PAGING_FILE_NUMBER (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro extracts the paging file number from a PTE.
//
// Arguments:
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    The paging file number.
//
//--

#define GET_PAGING_FILE_NUMBER(PTE) ((ULONG) (PTE).u.Soft.PageFileLow)



//++
//ULONG
//GET_PAGING_FILE_OFFSET (
//    IN MMPTE PTE
//    );
//
// Routine Description:
//
//    This macro extracts the offset into the paging file from a PTE.
//
// Arguments:
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    The paging file offset.
//
//--

#define GET_PAGING_FILE_OFFSET(PTE) ((ULONG) (PTE).u.Soft.PageFileHigh)




//++
//ULONG_PTR
//IS_PTE_NOT_DEMAND_ZERO (
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro checks to see if a given PTE is NOT a demand zero PTE.
//
// Arguments:
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//     Returns 0 if the PTE is demand zero, non-zero otherwise.
//
//--

#define IS_PTE_NOT_DEMAND_ZERO(PTE) \
                 ((PTE).u.Long & ((ULONG_PTR)0xFFFFFFFFF0000000 |  \
                                  MM_PTE_VALID_MASK |       \
                                  MM_PTE_PROTOTYPE_MASK |   \
                                  MM_PTE_TRANSITION_MASK))


//++
//VOID
//MI_MAKING_VALID_PTE_INVALID(
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    Prepare to make a single valid PTE invalid.
//    No action is required on IA64.
//
// Arguments:
//
//    SYSTEM_WIDE - Supplies TRUE if this will happen on all processors.
//
// Return Value:
//
//    None.
//
//--

#define MI_MAKING_VALID_PTE_INVALID(SYSTEM_WIDE)


//++
//VOID
//MI_MAKING_VALID_MULTIPLE_PTES_INVALID(
//    IN PMMPTE PPTE
//    );
//
// Routine Description:
//
//    Prepare to make multiple valid PTEs invalid.
//    No action is required on IA64.
//
// Arguments:
//
//    SYSTEM_WIDE - Supplies TRUE if this will happen on all processors.
//
// Return Value:
//
//    None.
//
//--

#define MI_MAKING_MULTIPLE_PTES_INVALID(SYSTEM_WIDE)



//++
//VOID
//MI_MAKE_PROTECT_WRITE_COPY (
//    IN OUT MMPTE PPTE
//    );
//
// Routine Description:
//
//    This macro makes a writable PTE a writeable-copy PTE.
//
// Arguments:
//
//    PTE - Supplies the PTE to operate upon.
//
// Return Value:
//
//    NONE
//
//--

#define MI_MAKE_PROTECT_WRITE_COPY(PTE) \
        if ((PTE).u.Soft.Protection & MM_PROTECTION_WRITE_MASK) {      \
            (PTE).u.Long |= MM_PROTECTION_COPY_MASK << MM_PROTECT_FIELD_SHIFT;      \
        }


//++
//VOID
//MI_SET_PAGE_DIRTY(
//    IN PMMPTE PPTE,
//    IN PVOID VA,
//    IN PVOID PFNHELD
//    );
//
// Routine Description:
//
//    This macro sets the dirty bit (and release page file space).
//
// Arguments:
//
//    TEMP - Supplies a temporary for usage.
//
//    PPTE - Supplies a pointer to the PTE that corresponds to VA.
//
//    VA - Supplies a the virtual address of the page fault.
//
//    PFNHELD - Supplies TRUE if the PFN lock is held.
//
// Return Value:
//
//    None.
//
//--

#define MI_SET_PAGE_DIRTY(PPTE,VA,PFNHELD)                          \
            if ((PPTE)->u.Hard.Dirty == 1) {                        \
                MiSetDirtyBit ((VA),(PPTE),(PFNHELD));              \
            }


//++
//VOID
//MI_NO_FAULT_FOUND(
//    IN FAULTSTATUS,
//    IN PMMPTE PPTE,
//    IN PVOID VA,
//    IN PVOID PFNHELD
//    );
//
// Routine Description:
//
//    This macro handles the case when a page fault is taken and no
//    PTE with the valid bit clear is found.
//
// Arguments:
//
//    FAULTSTATUS - Supplies the fault status.
//
//    PPTE - Supplies a pointer to the PTE that corresponds to VA.
//
//    VA - Supplies a the virtual address of the page fault.
//
//    PFNHELD - Supplies TRUE if the PFN lock is held.
//
// Return Value:
//
//    None.
//
//--

#define MI_NO_FAULT_FOUND(FAULTSTATUS,PPTE,VA,PFNHELD)              \
        if ((MI_FAULT_STATUS_INDICATES_WRITE(FAULTSTATUS)) && ((PPTE)->u.Hard.Dirty == 0)) {                                                        \
            MiSetDirtyBit ((VA),(PPTE),(PFNHELD));                  \
        } else {                                                    \
            MMPTE TempPte;                                          \
            TempPte = *(PPTE);                                      \
            MI_SET_ACCESSED_IN_PTE (&TempPte, 1);                   \
            MI_WRITE_VALID_PTE_NEW_PROTECTION((PPTE), TempPte);     \
            KiFlushSingleTb((VA));                                  \
        }


//++
//ULONG_PTR
//MI_CAPTURE_DIRTY_BIT_TO_PFN (
//    IN PMMPTE PPTE,
//    IN PMMPFN PPFN
//    );
//
// Routine Description:
//
//    This macro gets captures the state of the dirty bit to the PFN
//    and frees any associated page file space if the PTE has been
//    modified element.
//
//    NOTE - THE PFN LOCK MUST BE HELD!
//
// Arguments:
//
//    PPTE - Supplies the PTE to operate upon.
//
//    PPFN - Supplies a pointer to the PFN database element that corresponds
//           to the page mapped by the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_CAPTURE_DIRTY_BIT_TO_PFN(PPTE,PPFN)                      \
         ASSERT (KeGetCurrentIrql() > APC_LEVEL);                   \
         if (((PPFN)->u3.e1.Modified == 0) &&                       \
            ((PPTE)->u.Hard.Dirty != 0)) {                          \
             MI_SET_MODIFIED (PPFN, 1, 0x18);                       \
             if (((PPFN)->OriginalPte.u.Soft.Prototype == 0) &&     \
                          ((PPFN)->u3.e1.WriteInProgress == 0)) {   \
                 MiReleasePageFileSpace ((PPFN)->OriginalPte);      \
                 (PPFN)->OriginalPte.u.Soft.PageFileHigh = 0;       \
             }                                                      \
         }


//++
//BOOLEAN
//MI_IS_PHYSICAL_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    physical address.
//
// Arguments:
//
//    VA - Supplies the virtual address.
//
// Return Value:
//
//    FALSE if it is not a physical address, TRUE if it is.
//
//--


#define MI_IS_PHYSICAL_ADDRESS(Va) \
     ((((ULONG_PTR)(Va) >= KSEG3_BASE) && ((ULONG_PTR)(Va) < KSEG3_LIMIT)) || \
      (((ULONG_PTR)(Va) >= KSEG4_BASE) && ((ULONG_PTR)(Va) < KSEG4_LIMIT)) || \
      (((ULONG_PTR)Va >= KSEG0_BASE) && ((ULONG_PTR)Va < KSEG2_BASE)) || \
      ((MiGetPpeAddress(Va)->u.Hard.Valid == 1) && \
       (MiGetPdeAddress(Va)->u.Hard.Valid == 1) && \
       (MI_PDE_MAPS_LARGE_PAGE (MiGetPdeAddress (Va)))))


//++
//ULONG_PTR
//MI_CONVERT_PHYSICAL_TO_PFN (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro converts a physical address (see MI_IS_PHYSICAL_ADDRESS)
//    to its corresponding physical frame number.
//
// Arguments:
//
//    VA - Supplies a pointer to the physical address.
//
// Return Value:
//
//    Returns the PFN for the page.
//
//--

PVOID
KiGetPhysicalAddress (
    IN PVOID VirtualAddress
    );

#define MI_CONVERT_PHYSICAL_TO_PFN(Va)   \
    ((((ULONG_PTR)(Va) >= KSEG0_BASE) && ((ULONG_PTR)(Va) < KSEG2_BASE)) ? \
     ((PFN_NUMBER)(((ULONG_PTR)KiGetPhysicalAddress(Va)) >> PAGE_SHIFT)) : \
     ((((ULONG_PTR)(Va) >= KSEG3_BASE) && ((ULONG_PTR)(Va) < KSEG3_LIMIT)) || \
     (((ULONG_PTR)(Va) >= KSEG4_BASE) && ((ULONG_PTR)(Va) < KSEG4_LIMIT))) ? \
     ((PFN_NUMBER)(((ULONG_PTR)(Va) & ~VRN_MASK) >> PAGE_SHIFT)) : \
     ((PFN_NUMBER)(MiGetPdeAddress(Va)->u.Hard.PageFrameNumber) + (MiGetPteOffset((ULONG_PTR)Va))))


typedef struct _MMCOLOR_TABLES {
    PFN_NUMBER Flink;
    PVOID Blink;
    PFN_NUMBER Count;
} MMCOLOR_TABLES, *PMMCOLOR_TABLES;

#if MM_MAXIMUM_NUMBER_OF_COLORS > 1
extern MMPFNLIST MmFreePagesByPrimaryColor[2][MM_MAXIMUM_NUMBER_OF_COLORS];
#endif

extern PMMCOLOR_TABLES MmFreePagesByColor[2];

extern PFN_NUMBER MmTotalPagesForPagingFile;


//
// A VALID Page Table Entry on the IA64 has the following definition.
//

#define _MM_PAGING_FILE_LOW_SHIFT 28
#define _MM_PAGING_FILE_HIGH_SHIFT 32

#define MI_MAXIMUM_PAGEFILE_SIZE (((UINT64)4 * 1024 * 1024 * 1024 - 1) * PAGE_SIZE)

#define MI_PTE_LOOKUP_NEEDED ((ULONG64)0xffffffff)

typedef struct _MMPTE_SOFTWARE {
    ULONGLONG Valid : 1;
    ULONGLONG Prototype : 1;
    ULONGLONG Protection : 5;
    ULONGLONG Transition : 1;
    ULONGLONG Reserved0 : 3;
    ULONGLONG SplitPermissions : 1;
    ULONGLONG UsedPageTableEntries : PTE_PER_PAGE_BITS;
    ULONGLONG Reserved : 16 - PTE_PER_PAGE_BITS;
    ULONGLONG PageFileLow: 4;
    ULONGLONG PageFileHigh : 32;
} MMPTE_SOFTWARE;

typedef struct _MMPTE_TRANSITION {
    ULONGLONG Valid : 1;
    ULONGLONG Prototype : 1;
    ULONGLONG Protection : 5;
    ULONGLONG Transition : 1;
    ULONGLONG Rsvd0 : 3;
    ULONGLONG SplitPermissions : 1;
    ULONGLONG Reserved1 : 1;
    ULONGLONG PageFrameNumber : 50 - PAGE_SHIFT;
    ULONGLONG Rsvd1 : 14;
} MMPTE_TRANSITION;


#define _MM_PROTO_ADDRESS_SHIFT 12

typedef struct _MMPTE_PROTOTYPE {
    ULONGLONG Valid : 1;
    ULONGLONG Prototype : 1;
    ULONGLONG ReadOnly : 1;  // if set allow read only access.
    ULONGLONG Rsvd : 8;
    ULONGLONG SplitPermissions : 1;
    ULONGLONG ProtoAddress : 52;
} MMPTE_PROTOTYPE;


#define _MM_PTE_SUBSECTION_ADDRESS_SHIFT  12

typedef struct _MMPTE_SUBSECTION {
    ULONGLONG Valid : 1;
    ULONGLONG Prototype : 1;
    ULONGLONG Protection : 5;
    ULONGLONG WhichPool : 1;
    ULONGLONG Rsvd : 3;
    ULONGLONG SplitPermissions : 1;
    ULONGLONG SubsectionAddress : 52;
} MMPTE_SUBSECTION;

typedef struct _MMPTE_LIST {
    ULONGLONG Valid : 1;

    //
    // Note the Prototype bit must not be used for lists like freed nonpaged
    // pool because lookaside pops can legitimately reference bogus addresses
    // (since the pop is unsynchronized) and the fault handler must be able to
    // distinguish lists from protos so a retry status can be returned (vs a
    // fatal bugcheck).
    //
    // The same caveat applies to both the Transition and the Protection
    // fields as they are similarly examined in the fault handler and would
    // be misinterpreted if ever nonzero in the freed nonpaged pool chains.
    //

    ULONGLONG Prototype : 1;            // MUST BE ZERO as per above comment.
    ULONGLONG Protection : 5;
    ULONGLONG Transition : 1;
    ULONGLONG OneEntry : 1;
    ULONGLONG filler10 : 23;
    ULONGLONG NextEntry : 32;
} MMPTE_LIST;


//
// A Page Table Entry on the IA64 has the following definition.
//

#define _HARDWARE_PTE_WORKING_SET_BITS  11

typedef struct _MMPTE_HARDWARE {
    ULONGLONG Valid : 1;
    ULONGLONG Rsvd0 : 1;
    ULONGLONG Cache : 3;
    ULONGLONG Accessed : 1;
    ULONGLONG Dirty : 1;
    ULONGLONG Owner : 2;
    ULONGLONG Execute : 1;
    ULONGLONG Write : 1;
    ULONGLONG Rsvd1 : PAGE_SHIFT - 12;
    ULONGLONG CopyOnWrite : 1;
    ULONGLONG PageFrameNumber : 50 - PAGE_SHIFT;
    ULONGLONG Rsvd2 : 2;
    ULONGLONG Exception : 1;
    ULONGLONG SoftwareWsIndex : _HARDWARE_PTE_WORKING_SET_BITS;
} MMPTE_HARDWARE, *PMMPTE_HARDWARE;

typedef struct _MMPTE_LARGEPAGE {
    ULONGLONG Valid : 1;
    ULONGLONG Rsvd0 : 1;
    ULONGLONG Cache : 3;
    ULONGLONG Accessed : 1;
    ULONGLONG Dirty : 1;
    ULONGLONG Owner : 2;
    ULONGLONG Execute : 1;
    ULONGLONG Write : 1;
    ULONGLONG Rsvd1 : PAGE_SHIFT - 12;
    ULONGLONG CopyOnWrite : 1;
    ULONGLONG PageFrameNumber : 50 - PAGE_SHIFT;
    ULONGLONG Rsvd2 : 2;
    ULONGLONG Exception : 1;
    ULONGLONG Rsvd3 : 1;
    ULONGLONG LargePage : 1;
    ULONGLONG PageSize : 6;
    ULONGLONG Rsvd4 : 3;
} MMPTE_LARGEPAGE, *PMMPTE_LARGEPAGE;

typedef struct _ALT_4KPTE {
    ULONGLONG Commit : 1;
    ULONGLONG Rsvd0 : 1;
    ULONGLONG Cache : 3;
    ULONGLONG Accessed : 1;
    ULONGLONG InPageInProgress : 1;
    ULONGLONG Owner : 2;
    ULONGLONG Execute : 1;
    ULONGLONG Write : 1;
    ULONGLONG Rsvd1 : 1;
    ULONGLONG PteOffset : 32;
    ULONGLONG Rsvd2 : 8;
    ULONGLONG Exception : 1;
    ULONGLONG Protection : 5;
    ULONGLONG Lock : 1;
    ULONGLONG FillZero : 1;
    ULONGLONG NoAccess : 1;
    ULONGLONG CopyOnWrite : 1;
    ULONGLONG PteIndirect : 1;
    ULONGLONG Private : 1;
} ALT_4KPTE, *PALT_4KPTE;

//
// Use MM_PTE_CACHE_RESERVED to prevent the VHPT walker from speculatively
// filling this entry and also so the TB miss handler knows that this is
// a large (8mb) page directory entry.
//

#define MI_PDE_MAPS_LARGE_PAGE(PDE) ((PDE)->u.Hard.Cache == MM_PTE_CACHE_RESERVED)

#define MI_MAKE_PDE_MAP_LARGE_PAGE(PDE) ((PDE)->u.Hard.Cache = MM_PTE_CACHE_RESERVED)

#define MI_GET_PAGE_FRAME_FROM_PTE(PTE) ((ULONG)((PTE)->u.Hard.PageFrameNumber))
#define MI_GET_PAGE_FRAME_FROM_TRANSITION_PTE(PTE) ((ULONG)((PTE)->u.Trans.PageFrameNumber))
#define MI_GET_PROTECTION_FROM_SOFT_PTE(PTE) ((ULONG)((PTE)->u.Soft.Protection))
#define MI_GET_PROTECTION_FROM_TRANSITION_PTE(PTE) ((ULONG)((PTE)->u.Trans.Protection))


typedef struct _MMPTE {
    union  {
        ULONGLONG Long;
        MMPTE_HARDWARE Hard;
        MMPTE_LARGEPAGE Large;
        HARDWARE_PTE Flush;
        MMPTE_PROTOTYPE Proto;
        MMPTE_SOFTWARE Soft;
        MMPTE_TRANSITION Trans;
        MMPTE_SUBSECTION Subsect;
        MMPTE_LIST List;
        ALT_4KPTE Alt;
        } u;
} MMPTE;

typedef MMPTE *PMMPTE;

extern PMMPTE MiFirstReservedZeroingPte;

#define InterlockedCompareExchangePte(_PointerPte, _NewContents, _OldContents) \
        InterlockedCompareExchange64 ((PLONGLONG)(_PointerPte), (LONGLONG)(_NewContents), (LONGLONG)(_OldContents))

#define InterlockedExchangePte(_PointerPte, _NewContents) InterlockedExchange64((PLONG64)(_PointerPte), _NewContents)

//++
//VOID
//MI_WRITE_VALID_PTE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE fills in the specified PTE making it valid with the
//    specified contents.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 0);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*((volatile MMPTE *)(_PointerPte)) = (_PteContents))

//++
//VOID
//MI_WRITE_INVALID_PTE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_INVALID_PTE fills in the specified PTE making it invalid with the
//    specified contents.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_INVALID_PTE(_PointerPte, _PteContents)  \
            ASSERT ((_PteContents).u.Hard.Valid == 0);  \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MI_WRITE_VALID_PTE_NEW_PROTECTION (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE_NEW_PROTECTION fills in the specified PTE (which was
//    already valid) changing only the protection or the dirty bit.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE_NEW_PROTECTION(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 1);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            ASSERT ((_PointerPte)->u.Hard.PageFrameNumber == (_PteContents).u.Hard.PageFrameNumber); \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MI_WRITE_VALID_PTE_NEW_PAGE (
//    IN PMMPTE PointerPte,
//    IN MMPTE PteContents
//    );
//
// Routine Description:
//
//    MI_WRITE_VALID_PTE_NEW_PAGE fills in the specified PTE (which was
//    already valid) changing the page and the protection.
//    Note that the contents are very carefully written.
//
// Arguments
//
//    PointerPte - Supplies a PTE to fill.
//
//    PteContents - Supplies the contents to put in the PTE.
//
// Return Value:
//
//    None.
//
//--

#define MI_WRITE_VALID_PTE_NEW_PAGE(_PointerPte, _PteContents)    \
            ASSERT ((_PointerPte)->u.Hard.Valid == 1);  \
            ASSERT ((_PteContents).u.Hard.Valid == 1);  \
            ASSERT ((_PointerPte)->u.Hard.PageFrameNumber != (_PteContents).u.Hard.PageFrameNumber); \
            MI_LOG_PTE_CHANGE (_PointerPte, _PteContents);  \
            (*(_PointerPte) = (_PteContents))

//++
//VOID
//MiFillMemoryPte (
//    IN PMMPTE Destination,
//    IN ULONGLONG NumberOfPtes,
//    IN MMPTE Pattern
//    };
//
// Routine Description:
//
//    This function fills memory with the specified PTE pattern.
//
// Arguments
//
//    Destination - Supplies a pointer to the memory to fill.
//
//    NumberOfPtes - Supplies the number of PTEs (not bytes!) to be filled.
//
//    Pattern     - Supplies the PTE fill pattern.
//
// Return Value:
//
//    None.
//
//--

#define MiFillMemoryPte(Destination, Length, Pattern) \
             RtlFillMemoryUlonglong ((Destination), (Length) * sizeof (MMPTE), (Pattern))

#define MiZeroMemoryPte(Destination, Length) \
             RtlZeroMemory ((Destination), (Length) * sizeof (MMPTE))


#define KiWbInvalidateCache


//++
//BOOLEAN
//MI_IS_PAGE_TABLE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    page table address (PTE, PDE, PPE).
//
// Arguments
//
//    VA - Supplies the virtual address.
//
// Return Value:
//
//    FALSE if it is not a page table address, TRUE if it is.
//
//--

#define MI_IS_PAGE_TABLE_ADDRESS(VA) \
    ((((ULONG_PTR)VA >= PTE_UBASE) && ((ULONG_PTR)VA < (PDE_UTBASE + PAGE_SIZE))) || \
     (((ULONG_PTR)VA >= PTE_KBASE) && ((ULONG_PTR)VA < (PDE_KTBASE + PAGE_SIZE))) || \
     (((ULONG_PTR)VA >= PTE_SBASE) && ((ULONG_PTR)VA < (PDE_STBASE + PAGE_SIZE))) || \
    MI_IS_ALT_PAGE_TABLE_ADDRESS((PMMPTE)VA))

//++
//BOOLEAN
//MI_IS_PAGE_TABLE_OR_HYPER_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a page table or hyperspace address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is a page table or hyperspace address, FALSE if not.
//
//--

#define MI_IS_PAGE_TABLE_OR_HYPER_ADDRESS(VA)   \
            (MI_IS_PAGE_TABLE_ADDRESS(VA) || MI_IS_HYPER_SPACE_ADDRESS(VA))

//++
//BOOLEAN
//MI_IS_HYPER_SPACE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address resides in
//    hyperspace.
//
// Arguments
//
//    VA - Supplies the virtual address.
//
// Return Value:
//
//    FALSE if it is not a hyperspace address, TRUE if it is.
//
//--

#define MI_IS_HYPER_SPACE_ADDRESS(VA) \
    (((PVOID)VA >= HYPER_SPACE) && ((PVOID)VA <= HYPER_SPACE_END))

//++
//BOOLEAN
//MI_IS_PTE_ADDRESS (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    page table page (PTE) address.
//
// Arguments
//
//    PTE - Supplies the PTE virtual address.
//
// Return Value:
//
//    FALSE if it is not a PTE address, TRUE if it is.
//
//--

#define MI_IS_PTE_ADDRESS(PTE) \
    (((PTE >= (PMMPTE)PTE_UBASE) && (PTE <= (PMMPTE)PTE_UTOP)) || \
     ((PTE >= (PMMPTE)PTE_KBASE) && (PTE <= (PMMPTE)PTE_KTOP)) || \
     ((PTE >= (PMMPTE)PTE_SBASE) && (PTE <= (PMMPTE)PTE_STOP)))


#define MI_IS_PPE_ADDRESS(PTE) \
    (((PTE >= (PMMPTE)PDE_UTBASE) && (PTE <= (PMMPTE)(PDE_UTBASE + PAGE_SIZE))) || \
     ((PTE >= (PMMPTE)PDE_KTBASE) && (PTE <= (PMMPTE)(PDE_KTBASE + PAGE_SIZE))) || \
     ((PTE >= (PMMPTE)PDE_STBASE) && (PTE <= (PMMPTE)(PDE_STBASE + PAGE_SIZE))))

//++
//BOOLEAN
//MI_IS_KERNEL_PTE_ADDRESS (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    kernel page table page (PTE) address.
//
// Arguments
//
//    PTE - Supplies the PTE virtual address.
//
// Return Value:
//
//    FALSE if it is not a kernel PTE address, TRUE if it is.
//
//--

#define MI_IS_KERNEL_PTE_ADDRESS(PTE) \
     (((PMMPTE)PTE >= (PMMPTE)PTE_KBASE) && ((PMMPTE)PTE <= (PMMPTE)PTE_KTOP))


//++
//BOOLEAN
//MI_IS_USER_PTE_ADDRESS (
//    IN PMMPTE PTE
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    page table page (PTE) address.
//
// Arguments
//
//    PTE - Supplies the PTE virtual address.
//
// Return Value:
//
//    FALSE if it is not a PTE address, TRUE if it is.
//
//--

#define MI_IS_USER_PTE_ADDRESS(PTE) \
    ((PTE >= (PMMPTE)PTE_UBASE) && (PTE <= (PMMPTE)PTE_UTOP))


//++
//BOOLEAN
//MI_IS_PAGE_DIRECTORY_ADDRESS (
//    IN PMMPTE PDE
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    page directory page (PDE) address.
//
// Arguments
//
//    PDE - Supplies the virtual address.
//
// Return Value:
//
//    FALSE if it is not a PDE address, TRUE if it is.
//
//--

#define MI_IS_PAGE_DIRECTORY_ADDRESS(PDE) \
    (((PDE >= (PMMPTE)PDE_UBASE) && (PDE <= (PMMPTE)PDE_UTOP)) || \
     ((PDE >= (PMMPTE)PDE_KBASE) && (PDE <= (PMMPTE)PDE_KTOP)) || \
     ((PDE >= (PMMPTE)PDE_SBASE) && (PDE <= (PMMPTE)PDE_STOP)))

//++
//BOOLEAN
//MI_IS_USER_PDE_ADDRESS (
//    IN PMMPTE PDE
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    user page directory page (PDE) address.
//
// Arguments
//
//    PDE - Supplies the PDE virtual address.
//
// Return Value:
//
//    FALSE if it is not a user PDE address, TRUE if it is.
//
//--

#define MI_IS_USER_PDE_ADDRESS(PDE) \
    ((PDE >= (PMMPTE)PDE_UBASE) && (PDE <= (PMMPTE)PDE_UTOP))


//++
//BOOLEAN
//MI_IS_KERNEL_PDE_ADDRESS (
//    IN PMMPTE PDE
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address is really a
//    kernel page directory page (PDE) address.
//
// Arguments
//
//    PDE - Supplies the PDE virtual address.
//
// Return Value:
//
//    FALSE if it is not a user PDE address, TRUE if it is.
//
//--

#define MI_IS_KERNEL_PDE_ADDRESS(PDE) \
    ((PDE >= (PMMPTE)PDE_KBASE) && (PDE <= (PMMPTE)PDE_KTOP))


//++
//BOOLEAN
//MI_IS_PROCESS_SPACE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address resides in
//    the per-process space.
//
// Arguments
//
//    VA - Supplies the virtual address.
//
// Return Value:
//
//    FALSE if it is not a per-process address, TRUE if it is.
//
//--

#define MI_IS_PROCESS_SPACE_ADDRESS(VA) (((ULONG_PTR)VA >> 61) == UREGION_INDEX)

//++
//BOOLEAN
//MI_IS_SYSTEM_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro determines if a given virtual address resides in
//    the system (global) space.
//
// Arguments
//
//    VA - Supplies the virtual address.
//
// Return Value:
//
//    FALSE if it is not a system (global) address, TRUE if it is.
//
//--

#define MI_IS_SYSTEM_ADDRESS(VA) (((ULONG_PTR)VA >> 61) == KREGION_INDEX)


//
//++
//PVOID
//KSEG0_ADDRESS (
//    IN PFN_NUMBER PAGE
//    );
//
// Routine Description:
//
//    This macro returns a KSEG0 virtual address which maps the page.
//
// Arguments:
//
//    PAGE - Supplies the physical page frame number.
//
// Return Value:
//
//    The KSEG0 virtual address.
//
//--

#define KSEG0_ADDRESS(PAGE) \
     (PVOID)(KSEG0_BASE | ((PAGE) <<  PAGE_SHIFT))


extern MMPTE ValidPpePte;

//++
//PMMPTE
//MiGetPpeAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPpeAddress returns the address of the page directory parent entry
//    which maps the given virtual address.  This is one level above the
//    page directory.
//
// Arguments
//
//    Va - Supplies the virtual address to locate the PPE for.
//
// Return Value:
//
//    The address of the PPE.
//
//--

__forceinline
PMMPTE
MiGetPpeAddress(
    IN PVOID Va
    )
{
    if ((((ULONG_PTR)(Va) & PTE_BASE) == PTE_BASE) &&
        ((((ULONG_PTR)(Va)) & ~(VRN_MASK|PTE_BASE)) < (ULONG_PTR)PDE_PER_PAGE * PTE_PER_PAGE * PAGE_SIZE)) {

        return (PMMPTE) (((ULONG_PTR)Va & VRN_MASK) |
                         (PDE_TBASE + PAGE_SIZE - sizeof(MMPTE)));
    }

    if (((((ULONG_PTR)(Va)) & PDE_BASE) == PDE_BASE) &&
        ((((ULONG_PTR)(Va)) & ~(VRN_MASK|PDE_BASE)) < PDE_PER_PAGE * PAGE_SIZE)) {

        return (PMMPTE) ((((ULONG_PTR)(Va)) & VRN_MASK) |
                         (PDE_TBASE + PAGE_SIZE - sizeof(MMPTE)));
    }

    if (((((ULONG_PTR)(Va)) & PDE_TBASE) == PDE_TBASE) &&
        ((((ULONG_PTR)(Va)) & ~(VRN_MASK|PDE_TBASE)) < PAGE_SIZE)) {

        return (PMMPTE) ((((ULONG_PTR)(Va)) & VRN_MASK) |
                         (PDE_TBASE + PAGE_SIZE - sizeof(MMPTE)));
    }

    return (PMMPTE) (((((ULONG_PTR)(Va)) & VRN_MASK)) |
              ((((((ULONG_PTR)(Va)) >> PDI1_SHIFT) << PTE_SHIFT) &
                (~(PDE_TBASE|VRN_MASK)) ) + PDE_TBASE));
}

//MiGetPdeAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPdeAddress returns the address of the PDE which maps the
//    given virtual address.
//
// Arguments:
//
//    Va - Supplies the virtual address to locate the PDE for.
//
// Return Value:
//
//    The address of the PDE.
//
//--

__forceinline
PMMPTE
MiGetPdeAddress(
    IN PVOID Va
    )
{
    if (((((ULONG_PTR)(Va)) & PDE_BASE) == PDE_BASE) &&
        ((((ULONG_PTR)(Va)) & ~(VRN_MASK|PDE_BASE)) < PDE_PER_PAGE * PAGE_SIZE)) {

        return (PMMPTE) ((((ULONG_PTR)(Va)) & VRN_MASK) |
                         (PDE_TBASE + PAGE_SIZE - sizeof(MMPTE)));
    }

    if (((((ULONG_PTR)(Va)) & PDE_TBASE) == PDE_TBASE) &&
        ((((ULONG_PTR)(Va)) & ~(VRN_MASK|PDE_TBASE)) < PAGE_SIZE)) {

        return (PMMPTE) ((((ULONG_PTR)(Va)) & VRN_MASK) |
                         (PDE_TBASE + PAGE_SIZE - sizeof(MMPTE)));
    }

    return (PMMPTE) (((((ULONG_PTR)(Va)) & VRN_MASK)) |
             ((((((ULONG_PTR)(Va)) >> PDI_SHIFT) << PTE_SHIFT) & (~(PDE_BASE|VRN_MASK))) + PDE_BASE));
}

//++
//PMMPTE
//MiGetPteAddress (
//    IN PVOID va
//    );
//
// Routine Description:
//
//    MiGetPteAddress returns the address of the PTE which maps the
//    given virtual address.
//
// Arguments:
//
//    Va - Supplies the virtual address to locate the PTE for.
//
// Return Value:
//
//    The address of the PTE.
//
//--

__forceinline
PMMPTE
MiGetPteAddress(
    IN PVOID Va
    )
{
    if (((((ULONG_PTR)(Va)) & PDE_TBASE) == PDE_TBASE) &&
        ((((ULONG_PTR)(Va)) & ~(VRN_MASK|PDE_TBASE)) < PAGE_SIZE)) {

        return (PMMPTE) ((((ULONG_PTR)(Va)) & VRN_MASK) |
                         (PDE_TBASE + PAGE_SIZE - sizeof(MMPTE)));
    }

    return (PMMPTE) (((((ULONG_PTR)(Va)) & VRN_MASK)) |
             ((((((ULONG_PTR)(Va)) >> PTI_SHIFT) << PTE_SHIFT) & (~(PTE_BASE|VRN_MASK))) + PTE_BASE));
}

#define MI_IS_PTE_PROTOTYPE(PointerPte)  (!MI_IS_USER_PTE_ADDRESS (PointerPte))

//++
//BOOLEAN
//MI_IS_SYSTEM_CACHE_ADDRESS (
//    IN PVOID VA
//    );
//
// Routine Description:
//
//    This macro takes a virtual address and determines if
//    it is a system cache address.
//
// Arguments
//
//    VA - Supplies a virtual address.
//
// Return Value:
//
//    TRUE if the address is in the system cache, FALSE if not.
//
//--

#define MI_IS_SYSTEM_CACHE_ADDRESS(VA)                      \
         (((PVOID)(VA) >= (PVOID)MmSystemCacheStart &&      \
		     (PVOID)(VA) <= (PVOID)MmSystemCacheEnd))


#if defined(_MIALT4K_)

//
// Define constants and macros for the alternate 4kb table.
//
// These are constants and defines that mimic the PAGE_SIZE constant but are
// hard coded to use 4K page values.
//

#define PAGE_4K         4096
#define PAGE_4K_SHIFT   12
#define PAGE_4K_MASK    (PAGE_4K - 1)
#define PAGE_4K_ALIGN(Va) ((PVOID)((ULONG_PTR)(Va) & ~(PAGE_4K - 1)))
#define ROUND_TO_4K_PAGES(Size)  (((ULONG_PTR)(Size) + PAGE_4K - 1) & ~(PAGE_4K - 1))

#define PAGE_NEXT_ALIGN(Va) ((PVOID)(PAGE_ALIGN((ULONG_PTR)Va + PAGE_SIZE - 1)))

#define BYTES_TO_4K_PAGES(Size)  ((ULONG)((ULONG_PTR)(Size) >> PAGE_4K_SHIFT) + \
                               (((ULONG)(Size) & (PAGE_4K - 1)) != 0))

//
// Relative constants between native pages and 4K pages.
//

#define SPLITS_PER_PAGE (PAGE_SIZE / PAGE_4K)
#define PAGE_SHIFT_DIFF (PAGE_SHIFT - PAGE_4K_SHIFT)

#define ALT_PTE_SHIFT 3

#define ALT_PROTECTION_MASK (MM_PTE_EXECUTE_MASK|MM_PTE_WRITE_MASK)

#define MiGetAltPteAddress(VA) \
      ((PMMPTE) ((ULONG_PTR)ALT4KB_PERMISSION_TABLE_START + \
                     ((((ULONG_PTR) (VA)) >> PAGE_4K_SHIFT) << ALT_PTE_SHIFT)))

//
// Alternate 4k table flags.
//

#define MI_ALTFLG_FLUSH2G         0x0000000000000001

//
// MiProtectFor4kPage flags.
//

#define ALT_ALLOCATE      1
#define ALT_COMMIT        2
#define ALT_CHANGE        4

//
// ATE (Alternate PTE) protection bits.
//

#define MM_ATE_COMMIT             0x0000000000000001
#define MM_ATE_ACCESS             0x0000000000000020

#define MM_ATE_READONLY           0x0000000000000200
#define MM_ATE_EXECUTE            0x0400000000000200
#define MM_ATE_EXECUTE_READ       0x0400000000000200
#define MM_ATE_READWRITE          0x0000000000000600
#define MM_ATE_WRITECOPY          0x0020000000000200
#define MM_ATE_EXECUTE_READWRITE  0x0400000000000600
#define MM_ATE_EXECUTE_WRITECOPY  0x0420000000000400

#define MM_ATE_ZEROFILL           0x0800000000000000
#define MM_ATE_NOACCESS           0x1000000000000000
#define MM_ATE_COPY_ON_WRITE      0x2000000000000000
#define MM_ATE_PRIVATE            0x8000000000000000
#define MM_ATE_PROTO_MASK         0x0000000000000621


NTSTATUS
MmX86Fault (
    IN ULONG_PTR FaultStatus,
    IN PVOID VirtualAddress,
    IN KPROCESSOR_MODE PreviousMode,
    IN PVOID TrapInformation
    );

VOID
MiSyncAltPte (
    IN PVOID VirtualAddress
    );

VOID
MiProtectImageFileFor4kPage (
    IN PVOID VirtualAddress,
    IN SIZE_T ViewSize
    );

VOID
MiProtectFor4kPage (
    IN PVOID Base,
    IN SIZE_T Size,
    IN ULONG NewProtect,
    IN ULONG Flags,
    IN PEPROCESS Process
    );

VOID
MiProtectMapFileFor4kPage (
    IN PVOID Base,
    IN SIZE_T Size,
    IN ULONG NewProtect,
    IN SIZE_T CommitSize,
    IN PMMPTE PointerPte,
    IN PMMPTE LastPte,
    IN PEPROCESS Process
    );

VOID
MiReleaseFor4kPage (
    IN PVOID StartVirtual,
    IN PVOID EndVirtual,
    IN PEPROCESS Process
    );

VOID
MiDecommitFor4kPage (
    IN PVOID StartVirtual,
    IN PVOID EndVirtual,
    IN PEPROCESS Process
    );

VOID
MiDeleteFor4kPage (
    IN PVOID StartVirtual,
    IN PVOID EndVirtual,
    IN PEPROCESS Process
    );

VOID
MiQueryRegionFor4kPage (
    IN PVOID BaseAddress,
    IN PVOID EndAddress,
    IN OUT PSIZE_T RegionSize,
    IN OUT PULONG RegionState,
    IN OUT PULONG RegionProtect,
    IN PEPROCESS Process
    );

ULONG
MiQueryProtectionFor4kPage (
    IN PVOID BaseAddress,
    IN PEPROCESS Process
    );

NTSTATUS
MiInitializeAlternateTable (
    IN PEPROCESS Process,
    IN PVOID HighestUserAddress
    );

VOID
MiDuplicateAlternateTable (
    PEPROCESS CurrentProcess,
    PEPROCESS ProcessToInitialize
    );

VOID
MiDeleteAlternateTable (
    PEPROCESS Process
    );

VOID
MiLockFor4kPage (
    PVOID CapturedBase,
    SIZE_T CapturedRegionSize,
    PEPROCESS Process
    );

NTSTATUS
MiUnlockFor4kPage (
    PVOID CapturedBase,
    SIZE_T CapturedRegionSize,
    PEPROCESS Process
    );

LOGICAL
MiShouldBeUnlockedFor4kPage (
    PVOID VirtualAddress,
    PEPROCESS Process
    );

ULONG
MiMakeProtectForNativePage (
    IN PVOID VirtualAddress,
    IN ULONG NewProtect,
    IN PEPROCESS Process
    );

LOGICAL
MiArePreceding4kPagesAllocated (
    IN PVOID VirtualAddress
    );

LOGICAL
MiAreFollowing4kPagesAllocated (
    IN PVOID VirtualAddress
    );

extern ULONG MmProtectToPteMaskForIA32[32];
extern ULONG MmProtectToPteMaskForSplit[32];
extern ULONGLONG MmProtectToAteMask[32];


#define MiMakeProtectionAteMask(NewProtect) MmProtectToAteMask[NewProtect]

#define LOCK_ALTERNATE_TABLE_UNSAFE(PWOW64) \
        ASSERT (KeAreAllApcsDisabled () == TRUE);                           \
        KeAcquireGuardedMutexUnsafe (&(PWOW64)->AlternateTableLock);        \

#define UNLOCK_ALTERNATE_TABLE_UNSAFE(PWOW64) \
        ASSERT (KeAreAllApcsDisabled () == TRUE);                           \
        KeReleaseGuardedMutexUnsafe (&(PWOW64)->AlternateTableLock);           \
        ASSERT (KeAreAllApcsDisabled () == TRUE);

#define LOCK_ALTERNATE_TABLE(PWOW64) \
        KeAcquireGuardedMutex (&(PWOW64)->AlternateTableLock)

#define UNLOCK_ALTERNATE_TABLE(PWOW64) \
        KeReleaseGuardedMutex (&(PWOW64)->AlternateTableLock)

#endif

//++
//VOID
//MI_BARRIER_SYNCHRONIZE (
//    IN ULONG TimeStamp
//    );
//
// Routine Description:
//
//    MI_BARRIER_SYNCHRONIZE compares the argument timestamp against the
//    current IPI barrier sequence stamp.  When equal, all processors will
//    issue memory barriers to ensure that newly created pages remain coherent.
//
//    When a page is put in the zeroed or free page list the current
//    barrier sequence stamp is read (interlocked - this is necessary
//    to get the correct value - memory barriers won't do the trick)
//    and stored in the pfn entry for the page. The current barrier
//    sequence stamp is maintained by the IPI send logic and is
//    incremented (interlocked) when the target set of an IPI send
//    includes all processors, but the one doing the send. When a page
//    is needed its sequence number is compared against the current
//    barrier sequence number.  If it is equal, then the contents of
//    the page may not be coherent on all processors, and an IPI must
//    be sent to all processors to ensure a memory barrier is
//    executed (generic call can be used for this). Sending the IPI
//    automatically updates the barrier sequence number. The compare
//    is for equality as this is the only value that requires the IPI
//    (i.e., the sequence number wraps, values in both directions are
//    older). When a page is removed in this fashion and either found
//    to be coherent or made coherent, it cannot be modified between
//    that time and writing the PTE. If the page is modified between
//    these times, then an IPI must be sent.
//
// Arguments
//
//    TimeStamp - Supplies the timestamp at the time when the page was zeroed.
//
// Return Value:
//
//    None.
//
//--

#define MI_BARRIER_SYNCHRONIZE(TimeStamp) NOTHING              

//++
//VOID
//MI_BARRIER_STAMP_ZEROED_PAGE (
//    IN PULONG PointerTimeStamp
//    );
//
// Routine Description:
//
//    MI_BARRIER_STAMP_ZEROED_PAGE issues an interlocked read to get the
//    current IPI barrier sequence stamp.  This is called AFTER a page is
//    zeroed.
//
// Arguments
//
//    PointerTimeStamp - Supplies a timestamp pointer to fill with the
//                       current IPI barrier sequence stamp.
//
// Return Value:
//
//    None.
//
//--

#define MI_BARRIER_STAMP_ZEROED_PAGE(PointerTimeStamp) NOTHING


//++
//VOID
//MI_FLUSH_SINGLE_SESSION_TB (
//    IN PVOID Virtual
//    );
//
// Routine Description:
//
//    MI_FLUSH_SINGLE_SESSION_TB flushes the requested single address
//    translation from the TB.
//
//    Since IA64 supports ASNs and session space doesn't have one, the entire
//    TB needs to be flushed.
//
// Arguments
//
//    Virtual - Supplies the virtual address to invalidate.
//
// Return Value:
//
//    None.
//
//--

#define MI_FLUSH_SINGLE_SESSION_TB(Virtual) \
    KeFlushEntireTb (TRUE, TRUE);


//++
//VOID
//MI_FLUSH_ENTIRE_SESSION_TB (
//    IN ULONG Invalid,
//    IN LOGICAL AllProcessors
//    );
//
// Routine Description:
//
//    MI_FLUSH_ENTIRE_SESSION_TB flushes the entire TB on IA64 since
//    the IA64 supports ASNs.
//
// Arguments
//
//    Invalid - TRUE if invalidating.
//
//    AllProcessors - TRUE if all processors need to be IPI'd.
//
// Return Value:
//
//    None.
//

#define MI_FLUSH_ENTIRE_SESSION_TB(Invalid, AllProcessors) \
    KeFlushEntireTb (Invalid, AllProcessors);

VOID
MiSweepCacheMachineDependent (
    IN PVOID VirtualAddress,
    IN SIZE_T Size,
    IN ULONG CacheAttribute
    );

extern LOGICAL MiMappingsInitialized;

extern BOOLEAN MiKseg0Mapping;
extern PVOID MiKseg0Start;
extern PVOID MiKseg0End;

VOID
MiEliminateDriverTrEntries (
    VOID
    );

LOGICAL
MiIsVirtualAddressMappedByTr (
    IN PVOID VirtualAddress
    );

//++
//LOGICAL
//MI_RESERVED_BITS_CANONICAL (
//    IN PVOID VirtualAddress
//    );
//
// Routine Description:
//
//    This routine checks whether all of the reserved bits are correct.
//
//    The processor implements at least 51 bits of VA (in addition to the 3
//    bits of VRN) - this is greater than the 43 bits of VA decode implemented
//    by memory management so the VA is checked against 43 bits to prevent
//    bogus address crashes which would not be caught by the processor.
//
// Arguments
//
//    VirtualAddress - Supplies the virtual address to check.
//
// Return Value:
//
//    TRUE if the address is ok, FALSE if not.
//

LOGICAL
__forceinline
MI_RESERVED_BITS_CANONICAL (
    IN PVOID VirtualAddress
    )
{
    LONG_PTR ReservedBits;
    ULONG_PTR ImplVirtualMsb;
    PMMPTE PointerPte;
    LOGICAL ReservedBitsOn;

    //
    // The address must be validated as NT-canonical.  Note this is different
    // than being processor-canonical (which must also be done as well).  Of
    // course if the NT validation is stricter then it is sufficient for both.
    // Note however, there are certain addresses used by memory management for
    // internal purposes (ie: McKinley page table VHPT space) which are never
    // made visible to any external components and are thus allowed to violate
    // the NT-canonical rule because it is not possible for anyone else to
    // use them and thus they cannot encode values into them.  (We don't want
    // anyone trying to encode unused bits because if we ever expand the
    // virtual address space, they will break).
    //
    // NT uses 43 bits of virtual address (not including VRN bits) and Merced
    // has 51 while McKinley has 61.  All valid Merced addresses can be
    // validated via the 43 bit NT checking.  However, McKinley VHPT addresses 
    // begin at 0x1FF8.0000.0000.0000, so they need to be checked separately.
    //

    ImplVirtualMsb = 43;
    ReservedBitsOn = FALSE;

    if ((ULONG_PTR)VirtualAddress & ((ULONG_PTR)1 << ImplVirtualMsb)) {

        //
        // All the reserved bits (not including the VRN) must also be set
        // unless this is a special memory management-internal address.
        //

        ReservedBits = (LONG_PTR) VirtualAddress | VRN_MASK;
        ReservedBits >>= (ImplVirtualMsb + 1);

        if (ReservedBits != (LONG_PTR)-1) {
            ReservedBitsOn = TRUE;
        }
    }
    else {

        //
        // All the reserved bits (not including the VRN) must also be clear
        // unless this is a special memory management-internal address.
        //

        ReservedBits = (LONG_PTR) VirtualAddress & ~VRN_MASK;
        ReservedBits >>= (ImplVirtualMsb + 1);

        if (ReservedBits != 0) {
            ReservedBitsOn = TRUE;
        }
    }

    //
    // Note region registers are initialized for all regions so the VRN bits
    // are stripped now for speed (ie: only the region 0 PTE ranges need to
    // be checked below).
    //

    VirtualAddress = (PVOID) ((LONG_PTR) VirtualAddress & ~VRN_MASK);

    if (ReservedBitsOn == FALSE) {

        //
        // No reserved bits were on, ensure that the virtual address is
        // okay by ensuring the PPE/PDE/PTE are within bounds.
        //

        PointerPte = MiGetPteAddress (VirtualAddress);
    }
    else {

        //
        // Some reserved bits are on.  This better be an internal address
        // (ie: the McKinley VHPT), otherwise it's a bogus address.
        //
        // Note the Merced VHPT is NT-canonical so the checks below are
        // no-ops on that processor, but this would be an error path on
        // Merced anyway so the slight overhead is not critical.
        //

        PointerPte = (PMMPTE) VirtualAddress;
    }

    //
    // Because the IA64 VHPT must cover the number of virtual address bits
    // implemented by the processor and it must be on a natural boundary, the
    // following window exists and must be explicitly checked for here.
    //
    // The initial Merced implementation supports 50 bits of virtual address.
    // Hence the VHPT must cover 50-PAGE_SHIFT+PTE_SHIFT == 40 bits.
    //
    // However, NT uses PPE_PER_PAGE+PDE_PER_PAGE+PTE_PER_PAGE+PTE_SHIFT ==
    // 33 bits.
    //
    // This seven bit difference between what the VHPT actually covers and
    // what NT actually handles is what must be explicitly checked.
    //
    // Depending on what the VirtualAddress really represents, the PTE below
    // may really be a PPE or PDE so check for all cases.
    //

    if ((PointerPte >= (PMMPTE)PTE_BASE) &&
        (PointerPte < (PMMPTE)(PTE_BASE + (ULONG_PTR)PDE_PER_PAGE * PTE_PER_PAGE * PAGE_SIZE))) {

        return TRUE;
    }

    if ((PointerPte >= (PMMPTE)PDE_BASE) &&
        (PointerPte < (PMMPTE)(PDE_BASE + PDE_PER_PAGE * PAGE_SIZE))) {

        return TRUE;
    }

    if ((PointerPte >= (PMMPTE)PDE_TBASE) &&
        (PointerPte < (PMMPTE)(PDE_TBASE + PAGE_SIZE))) {

        return TRUE;
    }

    return FALSE;
}

//++
//VOID
//MI_DISPLAY_TRAP_INFORMATION (
//    IN PVOID TrapInformation
//    );
//
// Routine Description:
//
//    Display any relevant trap information to aid debugging.
//
// Arguments
//
//    TrapInformation - Supplies a pointer to a trap frame.
//
// Return Value:
//
//    None.
//
#define MI_DISPLAY_TRAP_INFORMATION(TrapInformation)                    \
            KdPrint(("MM:***IIP %p, IIPA %p\n",                         \
                     ((PKTRAP_FRAME) (TrapInformation))->StIIP,         \
                     ((PKTRAP_FRAME) (TrapInformation))->StIIPA));
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ntsym\sources.inc ===
TARGETTYPE=NOTARGET
TARGETPATH=obj

INCLUDES=\
    ..;\
    $(DDK_INC_PATH)\wdm; \
    $(PROJECT_ROOT)\ntos\inc;\
    $(PROJECT_ROOT)\ntos\cache;\
    $(PROJECT_ROOT)\ntos\config;\
    $(PROJECT_ROOT)\ntos\io\pnpmgr;\
    $(PROJECT_ROOT)\ntos\pnp;\
    $(PROJECT_ROOT)\ntos\ke;\
    $(PROJECT_ROOT)\ntos\mm;\
    $(PROJECT_ROOT)\ntos\po;\
    $(PROJECT_ROOT)\ntos\rtl;\
    $(PROJECT_ROOT)\ntos\se;\
    $(PROJECT_ROOT)\ntos\verifier;\
    $(PROJECT_ROOT)\busdrv\pci;\
    $(PROJECT_ROOT)\busdrv\pci\$(O);\
    $(PROJECT_ROOT)\busdrv\isapnp;\
    $(PROJECT_ROOT)\busdrv\isapnp\$(O);\
    $(PROJECT_ROOT)\hals\inc; \
    $(DDK_INC_PATH);\
    $(HALKIT_INC_PATH); \
    $(DS_INC_PATH)

SOURCES=..\ntsym.c

SOURCES_USED=..\sources.inc
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ntsym\mp\makefile.inc ===
$(O)\ntkrnlmp.c : ..\ntsym.c    
    $(CXX_COMPILER_NAME) @<<$(CL_RSP) /E $** > $@
$(CXX_COMPILER_FLAGS: =
)
<<NOKEEP
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ntsym\pae\makefile.inc ===
$(O)\ntkrnlpa.c : ..\ntsym.c    
    $(CXX_COMPILER_NAME) @<<$(CL_RSP) /E $** > $@
$(CXX_COMPILER_FLAGS: =
)
<<NOKEEP
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ntsym\paemp\makefile.inc ===
$(O)\ntkrpamp.c : ..\ntsym.c    
    $(CXX_COMPILER_NAME) @<<$(CL_RSP) /E $** > $@
$(CXX_COMPILER_FLAGS: =
)
<<NOKEEP
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ntsym\ntsym.c ===
/*++

Copyright (c) 1999  Microsoft Corporation

Module Name:

    ntsym.c

--*/

#define _NTSYM_HARDWARE_PTE_SYMBOL_ 1

#include "ntos.h"
#include "mi.h"
#include "cmp.h"
#include "pnpi.h"
#include "arbiter.h"
#include "dockintf.h"
#include "pnprlist.h"
#include "pnpiop.h"
#include "pop.h"
#include "pci.h"
#include "pcip.h"
#include "range.h"
#include "busp.h"
#include "ntldr.h"
#include <nturtl.h>
#include <atom.h>
#include "cc.h"
#include "heap.h"
#include "heappriv.h"
#include "heappage.h"
#include "heappagi.h"
#include "stktrace.h"
#include "vfdeadlock.h"
#if defined( _WIN64 )
#include "wow64t.h"
#endif
// fixes redifinition error in seopaque.h
#define _SEOPAQUE_
#include "tokenp.h"
//
// Structures not defined in header files, but used by kdexts ???
//   ETIMER is defined in a .c file
//

typedef struct _ETIMER {
    KTIMER KeTimer;
    KAPC TimerApc;
    KDPC TimerDpc;
    LIST_ENTRY ActiveTimerListEntry;
    KSPIN_LOCK Lock;
    LONG Period;
    BOOLEAN ApcAssociated;
    BOOLEAN WakeTimer;
    LIST_ENTRY WakeTimerListEntry;
} ETIMER, *PETIMER;

typedef struct _POOL_BLOCK_HEAD {
    POOL_HEADER Header;
    LIST_ENTRY List;
} POOL_BLOCK_HEAD, *PPOOL_BLOCK_HEADER;

typedef struct _POOL_HACKER {
    POOL_HEADER Header;
    ULONG Contents[8];
} POOL_HACKER;

typedef struct _SEGMENT_OBJECT {
    PVOID BaseAddress;
    ULONG TotalNumberOfPtes;
    LARGE_INTEGER SizeOfSegment;
    ULONG NonExtendedPtes;
    ULONG ImageCommitment;
    PCONTROL_AREA ControlArea;
    PSUBSECTION Subsection;
    PLARGE_CONTROL_AREA LargeControlArea;
    MMSECTION_FLAGS *MmSectionFlags;
    MMSUBSECTION_FLAGS *MmSubSectionFlags;
} SEGMENT_OBJECT, *PSEGMENT_OBJECT;

typedef struct _SECTION_OBJECT {
    PVOID StartingVa;
    PVOID EndingVa;
    PVOID Parent;
    PVOID LeftChild;
    PVOID RightChild;
    PSEGMENT_OBJECT Segment;
} SECTION_OBJECT;


ACL                                 acl;
BUS_EXTENSION_LIST                  busExtensionList;
CALL_HASH_ENTRY                     callHash;
CALL_PERFORMANCE_DATA               callPerformance;
CM_CACHED_VALUE_INDEX               cellvalue;
CM_KEY_BODY                         KeyBody;
CM_KEY_CONTROL_BLOCK                KeyBlock;
CM_RESOURCE_LIST                    cmreslst;
CMHIVE                              cmhive;
CONTROL_AREA                        ctrlArea;
CONTEXT                             ctxt;
DEFERRED_WRITE                      defdWrt;
DEVICE_NODE                         devnode;
DEVICE_OBJECT                       devOvbj;
DEVICE_OBJECT_POWER_EXTENSION       devobjPow;
EJOB                                ejob;
EPROCESS                            eprocess;
ERESOURCE                           eresource;
ETIMER                              eTimerVar;
ETHREAD                             eThread;
EX_WORK_QUEUE                       exWorkQueue;
EXCEPTION_POINTERS                  expointer;
EXCEPTION_RECORD                    exrecord;
FILE_OBJECT                         fileObj;

HANDLE_TABLE_ENTRY                  handletableentry;
HARDWARE_PTE                        hwPTE;
HEAP                                heapstruct;
HEAP_ENTRY                          heapentry;
HEAP_FREE_ENTRY                     heapfreeentry;
HEAP_FREE_ENTRY_EXTRA               heapfreeentryextra;
HEAP_LOOKASIDE                      heaplookaside;
HEAP_PSEUDO_TAG_ENTRY               heappseudatagentry;
HEAP_SEGMENT                        heapsegment;
HEAP_STOP_ON_VALUES                 heapstoponvalues;
HEAP_TAG_ENTRY                      heaptagentry;
HEAP_VIRTUAL_ALLOC_ENTRY            heapvirtualallocentry;
HEAP_UCR_SEGMENT                    heapucrsegment;
HEAP_UNCOMMMTTED_RANGE              heapuncommitedrange;
HIVE_LIST_ENTRY                     hiveList;
HMAP_DIRECTORY                      h1;
HMAP_ENTRY                          h2;
HMAP_TABLE                          h3;

IMAGE_DEBUG_DIRECTORY               debugdir;
IMAGE_DOS_HEADER                    dosHdr;
IMAGE_NT_HEADERS                    nthdr;
IMAGE_OPTIONAL_HEADER               opthdr;
IMAGE_ROM_OPTIONAL_HEADER           romopthdr;
IMAGE_SECTION_HEADER                sectHdr;
IO_RESOURCE_REQUIREMENTS_LIST       ioreslst;
IRP                                 irpVar;
KINTERRUPT                          kinterupt;
KMUTANT                             kmutant;
KPCR                                Pcr;
KPRCB                               kprcb;
KLOCK_QUEUE_HANDLE                  klockhandle;
KMUTANT                             kmutant;
KUSER_SHARED_DATA                   kuser;
KWAIT_BLOCK                         KwaitBlock;
LARGE_CONTROL_AREA                  largectrlArea;
LDR_DATA_TABLE_ENTRY                LdrEntry;
LPCP_MESSAGE                        lpcpMsg;
LPCP_PORT_OBJECT                    Obj;

MI_VERIFIER_DRIVER_ENTRY            VerifierDriverEntry;
MI_VERIFIER_POOL_HEADER             VerfierHdr;
MM_DRIVER_VERIFIER_DATA             DrvVerifierData;
MM_PAGED_POOL_INFO                  PagedPoolInfo;
MM_SESSION_SPACE                    MmSessionSpaceVar;
MMPAGING_FILE                       PageFile;
MMPFN                               pfn;
MMPFNLIST                           pfnlist;
MMSECTION_FLAGS                     secflags;
MMSUBSECTION_FLAGS                  subsecflags;
MMVAD                               mm6;
MMVAD_SHORT                         mm7;
MMVAD_LONG                          mm8;

OBJECT_ATTRIBUTES                   Obja;
OBJECT_HEADER                       ObjHead;
OBJECT_HEADER_NAME_INFO             ObjName;
OBJECT_HEADER_CREATOR_INFO          ObjCreatr;
OBJECT_SYMBOLIC_LINK                SymbolicLinkObject;
PCI_ARBITER_INSTANCE                PciInstance;
PCI_PDO_EXTENSION                   PdoX;
#if defined( _WIN64 )
PEB32                               peb32Struct;
PEB64                               peb64Struct;
#endif
PEB                                 pebStruct;
PEB_LDR_DATA                        pebldrdata;


PHYSICAL_MEMORY_DESCRIPTOR          PhysMemDesc;
PHYSICAL_MEMORY_RUN                 PhysMemoryRun;
PI_BUS_EXTENSION                    busEx;
PI_RESOURCE_ARBITER_ENTRY           ArbiterEntry;
PNP_DEVICE_EVENT_ENTRY              PnpEntry;
PNP_DEVICE_EVENT_LIST               devEvent;
POOL_DESCRIPTOR                     PoolDesc;
POOL_BLOCK_HEAD                     poolblk;
POOL_HACKER                         poolH;
POOL_TRACKER_BIG_PAGES              poolBigPages;
POOL_TRACKER_TABLE                  poolt;
POP_ACTION_TRIGGER                  popactiontrigger;
POP_IDLE_HANDLER                    popidlehandler;
POP_POWER_ACTION                    popoweraction;
POP_THERMAL_ZONE                    popthermalzone;
POWER_STATE                         pState;
PROCESSOR_POWER_POLICY              processorPowerPolicy;
PS_IMPERSONATION_INFORMATION        psImpersonationInfo;
PS_JOB_TOKEN_FILTER                 psJobTokenFilter;

RTL_ATOM_TABLE                      rtlatomtable;
RTLP_RANGE_LIST_ENTRY               RtlRangeLst;
SECTION_OBJECT                      setnObj;
SECURITY_DESCRIPTOR                 securitydes;
SEGMENT_OBJECT                      segObj;
SHARED_CACHE_MAP                    sharedCache;
SUBSECTION                          subsecArea;
SYSTEM_POWER_CAPABILITIES           systempowercapabilities;
SYSTEM_POWER_POLICY                 syspopolicy;
#if  defined( _WIN64 )
TEB32                               teb32Struct;
TEB64                               teb64Struct;
#endif
TEB                                 tebStruct;
THERMAL_INFORMATION                 thermalinformation;
VI_DEADLOCK_GLOBALS                 viDeadlockGlobals;

TOKEN                               TokenVar;
// Make it build

int cdecl main() {
    return 0;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ntsym\up\makefile.inc ===
$(O)\ntoskrnl.c : ..\ntsym.c    
    $(CXX_COMPILER_NAME) @<<$(CL_RSP) /E $** > $@
$(CXX_COMPILER_FLAGS: =
)
<<NOKEEP
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obdevmap.c ===
/*++

Copyright (c) 1992  Microsoft Corporation

Module Name:

    obdevmap.c

Abstract:

    This module contains routines for creating and querying Device Map objects.
    Device Map objects define a DOS device name space, such as drive letters
    and peripheral devices (e.g. COM1)

Author:

    Steve Wood (stevewo) 01-Oct-1996

Revision History:

--*/

#include "obp.h"

//
// Global that activates/disables LUID device maps
//
extern ULONG ObpLUIDDeviceMapsEnabled;


NTSTATUS
ObSetDirectoryDeviceMap (
    OUT PDEVICE_MAP *ppDeviceMap OPTIONAL,
    IN HANDLE DirectoryHandle
    );

NTSTATUS
ObSetDeviceMap (
    IN PEPROCESS TargetProcess OPTIONAL,
    IN HANDLE DirectoryHandle
    );

NTSTATUS
ObQueryDeviceMapInformation (
    IN PEPROCESS TargetProcess OPTIONAL,
    OUT PPROCESS_DEVICEMAP_INFORMATION DeviceMapInformation,
    IN ULONG Flags
    );
    
VOID
ObInheritDeviceMap (
    IN PEPROCESS NewProcess,
    IN PEPROCESS ParentProcess OPTIONAL
    );

VOID
ObDereferenceDeviceMap (
    IN PEPROCESS Process
    );

ULONG
ObIsLUIDDeviceMapsEnabled (
    );

#ifdef OBP_PAGEDPOOL_NAMESPACE
#if defined(ALLOC_PRAGMA)
#pragma alloc_text(PAGE,ObSetDirectoryDeviceMap)
#pragma alloc_text(PAGE,ObSetDeviceMap)
#pragma alloc_text(PAGE,ObQueryDeviceMapInformation)
#pragma alloc_text(PAGE,ObInheritDeviceMap)
#pragma alloc_text(PAGE,ObDereferenceDeviceMap)
#pragma alloc_text(PAGE,ObIsLUIDDeviceMapsEnabled)
#endif
#endif // OBP_PAGEDPOOL_NAMESPACE


NTSTATUS
ObSetDirectoryDeviceMap (
    OUT PDEVICE_MAP *ppDeviceMap OPTIONAL,
    IN HANDLE DirectoryHandle
    )

/*++

Routine Description:

    This function sets the device map for the specified object directory.
    A device map is a structure associated with an object directory and
    a Logon ID (LUID).  When the object manager sees a references to a
    name beginning with \??\ or just \??, then it requests the device
    map of the LUID from the kernel reference monitor, which keeps track
    of LUIDs.  This allows multiple virtual \??  object directories on
    a per LUID basis.  The WindowStation logic will use this
    functionality to allocate devices unique to each WindowStation.

    SeGetLogonIdDeviceMap() use this function to create the device map
    structure associated with the directory object for the LUID device
    map.  So, this function should only be called from kernel mode.

Arguments:

    ppDeviceMap - returns a pointer to the device map structure

    DirectoryHandle - Specifies the object directory to associate with the
        device map.


Return Value:

    Returns one of the following status codes:

        STATUS_SUCCESS - normal, successful completion.

        STATUS_SHARING_VIOLATION - The specified object directory is already
            associated with a device map.

        STATUS_INSUFFICIENT_RESOURCES - Unable to allocate pool for the device
            map data structure;

        STATUS_ACCESS_DENIED - Caller did not have DIRECTORY_TRAVERSE access
            to the specified object directory.

--*/

{
    NTSTATUS Status;
    POBJECT_DIRECTORY DosDevicesDirectory;
    PDEVICE_MAP DeviceMap, FreeDeviceMap;
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;

    PAGED_CODE();

    //
    //  Reference the object directory handle and see if it is already
    //  associated with a device map structure.  If so, fail this call.
    //

    Status = ObReferenceObjectByHandle( DirectoryHandle,
                                        DIRECTORY_TRAVERSE,
                                        ObpDirectoryObjectType,
                                        KernelMode,
                                        &DosDevicesDirectory,
                                        NULL );

    if (!NT_SUCCESS( Status )) {

        return( Status );
    }

    FreeDeviceMap = NULL;

    DeviceMap = ExAllocatePoolWithTag( OB_NAMESPACE_POOL_TYPE, sizeof( *DeviceMap ), 'mDbO' );

    if (DeviceMap == NULL) {

        ObDereferenceObject( DosDevicesDirectory );
        Status = STATUS_INSUFFICIENT_RESOURCES;
        return( Status );

    }

    RtlZeroMemory( DeviceMap, sizeof( *DeviceMap ) );

    DeviceMap->ReferenceCount = 1;
    DeviceMap->DosDevicesDirectory = DosDevicesDirectory;

    //
    //  Capture the device map
    //
    
    ObpLockDeviceMap();

    if (DosDevicesDirectory->DeviceMap != NULL) {
        FreeDeviceMap = DeviceMap;
        DeviceMap = DosDevicesDirectory->DeviceMap;
        DeviceMap->ReferenceCount++;
    } else {
        DosDevicesDirectory->DeviceMap = DeviceMap;
    }

    if (DosDevicesDirectory != ObSystemDeviceMap->DosDevicesDirectory) {
        DeviceMap->GlobalDosDevicesDirectory = ObSystemDeviceMap->DosDevicesDirectory;
    }

    ObpUnlockDeviceMap();

    //
    // pass back a pointer to the device map
    //
    if (ppDeviceMap != NULL) {
        *ppDeviceMap = DeviceMap;
    }

    //
    // Make the object permanent until the devmap is removed. This keeps the name in the tree
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( DosDevicesDirectory );
    NameInfo = ObpReferenceNameInfo( ObjectHeader );

    //
    // Other bits are set in this flags field by the handle database code. Synchronize with that.
    //
    
    ObpLockObject( ObjectHeader );

    if (NameInfo != NULL && NameInfo->Directory != NULL) {
        ObjectHeader->Flags |= OB_FLAG_PERMANENT_OBJECT;
    }

    ObpUnlockObject( ObjectHeader );

    ObpDereferenceNameInfo(NameInfo);

    //
    // If the directory already had a devmap and so was already referenced.
    // Drop ours and free the unused block.
    //
    if (FreeDeviceMap != NULL) {
        ObDereferenceObject (DosDevicesDirectory);
        ExFreePool (FreeDeviceMap);
    }
    return( Status );
}


NTSTATUS
ObSetDeviceMap (
    IN PEPROCESS TargetProcess OPTIONAL,
    IN HANDLE DirectoryHandle
    )

/*++

Routine Description:

    This function sets the device map for the specified process, using
    the specified object directory.  A device map is a structure
    associated with an object directory and a process.  When the object
    manager sees a references to a name beginning with \??\ or just \??,
    then it follows the device map object in the calling process's
    EPROCESS structure to get to the object directory to use for that
    reference.  This allows multiple virtual \??  object directories on
    a per process basis.  The WindowStation logic will use this
    functionality to allocate devices unique to each WindowStation.

Arguments:

    TargetProcess - Specifies the target process to associate the device map
        with.  If null then the current process is used and the directory
        becomes the system default dos device map.

    DirectoryHandle - Specifies the object directory to associate with the
        device map.


Return Value:

    Returns one of the following status codes:

        STATUS_SUCCESS - normal, successful completion.

        STATUS_SHARING_VIOLATION - The specified object directory is already
            associated with a device map.

        STATUS_INSUFFICIENT_RESOURCES - Unable to allocate pool for the device
            map data structure;

        STATUS_ACCESS_DENIED - Caller did not have DIRECTORY_TRAVERSE access
            to the specified object directory.

--*/

{
    NTSTATUS Status;
    POBJECT_DIRECTORY DosDevicesDirectory;
    PDEVICE_MAP DeviceMap, FreeDeviceMap, DerefDeviceMap;
    PEPROCESS Target = TargetProcess;
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;

    BOOLEAN PreserveName = FALSE;

    PAGED_CODE();

    //
    //  Reference the object directory handle and see if it is already
    //  associated with a device map structure.  If so, fail this call.
    //

    Status = ObReferenceObjectByHandle( DirectoryHandle,
                                        DIRECTORY_TRAVERSE,
                                        ObpDirectoryObjectType,
                                        KeGetPreviousMode(),
                                        &DosDevicesDirectory,
                                        NULL );

    if (!NT_SUCCESS( Status )) {

        return( Status );
    }

    FreeDeviceMap = NULL;

    DeviceMap = ExAllocatePoolWithTag( OB_NAMESPACE_POOL_TYPE, sizeof( *DeviceMap ), 'mDbO' );

    if (DeviceMap == NULL) {

        ObDereferenceObject( DosDevicesDirectory );
        Status = STATUS_INSUFFICIENT_RESOURCES;
        return( Status );

    }

    RtlZeroMemory( DeviceMap, sizeof( *DeviceMap ) );

    DeviceMap->ReferenceCount = 1;
    DeviceMap->DosDevicesDirectory = DosDevicesDirectory;

    //
    //  Capture the device map
    //

    ObpLockDeviceMap();

    if (DosDevicesDirectory->DeviceMap != NULL) {
        FreeDeviceMap = DeviceMap;
        DeviceMap = DosDevicesDirectory->DeviceMap;
        DeviceMap->ReferenceCount++;
    } else {
        DosDevicesDirectory->DeviceMap = DeviceMap;
    }


    if (Target == NULL) {

        Target = PsGetCurrentProcess();

        ObSystemDeviceMap = DeviceMap;

    }

    if (DosDevicesDirectory != ObSystemDeviceMap->DosDevicesDirectory) {
        DeviceMap->GlobalDosDevicesDirectory = ObSystemDeviceMap->DosDevicesDirectory;
        PreserveName = TRUE;
    }

    DerefDeviceMap = Target->DeviceMap;

    Target->DeviceMap = DeviceMap;

    ObpUnlockDeviceMap();

    if (PreserveName == TRUE) {
        //
        // Make the object permanent until the devmap is removed. This keeps the name in the tree
        //
        ObjectHeader = OBJECT_TO_OBJECT_HEADER( DosDevicesDirectory );
        NameInfo = ObpReferenceNameInfo( ObjectHeader );


        //
        // Other bits are set in this flags field by the handle database code. Synchronise with that.
        //
        ObpLockObject( ObjectHeader );

        if (NameInfo != NULL && NameInfo->Directory != NULL) {
            ObjectHeader->Flags |= OB_FLAG_PERMANENT_OBJECT;
        }

        ObpUnlockObject( ObjectHeader );

        ObpDereferenceNameInfo( NameInfo );
    }
    //
    // If the directory already had a devmap and so was already referenced.
    // Drop ours and free the unused bock.
    //
    if (FreeDeviceMap != NULL) {
        ObDereferenceObject (DosDevicesDirectory);
        ExFreePool (FreeDeviceMap);
    }
    //
    // If the target already had a device map then deref it now
    //
    if (DerefDeviceMap != NULL) {
        ObfDereferenceDeviceMap (DerefDeviceMap);
    }
    return( Status );
}


NTSTATUS
ObQueryDeviceMapInformation (
    IN PEPROCESS TargetProcess OPTIONAL,
    OUT PPROCESS_DEVICEMAP_INFORMATION DeviceMapInformation,
    IN ULONG Flags
    )

/*++

Routine Description:

    This function queries information from the device map associated with the
    specified process.  The returned information contains a bit map indicating
    which drive letters are defined in the associated object directory, along
    with an array of drive types that give the type of each drive letter.

Arguments:

    TargetProcess - Specifies the target process to retreive the device map
        from.  If not specified then we return the global default device map

    DeviceMapInformation - Specifies the location where to store the results.

    Flags - Specifies the query type

Return Value:

    Returns one of the following status codes:

        STATUS_SUCCESS - normal, successful completion.

        STATUS_END_OF_FILE - The specified process was not associated with
            a device map.

        STATUS_ACCESS_VIOLATION - The DeviceMapInformation buffer pointer
            value specified an invalid address.

        STATUS_INVALID_PARAMETER - if LUID device maps are enabled,
            specified process is not the current process
--*/

{
    NTSTATUS Status;
    PDEVICE_MAP DeviceMap = NULL;
    PROCESS_DEVICEMAP_INFORMATION LocalMapInformation;
    ULONG Mask;
    LOGICAL SearchShadow;
    BOOLEAN UsedLUIDDeviceMap = FALSE;

    if (Flags & ~(PROCESS_LUID_DOSDEVICES_ONLY)) {
        return STATUS_INVALID_PARAMETER;
    }

    SearchShadow = !(Flags & PROCESS_LUID_DOSDEVICES_ONLY);

    //
    // if LUID device maps are enabled,
    // Verify that the process is the current process or
    // no process was specified
    //

    if (ObpLUIDDeviceMapsEnabled != 0) {
        if (ARGUMENT_PRESENT( TargetProcess ) &&
           (PsGetCurrentProcess() != TargetProcess)) {
            return STATUS_INVALID_PARAMETER;
        }

        //
        // Get the caller's LUID device map
        //

        DeviceMap = ObpReferenceDeviceMap();
    }

    //
    //  First, while using a spinlock to protect the device map from
    //  going away we will make local copy of the information.
    //

    ObpLockDeviceMap();
    
    if (DeviceMap == NULL) {
        //
        //  Check if the caller gave us a target process and if not then use
        //  the globally defined one
        //

        if (ARGUMENT_PRESENT( TargetProcess )) {

            DeviceMap = TargetProcess->DeviceMap;

        } else {

            DeviceMap = ObSystemDeviceMap;
        }
    } else {
        UsedLUIDDeviceMap = TRUE;
    }

    //
    //  If we do not have a device map then we'll return an error otherwise
    //  we simply copy over the device map structure (bitmap and drive type
    //  array) into the output buffer
    //

    if (DeviceMap == NULL) {

        ObpUnlockDeviceMap();

        Status = STATUS_END_OF_FILE;

    } else {
        ULONG i;
        PDEVICE_MAP ShadowDeviceMap;

        Status = STATUS_SUCCESS;


        ShadowDeviceMap = DeviceMap;
        if (DeviceMap->GlobalDosDevicesDirectory != NULL &&
            DeviceMap->GlobalDosDevicesDirectory->DeviceMap != NULL) {
            ShadowDeviceMap = DeviceMap->GlobalDosDevicesDirectory->DeviceMap;
        }

        LocalMapInformation.Query.DriveMap = DeviceMap->DriveMap;

        for (i = 0, Mask = 1;
             i < sizeof (LocalMapInformation.Query.DriveType) /
                 sizeof (LocalMapInformation.Query.DriveType[0]);
             i++, Mask <<= 1) {
            LocalMapInformation.Query.DriveType[i] = DeviceMap->DriveType[i];
            if ( (Mask & DeviceMap->DriveMap) == 0 &&
                 SearchShadow &&
                 ( ( ObpLUIDDeviceMapsEnabled != 0   // check if LUID Device
                                                     // maps are enabled
                   ) ||
                   ( ShadowDeviceMap->DriveType[i] != DOSDEVICE_DRIVE_REMOTE &&
                     ShadowDeviceMap->DriveType[i] != DOSDEVICE_DRIVE_CALCULATE
                   ) ) ) {
                LocalMapInformation.Query.DriveType[i] = ShadowDeviceMap->DriveType[i];
                LocalMapInformation.Query.DriveMap |= ShadowDeviceMap->DriveMap & Mask;
            }
        }

        ObpUnlockDeviceMap();

        //
        // If the LUID device map was used,
        // then dereference the LUID device map
        //
        if (UsedLUIDDeviceMap == TRUE) {
            ObfDereferenceDeviceMap(DeviceMap);
        }

        //
        //  Now we can copy the information to the caller buffer using
        //  a try-except to guard against the output buffer changing.
        //  Note that the caller must have already probed the buffer
        //  for write.
        //

        try {

            RtlCopyMemory( &DeviceMapInformation->Query,
                           &LocalMapInformation.Query,
                           sizeof( DeviceMapInformation->Query ));

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            Status = GetExceptionCode();
        }

    }

    return Status;
}


VOID
ObInheritDeviceMap (
    IN PEPROCESS NewProcess,
    IN PEPROCESS ParentProcess OPTIONAL
    )

/*++

Routine Description:

    This function is called at process initialization time to inherit the
    device map for a process.  If no parent process, then inherits from
    the system device map.

Arguments:

    NewProcess - Supplies the process being initialized that needs a new
        dos device map

    ParentProcess - - Optionally specifies the parent process whose device
        map we inherit.  This process if specified must have a device map

Return Value:

    None.

--*/

{
    PDEVICE_MAP DeviceMap;

    //
    //  If we are called with a parent process then grab its device map
    //  otherwise grab the system wide device map and check that is does
    //  exist
    //

    ObpLockDeviceMap();

    if (ParentProcess) {

        DeviceMap = ParentProcess->DeviceMap;

    } else {

        //
        //  Note: WindowStation guys may want a callout here to get the
        //  device map to use for this case.
        //

        DeviceMap = ObSystemDeviceMap;

    }

    if (DeviceMap != NULL) {
        //
        //  With the device map bumps its reference count and add it to the
        //  new process
        //
        DeviceMap->ReferenceCount++;
        NewProcess->DeviceMap = DeviceMap;

    }
    ObpUnlockDeviceMap();

    return;
}


VOID
ObDereferenceDeviceMap (
    IN PEPROCESS Process
    )

/*++

Routine Description:

    This function is called at process tear down time to decrement the
    reference count on a device map.  When the reference count goes to
    zero, it means no more processes are using this, so it can be freed
    and the reference on the associated object directory can be released.

Arguments:

    Process - Process being destroyed.

Return Value:

    None.

--*/

{
    PDEVICE_MAP DeviceMap;

    //
    //  Grab the device map and then we only have work to do
    //  it there is one
    //

    ObpLockDeviceMap();

    DeviceMap = Process->DeviceMap;
    Process->DeviceMap = NULL;

    ObpUnlockDeviceMap();

    if (DeviceMap != NULL) {

        //
        //  To dereference the device map we need to null out the
        //  processes device map pointer, and decrement its ref count
        //  If the ref count goes to zero we can free up the memory
        //  and dereference the dos device directory object
        //


        ObfDereferenceDeviceMap(DeviceMap);

    }

    //
    //  And return to our caller
    //

    return;
}


ULONG
ObIsLUIDDeviceMapsEnabled (
    )

/*++

Routine Description:

    This function is checks if LUID DosDevices are enabled.

Arguments:

    None.

Return Value:

    0 - LUID DosDevices are disabled.
    1 - LUID DosDevices are enabled.

--*/

{
    return( ObpLUIDDeviceMapsEnabled );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\fastref.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    rundown.c

Abstract:

    This module houses routines that do fast referencing of object manager
    objects. This is just a thin layer around the fast ref package in EX.
    The EX routines are all inline so their description is here.

    The basic principle of these routines is to allow fast referencing of
    objects held in pointers protected by locks. This is done by assuming
    the pointer to an object is aligned on a 8 byte boundary and using the
    bottom 3 bits of the pointer as a fast referencing mechanism. The
    assumption of this algorithm is that the pointer changes far less
    frequently than it is referenced.

    Given the following bit definition of a
    pointer:

    +-----------+---+
    |    p      | n |
    +-----------+---+

    p << 3 : Object pointer. Bottom three bits are zero. p may be null in
             which case n must be zero
    n : Total number of pre-references unused

    For a non-null p the total number of references on the target object
    associated with this structure is >= 1 + 7 - n. There is an associated
    reference for the pointer itself and one for each of the possible
    extra references.

    Fast references proceed to perform one of the following transformation:

    +-----------+---+    +-----------+-----+
    |    p      | n | => |    p      | n-1 | n > 0, p != NULL
    +-----------+---+    +-----------+-----+

    +-----------+---+    +-----------+---+
    |   NULL    | 0 | => |   NULL    | 0 | NULL pointers are never fast refed
    +-----------+---+    +-----------+---+ and never have cached references

    Slow references do the following transformation:

    +-----------+---+    +-----------+-----+
    |    p      | 0 | => |    p      |  7  | An addition 8 references are
    +-----------+---+    +-----------+-----+ added to the object

    The second transformation is either done under a lock or done by the
    thread that does the transition with n = 1 => n = 0.

    The reference obtained by this fast algorithm may be released by
    dereferencing the target object directly or by attempting to return the
    reference to the pointer. Returning the reference to the pointer has
    the following transformations:

    +-----------+---+    +-----------+-----+
    |    p      | n | => |    p      | n+1 | n < 7, p != NULL
    +-----------+---+    +-----------+-----+

    +-----------+---+    +-----------+-----+
    |    p      | 7 | => |    p      |  0  | Dereference the object directly
    +-----------+---+    +-----------+-----+

    +-----------+---+    +-----------+-----+ Dereference the object directly
    |    q      | n | => |    q      |  n  | as the pointer p has been
    +-----------+---+    +-----------+-----+ replaced by q. q May be NULL


Author:

    Neill Clift (NeillC) 29-Jul-2000


Revision History:

--*/

#include "obp.h"

#pragma hdrstop

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,ObInitializeFastReference)
#pragma alloc_text(PAGE,ObFastReferenceObject)
#pragma alloc_text(PAGE,ObFastReferenceObjectLocked)
#pragma alloc_text(PAGE,ObFastDereferenceObject)
#pragma alloc_text(PAGE,ObFastReplaceObject)
#endif

NTKERNELAPI
VOID
FASTCALL
ObInitializeFastReference (
    IN PEX_FAST_REF FastRef,
    IN PVOID Object
    )
/*++

Routine Description:

    Initialize a fast reference structure.

Arguments:

    FastRef - Rundown block to be initialized

Return Value:

    None

--*/
{
    //
    // If an object was given then bias the object reference by the cache size.
    //
    if (Object != NULL) {
        ObReferenceObjectEx (Object, ExFastRefGetAdditionalReferenceCount ());
    }
    ExFastRefInitialize (FastRef, Object);
}

NTKERNELAPI
PVOID
FASTCALL
ObFastReferenceObject (
    IN PEX_FAST_REF FastRef
    )
/*++

Routine Description:

    This routine attempts a fast reference of an object in a fast ref
    structure.

Arguments:

    FastRef - Rundown block to be used for the reference

Return Value:

    PVOID - Object that was referenced or NULL if we failed

--*/
{
    EX_FAST_REF OldRef;
    PVOID Object;
    ULONG RefsToAdd, Unused;
    //
    // Attempt the fast reference
    //
    OldRef = ExFastReference (FastRef);

    Object = ExFastRefGetObject (OldRef);
    //
    // We fail if there wasn't an object or if it has no cached references
    // left. Both of these cases had the cached reference count zero.
    //
    Unused = ExFastRefGetUnusedReferences (OldRef);

    if (Unused <= 1) {
        if (Unused == 0) {
            return NULL;
        }
        //
        // If we took the counter to zero then attempt to make life easier for
        // the next referencer by resetting the counter to its max. Since we now
        // have a reference to the object we can do this.
        //
        RefsToAdd = ExFastRefGetAdditionalReferenceCount ();
        ObReferenceObjectEx (Object, RefsToAdd);

        //
        // Try to add the added references to the cache. If we fail then just
        // release them.
        //
        if (!ExFastRefAddAdditionalReferenceCounts (FastRef, Object, RefsToAdd)) {
            ObDereferenceObjectEx (Object, RefsToAdd);
        }
    }
    return Object;
}

NTKERNELAPI
PVOID
FASTCALL
ObFastReferenceObjectLocked (
    IN PEX_FAST_REF FastRef
    )
/*++

Routine Description:

    This routine does a slow object reference. This must be called while
    holding a lock.

Arguments:

    FastRef - Rundown block to be used to reference the object

Return Value:

    PVOID - Object that was referenced or NULL if there was no object.

--*/
{
    PVOID Object;
    EX_FAST_REF OldRef;

    OldRef = *FastRef;
    Object = ExFastRefGetObject (OldRef);
    if (Object != NULL) {
        ObReferenceObject (Object);
    }
    return Object;
}

NTKERNELAPI
VOID
FASTCALL
ObFastDereferenceObject (
    IN PEX_FAST_REF FastRef,
    IN PVOID Object
    )
/*++

Routine Description:

    This routine does a fast dereference if possible.

Arguments:

    FastRef - Rundown block to be used to dereference the object

Return Value:

    None.

--*/
{
    if (!ExFastRefDereference (FastRef, Object)) {
        //
        // If the object changed or there is no space left in the reference
        // cache then just deref the object.
        //
        ObDereferenceObject (Object);
    }
}

NTKERNELAPI
PVOID
FASTCALL
ObFastReplaceObject (
    IN PEX_FAST_REF FastRef,
    IN PVOID Object
    )
/*++

Routine Description:

    This routine does a swap of the object. This must be called while holding
    a lock.

Arguments:

    FastRef - Rundown block to be used to do the swap.

Return Value:

    PVOID - Object that was in the block before the swap..

--*/
{
    EX_FAST_REF OldRef;
    PVOID OldObject;
    ULONG RefsToReturn;

    //
    // If we have been given an object then bias it by the correct amount.
    //
    if (Object != NULL) {
        ObReferenceObjectEx (Object, ExFastRefGetAdditionalReferenceCount ());
    }
    //
    // Do the swap
    //
    OldRef = ExFastRefSwapObject (FastRef, Object);
    OldObject = ExFastRefGetObject (OldRef);
    //
    // If there was an original object then we need to work out how many
    // cached references there were (if any) and return them.
    //
    if (OldObject != NULL) {
        RefsToReturn = ExFastRefGetUnusedReferences (OldRef);
        if (RefsToReturn > 0) {
            ObDereferenceObjectEx (OldObject, RefsToReturn);
        }
    }
    return OldObject;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obhandle.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obhandle.c

Abstract:

    Object handle routines

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"

//
//  Define logical sum of all generic accesses.
//

#define GENERIC_ACCESS (GENERIC_READ | GENERIC_WRITE | GENERIC_EXECUTE | GENERIC_ALL)

//
//  Define the mask for the trace index. The last bit is used for
//  OBJ_PROTECT_CLOSE bit
//

#define OBP_CREATOR_BACKTRACE_LIMIT      0x7fff
#define OBP_CREATOR_BACKTRACE_INDEX_MASK OBP_CREATOR_BACKTRACE_LIMIT

//
// Define local prototypes
//

NTSTATUS
ObpIncrementHandleDataBase (
    IN POBJECT_HEADER ObjectHeader,
    IN PEPROCESS Process,
    OUT PULONG NewProcessHandleCount
    );

NTSTATUS
ObpCaptureHandleInformation (
    IN OUT PSYSTEM_HANDLE_TABLE_ENTRY_INFO *HandleEntryInfo,
    IN HANDLE UniqueProcessId,
    IN PVOID HandleTableEntry,
    IN HANDLE HandleIndex,
    IN ULONG Length,
    IN OUT PULONG RequiredLength
    );

NTSTATUS
ObpCaptureHandleInformationEx (
    IN OUT PSYSTEM_HANDLE_TABLE_ENTRY_INFO_EX *HandleEntryInfo,
    IN HANDLE UniqueProcessId,
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE HandleIndex,
    IN ULONG Length,
    IN OUT PULONG RequiredLength
    );

USHORT
ObpComputeGrantedAccessIndex (
    ACCESS_MASK GrantedAccess
    );

ACCESS_MASK
ObpTranslateGrantedAccessIndex (
    USHORT GrantedAccessIndex
    );

USHORT
RtlLogUmodeStackBackTrace(
    VOID
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,NtDuplicateObject)
#pragma alloc_text(PAGE,ObGetHandleInformation)
#pragma alloc_text(PAGE,ObGetHandleInformationEx)
#pragma alloc_text(PAGE,ObpCaptureHandleInformation)
#pragma alloc_text(PAGE,ObpCaptureHandleInformationEx)
#pragma alloc_text(PAGE,ObpIncrementHandleDataBase)
#pragma alloc_text(PAGE,ObpInsertHandleCount)
#pragma alloc_text(PAGE,ObpIncrementHandleCount)
#pragma alloc_text(PAGE,ObpIncrementUnnamedHandleCount)
#pragma alloc_text(PAGE,ObpChargeQuotaForObject)
#pragma alloc_text(PAGE,ObpDecrementHandleCount)
#pragma alloc_text(PAGE,ObpCreateHandle)
#pragma alloc_text(PAGE,ObpCreateUnnamedHandle)
#pragma alloc_text(PAGE,ObpValidateDesiredAccess)
#pragma alloc_text(PAGE,ObDuplicateObject)
#pragma alloc_text(PAGE,ObReferenceProcessHandleTable)
#pragma alloc_text(PAGE,ObDereferenceProcessHandleTable)
#pragma alloc_text(PAGE,ObpComputeGrantedAccessIndex)
#pragma alloc_text(PAGE,ObpTranslateGrantedAccessIndex)
#pragma alloc_text(PAGE,ObGetProcessHandleCount)
#endif



PHANDLE_TABLE
ObReferenceProcessHandleTable (
    PEPROCESS SourceProcess
    )

/*++

Routine Description:

    This function allows safe cross process handle table references. Table deletion
    at process exit waits for all outstanding references to finish. Once the table
    is marked deleted further references are denied byt this funtion.

Arguments:

    SourceProcesss - Process whose handle table is to be referenced

Return Value:

    Referenced handle table or NULL if the processes handle table has been or is in the
    process of being deleted.

--*/

{

    PHANDLE_TABLE ObjectTable;

    ObjectTable = NULL;

    if (ExAcquireRundownProtection (&SourceProcess->RundownProtect)) {

        ObjectTable = SourceProcess->ObjectTable;

        if (ObjectTable == NULL) {

            ExReleaseRundownProtection (&SourceProcess->RundownProtect);
        }
    }

    return ObjectTable;
}

VOID
ObDereferenceProcessHandleTable (
    PEPROCESS SourceProcess
    )
/*++

Routine Description:

    This function removes the outstanding reference obtained via ObReferenceProcessHandleTable.

Arguments:

    ObjectTable - Handle table to dereference

Return Value:

    None.

--*/
{
    ExReleaseRundownProtection (&SourceProcess->RundownProtect);
}

ULONG
ObGetProcessHandleCount (
    PEPROCESS Process
    )
/*++

Routine Description:

    This function returns the total number of open handles for a process.

Arguments:

    Process - Process whose handle table is to be queried.

Return Value:

    Count of open handles.

--*/
{
    PHANDLE_TABLE HandleTable;
    ULONG HandleCount;

    HandleTable = ObReferenceProcessHandleTable (Process);

    if ( HandleTable ) {
        HandleCount = HandleTable->HandleCount;

        ObDereferenceProcessHandleTable (Process);

    } else {
        HandleCount = 0;
    }

    return HandleCount;
}

NTSTATUS
ObDuplicateObject (
    IN PEPROCESS SourceProcess,
    IN HANDLE SourceHandle,
    IN PEPROCESS TargetProcess OPTIONAL,
    OUT PHANDLE TargetHandle OPTIONAL,
    IN ACCESS_MASK DesiredAccess,
    IN ULONG HandleAttributes,
    IN ULONG Options,
    IN KPROCESSOR_MODE PreviousMode
    )
/*++

Routine Description:

    This function creates a handle that is a duplicate of the specified
    source handle.  The source handle is evaluated in the context of the
    specified source process.  The calling process must have
    PROCESS_DUP_HANDLE access to the source process.  The duplicate
    handle is created with the specified attributes and desired access.
    The duplicate handle is created in the handle table of the specified
    target process.  The calling process must have PROCESS_DUP_HANDLE
    access to the target process.

Arguments:

    SourceProcess - Supplies a pointer to the source process for the
        handle being duplicated

    SourceHandle - Supplies the handle being duplicated

    TargetProcess - Optionally supplies a pointer to the target process
        that is to receive the new handle

    TargetHandle - Optionally returns a the new duplicated handle

    DesiredAccess - Desired access for the new handle

    HandleAttributes - Desired attributes for the new handle

    Options - Duplication options that control things like close source,
        same access, and same attributes.

    PreviousMode - Mode of caller

Return Value:

    NTSTATUS - Status pf call

--*/
{
    NTSTATUS Status;
    PVOID SourceObject;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    BOOLEAN Attached;
    PHANDLE_TABLE SourceObjectTable, TargetObjectTable;
    HANDLE_TABLE_ENTRY ObjectTableEntry;
    OBJECT_HANDLE_INFORMATION HandleInformation;
    HANDLE NewHandle;
    ACCESS_STATE AccessState;
    AUX_ACCESS_DATA AuxData;
    ACCESS_MASK SourceAccess;
    ACCESS_MASK TargetAccess;
    ACCESS_MASK AuditMask = (ACCESS_MASK)0;
    PACCESS_STATE PassedAccessState = NULL;
    HANDLE_TABLE_ENTRY_INFO ObjectInfo;
    KAPC_STATE ApcState;


    if (ARGUMENT_PRESENT (TargetHandle)) {
        *TargetHandle = NULL;
    }
    //
    //  If the caller is not asking for the same access then
    //  validate the access they are requesting doesn't contain
    //  any bad bits
    //

    if (!(Options & DUPLICATE_SAME_ACCESS)) {

        Status = ObpValidateDesiredAccess( DesiredAccess );

        if (!NT_SUCCESS( Status )) {

            return( Status );
        }
    }

    //
    //  The Attached variable indicates if we needed to
    //  attach to the source process because it was not the
    //  current process.
    //

    Attached = FALSE;


    //
    //  Lock down access to the process object tables
    //
    SourceObjectTable = ObReferenceProcessHandleTable (SourceProcess);

    //
    //  Make sure the source process has an object table still
    //

    if ( SourceObjectTable == NULL ) {

        return STATUS_PROCESS_IS_TERMINATING;
    }

    //
    //  The the input source handle get a pointer to the
    //  source object itself, then detach from the process
    //  if necessary and check if we were given a good
    //  source handle.
    //

    Status = ObpReferenceProcessObjectByHandle (SourceHandle,
                                                SourceProcess,
                                                SourceObjectTable,
                                                PreviousMode,
                                                &SourceObject,
                                                &HandleInformation,
                                                &AuditMask);

    if (NT_SUCCESS( Status )) {

        if ((HandleInformation.HandleAttributes & OBJ_AUDIT_OBJECT_CLOSE) == 0) {
            AuditMask = 0;
        }
    }


    if (!NT_SUCCESS( Status )) {

        ObDereferenceProcessHandleTable (SourceProcess);

        return( Status );
    }

    //
    //  We are all done if no target process handle was specified.
    //  This is practially a noop because the only really end result
    //  could be that we've closed the source handle.
    //

    if (!ARGUMENT_PRESENT( TargetProcess )) {

        //
        //  If no TargetProcessHandle, then only possible option is to close
        //  the source handle in the context of the source process.
        //

        if (!(Options & DUPLICATE_CLOSE_SOURCE)) {

            Status = STATUS_INVALID_PARAMETER;
        }

        if (Options & DUPLICATE_CLOSE_SOURCE) {

            KeStackAttachProcess( &SourceProcess->Pcb, &ApcState );

            NtClose( SourceHandle );

            KeUnstackDetachProcess (&ApcState);
        }

        ObDereferenceProcessHandleTable (SourceProcess);

        ObDereferenceObject( SourceObject );

        return( Status );
    }

    SourceAccess = HandleInformation.GrantedAccess;

    //
    //  Make sure the target process has not exited
    //

    TargetObjectTable = ObReferenceProcessHandleTable (TargetProcess);
    if ( TargetObjectTable == NULL ) {

        if (Options & DUPLICATE_CLOSE_SOURCE) {

            KeStackAttachProcess( &SourceProcess->Pcb, &ApcState );

            NtClose( SourceHandle );

            KeUnstackDetachProcess (&ApcState);
        }

        ObDereferenceProcessHandleTable (SourceProcess);

        ObDereferenceObject( SourceObject );

        return STATUS_PROCESS_IS_TERMINATING;
    }

    //
    //  If the specified target process is not the current process, attach
    //  to the specified target process.
    //

    if (PsGetCurrentProcess() != TargetProcess) {

        KeStackAttachProcess( &TargetProcess->Pcb, &ApcState );

        Attached = TRUE;
    }

    //
    //  Construct the proper desired access and attributes for the new handle
    //

    if (Options & DUPLICATE_SAME_ACCESS) {

        DesiredAccess = SourceAccess;
    }

    if (Options & DUPLICATE_SAME_ATTRIBUTES) {

        HandleAttributes = HandleInformation.HandleAttributes;

    } else {

        //
        //  Always propogate auditing information.
        //

        HandleAttributes |= HandleInformation.HandleAttributes & OBJ_AUDIT_OBJECT_CLOSE;
    }

    //
    //  Get the object header for the source object
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( SourceObject );
    ObjectType = ObjectHeader->Type;

    RtlZeroMemory( &ObjectTableEntry, sizeof( HANDLE_TABLE_ENTRY ) );

    ObjectTableEntry.Object = ObjectHeader;

    ObjectTableEntry.ObAttributes |= (HandleAttributes & OBJ_HANDLE_ATTRIBUTES);

    //
    //  The following will be reset below if AVR is performed.
    //

    ObjectInfo.AuditMask = AuditMask;

    //
    //  If any of the generic access bits are specified then map those to more
    //  specific access bits
    //

    if ((DesiredAccess & GENERIC_ACCESS) != 0) {

        RtlMapGenericMask( &DesiredAccess,
                           &ObjectType->TypeInfo.GenericMapping );
    }

    //
    //  Make sure to preserve ACCESS_SYSTEM_SECURITY, which most likely is not
    //  found in the ValidAccessMask
    //

    TargetAccess = DesiredAccess &
                   (ObjectType->TypeInfo.ValidAccessMask | ACCESS_SYSTEM_SECURITY);

    //
    //  If the access requested for the target is a superset of the
    //  access allowed in the source, perform full AVR.  If it is a
    //  subset or equal, do not perform any access validation.
    //
    //  Do not allow superset access if object type has a private security
    //  method, as there is no means to call them in this case to do the
    //  access check.
    //
    //  If the AccessState is not passed to ObpIncrementHandleCount
    //  there will be no AVR.
    //

    if (TargetAccess & ~SourceAccess) {

        if (ObjectType->TypeInfo.SecurityProcedure == SeDefaultObjectMethod) {

            Status = SeCreateAccessState( &AccessState,
                                          &AuxData,
                                          TargetAccess,       // DesiredAccess
                                          &ObjectType->TypeInfo.GenericMapping );

            PassedAccessState = &AccessState;

        } else {

            Status = STATUS_ACCESS_DENIED;
        }

    } else {

        //
        //  Do not perform AVR
        //

        PassedAccessState = NULL;

        Status = STATUS_SUCCESS;
    }

    //
    //  Increment the new handle count and get a pointer to
    //  the target processes object table
    //

    if ( NT_SUCCESS( Status )) {

        Status = ObpIncrementHandleCount( ObDuplicateHandle,
                                          PsGetCurrentProcess(), // this is already the target process
                                          SourceObject,
                                          ObjectType,
                                          PassedAccessState,
                                          PreviousMode,
                                          HandleAttributes );

    }

    if (Attached) {

        KeUnstackDetachProcess (&ApcState);

        Attached = FALSE;
    }

    if (Options & DUPLICATE_CLOSE_SOURCE) {

        KeStackAttachProcess( &SourceProcess->Pcb, &ApcState );

        NtClose( SourceHandle );

        KeUnstackDetachProcess(&ApcState);
    }

    if (!NT_SUCCESS( Status )) {

        if (PassedAccessState != NULL) {

            SeDeleteAccessState( PassedAccessState );
        }

        ObDereferenceProcessHandleTable (SourceProcess);
        ObDereferenceProcessHandleTable (TargetProcess);

        ObDereferenceObject( SourceObject );

        return( Status );
    }

    if ((PassedAccessState != NULL) && (PassedAccessState->GenerateOnClose == TRUE)) {

        //
        //  If we performed AVR opening the handle, then mark the handle as needing
        //  auditing when it's closed.  Also save away the maximum audit mask
        //  if one was created.
        //

        ObjectTableEntry.ObAttributes |= OBJ_AUDIT_OBJECT_CLOSE;
        ObjectInfo.AuditMask = ((PAUX_ACCESS_DATA)PassedAccessState->AuxData)->MaximumAuditMask;
    }

#if i386 

    if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

        LONG StackTraceIndex;

        ObjectTableEntry.GrantedAccessIndex = ObpComputeGrantedAccessIndex( TargetAccess );

        if (PreviousMode == KernelMode) {

            StackTraceIndex = RtlLogStackBackTrace();

        } else {

            StackTraceIndex = RtlLogUmodeStackBackTrace();
        }

        //
        //  Save the stack trace only if the index fits the CreatorBackTraceIndex
        //  minus the ProtectOnClose bit
        //

        if (StackTraceIndex < OBP_CREATOR_BACKTRACE_LIMIT) {

            ObjectTableEntry.CreatorBackTraceIndex = (USHORT)StackTraceIndex;
        
        } else {

            ObjectTableEntry.CreatorBackTraceIndex = 0;
        }
    
    } else {

        ObjectTableEntry.GrantedAccess = TargetAccess;
    }

#else

    ObjectTableEntry.GrantedAccess = TargetAccess;

#endif // i386 

    //
    //  Now that we've constructed a new object table entry for the duplicated handle
    //  we need to add it to the object table of the target process
    //

    ObpEncodeProtectClose(ObjectTableEntry);

    NewHandle = ExCreateHandle( TargetObjectTable, &ObjectTableEntry );

    if (NewHandle) {

        if ( ObjectInfo.AuditMask != 0 ) {

            //
            //  Make sure it's the same object before setting the handle information.
            //  The user may have closed it immediately after the ExCreateHandle call,
            //  so at this time it may either be invalid or a completely different object.
            //

            PHANDLE_TABLE_ENTRY HandleTableEntry;
            PKTHREAD CurrentThread;

            CurrentThread = KeGetCurrentThread ();

            KeEnterCriticalRegionThread (CurrentThread);

            HandleTableEntry = ExMapHandleToPointer ( TargetObjectTable, NewHandle );

            if (HandleTableEntry != NULL) {

                if (((ULONG_PTR)(HandleTableEntry->Object) & ~OBJ_HANDLE_ATTRIBUTES) == (ULONG_PTR)ObjectHeader) {

                    ExSetHandleInfo(TargetObjectTable, NewHandle, &ObjectInfo, TRUE);
                }

                ExUnlockHandleTableEntry( TargetObjectTable, HandleTableEntry );
            }

            KeLeaveCriticalRegionThread (CurrentThread);
        }

        //
        //  We have a new handle to audit the creation of the new handle if
        //  AVR was done.  And set the optional output handle variable.  Note
        //  that if we reach here the status variable is already a success
        //

        if (PassedAccessState != NULL) {

            SeAuditHandleCreation( PassedAccessState, NewHandle );
        }

        if ( (ObjectTableEntry.ObAttributes & OBJ_AUDIT_OBJECT_CLOSE) && 
             (SeDetailedAuditingWithToken( PassedAccessState ? SeQuerySubjectContextToken( &PassedAccessState->SubjectSecurityContext ) : NULL )) ) {

            SeAuditHandleDuplication( SourceHandle,
                                      NewHandle,
                                      SourceProcess,
                                      TargetProcess );
        }


    } else {

        //
        //  We didn't get a new handle to decrement the handle count dereference
        //  the necessary objects, set the optional output variable and indicate
        //  why we're failing
        //

        ObpDecrementHandleCount( TargetProcess,
                                 ObjectHeader,
                                 ObjectType,
                                 TargetAccess );

        ObDereferenceObject( SourceObject );


        Status = STATUS_INSUFFICIENT_RESOURCES;
    }

    if (ARGUMENT_PRESENT( TargetHandle )) {

        *TargetHandle = NewHandle;

    }

    //
    //  Cleanup from our selfs and then return to our caller
    //

    if (PassedAccessState != NULL) {

        SeDeleteAccessState( PassedAccessState );
    }

    ObDereferenceProcessHandleTable (SourceProcess);
    ObDereferenceProcessHandleTable (TargetProcess);

    return( Status );
}


NTSTATUS
NtDuplicateObject (
    IN HANDLE SourceProcessHandle,
    IN HANDLE SourceHandle,
    IN HANDLE TargetProcessHandle OPTIONAL,
    OUT PHANDLE TargetHandle OPTIONAL,
    IN ACCESS_MASK DesiredAccess,
    IN ULONG HandleAttributes,
    IN ULONG Options
    )

/*++

Routine Description:

    This function creates a handle that is a duplicate of the specified
    source handle.  The source handle is evaluated in the context of the
    specified source process.  The calling process must have
    PROCESS_DUP_HANDLE access to the source process.  The duplicate
    handle is created with the specified attributes and desired access.
    The duplicate handle is created in the handle table of the specified
    target process.  The calling process must have PROCESS_DUP_HANDLE
    access to the target process.

Arguments:

    SourceProcessHandle - Supplies a handle to the source process for the
        handle being duplicated

    SourceHandle - Supplies the handle being duplicated

    TargetProcessHandle - Optionally supplies a handle to the target process
        that is to receive the new handle

    TargetHandle - Optionally returns a the new duplicated handle

    DesiredAccess - Desired access for the new handle

    HandleAttributes - Desired attributes for the new handle

    Options - Duplication options that control things like close source,
        same access, and same attributes.

Return Value:

    TBS

--*/

{
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status, Status1;
    PEPROCESS SourceProcess;
    PEPROCESS TargetProcess;
    HANDLE NewHandle = NULL;

    //
    //  Get previous processor mode and probe output arguments if necessary.
    //

    PreviousMode = KeGetPreviousMode();

    if (ARGUMENT_PRESENT( TargetHandle ) && (PreviousMode != KernelMode)) {

        try {

            ProbeForWriteHandle( TargetHandle );
            *TargetHandle = NULL;

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            return( GetExceptionCode() );
        }
    }


    //
    //  Given the input source process handle get a pointer
    //  to the source process object
    //

    Status = ObReferenceObjectByHandle( SourceProcessHandle,
                                        PROCESS_DUP_HANDLE,
                                        PsProcessType,
                                        PreviousMode,
                                        (PVOID *)&SourceProcess,
                                        NULL );

    if (!NT_SUCCESS( Status )) {

        return Status;
    }

    //
    //  We are all done if no target process handle was specified.
    //  This is practially a noop because the only really end result
    //  could be that we've closed the source handle.
    //

    if (!ARGUMENT_PRESENT( TargetProcessHandle )) {

        //
        //  If no TargetProcessHandle, then only possible option is to close
        //  the source handle in the context of the source process.
        //

        TargetProcess = NULL;
        Status1 = STATUS_SUCCESS;
    } else {
        //
        //  At this point the caller did specify for a target process
        //  So from the target process handle get a pointer to the
        //  target process object.
        //

        Status1 = ObReferenceObjectByHandle( TargetProcessHandle,
                                             PROCESS_DUP_HANDLE,
                                             PsProcessType,
                                             PreviousMode,
                                             (PVOID *)&TargetProcess,
                                             NULL );
        //
        // The original structure of Duplicate cased us to still close the input handle if the output process handle
        // was bad. We preserve that functionality.
        //
        if (!NT_SUCCESS (Status1)) {
            TargetProcess = NULL;
        }
    }

    Status = ObDuplicateObject (SourceProcess,
                                SourceHandle,
                                TargetProcess,
                                &NewHandle,
                                DesiredAccess,
                                HandleAttributes,
                                Options,
                                PreviousMode );

    if (ARGUMENT_PRESENT( TargetHandle )) {

        try {

            *TargetHandle = NewHandle;

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            //
            //  Fall through, since we cannot undo what we have done.
            //
        }
    }

    ObDereferenceObject( SourceProcess );
    if ( TargetProcess != NULL) {
        ObDereferenceObject( TargetProcess );
    }

    if (!NT_SUCCESS (Status1)) {
        Status = Status1;
    }
    return( Status );
}


NTSTATUS
ObGetHandleInformation (
    OUT PSYSTEM_HANDLE_INFORMATION HandleInformation,
    IN ULONG Length,
    OUT PULONG ReturnLength OPTIONAL
    )

/*++

Routine Description:

    This routine returns information about the specified handle.

Arguments:

    HandleInformation - Supplies an array of handle information
        structures to fill in

    Length - Supplies the length the handle information array in bytes

    ReturnLength - Receives the number of bytes used by this call

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status;
    ULONG RequiredLength;

    PAGED_CODE();

    RequiredLength = FIELD_OFFSET( SYSTEM_HANDLE_INFORMATION, Handles );

    if (Length < RequiredLength) {

        return( STATUS_INFO_LENGTH_MISMATCH );
    }

    HandleInformation->NumberOfHandles = 0;

    //
    //  For every handle in every handle table we'll be calling
    //  our callback routine
    //

    Status = ExSnapShotHandleTables( ObpCaptureHandleInformation,
                                     HandleInformation,
                                     Length,
                                     &RequiredLength );

    if (ARGUMENT_PRESENT( ReturnLength )) {

        *ReturnLength = RequiredLength;
    }

    return( Status );
}


NTSTATUS
ObGetHandleInformationEx (
    OUT PSYSTEM_HANDLE_INFORMATION_EX HandleInformation,
    IN ULONG Length,
    OUT PULONG ReturnLength OPTIONAL
    )

/*++

Routine Description:

    This routine returns information about the specified handle.

Arguments:

    HandleInformation - Supplies an array of handle information
        structures to fill in

    Length - Supplies the length the handle information array in bytes

    ReturnLength - Receives the number of bytes used by this call

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status;
    ULONG RequiredLength;

    PAGED_CODE();

    RequiredLength = FIELD_OFFSET( SYSTEM_HANDLE_INFORMATION_EX, Handles );

    if (Length < RequiredLength) {

        return( STATUS_INFO_LENGTH_MISMATCH );
    }

    HandleInformation->NumberOfHandles = 0;

    //
    //  For every handle in every handle table we'll be calling
    //  our callback routine
    //

    Status = ExSnapShotHandleTablesEx( ObpCaptureHandleInformationEx,
                                       HandleInformation,
                                       Length,
                                       &RequiredLength );

    if (ARGUMENT_PRESENT( ReturnLength )) {

        *ReturnLength = RequiredLength;
    }

    return( Status );
}


NTSTATUS
ObpCaptureHandleInformation (
    IN OUT PSYSTEM_HANDLE_TABLE_ENTRY_INFO *HandleEntryInfo,
    IN HANDLE UniqueProcessId,
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE HandleIndex,
    IN ULONG Length,
    IN OUT PULONG RequiredLength
    )

/*++

Routine Description:

    This is the callback routine of ObGetHandleInformation

Arguments:

    HandleEntryInfo - Supplies a pointer to the output buffer to receive
        the handle information

    UniqueProcessId - Supplies the process id of the caller

    ObjectTableEntry - Supplies the handle table entry that is being
        captured

    HandleIndex - Supplies the index for the preceding handle table entry

    Length - Specifies the length, in bytes, of the original user buffer

    RequiredLength - Specifies the length, in bytes, that has already been
        used in the buffer to store information.  On return this receives
        the updated number of bytes being used.

        Note that the HandleEntryInfo does not necessarily point to the
        start of the original user buffer.  It will have been offset by
        the feed-in RequiredLength value.

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;

    //
    //  Figure out who much size we really need to contain this extra record
    //  and then check that it fits.
    //

    *RequiredLength += sizeof( SYSTEM_HANDLE_TABLE_ENTRY_INFO );

    if (Length < *RequiredLength) {

        Status = STATUS_INFO_LENGTH_MISMATCH;

    } else {

        //
        //  Get the object header from the table entry and then copy over the information
        //

        ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

        (*HandleEntryInfo)->UniqueProcessId       = (USHORT)((ULONG_PTR)UniqueProcessId);
        (*HandleEntryInfo)->HandleAttributes      = (UCHAR)ObpGetHandleAttributes(ObjectTableEntry);
        (*HandleEntryInfo)->ObjectTypeIndex       = (UCHAR)(ObjectHeader->Type->Index);
        (*HandleEntryInfo)->HandleValue           = (USHORT)((ULONG_PTR)(HandleIndex));
        (*HandleEntryInfo)->Object                = &ObjectHeader->Body;
        (*HandleEntryInfo)->CreatorBackTraceIndex = 0;

#if i386 

        if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

            (*HandleEntryInfo)->CreatorBackTraceIndex = ObjectTableEntry->CreatorBackTraceIndex & OBP_CREATOR_BACKTRACE_INDEX_MASK;
            (*HandleEntryInfo)->GrantedAccess = ObpTranslateGrantedAccessIndex( ObjectTableEntry->GrantedAccessIndex );

        } else {

            (*HandleEntryInfo)->GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);
        }

#else

        (*HandleEntryInfo)->GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);

#endif // i386 

        (*HandleEntryInfo)++;

        Status = STATUS_SUCCESS;
    }

    return( Status );
}


NTSTATUS
ObpCaptureHandleInformationEx (
    IN OUT PSYSTEM_HANDLE_TABLE_ENTRY_INFO_EX *HandleEntryInfo,
    IN HANDLE UniqueProcessId,
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE HandleIndex,
    IN ULONG Length,
    IN OUT PULONG RequiredLength
    )

/*++

Routine Description:

    This is the callback routine of ObGetHandleInformation

Arguments:

    HandleEntryInfo - Supplies a pointer to the output buffer to receive
        the handle information

    UniqueProcessId - Supplies the process id of the caller

    ObjectTableEntry - Supplies the handle table entry that is being
        captured

    HandleIndex - Supplies the index for the preceding handle table entry

    Length - Specifies the length, in bytes, of the original user buffer

    RequiredLength - Specifies the length, in bytes, that has already been
        used in the buffer to store information.  On return this receives
        the updated number of bytes being used.

        Note that the HandleEntryInfo does not necessarily point to the
        start of the original user buffer.  It will have been offset by
        the feed-in RequiredLength value.

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;

    //
    //  Figure out who much size we really need to contain this extra record
    //  and then check that it fits.
    //

    *RequiredLength += sizeof( SYSTEM_HANDLE_TABLE_ENTRY_INFO_EX );

    if (Length < *RequiredLength) {

        Status = STATUS_INFO_LENGTH_MISMATCH;

    } else {

        //
        //  Get the object header from the table entry and then copy over the information
        //

        ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

        (*HandleEntryInfo)->UniqueProcessId       = (ULONG_PTR)UniqueProcessId;
        (*HandleEntryInfo)->HandleAttributes      = (UCHAR)ObpGetHandleAttributes(ObjectTableEntry);
        (*HandleEntryInfo)->ObjectTypeIndex       = (USHORT)(ObjectHeader->Type->Index);
        (*HandleEntryInfo)->HandleValue           = (ULONG_PTR)(HandleIndex);
        (*HandleEntryInfo)->Object                = &ObjectHeader->Body;
        (*HandleEntryInfo)->CreatorBackTraceIndex = 0;

#if i386 

        if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

            (*HandleEntryInfo)->CreatorBackTraceIndex = ObjectTableEntry->CreatorBackTraceIndex & OBP_CREATOR_BACKTRACE_INDEX_MASK;
            (*HandleEntryInfo)->GrantedAccess = ObpTranslateGrantedAccessIndex( ObjectTableEntry->GrantedAccessIndex );

        } else {

            (*HandleEntryInfo)->GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);
        }

#else

        (*HandleEntryInfo)->GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);

#endif // i386 

        (*HandleEntryInfo)++;

        Status = STATUS_SUCCESS;
    }

    return( Status );
}


POBJECT_HANDLE_COUNT_ENTRY
ObpInsertHandleCount (
    POBJECT_HEADER ObjectHeader
    )

/*++

Routine Description:

    This function will increase the size of the handle database
    stored in the handle information of an object header.  If
    necessary it will allocate new and free old handle databases.

    This routine should not be called if there is already free
    space in the handle table.

Arguments:

    ObjectHeader - The object whose handle count is being incremented

Return Value:

    The pointer to the next free handle count entry within the
    handle database.

--*/

{
    POBJECT_HEADER_HANDLE_INFO HandleInfo;
    POBJECT_HANDLE_COUNT_DATABASE OldHandleCountDataBase;
    POBJECT_HANDLE_COUNT_DATABASE NewHandleCountDataBase;
    POBJECT_HANDLE_COUNT_ENTRY FreeHandleCountEntry;
    ULONG CountEntries;
    ULONG OldSize;
    ULONG NewSize;
    OBJECT_HANDLE_COUNT_DATABASE SingleEntryDataBase;

    PAGED_CODE();

    //
    //  Check if the object has any handle information
    //

    HandleInfo = OBJECT_HEADER_TO_HANDLE_INFO(ObjectHeader);

    if (HandleInfo == NULL) {

        return NULL;
    }

    //
    //  The object does have some handle information.  If it has
    //  a single handle entry then we'll construct a local dummy
    //  handle count database and come up with a new data base for
    //  storing two entries.
    //

    if (ObjectHeader->Flags & OB_FLAG_SINGLE_HANDLE_ENTRY) {

        SingleEntryDataBase.CountEntries = 1;
        SingleEntryDataBase.HandleCountEntries[0] = HandleInfo->SingleEntry;

        OldHandleCountDataBase = &SingleEntryDataBase;

        OldSize = sizeof( SingleEntryDataBase );

        CountEntries = 2;

        NewSize = sizeof(OBJECT_HANDLE_COUNT_DATABASE) +
               ((CountEntries - 1) * sizeof( OBJECT_HANDLE_COUNT_ENTRY ));

    } else {

        //
        //  The object already has multiple handles so we reference the
        //  current handle database, and compute a new size bumped by four
        //

        OldHandleCountDataBase = HandleInfo->HandleCountDataBase;

        CountEntries = OldHandleCountDataBase->CountEntries;

        OldSize = sizeof(OBJECT_HANDLE_COUNT_DATABASE) +
               ((CountEntries - 1) * sizeof( OBJECT_HANDLE_COUNT_ENTRY));

        CountEntries += 4;

        NewSize = sizeof(OBJECT_HANDLE_COUNT_DATABASE) +
               ((CountEntries - 1) * sizeof( OBJECT_HANDLE_COUNT_ENTRY));
    }

    //
    //  Now allocate pool for the new handle database.
    //

    NewHandleCountDataBase = ExAllocatePoolWithTag(PagedPool, NewSize,'dHbO');

    if (NewHandleCountDataBase == NULL) {

        return NULL;
    }

    //
    //  Copy over the old database.  Note that this might just copy our
    //  local dummy entry for the single entry case
    //

    RtlCopyMemory(NewHandleCountDataBase, OldHandleCountDataBase, OldSize);

    //
    //  If the previous mode was a single entry then remove that
    //  indication otherwise free up with previous handle database
    //

    if (ObjectHeader->Flags & OB_FLAG_SINGLE_HANDLE_ENTRY) {

        ObjectHeader->Flags &= ~OB_FLAG_SINGLE_HANDLE_ENTRY;

    } else {

        ExFreePool( OldHandleCountDataBase );
    }

    //
    //  Find the end of the new database that is used and zero out
    //  the memory
    //

    FreeHandleCountEntry =
        (POBJECT_HANDLE_COUNT_ENTRY)((PCHAR)NewHandleCountDataBase + OldSize);

    RtlZeroMemory(FreeHandleCountEntry, NewSize - OldSize);

    //
    //  Set the new database to the proper entry count and put it
    //  all in the object
    //

    NewHandleCountDataBase->CountEntries = CountEntries;

    HandleInfo->HandleCountDataBase = NewHandleCountDataBase;

    //
    //  And return to our caller
    //

    return FreeHandleCountEntry;
}


NTSTATUS
ObpIncrementHandleDataBase (
    IN POBJECT_HEADER ObjectHeader,
    IN PEPROCESS Process,
    OUT PULONG NewProcessHandleCount
    )

/*++

Routine Description:

    This function increments the handle count database associated with the
    specified object for a specified process. This function is assuming that
    is called only for MaintainHandleCount == TRUE.

Arguments:

    ObjectHeader - Supplies a pointer to the object.

    Process - Supplies a pointer to the process whose handle count is to be
        updated.

    NewProcessHandleCount - Supplies a pointer to a variable that receives
        the new handle count for the process.

Return Value:

    An appropriate status value

--*/

{
    POBJECT_HEADER_HANDLE_INFO HandleInfo;
    POBJECT_HANDLE_COUNT_DATABASE HandleCountDataBase;
    POBJECT_HANDLE_COUNT_ENTRY HandleCountEntry;
    POBJECT_HANDLE_COUNT_ENTRY FreeHandleCountEntry;
    ULONG CountEntries;

    PAGED_CODE();

    //
    //  Translate the object header to the handle information.
    //  The HandleInfo can't be null because this function should be
    //  called only if MaintainHandleCount == TRUE
    //

    HandleInfo = OBJECT_HEADER_TO_HANDLE_INFO(ObjectHeader);

    //
    //  Check if the object has space for only a single handle
    //

    if (ObjectHeader->Flags & OB_FLAG_SINGLE_HANDLE_ENTRY) {

        //
        //  If the single handle isn't in use then set the entry
        //  and tell the caller there is only one handle
        //

        if (HandleInfo->SingleEntry.HandleCount == 0) {

            *NewProcessHandleCount = 1;
            HandleInfo->SingleEntry.HandleCount = 1;
            HandleInfo->SingleEntry.Process = Process;

            return STATUS_SUCCESS;

        //
        //  If the single entry is for the same process as specified
        //  then increment the count and we're done
        //

        } else if (HandleInfo->SingleEntry.Process == Process) {

            *NewProcessHandleCount = ++HandleInfo->SingleEntry.HandleCount;

            return STATUS_SUCCESS;

        //
        //  Finally we have a object with a single handle entry already
        //  in use, so we need to grow the handle database before
        //  we can set this new value
        //

        } else {

            FreeHandleCountEntry = ObpInsertHandleCount( ObjectHeader );

            if (FreeHandleCountEntry == NULL) {

                return STATUS_INSUFFICIENT_RESOURCES;
            }

            FreeHandleCountEntry->Process = Process;
            FreeHandleCountEntry->HandleCount = 1;
            *NewProcessHandleCount = 1;

            return STATUS_SUCCESS;
        }
    }

    //
    //  The object does not contain a single entry, therefore we're
    //  assuming it already has a handle count database
    //

    HandleCountDataBase = HandleInfo->HandleCountDataBase;

    FreeHandleCountEntry = NULL;

    if (HandleCountDataBase != NULL) {

        //
        //  Get the number of entries and a pointer to the first one
        //  in the handle database
        //

        CountEntries = HandleCountDataBase->CountEntries;
        HandleCountEntry = &HandleCountDataBase->HandleCountEntries[ 0 ];

        //
        //  For each entry in the handle database check for a process
        //  match and if so then increment the handle count and return
        //  to our caller.  Otherwise if the entry is free then remember
        //  it so we can store to it later
        //

        while (CountEntries) {

            if (HandleCountEntry->Process == Process) {

                *NewProcessHandleCount = ++HandleCountEntry->HandleCount;

                return STATUS_SUCCESS;

            } else if (HandleCountEntry->HandleCount == 0) {

                FreeHandleCountEntry = HandleCountEntry;
            }

            ++HandleCountEntry;
            --CountEntries;
        }

        //
        //  If we did not find a free handle entry then we have to grow the
        //  handle database before we can set this new value
        //

        if (FreeHandleCountEntry == NULL) {

            FreeHandleCountEntry = ObpInsertHandleCount( ObjectHeader );

            if (FreeHandleCountEntry == NULL) {

                return(STATUS_INSUFFICIENT_RESOURCES);
            }
        }

        FreeHandleCountEntry->Process = Process;
        FreeHandleCountEntry->HandleCount = 1;
        *NewProcessHandleCount = 1;
    }

    return STATUS_SUCCESS;
}


NTSTATUS
ObpIncrementHandleCount (
    OB_OPEN_REASON OpenReason,
    PEPROCESS Process,
    PVOID Object,
    POBJECT_TYPE ObjectType,
    PACCESS_STATE AccessState OPTIONAL,
    KPROCESSOR_MODE AccessMode,
    ULONG Attributes
    )

/*++

Routine Description:

    Increments the count of number of handles to the given object.

    If the object is being opened or created, access validation and
    auditing will be performed as appropriate.

Arguments:

    OpenReason - Supplies the reason the handle count is being incremented.

    Process - Pointer to the process in which the new handle will reside.

    Object - Supplies a pointer to the body of the object.

    ObjectType - Supplies the type of the object.

    AccessState - Optional parameter supplying the current accumulated
        security information describing the attempt to access the object.

    AccessMode - Supplies the mode of the requestor.

    Attributes - Desired attributes for the handle

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status = STATUS_SUCCESS;
    ULONG ProcessHandleCount;
    BOOLEAN ExclusiveHandle;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POBJECT_HEADER ObjectHeader;
    BOOLEAN HasPrivilege = FALSE;
    PRIVILEGE_SET Privileges;
    BOOLEAN NewObject;
    BOOLEAN HoldObjectTypeMutex = FALSE;
    KPROCESSOR_MODE AccessCheckMode;
    ULONG NewTotal;

    PAGED_CODE();

    ObpValidateIrql( "ObpIncrementHandleCount" );

    //
    //  Get a pointer to the object header
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    //
    // If the caller asked us to always do an access check then use user mode for previous mode
    //
    if (Attributes & OBJ_FORCE_ACCESS_CHECK) {
        AccessCheckMode = UserMode;
    } else {
        AccessCheckMode = AccessMode;
    }

    ExclusiveHandle = FALSE;
    HoldObjectTypeMutex = TRUE;

    ObpLockObject( ObjectHeader );


    try {

        //
        //  Charge the user quota for the object
        //

        Status = ObpChargeQuotaForObject( ObjectHeader, ObjectType, &NewObject );

        if (!NT_SUCCESS( Status )) {

            leave;
        }

        //
        //  Check if the caller wants exlusive access and if so then
        //  make sure the attributes and header flags match up correctly
        //

        if (Attributes & OBJ_EXCLUSIVE) {

            if ((Attributes & OBJ_INHERIT) ||
                ((ObjectHeader->Flags & OB_FLAG_EXCLUSIVE_OBJECT) == 0)) {

                Status = STATUS_INVALID_PARAMETER;
                leave;
            }

            if (((OBJECT_HEADER_TO_EXCLUSIVE_PROCESS(ObjectHeader) == NULL) &&
                 (ObjectHeader->HandleCount != 0))

                    ||

                ((OBJECT_HEADER_TO_EXCLUSIVE_PROCESS(ObjectHeader) != NULL) &&
                 (OBJECT_HEADER_TO_EXCLUSIVE_PROCESS(ObjectHeader) != PsGetCurrentProcess()))) {

                Status = STATUS_ACCESS_DENIED;
                leave;
            }

            ExclusiveHandle = TRUE;

        //
        //  The user doesn't want exclusive access so now check to make sure
        //  the attriutes and header flags match up correctly
        //

        } else if ((ObjectHeader->Flags & OB_FLAG_EXCLUSIVE_OBJECT) &&
                   (OBJECT_HEADER_TO_EXCLUSIVE_PROCESS(ObjectHeader) != NULL)) {

            Status = STATUS_ACCESS_DENIED;
            leave;
        }

        //
        //  If handle count going from zero to one for an existing object that
        //  maintains a handle count database, but does not have an open procedure
        //  just a close procedure, then fail the call as they are trying to
        //  reopen an object by pointer and the close procedure will not know
        //  that the object has been 'recreated'
        //

        if ((ObjectHeader->HandleCount == 0) &&
            (!NewObject) &&
            (ObjectType->TypeInfo.MaintainHandleCount) &&
            (ObjectType->TypeInfo.OpenProcedure == NULL) &&
            (ObjectType->TypeInfo.CloseProcedure != NULL)) {

            Status = STATUS_UNSUCCESSFUL;
            leave;
        }

        if ((OpenReason == ObOpenHandle) ||
            ((OpenReason == ObDuplicateHandle) && ARGUMENT_PRESENT(AccessState))) {

            //
            //  Perform Access Validation to see if we can open this
            //  (already existing) object.
            //

            if (!ObCheckObjectAccess( Object,
                                      AccessState,
                                      TRUE,
                                      AccessCheckMode,
                                      &Status )) {

                leave;
            }

        } else if ((OpenReason == ObCreateHandle)) {

            //
            //  We are creating a new instance of this object type.
            //  A total of three audit messages may be generated:
            //
            //  1 - Audit the attempt to create an instance of this
            //      object type.
            //
            //  2 - Audit the successful creation.
            //
            //  3 - Audit the allocation of the handle.
            //

            //
            //  At this point, the RemainingDesiredAccess field in
            //  the AccessState may still contain either Generic access
            //  types, or MAXIMUM_ALLOWED.  We will map the generics
            //  and substitute GenericAll for MAXIMUM_ALLOWED.
            //

            if ( AccessState->RemainingDesiredAccess & MAXIMUM_ALLOWED ) {

                AccessState->RemainingDesiredAccess &= ~MAXIMUM_ALLOWED;
                AccessState->RemainingDesiredAccess |= GENERIC_ALL;
            }

            if ((GENERIC_ACCESS & AccessState->RemainingDesiredAccess) != 0) {

                RtlMapGenericMask( &AccessState->RemainingDesiredAccess,
                                   &ObjectType->TypeInfo.GenericMapping );
            }

            //
            //  Since we are creating the object, we can give any access the caller
            //  wants.  The only exception is ACCESS_SYSTEM_SECURITY, which requires
            //  a privilege.
            //

            if ( AccessState->RemainingDesiredAccess & ACCESS_SYSTEM_SECURITY ) {

                //
                //  We could use SeSinglePrivilegeCheck here, but it
                //  captures the subject context again, and we don't
                //  want to do that in this path for performance reasons.
                //

                Privileges.PrivilegeCount = 1;
                Privileges.Control = PRIVILEGE_SET_ALL_NECESSARY;
                Privileges.Privilege[0].Luid = SeSecurityPrivilege;
                Privileges.Privilege[0].Attributes = 0;

                HasPrivilege = SePrivilegeCheck( &Privileges,
                                                 &AccessState->SubjectSecurityContext,
                                                 AccessCheckMode );

                if (!HasPrivilege) {

                    SePrivilegedServiceAuditAlarm ( NULL,
                                                    &AccessState->SubjectSecurityContext,
                                                    &Privileges,
                                                    FALSE );

                    Status = STATUS_PRIVILEGE_NOT_HELD;
                    leave;
                }

                AccessState->RemainingDesiredAccess &= ~ACCESS_SYSTEM_SECURITY;
                AccessState->PreviouslyGrantedAccess |= ACCESS_SYSTEM_SECURITY;

                (VOID) SeAppendPrivileges( AccessState,
                                           &Privileges );
            }
        }

        if (ExclusiveHandle) {

            OBJECT_HEADER_TO_QUOTA_INFO(ObjectHeader)->ExclusiveProcess = Process;
        }

        ObpIncrHandleCount( ObjectHeader );
        ProcessHandleCount = 0;

        //
        //  If the object type wants us to keep try of the handle counts
        //  then call our routine to do the work
        //

        if (ObjectType->TypeInfo.MaintainHandleCount) {

            Status = ObpIncrementHandleDataBase( ObjectHeader,
                                                 Process,
                                                 &ProcessHandleCount );

            if (!NT_SUCCESS(Status)) {

                //
                //  The only thing we need to do is to remove the
                //  reference added before. The quota charge will be
                //  returned at object deletion
                //

                ObpDecrHandleCount( ObjectHeader );

                leave;
            }
        }

        ObpUnlockObject( ObjectHeader );
        HoldObjectTypeMutex = FALSE;
        //
        //  Set our preliminary status now to success because
        //  the call to the open procedure might change this
        //

        Status = STATUS_SUCCESS;

        //
        //  If the object type has an open procedure
        //  then invoke that procedure
        //

        if (ObjectType->TypeInfo.OpenProcedure != NULL) {

#if DBG
            KIRQL SaveIrql;
#endif

            //
            //  Leave the object type mutex when call the OpenProcedure. If an exception
            //  while OpenProcedure the HoldObjectTypeMutex disable leaving the mutex
            //  on finally block
            //

            ObpBeginTypeSpecificCallOut( SaveIrql );

            Status = (*ObjectType->TypeInfo.OpenProcedure)( OpenReason,
                                                            Process,
                                                            Object,
                                                            AccessState ?
                                                                AccessState->PreviouslyGrantedAccess :
                                                                0,
                                                            ProcessHandleCount );

            ObpEndTypeSpecificCallOut( SaveIrql, "Open", ObjectType, Object );

            //
            //  Hold back the object type mutex and set the HoldObjectTypeMutex variable
            //  to allow releasing the mutex while leaving this procedure
            //


            if (!NT_SUCCESS(Status)) {

                ObpLockObject( ObjectHeader );
                HoldObjectTypeMutex = TRUE;

                (VOID)ObpDecrHandleCount( ObjectHeader );
                leave;
            }
        }

        //
        //  Get the objects creator info block and insert it on the
        //  global list of objects for that type
        //

        if (OpenReason == ObCreateHandle) {
            CreatorInfo = OBJECT_HEADER_TO_CREATOR_INFO( ObjectHeader );

            if (CreatorInfo != NULL) {

                ObpEnterObjectTypeMutex( ObjectType );
                
                InsertTailList( &ObjectType->TypeList, &CreatorInfo->TypeList );
                
                ObpLeaveObjectTypeMutex( ObjectType );
            }
        }

        //
        //  Do some simple bookkeeping for the handle counts
        //  and then return to our caller
        //

        NewTotal = (ULONG) InterlockedIncrement((PLONG)&ObjectType->TotalNumberOfHandles);

        //
        //  Note: The hightwather is only for bookeeping. We can do this w/o
        //  lock. In the worst case next time will be updated
        //

        if (NewTotal > ObjectType->HighWaterNumberOfHandles) {

            ObjectType->HighWaterNumberOfHandles = NewTotal;
        }

    } finally {

        if ( HoldObjectTypeMutex ) {

            ObpUnlockObject( ObjectHeader );
        }
    }

    return( Status );
}


NTSTATUS
ObpIncrementUnnamedHandleCount (
    PACCESS_MASK DesiredAccess,
    PEPROCESS Process,
    PVOID Object,
    POBJECT_TYPE ObjectType,
    KPROCESSOR_MODE AccessMode,
    ULONG Attributes
    )

/*++

Routine Description:

    Increments the count of number of handles to the given object.

Arguments:

    Desired Access - Supplies the desired access to the object and receives
        the assign access mask

    Process - Pointer to the process in which the new handle will reside.

    Object - Supplies a pointer to the body of the object.

    ObjectType - Supplies the type of the object.

    AccessMode - Supplies the mode of the requestor.

    Attributes - Desired attributes for the handle

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status = STATUS_SUCCESS;
    BOOLEAN ExclusiveHandle;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POBJECT_HEADER ObjectHeader;
    BOOLEAN NewObject;
    ULONG ProcessHandleCount;
    BOOLEAN HoldObjectTypeMutex = FALSE;
    ULONG NewTotal;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (AccessMode);

    ObpValidateIrql( "ObpIncrementUnnamedHandleCount" );

    //
    //  Get a pointer to the object header
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    ExclusiveHandle = FALSE;
    HoldObjectTypeMutex = TRUE;

    ObpLockObject( ObjectHeader );

    try {


        //
        //  Charge the user quota for the object
        //

        Status = ObpChargeQuotaForObject( ObjectHeader, ObjectType, &NewObject );

        if (!NT_SUCCESS( Status )) {

            leave;
        }
        //
        //  Check if the caller wants exlusive access and if so then
        //  make sure the attributes and header flags match up correctly
        //

        if (Attributes & OBJ_EXCLUSIVE) {

            if ((Attributes & OBJ_INHERIT) ||
                ((ObjectHeader->Flags & OB_FLAG_EXCLUSIVE_OBJECT) == 0)) {

                Status = STATUS_INVALID_PARAMETER;
                leave;
            }

            if (((OBJECT_HEADER_TO_EXCLUSIVE_PROCESS(ObjectHeader) == NULL) &&
                 (ObjectHeader->HandleCount != 0))

                        ||

                ((OBJECT_HEADER_TO_EXCLUSIVE_PROCESS(ObjectHeader) != NULL) &&
                 (OBJECT_HEADER_TO_EXCLUSIVE_PROCESS(ObjectHeader) != PsGetCurrentProcess()))) {

                Status = STATUS_ACCESS_DENIED;
                leave;
            }

            ExclusiveHandle = TRUE;

        //
        //  The user doesn't want exclusive access so now check to make sure
        //  the attriutes and header flags match up correctly
        //

        } else if ((ObjectHeader->Flags & OB_FLAG_EXCLUSIVE_OBJECT) &&
                   (OBJECT_HEADER_TO_EXCLUSIVE_PROCESS(ObjectHeader) != NULL)) {

            Status = STATUS_ACCESS_DENIED;
            leave;
        }

        //
        //  If handle count going from zero to one for an existing object that
        //  maintains a handle count database, but does not have an open procedure
        //  just a close procedure, then fail the call as they are trying to
        //  reopen an object by pointer and the close procedure will not know
        //  that the object has been 'recreated'
        //

        if ((ObjectHeader->HandleCount == 0) &&
            (!NewObject) &&
            (ObjectType->TypeInfo.MaintainHandleCount) &&
            (ObjectType->TypeInfo.OpenProcedure == NULL) &&
            (ObjectType->TypeInfo.CloseProcedure != NULL)) {

            Status = STATUS_UNSUCCESSFUL;

            leave;
        }

        //
        //  If the user asked for the maximum allowed then remove the bit and
        //  or in generic all access
        //

        if ( *DesiredAccess & MAXIMUM_ALLOWED ) {

            *DesiredAccess &= ~MAXIMUM_ALLOWED;
            *DesiredAccess |= GENERIC_ALL;
        }

        //  If the user asked for any generic bit then translate it to
        //  someone more appropriate for the object type
        //

        if ((GENERIC_ACCESS & *DesiredAccess) != 0) {

            RtlMapGenericMask( DesiredAccess,
                               &ObjectType->TypeInfo.GenericMapping );
        }

        if (ExclusiveHandle) {

            OBJECT_HEADER_TO_QUOTA_INFO(ObjectHeader)->ExclusiveProcess = Process;
        }

        ObpIncrHandleCount( ObjectHeader );
        ProcessHandleCount = 0;

        //
        //  If the object type wants us to keep try of the handle counts
        //  then call our routine to do the work
        //

        if (ObjectType->TypeInfo.MaintainHandleCount) {

            Status = ObpIncrementHandleDataBase( ObjectHeader,
                                                 Process,
                                                 &ProcessHandleCount );

            if (!NT_SUCCESS(Status)) {

                //
                //  The only thing we need to do is to remove the
                //  reference added before. The quota charge will be
                //  returned at object deletion.
                //

                ObpDecrHandleCount( ObjectHeader );
                leave;
            }
        }

        ObpUnlockObject( ObjectHeader );
        HoldObjectTypeMutex = FALSE;

        //
        //  Set our preliminary status now to success because
        //  the call to the open procedure might change this
        //

        Status = STATUS_SUCCESS;

        //
        //  If the object type has an open procedure
        //  then invoke that procedure
        //

        if (ObjectType->TypeInfo.OpenProcedure != NULL) {

#if DBG
            KIRQL SaveIrql;
#endif

            //
            //  Call the OpenProcedure. If an exception
            //  while OpenProcedure the HoldObjectTypeMutex disable leaving the mutex
            //  on finally block
            //


            ObpBeginTypeSpecificCallOut( SaveIrql );

            Status = (*ObjectType->TypeInfo.OpenProcedure)( ObCreateHandle,
                                                       Process,
                                                       Object,
                                                       *DesiredAccess,
                                                       ProcessHandleCount );

            ObpEndTypeSpecificCallOut( SaveIrql, "Open", ObjectType, Object );

            //
            //  Hold back the object type mutex and set the HoldObjectTypeMutex variable
            //  to allow releasing the mutex while leaving this procedure
            //


            if (!NT_SUCCESS(Status)) {

                ObpLockObject( ObjectHeader );
                HoldObjectTypeMutex = TRUE;

                (VOID)ObpDecrHandleCount( ObjectHeader );
                leave;
            }
        }

        //
        //  Get a pointer to the creator info block for the object and insert
        //  it on the global list of object for that type
        //

        CreatorInfo = OBJECT_HEADER_TO_CREATOR_INFO( ObjectHeader );

        if (CreatorInfo != NULL) {

            ObpEnterObjectTypeMutex( ObjectType );

            InsertTailList( &ObjectType->TypeList, &CreatorInfo->TypeList );

            ObpLeaveObjectTypeMutex( ObjectType );
        }

        //
        //  Do some simple bookkeeping for the handle counts
        //  and then return to our caller
        //

        NewTotal = (ULONG) InterlockedIncrement((PLONG)&ObjectType->TotalNumberOfHandles);

        if (NewTotal > ObjectType->HighWaterNumberOfHandles) {

            ObjectType->HighWaterNumberOfHandles = NewTotal;
        }

    } finally {

        if ( HoldObjectTypeMutex ) {

            ObpUnlockObject( ObjectHeader );
        }
    }

    return( Status );
}


NTSTATUS
ObpChargeQuotaForObject (
    IN POBJECT_HEADER ObjectHeader,
    IN POBJECT_TYPE ObjectType,
    OUT PBOOLEAN NewObject
    )

/*++

Routine Description:

    This routine charges quota against the current process for the new
    object

Arguments:

    ObjectHeader - Supplies a pointer to the new object being charged for

    ObjectType - Supplies the type of the new object

    NewObject - Returns true if the object is really new and false otherwise

Return Value:

    An appropriate status value

--*/

{
    POBJECT_HEADER_QUOTA_INFO QuotaInfo;
    ULONG NonPagedPoolCharge;
    ULONG PagedPoolCharge;

    //
    //  Get a pointer to the quota block for this object
    //

    QuotaInfo = OBJECT_HEADER_TO_QUOTA_INFO( ObjectHeader );

    *NewObject = FALSE;

    //
    //  If the object is new then we have work to do otherwise
    //  we'll return with NewObject set to false
    //

    if (ObjectHeader->Flags & OB_FLAG_NEW_OBJECT) {

        //
        //  Say the object now isn't new
        //

        ObjectHeader->Flags &= ~OB_FLAG_NEW_OBJECT;

        //
        //  If there does exist a quota info structure for this
        //  object then calculate what our charge should be from
        //  the information stored in that structure
        //

        if (QuotaInfo != NULL) {

            PagedPoolCharge = QuotaInfo->PagedPoolCharge +
                              QuotaInfo->SecurityDescriptorCharge;
            NonPagedPoolCharge = QuotaInfo->NonPagedPoolCharge;

        } else {

            //
            //  There isn't any quota information so we're on our own
            //  Paged pool charge is the default for the object plus
            //  the security descriptor if present.  Nonpaged pool charge
            //  is the default for the object.
            //

            PagedPoolCharge = ObjectType->TypeInfo.DefaultPagedPoolCharge;

            if (ObjectHeader->SecurityDescriptor != NULL) {

                ObjectHeader->Flags |= OB_FLAG_DEFAULT_SECURITY_QUOTA;
                PagedPoolCharge += SE_DEFAULT_SECURITY_QUOTA;
            }

            NonPagedPoolCharge = ObjectType->TypeInfo.DefaultNonPagedPoolCharge;
        }

        //
        //  Now charge for the quota and make sure it succeeds
        //

        ObjectHeader->QuotaBlockCharged = (PVOID)PsChargeSharedPoolQuota( PsGetCurrentProcess(),
                                                                          PagedPoolCharge,
                                                                          NonPagedPoolCharge );

        if (ObjectHeader->QuotaBlockCharged == NULL) {

            return STATUS_QUOTA_EXCEEDED;
        }

        *NewObject = TRUE;
    }

    return STATUS_SUCCESS;
}


VOID
ObpDecrementHandleCount (
    PEPROCESS Process,
    POBJECT_HEADER ObjectHeader,
    POBJECT_TYPE ObjectType,
    ACCESS_MASK GrantedAccess
    )

/*++

Routine Description:

    This procedure decrements the handle count for the specified object

Arguments:

    Process - Supplies the process where the handle existed

    ObjectHeader - Supplies a pointer to the object header for the object

    ObjectType - Supplies a type of the object

    GrantedAccess - Supplies the current access mask to the object

Return Value:

    None.

--*/

{
    POBJECT_HEADER_HANDLE_INFO HandleInfo;
    POBJECT_HANDLE_COUNT_DATABASE HandleCountDataBase;
    POBJECT_HANDLE_COUNT_ENTRY HandleCountEntry;
    PVOID Object;
    ULONG CountEntries;
    ULONG ProcessHandleCount;
    ULONG_PTR SystemHandleCount;
    LOGICAL HandleCountIsZero;

    PAGED_CODE();


    Object = (PVOID)&ObjectHeader->Body;

    ProcessHandleCount = 0;

    ObpLockObject( ObjectHeader );

    SystemHandleCount = ObjectHeader->HandleCount;

    //
    //  Decrement the handle count and it was one and it
    //  was an exclusive object then zero out the exclusive
    //  process
    //

    HandleCountIsZero = ObpDecrHandleCount( ObjectHeader );

    if ( HandleCountIsZero &&
        (ObjectHeader->Flags & OB_FLAG_EXCLUSIVE_OBJECT)) {

        OBJECT_HEADER_TO_QUOTA_INFO( ObjectHeader )->ExclusiveProcess = NULL;
    }

    //
    //  If the object maintains a handle count database then
    //  search through the handle database and decrement
    //  the necessary information
    //

    if (ObjectType->TypeInfo.MaintainHandleCount) {

        HandleInfo = OBJECT_HEADER_TO_HANDLE_INFO( ObjectHeader );

        //
        //  Check if there is a single handle entry, then it better
        //  be ours
        //

        if (ObjectHeader->Flags & OB_FLAG_SINGLE_HANDLE_ENTRY) {

            ASSERT(HandleInfo->SingleEntry.Process == Process);
            ASSERT(HandleInfo->SingleEntry.HandleCount > 0);

            ProcessHandleCount = HandleInfo->SingleEntry.HandleCount--;
            HandleCountEntry = &HandleInfo->SingleEntry;

        } else {

            //
            //  Otherwise search the database for a process match
            //

            HandleCountDataBase = HandleInfo->HandleCountDataBase;

            if (HandleCountDataBase != NULL) {

                CountEntries = HandleCountDataBase->CountEntries;
                HandleCountEntry = &HandleCountDataBase->HandleCountEntries[ 0 ];

                while (CountEntries) {

                    if ((HandleCountEntry->HandleCount != 0) &&
                        (HandleCountEntry->Process == Process)) {

                        ProcessHandleCount = HandleCountEntry->HandleCount--;

                        break;
                    }

                    HandleCountEntry++;
                    CountEntries--;
                }
            }
            else {
                HandleCountEntry = NULL;
            }
        }

        //
        //  Now if the process is giving up all handles to the object
        //  then zero out the handle count entry.  For a single handle
        //  entry this is just the single entry in the header handle info
        //  structure
        //

        if (ProcessHandleCount == 1) {

            HandleCountEntry->Process = NULL;
            HandleCountEntry->HandleCount = 0;
        }
    }

    ObpUnlockObject( ObjectHeader );

    //
    //  If the Object Type has a Close Procedure, then release the type
    //  mutex before calling it, and then call ObpDeleteNameCheck without
    //  the mutex held.
    //

    if (ObjectType->TypeInfo.CloseProcedure) {

#if DBG
        KIRQL SaveIrql;
#endif

        ObpBeginTypeSpecificCallOut( SaveIrql );

        (*ObjectType->TypeInfo.CloseProcedure)( Process,
                                                Object,
                                                GrantedAccess,
                                                ProcessHandleCount,
                                                SystemHandleCount );

        ObpEndTypeSpecificCallOut( SaveIrql, "Close", ObjectType, Object );

    }

    ObpDeleteNameCheck( Object );

    InterlockedDecrement((PLONG)&ObjectType->TotalNumberOfHandles);

    return;
}


NTSTATUS
ObpCreateHandle (
    IN OB_OPEN_REASON OpenReason,
    IN PVOID Object,
    IN POBJECT_TYPE ExpectedObjectType OPTIONAL,
    IN PACCESS_STATE AccessState,
    IN ULONG ObjectPointerBias OPTIONAL,
    IN ULONG Attributes,
    IN POBP_LOOKUP_CONTEXT LookupContext,
    IN KPROCESSOR_MODE AccessMode,
    OUT PVOID *ReferencedNewObject OPTIONAL,
    OUT PHANDLE Handle
    )

/*++

Routine Description:

    This function creates a new handle to an existing object

Arguments:

    OpenReason - The reason why we are doing this work

    Object - A pointer to the body of the new object

    ExpectedObjectType - Optionally Supplies the object type that
        the caller is expecting

    AccessState - Supplies the access state for the handle requested
        by the caller

    ObjectPointerBias - Optionally supplies a count of addition
        increments we do to the pointer count for the object

    Attributes -  Desired attributes for the handle

    DirectoryLocked - Indicates if the root directory mutex is already held

    AccessMode - Supplies the mode of the requestor.

    ReferencedNewObject - Optionally receives a pointer to the body
        of the new object

    Handle - Receives the new handle value

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    PVOID ObjectTable;
    HANDLE_TABLE_ENTRY ObjectTableEntry;
    HANDLE NewHandle;
    ACCESS_MASK DesiredAccess;
    ACCESS_MASK GrantedAccess;
    BOOLEAN AttachedToProcess = FALSE;
    BOOLEAN KernelHandle = FALSE;
    KAPC_STATE ApcState;
    HANDLE_TABLE_ENTRY_INFO ObjectInfo;

    PAGED_CODE();

    ObpValidateIrql( "ObpCreateHandle" );

    //
    //  Get a pointer to the object header and object type
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;

    //
    //  If the object type isn't what was expected then
    //  return an error to our caller, but first see if
    //  we should release the directory mutex
    //

    if ((ARGUMENT_PRESENT( ExpectedObjectType )) &&
        (ObjectType != ExpectedObjectType )) {

        if (LookupContext) {
            ObpReleaseLookupContext( LookupContext );
        }

        return( STATUS_OBJECT_TYPE_MISMATCH );
    }

    //
    //  Set the first ulong of the object table entry to point
    //  back to the object header
    //

    ObjectTableEntry.Object = ObjectHeader;

    //
    //  Now get a pointer to the object table for either the current process
    //  of the kernel handle table. OBJ_KERNEL_HANDLE dropped for user mode on capture.
    //

    if ((Attributes & OBJ_KERNEL_HANDLE) /* && (AccessMode == KernelMode) */) {

        ObjectTable = ObpKernelHandleTable;
        KernelHandle = TRUE;

        //
        //  Go to the system process if we have to
        //

        if (PsGetCurrentProcess() != PsInitialSystemProcess) {
            KeStackAttachProcess (&PsInitialSystemProcess->Pcb, &ApcState);
            AttachedToProcess = TRUE;
        }


    } else {

        ObjectTable = ObpGetObjectTable();
    }

    //
    //  ObpIncrementHandleCount will perform access checking on the
    //  object being opened as appropriate.
    //

    Status = ObpIncrementHandleCount( OpenReason,
                                      PsGetCurrentProcess(),
                                      Object,
                                      ObjectType,
                                      AccessState,
                                      AccessMode,
                                      Attributes );

    if (AccessState->GenerateOnClose) {

        Attributes |= OBJ_AUDIT_OBJECT_CLOSE;
    }

    //
    //  Or in some low order bits into the first ulong of the object
    //  table entry
    //

    ObjectTableEntry.ObAttributes |= (Attributes & OBJ_HANDLE_ATTRIBUTES);

    //
    //  Merge both the remaining desired access and the currently
    //  granted access states into one mask and then compute
    //  the granted access
    //

    DesiredAccess = AccessState->RemainingDesiredAccess |
                    AccessState->PreviouslyGrantedAccess;

    GrantedAccess = DesiredAccess &
                    (ObjectType->TypeInfo.ValidAccessMask | ACCESS_SYSTEM_SECURITY );

    //
    // AccessState->PreviouslyGrantedAccess is used for success audits in SeAuditHandleCreation() which uses it in calls
    // to SepAdtPrivilegeObjectAuditAlarm() and SepAdtOpenObjectAuditAlarm().  Sanitize any bad bits from it.
    //

    AccessState->PreviouslyGrantedAccess = GrantedAccess;

    //
    //  Compute and save away the audit mask for this object
    //  (if one exists).  Note we only do this if the GenerateOnClose
    //  flag comes back in the access state, because this tells us
    //  that the audit is a result of what is in the SACL.
    //

    ObjectInfo.AuditMask = ((PAUX_ACCESS_DATA)AccessState->AuxData)->MaximumAuditMask;

    //
    //  Unlock the directory if it is locked and make sure
    //  we've been successful so far
    //
    
    if (LookupContext) {

        ObpReleaseLookupContext( LookupContext );
    }

    if (!NT_SUCCESS( Status )) {

        //
        //  If we are attached to the system process then return
        //  back to our caller
        //

        if (AttachedToProcess) {
            KeUnstackDetachProcess(&ApcState);
            AttachedToProcess = FALSE;
        }

        return( Status );
    }

    //
    //  Bias the pointer count if that is what the caller wanted
    //

    if (ARGUMENT_PRESENT( ObjectPointerBias )) {

        ObpIncrPointerCountEx (ObjectHeader, ObjectPointerBias);

    }

    //
    //  Set the granted access mask in the object table entry (second ulong)
    //

#if i386

    if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

        LONG StackTraceIndex;

        ObjectTableEntry.GrantedAccessIndex = ObpComputeGrantedAccessIndex( GrantedAccess );

        if (AccessMode == KernelMode) {

            StackTraceIndex = RtlLogStackBackTrace();

        } else {

            StackTraceIndex = RtlLogUmodeStackBackTrace();
        }

        //
        //  Save the stack trace only if the index fits the CreatorBackTraceIndex
        //  minus the ProtectOnClose bit
        //

        if (StackTraceIndex < OBP_CREATOR_BACKTRACE_LIMIT) {

            ObjectTableEntry.CreatorBackTraceIndex = (USHORT)StackTraceIndex;
        
        } else {

            ObjectTableEntry.CreatorBackTraceIndex = 0;
        }

    } else {

        ObjectTableEntry.GrantedAccess = GrantedAccess;
    }

#else

    ObjectTableEntry.GrantedAccess = GrantedAccess;

#endif // i386 

    //
    //  Add this new object table entry to the object table for the process
    //

    ObpEncodeProtectClose(ObjectTableEntry);

    NewHandle = ExCreateHandle( ObjectTable, &ObjectTableEntry );

    //
    //  If we didn't get a handle then cleanup after ourselves and return
    //  the error to our caller
    //

    if (NewHandle == NULL) {

        if (ARGUMENT_PRESENT( ObjectPointerBias )) {

            ObpDecrPointerCountEx (ObjectHeader, ObjectPointerBias);

        }

        ObpDecrementHandleCount( PsGetCurrentProcess(),
                                 ObjectHeader,
                                 ObjectType,
                                 GrantedAccess );

        //
        //  If we are attached to the system process then return
        //  back to our caller
        //

        if (AttachedToProcess) {
            KeUnstackDetachProcess(&ApcState);
            AttachedToProcess = FALSE;
        }

        return( STATUS_INSUFFICIENT_RESOURCES );
    }

    if ( ObjectInfo.AuditMask != 0 ) {

        PHANDLE_TABLE_ENTRY HandleTableEntry;
        PKTHREAD CurrentThread;
        
        CurrentThread = KeGetCurrentThread();

        KeEnterCriticalRegionThread( CurrentThread );
        
        //
        //  Make sure it's the same object before setting the handle information.
        //  The user may have closed it immediately after the ExCreateHandle call,
        //  so at this time it may either be invalid or a completely different object.
        //


        HandleTableEntry = ExMapHandleToPointer ( ObjectTable, NewHandle );

        if (HandleTableEntry != NULL) {

            if (((ULONG_PTR)(HandleTableEntry->Object) & ~OBJ_HANDLE_ATTRIBUTES) == (ULONG_PTR)ObjectHeader) {

                ExSetHandleInfo(ObjectTable, NewHandle, &ObjectInfo, TRUE);
            }

            ExUnlockHandleTableEntry( ObjectTable, HandleTableEntry );
        }
        
        KeLeaveCriticalRegionThread( CurrentThread );
    }

    //
    //  We have a new Ex style handle now make it an ob style handle and also
    //  adjust for the kernel handle by setting the sign bit in the handle
    //  value
    //

    if (KernelHandle) {

        NewHandle = EncodeKernelHandle( NewHandle );
    }

    *Handle = NewHandle;

    //
    //  If requested, generate audit messages to indicate that a new handle
    //  has been allocated.
    //
    //  This is the final security operation in the creation/opening of the
    //  object.
    //

    if ( AccessState->GenerateAudit ) {

        SeAuditHandleCreation( AccessState,
                               *Handle );
    }

    if (OpenReason == ObCreateHandle) {

        PAUX_ACCESS_DATA AuxData = AccessState->AuxData;

        if ( ( AuxData->PrivilegesUsed != NULL) && (AuxData->PrivilegesUsed->PrivilegeCount > 0) ) {

            SePrivilegeObjectAuditAlarm( *Handle,
                                         &AccessState->SubjectSecurityContext,
                                         GrantedAccess,
                                         AuxData->PrivilegesUsed,
                                         TRUE,
                                         KeGetPreviousMode() );
        }
    }

    //
    //  If the caller had a pointer bias and wanted the new reference object
    //  then return that value
    //

    if ((ARGUMENT_PRESENT( ObjectPointerBias )) &&
        (ARGUMENT_PRESENT( ReferencedNewObject ))) {

        *ReferencedNewObject = Object;
    }

    //
    //  If we are attached to the system process then return
    //  back to our caller
    //

    if (AttachedToProcess) {
        KeUnstackDetachProcess(&ApcState);
        AttachedToProcess = FALSE;
    }

    //
    //  And return to our caller
    //

    return( STATUS_SUCCESS );
}


NTSTATUS
ObpCreateUnnamedHandle (
    IN PVOID Object,
    IN ACCESS_MASK DesiredAccess,
    IN ULONG ObjectPointerBias OPTIONAL,
    IN ULONG Attributes,
    IN KPROCESSOR_MODE AccessMode,
    OUT PVOID *ReferencedNewObject OPTIONAL,
    OUT PHANDLE Handle
    )

/*++

Routine Description:

    This function creates a new unnamed handle for an existing object

Arguments:

    Object - A pointer to the body of the new object

    DesiredAccess - Supplies the access mask being requsted

    ObjectPointerBias - Optionally supplies a count of addition
        increments we do to the pointer count for the object

    Attributes -  Desired attributes for the handle

    AccessMode - Supplies the mode of the requestor.

    ReferencedNewObject - Optionally receives a pointer to the body
        of the new object

    Handle - Receives the new handle value

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    PVOID ObjectTable;
    HANDLE_TABLE_ENTRY ObjectTableEntry;
    HANDLE NewHandle;
    ACCESS_MASK GrantedAccess;
    BOOLEAN AttachedToProcess = FALSE;
    BOOLEAN KernelHandle = FALSE;
    KAPC_STATE ApcState;

    PAGED_CODE();

    ObpValidateIrql( "ObpCreateUnnamedHandle" );

    //
    //  Get the object header and type for the new object
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;

    //
    //  Set the first ulong of the object table entry to point
    //  to the object header and then or in the low order attribute
    //  bits
    //

    ObjectTableEntry.Object = ObjectHeader;

    ObjectTableEntry.ObAttributes |= (Attributes & OBJ_HANDLE_ATTRIBUTES);

    //
    //  Now get a pointer to the object table for either the current process
    //  of the kernel handle table
    //

    if ((Attributes & OBJ_KERNEL_HANDLE) /* && (AccessMode == KernelMode) */) {

        ObjectTable = ObpKernelHandleTable;
        KernelHandle = TRUE;

        //
        //  Go to the system process if we have to
        //

        if (PsGetCurrentProcess() != PsInitialSystemProcess) {
            KeStackAttachProcess (&PsInitialSystemProcess->Pcb, &ApcState);
            AttachedToProcess = TRUE;
        }

    } else {

        ObjectTable = ObpGetObjectTable();
    }

    //
    //  Increment the handle count, this routine also does the access
    //  check if necessary
    //

    Status = ObpIncrementUnnamedHandleCount( &DesiredAccess,
                                             PsGetCurrentProcess(),
                                             Object,
                                             ObjectType,
                                             AccessMode,
                                             Attributes );


    GrantedAccess = DesiredAccess &
                    (ObjectType->TypeInfo.ValidAccessMask | ACCESS_SYSTEM_SECURITY );

    if (!NT_SUCCESS( Status )) {

        //
        //  If we are attached to the system process then return
        //  back to our caller
        //

        if (AttachedToProcess) {
            KeUnstackDetachProcess(&ApcState);
            AttachedToProcess = FALSE;
        }

        return( Status );
    }

    //
    //  Bias the pointer count if that is what the caller wanted
    //

    if (ARGUMENT_PRESENT( ObjectPointerBias )) {

        ObpIncrPointerCountEx (ObjectHeader, ObjectPointerBias);

    }

    //
    //  Set the granted access mask in the object table entry (second ulong)
    //

#if i386 

    if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

        LONG StackTraceIndex;

        ObjectTableEntry.GrantedAccessIndex = ObpComputeGrantedAccessIndex( GrantedAccess );

        if (AccessMode == KernelMode) {

            StackTraceIndex = RtlLogStackBackTrace();

        } else {

            StackTraceIndex = RtlLogUmodeStackBackTrace();
        }

        //
        //  Save the stack trace only if the index fits the CreatorBackTraceIndex
        //  minus the ProtectOnClose bit
        //

        if (StackTraceIndex < OBP_CREATOR_BACKTRACE_LIMIT) {

            ObjectTableEntry.CreatorBackTraceIndex = (USHORT)StackTraceIndex;

        } else {

            ObjectTableEntry.CreatorBackTraceIndex = 0;
        }

    } else {

        ObjectTableEntry.GrantedAccess = GrantedAccess;
    }

#else

    ObjectTableEntry.GrantedAccess = GrantedAccess;

#endif // i386 

    //
    //  Add this new object table entry to the object table for the process
    //

    ObpEncodeProtectClose(ObjectTableEntry);

    NewHandle = ExCreateHandle( ObjectTable, &ObjectTableEntry );

    //
    //  If we didn't get a handle then cleanup after ourselves and return
    //  the error to our caller
    //

    if (NewHandle == NULL) {

        if (ARGUMENT_PRESENT( ObjectPointerBias )) {

            ObpDecrPointerCountEx (ObjectHeader, ObjectPointerBias);
        }

        ObpDecrementHandleCount( PsGetCurrentProcess(),
                                 ObjectHeader,
                                 ObjectType,
                                 GrantedAccess );

        //
        //  If we are attached to the system process then return
        //  back to our caller
        //

        if (AttachedToProcess) {
            KeUnstackDetachProcess(&ApcState);
            AttachedToProcess = FALSE;
        }

        return( STATUS_INSUFFICIENT_RESOURCES );
    }

    //
    //  We have a new Ex style handle now make it an ob style handle and also
    //  adjust for the kernel handle by setting the sign bit in the handle
    //  value
    //

    if (KernelHandle) {

        NewHandle = EncodeKernelHandle( NewHandle );
    }

    *Handle = NewHandle;

    //
    //  If the caller had a pointer bias and wanted the new reference object
    //  then return that value
    //

    if ((ARGUMENT_PRESENT( ObjectPointerBias )) &&
        (ARGUMENT_PRESENT( ReferencedNewObject ))) {

        *ReferencedNewObject = Object;
    }

    //
    //  If we are attached to the system process then return
    //  back to our caller
    //

    if (AttachedToProcess) {
        KeUnstackDetachProcess(&ApcState);
        AttachedToProcess = FALSE;
    }

    return( STATUS_SUCCESS );
}


NTSTATUS
ObpValidateDesiredAccess (
    IN ACCESS_MASK DesiredAccess
    )

/*++

Routine Description:

    This routine checks the input desired access mask to see that
    some invalid bits are not set.  The invalid bits are the top
    two reserved bits and the top three standard rights bits.
    See \nt\public\sdk\inc\ntseapi.h for more details.

Arguments:

    DesiredAccess - Supplies the mask being checked

Return Value:

    STATUS_ACCESS_DENIED if one or more of the wrongs bits are set and
    STATUS_SUCCESS otherwise

--*/

{
    if (DesiredAccess & 0x0CE00000) {

        return( STATUS_ACCESS_DENIED );

    } else {

        return( STATUS_SUCCESS );
    }
}


#if i386 

//
//  The following three variables are just performance counters
//  for the following two routines
//

ULONG ObpXXX1;
ULONG ObpXXX2;
ULONG ObpXXX3;

USHORT
ObpComputeGrantedAccessIndex (
    ACCESS_MASK GrantedAccess
    )

/*++

Routine Description:

    This routine takes a granted access and returns and index
    back to our cache of granted access masks.

Arguments:

    GrantedAccess - Supplies the access mask being added to the cache

Return Value:

    USHORT - returns an index in the cache for the input granted access

--*/

{
    ULONG GrantedAccessIndex, n;
    PACCESS_MASK p;
    PKTHREAD CurrentThread;

    ObpXXX1 += 1;

    //
    //  Lock the global data structure
    //

    CurrentThread = KeGetCurrentThread ();

    KeEnterCriticalRegionThread (CurrentThread);
    ExAcquirePushLockExclusive ( &ObpLock );

    n = ObpCurCachedGrantedAccessIndex;
    p = ObpCachedGrantedAccesses;

    //
    //  For each index in our cache look for a match and if found
    //  then unlock the data structure and return that index
    //

    for (GrantedAccessIndex = 0; GrantedAccessIndex < n; GrantedAccessIndex++, p++ ) {

        ObpXXX2 += 1;

        if (*p == GrantedAccess) {

            ExReleasePushLockExclusive ( &ObpLock );
            KeLeaveCriticalRegionThread (CurrentThread);
            return (USHORT)GrantedAccessIndex;
        }
    }

    //
    //  We didn't find a match now see if we've maxed out the cache
    //

    if (ObpCurCachedGrantedAccessIndex == ObpMaxCachedGrantedAccessIndex) {

        DbgPrint( "OB: GrantedAccess cache limit hit.\n" );
        DbgBreakPoint();
    }

    //
    //  Set the granted access to the next free slot and increment the
    //  number used in the cache, release the lock, and return the
    //  new index to our caller
    //

    *p = GrantedAccess;
    ObpCurCachedGrantedAccessIndex += 1;

    ExReleasePushLockExclusive ( &ObpLock );
    KeLeaveCriticalRegionThread (CurrentThread);

    return (USHORT)GrantedAccessIndex;
}

ACCESS_MASK
ObpTranslateGrantedAccessIndex (
    USHORT GrantedAccessIndex
    )

/*++

Routine Description:

    This routine takes as input a cache index and returns
    the corresponding granted access mask

Arguments:

    GrantedAccessIndex - Supplies the cache index to look up

Return Value:

    ACCESS_MASK - Returns the corresponding desired access mask

--*/

{
    ACCESS_MASK GrantedAccess = (ACCESS_MASK)0;
    PKTHREAD CurrentThread;

    ObpXXX3 += 1;

    //
    //  Lock the global data structure
    //

    CurrentThread = KeGetCurrentThread ();

    KeEnterCriticalRegionThread (CurrentThread);
    ExAcquirePushLockExclusive ( &ObpLock );

    //
    //  If the input index is within bounds then get the granted
    //  access
    //

    if (GrantedAccessIndex < ObpCurCachedGrantedAccessIndex) {

        GrantedAccess = ObpCachedGrantedAccesses[ GrantedAccessIndex ];
    }

    //
    //  Release the lock and return the granted access to our caller
    //

    ExReleasePushLockExclusive ( &ObpLock );
    KeLeaveCriticalRegionThread (CurrentThread);

    return GrantedAccess;
}

#endif // i386
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obclose.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obclose.c

Abstract:

    Object close system service

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,NtMakeTemporaryObject)
#pragma alloc_text(PAGE,NtClose)
#pragma alloc_text(PAGE,ObMakeTemporaryObject)
#pragma alloc_text(PAGE,ObpCloseHandleTableEntry)
#pragma alloc_text(PAGE,ObCloseHandle)
#pragma alloc_text(PAGE,ObpCloseHandle)
#endif

//
//  Indicates if auditing is enabled so we have to close down the object
//  audit alarm
//

extern BOOLEAN SepAdtAuditingEnabled;

NTSTATUS
ObpCloseHandleTableEntry (
    IN PHANDLE_TABLE ObjectTable,
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE Handle,
    IN KPROCESSOR_MODE PreviousMode,
    IN BOOLEAN Rundown
    )
/*++

Routine Description:

    This function is used to close a handle table entry

Arguments:

    ObjectTableEntry - Supplies the entry being closed. It must be locked
    PreviousMode     - Mode of caller
    Rundown          - Called as part of process rundown, ignore protected handles in this mode

Return Value:

    NTSTATUS.

--*/
{
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    PVOID Object;
    ULONG CapturedGrantedAccess;
    ULONG CapturedAttributes;
    #if DBG
    KIRQL SaveIrql;
    #endif // DBG

    //
    //  From the object table entry we can grab a pointer to the object
    //  header, get its type and its body
    //

    ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);
    ObjectType = ObjectHeader->Type;
    Object = &ObjectHeader->Body;

    //
    //  If the object type specifies an okay to close procedure then we
    //  need to invoke that callback.  If the callback doesn't want us to
    //  close handle then unlock the object table and return the error
    //  to our caller
    //

    if (ObjectType->TypeInfo.OkayToCloseProcedure != NULL) {

        ObpBeginTypeSpecificCallOut( SaveIrql );

        if (!(*ObjectType->TypeInfo.OkayToCloseProcedure)( PsGetCurrentProcess(),
                                                           Object,
                                                           Handle,
                                                           PreviousMode )) {

            ObpEndTypeSpecificCallOut( SaveIrql, "NtClose", ObjectType, Object );

            ExUnlockHandleTableEntry( ObjectTable, ObjectTableEntry );

            return STATUS_HANDLE_NOT_CLOSABLE;
        }

        ObpEndTypeSpecificCallOut( SaveIrql, "NtClose", ObjectType, Object );
    }

    CapturedAttributes = ObpGetHandleAttributes(ObjectTableEntry);

    //
    //  If the previous mode was user and the handle is protected from
    //  being closed, then we'll either raise or return an error depending
    //  on the global flags and debugger port situation.
    //

    if ((CapturedAttributes & OBJ_PROTECT_CLOSE) != 0 && Rundown == FALSE) {

        if (PreviousMode != KernelMode) {

            ExUnlockHandleTableEntry( ObjectTable, ObjectTableEntry );

            if (!KeIsAttachedProcess() &&
                ((NtGlobalFlag & FLG_ENABLE_CLOSE_EXCEPTIONS) ||
                 (PsGetCurrentProcess()->DebugPort != NULL) ||
                 (ObjectTable->DebugInfo != NULL))) {

                //
                //  Raise and exception in user mode
                //
                return KeRaiseUserException(STATUS_HANDLE_NOT_CLOSABLE);

            } else {

                return STATUS_HANDLE_NOT_CLOSABLE;
            }

        } else {
            KeBugCheckEx(INVALID_KERNEL_HANDLE, (ULONG_PTR)Handle, 0, 0, 0);
        }
    }
    
    //
    //  Get the granted access for the handle
    //

#if i386 

    if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

        CapturedGrantedAccess = ObpTranslateGrantedAccessIndex( ObjectTableEntry->GrantedAccessIndex );

    } else {

        CapturedGrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);
    }

#else

    CapturedGrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);

#endif // i386 

    //
    //  Now remove the handle from the handle table
    //

    ExDestroyHandle( ObjectTable,
                     Handle,
                     ObjectTableEntry );

    //
    //  perform any auditing required
    //

    //
    //  Extract the value of the GenerateOnClose bit stored
    //  after object open auditing is performed.  This value
    //  was stored by a call to ObSetGenerateOnClosed.
    //

    if (CapturedAttributes & OBJ_AUDIT_OBJECT_CLOSE) {

        if ( SepAdtAuditingEnabled ) {

            SeCloseObjectAuditAlarm( Object,
                                     (HANDLE)((ULONG_PTR)Handle & ~OBJ_HANDLE_TAGBITS),  // Mask off the tagbits defined for OB objects.
                                     TRUE );
        }
    }

    //
    //  Since we took the handle away we need to decrement the objects
    //  handle count, and remove a reference
    //

    ObpDecrementHandleCount( PsGetCurrentProcess(),
                             ObjectHeader,
                             ObjectType,
                             CapturedGrantedAccess );

    ObDereferenceObject( Object );

    //
    //  And return to our caller
    //

    return STATUS_SUCCESS;
}


NTSTATUS
ObpCloseHandle (
    IN HANDLE Handle,
    IN KPROCESSOR_MODE PreviousMode
    )
/*++

Routine Description:

    This function is used to close access to the specified handle with the given mode

Arguments:

    Handle - Supplies the handle being closed
    PreviousMode - Processor mode to be used in the handle access checks.
    CanNotRaise - We are not allowed to do a user mode raise.

Return Value:

    An appropriate status value

--*/
{
    PHANDLE_TABLE ObjectTable;
    PHANDLE_TABLE_ENTRY ObjectTableEntry;
    NTSTATUS Status;
    BOOLEAN AttachedToProcess = FALSE;
    KAPC_STATE ApcState;
    PETHREAD CurrentThread;
    PEPROCESS CurrentProcess;


    ObpValidateIrql( "NtClose" );

    CurrentThread = PsGetCurrentThread ();
    CurrentProcess = PsGetCurrentProcessByThread (CurrentThread);
    //
    //  For the current process we will grab its handle/object table and
    //  translate the handle to its corresponding table entry.  If the
    //  call is successful it also lock down the handle table.  But first
    //  check for a kernel handle and attach and use that table if so.
    //

    if (IsKernelHandle( Handle, PreviousMode ))  {

        Handle = DecodeKernelHandle( Handle );

        ObjectTable = ObpKernelHandleTable;

        //
        //  Go to the system process if we have to
        //
        if (CurrentProcess != PsInitialSystemProcess) {
           KeStackAttachProcess (&PsInitialSystemProcess->Pcb, &ApcState);
           AttachedToProcess = TRUE;
        }

    } else {

        ObjectTable = CurrentProcess->ObjectTable;
    }

    //
    //  Protect ourselves from being interrupted while we hold a handle table
    //  entry lock
    //

    KeEnterCriticalRegionThread(&CurrentThread->Tcb);

    ObjectTableEntry = ExMapHandleToPointer( ObjectTable,
                                             Handle );

    //
    //  Check that the specified handle is legitimate otherwise we can
    //  assume the caller just passed in some bogus handle value
    //

    if (ObjectTableEntry != NULL) {

        Status = ObpCloseHandleTableEntry (ObjectTable, ObjectTableEntry, Handle, PreviousMode, FALSE);

        KeLeaveCriticalRegionThread(&CurrentThread->Tcb);
        //
        //  If we are attached to the system process then detach
        //
        if (AttachedToProcess) {

            KeUnstackDetachProcess(&ApcState);
            AttachedToProcess = FALSE;
        }


    } else {

        KeLeaveCriticalRegionThread(&CurrentThread->Tcb);

        //
        //  At this point the input handle did not translate to a valid
        //  object table entry
        //

        //
        //  If we are attached to the system process then return
        //  back to our caller
        //

        if (AttachedToProcess) {
            KeUnstackDetachProcess(&ApcState);
            AttachedToProcess = FALSE;
        }

        //
        //  Now if the handle is not null and it does not represent the
        //  current thread or process then if we're user mode we either raise
        //  or return an error
        //

        if ((Handle != NULL) &&
            (Handle != NtCurrentThread()) &&
            (Handle != NtCurrentProcess())) {

            if (PreviousMode != KernelMode) {

                if ((NtGlobalFlag & FLG_ENABLE_CLOSE_EXCEPTIONS) ||
                    (CurrentProcess->DebugPort != NULL) ||
                    (ObjectTable->DebugInfo != NULL)) {

                    if (!KeIsAttachedProcess()) {
                        return KeRaiseUserException (STATUS_INVALID_HANDLE);
                    } else {
                        return STATUS_INVALID_HANDLE;
                    }

                }

            } else {

                //
                //  bugcheck here if kernel debugger is enabled and if kernel mode code is
                //  closing a bogus handle and process is not exiting.  Ignore
                //  if no PEB as this occurs if process is killed before
                //  really starting.
                //

                if ((!PsIsThreadTerminating(CurrentThread)) &&
                    (CurrentProcess->Peb != NULL)) {

                    if (KdDebuggerEnabled) {
                        KeBugCheckEx(INVALID_KERNEL_HANDLE, (ULONG_PTR)Handle, 1, 0, 0);
                    }
                }

            }
        }

        Status = STATUS_INVALID_HANDLE;
    }


    return Status;
}

NTSTATUS
ObCloseHandle (
    IN HANDLE Handle,
    IN KPROCESSOR_MODE PreviousMode
    )
/*++

Routine Description:

    This function is used to close access to the specified handle with the given mode

Arguments:

    Handle - Supplies the handle being closed
    PreviousMode - Processor mode to be used in the handle access checks.

Return Value:

    An appropriate status value

--*/
{
    return ObpCloseHandle (Handle,
                           PreviousMode);
}


NTSTATUS
NtClose (
    IN HANDLE Handle
    )

/*++

Routine Description:

    This function is used to close access to the specified handle

Arguments:

    Handle - Supplies the handle being closed

Return Value:

    An appropriate status value

--*/

{
    return ObpCloseHandle (Handle,
                           KeGetPreviousMode ());
}


NTSTATUS
NtMakeTemporaryObject (
    IN HANDLE Handle
    )

/*++

Routine Description:

    This routine makes the specified object non permanent.

Arguments:

    Handle - Supplies a handle to the object being modified

Return Value:

    An appropriate status value.

--*/

{
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;
    PVOID Object;
    OBJECT_HANDLE_INFORMATION HandleInformation;

    PAGED_CODE();

    //
    //  Get previous processor mode and probe output argument if necessary.
    //

    PreviousMode = KeGetPreviousMode();

    Status = ObReferenceObjectByHandle( Handle,
                                        DELETE,
                                        (POBJECT_TYPE)NULL,
                                        PreviousMode,
                                        &Object,
                                        &HandleInformation );
    if (!NT_SUCCESS( Status )) {

        return( Status );
    }

    //
    //  Make the object temporary.  Note that the object should still
    //  have a name and directory entry because its handle count is not
    //  zero
    //

    ObMakeTemporaryObject( Object );

    //
    //  Check if we need to generate a delete object audit/alarm
    //

    if (HandleInformation.HandleAttributes & OBJ_AUDIT_OBJECT_CLOSE) {

        SeDeleteObjectAuditAlarm( Object,
                                  Handle );
    }

    ObDereferenceObject( Object );

    return( Status );
}


VOID
ObMakeTemporaryObject (
    IN PVOID Object
    )

/*++

Routine Description:

    This routine removes the name of the object from its parent
    directory.  The object is only removed if it has a non zero
    handle count and a name.  Otherwise the object is simply
    made non permanent

Arguments:

    Object - Supplies the object being modified

Return Value:

    None.

--*/

{
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;

    PAGED_CODE();


    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;

    //
    // Other bits are set in this flags field by the handle database code. Synchronise with that.
    //
    ObpLockObject( ObjectHeader );

    ObjectHeader->Flags &= ~OB_FLAG_PERMANENT_OBJECT;

    ObpUnlockObject( ObjectHeader );

    //
    // Now delete the object name if no more handles are present.
    //
    ObpDeleteNameCheck( Object );

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obcreate.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obcreate.c

Abstract:

    Object creation

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"

#undef ObCreateObject

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, ObCreateObject)
#pragma alloc_text(PAGE, ObpCaptureObjectCreateInformation)
#pragma alloc_text(PAGE, ObpCaptureObjectName)
#pragma alloc_text(PAGE, ObpAllocateObjectNameBuffer)
#pragma alloc_text(PAGE, ObpFreeObjectNameBuffer)
#pragma alloc_text(PAGE, ObDeleteCapturedInsertInfo)
#pragma alloc_text(PAGE, ObpAllocateObject)
#pragma alloc_text(PAGE, ObpFreeObject)
#pragma alloc_text(PAGE, ObFreeObjectCreateInfoBuffer)
#endif


#if DBG

BOOLEAN ObWatchHandles = FALSE;

//
//  The following variable is only used on a checked build to control
//  echoing out the allocs and frees of objects
//

BOOLEAN ObpShowAllocAndFree;
#else

const BOOLEAN ObWatchHandles = FALSE;

#endif

//
//  Local performance counters
//

#if DBG
ULONG ObpObjectsCreated;
ULONG ObpObjectsWithPoolQuota;
ULONG ObpObjectsWithHandleDB;
ULONG ObpObjectsWithName;
ULONG ObpObjectsWithCreatorInfo;
#endif // DBG

C_ASSERT ( (FIELD_OFFSET (OBJECT_HEADER, Body) % MEMORY_ALLOCATION_ALIGNMENT) == 0 );
C_ASSERT ( (sizeof (OBJECT_HEADER_CREATOR_INFO) % MEMORY_ALLOCATION_ALIGNMENT) == 0 );
C_ASSERT ( (sizeof (OBJECT_HEADER_NAME_INFO) % MEMORY_ALLOCATION_ALIGNMENT) == 0 );
C_ASSERT ( (sizeof (OBJECT_HEADER_QUOTA_INFO) % MEMORY_ALLOCATION_ALIGNMENT) == 0 );


NTSTATUS
ObCreateObject (
    IN KPROCESSOR_MODE ProbeMode,
    IN POBJECT_TYPE ObjectType,
    IN POBJECT_ATTRIBUTES ObjectAttributes OPTIONAL,
    IN KPROCESSOR_MODE OwnershipMode,
    IN OUT PVOID ParseContext OPTIONAL,
    IN ULONG ObjectBodySize,
    IN ULONG PagedPoolCharge,
    IN ULONG NonPagedPoolCharge,
    OUT PVOID *Object
    )

/*++

Routine Description:

    This functions allocates space for an NT Object from either
    Paged or NonPaged pool. It captures the optional name and
    SECURITY_DESCRIPTOR parameters for later use when the object is
    inserted into an object table.  No quota is charged at this time.
    That occurs when the object is inserted into an object table.

Arguments:

    ProbeMode - The processor mode to consider when doing a probe
        of the input parameters

    ObjectType - A pointer of the type returned by ObCreateObjectType
        that gives the type of object being created.

    ObjectAttributes - Optionally supplies the attributes of the object
        being created (such as its name)

    OwnershipMode - The processor mode of who is going to own the object

    ParseContext - Ignored

    ObjectBodySize - Number of bytes to allocate for the object body.  The
        object body immediately follows the object header in memory and are
        part of a single allocation.

    PagedPoolCharge - Supplies the amount of paged pool to charge for the
        object.  If zero is specified then the default charge for the object
        type is used.

    NonPagedPoolCharge - Supplies the amount of nonpaged pool to charge for
        the object.  If zero is specified then the default charge for the
        object type is used.

    Object - Receives a pointer to the newly created object

Return Value:

    Following errors can occur:

        - invalid object type
        - insufficient memory

--*/

{
    UNICODE_STRING CapturedObjectName;
    POBJECT_CREATE_INFORMATION ObjectCreateInfo;
    POBJECT_HEADER ObjectHeader;
    NTSTATUS Status;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (ParseContext);

    //
    //  Allocate a buffer to capture the object creation information.
    //

    ObjectCreateInfo = ObpAllocateObjectCreateInfoBuffer();

    if (ObjectCreateInfo == NULL) {

        Status = STATUS_INSUFFICIENT_RESOURCES;

    } else {

        //
        //  Capture the object attributes, quality of service, and object
        //  name, if specified. Otherwise, initialize the captured object
        //  name, the security quality of service, and the create attributes
        //  to default values.
        //

        Status = ObpCaptureObjectCreateInformation( ObjectType,
                                                    ProbeMode,
                                                    OwnershipMode,
                                                    ObjectAttributes,
                                                    &CapturedObjectName,
                                                    ObjectCreateInfo,
                                                    FALSE );

        if (NT_SUCCESS(Status)) {

            //
            //  If the creation attributes are invalid, then return an error
            //  status.
            //

            if (ObjectType->TypeInfo.InvalidAttributes & ObjectCreateInfo->Attributes) {

                Status = STATUS_INVALID_PARAMETER;

            } else {

                //
                //  Set the paged and nonpaged pool quota charges for the
                //  object allocation.
                //

                if (PagedPoolCharge == 0) {

                    PagedPoolCharge = ObjectType->TypeInfo.DefaultPagedPoolCharge;
                }

                if (NonPagedPoolCharge == 0) {

                    NonPagedPoolCharge = ObjectType->TypeInfo.DefaultNonPagedPoolCharge;
                }

                ObjectCreateInfo->PagedPoolCharge = PagedPoolCharge;
                ObjectCreateInfo->NonPagedPoolCharge = NonPagedPoolCharge;

                //
                //  Allocate and initialize the object.
                //

                Status = ObpAllocateObject( ObjectCreateInfo,
                                            OwnershipMode,
                                            ObjectType,
                                            &CapturedObjectName,
                                            ObjectBodySize,
                                            &ObjectHeader );

                if (NT_SUCCESS(Status)) {

                    //
                    //  If a permanent object is being created, then check if
                    //  the caller has the appropriate privilege.
                    //

                    *Object = &ObjectHeader->Body;

                    if (ObjectHeader->Flags & OB_FLAG_PERMANENT_OBJECT) {

                        if (!SeSinglePrivilegeCheck( SeCreatePermanentPrivilege,
                                                     ProbeMode)) {

                            ObpFreeObject(*Object);

                            Status = STATUS_PRIVILEGE_NOT_HELD;
                        }
                    }

#ifdef POOL_TAGGING
                    if (ObpTraceEnabled && NT_SUCCESS(Status)) {

                        //
                        //  Register the object and push stack information for the
                        //  first reference
                        //

                        ObpRegisterObject( ObjectHeader );
                        ObpPushStackInfo( ObjectHeader, TRUE );
                    }
#endif //POOL_TAGGING

                    //
                    //  Here is the only successful path out of this module but
                    //  this path can also return privilege not held.  In the 
                    //  error case, all the resources have already been freed
                    //  by ObpFreeObject.
                    //

                    return Status;
                }
            }

            //
            //  An error path, free the create information.
            //

            ObpReleaseObjectCreateInformation(ObjectCreateInfo);

            if (CapturedObjectName.Buffer != NULL) {

                ObpFreeObjectNameBuffer(&CapturedObjectName);
            }
        }

        //
        //  An error path, free object creation information buffer.
        //

        ObpFreeObjectCreateInfoBuffer(ObjectCreateInfo);
    }

    //
    //  An error path
    //

    return Status;
}


NTSTATUS
ObpCaptureObjectCreateInformation (
    IN POBJECT_TYPE ObjectType OPTIONAL,
    IN KPROCESSOR_MODE ProbeMode,
    IN KPROCESSOR_MODE CreatorMode,
    IN POBJECT_ATTRIBUTES ObjectAttributes,
    IN OUT PUNICODE_STRING CapturedObjectName,
    IN POBJECT_CREATE_INFORMATION ObjectCreateInfo,
    IN LOGICAL UseLookaside
    )

/*++

Routine Description:

    This function captures the object creation information and stuff
    it into the input variable ObjectCreateInfo

Arguments:

    ObjectType - Specifies the type of object we expect to capture,
        currently ignored.

    ProbeMode - Specifies the processor mode for doing our parameter
        probes

    CreatorMode - Specifies the mode the object is being created for

    ObjectAttributes - Supplies the object attributes we are trying
        to capture

    CapturedObjectName - Recieves the name of the object being created

    ObjectCreateInfo - Receives the create information for the object
        like its root, attributes, and security information

    UseLookaside - Specifies if we are to allocate the captured name
        buffer from the lookaside list or from straight pool.

Return Value:

    An appropriate status value

--*/

{
    PUNICODE_STRING ObjectName;
    PSECURITY_DESCRIPTOR SecurityDescriptor;
    PSECURITY_QUALITY_OF_SERVICE SecurityQos;
    NTSTATUS Status;
    ULONG Size;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (ObjectType);

    //
    //  Capture the object attributes, the security quality of service, if
    //  specified, and object name, if specified.
    //

    Status = STATUS_SUCCESS;

    RtlZeroMemory(ObjectCreateInfo, sizeof(OBJECT_CREATE_INFORMATION));

    try {

        if (ARGUMENT_PRESENT(ObjectAttributes)) {

            //
            //  Probe the object attributes if necessary.
            //

            if (ProbeMode != KernelMode) {

                ProbeForReadSmallStructure( ObjectAttributes,
                                            sizeof(OBJECT_ATTRIBUTES),
                                            sizeof(ULONG_PTR) );
            }

            if (ObjectAttributes->Length != sizeof(OBJECT_ATTRIBUTES) ||
                (ObjectAttributes->Attributes & ~OBJ_VALID_ATTRIBUTES)) {

                Status = STATUS_INVALID_PARAMETER;

                goto failureExit;
            }

            //
            //  Capture the object attributes.
            //

            ObjectCreateInfo->RootDirectory = ObjectAttributes->RootDirectory;
            ObjectCreateInfo->Attributes = ObjectAttributes->Attributes & OBJ_VALID_ATTRIBUTES;
            //
            // Remove privileged option if passed in from user mode
            //
            if (CreatorMode != KernelMode) {
                ObjectCreateInfo->Attributes &= ~OBJ_KERNEL_HANDLE;
            } else if (ObWatchHandles) {
                if ((ObjectCreateInfo->Attributes&OBJ_KERNEL_HANDLE) == 0 &&
                    PsGetCurrentProcess() != PsInitialSystemProcess) {
                    DbgBreakPoint ();
                }
            }
            ObjectName = ObjectAttributes->ObjectName;
            SecurityDescriptor = ObjectAttributes->SecurityDescriptor;
            SecurityQos = ObjectAttributes->SecurityQualityOfService;

            if (ARGUMENT_PRESENT(SecurityDescriptor)) {

                Status = SeCaptureSecurityDescriptor( SecurityDescriptor,
                                                      ProbeMode,
                                                      PagedPool,
                                                      TRUE,
                                                      &ObjectCreateInfo->SecurityDescriptor );

                if (!NT_SUCCESS(Status)) {

                    KdPrint(( "OB: Failed to capture security descriptor at %08x - Status == %08x\n",
                              SecurityDescriptor,
                              Status) );

                    //
                    //  The cleanup routine depends on this being NULL if it isn't
                    //  allocated.  SeCaptureSecurityDescriptor may modify this
                    //  parameter even if it fails.
                    //

                    ObjectCreateInfo->SecurityDescriptor = NULL;

                    goto failureExit;
                }

                SeComputeQuotaInformationSize(  ObjectCreateInfo->SecurityDescriptor,
                                                &Size );

                ObjectCreateInfo->SecurityDescriptorCharge = SeComputeSecurityQuota( Size );
                ObjectCreateInfo->ProbeMode = ProbeMode;
            }

            if (ARGUMENT_PRESENT(SecurityQos)) {

                if (ProbeMode != KernelMode) {

                    ProbeForReadSmallStructure( SecurityQos, sizeof(*SecurityQos), sizeof(ULONG));
                }

                ObjectCreateInfo->SecurityQualityOfService = *SecurityQos;
                ObjectCreateInfo->SecurityQos = &ObjectCreateInfo->SecurityQualityOfService;
            }

        } else {

            ObjectName = NULL;
        }

    } except (ExSystemExceptionFilter()) {

        Status = GetExceptionCode();

        goto failureExit;
    }

    //
    //  If an object name is specified, then capture the object name.
    //  Otherwise, initialize the object name descriptor and check for
    //  an incorrectly specified root directory.
    //

    if (ARGUMENT_PRESENT(ObjectName)) {

        Status = ObpCaptureObjectName( ProbeMode,
                                       ObjectName,
                                       CapturedObjectName,
                                       UseLookaside );

    } else {

        CapturedObjectName->Buffer = NULL;
        CapturedObjectName->Length = 0;
        CapturedObjectName->MaximumLength = 0;

        if (ARGUMENT_PRESENT(ObjectCreateInfo->RootDirectory)) {

            Status = STATUS_OBJECT_NAME_INVALID;
        }
    }

    //
    //  If the completion status is not successful, and a security quality
    //  of service parameter was specified, then free the security quality
    //  of service memory.
    //

failureExit:

    if (!NT_SUCCESS(Status)) {

        ObpReleaseObjectCreateInformation(ObjectCreateInfo);
    }

    return Status;
}


NTSTATUS
ObpCaptureObjectName (
    IN KPROCESSOR_MODE ProbeMode,
    IN PUNICODE_STRING ObjectName,
    IN OUT PUNICODE_STRING CapturedObjectName,
    IN LOGICAL UseLookaside
    )

/*++

Routine Description:

    This function captures the object name but first verifies that
    it is at least properly sized.

Arguments:

    ProbeMode - Supplies the processor mode to use when probing
        the object name

    ObjectName - Supplies the caller's version of the object name

    CapturedObjectName - Receives the captured verified version
        of the object name

    UseLookaside - Indicates if the captured name buffer should be
        allocated from the lookaside list or from straight pool

Return Value:

    An appropriate status value

--*/

{
    PWCH FreeBuffer;
    UNICODE_STRING InputObjectName;
    ULONG Length;
    NTSTATUS Status;

    PAGED_CODE();

    //
    //  Initialize the object name descriptor and capture the specified name
    //  string.
    //

    CapturedObjectName->Buffer = NULL;
    CapturedObjectName->Length = 0;
    CapturedObjectName->MaximumLength = 0;

    Status = STATUS_SUCCESS;

    //
    //  Probe and capture the name string descriptor and probe the
    //  name string, if necessary.
    //

    FreeBuffer = NULL;

    try {

        if (ProbeMode != KernelMode) {

            InputObjectName = ProbeAndReadUnicodeString(ObjectName);

            ProbeForRead( InputObjectName.Buffer,
                          InputObjectName.Length,
                          sizeof(WCHAR) );

        } else {

            InputObjectName = *ObjectName;
        }

        //
        //  If the length of the string is not zero, then capture the string.
        //

        if (InputObjectName.Length != 0) {

            //
            //  If the length of the string is not an even multiple of the
            //  size of a UNICODE character or cannot be zero terminated,
            //  then return an error.
            //

            Length = InputObjectName.Length;

            if (((Length & (sizeof(WCHAR) - 1)) != 0) ||
                (Length == (MAXUSHORT - sizeof(WCHAR) + 1))) {

                Status = STATUS_OBJECT_NAME_INVALID;

            } else {

                //
                //  Allocate a buffer for the specified name string.
                //
                //  N.B. The name buffer allocation routine adds one
                //       UNICODE character to the length and initializes
                //       the string descriptor.
                //

                FreeBuffer = ObpAllocateObjectNameBuffer( Length,
                                                          UseLookaside,
                                                          CapturedObjectName );

                if (FreeBuffer == NULL) {

                    Status = STATUS_INSUFFICIENT_RESOURCES;

                } else {

                    //
                    //  Copy the specified name string to the destination
                    //  buffer.
                    //

                    RtlCopyMemory(FreeBuffer, InputObjectName.Buffer, Length);

                    //
                    //  Zero terminate the name string and initialize the
                    //  string descriptor.
                    //

                    FreeBuffer[Length / sizeof(WCHAR)] = UNICODE_NULL;
                }
            }
        }

    } except(ExSystemExceptionFilter()) {

        Status = GetExceptionCode();

        if (FreeBuffer != NULL) {

            ExFreePool(FreeBuffer);
        }
    }

    return Status;
}


PWCHAR
ObpAllocateObjectNameBuffer (
    IN ULONG Length,
    IN LOGICAL UseLookaside,
    IN OUT PUNICODE_STRING ObjectName
    )

/*++

Routine Description:

    This function allocates an object name buffer.

    N.B. This function is nonpageable.

Arguments:

    Length - Supplies the length of the required buffer in bytes.

    UseLookaside - Supplies a logical variable that determines whether an
        attempt is made to allocate the name buffer from the lookaside list.

    ObjectName - Supplies a pointer to a name buffer string descriptor.

Return Value:

    If the allocation is successful, then name buffer string descriptor
    is initialized and the address of the name buffer is returned as the
    function value. Otherwise, a value of NULL is returned.

--*/

{
    PVOID Buffer;
    ULONG Maximum;

    //
    //  If allocation from the lookaside lists is specified and the buffer
    //  size is less than the size of lookaside list entries, then attempt
    //  to allocate the name buffer from the lookaside lists. Otherwise,
    //  attempt to allocate the name buffer from nonpaged pool.
    //

    Maximum = Length + sizeof(WCHAR);

    if ((UseLookaside == FALSE) || (Maximum > OBJECT_NAME_BUFFER_SIZE)) {

        //
        //  Attempt to allocate the buffer from nonpaged pool.
        //

        Buffer = ExAllocatePoolWithTag( OB_NAMESPACE_POOL_TYPE , Maximum, 'mNbO' );

    } else {

        //
        //  Attempt to allocate the name buffer from the lookaside list. If
        //  the allocation attempt fails, then attempt to allocate the name
        //  buffer from pool.
        //

        Maximum = OBJECT_NAME_BUFFER_SIZE;
        Buffer = ExAllocateFromPPLookasideList(LookasideNameBufferList);
    }

    //
    //  Initialize the string descriptor and return the buffer address.
    //

    ObjectName->Length = (USHORT)Length;
    ObjectName->MaximumLength = (USHORT)Maximum;
    ObjectName->Buffer = Buffer;

    return (PWCHAR)Buffer;
}


VOID
FASTCALL
ObpFreeObjectNameBuffer (
    OUT PUNICODE_STRING ObjectName
    )

/*++

Routine Description:

    This function frees an object name buffer.

    N.B. This function is nonpageable.

Arguments:

    ObjectName - Supplies a pointer to a name buffer string descriptor.

Return Value:

    None.

--*/

{
    PVOID Buffer;

    //
    //  If the size of the buffer is not equal to the size of lookaside list
    //  entries, then  free the buffer to pool. Otherwise, free the buffer to
    //  the lookaside list.
    //

    Buffer = ObjectName->Buffer;

    if (ObjectName->MaximumLength != OBJECT_NAME_BUFFER_SIZE) {
        ExFreePool(Buffer);

    } else {
        ExFreeToPPLookasideList(LookasideNameBufferList, Buffer);
    }

    return;
}


NTKERNELAPI
VOID
ObDeleteCapturedInsertInfo (
    IN PVOID Object
    )

/*++

Routine Description:

    This function frees the creation information that could be pointed at
    by the object header.

Arguments:

    Object - Supplies the object being modified

Return Value:

    None.

--*/

{
    POBJECT_HEADER ObjectHeader;

    PAGED_CODE();

    //
    //  Get the address of the object header and free the object create
    //  information object if the object is being created.
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER(Object);

    if (ObjectHeader->Flags & OB_FLAG_NEW_OBJECT) {

        if (ObjectHeader->ObjectCreateInfo != NULL) {

            ObpFreeObjectCreateInformation(ObjectHeader->ObjectCreateInfo);

            ObjectHeader->ObjectCreateInfo = NULL;
        }
    }

    return;
}


NTSTATUS
ObpAllocateObject (
    IN POBJECT_CREATE_INFORMATION ObjectCreateInfo,
    IN KPROCESSOR_MODE OwnershipMode,
    IN POBJECT_TYPE ObjectType OPTIONAL,
    IN PUNICODE_STRING ObjectName,
    IN ULONG ObjectBodySize,
    OUT POBJECT_HEADER *ReturnedObjectHeader
    )

/*++

Routine Description:

    This routine allocates a new object including the object header
    and body from pool and fill in the appropriate fields.

Arguments:

    ObjectCreateInfo - Supplies the create information for the new object

    OwnershipMode - Supplies the processor mode of who is going to own
        the object

    ObjectType - Optionally supplies the object type of the object being
        created. If the object create info not null then this field must
        be supplied.

    ObjectName - Supplies the name of the object being created

    ObjectBodySize - Specifies the size, in bytes, of the body of the object
        being created

    ReturnedObjectHeader - Receives a pointer to the object header for the
        newly created objet.

Return Value:

    An appropriate status value.

--*/

{
    ULONG HeaderSize;
    POBJECT_HEADER ObjectHeader;
    ULONG QuotaInfoSize;
    ULONG HandleInfoSize;
    ULONG NameInfoSize;
    ULONG CreatorInfoSize;
    POBJECT_HEADER_QUOTA_INFO QuotaInfo;
    POBJECT_HEADER_HANDLE_INFO HandleInfo;
    POBJECT_HEADER_NAME_INFO NameInfo;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POOL_TYPE PoolType;

    PAGED_CODE();

#if DBG
    ObpObjectsCreated += 1;
#endif // DBG

    //
    //  Compute the sizes of the optional object header components.
    //

    if (ObjectCreateInfo == NULL) {

        QuotaInfoSize = 0;
        HandleInfoSize = 0;
        NameInfoSize = sizeof( OBJECT_HEADER_NAME_INFO );
        CreatorInfoSize = sizeof( OBJECT_HEADER_CREATOR_INFO );

    } else {

        //
        //  The caller specified some additional object create info
        //
        //  First check to see if we need to set the quota
        //

        if (((ObjectCreateInfo->PagedPoolCharge != ObjectType->TypeInfo.DefaultPagedPoolCharge ||
              ObjectCreateInfo->NonPagedPoolCharge != ObjectType->TypeInfo.DefaultNonPagedPoolCharge ||
              ObjectCreateInfo->SecurityDescriptorCharge > SE_DEFAULT_SECURITY_QUOTA) &&
                 PsGetCurrentProcess() != PsInitialSystemProcess) ||
            (ObjectCreateInfo->Attributes & OBJ_EXCLUSIVE)) {

            QuotaInfoSize = sizeof( OBJECT_HEADER_QUOTA_INFO );
#if DBG
            ObpObjectsWithPoolQuota += 1;
#endif // DBG

        } else {

            QuotaInfoSize = 0;
        }

        //
        //  Check if we are to allocate space to maintain handle counts
        //

        if (ObjectType->TypeInfo.MaintainHandleCount) {

            HandleInfoSize = sizeof( OBJECT_HEADER_HANDLE_INFO );
#if DBG
            ObpObjectsWithHandleDB += 1;
#endif // DBG

        } else {

            HandleInfoSize = 0;
        }

        //
        //  Check if we are to allocate space for the name
        //

        if (ObjectName->Buffer != NULL) {

            NameInfoSize = sizeof( OBJECT_HEADER_NAME_INFO );
#if DBG
            ObpObjectsWithName += 1;
#endif // DBG

        } else {

            NameInfoSize = 0;
        }

        //
        //  Finally check if we are to maintain the creator info
        //

        if (ObjectType->TypeInfo.MaintainTypeList) {

            CreatorInfoSize = sizeof( OBJECT_HEADER_CREATOR_INFO );
#if DBG
            ObpObjectsWithCreatorInfo += 1;
#endif // DBG

        } else {

            CreatorInfoSize = 0;
        }
    }

    //
    //  Now compute the total header size
    //

    HeaderSize = QuotaInfoSize +
                 HandleInfoSize +
                 NameInfoSize +
                 CreatorInfoSize +
                 FIELD_OFFSET( OBJECT_HEADER, Body );

    //
    //  Allocate and initialize the object.
    //
    //  If the object type is not specified or specifies nonpaged pool,
    //  then allocate the object from nonpaged pool.
    //  Otherwise, allocate the object from paged pool.
    //

    if ((ObjectType == NULL) || (ObjectType->TypeInfo.PoolType == NonPagedPool)) {

        PoolType = NonPagedPool;

    } else {

        PoolType = PagedPool;
    }

    ObjectHeader = ExAllocatePoolWithTag( PoolType,
                                          HeaderSize + ObjectBodySize,
                                          (ObjectType == NULL ? 'TjbO' : ObjectType->Key) |
                                            PROTECTED_POOL );

    if (ObjectHeader == NULL) {

        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    //  Now based on if we are to put in the quota, handle, name, or creator info we
    //  will do the extra work.  This order is very important because we rely on
    //  it to free the object.
    //

    if (QuotaInfoSize != 0) {

        QuotaInfo = (POBJECT_HEADER_QUOTA_INFO)ObjectHeader;
        QuotaInfo->PagedPoolCharge = ObjectCreateInfo->PagedPoolCharge;
        QuotaInfo->NonPagedPoolCharge = ObjectCreateInfo->NonPagedPoolCharge;
        QuotaInfo->SecurityDescriptorCharge = ObjectCreateInfo->SecurityDescriptorCharge;
        QuotaInfo->ExclusiveProcess = NULL;
        ObjectHeader = (POBJECT_HEADER)(QuotaInfo + 1);
    }

    if (HandleInfoSize != 0) {

        HandleInfo = (POBJECT_HEADER_HANDLE_INFO)ObjectHeader;
        HandleInfo->SingleEntry.HandleCount = 0;
        ObjectHeader = (POBJECT_HEADER)(HandleInfo + 1);
    }

    if (NameInfoSize != 0) {

        NameInfo = (POBJECT_HEADER_NAME_INFO)ObjectHeader;
        NameInfo->Name = *ObjectName;
        NameInfo->Directory = NULL;
        NameInfo->QueryReferences = 1;
        ObjectHeader = (POBJECT_HEADER)(NameInfo + 1);
    }

    if (CreatorInfoSize != 0) {

        CreatorInfo = (POBJECT_HEADER_CREATOR_INFO)ObjectHeader;
        CreatorInfo->CreatorBackTraceIndex = 0;
        CreatorInfo->CreatorUniqueProcess = PsGetCurrentProcess()->UniqueProcessId;
        InitializeListHead( &CreatorInfo->TypeList );

        PERFINFO_ADD_OBJECT_TO_ALLOCATED_TYPE_LIST(CreatorInfo, ObjectType);

        ObjectHeader = (POBJECT_HEADER)(CreatorInfo + 1);
    }

    //
    //  Compute the proper offsets based on what we have
    //

    if (QuotaInfoSize != 0) {

        ObjectHeader->QuotaInfoOffset = (UCHAR)(QuotaInfoSize + HandleInfoSize + NameInfoSize + CreatorInfoSize);

    } else {

        ObjectHeader->QuotaInfoOffset = 0;
    }

    if (HandleInfoSize != 0) {

        ObjectHeader->HandleInfoOffset = (UCHAR)(HandleInfoSize + NameInfoSize + CreatorInfoSize);

    } else {

        ObjectHeader->HandleInfoOffset = 0;
    }

    if (NameInfoSize != 0) {

        ObjectHeader->NameInfoOffset =  (UCHAR)(NameInfoSize + CreatorInfoSize);

    } else {

        ObjectHeader->NameInfoOffset = 0;
    }

    //
    //  Say that this is a new object, and conditionally set the other flags
    //

    ObjectHeader->Flags = OB_FLAG_NEW_OBJECT;

    if (CreatorInfoSize != 0) {

        ObjectHeader->Flags |= OB_FLAG_CREATOR_INFO;
    }

    if (HandleInfoSize != 0) {

        ObjectHeader->Flags |= OB_FLAG_SINGLE_HANDLE_ENTRY;
    }

    //
    //  Set the counters and its type
    //

    ObjectHeader->PointerCount = 1;
    ObjectHeader->HandleCount = 0;
    ObjectHeader->Type = ObjectType;

    //
    //  Initialize the object header.
    //
    //  N.B. The initialization of the object header is done field by
    //       field rather than zeroing the memory and then initializing
    //       the pertinent fields.
    //
    //  N.B. It is assumed that the caller will initialize the object
    //       attributes, object ownership, and parse context.
    //

    if (OwnershipMode == KernelMode) {

        ObjectHeader->Flags |= OB_FLAG_KERNEL_OBJECT;
    }

    if (ObjectCreateInfo != NULL &&
        ObjectCreateInfo->Attributes & OBJ_PERMANENT ) {

        ObjectHeader->Flags |= OB_FLAG_PERMANENT_OBJECT;
    }

    if ((ObjectCreateInfo != NULL) &&
        (ObjectCreateInfo->Attributes & OBJ_EXCLUSIVE)) {

        ObjectHeader->Flags |= OB_FLAG_EXCLUSIVE_OBJECT;
    }

    ObjectHeader->ObjectCreateInfo = ObjectCreateInfo;
    ObjectHeader->SecurityDescriptor = NULL;

    if (ObjectType != NULL) {

        InterlockedIncrement((PLONG)&ObjectType->TotalNumberOfObjects);

        if (ObjectType->TotalNumberOfObjects > ObjectType->HighWaterNumberOfObjects) {

            ObjectType->HighWaterNumberOfObjects = ObjectType->TotalNumberOfObjects;
        }
    }

#if DBG

    //
    //  On a checked build echo out allocs
    //

    if (ObpShowAllocAndFree) {

        DbgPrint( "OB: Alloc %lx (%lx) %04lu", ObjectHeader, ObjectHeader, ObjectBodySize );

        if (ObjectType) {

            DbgPrint(" - %wZ\n", &ObjectType->Name );

        } else {

            DbgPrint(" - Type\n" );
        }
    }
#endif

    *ReturnedObjectHeader = ObjectHeader;

    return STATUS_SUCCESS;
}


VOID
FASTCALL
ObpFreeObject (
    IN PVOID Object
    )

/*++

Routine Description:

    This routine undoes ObpAllocateObject.  It returns the object back to free pool.

Arguments:

    Object - Supplies a pointer to the body of the object being freed.

Return Value:

    None.

--*/

{
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    POBJECT_HEADER_QUOTA_INFO QuotaInfo;
    POBJECT_HEADER_HANDLE_INFO HandleInfo;
    POBJECT_HEADER_NAME_INFO NameInfo;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    PVOID FreeBuffer;
    ULONG NonPagedPoolCharge;
    ULONG PagedPoolCharge;

    PAGED_CODE();

    //
    //  Get the address of the object header.
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER(Object);
    ObjectType = ObjectHeader->Type;

    //
    //  Now from the header determine the start of the allocation.  We need
    //  to backup based on what precedes the header.  The order is very
    //  important and must be the inverse of that used by ObpAllocateObject
    //

    FreeBuffer = ObjectHeader;

    CreatorInfo = OBJECT_HEADER_TO_CREATOR_INFO( ObjectHeader );

    if (CreatorInfo != NULL) {

        FreeBuffer = CreatorInfo;
    }

    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

    if (NameInfo != NULL) {

        FreeBuffer = NameInfo;
    }

    HandleInfo = OBJECT_HEADER_TO_HANDLE_INFO( ObjectHeader );

    if (HandleInfo != NULL) {

        FreeBuffer = HandleInfo;
    }

    QuotaInfo = OBJECT_HEADER_TO_QUOTA_INFO( ObjectHeader );

    if (QuotaInfo != NULL) {

        FreeBuffer = QuotaInfo;
    }

#if DBG

    //
    //  On a checked build echo out frees
    //

    if (ObpShowAllocAndFree) {

        DbgPrint( "OB: Free  %lx (%lx) - Type: %wZ\n", ObjectHeader, ObjectHeader, &ObjectType->Name );
    }
#endif

    //
    //  Decrement the number of objects of this type
    //

    InterlockedDecrement((PLONG)&ObjectType->TotalNumberOfObjects);

    //
    //  Check where we were in the object initialization phase.  This
    //  flag really only tests if we have charged quota for this object.
    //  This is because the object create info and the quota block charged
    //  are unioned together.
    //

    if (ObjectHeader->Flags & OB_FLAG_NEW_OBJECT) {

        if (ObjectHeader->ObjectCreateInfo != NULL) {

            ObpFreeObjectCreateInformation( ObjectHeader->ObjectCreateInfo );

            ObjectHeader->ObjectCreateInfo = NULL;
        }

    } else {

        if (ObjectHeader->QuotaBlockCharged != NULL) {

            if (QuotaInfo != NULL) {

                PagedPoolCharge = QuotaInfo->PagedPoolCharge +
                                  QuotaInfo->SecurityDescriptorCharge;

                NonPagedPoolCharge = QuotaInfo->NonPagedPoolCharge;

            } else {

                PagedPoolCharge = ObjectType->TypeInfo.DefaultPagedPoolCharge;

                if (ObjectHeader->Flags & OB_FLAG_DEFAULT_SECURITY_QUOTA ) {

                    PagedPoolCharge += SE_DEFAULT_SECURITY_QUOTA;
                }

                NonPagedPoolCharge = ObjectType->TypeInfo.DefaultNonPagedPoolCharge;
            }

            PsReturnSharedPoolQuota( ObjectHeader->QuotaBlockCharged,
                                     PagedPoolCharge,
                                     NonPagedPoolCharge );

            ObjectHeader->QuotaBlockCharged = NULL;
        }
    }

    if ((HandleInfo != NULL) &&
        ((ObjectHeader->Flags & OB_FLAG_SINGLE_HANDLE_ENTRY) == 0)) {

        //
        //  If a handle database has been allocated, then free the memory.
        //

        ExFreePool( HandleInfo->HandleCountDataBase );

        HandleInfo->HandleCountDataBase = NULL;
    }

    //
    //  If a name string buffer has been allocated, then free the memory.
    //

    if (NameInfo != NULL && NameInfo->Name.Buffer != NULL) {

        ExFreePool( NameInfo->Name.Buffer );

        NameInfo->Name.Buffer = NULL;
    }

    PERFINFO_REMOVE_OBJECT_FROM_ALLOCATED_TYPE_LIST(CreatorInfo, ObjectHeader);

    //
    //  Trash type field so we don't get far if we attempt to
    //  use a stale object pointer to this object.
    //
    //  Sundown Note: trash it by zero-extended it. 
    //                sign-extension will create a valid kernel address.


    ObjectHeader->Type = UIntToPtr(0xBAD0B0B0); 
    ExFreePoolWithTag( FreeBuffer,
                       (ObjectType == NULL ? 'TjbO' : ObjectType->Key) |
                            PROTECTED_POOL );

    return;
}


VOID
FASTCALL
ObFreeObjectCreateInfoBuffer (
    IN POBJECT_CREATE_INFORMATION ObjectCreateInfo
    )

/*++

Routine Description:

    This function frees a create information buffer.  Called from IO component

    N.B. This function is nonpageable.

Arguments:

    ObjectCreateInfo - Supplies a pointer to a create information buffer.

Return Value:

    None.

--*/

{
    ObpFreeObjectCreateInfoBuffer( ObjectCreateInfo );

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obinit.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obinit.c

Abstract:

    Initialization module for the OB subcomponent of NTOS

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"

//
//  Define date structures for the object creation information region.
//

GENERAL_LOOKASIDE ObpCreateInfoLookasideList;

//
//  Define data structures for the object name buffer lookaside list.
//

#define OBJECT_NAME_BUFFER_SIZE 248

GENERAL_LOOKASIDE ObpNameBufferLookasideList;

//
//  Form some default access masks for the various object types
//

#ifdef ALLOC_DATA_PRAGMA
#pragma const_seg("INITCONST")
#endif


const GENERIC_MAPPING ObpTypeMapping = {
    STANDARD_RIGHTS_READ,
    STANDARD_RIGHTS_WRITE,
    STANDARD_RIGHTS_EXECUTE,
    OBJECT_TYPE_ALL_ACCESS
};

const GENERIC_MAPPING ObpDirectoryMapping = {
    STANDARD_RIGHTS_READ |
        DIRECTORY_QUERY |
        DIRECTORY_TRAVERSE,
    STANDARD_RIGHTS_WRITE |
        DIRECTORY_CREATE_OBJECT |
        DIRECTORY_CREATE_SUBDIRECTORY,
    STANDARD_RIGHTS_EXECUTE |
        DIRECTORY_QUERY |
        DIRECTORY_TRAVERSE,
    DIRECTORY_ALL_ACCESS
};

const GENERIC_MAPPING ObpSymbolicLinkMapping = {
    STANDARD_RIGHTS_READ |
        SYMBOLIC_LINK_QUERY,
    STANDARD_RIGHTS_WRITE,
    STANDARD_RIGHTS_EXECUTE |
        SYMBOLIC_LINK_QUERY,
    SYMBOLIC_LINK_ALL_ACCESS
};

//
//  Local procedure prototypes
//

NTSTATUS
ObpCreateDosDevicesDirectory (
    VOID
    );

NTSTATUS
ObpGetDosDevicesProtection (
    PSECURITY_DESCRIPTOR SecurityDescriptor
    );

VOID
ObpFreeDosDevicesProtection (
    PSECURITY_DESCRIPTOR SecurityDescriptor
    );

BOOLEAN
ObpShutdownCloseHandleProcedure (
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE HandleId,
    IN PVOID EnumParameter
    );


#ifdef ALLOC_PRAGMA
BOOLEAN
ObDupHandleProcedure (
    PEPROCESS Process,
    PHANDLE_TABLE OldObjectTable,
    PHANDLE_TABLE_ENTRY OldObjectTableEntry,
    PHANDLE_TABLE_ENTRY ObjectTableEntry
    );
BOOLEAN
ObAuditInheritedHandleProcedure (
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE HandleId,
    IN PVOID EnumParameter
    );
VOID
ObDestroyHandleProcedure (
    IN HANDLE HandleIndex
    );
BOOLEAN
ObpEnumFindHandleProcedure (
    PHANDLE_TABLE_ENTRY ObjectTableEntry,
    HANDLE HandleId,
    PVOID EnumParameter
    );

BOOLEAN
ObpCloseHandleProcedure (
    IN PHANDLE_TABLE_ENTRY HandleTableEntry,
    IN HANDLE Handle,
    IN PVOID EnumParameter
    );

#pragma alloc_text(INIT,ObInitSystem)
#pragma alloc_text(PAGE,ObDupHandleProcedure)
#pragma alloc_text(PAGE,ObAuditInheritedHandleProcedure)
#pragma alloc_text(PAGE,ObInitProcess)
#pragma alloc_text(PAGE,ObInitProcess2)
#pragma alloc_text(PAGE,ObDestroyHandleProcedure)
#pragma alloc_text(PAGE,ObKillProcess)
#pragma alloc_text(PAGE,ObClearProcessHandleTable)
#pragma alloc_text(PAGE,ObpCloseHandleProcedure)
#pragma alloc_text(PAGE,ObpEnumFindHandleProcedure)
#pragma alloc_text(PAGE,ObFindHandleForObject)
#pragma alloc_text(PAGE,ObpShutdownCloseHandleProcedure)
#pragma alloc_text(PAGE,ObShutdownSystem)
#pragma alloc_text(INIT,ObpCreateDosDevicesDirectory)
#pragma alloc_text(INIT,ObpGetDosDevicesProtection)
#pragma alloc_text(INIT,ObpFreeDosDevicesProtection)
#endif

//
//  The default quota block is setup by obinitsystem
//


ULONG ObpAccessProtectCloseBit = MAXIMUM_ALLOWED;


PDEVICE_MAP ObSystemDeviceMap = NULL;

//
//  CurrentControlSet values set by code in config\cmdat3.c at system load time
//  These are private variables within obinit.c
//

#define OBJ_SECURITY_MODE_BNO_RESTRICTED 1

ULONG ObpProtectionMode;
ULONG ObpLUIDDeviceMapsDisabled;
ULONG ObpAuditBaseDirectories;
ULONG ObpAuditBaseObjects;
ULONG ObpObjectSecurityMode = OBJ_SECURITY_MODE_BNO_RESTRICTED;

//
// ObpLUIDDeviceMapsEnabled holds the result of "Is LUID device maps enabled?"
// Depends on the DWORD registry keys, ProtectionMode & LUIDDeviceMapsDisabled:
// location: \Registry\Machine\System\CurrentControlSet\Control\Session Manager
//
// Enabling/Disabling works as follows:
// if ((ProtectionMode == 0) || (LUIDDeviceMapsDisabled !=0)) {
//     // LUID device maps are disabled
//     // ObpLUIDDeviceMapsEnabled == 0
// }
// else {
//     // LUID device maps are enabled
//     // ObpLUIDDeviceMapsEnabled == 1
// }
//
ULONG ObpLUIDDeviceMapsEnabled;

//
//  MmNumberOfPagingFiles is used in shutdown, to make sure we're not
//  leaking any kernel handles.
//
extern ULONG MmNumberOfPagingFiles;

//
//  These are global variables
//

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("PAGEDATA")
#pragma const_seg("PAGECONST")
#endif
//
//  A ULONGLONG aligned global variable
//  for use by ObpLookupObjectName for quick comparisons.
//
const ALIGNEDNAME ObpDosDevicesShortNamePrefix = { L'\\',L'?',L'?',L'\\' }; // L"\??\"
const ALIGNEDNAME ObpDosDevicesShortNameRoot = { L'\\',L'?',L'?',L'\0' }; // L"\??"
const UNICODE_STRING ObpDosDevicesShortName = {
    sizeof(ObpDosDevicesShortNamePrefix),
    sizeof(ObpDosDevicesShortNamePrefix),
    (PWSTR)&ObpDosDevicesShortNamePrefix
};

#define ObpGlobalDosDevicesShortName    L"\\GLOBAL??"  // \GLOBAL??

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg()
#pragma const_seg()
#endif

BOOLEAN
ObInitSystem (
    VOID
    )

/*++

Routine Description:

    This function performs the system initialization for the object
    manager.  The object manager data structures are self describing
    with the exception of the root directory, the type object type and
    the directory object type.  The initialization code then constructs
    these objects by hand to get the ball rolling.

Arguments:

    None.

Return Value:

    TRUE if successful and FALSE if an error occurred.

    The following errors can occur:

    - insufficient memory

--*/

{
    USHORT CreateInfoMaxDepth;
    USHORT NameBufferMaxDepth;
    OBJECT_TYPE_INITIALIZER ObjectTypeInitializer;
    UNICODE_STRING TypeTypeName;
    UNICODE_STRING SymbolicLinkTypeName;
    UNICODE_STRING DirectoryTypeName;
    UNICODE_STRING RootDirectoryName;
    UNICODE_STRING TypeDirectoryName;
    NTSTATUS Status;
    OBJECT_ATTRIBUTES ObjectAttributes;
    HANDLE RootDirectoryHandle;
    HANDLE TypeDirectoryHandle;
    PLIST_ENTRY Next, Head;
    POBJECT_HEADER ObjectTypeHeader;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POBJECT_HEADER_NAME_INFO NameInfo;
    MM_SYSTEMSIZE SystemSize;
    SECURITY_DESCRIPTOR AuditSd;
    PSECURITY_DESCRIPTOR EffectiveSd;
    PACL    AuditAllAcl;
    UCHAR   AuditAllBuffer[250];  // Ample room for the ACL
    ULONG   AuditAllLength;
    PACE_HEADER Ace;
    PGENERAL_LOOKASIDE Lookaside;
    ULONG Index;
    PKPRCB Prcb;
    OBP_LOOKUP_CONTEXT LookupContext;
    PACL Dacl;
    ULONG DaclLength;
    SECURITY_DESCRIPTOR SecurityDescriptor;

    //
    //  Determine the the size of the object creation and the name buffer
    //  lookaside lists.
    //

    SystemSize = MmQuerySystemSize();

    if (SystemSize == MmLargeSystem) {

        if (MmIsThisAnNtAsSystem()) {

            CreateInfoMaxDepth = 64;
            NameBufferMaxDepth = 32;

        } else {

            CreateInfoMaxDepth = 32;
            NameBufferMaxDepth = 16;
        }

    } else {

        CreateInfoMaxDepth = 3;
        NameBufferMaxDepth = 3;
    }

    //
    //  PHASE 0 Initialization
    //

    if (InitializationPhase == 0) {

        //
        //  Initialize the object creation lookaside list.
        //

        ExInitializeSystemLookasideList( &ObpCreateInfoLookasideList,
                                         NonPagedPool,
                                         sizeof(OBJECT_CREATE_INFORMATION),
                                         'iCbO',
                                         CreateInfoMaxDepth,
                                         &ExSystemLookasideListHead );

        //
        //  Initialize the name buffer lookaside list.
        //

        ExInitializeSystemLookasideList( &ObpNameBufferLookasideList,

#ifndef OBP_PAGEDPOOL_NAMESPACE

                                         NonPagedPool,

#else

                                         PagedPool,

#endif

                                         OBJECT_NAME_BUFFER_SIZE,
                                         'mNbO',
                                         NameBufferMaxDepth,
                                         &ExSystemLookasideListHead );

        //
        //  Initialize the system create info and name buffer lookaside lists
        //  for the current processor.
        //
        // N.B. Temporarily during the initialization of the system both
        //      lookaside list pointers in the processor block point to
        //      the same lookaside list structure. Later in initialization
        //      another lookaside list structure is allocated and filled
        //      for the per processor list.
        //

        Prcb = KeGetCurrentPrcb();
        Prcb->PPLookasideList[LookasideCreateInfoList].L = &ObpCreateInfoLookasideList;
        Prcb->PPLookasideList[LookasideCreateInfoList].P = &ObpCreateInfoLookasideList;
        Prcb->PPLookasideList[LookasideNameBufferList].L = &ObpNameBufferLookasideList;
        Prcb->PPLookasideList[LookasideNameBufferList].P = &ObpNameBufferLookasideList;

        //
        //  Initialize the object removal queue listhead.
        //

        ObpRemoveObjectList = NULL;

        //
        //  Initialize security descriptor cache
        //

        ObpInitSecurityDescriptorCache();

        KeInitializeEvent( &ObpDefaultObject, NotificationEvent, TRUE );
        ExInitializePushLock( &ObpLock );
        PsGetCurrentProcess()->GrantedAccess = PROCESS_ALL_ACCESS;
        PsGetCurrentThread()->GrantedAccess = THREAD_ALL_ACCESS;

#ifndef OBP_PAGEDPOOL_NAMESPACE
        KeInitializeSpinLock( &ObpDeviceMapLock );
#else
        KeInitializeGuardedMutex( &ObpDeviceMapLock );
#endif  // OBP_PAGEDPOOL_NAMESPACE

        //
        //  Initialize the quota system
        //
        PsInitializeQuotaSystem ();

        //
        //  Initialize the handle table for the system process and also the global
        //  kernel handle table
        //

        ObpKernelHandleTable = PsGetCurrentProcess()->ObjectTable = ExCreateHandleTable( NULL );
#if DBG
        //
        // On checked make handle reuse take much longer
        //
        ExSetHandleTableStrictFIFO (ObpKernelHandleTable);
#endif

        //
        // Initialize the deferred delete work item.
        //

        ExInitializeWorkItem( &ObpRemoveObjectWorkItem,
                              ObpProcessRemoveObjectQueue,
                              NULL );

        //
        //  Create an object type for the "Type" object.  This is the start of
        //  of the object types and goes in the ObpTypeDirectoryObject.
        //

        RtlZeroMemory( &ObjectTypeInitializer, sizeof( ObjectTypeInitializer ) );
        ObjectTypeInitializer.Length = sizeof( ObjectTypeInitializer );
        ObjectTypeInitializer.InvalidAttributes = OBJ_OPENLINK;
        ObjectTypeInitializer.PoolType = NonPagedPool;

        RtlInitUnicodeString( &TypeTypeName, L"Type" );
        ObjectTypeInitializer.ValidAccessMask = OBJECT_TYPE_ALL_ACCESS;
        ObjectTypeInitializer.GenericMapping = ObpTypeMapping;
        ObjectTypeInitializer.DefaultNonPagedPoolCharge = sizeof( OBJECT_TYPE );
        ObjectTypeInitializer.MaintainTypeList = TRUE;
        ObjectTypeInitializer.UseDefaultObject = TRUE;
        ObjectTypeInitializer.DeleteProcedure = &ObpDeleteObjectType;
        ObCreateObjectType( &TypeTypeName,
                            &ObjectTypeInitializer,
                            (PSECURITY_DESCRIPTOR)NULL,
                            &ObpTypeObjectType );

        //
        //  Create the object type for the "Directory" object.
        //
        
        ObjectTypeInitializer.PoolType = OB_NAMESPACE_POOL_TYPE;

        RtlInitUnicodeString( &DirectoryTypeName, L"Directory" );
        ObjectTypeInitializer.DefaultNonPagedPoolCharge = sizeof( OBJECT_DIRECTORY );
        ObjectTypeInitializer.ValidAccessMask = DIRECTORY_ALL_ACCESS;
        ObjectTypeInitializer.CaseInsensitive = TRUE;
        ObjectTypeInitializer.GenericMapping = ObpDirectoryMapping;
        ObjectTypeInitializer.UseDefaultObject = TRUE;
        ObjectTypeInitializer.MaintainTypeList = FALSE;
        ObjectTypeInitializer.DeleteProcedure = NULL;
        ObCreateObjectType( &DirectoryTypeName,
                            &ObjectTypeInitializer,
                            (PSECURITY_DESCRIPTOR)NULL,
                            &ObpDirectoryObjectType );
        
        //
        //  Clear SYNCHRONIZE from the access mask to not allow
        //  synchronization on directory objects
        //

        ObpDirectoryObjectType->TypeInfo.ValidAccessMask &= ~SYNCHRONIZE;

        //
        //  Create the object type for the "SymbolicLink" object.
        //

        RtlInitUnicodeString( &SymbolicLinkTypeName, L"SymbolicLink" );
        ObjectTypeInitializer.DefaultNonPagedPoolCharge = sizeof( OBJECT_SYMBOLIC_LINK );
        ObjectTypeInitializer.ValidAccessMask = SYMBOLIC_LINK_ALL_ACCESS;
        ObjectTypeInitializer.CaseInsensitive = TRUE;
        ObjectTypeInitializer.GenericMapping = ObpSymbolicLinkMapping;
        ObjectTypeInitializer.DeleteProcedure = ObpDeleteSymbolicLink;
        ObjectTypeInitializer.ParseProcedure = ObpParseSymbolicLink;
        ObCreateObjectType( &SymbolicLinkTypeName,
                            &ObjectTypeInitializer,
                            (PSECURITY_DESCRIPTOR)NULL,
                            &ObpSymbolicLinkObjectType );
        
        //
        //  Clear SYNCHRONIZE from the access mask to not allow
        //  synchronization on symbolic link objects objects
        //

        ObpSymbolicLinkObjectType->TypeInfo.ValidAccessMask &= ~SYNCHRONIZE;

#ifdef POOL_TAGGING
        //
        // Initialize the ref/deref object-tracing mechanism
        //

        ObpInitStackTrace();
#endif //POOL_TAGGING

#if i386 

        //
        //  Initialize the cached granted access structure.  These variables are used
        //  in place of the access mask in the object table entry.
        //

        ObpCurCachedGrantedAccessIndex = 0;

        if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

            ObpMaxCachedGrantedAccessIndex = 2*PAGE_SIZE / sizeof( ACCESS_MASK );
            ObpCachedGrantedAccesses = ExAllocatePoolWithTag( PagedPool, 2*PAGE_SIZE, 'gAbO' );

            if (ObpCachedGrantedAccesses == NULL) {

                return FALSE;
            }

            ObpAccessProtectCloseBit = 0x80000000;
        } else {

            ObpMaxCachedGrantedAccessIndex = 0;
            ObpCachedGrantedAccesses = NULL;
        }

#endif // i386 

    } // End of Phase 0 Initialization

    //
    //  PHASE 1 Initialization
    //

    if (InitializationPhase == 1) {

        //
        //  Initialize the per processor nonpaged lookaside lists and descriptors.
        //

        for (Index = 0; Index < (ULONG)KeNumberProcessors; Index += 1) {
            Prcb = KiProcessorBlock[Index];

            //
            //  Initialize the create information per processor lookaside pointers.
            //

            Prcb->PPLookasideList[LookasideCreateInfoList].L = &ObpCreateInfoLookasideList;
            Lookaside = ExAllocatePoolWithTag( NonPagedPool,
                                               sizeof(GENERAL_LOOKASIDE),
                                              'ICbO');

            if (Lookaside != NULL) {
                ExInitializeSystemLookasideList( Lookaside,
                                                 NonPagedPool,
                                                 sizeof(OBJECT_CREATE_INFORMATION),
                                                 'ICbO',
                                                 CreateInfoMaxDepth,
                                                 &ExSystemLookasideListHead );

            } else {
                Lookaside = &ObpCreateInfoLookasideList;
            }

            Prcb->PPLookasideList[LookasideCreateInfoList].P = Lookaside;

            //
            //  Initialize the name buffer per processor lookaside pointers.
            //


            Prcb->PPLookasideList[LookasideNameBufferList].L = &ObpNameBufferLookasideList;
            Lookaside = ExAllocatePoolWithTag( NonPagedPool,
                                               sizeof(GENERAL_LOOKASIDE),
                                               'MNbO');

            if (Lookaside != NULL) {
                ExInitializeSystemLookasideList( Lookaside,

#ifndef OBP_PAGEDPOOL_NAMESPACE

                                                 NonPagedPool,

#else

                                                PagedPool,

#endif

                                                 OBJECT_NAME_BUFFER_SIZE,
                                                 'MNbO',
                                                 NameBufferMaxDepth,
                                                 &ExSystemLookasideListHead );

            } else {
                Lookaside = &ObpNameBufferLookasideList;
            }

            Prcb->PPLookasideList[LookasideNameBufferList].P = Lookaside;

        }

        EffectiveSd = SePublicDefaultUnrestrictedSd;

        //
        //  This code is only executed if base auditing is turned on.
        //

        if ((ObpAuditBaseDirectories != 0) || (ObpAuditBaseObjects != 0)) {

            //
            //  build an SACL to audit
            //

            AuditAllAcl = (PACL)AuditAllBuffer;
            AuditAllLength = (ULONG)sizeof(ACL) +
                               ((ULONG)sizeof(SYSTEM_AUDIT_ACE)) +
                               SeLengthSid(SeWorldSid);

            ASSERT( sizeof(AuditAllBuffer)   >   AuditAllLength );

            Status = RtlCreateAcl( AuditAllAcl, AuditAllLength, ACL_REVISION2);

            ASSERT( NT_SUCCESS(Status) );

            Status = RtlAddAuditAccessAce ( AuditAllAcl,
                                            ACL_REVISION2,
                                            GENERIC_ALL,
                                            SeWorldSid,
                                            TRUE,  TRUE ); //Audit success and failure
            ASSERT( NT_SUCCESS(Status) );

            Status = RtlGetAce( AuditAllAcl, 0,  (PVOID)&Ace );

            ASSERT( NT_SUCCESS(Status) );

            if (ObpAuditBaseDirectories != 0) {

                Ace->AceFlags |= (CONTAINER_INHERIT_ACE | INHERIT_ONLY_ACE);
            }

            if (ObpAuditBaseObjects != 0) {

                Ace->AceFlags |= (OBJECT_INHERIT_ACE    |
                                  CONTAINER_INHERIT_ACE |
                                  INHERIT_ONLY_ACE);
            }

            //
            //  Now create a security descriptor that looks just like
            //  the public default, but has auditing in it as well.
            //

            EffectiveSd = (PSECURITY_DESCRIPTOR)&AuditSd;
            Status = RtlCreateSecurityDescriptor( EffectiveSd,
                                                  SECURITY_DESCRIPTOR_REVISION1 );

            ASSERT( NT_SUCCESS(Status) );

            Status = RtlSetDaclSecurityDescriptor( EffectiveSd,
                                                   TRUE,        // DaclPresent
                                                   SePublicDefaultUnrestrictedDacl,
                                                   FALSE );     // DaclDefaulted

            ASSERT( NT_SUCCESS(Status) );

            Status = RtlSetSaclSecurityDescriptor( EffectiveSd,
                                                   TRUE,        // DaclPresent
                                                   AuditAllAcl,
                                                   FALSE );     // DaclDefaulted

            ASSERT( NT_SUCCESS(Status) );
        }

        //
        //  We only need to use the EffectiveSd on the root.  The SACL
        //  will be inherited by all other objects.
        //

        //
        //  Create a directory object for the root directory
        //

        RtlInitUnicodeString( &RootDirectoryName, L"\\" );

        InitializeObjectAttributes( &ObjectAttributes,
                                    &RootDirectoryName,
                                    OBJ_CASE_INSENSITIVE |
                                    OBJ_PERMANENT,
                                    NULL,
                                    EffectiveSd );

        Status = NtCreateDirectoryObject( &RootDirectoryHandle,
                                          DIRECTORY_ALL_ACCESS,
                                          &ObjectAttributes );

        if (!NT_SUCCESS( Status )) {

            return( FALSE );
        }

        Status = ObReferenceObjectByHandle( RootDirectoryHandle,
                                            0,
                                            ObpDirectoryObjectType,
                                            KernelMode,
                                            (PVOID *)&ObpRootDirectoryObject,
                                            NULL );

        if (!NT_SUCCESS( Status )) {

            return( FALSE );
        }

        Status = NtClose( RootDirectoryHandle );

        if (!NT_SUCCESS( Status )) {

            return( FALSE );
        }

        //
        //  Create a directory object for the directory of kernel objects
        //

        Status = RtlCreateSecurityDescriptor (&SecurityDescriptor,
                                              SECURITY_DESCRIPTOR_REVISION);

        if (!NT_SUCCESS (Status)) {
            return( FALSE );
        }

        DaclLength = sizeof(ACL) + sizeof(ACCESS_ALLOWED_ACE) * 3 +
                                RtlLengthSid (SeLocalSystemSid) +
                                RtlLengthSid(SeAliasAdminsSid) +
                                RtlLengthSid (SeWorldSid);

        Dacl = ExAllocatePoolWithTag (PagedPool, DaclLength, 'lcaD');

        if (Dacl == NULL) {
            return( FALSE );
        }


        //
        // Create the SD for the the well-known directories
        //

        Status = RtlCreateAcl (Dacl, DaclLength, ACL_REVISION);

        if (!NT_SUCCESS (Status)) {
            ExFreePool (Dacl);
            return( FALSE );
        }

        Status = RtlAddAccessAllowedAce (Dacl,
                                         ACL_REVISION,
                                         DIRECTORY_QUERY | DIRECTORY_TRAVERSE | READ_CONTROL,
                                         SeWorldSid);

        if (!NT_SUCCESS (Status)) {
            ExFreePool (Dacl);
            return( FALSE );
        }

        Status = RtlAddAccessAllowedAce (Dacl,
                                         ACL_REVISION,
                                         DIRECTORY_ALL_ACCESS,
                                         SeAliasAdminsSid);

        if (!NT_SUCCESS (Status)) {
            ExFreePool (Dacl);
            return( FALSE );
        }

        Status = RtlAddAccessAllowedAce (Dacl,
                                         ACL_REVISION,
                                         DIRECTORY_ALL_ACCESS,
                                         SeLocalSystemSid);

        if (!NT_SUCCESS (Status)) {
            ExFreePool (Dacl);
            return( FALSE );
        }

        Status = RtlSetDaclSecurityDescriptor (&SecurityDescriptor,
                                               TRUE,
                                               Dacl,
                                               FALSE);

        if (!NT_SUCCESS (Status)) {
            ExFreePool (Dacl);
            return( FALSE );
        }
      
        RtlInitUnicodeString( &TypeDirectoryName, L"\\KernelObjects" );

        InitializeObjectAttributes( &ObjectAttributes,
                                    &TypeDirectoryName,
                                    OBJ_CASE_INSENSITIVE |
                                    OBJ_PERMANENT,
                                    NULL,
                                    &SecurityDescriptor );

        Status = NtCreateDirectoryObject( &TypeDirectoryHandle,
                                          DIRECTORY_ALL_ACCESS,
                                          &ObjectAttributes );

        if (!NT_SUCCESS( Status )) {

            return( FALSE );
        }

        Status = NtClose( TypeDirectoryHandle );

        if (!NT_SUCCESS( Status )) {

            return( FALSE );
        }

        //
        //  Create a directory object for the directory of object types
        //

        RtlInitUnicodeString( &TypeDirectoryName, L"\\ObjectTypes" );

        InitializeObjectAttributes( &ObjectAttributes,
                                    &TypeDirectoryName,
                                    OBJ_CASE_INSENSITIVE |
                                    OBJ_PERMANENT,
                                    NULL,
                                    NULL );

        Status = NtCreateDirectoryObject( &TypeDirectoryHandle,
                                          DIRECTORY_ALL_ACCESS,
                                          &ObjectAttributes );

        if (!NT_SUCCESS( Status )) {

            return( FALSE );
        }

        Status = ObReferenceObjectByHandle( TypeDirectoryHandle,
                                            0,
                                            ObpDirectoryObjectType,
                                            KernelMode,
                                            (PVOID *)&ObpTypeDirectoryObject,
                                            NULL );

        if (!NT_SUCCESS( Status )) {

            return( FALSE );
        }

        Status = NtClose( TypeDirectoryHandle );

        if (!NT_SUCCESS( Status )) {

            return( FALSE );
        }

        //
        //  For every object type that has already been created we will
        //  insert it in the type directory.  We do this looking down the
        //  linked list of type objects and for every one that has a name
        //  and isn't already in a directory we'll look the name up and
        //  then put it in the directory.  Be sure to skip the first
        //  entry in the type object types lists.
        //

        ObpInitializeLookupContext( &LookupContext );
        ObpLockLookupContext ( &LookupContext, ObpTypeDirectoryObject );

        Head = &ObpTypeObjectType->TypeList;
        Next = Head->Flink;

        while (Next != Head) {

            //
            //  Right after the creator info is the object header.  Get
            //  the object header and then see if there is a name.
            //

            CreatorInfo = CONTAINING_RECORD( Next,
                                             OBJECT_HEADER_CREATOR_INFO,
                                             TypeList );

            ObjectTypeHeader = (POBJECT_HEADER)(CreatorInfo+1);

            NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectTypeHeader );

            //
            //  Check if we have a name and we're not in a directory
            //


            if ((NameInfo != NULL) && (NameInfo->Directory == NULL)) {

                if (!ObpLookupDirectoryEntry( ObpTypeDirectoryObject,
                                              &NameInfo->Name,
                                              OBJ_CASE_INSENSITIVE,
                                              FALSE,
                                              &LookupContext)) {

                    ObpInsertDirectoryEntry( ObpTypeDirectoryObject,
                                             &LookupContext,
                                             ObjectTypeHeader );
                }
            }

            Next = Next->Flink;
        }
        
        ObpReleaseLookupContext(&LookupContext);

        //
        //  Create \DosDevices object directory for drive letters and Win32 device names
        //

        Status = ObpCreateDosDevicesDirectory();

        if (!NT_SUCCESS( Status )) {

            return FALSE;
        }
    }

    return TRUE;
}


BOOLEAN
ObDupHandleProcedure (
    PEPROCESS Process,
    PHANDLE_TABLE OldObjectTable,
    PHANDLE_TABLE_ENTRY OldObjectTableEntry,
    PHANDLE_TABLE_ENTRY ObjectTableEntry
    )

/*++

Routine Description:

    This is the worker routine for ExDupHandleTable and
    is invoked via ObInitProcess.

Arguments:

    Process - Supplies a pointer to the new process

    HandleTable - Old handle table we are duplicating

    ObjectTableEntry - Supplies a pointer to the newly
        created handle table entry

Return Value:

    TRUE if the item can be inserted in the new table
        and FALSE otherwise

--*/

{
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    PVOID Object;
    ACCESS_STATE AccessState;

    //
    //  If the object table should not be inherited then return false
    //
    if (!(ObjectTableEntry->ObAttributes & OBJ_INHERIT)) {

        ExUnlockHandleTableEntry (OldObjectTable, OldObjectTableEntry);
        return( FALSE );
    }

    //
    //  Get a pointer to the object header and body
    //

    ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

    Object = &ObjectHeader->Body;

    //
    //  Increment the pointer count to the object before we unlock the old entry
    //

    ObpIncrPointerCount (ObjectHeader);

    ExUnlockHandleTableEntry (OldObjectTable, OldObjectTableEntry);

    //
    //  If we are tracing the call stacks for cached security indices then
    //  we have a translation to do.  Otherwise the table entry contains
    //  straight away the granted access mask.
    //

#if i386

    if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

        AccessState.PreviouslyGrantedAccess = ObpTranslateGrantedAccessIndex( ObjectTableEntry->GrantedAccessIndex );

    } else {

        AccessState.PreviouslyGrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);
    }

#else

    AccessState.PreviouslyGrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);

#endif // i386 

    //
    //  Increment the handle count on the object because we've just added
    //  another handle to it.
    //

    Status = ObpIncrementHandleCount( ObInheritHandle,
                                      Process,
                                      Object,
                                      ObjectHeader->Type,
                                      &AccessState,
                                      KernelMode,
                                      0 );

    if (!NT_SUCCESS( Status )) {

        ObDereferenceObject (Object);
        return( FALSE );
    }


    return( TRUE );
}


BOOLEAN
ObAuditInheritedHandleProcedure (
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE HandleId,
    IN PVOID EnumParameter
    )

/*++

Routine Description:

    ExEnumHandleTable worker routine to generate audits when handles are
    inherited.  An audit is generated if the handle attributes indicate
    that the handle is to be audited on close.

Arguments:

    ObjectTableEntry - Points to the handle table entry of interest.

    HandleId - Supplies the handle.

    EnumParameter - Supplies information about the source and target processes.

Return Value:

    FALSE, which tells ExEnumHandleTable to continue iterating through the
    handle table.

--*/

{
    PSE_PROCESS_AUDIT_INFO ProcessAuditInfo = EnumParameter;

    //
    //  Check if we have to do an audit
    //

    if (!(ObjectTableEntry->ObAttributes & OBJ_AUDIT_OBJECT_CLOSE)) {

        return( FALSE );
    }

    //
    //  Do the audit then return for more
    //

    SeAuditHandleDuplication( HandleId,
                              HandleId,
                              ProcessAuditInfo->Parent,
                              ProcessAuditInfo->Process );

    return( FALSE );
}



NTSTATUS
ObInitProcess (
    PEPROCESS ParentProcess OPTIONAL,
    PEPROCESS NewProcess
    )

/*++

Routine Description:

    This function initializes a process object table.  If the ParentProcess
    is specified, then all object handles with the OBJ_INHERIT attribute are
    copied from the parent object table to the new process' object table.
    The HandleCount field of each object copied is incremented by one.  Both
    object table mutexes remained locked for the duration of the copy
    operation.

Arguments:

    ParentProcess - optional pointer to a process object that is the
        parent process to inherit object handles from.

    NewProcess - pointer to the process object being initialized.

Return Value:

    Status code.

    The following errors can occur:

    - insufficient memory
    - STATUS_PROCESS_IS_TERMINATING if the parent process is terminating

--*/

{
    PHANDLE_TABLE OldObjectTable;
    PHANDLE_TABLE NewObjectTable;
    SE_PROCESS_AUDIT_INFO ProcessAuditInfo;

    //
    //  If we have a parent process then we need to lock it down
    //  check that it is not going away and then make a copy
    //  of its handle table.  If there isn't a parent then
    //  we'll start with an empty handle table.
    //

    if (ARGUMENT_PRESENT( ParentProcess )) {

        OldObjectTable = ObReferenceProcessHandleTable (ParentProcess);

        if ( !OldObjectTable ) {

            return STATUS_PROCESS_IS_TERMINATING;
        }

        NewObjectTable = ExDupHandleTable( NewProcess,
                                           OldObjectTable,
                                           ObDupHandleProcedure,
                                           OBJ_INHERIT );

    } else {

        OldObjectTable = NULL;
        NewObjectTable = ExCreateHandleTable( NewProcess );
    }

    //
    //  Check that we really have a new handle table otherwise
    //  we must be out of resources
    //

    if ( NewObjectTable ) {

        //
        //  Set the new processes object table and if we are
        //  auditing then enumerate the new table calling
        //  the audit procedure
        //

        NewProcess->ObjectTable = NewObjectTable;

        if ( SeDetailedAuditingWithToken( NULL ) ) {

            ProcessAuditInfo.Process = NewProcess;
            ProcessAuditInfo.Parent  = ParentProcess;

            ExEnumHandleTable( NewObjectTable,
                               ObAuditInheritedHandleProcedure,
                               (PVOID)&ProcessAuditInfo,
                               (PHANDLE)NULL );
        }

        //
        //  Free the old table if it exists and then
        //  return to our caller
        //

        if ( OldObjectTable ) {

            ObDereferenceProcessHandleTable( ParentProcess );
        }

        return (STATUS_SUCCESS);

    } else {

        //
        //  We're out of resources to null out the new object table field,
        //  unlock the old object table, and tell our caller that this
        //  didn't work
        //

        NewProcess->ObjectTable = NULL;

        if ( OldObjectTable ) {

            ObDereferenceProcessHandleTable( ParentProcess );
        }

        return (STATUS_INSUFFICIENT_RESOURCES);
    }
}


VOID
ObInitProcess2 (
    PEPROCESS NewProcess
    )

/*++

Routine Description:

    This function is called after an image file has been mapped into the address
    space of a newly created process.  Allows the object manager to set LIFO/FIFO
    ordering for handle allocation based on the SubSystemVersion number in the
    image.

Arguments:

    NewProcess - pointer to the process object being initialized.

Return Value:

    None.

--*/

{
    //
    //  Set LIFO ordering of handles for images <= SubSystemVersion 3.50
    //

    if (NewProcess->ObjectTable) {

        ExSetHandleTableOrder( NewProcess->ObjectTable, (BOOLEAN)(NewProcess->SubSystemVersion <= 0x332) );
    }

    return;
}


VOID
ObDestroyHandleProcedure (
    IN HANDLE HandleIndex
    )

/*++

Routine Description:

    This function is used to close a handle but takes as input a
    handle table index that it first translates to an handle
    before calling close.  Note that the handle index is really
    just the offset within the handle table entries.

Arguments:

    HandleIndex - Supplies a handle index for the handle being closed.

Return Value:

    None.

--*/

{
    ZwClose( HandleIndex );

    return;
}

BOOLEAN
ObpCloseHandleProcedure (
    IN PHANDLE_TABLE_ENTRY HandleTableEntry,
    IN HANDLE Handle,
    IN PVOID EnumParameter
    )
/*++

Routine Description:

    This function is used to close all the handles in a table

Arguments:

    HandleTableEntry - Current handle entry
    Handle - Handle for the entry
    EnumParameter - Sweep context, table and mode

Return Value:

    None.

--*/

{
    POBP_SWEEP_CONTEXT SweepContext;

    SweepContext = EnumParameter;
    ObpCloseHandleTableEntry (SweepContext->HandleTable,
                              HandleTableEntry,
                              Handle,
                              SweepContext->PreviousMode,
                              TRUE);
    return TRUE;
}

VOID
ObClearProcessHandleTable (
    PEPROCESS Process
    )
/*++

Routine Description:

    This function marks the process handle table for deletion and clears out all the handles.

Arguments:

    Process - Pointer to the process that is to be acted on.

--*/

{
    PHANDLE_TABLE ObjectTable;
    BOOLEAN AttachedToProcess = FALSE;
    KAPC_STATE ApcState;
    PETHREAD CurrentThread;
    OBP_SWEEP_CONTEXT SweepContext;

    ObjectTable = ObReferenceProcessHandleTable (Process);

    if (ObjectTable == NULL) {
        return;
    }


    CurrentThread = PsGetCurrentThread ();
    if (PsGetCurrentProcessByThread(CurrentThread) != Process) {
        KeStackAttachProcess (&Process->Pcb, &ApcState);
        AttachedToProcess = TRUE;
    }

    KeEnterCriticalRegionThread(&CurrentThread->Tcb);
    //
    // Close all the handles
    //
    SweepContext.PreviousMode = UserMode;
    SweepContext.HandleTable = ObjectTable;

    ExSweepHandleTable (ObjectTable,
                        ObpCloseHandleProcedure,
                        &SweepContext);

    KeLeaveCriticalRegionThread(&CurrentThread->Tcb);

    if (AttachedToProcess == TRUE) {
        KeUnstackDetachProcess (&ApcState);
    }

    ObDereferenceProcessHandleTable (Process);
    return;
}


VOID
ObKillProcess (
    PEPROCESS Process
    )
/*++

Routine Description:

    This function is called whenever a process is destroyed.  It loops over
    the process' object table and closes all the handles.

Arguments:

    Process - Pointer to the process that is being destroyed.

Return Value:

    None.

--*/

{
    PHANDLE_TABLE ObjectTable;
    BOOLEAN PreviousIOHardError;
    PKTHREAD CurrentThread;
    OBP_SWEEP_CONTEXT SweepContext;

    PAGED_CODE();

    ObpValidateIrql( "ObKillProcess" );

    //
    // Wait for any cross process references to finish
    //
    ExWaitForRundownProtectionRelease (&Process->RundownProtect);
    //
    // This routine gets recalled multiple times for the same object so just mark the object so future waits
    // work ok.
    //
    ExRundownCompleted (&Process->RundownProtect);

    //
    //  If the process does NOT have an object table, return
    //

    ObjectTable = Process->ObjectTable;

    if (ObjectTable != NULL) {

        PreviousIOHardError = IoSetThreadHardErrorMode(FALSE);

        //
        //  For each valid entry in the object table, close the handle
        //  that points to that entry.
        //

        //
        // Close all the handles
        //

        CurrentThread = KeGetCurrentThread ();

        KeEnterCriticalRegionThread(CurrentThread);

        SweepContext.PreviousMode = KernelMode;
        SweepContext.HandleTable = ObjectTable;

        ExSweepHandleTable (ObjectTable,
                            ObpCloseHandleProcedure,
                            &SweepContext);

        ASSERT (ObjectTable->HandleCount == 0);

        KeLeaveCriticalRegionThread(CurrentThread);

        IoSetThreadHardErrorMode( PreviousIOHardError );


        Process->ObjectTable = NULL;

        ExDestroyHandleTable( ObjectTable, NULL );
    }

    //
    //  And return to our caller
    //

    return;
}


//
//  The following structure is only used by the enumeration routine
//  and the callback.  It provides context for the comparison of
//  the objects.
//

typedef struct _OBP_FIND_HANDLE_DATA {

    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    POBJECT_HANDLE_INFORMATION HandleInformation;

} OBP_FIND_HANDLE_DATA, *POBP_FIND_HANDLE_DATA;

BOOLEAN
ObpEnumFindHandleProcedure (
    PHANDLE_TABLE_ENTRY ObjectTableEntry,
    HANDLE HandleId,
    PVOID EnumParameter
    )

/*++

Routine Description:

    Call back routine when enumerating an object table to find a handle
    for a particular object

Arguments:

    HandleTableEntry - Supplies a pointer to the handle table entry
        being examined.

    HandleId - Supplies the actual handle value for the preceding entry

    EnumParameter - Supplies context for the matching.

Return Value:

    Returns TRUE if a match is found and the enumeration should stop.  Returns FALSE
    otherwise, so the enumeration will continue.

--*/

{
    POBJECT_HEADER ObjectHeader;
    ACCESS_MASK GrantedAccess;
    ULONG HandleAttributes;
    POBP_FIND_HANDLE_DATA MatchCriteria = EnumParameter;

    UNREFERENCED_PARAMETER (HandleId);

    //
    //  Get the object header from the table entry and see if
    //  object types and headers match if specified.
    //

    ObjectHeader = (POBJECT_HEADER)((ULONG_PTR)ObjectTableEntry->Object & ~OBJ_HANDLE_ATTRIBUTES);

    if ((MatchCriteria->ObjectHeader != NULL) &&
        (MatchCriteria->ObjectHeader != ObjectHeader)) {

        return FALSE;
    }

    if ((MatchCriteria->ObjectType != NULL) &&
        (MatchCriteria->ObjectType != ObjectHeader->Type)) {

        return FALSE;
    }

    //
    //  Check if we have handle information that we need to compare
    //

    if (ARGUMENT_PRESENT( MatchCriteria->HandleInformation )) {

        //
        //  If we are tracing the call stacks for cached security indices then
        //  we have a translation to do.  Otherwise the table entry contains
        //  straight away the granted access mask.
        //

#if i386 

        if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

            GrantedAccess = ObpTranslateGrantedAccessIndex( ObjectTableEntry->GrantedAccessIndex );

        } else {

            GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);
        }
#else

        GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);

#endif // i386

        //
        //  Get the handle attributes from table entry and see if the
        //  fields match.  If they do not match we will return false to
        //  continue the search.
        //

        HandleAttributes = ObpGetHandleAttributes(ObjectTableEntry);

        if (MatchCriteria->HandleInformation->HandleAttributes != HandleAttributes ||
            MatchCriteria->HandleInformation->GrantedAccess != GrantedAccess ) {

            return FALSE;
        }
    }

    //
    //  We found something that matches our criteria so return true to
    //  our caller to stop the enumeration
    //

    return TRUE;
}


BOOLEAN
ObFindHandleForObject (
    IN PEPROCESS Process,
    IN PVOID Object OPTIONAL,
    IN POBJECT_TYPE ObjectType OPTIONAL,
    IN POBJECT_HANDLE_INFORMATION HandleInformation OPTIONAL,
    OUT PHANDLE Handle
    )

/*++

Routine Description:

    This routine searches the handle table for the specified process,
    looking for a handle table entry that matches the passed parameters.
    If an an Object pointer is specified it must match.  If an
    ObjectType is specified it must match.  If HandleInformation is
    specified, then both the HandleAttributes and GrantedAccess mask
    must match.  If all three match parameters are NULL, then will
    match the first allocated handle for the specified process that
    matches the specified object pointer.

Arguments:

    Process - Specifies the process whose object table is to be searched.

    Object - Specifies the object pointer to look for.

    ObjectType - Specifies the object type to look for.

    HandleInformation - Specifies additional match criteria to look for.

    Handle - Specifies the location to receive the handle value whose handle
        entry matches the supplied object pointer and optional match criteria.

Return Value:

    TRUE if a match was found and FALSE otherwise.

--*/

{
    PHANDLE_TABLE ObjectTable;
    OBP_FIND_HANDLE_DATA EnumParameter;
    BOOLEAN Result;

    Result = FALSE;

    //
    //  Lock the object object name space
    //

    ObjectTable = ObReferenceProcessHandleTable (Process);

    //
    //  We only do the work if the process has an object table meaning
    //  it isn't going away
    //

    if (ObjectTable != NULL) {

        //
        //  Set the match parameters that our caller supplied
        //

        if (ARGUMENT_PRESENT( Object )) {

            EnumParameter.ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

        } else {

            EnumParameter.ObjectHeader = NULL;
        }

        EnumParameter.ObjectType = ObjectType;
        EnumParameter.HandleInformation = HandleInformation;

        //
        //  Call the routine the enumerate the object table, this will
        //  return true if we get match.  The enumeration routine really
        //  returns a index into the object table entries we need to
        //  translate it to a real handle before returning.
        //

        if (ExEnumHandleTable( ObjectTable,
                               ObpEnumFindHandleProcedure,
                               &EnumParameter,
                               Handle )) {

            Result = TRUE;
        }

        ObDereferenceProcessHandleTable( Process );
    }

    return Result;
}


//
//  Local support routine
//

NTSTATUS
ObpCreateDosDevicesDirectory (
    VOID
    )

/*++

Routine Description:

    This routine creates the directory object for the dos devices and sets
    the device map for the system process.

Arguments:

    None.

Return Value:

    STATUS_SUCCESS or an appropriate error

--*/

{
    NTSTATUS Status;
    UNICODE_STRING NameString;
    UNICODE_STRING RootNameString;
    UNICODE_STRING TargetString;
    OBJECT_ATTRIBUTES ObjectAttributes;
    HANDLE DirectoryHandle;
    HANDLE SymbolicLinkHandle;
    SECURITY_DESCRIPTOR DosDevicesSD;

    //
    // Determine if LUID device maps are enabled or disabled
    // Store the result in ObpLUIDDeviceMapsEnabled
    //     0 - LUID device maps are disabled
    //     1 - LUID device maps are enabled
    //
    if ((ObpProtectionMode == 0) || (ObpLUIDDeviceMapsDisabled != 0)) {
        ObpLUIDDeviceMapsEnabled = 0;
    }
    else {
        ObpLUIDDeviceMapsEnabled = 1;
    }

    //
    //  Create the security descriptor to use for the \?? directory
    //

    Status = ObpGetDosDevicesProtection( &DosDevicesSD );

    if (!NT_SUCCESS( Status )) {

        return Status;
    }

    //
    //  Create the root directory object for the global \?? directory.
    //

    RtlInitUnicodeString( &RootNameString, ObpGlobalDosDevicesShortName );

    InitializeObjectAttributes( &ObjectAttributes,
                                &RootNameString,
                                OBJ_PERMANENT,
                                (HANDLE) NULL,
                                &DosDevicesSD );

    Status = NtCreateDirectoryObject( &DirectoryHandle,
                                      DIRECTORY_ALL_ACCESS,
                                      &ObjectAttributes );

    if (!NT_SUCCESS( Status )) {

        return Status;
    }

    //
    //  Create a device map that will control this directory.  It will be
    //  stored in the each EPROCESS for use by ObpLookupObjectName when
    //  translating names that begin with \??\
    //  With LUID device maps, the device map is stored in the each EPROCESS
    //  upon the first reference to the device map, and the EPROCESS
    //  device map field is cleared when the EPROCESS access token is set.
    //

    Status = ObSetDeviceMap( NULL, DirectoryHandle );


    //
    //  Now create a symbolic link, \??\GLOBALROOT, that points to \
    //  WorkStation service needs some mechanism to access a session specific
    //  DosDevicesDirectory. DosPathToSessionPath API will take a DosPath
    //  e.g (C:) and convert it into session specific path
    //  (e.g GLOBALROOT\Sessions\6\DosDevices\C:). The GLOBALROOT symbolic
    //  link is used to escape out of the current process's DosDevices directory
    //

    RtlInitUnicodeString( &NameString, L"GLOBALROOT" );
    RtlInitUnicodeString( &TargetString, L"" );

    InitializeObjectAttributes( &ObjectAttributes,
                                &NameString,
                                OBJ_PERMANENT,
                                DirectoryHandle,
                                &DosDevicesSD );

    Status = NtCreateSymbolicLinkObject( &SymbolicLinkHandle,
                                         SYMBOLIC_LINK_ALL_ACCESS,
                                         &ObjectAttributes,
                                         &TargetString );

    if (NT_SUCCESS( Status )) {

        NtClose( SymbolicLinkHandle );
    }

    //
    //  Create a symbolic link, \??\Global, that points to the global \??
    //  Drivers loaded dynamically create the symbolic link in the global
    //  DosDevices directory. User mode components need some way to access this
    //  symbolic link in the global dosdevices directory. The Global symbolic
    //  link is used to escape out of the current sessions's DosDevices directory
    //  and use the global dosdevices directory. e.g CreateFile("\\\\.\\Global\\NMDev"..);
    //

    RtlInitUnicodeString( &NameString, L"Global" );

    InitializeObjectAttributes( &ObjectAttributes,
                                &NameString,
                                OBJ_PERMANENT,
                                DirectoryHandle,
                                &DosDevicesSD );

    Status = NtCreateSymbolicLinkObject( &SymbolicLinkHandle,
                                         SYMBOLIC_LINK_ALL_ACCESS,
                                         &ObjectAttributes,
                                         &RootNameString );

    if (NT_SUCCESS( Status )) {

        NtClose( SymbolicLinkHandle );
    }


    NtClose( DirectoryHandle );

    if (!NT_SUCCESS( Status )) {

        return Status;
    }

    //
    //  Now create a symbolic link, \DosDevices, that points to \??
    //  for backwards compatibility with old drivers that use the old
    //  name.
    //

    RtlInitUnicodeString( &RootNameString, (PWCHAR)&ObpDosDevicesShortNameRoot );

    RtlCreateUnicodeString( &NameString, L"\\DosDevices" );

    InitializeObjectAttributes( &ObjectAttributes,
                                &NameString,
                                OBJ_PERMANENT,
                                (HANDLE) NULL,
                                &DosDevicesSD );

    Status = NtCreateSymbolicLinkObject( &SymbolicLinkHandle,
                                         SYMBOLIC_LINK_ALL_ACCESS,
                                         &ObjectAttributes,
                                         &RootNameString );

    if (NT_SUCCESS( Status )) {

        NtClose( SymbolicLinkHandle );
    }

    //
    //  All done with the security descriptor for \??
    //

    ObpFreeDosDevicesProtection( &DosDevicesSD );

    return STATUS_SUCCESS;
}


//
//  Local support routine
//

NTSTATUS
ObpGetDosDevicesProtection (
    PSECURITY_DESCRIPTOR SecurityDescriptor
    )

/*++

Routine Description:

    This routine builds a security descriptor for use in creating
    the \DosDevices object directory.  The protection of \DosDevices
    must establish inheritable protection which will dictate how
    dos devices created via the DefineDosDevice() and
    IoCreateUnprotectedSymbolicLink() apis can be managed.

    The protection assigned is dependent upon an administrable registry
    key:

        Key: \hkey_local_machine\System\CurrentControlSet\Control\Session Manager
        Value: [REG_DWORD] ProtectionMode

    If this value is 0x1, then

            Administrators may control all Dos devices,
            Anyone may create new Dos devices (such as net drives
                or additional printers),
            Anyone may use any Dos device,
            The creator of a Dos device may delete it.
            Note that this protects system-defined LPTs and COMs so that only
                administrators may redirect them.  However, anyone may add
                additional printers and direct them to wherever they would
                like.

           This is achieved with the following protection for the DosDevices
           Directory object:

                    Grant:  World:   Execute | Read         (No Inherit)
                    Grant:  System:  All Access             (No Inherit)
                    Grant:  World:   Execute                (Inherit Only)
                    Grant:  Admins:  All Access             (Inherit Only)
                    Grant:  System:  All Access             (Inherit Only)
                    Grant:  Owner:   All Access             (Inherit Only)

    If this value is 0x0, or not present, then

            Administrators may control all Dos devices,
            Anyone may create new Dos devices (such as net drives
                or additional printers),
            Anyone may use any Dos device,
            Anyone may delete Dos devices created with either DefineDosDevice()
                or IoCreateUnprotectedSymbolicLink().  This is how network drives
                and LPTs are created (but not COMs).

           This is achieved with the following protection for the DosDevices
           Directory object:

                    Grant:  World:   Execute | Read | Write (No Inherit)
                    Grant:  System:  All Access             (No Inherit)
                    Grant:  World:   All Access             (Inherit Only)


Arguments:

    SecurityDescriptor - The address of a security descriptor to be
        initialized and filled in.  When this security descriptor is no
        longer needed, you should call ObpFreeDosDevicesProtection() to
        free the protection information.


Return Value:

    Returns one of the following status codes:

        STATUS_SUCCESS - normal, successful completion.

        STATUS_NO_MEMORY - not enough memory


--*/

{
    NTSTATUS Status;
    ULONG aceIndex, aclLength;
    PACL dacl;
    PACE_HEADER ace;
    ACCESS_MASK accessMask;

    UCHAR inheritOnlyFlags = (OBJECT_INHERIT_ACE    |
                              CONTAINER_INHERIT_ACE |
                              INHERIT_ONLY_ACE
                             );

    //
    //  NOTE:  This routine expects the value of ObpProtectionMode to have been set
    //

    Status = RtlCreateSecurityDescriptor( SecurityDescriptor, SECURITY_DESCRIPTOR_REVISION );

    ASSERT( NT_SUCCESS( Status ) );

    if (ObpProtectionMode & 0x00000001) {

        //
        //  Dacl:
        //          Grant:  World:   Execute | Read         (No Inherit)
        //          Grant:  System:  All Access             (No Inherit)
        //          Grant:  World:   Execute                (Inherit Only)
        //          Grant:  Admins:  All Access             (Inherit Only)
        //          Grant:  System:  All Access             (Inherit Only)
        //          Grant:  Owner:   All Access             (Inherit Only)
        //

        aclLength = sizeof( ACL )                           +
                    6 * sizeof( ACCESS_ALLOWED_ACE )        +
                    (2*RtlLengthSid( SeWorldSid ))          +
                    (2*RtlLengthSid( SeLocalSystemSid ))    +
                    RtlLengthSid( SeAliasAdminsSid )        +
                    RtlLengthSid( SeCreatorOwnerSid );

        dacl = (PACL)ExAllocatePool(PagedPool, aclLength );

        if (dacl == NULL) {

            return STATUS_NO_MEMORY;
        }

        Status = RtlCreateAcl( dacl, aclLength, ACL_REVISION2);
        ASSERT( NT_SUCCESS( Status ) );

        //
        //  Non-inheritable ACEs first
        //      World
        //      System
        //

        aceIndex = 0;
        accessMask = (GENERIC_READ | GENERIC_EXECUTE);
        Status = RtlAddAccessAllowedAce ( dacl, ACL_REVISION2, accessMask, SeWorldSid );
        ASSERT( NT_SUCCESS( Status ) );
        aceIndex++;
        accessMask = (GENERIC_ALL);
        Status = RtlAddAccessAllowedAce ( dacl, ACL_REVISION2, accessMask, SeLocalSystemSid );
        ASSERT( NT_SUCCESS( Status ) );

        //
        //  Inheritable ACEs at the end of the ACL
        //          World
        //          Admins
        //          System
        //          Owner
        //

        aceIndex++;
        accessMask = (GENERIC_EXECUTE);
        Status = RtlAddAccessAllowedAce ( dacl, ACL_REVISION2, accessMask, SeWorldSid );
        ASSERT( NT_SUCCESS( Status ) );
        Status = RtlGetAce( dacl, aceIndex, (PVOID)&ace );
        ASSERT( NT_SUCCESS( Status ) );
        ace->AceFlags |= inheritOnlyFlags;

        aceIndex++;
        accessMask = (GENERIC_ALL);
        Status = RtlAddAccessAllowedAce ( dacl, ACL_REVISION2, accessMask, SeAliasAdminsSid );
        ASSERT( NT_SUCCESS( Status ) );
        Status = RtlGetAce( dacl, aceIndex, (PVOID)&ace );
        ASSERT( NT_SUCCESS( Status ) );
        ace->AceFlags |= inheritOnlyFlags;

        aceIndex++;
        accessMask = (GENERIC_ALL);
        Status = RtlAddAccessAllowedAce ( dacl, ACL_REVISION2, accessMask, SeLocalSystemSid );
        ASSERT( NT_SUCCESS( Status ) );
        Status = RtlGetAce( dacl, aceIndex, (PVOID)&ace );
        ASSERT( NT_SUCCESS( Status ) );
        ace->AceFlags |= inheritOnlyFlags;

        aceIndex++;
        accessMask = (GENERIC_ALL);
        Status = RtlAddAccessAllowedAce ( dacl, ACL_REVISION2, accessMask, SeCreatorOwnerSid );
        ASSERT( NT_SUCCESS( Status ) );
        Status = RtlGetAce( dacl, aceIndex, (PVOID)&ace );
        ASSERT( NT_SUCCESS( Status ) );
        ace->AceFlags |= inheritOnlyFlags;

        Status = RtlSetDaclSecurityDescriptor( SecurityDescriptor,
                                               TRUE,               //DaclPresent,
                                               dacl,               //Dacl
                                               FALSE );            //!DaclDefaulted

        ASSERT( NT_SUCCESS( Status ) );

    } else {

        //
        //  DACL:
        //          Grant:  World:   Execute | Read | Write (No Inherit)
        //          Grant:  System:  All Access             (No Inherit)
        //          Grant:  World:   All Access             (Inherit Only)
        //

        aclLength = sizeof( ACL )                           +
                    3 * sizeof( ACCESS_ALLOWED_ACE )        +
                    (2*RtlLengthSid( SeWorldSid ))          +
                    RtlLengthSid( SeLocalSystemSid );

        dacl = (PACL)ExAllocatePool(PagedPool, aclLength );

        if (dacl == NULL) {

            return STATUS_NO_MEMORY;
        }

        Status = RtlCreateAcl( dacl, aclLength, ACL_REVISION2);
        ASSERT( NT_SUCCESS( Status ) );

        //
        //  Non-inheritable ACEs first
        //      World
        //      System
        //

        aceIndex = 0;
        accessMask = (GENERIC_READ | GENERIC_WRITE | GENERIC_EXECUTE);
        Status = RtlAddAccessAllowedAce ( dacl, ACL_REVISION2, accessMask, SeWorldSid );
        ASSERT( NT_SUCCESS( Status ) );

        aceIndex++;
        accessMask = (GENERIC_ALL);
        Status = RtlAddAccessAllowedAce ( dacl, ACL_REVISION2, accessMask, SeLocalSystemSid );
        ASSERT( NT_SUCCESS( Status ) );

        //
        //  Inheritable ACEs at the end of the ACL
        //          World
        //

        aceIndex++;
        accessMask = (GENERIC_ALL);
        Status = RtlAddAccessAllowedAce ( dacl, ACL_REVISION2, accessMask, SeWorldSid );
        ASSERT( NT_SUCCESS( Status ) );
        Status = RtlGetAce( dacl, aceIndex, (PVOID)&ace );
        ASSERT( NT_SUCCESS( Status ) );
        ace->AceFlags |= inheritOnlyFlags;

        Status = RtlSetDaclSecurityDescriptor( SecurityDescriptor,
                                               TRUE,               //DaclPresent,
                                               dacl,               //Dacl
                                               FALSE );            //!DaclDefaulted

        ASSERT( NT_SUCCESS( Status ) );
    }

    return STATUS_SUCCESS;
}


//
//  Local support routine
//

VOID
ObpFreeDosDevicesProtection (
    PSECURITY_DESCRIPTOR SecurityDescriptor
    )

/*++

Routine Description:

    This routine frees memory allocated via ObpGetDosDevicesProtection().

Arguments:

    SecurityDescriptor - The address of a security descriptor initialized by
        ObpGetDosDevicesProtection().

Return Value:

    None.

--*/

{
    NTSTATUS Status;
    PACL Dacl;
    BOOLEAN DaclPresent, Defaulted;

    Status = RtlGetDaclSecurityDescriptor ( SecurityDescriptor,
                                            &DaclPresent,
                                            &Dacl,
                                            &Defaulted );

    ASSERT( NT_SUCCESS( Status ) );
    ASSERT( DaclPresent );
    ASSERT( Dacl != NULL );

    ExFreePool( (PVOID)Dacl );
    
    return;
}

BOOLEAN
ObpShutdownCloseHandleProcedure (
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE HandleId,
    IN PVOID EnumParameter
    )

/*++

Routine Description:

    ExEnumHandleTable worker routine will call this routine for each
    valid handle into the kernel table at shutdown

Arguments:

    ObjectTableEntry - Points to the handle table entry of interest.

    HandleId - Supplies the handle.

    EnumParameter - Supplies information about the source and target processes.

Return Value:

    FALSE, which tells ExEnumHandleTable to continue iterating through the
    handle table.

--*/

{

    POBJECT_HEADER ObjectHeader;
    PULONG         NumberOfOpenHandles;

#if !DBG
    UNREFERENCED_PARAMETER (HandleId);
#endif
    //
    //  Get the object header from the table entry and then copy over the information
    //

    ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

    //
    //  Dump the leak info for the checked build
    //

    KdPrint(("\tFound object %p (handle %08lx)\n",
              &ObjectHeader->Body,
              HandleId
            ));

    NumberOfOpenHandles = (PULONG)EnumParameter;
    ASSERT(NumberOfOpenHandles);

    ++*NumberOfOpenHandles;

    return( FALSE );
}

extern PLIST_ENTRY *ObsSecurityDescriptorCache;


//
//  Object manager shutdown routine
//

VOID
ObShutdownSystem (
    IN ULONG Phase
    )

/*++

Routine Description:

    This routine frees the objects created by the object manager.

Arguments:

Return Value:

    None.

--*/

{
    switch (Phase) {
    case 0:
    {
        ULONG                    Bucket,
                                 Depth,
                                 SymlinkHitDepth;
        POBJECT_TYPE             ObjectType;
        POBJECT_HEADER_NAME_INFO NameInfo;
#if DBG
        KIRQL                    SaveIrql;
#endif
        POBJECT_HEADER           ObjectHeader;
        POBJECT_DIRECTORY        Directory,
                                 DescentDirectory;
        POBJECT_DIRECTORY_ENTRY  OldDirectoryEntry,
                                *DirectoryEntryPtr;
        PVOID                    Object;

        Directory = ObpRootDirectoryObject;

        DescentDirectory = NULL;

        // The starting depth is completely arbitrary, but not using
        // zero as a valid depth lets us use it as a sentinel to
        // ensure we haven't over-decremented it, and as a check at
        // the end (where it should be one less than its starting value).
        Depth = 1;
        SymlinkHitDepth = 1;

        while (Directory) {

            ASSERT(Depth);

      restart_dir_walk:
            ASSERT(Directory);

            for (Bucket = 0;
                 Bucket < NUMBER_HASH_BUCKETS;
                 Bucket++) {

                DirectoryEntryPtr = Directory->HashBuckets + Bucket;
                while (*DirectoryEntryPtr) {
                    Object = (*DirectoryEntryPtr)->Object;
                    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
                    ObjectType = ObjectHeader->Type;
                    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

                    if (DescentDirectory) {
                        // We're recovering from a descent; we want to
                        // iterate forward until we're past the
                        // directory which we were just processing.
                        if (Object == DescentDirectory) {
                            DescentDirectory = NULL;
                            if (SymlinkHitDepth > Depth) {
                                // We hit a symlink in that descent, which
                                // potentially rearranged the buckets in
                                // this chain; we need to rescan the
                                // entire chain.
                                DirectoryEntryPtr =
                                    Directory->HashBuckets + Bucket;
                                SymlinkHitDepth = Depth;
                                continue;
                            }
                        }

                        // Either we haven't found the descent dir
                        // yet, or we did (and set it to NULL, so
                        // we'll stop skipping things), and don't have
                        // to deal with a symlink readjustment --
                        // either way, march forward.

                        DirectoryEntryPtr =
                            &(*DirectoryEntryPtr)->ChainLink;

                        continue;
                    }

                    if (ObjectType == ObpTypeObjectType) {
                        // We'll clean these up later
                        // Keep going down the chain
                        DirectoryEntryPtr =
                            &(*DirectoryEntryPtr)->ChainLink;
                        continue;
                    } else if (ObjectType == ObpDirectoryObjectType) {
                        // Iteratively descend
                        Directory = Object;
                        Depth++;
                        goto restart_dir_walk;
                    } else {
                        // It's an object not related to Ob object
                        // management; mark it non-permanent, and if
                        // it doesn't have any handles, remove it from
                        // the directory (delete the name and
                        // dereference it once).

                        ObpLockObject( ObjectHeader );

                        ObjectHeader->Flags &= ~OB_FLAG_PERMANENT_OBJECT;

                        ObpUnlockObject( ObjectHeader );

                        if (ObjectHeader->HandleCount == 0) {
                            OldDirectoryEntry = *DirectoryEntryPtr;
                            *DirectoryEntryPtr = OldDirectoryEntry->ChainLink;
                            ExFreePool(OldDirectoryEntry);

                            if ( !ObjectType->TypeInfo.SecurityRequired ) {

                                ObpBeginTypeSpecificCallOut( SaveIrql );

                                (ObjectType->TypeInfo.SecurityProcedure)( Object,
                                                                          DeleteSecurityDescriptor,
                                                                          NULL,
                                                                          NULL,
                                                                          NULL,
                                                                          &ObjectHeader->SecurityDescriptor,
                                                                          ObjectType->TypeInfo.PoolType,
                                                                          NULL );

                                ObpEndTypeSpecificCallOut( SaveIrql, "Security", ObjectType, Object );
                            }

                            //
                            //  If this is a symbolic link object then we also need to
                            //  delete the symbolic link
                            //

                            if (ObjectType == ObpSymbolicLinkObjectType) {
                                SymlinkHitDepth = Depth;
                                ObpDeleteSymbolicLinkName( (POBJECT_SYMBOLIC_LINK)Object );
                                // Since ObpDeleteSymbolicLinkName may
                                // potentially rearrange our buckets,
                                // we need to rescan from the
                                // beginning of this hash chain.
                                DirectoryEntryPtr =
                                    Directory->HashBuckets + Bucket;
                            }

                            //
                            //  Free the name buffer and zero out the name data fields
                            //

                            ExFreePool( NameInfo->Name.Buffer );

                            NameInfo->Name.Buffer = NULL;
                            NameInfo->Name.Length = 0;
                            NameInfo->Name.MaximumLength = 0;
                            NameInfo->Directory = NULL;

                            ObDereferenceObject( Object );
                            ObDereferenceObject( Directory );
                        } else {
                            // Keep going down the chain
                            DirectoryEntryPtr = &(*DirectoryEntryPtr)->ChainLink;
                        }
                    }
                } // while *DirectoryObjectPtr
            } // loop over buckets

            // Well -- we're done with this directory.  We might have
            // been processing it as a child directory, though -- so
            // if it has a parent, we need to go back up to it, and
            // reset our iteration.

            Depth--;
            ObjectHeader = OBJECT_TO_OBJECT_HEADER(Directory);
            NameInfo = OBJECT_HEADER_TO_NAME_INFO(ObjectHeader);

            // We always assign DescentDirectory and Directory here; if
            // the current directory does not have a parent (i.e. it's
            // the root), this will terminate the iteration.
            DescentDirectory = Directory;
            Directory = NameInfo->Directory;
        } // while (Directory)

        ASSERT(Depth == 0);

        break;
    } // Phase 0

    case 1:
    {
        ULONG NumberOfOpenSystemHandles = 0;

        //
        //  Iterate through the handle tables, and look for existing handles
        //

        KdPrint(("Scanning open system handles...\n"));
        ExEnumHandleTable ( PsInitialSystemProcess->ObjectTable,
                            ObpShutdownCloseHandleProcedure,
                            &NumberOfOpenSystemHandles,
                            NULL );

        ASSERT(MmNumberOfPagingFiles == 0);

        // ISSUE-2000/03/30-earhart: Destroy the kernel handle table?
        // We really can't do this until the paging files are
        // closed... and once we do, we can't really touch pagable
        // memory.  Hrm.

        // ExDestroyHandleTable( ObpKernelHandleTable, NULL );

        break;

    } // Phase 1

    default:
    {
        NTSTATUS Status;
        UNICODE_STRING RootNameString;
        PLIST_ENTRY Next, Head;
        POBJECT_HEADER_CREATOR_INFO CreatorInfo;
        POBJECT_HEADER  ObjectTypeHeader;
        PVOID Object;

        ASSERT(Phase == 2);

        //
        //  Free the SecurityDescriptor chche
        //

    //
    //  Remove all types from the object type directory
    //

        Head = &ObpTypeObjectType->TypeList;
        Next = Head->Flink;

        while (Next != Head) {

            PVOID Object;

            //
            //  Right after the creator info is the object header.  Get\
            //  the object header and then see if there is a name
            //

            CreatorInfo = CONTAINING_RECORD( Next,
                                             OBJECT_HEADER_CREATOR_INFO,
                                             TypeList );

            ObjectTypeHeader = (POBJECT_HEADER)(CreatorInfo+1);

            Object = &ObjectTypeHeader->Body;

            Next = Next->Flink;

            ObMakeTemporaryObject(Object);
        }


        RtlInitUnicodeString( &RootNameString, L"DosDevices" );

        Status = ObReferenceObjectByName( &RootNameString,
                                          OBJ_CASE_INSENSITIVE,
                                          0L,
                                          0,
                                          ObpSymbolicLinkObjectType,
                                          KernelMode,
                                          NULL,
                                          &Object
            );
        if ( NT_SUCCESS( Status ) ) {

            ObMakeTemporaryObject(Object);
            ObDereferenceObject( Object );
        }

        RtlInitUnicodeString( &RootNameString, L"Global" );

        Status = ObReferenceObjectByName( &RootNameString,
                                          OBJ_CASE_INSENSITIVE,
                                          0L,
                                          0,
                                          ObpSymbolicLinkObjectType,
                                          KernelMode,
                                          NULL,
                                          &Object
            );
        
        if ( NT_SUCCESS( Status ) ) {

            ObMakeTemporaryObject(Object);
            ObDereferenceObject( Object );
        }

        RtlInitUnicodeString( &RootNameString, L"GLOBALROOT" );

        Status = ObReferenceObjectByName( &RootNameString,
                                          OBJ_CASE_INSENSITIVE,
                                          0L,
                                          0,
                                          ObpSymbolicLinkObjectType,
                                          KernelMode,
                                          NULL,
                                          &Object
            );
        if ( NT_SUCCESS( Status ) ) {

            ObMakeTemporaryObject(Object);
            ObDereferenceObject( Object );
        }

        //
        //  Destroy the root directory
        //

        ObDereferenceObject( ObpRootDirectoryObject );

        //
        //  Destroy the ObpDirectoryObjectType object
        //

        ObDereferenceObject( ObpDirectoryObjectType );

        //
        //  Destroy the ObpSymbolicLinkObjectType
        //

        ObDereferenceObject( ObpSymbolicLinkObjectType );

        //
        //  Destroy the type directory object
        //

        ObDereferenceObject( ObpTypeDirectoryObject );

        //
        //  Destroy the ObpTypeObjectType
        //

        ObDereferenceObject( ObpTypeObjectType );

        //
        //  Free the ObpCachedGrantedAccesses pool
        //

#if i386 
        if (ObpCachedGrantedAccesses) {
            ExFreePool( ObpCachedGrantedAccesses );
        }
#endif // i386 

    } // default Phase (2)
    } // switch (Phase)
}


ULONG
ObGetSecurityMode (
    )
{
    return ObpObjectSecurityMode;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obdir.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obdir.c

Abstract:

    Directory Object routines

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"
#include <stdio.h>

POBJECT_DIRECTORY
ObpGetShadowDirectory(
    POBJECT_DIRECTORY Dir
    );

//
// Defined in ntos\se\rmlogon.c
// private kernel function to obtain the LUID device map's directory
// object
// returns a kernel handle
//
NTSTATUS
SeGetLogonIdDeviceMap(
    IN PLUID pLogonId,
    OUT PDEVICE_MAP* ppDevMap
    );

NTSTATUS
ObpSetCurrentProcessDeviceMap(
    );

POBJECT_HEADER_NAME_INFO
ObpTryReferenceNameInfoExclusive(
    IN POBJECT_HEADER ObjectHeader
    );

VOID
ObpReleaseExclusiveNameLock(
    IN POBJECT_HEADER ObjectHeader
    );

POBJECT_DIRECTORY_ENTRY
ObpUnlinkDirectoryEntry (
    IN POBJECT_DIRECTORY Directory,
    IN ULONG HashIndex
    );

VOID
ObpLinkDirectoryEntry (
    IN POBJECT_DIRECTORY Directory,
    IN ULONG HashIndex,
    IN POBJECT_DIRECTORY_ENTRY NewDirectoryEntry
    );

VOID
ObpReleaseLookupContextObject (
    IN POBP_LOOKUP_CONTEXT LookupContext
    );

#if defined(ALLOC_PRAGMA)
#pragma alloc_text(PAGE,NtCreateDirectoryObject)
#pragma alloc_text(PAGE,NtOpenDirectoryObject)
#pragma alloc_text(PAGE,NtQueryDirectoryObject)
#pragma alloc_text(PAGE,ObpLookupDirectoryEntry)
#pragma alloc_text(PAGE,ObpInsertDirectoryEntry)
#pragma alloc_text(PAGE,ObpDeleteDirectoryEntry)
#pragma alloc_text(PAGE,ObpLookupObjectName)
#pragma alloc_text(PAGE,NtMakePermanentObject)

#ifdef OBP_PAGEDPOOL_NAMESPACE
#pragma alloc_text(PAGE,ObpGetShadowDirectory)
#pragma alloc_text(PAGE,ObpSetCurrentProcessDeviceMap)
#pragma alloc_text(PAGE,ObpReferenceDeviceMap)
#pragma alloc_text(PAGE,ObfDereferenceDeviceMap)
#pragma alloc_text(PAGE,ObSwapObjectNames)
#pragma alloc_text(PAGE,ObpReleaseLookupContextObject)
#pragma alloc_text(PAGE,ObpLinkDirectoryEntry)
#pragma alloc_text(PAGE,ObpUnlinkDirectoryEntry)
#pragma alloc_text(PAGE,ObpReleaseExclusiveNameLock)
#pragma alloc_text(PAGE,ObpTryReferenceNameInfoExclusive)
 
#endif  // OBP_PAGEDPOOL_NAMESPACE

#endif

//
//  Global Object manager flags to control the case sensitivity lookup
//  and the LUID devicemap lookup
//

ULONG ObpCaseInsensitive = 1;
extern ULONG ObpLUIDDeviceMapsEnabled;

WCHAR ObpUnsecureGlobalNamesBuffer[128] = { 0 };
ULONG ObpUnsecureGlobalNamesLength = sizeof(ObpUnsecureGlobalNamesBuffer);

BOOLEAN
ObpIsUnsecureName(
    IN PUNICODE_STRING ObjectName,
    IN BOOLEAN CaseInsensitive
    )
{
    PWCHAR CrtName;
    UNICODE_STRING UnsecurePrefix;

    if (ObpUnsecureGlobalNamesBuffer[0] == 0) {

        return FALSE;
    }

    CrtName = ObpUnsecureGlobalNamesBuffer;

    do {

        RtlInitUnicodeString(&UnsecurePrefix, CrtName);

        if (UnsecurePrefix.Length) {

            if (RtlPrefixUnicodeString( &UnsecurePrefix, ObjectName, CaseInsensitive)) {

                return TRUE;
            }
        }

        CrtName += (UnsecurePrefix.Length + sizeof(UNICODE_NULL)) / sizeof(WCHAR);

    } while ( UnsecurePrefix.Length );

    return FALSE;
}


NTSTATUS
NtCreateDirectoryObject (
    OUT PHANDLE DirectoryHandle,
    IN ACCESS_MASK DesiredAccess,
    IN POBJECT_ATTRIBUTES ObjectAttributes
    )

/*++

Routine Description:

    This routine creates a new directory object according to user
    specified object attributes

Arguments:

    DirectoryHandle - Receives the handle for the newly created
        directory object

    DesiredAccess - Supplies the access being requested for this
        new directory object

    ObjectAttributes - Supplies caller specified attributes for new
        directory object

Return Value:

    An appropriate status value.

--*/

{
    POBJECT_DIRECTORY Directory;
    HANDLE Handle;
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;

    PAGED_CODE();

    ObpValidateIrql( "NtCreateDirectoryObject" );

    //
    //  Get previous processor mode and probe output arguments if necessary.
    //

    PreviousMode = KeGetPreviousMode();

    if (PreviousMode != KernelMode) {

        try {

            ProbeForWriteHandle( DirectoryHandle );

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            return( GetExceptionCode() );
        }
    }

    //
    //  Allocate and initialize a new Directory Object.  We don't need
    //  to specify a parse context or charge any quota.  The size of
    //  the object body is simply a directory object.  This call gets
    //  us a new referenced object.
    //

    Status = ObCreateObject( PreviousMode,
                             ObpDirectoryObjectType,
                             ObjectAttributes,
                             PreviousMode,
                             NULL,
                             sizeof( *Directory ),
                             0,
                             0,
                             (PVOID *)&Directory );

    if (!NT_SUCCESS( Status )) {

        return( Status );
    }

    RtlZeroMemory( Directory, sizeof( *Directory ) );

    ExInitializePushLock( &Directory->Lock );
    Directory->SessionId = OBJ_INVALID_SESSION_ID;

    //
    //  Insert directory object in the current processes handle table,
    //  set directory handle value and return status.
    //
    //  ObInsertObject will delete the object in the case of failure
    //

    Status = ObInsertObject( Directory,
                             NULL,
                             DesiredAccess,
                             0,
                             (PVOID *)NULL,
                             &Handle );

    try {

        *DirectoryHandle = Handle;

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        //
        //  Fall through, since we do not want to undo what we have done.
        //
    }

    return( Status );
}


NTSTATUS
NtOpenDirectoryObject (
    OUT PHANDLE DirectoryHandle,
    IN ACCESS_MASK DesiredAccess,
    IN POBJECT_ATTRIBUTES ObjectAttributes
    )

/*++

Routine Description:

    This routine opens an existing directory object.

Arguments:

    DirectoryHandle - Receives the handle for the newly opened directory
        object

    DesiredAccess - Supplies the access being requested for this
        directory object

    ObjectAttributes - Supplies caller specified attributes for the
        directory object

Return Value:

    An appropriate status value.

--*/

{
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;
    HANDLE Handle;

    PAGED_CODE();

    ObpValidateIrql( "NtOpenDirectoryObject" );

    //
    //  Get previous processor mode and probe output arguments if necessary.
    //

    PreviousMode = KeGetPreviousMode();

    if (PreviousMode != KernelMode) {

        try {

            ProbeForWriteHandle( DirectoryHandle );

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            return( GetExceptionCode() );
        }
    }

    //
    //  Open handle to the directory object with the specified desired access,
    //  set directory handle value, and return service completion status.
    //

    Status = ObOpenObjectByName( ObjectAttributes,
                                 ObpDirectoryObjectType,
                                 PreviousMode,
                                 NULL,
                                 DesiredAccess,
                                 NULL,
                                 &Handle );

    try {

        *DirectoryHandle = Handle;

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        //
        //  Fall through, since we do not want to undo what we have done.
        //
    }

    return Status;
}


NTSTATUS
NtQueryDirectoryObject (
    IN HANDLE DirectoryHandle,
    OUT PVOID Buffer,
    IN ULONG Length,
    IN BOOLEAN ReturnSingleEntry,
    IN BOOLEAN RestartScan,
    IN OUT PULONG Context,
    OUT PULONG ReturnLength OPTIONAL
    )

/*++

Routine Description:

    This function returns information regarding a specified object
    directory.

Arguments:

    DirectoryHandle - Supplies a handle to the directory being queried

    Buffer - Supplies the output buffer to receive the directory
        information.  On return this contains one or more OBJECT DIRECTORY
        INFORMATION structures, the last one being null.  And then this is
        followed by the string names for the directory entries.

    Length - Supplies the length, in bytes, of the user supplied output
        buffer

    ReturnSingleEntry - Indicates if this routine should just return
        one entry in the directory

    RestartScan - Indicates if we are to restart the scan or continue
        relative to the enumeration context passed in as the next
        parameter

    Context - Supplies an enumeration context that must be resupplied
        to this routine on subsequent calls to keep the enumeration
        in sync

    ReturnLength - Optionally receives the length, in bytes, that this
        routine has stuffed into the output buffer

Return Value:

    An appropriate status value.

--*/

{
    POBJECT_DIRECTORY Directory;
    POBJECT_DIRECTORY_ENTRY DirectoryEntry;
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;
    UNICODE_STRING ObjectName;
    POBJECT_DIRECTORY_INFORMATION DirInfo;
    PWCH NameBuffer;
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;
    ULONG Bucket, EntryNumber, CapturedContext;
    ULONG TotalLengthNeeded, LengthNeeded, EntriesFound;
    PCHAR TempBuffer;
    OBP_LOOKUP_CONTEXT LookupContext;

    PAGED_CODE();

    ObpValidateIrql( "NtQueryDirectoryObject" );

    ObpInitializeLookupContext( &LookupContext );

    //
    //  Get previous processor mode and probe output arguments if necessary.
    //

    PreviousMode = KeGetPreviousMode();

    if (PreviousMode != KernelMode) {

        try {

            ProbeForWrite( Buffer, Length, sizeof( WCHAR ) );
            ProbeForWriteUlong( Context );

            if (ARGUMENT_PRESENT( ReturnLength )) {

                ProbeForWriteUlong( ReturnLength );
            }

            if (RestartScan) {

                CapturedContext = 0;

            } else {

                CapturedContext = *Context;
            }

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            return( GetExceptionCode() );
        }

    } else {

        if (RestartScan) {

            CapturedContext = 0;

        } else {

            CapturedContext = *Context;
        }
    }

    //
    //  Test for 64 bit if Length + sizeof( OBJECT_DIRECTORY_INFORMATION ) is less than Length
    //  Return STATUS_INVALID_PARAMETER if there is an overflow
    //

    if (ObpIsOverflow( Length, sizeof( OBJECT_DIRECTORY_INFORMATION ))) {

        return( STATUS_INVALID_PARAMETER );
    }

    //
    //  Allocate space for a temporary work buffer, make sure we got it,
    //  and then zero it out.  Make sure the buffer is large enough to
    //  hold at least one dir info record.  This will make the logic work
    //  better when the a bad length is passed in.
    //

    TempBuffer = ExAllocatePoolWithQuotaTag( PagedPool | POOL_QUOTA_FAIL_INSTEAD_OF_RAISE,
                                             Length + sizeof( OBJECT_DIRECTORY_INFORMATION ),
                                             'mNbO' );

    if (TempBuffer == NULL) {

        return( STATUS_INSUFFICIENT_RESOURCES );
    }

    RtlZeroMemory( TempBuffer, Length );

    //
    //  Reference the directory object
    //

    Status = ObReferenceObjectByHandle( DirectoryHandle,
                                        DIRECTORY_QUERY,
                                        ObpDirectoryObjectType,
                                        PreviousMode,
                                        (PVOID *)&Directory,
                                        NULL );

    if (!NT_SUCCESS( Status )) {

        ExFreePool( TempBuffer );

        return( Status );
    }

    //
    //  Lock down the directory structures for the life of this
    //  procedure
    //

    ObpLockDirectoryShared(Directory, &LookupContext);

    //
    //  DirInfo is used to march through the output buffer filling
    //  in directory information.  We'll start off by making sure
    //  there is room for a NULL entry at end.
    //

    DirInfo = (POBJECT_DIRECTORY_INFORMATION)TempBuffer;

    TotalLengthNeeded = sizeof( *DirInfo );

    //
    //  Keep track of the number of entries found and actual
    //  entry that we are processing
    //

    EntryNumber = 0;
    EntriesFound = 0;

    //
    //  By default we'll say there are no more entries until the
    //  following loop put in some data
    //

    Status = STATUS_NO_MORE_ENTRIES;

    //
    //  Our outer loop processes each hash bucket in the directory object
    //

    for (Bucket=0; Bucket<NUMBER_HASH_BUCKETS; Bucket++) {

        DirectoryEntry = Directory->HashBuckets[ Bucket ];

        //
        //  For this hash bucket we'll zip through its list of entries.
        //  This is a singly linked list so when the next pointer is null
        //  (i.e., false) we at the end of the hash list
        //

        while (DirectoryEntry) {

            //
            //  The captured context is simply the entry count unless the
            //  user specified otherwise we start at zero, which means
            //  the first entry is always returned in the enumeration.
            //  If we have an match based on the entry index then we
            //  process this entry.  We bump the captured context further
            //  done in the code.
            //

            if (CapturedContext == EntryNumber++) {

                //
                //  For this directory entry we'll get a pointer to the
                //  object body and see if it has an object name.  If it
                //  doesn't have a name then we'll give it an empty name.
                //

                ObjectHeader = OBJECT_TO_OBJECT_HEADER( DirectoryEntry->Object );
                NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

                if (NameInfo != NULL) {

                    ObjectName = NameInfo->Name;

                } else {

                    RtlInitUnicodeString( &ObjectName, NULL );
                }

                //
                //  Now compute the length needed for this entry.  This would
                //  be the size of the object directory information record,
                //  plus the size of the object name and object type name both
                //  null terminated.
                //

                LengthNeeded = sizeof( *DirInfo ) +
                               ObjectName.Length + sizeof( UNICODE_NULL ) +
                               ObjectHeader->Type->Name.Length + sizeof( UNICODE_NULL );

                //
                //  If there isn't enough room then take the following error
                //  path.   If the user wanted a single entry then tell the
                //  caller what length is really needed and say the buffer was
                //  too small.  Otherwise the user wanted multiple entries,
                //  so we'll just say there are more entries in the directory.
                //  In both cases we drop down the entry number because we
                //  weren't able to fit it in on this call
                //

                if ((TotalLengthNeeded + LengthNeeded) > Length) {

                    if (ReturnSingleEntry) {

                        TotalLengthNeeded += LengthNeeded;

                        Status = STATUS_BUFFER_TOO_SMALL;

                    } else {

                        Status = STATUS_MORE_ENTRIES;
                    }

                    EntryNumber -= 1;
                    goto querydone;
                }

                //
                //  The information will fit in the buffer.  So now fill
                //  in the output buffer.  We temporarily put in pointers
                //  to the name buffer as stored in the object and object
                //  type.  We copy the data buffer to the user buffer
                //  right before we return to the caller
                //

                try {

                    DirInfo->Name.Length            = ObjectName.Length;
                    DirInfo->Name.MaximumLength     = (USHORT)(ObjectName.Length+sizeof( UNICODE_NULL ));
                    DirInfo->Name.Buffer            = ObjectName.Buffer;

                    DirInfo->TypeName.Length        = ObjectHeader->Type->Name.Length;
                    DirInfo->TypeName.MaximumLength = (USHORT)(ObjectHeader->Type->Name.Length+sizeof( UNICODE_NULL ));
                    DirInfo->TypeName.Buffer        = ObjectHeader->Type->Name.Buffer;

                    Status = STATUS_SUCCESS;

                } except( EXCEPTION_EXECUTE_HANDLER ) {

                    Status = GetExceptionCode();
                }

                if (!NT_SUCCESS( Status )) {

                    goto querydone;
                }

                //
                //  Update the total number of bytes needed in this query.
                //  Push the dir info pointer to the next output location,
                //  and indicate how many entries we've processed
                //
                //

                TotalLengthNeeded += LengthNeeded;

                DirInfo++;
                EntriesFound++;

                //
                //  If we are to return only one entry then move on to the
                //  post processing phase, otherwise indicate that we're
                //  processing the next entry and go back to the top of
                //  the inner loop
                //

                if (ReturnSingleEntry) {

                    goto querydone;

                } else {

                    //
                    //  Bump the captured context by one entry.
                    //

                    CapturedContext++;
                }
            }

            //
            //  Get the next directory entry from the singly linked hash
            //  bucket chain
            //

            DirectoryEntry = DirectoryEntry->ChainLink;
        }
    }

    //
    //  At this point we've processed the directory entries and the first
    //  part of the output buffer now contains a bunch of object directory
    //  information records,  but the pointers in them refer to the wrong
    //  copies.  So now we have some fixup to do.
    //

querydone:

    try {

        //
        //  We'll only do this post processing if we've been successful
        //  so far.  Note that this means we could be returning in the
        //  user's output buffer system address that are meaningless, but
        //  then getting back an error status should tell the caller to
        //  forget about everything in the output buffer.  Given back
        //  a system address also isn't harmful because there is nothing
        //  that the user can really do with it.
        //

        if (NT_SUCCESS( Status )) {

            //
            //  Null terminate the string of object directory information
            //  records and point to where the actual names will go
            //

            RtlZeroMemory( DirInfo, sizeof( *DirInfo ));

            DirInfo++;

            NameBuffer = (PWCH)DirInfo;

            //
            //  Now for every entry that we've put in the output buffer
            //  DirInfo will point to the entry and EntriesFound kept the
            //  count.  Note that we are guaranteed space because of
            //  the math we did earlier in computing TotalLengthNeeded.
            //

            DirInfo = (POBJECT_DIRECTORY_INFORMATION)TempBuffer;

            while (EntriesFound--) {

                //
                //  Copy over the object name, set the dir info pointer into
                //  the user's buffer, then null terminate the string.  Note
                //  that we are really copying the data into our temp buffer
                //  but the pointer fix up is for the user's buffer which
                //  we'll copy into right after this loop.
                //

                RtlCopyMemory( NameBuffer,
                               DirInfo->Name.Buffer,
                               DirInfo->Name.Length );

                DirInfo->Name.Buffer = (PVOID)((ULONG_PTR)Buffer + ((ULONG_PTR)NameBuffer - (ULONG_PTR)TempBuffer));
                NameBuffer           = (PWCH)((ULONG_PTR)NameBuffer + DirInfo->Name.Length);
                *NameBuffer++        = UNICODE_NULL;

                //
                //  Do the same copy with the object type name
                //

                RtlCopyMemory( NameBuffer,
                               DirInfo->TypeName.Buffer,
                               DirInfo->TypeName.Length );

                DirInfo->TypeName.Buffer = (PVOID)((ULONG_PTR)Buffer + ((ULONG_PTR)NameBuffer - (ULONG_PTR)TempBuffer));
                NameBuffer               = (PWCH)((ULONG_PTR)NameBuffer + DirInfo->TypeName.Length);
                *NameBuffer++            = UNICODE_NULL;

                //
                //  Move on to the next dir info record
                //

                DirInfo++;
            }

            //
            //  Set the enumeration context to the entry number of the next
            //  entry to return.
            //

            *Context = EntryNumber;
        }

        //
        //  Copy over the results from our temp buffer to the users buffer.
        //  But adjust the amount copied just in case the total length needed
        //  exceeds the length we allocated.
        //

        RtlCopyMemory( Buffer,
                       TempBuffer,
                       (TotalLengthNeeded <= Length ? TotalLengthNeeded : Length) );

        //
        //  In all cases we'll tell the caller how much space if really needed
        //  provided the user asked for this information
        //

        if (ARGUMENT_PRESENT( ReturnLength )) {

            *ReturnLength = TotalLengthNeeded;
        }

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        //
        //  Fall through, since we do not want to undo what we have done.
        //
    }

    //
    //  Unlock the directroy structures, dereference the directory object,
    //  free up our temp buffer, and return to our caller
    //

    ObpUnlockDirectory( Directory, &LookupContext);

    ObDereferenceObject( Directory );

    ExFreePool( TempBuffer );

    return( Status );
}


PVOID
ObpLookupDirectoryEntry (
    IN POBJECT_DIRECTORY Directory,
    IN PUNICODE_STRING Name,
    IN ULONG Attributes,
    IN BOOLEAN SearchShadow,
    OUT POBP_LOOKUP_CONTEXT LookupContext
    )

/*++

Routine Description:

    This routine will lookup a single directory entry in a given directory.
    If it founds an object into that directory with the give name,
    that object will be referenced and the name will be referenced too, in order
    to prevent them going away when the directory is unlocked.
    The referenced object is saved in the LookupContext, and the references will be released
    at the next lookup, or when ObpReleaseLookupContext is called.

Arguments:

    Directory - Supplies the directory being searched

    Name - Supplies the name of entry we're looking for

    Attributes - Indicates if the lookup should be case insensitive
        or not

    SearchShadow - If TRUE, and the object name is not found in the current directory,
    it will search the object into the shadow directory.

    LookupContext - The lookup context for this call. This structure must be initialized
    before calling first time ObpLookupDirectoryEntry.

Return Value:

    Returns a pointer to the corresponding object body if found and NULL
    otherwise.
--*/

{
    POBJECT_DIRECTORY_ENTRY *HeadDirectoryEntry;
    POBJECT_DIRECTORY_ENTRY DirectoryEntry;
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;
    PWCH Buffer;
    WCHAR Wchar;
    ULONG HashIndex;
    ULONG WcharLength;
    BOOLEAN CaseInSensitive;
    POBJECT_DIRECTORY_ENTRY *LookupBucket;
    PVOID Object = NULL;

    PAGED_CODE();

    if (ObpLUIDDeviceMapsEnabled == 0) {

        SearchShadow = FALSE; // Disable global devmap search
    }

    //
    //  The caller needs to specify both a directory and a name otherwise
    //  we can't process the request
    //

    if (!Directory || !Name) {

        goto UPDATECONTEXT;
    }

    //
    //  Set a local variable to tell us if the search is case sensitive
    //

    if (Attributes & OBJ_CASE_INSENSITIVE) {

        CaseInSensitive = TRUE;

    } else {

        CaseInSensitive = FALSE;
    }

    //
    //  Establish our local pointer to the input name buffer and get the
    //  number of unicode characters in the input name.  Also make sure
    //  the caller gave us a non null name
    //

    Buffer = Name->Buffer;
    WcharLength = Name->Length / sizeof( *Buffer );

    if (!WcharLength || !Buffer) {

        goto UPDATECONTEXT;
    }

    //
    //  Compute the address of the head of the bucket chain for this name.
    //

    HashIndex = 0;
    while (WcharLength--) {

        Wchar = *Buffer++;
        HashIndex += (HashIndex << 1) + (HashIndex >> 1);

        if (Wchar < 'a') {

            HashIndex += Wchar;

        } else if (Wchar > 'z') {

            HashIndex += RtlUpcaseUnicodeChar( Wchar );

        } else {

            HashIndex += (Wchar - ('a'-'A'));
        }
    }

    HashIndex %= NUMBER_HASH_BUCKETS;

    LookupContext->HashIndex = (USHORT)HashIndex;

    while (1) {

        HeadDirectoryEntry = (POBJECT_DIRECTORY_ENTRY *)&Directory->HashBuckets[ HashIndex ];

        LookupBucket = HeadDirectoryEntry;

        //
        //  Lock the directory for read access, if the context was not previously locked
        //  exclusively
        //

        if (!LookupContext->DirectoryLocked) {

            ObpLockDirectoryShared( Directory, LookupContext);
        }

        //
        //  Walk the chain of directory entries for this hash bucket, looking
        //  for either a match, or the insertion point if no match in the chain.
        //

        while ((DirectoryEntry = *HeadDirectoryEntry) != NULL) {

            //
            //  Get the object header and name from the object body
            //
            //  This function assumes the name must exist, otherwise it
            //  wouldn't be in a directory
            //

            ObjectHeader = OBJECT_TO_OBJECT_HEADER( DirectoryEntry->Object );
            NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

            //
            //  Compare strings using appropriate function.
            //

            if ((Name->Length == NameInfo->Name.Length) &&
                RtlEqualUnicodeString( Name,
                                       &NameInfo->Name,
                                       CaseInSensitive )) {

                //
                //  If name matches, then exit loop with DirectoryEntry
                //  pointing to matching entry.
                //

                break;
            }

            HeadDirectoryEntry = &DirectoryEntry->ChainLink;
        }

        //
        //  At this point, there are two possiblilities:
        //
        //   - we found an entry that matched and DirectoryEntry points to that
        //     entry.  Update the bucket chain so that the entry found is at the
        //     head of the bucket chain.  This is so the ObpDeleteDirectoryEntry
        //     and ObpInsertDirectoryEntry functions will work.  Also repeated
        //     lookups of the same name will succeed quickly.
        //
        //   - we did not find an entry that matched and DirectoryEntry is NULL.
        //

        if (DirectoryEntry) {

            //
            //  The following convoluted piece of code moves a directory entry
            //  we've found to the front of the hash list.
            //

            if (HeadDirectoryEntry != LookupBucket) {

                if ( LookupContext->DirectoryLocked
                        ||
                     ExTryConvertPushLockSharedToExclusive(&Directory->Lock)) {

                    *HeadDirectoryEntry = DirectoryEntry->ChainLink;
                    DirectoryEntry->ChainLink = *LookupBucket;
                    *LookupBucket = DirectoryEntry;
                }
            }

            //
            //  Now return the object to our caller
            //

            Object = DirectoryEntry->Object;

            goto UPDATECONTEXT;

        } else {

            if (!LookupContext->DirectoryLocked) {

                ObpUnlockDirectory( Directory, LookupContext );
            }

            //
            // If this is a directory with a device map then search the second directory for an entry.
            //

            if (SearchShadow && Directory->DeviceMap != NULL) {
                POBJECT_DIRECTORY NewDirectory;

                NewDirectory = ObpGetShadowDirectory (Directory);
                if (NewDirectory != NULL) {
                    Directory = NewDirectory;
                    continue;
                }
            }

            goto UPDATECONTEXT;
        }
    }

UPDATECONTEXT:

    if (Object) {

        //
        //  Reference the name to keep it's directory alive and the object
        //  before returning from the lookup
        //

        ObpReferenceNameInfo( OBJECT_TO_OBJECT_HEADER(Object) );
        ObReferenceObject( Object );

        //
        //  We can safetly drop the lock now
        //

        if (!LookupContext->DirectoryLocked) {

            ObpUnlockDirectory( Directory, LookupContext );
        }
    }

    //
    //  If we have a previously referenced object we can dereference it
    //

    if (LookupContext->Object) {

        POBJECT_HEADER_NAME_INFO PreviousNameInfo;

        PreviousNameInfo = OBJECT_HEADER_TO_NAME_INFO(OBJECT_TO_OBJECT_HEADER(LookupContext->Object));

        ObpDereferenceNameInfo(PreviousNameInfo);
        ObDereferenceObject(LookupContext->Object);
    }

    LookupContext->Object = Object;

    return Object;
}


BOOLEAN
ObpInsertDirectoryEntry (
    IN POBJECT_DIRECTORY Directory,
    IN POBP_LOOKUP_CONTEXT LookupContext,
    IN POBJECT_HEADER ObjectHeader
    )

/*++

Routine Description:

    This routine will insert a new directory entry into a directory
    object.  The directory must have already have been searched using
    ObpLookupDirectoryEntry because that routine sets the LookupContext.

    N.B. The ObpLookupDirectoryEntry before should be done with the LookupContext
    locked.

Arguments:

    Directory - Supplies the directory object being modified.  This
        function assumes that we earlier did a lookup on the name
        that was successful or we just did an insertion

    Object - Supplies the object to insert into the directory

    LookupContext - The lookupContext passed in previously to  ObpLookupDirectoryEntry

Return Value:

    TRUE if the object is inserted successfully and FALSE otherwise

--*/

{
    POBJECT_DIRECTORY_ENTRY *HeadDirectoryEntry;
    POBJECT_DIRECTORY_ENTRY NewDirectoryEntry;
    POBJECT_HEADER_NAME_INFO NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

#if DBG

    //
    //  This function should be always called with a valid Directory
    //  and LookupContext. Test this on checked builds
    //

    if ((LookupContext->Object != NULL) ||
        !LookupContext->DirectoryLocked ||
        (Directory != LookupContext->Directory)) {

        DbgPrint("OB: ObpInsertDirectoryEntry - invalid context %p %ld\n",
                 LookupContext->Object,
                 (ULONG)LookupContext->DirectoryLocked );
        DbgBreakPoint();

        return FALSE;
    }

#endif // DBG

    //
    //  Allocate memory for a new entry, and fail if not enough memory.
    //

    NewDirectoryEntry = (POBJECT_DIRECTORY_ENTRY)ExAllocatePoolWithTag( PagedPool,
                                                                        sizeof( OBJECT_DIRECTORY_ENTRY ),
                                                                        'iDbO' );

    if (NewDirectoryEntry == NULL) {

        return( FALSE );
    }

    //
    //  Get the right lookup bucket based on the HashIndex
    //

    HeadDirectoryEntry = (POBJECT_DIRECTORY_ENTRY *)&Directory->HashBuckets[ LookupContext->HashIndex ];

    //
    //  Link the new entry into the chain at the insertion point.
    //  This puts the new object right at the head of the current
    //  hash bucket chain
    //

    NewDirectoryEntry->ChainLink = *HeadDirectoryEntry;
    *HeadDirectoryEntry = NewDirectoryEntry;
    NewDirectoryEntry->Object = &ObjectHeader->Body;

    //
    //  Point the object header back to the directory we just inserted
    //  it into.
    //

    NameInfo->Directory = Directory;

    //
    //  Return success.
    //

    return( TRUE );
}


BOOLEAN
ObpDeleteDirectoryEntry (
    IN POBP_LOOKUP_CONTEXT LookupContext
    )

/*++

Routine Description:

    This routine deletes the most recently found directory entry from
    the specified directory object.  It will only succeed after a
    successful ObpLookupDirectoryEntry call.

Arguments:

    Directory - Supplies the directory being modified

Return Value:

    TRUE if the deletion succeeded and FALSE otherwise

--*/

{
    POBJECT_DIRECTORY_ENTRY *HeadDirectoryEntry;
    POBJECT_DIRECTORY_ENTRY DirectoryEntry;
    IN POBJECT_DIRECTORY Directory = LookupContext->Directory;

    //
    //  Make sure we have a directory and that it has a found entry
    //

    if (!Directory ) {

        return( FALSE );
    }

    //
    //  The lookup path places the object in the front of the list, so basically
    //  we find the object immediately
    //

    HeadDirectoryEntry = (POBJECT_DIRECTORY_ENTRY *)&Directory->HashBuckets[ LookupContext->HashIndex ];

    DirectoryEntry = *HeadDirectoryEntry;

    //
    //  Unlink the entry from the head of the bucket chain and free the
    //  memory for the entry.
    //

    *HeadDirectoryEntry = DirectoryEntry->ChainLink;
    DirectoryEntry->ChainLink = NULL;

    ExFreePool( DirectoryEntry );

    return TRUE;
}

POBJECT_DIRECTORY
ObpGetShadowDirectory(
    POBJECT_DIRECTORY Dir
    )
{
    POBJECT_DIRECTORY NewDir;

    NewDir = NULL;

    ObpLockDeviceMap();

    if (Dir->DeviceMap != NULL) {
        NewDir = Dir->DeviceMap->GlobalDosDevicesDirectory;
    }

    ObpUnlockDeviceMap();

    return NewDir;
}


NTSTATUS
ObpSetCurrentProcessDeviceMap(
    )
/*++

Routine Description:

    This function sets the process' device map to the device map associated
    with the process token's LUID.

Arguments:

    none

Return Values:

    STATUS_NO_TOKEN - process does not have a primary token

    STATUS_OBJECT_PATH_INVALID - could not obtain the device map associated
                                 with the process token's LUID

    An appropriate status - unexcepted error occurred

--*/
{
    PEPROCESS pProcess;
    PACCESS_TOKEN pToken = NULL;
    LUID userLuid;
    LUID SystemAuthenticationId = SYSTEM_LUID;  // Local_System's LUID
    PDEVICE_MAP DeviceMap = NULL;
    PDEVICE_MAP DerefDeviceMap = NULL;
    NTSTATUS Status = STATUS_SUCCESS;

    pProcess = PsGetCurrentProcess();

    pToken = PsReferencePrimaryToken( pProcess );

    if (pToken == NULL) {
        return (STATUS_NO_TOKEN);
    }

    Status = SeQueryAuthenticationIdToken( pToken, &userLuid );

    if (!NT_SUCCESS(Status)) {
        PsDereferencePrimaryToken( pToken );
        return (Status);
    }

    if (!RtlEqualLuid( &userLuid, &SystemAuthenticationId )) {
        PDEVICE_MAP pDevMap;

        //
        // Get a handle to the Device Map for the user's LUID
        //
        Status = SeGetLogonIdDeviceMap( &userLuid,
                                        &pDevMap );

        if (NT_SUCCESS(Status)) {
            DeviceMap = pDevMap;
        }
    }
    else {
        //
        // Process is Local_System, so use the System's device map
        //
        DeviceMap = ObSystemDeviceMap;
    }

    if (DeviceMap != NULL) {
        //
        // set the process' device map
        //

        ObpLockDeviceMap();

        DerefDeviceMap = pProcess->DeviceMap;

        pProcess->DeviceMap = DeviceMap;

        DeviceMap->ReferenceCount++;

        ObpUnlockDeviceMap();
    }
    else {
        Status = STATUS_OBJECT_PATH_INVALID;
    }

    PsDereferencePrimaryToken( pToken );

    //
    // If the process already had a device map, then deref it now
    //
    if (DerefDeviceMap != NULL) {
        ObfDereferenceDeviceMap (DerefDeviceMap);
    }

    return (Status);
}


PDEVICE_MAP
ObpReferenceDeviceMap(
    )
/*++

Routine Description:

    This function obtains the correct device map associated with the
    caller.
    If LUID device maps are enabled,
    then we obtain the LUID's device map.

    We use the existing process device map field as a cache for the
    process token's LUID device map.

    If LUID device maps are disabled,
    then use the device map associated with the process

Arguments:

    none

Return Values:

    A pointer to the caller's device map
    NULL - could not obtain the user's device map

--*/
{
    PDEVICE_MAP DeviceMap = NULL;
    BOOLEAN LocalSystemRequest = FALSE;
    LOGICAL LUIDDeviceMapsEnabled;
    PACCESS_TOKEN pToken = NULL;
    NTSTATUS Status;

    LUIDDeviceMapsEnabled = (ObpLUIDDeviceMapsEnabled != 0);

    if (LUIDDeviceMapsEnabled == TRUE) {

        PETHREAD Thread = NULL;

        //
        //     Separate device maps for each user LUID
        // if (thread is impersonating)
        //    then get user's LUID to retrieve their device map
        //    else use the process' device map
        // if (LUID is the Local_System)
        //    then use the system's device map
        // if (unable to retrieve LUID's device map),
        //    then use the process' device map
        //

        //
        // Get the current thread & check if the thread is impersonating
        //
        // if impersonating,
        //     then take the long path
        //          - get thread's access token
        //          - read the caller's LUID from the token
        //          - get the device map associate with this LUID
        // if not impersonating,
        //     then use the device map associated with the process
        //
        Thread = PsGetCurrentThread();

        if ( PS_IS_THREAD_IMPERSONATING (Thread) ) {
            BOOLEAN fCopyOnOpen;
            BOOLEAN fEffectiveOnly;
            SECURITY_IMPERSONATION_LEVEL ImpersonationLevel;
            LUID userLuid;


            //
            // Get the caller's access token from the thread
            //
            pToken = PsReferenceImpersonationToken( Thread,
                                                    &fCopyOnOpen,
                                                    &fEffectiveOnly,
                                                    &ImpersonationLevel);

            if (pToken != NULL) {

                //
                // query the token for the LUID
                //
                Status = SeQueryAuthenticationIdToken( pToken, &userLuid );
            }
            else {
                Status = STATUS_NO_TOKEN;
                userLuid.LowPart = 0;
                userLuid.HighPart = 0;
            }

            if (NT_SUCCESS(Status)) {
                LUID SystemAuthenticationId = SYSTEM_LUID;  // Local_System's LUID

                //
                // Verify the caller is not Local_System by
                // comparing the LUID with Local_System's LUID
                //
                if (!RtlEqualLuid( &userLuid, &SystemAuthenticationId )) {
                    PDEVICE_MAP pDevMap;

                    //
                    // Get a handle to the Device Map for the LUID
                    //
                    Status = SeGetLogonIdDeviceMap( &userLuid,
                                                    &pDevMap );

                    if (NT_SUCCESS(Status)) {

                        //
                        // Use the device map associated with the LUID
                        //

                        DeviceMap = pDevMap;

                        ObpLockDeviceMap();

                        if (DeviceMap != NULL) {
                            DeviceMap->ReferenceCount++;
                        }

                        ObpUnlockDeviceMap();

                    }

                }
                else {
                    //
                    // Local_System will use the system's device map
                    //
                    LocalSystemRequest = TRUE;
                }

            }

        }

    }

    if (DeviceMap == NULL) {
        //
        // if (going to reference the process' device map and the process'
        // device map is not set),
        // then set the process' device map
        //
        if ((LUIDDeviceMapsEnabled == TRUE) &&
            (LocalSystemRequest == FALSE) &&
            ((PsGetCurrentProcess()->DeviceMap) == NULL)) {

            Status = ObpSetCurrentProcessDeviceMap();

            if (!NT_SUCCESS(Status)) {
                goto Error_Exit;
            }
        }

        ObpLockDeviceMap();

        if (LocalSystemRequest == TRUE) {
            //
            // Use the system's device map
            //
            DeviceMap = ObSystemDeviceMap;
        }
        else {
            //
            // Use the device map from the process
            //
            DeviceMap = PsGetCurrentProcess()->DeviceMap;
        }

        if (DeviceMap != NULL) {
            DeviceMap->ReferenceCount++;
        }
        ObpUnlockDeviceMap();
    }

Error_Exit:

    if( pToken != NULL ) {
        PsDereferenceImpersonationToken(pToken);
    }

    return DeviceMap;
}


VOID
FASTCALL
ObfDereferenceDeviceMap(
    IN PDEVICE_MAP DeviceMap
    )
{
    ObpLockDeviceMap();

    DeviceMap->ReferenceCount--;

    if (DeviceMap->ReferenceCount == 0) {

        DeviceMap->DosDevicesDirectory->DeviceMap = NULL;

        ObpUnlockDeviceMap();

        //
        // This devmap is dead so mark the directory temporary so its name will go away and dereference it.
        //
        ObMakeTemporaryObject (DeviceMap->DosDevicesDirectory);
        ObDereferenceObject( DeviceMap->DosDevicesDirectory );

        ExFreePool( DeviceMap );

    } else {

        ObpUnlockDeviceMap();
    }
}


NTSTATUS
ObpLookupObjectName (
    IN HANDLE RootDirectoryHandle OPTIONAL,
    IN PUNICODE_STRING ObjectName,
    IN ULONG Attributes,
    IN POBJECT_TYPE ObjectType,
    IN KPROCESSOR_MODE AccessMode,
    IN PVOID ParseContext OPTIONAL,
    IN PSECURITY_QUALITY_OF_SERVICE SecurityQos OPTIONAL,
    IN PVOID InsertObject OPTIONAL,
    IN OUT PACCESS_STATE AccessState,
    OUT POBP_LOOKUP_CONTEXT LookupContext,
    OUT PVOID *FoundObject
    )

/*++

Routine Description:

    This function will search a given directoroy for a specified
    object name.  It will also create a new object specified by
    InsertObject.

Arguments:

    RootDirectoryHandle - Optionally supplies the directory being
        searched.  If not supplied then this routine searches
        the root directory

    ObjectName - Supplies the name of object to lookup

    Attributes - Specifies the attributes for the lookup (e.g., case
        insensitive)

    ObjectType - Specifies the type of the object to lookup

    AccessMode - Specifies the callers processor mode

    ParseContext - Optionally supplies a parse context that is blindly
        passed to the parse callback routines

    SecurityQos - Optionally supplies a pointer to the passed Security
        Quality of Service parameter that is blindly passed to the parse
        callback routines

    InsertObject - Optionally supplies the object we think will be found.
        This is used if the caller did not give a root directory handle
        and the object name is "\" and the root object directory hasn't
        been created yet.  In other cases where we wind up creating
        a new directory entry this is the object inserted.

    AccessState - Current access state, describing already granted access
        types, the privileges used to get them, and any access types yet to
        be granted.  The access masks may not contain any generic access
        types.

    DirectoryLocked - Receives an indication if this routine has returned
        with the input directory locked

    FoundObject - Receives a pointer to the object body if found

Return Value:

    An appropriate status value.

    N.B. If the status returned is SUCCESS the caller has the
    responsability to release the lookup context

--*/

{
    POBJECT_DIRECTORY RootDirectory;
    POBJECT_DIRECTORY Directory = NULL;
    POBJECT_DIRECTORY ParentDirectory = NULL;
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;
    PDEVICE_MAP DeviceMap = NULL;
    PVOID Object;
    UNICODE_STRING RemainingName;
    UNICODE_STRING ComponentName;
    PWCH NewName;
    NTSTATUS Status;
    BOOLEAN Reparse = FALSE;  // BUGBUG - remove initialization & validate
    BOOLEAN ReparsedSymbolicLink = FALSE;
    ULONG MaxReparse = OBJ_MAX_REPARSE_ATTEMPTS;
    OB_PARSE_METHOD ParseProcedure;
    extern POBJECT_TYPE IoFileObjectType;
    KPROCESSOR_MODE AccessCheckMode;

    ObpValidateIrql( "ObpLookupObjectName" );

    //
    //  Initialize our output variables to say we haven't lock or found
    //  anything but we were successful at it
    //

    ObpInitializeLookupContext(LookupContext);

    *FoundObject = NULL;
    Status = STATUS_SUCCESS;

    Object = NULL;

    //
    //  If the global flag says that we need to perform a case-insensitive check
    //  we'll force the OBJ_CASE_INSENSITIVE flag in attributes at lookup
    //

    if ( ObpCaseInsensitive ) {

        if ( (ObjectType == NULL) ||
             (ObjectType->TypeInfo.CaseInsensitive)
           ) {

            Attributes |= OBJ_CASE_INSENSITIVE;
        }
    }

    if (Attributes & OBJ_FORCE_ACCESS_CHECK) {
        AccessCheckMode = UserMode;
    } else {
        AccessCheckMode = AccessMode;
    }

    //
    //  Check if the caller has given us a directory to search.  Otherwise
    //  we'll search the root object directory
    //

    if (ARGUMENT_PRESENT( RootDirectoryHandle )) {

        //
        //  Otherwise reference the directory object and make sure
        //  that we successfully got the object
        //

        Status = ObReferenceObjectByHandle( RootDirectoryHandle,
                                            0,
                                            NULL,
                                            AccessMode,
                                            (PVOID *)&RootDirectory,
                                            NULL );

        if (!NT_SUCCESS( Status )) {

            return( Status );
        }

        //
        //  Translate the directory object to its object header
        //

        ObjectHeader = OBJECT_TO_OBJECT_HEADER( RootDirectory );

        //
        //  Now if the name we're looking up starts with a "\" and it
        //  does not have a parse procedure then the syntax is bad
        //

        if ((ObjectName->Buffer != NULL) &&
            (*(ObjectName->Buffer) == OBJ_NAME_PATH_SEPARATOR) &&
            (ObjectHeader->Type != IoFileObjectType)) {

            ObDereferenceObject( RootDirectory );

            return( STATUS_OBJECT_PATH_SYNTAX_BAD );
        }

        //
        //  Now make sure that we do not have the directory of the
        //  object types
        //

        if (ObjectHeader->Type != ObpDirectoryObjectType) {

            //
            //  We have an object directory that is not the object type
            //  directory.  So now if it doesn't have a parse routine
            //  then there is nothing we can
            //

            if (ObjectHeader->Type->TypeInfo.ParseProcedure == NULL) {

                ObDereferenceObject( RootDirectory );

                return( STATUS_INVALID_HANDLE );

            } else {

                MaxReparse = OBJ_MAX_REPARSE_ATTEMPTS;

                //
                //  The following loop cycles cycles through the various
                //  parse routine to we could encounter trying to resolve
                //  this name through symbolic links.
                //

                while (TRUE) {

#if DBG
                    KIRQL SaveIrql;
#endif

                    RemainingName = *ObjectName;

                    //
                    //  Invoke the callback routine to parse the remaining
                    //  object name
                    //

                    ObpBeginTypeSpecificCallOut( SaveIrql );

                    Status = (*ObjectHeader->Type->TypeInfo.ParseProcedure)( RootDirectory,
                                                                             ObjectType,
                                                                             AccessState,
                                                                             AccessCheckMode,
                                                                             Attributes,
                                                                             ObjectName,
                                                                             &RemainingName,
                                                                             ParseContext,
                                                                             SecurityQos,
                                                                             &Object );

                    ObpEndTypeSpecificCallOut( SaveIrql, "Parse", ObjectHeader->Type, Object );

                    //
                    //  If the status was not to do a reparse and the lookup
                    //  was not successful then we found nothing so we
                    //  dereference the directory and return the status to
                    //  our caller.  If the object we got back was null then
                    //  we'll tell our caller that we couldn't find the name.
                    //  Lastly if we did not get a reparse and we were
                    //  successful and the object is not null then everything
                    //  gets nicely returned to our caller
                    //

                    if ( ( Status != STATUS_REPARSE ) &&
                         ( Status != STATUS_REPARSE_OBJECT )) {

                        if (!NT_SUCCESS( Status )) {

                            Object = NULL;

                        } else if (Object == NULL) {

                            Status = STATUS_OBJECT_NAME_NOT_FOUND;
                        }

                        ObDereferenceObject( RootDirectory );

                        *FoundObject = Object;

                        return( Status );

                    //
                    //  We got a status reparse, which means the object
                    //  name has been modified to have use start all over
                    //  again.  If the reparse target is now empty or it
                    //  is a path separator then we start the parse at the
                    //  root directory
                    //

                    } else if ((ObjectName->Length == 0) ||
                               (ObjectName->Buffer == NULL) ||
                               (*(ObjectName->Buffer) == OBJ_NAME_PATH_SEPARATOR)) {

                        //
                        //  Restart the parse relative to the root directory.
                        //

                        ObDereferenceObject( RootDirectory );

                        RootDirectory = ObpRootDirectoryObject;
                        RootDirectoryHandle = NULL;

                        goto ParseFromRoot;

                    //
                    //  We got a reparse and we actually have a new name to
                    //  go to we if we haven't exhausted our reparse attempts
                    //  yet then just continue to the top of this loop.
                    //

                    } else if (--MaxReparse) {

                        continue;

                    //
                    //  We got a reparse and we've exhausted our times through
                    //  the loop so we'll return what we found.
                    //

                    } else {

                        ObDereferenceObject( RootDirectory );

                        *FoundObject = Object;

                        //
                        //  At this point we were failing in stress by
                        //  returning to the caller with a success status but
                        //  a null object pointer.
                        //

                        if (Object == NULL) {

                            Status = STATUS_OBJECT_NAME_NOT_FOUND;
                        }

                        return( Status );
                    }
                }
            }

        //
        //  At this point the caller has given us the directory of object
        //  types.  If the caller didn't specify a name then we'll return
        //  a pointer to the root object directory.
        //

        } else if ((ObjectName->Length == 0) ||
                   (ObjectName->Buffer == NULL)) {

            Status = ObReferenceObjectByPointer( RootDirectory,
                                                 0,
                                                 ObjectType,
                                                 AccessMode );

            if (NT_SUCCESS( Status )) {

                Object = RootDirectory;
            }

            ObDereferenceObject( RootDirectory );

            *FoundObject = Object;

            return( Status );
        }

    //
    //  Otherwise the caller did not specify a directory to search so
    //  we'll default to the object root directory
    //

    } else {

        RootDirectory = ObpRootDirectoryObject;

        //
        //  If the name we're looking for is empty then it is illformed.
        //  Also it has to start with a "\" or it is illformed.
        //

        if ((ObjectName->Length == 0) ||
            (ObjectName->Buffer == NULL) ||
            (*(ObjectName->Buffer) != OBJ_NAME_PATH_SEPARATOR)) {

            return( STATUS_OBJECT_PATH_SYNTAX_BAD );
        }

        //
        //  Check if the name is has only one character (that is the "\")
        //  Which means that the caller really just wants to lookup the
        //  root directory.
        //

        if (ObjectName->Length == sizeof( OBJ_NAME_PATH_SEPARATOR )) {

            //
            //  If there is not a root directory yet.  Then we really
            //  can't return it, however if the caller specified
            //  an insert object that is the one we'll reference and
            //  return to our caller
            //

            if (!RootDirectory) {

                if (InsertObject) {

                    Status = ObReferenceObjectByPointer( InsertObject,
                                                         0,
                                                         ObjectType,
                                                         AccessMode );

                    if (NT_SUCCESS( Status )) {

                        *FoundObject = InsertObject;
                    }

                    return( Status );

                } else {

                    return( STATUS_INVALID_PARAMETER );
                }

            //
            //  At this point the caller did not specify a root directory,
            //  the name is "\" and the root object directory exists so
            //  we'll simply return the real root directory object
            //

            } else {

                Status = ObReferenceObjectByPointer( RootDirectory,
                                                     0,
                                                     ObjectType,
                                                     AccessMode );

                if (NT_SUCCESS( Status )) {

                    *FoundObject = RootDirectory;
                }

                return( Status );
            }

        //
        //  At this pointer the caller did not specify a root directory,
        //  and the name is more than just a "\"
        //
        //  Now if the lookup is case insensitive, and the name buffer is a
        //  legitimate pointer (meaning that is it quadword aligned), and
        //  there is a dos device map for the process.  Then we'll handle
        //  the situation here. First get the device map and make sure it
        //  doesn't go away while we're using it.
        //

        } else {

ParseFromRoot:

            if (DeviceMap != NULL) {

                ObfDereferenceDeviceMap(DeviceMap);
                DeviceMap = NULL;
            }

            if (!((ULONG_PTR)(ObjectName->Buffer) & (sizeof(ULONGLONG)-1))) {

                //
                //  Check if the object name is actually equal to the
                //  global dos devices short name prefix "\??\"
                //

                if ((ObjectName->Length >= ObpDosDevicesShortName.Length)

                        &&

                    (*(PULONGLONG)(ObjectName->Buffer) == ObpDosDevicesShortNamePrefix.Alignment.QuadPart)) {

                    if ((DeviceMap = ObpReferenceDeviceMap()) != NULL) {
                        if (DeviceMap->DosDevicesDirectory != NULL ) {

                            //
                            //  The user gave us the dos short name prefix so we'll
                            //  look down the directory, and start the search at the
                            //  dos device directory
                            //

                            ParentDirectory = RootDirectory;

                            Directory = DeviceMap->DosDevicesDirectory;

                            RemainingName = *ObjectName;
                            RemainingName.Buffer += (ObpDosDevicesShortName.Length / sizeof( WCHAR ));
                            RemainingName.Length = (USHORT)(RemainingName.Length - ObpDosDevicesShortName.Length);

                            goto quickStart;

                        }
                    }
                    //
                    //  The name is not equal to "\??\" but check if it is
                    //  equal to "\??"
                    //

                } else if ((ObjectName->Length == ObpDosDevicesShortName.Length - sizeof( WCHAR ))

                                &&

                    (*(PULONG)(ObjectName->Buffer) == ObpDosDevicesShortNameRoot.Alignment.LowPart)

                                &&

                    (*((PWCHAR)(ObjectName->Buffer)+2) == (WCHAR)(ObpDosDevicesShortNameRoot.Alignment.HighPart))) {

                    //
                    //  The user specified "\??" so we return to dos devices
                    //  directory to our caller
                    //

                    if ((DeviceMap = ObpReferenceDeviceMap()) != NULL) {
                        if (DeviceMap->DosDevicesDirectory != NULL ) {

                            Status = ObReferenceObjectByPointer( DeviceMap->DosDevicesDirectory,
                                                                 0,
                                                                 ObjectType,
                                                                 AccessMode );

                            if (NT_SUCCESS( Status )) {

                                *FoundObject = DeviceMap->DosDevicesDirectory;
                            }

                            //
                            //  Dereference the Device Map
                            //

                            ObfDereferenceDeviceMap(DeviceMap);

                            return( Status );
                        }
                    }
                }
            }
        }
    }

    //
    //  At this point either
    //
    //  the user specified a directory that is not the object
    //  type directory and got repase back to the root directory
    //
    //  the user specified the object type directory and gave us
    //  a name to actually look up
    //
    //  the user did not specify a search directory (default
    //  to root object directory) and if the name did start off
    //  with the dos device prefix we've munged outselves back to
    //  it to the dos device directory for the process
    //

    if( ReparsedSymbolicLink == FALSE ) {
        Reparse = TRUE;
        MaxReparse = OBJ_MAX_REPARSE_ATTEMPTS;
    }

    while (Reparse) {

        RemainingName = *ObjectName;

quickStart:

        Reparse = FALSE;

        while (TRUE) {

            Object = NULL;

            //if (RemainingName.Length == 0) {
            //    Status = STATUS_OBJECT_NAME_INVALID;
            //    break;
            //    }

            //
            //  If the remaining name for the object starts with a
            //  "\" then just gobble up the "\"
            //

            if ( (RemainingName.Length != 0) &&
                 (*(RemainingName.Buffer) == OBJ_NAME_PATH_SEPARATOR) ) {

                RemainingName.Buffer++;
                RemainingName.Length -= sizeof( OBJ_NAME_PATH_SEPARATOR );
            }

            //
            //  The following piece of code will calculate the first
            //  component of the remaining name.  If there is not
            //  a remaining component then the object name is illformed
            //

            ComponentName = RemainingName;

            while (RemainingName.Length != 0) {

                if (*(RemainingName.Buffer) == OBJ_NAME_PATH_SEPARATOR) {

                    break;
                }

                RemainingName.Buffer++;
                RemainingName.Length -= sizeof( OBJ_NAME_PATH_SEPARATOR );
            }

            ComponentName.Length = (USHORT)(ComponentName.Length - RemainingName.Length);

            if (ComponentName.Length == 0) {

                Status = STATUS_OBJECT_NAME_INVALID;
                break;
            }

            //
            //  Now we have the first component name to lookup so we'll
            //  look the directory is necessary
            //

            if ( Directory == NULL ) {

                Directory = RootDirectory;
            }

            //
            //  Now if the caller does not have traverse privilege and
            //  there is a parent directory then we must check if the
            //  user has traverse access to the directory.  Our local
            //  Reparse variable should be false at this point so we'll
            //  drop out of both loops
            //

            if ( (AccessCheckMode != KernelMode) &&
                 !(AccessState->Flags & TOKEN_HAS_TRAVERSE_PRIVILEGE) &&
                 (ParentDirectory != NULL) ) {

                if (!ObpCheckTraverseAccess( ParentDirectory,
                                             DIRECTORY_TRAVERSE,
                                             AccessState,
                                             FALSE,
                                             AccessCheckMode,
                                             &Status )) {

                    break;
                }
            }

            //
            //  If the object already exists in this directory, find it,
            //  else return NULL.
            //

            if ((RemainingName.Length == 0) && (InsertObject != NULL)) {

                //
                //  If we are searching the last name, and we have an object
                //  to insert into that directory, we lock the context
                //  exclusively before the lookup. An insertion is likely
                //  to occur after this lookup if it fails, so we need to protect
                //  this directory to be changed until the ObpInsertDirectoryEntry call
                //

                ObpLockLookupContext( LookupContext, Directory );
            }

            Object = ObpLookupDirectoryEntry( Directory,
                                              &ComponentName,
                                              Attributes,
                                              InsertObject == NULL ? TRUE : FALSE,
                                              LookupContext );

            if (!Object) {

                //
                //  We didn't find the object.  If there is some remaining
                //  name left (meaning the component name is a directory in
                //  path we trying to break) or the caller didn't specify an
                //  insert object then we then we'll break out here with an
                //  error status
                //

                if (RemainingName.Length != 0) {

                    Status = STATUS_OBJECT_PATH_NOT_FOUND;
                    break;
                }

                if (!InsertObject) {

                    Status = STATUS_OBJECT_NAME_NOT_FOUND;
                    break;
                }

                //
                //  Check that the caller has the access to the directory
                //  to either create a subdirectory (in the object type
                //  directory) or to create an object of the given component
                //  name.  If the call fails then we'll break out of here
                //  with the status value set
                //

                if (!ObCheckCreateObjectAccess( Directory,
                                                ObjectType == ObpDirectoryObjectType ?
                                                        DIRECTORY_CREATE_SUBDIRECTORY :
                                                        DIRECTORY_CREATE_OBJECT,
                                                AccessState,
                                                &ComponentName,
                                                FALSE,
                                                AccessCheckMode,
                                                &Status )) {

                    break;
                }
                
                ObjectHeader = OBJECT_TO_OBJECT_HEADER( InsertObject );

                if ((Directory->SessionId != OBJ_INVALID_SESSION_ID)
                        &&
                    ((ObjectHeader->Type == MmSectionObjectType)
                            ||
                    (ObjectHeader->Type == ObpSymbolicLinkObjectType))) {

                    //
                    //  This directory is restricted to session. Check whether we are
                    //  in the same session with the directory, and if we have privilege to 
                    //  access it otherwise
                    //

                    if ((Directory->SessionId != PsGetCurrentProcessSessionId())
                            &&
                        !SeSinglePrivilegeCheck( SeCreateGlobalPrivilege, AccessCheckMode)
                            &&
                        !ObpIsUnsecureName( &ComponentName,
                                            ((Attributes & OBJ_CASE_INSENSITIVE) ? TRUE : FALSE ))) {

                        Status = STATUS_ACCESS_DENIED;

                        break;
                    }
                }

                //
                //  The object does not exist in the directory and
                //  we are allowed to create one.  So allocate space
                //  for the name and insert the name into the directory
                //

                NewName = ExAllocatePoolWithTag( PagedPool, ComponentName.Length, 'mNbO' );

                if ((NewName == NULL) ||
                    !ObpInsertDirectoryEntry( Directory, LookupContext, ObjectHeader )) {

                    if (NewName != NULL) {

                        ExFreePool( NewName );
                    }


                    Status = STATUS_INSUFFICIENT_RESOURCES;
                    break;
                }

                //
                //  We have an insert object so now get its name info,
                //  because we are going to change its name and insert it
                //  into the directory
                //

                ObReferenceObject( InsertObject );

                NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

                ObReferenceObject( Directory );

                RtlCopyMemory( NewName,
                               ComponentName.Buffer,
                               ComponentName.Length );

                if (NameInfo->Name.Buffer) {

                    ExFreePool( NameInfo->Name.Buffer );
                }

                NameInfo->Name.Buffer = NewName;
                NameInfo->Name.Length = ComponentName.Length;
                NameInfo->Name.MaximumLength = ComponentName.Length;

                Object = InsertObject;

                Status = STATUS_SUCCESS;

                break;
            }

            //
            //  At this point we've found the component name within
            //  the directory.  So we'll now grab the components object
            //  header, and get its parse routine
            //

ReparseObject:

            ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
            ParseProcedure = ObjectHeader->Type->TypeInfo.ParseProcedure;

            //
            //  Now if there is a parse routine for the type and we are not
            //  inserting a new object or the parse routine is for symbolic
            //  links then we'll actually call the parse routine
            //

            if (ParseProcedure && (!InsertObject || (ParseProcedure == ObpParseSymbolicLink))) {

#if DBG
                KIRQL SaveIrql;
#endif

                //
                //  Reference the object and then free the directory lock
                //  This will keep the object from going away with the
                //  directory unlocked
                //

                ObpIncrPointerCount( ObjectHeader );

                Directory = NULL;
                ObpReleaseLookupContext(LookupContext);

                ObpBeginTypeSpecificCallOut( SaveIrql );

                //
                //  Call the objects parse routine
                //

                Status = (*ParseProcedure)( Object,
                                            (PVOID)ObjectType,
                                            AccessState,
                                            AccessCheckMode,
                                            Attributes,
                                            ObjectName,
                                            &RemainingName,
                                            ParseContext,
                                            SecurityQos,
                                            &Object );

                ObpEndTypeSpecificCallOut( SaveIrql, "Parse", ObjectHeader->Type, Object );

                //
                //  We can now decrement the object reference count
                //

                ObDereferenceObject( &ObjectHeader->Body );

                //
                //  Check if we have some reparsing to do
                //

                if ((Status == STATUS_REPARSE) || (Status == STATUS_REPARSE_OBJECT)) {

                    //
                    //  See if we've reparsed too many times already and if
                    //  so we'll fail the request
                    //

                    if (--MaxReparse) {

                        //
                        //  Tell the outer loop to continue looping
                        //

                        Reparse = TRUE;

                        //
                        //  Check if we have a reparse object or the name
                        //  starts with a "\"
                        //

                        if ((Status == STATUS_REPARSE_OBJECT) ||
                            (*(ObjectName->Buffer) == OBJ_NAME_PATH_SEPARATOR)) {

                            //
                            //  If the user specified a start directory then
                            //  remove this information because we're taking
                            //  a reparse point to someplace else
                             //

                            if (ARGUMENT_PRESENT( RootDirectoryHandle )) {

                                ObDereferenceObject( RootDirectory );
                                RootDirectoryHandle = NULL;
                            }

                            //
                            //  And where we start is the root directory
                            //  object
                            //

                            ParentDirectory = NULL;
                            RootDirectory = ObpRootDirectoryObject;

                            //
                            //  Now if this is a reparse object (means we have
                            //  encountered a symbolic link that has already been
                            //  snapped so we have an object and remaining
                            //  name that need to be examined) and we didn't
                            //  find an object from the parse routine object
                            //  break out of both loops.
                            //

                            if (Status == STATUS_REPARSE_OBJECT) {

                                Reparse = FALSE;

                                if (Object == NULL) {

                                    Status = STATUS_OBJECT_NAME_NOT_FOUND;

                                } else {

                                    //
                                    //  At this point we have a reparse object
                                    //  so we'll look the directory down and
                                    //  parse the new object
                                    //

                                    goto ReparseObject;
                                }
                            } else {
                                //
                                // At this point Status must be equal to
                                // STATUS_REPARSE because [(Status equals
                                // (STATUS_REPARSE_OBJECT or STATUS_REPARSE))
                                // && (Status != STATUS_REPARSE_OBJECT)]
                                //
                                ReparsedSymbolicLink = TRUE;
                                goto ParseFromRoot;
                            }

                        //
                        //  We did not have a reparse object and the name
                        //  does not start with a "\".  Meaning we got back
                        //  STATUS_REPASE, so now check if the directory
                        //  is the root object directory and if so then
                        //  we didn't the name otherwise we'll drop out of
                        //  the inner loop and reparse true to get back to
                        //  outer loop
                        //

                        } else if (RootDirectory == ObpRootDirectoryObject) {

                            Object = NULL;
                            Status = STATUS_OBJECT_NAME_NOT_FOUND;

                            Reparse = FALSE;
                        }

                    } else {

                        //
                        //  We return object not found if we've exhausted
                        //  the MaxReparse time
                        //

                        Object = NULL;
                        Status = STATUS_OBJECT_NAME_NOT_FOUND;
                    }

                //
                //  We are not reparsing and if we did not get success then
                //  the object is null and we'll break out of our loops
                //

                } else if (!NT_SUCCESS( Status )) {

                    Object = NULL;

                //
                //  We are not reparsing and we got back success but check
                //  if the object is null because that means we really didn't
                //  find the object, and then break out of our loops
                //
                //  If the object is not null then we've been successful and
                //  prosperous so break out with the object set.
                //

                } else if (Object == NULL) {

                    Status = STATUS_OBJECT_NAME_NOT_FOUND;
                }

                break;

            } else {

                //
                //  At this point we do not have a parse routine or if there
                //  is a parse routine it is not for symbolic links or there
                //  may not be a specified insert object
                //
                //  Check to see if we have exhausted the remaining name
                //

                if (RemainingName.Length == 0) {

                    //
                    //  Check if the caller specified an object to insert.
                    //  If specified then we'll break out of our loops with
                    //  the object that we've found
                    //

                    if (!InsertObject) {

                        //
                        //  The user did not specify an insert object
                        //  so we're opening an existing object.  Make sure
                        //  we have traverse access to the container
                        //  directory.
                        //

                        if ( (AccessCheckMode != KernelMode) &&
                             !(AccessState->Flags & TOKEN_HAS_TRAVERSE_PRIVILEGE) ) {

                            if (!ObpCheckTraverseAccess( Directory,
                                                         DIRECTORY_TRAVERSE,
                                                         AccessState,
                                                         FALSE,
                                                         AccessCheckMode,
                                                         &Status )) {

                                Object = NULL;
                                break;
                            }
                        }

                        Status = ObReferenceObjectByPointer( Object,
                                                             0,
                                                             ObjectType,
                                                             AccessMode );

                        if (!NT_SUCCESS( Status )) {

                            Object = NULL;
                        }
                    }

                    break;

                } else {

                    //
                    //  There is some name remaining names to process
                    //  if the directory we're looking at is the
                    //  directory of object types and set ourselves
                    //  up to parse it all over again.
                    //

                    if (ObjectHeader->Type == ObpDirectoryObjectType) {

                        ParentDirectory = Directory;
                        Directory = (POBJECT_DIRECTORY)Object;

                    } else {

                        //
                        //  Otherwise there has been a mismatch so we'll
                        //  set our error status and break out of the
                        //  loops
                        //

                        Status = STATUS_OBJECT_TYPE_MISMATCH;
                        Object = NULL;

                        break;
                    }
                }
            }
        }
    }

    //
    //  We can release the context if our search was unsuccesful.
    //  We still need the directory to be locked if a new object is
    //  inserted into that directory, until we finish the initialization
    //  (i.e SD, handle, ...). Note the object is visible now and could be accessed
    //  via name. We need to hold the directory lock until we are done.
    //

    if ( !NT_SUCCESS(Status) ) {

        ObpReleaseLookupContext(LookupContext);
    }

    //
    //  If the device map has been referenced then dereference it
    //

    if (DeviceMap != NULL) {

        ObfDereferenceDeviceMap(DeviceMap);
    }

    //
    //  At this point we've parsed the object name as much as possible
    //  going through symbolic links as necessary.  So now set the
    //  output object pointer, and if we really did not find an object
    //  then we might need to modify the error status.  If the
    //  status was repase or some success status then translate it
    //  to name not found.
    //

    if (!(*FoundObject = Object)) {

        if (Status == STATUS_REPARSE) {

            Status = STATUS_OBJECT_NAME_NOT_FOUND;

        } else if (NT_SUCCESS( Status )) {

            Status = STATUS_OBJECT_NAME_NOT_FOUND;
        }
    }

    //
    //  If the caller gave us a root directory to search (and we didn't
    //  zero out this value) then free up our reference
    //

    if (ARGUMENT_PRESENT( RootDirectoryHandle )) {

        ObDereferenceObject( RootDirectory );
        RootDirectoryHandle = NULL;
    }

    //
    //  And return to our caller
    //

    return( Status );
}


NTSTATUS
NtMakePermanentObject (
    IN HANDLE Handle
    )

/*++

Routine Description:

    This routine makes the specified object permanent.
    By default, only Local_System may make this call

Arguments:

    Handle - Supplies a handle to the object being modified

Return Value:

    An appropriate status value.

--*/

{
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;
    PVOID Object;
    OBJECT_HANDLE_INFORMATION HandleInformation;
    POBJECT_HEADER ObjectHeader;


    PAGED_CODE();

    //
    //  Get previous processor mode and probe output argument if necessary.
    //

    PreviousMode = KeGetPreviousMode();

    //
    //  The object is being changed to permanent, check if
    //  the caller has the appropriate privilege.
    //
    if (!SeSinglePrivilegeCheck( SeCreatePermanentPrivilege,
                                 PreviousMode)) {

        Status = STATUS_PRIVILEGE_NOT_HELD;
        return( Status );
    }

    Status = ObReferenceObjectByHandle( Handle,
                                        0,
                                        (POBJECT_TYPE)NULL,
                                        PreviousMode,
                                        &Object,
                                        &HandleInformation );
    if (!NT_SUCCESS( Status )) {
        return( Status );
    }

    //
    //  Make the object permanant.  Note that the object should still
    //  have a name and directory entry because its handle count is not
    //  zero
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    //
    // Other bits are set in this flags field by the handle database code. Synchronize with that.
    //

    ObpLockObject( ObjectHeader );

    ObjectHeader->Flags |= OB_FLAG_PERMANENT_OBJECT;

    //
    // This routine releases the type mutex
    //

    ObpUnlockObject( ObjectHeader );

    ObDereferenceObject( Object );

    return( Status );
}

POBJECT_HEADER_NAME_INFO
ObpTryReferenceNameInfoExclusive(
    IN POBJECT_HEADER ObjectHeader
    )

/*++

    Routine Description:

        The function references exclusively the name information for a named object
        Note that if there are outstanding references to the name info this function can fail


    Arguments:

        ObjectHeader - Object being locked

    Return Value:
        
        Returns the name information or NULL if it cannot be locked
    
    Assumptions:
    
        The parent directory is assumed to be exclusively locked (so that other threads
        waiting to reference the name will have first to grab the directory lock). 
        
--*/

{
    POBJECT_HEADER_NAME_INFO NameInfo;
    LONG References, NewReferences;
    
    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );
    
    References = NameInfo->QueryReferences;

    do {

        //
        //  If this is not the only reference to the object then we cannot lock the name
        //  N.B. The caller needs also to have a reference to this name
        //

        if ((References != 2) 
                ||
            (NameInfo->Directory == NULL)) {

            return NULL;
        }

        NewReferences = InterlockedCompareExchange ( (PLONG) &NameInfo->QueryReferences,
                                                     OBP_NAME_LOCKED | References,
                                                     References);

        //
        // If the exchange compare completed ok then we did a reference so return true.
        //

        if (NewReferences == References) {

            return NameInfo;
        }

        //
        // We failed because somebody else got in and changed the refence count on us. Use the new value to
        // prime the exchange again.
        //

        References = NewReferences;

    } while (TRUE);

    return NULL;
}

VOID
ObpReleaseExclusiveNameLock(
    IN POBJECT_HEADER ObjectHeader
    )

/*++

    Routine Description:

        The routine releases the exclusive lock for the name information

    Arguments:

        ObjectHeader - Object being locked

    Return Value:

        None.

--*/

{
    POBJECT_HEADER_NAME_INFO NameInfo;
    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

    InterlockedExchangeAdd((PLONG)&NameInfo->QueryReferences, -OBP_NAME_LOCKED);
}

POBJECT_DIRECTORY_ENTRY
ObpUnlinkDirectoryEntry (
    IN POBJECT_DIRECTORY Directory,
    IN ULONG HashIndex
    )

/*++

    Routine Description:

        This function removes the directory entry from a directory. Note that before calling this 
        function a lookup is necessary.

    Arguments:

        Directory - Supplies the directory

        HashIndex - The hash value obtained from from the lookup context

    Return Value:

        Returns the directory entry removed from parent

--*/

{
    POBJECT_DIRECTORY_ENTRY *HeadDirectoryEntry;
    POBJECT_DIRECTORY_ENTRY DirectoryEntry;

    //
    //  The lookup path places the object in the front of the list, so basically
    //  we find the object immediately
    //

    HeadDirectoryEntry = (POBJECT_DIRECTORY_ENTRY *)&Directory->HashBuckets[ HashIndex ];

    DirectoryEntry = *HeadDirectoryEntry;

    //
    //  Unlink the entry from the head of the bucket chain and free the
    //  memory for the entry.
    //

    *HeadDirectoryEntry = DirectoryEntry->ChainLink;
    DirectoryEntry->ChainLink = NULL;

    return DirectoryEntry;
}


VOID
ObpLinkDirectoryEntry (
    IN POBJECT_DIRECTORY Directory,
    IN ULONG HashIndex,
    IN POBJECT_DIRECTORY_ENTRY NewDirectoryEntry
    )

/*++

    Routine Description:

        The function inserts a new directory entry into a directory object

    Arguments:

        Directory - Supplies the directory object being modified.  This
            function assumes that we earlier did a lookup on the name
            that was successful or we just did an insertion

        HashIndex - The hash value obtained from from the lookup context

        NewDirectoryEntry - Supplies the directory entry to be inserted

Return Value:

        None

--*/

{
    POBJECT_DIRECTORY_ENTRY *HeadDirectoryEntry;
    
    //
    //  Get the right lookup bucket based on the HashIndex
    //

    HeadDirectoryEntry = (POBJECT_DIRECTORY_ENTRY *)&Directory->HashBuckets[ HashIndex ];

    //
    //  Link the new entry into the chain at the insertion point.
    //  This puts the new object right at the head of the current
    //  hash bucket chain
    //

    NewDirectoryEntry->ChainLink = *HeadDirectoryEntry;
    *HeadDirectoryEntry = NewDirectoryEntry;
}

VOID
ObpReleaseLookupContextObject (
    IN POBP_LOOKUP_CONTEXT LookupContext
    )

/*++

    Routine Description:
    
        This function releases the object references (added during the lookup)
        but still keeps the directory locked. 
        
        N.B. The caller must retain at least one reference to the object and
        to the name to make sure the deletion does not happen under the lock.

    Arguments:
    
        LookupContext - Supplies the context used in previous lookup

    Return Value:
    
        None.

--*/

{
    //
    //  Remove the references added to the name info and object
    //

    if (LookupContext->Object) {
        POBJECT_HEADER_NAME_INFO NameInfo;

        NameInfo = OBJECT_HEADER_TO_NAME_INFO(OBJECT_TO_OBJECT_HEADER(LookupContext->Object));

        ObpDereferenceNameInfo( NameInfo );
        ObDereferenceObject(LookupContext->Object);
        LookupContext->Object = NULL;
    }
}

NTSTATUS
ObSwapObjectNames (
    IN HANDLE DirectoryHandle,
    IN HANDLE Handle1,
    IN HANDLE Handle2,
    IN ULONG Flags
    )

/*++

    Routine Description:

        The function swaps the names (and permanent object attribute) for two objects inserted into
        the same directory. Both objects must be named and have the same object type.
        The function can fail if another one of these objects has the name locked (for a lookup for example)
    
    Arguments:

        DirectoryHandle - Supplies the parent directory for both objects

        Handle1 - Supplies the handle to the first object

        Handle2 - Supplies the handle to the second object

    Return Value:

    	NTSTATUS.

--*/

{

    #define INVALID_HASH_INDEX 0xFFFFFFFF

    KPROCESSOR_MODE PreviousMode;
    PVOID Object1, Object2;
    NTSTATUS Status;
    POBJECT_HEADER_NAME_INFO NameInfo1, NameInfo2;
    POBJECT_HEADER ObjectHeader1 = NULL, ObjectHeader2 = NULL;
    POBJECT_DIRECTORY Directory;
    OBP_LOOKUP_CONTEXT LookupContext;
    POBJECT_HEADER_NAME_INFO ExclusiveNameInfo1 = NULL, ExclusiveNameInfo2 = NULL;
    POBJECT_DIRECTORY_ENTRY DirectoryEntry1 = NULL, DirectoryEntry2 = NULL;
    ULONG HashIndex1 = INVALID_HASH_INDEX, HashIndex2 = INVALID_HASH_INDEX;
    UNICODE_STRING TmpStr;
    OBJECT_HANDLE_INFORMATION HandleInformation;
    
    PreviousMode = KeGetPreviousMode();

    UNREFERENCED_PARAMETER(Flags);

    Object1 = NULL;
    Object2 = NULL;
    NameInfo1 = NULL;
    NameInfo2 = NULL;

    ObpInitializeLookupContext(&LookupContext);

    Status = ObReferenceObjectByHandle( DirectoryHandle,
                                        DIRECTORY_CREATE_OBJECT | DIRECTORY_CREATE_SUBDIRECTORY,
                                        ObpDirectoryObjectType,
                                        PreviousMode,
                                        (PVOID *)&Directory,
                                        NULL );

    if (!NT_SUCCESS(Status)) {

        goto exit;
    }
    
    Status = ObReferenceObjectByHandle( Handle1,
                                        DELETE,
                                        (POBJECT_TYPE)NULL,
                                        PreviousMode,
                                        &Object1,
                                        &HandleInformation );

    if (!NT_SUCCESS(Status)) {

        goto exit;
    }
    
    Status = ObReferenceObjectByHandle( Handle2,
                                        DELETE,
                                        (POBJECT_TYPE)NULL,
                                        PreviousMode,
                                        &Object2,
                                        &HandleInformation );

    if (!NT_SUCCESS(Status)) {

        goto exit;
    }

    if (Object1 == Object2) {

        Status = STATUS_OBJECT_NAME_COLLISION;
        goto exit;
    }

    ObjectHeader1 = OBJECT_TO_OBJECT_HEADER( Object1 );
    NameInfo1 = ObpReferenceNameInfo( ObjectHeader1 );

    ObjectHeader2 = OBJECT_TO_OBJECT_HEADER( Object2 );
    NameInfo2 = ObpReferenceNameInfo( ObjectHeader2 );

    if (ObjectHeader1->Type != ObjectHeader2->Type) {

        Status = STATUS_OBJECT_TYPE_MISMATCH;
        goto exit;
    }

    if ((NameInfo1 == NULL)
            ||
        (NameInfo2 == NULL)) {

        Status = STATUS_OBJECT_NAME_INVALID;
        goto exit;
    }

    if ((Directory != NameInfo1->Directory)
            ||
        (Directory != NameInfo2->Directory)) {

        Status = STATUS_OBJECT_NAME_INVALID;
        goto exit;
    }

    ObpLockLookupContext ( &LookupContext, Directory );

    //
    //  Check that the object we is still in the directory
    //

    if (Object1 != ObpLookupDirectoryEntry( Directory,
                                            &NameInfo1->Name,
                                            0,
                                            FALSE,
                                            &LookupContext )) {

        //
        //  The object is no longer in directory
        //

        Status = STATUS_OBJECT_NAME_NOT_FOUND;
        goto exit;
    }

    HashIndex1 = LookupContext.HashIndex;
    DirectoryEntry1 = ObpUnlinkDirectoryEntry(Directory, HashIndex1);

    ObpReleaseLookupContextObject(&LookupContext);

    if (Object2 != ObpLookupDirectoryEntry( Directory,
                                            &NameInfo2->Name,
                                            0,
                                            FALSE,
                                            &LookupContext )) {

        //
        //  The object is no longer in directory
        //

        Status = STATUS_OBJECT_NAME_NOT_FOUND;
        goto exit;
    }

    HashIndex2 = LookupContext.HashIndex;
    DirectoryEntry2 = ObpUnlinkDirectoryEntry(Directory, HashIndex2);
    
    ObpReleaseLookupContextObject(&LookupContext);

    //
    //  Now try to lock exclusively both object names
    //

    ExclusiveNameInfo1 = ObpTryReferenceNameInfoExclusive(ObjectHeader1);

    if (ExclusiveNameInfo1 == NULL) {

        Status = STATUS_LOCK_NOT_GRANTED;
        goto exit;
    }

    ExclusiveNameInfo2 = ObpTryReferenceNameInfoExclusive(ObjectHeader2);

    if (ExclusiveNameInfo2 == NULL) {

        Status = STATUS_LOCK_NOT_GRANTED;
        goto exit;
    }

    //
    //  We have both names exclusively locked. we can swap now them 
    //

    TmpStr = ExclusiveNameInfo1->Name;
    ExclusiveNameInfo1->Name = ExclusiveNameInfo2->Name;
    ExclusiveNameInfo2->Name = TmpStr;

    //
    //  Now link back the objects, using the swaped hashes
    //

    ObpLinkDirectoryEntry(Directory, HashIndex2, DirectoryEntry1);
    ObpLinkDirectoryEntry(Directory, HashIndex1, DirectoryEntry2);
    
    DirectoryEntry1 = NULL;
    DirectoryEntry2 = NULL;

exit:
    
    if (DirectoryEntry1) {

        ObpLinkDirectoryEntry(Directory, HashIndex1, DirectoryEntry1);
    }
    
    if (DirectoryEntry2) {

        ObpLinkDirectoryEntry(Directory, HashIndex2, DirectoryEntry2);
    }

    if (ExclusiveNameInfo1) {
        ObpReleaseExclusiveNameLock(ObjectHeader1);
    }
    
    if (ExclusiveNameInfo2) {
        ObpReleaseExclusiveNameLock(ObjectHeader2);
    }

    ObpReleaseLookupContext( &LookupContext );

    if ( NT_SUCCESS( Status ) 
            &&
         (ObjectHeader1 != NULL)
            &&
         (ObjectHeader2 != NULL)) {
        
        //
        //  Lock now both objects and move swap the permanent object flag, if different
        //

        if ((ObjectHeader1->Flags ^ ObjectHeader2->Flags) & OB_FLAG_PERMANENT_OBJECT) {

            //
            //  Both objects are required to have the same object type. We lock them all
            //  before swaping the flags
            //

            ObpLockAllObjects(ObjectHeader1->Type);

            //
            //  Test again under the lock whether flags were changed
            //

            if ((ObjectHeader1->Flags ^ ObjectHeader2->Flags) & OB_FLAG_PERMANENT_OBJECT) {

                //
                //  swap the flags
                //

                ObjectHeader1->Flags ^= OB_FLAG_PERMANENT_OBJECT;
                ObjectHeader2->Flags ^= OB_FLAG_PERMANENT_OBJECT;
            }

            ObpUnlockAllObjects(ObjectHeader1->Type);
        }
    }

    ObpDereferenceNameInfo(NameInfo1);
    ObpDereferenceNameInfo(NameInfo2);

    if (Object1) {

        ObpDeleteNameCheck( Object1 ); // check whether the permanent flag went away meanwhile
        ObDereferenceObject( Object1 );
    }
    
    if (Object2) {
        
        ObpDeleteNameCheck( Object2 ); // check whether the permanent flag went away meanwhile
        ObDereferenceObject( Object2 );
    }

    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obperf.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    obperf.c

Abstract:

    This module contains ob support routines for performance hooks.

Author:

    Stephen Hsiao (shsiao) 11-May-2000

Revision History:

--*/

#include "obp.h"

BOOLEAN
ObPerfDumpHandleEntry (
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE HandleId,
    IN PVOID EnumParameter
    );

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGEWMI, ObPerfDumpHandleEntry)
#pragma alloc_text(PAGEWMI, ObPerfHandleTableWalk)
#endif

BOOLEAN
ObPerfDumpHandleEntry (
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE HandleId,
    IN PVOID EnumParameter
    )
/*++

Routine Description:

    This routine checks a HandleTableEntry and see if it a file

Arguments:

    ObjectTableEntry - Points to the handle table entry of interest.

    HandleId - Supplies the handle.

    EnumParameter - The HashTable to be used

Return Value:

    FALSE, which tells ExEnumHandleTable to continue iterating through the
    handle table.

--*/
{
    extern POBJECT_TYPE ObpDirectoryObjectType;
    extern POBJECT_TYPE IoFileObjectType;
    POBJECT_HEADER ObjectHeader;
    PVOID Object;
    PPERFINFO_ENTRY_TABLE HashTable = EnumParameter;

    UNREFERENCED_PARAMETER (HandleId);

    ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);
    Object = &ObjectHeader->Body;

    if (ObjectHeader->Type == IoFileObjectType) {
        //
        // File Object
        //
        PFILE_OBJECT FileObject = (PFILE_OBJECT) Object;
        PerfInfoAddToFileHash(HashTable, FileObject);

#if 0
    } else if (ObjectHeader->Type == ObpDirectoryObjectType) {
    } else if (ObjectHeader->Type == MmSectionObjectType) {
#endif
    }

    return FALSE;
}

VOID
ObPerfHandleTableWalk (
    PEPROCESS Process,
    PPERFINFO_ENTRY_TABLE HashTable
    )

/*++

Routine Description:

    This routine adds files in the handle table to the hash table.

Arguments:

    Process - Process to walk through.  
              If NULL, walk through the ObpKernelHandleTable;  

    HashTable - HashTable in which to add the file

Return Value:

    None.

--*/
{
    PHANDLE_TABLE ObjectTable;

    if (Process) {
        ObjectTable = ObReferenceProcessHandleTable (Process);
        if ( !ObjectTable ) {
             return ;
        }
    } else {
        //
        //
        //
        ObjectTable = ObpKernelHandleTable;
    }

    ExEnumHandleTable( ObjectTable,
                       ObPerfDumpHandleEntry,
                       (PVOID) HashTable,
                       (PHANDLE)NULL );

    if (Process) {
        ObDereferenceProcessHandleTable( Process );
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\oblink.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    oblink.c

Abstract:

    Symbolic Link Object routines

Author:

    Steve Wood (stevewo) 3-Aug-1989

Revision History:

--*/

#include "obp.h"

VOID
ObpProcessDosDeviceSymbolicLink (
    POBJECT_SYMBOLIC_LINK SymbolicLink,
    ULONG Action
    );

#if defined(ALLOC_PRAGMA)
#pragma alloc_text(PAGE,NtCreateSymbolicLinkObject)
#pragma alloc_text(PAGE,NtOpenSymbolicLinkObject)
#pragma alloc_text(PAGE,NtQuerySymbolicLinkObject)
#pragma alloc_text(PAGE,ObpParseSymbolicLink)
#pragma alloc_text(PAGE,ObpDeleteSymbolicLink)
#pragma alloc_text(PAGE,ObpDeleteSymbolicLinkName)
#pragma alloc_text(PAGE,ObpCreateSymbolicLinkName)
#pragma alloc_text(PAGE,ObpProcessDosDeviceSymbolicLink)
#endif

//
//  This is the object type for device objects.
//

extern POBJECT_TYPE IoDeviceObjectType;

//
//  Global that enables/disables LUID device maps
//
extern ULONG ObpLUIDDeviceMapsEnabled;

//
//  Local procedure prototypes
//

#define CREATE_SYMBOLIC_LINK 0
#define DELETE_SYMBOLIC_LINK 1


NTSTATUS
NtCreateSymbolicLinkObject (
    OUT PHANDLE LinkHandle,
    IN ACCESS_MASK DesiredAccess,
    IN POBJECT_ATTRIBUTES ObjectAttributes,
    IN PUNICODE_STRING LinkTarget
    )

/*++

Routine Description:

    This function creates a symbolic link object, sets it initial value to
    value specified in the LinkTarget parameter, and opens a handle to the
    object with the specified desired access.

Arguments:

    LinkHandle - Supplies a pointer to a variable that will receive the
        symbolic link object handle.

    DesiredAccess - Supplies the desired types of access for the symbolic link
        object.

    ObjectAttributes - Supplies a pointer to an object attributes structure.

    LinkTarget - Supplies the target name for the symbolic link object.

Return Value:

    An appropriate status value

--*/

{
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;
    POBJECT_SYMBOLIC_LINK SymbolicLink;
    PVOID Object;
    HANDLE Handle;
    UNICODE_STRING CapturedLinkTarget;

    PAGED_CODE();

    //
    //  Get previous processor mode and probe output arguments if necessary.
    //

    PreviousMode = KeGetPreviousMode();

    if (PreviousMode != KernelMode) {

        try {

            ProbeForReadSmallStructure( ObjectAttributes,
                                        sizeof( OBJECT_ATTRIBUTES ),
                                        sizeof( ULONG ));

            ProbeForReadSmallStructure( LinkTarget,
                                        sizeof( *LinkTarget ),
                                        sizeof( UCHAR ));

            CapturedLinkTarget = *LinkTarget;

            ProbeForRead( CapturedLinkTarget.Buffer,
                          CapturedLinkTarget.MaximumLength,
                          sizeof( UCHAR ));

            ProbeForWriteHandle( LinkHandle );

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            return( GetExceptionCode() );
        }

    } else {

        CapturedLinkTarget = *LinkTarget;
    }

    //
    //  Check if there is an odd MaximumLength
    //

    if (CapturedLinkTarget.MaximumLength % sizeof( WCHAR )) {

        //
        //  Round down the MaximumLength to a valid even size
        //

        CapturedLinkTarget.MaximumLength = (CapturedLinkTarget.MaximumLength / sizeof( WCHAR )) * sizeof( WCHAR );
    }

    //
    //  Error if link target name length is odd, the length is greater than
    //  the maximum length, or zero and creating.
    //

    if ((CapturedLinkTarget.MaximumLength == 0) ||
        (CapturedLinkTarget.Length > CapturedLinkTarget.MaximumLength) ||
        (CapturedLinkTarget.Length % sizeof( WCHAR ))) {

        KdPrint(( "OB: Invalid symbolic link target - %wZ\n", &CapturedLinkTarget ));

        return( STATUS_INVALID_PARAMETER );
    }

    //
    //  Create the symbolic link object
    //

    Status = ObCreateObject( PreviousMode,
                             ObpSymbolicLinkObjectType,
                             ObjectAttributes,
                             PreviousMode,
                             NULL,
                             sizeof( *SymbolicLink ),
                             0,
                             0,
                             (PVOID *)&SymbolicLink );

    if (!NT_SUCCESS( Status )) {

        return( Status );
    }

    //
    //  Fill in symbolic link object with link target name string
    //

    KeQuerySystemTime( &SymbolicLink->CreationTime );

    SymbolicLink->DosDeviceDriveIndex = 0;
    SymbolicLink->LinkTargetObject = NULL;

    RtlInitUnicodeString( &SymbolicLink->LinkTargetRemaining,  NULL );

    SymbolicLink->LinkTarget.MaximumLength = CapturedLinkTarget.MaximumLength;
    SymbolicLink->LinkTarget.Length = CapturedLinkTarget.Length;
    SymbolicLink->LinkTarget.Buffer = (PWCH)ExAllocatePoolWithTag( PagedPool,
                                                                   CapturedLinkTarget.MaximumLength,
                                                                   'tmyS' );

    if (SymbolicLink->LinkTarget.Buffer == NULL) {

        ObDereferenceObject( SymbolicLink );

        return STATUS_NO_MEMORY;
    }

    try {

        RtlCopyMemory( SymbolicLink->LinkTarget.Buffer,
                       CapturedLinkTarget.Buffer,
                       CapturedLinkTarget.MaximumLength );

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        ObDereferenceObject( SymbolicLink );

        return( GetExceptionCode() );
    }

    //
    //  Insert symbolic link object in the current processes object table,
    //  set symbolic link handle value and return status.
    //

    Status = ObInsertObject( SymbolicLink,
                             NULL,
                             DesiredAccess,
                             0,
                             (PVOID *)&Object,
                             &Handle );

    try {

        *LinkHandle = Handle;

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        //
        // Fall through, since we do not want to undo what we have done.
        //
    }

    return( Status );
}


NTSTATUS
NtOpenSymbolicLinkObject (
    OUT PHANDLE LinkHandle,
    IN ACCESS_MASK DesiredAccess,
    IN POBJECT_ATTRIBUTES ObjectAttributes
    )

/*++

Routine Description:

    This function opens a handle to an symbolic link object with the specified
    desired access.

Arguments:

    LinkHandle - Supplies a pointer to a variable that will receive the
        symbolic link object handle.

    DesiredAccess - Supplies the desired types of access for the symbolic link
        object.

    ObjectAttributes - Supplies a pointer to an object attributes structure.

Return Value:

    An appropriate status value

--*/

{
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;
    HANDLE Handle;

    PAGED_CODE();

    //
    //  Get previous processor mode and probe output arguments if necessary.
    //  The object attributes does not need to be probed because the
    //  ObOpenObjectByName does the probe for us
    //

    PreviousMode = KeGetPreviousMode();

    if (PreviousMode != KernelMode) {

        try {

            ProbeForWriteHandle( LinkHandle );

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            return( GetExceptionCode() );
        }
    }

    //
    //  Open handle to the symbolic link object with the specified desired
    //  access, set symbolic link handle value, and return service completion
    //  status.
    //

    Status = ObOpenObjectByName( ObjectAttributes,
                                 ObpSymbolicLinkObjectType,
                                 PreviousMode,
                                 NULL,
                                 DesiredAccess,
                                 NULL,
                                 &Handle );

    try {

        *LinkHandle = Handle;

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        //
        //  Fall through, since we do not want to undo what we have done.
        //
    }

    return( Status );
}


NTSTATUS
NtQuerySymbolicLinkObject (
    IN HANDLE LinkHandle,
    IN OUT PUNICODE_STRING LinkTarget,
    OUT PULONG ReturnedLength OPTIONAL
    )

/*++

Routine Description:

    This function queries the state of a symbolic link object and returns the
    requested information in the specified record structure.

Arguments:

    LinkHandle - Supplies a handle to a symbolic link object.  This handle
        must have SYMBOLIC_LINK_QUERY access granted.

    LinkTarget - Supplies a pointer to a record that is to receive the
        target name of the symbolic link object.

    ReturnedLength - Optionally receives the maximum length, in bytes, of
        the link target on return

Return Value:

    An appropriate status value

--*/

{
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;
    POBJECT_SYMBOLIC_LINK SymbolicLink;
    UNICODE_STRING CapturedLinkTarget;

    //
    //  Get previous processor mode and probe output arguments if necessary.
    //

    PAGED_CODE();

    PreviousMode = KeGetPreviousMode();

    if (PreviousMode != KernelMode) {

        try {

            ProbeForReadSmallStructure( LinkTarget,
                                        sizeof( *LinkTarget ),
                                        sizeof( WCHAR ) );

            ProbeForWriteUshort( &LinkTarget->Length );

            ProbeForWriteUshort( &LinkTarget->MaximumLength );

            CapturedLinkTarget = *LinkTarget;

            ProbeForWrite( CapturedLinkTarget.Buffer,
                           CapturedLinkTarget.MaximumLength,
                           sizeof( UCHAR ) );

            if (ARGUMENT_PRESENT( ReturnedLength )) {

                ProbeForWriteUlong( ReturnedLength );
            }

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            return( GetExceptionCode() );
        }

    } else {

        CapturedLinkTarget = *LinkTarget;
    }

    //
    //  Reference symbolic link object by handle, read current state, deference
    //  symbolic link object, fill in target name structure and return service
    //  status.
    //

    Status = ObReferenceObjectByHandle( LinkHandle,
                                        SYMBOLIC_LINK_QUERY,
                                        ObpSymbolicLinkObjectType,
                                        PreviousMode,
                                        (PVOID *)&SymbolicLink,
                                        NULL );

    if (NT_SUCCESS( Status )) {

        POBJECT_HEADER ObjectHeader;

        ObjectHeader = OBJECT_TO_OBJECT_HEADER( SymbolicLink );

        ObpLockObject( ObjectHeader );

        //
        //  If the caller wants a return length and what we found can easily
        //  fit in the output buffer then we copy into the output buffer all
        //  the bytes from the link.
        //
        //  If the caller did not want a return length and we found can still
        //  easily fit in the output buffer then copy over the bytes that just
        //  make up the string and nothing extra
        //

        if ((ARGUMENT_PRESENT( ReturnedLength ) &&
                (SymbolicLink->LinkTarget.MaximumLength <= CapturedLinkTarget.MaximumLength))

                    ||

            (!ARGUMENT_PRESENT( ReturnedLength ) &&
                (SymbolicLink->LinkTarget.Length <= CapturedLinkTarget.MaximumLength)) ) {

            try {

                RtlCopyMemory( CapturedLinkTarget.Buffer,
                               SymbolicLink->LinkTarget.Buffer,
                               ARGUMENT_PRESENT( ReturnedLength ) ? SymbolicLink->LinkTarget.MaximumLength
                                                                  : SymbolicLink->LinkTarget.Length );

                LinkTarget->Length = SymbolicLink->LinkTarget.Length;

                if (ARGUMENT_PRESENT( ReturnedLength )) {

                    *ReturnedLength = SymbolicLink->LinkTarget.MaximumLength;
                }

            } except( EXCEPTION_EXECUTE_HANDLER ) {

                //
                // Fall through, since we do cannot undo what we have done.
                //
            }

        } else {

            //
            //  The output buffer is just too small for the link target, but
            //  we'll tell the user how much is needed if they asked for that
            //  return value
            //

            if (ARGUMENT_PRESENT( ReturnedLength )) {

                try {

                    *ReturnedLength = SymbolicLink->LinkTarget.MaximumLength;

                } except( EXCEPTION_EXECUTE_HANDLER ) {

                    //
                    // Fall through, since we do cannot undo what we have done.
                    //
                }
            }

            Status = STATUS_BUFFER_TOO_SMALL;
        }

        ObpUnlockObject( ObjectHeader );

        ObDereferenceObject( SymbolicLink );
    }

    return( Status );
}


NTSTATUS
ObpParseSymbolicLink (
    IN PVOID ParseObject,
    IN PVOID ObjectType,
    IN PACCESS_STATE AccessState,
    IN KPROCESSOR_MODE AccessMode,
    IN ULONG Attributes,
    IN OUT PUNICODE_STRING CompleteName,
    IN OUT PUNICODE_STRING RemainingName,
    IN OUT PVOID Context OPTIONAL,
    IN PSECURITY_QUALITY_OF_SERVICE SecurityQos OPTIONAL,
    OUT PVOID *Object
    )

/*++

Routine Description:

    This is the call back routine for parsing symbolic link objects.  It is invoked
    as part of ObpLookupObjectName

Arguments:

    ParseObject - This will actually be a symbolic link object

    ObjectType - Specifies the type of the object to lookup

    AccessState - Current access state, describing already granted access
        types, the privileges used to get them, and any access types yet to
        be granted.  The access masks may not contain any generic access
        types.

    AccessMode - Specifies the callers processor mode

    Attributes - Specifies the attributes for the lookup (e.g., case
        insensitive)

    CompleteName - Supplies a pointer to the complete name that we are trying
        to open.  On return this could be modified to fit the new reparse
        buffer

    RemainingName - Supplies a pointer to the remaining name that we are
        trying to open.  On return this will point to what remains after
        we processed the symbolic link.

    Context - Unused

    SecurityQos - Unused

    Object - Receives a pointer to the symbolic link object that we
        resolve to

Return Value:

    STATUS_REPARSE_OBJECT if the parse object is already a snapped
        symbolic link meaning we've modified the remaining name and
        and have returned the target object of the symbolic link


    STATUS_REPARSE if the parse object has not been snapped.  In this
        case the Complete name has been modified with the link target
        name added in front of the remaining name.  The parameters
        remaining name and object must now be ignored by the caller

    An appropriate error value

--*/

{
    ULONG NewLength;
    USHORT Length;
    USHORT MaximumLength;
    PWCHAR NewName, NewRemainingName;
    ULONG InsertAmount;
    NTSTATUS Status;
    POBJECT_SYMBOLIC_LINK SymbolicLink;
    PUNICODE_STRING LinkTargetName;

    UNREFERENCED_PARAMETER (Context);
    UNREFERENCED_PARAMETER (AccessState);
    UNREFERENCED_PARAMETER (SecurityQos);
    UNREFERENCED_PARAMETER (Attributes);

    PAGED_CODE();

    //
    //  This routine needs to be synchonized with the delete symbolic link
    //  operation.  Which uses the root directory mutex.
    //

    *Object = NULL;

    //
    //  If there isn't any name remaining and the caller gave us
    //  an object type then we'll reference the parse object.  If
    //  this is successful then that's the object we return.  Otherwise
    //  if the status is anything but a type mismatch then we'll
    //  return that error status
    //

    if (RemainingName->Length == 0) {

        if ( ObjectType ) {

            Status = ObReferenceObjectByPointer( ParseObject,
                                                 0,
                                                 ObjectType,
                                                 AccessMode );

            if (NT_SUCCESS( Status )) {

                *Object = ParseObject;

                return Status;

            } else if (Status != STATUS_OBJECT_TYPE_MISMATCH) {

                return Status;
            }
       }

       //
       //  If the remaining name does not start with a "\" then
       //  its is illformed and we'll call it a type mismatch
       //

    } else if (*(RemainingName->Buffer) != OBJ_NAME_PATH_SEPARATOR) {

        return STATUS_OBJECT_TYPE_MISMATCH;
    }

    //
    //  A symbolic link has been encountered. See if this link has been snapped
    //  to a particular object.
    //

    SymbolicLink = (POBJECT_SYMBOLIC_LINK)ParseObject;

    if (SymbolicLink->LinkTargetObject != NULL) {

        //
        //  This is a snapped link.  Get the remaining portion of the
        //  symbolic link target, if any.
        //

        LinkTargetName = &SymbolicLink->LinkTargetRemaining;

        if (LinkTargetName->Length == 0) {

            //
            //  Remaining link target string is zero, so return to caller
            //  quickly with snapped object pointer and remaining object name
            //  which we haven't touched yet.
            //

            *Object = SymbolicLink->LinkTargetObject;

            return STATUS_REPARSE_OBJECT;
        }

        //
        //  We have a snapped symbolic link that has additional text.
        //  Insert that in front of the current remaining name, preserving
        //  and text between CompleteName and RemainingName
        //

        InsertAmount = LinkTargetName->Length;

        if ((LinkTargetName->Buffer[ (InsertAmount / sizeof( WCHAR )) - 1 ] == OBJ_NAME_PATH_SEPARATOR)

                &&

            (*(RemainingName->Buffer) == OBJ_NAME_PATH_SEPARATOR)) {

            //
            //  Both the link target name ends in a "\" and the remaining
            //  starts with a "\" but we only need one when we're done
            //

            InsertAmount -= sizeof( WCHAR );
        }

        //
        //  We need to bias the differnce between two
        //  pointers with * sizeof(wchar) because the difference is in wchar
        //  and we need the length in bytes
        //

        NewLength = (ULONG)(((RemainingName->Buffer - CompleteName->Buffer) * sizeof( WCHAR )) +
                    InsertAmount +
                    RemainingName->Length);

        if (NewLength > 0xFFF0) {

            return STATUS_NAME_TOO_LONG;
        }

        Length = (USHORT)NewLength;

        //
        //  Now check if the new computed length is too big for the input
        //  buffer containing the complete name
        //

        if (CompleteName->MaximumLength <= Length) {

            //
            //  The new concatentated name is larger than the buffer supplied for
            //  the complete name.  Allocate space for this new string
            //

            MaximumLength = Length + sizeof( UNICODE_NULL );
            NewName = ExAllocatePoolWithTag( OB_NAMESPACE_POOL_TYPE, MaximumLength, 'mNbO' );

            if (NewName == NULL) {

                return STATUS_INSUFFICIENT_RESOURCES;
            }

            //
            //  Calculate the pointer within this buffer for the remaining
            //  name.  This value has not been biased by the new link
            //  target name
            //

            NewRemainingName = NewName + (RemainingName->Buffer - CompleteName->Buffer);

            //
            //  Copy over all the names that we've processed so far
            //

            RtlCopyMemory( NewName,
                           CompleteName->Buffer,
                           ((RemainingName->Buffer - CompleteName->Buffer) * sizeof( WCHAR )));

            //
            //  If we have some remaining names then those over at the
            //  the location offset to hold the link target name
            //

            if (RemainingName->Length != 0) {

                RtlCopyMemory( (PVOID)((PUCHAR)NewRemainingName + InsertAmount),
                               RemainingName->Buffer,
                               RemainingName->Length );
            }

            //
            //  Now insert the link target name
            //

            RtlCopyMemory( NewRemainingName, LinkTargetName->Buffer, InsertAmount );

            //
            //  Free the old complete name buffer and reset the input
            //  strings to use the new buffer
            //

            ExFreePool( CompleteName->Buffer );

            CompleteName->Buffer = NewName;
            CompleteName->Length = Length;
            CompleteName->MaximumLength = MaximumLength;

            RemainingName->Buffer = NewRemainingName;
            RemainingName->Length = Length - (USHORT)((PCHAR)NewRemainingName - (PCHAR)NewName);
            RemainingName->MaximumLength = RemainingName->Length + sizeof( UNICODE_NULL );

        } else {

            //
            //  Insert extra text associated with this symbolic link name before
            //  existing remaining name, if any.
            //
            //  First shove over the remaining name to make a hole for the
            //  link target name
            //

            if (RemainingName->Length != 0) {

                RtlMoveMemory( (PVOID)((PUCHAR)RemainingName->Buffer + InsertAmount),
                               RemainingName->Buffer,
                               RemainingName->Length );
            }

            //
            //  Now insert the link target name
            //

            RtlCopyMemory( RemainingName->Buffer, LinkTargetName->Buffer, InsertAmount );

            //
            //  Adjust input strings to account for this inserted text
            //

            CompleteName->Length = (USHORT)(CompleteName->Length + LinkTargetName->Length);

            RemainingName->Length = (USHORT)(RemainingName->Length + LinkTargetName->Length);
            RemainingName->MaximumLength += RemainingName->Length + sizeof( UNICODE_NULL );

            CompleteName->Buffer[ CompleteName->Length / sizeof( WCHAR ) ] = UNICODE_NULL;
        }

        //
        //  Return the object address associated with snapped symbolic link
        //  and the reparse object status code.
        //

        *Object = SymbolicLink->LinkTargetObject;

        return STATUS_REPARSE_OBJECT;
    }

    //
    //  The symbolic has not yet been snapped
    //
    //  Compute the size of the new name and check if the name will
    //  fit in the existing complete name buffer.
    //

    LinkTargetName = &SymbolicLink->LinkTarget;

    InsertAmount = LinkTargetName->Length;

    if ((InsertAmount != 0)
            &&
        (LinkTargetName->Buffer[ (InsertAmount / sizeof( WCHAR )) - 1 ] == OBJ_NAME_PATH_SEPARATOR)
            &&
        (RemainingName->Length != 0)
            &&
        (*(RemainingName->Buffer) == OBJ_NAME_PATH_SEPARATOR)) {

        //
        //  Both the link target name ends in a "\" and the remaining
        //  starts with a "\" but we only need one when we're done
        //

        InsertAmount -= sizeof( WCHAR );
    }

    NewLength = InsertAmount + RemainingName->Length;

    if (NewLength > 0xFFF0) {

        return STATUS_NAME_TOO_LONG;
    }

    Length = (USHORT)NewLength;

    if (CompleteName->MaximumLength <= Length) {

        //
        //  The new concatentated name is larger than the buffer supplied for
        //  the complete name.
        //

        MaximumLength = Length + sizeof( UNICODE_NULL );
        NewName = ExAllocatePoolWithTag( OB_NAMESPACE_POOL_TYPE, MaximumLength, 'mNbO' );

        if (NewName == NULL) {

            return STATUS_INSUFFICIENT_RESOURCES;
        }

    } else {

        MaximumLength = CompleteName->MaximumLength;
        NewName = CompleteName->Buffer;
    }

    //
    //  Concatenate the symbolic link name with the remaining name,
    //  if any.  What this does is overwrite the front of the complete
    //  name up to the remaining name with the links target name
    //

    if (RemainingName->Length != 0) {

        RtlMoveMemory( (PVOID)((PUCHAR)NewName + InsertAmount),
                       RemainingName->Buffer,
                       RemainingName->Length );
    }

    RtlCopyMemory( NewName, LinkTargetName->Buffer, InsertAmount );

    NewName[ Length / sizeof( WCHAR ) ] = UNICODE_NULL;

    //
    //  If a new name buffer was allocated, then free the original complete
    //  name buffer.
    //

    if (NewName != CompleteName->Buffer) {

        ExFreePool( CompleteName->Buffer );
    }

    //
    //  Set the new complete name buffer parameters and return a reparse
    //  status.
    //

    CompleteName->Buffer = NewName;
    CompleteName->Length = Length;
    CompleteName->MaximumLength = MaximumLength;

    return STATUS_REPARSE;
}


VOID
ObpDeleteSymbolicLink (
    IN  PVOID   Object
    )

/*++

Routine Description:

    This routine is called when a reference to a symbolic link goes to zero.
    Its job is to clean up the memory used to the symbolic link string

Arguments:

    Object - Supplies a pointer to the symbolic link object being deleted

Return Value:

    None.

--*/

{
    POBJECT_SYMBOLIC_LINK SymbolicLink = (POBJECT_SYMBOLIC_LINK)Object;

    PAGED_CODE();

    //
    //  The only cleaning up we need to do is to free the link target
    //  buffer
    //

    if (SymbolicLink->LinkTarget.Buffer != NULL) {

        ExFreePool( SymbolicLink->LinkTarget.Buffer );
    }

    SymbolicLink->LinkTarget.Buffer = NULL;

    //
    //  And return to our caller
    //

    return;
}


VOID
ObpDeleteSymbolicLinkName (
    POBJECT_SYMBOLIC_LINK SymbolicLink
    )

/*++

Routine Description:

    This routine delete the symbolic from the system

Arguments:

    SymbolicLink - Supplies a pointer to the object body for the symbolic
        link object to delete

Return Value:

    None.

    This function must be called with the symbolic link object locked.
    That lock is protecting the symlink specific fields.

--*/

{

    ObpProcessDosDeviceSymbolicLink( SymbolicLink, DELETE_SYMBOLIC_LINK );

    return;
}


VOID
ObpCreateSymbolicLinkName (
    POBJECT_SYMBOLIC_LINK SymbolicLink
    )

/*++

Routine Description:

    This routine does extra processing for symbolic links being created in
    object directories controlled by device map objects.

    This processing consists of:

    1.  Determine if the name of the symbolic link is a drive letter.
        If so, then we will need to update the drive type in the
        associated device map object.

    2.  Process the link target, trying to resolve it into a pointer to
        an object other than a object directory object.  All object
        directories traversed must grant world traverse access other
        wise we bail out.  If we successfully find a non object
        directory object, then reference the object pointer and store it
        in the symbolic link object, along with a remaining string if
        any.  ObpLookupObjectName will used this cache object pointer to
        short circuit the name lookup directly to the cached object's
        parse routine.  For any object directory objects traversed along
        the way, increment their symbolic link SymbolicLinkUsageCount
        field.  This field is used whenever an object directory is
        deleted or its security is changed such that it no longer grants
        world traverse access.  In either case, if the field is non-zero
        we walk all the symbolic links and resnap them.

Arguments:

    SymbolicLink - pointer to symbolic link object being created.

Return Value:

    None.

--*/

{
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;
    WCHAR DosDeviceDriveLetter;
    ULONG DosDeviceDriveIndex;

    //
    //  Now see if this symbolic link is being created in an object directory
    //  controlled by a device map object.  Since we are only called from
    //  NtCreateSymbolicLinkObject, after the handle to this symbolic link
    //  has been created but before it is returned to the caller the handle can't
    //  be closed while we are executing, unless via a random close,
    //  So no need to hold the type specific mutex while we look at the name.
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( SymbolicLink );
    NameInfo = ObpReferenceNameInfo( ObjectHeader );

    if ((NameInfo == NULL) ||
        (NameInfo->Directory == NULL) ||
        (NameInfo->Directory->DeviceMap == NULL)) {

        ObpDereferenceNameInfo( NameInfo );
        return;
    }

    //
    //  Here if we are creating a symbolic link in an object directory controlled
    //  by a device map object.  See if this is a drive letter definition.  If so
    //  calculate the drive letter index and remember in the symbolic link object.
    //

    DosDeviceDriveIndex = 0;

    if ((NameInfo->Name.Length == (2 * sizeof( WCHAR ))) &&
        (NameInfo->Name.Buffer[ 1 ] == L':')) {

        DosDeviceDriveLetter = RtlUpcaseUnicodeChar( NameInfo->Name.Buffer[ 0 ] );

        if ((DosDeviceDriveLetter >= L'A') && (DosDeviceDriveLetter <= L'Z')) {

            DosDeviceDriveIndex = DosDeviceDriveLetter - L'A';
            DosDeviceDriveIndex += 1;

            SymbolicLink->DosDeviceDriveIndex = DosDeviceDriveIndex;
        }
    }

    //
    //  Now traverse the target path seeing if we can snap the link now.
    //

    ObpProcessDosDeviceSymbolicLink( SymbolicLink, CREATE_SYMBOLIC_LINK );

    ObpDereferenceNameInfo( NameInfo );

    return;
}


//
//  Local support routine
//

#define MAX_DEPTH 16

VOID
ObpProcessDosDeviceSymbolicLink (
    POBJECT_SYMBOLIC_LINK SymbolicLink,
    ULONG Action
    )

/*++

Routine Description:

    This function is called whenever a symbolic link is created or deleted
    in an object directory controlled by a device map object.

    For creates, it attempts to snap the symbolic link to a non-object
    directory object.  It does this by walking the symbolic link target
    string, until it sees a non-directory object or a directory object
    that does NOT allow World traverse access.  It stores a referenced
    pointer to this object in the symbolic link object.  It also
    increments a count in each of the object directory objects that it
    walked over.  This count is used to disallow any attempt to remove
    World traverse access from a directory object after it has
    participated in a snapped symbolic link.

    For deletes, it repeats the walk of the target string, decrementing
    the count associated with each directory object walked over.  It also
    dereferences the snapped object pointer.

Arguments:

    SymbolicLink - pointer to symbolic link object being created or deleted.

    Action - describes whether this is a create or a delete action

Return Value:

    None.

--*/

{
    PVOID Object;
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;
    UNICODE_STRING RemainingName;
    UNICODE_STRING ComponentName;
#if 0
    NTSTATUS Status;
    PSECURITY_DESCRIPTOR SecurityDescriptor;
    BOOLEAN MemoryAllocated;
    BOOLEAN HaveWorldTraverseAccess;
    ULONG Depth;
    POBJECT_DIRECTORY Directories[ MAX_DEPTH ];
#endif
    POBJECT_DIRECTORY Directory, ParentDirectory;
    PDEVICE_OBJECT DeviceObject;
    PDEVICE_MAP DeviceMap = NULL;
    ULONG DosDeviceDriveType;
    BOOLEAN DeviceMapUsed = FALSE;
    UNICODE_STRING RemainingTarget;
    ULONG MaxReparse = OBJ_MAX_REPARSE_ATTEMPTS;
    OBP_LOOKUP_CONTEXT LookupContext;
    POBJECT_DIRECTORY SymLinkDirectory = NULL;
    BOOLEAN PreviousLockingState;

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( SymbolicLink );
    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

    if (NameInfo != NULL) {

        SymLinkDirectory = NameInfo->Directory;
    }

    Object = NULL;
    RtlInitUnicodeString( &RemainingTarget, NULL );

    ObpInitializeLookupContext( &LookupContext );

    //
    //  Check if we are creating a symbolic link or if the link has already
    //  been snapped
    //

    if ((Action == CREATE_SYMBOLIC_LINK) ||
        (SymbolicLink->LinkTargetObject != NULL)) {

        ParentDirectory = NULL;
#if 0
        Depth    = 0;
#endif
        Directory = ObpRootDirectoryObject;
        RemainingName = SymbolicLink->LinkTarget;

        //
        // If LUID device maps are enabled,
        // then use the Object Manager's pointer to the global
        // device map
        // With LUID device maps enabled, the process' device map pointer
        // may be NULL
        //
        if (ObpLUIDDeviceMapsEnabled != 0) {
            DeviceMap = ObSystemDeviceMap;
        }
        else {
            //
            // use the device map associated with the process
            //
            DeviceMap = PsGetCurrentProcess()->DeviceMap;
        }


ReCalcDeviceMap:

        if (DeviceMap) {


            if (!((ULONG_PTR)(RemainingName.Buffer) & (sizeof(ULONGLONG)-1))

                        &&

                (DeviceMap->DosDevicesDirectory != NULL )) {

                //
                //  Check if the object name is actually equal to the
                //  global dos devices short name prefix "\??\"
                //

                if ((RemainingName.Length >= ObpDosDevicesShortName.Length)

                        &&

                    (*(PULONGLONG)(RemainingName.Buffer) == ObpDosDevicesShortNamePrefix.Alignment.QuadPart)) {

                    //
                    //  The user gave us the dos short name prefix so we'll
                    //  look down the directory, and start the search at the
                    //  dos device directory
                    //

                    Directory = DeviceMap->DosDevicesDirectory;

                    RemainingName.Buffer += (ObpDosDevicesShortName.Length / sizeof( WCHAR ));
                    RemainingName.Length = (USHORT)(RemainingName.Length - ObpDosDevicesShortName.Length);

                    DeviceMapUsed = TRUE;

                }
            }
        }

        //
        //  The following loop will dissect the link target checking
        //  that each directory exists and that we have access to
        //  the directory.  When we pop out the local directories
        //  array will contain a list of directories that we need
        //  to traverse to process this action.
        //

        while (TRUE) {

            //
            //  Gobble up the "\" in the remaining name
            //

            if (*(RemainingName.Buffer) == OBJ_NAME_PATH_SEPARATOR) {

                RemainingName.Buffer++;
                RemainingName.Length -= sizeof( OBJ_NAME_PATH_SEPARATOR );
            }

            //
            //  And dissect the name into its first component and any
            //  remaining part
            //

            ComponentName = RemainingName;

            while (RemainingName.Length != 0) {

                if (*(RemainingName.Buffer) == OBJ_NAME_PATH_SEPARATOR) {

                    break;
                }

                RemainingName.Buffer++;
                RemainingName.Length -= sizeof( OBJ_NAME_PATH_SEPARATOR );
            }

            ComponentName.Length = (USHORT)(ComponentName.Length - RemainingName.Length);

            if (ComponentName.Length == 0) {

                ObpReleaseLookupContext(&LookupContext);
                return;
            }

#if 0
            //
            //  See if we have world traverse access to look this name up
            //

            if (ParentDirectory != NULL) {

                HaveWorldTraverseAccess = FALSE;

                //
                //  Obtain the object's security descriptor
                //

                Status = ObGetObjectSecurity( ParentDirectory,
                                              &SecurityDescriptor,
                                              &MemoryAllocated );

                if (NT_SUCCESS( Status )) {

                    //
                    //  Check to see if WORLD has TRAVERSE access and then release
                    //  the security descriptor
                    //

                    HaveWorldTraverseAccess = SeFastTraverseCheck( SecurityDescriptor,
                                                                   DIRECTORY_TRAVERSE,
                                                                   UserMode );

                    ObReleaseObjectSecurity( SecurityDescriptor,
                                             MemoryAllocated );
                }

                if (!HaveWorldTraverseAccess) {

                    Object = NULL;
                    break;
                }

                if (Depth >= MAX_DEPTH) {

                    Object = NULL;
                    break;
                }

                Directories[ Depth++ ] = ParentDirectory;
            }
#endif

            //
            //  Look this component name up in this directory.  If not found, then
            //  bail.
            //

            //
            //  If we are searching the same directory that contains the sym link
            //  we have already the directory exclusively locked. We need to adjust
            //  the lookupcontext state and avoid recursive locking
            //

            if (Directory == SymLinkDirectory) {

                PreviousLockingState = LookupContext.DirectoryLocked;
                LookupContext.DirectoryLocked = TRUE;
            }
            else {
                PreviousLockingState = FALSE;
            }

            Object = ObpLookupDirectoryEntry( Directory,
                                              &ComponentName,
                                              0,
                                              FALSE ,
                                              &LookupContext);

            if (Directory == SymLinkDirectory) {

                LookupContext.DirectoryLocked = PreviousLockingState;
            }

            if (Object == NULL) {

                break;
            }

            //
            //  See if this is a object directory object.  If so, keep going
            //

            ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

            if (ObjectHeader->Type == ObpDirectoryObjectType) {

                ParentDirectory = Directory;
                Directory = (POBJECT_DIRECTORY)Object;

            } else if ((ObjectHeader->Type == ObpSymbolicLinkObjectType) &&
                       (((POBJECT_SYMBOLIC_LINK)Object)->DosDeviceDriveIndex == 0)) {

                //
                // To prevent Denial of Service attacks from parsing
                // symbolic links infinitely.
                // Check the number of symbolic link parse attempts
                //
                if (MaxReparse == 0) {

                    Object = NULL;
                    break;
                }

                MaxReparse--;

                //
                //  Found a symbolic link to another symbolic link that is
                //  not already snapped.  So switch to its target string
                //  so we can chase down the real device object
                //

                ParentDirectory = NULL;
#if 0
                Depth = 0;
#endif
                Directory = ObpRootDirectoryObject;

                //
                //  Save the remaining name
                //

                if (RemainingTarget.Length == 0) {

                    RemainingTarget = RemainingName;
                }

                RemainingName = ((POBJECT_SYMBOLIC_LINK)Object)->LinkTarget;

                goto ReCalcDeviceMap;

            } else {

                //
                //  Not an object directory object, or a symbolic link to an
                //  unsnapped symbolic link, so all done.  Exit the loop
                //

                break;
            }
        }

#if 0
        //
        //  Done walking the target path.  Now update the counts associated
        //  with each directory object walked over.
        //

        while (Depth--) {

            Directory = Directories[ Depth ];

            if (Action == CREATE_SYMBOLIC_LINK) {

                if (Object != NULL) {

                    Directory->SymbolicLinkUsageCount += 1;
                }

            } else {

                Directory->SymbolicLinkUsageCount -= 1;
            }
        }
#endif
    }

    //
    //  Done processing symbolic link target path.  Update symbolic link
    //  object as appropriate for passed in reason
    //

    //
    //  If this is a drive letter symbolic link, get the address of the device
    //  map object that is controlling the containing object directory so we
    //  can update the drive type in the device map.
    //

    DeviceMap = NULL;

    if (SymbolicLink->DosDeviceDriveIndex != 0) {

        ObjectHeader = OBJECT_TO_OBJECT_HEADER( SymbolicLink );
        NameInfo = ObpReferenceNameInfo( ObjectHeader );

        if (NameInfo != NULL && NameInfo->Directory) {

            DeviceMap = NameInfo->Directory->DeviceMap;
        }

        ObpDereferenceNameInfo( NameInfo );
    }

    //
    //  Check if we are creating a symbolic link
    //

    if (Action == CREATE_SYMBOLIC_LINK) {

        DosDeviceDriveType = DOSDEVICE_DRIVE_CALCULATE;

        if (Object != NULL) {


            //
            // We only want to do snapping for console session. When we create a
            // remote session all the symbolic links stored in the console dos devices
            // directory (\??) are copied into the per session DosDevices object directory
            // (\Session\<id>\DosDevices). We don't want to do snapping for the copied
            // symbolic links since for each copy we will increment the ref count on the
            // target object. All these counts have to go to zero before the device can be
            // deleted.
            //
            // Disable snapping until we come up with a delete scheme for it
            //
            if (FALSE /*( PsGetCurrentProcess()->SessionId == 0) || (DeviceMapUsed)*/) {
                //
                //  Create action.  Store a referenced pointer to the snapped object
                //  along with the description of any remaining name string.  Also,
                //  for Dos drive letters, update the drive type in the appropriate
                //  device map object.
                //

                ObReferenceObject( Object );

                SymbolicLink->LinkTargetObject = Object;

                //
                //  If we have saved a remaining target string
                //  we'll set it to the symbolic link object
                //

                if ( RemainingTarget.Length ) {

                    RemainingName = RemainingTarget;
                }

                if ((*(RemainingName.Buffer) == OBJ_NAME_PATH_SEPARATOR) &&
                    (RemainingName.Length == sizeof( OBJ_NAME_PATH_SEPARATOR))) {

                    RtlInitUnicodeString( &SymbolicLink->LinkTargetRemaining, NULL );

                } else {

                    SymbolicLink->LinkTargetRemaining = RemainingName;
                }
            }

            if (SymbolicLink->DosDeviceDriveIndex != 0) {

                //
                //  Default is to calculate the drive type in user mode if we are
                //  unable to snap the symbolic link or it does not resolve to a
                //  DEVICE_OBJECT we know about.
                //

                ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

                if (ObjectHeader->Type == IoDeviceObjectType) {

                    DeviceObject = (PDEVICE_OBJECT)Object;

                    switch (DeviceObject->DeviceType) {

                    case FILE_DEVICE_CD_ROM:
                    case FILE_DEVICE_CD_ROM_FILE_SYSTEM:

                        DosDeviceDriveType = DOSDEVICE_DRIVE_CDROM;

                        break;

                    case FILE_DEVICE_DISK:
                    case FILE_DEVICE_DISK_FILE_SYSTEM:
                    case FILE_DEVICE_FILE_SYSTEM:

                        if (DeviceObject->Characteristics & FILE_REMOVABLE_MEDIA) {

                            DosDeviceDriveType = DOSDEVICE_DRIVE_REMOVABLE;

                        } else {

                            DosDeviceDriveType = DOSDEVICE_DRIVE_FIXED;
                        }

                        break;

                    case FILE_DEVICE_MULTI_UNC_PROVIDER:
                    case FILE_DEVICE_NETWORK:
                    case FILE_DEVICE_NETWORK_BROWSER:
                    case FILE_DEVICE_NETWORK_REDIRECTOR:

                        DosDeviceDriveType = DOSDEVICE_DRIVE_REMOTE;

                        break;

                    case FILE_DEVICE_NETWORK_FILE_SYSTEM:

#if defined(REMOTE_BOOT)
                        //
                        //  If this is a remote boot workstation, the X:
                        //  drive is a redirected drive, but needs to look
                        //  like a local drive.
                        //

                        if (IoRemoteBootClient &&
                            (SymbolicLink->DosDeviceDriveIndex == 24)) {

                            DosDeviceDriveType = DOSDEVICE_DRIVE_FIXED;

                        } else
#endif // defined(REMOTE_BOOT)
                        {
                            DosDeviceDriveType = DOSDEVICE_DRIVE_REMOTE;
                        }

                        break;

                    case FILE_DEVICE_VIRTUAL_DISK:

                        DosDeviceDriveType = DOSDEVICE_DRIVE_RAMDISK;

                        break;

                    default:

                        DosDeviceDriveType = DOSDEVICE_DRIVE_UNKNOWN;

                        break;
                    }
                }
            }
        }

        //
        //  If this is a drive letter symbolic link, update the drive type and
        //  and mark as valid drive letter.
        //

        if (DeviceMap != NULL) {

            ObpLockDeviceMap();

            DeviceMap->DriveType[ SymbolicLink->DosDeviceDriveIndex-1 ] = (UCHAR)DosDeviceDriveType;
            DeviceMap->DriveMap |= 1 << (SymbolicLink->DosDeviceDriveIndex-1) ;

            ObpUnlockDeviceMap();
        }

    } else {

        //
        //  Deleting the symbolic link.  Dereference the snapped object pointer if any
        //  and zero out the snapped object fields.
        //

        RtlInitUnicodeString( &SymbolicLink->LinkTargetRemaining, NULL );

        Object = SymbolicLink->LinkTargetObject;

        if (Object != NULL) {

            SymbolicLink->LinkTargetObject = NULL;
            ObDereferenceObject( Object );
        }

        //
        //  If this is a drive letter symbolic link, set the drive type to
        //  unknown and clear the bit in the drive letter bit map.
        //

        if (DeviceMap != NULL) {

            ObpLockDeviceMap();

            DeviceMap->DriveMap &= ~(1 << (SymbolicLink->DosDeviceDriveIndex-1));
            DeviceMap->DriveType[ SymbolicLink->DosDeviceDriveIndex-1 ] = DOSDEVICE_DRIVE_UNKNOWN;

            ObpUnlockDeviceMap();

            SymbolicLink->DosDeviceDriveIndex = 0;
        }

        //
        //  N.B. The original code freed here the target buffer. This is
        //  illegal because the parse routine for symbolic links reads the buffer unsynchronized
        //  The buffer will be released in the delete procedure, when the sym link goes away
        //

    }

    ObpReleaseLookupContext(&LookupContext);

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obp.h ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obp.h

Abstract:

    Private include file for the OB subcomponent of the NTOS project

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#pragma warning(disable:4214)   // bit field types other than int
#pragma warning(disable:4201)   // nameless struct/union
#pragma warning(disable:4324)   // alignment sensitive to declspec
#pragma warning(disable:4127)   // condition expression is constant
#pragma warning(disable:4115)   // named type definition in parentheses
#pragma warning(disable:4053)   // one void operand
#pragma warning(disable:4706)   // assignment within conditional

#include "ntos.h"
#include "seopaque.h"
#include <zwapi.h>

#ifdef _WIN64

#define ObpInterlockedExchangeAdd InterlockedExchangeAdd64
#define ObpInterlockedIncrement InterlockedIncrement64
#define ObpInterlockedDecrement InterlockedDecrement64
#define ObpInterlockedCompareExchange InterlockedCompareExchange64

#else 

#define ObpInterlockedExchangeAdd InterlockedExchangeAdd
#define ObpInterlockedIncrement InterlockedIncrement
#define ObpInterlockedDecrement InterlockedDecrement
#define ObpInterlockedCompareExchange InterlockedCompareExchange

#endif

#define OBP_PAGEDPOOL_NAMESPACE

//
//  The Object Header structures are private, but are defined in ob.h
//  so that various macros can directly access header fields.
//

struct _OBJECT_HEADER;
struct _OBJECT_BODY_HEADER;

//
//  Setup default pool tags
//

#ifdef POOL_TAGGING
#define ExAllocatePool(a,b) ExAllocatePoolWithTag(a,b,'  bO')
#define ExAllocatePoolWithQuota(a,b) ExAllocatePoolWithQuotaTag(a,b,'  bO')
#endif

//
//  Define some macros that will verify that our callbacks don't give us a bad irql
//

#if DBG
#define ObpBeginTypeSpecificCallOut( IRQL ) (IRQL)=KeGetCurrentIrql()
#define ObpEndTypeSpecificCallOut( IRQL, str, ot, o ) {                                               \
    if ((IRQL)!=KeGetCurrentIrql()) {                                                                 \
        DbgPrint( "OB: ObjectType: %wZ  Procedure: %s  Object: %08x\n", &ot->Name, str, o );          \
        DbgPrint( "    Returned at %x IRQL, but was called at %x IRQL\n", KeGetCurrentIrql(), IRQL ); \
        DbgBreakPoint();                                                                              \
    }                                                                                                 \
}
#else
#define ObpBeginTypeSpecificCallOut( IRQL )
#define ObpEndTypeSpecificCallOut( IRQL, str, ot, o )
#endif // DBG

//
//  Define some more macros to validate the current irql
//

#if DBG
#define ObpValidateIrql( str ) \
    if (KeGetCurrentIrql() > APC_LEVEL) { \
        DbgPrint( "OB: %s called at IRQL %d\n", (str), KeGetCurrentIrql() ); \
        DbgBreakPoint(); \
        }
#else
#define ObpValidateIrql( str )
#endif // DBG


//
//  This global lock protects the granted access lists when we are collecting stack traces
//

EX_PUSH_LOCK ObpLock;

KEVENT ObpDefaultObject;
WORK_QUEUE_ITEM ObpRemoveObjectWorkItem;
PVOID ObpRemoveObjectList;

//
//  This global lock is used to protect the device map tear down and build up
//  We can no longer use an individual lock in the device map itself because
//  that wasn't sufficient to protect the device map itself.
//

#ifdef OBP_PAGEDPOOL_NAMESPACE

#define OB_NAMESPACE_POOL_TYPE PagedPool

KGUARDED_MUTEX ObpDeviceMapLock;

#define OBP_DECLARE_OLDIRQL

#define ObpLockDeviceMap() \
    KeAcquireGuardedMutex( &ObpDeviceMapLock )

#define ObpUnlockDeviceMap() \
    KeReleaseGuardedMutex( &ObpDeviceMapLock )

#else // !OBP_PAGEDPOOL_NAMESPACE

#define OB_NAMESPACE_POOL_TYPE NonPagedPool

KSPIN_LOCK ObpDeviceMapLock;

#define ObpLockDeviceMap() \
    ExAcquireSpinLock( &ObpDeviceMapLock, &OldIrql )

#define ObpUnlockDeviceMap() \
    ExReleaseSpinLock( &ObpDeviceMapLock, OldIrql )

#endif  // OBP_PAGEDPOOL_NAMESPACE

#define ObpIncrPointerCountEx(np,Count) (ObpInterlockedExchangeAdd (&np->PointerCount, Count) + Count)
#define ObpDecrPointerCountEx(np,Count) (ObpInterlockedExchangeAdd (&np->PointerCount, -(LONG_PTR)(Count)) - Count)

#ifndef POOL_TAGGING

#define ObpIncrPointerCount(np)           ObpInterlockedIncrement( &np->PointerCount )
#define ObpDecrPointerCount(np)           ObpInterlockedDecrement( &np->PointerCount )
#define ObpDecrPointerCountWithResult(np) (ObpInterlockedDecrement( &np->PointerCount ) == 0)

#define ObpPushStackInfo(np, inc)

#else //POOL_TAGGING

VOID
ObpInitStackTrace();

VOID
ObpRegisterObject (
    POBJECT_HEADER ObjectHeader
    );

VOID
ObpDeregisterObject (
    POBJECT_HEADER ObjectHeader
    );

VOID
ObpPushStackInfo (
    POBJECT_HEADER ObjectHeader,
    BOOLEAN IsRef
    );

extern BOOLEAN ObpTraceEnabled;

#define ObpIncrPointerCount(np)           ((ObpTraceEnabled ? ObpPushStackInfo(np,TRUE) : 0),ObpInterlockedIncrement( &np->PointerCount ))
#define ObpDecrPointerCount(np)           ((ObpTraceEnabled ? ObpPushStackInfo(np,FALSE) : 0),ObpInterlockedDecrement( &np->PointerCount ))
#define ObpDecrPointerCountWithResult(np) ((ObpTraceEnabled ? ObpPushStackInfo(np,FALSE) : 0),(ObpInterlockedDecrement( &np->PointerCount ) == 0))

#endif //POOL_TAGGING

#define ObpIncrHandleCount(np)            ObpInterlockedIncrement( &np->HandleCount )
#define ObpDecrHandleCount(np)            (ObpInterlockedDecrement( &np->HandleCount ) == 0)



//
//  Define macros to acquire and release an object type fast mutex.
//
//
//  VOID
//  ObpEnterObjectTypeMutex (
//      IN POBJECT_TYPE ObjectType
//      )
//

#define ObpEnterObjectTypeMutex(_ObjectType) {                   \
    ObpValidateIrql("ObpEnterObjectTypeMutex");                  \
    KeEnterCriticalRegion();                                     \
    ExAcquireResourceExclusiveLite(&(_ObjectType)->Mutex, TRUE); \
}

//
//  VOID
//  ObpLeaveObjectTypeMutex (
//      IN POBJECT_TYPE ObjectType
//      )
//

#define ObpLeaveObjectTypeMutex(_ObjectType) {  \
    ExReleaseResourceLite(&(_ObjectType)->Mutex);   \
    KeLeaveCriticalRegion();                    \
    ObpValidateIrql("ObpLeaveObjectTypeMutex"); \
}

#define LOCK_HASH_MASK (OBJECT_LOCK_COUNT - 1)

#define ObpHashObjectHeader(_ObjectHeader)      \
    ((((ULONG_PTR)(_ObjectHeader)) >> 8) & LOCK_HASH_MASK)

#define ObpLockObject(_ObjectHeader) {                           \
    ULONG_PTR LockIndex = ObpHashObjectHeader(_ObjectHeader);    \
    ObpValidateIrql("ObpEnterObjectTypeMutex");                  \
    KeEnterCriticalRegion();                                     \
    ExAcquireResourceExclusiveLite(&((_ObjectHeader)->Type->ObjectLocks[LockIndex]), TRUE); \
}

#define ObpLockObjectShared(_ObjectHeader) {                     \
    ULONG_PTR LockIndex = ObpHashObjectHeader(_ObjectHeader);    \
    ObpValidateIrql("ObpEnterObjectTypeMutex");                  \
    KeEnterCriticalRegion();                                     \
    ExAcquireResourceSharedLite(&((_ObjectHeader)->Type->ObjectLocks[LockIndex]), TRUE); \
}

#define ObpUnlockObject(_ObjectHeader) {                                        \
    ULONG_PTR LockIndex = ObpHashObjectHeader(_ObjectHeader);                   \
    ExReleaseResourceLite(&((_ObjectHeader)->Type->ObjectLocks[LockIndex]));        \
    KeLeaveCriticalRegion();                                                    \
    ObpValidateIrql("ObpLeaveObjectTypeMutex");                                 \
}


//
//  A Macro to return the object table for the current process
//

#define ObpGetObjectTable() (PsGetCurrentProcess()->ObjectTable)

//
//  Macro to test whether or not the object manager is responsible for
//  an object's security descriptor, or if the object has its own
//  security management routines.
//

#define ObpCentralizedSecurity(_ObjectType)                              \
    ((_ObjectType)->TypeInfo.SecurityProcedure == SeDefaultObjectMethod)

//
//  Declare a global table of object types.
//

#define OBP_MAX_DEFINED_OBJECT_TYPES 48
POBJECT_TYPE ObpObjectTypes[ OBP_MAX_DEFINED_OBJECT_TYPES ];


//
//  This is some special purpose code to keep a table of access masks correlated with
//  back traces.  If used these routines replace the GrantedAccess mask in the
//  preceding object table entry with a granted access index and a call back index.
//

#if i386 
ACCESS_MASK
ObpTranslateGrantedAccessIndex (
    USHORT GrantedAccessIndex
    );

USHORT
ObpComputeGrantedAccessIndex (
    ACCESS_MASK GrantedAccess
    );

USHORT ObpCurCachedGrantedAccessIndex;
USHORT ObpMaxCachedGrantedAccessIndex;
PACCESS_MASK ObpCachedGrantedAccesses;
#endif // i386 

//
//  The three low order bits of the object table entry are used for handle
//  attributes.
//

//
//  We moved the PROTECT_CLOSE in the granted access mask
//

extern ULONG ObpAccessProtectCloseBit;

//
//  The bit mask for inherit MUST be 0x2.
//

#if (OBJ_INHERIT != 0x2)

#error Object inheritance bit definition conflicts

#endif

//
//  Define the bit mask for the generate audit on close attribute.
//
//  When a handle to an object with security is created, audit routines will
//  be called to perform any auditing that may be required. The audit routines
//  will return a boolean indicating whether or not audits should be generated
//  on close.
//

#define OBJ_AUDIT_OBJECT_CLOSE 0x00000004L


//
//  The following three bits are available for handle attributes in the
//  Object field of an ObjectTableEntry.
//

#define OBJ_HANDLE_ATTRIBUTES (OBJ_PROTECT_CLOSE | OBJ_INHERIT | OBJ_AUDIT_OBJECT_CLOSE)

#define ObpDecodeGrantedAccess(Access)       \
    ((Access) & ~ObpAccessProtectCloseBit)

#define ObpGetHandleAttributes(HandleTableEntry)                                    \
     ((((HandleTableEntry)->GrantedAccess) & ObpAccessProtectCloseBit) ?            \
     ((((HandleTableEntry)->ObAttributes) & OBJ_HANDLE_ATTRIBUTES) | OBJ_PROTECT_CLOSE) : \
     (((HandleTableEntry)->ObAttributes) & (OBJ_INHERIT | OBJ_AUDIT_OBJECT_CLOSE)) )

#define ObpEncodeProtectClose(ObjectTableEntry)                         \
    if ( (ObjectTableEntry).ObAttributes & OBJ_PROTECT_CLOSE ) {        \
                                                                        \
        (ObjectTableEntry).ObAttributes &= ~OBJ_PROTECT_CLOSE;          \
        (ObjectTableEntry).GrantedAccess |= ObpAccessProtectCloseBit;   \
    }


//
//  Security Descriptor Cache
//
//  Cache entry header.
//

typedef struct _SECURITY_DESCRIPTOR_HEADER {

    LIST_ENTRY Link;
    ULONG  RefCount;
    ULONG  FullHash;
#if defined (_WIN64)
    PVOID  Spare;   // Align to 16 byte boundary.
#endif
    QUAD   SecurityDescriptor;

} SECURITY_DESCRIPTOR_HEADER, *PSECURITY_DESCRIPTOR_HEADER;

//
//  Macro to convert a security descriptor into its security descriptor header
//

#define SD_TO_SD_HEADER(_sd) \
    CONTAINING_RECORD( (_sd), SECURITY_DESCRIPTOR_HEADER, SecurityDescriptor )

//
//  Macro to convert a header link into its security descriptor header
//

#define LINK_TO_SD_HEADER(_link) \
    CONTAINING_RECORD( (_link), SECURITY_DESCRIPTOR_HEADER, Link )


//
//  Number of minor hash entries
//

#define SECURITY_DESCRIPTOR_CACHE_ENTRIES    257



//
//  Lock state signatures
//

#define OBP_LOCK_WAITEXCLUSIVE_SIGNATURE    0xAAAA1234
#define OBP_LOCK_WAITSHARED_SIGNATURE       0xBBBB1234
#define OBP_LOCK_OWNEDEXCLUSIVE_SIGNATURE   0xCCCC1234
#define OBP_LOCK_OWNEDSHARED_SIGNATURE      0xDDDD1234
#define OBP_LOCK_RELEASED_SIGNATURE         0xEEEE1234
#define OBP_LOCK_UNUSED_SIGNATURE           0xFFFF1234

//
//  Lookup directories
//

typedef struct _OBP_LOOKUP_CONTEXT {

    POBJECT_DIRECTORY Directory;
    PVOID Object;
    USHORT HashIndex;
    BOOLEAN DirectoryLocked;
    volatile ULONG LockStateSignature;

} OBP_LOOKUP_CONTEXT, *POBP_LOOKUP_CONTEXT;

//
// Context for the sweep routine. Passed through handle enumeration.
//
typedef struct _OBP_SWEEP_CONTEXT {
    PHANDLE_TABLE HandleTable;
    KPROCESSOR_MODE PreviousMode;
} OBP_SWEEP_CONTEXT, *POBP_SWEEP_CONTEXT;


//
//  Global data
//

POBJECT_TYPE ObpTypeObjectType;
POBJECT_TYPE ObpDirectoryObjectType;
POBJECT_TYPE ObpSymbolicLinkObjectType;
POBJECT_TYPE ObpDeviceMapObjectType;
POBJECT_DIRECTORY ObpRootDirectoryObject;
POBJECT_DIRECTORY ObpTypeDirectoryObject;

typedef union {
    WCHAR Name[sizeof(ULARGE_INTEGER)/sizeof(WCHAR)];
    ULARGE_INTEGER Alignment;
} ALIGNEDNAME;

extern const ALIGNEDNAME ObpDosDevicesShortNamePrefix;
extern const ALIGNEDNAME ObpDosDevicesShortNameRoot;
extern const UNICODE_STRING ObpDosDevicesShortName;

ERESOURCE SecurityDescriptorCacheLock;

//
//  Define date structures for the object creation information region.
//

extern GENERAL_LOOKASIDE ObpCreateInfoLookasideList;

//
//  Define data structures for the object name buffer lookaside list.
//

#define OBJECT_NAME_BUFFER_SIZE 248

extern GENERAL_LOOKASIDE ObpNameBufferLookasideList;

//
//  There is one global kernel handle table accessed via negative handle
//  and only in kernel mode
//

PHANDLE_TABLE ObpKernelHandleTable;

//
//  The following macros are used to test and manipulate special kernel
//  handles.  A kernel handle is just a regular handle with its sign
//  bit set.  But must exclude -1 and -2 values which are the current
//  process and current thread constants.
//

#define KERNEL_HANDLE_MASK ((ULONG_PTR)((LONG)0x80000000))

#define IsKernelHandle(H,M)                                \
    (((KERNEL_HANDLE_MASK & (ULONG_PTR)(H)) == KERNEL_HANDLE_MASK) && \
     ((M) == KernelMode) &&                                \
     ((H) != NtCurrentThread()) &&                         \
     ((H) != NtCurrentProcess()))

#define EncodeKernelHandle(H) (HANDLE)(KERNEL_HANDLE_MASK | (ULONG_PTR)(H))

#define DecodeKernelHandle(H) (HANDLE)(KERNEL_HANDLE_MASK ^ (ULONG_PTR)(H))

//
//  Test macro for overflow
//

#define ObpIsOverflow(A,B) ((A) > ((A) + (B)))


//
//  Internal Entry Points defined in obcreate.c and some associated macros
//

#define ObpFreeObjectCreateInformation(_ObjectCreateInfo) { \
    ObpReleaseObjectCreateInformation((_ObjectCreateInfo)); \
    ObpFreeObjectCreateInfoBuffer((_ObjectCreateInfo));     \
}

#define ObpReleaseObjectCreateInformation(_ObjectCreateInfo) {               \
    if ((_ObjectCreateInfo)->SecurityDescriptor != NULL) {                   \
        SeReleaseSecurityDescriptor((_ObjectCreateInfo)->SecurityDescriptor, \
                                    (_ObjectCreateInfo)->ProbeMode,          \
                                     TRUE);                                  \
        (_ObjectCreateInfo)->SecurityDescriptor = NULL;                      \
    }                                                                        \
}

NTSTATUS
ObpCaptureObjectCreateInformation (
    IN POBJECT_TYPE ObjectType OPTIONAL,
    IN KPROCESSOR_MODE ProbeMode,
    IN KPROCESSOR_MODE CreatorMode,
    IN POBJECT_ATTRIBUTES ObjectAttributes,
    OUT PUNICODE_STRING CapturedObjectName,
    IN POBJECT_CREATE_INFORMATION ObjectCreateInfo,
    IN LOGICAL UseLookaside
    );

NTSTATUS
ObpCaptureObjectName (
    IN KPROCESSOR_MODE ProbeMode,
    IN PUNICODE_STRING ObjectName,
    IN OUT PUNICODE_STRING CapturedObjectName,
    IN LOGICAL UseLookaside
    );

PWCHAR
ObpAllocateObjectNameBuffer (
    IN ULONG Length,
    IN LOGICAL UseLookaside,
    IN OUT PUNICODE_STRING ObjectName
    );

VOID
FASTCALL
ObpFreeObjectNameBuffer (
    IN PUNICODE_STRING ObjectName
    );

NTSTATUS
ObpAllocateObject (
    IN POBJECT_CREATE_INFORMATION ObjectCreateInfo,
    IN KPROCESSOR_MODE OwnershipMode,
    IN POBJECT_TYPE ObjectType,
    IN PUNICODE_STRING ObjectName,
    IN ULONG ObjectBodySize,
    OUT POBJECT_HEADER *ReturnedObjectHeader
    );


VOID
FASTCALL
ObpFreeObject (
    IN PVOID Object
    );


/*++

POBJECT_CREATE_INFORMATION
ObpAllocateObjectCreateInfoBuffer (
    VOID
    )

Routine Description:

    This function allocates a created information buffer.

    N.B. This function is nonpageable.

Arguments:

    None.

Return Value:

    If the allocation is successful, then the address of the allocated
    create information buffer is is returned as the function value.
    Otherwise, a value of NULL is returned.

--*/

#define ObpAllocateObjectCreateInfoBuffer()             \
    (POBJECT_CREATE_INFORMATION)ExAllocateFromPPLookasideList(LookasideCreateInfoList)


/*++

VOID
FASTCALL
ObpFreeObjectCreateInfoBuffer (
    IN POBJECT_CREATE_INFORMATION ObjectCreateInfo
    )

Routine Description:

    This function frees a create information buffer.

    N.B. This function is nonpageable.

Arguments:

    ObjectCreateInfo - Supplies a pointer to a create information buffer.

Return Value:

    None.

--*/

#define ObpFreeObjectCreateInfoBuffer(ObjectCreateInfo) \
    ExFreeToPPLookasideList(LookasideCreateInfoList, ObjectCreateInfo)

//
//  Internal Entry Points defined in oblink.c
//

NTSTATUS
ObpParseSymbolicLink (
    IN PVOID ParseObject,
    IN PVOID ObjectType,
    IN PACCESS_STATE AccessState,
    IN KPROCESSOR_MODE AccessMode,
    IN ULONG Attributes,
    IN OUT PUNICODE_STRING CompleteName,
    IN OUT PUNICODE_STRING RemainingName,
    IN OUT PVOID Context OPTIONAL,
    IN PSECURITY_QUALITY_OF_SERVICE SecurityQos OPTIONAL,
    OUT PVOID *Object
    );

VOID
ObpDeleteSymbolicLink (
    IN  PVOID   Object
    );

VOID
ObpCreateSymbolicLinkName (
    POBJECT_SYMBOLIC_LINK SymbolicLink
    );

VOID
ObpDeleteSymbolicLinkName (
    POBJECT_SYMBOLIC_LINK SymbolicLink
    );


//
//  Internal Entry Points defined in obdir.c
//

PVOID
ObpLookupDirectoryEntry (
    IN POBJECT_DIRECTORY Directory,
    IN PUNICODE_STRING Name,
    IN ULONG Attributes,
    IN BOOLEAN SearchShadow,
    OUT POBP_LOOKUP_CONTEXT LookupContext
    );


BOOLEAN
ObpInsertDirectoryEntry (
    IN POBJECT_DIRECTORY Directory,
    IN POBP_LOOKUP_CONTEXT LookupContext,
    IN POBJECT_HEADER ObjectHeader
    );


BOOLEAN
ObpDeleteDirectoryEntry (
    IN POBP_LOOKUP_CONTEXT LookupContext
    );


NTSTATUS
ObpLookupObjectName (
    IN HANDLE RootDirectoryHandle,
    IN PUNICODE_STRING ObjectName,
    IN ULONG Attributes,
    IN POBJECT_TYPE ObjectType,
    IN KPROCESSOR_MODE AccessMode,
    IN PVOID ParseContext OPTIONAL,
    IN PSECURITY_QUALITY_OF_SERVICE SecurityQos OPTIONAL,
    IN PVOID InsertObject OPTIONAL,
    IN OUT PACCESS_STATE AccessState,
    OUT POBP_LOOKUP_CONTEXT LookupContext,
    OUT PVOID *FoundObject
    );

VOID
ObpUnlockObjectDirectoryPath (
    IN POBJECT_DIRECTORY LockedDirectory
    );

PDEVICE_MAP
ObpReferenceDeviceMap(
    );

VOID
FASTCALL
ObfDereferenceDeviceMap(
    IN PDEVICE_MAP DeviceMap
    );


//
//  Internal entry points defined in obref.c
//


VOID
ObpDeleteNameCheck (
    IN PVOID Object
    );


VOID
ObpProcessRemoveObjectQueue (
    PVOID Parameter
    );

VOID
ObpRemoveObjectRoutine (
    IN  PVOID   Object,
    IN  BOOLEAN CalledOnWorkerThread
    );


//
//  Internal entry points defined in obhandle.c
//


POBJECT_HANDLE_COUNT_ENTRY
ObpInsertHandleCount (
    POBJECT_HEADER ObjectHeader
    );

NTSTATUS
ObpIncrementHandleCount (
    OB_OPEN_REASON OpenReason,
    PEPROCESS Process,
    PVOID Object,
    POBJECT_TYPE ObjectType,
    PACCESS_STATE AccessState OPTIONAL,
    KPROCESSOR_MODE AccessMode,
    ULONG Attributes
    );


VOID
ObpDecrementHandleCount (
    PEPROCESS Process,
    POBJECT_HEADER ObjectHeader,
    POBJECT_TYPE ObjectType,
    ACCESS_MASK GrantedAccess
    );

NTSTATUS
ObpCreateHandle (
    IN OB_OPEN_REASON OpenReason,
    IN PVOID Object,
    IN POBJECT_TYPE ExpectedObjectType OPTIONAL,
    IN PACCESS_STATE AccessState,
    IN ULONG ObjectPointerBias OPTIONAL,
    IN ULONG Attributes,
    IN POBP_LOOKUP_CONTEXT LookupContext,
    IN KPROCESSOR_MODE AccessMode,
    OUT PVOID *ReferencedNewObject OPTIONAL,
    OUT PHANDLE Handle
    );

NTSTATUS
ObpIncrementUnnamedHandleCount (
    PACCESS_MASK DesiredAccess,
    PEPROCESS Process,
    PVOID Object,
    POBJECT_TYPE ObjectType,
    KPROCESSOR_MODE AccessMode,
    ULONG Attributes
    );


NTSTATUS
ObpCreateUnnamedHandle (
    IN PVOID Object,
    IN ACCESS_MASK DesiredAccess,
    IN ULONG ObjectPointerBias OPTIONAL,
    IN ULONG Attributes,
    IN KPROCESSOR_MODE AccessMode,
    OUT PVOID *ReferencedNewObject OPTIONAL,
    OUT PHANDLE Handle
    );

NTSTATUS
ObpChargeQuotaForObject (
    IN POBJECT_HEADER ObjectHeader,
    IN POBJECT_TYPE ObjectType,
    OUT PBOOLEAN NewObject
    );

NTSTATUS
ObpValidateDesiredAccess (
    IN ACCESS_MASK DesiredAccess
    );


//
//  Internal entry points defined in obse.c
//

BOOLEAN
ObpCheckPseudoHandleAccess (
    IN PVOID Object,
    IN ACCESS_MASK DesiredAccess,
    OUT PNTSTATUS AccessStatus,
    IN BOOLEAN TypeMutexLocked
    );


BOOLEAN
ObpCheckTraverseAccess (
    IN PVOID DirectoryObject,
    IN ACCESS_MASK TraverseAccess,
    IN PACCESS_STATE AccessState,
    IN BOOLEAN TypeMutexLocked,
    IN KPROCESSOR_MODE PreviousMode,
    OUT PNTSTATUS AccessStatus
    );

BOOLEAN
ObpCheckObjectReference (
    IN PVOID Object,
    IN OUT PACCESS_STATE AccessState,
    IN BOOLEAN TypeMutexLocked,
    IN KPROCESSOR_MODE AccessMode,
    OUT PNTSTATUS AccessStatus
    );


//
//  Internal entry points defined in obsdata.c
//

NTSTATUS
ObpInitSecurityDescriptorCache (
    VOID
    );

ULONG
ObpHashSecurityDescriptor (
    PSECURITY_DESCRIPTOR SecurityDescriptor,
    ULONG Length
    );

ULONG
ObpHashBuffer (
    PVOID Data,
    ULONG Length
    );

PSECURITY_DESCRIPTOR_HEADER
ObpCreateCacheEntry (
    PSECURITY_DESCRIPTOR InputSecurityDescriptor,
    ULONG Length,
    ULONG FullHash,
    ULONG RefBias
    );


PSECURITY_DESCRIPTOR
ObpReferenceSecurityDescriptor (
    POBJECT_HEADER ObjectHeader
    );


PVOID
ObpDestroySecurityDescriptorHeader (
    IN PSECURITY_DESCRIPTOR_HEADER Header
    );

BOOLEAN
ObpCompareSecurityDescriptors (
    IN PSECURITY_DESCRIPTOR SD1,
    ULONG Length,
    IN PSECURITY_DESCRIPTOR SD2
    );

NTSTATUS
ObpValidateAccessMask (
    PACCESS_STATE AccessState
    );

NTSTATUS
ObpCloseHandleTableEntry (
    IN PHANDLE_TABLE ObjectTable,
    IN PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN HANDLE Handle,
    IN KPROCESSOR_MODE PreviousMode,
    IN BOOLEAN Rundown
    );

NTSTATUS
ObpCloseHandle (
    IN HANDLE Handle,
    IN KPROCESSOR_MODE PreviousMode
    );

VOID
ObpDeleteObjectType (
    IN  PVOID   Object
    );

VOID
ObpAuditObjectAccess(
    IN HANDLE Handle,
    IN PHANDLE_TABLE_ENTRY_INFO ObjectTableEntryInfo,
    IN PUNICODE_STRING ObjectTypeName,
    IN ACCESS_MASK DesiredAccess
    );

NTSTATUS
ObpQueryNameString (
    IN PVOID Object,
    OUT POBJECT_NAME_INFORMATION ObjectNameInfo,
    IN ULONG Length,
    OUT PULONG ReturnLength,
    IN KPROCESSOR_MODE Mode
    );



//
//  Inline functions
//

FORCEINLINE
BOOLEAN
ObpSafeInterlockedIncrement(
    IN OUT PLONG_PTR lpValue
    )

/*

Routine Description:

    This function increments the LONG value passed in.
    Unlike the InterlockedIncrement function, this will not increment from 0 to 1.
    It will return FALSE if it's trying to reference from 0.

Arguments:

    lpValue - The pointer to the LONG value that should be safe incremented

Return Value:

    Returns FALSE if the current value is 0 (so it cannot increment to 1). TRUE means the LONG
    value was increnemted

*/

{
    LONG_PTR PointerCount, NewPointerCount;

    //
    // If the object is being deleted then the reference count is zero. So the idea here is to reference
    // the long value but avoid the 0 -> 1 transition that would cause a double delete.
    //

    PointerCount = *(volatile *) lpValue;

    do {
        if (PointerCount == 0) {
            return FALSE;
        }
        NewPointerCount = ObpInterlockedCompareExchange (lpValue,
                                                         PointerCount+1,
                                                         PointerCount);

        //
        // If the exchange compare completed ok then we did a reference so return true.
        //

        if (NewPointerCount == PointerCount) {

            return TRUE;
        }

        //
        // We failed because somebody else got in and changed the refence count on us. Use the new value to
        // prime the exchange again.
        //

        PointerCount = NewPointerCount;
    } while (TRUE);

    return TRUE;
}

#define OBP_NAME_LOCKED ((LONG)0x80000000)

FORCEINLINE
BOOLEAN
ObpSafeInterlockedIncrementLong(
    IN OUT PLONG lpValue
    )

/*

Routine Description:

    This function increments the LONG value passed in.
    Unlike the InterlockedIncrement function, this will not increment from 0 to 1.
    It will return FALSE if it's trying to reference from 0.

Arguments:

    lpValue - The pointer to the LONG value that should be safe incremented

Return Value:

    Returns FALSE if the current value is 0 (so it cannot increment to 1). TRUE means the LONG
    value was increnemted

*/

{
    LONG PointerCount, NewPointerCount;

    //
    // If the object is being deleted then the reference count is zero. So the idea here is to reference
    // the long value but avoid the 0 -> 1 transition that would cause a double delete.
    //

    PointerCount = *(volatile *) lpValue;

    do {
        if (PointerCount == 0) {
            return FALSE;
        }
        NewPointerCount = InterlockedCompareExchange (lpValue,
                                                      PointerCount+1,
                                                      PointerCount);

        //
        // If the exchange compare completed ok then we did a reference so return true.
        //

        if (NewPointerCount == PointerCount) {

            return TRUE;
        }

        //
        // We failed because somebody else got in and changed the refence count on us. Use the new value to
        // prime the exchange again.
        //

        PointerCount = NewPointerCount;
    } while (TRUE);

    return TRUE;
}


POBJECT_HEADER_NAME_INFO
FORCEINLINE
ObpReferenceNameInfo(
    IN POBJECT_HEADER ObjectHeader
    )

/*

Routine Description:
    This function references the name information structure. This is a substitute
    for the previous global locking mechanism that used the RootDirectoryMutex to protect
    the fields inside the NAME_INFO as well.
    If the function returnes a non-NULL name info, the name buffer and Directory will not go away
    until the ObpDereferenceNameInfo call.

Arguments:

    ObjectHeader - The object header whose name should be safe-referenced

Return Value:
    Returns NULL if the object doesn't have a name information structure, or if the name info is being deleted
    Returns a pointer to the POBJECT_HEADER_NAME_INFO if it's safe to use the fields inside it.

*/

{
    POBJECT_HEADER_NAME_INFO NameInfo;
    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

    if ((NameInfo != NULL)
            &&
        ObpSafeInterlockedIncrementLong((PLONG) &NameInfo->QueryReferences )) {

        if (NameInfo->QueryReferences & OBP_NAME_LOCKED) {

            //
            //  The name is locked this means that the directory entry must be valid
            //

            ExAcquireReleasePushLockExclusive(&NameInfo->Directory->Lock);
        }

        return NameInfo;
    }

    return NULL;
}


VOID
FORCEINLINE
ObpDereferenceNameInfo(
    IN POBJECT_HEADER_NAME_INFO NameInfo
    )

/*

Routine Description:
    This function dereferences the name information structure. If the number of references
    drops to 0, the name is freed and the directory dereferenced

Arguments:

    NameInfo - The pointer to the name info structure, as returned by ObpReferenceNameInfo.
    (NULL value is allowed)

Return Value:
    None

*/

{

    if ( (NameInfo != NULL)
            &&
         (InterlockedDecrement((PLONG)&NameInfo->QueryReferences) == 0)) {

        PVOID DirObject;

        //
        //  Free the name buffer and zero out the name data fields
        //

        if (NameInfo->Name.Buffer != NULL) {

            ExFreePool( NameInfo->Name.Buffer );

            NameInfo->Name.Buffer = NULL;
            NameInfo->Name.Length = 0;
            NameInfo->Name.MaximumLength = 0;
        }

        DirObject = NameInfo->Directory;

        if (DirObject != NULL) {

            NameInfo->Directory = NULL;
            ObDereferenceObjectDeferDelete( DirObject );
        }
    }
}


VOID
FORCEINLINE
ObpLockDirectoryExclusive(
    IN POBJECT_DIRECTORY Directory,
    IN POBP_LOOKUP_CONTEXT LockContext
    )

/*

Routine Description:
    This Function locks exclusively the Directory. It is used for write access to
    the directory structure.

Arguments:

    Directory - The directory being locked

Return Value:
    None

*/

{
    LockContext->LockStateSignature = OBP_LOCK_WAITEXCLUSIVE_SIGNATURE;
    KeEnterCriticalRegion();
    ExAcquirePushLockExclusive( &Directory->Lock );
    LockContext->LockStateSignature = OBP_LOCK_OWNEDEXCLUSIVE_SIGNATURE;
}


VOID
FORCEINLINE
ObpLockDirectoryShared (
    IN POBJECT_DIRECTORY Directory,
    IN POBP_LOOKUP_CONTEXT LockContext
    )

/*

Routine Description:
    This Function locks shared the Directory. It is used to read fields inside
    the directory structure.

Arguments:

    Directory - The directory being locked

Return Value:
    None

*/

{
    LockContext->LockStateSignature = OBP_LOCK_WAITSHARED_SIGNATURE;
    KeEnterCriticalRegion();
    ExAcquirePushLockShared( &Directory->Lock );
    LockContext->LockStateSignature = OBP_LOCK_OWNEDSHARED_SIGNATURE;
}


VOID
FORCEINLINE
ObpUnlockDirectory(
    IN POBJECT_DIRECTORY Directory,
    IN POBP_LOOKUP_CONTEXT LockContext
    )

/*

Routine Description:
    This Function unlocks a Directory (previously locked exclusive or shared).

Arguments:

    Directory - The directory that needs to be unlocked

Return Value:
    None

*/

{
    ExReleasePushLock( &Directory->Lock );
    LockContext->LockStateSignature = OBP_LOCK_RELEASED_SIGNATURE;
    KeLeaveCriticalRegion();
}


VOID
FORCEINLINE
ObpInitializeLookupContext(
    IN POBP_LOOKUP_CONTEXT LookupContext
    )

/*

Routine Description:
    This Function initialize a lookup context structure.

Arguments:

    LookupContext - The LookupContext to be initialized

Return Value:
    None

*/

{
    LookupContext->DirectoryLocked = FALSE;
    LookupContext->Object = NULL;
    LookupContext->Directory = NULL;
    LookupContext->LockStateSignature = OBP_LOCK_UNUSED_SIGNATURE;
}


VOID
FORCEINLINE
ObpLockLookupContext (
    IN POBP_LOOKUP_CONTEXT LookupContext,
    IN POBJECT_DIRECTORY Directory
    )

/*

Routine Description:
    This function locks a lookup context. The directory
    is exclusively owned after this call and it's safe to access
    the directory in write mode. This function is intended to be used in
    insertion / deletion into/from the specified directory.

    The directory is unlocked at the next ObpReleaseLookupContext.

Arguments:

    LookupContext - The LookupContext to be initialized

    Directory - The directory beling locked for exclusive access.

Return Value:
    None

*/

{

    ObpLockDirectoryExclusive(Directory, LookupContext);
    LookupContext->DirectoryLocked = TRUE;
    LookupContext->Directory = Directory;
}



VOID
FORCEINLINE
ObpReleaseLookupContext (
    IN POBP_LOOKUP_CONTEXT LookupContext
    )

/*

Routine Description:
    This function undoes the references and locking changes during these calls:
    ObpLockLookupContext and ObpLookupDirectoryEntry.

    N.B. If ObpLookupDirectoryEntry is called several times in a loop, each call
    will undo the references done at the previous call. ObpReleaseLookupContext
    should be called only ones at the end.

Arguments:

    LookupContext - The LookupContext to be released

Return Value:
    None

*/

{
    //
    //  If the context was locked we need to unlock the directory
    //

    if (LookupContext->DirectoryLocked) {

        ObpUnlockDirectory( LookupContext->Directory, LookupContext );
        LookupContext->Directory = NULL;
        LookupContext->DirectoryLocked = FALSE;
    }

    //
    //  Remove the references added to the name info and object
    //

    if (LookupContext->Object) {
        POBJECT_HEADER_NAME_INFO NameInfo;

        NameInfo = OBJECT_HEADER_TO_NAME_INFO(OBJECT_TO_OBJECT_HEADER(LookupContext->Object));

        ObpDereferenceNameInfo( NameInfo );
        ObDereferenceObject(LookupContext->Object);
        LookupContext->Object = NULL;
    }
}

NTSTATUS
ObpReferenceProcessObjectByHandle (
    IN HANDLE Handle,
    IN PEPROCESS Process,
    IN PHANDLE_TABLE HandleTable,
    IN KPROCESSOR_MODE AccessMode,
    OUT PVOID *Object,
    OUT POBJECT_HANDLE_INFORMATION HandleInformation,
    OUT PACCESS_MASK AuditMask
    );

VOID
FORCEINLINE
ObpLockAllObjects (
    IN POBJECT_TYPE ObjectType
    )
{
    LONG i;

    KeEnterCriticalRegion();                                    

    for (i = 0; i < OBJECT_LOCK_COUNT; i++) {

        ExAcquireResourceExclusiveLite(&(ObjectType->ObjectLocks[i]), TRUE);
    }
}

VOID
FORCEINLINE
ObpUnlockAllObjects (
    IN POBJECT_TYPE ObjectType
    )
{
    LONG i;

    for (i = OBJECT_LOCK_COUNT - 1; i >= 0; i--) {

        ExReleaseResourceLite(&(ObjectType->ObjectLocks[i]));       
    }

    KeLeaveCriticalRegion();                                                    
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obref.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obref.c

Abstract:

    Object open API

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"

#undef ObReferenceObjectByHandle

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT,ObpInitStackTrace)
#pragma alloc_text(PAGE,ObOpenObjectByName)
#pragma alloc_text(PAGE,ObOpenObjectByPointer)
#pragma alloc_text(PAGE,ObReferenceObjectByHandle)
#pragma alloc_text(PAGE,ObpReferenceProcessObjectByHandle)
#pragma alloc_text(PAGE,ObReferenceObjectByName)
#pragma alloc_text(PAGE,ObReferenceFileObjectForWrite)
#pragma alloc_text(PAGE,ObpProcessRemoveObjectQueue)
#pragma alloc_text(PAGE,ObpRemoveObjectRoutine)
#pragma alloc_text(PAGE,ObpDeleteNameCheck)
#pragma alloc_text(PAGE,ObpAuditObjectAccess)
#pragma alloc_text(PAGE,ObIsObjectDeletionInline)
#pragma alloc_text(PAGE,ObAuditObjectAccess)
#endif

//
//
//  Stack Trace code
//
//
ULONG ObpTraceNoDeregister = 0;
WCHAR ObpTracePoolTagsBuffer[128] = { 0 };
ULONG ObpTracePoolTagsLength = sizeof(ObpTracePoolTagsBuffer);
ULONG ObpTracePoolTags[16];
BOOLEAN ObpTraceEnabled = FALSE;

#ifdef POOL_TAGGING

#define OBTRACE_OBJECTBUCKETS   401     // # of buckets in the object hash table (a prime)
#define OBTRACE_STACKS          14747   // max # of unique stack traces (a prime)
#define OBTRACE_STACKSPEROBJECT 32768   // max number of object references
#define OBTRACE_TRACEDEPTH      16      // depth of stack traces

//
//  The constants below are used by the !obtrace debugger extension
//

const ObpObjectBuckets   = OBTRACE_OBJECTBUCKETS;
const ObpMaxStacks       = OBTRACE_STACKS;
const ObpStacksPerObject = OBTRACE_STACKSPEROBJECT;
const ObpTraceDepth      = OBTRACE_TRACEDEPTH;

//
// Object reference stacktrace structure
//

typedef struct _OBJECT_REF_TRACE {
    PVOID StackTrace[OBTRACE_TRACEDEPTH];
} OBJECT_REF_TRACE, *POBJECT_REF_TRACE;


typedef struct _OBJECT_REF_STACK_INFO {
    USHORT Sequence;
    USHORT Index;
} OBJECT_REF_STACK_INFO, *POBJECT_REF_STACK_INFO;

//
// Object reference info structure
//

typedef struct _OBJECT_REF_INFO {
    POBJECT_HEADER ObjectHeader;
    PVOID NextRef;
    UCHAR ImageFileName[16];
    ULONG  NextPos;
    OBJECT_REF_STACK_INFO StackInfo[OBTRACE_STACKSPEROBJECT];
} OBJECT_REF_INFO, *POBJECT_REF_INFO;

//
// The stack hash table, and the object hash table
//

OBJECT_REF_TRACE *ObpStackTable = NULL;
POBJECT_REF_INFO *ObpObjectTable = NULL;

//
// Some statistics
//

ULONG ObpNumStackTraces;
ULONG ObpNumTracedObjects;
ULONG ObpStackSequence;

//
// Spin lock for object tracing
//

KSPIN_LOCK ObpStackTraceLock;

#define OBTRACE_HASHOBJECT(x) (((((ULONG)(ULONG_PTR)(&(x)->Body)) >> 4) & 0xfffff) % OBTRACE_OBJECTBUCKETS)

POBJECT_REF_INFO
ObpGetObjectRefInfo (
    POBJECT_HEADER ObjectHeader
    )

/*++

Routine Description:

    This routine returns a pointer to the OBJECT_REF_INFO for the
    specified object, or NULL, if it doesn't exist.

Arguments:

    ObjectHeader - Pointer to the object header

Return Value:

    The pointer to a OBJECT_REF_INFO object for the specified object.

--*/

{
    POBJECT_REF_INFO ObjectRefInfo = ObpObjectTable[OBTRACE_HASHOBJECT(ObjectHeader)];

    while (ObjectRefInfo && ObjectRefInfo->ObjectHeader != ObjectHeader) {

        ObjectRefInfo = (POBJECT_REF_INFO)ObjectRefInfo->NextRef;
    }

    return ObjectRefInfo;
}


ULONG
ObpGetTraceIndex (
    POBJECT_REF_TRACE Trace
    )

/*++

Routine Description:

    This routine returns the index of 'Trace' in the stack
    trace hash table (ObpStackTable).  If Trace does not exist
    in the table, it is added, and the new index is returned.

Arguments:

    Trace - Pointer to a stack trace to find in the table

Return Value:

    The index of Trace in ObpStackTable

--*/

{
    ULONG_PTR Value = 0;
    ULONG Index;
    PUSHORT Key;
    ULONG Hash;

    //
    // Determine the hash value for the stack trace
    //

    Key = (PUSHORT)Trace->StackTrace;
    for (Index = 0; Index < sizeof(Trace->StackTrace) / sizeof(*Key); Index += 2) {

        Value += Key[Index] ^ Key[Index + 1];
    }

    Hash = ((ULONG)Value) % OBTRACE_STACKS;

    //
    // Look up the trace at that index (linear probing)
    //

    while (ObpStackTable[Hash].StackTrace[0] != NULL &&
           RtlCompareMemory(&ObpStackTable[Hash], Trace, sizeof(OBJECT_REF_TRACE)) != sizeof(OBJECT_REF_TRACE)) {

        Hash = (Hash + 1) % OBTRACE_STACKS;
        if (Hash == ((ULONG)Value) % OBTRACE_STACKS) {

            return OBTRACE_STACKS;
        }
    }

    //
    // If the trace doesn't already exist in the table, add it.
    //

    if (ObpStackTable[Hash].StackTrace[0] == NULL) {

        RtlCopyMemory(&ObpStackTable[Hash], Trace, sizeof(OBJECT_REF_TRACE));
        ObpNumStackTraces++;
    }

    return Hash;
}


VOID
ObpInitStackTrace()

/*++

Routine Description:

    Initialize the ob ref/deref stack-tracing code.

Arguments:

Return Value:

--*/

{
    ULONG i,j;

    KeInitializeSpinLock( &ObpStackTraceLock );
    RtlZeroMemory(ObpTracePoolTags, sizeof(ObpTracePoolTags));
    ObpStackSequence = 0;
    ObpNumStackTraces = 0;
    ObpNumTracedObjects = 0;
    ObpTraceEnabled = FALSE;

    //
    // Loop through the ObpTracePoolTagsBuffer string, and convert it to
    // an array of pool tags.
    //
    // The string should be in the form "Tag1;Tag2;Tag3; ..."
    //

    for (i = 0; i < sizeof(ObpTracePoolTags) / sizeof(ULONG); i++) {
        for (j = 0; j < 4; j++) {
            ObpTracePoolTags[i] = (ObpTracePoolTags[i] << 8) | ObpTracePoolTagsBuffer[5*i+(3-j)];
        }
    }

    //
    // If object tracing was turned on via the registry key, then we
    // need to allocate memory for the tables.  If the memory allocations
    // fail, we turn off tracing by clearing the pool tag array.
    //

    if (ObpTracePoolTags[0] != 0) {

        ObpStackTable = ExAllocatePoolWithTag( NonPagedPool,
                                               OBTRACE_STACKS * sizeof(OBJECT_REF_TRACE),
                                               'TSbO' );

        if (ObpStackTable != NULL) {

            RtlZeroMemory(ObpStackTable, OBTRACE_STACKS * sizeof(OBJECT_REF_TRACE));

            ObpObjectTable = ExAllocatePoolWithTag( NonPagedPool,
                                                    OBTRACE_OBJECTBUCKETS * sizeof(POBJECT_REF_INFO),
                                                    'TSbO' );
            if (ObpObjectTable != NULL) {

                RtlZeroMemory(ObpObjectTable, OBTRACE_OBJECTBUCKETS * sizeof(POBJECT_REF_INFO));
                ObpTraceEnabled = TRUE;

            } else {

                ExFreePoolWithTag( ObpStackTable, 'TSbO' );
                ObpStackTable = NULL;
                RtlZeroMemory(ObpTracePoolTags, sizeof(ObpTracePoolTags));
            }

        } else {

            RtlZeroMemory(ObpTracePoolTags, sizeof(ObpTracePoolTags));
        }
    }
}


BOOLEAN
ObpIsObjectTraced (
    POBJECT_HEADER ObjectHeader
    )

/*++

Routine Description:

    This routine determines if an object should have its references
    and dereferences traced.

Arguments:

    ObjectHeader - The object to check

Return Value:

    TRUE, if the object should be traced, and FALSE, otherwise

--*/

{
    ULONG i;

    if (ObjectHeader != NULL) {

        //
        // Loop through the ObpTracePoolTags array, and return true if
        // the object type key matches one of them.
        //

        for (i = 0; i < sizeof(ObpTracePoolTags) / sizeof(ULONG); i++) {

            if (ObjectHeader->Type->Key == ObpTracePoolTags[i]) {

                return TRUE;
            }
        }
    }

    return FALSE;
}


VOID
ObpRegisterObject (
    POBJECT_HEADER ObjectHeader
    )

/*++

Routine Description:

    This routine is called once for each object that is created.
    It determines if the object should be traced, and if so, adds
    it to the hash table.

Arguments:

    ObjectHeader - The object to register

Return Value:

--*/

{
    KIRQL OldIrql;
    POBJECT_REF_INFO ObjectRefInfo = NULL;

    //
    // Are we tracing this object?
    //

    if (ObpIsObjectTraced( ObjectHeader )) {

        ExAcquireSpinLock( &ObpStackTraceLock, &OldIrql );

        ObjectRefInfo = ObpGetObjectRefInfo(ObjectHeader);

        if (ObjectRefInfo == NULL) {

            //
            // Allocate a new OBJECT_REF_INFO for the object
            //

            ObjectRefInfo = ExAllocatePoolWithTag( NonPagedPool,
                                                   sizeof(OBJECT_REF_INFO),
                                                   'TSbO' );

            if (ObjectRefInfo != NULL) {

                //
                // Place the object into the hash table (at the beginning of the bucket)
                //

                ObjectRefInfo->NextRef = ObpObjectTable[OBTRACE_HASHOBJECT(ObjectHeader)];
                ObpObjectTable[OBTRACE_HASHOBJECT(ObjectHeader)] = ObjectRefInfo;

            } else {

                DbgPrint( "ObpRegisterObject - ExAllocatePoolWithTag failed.\n" );
            }
        }

        if (ObjectRefInfo != NULL) {

            ObpNumTracedObjects++;

            //
            // Initialize the OBJECT_REF_INFO
            //

            ObjectRefInfo->ObjectHeader = ObjectHeader;
            RtlCopyMemory( ObjectRefInfo->ImageFileName,
                           PsGetCurrentProcess()->ImageFileName,
                           sizeof(ObjectRefInfo->ImageFileName) );
            ObjectRefInfo->NextPos = 0;
            RtlZeroMemory( ObjectRefInfo->StackInfo,
                           sizeof(ObjectRefInfo->StackInfo) );
        }

        ExReleaseSpinLock( &ObpStackTraceLock, OldIrql );
    }
}


VOID
ObpDeregisterObject (
    POBJECT_HEADER ObjectHeader
    )

/*++

Routine Description:

    This routine is called once for each object that is deleted.
    It determines if the object is traced, and if so, deletes
    it from the hash table.

Arguments:

    ObjectHeader - The object to deregister

Return Value:

--*/

{
    KIRQL OldIrql;
    POBJECT_REF_INFO ObjectRefInfo = NULL;

    //
    // Are we tracing this object?
    //

    if (ObpIsObjectTraced( ObjectHeader )) {

        ExAcquireSpinLock( &ObpStackTraceLock, &OldIrql );

        ObjectRefInfo = ObpObjectTable[OBTRACE_HASHOBJECT(ObjectHeader)];

        if (ObjectRefInfo != NULL) {

            //
            // Remove the entry from the list
            //

            if (ObjectRefInfo->ObjectHeader == ObjectHeader) {

                ObpObjectTable[OBTRACE_HASHOBJECT(ObjectHeader)] = ObjectRefInfo->NextRef;

            } else {

                POBJECT_REF_INFO PrevObjectRefInfo;
                do {
                    PrevObjectRefInfo = ObjectRefInfo;
                    ObjectRefInfo = ObjectRefInfo->NextRef;
                } while (ObjectRefInfo && (ObjectRefInfo->ObjectHeader != ObjectHeader));

                if (ObjectRefInfo && (ObjectRefInfo->ObjectHeader == ObjectHeader)) {

                    PrevObjectRefInfo->NextRef = ObjectRefInfo->NextRef;
                }
            }
        }

        //
        // Free the object we just removed from the list
        //

        if (ObjectRefInfo != NULL) {

            ExFreePoolWithTag( ObjectRefInfo, 'TSbO' );
        }

        ExReleaseSpinLock( &ObpStackTraceLock, OldIrql );
    }
}


VOID
ObpPushStackInfo (
    POBJECT_HEADER ObjectHeader,
    BOOLEAN IsRef
    )

/*++

Routine Description:

    This routine is called each time an object is referenced or
    dereferenced.  It determines if the object is traced, and if
    so, adds the necessary trace to the object reference info.

Arguments:

    ObjectHeader - The object to trace.
    IsRef - TRUE if this is a ref, FALSE if a deref

Return Value:

--*/

{
    KIRQL OldIrql;
    POBJECT_REF_INFO ObjectInfo;

    //
    // Are we tracing this object?
    //

    if (ObpIsObjectTraced( ObjectHeader )) {

        ExAcquireSpinLock( &ObpStackTraceLock, &OldIrql );

        ObjectInfo = ObpGetObjectRefInfo( ObjectHeader );

        if (ObjectInfo) {

            OBJECT_REF_TRACE Stack = { 0 };
            ULONG StackIndex;
            ULONG CapturedTraces;

            //
            // Capture the stack trace
            //

            CapturedTraces = RtlCaptureStackBackTrace( 1, OBTRACE_TRACEDEPTH, Stack.StackTrace, &StackIndex );

            if (CapturedTraces >= 1) {

                //
                // Get the table index for the trace
                //

                StackIndex = ObpGetTraceIndex( &Stack );

                if (StackIndex < OBTRACE_STACKS) {

                    //
                    // Add new reference info to the object
                    //

                    if (ObjectInfo->NextPos < OBTRACE_STACKSPEROBJECT) {

                        ObjectInfo->StackInfo[ObjectInfo->NextPos].Index = (USHORT)StackIndex | (IsRef ? 0x8000 : 0);
                        ObpStackSequence++;
                        ObjectInfo->StackInfo[ObjectInfo->NextPos].Sequence = (USHORT)ObpStackSequence;
                        ObjectInfo->NextPos++;
                    }

                } else {
                    DbgPrint( "ObpPushStackInfo -- ObpStackTable overflow!\n" );
                }
            }
        }

        ExReleaseSpinLock( &ObpStackTraceLock, OldIrql );
    }
}

#endif //POOL_TAGGING
//
//
//  End Stack trace code
//

typedef struct _OB_TEMP_BUFFER {

    ACCESS_STATE LocalAccessState;
    OBJECT_CREATE_INFORMATION ObjectCreateInfo;
    OBP_LOOKUP_CONTEXT LookupContext;
    AUX_ACCESS_DATA AuxData;

} OB_TEMP_BUFFER,  *POB_TEMP_BUFFER;


NTSTATUS
ObOpenObjectByName (
    IN POBJECT_ATTRIBUTES ObjectAttributes,
    IN POBJECT_TYPE ObjectType OPTIONAL,
    IN KPROCESSOR_MODE AccessMode,
    IN OUT PACCESS_STATE AccessState OPTIONAL,
    IN ACCESS_MASK DesiredAccess OPTIONAL,
    IN OUT PVOID ParseContext OPTIONAL,
    OUT PHANDLE Handle
    )

/*++

Routine Description:


    This function opens an object with full access validation and auditing.
    Soon after entering we capture the SubjectContext for the caller. This
    context must remain captured until auditing is complete, and passed to
    any routine that may have to do access checking or auditing.

Arguments:

    ObjectAttributes - Supplies a pointer to the object attributes.

    ObjectType - Supplies an optional pointer to the object type descriptor.

    AccessMode - Supplies the processor mode of the access.

    AccessState - Supplies an optional pointer to the current access status
        describing already granted access types, the privileges used to get
        them, and any access types yet to be granted.

    DesiredAcess - Supplies the desired access to the object.

    ParseContext - Supplies an optional pointer to parse context.

    Handle - Supplies a pointer to a variable that receives the handle value.

Return Value:

    If the object is successfully opened, then a handle for the object is
    created and a success status is returned. Otherwise, an error status is
    returned.

--*/

{
    NTSTATUS Status;
    NTSTATUS HandleStatus;
    PVOID ExistingObject;
    HANDLE NewHandle;
    OB_OPEN_REASON OpenReason;
    POBJECT_HEADER ObjectHeader;
    UNICODE_STRING CapturedObjectName;
    PGENERIC_MAPPING GenericMapping;
    
    PAGED_CODE();

    ObpValidateIrql("ObOpenObjectByName");

    //
    //  If the object attributes are not specified, then return an error.
    //

    *Handle = NULL;

    if (!ARGUMENT_PRESENT(ObjectAttributes)) {

        Status = STATUS_INVALID_PARAMETER;

    } else {

        POB_TEMP_BUFFER TempBuffer;

        TempBuffer = ExAllocatePoolWithTag( NonPagedPool,
                                            sizeof(OB_TEMP_BUFFER),
                                            'tSbO'
                                          );

        if (TempBuffer == NULL) {

            return STATUS_INSUFFICIENT_RESOURCES;
        }

        //
        //  Capture the object creation information.
        //

        Status = ObpCaptureObjectCreateInformation( ObjectType,
                                                    AccessMode,
                                                    AccessMode,
                                                    ObjectAttributes,
                                                    &CapturedObjectName,
                                                    &TempBuffer->ObjectCreateInfo,
                                                    TRUE );

        //
        //  If the object creation information is successfully captured,
        //  then generate the access state.
        //

        if (NT_SUCCESS(Status)) {

            if (!ARGUMENT_PRESENT(AccessState)) {

                //
                //  If an object type descriptor is specified, then use
                //  associated generic mapping. Otherwise, use no generic
                //  mapping.
                //

                GenericMapping = NULL;

                if (ARGUMENT_PRESENT(ObjectType)) {

                    GenericMapping = &ObjectType->TypeInfo.GenericMapping;
                }

                AccessState = &TempBuffer->LocalAccessState;

                Status = SeCreateAccessState( &TempBuffer->LocalAccessState,
                                              &TempBuffer->AuxData,
                                              DesiredAccess,
                                              GenericMapping );

                if (!NT_SUCCESS(Status)) {

                    goto FreeCreateInfo;
                }
            }

            //
            //  If there is a security descriptor specified in the object
            //  attributes, then capture it in the access state.
            //

            if (TempBuffer->ObjectCreateInfo.SecurityDescriptor != NULL) {

                AccessState->SecurityDescriptor = TempBuffer->ObjectCreateInfo.SecurityDescriptor;
            }

            //
            //  Validate the access state.
            //

            Status = ObpValidateAccessMask(AccessState);

            //
            //  If the access state is valid, then lookup the object by
            //  name.
            //

            if (NT_SUCCESS(Status)) {

                Status = ObpLookupObjectName( TempBuffer->ObjectCreateInfo.RootDirectory,
                                              &CapturedObjectName,
                                              TempBuffer->ObjectCreateInfo.Attributes,
                                              ObjectType,
                                              AccessMode,
                                              ParseContext,
                                              TempBuffer->ObjectCreateInfo.SecurityQos,
                                              NULL,
                                              AccessState,
                                              &TempBuffer->LookupContext,
                                              &ExistingObject );

                //
                //  If the object was successfully looked up, then attempt
                //  to create or open a handle.
                //

                if (NT_SUCCESS(Status)) {

                    ObjectHeader = OBJECT_TO_OBJECT_HEADER(ExistingObject);

                    //
                    //  If the object is being created, then the operation
                    //  must be a open-if operation. Otherwise, a handle to
                    //  an object is being opened.
                    //

                    if (ObjectHeader->Flags & OB_FLAG_NEW_OBJECT) {

                        OpenReason = ObCreateHandle;

                        if (ObjectHeader->ObjectCreateInfo != NULL) {

                            ObpFreeObjectCreateInformation(ObjectHeader->ObjectCreateInfo);
                            ObjectHeader->ObjectCreateInfo = NULL;
                        }

                    } else {

                        OpenReason = ObOpenHandle;
                    }

                    //
                    //  If any of the object attributes are invalid, then
                    //  return an error status.
                    //

                    if (ObjectHeader->Type->TypeInfo.InvalidAttributes & TempBuffer->ObjectCreateInfo.Attributes) {

                        Status = STATUS_INVALID_PARAMETER;

                        ObpReleaseLookupContext( &TempBuffer->LookupContext );

                    } else {

                        //
                        //  The status returned by the object lookup routine
                        //  must be returned if the creation of a handle is
                        //  successful. Otherwise, the handle creation status
                        //  is returned.
                        //

                        HandleStatus = ObpCreateHandle( OpenReason,
                                                        ExistingObject,
                                                        ObjectType,
                                                        AccessState,
                                                        0,
                                                        TempBuffer->ObjectCreateInfo.Attributes,
                                                        &TempBuffer->LookupContext,
                                                        AccessMode,
                                                        (PVOID *)NULL,
                                                        &NewHandle );

                        if (!NT_SUCCESS(HandleStatus)) {

                            ObDereferenceObject(ExistingObject);

                            Status = HandleStatus;

                        } else {

                            *Handle = NewHandle;
                        }
                    }

                } else {

                    ObpReleaseLookupContext( &TempBuffer->LookupContext );
                }
            }

            //
            //  If the access state was generated, then delete the access
            //  state.
            //

            if (AccessState == &TempBuffer->LocalAccessState) {

                SeDeleteAccessState(AccessState);
            }

            //
            //  Free the create information.
            //

        FreeCreateInfo:

            ObpReleaseObjectCreateInformation(&TempBuffer->ObjectCreateInfo);

            if (CapturedObjectName.Buffer != NULL) {

                ObpFreeObjectNameBuffer(&CapturedObjectName);
            }
        }

        ExFreePool(TempBuffer);
    }

    return Status;
}


NTSTATUS
ObOpenObjectByPointer (
    IN PVOID Object,
    IN ULONG HandleAttributes,
    IN PACCESS_STATE PassedAccessState OPTIONAL,
    IN ACCESS_MASK DesiredAccess,
    IN POBJECT_TYPE ObjectType,
    IN KPROCESSOR_MODE AccessMode,
    OUT PHANDLE Handle
    )

/*++

Routine Description:

    This routine opens an object referenced by a pointer.

Arguments:

    Object - A pointer to the object being opened.

    HandleAttributes - The desired attributes for the handle, such
        as OBJ_INHERIT, OBJ_PERMANENT, OBJ_EXCLUSIVE, OBJ_CASE_INSENSITIVE,
        OBJ_OPENIF, and OBJ_OPENLINK

    PassedAccessState - Supplies an optional pointer to the current access
        status describing already granted access types, the privileges used
        to get them, and any access types yet to be granted.

    DesiredAcess - Supplies the desired access to the object.

    ObjectType - Supplies the type of the object being opened

    AccessMode - Supplies the processor mode of the access.

    Handle - Supplies a pointer to a variable that receives the handle value.

Return Value:

    An appropriate NTSTATUS value

--*/

{
    NTSTATUS Status;
    HANDLE NewHandle = (HANDLE)-1;
    POBJECT_HEADER ObjectHeader;
    ACCESS_STATE LocalAccessState;
    PACCESS_STATE AccessState = NULL;
    AUX_ACCESS_DATA AuxData;

    PAGED_CODE();

    ObpValidateIrql( "ObOpenObjectByPointer" );

    //
    //  First increment the pointer count for the object.  This routine
    //  also checks the object types
    //

    Status = ObReferenceObjectByPointer( Object,
                                         0,
                                         ObjectType,
                                         AccessMode );

    if (NT_SUCCESS( Status )) {

        //
        //  Get the object header for the input object body
        //

        ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

        //
        //  If the caller did not pass in an access state then
        //  we will create a new one based on the desired access
        //  and the object types generic mapping
        //

        if (!ARGUMENT_PRESENT( PassedAccessState )) {

            Status = SeCreateAccessState( &LocalAccessState,
                                          &AuxData,
                                          DesiredAccess,
                                          &ObjectHeader->Type->TypeInfo.GenericMapping );

            if (!NT_SUCCESS( Status )) {

                ObDereferenceObject( Object );

                return(Status);
            }

            AccessState = &LocalAccessState;

        //
        //  Otherwise the caller did specify an access state so
        //  we use the one passed in.
        //

        } else {

            AccessState = PassedAccessState;
        }

        //
        //  Make sure the caller is asking for handle attributes that are
        //  valid for the given object type
        //

        if (ObjectHeader->Type->TypeInfo.InvalidAttributes & HandleAttributes) {

            if (AccessState == &LocalAccessState) {

                SeDeleteAccessState( AccessState );
            }

            ObDereferenceObject( Object );

            return( STATUS_INVALID_PARAMETER );
        }

        //
        //  We've referenced the object and have an access state to give
        //  the new handle so now create a new handle for the object.
        //

        Status = ObpCreateHandle( ObOpenHandle,
                                  Object,
                                  ObjectType,
                                  AccessState,
                                  0,
                                  HandleAttributes,
                                  NULL,
                                  AccessMode,
                                  (PVOID *)NULL,
                                  &NewHandle );

        if (!NT_SUCCESS( Status )) {

            ObDereferenceObject( Object );
        }
    }

    //
    //  If we successfully opened by object and created a new handle
    //  then set the output variable correctly
    //

    if (NT_SUCCESS( Status )) {

        *Handle = NewHandle;

    } else {

        *Handle = NULL;
    }

    //
    //  Check if we used our own access state and now need to cleanup
    //

    if (AccessState == &LocalAccessState) {

        SeDeleteAccessState( AccessState );
    }

    //
    //  And return to our caller
    //

    return( Status );
}


NTSTATUS
ObReferenceObjectByHandle (
    IN HANDLE Handle,
    IN ACCESS_MASK DesiredAccess,
    IN POBJECT_TYPE ObjectType OPTIONAL,
    IN KPROCESSOR_MODE AccessMode,
    OUT PVOID *Object,
    OUT POBJECT_HANDLE_INFORMATION HandleInformation OPTIONAL
    )

/*++

Routine Description:

    Given a handle to an object this routine returns a pointer
    to the body of the object with proper ref counts

Arguments:

    Handle - Supplies a handle to the object being referenced.  It can
        also be the result of NtCurrentProcess or NtCurrentThread

    DesiredAccess - Supplies the access being requested by the caller

    ObjectType - Optionally supplies the type of the object we
        are expecting

    AccessMode - Supplies the processor mode of the access

    Object - Receives a pointer to the object body if the operation
        is successful

    HandleInformation - Optionally receives information regarding the
        input handle.

Return Value:

    An appropriate NTSTATUS value

--*/

{
    ACCESS_MASK GrantedAccess;
    PHANDLE_TABLE HandleTable;
    POBJECT_HEADER ObjectHeader;
    PHANDLE_TABLE_ENTRY ObjectTableEntry;
    PEPROCESS Process;
    NTSTATUS Status;
    PETHREAD Thread;

    ObpValidateIrql("ObReferenceObjectByHandle");

    Thread = PsGetCurrentThread ();
    *Object = NULL;

    //
    // Check is this handle is a kernel handle or one of the two builtin pseudo handles
    //
    if ((LONG)(ULONG_PTR) Handle < 0) {
        //
        //  If the handle is equal to the current process handle and the object
        //  type is NULL or type process, then attempt to translate a handle to
        //  the current process. Otherwise, check if the handle is the current
        //  thread handle.
        //

        if (Handle == NtCurrentProcess()) {

            if ((ObjectType == PsProcessType) || (ObjectType == NULL)) {

                Process = PsGetCurrentProcessByThread(Thread);
                GrantedAccess = Process->GrantedAccess;

                if ((SeComputeDeniedAccesses(GrantedAccess, DesiredAccess) == 0) ||
                    (AccessMode == KernelMode)) {

                    ObjectHeader = OBJECT_TO_OBJECT_HEADER(Process);

                    if (ARGUMENT_PRESENT(HandleInformation)) {

                        HandleInformation->GrantedAccess = GrantedAccess;
                        HandleInformation->HandleAttributes = 0;
                    }

                    ObpIncrPointerCount(ObjectHeader);
                    *Object = Process;

                    ASSERT( *Object != NULL );

                    Status = STATUS_SUCCESS;

                } else {

                    Status = STATUS_ACCESS_DENIED;
                }

            } else {

                Status = STATUS_OBJECT_TYPE_MISMATCH;
            }

            return Status;

        //
        //  If the handle is equal to the current thread handle and the object
        //  type is NULL or type thread, then attempt to translate a handle to
        //  the current thread. Otherwise, the we'll try and translate the
        //  handle
        //

        } else if (Handle == NtCurrentThread()) {

            if ((ObjectType == PsThreadType) || (ObjectType == NULL)) {

                GrantedAccess = Thread->GrantedAccess;

                if ((SeComputeDeniedAccesses(GrantedAccess, DesiredAccess) == 0) ||
                    (AccessMode == KernelMode)) {

                    ObjectHeader = OBJECT_TO_OBJECT_HEADER(Thread);

                    if (ARGUMENT_PRESENT(HandleInformation)) {

                        HandleInformation->GrantedAccess = GrantedAccess;
                        HandleInformation->HandleAttributes = 0;
                    }

                    ObpIncrPointerCount(ObjectHeader);
                    *Object = Thread;

                    ASSERT( *Object != NULL );

                    Status = STATUS_SUCCESS;

                } else {

                    Status = STATUS_ACCESS_DENIED;
                }

            } else {

                Status = STATUS_OBJECT_TYPE_MISMATCH;
            }

            return Status;

        } else if (AccessMode == KernelMode) {
            //
            //  Make the handle look like a regular handle
            //

            Handle = DecodeKernelHandle( Handle );

            //
            //  The global kernel handle table
            //

            HandleTable = ObpKernelHandleTable;
        } else {
            //
            // The previous mode was user for this kernel handle value. Reject it here.
            //

            return STATUS_INVALID_HANDLE;
        }

    } else {
        HandleTable = PsGetCurrentProcessByThread(Thread)->ObjectTable;
    }

    ASSERT(HandleTable != NULL);

    //
    // Protect this thread from being suspended while we hold the handle table entry lock
    //

    KeEnterCriticalRegionThread(&Thread->Tcb);

    //
    //  Translate the specified handle to an object table index.
    //

    ObjectTableEntry = ExMapHandleToPointerEx ( HandleTable, Handle, AccessMode );

    //
    //  Make sure the object table entry really does exist
    //

    if (ObjectTableEntry != NULL) {

        ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

        if ((ObjectHeader->Type == ObjectType) || (ObjectType == NULL)) {

#if i386 
            if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

                GrantedAccess = ObpTranslateGrantedAccessIndex( ObjectTableEntry->GrantedAccessIndex );

            } else {

                GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);
            }
#else
            GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);

#endif // i386 

            if ((SeComputeDeniedAccesses(GrantedAccess, DesiredAccess) == 0) ||
                (AccessMode == KernelMode)) {

                PHANDLE_TABLE_ENTRY_INFO ObjectInfo;

                ObjectInfo = ExGetHandleInfo(HandleTable, Handle, TRUE);

                //
                //  Access to the object is allowed. Return the handle
                //  information is requested, increment the object
                //  pointer count, unlock the handle table and return
                //  a success status.
                //
                //  Note that this is the only successful return path
                //  out of this routine if the user did not specify
                //  the current process or current thread in the input
                //  handle.
                //

                if (ARGUMENT_PRESENT(HandleInformation)) {

                    HandleInformation->GrantedAccess = GrantedAccess;
                    HandleInformation->HandleAttributes = ObpGetHandleAttributes(ObjectTableEntry);
                }

                //
                //  If this object was audited when it was opened, it may
                //  be necessary to generate an audit now.  Check the audit
                //  mask that was saved when the handle was created.
                //
                //  It is safe to do this check in a non-atomic fashion,
                //  because bits will never be added to this mask once it is
                //  created.
                //

                if ( (ObjectTableEntry->ObAttributes & OBJ_AUDIT_OBJECT_CLOSE) &&
                     (ObjectInfo != NULL) &&
                     (ObjectInfo->AuditMask != 0) &&
                     (DesiredAccess != 0) &&
                     (AccessMode != KernelMode)) {

                      
                      ObpAuditObjectAccess( Handle, ObjectInfo, &ObjectHeader->Type->Name, DesiredAccess );
                }

                ObpIncrPointerCount(ObjectHeader);

                ExUnlockHandleTableEntry( HandleTable, ObjectTableEntry );

                KeLeaveCriticalRegionThread(&Thread->Tcb);

                *Object = &ObjectHeader->Body;

                ASSERT( *Object != NULL );

                return STATUS_SUCCESS;

            } else {

                Status = STATUS_ACCESS_DENIED;
            }

        } else {

            Status = STATUS_OBJECT_TYPE_MISMATCH;
        }

        ExUnlockHandleTableEntry( HandleTable, ObjectTableEntry );

    } else {

        Status = STATUS_INVALID_HANDLE;
    }

    KeLeaveCriticalRegionThread(&Thread->Tcb);


    return Status;
}


NTSTATUS
ObpReferenceProcessObjectByHandle (
    IN HANDLE Handle,
    IN PEPROCESS Process,
    IN PHANDLE_TABLE HandleTable,
    IN KPROCESSOR_MODE AccessMode,
    OUT PVOID *Object,
    OUT POBJECT_HANDLE_INFORMATION HandleInformation,
    OUT PACCESS_MASK AuditMask
    )

/*++

Routine Description:

    Given a handle to an object a process and its handle table
    this routine returns a pointer to the body of the object with
    proper ref counts

Arguments:

    Handle - Supplies a handle to the object being referenced.  It can
        also be the result of NtCurrentProcess or NtCurrentThread

    Process - Process that the handle should be referenced from.

    HandleTable - Handle table of target process

    AccessMode - Supplies the processor mode of the access

    Object - Receives a pointer to the object body if the operation
        is successful

    HandleInformation - receives information regarding the
        input handle.

    AuditMask - Pointer to any audit mask associated with the handle.

Return Value:

    An appropriate NTSTATUS value

--*/

{
    ACCESS_MASK GrantedAccess;
    POBJECT_HEADER ObjectHeader;
    PHANDLE_TABLE_ENTRY ObjectTableEntry;
    NTSTATUS Status;
    PETHREAD Thread;
    PHANDLE_TABLE_ENTRY_INFO ObjectInfo;

    ObpValidateIrql("ObReferenceObjectByHandle");

    Thread = PsGetCurrentThread ();
    *Object = NULL;

    //
    // Check is this handle is a kernel handle or one of the two builtin pseudo handles
    //
    if ((LONG)(ULONG_PTR) Handle < 0) {
        //
        //  If the handle is equal to the current process handle and the object
        //  type is NULL or type process, then attempt to translate a handle to
        //  the current process. Otherwise, check if the handle is the current
        //  thread handle.
        //

        if (Handle == NtCurrentProcess()) {

            GrantedAccess = Process->GrantedAccess;

            ObjectHeader = OBJECT_TO_OBJECT_HEADER(Process);

            HandleInformation->GrantedAccess = GrantedAccess;
            HandleInformation->HandleAttributes = 0;

            *AuditMask = 0;

            ObpIncrPointerCount(ObjectHeader);
            *Object = Process;

            ASSERT( *Object != NULL );

            Status = STATUS_SUCCESS;

            return Status;

        //
        //  If the handle is equal to the current thread handle and the object
        //  type is NULL or type thread, then attempt to translate a handle to
        //  the current thread. Otherwise, the we'll try and translate the
        //  handle
        //

        } else if (Handle == NtCurrentThread()) {

            GrantedAccess = Thread->GrantedAccess;

            ObjectHeader = OBJECT_TO_OBJECT_HEADER(Thread);

            HandleInformation->GrantedAccess = GrantedAccess;
            HandleInformation->HandleAttributes = 0;

            *AuditMask = 0;

            ObpIncrPointerCount(ObjectHeader);
            *Object = Thread;

            ASSERT( *Object != NULL );

            Status = STATUS_SUCCESS;

            return Status;

        } else if (AccessMode == KernelMode) {
            //
            //  Make the handle look like a regular handle
            //

            Handle = DecodeKernelHandle( Handle );

            //
            //  The global kernel handle table
            //

            HandleTable = ObpKernelHandleTable;
        } else {
            //
            // The previous mode was user for this kernel handle value. Reject it here.
            //

            return STATUS_INVALID_HANDLE;
        }

    }

    ASSERT(HandleTable != NULL);

    //
    // Protect this thread from being suspended while we hold the handle table entry lock
    //

    KeEnterCriticalRegionThread(&Thread->Tcb);

    //
    //  Translate the specified handle to an object table index.
    //

    ObjectTableEntry = ExMapHandleToPointer ( HandleTable, Handle );

    //
    //  Make sure the object table entry really does exist
    //

    if (ObjectTableEntry != NULL) {

        ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

#if i386 
        if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

            GrantedAccess = ObpTranslateGrantedAccessIndex( ObjectTableEntry->GrantedAccessIndex );

        } else {

            GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);
        }
#else
        GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);

#endif // i386 


        ObjectInfo = ExGetHandleInfo(HandleTable, Handle, TRUE);

        //
        //  Return the handle information, increment the object
        //  pointer count, unlock the handle table and return
        //  a success status.
        //
        //  Note that this is the only successful return path
        //  out of this routine if the user did not specify
        //  the current process or current thread in the input
        //  handle.
        //

        HandleInformation->GrantedAccess = GrantedAccess;
        HandleInformation->HandleAttributes = ObpGetHandleAttributes(ObjectTableEntry);

        //
        //  Return handle audit information to the caller
        //
        if (ObjectInfo != NULL) {
            *AuditMask = ObjectInfo->AuditMask;
        } else {
            *AuditMask = 0;
        }

        ObpIncrPointerCount(ObjectHeader);

        ExUnlockHandleTableEntry( HandleTable, ObjectTableEntry );

        KeLeaveCriticalRegionThread(&Thread->Tcb);

        *Object = &ObjectHeader->Body;

        ASSERT( *Object != NULL );

        return STATUS_SUCCESS;


    } else {

        Status = STATUS_INVALID_HANDLE;
    }

    KeLeaveCriticalRegionThread(&Thread->Tcb);


    return Status;
}



NTSTATUS
ObReferenceFileObjectForWrite(
    IN HANDLE Handle,
    IN KPROCESSOR_MODE AccessMode,
    OUT PVOID *FileObject,
    OUT POBJECT_HANDLE_INFORMATION HandleInformation
    )

/*++

Routine Description:

    Given a handle to a file object this routine returns a pointer
    to the body of the object with proper ref counts and auditing.  This
    routine is meant to solve a very particular handle reference issue with
    file object access auditing.  Do not call this unless you understand exactly
    what you are doing.

Arguments:

    Handle - Supplies a handle to the IoFileObjectType being referenced.

    AccessMode - Supplies the processor mode of the access

    FileObject - Receives a pointer to the object body if the operation
        is successful

    HandleInformation - receives information regarding the input handle.

Return Value:

    An appropriate NTSTATUS value

--*/

{
    ACCESS_MASK GrantedAccess;
    ACCESS_MASK DesiredAccess;
    PHANDLE_TABLE HandleTable;
    POBJECT_HEADER ObjectHeader;
    PHANDLE_TABLE_ENTRY ObjectTableEntry;
    NTSTATUS Status;
    PETHREAD Thread;
    PHANDLE_TABLE_ENTRY_INFO ObjectInfo;

    ObpValidateIrql("ObReferenceFileObjectForWrite");

    Thread = PsGetCurrentThread ();

    //
    // Check is this handle is a kernel handle
    //

    if ((LONG)(ULONG_PTR) Handle < 0) {
        
        if ((AccessMode == KernelMode) && (Handle != NtCurrentProcess()) && (Handle != NtCurrentThread())) {
            
            //
            //  Make the handle look like a regular handle
            //

            Handle = DecodeKernelHandle( Handle );

            //
            //  The global kernel handle table
            //

            HandleTable = ObpKernelHandleTable;
        } else {
            //
            // The previous mode was user for this kernel handle value, or it was a builtin handle. Reject it here.
            //

            return STATUS_INVALID_HANDLE;
        } 
    } else {
        HandleTable = PsGetCurrentProcessByThread(Thread)->ObjectTable;
    }

    ASSERT(HandleTable != NULL);

    //
    // Protect this thread from being suspended while we hold the handle table entry lock
    //

    KeEnterCriticalRegionThread(&Thread->Tcb);

    //
    //  Translate the specified handle to an object table index.
    //

    ObjectTableEntry = ExMapHandleToPointerEx ( HandleTable, Handle, AccessMode );

    //
    //  Make sure the object table entry really does exist
    //

    if (ObjectTableEntry != NULL) {

        ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

        if (NT_SUCCESS(IoComputeDesiredAccessFileObject((PFILE_OBJECT)&ObjectHeader->Body, (PNTSTATUS)&DesiredAccess))) {

#if i386
            if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

                GrantedAccess = ObpTranslateGrantedAccessIndex( ObjectTableEntry->GrantedAccessIndex );

            } else {

                GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);
            }
#else
            GrantedAccess = ObpDecodeGrantedAccess(ObjectTableEntry->GrantedAccess);

#endif // i386

            ObjectInfo = ExGetHandleInfo(HandleTable, Handle, TRUE);

            //
            //  Access to the object is allowed. Return the handle
            //  information, increment the object pointer count,
            //  compute correct access, audit, unlock the handle
            //  table and return a success status.
            //
            //  Note that this is the only successful return path
            //  out of this routine.
            //

            HandleInformation->GrantedAccess = GrantedAccess;
            HandleInformation->HandleAttributes = ObpGetHandleAttributes(ObjectTableEntry);

            //
            // Check to ensure that the caller has either WRITE_DATA or APPEND_DATA
            // access to the file.  If not, cleanup and return an access denied
            // error status value.  Note that if this is a pipe then the APPEND_DATA
            // access check may not be made since this access code is overlaid with
            // CREATE_PIPE_INSTANCE access.
            //

            if (SeComputeGrantedAccesses( GrantedAccess, DesiredAccess )) {

                //
                //  If this object was audited when it was opened, it may
                //  be necessary to generate an audit now.  Check the audit
                //  mask that was saved when the handle was created.
                //
                //  It is safe to do this check in a non-atomic fashion,
                //  because bits will never be added to this mask once it is
                //  created.
                //

                if ( (ObjectTableEntry->ObAttributes & OBJ_AUDIT_OBJECT_CLOSE) &&
                     (ObjectInfo != NULL) &&
                     (ObjectInfo->AuditMask != 0) &&
                     (DesiredAccess != 0) &&
                     (AccessMode != KernelMode)) {

                      ObpAuditObjectAccess( Handle, ObjectInfo, &ObjectHeader->Type->Name, DesiredAccess );
                }

                ObpIncrPointerCount(ObjectHeader);
                ExUnlockHandleTableEntry( HandleTable, ObjectTableEntry );
                KeLeaveCriticalRegionThread(&Thread->Tcb);
            
                *FileObject = &ObjectHeader->Body;
                
                ASSERT( *FileObject != NULL );

                return STATUS_SUCCESS;
            
            } else {

                Status = STATUS_ACCESS_DENIED;
            }

        } else {

            Status = STATUS_OBJECT_TYPE_MISMATCH;
        }

        ExUnlockHandleTableEntry( HandleTable, ObjectTableEntry );

    } else {

        Status = STATUS_INVALID_HANDLE;
    }

    KeLeaveCriticalRegionThread(&Thread->Tcb);

    //
    //  No handle translation is possible. Set the object address to NULL
    //  and return an error status.
    //

    *FileObject = NULL;

    return Status;
}


VOID
ObAuditObjectAccess(
    IN HANDLE Handle,
    IN POBJECT_HANDLE_INFORMATION HandleInformation OPTIONAL,
    IN KPROCESSOR_MODE AccessMode,
    IN ACCESS_MASK DesiredAccess
    )

/*++

Routine Description:

    This routine will determine if it is necessary to audit the operation being
    performed on the passed handle.  If so, it will clear the bits in the handle
    and generate the appropriate audit before returning.

    The bits in the handle's audit mask are cleared in an atomic way so that
    multiple threads coming through this code do not generate more than one
    audit for the same operation.

Arguments:

    Handle - Supplies the handle being accessed.

    AccessMode - The mode (kernel or user) that originated the handle.

    DesiredAccess - Supplies the access mask describing how the handle is being used
        in this operation.

Return Value:

    None.

--*/

{
    PHANDLE_TABLE HandleTable;
    PHANDLE_TABLE_ENTRY ObjectTableEntry;
    POBJECT_HEADER ObjectHeader;
    PKTHREAD CurrentThread;

    //
    // Exit fast if we have nothing to do.
    //

    if (ARGUMENT_PRESENT(HandleInformation)) {
        if (!(HandleInformation->HandleAttributes & OBJ_AUDIT_OBJECT_CLOSE)) {
            return;
        }
    }

    //
    // Do not currently support this on kernel mode
    // handles.
    //

    if (AccessMode == KernelMode) {
        return;
    }

    HandleTable = ObpGetObjectTable();

    ASSERT(HandleTable != NULL);

    //
    //  Translate the specified handle to an object table index.
    //

    CurrentThread = KeGetCurrentThread ();
    KeEnterCriticalRegionThread (CurrentThread);

    ObjectTableEntry = ExMapHandleToPointer( HandleTable, Handle );

    //
    //  Make sure the object table entry really does exist
    //

    if (ObjectTableEntry != NULL) {

        PHANDLE_TABLE_ENTRY_INFO ObjectInfo;

        ObjectInfo = ExGetHandleInfo(HandleTable, Handle, TRUE);

        ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

        //
        //  If this object was audited when it was opened, it may
        //  be necessary to generate an audit now.  Check the audit
        //  mask that was saved when the handle was created.
        //
        //  It is safe to do this check in a non-atomic fashion,
        //  because bits will never be added to this mask once it is
        //  created.
        //
        //  Note: is OBJ_AUDIT_OBJECT_CLOSE in ObAttributes kept in synch with
        //  HandleAttributes?
        //

        if ( (ObjectTableEntry->ObAttributes & OBJ_AUDIT_OBJECT_CLOSE) &&
             (ObjectInfo != NULL) &&
             (ObjectInfo->AuditMask != 0) &&
             (DesiredAccess != 0))  {

              ObpAuditObjectAccess( Handle, ObjectInfo, &ObjectHeader->Type->Name, DesiredAccess );
        }

        ExUnlockHandleTableEntry( HandleTable, ObjectTableEntry );
    }
    KeLeaveCriticalRegionThread (CurrentThread);
}



VOID
ObpAuditObjectAccess(
    IN HANDLE Handle,
    IN PHANDLE_TABLE_ENTRY_INFO ObjectTableEntryInfo,
    IN PUNICODE_STRING ObjectTypeName,
    IN ACCESS_MASK DesiredAccess
    )
/*++

Routine Description:

    This routine will determine if it is necessary to audit the operation being
    performed on the passed handle.  If so, it will clear the bits in the handle
    and generate the appropriate audit before returning.

    The bits in the handle's audit mask are cleared in an atomic way so that
    multiple threads coming through this code do not generate more than one
    audit for the same operation.

Arguments:

    Handle - Supplies the handle being accessed.

    ObjectTableEntry - Supplies the object table entry for the handle passed in the
        first parameter.

    DesiredAccess - Supplies the access mask describing how the handle is being used
        in this operation.

Return Value:

    None.

--*/
{
    ACCESS_MASK t1, t2, r;
    ACCESS_MASK BitsToAudit;

    //
    //  Determine if this access is to
    //  be audited, and if so, clear the bits
    //  in the ObjectTableEntry.
    //

    while (ObjectTableEntryInfo->AuditMask != 0) {

        t1 = ObjectTableEntryInfo->AuditMask;
        t2 = t1 & ~DesiredAccess;

        if (t2 != t1) {

            r = (ACCESS_MASK) InterlockedCompareExchange((PLONG)&ObjectTableEntryInfo->AuditMask,  t2, t1);

            if (r == t1) {

                //
                //  AuditMask was == t1, so AuditMask is now == t2
                //  it worked, r contains what was in AuditMask, which
                //  we can examine safely.
                //

                BitsToAudit = r & DesiredAccess;

                //
                // Generate audit here
                //

                if (BitsToAudit != 0) {

                    SeOperationAuditAlarm( NULL,
                                           Handle,
                                           ObjectTypeName,
                                           BitsToAudit,
                                           NULL
                                           );
                }

                return;
            }

            //
            // else, somebody changed it, go around for another try
            //

        } else {

            //
            //  There are no bits in the AuditMask that we
            //  want to audit here, just leave.
            //

            return;
        }
    }
}


NTSTATUS
ObReferenceObjectByName (
    IN PUNICODE_STRING ObjectName,
    IN ULONG Attributes,
    IN PACCESS_STATE AccessState OPTIONAL,
    IN ACCESS_MASK DesiredAccess OPTIONAL,
    IN POBJECT_TYPE ObjectType,
    IN KPROCESSOR_MODE AccessMode,
    IN OUT PVOID ParseContext OPTIONAL,
    OUT PVOID *Object
    )

/*++

Routine Description:

    Given a name of an object this routine returns a pointer
    to the body of the object with proper ref counts

Arguments:

    ObjectName - Supplies the name of the object being referenced

    Attributes - Supplies the desired handle attributes

    AccessState - Supplies an optional pointer to the current access
        status describing already granted access types, the privileges used
        to get them, and any access types yet to be granted.

    DesiredAccess - Optionally supplies the desired access to the
        for the object

    ObjectType - Specifies the object type according to the caller

    AccessMode - Supplies the processor mode of the access

    ParseContext - Optionally supplies a context to pass down to the
        parse routine

    Object - Receives a pointer to the referenced object body

Return Value:

    An appropriate NTSTATUS value

--*/

{
    UNICODE_STRING CapturedObjectName;
    PVOID ExistingObject;
    ACCESS_STATE LocalAccessState;
    AUX_ACCESS_DATA AuxData;
    NTSTATUS Status;
    OBP_LOOKUP_CONTEXT LookupContext;

    PAGED_CODE();

    ObpValidateIrql("ObReferenceObjectByName");

    //
    //  If the object name descriptor is not specified, or the object name
    //  length is zero (tested after capture), then the object name is
    //  invalid.
    //

    if (ObjectName == NULL) {

        return STATUS_OBJECT_NAME_INVALID;
    }

    //
    //  Capture the object name.
    //

    Status = ObpCaptureObjectName( AccessMode,
                                   ObjectName,
                                   &CapturedObjectName,
                                   TRUE );

    if (NT_SUCCESS(Status)) {

        //
        //  No buffer has been allocated for a zero length name so no free
        //  needed
        //

        if (CapturedObjectName.Length == 0) {

           return STATUS_OBJECT_NAME_INVALID;
        }

        //
        //  If the access state is not specified, then create the access
        //  state.
        //

        if (!ARGUMENT_PRESENT(AccessState)) {

            AccessState = &LocalAccessState;

            Status = SeCreateAccessState( &LocalAccessState,
                                          &AuxData,
                                          DesiredAccess,
                                          &ObjectType->TypeInfo.GenericMapping );

            if (!NT_SUCCESS(Status)) {

                goto FreeBuffer;
            }
        }

        //
        //  Lookup object by name.
        //

        Status = ObpLookupObjectName( NULL,
                                      &CapturedObjectName,
                                      Attributes,
                                      ObjectType,
                                      AccessMode,
                                      ParseContext,
                                      NULL,
                                      NULL,
                                      AccessState,
                                      &LookupContext,
                                      &ExistingObject );

        //
        //  If the directory is returned locked, then unlock it.
        //

        ObpReleaseLookupContext( &LookupContext );
        //
        //  If the lookup was successful, then return the existing
        //  object if access is allowed. Otherwise, return NULL.
        //

        *Object = NULL;

        if (NT_SUCCESS(Status)) {

            if (ObpCheckObjectReference( ExistingObject,
                                         AccessState,
                                         FALSE,
                                         AccessMode,
                                         &Status )) {

                *Object = ExistingObject;
            }
        }

        //
        //  If the access state was generated, then delete the access
        //  state.
        //

        if (AccessState == &LocalAccessState) {

            SeDeleteAccessState(AccessState);
        }

        //
        //  Free the object name buffer.
        //

FreeBuffer:

        ObpFreeObjectNameBuffer(&CapturedObjectName);
    }

    return Status;
}


NTSTATUS
ObReferenceObjectByPointer (
    IN PVOID Object,
    IN ACCESS_MASK DesiredAccess,
    IN POBJECT_TYPE ObjectType,
    IN KPROCESSOR_MODE AccessMode
    )

/*++

Routine Description:

    This routine adds another reference count to an object denoted by
    a pointer to the object body

Arguments:

    Object - Supplies a pointer to the object being referenced

    DesiredAccess - Specifies the desired access for the reference

    ObjectType - Specifies the object type according to the caller

    AccessMode - Supplies the processor mode of the access

Return Value:

    STATUS_SUCCESS if successful and STATUS_OBJECT_TYPE_MISMATCH otherwise

--*/

{
    POBJECT_HEADER ObjectHeader;

    UNREFERENCED_PARAMETER (DesiredAccess);

    //
    //  Translate the pointer to the object body to a pointer to the
    //  object header
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    //
    //  If the specified object type does not match and either the caller is
    //  not kernel mode or it is not a symbolic link object then it is an
    //  error
    //

    if ((ObjectHeader->Type != ObjectType) && (AccessMode != KernelMode ||
                                               ObjectType == ObpSymbolicLinkObjectType)) {

        return( STATUS_OBJECT_TYPE_MISMATCH );
    }

    //
    //  Otherwise increment the pointer count and return success to
    //  our caller
    //

    ObpIncrPointerCount( ObjectHeader );

    return( STATUS_SUCCESS );
}

VOID
ObpDeferObjectDeletion (
    IN POBJECT_HEADER ObjectHeader
    )
{
    PVOID OldValue;
    //
    // Push this object on the list. If we make an empty to non-empty
    // transition then we may have to start a worker thread.
    //

    while (1) {
        OldValue = ObpRemoveObjectList;
        ObjectHeader->NextToFree = OldValue;
        if (InterlockedCompareExchangePointer (&ObpRemoveObjectList,
                                               ObjectHeader,
                                               OldValue) == OldValue) {
            break;
        }
    }

    if (OldValue == NULL) {
        //
        //  If we have to start the worker thread then go ahead
        //  and enqueue the work item
        //

        ExQueueWorkItem( &ObpRemoveObjectWorkItem, CriticalWorkQueue );
    }

}


LONG_PTR
FASTCALL
ObfReferenceObject (
    IN PVOID Object
    )

/*++

Routine Description:

    This function increments the reference count for an object.

    N.B. This function should be used to increment the reference count
        when the accessing mode is kernel or the objct type is known.

Arguments:

    Object - Supplies a pointer to the object whose reference count is
        incremented.

Return Value:

    None.

--*/

{
    POBJECT_HEADER ObjectHeader;
    LONG_PTR RetVal;

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    RetVal = ObpIncrPointerCount( ObjectHeader );
    ASSERT (RetVal != 1);
    return RetVal;
}

LONG_PTR
FASTCALL
ObReferenceObjectEx (
    IN PVOID Object,
    IN ULONG Count
    )
/*++

Routine Description:

    This function increments the reference count for an object by the specified amount.

Arguments:

    Object - Supplies a pointer to the object whose reference count is
        incremented.
    Count - Amount to increment by

Return Value:

    LONG - New value of count

--*/
{
    POBJECT_HEADER ObjectHeader;

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    return ObpIncrPointerCountEx (ObjectHeader, Count);
}

LONG_PTR
FASTCALL
ObDereferenceObjectEx (
    IN PVOID Object,
    IN ULONG Count
    )
/*++

Routine Description:

    This function decrements the reference count for an object by the specified amount.

Arguments:

    Object - Supplies a pointer to the object whose reference count is
        incremented.
    Count - Amount to decrement by

Return Value:

    LONG - New value of count

--*/
{
    POBJECT_HEADER ObjectHeader;
    LONG_PTR Result;

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    Result = ObpDecrPointerCountEx (ObjectHeader, Count);
    if (Result == 0) {
        ObpDeferObjectDeletion (ObjectHeader);
    }
    return Result;
}



BOOLEAN
FASTCALL
ObReferenceObjectSafe (
    IN PVOID Object
    )

/*++

Routine Description:

    This function increments the reference count for an object. It returns
    FALSE if the object is being deleted or TRUE if it's safe to use the object further

Arguments:

    Object - Supplies a pointer to the object whose reference count is
             incremented.

Return Value:

    TRUE    - The object was successfuly referenced and safe to use
    FALSE   - The object is being deleted

--*/

{
    POBJECT_HEADER ObjectHeader;

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    if (ObpSafeInterlockedIncrement(&ObjectHeader->PointerCount)) {

#ifdef POOL_TAGGING
        if(ObpTraceEnabled) {
            ObpPushStackInfo(ObjectHeader, TRUE);
        }
#endif // POOL_TAGGING

        return TRUE;
    }

    return FALSE;
}



LONG_PTR
FASTCALL
ObfDereferenceObject (
    IN PVOID Object
    )

/*++

Routine Description:

    This routine decrments the refernce count of the specified object and
    does whatever cleanup there is if the count goes to zero.

Arguments:

    Object - Supplies a pointer to the body of the object being dereferenced

Return Value:

    None.

--*/

{
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    KIRQL OldIrql;
    LONG_PTR Result;

    //
    //  Translate a pointer to the object body to a pointer to the object
    //  header.
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

#if DBG
    {
        POBJECT_HEADER_NAME_INFO NameInfo;

        NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

        if (NameInfo) {

            InterlockedDecrement(&NameInfo->DbgDereferenceCount) ;
        }
    }
#endif

    //
    //  Decrement the point count and if the result is now then
    //  there is extra work to do
    //

    ObjectType = ObjectHeader->Type;


    Result = ObpDecrPointerCount( ObjectHeader );

    if (Result == 0) {

        //
        //  Find out the level we're at and the object type
        //

        OldIrql = KeGetCurrentIrql();

        ASSERT(ObjectHeader->HandleCount == 0);

        //
        //  If we're at the passive level then go ahead and delete the
        //  object now.
        //

        if (OldIrql == PASSIVE_LEVEL) {

#ifdef POOL_TAGGING
                //
                // The object is going away, so we deregister it.
                //

                if (ObpTraceEnabled && !ObpTraceNoDeregister) {

                    ObpDeregisterObject( ObjectHeader );
                }
#endif //POOL_TAGGING

                ObpRemoveObjectRoutine( Object, FALSE );

                return Result;

        } else {

            //
            //  Objects can't be deleted from an IRQL above PASSIVE_LEVEL.
            //  So queue the delete operation.
            //

            ObpDeferObjectDeletion (ObjectHeader);
        }
    }

    return Result;
}

VOID
ObDereferenceObjectDeferDelete (
    IN PVOID Object
    )
{
    POBJECT_HEADER ObjectHeader;
    LONG_PTR Result;

#if DBG
    POBJECT_HEADER_NAME_INFO NameInfo;
#endif

    //
    //  Translate a pointer to the object body to a pointer to the object
    //  header.
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

#if DBG
    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

    if (NameInfo) {

        InterlockedDecrement(&NameInfo->DbgDereferenceCount) ;
    }
#endif

    //
    //  Decrement the point count and if the result is now then
    //  there is extra work to do
    //

    Result = ObpDecrPointerCount( ObjectHeader );

    if (Result == 0) {
        ObpDeferObjectDeletion (ObjectHeader);
    }
}


VOID
ObpProcessRemoveObjectQueue (
    PVOID Parameter
    )

/*++

Routine Description:

    This is the work routine for the remove object work queue.  Its
    job is to remove and process items from the remove object queue.

Arguments:

    Parameter - Ignored

Return Value:

    None.

--*/

{
    POBJECT_HEADER ObjectHeader, NextObject;

    UNREFERENCED_PARAMETER (Parameter);
    //
    // Process the list of defered delete objects.
    // The list head serves two purposes. First it maintains
    // the list of objects we need to delete and second
    // it signals that this thread is active.
    // While we are processing the latest list we leave the
    // header as the value 1. This will never be an object address
    // as the bottom bits should be clear for an object.
    //
    while (1) {
        ObjectHeader = InterlockedExchangePointer (&ObpRemoveObjectList,
                                                  (PVOID) 1);
        while (1) {
#ifdef POOL_TAGGING
            if (ObpTraceEnabled && !ObpTraceNoDeregister) {

                ObpDeregisterObject( ObjectHeader );
            }
#endif
            NextObject = ObjectHeader->NextToFree;
            ObpRemoveObjectRoutine( &ObjectHeader->Body, TRUE );
            ObjectHeader = NextObject;
            if (ObjectHeader == NULL || ObjectHeader == (PVOID) 1) {
                break;
            }
        }

        if (ObpRemoveObjectList == (PVOID) 1 &&
            InterlockedCompareExchangePointer (&ObpRemoveObjectList,
                                               NULL,
                                               (PVOID) 1) == (PVOID) 1) {
            break;
        }
    }
}


VOID
ObpRemoveObjectRoutine (
    IN  PVOID   Object,
    IN  BOOLEAN CalledOnWorkerThread
    )

/*++

Routine Description:

    This routine is used to delete an object whose reference count has
    gone to zero.

Arguments:

    Object - Supplies a pointer to the body of the object being deleted

    CalledOnWorkerThread - TRUE if called on worker thread, FALSE if called in
                           the context of the ObDereferenceObject.

Return Value:

    None.

--*/

{
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POBJECT_HEADER_NAME_INFO NameInfo;

    PAGED_CODE();

    ObpValidateIrql( "ObpRemoveObjectRoutine" );

    //
    //  Retrieve an object header from the object body, and also get
    //  the object type, creator and name info if available
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;
    CreatorInfo = OBJECT_HEADER_TO_CREATOR_INFO( ObjectHeader );
    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );


    //
    //  If there is a creator info record and we are on the list
    //  for the object type then remove this object from the list
    //

    if (CreatorInfo != NULL && !IsListEmpty( &CreatorInfo->TypeList )) {

        //
        //  Get exclusive access to the object type object
        //

        ObpEnterObjectTypeMutex( ObjectType );

        RemoveEntryList( &CreatorInfo->TypeList );

        //
        //  We are done with the object type object so we can now release it
        //

        ObpLeaveObjectTypeMutex( ObjectType );
    }

    //
    //  If there is a name info record and the name buffer is not null
    //  then free the buffer and zero out the name record
    //

    if (NameInfo != NULL && NameInfo->Name.Buffer != NULL) {

        ExFreePool( NameInfo->Name.Buffer );

        NameInfo->Name.Buffer = NULL;
        NameInfo->Name.Length = 0;
        NameInfo->Name.MaximumLength = 0;
    }


    //
    //  Security descriptor deletion must precede the
    //  call to the object's DeleteProcedure.  Check if we have
    //  a security descriptor and if so then call the routine
    //  to delete the security descritpor.
    //

    if (ObjectHeader->SecurityDescriptor != NULL) {

#if DBG
        KIRQL SaveIrql;
#endif

        ObpBeginTypeSpecificCallOut( SaveIrql );

        Status = (ObjectType->TypeInfo.SecurityProcedure)( Object,
                                                           DeleteSecurityDescriptor,
                                                           NULL, NULL, NULL,
                                                           &ObjectHeader->SecurityDescriptor,
                                                           0,
                                                           NULL );

        ObpEndTypeSpecificCallOut( SaveIrql, "Security", ObjectType, Object );
    }

    //
    //  Now if there is a delete callback for the object type invoke
    //  the routine
    //

    if (ObjectType->TypeInfo.DeleteProcedure) {

#if DBG
        KIRQL SaveIrql;
#endif

        ObpBeginTypeSpecificCallOut( SaveIrql );

        if (!CalledOnWorkerThread) {

            ObjectHeader->Flags |= OB_FLAG_DELETED_INLINE;
        }

        (*(ObjectType->TypeInfo.DeleteProcedure))(Object);

        ObpEndTypeSpecificCallOut( SaveIrql, "Delete", ObjectType, Object );
    }

    //
    //  Finally return the object back to pool including releasing any quota
    //  charges
    //

    ObpFreeObject( Object );
}


VOID
ObpDeleteNameCheck (
    IN PVOID Object
    )

/*++

Routine Description:

    This routine removes the name of an object from its parent directory

Arguments:

    Object - Supplies a pointer to the object body whose name is being checked

    TypeMutexHeld - Indicates if the lock on object type is being held by the
        caller

Return Value:

    None.

--*/

{
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    POBJECT_HEADER_NAME_INFO NameInfo;
    PVOID DirObject;
    OBP_LOOKUP_CONTEXT LookupContext;

    PAGED_CODE();

    ObpValidateIrql( "ObpDeleteNameCheck" );

    //
    //  Translate the object body to an object header also get
    //  the object type and name info if present
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    NameInfo = ObpReferenceNameInfo( ObjectHeader );
    ObjectType = ObjectHeader->Type;

    //
    //  Make sure that the object has a zero handle count, has a non
    //  empty name buffer, and is not a permanent object
    //

    if ((ObjectHeader->HandleCount == 0) &&
        (NameInfo != NULL) &&
        (NameInfo->Name.Length != 0) &&
        (!(ObjectHeader->Flags & OB_FLAG_PERMANENT_OBJECT)) &&
        (NameInfo->Directory != NULL)) {

        ObpInitializeLookupContext(&LookupContext);
        ObpLockLookupContext ( &LookupContext, NameInfo->Directory );

        DirObject = NULL;

        //
        //  Check that the object we is still in the directory otherwise
        //  then is nothing for us to remove
        //

        if (Object == ObpLookupDirectoryEntry( NameInfo->Directory,
                                               &NameInfo->Name,
                                               0,
                                               FALSE,
                                               &LookupContext )) {

            //
            //  Now reacquire the lock on the object type and
            //  check check the handle count again.  If it is still
            //  zero then we can do the actual delete name operation
            //
            //
            //  Delete the directory entry, if the entry is still there
            //

            ObpLockObject( ObjectHeader );

            if (ObjectHeader->HandleCount == 0 &&
                (ObjectHeader->Flags & OB_FLAG_PERMANENT_OBJECT) == 0) {

                //
                //  Delete the directory entry
                //

                ObpDeleteDirectoryEntry( &LookupContext );

                //
                //  If this is a symbolic link object then we also need to
                //  delete the symbolic link
                //

                if (ObjectType == ObpSymbolicLinkObjectType) {

                    ObpDeleteSymbolicLinkName( (POBJECT_SYMBOLIC_LINK)Object );
                }

                DirObject = NameInfo->Directory;
            }

            ObpUnlockObject( ObjectHeader );
        }

        ObpReleaseLookupContext( &LookupContext );

        //
        //  If there is a directory object for the name then decrement
        //  its reference count for it and for the object
        //

        if (DirObject != NULL) {

            //
            //  Dereference the name twice: one because we referenced it to
            //  saftely access the name info, and the second deref is because
            //  we want a deletion for the NameInfo
            //

            ObpDereferenceNameInfo(NameInfo);
            ObpDereferenceNameInfo(NameInfo);

            ObDereferenceObject( Object );
        }

    } else {

        ObpDereferenceNameInfo(NameInfo);

    }

    return;
}


//
// Thunks to support standard call callers
//

#ifdef ObDereferenceObject
#undef ObDereferenceObject
#endif

LONG_PTR
ObDereferenceObject (
    IN PVOID Object
    )

/*++

Routine Description:

    This is really just a thunk for the Obf version of the dereference
    routine

Arguments:

    Object - Supplies a pointer to the body of the object being dereferenced

Return Value:

    None.

--*/

{
    return ObfDereferenceObject (Object) ;
}


BOOLEAN
ObIsObjectDeletionInline(
    IN PVOID Object
    )

/*++

Routine Description:

    This is available only of object DeleteProcedure callbacks. It allows the
    callback to determine whether the stack on which it is invoked is
Arguments:

    Object - Supplies a pointer to the body of the object being deleted

Return Value:

    TRUE if the deletion procedure is being invoked on the same stack as the
    ObDereferenceObject, and FALSE if the procedure is being invoked from a
    queued work item.

--*/
{
    POBJECT_HEADER ObjectHeader;

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    return ((ObjectHeader->Flags & OB_FLAG_DELETED_INLINE) != 0);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obinsert.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obinsert.c

Abstract:

    Object instantiation API

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE,ObInsertObject)
#endif


NTSTATUS
ObInsertObject (
    IN PVOID Object,
    IN PACCESS_STATE AccessState OPTIONAL,
    IN ACCESS_MASK DesiredAccess OPTIONAL,
    IN ULONG ObjectPointerBias,
    OUT PVOID *NewObject OPTIONAL,
    OUT PHANDLE Handle OPTIONAL
    )

/*++

Routine Description:

    This routine inserts an object into the current processes handle table.

    The Object header includes a pointer to a SecurityDescriptor passed in
    an object creation call.  This SecurityDescriptor is not assumed to have
    been captured.  This routine is responsible for making an appropriate
    SecurityDescriptor and removing the reference in the object header.

Arguments:

    Object - Supplies a pointer to the new object body

    AccessState - Optionally supplies the access state for the new
        handle

    DesiredAccess - Optionally supplies the desired access we want for the
        new handle

    ObjectPointerBias - Supplies a bias to apply for the pointer count for the
        object

    NewObject - Optionally receives the pointer to the new object that we've
        created a handle for

    Handle - Receives the new handle, If NULL then no handle is created.
             Objects that don't have handles created must be unnamed and
             have an object bias of zero.

Return Value:

    An appropriate NTSTATUS value.

--*/

{
    POBJECT_CREATE_INFORMATION ObjectCreateInfo;
    POBJECT_HEADER ObjectHeader;
    PUNICODE_STRING ObjectName;
    POBJECT_TYPE ObjectType;
    POBJECT_HEADER_NAME_INFO NameInfo;
    PSECURITY_DESCRIPTOR ParentDescriptor = NULL;
    PVOID InsertObject;
    HANDLE NewHandle;
    OB_OPEN_REASON OpenReason;
    NTSTATUS Status = STATUS_SUCCESS;
    ACCESS_STATE LocalAccessState;
    AUX_ACCESS_DATA AuxData;
    BOOLEAN SecurityDescriptorAllocated;
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS ReturnStatus;
    PVOID DirObject = NULL;
    OBP_LOOKUP_CONTEXT LookupContext;

    PAGED_CODE();

    ObpValidateIrql("ObInsertObject");

    //
    //  Get the address of the object header, the object create information,
    //  the object type, and the address of the object name descriptor, if
    //  specified.
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER(Object);

#if DBG

    if ((ObjectHeader->Flags & OB_FLAG_NEW_OBJECT) == 0) {

        KdPrint(("OB: Attempting to insert existing object %08x\n", Object));
        KdBreakPoint();

        ObDereferenceObject(Object);

        return STATUS_INVALID_PARAMETER;
    }

#endif

    ObjectCreateInfo = ObjectHeader->ObjectCreateInfo;

    ObjectType = ObjectHeader->Type;

    NameInfo = ObpReferenceNameInfo( ObjectHeader );

    ObjectName = NULL;

    if ((NameInfo != NULL) && (NameInfo->Name.Buffer != NULL)) {

        ObjectName = &NameInfo->Name;
    }

    ASSERT (ARGUMENT_PRESENT (Handle) || (ObjectPointerBias == 0 && ObjectName == NULL &&
                                          ObjectType->TypeInfo.SecurityRequired && NewObject == NULL));

    //
    //  If security checks are not required and an object name is not
    //  specified, insert an unnamed object, biasing the count
    //  by one, dereference the bias, and return to our caller
    //

    PreviousMode = KeGetPreviousMode();

    if (!ObjectType->TypeInfo.SecurityRequired && (ObjectName == NULL)) {

        ObjectHeader->ObjectCreateInfo = NULL;

        *Handle = NULL;

        Status = ObpCreateUnnamedHandle( Object,
                                         DesiredAccess,
                                         1 + ObjectPointerBias,
                                         ObjectCreateInfo->Attributes,
                                         PreviousMode,
                                         NewObject,
                                         Handle );
        //
        //  Free the object creation information and dereference the object.
        //

        ObpFreeObjectCreateInformation(ObjectCreateInfo);

        ObpDereferenceNameInfo( NameInfo );
        ObDereferenceObject(Object);

        return Status;
    }

    //
    //  The object is either named or requires full security checks.  If the
    //  caller hasn't specified an access state then dummy up a local one
    //  using the requested desired access
    //

    if (!ARGUMENT_PRESENT(AccessState)) {

        AccessState = &LocalAccessState;

        Status = SeCreateAccessState( &LocalAccessState,
                                      &AuxData,
                                      DesiredAccess,
                                      &ObjectType->TypeInfo.GenericMapping );

        if (!NT_SUCCESS(Status)) {

            ObpDereferenceNameInfo( NameInfo );
            ObDereferenceObject(Object);

            return Status;
        }
    }

    AccessState->SecurityDescriptor = ObjectCreateInfo->SecurityDescriptor;

    //
    //  Check the desired access mask against the security descriptor
    //

    Status = ObpValidateAccessMask( AccessState );

    if (!NT_SUCCESS( Status )) {

        if (AccessState == &LocalAccessState) {

            SeDeleteAccessState( AccessState );
        }

        ObpDereferenceNameInfo( NameInfo );
        ObDereferenceObject(Object);

        if (AccessState == &LocalAccessState) {

            SeDeleteAccessState( AccessState );
        }

        return( Status );
    }

    //
    //  Set some local state variables
    //

    ObpInitializeLookupContext(&LookupContext);

    InsertObject = Object;
    OpenReason = ObCreateHandle;

    //
    //  Check if we have an object name.  If so then
    //  lookup the name
    //

    if (ObjectName != NULL) {

        Status = ObpLookupObjectName( ObjectCreateInfo->RootDirectory,
                                      ObjectName,
                                      ObjectCreateInfo->Attributes,
                                      ObjectType,
                                      (KPROCESSOR_MODE)(ObjectHeader->Flags & OB_FLAG_KERNEL_OBJECT
                                                            ? KernelMode : UserMode),
                                      ObjectCreateInfo->ParseContext,
                                      ObjectCreateInfo->SecurityQos,
                                      Object,
                                      AccessState,
                                      &LookupContext,
                                      &InsertObject );

        //
        //  We found the name and it is not the object we have as our input.
        //  So we cannot insert the object again so we'll return an
        //  appropriate status
        //

        if (NT_SUCCESS(Status) &&
            (InsertObject != NULL) &&
            (InsertObject != Object)) {

            OpenReason = ObOpenHandle;

            if (ObjectCreateInfo->Attributes & OBJ_OPENIF) {

                if (ObjectType != OBJECT_TO_OBJECT_HEADER(InsertObject)->Type) {

                    Status = STATUS_OBJECT_TYPE_MISMATCH;

                } else {

                    Status = STATUS_OBJECT_NAME_EXISTS;     // Warning only
                }

            } else {

                Status = STATUS_OBJECT_NAME_COLLISION;
            }
        }

        //
        //  We did not find the name so we'll cleanup after ourselves
        //  and return to our caller
        //

        if (!NT_SUCCESS( Status )) {

            ObpReleaseLookupContext( &LookupContext );

            ObpDereferenceNameInfo( NameInfo );
            ObDereferenceObject( Object );

            //
            //  Free security information if we allocated it
            //

            if (AccessState == &LocalAccessState) {

                SeDeleteAccessState( AccessState );
            }

            return( Status );

        } else {

            //
            //  Otherwise we did locate the object name
            //
            //  If we just created a named symbolic link then call out to
            //  handle any Dos Device name semanatics.
            //

            if (ObjectType == ObpSymbolicLinkObjectType) {

                ObpCreateSymbolicLinkName( (POBJECT_SYMBOLIC_LINK)InsertObject );
            }
        }
    }

    //
    //  If we are creating a new object, then we need assign security
    //  to it.  A pointer to the captured caller-proposed security
    //  descriptor is contained in the AccessState structure.  The
    //  SecurityDescriptor field in the object header must point to
    //  the final security descriptor, or to NULL if no security is
    //  to be assigned to the object.
    //

    if (InsertObject == Object) {

        //
        //  Only the following objects have security descriptors:
        //
        //       - Named Objects
        //       - Unnamed objects whose object-type information explicitly
        //         indicates a security descriptor is required.
        //

        if ((ObjectName != NULL) || ObjectType->TypeInfo.SecurityRequired) {

            //
            //  Get the parent's descriptor, if there is one...
            //

            if ((NameInfo != NULL) && (NameInfo->Directory != NULL)) {

                //
                //  This will allocate a block of memory and copy
                //  the parent's security descriptor into it, and
                //  return the pointer to the block.
                //
                //  Call ObReleaseObjectSecurity to free up this
                //  memory.
                //

                ObGetObjectSecurity( NameInfo->Directory,
                                     &ParentDescriptor,
                                     &SecurityDescriptorAllocated );
            }
            else {
                SecurityDescriptorAllocated = FALSE;
            }

            //
            //  Take the captured security descriptor in the AccessState,
            //  put it into the proper format, and call the object's
            //  security method to assign the new security descriptor to
            //  the new object.
            //

            Status = ObAssignSecurity( AccessState,
                                       ParentDescriptor,
                                       Object,
                                       ObjectType );

            if (ParentDescriptor != NULL) {

                ObReleaseObjectSecurity( ParentDescriptor,
                                         SecurityDescriptorAllocated );

            } else if (NT_SUCCESS( Status )) {

                SeReleaseSecurityDescriptor( ObjectCreateInfo->SecurityDescriptor,
                                             ObjectCreateInfo->ProbeMode,
                                             TRUE );

                ObjectCreateInfo->SecurityDescriptor = NULL;
                AccessState->SecurityDescriptor = NULL;
            }
        }

        if (!NT_SUCCESS( Status )) {

            //
            //  The attempt to assign the security descriptor to
            //  the object failed.
            //
            
            if (LookupContext.DirectoryLocked) {
                
                //
                //  If ObpLookupObjectName already inserted the 
                //  object into the directory we have to backup this
                //

                //
                //  Capture the object Directory 
                //

                DirObject = NameInfo->Directory;

                ObpDeleteDirectoryEntry( &LookupContext ); 
            }

            ObpReleaseLookupContext( &LookupContext );

            //
            //  If ObpLookupObjectName inserted the object into the directory
            //  it added a reference to the object and to its directory
            //  object. We should remove the extra-references
            //

            if (DirObject) {

                ObDereferenceObject( Object );
                ObDereferenceObject( DirObject );
            }

            //
            //  The first backout logic used ObpDeleteNameCheck
            //  which is wrong because the security descriptor for
            //  the object is not initialized. Actually  ObpDeleteNameCheck
            //  had no effect because the object was removed before from 
            //  the directory
            //

            ObpDereferenceNameInfo( NameInfo );
            ObDereferenceObject( Object );

            //
            //  Free security information if we allocated it
            //

            if (AccessState == &LocalAccessState) {

                SeDeleteAccessState( AccessState );
            }

            return( Status );
        }
    }

    ReturnStatus = Status;

    ObjectHeader->ObjectCreateInfo = NULL;

    //
    //  Create a named handle for the object with a pointer bias
    //  This call also will unlock the directory lock is necessary
    //  on return
    //

    if (ARGUMENT_PRESENT (Handle)) {

        Status = ObpCreateHandle( OpenReason,
                                  InsertObject,
                                  NULL,
                                  AccessState,
                                  1 + ObjectPointerBias,
                                  ObjectCreateInfo->Attributes,
                                  &LookupContext,
                                  PreviousMode,
                                  NewObject,
                                  &NewHandle );

        //
        //  If the insertion failed, the following dereference will cause
        //  the newly created object to be deallocated.
        //

        if (!NT_SUCCESS( Status )) {

            //
            //  Make the name reference go away if an error.
            //

            if (ObjectName != NULL) {

                ObpDeleteNameCheck( Object );
            }

            *Handle = NULL;

            ReturnStatus = Status;

        } else {
            *Handle = NewHandle;
        }

        ObpDereferenceNameInfo( NameInfo );

        ObDereferenceObject( Object );


    } else {

        BOOLEAN IsNewObject;

        //
        //  Charge the user quota for the object.
        //

        ObpLockObject( ObjectHeader );

        ReturnStatus = ObpChargeQuotaForObject( ObjectHeader, ObjectType, &IsNewObject );

        ObpUnlockObject( ObjectHeader );

        if (!NT_SUCCESS (ReturnStatus)) {
            ObDereferenceObject( Object );
        }

        //
        //  N.B. An object cannot be named if no Handle parameter is specified.
        //  The calls to ObpDereferenceNameInfo and ObpReleaseLookupContext are 
        //  not necessary in this path then.
        //
    }

    ObpFreeObjectCreateInformation( ObjectCreateInfo );

    //
    //  Free security information if we allocated it
    //

    if (AccessState == &LocalAccessState) {

        SeDeleteAccessState( AccessState );
    }

    return( ReturnStatus );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obsdata.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obsdata.c

Abstract:

    Object Manager Security Descriptor Caching

Author:

    Robert Reichel  (robertre)  12-Oct-1993

Revision History:

    Neill Clift (NeillC) 16-Nov-2000

    General cleanup. Don't free/allocate pool under locks. Don't do unaligned fetches during hashing.
    Reduce lock contention etc. Add fast referencing of security descriptor.

--*/

#include "obp.h"


#if DBG
#define OB_DIAGNOSTICS_ENABLED 1
#endif // DBG

//
//  These definitions are useful diagnostics aids
//

#if OB_DIAGNOSTICS_ENABLED

//
//  Test for enabled diagnostic
//

#define IF_OB_GLOBAL( FlagName ) if (ObsDebugFlags & (OBS_DEBUG_##FlagName))

//
//  Diagnostics print statement
//

#define ObPrint( FlagName, _Text_ ) IF_OB_GLOBAL( FlagName ) DbgPrint _Text_

#else

//
//  diagnostics not enabled - No diagnostics included in build
//

//
//  Test for diagnostics enabled
//

#define IF_OB_GLOBAL( FlagName ) if (FALSE)

//
//  Diagnostics print statement (expands to no-op)
//

#define ObPrint( FlagName, _Text_ )     ;

#endif // OB_DIAGNOSTICS_ENABLED


//
//  The following flags enable or disable various diagnostic
//  capabilities within OB code.  These flags are set in
//  ObGlobalFlag (only available within a DBG system).
//
//

#define OBS_DEBUG_ALLOC_TRACKING          ((ULONG) 0x00000001L)
#define OBS_DEBUG_CACHE_FREES             ((ULONG) 0x00000002L)
#define OBS_DEBUG_BREAK_ON_INIT           ((ULONG) 0x00000004L)
#define OBS_DEBUG_SHOW_COLLISIONS         ((ULONG) 0x00000008L)
#define OBS_DEBUG_SHOW_STATISTICS         ((ULONG) 0x00000010L)
#define OBS_DEBUG_SHOW_REFERENCES         ((ULONG) 0x00000020L)
#define OBS_DEBUG_SHOW_DEASSIGN           ((ULONG) 0x00000040L)
#define OBS_DEBUG_STOP_INVALID_DESCRIPTOR ((ULONG) 0x00000080L)
#define OBS_DEBUG_SHOW_HEADER_FREE        ((ULONG) 0x00000100L)

//
// Define struct of single hash clash chain
//
typedef struct _OB_SD_CACHE_LIST {
    EX_PUSH_LOCK PushLock;
    LIST_ENTRY Head;
} OB_SD_CACHE_LIST, *POB_SD_CACHE_LIST;
//
//  Array of pointers to security descriptor entries
//

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg("PAGEDATA")
#endif

OB_SD_CACHE_LIST ObsSecurityDescriptorCache[SECURITY_DESCRIPTOR_CACHE_ENTRIES];

#if OB_DIAGNOSTICS_ENABLED

LONG ObsTotalCacheEntries = 0;
ULONG ObsDebugFlags = 0;

#endif

#ifdef ALLOC_DATA_PRAGMA
#pragma data_seg()
#endif


#if defined (ALLOC_PRAGMA)
#pragma alloc_text(INIT,ObpInitSecurityDescriptorCache)
#pragma alloc_text(PAGE,ObpHashSecurityDescriptor)
#pragma alloc_text(PAGE,ObpHashBuffer)
#pragma alloc_text(PAGE,ObLogSecurityDescriptor)
#pragma alloc_text(PAGE,ObpCreateCacheEntry)
#pragma alloc_text(PAGE,ObpReferenceSecurityDescriptor)
#pragma alloc_text(PAGE,ObDeassignSecurity)
#pragma alloc_text(PAGE,ObDereferenceSecurityDescriptor)
#pragma alloc_text(PAGE,ObpDestroySecurityDescriptorHeader)
#pragma alloc_text(PAGE,ObpCompareSecurityDescriptors)
#pragma alloc_text(PAGE,ObReferenceSecurityDescriptor)
#endif



NTSTATUS
ObpInitSecurityDescriptorCache (
    VOID
    )

/*++

Routine Description:

    Allocates and initializes the globalSecurity Descriptor Cache

Arguments:

    None

Return Value:

    STATUS_SUCCESS on success, NTSTATUS on failure.

--*/

{
    ULONG i;

    IF_OB_GLOBAL( BREAK_ON_INIT ) {

        DbgBreakPoint();
    }

    //
    // Initialize all the list heads and their associated locks.
    //
    for (i = 0; i < SECURITY_DESCRIPTOR_CACHE_ENTRIES; i++) {
        ExInitializePushLock (&ObsSecurityDescriptorCache[i].PushLock);
        InitializeListHead (&ObsSecurityDescriptorCache[i].Head);
    }

    //
    //  And return to our caller
    //

    return( STATUS_SUCCESS );
}


ULONG
ObpHashSecurityDescriptor (
    PSECURITY_DESCRIPTOR SecurityDescriptor,
    ULONG Length
    )

/*++

Routine Description:

    Hashes a security descriptor to a 32 bit value

Arguments:

    SecurityDescriptor - Provides the security descriptor to be hashed
    Length - Length of security descriptor

Return Value:

    ULONG - a 32 bit hash value.

--*/

{
    ULONG Hash;

    Hash = ObpHashBuffer (SecurityDescriptor, Length);

    return Hash;
}


ULONG
ObpHashBuffer (
    PVOID Data,
    ULONG Length
    )

/*++

Routine Description:

    Hashes a buffer into a 32 bit value

Arguments:

    Data - Buffer containing the data to be hashed.

    Length - The length in bytes of the buffer


Return Value:

    ULONG - a 32 bit hash value.

--*/

{
    PULONG Buffer, BufferEnd;
    PUCHAR Bufferp, BufferEndp;

    ULONG Result = 0;

    //
    // Calculate buffer bounds as byte pointers
    //
    Bufferp = Data;
    BufferEndp = Bufferp + Length;

    //
    // Calculate buffer bounds as rounded down ULONG pointers
    //
    Buffer = Data;
    BufferEnd = (PULONG)(Bufferp + (Length&~(sizeof (ULONG) - 1)));

    //
    // Loop over a whole number of ULONGs
    //
    while (Buffer < BufferEnd) {
        Result ^= *Buffer++;
        Result = _rotl (Result, 3);
    }

    //
    // Pull in the remaining bytes
    //
    Bufferp = (PUCHAR) Buffer;
    while (Bufferp < BufferEndp) {
        Result ^= *Bufferp++;
        Result = _rotl (Result, 3);
    }

    

    return Result;
}


NTSTATUS
ObLogSecurityDescriptor (
    IN PSECURITY_DESCRIPTOR InputSecurityDescriptor,
    OUT PSECURITY_DESCRIPTOR *OutputSecurityDescriptor,
    IN ULONG RefBias
    )

/*++

Routine Description:

    Takes a passed security descriptor and registers it into the
    security descriptor database.

Arguments:

    InputSecurityDescriptor - The new security descriptor to be logged into
        the database. On a successful return this memory will have been
        freed back to pool.

    OutputSecurityDescriptor - Output security descriptor to be used by the
        caller.

    RefBias - Amount to bias the security descriptor reference count by.
              Typicaly either 1 or ExFastRefGetAdditionalReferenceCount () + 1,

Return Value:

    An appropriate status value

--*/

{
    ULONG FullHash;
    ULONG Slot;
    PSECURITY_DESCRIPTOR_HEADER NewDescriptor;
    PLIST_ENTRY Front;
    PSECURITY_DESCRIPTOR_HEADER Header = NULL;
    BOOLEAN Match;
    POB_SD_CACHE_LIST Chain;
    PETHREAD CurrentThread;
    ULONG Length;

    Length = RtlLengthSecurityDescriptor (InputSecurityDescriptor);

    FullHash = ObpHashSecurityDescriptor (InputSecurityDescriptor, Length);

    Slot = FullHash % SECURITY_DESCRIPTOR_CACHE_ENTRIES;

    NewDescriptor = NULL;

    //
    // First lock the table for read access. We will change this to write if we have to insert later
    //
    Chain = &ObsSecurityDescriptorCache[Slot];

    CurrentThread = PsGetCurrentThread ();
    KeEnterCriticalRegionThread (&CurrentThread->Tcb);
    ExAcquirePushLockShared (&Chain->PushLock);

    do {
        //
        //  See if the list for this slot is in use.
        //  Lock the table first, unlock if if we don't need it.
        //
        Match = FALSE;

        //
        //  Zoom down the hash bucket looking for a full hash match
        //

        for (Front = Chain->Head.Flink;
             Front != &Chain->Head;
             Front = Front->Flink) {

            Header = LINK_TO_SD_HEADER (Front);

            //
            // The list is ordered by full hash value and is maintained this way by virtue
            // of the fact that we use the 'Back' variable for the insert.
            //

            if (Header->FullHash > FullHash) {
                break;
            }

            if (Header->FullHash == FullHash) {

                Match = ObpCompareSecurityDescriptors (InputSecurityDescriptor,
                                                       Length,
                                                       &Header->SecurityDescriptor);

                if (Match) {

                    break;
                }

                ObPrint (SHOW_COLLISIONS, ("Got a collision on %d, no match\n", Slot));
            }
        }

        //
        //  If we have a match then we'll get the caller to use the old
        //  cached descriptor, but bumping its ref count, freeing what  
        //  the caller supplied and returning the old one to our caller
        //

        if (Match) {

            InterlockedExchangeAdd ((PLONG)&Header->RefCount, RefBias);

            ObPrint (SHOW_REFERENCES, ("Reference Hash = 0x%lX, New RefCount = %d\n", Header->FullHash, Header->RefCount));

            ExReleasePushLock (&Chain->PushLock);
            KeLeaveCriticalRegionThread (&CurrentThread->Tcb);

            *OutputSecurityDescriptor = &Header->SecurityDescriptor;

            if (NewDescriptor != NULL) {
                ExFreePool (NewDescriptor);
            }

            return STATUS_SUCCESS;
        }


        if (NewDescriptor == NULL) {
            ExReleasePushLockShared (&Chain->PushLock);
            KeLeaveCriticalRegionThread (&CurrentThread->Tcb);

            //
            //  Can't use an existing one, create a new entry
            //  and insert it into the list.
            //

            NewDescriptor = ObpCreateCacheEntry (InputSecurityDescriptor,
                                                 Length,
                                                 FullHash,
                                                 RefBias);

            if (NewDescriptor == NULL) {
                return STATUS_INSUFFICIENT_RESOURCES;
            }
            //
            // Reacquire the lock in write mode. We will probably have to insert now
            //
            KeEnterCriticalRegionThread (&CurrentThread->Tcb);
            ExAcquirePushLockExclusive (&Chain->PushLock);
        } else {
            break;
        }
    } while (1);

#if OB_DIAGNOSTICS_ENABLED

    InterlockedIncrement (&ObsTotalCacheEntries);

#endif

    ObPrint (SHOW_STATISTICS, ("ObsTotalCacheEntries = %d \n", ObsTotalCacheEntries));
    ObPrint (SHOW_COLLISIONS, ("Adding new entry for index #%d \n", Slot));


    //
    // Insert the entry before the 'Front' entry. If there is no 'Front' entry then this
    // is just inserting at the head
    //

    InsertTailList (Front, &NewDescriptor->Link);

    ExReleasePushLockExclusive (&Chain->PushLock);
    KeLeaveCriticalRegionThread (&CurrentThread->Tcb);

    //
    //  Set the output security descriptor and return to our caller
    //

    *OutputSecurityDescriptor = &NewDescriptor->SecurityDescriptor;

    return( STATUS_SUCCESS );
}


PSECURITY_DESCRIPTOR_HEADER
ObpCreateCacheEntry (
    PSECURITY_DESCRIPTOR InputSecurityDescriptor,
    ULONG SecurityDescriptorLength,
    ULONG FullHash,
    ULONG RefBias
    )

/*++

Routine Description:

    Allocates and initializes a new cache entry.

Arguments:

    InputSecurityDescriptor - The security descriptor to be cached.

    Length - Length of security descriptor

    FullHash - Full 32 bit hash of the security descriptor.

    RefBias - Amount to bias the security descriptor reference count by.
              Typicaly either 1 or ExFastRefGetAdditionalReferenceCount () + 1,

Return Value:

    A pointer to the newly allocated cache entry, or NULL

--*/

{
    ULONG CacheEntrySize;
    PSECURITY_DESCRIPTOR_HEADER NewDescriptor;

    //
    //  Compute the size that we'll need to allocate.  We need space for
    //  the security descriptor cache minus the funny quad at the end and the
    //  security descriptor itself.
    //

    ASSERT (SecurityDescriptorLength == RtlLengthSecurityDescriptor (InputSecurityDescriptor));
    CacheEntrySize = SecurityDescriptorLength + (sizeof (SECURITY_DESCRIPTOR_HEADER) - sizeof(QUAD));

    //
    //  Now allocate space for the cached entry
    //

    NewDescriptor = ExAllocatePoolWithTag (PagedPool, CacheEntrySize, 'cSbO');

    if (NewDescriptor == NULL) {

        return NULL;
    }

    //
    //  Fill the header, copy over the descriptor data, and return to our
    //  caller
    //

    NewDescriptor->RefCount   = RefBias;
    NewDescriptor->FullHash   = FullHash;

    RtlCopyMemory (&NewDescriptor->SecurityDescriptor,
                   InputSecurityDescriptor,
                   SecurityDescriptorLength);

    return NewDescriptor;
}

VOID
ObReferenceSecurityDescriptor (
    IN PSECURITY_DESCRIPTOR SecurityDescriptor,
    IN ULONG Count
    )
/*++

Routine Description:

    References the security descriptor.

Arguments:

    SecurityDescriptor - Security descriptor inside the cache to reference.
    Count - Amount to reference by

Return Value:

    None.

--*/
{
    PSECURITY_DESCRIPTOR_HEADER SecurityDescriptorHeader;

    SecurityDescriptorHeader = SD_TO_SD_HEADER( SecurityDescriptor );
    ObPrint( SHOW_REFERENCES, ("Referencing Hash %lX, Refcount = %d \n",SecurityDescriptorHeader->FullHash,
                               SecurityDescriptorHeader->RefCount));

    //
    //  Increment the reference count
    //
    InterlockedExchangeAdd ((PLONG)&SecurityDescriptorHeader->RefCount, Count);
}


PSECURITY_DESCRIPTOR
ObpReferenceSecurityDescriptor (
    POBJECT_HEADER ObjectHeader
    )

/*++

Routine Description:

    References the security descriptor of the passed object.

Arguments:

    Object - Object being access validated.

Return Value:

    The security descriptor of the object.

--*/

{
    PSECURITY_DESCRIPTOR_HEADER SecurityDescriptorHeader;
    PSECURITY_DESCRIPTOR SecurityDescriptor;
    PEX_FAST_REF FastRef;
    EX_FAST_REF OldRef;
    ULONG RefsToAdd, Unused;

    //
    // Attempt the fast reference
    //
    FastRef = (PEX_FAST_REF) &ObjectHeader->SecurityDescriptor;

    OldRef = ExFastReference (FastRef);

    SecurityDescriptor = ExFastRefGetObject (OldRef);

    //
    // See if we can fast reference this security descriptor. Return NULL if there wasn't one
    // and go the slow way if there are no more cached references left.
    //
    Unused = ExFastRefGetUnusedReferences (OldRef);

    if (Unused >= 1 || SecurityDescriptor == NULL) {
        if (Unused == 1) {
            //
            // If we took the counter to zero then attempt to make life easier for
            // the next referencer by resetting the counter to its max. Since we now
            // have a reference to the security descriptor we can do this.
            //
            RefsToAdd = ExFastRefGetAdditionalReferenceCount ();
            SecurityDescriptorHeader = SD_TO_SD_HEADER( SecurityDescriptor );
            InterlockedExchangeAdd ((PLONG)&SecurityDescriptorHeader->RefCount, RefsToAdd);

            //
            // Try to add the added references to the cache. If we fail then just
            // release them. This dereference can not take the reference count to zero.
            //
            if (!ExFastRefAddAdditionalReferenceCounts (FastRef, SecurityDescriptor, RefsToAdd)) {
                InterlockedExchangeAdd ((PLONG)&SecurityDescriptorHeader->RefCount, -(LONG)RefsToAdd);
            }
        }
        return SecurityDescriptor;
    }

    ObpLockObjectShared( ObjectHeader );

    SecurityDescriptor = ExFastRefGetObject (*FastRef);

    IF_OB_GLOBAL( STOP_INVALID_DESCRIPTOR ) {

        if(!RtlValidSecurityDescriptor ( SecurityDescriptor )) {

            DbgBreakPoint();
        }
    }

    //
    //  The obejcts security descriptor is not allowed to go fron NON-NULL to NULL.
    //
    SecurityDescriptorHeader = SD_TO_SD_HEADER( SecurityDescriptor );
    ObPrint( SHOW_REFERENCES, ("Referencing Hash %lX, Refcount = %d \n",SecurityDescriptorHeader->FullHash,
                               SecurityDescriptorHeader->RefCount));

    //
    //  Increment the reference count
    //
    InterlockedIncrement ((PLONG) &SecurityDescriptorHeader->RefCount);

    ObpUnlockObject( ObjectHeader );


    return( SecurityDescriptor );
}


NTSTATUS
ObDeassignSecurity (
    IN OUT PSECURITY_DESCRIPTOR *pSecurityDescriptor
    )

/*++

Routine Description:

    This routine dereferences the input security descriptor

Arguments:

    SecurityDescriptor - Supplies the security descriptor
        being modified

Return Value:

    Only returns STATUS_SUCCESS

--*/

{
    PSECURITY_DESCRIPTOR SecurityDescriptor;
    EX_FAST_REF FastRef;

    ObPrint( SHOW_DEASSIGN,("Deassigning security descriptor %x\n",*pSecurityDescriptor));

    //
    //  NULL out the SecurityDescriptor in the object's
    //  header so we don't try to free it again.
    //
    FastRef = *(PEX_FAST_REF) pSecurityDescriptor;
    *pSecurityDescriptor = NULL;

    SecurityDescriptor = ExFastRefGetObject (FastRef);
    ObDereferenceSecurityDescriptor (SecurityDescriptor, ExFastRefGetUnusedReferences (FastRef) + 1);
    
    return STATUS_SUCCESS;
}


VOID
ObDereferenceSecurityDescriptor (
    PSECURITY_DESCRIPTOR SecurityDescriptor,
    ULONG Count
    )

/*++

Routine Description:

    Decrements the refcount of a cached security descriptor

Arguments:

    SecurityDescriptor - Points to a cached security descriptor

Return Value:

    None.

--*/

{
    PSECURITY_DESCRIPTOR_HEADER SecurityDescriptorHeader;
    PVOID PoolToFree;
    LONG OldValue, NewValue;
    POB_SD_CACHE_LIST Chain;
    PETHREAD CurrentThread;
    ULONG Slot;

    SecurityDescriptorHeader = SD_TO_SD_HEADER( SecurityDescriptor );

    //
    // First see if its possible to do a non-zero transition lock free.
    //
    OldValue = SecurityDescriptorHeader->RefCount;

    //
    // If the old value is equal to the decrement then we will be the deleter of this block. We need the lock for that
    //
    while (OldValue != (LONG) Count) {

        NewValue = InterlockedCompareExchange ((PLONG)&SecurityDescriptorHeader->RefCount, OldValue - Count, OldValue);
        if (NewValue == OldValue) {
            return;
        }
        OldValue = NewValue;
    }

    //
    //  Lock the security descriptor cache and get a pointer
    //  to the security descriptor header
    //
    Slot = SecurityDescriptorHeader->FullHash % SECURITY_DESCRIPTOR_CACHE_ENTRIES;

    Chain = &ObsSecurityDescriptorCache[Slot];

    CurrentThread = PsGetCurrentThread ();
    KeEnterCriticalRegionThread (&CurrentThread->Tcb);
    ExAcquirePushLockExclusive (&Chain->PushLock);

    //
    //  Do some debug work
    //

    ObPrint( SHOW_REFERENCES, ("Dereferencing SecurityDescriptor %x, hash %lx, refcount = %d \n", SecurityDescriptor,
                               SecurityDescriptorHeader->FullHash,
                               SecurityDescriptorHeader->RefCount));

    ASSERT(SecurityDescriptorHeader->RefCount != 0);

    //
    //  Decrement the ref count and if it is now zero then
    //  we can completely remove this entry from the cache
    //

    if (InterlockedExchangeAdd ((PLONG)&SecurityDescriptorHeader->RefCount, -(LONG)Count) == (LONG)Count) {

        PoolToFree = ObpDestroySecurityDescriptorHeader (SecurityDescriptorHeader);
        //
        //  Unlock the security descriptor cache and free the pool
        //

        ExReleasePushLockExclusive (&Chain->PushLock);
        KeLeaveCriticalRegionThread (&CurrentThread->Tcb);

        ExFreePool (PoolToFree);
    } else {

        //
        //  Unlock the security descriptor cache and return to our caller
        //

        ExReleasePushLockExclusive (&Chain->PushLock);
        KeLeaveCriticalRegionThread (&CurrentThread->Tcb);
    }

}


PVOID
ObpDestroySecurityDescriptorHeader (
    IN PSECURITY_DESCRIPTOR_HEADER Header
    )

/*++

Routine Description:

    Frees a cached security descriptor and unlinks it from the chain.

Arguments:

    Header - Pointer to a security descriptor header (cached security
        descriptor)

Return Value:

    None.

--*/

{
    ASSERT ( Header->RefCount == 0 );

#if OB_DIAGNOSTICS_ENABLED

    InterlockedDecrement (&ObsTotalCacheEntries);

#endif

    ObPrint( SHOW_STATISTICS, ("ObsTotalCacheEntries = %d \n",ObsTotalCacheEntries));

    //
    //  Unlink the cached security descriptor from its linked list
    //

    RemoveEntryList (&Header->Link);

    ObPrint( SHOW_HEADER_FREE, ("Freeing memory at %x \n",Header));

    //
    //  Now return the cached descriptor to our caller to free
    //

    return Header;
}


BOOLEAN
ObpCompareSecurityDescriptors (
    IN PSECURITY_DESCRIPTOR SD1,
    IN ULONG Length1,
    IN PSECURITY_DESCRIPTOR SD2
    )

/*++

Routine Description:

    Performs a byte by byte comparison of two self relative security
    descriptors to determine if they are identical.

Arguments:

    SD1, SD2 - Security descriptors to be compared.
    Length1 - Length of SD1

Return Value:

    TRUE - They are the same.

    FALSE - They are different.

--*/

{
    ULONG Length2;

    //
    //  Calculating the length is pretty fast, see if we
    //  can get away with doing only that.
    //

    ASSERT (Length1 == RtlLengthSecurityDescriptor ( SD1 ));

    Length2 =  RtlLengthSecurityDescriptor ( SD2 );

    if (Length1 != Length2) {

        return( FALSE );
    }

    return (BOOLEAN)RtlEqualMemory ( SD1, SD2, Length1 );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obquery.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obquery.c

Abstract:

    Query Object system service

Author:

    Steve Wood (stevewo) 12-May-1989

Revision History:

--*/

#include "obp.h"

//
//  Local procedure prototypes
//

//
//  The following structure is used to pass the call back routine
//  "ObpSetHandleAttributes" the captured object information and
//  the processor mode of the caller.
//

typedef struct __OBP_SET_HANDLE_ATTRIBUTES {

    OBJECT_HANDLE_FLAG_INFORMATION ObjectInformation;

    KPROCESSOR_MODE PreviousMode;

} OBP_SET_HANDLE_ATTRIBUTES, *POBP_SET_HANDLE_ATTRIBUTES;

BOOLEAN
ObpSetHandleAttributes (
    IN OUT PVOID TableEntry,
    IN ULONG_PTR Parameter
    );

#if defined(ALLOC_PRAGMA)
#pragma alloc_text(PAGE,NtQueryObject)
#pragma alloc_text(PAGE,ObpQueryNameString)
#pragma alloc_text(PAGE,ObQueryNameString)
#pragma alloc_text(PAGE,ObQueryTypeName)
#pragma alloc_text(PAGE,ObQueryTypeInfo)
#pragma alloc_text(PAGE,ObQueryObjectAuditingByHandle)
#pragma alloc_text(PAGE,NtSetInformationObject)
#pragma alloc_text(PAGE,ObpSetHandleAttributes)
#pragma alloc_text(PAGE,ObSetHandleAttributes)
#endif


NTSTATUS
NtQueryObject (
    IN HANDLE Handle,
    IN OBJECT_INFORMATION_CLASS ObjectInformationClass,
    OUT PVOID ObjectInformation,
    IN ULONG ObjectInformationLength,
    OUT PULONG ReturnLength OPTIONAL
    )

/*++

Routine description:

    This routine is used to query information about a given object

Arguments:

    Handle - Supplies a handle to the object being queried.  This value
        is ignored if the requested information class is for type
        information.

    ObjectInformationClass - Specifies the type of information to return

    ObjectInformation - Supplies an output buffer for the information being
        returned

    ObjectInformationLength - Specifies, in bytes, the length of the
        preceding object information buffer

    ReturnLength - Optionally receives the length, in bytes, used to store
        the object information

Return Value:

    An appropriate status value

--*/

{
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;
    PVOID Object;
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_QUOTA_INFO QuotaInfo;
    POBJECT_HEADER_NAME_INFO NameInfo;
    POBJECT_TYPE ObjectType;
    POBJECT_HEADER ObjectDirectoryHeader;
    POBJECT_DIRECTORY ObjectDirectory;
    ACCESS_MASK GrantedAccess;
    POBJECT_HANDLE_FLAG_INFORMATION HandleFlags;
    OBJECT_HANDLE_INFORMATION HandleInformation = {0};
    ULONG NameInfoSize;
    ULONG SecurityDescriptorSize;
    ULONG TempReturnLength;
    OBJECT_BASIC_INFORMATION ObjectBasicInfo;
    POBJECT_TYPES_INFORMATION TypesInformation;
    POBJECT_TYPE_INFORMATION TypeInfo;
    ULONG i;

    PAGED_CODE();

    //
    //  Initialize our local variables
    //

    TempReturnLength = 0;

    //
    //  Get previous processor mode and probe output argument if necessary.
    //

    PreviousMode = KeGetPreviousMode();

    if (PreviousMode != KernelMode) {

        try {

            if (ObjectInformationClass != ObjectHandleFlagInformation) {

                ProbeForWrite( ObjectInformation,
                               ObjectInformationLength,
                               sizeof( ULONG ));

            } else {

                ProbeForWrite( ObjectInformation,
                               ObjectInformationLength,
                               1 );
            }

            //
            //  We'll use a local temp return length variable to pass
            //  through to the later ob query calls which will increment
            //  its value.  We can't pass the users return length directly
            //  because the user might also be altering its value behind
            //  our back.
            //

            if (ARGUMENT_PRESENT( ReturnLength )) {

                ProbeForWriteUlong( ReturnLength );
            }

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            return( GetExceptionCode() );
        }
    }

    //
    //  If the query is not for types information then we
    //  will have to get the object in question. Otherwise
    //  for types information there really isn't an object
    //  to grab.
    //

    if (ObjectInformationClass != ObjectTypesInformation) {

        Status = ObReferenceObjectByHandle( Handle,
                                            0,
                                            NULL,
                                            PreviousMode,
                                            &Object,
                                            &HandleInformation );

        if (!NT_SUCCESS( Status )) {

            return( Status );
        }

        GrantedAccess = HandleInformation.GrantedAccess;

        ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
        ObjectType = ObjectHeader->Type;

    } else {

        GrantedAccess = 0;
        Object = NULL;
        ObjectHeader = NULL;
        ObjectType = NULL;
        Status = STATUS_SUCCESS;
    }

    //
    //  Now process the particular information class being
    //  requested
    //

    switch( ObjectInformationClass ) {

    case ObjectBasicInformation:

        //
        //  Make sure the output buffer is long enough and then
        //  fill in the appropriate fields into our local copy
        //  of basic information.
        //

        if (ObjectInformationLength != sizeof( OBJECT_BASIC_INFORMATION )) {

            ObDereferenceObject( Object );

            return( STATUS_INFO_LENGTH_MISMATCH );
        }

        ObjectBasicInfo.Attributes = HandleInformation.HandleAttributes;

        if (ObjectHeader->Flags & OB_FLAG_PERMANENT_OBJECT) {

            ObjectBasicInfo.Attributes |= OBJ_PERMANENT;
        }

        if (ObjectHeader->Flags & OB_FLAG_EXCLUSIVE_OBJECT) {

            ObjectBasicInfo.Attributes |= OBJ_EXCLUSIVE;
        }

        ObjectBasicInfo.GrantedAccess = GrantedAccess;
        ObjectBasicInfo.HandleCount = (ULONG)ObjectHeader->HandleCount;
        ObjectBasicInfo.PointerCount = (ULONG)ObjectHeader->PointerCount;

        QuotaInfo = OBJECT_HEADER_TO_QUOTA_INFO( ObjectHeader );

        if (QuotaInfo != NULL) {

            ObjectBasicInfo.PagedPoolCharge = QuotaInfo->PagedPoolCharge;
            ObjectBasicInfo.NonPagedPoolCharge = QuotaInfo->NonPagedPoolCharge;

        } else {

            ObjectBasicInfo.PagedPoolCharge = 0;
            ObjectBasicInfo.NonPagedPoolCharge = 0;
        }

        if (ObjectType == ObpSymbolicLinkObjectType) {

            ObjectBasicInfo.CreationTime = ((POBJECT_SYMBOLIC_LINK)Object)->CreationTime;

        } else {

            RtlZeroMemory( &ObjectBasicInfo.CreationTime,
                           sizeof( ObjectBasicInfo.CreationTime ));
        }

        //
        //  Compute the size of the object name string by taking its name plus
        //  seperators and traversing up to the root adding each directories
        //  name length plus seperators
        //

        NameInfo = ObpReferenceNameInfo( ObjectHeader );

        if ((NameInfo != NULL) && (NameInfo->Directory != NULL)) {

            PVOID ReferencedDirectory = NULL;
        
            //
            //  We grab the root directory lock and test again the directory
            //

            ObjectDirectory = NameInfo->Directory;

            ASSERT (ObjectDirectory);

            ObfReferenceObject( ObjectDirectory );
            ReferencedDirectory = ObjectDirectory;

            NameInfoSize = sizeof( OBJ_NAME_PATH_SEPARATOR ) + NameInfo->Name.Length;

            ObpDereferenceNameInfo( NameInfo );
            NameInfo = NULL;

            while (ObjectDirectory) {

                ObjectDirectoryHeader = OBJECT_TO_OBJECT_HEADER( ObjectDirectory );
                NameInfo = ObpReferenceNameInfo( ObjectDirectoryHeader );

                if ((NameInfo != NULL) && (NameInfo->Directory != NULL)) {

                    NameInfoSize += sizeof( OBJ_NAME_PATH_SEPARATOR ) + NameInfo->Name.Length;
                        
                    ObjectDirectory = NameInfo->Directory;

                    ObfReferenceObject( ObjectDirectory );
                        
                    ObpDereferenceNameInfo( NameInfo );
                    NameInfo = NULL;
                    ObDereferenceObject( ReferencedDirectory );
                    ReferencedDirectory = ObjectDirectory;

                } else {

                    break;
                }
            }

            if (ReferencedDirectory) {

                ObDereferenceObject( ReferencedDirectory );
            }

            NameInfoSize += sizeof( OBJECT_NAME_INFORMATION ) + sizeof( UNICODE_NULL );

        } else {

            NameInfoSize = 0;
        }

        ObpDereferenceNameInfo( NameInfo );
        NameInfo = NULL;

        ObjectBasicInfo.NameInfoSize = NameInfoSize;
        ObjectBasicInfo.TypeInfoSize = ObjectType->Name.Length + sizeof( UNICODE_NULL ) +
                                        sizeof( OBJECT_TYPE_INFORMATION );
        
        if ((GrantedAccess & READ_CONTROL) &&
            ARGUMENT_PRESENT( ObjectHeader->SecurityDescriptor )) {

            SECURITY_INFORMATION SecurityInformation;

            //
            //  Request a complete security descriptor
            //

            SecurityInformation = OWNER_SECURITY_INFORMATION |
                                  GROUP_SECURITY_INFORMATION |
                                  DACL_SECURITY_INFORMATION  |
                                  SACL_SECURITY_INFORMATION;
            
            SecurityDescriptorSize = 0;

            (ObjectType->TypeInfo.SecurityProcedure)( Object,
                                                      QuerySecurityDescriptor,
                                                      &SecurityInformation,
                                                      NULL,
                                                      &SecurityDescriptorSize,
                                                      &ObjectHeader->SecurityDescriptor,
                                                      ObjectType->TypeInfo.PoolType,
                                                      &ObjectType->TypeInfo.GenericMapping );

        } else {

            SecurityDescriptorSize = 0;
        }

        ObjectBasicInfo.SecurityDescriptorSize = SecurityDescriptorSize;

        //
        //  Now that we've packaged up our local copy of basic info we need
        //  to copy it into the output buffer and set the return
        //  length
        //

        try {

            *(POBJECT_BASIC_INFORMATION) ObjectInformation = ObjectBasicInfo;

            TempReturnLength = ObjectInformationLength;

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            //
            // Fall through, since we cannot undo what we have done.
            //
        }

        break;

    case ObjectNameInformation:

        //
        //  Call a local worker routine
        //

        Status = ObpQueryNameString( Object,
                                     (POBJECT_NAME_INFORMATION)ObjectInformation,
                                     ObjectInformationLength,
                                     &TempReturnLength,
                                     PreviousMode );
        break;

    case ObjectTypeInformation:

        //
        //  Call a local worker routine
        //

        Status = ObQueryTypeInfo( ObjectType,
                                  (POBJECT_TYPE_INFORMATION)ObjectInformation,
                                  ObjectInformationLength,
                                  &TempReturnLength );
        break;

    case ObjectTypesInformation:

        try {

            //
            //  The first thing we do is set the return length to cover the
            //  types info record.  Later in each call to query type info
            //  this value will be updated as necessary
            //

            TempReturnLength = sizeof( OBJECT_TYPES_INFORMATION );

            //
            //  Make sure there is enough room to hold the types info record
            //  and if so then compute the number of defined types there are
            //

            TypesInformation = (POBJECT_TYPES_INFORMATION)ObjectInformation;

            if (ObjectInformationLength < sizeof( OBJECT_TYPES_INFORMATION ) ) {

                Status = STATUS_INFO_LENGTH_MISMATCH;

            } else {

                TypesInformation->NumberOfTypes = 0;

                for (i=0; i<OBP_MAX_DEFINED_OBJECT_TYPES; i++) {

                    ObjectType = ObpObjectTypes[ i ];

                    if (ObjectType == NULL) {

                        break;
                    }

                    TypesInformation->NumberOfTypes += 1;
                }
            }

            //
            //  For each defined type we will query the type info for the
            //  object type and adjust the TypeInfo pointer to the next
            //  free spot
            //

            TypeInfo = (POBJECT_TYPE_INFORMATION)(((PUCHAR)TypesInformation) + ALIGN_UP( sizeof(*TypesInformation), ULONG_PTR ));

            for (i=0; i<OBP_MAX_DEFINED_OBJECT_TYPES; i++) {

                ObjectType = ObpObjectTypes[ i ];

                if (ObjectType == NULL) {

                    break;
                }

                Status = ObQueryTypeInfo( ObjectType,
                                          TypeInfo,
                                          ObjectInformationLength,
                                          &TempReturnLength );

                if (NT_SUCCESS( Status )) {

                    TypeInfo = (POBJECT_TYPE_INFORMATION)
                        ((PCHAR)(TypeInfo+1) + ALIGN_UP( TypeInfo->TypeName.MaximumLength, ULONG_PTR ));
                }
            }

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            Status = GetExceptionCode();
        }

        break;

    case ObjectHandleFlagInformation:

        try {

            //
            //  Set the amount of data we are going to return
            //

            TempReturnLength = sizeof(OBJECT_HANDLE_FLAG_INFORMATION);

            HandleFlags = (POBJECT_HANDLE_FLAG_INFORMATION)ObjectInformation;

            //
            //  Make sure we have enough room for the query, and if so we'll
            //  set the output based on the flags stored in the handle
            //

            if (ObjectInformationLength < sizeof( OBJECT_HANDLE_FLAG_INFORMATION)) {

                Status = STATUS_INFO_LENGTH_MISMATCH;

            } else {

                HandleFlags->Inherit = FALSE;

                if (HandleInformation.HandleAttributes & OBJ_INHERIT) {

                    HandleFlags->Inherit = TRUE;
                }

                HandleFlags->ProtectFromClose = FALSE;

                if (HandleInformation.HandleAttributes & OBJ_PROTECT_CLOSE) {

                    HandleFlags->ProtectFromClose = TRUE;
                }
            }

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            Status = GetExceptionCode();
        }

        break;

    default:

        //
        //  To get to this point we must have had an object and the
        //  information class is not defined, so we should dereference the
        //  object and return to our user the bad status
        //

        ObDereferenceObject( Object );

        return( STATUS_INVALID_INFO_CLASS );
    }

    //
    //  Now if the caller asked for a return length we'll set it from
    //  our local copy
    //

    try {

        if (ARGUMENT_PRESENT( ReturnLength ) ) {

            *ReturnLength = TempReturnLength;
        }

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        //
        //  Fall through, since we cannot undo what we have done.
        //
    }

    //
    //  In the end we can free the object if there was one and return
    //  to our caller
    //

    if (Object != NULL) {

        ObDereferenceObject( Object );
    }

    return( Status );
}

NTSTATUS
ObSetHandleAttributes (
    IN HANDLE Handle,
    IN POBJECT_HANDLE_FLAG_INFORMATION HandleFlags,
    IN KPROCESSOR_MODE PreviousMode
    )
{
    BOOLEAN AttachedToProcess = FALSE;
    KAPC_STATE ApcState;
    OBP_SET_HANDLE_ATTRIBUTES CapturedInformation;
    PVOID ObjectTable;
    HANDLE ObjectHandle;
    NTSTATUS Status;

    PAGED_CODE();

    CapturedInformation.PreviousMode = PreviousMode;
    CapturedInformation.ObjectInformation = *HandleFlags;

    //
    //  Get the address of the object table for the current process.  Or
    //  get the system handle table if this is a kernel handle and we are
    //  in kernel mode
    //

    if (IsKernelHandle( Handle, PreviousMode )) {

        //
        //  Make the handle look like a regular handle
        //

        ObjectHandle = DecodeKernelHandle( Handle );

        //
        //  The global kernel handle table
        //

        ObjectTable = ObpKernelHandleTable;

        //
        //  Go to the system process
        //

        if (PsGetCurrentProcess() != PsInitialSystemProcess) {
            KeStackAttachProcess (&PsInitialSystemProcess->Pcb, &ApcState);
            AttachedToProcess = TRUE;
        }

    } else {

        ObjectTable = ObpGetObjectTable();
        ObjectHandle = Handle;
    }

    //
    //  Make the change to the handle table entry.  The callback
    //  routine will do the actual change
    //

    if (ExChangeHandle( ObjectTable,
                        ObjectHandle,
                        ObpSetHandleAttributes,
                        (ULONG_PTR)&CapturedInformation) ) {

        Status = STATUS_SUCCESS;

    } else {

        Status = STATUS_ACCESS_DENIED;
    }

    //
    //  If we are attached to the system process then return
    //  back to our caller
    //

    if (AttachedToProcess) {
        KeUnstackDetachProcess(&ApcState);
        AttachedToProcess = FALSE;
    }
    return Status;
}


NTSTATUS
NTAPI
NtSetInformationObject (
    IN HANDLE Handle,
    IN OBJECT_INFORMATION_CLASS ObjectInformationClass,
    IN PVOID ObjectInformation,
    IN ULONG ObjectInformationLength
    )

/*++

Routine description:

    This routine is used to set handle information about a specified
    handle

Arguments:

    Handle - Supplies the handle being modified

    ObjectInformationClass - Specifies the class of information being
        modified.  The only accepted value is ObjectHandleFlagInformation

    ObjectInformation - Supplies the buffer containing the handle
        flag information structure

    ObjectInformationLength - Specifies the length, in bytes, of the
        object information buffer

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status;
    OBJECT_HANDLE_FLAG_INFORMATION CapturedFlags;
    KPROCESSOR_MODE PreviousMode;

    PAGED_CODE();


    Status = STATUS_INVALID_INFO_CLASS;

    switch (ObjectInformationClass) {
         
        case ObjectHandleFlagInformation:
            {
                if (ObjectInformationLength != sizeof(OBJECT_HANDLE_FLAG_INFORMATION)) {

                    return STATUS_INFO_LENGTH_MISMATCH;
                }

                //
                //  Get previous processor mode and probe and capture the input
                //  buffer
                //

                PreviousMode = KeGetPreviousMode();

                try {

                    if (PreviousMode != KernelMode) {

                        ProbeForRead(ObjectInformation, ObjectInformationLength, 1);
                    }

                    CapturedFlags = *(POBJECT_HANDLE_FLAG_INFORMATION)ObjectInformation;

                } except(ExSystemExceptionFilter()) {

                    return GetExceptionCode();
                }

                Status = ObSetHandleAttributes (Handle,
                                                &CapturedFlags,
                                                PreviousMode);

            }

            break;
        
        case ObjectSessionInformation:
            {
                PreviousMode = KeGetPreviousMode();

                if (!SeSinglePrivilegeCheck( SeTcbPrivilege,
                                             PreviousMode)) {

                    Status = STATUS_PRIVILEGE_NOT_HELD;

                } else {
                    
                    PVOID Object;
                    OBJECT_HANDLE_INFORMATION HandleInformation;

                    Status = ObReferenceObjectByHandle(Handle, 
                                                       0, 
                                                       ObpDirectoryObjectType,
                                                       PreviousMode,
                                                       &Object,
                                                       &HandleInformation
                                                       );

                    if (NT_SUCCESS(Status)) {

                        POBJECT_DIRECTORY Directory;
                        OBP_LOOKUP_CONTEXT LockContext;
                        Directory = (POBJECT_DIRECTORY)Object;

                        ObpInitializeLookupContext( &LockContext );
                        
                        ObpLockDirectoryExclusive(Directory, &LockContext);

                        Directory->SessionId = PsGetCurrentProcessSessionId();

                        ObpUnlockDirectory(Directory, &LockContext);

                        ObDereferenceObject(Object);
                    }
                }
            }

            break;
    }

    //
    //  And return to our caller
    //

    return Status;
}


#define OBP_MISSING_NAME_LITERAL L"..."
#define OBP_MISSING_NAME_LITERAL_SIZE (sizeof( OBP_MISSING_NAME_LITERAL ) - sizeof( UNICODE_NULL ))

NTSTATUS
ObQueryNameString (
    IN PVOID Object,
    OUT POBJECT_NAME_INFORMATION ObjectNameInfo,
    IN ULONG Length,
    OUT PULONG ReturnLength
    )
/*++

Routine description:

    This routine processes a query of an object's name information

Arguments:

    Object - Supplies the object being queried

    ObjectNameInfo - Supplies the buffer to store the name string
        information

    Length - Specifies the length, in bytes, of the original object
        name info buffer.

    ReturnLength - Contains the number of bytes already used up
        in the object name info. On return this receives an updated
        byte count.

        (Length minus ReturnLength) is really now many bytes are left
        in the output buffer.  The buffer supplied to this call may
        actually be offset within the original users buffer

Return Value:

    An appropriate status value

--*/

{
    return ObpQueryNameString( Object,
                               ObjectNameInfo,
                               Length,
                               ReturnLength,
                               KernelMode );
}

NTSTATUS
ObpQueryNameString (
    IN PVOID Object,
    OUT POBJECT_NAME_INFORMATION ObjectNameInfo,
    IN ULONG Length,
    OUT PULONG ReturnLength,
    IN KPROCESSOR_MODE Mode
    )

/*++

Routine description:

    This routine processes a query of an object's name information

Arguments:

    Object - Supplies the object being queried

    ObjectNameInfo - Supplies the buffer to store the name string
        information

    Length - Specifies the length, in bytes, of the original object
        name info buffer.

    ReturnLength - Contains the number of bytes already used up
        in the object name info. On return this receives an updated
        byte count.

        (Length minus ReturnLength) is really now many bytes are left
        in the output buffer.  The buffer supplied to this call may
        actually be offset within the original users buffer

    Mode - Mode of caller

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status = STATUS_UNSUCCESSFUL;
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;
    POBJECT_HEADER ObjectDirectoryHeader;
    POBJECT_DIRECTORY ObjectDirectory;
    ULONG NameInfoSize = 0;
    PUNICODE_STRING String;
    PWCH StringBuffer;
    ULONG NameSize;
    PVOID ReferencedObject = NULL;
    BOOLEAN DoFullQuery = TRUE;
    ULONG BufferLength;
    PWCH OriginalBuffer;
    BOOLEAN ForceRetry = FALSE;

    PAGED_CODE();

    //
    //  Get the object header and name info record if it exists
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    NameInfo = ObpReferenceNameInfo( ObjectHeader );

    //
    //  If the object type has a query name callback routine then
    //  that is how we get the name
    //

    if (ObjectHeader->Type->TypeInfo.QueryNameProcedure != NULL) {

        try {

#if DBG
            KIRQL SaveIrql;
#endif

            ObpBeginTypeSpecificCallOut( SaveIrql );
            ObpEndTypeSpecificCallOut( SaveIrql, "Query", ObjectHeader->Type, Object );

            Status = (*ObjectHeader->Type->TypeInfo.QueryNameProcedure)( Object,
                                                                         (BOOLEAN)((NameInfo != NULL) && (NameInfo->Name.Length != 0)),
                                                                         ObjectNameInfo,
                                                                         Length,
                                                                         ReturnLength,
                                                                         Mode );

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            Status = GetExceptionCode();
        }

        ObpDereferenceNameInfo( NameInfo );

        return( Status );
    }

    //
    //  Otherwise, the object type does not specify a query name
    //  procedure so we get to do the work.  The first thing
    //  to check is if the object doesn't even have a name.  If
    //  object doesn't have a name then we'll return an empty name
    //  info structure.
    //

RETRY:
    if ((NameInfo == NULL) || (NameInfo->Name.Buffer == NULL)) {

        //
        //  Compute the length of our return buffer, set the output
        //  if necessary and make sure the supplied buffer is large
        //  enough
        //

        NameInfoSize = sizeof( OBJECT_NAME_INFORMATION );

        try {

            *ReturnLength = NameInfoSize;

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            ObpDereferenceNameInfo( NameInfo );

            return( GetExceptionCode() );
        }

        if (Length < NameInfoSize) {

            ObpDereferenceNameInfo( NameInfo );

            return( STATUS_INFO_LENGTH_MISMATCH );
        }

        //
        //  Initialize the output buffer to be an empty string
        //  and then return to our caller
        //

        try {

            ObjectNameInfo->Name.Length = 0;
            ObjectNameInfo->Name.MaximumLength = 0;
            ObjectNameInfo->Name.Buffer = NULL;

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            //
            //  Fall through, since we cannot undo what we have done.
            //
            ObpDereferenceNameInfo(NameInfo);

            return( GetExceptionCode() );
        }

        ObpDereferenceNameInfo(NameInfo);

        return( STATUS_SUCCESS );
    }

    try {

        //
        //  The object does have a name but now see if this is
        //  just the root directory object in which case the name size
        //  is only the "\" character
        //

        if (Object == ObpRootDirectoryObject) {

            NameSize = sizeof( OBJ_NAME_PATH_SEPARATOR );

        } else {

            //
            //  The named object is not the root so for every directory
            //  working out way up we'll add its size to the name keeping
            //  track of "\" characters inbetween each component.  We first
            //  start with the object name itself and then move on to
            //  the directories
            //

            ObjectDirectory = NameInfo->Directory;
            
            if (ObjectDirectory) {
                
                ObfReferenceObject( ObjectDirectory );
                ReferencedObject = ObjectDirectory;
            }
            
            NameSize = sizeof( OBJ_NAME_PATH_SEPARATOR ) + NameInfo->Name.Length;

            ObpDereferenceNameInfo( NameInfo );
            NameInfo = NULL;

            //
            //  While we are not at the root we'll keep moving up
            //

            while ((ObjectDirectory != ObpRootDirectoryObject) && (ObjectDirectory)) {

                //
                //  Get the name information for this directory
                //


                ObjectDirectoryHeader = OBJECT_TO_OBJECT_HEADER( ObjectDirectory );
                NameInfo = ObpReferenceNameInfo( ObjectDirectoryHeader );

                if ((NameInfo != NULL) && (NameInfo->Directory != NULL)) {

                    //
                    //  This directory has a name so add it to the accumulated
                    //  size and move up the tree
                    //

                    NameSize += sizeof( OBJ_NAME_PATH_SEPARATOR ) + NameInfo->Name.Length;
                    
                    ObjectDirectory = NameInfo->Directory;

                    if (ObjectDirectory) {

                        ObfReferenceObject( ObjectDirectory );
                    }
                    
                    ObpDereferenceNameInfo( NameInfo );
                    NameInfo = NULL;
                    ObDereferenceObject( ReferencedObject );
                    
                    ReferencedObject = ObjectDirectory;

                    //
                    //  UNICODE_STRINGs can only hold MAXUSHORT bytes.
                    //

                    if (NameSize > MAXUSHORT) {

                        break;
                    }

                } else {

                    //
                    //  This directory does not have a name so we'll give it
                    //  the "..." name and stop the loop
                    //

                    NameSize += sizeof( OBJ_NAME_PATH_SEPARATOR ) + OBP_MISSING_NAME_LITERAL_SIZE;
                    break;
                }
            }
        }

        //
        //  UNICODE_STRINGs can only hold MAXUSHORT bytes
        //

        if (NameSize > MAXUSHORT) {

            Status = STATUS_NAME_TOO_LONG;
            DoFullQuery = FALSE;
            leave;
        }

        //
        //  At this point NameSize is the number of bytes we need to store the
        //  name of the object from the root down.  The total buffer size we are
        //  going to need will include this size, plus object name information
        //  structure, plus an ending null character
        //

        NameInfoSize = NameSize + sizeof( OBJECT_NAME_INFORMATION ) + sizeof( UNICODE_NULL );

        //
        //  Set the output size and make sure the supplied buffer is large enough
        //  to hold the information
        //

        try {

            *ReturnLength = NameInfoSize;

        } except( EXCEPTION_EXECUTE_HANDLER ) {

            Status = GetExceptionCode();
            DoFullQuery = FALSE;
            leave;
        }

        if (Length < NameInfoSize) {

            Status = STATUS_INFO_LENGTH_MISMATCH;
            DoFullQuery = FALSE;
            leave;
        }

    } finally {

        ObpDereferenceNameInfo( NameInfo );
        NameInfo = NULL;

        if (ReferencedObject) {

            ObDereferenceObject( ReferencedObject );
            ReferencedObject = NULL;
        }
    }
    
    if (!DoFullQuery) {

        return Status;
    }

    NameInfo = ObpReferenceNameInfo( ObjectHeader );

    //
    //  Check whether someone else removed the name meanwhile
    //

    if (!NameInfo) {

        //
        //  The name is gone, we need to jump to the code path that handles
        //  empty object name
        //

        goto RETRY;
    }

    //
    //  Set the String buffer to point to the byte right after the
    //  last byte in the output string.  This following logic actually
    //  fills in the buffer backwards working from the name back to the
    //  root
    //

    StringBuffer = (PWCH)ObjectNameInfo;
    StringBuffer = (PWCH)((PCH)StringBuffer + NameInfoSize);
    OriginalBuffer = (PWCH)((PCH)ObjectNameInfo + sizeof( OBJECT_NAME_INFORMATION ));

    try {

        //
        //  Terminate the string with a null and backup one unicode
        //  character
        //

        *--StringBuffer = UNICODE_NULL;

        //
        //  If the object in question is not the root directory
        //  then we are going to put its name in the string buffer
        //  When we finally reach the root directory we'll append on
        //  the final "\"
        //

        if (Object != ObpRootDirectoryObject) {

            //
            //  Add in the objects name
            //

            String = &NameInfo->Name;
            StringBuffer = (PWCH)((PCH)StringBuffer - String->Length);

            if (StringBuffer <= OriginalBuffer) {

                ForceRetry = TRUE;
                leave;
            }

            RtlCopyMemory( StringBuffer, String->Buffer, String->Length );

            //
            //  While we are not at the root directory we'll keep
            //  moving up
            //

            ObjectDirectory = NameInfo->Directory;

            if (ObjectDirectory) {

                //
                //  Reference the directory for this object to make sure it's
                //  valid while looking up
                //

                ObfReferenceObject( ObjectDirectory );
                ReferencedObject = ObjectDirectory;
            }
                
            ObpDereferenceNameInfo( NameInfo );
            NameInfo = NULL;

            while ((ObjectDirectory != ObpRootDirectoryObject) && (ObjectDirectory)) {

                //
                //  Get the name information for this directory
                //

                ObjectDirectoryHeader = OBJECT_TO_OBJECT_HEADER( ObjectDirectory );
                NameInfo = ObpReferenceNameInfo( ObjectDirectoryHeader );

                //
                //  Tack on the "\" between the last name we added and
                //  this new name
                //

                *--StringBuffer = OBJ_NAME_PATH_SEPARATOR;

                //
                //  Preappend the directory name, if it has one, and
                //  move up to the next directory.
                //

                if ((NameInfo != NULL) && (NameInfo->Directory != NULL)) {

                    String = &NameInfo->Name;
                    StringBuffer = (PWCH)((PCH)StringBuffer - String->Length);
                    
                    if (StringBuffer <= OriginalBuffer) {
                        
                        ForceRetry = TRUE;
                        leave;
                    }

                    RtlCopyMemory( StringBuffer, String->Buffer, String->Length );

                    ObjectDirectory = NameInfo->Directory;

                    if (ObjectDirectory) {

                        ObfReferenceObject( ObjectDirectory );
                    }

                    //
                    //  Dereference the name info (it must be done before dereferencing the object)
                    //

                    ObpDereferenceNameInfo( NameInfo );
                    NameInfo = NULL;

                    ObDereferenceObject( ReferencedObject );

                    ReferencedObject = ObjectDirectory;

                } else {

                    //
                    //  The directory is nameless so use the "..." for
                    //  its name and break out of the loop
                    //

                    StringBuffer = (PWCH)((PCH)StringBuffer - OBP_MISSING_NAME_LITERAL_SIZE);

                    //
                    //  Because we don't hold the global lock any more, we can have a special case
                    //  where a directory of 1 or 2 letters name AND inserted into the root
                    //  can go away meanwhile and "..." will be too long to fit the remaining space
                    //  We already copied the buffer so we cannot rollback everything we done.
                    //  We'll return \..  if the original directory was 1 char length,
                    //  \..\ for 2 char length
                    //

                    if (StringBuffer < OriginalBuffer) {

                        StringBuffer = OriginalBuffer;
                    }

                    RtlCopyMemory( StringBuffer,
                                   OBP_MISSING_NAME_LITERAL,
                                   OBP_MISSING_NAME_LITERAL_SIZE );

                    //
                    //  Test if we are in the case commented above. If yes, we need to move the 
                    //  current pointer to the next char, so the final assignment for \ a few lines
                    //  below will take effect on the start of the block.
                    //

                    if (StringBuffer == OriginalBuffer) {

                        StringBuffer++;
                    }

                    break;
                }
            }
        }

        //
        //  Tack on the "\" for the root directory and then set the
        //  output unicode string variable to have the right size
        //  and point to the right spot.
        //

        *--StringBuffer = OBJ_NAME_PATH_SEPARATOR;

        BufferLength = (USHORT)((ULONG_PTR)ObjectNameInfo + NameInfoSize - (ULONG_PTR)StringBuffer);

        ObjectNameInfo->Name.MaximumLength = (USHORT)BufferLength;
        ObjectNameInfo->Name.Length = (USHORT)(BufferLength - sizeof( UNICODE_NULL ));
        ObjectNameInfo->Name.Buffer = OriginalBuffer;

        //
        //  If one of the parent directories disappeared, the final length
        //  will be smaller than we estimated before. We need to move the string to
        //  the beginning and adjust the returned size.
        //

        if (OriginalBuffer != StringBuffer) {

            RtlMoveMemory(OriginalBuffer, StringBuffer, BufferLength);
            
            *ReturnLength = BufferLength + sizeof( OBJECT_NAME_INFORMATION );
        }

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        //
        //  Fall through, since we cannot undo what we have done.
        //
        //  This should probably get the exception code and return
        //  that value. However, the caller we'll get an exception
        //  at the first access of the ObjectNameInfo
        //
    }

    ObpDereferenceNameInfo( NameInfo );
    
    if (ReferencedObject) {

        ObDereferenceObject( ReferencedObject );
    }

    if (ForceRetry) {

        //
        //  The query failed maybe because the object name changed during the query
        //
        
        NameInfo = ObpReferenceNameInfo( ObjectHeader );
        ForceRetry = FALSE;

        goto RETRY;
    }

    return STATUS_SUCCESS;
}



NTSTATUS
ObQueryTypeName (
    IN PVOID Object,
    PUNICODE_STRING ObjectTypeName,
    IN ULONG Length,
    OUT PULONG ReturnLength
    )

/*++

Routine description:

    This routine processes a query of an object's type name

Arguments:

    Object - Supplies the object being queried

    ObjectTypeName - Supplies the buffer to store the type name
        string information

    Length - Specifies the length, in bytes, of the object type
        name buffer

    ReturnLength - Contains the number of bytes already used up
        in the object type name buffer. On return this receives
        an updated byte count

        (Length minus ReturnLength) is really now many bytes are left
        in the output buffer.  The buffer supplied to this call may
        actually be offset within the original users buffer

Return Value:

    An appropriate status value

--*/

{
    POBJECT_TYPE ObjectType;
    POBJECT_HEADER ObjectHeader;
    ULONG TypeNameSize;
    PUNICODE_STRING String;
    PWCH StringBuffer;
    ULONG NameSize;

    PAGED_CODE();

    //
    //  From the object get its object type and from that get the size of
    //  the object type name.  The total size for we need for the output
    //  buffer must fit the name, a terminating null, and a preceding
    //  unicode string structure
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;

    NameSize = ObjectType->Name.Length;
    TypeNameSize = NameSize + sizeof( UNICODE_NULL ) + sizeof( UNICODE_STRING );

    //
    //  Update the number of bytes we need and make sure the output buffer is
    //  large enough
    //

    try {

        *ReturnLength = TypeNameSize;

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        return( GetExceptionCode() );
    }

    if (Length < TypeNameSize) {

        return( STATUS_INFO_LENGTH_MISMATCH );
    }

    //
    //  Set string buffer to point to the one byte beyond the
    //  buffer that we're going to fill in
    //

    StringBuffer = (PWCH)ObjectTypeName;
    StringBuffer = (PWCH)((PCH)StringBuffer + TypeNameSize);

    String = &ObjectType->Name;

    try {

        //
        //  Tack on the terminating null character and copy over
        //  the type name
        //

        *--StringBuffer = UNICODE_NULL;

        StringBuffer = (PWCH)((PCH)StringBuffer - String->Length);

        RtlCopyMemory( StringBuffer, String->Buffer, String->Length );

        //
        //  Now set the preceding unicode string to have the right
        //  lengths and to point to this buffer
        //

        ObjectTypeName->Length = (USHORT)NameSize;
        ObjectTypeName->MaximumLength = (USHORT)(NameSize+sizeof( UNICODE_NULL ));
        ObjectTypeName->Buffer = StringBuffer;

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        //
        // Fall through, since we cannot undo what we have done.
        //
    }

    return( STATUS_SUCCESS );
}


NTSTATUS
ObQueryTypeInfo (
    IN POBJECT_TYPE ObjectType,
    OUT POBJECT_TYPE_INFORMATION ObjectTypeInfo,
    IN ULONG Length,
    OUT PULONG ReturnLength
    )

/*++

Routine description:

    This routine processes the query for object type information

Arguments:

    Object - Supplies a pointer to the object type being queried

    ObjectTypeInfo - Supplies the buffer to store the type information

    Length - Specifies the length, in bytes, of the object type
        information buffer

    ReturnLength - Contains the number of bytes already used up
        in the object type information buffer. On return this receives
        an updated byte count

        (Length minus ReturnLength) is really now many bytes are left
        in the output buffer.  The buffer supplied to this call may
        actually be offset within the original users buffer

Return Value:

    An appropriate status value

--*/

{
    NTSTATUS Status;

    try {

        //
        //  The total number of bytes needed for this query includes the
        //  object type information structure plus the name of the type
        //  rounded up to a ulong boundary
        //

        *ReturnLength += sizeof( *ObjectTypeInfo ) + ALIGN_UP( ObjectType->Name.MaximumLength, ULONG );

        //
        //  Make sure the buffer is large enough for this information and
        //  then fill in the record
        //

        if (Length < *ReturnLength) {

            Status = STATUS_INFO_LENGTH_MISMATCH;

        } else {

            ObjectTypeInfo->TotalNumberOfObjects = ObjectType->TotalNumberOfObjects;
            ObjectTypeInfo->TotalNumberOfHandles = ObjectType->TotalNumberOfHandles;
            ObjectTypeInfo->HighWaterNumberOfObjects = ObjectType->HighWaterNumberOfObjects;
            ObjectTypeInfo->HighWaterNumberOfHandles = ObjectType->HighWaterNumberOfHandles;
            ObjectTypeInfo->InvalidAttributes = ObjectType->TypeInfo.InvalidAttributes;
            ObjectTypeInfo->GenericMapping = ObjectType->TypeInfo.GenericMapping;
            ObjectTypeInfo->ValidAccessMask = ObjectType->TypeInfo.ValidAccessMask;
            ObjectTypeInfo->SecurityRequired = ObjectType->TypeInfo.SecurityRequired;
            ObjectTypeInfo->MaintainHandleCount = ObjectType->TypeInfo.MaintainHandleCount;
            ObjectTypeInfo->PoolType = ObjectType->TypeInfo.PoolType;
            ObjectTypeInfo->DefaultPagedPoolCharge = ObjectType->TypeInfo.DefaultPagedPoolCharge;
            ObjectTypeInfo->DefaultNonPagedPoolCharge = ObjectType->TypeInfo.DefaultNonPagedPoolCharge;

            //
            //  The type name goes right after this structure.  We cannot use
            //  rtl routine like RtlCopyUnicodeString that might use the local
            //  memory to keep state, because this is the user buffer and it
            //  could be changing by user
            //

            ObjectTypeInfo->TypeName.Buffer = (PWSTR)(ObjectTypeInfo+1);
            ObjectTypeInfo->TypeName.Length = ObjectType->Name.Length;
            ObjectTypeInfo->TypeName.MaximumLength = ObjectType->Name.MaximumLength;

            RtlCopyMemory( (PWSTR)(ObjectTypeInfo+1),
                           ObjectType->Name.Buffer,
                           ObjectType->Name.Length );

            ((PWSTR)(ObjectTypeInfo+1))[ ObjectType->Name.Length/sizeof(WCHAR) ] = UNICODE_NULL;

            Status = STATUS_SUCCESS;
        }

    } except( EXCEPTION_EXECUTE_HANDLER ) {

        Status = GetExceptionCode();
    }

    return Status;
}


NTSTATUS
ObQueryObjectAuditingByHandle (
    IN HANDLE Handle,
    OUT PBOOLEAN GenerateOnClose
    )

/*++

Routine description:

    This routine tells the caller if the indicated handle will
    generate an audit if it is closed

Arguments:

    Handle - Supplies the handle being queried

    GenerateOnClose - Receives TRUE if the handle will generate
        an audit if closed and FALSE otherwise

Return Value:

    An appropriate status value

--*/

{
    PHANDLE_TABLE ObjectTable;
    PHANDLE_TABLE_ENTRY ObjectTableEntry;
    ULONG CapturedAttributes;
    NTSTATUS Status;
    PETHREAD CurrentThread;

    PAGED_CODE();

    ObpValidateIrql( "ObQueryObjectAuditingByHandle" );

    CurrentThread = PsGetCurrentThread ();

    //
    //  For the current process we'll grab its object table and
    //  then get the object table entry
    //

    if (IsKernelHandle( Handle, KeGetPreviousMode() ))  {

        Handle = DecodeKernelHandle( Handle );

        ObjectTable = ObpKernelHandleTable;

    } else {

        ObjectTable = PsGetCurrentProcessByThread (CurrentThread)->ObjectTable;
    }

    //
    //  Protect ourselves from being interrupted while we hold a handle table
    //  entry lock
    //

    KeEnterCriticalRegionThread(&CurrentThread->Tcb);

    ObjectTableEntry = ExMapHandleToPointer( ObjectTable,
                                             Handle );

    //
    //  If we were given a valid handle we'll look at the attributes
    //  stored in the object table entry to decide if we generate
    //  an audit on close
    //

    if (ObjectTableEntry != NULL) {

        CapturedAttributes = ObjectTableEntry->ObAttributes;

        ExUnlockHandleTableEntry( ObjectTable, ObjectTableEntry );

        if (CapturedAttributes & OBJ_AUDIT_OBJECT_CLOSE) {

            *GenerateOnClose = TRUE;

        } else {

            *GenerateOnClose = FALSE;
        }

        Status = STATUS_SUCCESS;

    } else {

        Status = STATUS_INVALID_HANDLE;
    }

    KeLeaveCriticalRegionThread(&CurrentThread->Tcb);

    return Status;
}


#if DBG
PUNICODE_STRING
ObGetObjectName (
    IN PVOID Object
    )

/*++

Routine description:

    This routine returns a pointer to the name of object

Arguments:

    Object - Supplies the object being queried

Return Value:

    The address of the unicode string that stores the object
    name if available and NULL otherwise

--*/

{
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;

    //
    //  Translate the input object to a name info structure
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

    //
    //  If the object has a name then return the address of
    //  the name otherwise return null
    //

    if ((NameInfo != NULL) && (NameInfo->Name.Length != 0)) {

        return &NameInfo->Name;

    } else {

        return NULL;
    }
}
#endif // DBG


//
//  Local support routine
//

BOOLEAN
ObpSetHandleAttributes (
    IN OUT PHANDLE_TABLE_ENTRY ObjectTableEntry,
    IN ULONG_PTR Parameter
    )

/*++

Routine description:

    This is the call back routine for the ExChangeHandle from
    NtSetInformationObject

Arguments:

    ObjectTableEntry - Supplies a pointer to the object table entry being
        modified

    Parameter - Supplies a pointer to the OBJECT_HANDLE_FLAG_INFORMATION
        structure to set into the table entry

Return Value:

    Returns TRUE if the operation is successful otherwise FALSE

--*/

{
    POBP_SET_HANDLE_ATTRIBUTES ObjectInformation;
    POBJECT_HEADER ObjectHeader;

    ObjectInformation = (POBP_SET_HANDLE_ATTRIBUTES)Parameter;

    //
    //  Get a pointer to the object type via the object header and if the
    //  caller has asked for inherit but the object type says that inherit
    //  is an invalid flag then return false
    //

    ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(ObjectTableEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

    if ((ObjectInformation->ObjectInformation.Inherit) &&
        ((ObjectHeader->Type->TypeInfo.InvalidAttributes & OBJ_INHERIT) != 0)) {

        return FALSE;
    }

    //
    //  For each piece of information (inheriit and protect from close) that
    //  is in the object information buffer we'll set or clear the bits in
    //  the object table entry.  The bits modified are the low order bits of
    //  used to store the pointer to the object header.
    //

    if (ObjectInformation->ObjectInformation.Inherit) {

        ObjectTableEntry->ObAttributes |= OBJ_INHERIT;

    } else {

        ObjectTableEntry->ObAttributes &= ~OBJ_INHERIT;
    }

    if (ObjectInformation->ObjectInformation.ProtectFromClose) {
        
        ObjectTableEntry->GrantedAccess |= ObpAccessProtectCloseBit;

    } else {

        ObjectTableEntry->GrantedAccess &= ~ObpAccessProtectCloseBit;
    }

    //
    //  And return to our caller
    //

    return TRUE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obvutil.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    obvutil.c

Abstract:

    This module implements various utilities required to do driver verification.

Author:

    Adrian J. Oney (adriao) 20-Apr-1998

Environment:

    Kernel mode

Revision History:

    AdriaO      06/15/2000 - Separated out from ntos\io\flunkirp.c

--*/

#include "obp.h"
#include "obvutil.h"

//
// When enabled, everything is locked down on demand...
//
#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGEVRFY, ObvUtilStartObRefMonitoring)
#pragma alloc_text(PAGEVRFY, ObvUtilStopObRefMonitoring)
#endif

LONG_PTR
ObvUtilStartObRefMonitoring(
    IN PDEVICE_OBJECT DeviceObject
    )
/*++

  Description:

     Determines if ObRef has not been called between a call to this
     function and a subsequent call to ObvUtilStopObRefMonitoring.

  Arguments:

     Device object to monitor.

  Return Value:

     A start skew time to pass into ObvUtilStopObRefMonitoring.

     N.B. - A reference count is taken by this API and released
            by ObvUtilStopObRefMonitoring. That reference is not
            counted among the noticed calls to ObRef.
--*/
{
#if DBG
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;
    LONG_PTR startSkew, pointerCount ;

    ObReferenceObject(DeviceObject) ;

    ObjectHeader = OBJECT_TO_OBJECT_HEADER(DeviceObject);
    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

    ASSERT(NameInfo) ;
    //
    // We will always decrement DbgDereferenceCount prior to PointerCount,
    // so any race conditions will look like an increment occured, which
    // is an allowable misread...
    //
    do {
        pointerCount = ObjectHeader->PointerCount ;
        startSkew = pointerCount - NameInfo->DbgDereferenceCount ;

    } while(pointerCount != ObjectHeader->PointerCount) ;

    return startSkew ;
#else
    UNREFERENCED_PARAMETER (DeviceObject);
    return 1;
#endif
}


LONG_PTR
ObvUtilStopObRefMonitoring(
    IN PDEVICE_OBJECT   DeviceObject,
    IN LONG             StartSkew
    )
/*++

  Description:

     Determines if ObRef has not been called between a call to
     ObvUtilStartObRefMonitoring and a call to this API.

     In a race condition (say ObDereferenceObject is ran in-simo
     with this function), the return is gaurenteed to err on
     the side of a reference occuring.

  Arguments:

     Device Object and the skew returned by ObvUtilStartObRefMonitoring

  Return Value:

     Number of calls to ObRef that occured throughout the monitored timeframe.
     Note that the return could be positive even though the reference count
     actually dropped (ie, one ObRef and two ObDeref's).

--*/
{
#if DBG
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_NAME_INFO NameInfo;
    LONG_PTR currentSkew, refDelta, pointerCount ;

    ObjectHeader = OBJECT_TO_OBJECT_HEADER(DeviceObject);
    NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

    ASSERT(NameInfo) ;

    //
    // We will always decrement DbgDereferenceCount prior to PointerCount,
    // so any race conditions will look like an increment occured, which
    // is an allowable misread...
    //
    do {
        pointerCount = ObjectHeader->PointerCount ;
        currentSkew = pointerCount - NameInfo->DbgDereferenceCount ;

    } while(pointerCount != ObjectHeader->PointerCount) ;

    refDelta = currentSkew - StartSkew ;
    ASSERT(refDelta>=0) ;

    ObDereferenceObject(DeviceObject) ;

    return refDelta ;
#else
    UNREFERENCED_PARAMETER (DeviceObject);
    UNREFERENCED_PARAMETER (StartSkew);
    return 1;
#endif
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obtype.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obtype.c

Abstract:

    Object type routines.

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"


typedef struct _OBJECT_TYPE_ARRAY {

    ULONG   Size;
    POBJECT_HEADER_CREATOR_INFO CreatorInfoArray[1];

} OBJECT_TYPE_ARRAY, *POBJECT_TYPE_ARRAY;

#ifdef ALLOC_PRAGMA
POBJECT_TYPE_ARRAY
ObpCreateTypeArray (
    IN POBJECT_TYPE ObjectType
    );
VOID
ObpDestroyTypeArray (
    IN POBJECT_TYPE_ARRAY ObjectArray
    );
#pragma alloc_text(PAGE,ObCreateObjectType)
#pragma alloc_text(PAGE,ObEnumerateObjectsByType)
#pragma alloc_text(PAGE,ObpCreateTypeArray)
#pragma alloc_text(PAGE,ObpDestroyTypeArray)
#pragma alloc_text(PAGE,ObGetObjectInformation)
#pragma alloc_text(PAGE,ObpDeleteObjectType)
#endif

/*

 IMPORTANT IMPORTANT IMPORTANT IMPORTANT IMPORTANT IMPORTANT

 There is currently no system service that permits changing
 the security on an object type object.  Consequently, the object
 manager does not check to make sure that a subject is allowed
 to create an object of a given type.

 Should such a system service be added, the following section of
 code must be re-enabled in obhandle.c:

        //
        // Perform access check to see if we are allowed to create
        // an instance of this object type.
        //
        // This routine will audit the attempt to create the
        // object as appropriate.  Note that this is different
        // from auditing the creation of the object itself.
        //

        if (!ObCheckCreateInstanceAccess( ObjectType,
                                          OBJECT_TYPE_CREATE,
                                          AccessState,
                                          TRUE,
                                          AccessMode,
                                          &Status
                                        ) ) {
            return( Status );

            }

 The code is already there, but is not compiled.

 This will ensure that someone who is denied access to an object
 type is not permitted to create an object of that type.

*/


NTSTATUS
ObCreateObjectType (
    IN PUNICODE_STRING TypeName,
    IN POBJECT_TYPE_INITIALIZER ObjectTypeInitializer,
    IN PSECURITY_DESCRIPTOR SecurityDescriptor OPTIONAL, // currently ignored
    OUT POBJECT_TYPE *ObjectType
    )

/*++

Routine Description:

    This routine creates a new object type.

Arguments:

    TypeName - Supplies the name of the new object type

    ObjectTypeInitializer - Supplies a object initialization
        structure.  This structure denotes the default object
        behavior including callbacks.

    SecurityDescriptor - Currently ignored

    ObjectType - Receives a pointer to the newly created object
        type.

Return Value:

    An appropriate NTSTATUS value.

--*/

{
    POOL_TYPE PoolType;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POBJECT_HEADER NewObjectTypeHeader;
    POBJECT_TYPE NewObjectType;
    ULONG i;
    UNICODE_STRING ObjectName;
    PWCH s;
    NTSTATUS Status;
    ULONG StandardHeaderCharge;
    OBP_LOOKUP_CONTEXT LookupContext;

    UNREFERENCED_PARAMETER (SecurityDescriptor);

    ObpValidateIrql( "ObCreateObjectType" );

    //
    //  Return an error if invalid type attributes or no type name specified.
    //  No type name is okay if the type directory object does not exist
    //  yet (see init.c).
    //

    PoolType = ObjectTypeInitializer->PoolType;

    if ((!TypeName)

            ||

        (!TypeName->Length)

            ||

        (TypeName->Length % sizeof( WCHAR ))

            ||

        (ObjectTypeInitializer == NULL)

            ||

        (ObjectTypeInitializer->InvalidAttributes & ~OBJ_VALID_ATTRIBUTES)

            ||

        (ObjectTypeInitializer->Length != sizeof( *ObjectTypeInitializer ))

            ||

        (ObjectTypeInitializer->MaintainHandleCount &&
            (ObjectTypeInitializer->OpenProcedure == NULL &&
             ObjectTypeInitializer->CloseProcedure == NULL ))

            ||

        ((!ObjectTypeInitializer->UseDefaultObject) &&
            (PoolType != NonPagedPool))) {

        return( STATUS_INVALID_PARAMETER );
    }

    //
    //  Make sure that the type name does not contain an
    //  path name separator
    //

    s = TypeName->Buffer;
    i = TypeName->Length / sizeof( WCHAR );

    while (i--) {

        if (*s++ == OBJ_NAME_PATH_SEPARATOR) {

            return( STATUS_OBJECT_NAME_INVALID );
        }
    }

    //
    //  See if TypeName string already exists in the \ObjectTypes directory
    //  Return an error if it does.  Otherwise add the name to the directory.
    //  Note that there may not necessarily be a type directory.
    //

    ObpInitializeLookupContext( &LookupContext );

    if (ObpTypeDirectoryObject) {

        ObpLockLookupContext( &LookupContext, ObpTypeDirectoryObject);

        if (ObpLookupDirectoryEntry( ObpTypeDirectoryObject,
                                     TypeName,
                                     OBJ_CASE_INSENSITIVE,
                                     FALSE,
                                     &LookupContext )) {

            ObpReleaseLookupContext( &LookupContext );

            return( STATUS_OBJECT_NAME_COLLISION );
        }
    }

    //
    //  Allocate a buffer for the type name and then
    //  copy over the name
    //

    ObjectName.Buffer = ExAllocatePoolWithTag( PagedPool,
                                               (ULONG)TypeName->MaximumLength,
                                               'mNbO' );

    if (ObjectName.Buffer == NULL) {

        ObpReleaseLookupContext( &LookupContext );

        return STATUS_INSUFFICIENT_RESOURCES;
    }

    ObjectName.MaximumLength = TypeName->MaximumLength;

    RtlCopyUnicodeString( &ObjectName, TypeName );

    //
    //  Allocate memory for the object
    //

    Status = ObpAllocateObject( NULL,
                                KernelMode,
                                ObpTypeObjectType,
                                &ObjectName,
                                sizeof( OBJECT_TYPE ),
                                &NewObjectTypeHeader );

    if (!NT_SUCCESS( Status )) {

        ObpReleaseLookupContext( &LookupContext );
        ExFreePool(ObjectName.Buffer);

        return( Status );
    }

    //
    //  Initialize the create attributes, object ownership. parse context,
    //  and object body pointer.
    //
    //  N.B. This is required since these fields are not initialized.
    //

    NewObjectTypeHeader->Flags |= OB_FLAG_KERNEL_OBJECT |
                                  OB_FLAG_PERMANENT_OBJECT;

    NewObjectType = (POBJECT_TYPE)&NewObjectTypeHeader->Body;
    NewObjectType->Name = ObjectName;

    //
    //  The following call zeros out the number of handles and objects
    //  field plus high water marks
    //

    RtlZeroMemory( &NewObjectType->TotalNumberOfObjects,
                   FIELD_OFFSET( OBJECT_TYPE, TypeInfo ) -
                   FIELD_OFFSET( OBJECT_TYPE, TotalNumberOfObjects ));

    //
    //  If there is not a type object type yet then this must be
    //  that type (i.e., type object type must be the first object type
    //  ever created.  Consequently we'll need to setup some self
    //  referencing pointers.
    //

    if (!ObpTypeObjectType) {

        ObpTypeObjectType = NewObjectType;
        NewObjectTypeHeader->Type = ObpTypeObjectType;
        NewObjectType->TotalNumberOfObjects = 1;

#ifdef POOL_TAGGING

        NewObjectType->Key = 'TjbO';

    } else {

        //
        //  Otherwise this is not the type object type so we'll
        //  try and generate a tag for the new object type provided
        //  pool tagging is turned on.
        //

        ANSI_STRING AnsiName;

        if (NT_SUCCESS( RtlUnicodeStringToAnsiString( &AnsiName, TypeName, TRUE ) )) {

            for (i=3; i>=AnsiName.Length; i--) {

                AnsiName.Buffer[ i ] = ' ';

            }

            NewObjectType->Key = *(PULONG)AnsiName.Buffer;
            ExFreePool( AnsiName.Buffer );

        } else {

            NewObjectType->Key = *(PULONG)TypeName->Buffer;
        }

#endif //POOL_TAGGING

    }

    //
    //  Continue initializing the new object type fields
    //

    NewObjectType->TypeInfo = *ObjectTypeInitializer;
    NewObjectType->TypeInfo.PoolType = PoolType;

    if (NtGlobalFlag & FLG_MAINTAIN_OBJECT_TYPELIST) {

        NewObjectType->TypeInfo.MaintainTypeList = TRUE;
    }

    //
    //  Whack quotas passed in so that headers are properly charged
    //
    //  Quota for object name is charged independently
    //

    StandardHeaderCharge = sizeof( OBJECT_HEADER ) +
                           sizeof( OBJECT_HEADER_NAME_INFO ) +
                           (ObjectTypeInitializer->MaintainHandleCount ?
                                sizeof( OBJECT_HEADER_HANDLE_INFO )
                              : 0 );

    if ( PoolType == NonPagedPool ) {

        NewObjectType->TypeInfo.DefaultNonPagedPoolCharge += StandardHeaderCharge;

    } else {

        NewObjectType->TypeInfo.DefaultPagedPoolCharge += StandardHeaderCharge;
    }

    //
    //  If there is not an object type specific security procedure then set
    //  the default one supplied by Se.
    //

    if (ObjectTypeInitializer->SecurityProcedure == NULL) {

        NewObjectType->TypeInfo.SecurityProcedure = SeDefaultObjectMethod;
    }

    //
    //  Initialize the object type lock and its list of objects created
    //  of this type
    //

    ExInitializeResourceLite( &NewObjectType->Mutex );

    for (i = 0; i < OBJECT_LOCK_COUNT; i++) {

        ExInitializeResourceLite( &NewObjectType->ObjectLocks[i] );
    }

    InitializeListHead( &NewObjectType->TypeList );
    PERFINFO_INITIALIZE_OBJECT_ALLOCATED_TYPE_LIST_HEAD(NewObjectType);

    //
    //  If we are to use the default object (meaning that we'll have our
    //  private event as our default object) then the type must allow
    //  synchronize and we'll set the default object
    //

    if (NewObjectType->TypeInfo.UseDefaultObject) {

        NewObjectType->TypeInfo.ValidAccessMask |= SYNCHRONIZE;
        NewObjectType->DefaultObject = &ObpDefaultObject;

    //
    //  Otherwise if this is the type file object then we'll put
    //  in the offset to the event of a file object.
    //

    } else if (ObjectName.Length == 8 && !wcscmp( ObjectName.Buffer, L"File" )) {

        NewObjectType->DefaultObject = ULongToPtr( FIELD_OFFSET( FILE_OBJECT, Event ) );


    //
    // If this is a waitable port, set the offset to the event in the
    // waitableport object.  Another hack
    //

    } else if ( ObjectName.Length == 24 && !wcscmp( ObjectName.Buffer, L"WaitablePort")) {

        NewObjectType->DefaultObject = ULongToPtr( FIELD_OFFSET( LPCP_PORT_OBJECT, WaitEvent ) );

    //
    //  Otherwise indicate that there isn't a default object to wait
    //  on
    //

    } else {

        NewObjectType->DefaultObject = NULL;
    }

    //
    //  Lock down the type object type and if there is a creator info
    //  record then insert this object on that list
    //

    ObpEnterObjectTypeMutex( ObpTypeObjectType );

    CreatorInfo = OBJECT_HEADER_TO_CREATOR_INFO( NewObjectTypeHeader );

    if (CreatorInfo != NULL) {

        InsertTailList( &ObpTypeObjectType->TypeList, &CreatorInfo->TypeList );
    }

    //
    //  Store a pointer to this new object type in the
    //  global object types array.  We'll use the index from
    //  the type object type number of objects count
    //

    NewObjectType->Index = ObpTypeObjectType->TotalNumberOfObjects;

    if (NewObjectType->Index < OBP_MAX_DEFINED_OBJECT_TYPES) {

        ObpObjectTypes[ NewObjectType->Index - 1 ] = NewObjectType;
    }

    //
    //  Unlock the type object type lock
    //

    ObpLeaveObjectTypeMutex( ObpTypeObjectType );

    //
    //  Lastly if there is not a directory object type yet then the following
    //  code will actually drop through and set the output object type
    //  and return success.
    //
    //  Otherwise, there is a directory object type and we try to insert the
    //  new type into the directory.  If this succeeds then we'll reference
    //  the directory type object, unlock the root directory, set the
    //  output type and return success
    //

    if (!ObpTypeDirectoryObject ||
        ObpInsertDirectoryEntry( ObpTypeDirectoryObject, &LookupContext, NewObjectTypeHeader )) {

        if (ObpTypeDirectoryObject) {

            ObReferenceObject( ObpTypeDirectoryObject );
        }

        ObpReleaseLookupContext( &LookupContext );

        *ObjectType = NewObjectType;

        return( STATUS_SUCCESS );

    } else {

        //
        //  Otherwise there is a directory object type and
        //  the insertion failed.  So release the root directory
        //  and return failure to our caller.
        //

        ObpReleaseLookupContext( &LookupContext );

        return( STATUS_INSUFFICIENT_RESOURCES );
    }
}


VOID
ObpDeleteObjectType (
    IN  PVOID   Object
    )

/*++

Routine Description:

    This routine is called when a reference to a type object goes to zero.

Arguments:

    Object - Supplies a pointer to the type object being deleted

Return Value:

    None.

--*/

{
    ULONG i;
    POBJECT_TYPE ObjectType = (POBJECT_TYPE)Object;

    //
    //  The only cleaning up we need to do is to delete the type resource
    //

    for (i = 0; i < OBJECT_LOCK_COUNT; i++) {

        ExDeleteResourceLite( &ObjectType->ObjectLocks[i] );
    }

    ExDeleteResourceLite( &ObjectType->Mutex );

    //
    //  And return to our caller
    //

    return;
}


NTSTATUS
ObEnumerateObjectsByType(
    IN POBJECT_TYPE ObjectType,
    IN OB_ENUM_OBJECT_TYPE_ROUTINE EnumerationRoutine,
    IN PVOID Parameter
    )

/*++

Routine Description:

    This routine, via a callback, will enumerate through all
    the objects of a specified type.  This only works on objects
    that maintain the type list (i.e., have an object creator
    info record).

Arguments:

    ObjectType - Supplies the object type being enumerated

    EnumerationRoutine - Supplies the callback routine to use

    Parameter - Supplies a parameter to pass through to the callback
        routine

Return Value:

    STATUS_SUCCESS if the enumeration finishes because the
    end of the list is reached and STATUS_NO_MORE_ENTRIES if
    the enmeration callback routine ever returns false.

--*/

{
    NTSTATUS Status;
    UNICODE_STRING ObjectName;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POBJECT_HEADER_NAME_INFO NameInfo;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE_ARRAY ObjectTypeArray;
    ULONG i;

    Status = STATUS_SUCCESS;

    //
    //  Capture the  object type array
    //

    ObjectTypeArray = ObpCreateTypeArray ( ObjectType );

    //
    //  If it is any object in that queue, start
    //  quering information about it
    //

    if (ObjectTypeArray != NULL) {

        //
        //  The following loop iterates through each object
        //  of the specified type.
        //

        for ( i = 0; i < ObjectTypeArray->Size; i++) {

            //
            //  For each object we'll grab its creator info record,
            //  its object header, and its object body
            //

            CreatorInfo = ObjectTypeArray->CreatorInfoArray[i];

            //
            //  If the object is being deleted, the creator info
            //  will be NULL in the array. Jump then to the next object
            //

            if (!CreatorInfo) {

                continue;
            }

            ObjectHeader = (POBJECT_HEADER)(CreatorInfo+1);

            //
            //  From the object header see if there is a name for the
            //  object. If there is not a name then we'll supply an
            //  empty name.
            //

            NameInfo = OBJECT_HEADER_TO_NAME_INFO( ObjectHeader );

            if (NameInfo != NULL) {

                ObjectName = NameInfo->Name;

            } else {

                RtlZeroMemory( &ObjectName, sizeof( ObjectName ) );
            }

            //
            //  Now invoke the callback and if it returns false then
            //  we're done with the enumeration and will return
            //  an alternate ntstatus value
            //

            if (!(EnumerationRoutine)( &ObjectHeader->Body,
                                       &ObjectName,
                                       ObjectHeader->HandleCount,
                                       ObjectHeader->PointerCount,
                                       Parameter )) {

                Status = STATUS_NO_MORE_ENTRIES;

                break;
            }
        }

        ObpDestroyTypeArray(ObjectTypeArray);
    }

    return Status;
}

PERFINFO_DEFINE_OB_ENUMERATE_ALLOCATED_OBJECTS_BY_TYPE()


POBJECT_TYPE_ARRAY
ObpCreateTypeArray (
    IN POBJECT_TYPE ObjectType
    )

/*++

Routine Description:

    This routine create an array with pointers to all objects queued
    for a given ObjectType. All objects are referenced when are stored
    in the array.

Arguments:

    ObjectType - Supplies the object type for which we make copy
    for all objects.


Return Value:

    The array with objects created. returns NULL if the specified ObjectType
    has the TypeList empty.

--*/

{
    ULONG Count;
    POBJECT_TYPE_ARRAY ObjectArray;
    PLIST_ENTRY Next1, Head1;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POBJECT_HEADER ObjectHeader;
    PVOID Object;

    //
    //  Acquire the ObjectType mutex
    //

    ObpEnterObjectTypeMutex( ObjectType );

    ObjectArray = NULL;

    //
    //  Count the number of elements into the list
    //

    Count = 0;

    Head1 = &ObjectType->TypeList;
    Next1 = Head1->Flink;

    while (Next1 != Head1) {

        Next1 = Next1->Flink;
        Count += 1;
    }

    //
    //  If we have a number of objects > 0 then we'll create an array
    //  and copy all pointers into that array
    //

    if ( Count > 0 ) {

        //
        //  Allocate the memory for array
        //

        ObjectArray = ExAllocatePoolWithTag( PagedPool,
                                             sizeof(OBJECT_TYPE_ARRAY) + sizeof(POBJECT_HEADER_CREATOR_INFO) * (Count - 1),
                                             'rAbO' );
        if ( ObjectArray != NULL ) {

            ObjectArray->Size = Count;

            Count = 0;

            //
            //  Start parsing the TypeList
            //

            Head1 = &ObjectType->TypeList;
            Next1 = Head1->Flink;

            while (Next1 != Head1) {

                ASSERT( Count < ObjectArray->Size );

                //
                //  For each object we'll grab its creator info record,
                //  its object header, and its object body
                //

                CreatorInfo = CONTAINING_RECORD( Next1,
                                                 OBJECT_HEADER_CREATOR_INFO,
                                                 TypeList );

                //
                //  We'll store the CreatorInfo into the ObjectArray
                //

                ObjectArray->CreatorInfoArray[Count] = CreatorInfo;

                //
                //  Find the Object and increment the references to that object
                //  to avoid deleting while are stored copy in this array
                //

                ObjectHeader = (POBJECT_HEADER)(CreatorInfo+1);

                Object = &ObjectHeader->Body;

                if (!ObReferenceObjectSafe( Object))
                {
                    //
                    //  We can't reference the object because it is being deleted
                    //

                    ObjectArray->CreatorInfoArray[Count] = NULL;
                }

                Next1 = Next1->Flink;
                Count++;
            }
        }
    }

    //
    //  Release the ObjectType mutex
    //

    ObpLeaveObjectTypeMutex( ObjectType );

    return ObjectArray;
}


VOID
ObpDestroyTypeArray (
    IN POBJECT_TYPE_ARRAY ObjectArray
    )

/*++

Routine Description:

    This routine destroy an array with pointers to objects, created by
    ObpCreateTypeArray. Each object is dereferenced before releasing the
    array memory.

Arguments:

    ObjectArray - Supplies the array to be freed

Return Value:


--*/

{
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POBJECT_HEADER ObjectHeader;
    PVOID Object;
    ULONG i;

    if (ObjectArray != NULL) {

        //
        //  Go through array and dereference all objects.
        //

        for (i = 0; i < ObjectArray->Size; i++) {

            //
            //  Retrieving the Object from the CreatorInfo
            //

            CreatorInfo = ObjectArray->CreatorInfoArray[i];

            if (CreatorInfo) {

                ObjectHeader = (POBJECT_HEADER)(CreatorInfo+1);

                Object = &ObjectHeader->Body;

                //
                //  Dereference the object
                //

                ObDereferenceObject( Object );
            }
        }

        //
        //  Free the memory alocated for this array
        //

        ExFreePoolWithTag( ObjectArray, 'rAbO' );
    }
}


NTSTATUS
ObGetObjectInformation(
    IN PCHAR UserModeBufferAddress,
    OUT PSYSTEM_OBJECTTYPE_INFORMATION ObjectInformation,
    IN ULONG Length,
    OUT PULONG ReturnLength OPTIONAL
    )

/*++

Routine Description:

    This routine returns information for all the object in the
    system.  It enuermates through all the object types and in
    each type it enumerates through their type list.

Arguments:

    UserModeBufferAddress - Supplies the address of the query buffer
        as specified by the user.

    ObjectInformation - Supplies a buffer to receive the object
        type information.  This is essentially the same as the first
        parameter except that one is a system address and the other
        is in the user's address space.

    Length - Supplies the length, in bytes, of the object information
        buffer

    ReturnLength - Optionally receives the total length, in bytes,
        needed to store the object information


Return Value:

    An appropriate status value

--*/

{
    #define OBGETINFO_MAXFILENAME (260 * sizeof(WCHAR))
    
    NTSTATUS ReturnStatus, Status;
    POBJECT_TYPE ObjectType;
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_CREATOR_INFO CreatorInfo;
    POBJECT_HEADER_QUOTA_INFO QuotaInfo;
    PVOID Object;
    BOOLEAN FirstObjectForType;
    PSYSTEM_OBJECTTYPE_INFORMATION TypeInfo;
    PSYSTEM_OBJECT_INFORMATION ObjectInfo = NULL;
    ULONG TotalSize, NameSize;
    POBJECT_HEADER ObjectTypeHeader;
    PVOID TmpBuffer = NULL;
    SIZE_T TmpBufferSize = OBGETINFO_MAXFILENAME + sizeof(UNICODE_STRING);
    POBJECT_NAME_INFORMATION NameInformation;
    extern POBJECT_TYPE IoFileObjectType;
    PWSTR TempBuffer;
    USHORT TempMaximumLength;
    POBJECT_TYPE_ARRAY ObjectTypeArray = NULL;
    POBJECT_TYPE_ARRAY TypeObjectTypeArray;
    ULONG i, TypeIndex;

    PAGED_CODE();

    //
    //  Initialize some local variables
    //

    TmpBuffer = ExAllocatePoolWithTag( PagedPool,
                                       TmpBufferSize,
                                       'rAbO' );

    if (TmpBuffer == NULL) {

        return STATUS_INSUFFICIENT_RESOURCES;
    }

    NameInformation = (POBJECT_NAME_INFORMATION)TmpBuffer;
    ReturnStatus = STATUS_SUCCESS;
    TotalSize = 0;
    TypeInfo = NULL;

    //
    //  Capture the object types into an array
    //

    TypeObjectTypeArray = ObpCreateTypeArray ( ObpTypeObjectType );

    if (!TypeObjectTypeArray) {

        ExFreePoolWithTag( TmpBuffer, 'rAbO' );
        return STATUS_UNSUCCESSFUL;
    }

    try {

        for ( TypeIndex = 0; TypeIndex < TypeObjectTypeArray->Size; TypeIndex++ ) {

            //
            //  For each object type object we'll grab its creator
            //  info record and which must directly precede the
            //  object header followed by the object body
            //

            CreatorInfo = TypeObjectTypeArray->CreatorInfoArray[ TypeIndex ];

            //
            //  If the object type is being deleted, the creator info
            //  will be NULL in the array. Jump then to the next object
            //

            if (!CreatorInfo) {

                continue;
            }

            ObjectTypeHeader = (POBJECT_HEADER)(CreatorInfo+1);
            ObjectType = (POBJECT_TYPE)&ObjectTypeHeader->Body;

            //
            //  Now if this is not the object type object, which is what
            //  the outer loop is going through then we'll jump in one
            //  more loop
            //

            if (ObjectType != ObpTypeObjectType) {

                //
                //  Capture the array with objects queued in the TypeList
                //

                ObjectTypeArray = ObpCreateTypeArray ( ObjectType );

                //
                //  If it is any object in that queue, start
                //  quering information about it
                //

                if (ObjectTypeArray != NULL) {

                    //
                    //  The following loop iterates through each object
                    //  of the specified type.
                    //

                    FirstObjectForType = TRUE;

                    for ( i = 0; i < ObjectTypeArray->Size; i++) {

                        //
                        //  For each object we'll grab its creator info record,
                        //  its object header, and its object body
                        //

                        CreatorInfo = ObjectTypeArray->CreatorInfoArray[i];

                        //
                        //  If the object is being deleted, the creator info
                        //  will be NULL in the array. Jump then to the next object
                        //

                        if (!CreatorInfo) {

                            continue;
                        }

                        ObjectHeader = (POBJECT_HEADER)(CreatorInfo+1);

                        Object = &ObjectHeader->Body;

                        //
                        //  If this is the first time through the inner loop for this
                        //  type then we'll fill in the type info buffer
                        //

                        if (FirstObjectForType) {

                            FirstObjectForType = FALSE;

                            //
                            //  If the pointer it not null (i.e., we've been through
                            //  this loop before) and the total size we've used so
                            //  far hasn't exhausted the output buffer then
                            //  set the previous type info record to point to the
                            //  next type info record
                            //

                            if ((TypeInfo != NULL) && (TotalSize < Length)) {

                                TypeInfo->NextEntryOffset = TotalSize;
                            }

                            //
                            //  Set the current type info record to point to the next
                            //  free spot in the output buffer, and adjust the total
                            //  size used so far to account for the object type info
                            //  buffer
                            //

                            TypeInfo = (PSYSTEM_OBJECTTYPE_INFORMATION)((PCHAR)ObjectInformation + TotalSize);

                            TotalSize += FIELD_OFFSET( SYSTEM_OBJECTTYPE_INFORMATION, TypeName );

                            //
                            //  See if the data will fit into the info buffer, and if
                            //  so then fill in the record
                            //

                            if (TotalSize >= Length) {

                                ReturnStatus = STATUS_INFO_LENGTH_MISMATCH;

                            } else {

                                TypeInfo->NextEntryOffset   = 0;
                                TypeInfo->NumberOfObjects   = ObjectType->TotalNumberOfObjects;
                                TypeInfo->NumberOfHandles   = ObjectType->TotalNumberOfHandles;
                                TypeInfo->TypeIndex         = ObjectType->Index;
                                TypeInfo->InvalidAttributes = ObjectType->TypeInfo.InvalidAttributes;
                                TypeInfo->GenericMapping    = ObjectType->TypeInfo.GenericMapping;
                                TypeInfo->ValidAccessMask   = ObjectType->TypeInfo.ValidAccessMask;
                                TypeInfo->PoolType          = ObjectType->TypeInfo.PoolType;
                                TypeInfo->SecurityRequired  = ObjectType->TypeInfo.SecurityRequired;
                            }

                            //
                            //  Now we need to do the object's type name. The name
                            //  goes right after the type info field.  The following
                            //  query type name call knows to take the address of a
                            //  unicode string and assumes that the buffer to stuff
                            //  the string is right after the unicode string structure.
                            //  The routine also assumes that name size is the number
                            //  of bytes already use in the buffer and add to it the
                            //  number of bytes it uses.  That is why we need to
                            //  initialize it to zero before doing the call.
                            //

                            NameSize = 0;

                            Status = ObQueryTypeName( Object,
                                                      &TypeInfo->TypeName,
                                                      TotalSize < Length ? Length - TotalSize : 0,
                                                      &NameSize );

                            //
                            //  Round the name size up to the next ulong boundary
                            //

                            NameSize = (NameSize + TYPE_ALIGNMENT (SYSTEM_OBJECTTYPE_INFORMATION) - 1) &
                                                   (~(TYPE_ALIGNMENT (SYSTEM_OBJECTTYPE_INFORMATION) - 1));

                            //
                            //  If we were able to successfully get the type name then
                            //  set the max length to the rounded ulong that does not
                            //  include the heading unicode string structure.  Also set
                            //  the buffer to the address that the user would use to
                            //  access the string.
                            //

                            if (NT_SUCCESS( Status )) {

                                TypeInfo->TypeName.MaximumLength = (USHORT)
                                    (NameSize - sizeof( TypeInfo->TypeName ));
                                TypeInfo->TypeName.Buffer = (PWSTR)
                                    (UserModeBufferAddress +
                                     ((PCHAR)TypeInfo->TypeName.Buffer - (PCHAR)ObjectInformation)
                                    );

                            } else {

                                ReturnStatus = Status;
                            }

                            //
                            //  Now we need to bias the total size we've used by the
                            //  size of the object name
                            //

                            TotalSize += NameSize;

                        } else {

                            //
                            //  Otherwise this is not the first time through the inner
                            //  loop for this object type so the only thing we need to
                            //  do is set the previous object info record to "point via
                            //  relative offset" to the next object info record
                            //

                            if (TotalSize < Length) {

                                ObjectInfo->NextEntryOffset = TotalSize;
                            }
                        }

                        //
                        //  We still have an object info record to fill in for this
                        //  record.  The only thing we've done so far is the type info
                        //  record.  So now get a pointer to the new object info record
                        //  and adjust the total size to account for the object record
                        //

                        ObjectInfo = (PSYSTEM_OBJECT_INFORMATION)((PCHAR)ObjectInformation + TotalSize);

                        TotalSize += FIELD_OFFSET( SYSTEM_OBJECT_INFORMATION, NameInfo );

                        //
                        //  If there is room for the object info record then fill
                        //  in the record
                        //

                        if (TotalSize >= Length) {

                            ReturnStatus = STATUS_INFO_LENGTH_MISMATCH;

                        } else {

                            ObjectInfo->NextEntryOffset       = 0;
                            ObjectInfo->Object                = Object;
                            ObjectInfo->CreatorUniqueProcess  = CreatorInfo->CreatorUniqueProcess;
                            ObjectInfo->CreatorBackTraceIndex = CreatorInfo->CreatorBackTraceIndex;
                            ObjectInfo->PointerCount          = (ULONG)ObjectHeader->PointerCount;
                            ObjectInfo->HandleCount           = (ULONG)ObjectHeader->HandleCount;
                            ObjectInfo->Flags                 = (USHORT)ObjectHeader->Flags;
                            ObjectInfo->SecurityDescriptor    =
                                ExFastRefGetObject (*(PEX_FAST_REF) &ObjectHeader->SecurityDescriptor);

                            //
                            //  Fill in the appropriate quota information if there is
                            //  any quota information available
                            //

                            QuotaInfo = OBJECT_HEADER_TO_QUOTA_INFO( ObjectHeader );

                            if (QuotaInfo != NULL) {

                                ObjectInfo->PagedPoolCharge    = QuotaInfo->PagedPoolCharge;
                                ObjectInfo->NonPagedPoolCharge = QuotaInfo->NonPagedPoolCharge;

                                if (QuotaInfo->ExclusiveProcess != NULL) {

                                    ObjectInfo->ExclusiveProcessId = QuotaInfo->ExclusiveProcess->UniqueProcessId;
                                }

                            } else {

                                ObjectInfo->PagedPoolCharge    = ObjectType->TypeInfo.DefaultPagedPoolCharge;
                                ObjectInfo->NonPagedPoolCharge = ObjectType->TypeInfo.DefaultNonPagedPoolCharge;
                            }
                        }

                        //
                        //  Now we are ready to get the object name.  If there is not a
                        //  private routine to get the object name then we can call our
                        //  ob routine to query the object name.  Also if this is not
                        //  a file object we can do the query call.  The call will
                        //  fill in our local name buffer.
                        //

                        NameSize = 0;
                        Status = STATUS_SUCCESS;

                        if ((ObjectType->TypeInfo.QueryNameProcedure == NULL) ||
                            (ObjectType != IoFileObjectType)) {

                            Status = ObQueryNameString( Object,
                                                        NameInformation,
                                                        (ULONG)TmpBufferSize,
                                                        &NameSize );

                            //
                            //  Increase the temporary buffer, if the name does not fit
                            //

                            if ((Status == STATUS_INFO_LENGTH_MISMATCH)
                                    &&
                                (NameSize > TmpBufferSize)  //  just sanity checking to not shrink the buffer
                                    &&
                                ((NameSize + TotalSize) < Length)) {

                                PVOID PreviousBuffer = TmpBuffer;

                                TmpBuffer = ExAllocatePoolWithTag( PagedPool,
                                                                   NameSize,
                                                                   'rAbO' );

                                if (TmpBuffer) {
                                    
                                    ExFreePoolWithTag( PreviousBuffer, 'rAbO' );
                                    TmpBufferSize = NameSize;
                                    NameInformation = (POBJECT_NAME_INFORMATION)TmpBuffer;
                                    
                                    //
                                    //  Retry the query.
                                    //

                                    Status = ObQueryNameString( Object,
                                                                NameInformation,
                                                                (ULONG)TmpBufferSize,
                                                                &NameSize );

                                } else {

                                    //
                                    //  The allocation failed. Continue to use the previous buffer
                                    //

                                    TmpBuffer = PreviousBuffer;
                                    Status = STATUS_INSUFFICIENT_RESOURCES;
                                }
                            }

                        //
                        //  If this is a file object then we can get the
                        //  name directly from the file object.  We start by
                        //  directly copying the file object unicode string structure
                        //  into our local memory and then adjust the lengths, copy
                        //  the buffer and modify the pointers as necessary.
                        //

                        } else if (ObjectType == IoFileObjectType) {

                            NameInformation->Name = ((PFILE_OBJECT)Object)->FileName;

                            if ((NameInformation->Name.Length != 0) &&
                                (NameInformation->Name.Buffer != NULL)) {

                                NameSize = NameInformation->Name.Length + sizeof( UNICODE_NULL );

                                //
                                //  We will trim down names that are longer than 260 unicode
                                //  characters in length
                                //

                                if (NameSize > OBGETINFO_MAXFILENAME) {

                                    NameSize = OBGETINFO_MAXFILENAME;
                                    NameInformation->Name.Length = (USHORT)(NameSize - sizeof( UNICODE_NULL ));
                                }

                                //
                                //  Now copy over the name from the buffer used by the
                                //  file object into our local buffer, adjust the
                                //  fields in the unicode string structure and null
                                //  terminate the string.  In the copy we cannot copy
                                //  the null character from the filename because it
                                //  may not be valid memory
                                //

                                RtlMoveMemory( (NameInformation+1),
                                               NameInformation->Name.Buffer,
                                               NameSize - sizeof( UNICODE_NULL) );

                                NameInformation->Name.Buffer = (PWSTR)(NameInformation+1);
                                NameInformation->Name.MaximumLength = (USHORT)NameSize;
                                NameInformation->Name.Buffer[ NameInformation->Name.Length / sizeof( WCHAR )] = UNICODE_NULL;

                                //
                                //  Adjust the name size to account for the unicode
                                //  string structure
                                //

                                NameSize += sizeof( *NameInformation );

                            } else {

                                //
                                //  The file object does not have a name so the name
                                //  size stays zero
                                //
                            }
                        }

                        //
                        //  At this point if we have a name then the name size will
                        //  not be zero and the name is stored in our local name
                        //  information variable
                        //

                        if (NameSize != 0) {

                            //
                            //  Adjust the size of the name up to the next ulong
                            //  boundary and modify the total size required when
                            //  we add in the object name
                            //
                            NameSize = (NameSize + TYPE_ALIGNMENT (SYSTEM_OBJECTTYPE_INFORMATION) - 1) &
                                                   (~(TYPE_ALIGNMENT (SYSTEM_OBJECTTYPE_INFORMATION) - 1));

                            TotalSize += NameSize;

                            //
                            //  If everything has been successful so far, and we have
                            //  a non empty name, and everything fits in the output
                            //  buffer then copy over the name from our local buffer
                            //  into the caller supplied output buffer, append on the
                            //  null terminating character, and adjust the buffer point
                            //  to use the user's buffer
                            //

                            if ((NT_SUCCESS( Status )) &&
                                (NameInformation->Name.Length != 0) &&
                                (TotalSize < Length)) {

                                //
                                //  Use temporary local variable for RltMoveMemory
                                //

                                TempBuffer = (PWSTR)((&ObjectInfo->NameInfo)+1);
                                TempMaximumLength = (USHORT)
                                    (NameInformation->Name.Length + sizeof( UNICODE_NULL ));

                                ObjectInfo->NameInfo.Name.Length = NameInformation->Name.Length;

                                RtlMoveMemory( TempBuffer,
                                               NameInformation->Name.Buffer,
                                               TempMaximumLength);

                                ObjectInfo->NameInfo.Name.Buffer = (PWSTR)
                                    (UserModeBufferAddress +
                                     ((PCHAR)TempBuffer - (PCHAR)ObjectInformation));
                                ObjectInfo->NameInfo.Name.MaximumLength = TempMaximumLength;

                            //
                            //  Otherwise if we've been successful so far but for some
                            //  reason we weren't able to store the object name then
                            //  decide if it was because of an not enough space or
                            //  because the object name is null
                            //

                            } else if (NT_SUCCESS( Status )) {

                                if ((NameInformation->Name.Length != 0) ||
                                    (TotalSize >= Length)) {

                                    ReturnStatus = STATUS_INFO_LENGTH_MISMATCH;

                                } else {

                                    RtlInitUnicodeString( &ObjectInfo->NameInfo.Name, NULL );
                                }

                            //
                            //  Otherwise we have not been successful so far, we'll
                            //  adjust the total size to account for a null unicode
                            //  string, and if it doesn't fit then that's an error
                            //  otherwise we'll put in the null object name
                            //

                            } else {

                                TotalSize += sizeof( ObjectInfo->NameInfo.Name );

                                if (TotalSize >= Length) {

                                    ReturnStatus = STATUS_INFO_LENGTH_MISMATCH;

                                } else {

                                    RtlInitUnicodeString( &ObjectInfo->NameInfo.Name, NULL );

                                    ReturnStatus = Status;
                                }
                            }

                        //
                        //  Otherwise the name size is zero meaning we have not found
                        //  an object name, so we'll adjust total size for the null
                        //  unicode string, and check that it fits in the output
                        //  buffer.  If it fits we'll output a null object name
                        //

                        } else {

                            TotalSize += sizeof( ObjectInfo->NameInfo.Name );

                            if (TotalSize >= Length) {

                                ReturnStatus = STATUS_INFO_LENGTH_MISMATCH;

                            } else {

                                RtlInitUnicodeString( &ObjectInfo->NameInfo.Name, NULL );
                            }
                        }

                    }

                    //
                    //  Release the array with objects
                    //

                    ObpDestroyTypeArray(ObjectTypeArray);
                    ObjectTypeArray = NULL;
                }
            }
        }

        //
        //  Fill in the total size needed to store the buffer if the user wants
        //  that information.  And return to our caller
        //

        if (ARGUMENT_PRESENT( ReturnLength )) {

            *ReturnLength = TotalSize;
        }


    } finally {

        if (ObjectTypeArray != NULL) {

            ObpDestroyTypeArray(ObjectTypeArray);
        }

        ObpDestroyTypeArray( TypeObjectTypeArray );
        
        ExFreePoolWithTag( TmpBuffer, 'rAbO' );
    }
    
    if (TypeInfo == NULL) {

        return STATUS_UNSUCCESSFUL;
    }

    return( ReturnStatus );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obse.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    obse.c

Abstract:

    Object Security API calls

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"

#if defined(ALLOC_PRAGMA)

#pragma alloc_text(PAGE,NtSetSecurityObject)
#pragma alloc_text(PAGE,NtQuerySecurityObject)
#pragma alloc_text(PAGE,ObAssignObjectSecurityDescriptor)
#pragma alloc_text(PAGE,ObAssignSecurity)
#pragma alloc_text(PAGE,ObCheckCreateObjectAccess)
#pragma alloc_text(PAGE,ObCheckObjectAccess)
#pragma alloc_text(PAGE,ObpCheckObjectReference)
#pragma alloc_text(PAGE,ObpCheckTraverseAccess)
#pragma alloc_text(PAGE,ObGetObjectSecurity)
#pragma alloc_text(PAGE,ObSetSecurityDescriptorInfo)
#pragma alloc_text(PAGE,ObQuerySecurityDescriptorInfo)
#pragma alloc_text(PAGE,ObReleaseObjectSecurity)
#pragma alloc_text(PAGE,ObValidateSecurityQuota)
#pragma alloc_text(PAGE,ObpValidateAccessMask)
#pragma alloc_text(PAGE,ObSetSecurityObjectByPointer)

#endif

ULONG ObpDefaultSecurityDescriptorLength = 256;


NTSTATUS
NtSetSecurityObject (
    IN HANDLE Handle,
    IN SECURITY_INFORMATION SecurityInformation,
    IN PSECURITY_DESCRIPTOR SecurityDescriptor
    )

/*++

Routine Description:

    This routine is used to invoke an object's security routine.  It
    is used to set the object's security state.

Arguments:

    Handle - Supplies the handle for the object being modified

    SecurityInformation - Indicates the type of information we are
        interested in setting. e.g., owner, group, dacl, or sacl.

    SecurityDescriptor - Supplies the security descriptor for the
        object being modified.

Return Value:

    An appropriate NTSTATUS value

--*/

{
    NTSTATUS Status;
    PVOID Object;
    ACCESS_MASK DesiredAccess;
    OBJECT_HANDLE_INFORMATION HandleInformation;
    KPROCESSOR_MODE RequestorMode;
    SECURITY_DESCRIPTOR_RELATIVE *CapturedDescriptor;

    PAGED_CODE();

    //
    //  Make sure the passed security descriptor is really there.
    //  SeCaptureSecurityDescriptor doesn't mind being passed a NULL
    //  SecurityDescriptor, and will just return NULL back.
    //

    if (!ARGUMENT_PRESENT( SecurityDescriptor )) {

        return( STATUS_ACCESS_VIOLATION );
    }

    //
    //  Establish the accesses needed to the object based upon the
    //  security information being modified.
    //

    SeSetSecurityAccessMask( SecurityInformation, &DesiredAccess );

    Status = ObReferenceObjectByHandle( Handle,
                                        DesiredAccess,
                                        NULL,
                                        RequestorMode = KeGetPreviousMode(),
                                        &Object,
                                        &HandleInformation );

    if (NT_SUCCESS( Status )) {

        //
        //  Probe and capture the input security descriptor, and return
        //  right away if it is ill-formed.
        //
        //  Because the security descriptor is always captured the returned
        //  security descriptor is in self-relative format.
        //

        Status = SeCaptureSecurityDescriptor( SecurityDescriptor,
                                              RequestorMode,
                                              PagedPool,
                                              TRUE,
                                              (PSECURITY_DESCRIPTOR *)&CapturedDescriptor );

        if (NT_SUCCESS( Status )) {

            //
            //  Now check for a valid combination of what the user wants to set
            //  and what was supplied in the input security descriptor.  If the
            //  caller wants to set the owner then the owner field of the
            //  security descriptor better not be null, likewise for the group
            //  setting.  If anything is missing we'll return and error.
            //

            ASSERT(CapturedDescriptor->Control & SE_SELF_RELATIVE);

            if (((SecurityInformation & OWNER_SECURITY_INFORMATION) &&
                (CapturedDescriptor->Owner == 0))

                ||

                ((SecurityInformation & GROUP_SECURITY_INFORMATION) &&
                (CapturedDescriptor->Group == 0))) {

                SeReleaseSecurityDescriptor( (PSECURITY_DESCRIPTOR)CapturedDescriptor,
                                             RequestorMode,
                                             TRUE );

                ObDereferenceObject( Object );

                return( STATUS_INVALID_SECURITY_DESCR );
            }

            Status = ObSetSecurityObjectByPointer( Object,
                                                   SecurityInformation,
                                                   CapturedDescriptor );

            SeReleaseSecurityDescriptor( (PSECURITY_DESCRIPTOR)CapturedDescriptor,
                                         RequestorMode,
                                         TRUE );
        }

        ObDereferenceObject( Object );

    }

    return( Status );
}


NTSTATUS
ObSetSecurityObjectByPointer (
    IN PVOID Object,
    IN SECURITY_INFORMATION SecurityInformation,
    IN PSECURITY_DESCRIPTOR SecurityDescriptor
    )

/*++

Routine Description:

    This routine is used to invoke an object's security routine.  It
    is used to set the object's security state.

    This routine is accessible only to the kernel and assumes that all
    necessary validation of parameters has been done by the caller.

Arguments:

    Object - Supplies the pointer for the object being modified

    SecurityInformation - Indicates the type of information we are
        interested in setting. e.g., owner, group, dacl, or sacl.

    SecurityDescriptor - Supplies the security descriptor for the
        object being modified.

Return Value:

    An appropriate NTSTATUS value

--*/

{
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;

    PAGED_CODE();

//    DbgPrint("ObSetSecurityObjectByPointer called for object %#08lx with info "
//             "%x and descriptor %#08lx\n",
//             Object, SecurityInformation, SecurityDescriptor);

    //
    //  Map the object body to an object header and the corresponding
    //  object type
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;

    //
    //  Make sure the passed security descriptor is really there.
    //

    ASSERT(ARGUMENT_PRESENT( SecurityDescriptor ));

    //
    //  Now invoke the security procedure call back to set the security
    //  descriptor for the object
    //

    Status = (ObjectType->TypeInfo.SecurityProcedure)
                ( Object,
                  SetSecurityDescriptor,
                  &SecurityInformation,
                  SecurityDescriptor,
                  NULL,
                  &ObjectHeader->SecurityDescriptor,
                  ObjectType->TypeInfo.PoolType,
                  &ObjectType->TypeInfo.GenericMapping );


//    DbgPrint("ObSetSecurityObjectByPointer: object security routine returned "
//             "%#08lx\n", Status);

    return( Status );
}


NTSTATUS
NtQuerySecurityObject (
    IN HANDLE Handle,
    IN SECURITY_INFORMATION SecurityInformation,
    OUT PSECURITY_DESCRIPTOR SecurityDescriptor,
    IN ULONG Length,
    OUT PULONG LengthNeeded
    )

/*++

Routine Description:

    This routine is used to query the security descriptor for an
    object.

Arguments:

    Handle - Supplies the handle for the object being investigated

    SecurityInformation - Indicates the type of information we are
        interested in getting. e.g., owner, group, dacl, or sacl.

    SecurityDescriptor - Supplies a pointer to where the information
        should be returned

    Length - Supplies the size, in bytes, of the output buffer

    LengthNeeded - Receives the length, in bytes, needed to store
        the output security descriptor

Return Value:

    An appropriate NTSTATUS value

--*/

{
    NTSTATUS Status;
    PVOID Object;
    ACCESS_MASK DesiredAccess;
    OBJECT_HANDLE_INFORMATION HandleInformation;
    KPROCESSOR_MODE RequestorMode;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;

    PAGED_CODE();

    //
    //  Probe output parameters
    //

    RequestorMode = KeGetPreviousMode();

    if (RequestorMode != KernelMode) {

        try {

            ProbeForWriteUlong( LengthNeeded );

            ProbeForWrite( SecurityDescriptor, Length, sizeof(ULONG) );

        } except(EXCEPTION_EXECUTE_HANDLER) {

            return GetExceptionCode();
        }
    }

    //
    //  Establish the accesses needed to the object based upon the
    //  security information being queried
    //

    SeQuerySecurityAccessMask( SecurityInformation, &DesiredAccess );

    Status = ObReferenceObjectByHandle( Handle,
                                        DesiredAccess,
                                        NULL,
                                        RequestorMode,
                                        &Object,
                                        &HandleInformation );

    if (!NT_SUCCESS( Status )) {

        return( Status );
    }

    //
    //  Map the object body to an object header and the corresponding
    //  object type
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;

    //
    //  Invoke the object type's security callback routine to query
    //  the object.  This routine is assumed to have a try-except around
    //  the setting of the output security descriptor
    //

    Status = (ObjectType->TypeInfo.SecurityProcedure)( Object,
                                                       QuerySecurityDescriptor,
                                                       &SecurityInformation,
                                                       SecurityDescriptor,
                                                       &Length,
                                                       &ObjectHeader->SecurityDescriptor,
                                                       ObjectType->TypeInfo.PoolType,
                                                       &ObjectType->TypeInfo.GenericMapping );

    //
    //  Indicate the length needed for the security descriptor.  This
    //  will be set even if the callback failed so the caller will know
    //  the number of bytes necessary
    //

    try {

        *LengthNeeded = Length;

    } except(EXCEPTION_EXECUTE_HANDLER) {

        ObDereferenceObject( Object );

        return(GetExceptionCode());
    }

    //
    //  And return to our caller
    //

    ObDereferenceObject( Object );

    return( Status );
}


BOOLEAN
ObCheckObjectAccess (
    IN PVOID Object,
    IN OUT PACCESS_STATE AccessState,
    IN BOOLEAN TypeMutexLocked,
    IN KPROCESSOR_MODE AccessMode,
    OUT PNTSTATUS AccessStatus
    )

/*++

Routine Description:

    This routine performs access validation on the passed object.  The
    remaining desired access mask is extracted from the AccessState
    parameter and passes to the appropriate security routine to perform the
    access check.

    If the access attempt is successful, SeAccessCheck returns a mask
    containing the granted accesses.  The bits in this mask are turned
    on in the PreviouslyGrantedAccess field of the AccessState, and
    are turned off in the RemainingDesiredAccess field.

Arguments:

    Object - The object being examined.

    AccessState - The ACCESS_STATE structure containing accumulated
        information about the current attempt to gain access to the object.

    TypeMutexLocked - Indicates whether the type mutex for this object's
        type is locked.  The type mutex is used to protect the object's
        security descriptor from being modified while it is being accessed.

    AccessMode - The previous processor mode.

    AccessStatus - Pointer to a variable to return the status code of the
        access attempt.  In the case of failure this status code must be
        propagated back to the user.


Return Value:

    BOOLEAN - TRUE if access is allowed and FALSE otherwise

--*/

{
    ACCESS_MASK GrantedAccess = 0;
    BOOLEAN AccessAllowed;
    BOOLEAN MemoryAllocated;
    NTSTATUS Status;
    PSECURITY_DESCRIPTOR SecurityDescriptor = NULL;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    PPRIVILEGE_SET Privileges = NULL;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (TypeMutexLocked);

    //
    //  Map the object body to an object header and the
    //  corresponding object type
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;

    //
    //  Obtain the object's security descriptor
    //

    Status = ObGetObjectSecurity( Object,
                                  &SecurityDescriptor,
                                  &MemoryAllocated );

    //
    //  If we failed in getting the security descriptor then
    //  put the object type lock back where it was and return
    //  the error back to our caller
    //

    if (!NT_SUCCESS( Status )) {

        *AccessStatus = Status;

        return( FALSE );

    } else {

        //
        //  Otherwise we've been successful at getting the
        //  object's security descriptor, but now make sure
        //  it is not null.

        if (SecurityDescriptor == NULL) {

            *AccessStatus = Status;

            return(TRUE);
        }
    }

    //
    //  We have a non-null security descriptor so now
    //  lock the caller's tokens until after auditing has been
    //  performed.
    //

    SeLockSubjectContext( &AccessState->SubjectSecurityContext );

    //
    //  Do the access check, and if we have some privileges then
    //  put those in the access state too.
    //

    AccessAllowed = SeAccessCheck( SecurityDescriptor,
                                   &AccessState->SubjectSecurityContext,
                                   TRUE,                        // Tokens are locked
                                   AccessState->RemainingDesiredAccess,
                                   AccessState->PreviouslyGrantedAccess,
                                   &Privileges,
                                   &ObjectType->TypeInfo.GenericMapping,
                                   AccessMode,
                                   &GrantedAccess,
                                   AccessStatus );

    if (Privileges != NULL) {

        Status = SeAppendPrivileges( AccessState,
                                     Privileges );

        SeFreePrivileges( Privileges );
    }

    //
    //  If we were granted access then set that fact into
    //  what we've been granted and remove it from what remains
    //  to be granted.
    //

    if (AccessAllowed) {

        AccessState->PreviouslyGrantedAccess |= GrantedAccess;
        AccessState->RemainingDesiredAccess &= ~(GrantedAccess | MAXIMUM_ALLOWED);
    }

    //
    //  Audit the attempt to open the object, audit
    //  the creation of its handle later.
    //

    if ( SecurityDescriptor != NULL ) {

        SeOpenObjectAuditAlarm( &ObjectType->Name,
                                Object,
                                NULL,                    // AbsoluteObjectName
                                SecurityDescriptor,
                                AccessState,
                                FALSE,                   // ObjectCreated (FALSE, only open here)
                                AccessAllowed,
                                AccessMode,
                                &AccessState->GenerateOnClose );
    }

    SeUnlockSubjectContext( &AccessState->SubjectSecurityContext );

    //
    //  Free the security descriptor before returning to
    //  our caller
    //

    ObReleaseObjectSecurity( SecurityDescriptor,
                             MemoryAllocated );

    return( AccessAllowed );
}


BOOLEAN
ObpCheckObjectReference (
    IN PVOID Object,
    IN OUT PACCESS_STATE AccessState,
    IN BOOLEAN TypeMutexLocked,
    IN KPROCESSOR_MODE AccessMode,
    OUT PNTSTATUS AccessStatus
    )

/*++

Routine Description:

    The routine performs access validation on the passed object.  The
    remaining desired access mask is extracted from the AccessState
    parameter and passes to the appropriate security routine to
    perform the access check.

    If the access attempt is successful, SeAccessCheck returns a mask
    containing the granted accesses.  The bits in this mask are turned
    on in the PreviouslyGrantedAccess field of the AccessState, and
    are turned off in the RemainingDesiredAccess field.

    This routine differs from ObpCheckObjectAccess in that it calls
    a different audit routine.

Arguments:

    Object - The object being examined.

    AccessState - The ACCESS_STATE structure containing accumulated
        information about the current attempt to gain access to the object.

    TypeMutexLocked - Indicates whether the type mutex for this object's
        type is locked.  The type mutex is used to protect the object's
        security descriptor from being modified while it is being accessed.

    AccessMode - The previous processor mode.

    AccessStatus - Pointer to a variable to return the status code of the
        access attempt.  In the case of failure this status code must be
        propagated back to the user.


Return Value:

    BOOLEAN - TRUE if access is allowed and FALSE otherwise

--*/

{
    BOOLEAN AccessAllowed;
    ACCESS_MASK GrantedAccess = 0;
    BOOLEAN MemoryAllocated;
    PSECURITY_DESCRIPTOR SecurityDescriptor;
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    PPRIVILEGE_SET Privileges = NULL;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (TypeMutexLocked);

    //
    //  Map the object body to an object header and the
    //  corresponding object type
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;

    //
    //  Obtain the object's security descriptor
    //

    Status = ObGetObjectSecurity( Object,
                                  &SecurityDescriptor,
                                  &MemoryAllocated );

    //
    //  If we failed in getting the security descriptor then
    //  put the object type lock back where it was and return
    //  the error back to our caller
    //

    if (!NT_SUCCESS( Status )) {

        *AccessStatus = Status;

        return( FALSE );
    }

    //
    //  Lock the caller's tokens until after auditing has been
    //  performed.
    //

    SeLockSubjectContext( &AccessState->SubjectSecurityContext );

    //
    //  Do the access check, and if we have some privileges then
    //  put those in the access state too.
    //

    AccessAllowed = SeAccessCheck( SecurityDescriptor,
                                   &AccessState->SubjectSecurityContext,
                                   TRUE,               // Tokens are locked
                                   AccessState->RemainingDesiredAccess,
                                   AccessState->PreviouslyGrantedAccess,
                                   &Privileges,
                                   &ObjectType->TypeInfo.GenericMapping,
                                   AccessMode,
                                   &GrantedAccess,
                                   AccessStatus );

    if (AccessAllowed) {

        AccessState->PreviouslyGrantedAccess |= GrantedAccess;
        AccessState->RemainingDesiredAccess &= ~GrantedAccess;
    }

    //
    //  If we have a security descriptor then call the security routine
    //  to audit this reference and then unlock the caller's token
    //

    if ( SecurityDescriptor != NULL ) {

        SeObjectReferenceAuditAlarm( &AccessState->OperationID,
                                     Object,
                                     SecurityDescriptor,
                                     &AccessState->SubjectSecurityContext,
                                     AccessState->RemainingDesiredAccess | AccessState->PreviouslyGrantedAccess,
                                     ((PAUX_ACCESS_DATA)(AccessState->AuxData))->PrivilegesUsed,
                                     AccessAllowed,
                                     AccessMode );
    }

    SeUnlockSubjectContext( &AccessState->SubjectSecurityContext );

    //
    //  Finally free the security descriptor
    //  and return to our caller
    //

    ObReleaseObjectSecurity( SecurityDescriptor,
                             MemoryAllocated );

    return( AccessAllowed );
}


BOOLEAN
ObpCheckTraverseAccess (
    IN PVOID DirectoryObject,
    IN ACCESS_MASK TraverseAccess,
    IN PACCESS_STATE AccessState,
    IN BOOLEAN TypeMutexLocked,
    IN KPROCESSOR_MODE PreviousMode,
    OUT PNTSTATUS AccessStatus
    )

/*++

Routine Description:

    This routine checks for traverse access to the given directory object.

    Note that the contents of the AccessState structure are not
    modified, since it is assumed that this access check is incidental
    to another access operation.

Arguments:

    DirectoryObject - The object body of the object being examined.

    TraverseAccess - The desired access to the object, most likely DIRECTORY
        TRAVERSE access.

    AccessState - Checks for traverse access will typically be incidental
        to some other access attempt.  Information on the current state of
        that access attempt is required so that the constituent access
        attempts may be associated with each other in the audit log.

    TypeMutexLocked - Indicates whether the type mutex for this object's
        type is locked.  The type mutex is used to protect the object's
        security descriptor from being modified while it is being accessed.

    PreviousMode - The previous processor mode.

    AccessStatus - Pointer to a variable to return the status code of the
        access attempt.  In the case of failure this status code must be
        propagated back to the user.

Return Value:

    BOOLEAN - TRUE if access is allowed and FALSE otherwise.  AccessStatus
    contains the status code to be passed back to the caller.  It is not
    correct to simply pass back STATUS_ACCESS_DENIED, since this will have
    to change with the advent of mandatory access control.

--*/

{
    BOOLEAN AccessAllowed;
    ACCESS_MASK GrantedAccess = 0;
    PSECURITY_DESCRIPTOR SecurityDescriptor;
    BOOLEAN MemoryAllocated;
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    PPRIVILEGE_SET Privileges = NULL;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (TypeMutexLocked);

    //
    //  Map the object body to an object header and corresponding
    //  object type
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( DirectoryObject );
    ObjectType = ObjectHeader->Type;

    //
    //  Obtain the object's security descriptor and make it was
    //  successful
    //

    Status = ObGetObjectSecurity( DirectoryObject,
                                  &SecurityDescriptor,
                                  &MemoryAllocated );

    if (!NT_SUCCESS( Status )) {

        *AccessStatus = Status;

        return( FALSE );
    }

    if (!SeFastTraverseCheck( SecurityDescriptor,
                              AccessState,
                              DIRECTORY_TRAVERSE,
                              PreviousMode )) {

        //
        //  SeFastTraverseCheck could be modified to tell us that
        //  no one has any access to this directory.  However,
        //  we're going to have to fail this entire call if
        //  that is the case, so we really don't need to worry
        //  all that much about making it blindingly fast.
        //
        //  The world does not have traverse access and we have
        //  the client's access state so lock down the client's
        //  token and then do the access check, appending privileges
        //  if present.  The access check will give the answer
        //  we return back to our caller
        //

        SeLockSubjectContext( &AccessState->SubjectSecurityContext );

        AccessAllowed = SeAccessCheck( SecurityDescriptor,
                                       &AccessState->SubjectSecurityContext,
                                       TRUE,             // Tokens are locked
                                       TraverseAccess,
                                       0,
                                       &Privileges,
                                       &ObjectType->TypeInfo.GenericMapping,
                                       PreviousMode,
                                       &GrantedAccess,
                                       AccessStatus );

        if (Privileges != NULL) {

            Status = SeAppendPrivileges( AccessState,
                                         Privileges );

            SeFreePrivileges( Privileges );
        }

        //
        //  If the client's token is locked then now we can unlock it
        //

        SeUnlockSubjectContext( &AccessState->SubjectSecurityContext );

    } else {

        //
        //  At this point the world has traverse access
        //

        AccessAllowed = TRUE;
    }

    //
    //  Finally free the security descriptor
    //  and then return to our caller
    //

    ObReleaseObjectSecurity( SecurityDescriptor,
                             MemoryAllocated );

    return( AccessAllowed );
}


BOOLEAN
ObCheckCreateObjectAccess (
    IN PVOID DirectoryObject,
    IN ACCESS_MASK CreateAccess,
    IN PACCESS_STATE AccessState,
    IN PUNICODE_STRING ComponentName,
    IN BOOLEAN TypeMutexLocked,
    IN KPROCESSOR_MODE PreviousMode,
    OUT PNTSTATUS AccessStatus
    )

/*++

Routine Description:

    This routine checks to see if we are allowed to create an object in the
    given directory, and performs auditing as appropriate.

Arguments:

    DirectoryObject - The directory object being examined.

    CreateAccess - The access mask corresponding to create access for
        this directory type.

    AccessState - Checks for traverse access will typically be incidental
        to some other access attempt.  Information on the current state of
        that access attempt is required so that the constituent access
        attempts may be associated with each other in the audit log.

    ComponentName - Pointer to a Unicode string containing the name of
        the object being created.

    TypeMutexLocked - Indicates whether the type mutex for this object's
        type is locked.  The type mutex is used to protect the object's
        security descriptor from being modified while it is being accessed.

    PreviousMode - The previous processor mode.

    AccessStatus - Pointer to a variable to return the status code of the
        access attempt.  In the case of failure this status code must be
        propagated back to the user.

Return Value:

    BOOLEAN - TRUE if access is allowed and FALSE otherwise.  AccessStatus
    contains the status code to be passed back to the caller.  It is not
    correct to simply pass back STATUS_ACCESS_DENIED, since this will have
    to change with the advent of mandatory access control.

--*/

{
    BOOLEAN AccessAllowed;
    ACCESS_MASK GrantedAccess = 0;
    PSECURITY_DESCRIPTOR SecurityDescriptor;
    BOOLEAN MemoryAllocated;
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    POBJECT_TYPE ObjectType;
    PPRIVILEGE_SET Privileges = NULL;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (ComponentName);
    UNREFERENCED_PARAMETER (TypeMutexLocked);

    //
    //  Map the object body to its object header and corresponding
    //  object type
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( DirectoryObject );
    ObjectType = ObjectHeader->Type;

    //
    //  Obtain the object's security descriptor and make it was
    //  successful
    //

    Status = ObGetObjectSecurity( DirectoryObject,
                                  &SecurityDescriptor,
                                  &MemoryAllocated );

    if (!NT_SUCCESS( Status )) {

        *AccessStatus = Status;

        return( FALSE );
    }

    //
    //  lock the caller's tokens until after auditing has been
    //  performed.
    //

    SeLockSubjectContext( &AccessState->SubjectSecurityContext );

    //
    //  if we have a security descriptor then do an access
    //  check to see if access is allowed and set in the
    //  privileges if necessary
    //

    if (SecurityDescriptor != NULL) {

        AccessAllowed = SeAccessCheck( SecurityDescriptor,
                                       &AccessState->SubjectSecurityContext,
                                       TRUE,            // Tokens are locked
                                       CreateAccess,
                                       0,
                                       &Privileges,
                                       &ObjectType->TypeInfo.GenericMapping,
                                       PreviousMode,
                                       &GrantedAccess,
                                       AccessStatus );

        if (Privileges != NULL) {

            Status = SeAppendPrivileges( AccessState,
                                         Privileges );

            SeFreePrivileges( Privileges );
        }

        //
        //  This is wrong, but leave for reference.
        //
        //  if (AccessAllowed) {
        //
        //      AccessState->PreviouslyGrantedAccess |= GrantedAccess;
        //      AccessState->RemainingDesiredAccess &= ~GrantedAccess;
        //  }
        //

    } else {

        //
        //  At this point there is not a security descriptor
        //  so we'll assume access is allowed
        //

        AccessAllowed = TRUE;
    }

    //
    //  Free the caller's token and if the caller didn't have the
    //  object type locked we need to free it.
    //

    SeUnlockSubjectContext( &AccessState->SubjectSecurityContext );

    //
    //  Finally free the security descriptor
    //  and return to our caller
    //

    ObReleaseObjectSecurity( SecurityDescriptor,
                             MemoryAllocated );

    return( AccessAllowed );
}


NTSTATUS
ObAssignObjectSecurityDescriptor (
    IN PVOID Object,
    IN PSECURITY_DESCRIPTOR SecurityDescriptor OPTIONAL,
    IN POOL_TYPE PoolType // This field is currently ignored.
    )

/*++

Routine Description:

    Takes a pointer to an object and sets the SecurityDescriptor field
    in the object's header.

Arguments:

    Object - Supplies a pointer to the object

    SecurityDescriptor - Supplies a pointer to the security descriptor
        to be assigned to the object.  This pointer may be null if there
        is no security on the object.

    PoolType - Supplies the type of pool memory used to allocate the
        security descriptor.  This field is currently ignored.

Return Value:

    An appropriate NTSTATUS value.

--*/

{
    NTSTATUS Status;
    PSECURITY_DESCRIPTOR OutputSecurityDescriptor;
    POBJECT_HEADER ObjectHeader;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (PoolType);

    //
    //  If the security descriptor isn't supplied then we set the
    //  object header's security descriptor to null and return
    //  to our caller
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    if (!ARGUMENT_PRESENT(SecurityDescriptor)) {

        ExFastRefInitialize ((PEX_FAST_REF) &ObjectHeader->SecurityDescriptor, NULL);

        return( STATUS_SUCCESS );
    }

    //
    //  Log the new security descriptor into our security database and
    //  get back the real security descriptor to use
    //

    Status = ObLogSecurityDescriptor( SecurityDescriptor,
                                      &OutputSecurityDescriptor,
                                      ExFastRefGetAdditionalReferenceCount () + 1 );

    //
    //  If we've been successful so far then set the object's
    //  security descriptor to the newly allocated one.
    //

    if (NT_SUCCESS(Status)) {

        ExFreePool (SecurityDescriptor);

        ASSERT (OutputSecurityDescriptor);
        __assume (OutputSecurityDescriptor);
        //
        // Initialize a fast reference structure with zero additional references
        //
        ExFastRefInitialize ((PEX_FAST_REF) &ObjectHeader->SecurityDescriptor, OutputSecurityDescriptor);
    }

    //
    //  And return to our caller
    //

    return( Status );
}



NTSTATUS
ObGetObjectSecurity (
    IN PVOID Object,
    OUT PSECURITY_DESCRIPTOR *SecurityDescriptor,
    OUT PBOOLEAN MemoryAllocated
    )

/*++

Routine Description:

    Given an object, this routine will find its security descriptor.
    It will do this by calling the object's security method.

    It is possible for an object not to have a security descriptor
    at all.  Unnamed objects such as events that can only be referenced
    by a handle are an example of an object that does not have a
    security descriptor.

Arguments:

    Object - Supplies the object body being queried.

    SecurityDescriptor - Returns a pointer to the object's security
        descriptor.

    MemoryAllocated - indicates whether we had to allocate pool
        memory to hold the security descriptor or not.  This should
        be passed back into ObReleaseObjectSecurity.

Return Value:

    STATUS_SUCCESS - The operation was successful.  Note that the
        operation may be successful and still return a NULL security
        descriptor.

    STATUS_INSUFFICIENT_RESOURCES - Insufficient memory was available
        to satisfy the request.

--*/

{
    SECURITY_INFORMATION SecurityInformation;
    ULONG Length = ObpDefaultSecurityDescriptorLength;
    NTSTATUS Status;
    POBJECT_TYPE ObjectType;
    POBJECT_HEADER ObjectHeader;
#if DBG
    KIRQL SaveIrql;
#endif

    PAGED_CODE();

    //
    //  Map the object body to its object header and corresponding
    //  object type
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
    ObjectType = ObjectHeader->Type;

    //
    //  If the object is one that uses the default object method,
    //  its security descriptor is contained in ob's security
    //  descriptor cache.
    //
    //  Reference it so that it doesn't go away out from under us.
    //

    if (ObpCentralizedSecurity(ObjectType))  {

        *SecurityDescriptor = ObpReferenceSecurityDescriptor( ObjectHeader );

        *MemoryAllocated = FALSE;

        return( STATUS_SUCCESS );
    }

    //
    //  Request a complete security descriptor
    //

    SecurityInformation = OWNER_SECURITY_INFORMATION |
                          GROUP_SECURITY_INFORMATION |
                          DACL_SECURITY_INFORMATION  |
                          SACL_SECURITY_INFORMATION;

    //
    //  We don't know exactly how large is the SD, but we try with the largest
    //  size we get so far. In general the SD will be released after
    //  the access is checked. It shouldn't be then a problem of an extra pool usage
    //  because this oversizing
    //

    *SecurityDescriptor = ExAllocatePoolWithTag( PagedPool, Length, 'qSbO' );

    if (*SecurityDescriptor == NULL) {

        return( STATUS_INSUFFICIENT_RESOURCES );
    }

    *MemoryAllocated = TRUE;

    //
    //  The security method will return an absolute format
    //  security descriptor that just happens to be in a self
    //  contained buffer (not to be confused with a self-relative
    //  security descriptor).
    //

    ObpBeginTypeSpecificCallOut( SaveIrql );

    Status = (*ObjectType->TypeInfo.SecurityProcedure)( Object,
                                                        QuerySecurityDescriptor,
                                                        &SecurityInformation,
                                                        *SecurityDescriptor,
                                                        &Length,
                                                        &ObjectHeader->SecurityDescriptor,
                                                        ObjectType->TypeInfo.PoolType,
                                                        &ObjectType->TypeInfo.GenericMapping );

    ObpEndTypeSpecificCallOut( SaveIrql, "Security", ObjectType, Object );

    if (Status == STATUS_BUFFER_TOO_SMALL) {

        //
        //  The SD is larger than we tried first time. We need to allocate an other
        //  buffer and try again with this size
        //

        ExFreePool( *SecurityDescriptor );
        *MemoryAllocated = FALSE;

        //
        //  Save the new largest size
        //

        ObpDefaultSecurityDescriptorLength = Length;

//        DbgPrint( "ObpDefaultSecurityDescriptorLength increased to %ld\n",
//                  ObpDefaultSecurityDescriptorLength);

        //
        //  Now that we know how large the security descriptor is we
        //  can allocate space for it
        //

        *SecurityDescriptor = ExAllocatePoolWithTag( PagedPool, Length, 'qSbO' );

        if (*SecurityDescriptor == NULL) {

            return( STATUS_INSUFFICIENT_RESOURCES );
        }

        *MemoryAllocated = TRUE;

        //
        //  The security method will return an absolute format
        //  security descriptor that just happens to be in a self
        //  contained buffer (not to be confused with a self-relative
        //  security descriptor).
        //

        ObpBeginTypeSpecificCallOut( SaveIrql );

        Status = (*ObjectType->TypeInfo.SecurityProcedure)( Object,
                                                            QuerySecurityDescriptor,
                                                            &SecurityInformation,
                                                            *SecurityDescriptor,
                                                            &Length,
                                                            &ObjectHeader->SecurityDescriptor,
                                                            ObjectType->TypeInfo.PoolType,
                                                            &ObjectType->TypeInfo.GenericMapping );

        ObpEndTypeSpecificCallOut( SaveIrql, "Security", ObjectType, Object );
    }

    if (!NT_SUCCESS( Status )) {

        ExFreePool( *SecurityDescriptor );

        *MemoryAllocated = FALSE;
    }

    return( Status );
}


VOID
ObReleaseObjectSecurity (
    IN PSECURITY_DESCRIPTOR SecurityDescriptor,
    IN BOOLEAN MemoryAllocated
    )

/*++

Routine Description:

    This function will free up any memory associated with a queried
    security descriptor.  This undoes the function ObGetObjectSecurity

Arguments:

    SecurityDescriptor - Supplies a pointer to the security descriptor
        to be freed.

    MemoryAllocated - Supplies whether or not we should free the
        memory pointed to by SecurityDescriptor.

Return Value:

    None.

--*/

{
    PAGED_CODE();

    //
    //  Check if there is a security descriptor to actually free
    //

    if ( SecurityDescriptor != NULL ) {

        //
        //  If ObGetObjectSecurity allocated memory then we
        //  need to free it. Otherwise what the earlier routine did
        //  was reference the object to keep the security descriptor
        //  to keep it from going away
        //

        if (MemoryAllocated) {

            ExFreePool( SecurityDescriptor );

        } else {

            ObDereferenceSecurityDescriptor( SecurityDescriptor, 1);
        }
    }
}


NTSTATUS
ObValidateSecurityQuota (
    IN PVOID Object,
    IN ULONG NewSize
    )

/*++

Routine Description:

    This routine will check to see if the new security information
    is larger than is allowed by the object's pre-allocated quota.

Arguments:

    Object - Supplies a pointer to the object whose information is to be
        modified.

    NewSize - Supplies the size of the proposed new security
        information.

Return Value:

    STATUS_SUCCESS - New size is within alloted quota.

    STATUS_QUOTA_EXCEEDED - The desired adjustment would have exceeded
        the permitted security quota for this object.

--*/

{
    POBJECT_HEADER ObjectHeader;
    POBJECT_HEADER_QUOTA_INFO QuotaInfo;

    PAGED_CODE();

    //
    //  Map the object body to its object header and corresponding
    //  quota information block
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    //
    // If we never charged quota originaly then don't worry about it now.
    //
    if (ObjectHeader->QuotaBlockCharged == (PEPROCESS_QUOTA_BLOCK) 1) {
        return( STATUS_SUCCESS );
    }

    QuotaInfo = OBJECT_HEADER_TO_QUOTA_INFO( ObjectHeader );

    //
    //  If there isn't any quota info and the new size is greater
    //  then the default security quota then if the object uses
    //  the default value then we've exceeded quota otherwise
    //  let the caller get the quota
    //

    if ((QuotaInfo == NULL) && (NewSize > SE_DEFAULT_SECURITY_QUOTA)) {


        if (!(ObjectHeader->Flags & OB_FLAG_DEFAULT_SECURITY_QUOTA)) {

            return( STATUS_SUCCESS );
        }

        return( STATUS_QUOTA_EXCEEDED );

    //
    //  If the quota is not null and the new size is greater than the
    //  allowed quota charge then if the charge is zero we grant the
    //  request otherwise we've exceeded quota.
    //

    } else if ((QuotaInfo != NULL) && (NewSize > QuotaInfo->SecurityDescriptorCharge)) {

        if (QuotaInfo->SecurityDescriptorCharge == 0) {

            //
            //  Should really charge quota here.
            //

            //  QuotaInfo->SecurityDescriptorCharge = SeComputeSecurityQuota( NewSize );

            return( STATUS_SUCCESS );
        }

        return( STATUS_QUOTA_EXCEEDED );

    //
    //  Otherwise we have two cases.  (1) there isn't any quota info but
    //  the size is within limits or (2) there is a quota info block and
    //  the size is within the specified security descriptor charge so
    //  return success to our caller
    //

    } else {

        return( STATUS_SUCCESS );
    }
}


NTSTATUS
ObAssignSecurity (
    IN PACCESS_STATE AccessState,
    IN PSECURITY_DESCRIPTOR ParentDescriptor OPTIONAL,
    IN PVOID Object,
    IN POBJECT_TYPE ObjectType
    )

/*++

Routine Description:

    This routine will assign a security descriptor to a newly created object.
    It assumes that the AccessState parameter contains a captured security
    descriptor.

Arguments:

     AccessState - The AccessState containing the security information
        for this object creation.

     ParentDescriptor - The security descriptor from the parent object, if
        available.

     Object - A pointer to the object being created.

     ObjectType - Supplies the type of object being created.

Return Value:

    STATUS_SUCCESS - indicates the operation was successful.

    STATUS_INVALID_OWNER - The owner SID provided as the owner of the
        target security descriptor is not one the caller is authorized
        to assign as the owner of an object.

    STATUS_PRIVILEGE_NOT_HELD - The caller does not have the privilege
        necessary to explicitly assign the specified system ACL.
        SeSecurityPrivilege privilege is needed to explicitly assign
        system ACLs to objects.

--*/

{
    PSECURITY_DESCRIPTOR NewDescriptor = NULL;
    NTSTATUS Status;
#if DBG
    KIRQL SaveIrql;
#endif

    PAGED_CODE();

    //
    //  SeAssignSecurity will construct the final version
    //  of the security  descriptor
    //

    Status = SeAssignSecurity( ParentDescriptor,
                               AccessState->SecurityDescriptor,
                               &NewDescriptor,
                               (BOOLEAN)(ObjectType == ObpDirectoryObjectType),
                               &AccessState->SubjectSecurityContext,
                               &ObjectType->TypeInfo.GenericMapping,
                               PagedPool );

    if (!NT_SUCCESS( Status )) {

        return( Status );
    }

    ObpBeginTypeSpecificCallOut( SaveIrql );

    //
    //  Now invoke the security method callback to finish
    //  the assignment.
    //

    Status = (*ObjectType->TypeInfo.SecurityProcedure)( Object,
                                                        AssignSecurityDescriptor,
                                                        NULL,
                                                        NewDescriptor,
                                                        NULL,
                                                        NULL,
                                                        PagedPool,
                                                        &ObjectType->TypeInfo.GenericMapping );

    ObpEndTypeSpecificCallOut( SaveIrql, "Security", ObjectType, Object );

    if (!NT_SUCCESS( Status )) {

        //
        // The attempt to assign the security descriptor to the object
        // failed.  Free the space used by the new security descriptor.
        //

        SeDeassignSecurity( &NewDescriptor );
    }

    //
    //  And return to our caller
    //

    return( Status );
}



NTSTATUS
ObQuerySecurityDescriptorInfo(
    IN PVOID Object,
    IN PSECURITY_INFORMATION SecurityInformation,
    OUT PSECURITY_DESCRIPTOR SecurityDescriptor,
    IN OUT PULONG Length,
    IN PSECURITY_DESCRIPTOR *ObjectsSecurityDescriptor
    )
/*++

Routine Description:

    This routine will extract the desired information from the
    passed security descriptor and return the information in
    the passed buffer as a security descriptor in self-relative
    format.

    This routine assumes that all parameters are captured and
    safe to reference.

Arguments:

    Object - Object that is having its security queried

    SecurityInformation - Specifies what information is being queried.

    SecurityDescriptor - Supplies the buffer to output the requested
        information into.

        This buffer has been probed only to the size indicated by
        the Length parameter.  Since it still points into user space,
        it must always be accessed in a try clause.

    Length - Supplies the address of a variable containing the length of
        the security descriptor buffer.  Upon return this variable will
        contain the length needed to store the requested information.

    ObjectsSecurityDescriptor - Supplies the address of a pointer to
        the objects security descriptor.  The passed security descriptor
        must be in self-relative format.

Return Value:

    NTSTATUS - STATUS_SUCCESS if successful and an appropriate error value
        otherwise

--*/
{
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    PSECURITY_DESCRIPTOR ReferencedSecurityDescriptor;

    PAGED_CODE();

    UNREFERENCED_PARAMETER (ObjectsSecurityDescriptor);

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    //
    // Reference the security descriptor
    //
    ReferencedSecurityDescriptor = ObpReferenceSecurityDescriptor( ObjectHeader );

    Status = SeQuerySecurityDescriptorInfo( SecurityInformation,
                                            SecurityDescriptor,
                                            Length,
                                            &ReferencedSecurityDescriptor
                                            );

    if (ReferencedSecurityDescriptor != NULL) {
        ObDereferenceSecurityDescriptor ( ReferencedSecurityDescriptor, 1 );
    }

    return( Status );
}



NTSTATUS
ObSetSecurityDescriptorInfo (
    IN PVOID Object,
    IN PSECURITY_INFORMATION SecurityInformation,
    IN OUT PSECURITY_DESCRIPTOR SecurityDescriptor,
    IN OUT PSECURITY_DESCRIPTOR *ObjectsSecurityDescriptor,
    IN POOL_TYPE PoolType,
    IN PGENERIC_MAPPING GenericMapping
    )

/*++

Routine Description:

    Sets the security descriptor on an already secure object.

Arguments:

    Object - Pointer to the object being modified.

    SecurityInformation - Describes which information in the SecurityDescriptor parameter
        is relevent.

    SecurityDescriptor - Provides the new security information.

    ObjectsSecurityDescriptor - Provides/returns the object's security descriptor.

    PoolType - The pool the ObjectSecurityDescriptor is allocated from.

    GenericMapping - Supplies the generic mapping for the object.

Return Value:

    An appropriate status value

--*/

{
    PSECURITY_DESCRIPTOR OldDescriptor;
    PSECURITY_DESCRIPTOR NewDescriptor;
    PSECURITY_DESCRIPTOR CachedDescriptor;
    NTSTATUS Status;
    POBJECT_HEADER ObjectHeader;
    EX_FAST_REF OldRef;

    PAGED_CODE();

    //
    //  Check the rest of our input and call the default set security
    //  method.  Also make sure no one is modifying the security descriptor
    //  while we're looking at it.
    //

    ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

    //
    // In order to preserve some protected fields in the SD (like the SACL) we need to make sure that only one
    // thread updates it at any one time. If we didn't do this another modification could wipe out a SACL
    // an administrator was adding.
    //
    while (1) {

        //
        // Reference the security descriptor
        //

        OldDescriptor = ObpReferenceSecurityDescriptor( ObjectHeader );
        NewDescriptor = OldDescriptor;

        Status = SeSetSecurityDescriptorInfo( Object,
                                              SecurityInformation,
                                              SecurityDescriptor,
                                              &NewDescriptor,
                                              PoolType,
                                              GenericMapping );
        //
        //  If we successfully set the new security descriptor then we
        //  need to log it in our database and get yet another pointer
        //  to the finaly security descriptor
        //
        if ( NT_SUCCESS( Status )) {
            Status = ObLogSecurityDescriptor( NewDescriptor,
                                              &CachedDescriptor,
                                              ExFastRefGetAdditionalReferenceCount () + 1 );
            ExFreePool( NewDescriptor );
            if ( NT_SUCCESS( Status )) {
                //
                // Now we need to see if anyone else update this security descriptor inside the
                // gap where we didn't hold the lock. If they did then we just try it all again.
                //
                OldRef = ExFastRefCompareSwapObject ((PEX_FAST_REF)ObjectsSecurityDescriptor,
                                                     CachedDescriptor,
                                                     OldDescriptor);
                if (ExFastRefEqualObjects (OldRef, OldDescriptor)) {
                    //
                    // The swap occured ok. We must now flush any slow refers out of the slow ref path before
                    // dereferencing the object. We do this by obtaining and dropping the object lock.
                    //
                    ObpLockObject( ObjectHeader );
                    ObpUnlockObject( ObjectHeader );
                    //
                    // If there was an original object then we need to work out how many
                    // cached references there were (if any) and return them.
                    //
                    ObDereferenceSecurityDescriptor( OldDescriptor, ExFastRefGetUnusedReferences (OldRef) + 2 );
                    break;
                } else {
                    ObDereferenceSecurityDescriptor( OldDescriptor, 1 );
                    ObDereferenceSecurityDescriptor( CachedDescriptor, ExFastRefGetAdditionalReferenceCount () + 1);
                }

            } else {

                //
                //  Dereference old SecurityDescriptor
                //

                ObDereferenceSecurityDescriptor( OldDescriptor, 1 );
                break;
            }
        } else {

            //
            //  Dereference old SecurityDescriptor
            //
            if (OldDescriptor != NULL) {
                ObDereferenceSecurityDescriptor( OldDescriptor, 1 );
            }
            break;
        }
    }

    //
    //  And return to our caller
    //

    return( Status );
}


NTSTATUS
ObpValidateAccessMask (
    PACCESS_STATE AccessState
    )

/*++

Routine Description:

    Checks the desired access mask of a passed object against the
    passed security descriptor.

Arguments:

    AccessState - A pointer to the AccessState for the pending operation.

Return Value:

    Only returns STATUS_SUCCESS

--*/

{
    SECURITY_DESCRIPTOR *SecurityDescriptor = AccessState->SecurityDescriptor;

    PAGED_CODE();

    //
    //  First make sure the access state has a security descriptor.  If there
    //  is one and it has a system acl and the previously granted access did
    //  not include system security then add the fact that we want system
    //  security to the remaining desired access state.
    //

    if (SecurityDescriptor != NULL) {

        if ( SecurityDescriptor->Control & SE_SACL_PRESENT ) {

            if ( !(AccessState->PreviouslyGrantedAccess & ACCESS_SYSTEM_SECURITY)) {

                AccessState->RemainingDesiredAccess |= ACCESS_SYSTEM_SECURITY;
            }
        }
    }

    return( STATUS_SUCCESS );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\sources.inc ===
MAJORCOMP=ntos
MINORCOMP=ob

TARGETNAME=ob
TARGETTYPE=LIBRARY
TARGETPATH=obj

BUILD_PRODUCES=ntosob$(NT_UP)

INCLUDES=..;..\..\inc

MSC_WARNING_LEVEL=/W4 /WX

SOURCES=..\obinit.c   \
        ..\obcreate.c \
        ..\obhandle.c \
        ..\obinsert.c \
        ..\obperf.c   \
        ..\obref.c    \
        ..\obse.c     \
        ..\obtype.c   \
        ..\obdir.c    \
        ..\obdevmap.c \
        ..\oblink.c   \
        ..\obclose.c  \
        ..\obquery.c  \
        ..\obsdata.c  \
        ..\obwait.c   \
        ..\obvutil.c  \
        ..\fastref.c

PRECOMPILED_INCLUDE=..\obp.h
PRECOMPILED_PCH=obp.pch
PRECOMPILED_OBJ=obp.obj

OPTIONAL_NTTEST=tob
UMTEST=uob

SOURCES_USED=..\sources.inc
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obvutil.h ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    obvutil.h

Abstract:

    This header exposes various utilities required to do driver verification.

Author:

    Adrian J. Oney (adriao) 20-Apr-1998

Environment:

    Kernel mode

Revision History:

    AdriaO      06/15/2000 - Seperated out from ntos\io\flunkirp.h

--*/

LONG_PTR
ObvUtilStartObRefMonitoring(
    IN PDEVICE_OBJECT DeviceObject
    );

LONG_PTR
ObvUtilStopObRefMonitoring(
    IN PDEVICE_OBJECT DeviceObject,
    IN LONG StartSkew
    );
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\tob.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    tex.c

Abstract:

    Test program for the OB subcomponent of the NTOS project

Author:

    Steve Wood (stevewo) 31-Mar-1989

Revision History:

--*/

#include "obp.h"

GENERIC_MAPPING MyGenericMapping = {
    STANDARD_RIGHTS_READ,
    STANDARD_RIGHTS_WRITE,
    STANDARD_RIGHTS_EXECUTE,
    STANDARD_RIGHTS_READ |
        STANDARD_RIGHTS_WRITE |
        STANDARD_RIGHTS_EXECUTE
};

typedef struct _OBJECTTYPEA {
    KEVENT  Event;
    ULONG   TypeALength;
    ULONG   Stuff[ 4 ];
} OBJECTTYPEA, *POBJECTTYPEA;


typedef struct _OBJECTTYPEB {
    KSEMAPHORE Semaphore;
    ULONG   TypeBLength;
    ULONG   Stuff[ 16 ];
} OBJECTTYPEB, *POBJECTTYPEB;

OBJECT_ATTRIBUTES    DirectoryObjA;
OBJECT_ATTRIBUTES    ObjectAObjA;
OBJECT_ATTRIBUTES    ObjectBObjA;
STRING  DirectoryName;
STRING  ObjectAName;
STRING  ObjectBName;
STRING  ObjectAPathName;
STRING  ObjectBPathName;
STRING  ObjectTypeAName;
STRING  ObjectTypeBName;
POBJECT_TYPE    ObjectTypeA;
POBJECT_TYPE    ObjectTypeB;
PVOID   ObjectBodyA;
PVOID   ObjectBodyB;
PVOID   ObjectBodyA1;
PVOID   ObjectBodyA2;
POBJECTTYPEA ObjectA;
POBJECTTYPEB ObjectB;
HANDLE  DirectoryHandle;
HANDLE  ObjectHandleA1;
HANDLE  ObjectHandleB1;
HANDLE  ObjectHandleA2;
HANDLE  ObjectHandleB2;


VOID
DumpAProc(
    IN PVOID Object,
    IN POB_DUMP_CONTROL Control OPTIONAL
    )
{
    POBJECTTYPEA p = (POBJECTTYPEA)Object;
    ULONG i;

    DbgPrint( "DumpAProc: %lx\n", p );
    DbgPrint( "    Length: %ld\n", p->TypeALength );
    for (i=0; i<4; i++) {
        DbgPrint( "    Stuff[%ld]: %ld\n", i, p->Stuff[i] );
        }
}

char *OpenReasonStrings[] = {
    "ObCreateHandle",
    "ObOpenHandle",
    "ObDuplicateHandle",
    "ObInheritHandle"
};

VOID
OpenAProc(
    IN OB_OPEN_REASON OpenReason,
    IN PEPROCESS Process OPTIONAL,
    IN PVOID Object,
    IN ACCESS_MASK GrantedAccess,
    IN ULONG HandleCount
    )
{
    DbgPrint( "OpenAProc: OpenReason = %s  Process: %lx  \n",
             OpenReasonStrings[ OpenReason ], Process );
    DbgPrint( "    Object: %lx  Access: %lx  Count: %lu\n",
             Object, GrantedAccess, HandleCount );
}


VOID
CloseAProc(
    IN PEPROCESS Process OPTIONAL,
    IN PVOID Object,
    IN ACCESS_MASK GrantedAccess,
    IN ULONG ProcessHandleCount,
    IN ULONG SystemHandleCount
    )
{
    DbgPrint( "CloseAProc: Process: %lx  \n", Process );
    DbgPrint( "    Object: %lx  Access: %lx  ProcessHandleCount: %lu  SystemHandleCount: %lu\n",
             Object, GrantedAccess, ProcessHandleCount, SystemHandleCount );
}


VOID
DeleteAProc(
    IN  PVOID   Object
    )
{
    DbgPrint( "DeleteAProc: %lx\n", Object );
}

NTSTATUS
ParseAProc(
    IN PVOID ParseObject,
    IN ULONG DesiredAccess,
    IN KPROCESSOR_MODE AccessMode,
    IN ULONG Attributes,
    IN OUT PSTRING CompleteName,
    IN OUT PSTRING RemainingName,
    IN OUT PVOID Context OPTIONAL,
    OUT PVOID *Object
    )
{
    DbgPrint( "ParseAProc: %lx\n", ParseObject );
    DbgPrint( "    CompleteName:  %.*s\n", CompleteName->Length,
                                         CompleteName->Buffer );
    DbgPrint( "    RemainingName: %.*s\n", RemainingName->Length,
                                         RemainingName->Buffer );
    ObReferenceObjectByPointer(
        ParseObject,
        DesiredAccess,
        ObjectTypeA,
        AccessMode
        );

    *Object = ParseObject;
    return( STATUS_SUCCESS );
}


VOID
DumpBProc(
    IN PVOID Object,
    IN POB_DUMP_CONTROL Control OPTIONAL
    )
{
    POBJECTTYPEB p = (POBJECTTYPEB)Object;
    ULONG i;

    DbgPrint( "DumpBProc: %lx\n", p );
    DbgPrint( "    Length: %ld\n", p->TypeBLength );
    for (i=0; i<16; i++) {
        DbgPrint( "    Stuff[%ld]: %ld\n", i, p->Stuff[i] );
        }
}

VOID
DeleteBProc(
    IN  PVOID   Object
    )
{
    DbgPrint( "DeleteBProc: %lx\n", Object );
}


BOOLEAN
obtest( void )
{
    ULONG i;
    HANDLE Handles[ 2 ];
    NTSTATUS Status;
    OBJECT_TYPE_INITIALIZER ObjectTypeInitializer;

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    RtlInitString( &ObjectTypeAName, "ObjectTypeA" );
    RtlInitString( &ObjectTypeBName, "ObjectTypeB" );

    RtlZeroMemory( &ObjectTypeInitializer, sizeof( ObjectTypeInitializer ) );
    ObjectTypeInitializer.Length = sizeof( ObjectTypeInitializer );
    ObjectTypeInitializer.ValidAccessMask = -1;

    ObjectTypeInitializer.PoolType = NonPagedPool;
    ObjectTypeInitializer.MaintainHandleCount = TRUE;
    ObjectTypeInitializer.DumpProcedure = DumpAProc;
    ObjectTypeInitializer.OpenProcedure = OpenAProc;
    ObjectTypeInitializer.CloseProcedure = CloseAProc;
    ObjectTypeInitializer.DeleteProcedure = DeleteAProc;
    ObjectTypeInitializer.ParseProcedure = ParseAProc;
    ObCreateObjectType(
        &ObjectTypeAName,
        &ObjectTypeInitializer,
        (PSECURITY_DESCRIPTOR)NULL,
        &ObjectTypeA
        );

    ObjectTypeInitializer.PoolType = NonPagedPool;
    ObjectTypeInitializer.MaintainHandleCount = FALSE;
    ObjectTypeInitializer.GenericMapping = MyGenericMapping;
    ObjectTypeInitializer.DumpProcedure = DumpBProc;
    ObjectTypeInitializer.OpenProcedure = NULL;
    ObjectTypeInitializer.CloseProcedure = NULL;
    ObjectTypeInitializer.DeleteProcedure = DeleteBProc;
    ObjectTypeInitializer.ParseProcedure = NULL;
    ObCreateObjectType(
        &ObjectTypeBName,
        &ObjectTypeInitializer,
        (PSECURITY_DESCRIPTOR)NULL,
        &ObjectTypeB
        );

    ObpDumpTypes( NULL );

    RtlInitString( &DirectoryName, "\\MyObjects" );
    InitializeObjectAttributes( &DirectoryObjA,
                                &DirectoryName,
                                OBJ_PERMANENT |
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    NtCreateDirectoryObject( &DirectoryHandle,
                             0,
                             &DirectoryObjA
                           );
    NtClose( DirectoryHandle );

    RtlInitString( &ObjectAName, "\\myobjects\\ObjectA" );
    InitializeObjectAttributes( &ObjectAObjA,
                                &ObjectAName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );

    RtlInitString( &ObjectBName, "\\myobjects\\ObjectB" );
    InitializeObjectAttributes( &ObjectBObjA,
                                &ObjectBName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );

    Status = ObCreateObject(
        KernelMode,
        ObjectTypeA,
        &ObjectAObjA,
        KernelMode,
        NULL,
        (ULONG)sizeof( OBJECTTYPEA ),
        0L,
        0L,
        (PVOID *)&ObjectBodyA
        );

    ObjectA = (POBJECTTYPEA)ObjectBodyA;
    ObjectA->TypeALength = sizeof( *ObjectA );
    for (i=0; i<4; i++) {
        ObjectA->Stuff[i] = i+1;
        }
    KeInitializeEvent( &ObjectA->Event, NotificationEvent, TRUE );

    Status = ObCreateObject(
        KernelMode,
        ObjectTypeB,
        &ObjectBObjA,
        KernelMode,
        NULL,
        (ULONG)sizeof( OBJECTTYPEB ),
        0L,
        0L,
        (PVOID *)&ObjectBodyB
        );

    ObjectB = (POBJECTTYPEB)ObjectBodyB;
    ObjectB->TypeBLength = sizeof( *ObjectB );
    for (i=0; i<16; i++) {
        ObjectB->Stuff[i] = i+1;
        }
    KeInitializeSemaphore ( &ObjectB->Semaphore, 2L, 2L );

    Status = ObInsertObject(
        ObjectBodyA,
        SYNCHRONIZE | 0x3,
        NULL,
        1,
        &ObjectBodyA,
        &ObjectHandleA1
        );

    DbgPrint( "Status: %lx  ObjectBodyA: %lx  ObjectHandleA1: %lx\n",
             Status, ObjectBodyA, ObjectHandleA1
           );

    Status = ObInsertObject(
        ObjectBodyB,
        SYNCHRONIZE | 0x1,
        NULL,
        1,
        &ObjectBodyB,
        &ObjectHandleB1
        );

    DbgPrint( "Status: %lx  ObjectBodyB: %lx  ObjectHandleB1: %lx\n",
             Status, ObjectBodyB, ObjectHandleB1
           );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    RtlInitString( &ObjectAName, "\\MyObjects\\ObjectA" );
    InitializeObjectAttributes( &ObjectAObjA,
                                &ObjectAName,
                                OBJ_OPENIF,
                                NULL,
                                NULL
                              );

    Status = ObCreateObject(
        KernelMode,
        ObjectTypeA,
        &ObjectAObjA,
        KernelMode,
        NULL,
        (ULONG)sizeof( OBJECTTYPEA ),
        0L,
        0L,
        (PVOID *)&ObjectBodyA1
        );


    Status = ObInsertObject(
        ObjectBodyA1,
        SYNCHRONIZE | 0x3,
        NULL,
        1,
        &ObjectBodyA2,
        &ObjectHandleA2
        );

    DbgPrint( "Status: %lx  ObjectBodyA1: %lx  ObjectBodyA2: %lx  ObjectHandleA2: %lx\n",
             Status, ObjectBodyA1, ObjectBodyA2, ObjectHandleA2
           );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );
    NtClose( ObjectHandleA2 );
    ObDereferenceObject( ObjectBodyA2 );    // ObInsertObject,ObjectPointerBias

    NtWaitForSingleObject( ObjectHandleB1, TRUE, NULL );
    Handles[ 0 ] = ObjectHandleA1;
    Handles[ 1 ] = ObjectHandleB1;
    NtWaitForMultipleObjects( 2, Handles, WaitAny, TRUE, NULL );

    ObReferenceObjectByHandle(
        ObjectHandleA1,
        0L,
        ObjectTypeA,
        KernelMode,
        &ObjectBodyA,
        NULL
        );

    ObReferenceObjectByHandle(
        ObjectHandleB1,
        0L,
        ObjectTypeB,
        KernelMode,
        &ObjectBodyB,
        NULL
        );
    DbgPrint( "Reference Handle %lx = %lx\n", ObjectHandleA1, ObjectBodyA );

    DbgPrint( "Reference Handle %lx = %lx\n", ObjectHandleB1, ObjectBodyB );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    ObReferenceObjectByPointer(
        ObjectBodyA,
        0L,
        ObjectTypeA,
        KernelMode
        );

    ObReferenceObjectByPointer(
        ObjectBodyB,
        0L,
        ObjectTypeB,
        KernelMode
        );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    RtlInitString( &ObjectAPathName, "\\MyObjects\\ObjectA" );
    RtlInitString( &ObjectBPathName, "\\MyObjects\\ObjectB" );
    ObReferenceObjectByName(
        &ObjectAPathName,
        OBJ_CASE_INSENSITIVE,
        0L,
        ObjectTypeA,
        KernelMode,
        NULL,
        &ObjectBodyA
        );

    ObReferenceObjectByName(
        &ObjectBPathName,
        OBJ_CASE_INSENSITIVE,
        0L,
        ObjectTypeB,
        KernelMode,
        NULL,
        &ObjectBodyB
        );

    DbgPrint( "Reference Name %s = %lx\n", ObjectAPathName.Buffer,
            ObjectBodyA );

    DbgPrint( "Reference Name %s = %lx\n", ObjectBPathName.Buffer,
            ObjectBodyB );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    ObDereferenceObject( ObjectBodyA );     // ObInsertObject,ObjectPointerBias
    ObDereferenceObject( ObjectBodyB );

    ObDereferenceObject( ObjectBodyA );     // ObReferenceObjectByHandle
    ObDereferenceObject( ObjectBodyB );

    ObDereferenceObject( ObjectBodyA );     // ObReferenceObjectByPointer
    ObDereferenceObject( ObjectBodyB );

    ObDereferenceObject( ObjectBodyA );     // ObReferenceObjectByName
    ObDereferenceObject( ObjectBodyB );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    InitializeObjectAttributes( &ObjectAObjA,
                                &ObjectAPathName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    ObOpenObjectByName(
        &ObjectAObjA,
        0L,
        NULL,
        ObjectTypeA,
        KernelMode,
        NULL,
        &ObjectHandleA2
        );

    InitializeObjectAttributes( &ObjectBObjA,
                                &ObjectBPathName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    ObOpenObjectByName(
        &ObjectBObjA,
        0L,
        NULL,
        ObjectTypeB,
        KernelMode,
        NULL,
        &ObjectHandleB2
        );

    DbgPrint( "Open Object Name %s = %lx\n", ObjectAPathName.Buffer,
            ObjectHandleA2 );

    DbgPrint( "Open Object Name %s = %lx\n", ObjectBPathName.Buffer,
            ObjectHandleB2 );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    NtClose( ObjectHandleA1 );
    NtClose( ObjectHandleB1 );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    ObReferenceObjectByHandle(
        ObjectHandleA2,
        0L,
        ObjectTypeA,
        KernelMode,
        &ObjectBodyA,
        NULL
        );

    ObReferenceObjectByHandle(
        ObjectHandleB2,
        0L,
        ObjectTypeB,
        KernelMode,
        &ObjectBodyB,
        NULL
        );
    DbgPrint( "Reference Handle %lx = %lx\n", ObjectHandleA2, ObjectBodyA );

    DbgPrint( "Reference Handle %lx = %lx\n", ObjectHandleB2, ObjectBodyB );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    ObOpenObjectByPointer(
        ObjectBodyA,
        OBJ_CASE_INSENSITIVE,
        0L,
        NULL,
        ObjectTypeA,
        KernelMode,
        &ObjectHandleA1
        );

    ObOpenObjectByPointer(
        ObjectBodyB,
        OBJ_CASE_INSENSITIVE,
        0L,
        NULL,
        ObjectTypeB,
        KernelMode,
        &ObjectHandleB1
        );

    DbgPrint( "Open Object Pointer %lx = %lx\n", ObjectBodyA,
            ObjectHandleA1 );

    DbgPrint( "Open Object Pointer %lx = %lx\n", ObjectBodyB,
            ObjectHandleB1 );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    ObReferenceObjectByHandle(
        ObjectHandleA1,
        0L,
        ObjectTypeA,
        KernelMode,
        &ObjectBodyA,
        NULL
        );

    ObReferenceObjectByHandle(
        ObjectHandleB1,
        0L,
        ObjectTypeB,
        KernelMode,
        &ObjectBodyB,
        NULL
        );
    DbgPrint( "Reference Handle %lx = %lx\n", ObjectHandleA1, ObjectBodyA );

    DbgPrint( "Reference Handle %lx = %lx\n", ObjectHandleB1, ObjectBodyB );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    ObDereferenceObject( ObjectBodyA );     // ObReferenceObjectByHandle
    ObDereferenceObject( ObjectBodyB );

    ObDereferenceObject( ObjectBodyA );     // ObReferenceObjectByHandle
    ObDereferenceObject( ObjectBodyB );

    NtClose( ObjectHandleA1 );
    NtClose( ObjectHandleB1 );

    NtClose( ObjectHandleA2 );
    NtClose( ObjectHandleB2 );

    ObpDumpObjectTable( ObpGetObjectTable(), NULL );

    TestFunction = NULL;

    return( TRUE );
}


int
_CDECL
main(
    int argc,
    char *argv[]
    )
{
#ifdef SIMULATOR
    extern ULONG MmNumberOfPhysicalPages;
    char *s;

    while (--argc) {
        s = *++argv;
        if (*s == '-') {
            s++;
            if (*s >= '0' && *s <= '9') {
                MmNumberOfPhysicalPages = atol( s );
                DbgPrint( "INIT: Configured with %d pages of physical memory.\n",
                          MmNumberOfPhysicalPages
                        );
                }
            else
            if (!strcmp( s, "SCR" )) {
                IoInitIncludeDevices |= IOINIT_SCREEN;
                DbgPrint( "INIT: Configured with Screen device driver.\n" );
                }
            else
            if (!strcmp( s, "MOU" )) {
                IoInitIncludeDevices |= IOINIT_MOUSE;
                DbgPrint( "INIT: Configured with Mouse device driver.\n" );
                }
            else
            if (!strcmp( s, "KBD" )) {
                IoInitIncludeDevices |= IOINIT_KEYBOARD;
                DbgPrint( "INIT: Configured with Keyboard device driver.\n" );
                }
            else
            if (!strcmp( s, "RAW" )) {
                IoInitIncludeDevices |= IOINIT_RAWFS;
                DbgPrint( "INIT: Configured with RAW File System driver.\n" );
                }
            else
            if (!strcmp( s, "FAT" )) {
                IoInitIncludeDevices |= IOINIT_FATFS;
                DbgPrint( "INIT: Configured with FAT File System driver.\n" );
                }
            else
            if (!strcmp( s, "SVR" )) {
                IoInitIncludeDevices |= IOINIT_DDFS |
                                        IOINIT_FATFS |
                                        IOINIT_SERVER_FSD |
                                        IOINIT_SERVER_LOOPBACK |
                                        IOINIT_NBF;
                if ( MmNumberOfPhysicalPages < 512 ) {
                    MmNumberOfPhysicalPages = 512;
                }
                DbgPrint( "INIT: Configured for LAN Manager server.\n" );
                }
            else {
                DbgPrint( "INIT: Invalid switch - %s\n", s );
                }
            }
        else {
            break;
            }
        }

#endif // SIMULATOR
    TestFunction = NULL;
    KiSystemStartup();
    return( 0 );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\uob.c ===
/*++

Copyright (c) 1989  Microsoft Corporation

Module Name:

    uob.c

Abstract:

    Object Manager User Mode Test Program

Author:

    Steve Wood (stevewo) 03-Aug-1989

Environment:

    User Mode

Revision History:

--*/

#include <nt.h>
#include <ntrtl.h>
#include <string.h>

STRING  DirTypeName;
STRING  LinkTypeName;

VOID
TestParent( VOID );

VOID
TestChild( VOID );

VOID
DumpObjectDirs(
    IN PCH DirName,
    IN ULONG Level
    )
{
    OBJECT_ATTRIBUTES ObjectAttributes;
    STRING Name;
    HANDLE Handle;
    ULONG Context, Length;
    NTSTATUS Status;
    BOOLEAN RestartScan;
    POBJECT_DIRECTORY_INFORMATION DirInfo;
    CHAR DirInfoBuffer[ 256 ];
    CHAR SubDirName[ 128 ];
    STRING LinkName;
    STRING LinkTarget;
    HANDLE LinkHandle;

    RtlInitString( &Name, DirName );
    InitializeObjectAttributes( &ObjectAttributes,
                                &Name,
                                OBJ_OPENIF | OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    NtCreateDirectoryObject( &Handle,
                             DIRECTORY_ALL_ACCESS,
                             &ObjectAttributes
                           );

    DirInfo = (POBJECT_DIRECTORY_INFORMATION)&DirInfoBuffer;
    RestartScan = TRUE;
    while (TRUE) {
        Status = NtQueryDirectoryObject( Handle,
                                         (PVOID)DirInfo,
                                         sizeof( DirInfoBuffer ),
                                         TRUE,
                                         RestartScan,
                                         &Context,
                                         &Length
                                       );
        if (!NT_SUCCESS( Status )) {
            break;
            }

        DbgPrint( "%s%s%Z - %Z",
                 DirName,
                 Level ? "\\" : "",
                 &DirInfo->Name,
                 &DirInfo->TypeName
                 );
        if (RtlEqualString( &DirInfo->TypeName, &DirTypeName, TRUE )) {
            DbgPrint( "\n" );
            strcpy( SubDirName, DirName );
            if (Level) {
                strcat( SubDirName, "\\" );
                }
            strcat( SubDirName, DirInfo->Name.Buffer );
            DumpObjectDirs( SubDirName, Level+1 );
            }
        else
        if (RtlEqualString( &DirInfo->TypeName, &LinkTypeName, TRUE )) {
            strcpy( SubDirName, DirName );
            if (Level) {
                strcat( SubDirName, "\\" );
                }
            strcat( SubDirName, DirInfo->Name.Buffer );
            RtlInitString( &LinkName, SubDirName );
            InitializeObjectAttributes( &ObjectAttributes,
                                        &LinkName,
                                        0,
                                        NULL,
                                        NULL
                                      );
            Status = NtOpenSymbolicLinkObject( &LinkHandle,
                                               SYMBOLIC_LINK_ALL_ACCESS,
                                               &ObjectAttributes
                                             );
            if (!NT_SUCCESS( Status )) {
                DbgPrint( " - unable to open symbolic link (%X)\n", Status  );
                }
            else {
                LinkTarget.MaximumLength = sizeof( SubDirName );
                LinkTarget.Length = 0;
                LinkTarget.Buffer = SubDirName;
                Status = NtQuerySymbolicLinkObject( LinkHandle,
                                                    &LinkTarget
                                                  );
                if (!NT_SUCCESS( Status )) {
                    DbgPrint( " - unable to query symbolic link target (%X)\n", Status );
                    }
                else {
                    DbgPrint( " => %Z\n", &LinkTarget );
                    }

                NtClose( LinkHandle );
                }
            }
        else {
            DbgPrint( "\n" );
            }

        RestartScan = FALSE;
        }

    NtClose( Handle );
}

char ParameterBuffer[ 4096 ];

main(
    int argc,
    char **argv,
    char **envp,
    int DebugFlag
    )
{
    NTSTATUS Status;
    STRING ImageName;
    PRTL_USER_PROCESS_PARAMETERS ProcessParameters;
    RTL_USER_PROCESS_INFORMATION ProcessInformation;

    if (argc == 1) {
        TestParent();

        Parameters[ RTL_USER_PROC_PARAMS_IMAGEFILE ] = argv[ 0 ];

        Parameters[ RTL_USER_PROC_PARAMS_CMDLINE ] = " CHILD";

        Parameters[ RTL_USER_PROC_PARAMS_DEBUGFLAG ] =
             DebugFlag ? "1" : "0";

        Parameters[ RTL_USER_PROC_PARAMS_DEBUGFLAG+1 ] = NULL;

        Arguments[ 0 ] = argv[ 0 ];
        Arguments[ 1 ] = "CHILD";
        Arguments[ 2 ] = NULL;

        ProcessParameters = (PRTL_USER_PROCESS_PARAMETERS)ParameterBuffer;
        ProcessParameters->Length = 0;
        ProcessParameters->MaximumLength = sizeof( ParameterBuffer );

        Status = RtlVectorsToProcessParameters( Arguments,
                                                envp,
                                                Parameters,
                                                ProcessParameters
                                              );
        if (!NT_SUCCESS( Status )) {
            DbgPrint( "RtlVectorToProcessParameters failed - Status = %X\n",
                      Status
                    );
            }
        else {
            RtlInitString( &ImageName, "\\C:\\TMP\\UOB.EXE" );
            Status = RtlCreateUserProcess( &ImageName,
                                           NULL,
                                           NULL,
                                           NULL,
                                           TRUE,
                                           NULL,
                                           NULL,
                                           ProcessParameters,
                                           &ProcessInformation,
                                           NULL
                                         );
            if (!NT_SUCCESS( Status )) {
                DbgPrint( "RtlCreateUserProcess( %Z ) failed - Status = %X\n",
                          &ImageName, Status
                        );
                }
            else {
                Status = NtResumeThread( ProcessInformation.Thread, NULL );
                Status = NtWaitForSingleObject( ProcessInformation.Process,
                                                FALSE,
                                                (PLARGE_INTEGER)NULL
                                              );
                if (!NT_SUCCESS( Status )) {
                    DbgPrint( "NtWaitForSingleObject failed - Status = %X\n",
                              Status
                            );
                    }
                }
            }
        }
    else {
        TestChild();
        }

    NtTerminateProcess( NtCurrentProcess(), Status );
}


VOID
TestParent( VOID )
{
    NTSTATUS Status;
    STRING DirectoryName;
    STRING LinkName;
    STRING LinkTarget;
    STRING SectionName;
    OBJECT_ATTRIBUTES ObjectAttributes;
    HANDLE DirectoryHandle, LinkHandle, SectionHandle;
    ULONG ReturnedLength;
    CHAR ObjectInfoBuffer[ 512 ];
    OBJECT_BASIC_INFORMATION ObjectBasicInfo;
    POBJECT_NAME_INFORMATION ObjectNameInfo;
    POBJECT_TYPE_INFORMATION ObjectTypeInfo;
    LARGE_INTEGER SectionSize;

    Status = STATUS_SUCCESS;

    DbgPrint( "Entering Object Manager User Mode Test Program\n" );

    RtlInitString( &SectionName, "\\A:\\OSO001.MSG" );
    InitializeObjectAttributes( &ObjectAttributes,
                                &SectionName,
                                OBJ_OPENIF | OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );

    SectionSize.LowPart = 0x1000;
    SectiinSize.HighPart = 0;
    Status = NtCreateSection( &SectionHandle,
                              GENERIC_READ,
                              &ObjectAttributes,
                              &SectionSize,
                              PAGE_READONLY,
                              SEC_RESERVE,
                              NULL
                            );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to create %Z section object (%X) [OK]\n", &SectionName, Status );
        }

    RtlInitString( &DirectoryName, "\\Drives" );
    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE | OBJ_PERMANENT,
                                NULL,
                                (PSECURITY_DESCRIPTOR)1

                              );
    ObjectAttributes.Length = 0;
    Status = NtCreateDirectoryObject( &DirectoryHandle,
                                      -1,
                                      &ObjectAttributes
                                    );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to create %Z directory object (%X) [OK]\n",
                 &DirectoryName, Status );
        }

    RtlInitString( &DirectoryName, "\\Drives" );
    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE | OBJ_PERMANENT,
                                NULL,
                                (PSECURITY_DESCRIPTOR)1

                              );
    ObjectAttributes.Length = 0;
    Status = NtCreateDirectoryObject( &DirectoryHandle,
                                      DIRECTORY_ALL_ACCESS,
                                      &ObjectAttributes
                                    );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to create %Z directory object (%X) [OK]\n",
                 &DirectoryName, Status );
        }

    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                -1,
                                NULL,
                                (PSECURITY_DESCRIPTOR)1

                              );
    Status = NtCreateDirectoryObject( &DirectoryHandle,
                                      DIRECTORY_ALL_ACCESS,
                                      &ObjectAttributes
                                    );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to create %Z directory object (%X) [OK]\n",
                 &DirectoryName, Status );
        }

    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE | OBJ_PERMANENT,
                                NULL,
                                (PSECURITY_DESCRIPTOR)1

                              );
    Status = NtCreateDirectoryObject( &DirectoryHandle,
                                      DIRECTORY_ALL_ACCESS,
                                      &ObjectAttributes
                                    );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to create %Z directory object (%X) [OK]\n",
                 &DirectoryName, Status );
        }

    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE | OBJ_PERMANENT,
                                NULL,
                                NULL

                              );
    Status = NtCreateDirectoryObject( &DirectoryHandle,
                                      DIRECTORY_ALL_ACCESS,
                                      &ObjectAttributes
                                    );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to create %Z directory object (%X)\n",
                 &DirectoryName, Status );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    Status = NtClose( DirectoryHandle );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to close %Z directory object handle - %lx (%X)\n",
                 &DirectoryName,
                 DirectoryHandle,
                 Status
                 );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    Status = NtOpenDirectoryObject( &DirectoryHandle,
                                    DIRECTORY_ALL_ACCESS,
                                    &ObjectAttributes
                                  );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to open %Z directory object (%X)\n",
                 &DirectoryName, Status );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    Status = NtQueryObject( DirectoryHandle,
                            ObjectBasicInformation,
                            &ObjectBasicInfo,
                            sizeof( ObjectBasicInfo ),
                            &ReturnedLength
                          );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "NtQueryObject( %lx, ObjectBasicInfo ) failed - Status == %X\n",
                 DirectoryHandle,
                 Status
                 );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }
    DbgPrint( "NtQueryObject( %lx, ObjectBasicInfo ) returned %lx bytes\n",
             DirectoryHandle,
             ReturnedLength
             );
    DbgPrint( "    Attributes = %lx\n",          ObjectBasicInfo.Attributes );
    DbgPrint( "    GrantedAccess = %lx\n",       ObjectBasicInfo.GrantedAccess );
    DbgPrint( "    HandleCount = %lx\n",         ObjectBasicInfo.HandleCount );
    DbgPrint( "    PointerCount = %lx\n",        ObjectBasicInfo.PointerCount );
    DbgPrint( "    PagedPoolCharge = %lx\n",     ObjectBasicInfo.PagedPoolCharge );
    DbgPrint( "    NonPagedPoolCharge = %lx\n",  ObjectBasicInfo.NonPagedPoolCharge );
    DbgPrint( "    NameInfoSize = %lx\n",        ObjectBasicInfo.NameInfoSize );
    DbgPrint( "    TypeInfoSize = %lx\n",        ObjectBasicInfo.TypeInfoSize );
    DbgPrint( "    SecurityDescriptorSize = %lx\n", ObjectBasicInfo.SecurityDescriptorSize );

    ObjectNameInfo = (POBJECT_NAME_INFORMATION)ObjectInfoBuffer;
    Status = NtQueryObject( DirectoryHandle,
                            ObjectNameInformation,
                            ObjectNameInfo,
                            sizeof( ObjectInfoBuffer ),
                            &ReturnedLength
                          );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "NtQueryObject( %lx, ObjectNameInfo ) failed - Status == %X\n",
                 DirectoryHandle,
                 Status
                 );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }
    DbgPrint( "NtQueryObject( %lx, ObjectNameInfo ) returned %lx bytes\n",
             DirectoryHandle,
             ReturnedLength
             );
    DbgPrint( "    Name = (%ld,%ld) '%Z'\n",
             ObjectNameInfo->Name.MaximumLength,
             ObjectNameInfo->Name.Length,
             &ObjectNameInfo->Name
           );


    ObjectTypeInfo = (POBJECT_TYPE_INFORMATION)ObjectInfoBuffer;
    Status = NtQueryObject( DirectoryHandle,
                            ObjectTypeInformation,
                            ObjectTypeInfo,
                            sizeof( ObjectInfoBuffer ),
                            &ReturnedLength
                          );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "NtQueryObject( %lx, ObjectTypeInfo ) failed - Status == %X\n",
                 DirectoryHandle,
                 Status
                 );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }
    DbgPrint( "NtQueryObject( %lx, ObjectTypeInfo ) returned %lx bytes\n",
             DirectoryHandle,
             ReturnedLength
             );
    DbgPrint( "    TypeName = (%ld,%ld) '%Z'\n",
             ObjectTypeInfo->TypeName.MaximumLength,
             ObjectTypeInfo->TypeName.Length,
             &ObjectTypeInfo->TypeName
           );

    RtlInitString( &LinkName, "TestSymbolicLink" );
    InitializeObjectAttributes( &ObjectAttributes,
                                &LinkName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    ObjectAttributes.RootDirectory = DirectoryHandle;
    RtlInitString( &LinkTarget, "\\Device\\FileSystem" );
    Status = NtCreateSymbolicLinkObject( &LinkHandle,
                                         SYMBOLIC_LINK_ALL_ACCESS,
                                         &ObjectAttributes,
                                         &LinkTarget
                                       );

    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to create %Z => %Z symbolic link object (%X)\n",
                 &LinkName, &LinkTarget, Status );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    Status = NtClose( DirectoryHandle );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to close %Z directory object handle - %lx (%X)\n",
                 &DirectoryName,
                 DirectoryHandle,
                 Status
                 );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    RtlInitString( &DirTypeName, "Directory" );
    RtlInitString( &LinkTypeName, "SymbolicLink" );
    DumpObjectDirs( "\\", 0 );

    RtlInitString( &LinkName, "TestSymbolicLink" );
    InitializeObjectAttributes( &ObjectAttributes,
                                &LinkName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    ObjectAttributes.RootDirectory = LinkHandle;
    Status = NtOpenDirectoryObject( &DirectoryHandle,
                                    DIRECTORY_ALL_ACCESS,
                                    &ObjectAttributes
                                  );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to open %Z directory object (%X) [OK]\n", &DirectoryName, Status );
        }

    Status = NtClose( LinkHandle );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to close %Z symbolic link handle - %lx (%X)\n",
                 &LinkName,
                 LinkHandle,
                 Status
                 );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    Status = NtOpenDirectoryObject( &DirectoryHandle,
                                    DIRECTORY_ALL_ACCESS,
                                    &ObjectAttributes
                                  );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to open %Z directory object (%X)\n", &DirectoryName, Status );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    Status = NtMakeTemporaryObject( DirectoryHandle );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "NtMakeTemporaryObject( %lx ) failed - Status == %X\n",
                 DirectoryHandle,
                 Status
               );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    Status = NtClose( DirectoryHandle );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to close %Z directory object handle - %lx (%X)\n",
                 &DirectoryName,
                 DirectoryHandle,
                 Status
                 );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    Status = NtOpenDirectoryObject( &DirectoryHandle,
                                    DIRECTORY_ALL_ACCESS,
                                    &ObjectAttributes
                                  );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to open %Z directory object (%X) [OK]\n", &DirectoryName, Status );
        }

    RtlInitString( &DirectoryName, "\\ExclusiveDir" );
    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE | OBJ_EXCLUSIVE,
                                NULL,
                                NULL

                              );
    Status = NtCreateDirectoryObject( &DirectoryHandle,
                                      DIRECTORY_ALL_ACCESS,
                                      &ObjectAttributes
                                    );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to create %Z directory object (%X)\n",
                 &DirectoryName, Status );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE | OBJ_EXCLUSIVE,
                                NULL,
                                NULL
                              );
    Status = NtOpenDirectoryObject( &DirectoryHandle,
                                    DIRECTORY_ALL_ACCESS,
                                    &ObjectAttributes
                                  );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to open %Z directory object (%X)\n",
                 &DirectoryName, Status );
        NtTerminateProcess( NtCurrentProcess(), Status );
        }

    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    Status = NtOpenDirectoryObject( &DirectoryHandle,
                                    DIRECTORY_ALL_ACCESS,
                                    &ObjectAttributes
                                  );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to open %Z directory object (%X) [OK]\n",
                 &DirectoryName, Status );
        }

    DbgPrint( "Exiting Object Manager User Mode Test Program with Status = %X\n", Status );
}


VOID
TestChild( VOID )
{
    NTSTATUS Status;
    STRING DirectoryName;
    HANDLE DirectoryHandle;
    OBJECT_ATTRIBUTES ObjectAttributes;

    Status = STATUS_SUCCESS;

    DbgPrint( "Entering Object Manager User Mode Child Test Program\n" );

    RtlInitString( &DirectoryName, "\\ExclusiveDir" );
    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE,
                                NULL,
                                NULL
                              );
    Status = NtOpenDirectoryObject( &DirectoryHandle,
                                    DIRECTORY_ALL_ACCESS,
                                    &ObjectAttributes
                                  );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to open %Z directory object (%X) [OK]\n",
                 &DirectoryName, Status );
        }

    InitializeObjectAttributes( &ObjectAttributes,
                                &DirectoryName,
                                OBJ_CASE_INSENSITIVE | OBJ_EXCLUSIVE,
                                NULL,
                                NULL
                              );
    Status = NtOpenDirectoryObject( &DirectoryHandle,
                                    DIRECTORY_ALL_ACCESS,
                                    &ObjectAttributes
                                  );
    if (!NT_SUCCESS( Status )) {
        DbgPrint( "Unable to open %Z directory object (%X) [OK]\n",
                 &DirectoryName, Status );
        }

    DbgPrint( "Exiting Object Manager User Mode Child Test Program with Status = %X\n", Status );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\ob\obwait.c ===
/*++

Copyright (c) 1989  Microsoft Corporation
Copyright (c) 1992  Microsoft Corporation

Module Name:

    obwait.c

Abstract:

    This module implements the generic wait system services.

Author:

    Steve Wood (stevewo) 12-May-1989

Revision History:

--*/

#include "obp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, NtWaitForSingleObject)
#pragma alloc_text(PAGE, NtWaitForMultipleObjects)
#pragma alloc_text(PAGE, ObWaitForSingleObject)
#endif

//
//  We special case these three object types in the wait routine
//

extern POBJECT_TYPE ExEventObjectType;
extern POBJECT_TYPE ExMutantObjectType;
extern POBJECT_TYPE ExSemaphoreObjectType;


NTSTATUS
NtSignalAndWaitForSingleObject (
    IN HANDLE SignalHandle,
    IN HANDLE WaitHandle,
    IN BOOLEAN Alertable,
    IN PLARGE_INTEGER Timeout OPTIONAL
    )

/*++

Routine Description:

    This function atomically signals the specified signal object and then
    waits until the specified wait object attains a state of Signaled.  An
    optional timeout can also be specified.  If a timeout is not specified,
    then the wait will not be satisfied until the wait object attains a
    state of Signaled.  If a timeout is specified, and the wait object has
    not attained a state of Signaled when the timeout expires, then the
    wait is automatically satisfied.  If an explicit timeout value of zero
    is specified, then no wait will occur if the wait cannot be satisfied
    immediately.  The wait can also be specified as alertable.

Arguments:

    SignalHandle - Supplies the handle of the signal object.

    WaitHandle  - Supplies the handle for the wait object.

    Alertable - Supplies a boolean value that specifies whether the wait
        is alertable.

    Timeout - Supplies an pointer to an absolute or relative time over
        which the wait is to occur.

Return Value:

    The wait completion status.  A value of STATUS_TIMEOUT is returned if a
    timeout occurred.  A value of STATUS_SUCCESS is returned if the specified
    object satisfied the wait.  A value of STATUS_ALERTED is returned if the
    wait was aborted to deliver an alert to the current thread.  A value of
    STATUS_USER_APC is returned if the wait was aborted to deliver a user
    APC to the current thread.

--*/

{
    OBJECT_HANDLE_INFORMATION HandleInformation;
    KPROCESSOR_MODE PreviousMode;
    PVOID RealObject;
    PVOID SignalObject;
    POBJECT_HEADER SignalObjectHeader;
    NTSTATUS Status;
    LARGE_INTEGER TimeoutValue;
    PVOID WaitObject;
    POBJECT_HEADER WaitObjectHeader;

    //
    //  Establish an exception handler and probe the specified timeout value
    //  if necessary.  If the probe fails, then return the exception code as
    //  the service status.
    //

    PreviousMode = KeGetPreviousMode();

    if ((ARGUMENT_PRESENT(Timeout)) && (PreviousMode != KernelMode)) {

        try {

            TimeoutValue = ProbeAndReadLargeInteger(Timeout);
            Timeout = &TimeoutValue;

        } except(EXCEPTION_EXECUTE_HANDLER) {

            return GetExceptionCode();
        }
    }

    //
    //  Reference the signal object by handle.
    //

    Status = ObReferenceObjectByHandle( SignalHandle,
                                        0,
                                        NULL,
                                        PreviousMode,
                                        &SignalObject,
                                        &HandleInformation );

    //
    //  If the reference was successful, then reference the wait object by
    //  handle.
    //

    if (NT_SUCCESS(Status)) {

        Status = ObReferenceObjectByHandle( WaitHandle,
                                            SYNCHRONIZE,
                                            NULL,
                                            PreviousMode,
                                            &WaitObject,
                                            NULL );

        //
        //  If the reference was successful, then determine the real wait
        //  object, check the signal object access, signal the signal object,
        //  and wait for the real wait object.
        //

        if (NT_SUCCESS(Status)) {

            WaitObjectHeader = OBJECT_TO_OBJECT_HEADER(WaitObject);
            RealObject = WaitObjectHeader->Type->DefaultObject;

            if ((LONG_PTR)RealObject >= 0) {

                RealObject = (PVOID)((PCHAR)WaitObject + (ULONG_PTR)RealObject);
            }

            //
            //  If the signal object is an event, then check for modify access
            //  and set the event.  Otherwise, if the signal object is a
            //  mutant, then attempt to release ownership of the mutant.
            //  Otherwise, if the object is a semaphore, then check for modify
            //  access and release the semaphore.  Otherwise, the signal objet
            //  is invalid.
            //

            SignalObjectHeader = OBJECT_TO_OBJECT_HEADER(SignalObject);
            Status = STATUS_ACCESS_DENIED;

            if (SignalObjectHeader->Type == ExEventObjectType) {

                //
                //  Check for access to the specified event object,
                //

                if ((PreviousMode != KernelMode) &&
                    (SeComputeDeniedAccesses( HandleInformation.GrantedAccess,
                                              EVENT_MODIFY_STATE) != 0 )) {

                    goto WaitExit;
                }

                //
                //  Set the specified event and wait atomically.
                //
                //  N.B.  This returns with the dispatcher lock held !!!
                //

                KeSetEvent((PKEVENT)SignalObject, EVENT_INCREMENT, TRUE);

            } else if (SignalObjectHeader->Type == ExMutantObjectType) {

                //
                //  Release the specified mutant and wait atomically.
                //
                //  N.B. The release will only be successful if the current
                //       thread is the owner of the mutant.
                //

                try {

                    KeReleaseMutant( (PKMUTANT)SignalObject,
                                     MUTANT_INCREMENT,
                                     FALSE,
                                     TRUE );

                } except((GetExceptionCode () == STATUS_ABANDONED ||
                          GetExceptionCode () == STATUS_MUTANT_NOT_OWNED)?
                             EXCEPTION_EXECUTE_HANDLER :
                             EXCEPTION_CONTINUE_SEARCH) {
                    Status = GetExceptionCode();

                    goto WaitExit;
                }

            } else if (SignalObjectHeader->Type == ExSemaphoreObjectType) {

                //
                //  Check for access to the specified semaphore object,
                //

                if ((PreviousMode != KernelMode) &&
                    (SeComputeDeniedAccesses( HandleInformation.GrantedAccess,
                                              SEMAPHORE_MODIFY_STATE) != 0 )) {

                    goto WaitExit;
                }

                //
                //  Release the specified semaphore and wait atomically.
                //

                try {

                    //
                    //  Release the specified semaphore and wait atomically.
                    //

                    KeReleaseSemaphore( (PKSEMAPHORE)SignalObject,
                                        SEMAPHORE_INCREMENT,
                                        1,
                                        TRUE );

                } except((GetExceptionCode () == STATUS_SEMAPHORE_LIMIT_EXCEEDED)?
                             EXCEPTION_EXECUTE_HANDLER :
                             EXCEPTION_CONTINUE_SEARCH) {

                    Status = GetExceptionCode();

                    goto WaitExit;
                }

            } else {

                Status = STATUS_OBJECT_TYPE_MISMATCH;

                goto WaitExit;
            }

            //
            //  Protect the wait call just in case KeWait decides to raise
            //  For example, a mutant level is exceeded
            //

            try {

                Status = KeWaitForSingleObject( RealObject,
                                                UserRequest,
                                                PreviousMode,
                                                Alertable,
                                                Timeout );

            } except((GetExceptionCode () == STATUS_MUTANT_LIMIT_EXCEEDED)?
                         EXCEPTION_EXECUTE_HANDLER :
                         EXCEPTION_CONTINUE_SEARCH) {

                Status = GetExceptionCode();
            }

WaitExit:

            ObDereferenceObject(WaitObject);
        }

        ObDereferenceObject(SignalObject);
    }

    return Status;
}


NTSTATUS
NtWaitForSingleObject (
    IN HANDLE Handle,
    IN BOOLEAN Alertable,
    IN PLARGE_INTEGER Timeout OPTIONAL
    )

/*++

Routine Description:

    This function waits until the specified object attains a state of
    Signaled.  An optional timeout can also be specified.  If a timeout
    is not specified, then the wait will not be satisfied until the
    object attains a state of Signaled.  If a timeout is specified, and
    the object has not attained a state of Signaled when the timeout
    expires, then the wait is automatically satisfied.  If an explicit
    timeout value of zero is specified, then no wait will occur if the
    wait cannot be satisfied immediately.  The wait can also be specified
    as alertable.

Arguments:

    Handle  - Supplies the handle for the wait object.

    Alertable - Supplies a boolean value that specifies whether the wait
        is alertable.

    Timeout - Supplies an pointer to an absolute or relative time over
        which the wait is to occur.

Return Value:

    The wait completion status. A value of STATUS_TIMEOUT is returned if a
    timeout occurred.  A value of STATUS_SUCCESS is returned if the specified
    object satisfied the wait.  A value of STATUS_ALERTED is returned if the
    wait was aborted to deliver an alert to the current thread. A value of
    STATUS_USER_APC is returned if the wait was aborted to deliver a user
    APC to the current thread.

--*/

{
    PVOID Object;
    POBJECT_HEADER ObjectHeader;
    KPROCESSOR_MODE PreviousMode;
    NTSTATUS Status;
    LARGE_INTEGER TimeoutValue;
    PVOID WaitObject;

    PAGED_CODE();

    //
    //  Get previous processor mode and probe and capture timeout argument
    //  if necessary.
    //

    PreviousMode = KeGetPreviousMode();

    if ((ARGUMENT_PRESENT(Timeout)) && (PreviousMode != KernelMode)) {

        try {

            TimeoutValue = ProbeAndReadLargeInteger(Timeout);
            Timeout = &TimeoutValue;

        } except(EXCEPTION_EXECUTE_HANDLER) {

            return GetExceptionCode();
        }
    }

    //
    //  Get a referenced pointer to the specified object with synchronize
    //  access.
    //

    Status = ObReferenceObjectByHandle( Handle,
                                        SYNCHRONIZE,
                                        NULL,
                                        PreviousMode,
                                        &Object,
                                        NULL );

    //
    //  If access is granted, then check to determine if the specified object
    //  can be waited on.
    //

    if (NT_SUCCESS(Status)) {

        ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );
        WaitObject = ObjectHeader->Type->DefaultObject;

        if ((LONG_PTR)WaitObject >= 0) {

            WaitObject = (PVOID)((PCHAR)Object + (ULONG_PTR)WaitObject);
        }

        //
        //  Protect the wait call just in case KeWait decides to raise
        //  For example, a mutant level is exceeded
        //

        try {
            PERFINFO_DECLARE_OBJECT(Object);

            Status = KeWaitForSingleObject( WaitObject,
                                            UserRequest,
                                            PreviousMode,
                                            Alertable,
                                            Timeout );

        } except((GetExceptionCode () == STATUS_MUTANT_LIMIT_EXCEEDED)?
                     EXCEPTION_EXECUTE_HANDLER :
                     EXCEPTION_CONTINUE_SEARCH) {

            Status = GetExceptionCode();
        }

        ObDereferenceObject(Object);
    }

    return Status;
}


NTSTATUS
NtWaitForMultipleObjects (
    IN ULONG Count,
    IN HANDLE Handles[],
    IN WAIT_TYPE WaitType,
    IN BOOLEAN Alertable,
    IN PLARGE_INTEGER Timeout OPTIONAL
    )

/*++

Routine Description:

    This function waits until the specified objects attain a state of
    Signaled.  The wait can be specified to wait until all of the objects
    attain a state of Signaled or until one of the objects attains a state
    of Signaled.  An optional timeout can also be specified.  If a timeout
    is not specified, then the wait will not be satisfied until the objects
    attain a state of Signaled.  If a timeout is specified, and the objects
    have not attained a state of Signaled when the timeout expires, then
    the wait is automatically satisfied.  If an explicit timeout value of
    zero is specified, then no wait will occur if the wait cannot be satisfied
    immediately.  The wait can also be specified as alertable.

Arguments:

    Count - Supplies a count of the number of objects that are to be waited
        on.

    Handles[] - Supplies an array of handles to wait objects.

    WaitType - Supplies the type of wait to perform (WaitAll, WaitAny).

    Alertable - Supplies a boolean value that specifies whether the wait is
        alertable.

    Timeout - Supplies a pointer to an optional absolute of relative time over
        which the wait is to occur.

Return Value:

    The wait completion status.  A value of STATUS_TIMEOUT is returned if a
    timeout occurred.  The index of the object (zero based) in the object
    pointer array is returned if an object satisfied the wait.  A value of
    STATUS_ALERTED is returned if the wait was aborted to deliver an alert
    to the current thread.  A value of STATUS_USER_APC is returned if the
    wait was aborted to deliver a user APC to the current thread.

--*/

{
    HANDLE CapturedHandles[MAXIMUM_WAIT_OBJECTS];
    ULONG i;
    ULONG j;
    POBJECT_HEADER ObjectHeader;
    PVOID Objects[MAXIMUM_WAIT_OBJECTS];
    KPROCESSOR_MODE PreviousMode;
    ULONG RefCount;
    ULONG Size;
    NTSTATUS Status;
    LARGE_INTEGER TimeoutValue;
    PKWAIT_BLOCK WaitBlockArray;
    ACCESS_MASK GrantedAccess;
    PVOID WaitObjects[MAXIMUM_WAIT_OBJECTS];
    PHANDLE_TABLE HandleTable;
    PHANDLE_TABLE_ENTRY HandleEntry;
    BOOLEAN InCriticalRegion = FALSE;
    PETHREAD CurrentThread;

    PAGED_CODE();

    //
    //  If the number of objects is zero or greater than the largest number
    //  that can be waited on, then return and invalid parameter status.
    //

    if ((Count == 0) || (Count > MAXIMUM_WAIT_OBJECTS)) {

        return STATUS_INVALID_PARAMETER_1;
    }

    //
    //  If the wait type is not wait any or wait all, then return an invalid
    //  parameter status.
    //

    if ((WaitType != WaitAny) && (WaitType != WaitAll)) {

        return STATUS_INVALID_PARAMETER_3;
    }

    //
    //  Get previous processor mode and probe and capture input arguments if
    //  necessary.
    //

    PreviousMode = KeGetPreviousMode();

    try {

        if (PreviousMode != KernelMode) {

            if (ARGUMENT_PRESENT(Timeout)) {

                TimeoutValue = ProbeAndReadLargeInteger(Timeout);
                Timeout = &TimeoutValue;
            }

            ProbeForRead( Handles, Count * sizeof(HANDLE), sizeof(HANDLE) );
        }

        RtlCopyMemory (CapturedHandles, Handles, Count * sizeof(HANDLE));

    } except(EXCEPTION_EXECUTE_HANDLER) {

        return GetExceptionCode();
    }

    //
    //  If the number of objects to be waited on is greater than the number
    //  of builtin wait blocks, then allocate an array of wait blocks from
    //  nonpaged pool. If the wait block array cannot be allocated, then
    //  return insufficient resources.
    //

    WaitBlockArray = NULL;

    if (Count > THREAD_WAIT_OBJECTS) {

        Size = Count * sizeof( KWAIT_BLOCK );
        WaitBlockArray = ExAllocatePoolWithTag(NonPagedPool, Size, 'tiaW');

        if (WaitBlockArray == NULL) {

            return STATUS_INSUFFICIENT_RESOURCES;
        }
    }

    //
    //  Loop through the array of handles and get a referenced pointer to
    //  each object.
    //

    i = 0;
    RefCount = 0;

    Status = STATUS_SUCCESS;

    //
    //  Protect ourselves from being interrupted while we hold a handle table
    //  entry lock
    //

    CurrentThread = PsGetCurrentThread ();
    KeEnterCriticalRegionThread(&CurrentThread->Tcb);
    InCriticalRegion = TRUE;

    do {

        //
        //  Get a pointer to the object table entry.  Check if this is a kernel
        //  handle and if so then use the kernel handle table otherwise use the
        //  processes handle table.  If we are going for a kernel handle we'll
        //  need to attach to the kernel process otherwise we need to ensure
        //  that we aren't attached.
        //

        if (IsKernelHandle( CapturedHandles[i], PreviousMode )) {

            HANDLE KernelHandle;

            //
            //  Decode the user supplied handle into a regular handle value
            //  and get its handle table entry
            //

            KernelHandle = DecodeKernelHandle( CapturedHandles[i] );

            HandleTable = ObpKernelHandleTable;
            HandleEntry = ExMapHandleToPointerEx ( HandleTable, KernelHandle, PreviousMode );

        } else {

            //
            //  Get the handle table entry
            //

            HandleTable = PsGetCurrentProcessByThread (CurrentThread)->ObjectTable;
            HandleEntry = ExMapHandleToPointerEx ( HandleTable, CapturedHandles[ i ], PreviousMode );
        }

        //
        //  Make sure the handle really did translate to a valid
        //  entry
        //

        if (HandleEntry != NULL) {

            //
            //  Get the granted access for the handle
            //

#if i386 

            if (NtGlobalFlag & FLG_KERNEL_STACK_TRACE_DB) {

                GrantedAccess = ObpTranslateGrantedAccessIndex( HandleEntry->GrantedAccessIndex );

            } else {

                GrantedAccess = ObpDecodeGrantedAccess(HandleEntry->GrantedAccess);
            }

#else
            GrantedAccess = ObpDecodeGrantedAccess(HandleEntry->GrantedAccess);

#endif // i386

            //
            //  Make sure the handle as synchronize access to the
            //  object
            //

            if ((PreviousMode != KernelMode) &&
                (SeComputeDeniedAccesses( GrantedAccess, SYNCHRONIZE ) != 0)) {

                Status = STATUS_ACCESS_DENIED;

                ExUnlockHandleTableEntry( HandleTable, HandleEntry );

                goto ServiceFailed;

            } else {

                //
                //  We have a object with proper access so get the header
                //  and if the default objects points to a real object
                //  then that is the one we're going to wait on.
                //  Otherwise we'll find the kernel wait object at an
                //  offset into the object body
                //

                ObjectHeader = (POBJECT_HEADER)(((ULONG_PTR)(HandleEntry->Object)) & ~OBJ_HANDLE_ATTRIBUTES);

                if ((LONG_PTR)ObjectHeader->Type->DefaultObject < 0) {

                    RefCount += 1;
                    Objects[i] = NULL;
                    WaitObjects[i] = ObjectHeader->Type->DefaultObject;

                } else {

                    ObpIncrPointerCount( ObjectHeader );
                    RefCount += 1;
                    Objects[i] = &ObjectHeader->Body;

                    PERFINFO_DECLARE_OBJECT(Objects[i]);

                    //
                    //  Compute the address of the kernel wait object.
                    //

                    WaitObjects[i] = (PVOID)((PCHAR)&ObjectHeader->Body +
                                             (ULONG_PTR)ObjectHeader->Type->DefaultObject);
                }
            }

            ExUnlockHandleTableEntry( HandleTable, HandleEntry );

        } else {

            //
            //  The entry in the handle table isn't in use
            //

            Status = STATUS_INVALID_HANDLE;

            goto ServiceFailed;
        }

        i += 1;

    } while (i < Count);

    //
    //  At this point the WaitObjects[] is set to the kernel wait objects
    //
    //  Now Check to determine if any of the objects are specified more than
    //  once, but we only need to check this for wait all, with a wait any
    //  the user can specify the same object multiple times.
    //

    if (WaitType == WaitAll) {

        i = 0;

        do {

            for (j = i + 1; j < Count; j += 1) {
                if (WaitObjects[i] == WaitObjects[j]) {

                    Status = STATUS_INVALID_PARAMETER_MIX;

                    goto ServiceFailed;
                }
            }

            i += 1;

        } while (i < Count);
    }

    //
    //  Wait for the specified objects to attain a state of Signaled or a
    //  time out to occur.  Protect the wait call just in case KeWait decides
    //  to raise For example, a mutant level is exceeded
    //

    try {

        InCriticalRegion = FALSE;
        KeLeaveCriticalRegionThread(&CurrentThread->Tcb);
        Status = KeWaitForMultipleObjects( Count,
                                           WaitObjects,
                                           WaitType,
                                           UserRequest,
                                           PreviousMode,
                                           Alertable,
                                           Timeout,
                                           WaitBlockArray );

    } except((GetExceptionCode () == STATUS_MUTANT_LIMIT_EXCEEDED)?
                 EXCEPTION_EXECUTE_HANDLER :
                 EXCEPTION_CONTINUE_SEARCH) {

        Status = GetExceptionCode();
    }

    //
    //  If any objects were referenced, then deference them.
    //

ServiceFailed:

    while (RefCount > 0) {

        RefCount -= 1;

        if (Objects[RefCount] != NULL) {

            ObDereferenceObject(Objects[RefCount]);
        }
    }

    //
    //  If a wait block array was allocated, then deallocate it.
    //

    if (WaitBlockArray != NULL) {

        ExFreePool(WaitBlockArray);
    }

    if (InCriticalRegion) {
        KeLeaveCriticalRegionThread(&CurrentThread->Tcb);
    }

    return Status;
}


NTSTATUS
ObWaitForSingleObject (
    IN HANDLE Handle,
    IN BOOLEAN Alertable,
    IN PLARGE_INTEGER Timeout OPTIONAL
    )

/*++

Routine Description:

    Please refer to NtWaitForSingleObject

Arguments:

    Handle  - Supplies the handle for the wait object.

    Alertable - Supplies a boolean value that specifies whether the wait
        is alertable.

    Timeout - Supplies an pointer to an absolute or relative time over
        which the wait is to occur.

Return Value:

    The wait completion status. A value of STATUS_TIMEOUT is returned if a
    timeout occurred.  A value of STATUS_SUCCESS is returned if the specified
    object satisfied the wait.  A value of STATUS_ALERTED is returned if the
    wait was aborted to deliver an alert to the current thread. A value of
    STATUS_USER_APC is returned if the wait was aborted to deliver a user
    APC to the current thread.

--*/

{
    POBJECT_HEADER ObjectHeader;
    PVOID Object;
    NTSTATUS Status;
    PVOID WaitObject;

    PAGED_CODE();

    //
    //  Get a referenced pointer to the specified object with synchronize
    //  access.
    //

    Status = ObReferenceObjectByHandle( Handle,
                                        SYNCHRONIZE,
                                        (POBJECT_TYPE)NULL,
                                        KernelMode,
                                        &Object,
                                        NULL );

    //
    //  If access is granted, then check to determine if the specified object
    //  can be waited on.
    //

    if (NT_SUCCESS( Status ) != FALSE) {

        ObjectHeader = OBJECT_TO_OBJECT_HEADER( Object );

        if ((LONG_PTR)ObjectHeader->Type->DefaultObject < 0) {

            WaitObject = (PVOID)ObjectHeader->Type->DefaultObject;

        } else {

            WaitObject = (PVOID)((PCHAR)Object + (ULONG_PTR)ObjectHeader->Type->DefaultObject);
        }

        //
        //  Protect the wait call just in case KeWait decides
        //  to raise For example, a mutant level is exceeded
        //

        try {

            Status = KeWaitForSingleObject( WaitObject,
                                            UserRequest,
                                            KernelMode,
                                            Alertable,
                                            Timeout );

        } except((GetExceptionCode () == STATUS_MUTANT_LIMIT_EXCEEDED)?
                     EXCEPTION_EXECUTE_HANDLER :
                     EXCEPTION_CONTINUE_SEARCH) {

            Status = GetExceptionCode();
        }

        ObDereferenceObject(Object);
    }

    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\perfinfokrn.h ===
#ifdef NTPERF
#include "..\..\tools\ntperf\ntosperf\perfinfokrn.h"
#endif //NTPERF
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\perfp.h ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    perfp.h

Abstract:

    This module contains the definitions of data structures and macros
    used by kernel-mode logging in the performance data event log.

Author:

    David Fields (DavidFie)

Revision History:

    5/15/2000      David Fields (DavidFie)
        Initial

--*/

#ifndef _PERFP_
#define _PERFP_

#if _MSC_VER >= 1000
#pragma once
#endif

#pragma warning(error:4100)   // Unreferenced formal parameter
#pragma warning(error:4101)   // Unreferenced local variable
#pragma warning(error:4705)   // Statement has no effect

#pragma warning(disable:4214)   // bit field types other than int
#pragma warning(disable:4201)   // nameless struct/union
#pragma warning(disable:4127)   // condition expression is constant
#pragma warning(disable:4115)   // named type definition in parentheses
#if 0
#pragma warning(disable:4324)   // alignment sensitive to declspec
#pragma warning(disable:4232)   // dllimport not static
#pragma warning(disable:4206)   // translation unit empty
#endif

#include "ntos.h"

//
// Profiling structures
//
extern KPROFILE PerfInfoProfileObject; 
extern PERFINFO_SAMPLED_PROFILE_CACHE PerfProfileCache;
extern BOOLEAN PerfInfoSampledProfileCaching;
extern KPROFILE_SOURCE PerfInfoProfileSourceActive;
extern KPROFILE_SOURCE PerfInfoProfileSourceRequested;
extern KPROFILE_SOURCE PerfInfoProfileInterval;
extern LONG PerfInfoSampledProfileFlushInProgress;
extern PERFINFO_GROUPMASK PerfGlobalGroupMask;


#define PERFPOOLTAG 'freP'

NTSTATUS
PerfInfoReserveBytesWMI(
    PPERFINFO_HOOK_HANDLE Hook,
    USHORT HookId,
    ULONG BytesToReserve
    );

NTSTATUS
PerfInfoFileNameRunDown(
    );

NTSTATUS
PerfInfoProcessRunDown(
    );

NTSTATUS
PerfInfoSysModuleRunDown(
    );

VOID
PerfInfoProfileInit(
    );

VOID
PerfInfoProfileUninit(
    );

#ifdef NTPERF
extern ULONGLONG PerfInfoTickFrequency;

NTSTATUS
PerfInfoReserveBytesPerfMem(
    PPERFINFO_HOOK_HANDLE Hook,
    USHORT HookId,
    ULONG BytesToReserve
    );

NTSTATUS
PerfTurnOnBranchTracing(
    );

NTSTATUS
PerfTurnOffBranchTracing(
    );

BOOLEAN
PerfInfoFlushBranchCache(
    BOOLEAN bIntsOff
    );

#endif // NTPERF

VOID
PerfSetLogging (
    PVOID MaskAddress
    );

#endif // _PERFP_
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\perfsup.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    perfsup.c

Abstract:

    This module contains support routines for performance traces.

Author:

    Stephen Hsiao (shsiao) 01-Jan-2000

Revision History:

--*/

#include "perfp.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, PerfInfoProfileInit)
#pragma alloc_text(PAGE, PerfInfoProfileUninit)
#pragma alloc_text(PAGE, PerfInfoStartLog)
#pragma alloc_text(PAGE, PerfInfoStopLog)
#endif //ALLOC_PRAGMA

extern NTSTATUS IoPerfInit();
extern NTSTATUS IoPerfReset();

#ifdef NTPERF
NTSTATUS
PerfInfopStartLog(
    PERFINFO_GROUPMASK *pGroupMask,
    PERFINFO_START_LOG_LOCATION StartLogLocation
    );

NTSTATUS
PerfInfopStopLog(
    VOID
    );

VOID
PerfInfoSetProcessorSpeed(
    VOID
    );
#endif // NTPERF


VOID
PerfInfoProfileInit(
    )
/*++

Routine description:

    Starts the sampled profile and initializes the cache

Arguments:
    None

Return Value:
    None

--*/
{
#if !defined(NT_UP)
    PerfInfoSampledProfileCaching = FALSE;
#else
    PerfInfoSampledProfileCaching = TRUE;
#endif // !defined(NT_UP)
    PerfInfoSampledProfileFlushInProgress = 0;
    PerfProfileCache.Entries = 0;

    PerfInfoProfileSourceActive = PerfInfoProfileSourceRequested;

    KeSetIntervalProfile(PerfInfoProfileInterval, PerfInfoProfileSourceActive);
    KeInitializeProfile(&PerfInfoProfileObject,
                        NULL,
                        NULL,
                        0,
                        0,
                        0,
                        PerfInfoProfileSourceActive,
                        0
                        );
    KeStartProfile(&PerfInfoProfileObject, NULL);
}


VOID
PerfInfoProfileUninit(
    )
/*++

Routine description:

    Stops the sampled profile

Arguments:
    None

Return Value:
    None

--*/
{
    PerfInfoProfileSourceActive = ProfileMaximum;   // Invalid value stops us from
                                                    // collecting more samples
    KeStopProfile(&PerfInfoProfileObject);
    PerfInfoFlushProfileCache();
}


NTSTATUS
PerfInfoStartLog (
    PERFINFO_GROUPMASK *PGroupMask,
    PERFINFO_START_LOG_LOCATION StartLogLocation
    )

/*++

Routine Description:

    This routine is called by WMI as part of kernel logger initiaziation.

Arguments:

    GroupMask - Masks for what to log.  This pointer point to an allocated
                area in WMI LoggerContext.
    StartLogLocation - Indication of whether we're starting logging
                at boot time or while the system is running.  If
                we're starting at boot time, we don't need to snapshot
                the open files because there aren't any and we would
                crash if we tried to find the list.

Return Value:

    BUGBUG Need proper return/ error handling

--*/

{
    NTSTATUS Status = STATUS_SUCCESS;
    BOOLEAN ProfileInitialized = FALSE;
    BOOLEAN ContextSwapStarted = FALSE;
    BOOLEAN IoPerfInitialized = FALSE;

    PERFINFO_CLEAR_GROUPMASK(&PerfGlobalGroupMask);

    //
    // Enable logging.
    //

    PPerfGlobalGroupMask = &PerfGlobalGroupMask;
    PerfSetLogging(PPerfGlobalGroupMask);

    if (PerfIsGroupOnInGroupMask(PERF_MEMORY, PGroupMask) ||
        PerfIsGroupOnInGroupMask(PERF_FILENAME, PGroupMask) ||
        PerfIsGroupOnInGroupMask(PERF_DRIVERS, PGroupMask)) {
            PERFINFO_OR_GROUP_WITH_GROUPMASK(PERF_FILENAME_ALL, PGroupMask);
    }


    if (StartLogLocation == PERFINFO_START_LOG_FROM_GLOBAL_LOGGER) {
        //
        // From the wmi global logger, need to do Rundown in kernel mode
        //
        if (PerfIsGroupOnInGroupMask(PERF_PROC_THREAD, PGroupMask)) {
            Status = PerfInfoProcessRunDown();
            if (!NT_SUCCESS(Status)) {
                goto Finish;
            }
        }

        if (PerfIsGroupOnInGroupMask(PERF_PROC_THREAD, PGroupMask)) {
            Status = PerfInfoSysModuleRunDown();
            if (!NT_SUCCESS(Status)) {
                goto Finish;
            }
        }
    }

    //
    // File Name Rundown code
    //
    if ((StartLogLocation != PERFINFO_START_LOG_AT_BOOT) && 
        PerfIsGroupOnInGroupMask(PERF_FILENAME_ALL, PGroupMask)) {
        PERFINFO_OR_GROUP_WITH_GROUPMASK(PERF_FILENAME_ALL, PPerfGlobalGroupMask);
        Status = PerfInfoFileNameRunDown();
        if (!NT_SUCCESS(Status)) {
            goto Finish;
        }
    }

    //
    // Initialize Perf Driver hooks
    //
    if (PerfIsGroupOnInGroupMask(PERF_DRIVERS, PGroupMask)) {
        Status = IoPerfInit();
        if (NT_SUCCESS(Status)) {
            IoPerfInitialized = TRUE;
        } else {
            goto Finish;
        }
    }

    //
    // Enable context swap tracing
    //
    if ( PerfIsGroupOnInGroupMask(PERF_CONTEXT_SWITCH, PGroupMask) ) {
        WmiStartContextSwapTrace();
        ContextSwapStarted = TRUE;
    }

    //
    // Sampled Profile
    //
    if (PerfIsGroupOnInGroupMask(PERF_PROFILE, PGroupMask)) {
        if ((KeGetPreviousMode() == KernelMode)  ||
            (SeSinglePrivilegeCheck(SeSystemProfilePrivilege, UserMode))) {
            PerfInfoProfileInit();
            ProfileInitialized = TRUE;
        } else {
            Status = STATUS_NO_SUCH_PRIVILEGE;
            goto Finish;
        }
    }

#ifdef NTPERF
    Status = PerfInfopStartLog(PGroupMask,  StartLogLocation);
#else
    //
    // See if we need to empty the working set to start
    //
    if (PerfIsGroupOnInGroupMask(PERF_FOOTPRINT, PGroupMask) ||
        PerfIsGroupOnInGroupMask(PERF_BIGFOOT, PGroupMask)) {
        MmEmptyAllWorkingSets ();
    }
#endif // NTPERF

Finish:

    if (!NT_SUCCESS(Status)) {
        //
        // Failed to turn on trace, clean up now.
        //

        if (ContextSwapStarted) {
            WmiStopContextSwapTrace();
        }

        if (ProfileInitialized) {
            PerfInfoProfileUninit();
        }

        if (IoPerfInitialized) {
            IoPerfReset();
        }

        //
        // Disable logging.
        //

        PPerfGlobalGroupMask = NULL;
        PerfSetLogging(NULL);

        PERFINFO_CLEAR_GROUPMASK(&PerfGlobalGroupMask);
    } else {
#ifdef NTPERF
        if (PERFINFO_IS_LOGGING_TO_PERFMEM()) {
            //
            // Make a copy of the GroupMask in PerfMem header
            // so user mode logging can work
            //
            PerfBufHdr()->GlobalGroupMask = *PGroupMask;
        }
#endif // NTPERF
        *PPerfGlobalGroupMask = *PGroupMask;
    }

    return Status;
}


NTSTATUS
PerfInfoStopLog (
    )

/*++

Routine Description: 

    This routine turn off the PerfInfo trace hooks.

Arguments:

    None.

Return Value:

    BUGBUG Need proper return/ error handling

--*/

{
    NTSTATUS Status = STATUS_SUCCESS;
    BOOLEAN DisableContextSwaps=FALSE;

    if (PPerfGlobalGroupMask == NULL) {
        return Status;
    }

    if (PERFINFO_IS_GROUP_ON(PERF_MEMORY)) {
        MmIdentifyPhysicalMemory();
    }

    if (PERFINFO_IS_GROUP_ON(PERF_PROFILE)) {
        PerfInfoProfileUninit();
    }

    if (PERFINFO_IS_GROUP_ON(PERF_DRIVERS)) {
        IoPerfReset();
    }

#ifdef NTPERF
    if (PERFINFO_IS_LOGGING_TO_PERFMEM()) {
        // 
        // Now clear the GroupMask in Perfmem to stop logging.
        //
        PERFINFO_CLEAR_GROUPMASK(&PerfBufHdr()->GlobalGroupMask);
    }
    Status = PerfInfopStopLog();
#endif // NTPERF

    if ( PERFINFO_IS_GROUP_ON(PERF_CONTEXT_SWITCH) ) {
        DisableContextSwaps = TRUE;
    }

    //
    // Reset the PPerfGlobalGroupMask.
    //

    PERFINFO_CLEAR_GROUPMASK(PPerfGlobalGroupMask);

    //
    // Disable logging.
    //

    PPerfGlobalGroupMask = NULL;
    PerfSetLogging(NULL);

    //
    // Disable context swap tracing.
    // IMPORTANT: This must be done AFTER the global flag is set to NULL!!!
    //
    if( DisableContextSwaps ) {

        WmiStopContextSwapTrace();
    }

    return (Status);

}

#ifdef NTPERF

NTSTATUS
PerfInfoStartPerfMemLog (
    )

/*++

Routine Description:

    Indicate a logger wants to log into Perfmem.  If it is the first logger,
    initialize the shared memory buffer.  Otherwise, just increment LoggerCounts.

Arguments:

    None

Return Value:

    STATUS_BUFFER_TOO_SMALL - if buffer not big enough
    STATUS_SUCCESS - otherwize

--*/
{
    PPERF_BYTE pbCurrentStart;
    ULONG cbBufferSize;
    LARGE_INTEGER PerformanceFrequency;
    const PPERFINFO_TRACEBUF_HEADER Buffer = PerfBufHdr();
    ULONG LoggerCounts;
    ULONG Idx;

    //
    // Is it big enough to use?
    //
    if (PerfQueryBufferSizeBytes() <= 2 * PERFINFO_HEADER_ZONE_SIZE) {
        PERFINFO_SET_LOGGING_TO_PERFMEM(FALSE);
        return STATUS_BUFFER_TOO_SMALL;
    }

    //
    // It is OK to use the buffer, increment the reference count
    //
    LoggerCounts = InterlockedIncrement(&Buffer->LoggerCounts);
    if (LoggerCounts != 1) {
        //
        // Other logger has turned on logging, just return.
        //
        return STATUS_SUCCESS; 
    }

    //
    // Code to acquire the buffer would go here.
    //


    Buffer->SelfPointer = Buffer;
    Buffer->MmSystemRangeStart = MmSystemRangeStart;

    //
    // initialize buffer version information
    //
    Buffer->usMajorVersion = PERFINFO_MAJOR_VERSION;
    Buffer->usMinorVersion = PERFINFO_MINOR_VERSION;

    //
    // initialize timer stuff
    //
    Buffer->BufferFlag = FLAG_CYCLE_COUNT;
    KeQuerySystemTime(&Buffer->PerfInitSystemTime);
    Buffer->PerfInitTime = PerfGetCycleCount();

    Buffer->LastClockRef.SystemTime = Buffer->PerfInitSystemTime;
    Buffer->LastClockRef.TickCount = Buffer->PerfInitTime;

    Buffer->CalcPerfFrequency = PerfInfoTickFrequency;
    Buffer->EventPerfFrequency = PerfInfoTickFrequency;

    Buffer->PerfBufHeaderZoneSize = PERFINFO_HEADER_ZONE_SIZE;

    KeQueryPerformanceCounter(&PerformanceFrequency);
    Buffer->KePerfFrequency = PerformanceFrequency.QuadPart;

    //
    // Determine the size of the thread hash table
    //
    Buffer->ThreadHash = (PERFINFO_THREAD_HASH_ENTRY *)
                            (((PCHAR) Buffer) + sizeof(PERFINFO_TRACEBUF_HEADER));
    Buffer->ThreadHashOverflow = FALSE;
    RtlZeroMemory(Buffer->ThreadHash,
                  PERFINFO_THREAD_HASH_SIZE *
                  sizeof(PERFINFO_THREAD_HASH_ENTRY));
    for (Idx = 0; Idx < PERFINFO_THREAD_HASH_SIZE; Idx++)
        Buffer->ThreadHash[Idx].CurThread = PERFINFO_INVALID_ID;

    pbCurrentStart = (PPERF_BYTE) Buffer + Buffer->PerfBufHeaderZoneSize;
    cbBufferSize = PerfQueryBufferSizeBytes() - Buffer->PerfBufHeaderZoneSize;

    Buffer->Start.Ptr = Buffer->Current.Ptr = pbCurrentStart;
    Buffer->Max.Ptr = pbCurrentStart + cbBufferSize;

    //
    // initialize version mismatch tracking
    //
    Buffer->fVersionMismatch = FALSE;

    //
    // initialize buffer overflow counter
    //
    Buffer->BufferBytesLost = 0;

    //
    // initialize the pointer to the COWHeader
    //
    Buffer->pCOWHeader = NULL;

    RtlZeroMemory(Buffer->Start.Ptr, Buffer->Max.Ptr - Buffer->Start.Ptr);

    PERFINFO_SET_LOGGING_TO_PERFMEM(TRUE);

    return STATUS_SUCCESS;
}


NTSTATUS
PerfInfoStopPerfMemLog (
    )

/*++

Routine Description:

    Indicate a logger finishes logging.  If the loggerCounts goes to zero, the
    buffer will be reset the next time it is turned on.

Arguments:

    None

Return Value:

    STATUS_BUFFER_TOO_SMALL - if buffer not big enough
    STATUS_SUCCESS - otherwize

--*/
{
    ULONG LoggerCounts;
    const PPERFINFO_TRACEBUF_HEADER Buffer = PerfBufHdr();

    LoggerCounts = InterlockedDecrement(&Buffer->LoggerCounts);
    if (LoggerCounts == 0) {
        //
        // Other logger has turned on logging, just return.
        //
        PERFINFO_SET_LOGGING_TO_PERFMEM(FALSE);
    }
    return STATUS_SUCCESS; 
}


NTSTATUS
PerfInfopStartLog(
    PERFINFO_GROUPMASK *pGroupMask,
    PERFINFO_START_LOG_LOCATION StartLogLocation
    )

/*++

Routine Description:

    This routine initialize the mminfo log and turn on the monitor.

Arguments:

    GroupMask: Masks for what to log.

Return Value:

    BUGBUG Need proper return/ error handling

--*/

{
    NTSTATUS Status = STATUS_SUCCESS;

#ifdef NTPERF_PRIVATE
    Status = PerfInfopStartPrivateLog(pGroupMask, StartLogLocation);
    if (!NT_SUCCESS(Status)) {
        PERFINFO_CLEAR_GROUPMASK(PPerfGlobalGroupMask);
        return Status;
    }
#else
    UNREFERENCED_PARAMETER(pGroupMask);
    UNREFERENCED_PARAMETER(StartLogLocation);
#endif // NTPERF_PRIVATE

    return Status;
}


NTSTATUS
PerfInfopStopLog (
    VOID
    )

/*++

Routine Description:

    This routine turn off the mminfo monitor and (if needed) dump the
    data for user.

    NOTE: The shutdown and hibernate paths have similar code.  Check
    those if you make changes.

Arguments:

    None

Return Value:

    STATUS_SUCCESS

--*/

{
    if (PERFINFO_IS_ANY_GROUP_ON()) {

#ifdef NTPERF_PRIVATE
        PerfInfopStopPrivateLog();
#endif // NTPERF_PRIVATE

        if (PERFINFO_IS_LOGGING_TO_PERFMEM()) {
            PerfBufHdr()->LogStopTime = PerfGetCycleCount();
        }
    }

    return STATUS_SUCCESS;
}


NTSTATUS
PerfInfoSetPerformanceTraceInformation (
    IN PVOID SystemInformation,
    IN ULONG SystemInformationLength
    )
/*++

Routine Description:

    This routine implements the performance system information functions.

Arguments:

    SystemInformation - A pointer to a buffer which receives the specified
        information.  This is of type PPERFINFO_PERFORMANCE_INFORMATION.

    SystemInformationLength - Specifies the length in bytes of the system
        information buffer.

Return Value:

    STATUS_SUCCESS if successful

    STATUS_INFO_LENGTH_MISMATCH if size of buffer is incorrect

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PPERFINFO_PERFORMANCE_INFORMATION PerfInfo;
    PVOID PerfBuffer;

    if (SystemInformationLength < sizeof(PERFINFO_PERFORMANCE_INFORMATION)) {
        return STATUS_INFO_LENGTH_MISMATCH;
    }

    PerfInfo = (PPERFINFO_PERFORMANCE_INFORMATION) SystemInformation;
    PerfBuffer = PerfInfo + 1;

    switch (PerfInfo->PerformanceType) {

    case PerformancePerfInfoStart:
        // Status = PerfInfoStartLog(&PerfInfo->StartInfo.Flags, PERFINFO_START_LOG_POST_BOOT);
        Status = STATUS_INVALID_INFO_CLASS;
        break;

    case PerformancePerfInfoStop:
        // Status = PerfInfoStopLog();
        Status = STATUS_INVALID_INFO_CLASS;
        break;

#ifdef NTPERF_PRIVATE
    case PerformanceMmInfoMarkWithFlush:
    case PerformanceMmInfoMark:
    case PerformanceMmInfoAsyncMark:
    {
        USHORT LogType;
        ULONG StringLength;

        if (PerfInfo->PerformanceType == PerformanceMmInfoMarkWithFlush) {
            if (PERFINFO_IS_GROUP_ON(PERF_FOOTPRINT) ||
                PERFINFO_IS_GROUP_ON(PERF_FOOTPRINT_PROC)) {

                //
                // BUGBUG We should get a non-Mi* call for this...
                //
                MmEmptyAllWorkingSets();
                Status = MmPerfSnapShotValidPhysicalMemory();
            }
            else if (PERFINFO_IS_GROUP_ON(PERF_CLEARWS)) {
                MmEmptyAllWorkingSets();
            }
        } else if (PerfinfoBigFootSize) {
            MmEmptyAllWorkingSets();
        }

        if (PERFINFO_IS_ANY_GROUP_ON()) {
            PERFINFO_MARK_INFORMATION Event;
            StringLength = SystemInformationLength - sizeof(PERFINFO_PERFORMANCE_INFORMATION);

            LogType = (PerfInfo->PerformanceType == PerformanceMmInfoAsyncMark) ?
                                    PERFINFO_LOG_TYPE_ASYNCMARK :
                                    PERFINFO_LOG_TYPE_MARK;

            PerfInfoLogBytesAndANSIString(LogType,
                                        &Event,
                                        FIELD_OFFSET(PERFINFO_MARK_INFORMATION, Name),
                                        (PCSTR) PerfBuffer,
                                        StringLength
                                        );
        }

        if (PERFINFO_IS_GROUP_ON(PERF_FOOTPRINT_PROC)) {
            PerfInfoDumpWSInfo (TRUE);
        }
        break;
    }
    case PerformanceMmInfoFlush:
        MmEmptyAllWorkingSets();
        break;
#endif // NTPERF_PRIVATE

    default:
#ifdef NTPERF_PRIVATE
        Status = PerfInfoSetPerformanceTraceInformationPrivate(PerfInfo, SystemInformationLength);
#else
        Status = STATUS_INVALID_INFO_CLASS;
#endif // NTPERF_PRIVATE
        break;
    }
    return Status;
}


NTSTATUS
PerfInfoQueryPerformanceTraceInformation (
    IN PVOID SystemInformation,
    IN ULONG SystemInformationLength,
    OUT PULONG ReturnLength
    )
/*++

Routine Description:

    Satisfy queries for performance trace state information.

Arguments:

    SystemInformation - A pointer to a buffer which receives the specified
        information.  This is of type PPERFINFO_PERFORMANCE_INFORMATION.

    SystemInformationLength - Specifies the length in bytes of the system
        information buffer.

    ReturnLength - Receives the number of bytes placed in the system information buffer.

Return Value:

    STATUS_SUCCESS

--*/
{
    NTSTATUS Status = STATUS_SUCCESS;

    if (SystemInformationLength != sizeof(PERFINFO_PERFORMANCE_INFORMATION)) {
        return STATUS_INFO_LENGTH_MISMATCH;
    }

#ifdef NTPERF_PRIVATE

    return PerfInfoQueryPerformanceTraceInformationPrivate(
                (PPERFINFO_PERFORMANCE_INFORMATION) SystemInformation,
                ReturnLength
                );
#else
    UNREFERENCED_PARAMETER(ReturnLength);
    UNREFERENCED_PARAMETER(SystemInformation);
    return STATUS_INVALID_INFO_CLASS;
#endif // NTPERF_PRIVATE
}


VOID
PerfInfoSetProcessorSpeed(
    VOID
    )
/*++

Routine Description:

    Calculate and set the processor speed in MHz.

    Note: KPRCB->MHz, once it's set reliably, should be used instead

Arguments:

    None

Return Value:

    None

--*/
{
    ULONGLONG start;
    ULONGLONG end;
    ULONGLONG freq;
    ULONGLONG TSCStart;
    LARGE_INTEGER *Pstart = (LARGE_INTEGER *) &start;
    LARGE_INTEGER *Pend = (LARGE_INTEGER *) &end;
    LARGE_INTEGER Delay;
    ULONGLONG time[3];
    ULONGLONG clocks;
    int i;
    int RetryCount = 50;


    Delay.QuadPart = -50000;   // relative delay of 5ms (100ns ticks)

    while (RetryCount) {
        for (i = 0; i < 3; i++) {
            *Pstart = KeQueryPerformanceCounter(NULL);

            TSCStart = PerfGetCycleCount();
            KeDelayExecutionThread (KernelMode, FALSE, &Delay);
            clocks = PerfGetCycleCount() - TSCStart;

            *Pend = KeQueryPerformanceCounter((LARGE_INTEGER*)&freq);
            time[i] = (((end-start) * 1000000) / freq);
            time[i] = (clocks + time[i]/2) / time[i];
        }
        // If all three match then use it, else try again.
        if (time[0] == time[1] && time[1] == time[2])
            break;
        --RetryCount;
    }

    if (!RetryCount) {
        // Take the largest value.
        if (time[1] > time[0])
            time[0] = time[1];
        if (time[2] > time[0])
            time[0] = time[2];
    }
    PerfInfoTickFrequency = time[0];
}


BOOLEAN
PerfInfoIsGroupOn(
    ULONG Group
    )
{
    return PERFINFO_IS_GROUP_ON(Group);
}

#ifdef NTPERF_PRIVATE
#include "..\..\tools\ntperf\ntosperf\perfinfokrn.c"
#endif // NTPERF_PRIVATE
#endif // NTPERF
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\perfdata.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    perfdata.c

Abstract:

    This module contains the global read/write data for the perf subsystem

Author:

    Stephen Hsiao (shsiao) 01-Jan-2000

Revision History:

--*/

#include "perfp.h"

PERFINFO_GROUPMASK PerfGlobalGroupMask;
PERFINFO_GROUPMASK *PPerfGlobalGroupMask;
const PERFINFO_HOOK_HANDLE PerfNullHookHandle = { NULL, NULL };

//
// Profiling
//

KPROFILE PerfInfoProfileObject;
KPROFILE_SOURCE PerfInfoProfileSourceActive = ProfileMaximum;   // Set to invalid source
KPROFILE_SOURCE PerfInfoProfileSourceRequested = ProfileTime;
KPROFILE_SOURCE PerfInfoProfileInterval = 10000;    // 1ms in 100ns ticks
BOOLEAN PerfInfoSampledProfileCaching;
LONG PerfInfoSampledProfileFlushInProgress;
PERFINFO_SAMPLED_PROFILE_CACHE PerfProfileCache;

#ifdef NTPERF
ULONGLONG PerfInfoTickFrequency;
PERFINFO_GROUPMASK StartAtBootGroupMask;
ULONG PerfInfo_InitialStackWalk_Threshold_ms = 3000 * 1000;
ULONG PerfInfoLoggingToPerfMem = 0;
#endif //NTPERF
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\sources.inc ===
!IF 0

Copyright (c) 1997-1999  Microsoft Corporation

Module Name:

    sources.

Abstract:

    This file specifies the target component being built and the list of
    sources files needed to build that component.  Also specifies optional
    compiler switches and libraries that are unique for the component being
    built.


Author:

    Stephen Hsiao (shsiao) 05-Jan-2000

NOTE:   Commented description of this file is in \nt\bak\bin\sources.tpl

!ENDIF

MAJORCOMP=ntos
MINORCOMP=perf

TARGETNAME=perf
TARGETTYPE=LIBRARY
TARGETPATH=obj

INCLUDES=..;..\..\inc

BUILD_PRODUCES=ntosperf$(NT_UP)

MSC_WARNING_LEVEL=/W4 /WX

SOURCES=\
    ..\hooks.c \
    ..\logging.c \
    ..\perfdata.c \
    ..\perfsup.c

PRECOMPILED_INCLUDE=..\perfp.h
PRECOMPILED_PCH=perfp.pch
PRECOMPILED_OBJ=perfp.obj

SOURCES_USED=..\sources.inc
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\logging.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    logging.c

Abstract:

    This module contains routines for trace logging.

Author:

    Stephen Hsiao (shsiao) 01-Jan-2000

Revision History:

--*/

#include "perfp.h"

#ifndef NTPERF
#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGEWMI, PerfInfoReserveBytes)
#pragma alloc_text(PAGEWMI, PerfInfoLogBytes)
#endif //ALLOC_PRAGMA
#endif // !NTPERF


NTSTATUS
PerfInfoReserveBytes(
    PPERFINFO_HOOK_HANDLE Hook,
    USHORT HookId,
    ULONG BytesToReserve
    )
/*++

Routine Description:

    Reserves memory for the hook via WMI and initializes the header.

Arguments:

    Hook - pointer to hook handle (used for reference decrement)
    HookId - Id for the hook
    BytesToLog - size of data in bytes

Return Value:

    STATUS_SUCCESS on success
    STATUS_UNSUCCESSFUL if the buffer memory couldn't be allocated.
--*/
{
    NTSTATUS Status = STATUS_UNSUCCESSFUL;
    PPERFINFO_TRACE_HEADER PPerfTraceHeader = NULL;
    PWMI_BUFFER_HEADER PWmiBufferHeader = NULL;

    PERF_ASSERT((BytesToReserve + FIELD_OFFSET(PERFINFO_TRACE_HEADER, Data)) <= MAXUSHORT);
    PERF_ASSERT(Hook != NULL);

    PPerfTraceHeader = WmiReserveWithPerfHeader(BytesToReserve, &PWmiBufferHeader);

    if (PPerfTraceHeader != NULL) {
        PPerfTraceHeader->Packet.HookId = HookId;
        Hook->PerfTraceHeader = PPerfTraceHeader;
        Hook->WmiBufferHeader = PWmiBufferHeader;

        Status = STATUS_SUCCESS;
    } else {
        *Hook = PERF_NULL_HOOK_HANDLE;
    }

    return Status;
}


NTSTATUS
PerfInfoLogBytes(
    USHORT HookId,
    PVOID Data,
    ULONG BytesToLog
    )
/*++

Routine Description:

    Reserves memory for the hook, copies the data, and unref's the hook entry.

Arguments:

    HookId - Id for the hook
    Data - pointer to the data to be logged
    BytesToLog - size of data in bytes

Return Value:

    STATUS_SUCCESS on success
--*/
{
    PERFINFO_HOOK_HANDLE Hook;
    NTSTATUS Status;

    Status = PerfInfoReserveBytes(&Hook, HookId, BytesToLog);
    if (!NT_SUCCESS(Status)) {
        return Status;
    }

    RtlCopyMemory(PERFINFO_HOOK_HANDLE_TO_DATA(Hook, PPERF_BYTE), Data, BytesToLog);
    PERF_FINISH_HOOK(Hook);

    return STATUS_SUCCESS;
}

#ifdef NTPERF

PVOID
FASTCALL
PerfInfoReserveBytesFromPerfMem(
    ULONG BytesToReserve
    )
/*++

Routine Description:

    Reserves memory for the hook from the buffer, initializes the header,
    and the hook handle.

Arguments:

    Hook - pointer to hook handle (used for reference decrement)
    HookId - Id for the hook
    BytesToLog - size of data in bytes

Return Value:

    STATUS_SUCCESS on success
    STATUS_UNSUCCESSFUL if the buffer memory couldn't be allocated.
--*/
{
    PPERFINFO_TRACEBUF_HEADER pPerfBufHdr;
    PPERF_BYTE CurrentPtr;
    PPERF_BYTE NewPtr;
    PPERF_BYTE OriginalPtr;
    BOOLEAN Done = FALSE;
    ULONG AlignedTotBytes;

    pPerfBufHdr = PerfBufHdr();

    AlignedTotBytes = ALIGN_TO_POWER2(BytesToReserve, DEFAULT_TRACE_ALIGNMENT);

    OriginalPtr = pPerfBufHdr->Current.Ptr;
    while (!Done) {
        NewPtr = OriginalPtr + AlignedTotBytes;
        if (NewPtr <= pPerfBufHdr->Max.Ptr) {
            //
            // If the buffer pointer has not changed, returned value will be == to the comparand,
            // OriginalPointer, and the Destenation will be updated with the new end of buffer.
            //
            // If it did change, the Destination will not change and the a new end of buffer will
            // be returned.  We loop until we get it in or the buffer is full.
            //

            CurrentPtr = (PPERF_BYTE) InterlockedCompareExchangePointer(
                                                    (PVOID *)&(pPerfBufHdr->Current.Ptr),
                                                    (PVOID)NewPtr,
                                                    (PVOID)OriginalPtr
                                                    );
            if (OriginalPtr == CurrentPtr) {
                Done = TRUE;
            } else {
                OriginalPtr = CurrentPtr;
            }
        } else {
            //
            // Buffer overflow
            //
            Done = TRUE;
            CurrentPtr = NULL;
        }
    }

    return CurrentPtr;
}
#endif //NTPERF
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\hooks.c ===
/*++

Copyright (c) 2000  Microsoft Corporation

Module Name:

    hooks.c

Abstract:

    This module contains performance hooks.

Author:

    Stephen Hsiao (shsiao) 01-Jan-2000

Revision History:

--*/

#include "perfp.h"
#include "zwapi.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, PerfInfoFlushProfileCache)
#pragma alloc_text(PAGEWMI, PerfProfileInterrupt)
#pragma alloc_text(PAGEWMI, PerfInfoLogInterrupt)
#pragma alloc_text(PAGEWMI, PerfInfoLogBytesAndUnicodeString)
#pragma alloc_text(PAGEWMI, PerfInfoLogFileName)
#pragma alloc_text(PAGEWMI, PerfInfoCalcHashValue)
#pragma alloc_text(PAGEWMI, PerfInfoAddToFileHash)
#pragma alloc_text(PAGEWMI, PerfInfoFileNameRunDown)
#pragma alloc_text(PAGEWMI, PerfInfoProcessRunDown)
#pragma alloc_text(PAGEWMI, PerfInfoSysModuleRunDown)
#endif //ALLOC_PRAGMA

#define MAX_FILENAME_TO_LOG   8192


VOID
PerfInfoFlushProfileCache(
    VOID
    )
/*++

Routine description:

    Flushes the profile cache to the log buffer.  To make sure it get's valid data
    we read the 2 seperate version numbers (1 before and 1 after) to check if it's
    been changed.  If so, we just read again.  If that fails often, then we disable
    the cache.  Once the cache is read, we clear it.  This may cause samples to be
    lost but that's ok as this is statistical and it won't matter.

Arguments:
    CheckVersion - If FALSE, the version is not checked. This used when the profile
        interrupt code flushes the cache.

Return Value:
    None

--*/
{
    ULONG PreviousInProgress;

    if ((PerfProfileCache.Entries == 0) || (PerfInfoSampledProfileCaching == FALSE)) {
        return;
    }

    //
    // Signal the interrupt not to mess with the cache
    //
    PreviousInProgress = InterlockedIncrement(&PerfInfoSampledProfileFlushInProgress);
    if (PreviousInProgress != 1) {
        //
        // A flush is already in progress so just return.
        //
        InterlockedDecrement(&PerfInfoSampledProfileFlushInProgress);
        return;
    }

    //
    // Log the portion of the cache that has valid data.
    //
    PerfInfoLogBytes(PERFINFO_LOG_TYPE_SAMPLED_PROFILE_CACHE,
                        &PerfProfileCache,
                        FIELD_OFFSET(PERFINFO_SAMPLED_PROFILE_CACHE, Sample) +
                            (PerfProfileCache.Entries *
                                sizeof(PERFINFO_SAMPLED_PROFILE_INFORMATION))
                        );

    //
    // Clear the cache for the next set of entries.
    //
    PerfProfileCache.Entries = 0;

    //
    // Let the interrupt fill the cache again.
    //
    InterlockedDecrement(&PerfInfoSampledProfileFlushInProgress);
}


VOID
FASTCALL
PerfProfileInterrupt(
    IN KPROFILE_SOURCE Source,
    IN PVOID InstructionPointer
    )
/*++

Routine description:

    Implements instruction profiling.  If the source is not the one we're sampling on,
    we return.  If caching is off, we write any samples coming from the immediately to
    the log.  If caching is on, wrap the cache update with writes to the two versions so
    that the flush routine can know if it has a valid buffer.

Arguments:
    
    Source - Type of profile interrupt

    InstructionPointer - IP at the time of the interrupt

Return Value:
    None

--*/
{
    ULONG i;
    PERFINFO_SAMPLED_PROFILE_INFORMATION SampleData;
#ifdef _X86_
    ULONG_PTR TwiddledIP;
#endif // _X86_
    ULONG ThreadId;

    if (!PERFINFO_IS_GROUP_ON(PERF_PROFILE) &&
        (Source != PerfInfoProfileSourceActive)
        ) {
        //
        // We don't handle multple sources.
        //
        return;
    }

    ThreadId = HandleToUlong(PsGetCurrentThread()->Cid.UniqueThread);

    if (!PerfInfoSampledProfileCaching ||
        PerfInfoSampledProfileFlushInProgress != 0) {
        //
        // No caching. Log and return.
        //
        SampleData.ThreadId = ThreadId;
        SampleData.InstructionPointer = InstructionPointer;
        SampleData.Count = 1;

        PerfInfoLogBytes(PERFINFO_LOG_TYPE_SAMPLED_PROFILE,
                            &SampleData,
                            sizeof(PERFINFO_SAMPLED_PROFILE_INFORMATION)
                            );
        return;
    }

#ifdef _X86_
    //
    // Clear the low two bits to have more cache hits for loops.  Don't waste
    // cycles on other architectures.
    //
    TwiddledIP = (ULONG_PTR)InstructionPointer & ~3;
#endif // _X86_

    //
    // Initial walk thru Instruction Pointer Cache.  Bump Count if address is in cache.
    //
    for (i = 0; i < PerfProfileCache.Entries ; i++) {

        if ((PerfProfileCache.Sample[i].ThreadId == ThreadId) &&
#ifdef _X86_
            (((ULONG_PTR)PerfProfileCache.Sample[i].InstructionPointer & ~3) == TwiddledIP)
#else
            (PerfProfileCache.Sample[i].InstructionPointer == InstructionPointer)
#endif // _X86_
            ) {
            //
            // If we find the instruction pointer in the cache, bump the count
            //

            PerfProfileCache.Sample[i].Count++;
            return;
        }
    }
    if (PerfProfileCache.Entries < PERFINFO_SAMPLED_PROFILE_CACHE_MAX) {
        //
        // If we find an empty spot in the cache, use it for this instruction pointer
        //

        PerfProfileCache.Sample[i].ThreadId = ThreadId;
        PerfProfileCache.Sample[i].InstructionPointer = InstructionPointer;
        PerfProfileCache.Sample[i].Count = 1;
        PerfProfileCache.Entries++;
        return;
    }

    //
    // Flush the cache
    //
    PerfInfoLogBytes(PERFINFO_LOG_TYPE_SAMPLED_PROFILE_CACHE,
                    &PerfProfileCache,
                    sizeof(PERFINFO_SAMPLED_PROFILE_CACHE)
                    );

    PerfProfileCache.Sample[0].ThreadId = ThreadId;
    PerfProfileCache.Sample[0].InstructionPointer = InstructionPointer;
    PerfProfileCache.Sample[0].Count = 1;
    PerfProfileCache.Entries = 1;
    return;
}



VOID
FASTCALL
PerfInfoLogInterrupt(
    IN PVOID ServiceRoutine,
    IN ULONG RetVal,
    IN ULONGLONG InitialTime
    )
/*++

Routine Description:

    This callout routine is called from ntoskrnl.exe (ke\intsup.asm) to log an
    interrupt.

Arguments:

    ServiceRoutine - Address of routine that serviced the interrupt.

    RetVal - Value returned from ServiceRoutine.

    InitialTime - Timestamp before ISR was called.  The timestamp in
                  the event is used as the end time.

Return Value:

    None

--*/
{
    PERFINFO_INTERRUPT_INFORMATION EventInfo;

    EventInfo.ServiceRoutine = ServiceRoutine;
    EventInfo.ReturnValue = RetVal;
    EventInfo.InitialTime = InitialTime;

    PerfInfoLogBytes(PERFINFO_LOG_TYPE_INTERRUPT,
                     &EventInfo,
                     sizeof(EventInfo));

    return;
}


NTSTATUS
PerfInfoLogBytesAndUnicodeString(
    USHORT HookId,
    PVOID SourceData,
    ULONG SourceByteCount,
    PUNICODE_STRING String
    )
/*++

Routine description:

    This routine logs data with UniCode string at the end of the hook.

Arguments:
    
    HookId - Hook Id.

    SourceData - Pointer to the data to be copied

    SourceByteCount - Number of bytes to be copied.
    
    String - The string to be logged.

Return Value:
    Status

--*/
{
    NTSTATUS Status;
    PERFINFO_HOOK_HANDLE Hook;
    ULONG ByteCount;
    ULONG StringBytes;

    if (String == NULL) {
        StringBytes = 0;
    } else {
        StringBytes = String->Length;
        if (StringBytes > MAX_FILENAME_TO_LOG) {
            StringBytes = MAX_FILENAME_TO_LOG;
        }
    }

    ByteCount = (SourceByteCount + StringBytes + sizeof(WCHAR));

    Status = PerfInfoReserveBytes(&Hook, HookId, ByteCount);
    if (NT_SUCCESS(Status))
    {
        const PVOID pvTemp = PERFINFO_HOOK_HANDLE_TO_DATA(Hook, PVOID);
        RtlCopyMemory(pvTemp, SourceData, SourceByteCount);
        if (StringBytes != 0) {
            RtlCopyMemory(PERFINFO_APPLY_OFFSET_GIVING_TYPE(pvTemp, SourceByteCount, PVOID),
                          String->Buffer,
                          StringBytes
                          );
        }
        (PERFINFO_APPLY_OFFSET_GIVING_TYPE(pvTemp, SourceByteCount, PWCHAR))[StringBytes / sizeof(WCHAR)] = UNICODE_NULL;
        PERF_FINISH_HOOK(Hook);

        Status = STATUS_SUCCESS;
    }
    return Status;
}


NTSTATUS
PerfInfoLogFileName(
    PVOID  FileObject,
    PUNICODE_STRING SourceString
    )
/*++

Routine Description:

    This routine logs a FileObject pointer and FileName to the log.  The pointer is used
    as hash key to map this name to other trace events.

Arguments:

    FileObject - Pointer to the FileName member within the FILE_OBJECT
                 structure.  The FileName may not yet be initialized,
                 so the actual data comes from the SourceString
                 parameter.

    SourceString - Optional pointer to the source string.


Return Value:

    STATUS_SUCCESS
--*/
{
    NTSTATUS Status = STATUS_SUCCESS;
    PERFINFO_FILENAME_INFORMATION FileInfo;

    if ((FileObject != NULL) &&
        (SourceString != NULL) &&
        (SourceString->Length != 0)) {
        FileInfo.HashKeyFileNamePointer = FileObject;
        Status = PerfInfoLogBytesAndUnicodeString(PERFINFO_LOG_TYPE_FILENAME_CREATE,
                                                  &FileInfo,
                                                  FIELD_OFFSET(PERFINFO_FILENAME_INFORMATION, FileName),
                                                  SourceString);
    }

    return Status;
}


ULONG
PerfInfoCalcHashValue(
    PVOID Key,
    ULONG Len
    )

/*++

Routine Description:

    Generic hash routine.

Arguments:

    Key - Pointer to data to calculate a hash value for.

    Len - Number of bytes pointed to by key.

Return Value:

    Hash value.

--*/

{
    char *cp = Key;
    ULONG i, ConvKey=0;
    for(i = 0; i < Len; i++)
    {
        ConvKey = 37 * ConvKey + (unsigned int) *cp;
        cp++;
    }

    #define RNDM_CONSTANT   314159269
    #define RNDM_PRIME     1000000007

    return (abs(RNDM_CONSTANT * ConvKey) % RNDM_PRIME);
}


BOOLEAN
PerfInfoAddToFileHash(
    PPERFINFO_ENTRY_TABLE HashTable,
    PFILE_OBJECT ObjectPointer
    )
/*++

Routine Description:

    This routine add a FileObject into the specified
    hash table if it is not already there. 

Arguments:

    HashTable - pointer to a hash table to be used.

    ObjectPointer - This is used as a key to identify a mapping.

Return Value:

    TRUE - If either the FileObject was in the table or we add it.
    FALSE - If the table is full.

--*/
{
    ULONG HashIndex;
    LONG i;
    BOOLEAN Result = FALSE;
    LONG TableSize = HashTable->NumberOfEntries;
    PVOID *Table;

    ASSERT (ObjectPointer != NULL);

    Table = HashTable->Table;
    //
    // Get the hashed index into the table where the entry ideally
    // should be at.
    //

    HashIndex = PerfInfoCalcHashValue((PVOID)&ObjectPointer,
                                      sizeof(ObjectPointer)) % TableSize;

    for (i = 0; i < TableSize; i++) {

        if(Table[HashIndex] == NULL) {
            //
            // Found a empty slot. Reference the object and insert
            // it into the table.
            //
            ObReferenceObject(ObjectPointer);
            Table[HashIndex] = ObjectPointer;

            Result = TRUE;
            break;
        } else if (Table[HashIndex] == ObjectPointer) {
            //
            // Found a slot. Reference the object and insert
            // it into the table.
            //
            Result = TRUE;
            break;
        }

        //
        // Try next slot.
        //
        HashIndex = (HashIndex + 1) % TableSize;
    }
    return Result;
}


NTSTATUS
PerfInfoFileNameRunDown (
    )
/*++

Routine Description:

    This routine walks through multiple lists to collect the names of all files.
    It includes:
    1. Handle table: for all file handles
    2. Process Vad for all file objects mapped in VAD.
    3. MmUnusedSegment List
    4. CcDirtySharedCacheMapList & CcCleanSharedCacheMapList

Arguments:

    None.

Return Value:

    BUGBUG Need proper return/ error handling

--*/
{
    PEPROCESS Process;
    ULONG AllocateBytes;
    PFILE_OBJECT *FileObjects;
    PFILE_OBJECT *File;
    PERFINFO_ENTRY_TABLE HashTable;
    extern POBJECT_TYPE IoFileObjectType;
    POBJECT_NAME_INFORMATION FileNameInfo;
    ULONG ReturnLen;
    NTSTATUS Status;
    LONG i;

    //
    // First create a tempory hash table to build the list of
    // files to walk through
    //
    AllocateBytes = PAGE_SIZE + sizeof(PVOID) * IoFileObjectType->TotalNumberOfObjects;

    //
    // Run up to page boundary
    //
    AllocateBytes = PERFINFO_ROUND_UP(AllocateBytes, PAGE_SIZE);

    HashTable.Table = ExAllocatePoolWithTag(NonPagedPool, AllocateBytes, PERFPOOLTAG);

    if (HashTable.Table == NULL) {
        return STATUS_NO_MEMORY;
    } else {
        //
        // Allocation Succeeded
        //
        HashTable.NumberOfEntries = AllocateBytes / sizeof(PVOID);
        RtlZeroMemory(HashTable.Table, AllocateBytes);
    }

    //
    // Allocate Buffers for FileNames
    //
    FileNameInfo = ExAllocatePoolWithTag (NonPagedPool, MAX_FILENAME_TO_LOG, PERFPOOLTAG);

    if (FileNameInfo == NULL) {
        ExFreePool(HashTable.Table);
        return STATUS_NO_MEMORY;
    }

    //
    // Walk through the Cc SharedCacheMapList
    //

    CcPerfFileRunDown(&HashTable);

    //
    // Now, walk through each process
    //
    for (Process = PsGetNextProcess (NULL);
         Process != NULL;
         Process = PsGetNextProcess (Process)) {

        //
        // First Walk the VAD tree
        //

        FileObjects = MmPerfVadTreeWalk(Process);
        if (FileObjects != NULL) {
            File = FileObjects;
            while (*File != NULL) {
                PerfInfoAddToFileHash(&HashTable, *File);
                ObDereferenceObject(*File);
                File += 1;
            }
            ExFreePool(FileObjects);
        }

        //
        // Next, walk the handle Table
        //
        ObPerfHandleTableWalk (Process, &HashTable);
    }

    //
    // Walk through the kernel handle table;
    //
    ObPerfHandleTableWalk(NULL, &HashTable);

    //
    // Walk through the MmUnusedSegmentList;
    //

    FileObjects = MmPerfUnusedSegmentsEnumerate();

    if (FileObjects != NULL) {
        File = FileObjects;
        while (*File != NULL) {
            PerfInfoAddToFileHash(&HashTable, *File);
            ObDereferenceObject(*File);
            File += 1;
        }
        ExFreePool(FileObjects);
    }

    //
    // Now we have walked through all list.
    // Log the filenames and dereference the objects.
    //

    for (i = 0; i < HashTable.NumberOfEntries; i++) {
        if (HashTable.Table[i]) {
            PFILE_OBJECT FileObject = HashTable.Table[i];

            Status = ObQueryNameString( FileObject,
                                        FileNameInfo,
                                        MAX_FILENAME_TO_LOG,
                                        &ReturnLen
                                        );

            if (NT_SUCCESS (Status)) {
                PerfInfoLogFileName(FileObject, &FileNameInfo->Name);
            }
            ObDereferenceObject(FileObject);
        }
    }

    //
    // Free the pool reserved.
    //
    ExFreePool(HashTable.Table);
    ExFreePool(FileNameInfo);

    return STATUS_SUCCESS;
}


NTSTATUS
PerfInfoProcessRunDown (
    )
/*++

Routine Description:

    This routine does the Process and thread rundown in the kernel mode.
    Since this routine is called only by global logger (i.e., trace from boot),
    no Sid info is collected.

Arguments:

    None.

Return Value:

    Status

--*/
{
    NTSTATUS Status;
    PSYSTEM_PROCESS_INFORMATION ProcessInfo;
    PSYSTEM_EXTENDED_THREAD_INFORMATION ThreadInfo;
    PCHAR Buffer;
    ULONG BufferSize = 4096;
    ULONG ReturnLength;

retry:
    Buffer = ExAllocatePoolWithTag(NonPagedPool, BufferSize, PERFPOOLTAG);

    if (!Buffer) {
        return STATUS_NO_MEMORY;
    }
    Status = ZwQuerySystemInformation( SystemExtendedProcessInformation,
                                       Buffer,
                                       BufferSize,
                                       &ReturnLength
                                       );

    if (Status == STATUS_INFO_LENGTH_MISMATCH) {
        ExFreePool(Buffer);
        BufferSize = ReturnLength;
        goto retry;
    }

    if (NT_SUCCESS(Status)) {
        ULONG TotalOffset = 0;
        ProcessInfo = (PSYSTEM_PROCESS_INFORMATION) Buffer;
        while (TRUE) {
            PWMI_PROCESS_INFORMATION WmiProcessInfo;
            PWMI_EXTENDED_THREAD_INFORMATION WmiThreadInfo;
            PERFINFO_HOOK_HANDLE Hook;
            ANSI_STRING ProcessName;
            PCHAR AuxPtr;
            ULONG NameLength;
            ULONG ByteCount;
            ULONG SidLength = sizeof(ULONG);
            ULONG TmpSid = 0;
            ULONG i;

            //
            // Process Information
            //
            if ( ProcessInfo->ImageName.Buffer  && ProcessInfo->ImageName.Length > 0 ) {
                NameLength = ProcessInfo->ImageName.Length / sizeof(WCHAR) + 1;
            }
            else {
                NameLength = 1;
            }
            ByteCount = FIELD_OFFSET(WMI_PROCESS_INFORMATION, Sid) + SidLength + NameLength;

            Status = PerfInfoReserveBytes(&Hook, 
                                          WMI_LOG_TYPE_PROCESS_DC_START, 
                                          ByteCount);

            if (NT_SUCCESS(Status)){
                WmiProcessInfo = PERFINFO_HOOK_HANDLE_TO_DATA(Hook, PWMI_PROCESS_INFORMATION);

                WmiProcessInfo->ProcessId = HandleToUlong(ProcessInfo->UniqueProcessId);
                WmiProcessInfo->ParentId = HandleToUlong(ProcessInfo->InheritedFromUniqueProcessId);
                WmiProcessInfo->SessionId = ProcessInfo->SessionId;
                WmiProcessInfo->PageDirectoryBase = ProcessInfo->PageDirectoryBase;

                AuxPtr = (PCHAR) &WmiProcessInfo->Sid;
                RtlCopyMemory(AuxPtr, &TmpSid, SidLength);

                AuxPtr += SidLength;
                if (NameLength > 1) {
    
                    ProcessName.Buffer = AuxPtr;
                    ProcessName.MaximumLength = (USHORT) NameLength;
    
                    RtlUnicodeStringToAnsiString( &ProcessName,
                                                (PUNICODE_STRING) &ProcessInfo->ImageName,
                                                FALSE);
                    AuxPtr += NameLength - 1; //point to the place for the '\0'
                }
                *AuxPtr = '\0';

                PERF_FINISH_HOOK(Hook);
            }

            //
            // Thread Information
            //
            ThreadInfo = (PSYSTEM_EXTENDED_THREAD_INFORMATION) (ProcessInfo + 1);

            for (i=0; i < ProcessInfo->NumberOfThreads; i++) {
                Status = PerfInfoReserveBytes(&Hook, 
                                              WMI_LOG_TYPE_THREAD_DC_START, 
                                              sizeof(WMI_EXTENDED_THREAD_INFORMATION));
                if (NT_SUCCESS(Status)){
                    WmiThreadInfo = PERFINFO_HOOK_HANDLE_TO_DATA(Hook, PWMI_EXTENDED_THREAD_INFORMATION);
                    WmiThreadInfo->ProcessId =  HandleToUlong(ThreadInfo->ThreadInfo.ClientId.UniqueProcess);
                    WmiThreadInfo->ThreadId =  HandleToUlong(ThreadInfo->ThreadInfo.ClientId.UniqueThread);
                    WmiThreadInfo->StackBase = ThreadInfo->StackBase;
                    WmiThreadInfo->StackLimit = ThreadInfo->StackLimit;

                    WmiThreadInfo->UserStackBase = NULL;
                    WmiThreadInfo->UserStackLimit = NULL;
                    WmiThreadInfo->StartAddr = ThreadInfo->ThreadInfo.StartAddress;
                    WmiThreadInfo->Win32StartAddr = ThreadInfo->Win32StartAddress;
                    WmiThreadInfo->WaitMode = -1;
                    PERF_FINISH_HOOK(Hook);
                }

                ThreadInfo  += 1;
            }

            if (ProcessInfo->NextEntryOffset == 0) {
                break;
            } else {
                TotalOffset += ProcessInfo->NextEntryOffset;
                ProcessInfo = (PSYSTEM_PROCESS_INFORMATION) &Buffer[TotalOffset];
            }
        }
    } 

    ExFreePool(Buffer);
    return Status;

}


NTSTATUS
PerfInfoSysModuleRunDown (
    )
/*++

Routine Description:

    This routine does the rundown for loaded drivers in the kernel mode.

Arguments:

    None.

Return Value:

    Status

--*/
{
    NTSTATUS Status;
    PRTL_PROCESS_MODULES            Modules;
    PRTL_PROCESS_MODULE_INFORMATION ModuleInfo;
    PVOID Buffer;
    ULONG BufferSize = 4096;
    ULONG ReturnLength;
    ULONG i;

retry:
    Buffer = ExAllocatePoolWithTag(NonPagedPool, BufferSize, PERFPOOLTAG);

    if (!Buffer) {
        return STATUS_NO_MEMORY;
    }
    Status = ZwQuerySystemInformation( SystemModuleInformation,
                                       Buffer,
                                       BufferSize,
                                       &ReturnLength
                                       );

    if (Status == STATUS_INFO_LENGTH_MISMATCH) {
        ExFreePool(Buffer);
        BufferSize = ReturnLength;
        goto retry;
    }

    if (NT_SUCCESS(Status)) {
        Modules = (PRTL_PROCESS_MODULES) Buffer;
        for (i = 0, ModuleInfo = & (Modules->Modules[0]);
             i < Modules->NumberOfModules;
             i ++, ModuleInfo ++) {

            PWMI_IMAGELOAD_INFORMATION ImageLoadInfo;
            UNICODE_STRING WstrModuleName;
            ANSI_STRING    AstrModuleName;
            ULONG          SizeModuleName;
            PERFINFO_HOOK_HANDLE Hook;
            ULONG ByteCount;

            RtlInitAnsiString( &AstrModuleName, (PCSZ) ModuleInfo->FullPathName);
            SizeModuleName = sizeof(WCHAR) * (AstrModuleName.Length) + sizeof(WCHAR);
            ByteCount = FIELD_OFFSET(WMI_IMAGELOAD_INFORMATION, FileName) 
                        + SizeModuleName;

            Status = PerfInfoReserveBytes(&Hook, WMI_LOG_TYPE_PROCESS_LOAD_IMAGE, ByteCount);

            if (NT_SUCCESS(Status)){
                ImageLoadInfo = PERFINFO_HOOK_HANDLE_TO_DATA(Hook, PWMI_IMAGELOAD_INFORMATION);
                ImageLoadInfo->ImageBase = ModuleInfo->ImageBase;
                ImageLoadInfo->ImageSize = ModuleInfo->ImageSize;
                ImageLoadInfo->ProcessId = HandleToUlong(NULL);
                WstrModuleName.Buffer    = (LPWSTR) &ImageLoadInfo->FileName[0];
                WstrModuleName.MaximumLength = (USHORT) SizeModuleName; 
                Status = RtlAnsiStringToUnicodeString(&WstrModuleName, & AstrModuleName, FALSE);
                if (!NT_SUCCESS(Status)){
                    ImageLoadInfo->FileName[0] = UNICODE_NULL;
                }

                PERF_FINISH_HOOK(Hook);
            }
        }

    } 

    ExFreePool(Buffer);
    return Status;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\amd64\setlog.c ===
/*++

Copyright (c) 2001  Microsoft Corporation

Module Name:

    setlog.c

Abstract:

    This module contains code to enable/disable performance logging. This
    routine is platform specific to optimize cache usage.

Author:

    David N. Cutler (davec) 8-Sep-2001

Environment:

    Kernel mode only.

Revision History:

--*/

#include "perfp.h"

VOID
PerfSetLogging (
    IN PVOID MaskAddress
    )

/*++

Routine Description:

    This function is called to enable (MaskAddress is nonNULL) or disable
    (MaskAddress is NULL) performance data collection at context switches.

Arguments:

    MaskAddress - Supplies a pointer to the performance logging mask or
        NULL.

Return Value:

    None.

--*/

{

    ULONG Index;
    PKPCR Pcr;
    PKPRCB Prcb;

    //
    // Store the specified mask address in the stack limit field of the PCR
    // for each processor in the configuation.
    //

    for (Index = 0; Index < (ULONG)KeNumberProcessors; Index += 1) {
        Prcb = KiProcessorBlock[Index];
        Pcr = CONTAINING_RECORD(Prcb, KPCR, Prcb);
        Pcr->PerfGlobalGroupMask = MaskAddress;
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\ia64\setlog.c ===
/*++

Copyright (c) 2001  Microsoft Corporation

Module Name:

    setlog.c

Abstract:

    This module contains code to enable/disable performance logging. This
    routine is platform specific to optimize cache usage.

Author:

    David N. Cutler (davec) 8-Sep-2001

Environment:

    Kernel mode only.

Revision History:

--*/

#include "perfp.h"

VOID
PerfSetLogging (
    IN PVOID MaskAddress
    )

/*++

Routine Description:

    This function is called to enable (MaskAddress is nonNULL) or disable
    (MaskAddress is NULL) performance data collection at context switches.

Arguments:

    MaskAddress - Supplies a pointer to the performance logging mask or
        NULL.

Return Value:

    None.

--*/

{

    ULONG Index;
    PKPRCB Prcb;

    //
    // Store the specified mask address in the stack limit field of the PCR
    // for each processor in the configuation.
    //

    for (Index = 0; Index < (ULONG)KeNumberProcessors; Index += 1) {
        Prcb = KiProcessorBlock[Index];

        //
        // What even is needed.
        //

        Prcb->SpareHotData[1] = MaskAddress;
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\perf\i386\setlog.c ===
/*++

Copyright (c) 2001  Microsoft Corporation

Module Name:

    setlog.c

Abstract:

    This module contains code to enable/disable performance logging. This
    routine is platform specific to optimize cache usage.

Author:

    David N. Cutler (davec) 8-Sep-2001

Environment:

    Kernel mode only.

Revision History:

--*/

#include "perfp.h"

VOID
PerfSetLogging (
    IN PVOID MaskAddress
    )

/*++

Routine Description:

    This function is called to enable (MaskAddress is nonNULL) or disable
    (MaskAddress is NULL) performance data collection at context switches.

Arguments:

    MaskAddress - Supplies a pointer to the performance logging mask or
        NULL.

Return Value:

    None.

--*/

{

    ULONG Index;
    PKPCR Pcr;
    PKPRCB Prcb;

    //
    // Store the specified mask address in the stack limit field of the PCR
    // for each processor in the configuation.
    //

    for (Index = 0; Index < (ULONG)KeNumberProcessors; Index += 1) {
        Prcb = KiProcessorBlock[Index];
        Pcr = CONTAINING_RECORD(Prcb, KPCR, PrcbData);
        Pcr->PerfGlobalGroupMask = MaskAddress;
    }

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\po\idle.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    idle.c

Abstract:

    This module implements the power management idle timing code for
    device objects

Author:

    Bryan Willman (bryanwi) 7-Nov-96

Revision History:

--*/


#include "pop.h"

NTKERNELAPI
PULONG
PoRegisterDeviceForIdleDetection (
    IN PDEVICE_OBJECT       DeviceObject,
    IN ULONG                ConservationIdleTime,
    IN ULONG                PerformanceIdleTime,
    IN DEVICE_POWER_STATE   State
    )
/*++

Routine Description:

    A device driver calls this routine to either:
        a. Create and initialize a new idle detection block
        b. Reset values in an existing idle detection block

    If the device object has an idle detection block, it is
    filled in with new values.

    Otherwise, an idle detect block is created and linked to the device
    object.

Arguments:

    DeviceObject - Device object which wants idle detection, set_power
                    IRPs will be sent here

    ConservationIdleTime - timeout for system in "conserve mode"

    PerformanceIdleTime - timeout for system in "performance mode"

    Type            - Type of set_power sent (for set_power irp)

    State           - what state to go to (for set_power irp)

Return Value:

    NULL - if an attempt to create a new idle block failed

    non-NULL - if an idle block was created, or if an existing one was reset

--*/
{
    PDEVICE_OBJECT_POWER_EXTENSION  pdope;
    KIRQL           OldIrql;
    ULONG           DeviceType, OldDeviceType;

    ASSERT(KeGetCurrentIrql() < DISPATCH_LEVEL);
    ASSERT(DeviceObject != NULL);

    //
    // deal with the case where idle detection is being turned off
    //
    if ((ConservationIdleTime == 0) && (PerformanceIdleTime == 0)) {
        PopLockDopeGlobal(&OldIrql);
        pdope = DeviceObject->DeviceObjectExtension->Dope;

        if (pdope == NULL) {
            //
            // cannot be linked into the chain, so must already be off,
            // so we're done
            //

        } else {
            //
            // there is a pdope, so we may be on the idle list
            //
            if ((pdope->IdleList.Flink == &(pdope->IdleList)) &&
                (pdope->IdleList.Blink == &(pdope->IdleList)))
            {
                //
                // we're off the queue already, so we're done
                //

            } else {
                //
                // a dope vector exists and is on the idle scan list,
                // so we must delist ourselves
                //
                RemoveEntryList(&(pdope->IdleList));
                OldDeviceType = pdope->DeviceType | ES_CONTINUOUS;
                pdope->DeviceType = 0;
                PopApplyAttributeState (ES_CONTINUOUS, OldDeviceType);

                pdope->ConservationIdleTime = 0L;
                pdope->PerformanceIdleTime = 0L;
                pdope->State = PowerDeviceUnspecified;
                pdope->IdleCount = 0;
                InitializeListHead(&(pdope->IdleList));
            }
        }
        PopUnlockDopeGlobal(OldIrql);
        return NULL;
    }

    //
    // Set DeviceType if this is an idle registration by type
    //

    DeviceType = 0;
    if (ConservationIdleTime == (ULONG) -1 &&
        PerformanceIdleTime  == (ULONG) -1) {

        switch (DeviceObject->DeviceType) {
            case FILE_DEVICE_DISK:
            case FILE_DEVICE_MASS_STORAGE:

                //
                // Or-in ES_CONTINUOUS which will go up
                // in the high bits.  We'll ignore this bit
                // when we typecast this into a UCHAR as we
                // assign this to pdope->DeviceType, however, we
                // need this high bit set for when we call into
                // PopApplyAttributeState.  That's because we
                // overload the flags we send into this function
                // with both the device type and the flags to
                // apply to that device type.
                //
                DeviceType = POP_DISK_SPINDOWN | ES_CONTINUOUS;
                break;

            default:
                //
                // Unsupported type
                //

                return NULL;
        }
    }


    //
    // now, the case where it's being turned on
    //
    pdope = PopGetDope(DeviceObject);
    if (pdope == NULL) {
        //
        // we didn't have a DOPE structure and couldn't allocate one, fail
        //
        return NULL;
    }

    //
    // May be a newly allocated Dope, or an existing one.
    // In either case, update values.
    // Enqueue if not already in queue
    //

    PopLockDopeGlobal(&OldIrql);

    OldDeviceType = pdope->DeviceType | ES_CONTINUOUS;

    pdope->ConservationIdleTime = ConservationIdleTime;
    pdope->PerformanceIdleTime = PerformanceIdleTime;
    pdope->State = State;
    pdope->IdleCount = 0;

    //
    // type cast this so we ignore any high bits set which
    // may contain attributes.  All we care about is the
    // device type, which is in the low byte.
    //
    pdope->DeviceType = (UCHAR) DeviceType;

    if ((pdope->IdleList.Flink == &(pdope->IdleList)) &&
        (pdope->IdleList.Blink == &(pdope->IdleList)))
    {
        //
        // we're off the queue, and must be enqueued
        //
        InsertTailList(&PopIdleDetectList, &(pdope->IdleList));
    }

    PopUnlockDopeGlobal(OldIrql);
    PopApplyAttributeState(DeviceType, OldDeviceType);
    PopCheckForWork(TRUE);

    return (PULONG) &(pdope->IdleCount);  // success
}




VOID
PopScanIdleList(
    IN PKDPC    Dpc,
    IN PVOID    DeferredContext,
    IN PVOID    SystemArgument1,
    IN PVOID    SystemArgument2
    )

/*++

Routine Description:

    Called by the PopIdleScanTimer at PopIdleScanTimeInseconds interval,
    this routine runs the list of Idle Blocks, finding any that meet the
    trip conditions, and sends commands to the appropriate device objects
    to change state.

    The timer that calls this DPC is setup in poinit.c.

Arguments:

    Standard DPC arguments, all are ignored.

Return Value:

    None.

--*/
{
    KIRQL   OldIrql;
    PLIST_ENTRY link;
    ULONG       idlelimit;
    PDEVICE_OBJECT_POWER_EXTENSION  pblock;
    POWER_STATE PowerState;
    PLONG  pIdleCount;
    ULONG   oldCount;

    UNREFERENCED_PARAMETER (Dpc);
    UNREFERENCED_PARAMETER (DeferredContext);
    UNREFERENCED_PARAMETER (SystemArgument1);
    UNREFERENCED_PARAMETER (SystemArgument2);

    PopLockDopeGlobal(&OldIrql);

    link = PopIdleDetectList.Flink;
    while (link != &PopIdleDetectList) {


        pblock = CONTAINING_RECORD(link, DEVICE_OBJECT_POWER_EXTENSION, IdleList);
        pIdleCount = &(pblock->IdleCount);
        oldCount = InterlockedIncrement(pIdleCount);

        switch (pblock->DeviceType) {
            case 0:
                idlelimit = pblock->PerformanceIdleTime;
                if (PopIdleDetectionMode == PO_IDLE_CONSERVATION) {
                    idlelimit = pblock->ConservationIdleTime;
                }
                break;

            case POP_DISK_SPINDOWN:
                idlelimit = PopPolicy->SpindownTimeout;
                break;

            default:
                idlelimit = 0;
                PopInternalAddToDumpFile( NULL, 0, pblock->DeviceObject, NULL, NULL, pblock );
                KeBugCheckEx( INTERNAL_POWER_ERROR,
                              0x200,
                              POP_IDLE,
                              (ULONG_PTR)pblock->DeviceObject,
                              (ULONG_PTR)pblock );
        }

        if ((idlelimit > 0) && ((oldCount+1) == idlelimit)) {
            PowerState.DeviceState = pblock->State;
            PoRequestPowerIrp (
                pblock->DeviceObject,
                IRP_MN_SET_POWER,
                PowerState,
                NULL,
                NULL,
                NULL
                );
        }

        link = link->Flink;
    }

    PopUnlockDopeGlobal(OldIrql);
    return;
}


PDEVICE_OBJECT_POWER_EXTENSION
PopGetDope (
    PDEVICE_OBJECT DeviceObject
    )
{
    PDEVOBJ_EXTENSION               Doe;
    PDEVICE_OBJECT_POWER_EXTENSION  Dope;
    KIRQL                           OldIrql;

    Doe = (PDEVOBJ_EXTENSION) DeviceObject->DeviceObjectExtension;

    if (!Doe->Dope) {
        PopLockDopeGlobal(&OldIrql);

        if (!Doe->Dope) {
            Dope = (PDEVICE_OBJECT_POWER_EXTENSION)
                    ExAllocatePoolWithTag(
                        NonPagedPool,
                        sizeof(DEVICE_OBJECT_POWER_EXTENSION),
                        POP_DOPE_TAG
                        );
            if (Dope) {
                RtlZeroMemory (Dope, sizeof(DEVICE_OBJECT_POWER_EXTENSION));
                Dope->DeviceObject = DeviceObject;
                Dope->State = PowerDeviceUnspecified;
                InitializeListHead(&(Dope->IdleList));
                InitializeListHead(&(Dope->NotifySourceList));
                InitializeListHead(&(Dope->NotifyTargetList));

                // force the signature to 0 so buildpowerchannel gets called
                Dope->PowerChannelSummary.Signature = (ULONG)0;
                InitializeListHead(&(Dope->PowerChannelSummary.NotifyList));

                Doe->Dope = Dope;
            }
        }

        PopUnlockDopeGlobal(OldIrql);
    }

    return Doe->Dope;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\po\attrib.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    attrib.c

Abstract:

    Power management attribute accounting

Author:

    Ken Reneris (kenr) 25-Feb-97

Revision History:

--*/


#include "pop.h"

VOID
PopUserPresentSetWorker(
    PVOID Context
    );

//
// System state structure to track registered settings
//

typedef struct {
    LONG                   State;
} POP_SYSTEM_STATE, *PPOP_SYSTEM_STATE;

#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, PopUserPresentSetWorker)
#endif

VOID
PoSetSystemState (
    IN ULONG Flags
    )
/*++

Routine Description:

    Used to pulse attribute(s) as busy.

Arguments:

    Flags       - Attributes to pulse

Return Value:

    None.

--*/
{
    //
    // Verify reserved bits are clear and continous is not set
    //

    if (Flags & ~(ES_DISPLAY_REQUIRED | ES_SYSTEM_REQUIRED | POP_LOW_LATENCY | ES_USER_PRESENT)) {
        ASSERT(0);
        return;
    }

    //
    // Apply the attributes
    //

    PopApplyAttributeState (Flags, 0);

    //
    // Check for work
    //

    PopCheckForWork (TRUE);
}




PVOID
PoRegisterSystemState (
    IN PVOID        StateHandle,
    IN ULONG        NewFlags
    )
/*++

Routine Description:

    Used to register or pulse attribute(s) as busy.

Arguments:

    StateHandle - If StateHandle is null, then a new registration is allocated, set
                  accordingly, and returned.   If non-null, the pass registeration
                  is adjusted to its new setting.

    NewFlags    - Attributes to set or pulse

Return Value:

    Handle to unregister when complete

--*/
{
    ULONG               OldFlags;
    PPOP_SYSTEM_STATE   SystemState;

    //
    // Verify reserved bits are clear
    //

    if (NewFlags & ~(ES_CONTINUOUS | ES_SYSTEM_REQUIRED | ES_DISPLAY_REQUIRED |
                    POP_LOW_LATENCY | ES_USER_PRESENT)) {
        ASSERT(0);
        return NULL;
    }

    //
    // If there's no state handle allocated, do it now
    //

    if (!StateHandle) {
        StateHandle = ExAllocatePoolWithTag (
                            NonPagedPool,
                            sizeof (POP_SYSTEM_STATE),
                            POP_PSTA_TAG
                            );

        if (!StateHandle) {
            return NULL;
        }
        RtlZeroMemory(StateHandle, sizeof(POP_SYSTEM_STATE));
    }

    //
    // If the continous bit is set, modify current flags
    //

    SystemState = (PPOP_SYSTEM_STATE) StateHandle;
    OldFlags = SystemState->State | ES_CONTINUOUS;
    if (NewFlags & ES_CONTINUOUS) {
        OldFlags = InterlockedExchange (&SystemState->State, NewFlags);
    }

    //
    // Apply the changes
    //

    PopApplyAttributeState (NewFlags, OldFlags);

    //
    // Check for any outstanding work
    //

    PopCheckForWork (FALSE);

    //
    // Done
    //

    return SystemState;
}


VOID
PoUnregisterSystemState (
    IN PVOID    StateHandle
    )
/*++

Routine Description:

    Frees a registration allocated by PoRegisterSystemState

Arguments:

    StateHandle - If non-null, existing registeration to change

    NewFlags    - Attributes to set or pulse

Return Value:

    Handle to unregister when complete

--*/
{
    ASSERT(StateHandle);
    
    //
    // Make sure current attribute settings are clear
    //

    PoRegisterSystemState (StateHandle, ES_CONTINUOUS);

    //
    // Free state structure
    //

    ExFreePool (StateHandle);
}


VOID
PopApplyAttributeState (
    IN ULONG NewFlags,
    IN ULONG OldFlags
    )
/*++

Routine Description:

    Function applies attribute flags to system.  If the attributes
    are continuous in nature, then a count is updated to reflect
    the total number of outstanding settings.

Arguments:

    NewFlags    - Attributes being set

    OldFlags    - Current attributes

Return Value:

    None.

--*/
{
    ULONG                i;
    ULONG                Count;
    ULONG                Changes;
    ULONG                Mask;
    PPOP_STATE_ATTRIBUTE Attribute;

    //
    // Get flags which have changed, ignoring any change
    // in ES_CONTINUOUS.
    //

    Changes = (NewFlags ^ OldFlags) & ~ES_CONTINUOUS;

    //
    // Check each flag
    //

    while (Changes) {
        
        //
        // Get the right-most change, then clear
        // that bit in the 'Changes' vector.
        //
        // Mask tells gives us an index into NewFlags
        // which will indicate if the attribute is being
        // set or cleared.
        //
        //
        // N.B. The incoming flags are being overloaded
        //      and is also being used as an index into
        //      PopAttributes.  Maintainers of this code
        //      need to be careful here.  KeFindFirstSetRightMember
        //      will give us the bit position of the lower-order
        //      bit that's set.  So if Changes == 1, we'll get
        //      back 0.
        //      This means if someone sends in ES_DISPLAY_REQUIRED, where
        //      #define ES_DISPLAY_REQUIRED ((ULONG)0x00000002),
        //      then i would be 1, which happens to correspond to
        //      PopAttributes[POP_DISPLAY_ATTRIBUTE] because
        //      #define ES_DISPLAY_REQUIRED ((ULONG)0x00000002)
        //
        //      Be careful to keep these sets of constants in sync.
        //
        i = KeFindFirstSetRightMember(Changes);
        Mask = 1 << i;
        Changes &= ~Mask;



        //
        // Which system attribute are they setting
        // flags for?
        //
        if( i <= POP_NUMBER_ATTRIBUTES ) {
            Attribute = PopAttributes + i;
    
            //
            // If this is a continous change, update the flags
            //
    
            if (NewFlags & ES_CONTINUOUS) {
    
                //
                // Count the times the attribute is set or cleared
                //
    
                if (NewFlags & Mask) {
    
                    //
                    // Being set
                    //
    
                    Count = InterlockedIncrement (&Attribute->Count);
    
                    //
                    // If attributes count is moved from zero, set it
                    //
    
                    if (Count == 1) {
                        Attribute->Set (Attribute->Arg);
                    }
    
                } else {
    
                    //
                    // Being cleared
                    //
    
                    Count = InterlockedDecrement (&Attribute->Count);
                    ASSERT (Count != -1);
    
                    //
                    // If attributes count is now zero, clear it
                    //
    
                    if (Count == 0  &&  Attribute->NotifyOnClear) {
                        Attribute->Set (Attribute->Arg);
                    }
                }
    
            } else {
    
                //
                // If count is 0, pulse it
                //
    
    
                if (Attribute->Count == 0) {
    
                    //
                    // Pulse the attribute
                    //
    
                    Attribute->Set (Attribute->Arg);
                }
    
            }
        } else {
            //
            // They're asking us to fiddle with a system attribute
            // that doesn't exist.
            //
            ASSERT(0);
        }
    }
}

VOID
PopAttribNop (
    IN ULONG Arg
    )
{
    UNREFERENCED_PARAMETER (Arg);
}

VOID
PopSystemRequiredSet (
    IN ULONG Arg
    )
/*++

Routine Description:

    System required attribute has been set

Arguments:

    None

Return Value:

    None.

--*/
{
    UNREFERENCED_PARAMETER (Arg);

    //
    // System is not idle
    //

    if (PopSIdle.Time) {
        PopSIdle.Time = 0;
    }
}

#define AllBitsSet(a,b)    ( ((a) & (b)) == (b) )

VOID
PopDisplayRequired (
    IN ULONG Arg
    )
/*++

Routine Description:

    Display required attribute has been set/cleared

Arguments:

    None

Return Value:

    None.

--*/
{
    UNREFERENCED_PARAMETER (Arg);

    //
    // If gdi isn't on, do it now
    //

    if ( !AnyBitsSet (PopFullWake, PO_GDI_STATUS | PO_GDI_ON_PENDING)) {
        InterlockedOr (&PopFullWake, PO_GDI_ON_PENDING);
    }

    //
    // Inform GDI of the display needed change
    //

    PopSetNotificationWork (PO_NOTIFY_DISPLAY_REQUIRED);
}




VOID
PopUserPresentSet (
    IN ULONG Arg
    )
/*++

Routine Description:

    User presence attribute has been set

Arguments:

    None

Return Value:

    None.

--*/
{
    PULONG runningWorker;

    UNREFERENCED_PARAMETER (Arg);

    //
    // System is not idle
    //

    if (PopSIdle.Time) {
        PopSIdle.Time = 0;
    }

    //
    // If the system isn't fully awake, and the all the wake pending bits
    // are not set, set them
    //

    if (!AllBitsSet (PopFullWake, PO_FULL_WAKE_STATUS | PO_GDI_STATUS)) {

        if (!AllBitsSet (PopFullWake, PO_FULL_WAKE_PENDING | PO_GDI_ON_PENDING)) {

            InterlockedOr (&PopFullWake, (PO_FULL_WAKE_PENDING | PO_GDI_ON_PENDING));
            PopSetNotificationWork (PO_NOTIFY_FULL_WAKE);
        }
    }

    //
    // Go to passive level to look for lid switches.
    //
    
    runningWorker = InterlockedExchangePointer(&PopUserPresentWorkItem.Parameter,
                                               (PVOID)TRUE);
    
    if (runningWorker) {
        return;
    }

    ExInitializeWorkItem(&PopUserPresentWorkItem,
                         PopUserPresentSetWorker,
                         PopUserPresentWorkItem.Parameter);

    ExQueueWorkItem(
      &PopUserPresentWorkItem,
      DelayedWorkQueue
      );
}

VOID
PopUserPresentSetWorker(
    PVOID Context
    )
{
    PPOP_SWITCH_DEVICE switchDev; 
    
    PAGED_CODE();

    UNREFERENCED_PARAMETER (Context);

    //
    // We can't always know for sure whether the lid (if there is one)
    // is opened or closed.  Assume that if the user is present,
    // the lid is opened.
    //

    switchDev = (PPOP_SWITCH_DEVICE)PopSwitches.Flink;

    while (switchDev != (PPOP_SWITCH_DEVICE)&PopSwitches) {

        if ((switchDev->Caps & SYS_BUTTON_LID) &&
            (switchDev->Opened == FALSE)) {

            //
            // We currently believe that the lid is closed.  Set
            // it to "opened."
            //
            
            switchDev->Opened = TRUE;
            //
            // Notify the PowerState callback.
            //

            ExNotifyCallback (
                ExCbPowerState,
                UIntToPtr(PO_CB_LID_SWITCH_STATE),
                UIntToPtr(switchDev->Opened)
                );
        }

        switchDev = (PPOP_SWITCH_DEVICE)switchDev->Link.Flink;
    }

    InterlockedExchangePointer(&PopUserPresentWorkItem.Parameter,
                               (PVOID)FALSE);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\base\ntos\po\hiber.c ===
/*++

Copyright (c) 1990  Microsoft Corporation

Module Name:

    hiber.c

Abstract:

Author:

    Ken Reneris (kenr) 13-April-1997

Revision History:

   Elliot Shmukler (t-ellios) 8/7/1998       Added Hiber file compression
   Andrew Kadatch  (akadatch)
     Added Xpress file compression
     Added DMA-based IO

--*/


#include "pop.h"
#include "stdio.h"              // for sprintf
#include "inbv.h"
#include "xpress.h"             // XPRESS declarations

// size of buffer to store compressed data
#define POP_COMPRESSED_PAGE_SET_SIZE  (((XPRESS_MAX_SIZE + 2 * XPRESS_HEADER_SIZE + PAGE_SIZE - 1) >> PAGE_SHIFT) + 1)

// Structure used to allocate memory for hand-crafted MDL
typedef struct _DUMP_MDL {
    MDL        BaseMdl;
    PFN_NUMBER PfnArray[POP_MAX_MDL_SIZE + 1];
} DUMP_MDL[1];

typedef struct _COMPRESSION_BLOCK {
    UCHAR Buffer[XPRESS_MAX_SIZE], *Ptr;
} COMPRESSION_BLOCK, *PCOMPRESSION_BLOCK;


// Data structures for DMA-based IO
typedef struct
{
    PUCHAR Beg;       // ptr to the beginning of entire
    PUCHAR End;       // ptr to the end of memory block

    PUCHAR Ptr;       // ptr to beginning of region
    LONG   Size;      // size of region after ptr
    LONG   SizeOvl;       // size of overlapping piece starting from beginning of buffer
} IOREGION;


#define IOREGION_BUFF_PAGES 64  /* 256 KB */
#define IOREGION_BUFF_SIZE  (IOREGION_BUFF_PAGES << PAGE_SHIFT)

typedef struct {
    PLARGE_INTEGER          FirstMcb;
    PLARGE_INTEGER          Mcb;
    ULONGLONG               Base;
} POP_MCB_CONTEXT, *PPOP_MCB_CONTEXT;

#define HIBER_WRITE_PAGES_LOCALS_LIST(X)\
    X (ULONGLONG,        FileBase);     \
    X (ULONGLONG,        PhysBase);     \
    X (ULONG_PTR,        Length);       \
    X (ULONGLONG,        McbOffset);    \
    X (LARGE_INTEGER,    IoLocation);   \
    X (PHYSICAL_ADDRESS, pa);           \
    X (PPOP_MCB_CONTEXT, CMcb);         \
    X (PVOID,            PageVa);       \
    X (PMDL,             Mdl);          \
    X (PPFN_NUMBER,      MdlPage);      \
    X (PFN_NUMBER,       NoPages);      \
    X (PFN_NUMBER,       FilePage);     \
    X (ULONG,            IoLength);     \
    X (ULONG,            i);            \
    X (NTSTATUS,         Status);

typedef struct
{
    DUMP_MDL DumpMdl;
#define X(type,name) type name
    HIBER_WRITE_PAGES_LOCALS_LIST (X)
#undef  X
} HIBER_WRITE_PAGES_LOCALS;

typedef struct {
    IOREGION Free, Used, Busy;
    PFN_NUMBER FilePage[IOREGION_BUFF_PAGES];
    PVOID DumpLocalData;
    ULONG UseDma;
    ULONG DmaInitialized;

    struct {
        PUCHAR Ptr;
        ULONG  Bytes;
    } Chk;

    HIBER_WRITE_PAGES_LOCALS HiberWritePagesLocals;
} DMA_IOREGIONS;

#define DmaIoPtr ((DMA_IOREGIONS *)(HiberContext->DmaIO))

// May we use DMA IO?
#define HIBER_USE_DMA(HiberContext) \
  (DmaIoPtr != NULL && \
   DmaIoPtr->UseDma && \
   HiberContext->DumpStack->Init.WritePendingRoutine != NULL)

#define HbCopy(_hibercontext_,_dest_,_src_,_len_) {               \
    ULONGLONG _starttime_;                                        \
                                                                  \
    (_hibercontext_)->PerfInfo.BytesCopied += (ULONG)(_len_);     \
    _starttime_ = HIBER_GET_TICK_COUNT(NULL);                     \
    RtlCopyMemory((_dest_),(_src_),(_len_));                       \
    (_hibercontext_)->PerfInfo.CopyTicks +=                       \
        HIBER_GET_TICK_COUNT(NULL) - _starttime_;                 \
}


#ifdef HIBER_DEBUG
#define DBGOUT(x) DbgPrint x
#else
#define DBGOUT(x)
#endif

//
// The performance counter on x86 doesn't work very well during hibernate
// because interrupts are turned off and we don't get the rollovers. So use
// RDTSC instead.
//
#if !defined(i386)
#define HIBER_GET_TICK_COUNT(_x_) KeQueryPerformanceCounter(_x_).QuadPart
#else
__inline
LONGLONG
HIBER_GET_TICK_COUNT(
    OUT PLARGE_INTEGER Frequency OPTIONAL
    )
{
    if (ARGUMENT_PRESENT(Frequency)) {
        Frequency->QuadPart = (ULONGLONG)KeGetCurrentPrcb()->MHz * 1000000;
    }
    _asm _emit 0x0f
    _asm _emit 0x31
}
#endif



extern LARGE_INTEGER  KdTimerDifference;
extern UNICODE_STRING IoArcBootDeviceName;
extern PUCHAR IoLoaderArcBootDeviceName;
extern UNICODE_STRING IoArcHalDeviceName;
extern POBJECT_TYPE IoFileObjectType;
extern ULONG MmAvailablePages;
extern PFN_NUMBER MmHighestPhysicalPage;
extern ULONG MmHiberPages;
extern ULONG MmZeroPageFile;

KPROCESSOR_STATE        PoWakeState;

//
// Define the size of the I/Os used to zero the hiber file
//
#define POP_ZERO_CHUNK_SIZE (64 * 1024)

VOID
RtlpGetStackLimits (
    OUT PULONG_PTR LowLimit,
    OUT PULONG_PTR HighLimit
    );

NTSTATUS
PopCreateHiberFile (
    IN PPOP_HIBER_FILE  HiberFile,
    IN PWCHAR           NameString,
    IN PLARGE_INTEGER   FileSize,
    IN BOOLEAN          DebugHiberFile
    );

PSECURITY_DESCRIPTOR
PopCreateHiberFileSecurityDescriptor(
    VOID
    );

NTSTATUS
PopCreateHiberLinkFile (
    IN PPOP_HIBER_CONTEXT   HiberContext
    );

VOID
PopClearHiberFileSignature (
    IN BOOLEAN              GetStats
    );

VOID
PopPreserveRange(
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PFN_NUMBER           StartPage,
    IN PFN_NUMBER           PageCount,
    IN ULONG                Tag
    );

VOID
PopCloneRange(
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PFN_NUMBER           StartPage,
    IN PFN_NUMBER           PageCount,
    IN ULONG                Tag
    );

VOID
PopDiscardRange(
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PFN_NUMBER           StartPage,
    IN PFN_NUMBER           PageCount,
    IN ULONG                Tag
    );

VOID
PopSetRange (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN ULONG                Flags,
    IN PFN_NUMBER           StartPage,
    IN PFN_NUMBER           PageCount,
    IN ULONG                Tag
    );

ULONG
PopSimpleRangeCheck (
    IN PPOP_MEMORY_RANGE    Range
    );

VOID
PopCreateDumpMdl (
    IN PMDL         Mdl,
    IN PFN_NUMBER   StartPage,
    IN PFN_NUMBER   EndPage
    );

PVOID
PopAllocatePages (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PFN_NUMBER           NoPages
    );

VOID
PopWriteHiberPages (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PVOID                Page,
    IN PFN_NUMBER           NoPages,
    IN PFN_NUMBER           FilePage,
    IN HIBER_WRITE_PAGES_LOCALS *Locals
    );

NTSTATUS
PopWriteHiberImage (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PPO_MEMORY_IMAGE     MemImage,
    IN PPOP_HIBER_FILE      HiberFile
    );

VOID
PopUpdateHiberComplete (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN ULONG                Percent
    );

VOID
PopReturnMemoryForHibernate (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN BOOLEAN              Unmap,
    IN OUT PMDL             *MdlList
    );

VOID
PopAddPagesToCompressedPageSet(
   IN BOOLEAN              AllowDataBuffering,
   IN PPOP_HIBER_CONTEXT   HiberContext,
   IN OUT PULONG_PTR       CompressedBufferOffset,
   IN PVOID                StartVa,
   IN PFN_NUMBER           NumPages,
   IN OUT PPFN_NUMBER      SetFilePage
   );

VOID
PopEndCompressedPageSet(
   IN PPOP_HIBER_CONTEXT   HiberContext,
   IN OUT PULONG_PTR       CompressedBufferOffset,
   IN OUT PPFN_NUMBER      SetFilePage
   );

UCHAR
PopGetHiberFlags(
    VOID
    );

PMDL
PopSplitMdl(
    IN PMDL Original,
    IN ULONG SplitPages
    );

VOID
PopZeroHiberFile(
    IN HANDLE FileHandle,
    IN PFILE_OBJECT FileObject
    );

PVOID
PopAllocateOwnMemory(
    IN PPOP_HIBER_CONTEXT HiberContext,
    IN ULONG Bytes,
    IN ULONG Tag
    );

PVOID
XPRESS_CALL
PopAllocateHiberContextCallback(
    PVOID context,
    int CompressionWorkspaceSize
    );

VOID
PopIORegionMove (
    IN IOREGION *To,      // ptr to region descriptor to put bytes to
    IN IOREGION *From,        // ptr to region descriptor to get bytes from
    IN LONG Bytes         // # of bytes to add to the end of region
    );

BOOLEAN
PopIOResume (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN BOOLEAN Complete
    );

VOID
XPRESS_CALL
PopIOCallback (
    PVOID Context,
    int Compressed
    );

VOID
PopIOWrite (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PUCHAR               Ptr,
    IN LONG                 Bytes,
    IN PFN_NUMBER           FilePage
    );

VOID
PopHiberPoolInit (
    PPOP_HIBER_CONTEXT HiberContext,
    PVOID Memory,
    ULONG Size
    );

BOOLEAN
PopHiberPoolCheckFree(
    PVOID HiberPoolPtr,
    PVOID BlockPtr
    );

PVOID
PopHiberPoolAllocFree (
    IN POOL_TYPE PoolType,
    IN SIZE_T NumberOfBytes,
    IN ULONG Tag,
    PVOID MemoryPtr
    );

VOID
PopDumpStatistics(
    IN PPO_HIBER_PERF PerfInfo
    );


#ifdef ALLOC_PRAGMA
#pragma alloc_text(PAGE, PopEnableHiberFile)
#pragma alloc_text(PAGE, PopCreateHiberFile)
#pragma alloc_text(PAGE, PopClearHiberFileSignature)
#pragma alloc_text(PAGE, PopAllocateHiberContext)
#pragma alloc_text(PAGE, PopCreateHiberLinkFile)
#pragma alloc_text(PAGE, PopGetHiberFlags)
#pragma alloc_text(PAGE, PopZeroHiberFile)
#pragma alloc_text(PAGE, PopAllocateHiberContextCallback)
#pragma alloc_text(PAGELK, PoSetHiberRange)
#pragma alloc_text(PAGELK, PopGatherMemoryForHibernate)
#pragma alloc_text(PAGELK, PopCloneStack)
#pragma alloc_text(PAGELK, PopPreserveRange)
#pragma alloc_text(PAGELK, PopCloneRange)
#pragma alloc_text(PAGELK, PopDiscardRange)
#pragma alloc_text(PAGELK, PopAllocatePages)
#pragma alloc_text(PAGELK, PopBuildMemoryImageHeader)
#pragma alloc_text(PAGELK, PopSaveHiberContext)
#pragma alloc_text(PAGELK, PopWriteHiberImage)
#pragma alloc_text(PAGELK, PopHiberComplete)
#pragma alloc_text(PAGELK, PopSimpleRangeCheck)
#pragma alloc_text(PAGELK, PopCreateDumpMdl)
#pragma alloc_text(PAGELK, PopWriteHiberPages)
#pragma alloc_text(PAGELK, PopUpdateHiberComplete)
#pragma alloc_text(PAGELK, PopFreeHiberContext)
#pragma alloc_text(PAGELK, PopReturnMemoryForHibernate)
#pragma alloc_text(PAGELK, PopAddPagesToCompressedPageSet)
#pragma alloc_text(PAGELK, PopEndCompressedPageSet)
#pragma alloc_text(PAGELK, PopAllocateOwnMemory)
#pragma alloc_text(PAGELK, PopIORegionMove)
#pragma alloc_text(PAGELK, PopIOResume)
#pragma alloc_text(PAGELK, PopIOCallback)
#pragma alloc_text(PAGELK, PopIOWrite)
#pragma alloc_text(PAGELK, PopHiberPoolInit)
#pragma alloc_text(PAGELK, PopHiberPoolCheckFree)
#pragma alloc_text(PAGELK, PopHiberPoolAllocFree)
#pragma alloc_text(PAGELK, PopDumpStatistics)
#ifdef HIBER_DEBUG
#pragma alloc_text(PAGELK, PopHiberPoolVfy)
#endif

#endif

NTSTATUS
PopEnableHiberFile (
    IN BOOLEAN Enable
    )
/*++

Routine Description:

    This function commits or decommits the storage required to hold the
    hibernation image on the boot volume.

    N.B. The power policy lock must be held

Arguments:

    Enable      - TRUE if hibernation file is to be reserved; otherwise, false

Return Value:

    Status

--*/
{
    PDUMP_STACK_CONTEXT             DumpStack;
    NTSTATUS                        Status;
    LARGE_INTEGER                   FileSize;
    ULONG                           i;
    PFN_NUMBER                      NoPages;

    //
    // If this is a disable handle it
    //

    if (!Enable) {
        if (!PopHiberFile.FileObject) {
            Status = STATUS_SUCCESS;
            goto Done;
        }

        //
        // Disable hiber file
        //
        if (MmZeroPageFile) {
            PopZeroHiberFile(PopHiberFile.FileHandle, PopHiberFile.FileObject);
        }

        ObDereferenceObject (PopHiberFile.FileObject);
        ZwClose (PopHiberFile.FileHandle);
        ExFreePool (PopHiberFile.PagedMcb);
        RtlZeroMemory (&PopHiberFile, sizeof(PopHiberFile));

        if (PopHiberFileDebug.FileObject) {

            if (MmZeroPageFile) {
                PopZeroHiberFile(PopHiberFileDebug.FileHandle,PopHiberFileDebug.FileObject );
            }
            ObDereferenceObject (PopHiberFileDebug.FileObject);
            ZwClose (PopHiberFileDebug.FileHandle);
            RtlZeroMemory (&PopHiberFileDebug, sizeof(PopHiberFileDebug));
        }

        //
        // Disable hiberfile allocation
        //

        PopCapabilities.HiberFilePresent = FALSE;
        PopHeuristics.HiberFileEnabled = FALSE;
        PopHeuristics.Dirty = TRUE;

        //
        // remove any logging records related to hibernation.
        //
        PopRemoveReasonRecordByReasonCode(SPSD_REASON_HIBERSTACK);
        PopRemoveReasonRecordByReasonCode(SPSD_REASON_HIBERFILE);

        //
        // recompute the policies and make the proper notification
        //
        Status = PopResetCurrentPolicies ();
        PopSetNotificationWork (PO_NOTIFY_CAPABILITIES);
        goto Done;
    }

    //
    // Enable hiber file
    //

    if (PopHiberFile.FileObject) {
        Status = STATUS_SUCCESS;
        goto Done;
    }

    //
    // If the hal hasn't registered an S4 handler, then it's not possible
    //

    if (!PopCapabilities.SystemS4) {
        Status = STATUS_NOT_SUPPORTED;
        goto Done;
    }

    //
    // Compute the size required for a hibernation file
    //

    NoPages = 0;
    for (i=0; i < MmPhysicalMemoryBlock->NumberOfRuns; i++) {
        NoPages += MmPhysicalMemoryBlock->Run[i].PageCount;
    }

    FileSize.QuadPart = (ULONGLONG) NoPages << PAGE_SHIFT;

    //
    // If we've never verified that the dumpstack loads do so now
    // before we allocate a huge file on the boot disk
    //

    if (!PopHeuristics.GetDumpStackVerified) {
        Status = IoGetDumpStack ((PWCHAR)PopDumpStackPrefix,
                                 &DumpStack,
                                 DeviceUsageTypeHibernation,
                                 (POP_IGNORE_UNSUPPORTED_DRIVERS & PopSimulate));

        if (!NT_SUCCESS(Status)) {
            //
            // try to remember that we can't do S4 because of this.
            //
            PSYSTEM_POWER_STATE_DISABLE_REASON pReason;
            NTSTATUS LogStatus;
            
            //
            // alloc and initialize the entry, then insert it.
            //
            pReason = ExAllocatePoolWithTag(
                                    PagedPool,
                                    sizeof(SYSTEM_POWER_STATE_DISABLE_REASON),
                                    POP_COMMON_BUFFER_TAG);
            if (pReason) {
                RtlZeroMemory(pReason,sizeof(SYSTEM_POWER_STATE_DISABLE_REASON));
                pReason->AffectedState[PowerStateSleeping4] = TRUE;
                pReason->PowerReasonCode = SPSD_REASON_HIBERSTACK;
                
                LogStatus = PopInsertLoggingEntry(pReason);
                if (LogStatus != STATUS_SUCCESS) {
                    ExFreePool(pReason);
                }
                
            }

            goto Done;
        }
        IoFreeDumpStack (DumpStack);
        PopHeuristics.GetDumpStackVerified = TRUE;
    }

    //
    // Create the hiberfile file
    //

    Status = PopCreateHiberFile (&PopHiberFile, (PWCHAR)PopHiberFileName, &FileSize, FALSE);
    if (!NT_SUCCESS(Status)) {
        //
        // try to remember that we can't do S4 because of this.
        //
        PSYSTEM_POWER_STATE_DISABLE_REASON pReason;
        NTSTATUS LogStatus;
        
        //
        // alloc and initialize the entry, then insert it.
        //
        pReason = ExAllocatePoolWithTag(
                                PagedPool,
                                sizeof(SYSTEM_POWER_STATE_DISABLE_REASON)+sizeof(Status),
                                POP_COMMON_BUFFER_TAG);
        if (pReason) {
            RtlZeroMemory(pReason,sizeof(SYSTEM_POWER_STATE_DISABLE_REASON));
            pReason->AffectedState[PowerStateSleeping4] = TRUE;
            pReason->PowerReasonCode = SPSD_REASON_HIBERFILE;
            pReason->PowerReasonLength = sizeof(Status);
            RtlCopyMemory(
                (PCHAR)((PCHAR)pReason+sizeof(SYSTEM_POWER_STATE_DISABLE_REASON)),
                &Status,
                sizeof(Status));
            
            LogStatus = PopInsertLoggingEntry(pReason);
            if (LogStatus != STATUS_SUCCESS) {
                ExFreePool(pReason);
            }
            
        }

        goto Done;
    }

    //
    // Create the debug hiberfile file
    //

    if (PopSimulate  & POP_DEBUG_HIBER_FILE) {
        PopCreateHiberFile (&PopHiberFileDebug, (PWCHAR)PopDebugHiberFileName, &FileSize, TRUE);
    }

    //
    // Success
    //

    PopCapabilities.HiberFilePresent = TRUE;
    if (!PopHeuristics.HiberFileEnabled) {
        PopHeuristics.HiberFileEnabled = TRUE;
        PopHeuristics.Dirty = TRUE;
    }

    PopClearHiberFileSignature (FALSE);

Done:
    PopSaveHeuristics ();
    return Status;
}

NTSTATUS
PopCreateHiberFile (
    IN PPOP_HIBER_FILE  HiberFile,
    IN PWCHAR           NameString,
    IN PLARGE_INTEGER   FileSize,
    IN BOOLEAN          DebugHiberFile
    )
{
    UNICODE_STRING                  BaseName;
    UNICODE_STRING                  HiberFileName;
    OBJECT_ATTRIBUTES               ObjectAttributes;
    FILE_END_OF_FILE_INFORMATION    Eof;
    NTSTATUS                        Status;
    IO_STATUS_BLOCK                 IoStatus;
    HANDLE                          FileHandle = NULL;
    LONGLONG                        McbFileSize;
    PFILE_OBJECT                    File = NULL;
    PDEVICE_OBJECT                  DeviceObject;
    PLARGE_INTEGER                  mcb;
    ULONG                           i;
    PSECURITY_DESCRIPTOR            SecurityDescriptor = NULL;

    HiberFileName.Buffer = NULL;
    mcb = NULL;

    RtlInitUnicodeString (&BaseName, NameString);

    HiberFileName.Length = 0;
    HiberFileName.MaximumLength = IoArcBootDeviceName.Length + BaseName.Length;
    HiberFileName.Buffer = ExAllocatePoolWithTag (PagedPool|POOL_COLD_ALLOCATION,
                                                  HiberFileName.MaximumLength,
                                                  POP_HIBR_TAG);

    if (!HiberFileName.Buffer) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto Done;
    }

    RtlAppendUnicodeStringToString(&HiberFileName, &IoArcBootDeviceName);
    RtlAppendUnicodeStringToString(&HiberFileName, &BaseName);

    //
    // create security descriptor
    //
    SecurityDescriptor = PopCreateHiberFileSecurityDescriptor();

    InitializeObjectAttributes(&ObjectAttributes,
                               &HiberFileName,
                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                               NULL,
                               SecurityDescriptor);

    //
    // Whack any existing file to avoid someone's attempt
    // at file-squatting.
    //
    Status = ZwDeleteFile( &ObjectAttributes );

    if( !NT_SUCCESS(Status) && (Status != STATUS_OBJECT_NAME_NOT_FOUND) ) {

        //
        // Could be a directory or a stubborn file...
        // Open the file, fix attributes, then try the delete
        // again.
        //

        HANDLE                      Handle;
        PFILE_OBJECT                FileObject;
        OBJECT_HANDLE_INFORMATION   HandleInfo;
        FILE_BASIC_INFORMATION      BasicInfo;
        FILE_DISPOSITION_INFORMATION Disposition;

        Status = ZwOpenFile( &Handle,
                            (ACCESS_MASK)(DELETE | FILE_WRITE_ATTRIBUTES),
                            &ObjectAttributes,
                            &IoStatus,
                            FILE_SHARE_DELETE | FILE_SHARE_READ | FILE_SHARE_WRITE,
                            FILE_OPEN_FOR_BACKUP_INTENT | FILE_OPEN_REPARSE_POINT );
        if( NT_SUCCESS(Status) ) {
            
           Status = ObReferenceObjectByHandle(
                            Handle,
                            (ACCESS_MASK)DELETE,
                            IoFileObjectType,
                            ExGetPreviousMode(),
                            &FileObject,
                            &HandleInfo
                            );
            
            if( NT_SUCCESS(Status) ) {


                //
                // Reset attributes.
                //
                RtlZeroMemory( &BasicInfo, sizeof( FILE_BASIC_INFORMATION ) );
                BasicInfo.FileAttributes = FILE_ATTRIBUTE_NORMAL;
                IoSetInformation( FileObject,
                                  FileBasicInformation,
                                  sizeof(BasicInfo),
                                  &BasicInfo);
                
                
                //
                // Setup for delete.
                //
                Disposition.DeleteFile = TRUE;
                IoSetInformation( FileObject,
                                  FileDispositionInformation,
                                  sizeof(Disposition),
                                  &Disposition);
                
                
                ObDereferenceObject(FileObject);
            }

            // Close the handle, which should delete the file/directory.
            ZwClose( Handle );

        }

    }


    Status = IoCreateFile(
                &FileHandle,
                FILE_READ_DATA | FILE_WRITE_DATA | SYNCHRONIZE,
                &ObjectAttributes,
                &IoStatus,
                FileSize,
                FILE_ATTRIBUTE_HIDDEN | FILE_ATTRIBUTE_SYSTEM | FILE_ATTRIBUTE_NOT_CONTENT_INDEXED,
                0L,
                FILE_SUPERSEDE,
                FILE_WRITE_THROUGH | FILE_NO_INTERMEDIATE_BUFFERING | FILE_NO_COMPRESSION | FILE_DELETE_ON_CLOSE,
                (PVOID) NULL,
                0L,
                CreateFileTypeNone,
                (PVOID) NULL,
                IO_OPEN_PAGING_FILE | IO_NO_PARAMETER_CHECKING
                );

    if (!NT_SUCCESS(Status)) {
        PoPrint (PO_HIBERNATE, ("PopCreateHiberFile: failed to create file %x\n", Status));
        goto Done;
    }

    Status = ObReferenceObjectByHandle (FileHandle,
                                        FILE_READ_DATA | FILE_WRITE_DATA,
                                        IoFileObjectType,
                                        KernelMode,
                                        (PVOID *)&File,
                                        NULL);
    if (!NT_SUCCESS(Status)) {
        goto Done;
    }

    //
    // Set the size
    //

    Eof.EndOfFile.QuadPart = FileSize->QuadPart;
    Status = ZwSetInformationFile (
                   FileHandle,
                   &IoStatus,
                   &Eof,
                   sizeof(Eof),
                   FileEndOfFileInformation
                   );
    if (Status == STATUS_PENDING) {
        Status = KeWaitForSingleObject(
                        &File->Event,
                        Executive,
                        KernelMode,
                        FALSE,
                        NULL
                        );

        Status = IoStatus.Status;
    }

    if (!NT_SUCCESS(Status) || !NT_SUCCESS(IoStatus.Status)) {
        PoPrint (PO_HIBERNATE, ("PopCreateHiberFile: failed to set eof %x  %x\n",
            Status, IoStatus.Status
            ));
        goto Done;
    }


    //
    // Hibernation file needs to be on the boot partition
    //

    DeviceObject = File->DeviceObject;
    if (!(DeviceObject->Flags & DO_SYSTEM_BOOT_PARTITION)) {
        Status = STATUS_UNSUCCESSFUL;
        goto Done;
    }

    //
    // Get the hiber file's layout
    //

    Status = ZwFsControlFile (
                    FileHandle,
                    (HANDLE) NULL,
                    (PIO_APC_ROUTINE) NULL,
                    (PVOID) NULL,
                    &IoStatus,
                    FSCTL_QUERY_RETRIEVAL_POINTERS,
                    FileSize,
                    sizeof (LARGE_INTEGER),
                    &mcb,
                    sizeof (PVOID)
                    );

    if (Status == STATUS_PENDING) {
        Status = KeWaitForSingleObject(
                        &File->Event,
                        Executive,
                        KernelMode,
                        FALSE,
                        NULL
                        );

        Status = IoStatus.Status;
    }

    if (!NT_SUCCESS(Status)) {
        goto Done;
    }

    //
    // We have a hibernation file.   Determine the number of mcbs, and perform
    // a simply sanity check on them.
    //

    McbFileSize = 0;
    for (i=0; mcb[i].QuadPart; i += 2) {
        McbFileSize += mcb[i].QuadPart;
        if (mcb[i+1].HighPart < 0) {
            Status = STATUS_UNSUCCESSFUL;
            goto Done;
        }
    }

    if (McbFileSize < FileSize->QuadPart) {
        Status = STATUS_UNSUCCESSFUL;
        goto Done;
    }

    HiberFile->NonPagedMcb = mcb;
    HiberFile->McbSize = (i+2) * sizeof(LARGE_INTEGER);
    HiberFile->PagedMcb = ExAllocatePoolWithTag (PagedPool|POOL_COLD_ALLOCATION,
                                                 HiberFile->McbSize,
                                                 POP_HIBR_TAG);

    if (!HiberFile->PagedMcb) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto Done;
    }

    memcpy (HiberFile->PagedMcb, mcb, HiberFile->McbSize);
    HiberFile->FileHandle = FileHandle;
    HiberFile->FileObject = File;
    HiberFile->FilePages = (PFN_NUMBER) (FileSize->QuadPart >> PAGE_SHIFT);
    HiberFile->McbCheck = PoSimpleCheck (0, HiberFile->PagedMcb, HiberFile->McbSize);

Done:
    if (!NT_SUCCESS(Status)) {
        if (FileHandle != NULL) {
            ZwClose (FileHandle);
        }
        if (File != NULL) {
            ObDereferenceObject(File);
        }
    }

    if (SecurityDescriptor) {
        ExFreePool(SecurityDescriptor);
    }

    if (HiberFileName.Buffer) {
        ExFreePool (HiberFileName.Buffer);
    }

    if (mcb  &&  !DebugHiberFile) {
        HiberFile->NonPagedMcb = NULL;
        ExFreePool (mcb);
    }


    //
    // If no error, then hiber file being present change one way or another -
    // recompute the policies and make the proper notification
    //

    if (NT_SUCCESS(Status)) {
        PopResetCurrentPolicies ();
        PopSetNotificationWork (PO_NOTIFY_CAPABILITIES);
    }

    return Status;
}

NTSTATUS
PopCreateHiberLinkFile (
    IN PPOP_HIBER_CONTEXT       HiberContext
    )
/*++

Routine Description:

    This function creates a file on the loader partition which supplies
    the loader with the location of the hibernation context file

Arguments:

    None

Return Value:

    None

--*/
{
    UNICODE_STRING                  BaseName;
    UNICODE_STRING                  HiberFileName;
    OBJECT_ATTRIBUTES               ObjectAttributes;
    NTSTATUS                        Status;
    IO_STATUS_BLOCK                 IoStatus;
    LARGE_INTEGER                   FileSize;
    LARGE_INTEGER                   ByteOffset;
    PPO_IMAGE_LINK                  LinkImage;
    PUCHAR                          Buffer;
    ULONG                           Length;
    HANDLE                          FileHandle=NULL;

    Buffer = NULL;

    RtlInitUnicodeString (&BaseName, PopHiberFileName);

    //
    // Allocate working space
    //

    Length = IoArcHalDeviceName.Length + BaseName.Length;
    if (Length < IoArcBootDeviceName.Length + sizeof(PO_IMAGE_LINK)) {
        Length = IoArcBootDeviceName.Length + sizeof(PO_IMAGE_LINK);
    }

    Buffer = ExAllocatePoolWithTag (PagedPool, Length, POP_HIBR_TAG);
    if (!Buffer) {
        Status = STATUS_INSUFFICIENT_RESOURCES;
        goto Done;
    }

    LinkImage = (PPO_IMAGE_LINK) Buffer;
    HiberFileName.Buffer = (PWCHAR) Buffer;
    HiberFileName.MaximumLength = (USHORT) Length;

    //
    // Open hiberfil.sys on loader partition
    //

    HiberFileName.Length = 0;
    RtlAppendUnicodeStringToString(&HiberFileName, &IoArcHalDeviceName);
    RtlAppendUnicodeStringToString(&HiberFileName, &BaseName);

    InitializeObjectAttributes(
        &ObjectAttributes,
        &HiberFileName,
        OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
        NULL,
        NULL
        );

    FileSize.QuadPart = 0;
    Status = IoCreateFile (
                &FileHandle,
                FILE_READ_DATA | FILE_WRITE_DATA | SYNCHRONIZE,
                &ObjectAttributes,
                &IoStatus,
                &FileSize,
                FILE_ATTRIBUTE_HIDDEN | FILE_ATTRIBUTE_SYSTEM,
                0,
                FILE_SUPERSEDE,
                FILE_SYNCHRONOUS_IO_NONALERT | FILE_NO_COMPRESSION | FILE_DELETE_ON_CLOSE,
                (PVOID) NULL,
                0L,
                CreateFileTypeNone,
                (PVOID) NULL,
                0
                );

    if (!NT_SUCCESS(Status)) {

        if (Status != STATUS_SHARING_VIOLATION && Status != STATUS_ACCESS_DENIED) {
            PoPrint (PO_HIBERNATE, ("PopCreateHiberLinkFile: failed to create file %x\n", Status));
        }

        //
        // Having a link file is nice, but it's not a requirement
        //

        Status = STATUS_SUCCESS;
        goto Done;
    }

    //
    // Write the partition name to link to
    //

    LinkImage->Signature = PO_IMAGE_SIGNATURE_LINK;
    Length = (ULONG) (strlen ((PCHAR)IoLoaderArcBootDeviceName) + 1);
    memcpy (LinkImage->Name, IoLoaderArcBootDeviceName, Length);

    ByteOffset.QuadPart = 0;
    Status = ZwWriteFile (
                FileHandle,
                NULL,
                NULL,
                NULL,
                &IoStatus,
                LinkImage,
                FIELD_OFFSET (PO_IMAGE_LINK, Name) + Length,
                &ByteOffset,
                NULL
                );

    if (!NT_SUCCESS(Status)) {
        goto Done;
    }

    //
    // Link file needs to make it to the disk
    //

    ZwFlushBuffersFile (FileHandle, &IoStatus);

    //
    // Success, keep the file around
    //

    HiberContext->LinkFile = TRUE;
    HiberContext->LinkFileHandle = FileHandle;

Done:
    if (Buffer) {
        ExFreePool (Buffer);
    }

    if ((!NT_SUCCESS(Status)) &&
        (FileHandle != NULL)) {
        ZwClose (FileHandle);
    }
    return Status;
}


VOID
PopClearHiberFileSignature (
    IN BOOLEAN GetStats
    )
/*++

Routine Description:

    This function sets the signature in the hibernation image to be 0,
    which indicates no context is contained in the image.

    N.B. The power policy lock must be held

Arguments:

    GetStats - if TRUE indicates performance statistics should be read
               out of the hiberfile and written into the registry

Return Value:

    None

--*/
{
    NTSTATUS            Status;
    IO_STATUS_BLOCK     IoStatus;
    PUCHAR              Buffer;
    LARGE_INTEGER       ByteOffset;
    KEVENT              Event;
    PMDL                Mdl;

    if (PopHiberFile.FileObject) {
        Buffer = ExAllocatePoolWithTag (NonPagedPool, PAGE_SIZE, POP_HIBR_TAG);
        if (Buffer == NULL) {
            return;
        }

        KeInitializeEvent(&Event, NotificationEvent, FALSE);
        RtlZeroMemory (Buffer, PAGE_SIZE);
        ByteOffset.QuadPart = 0;

        Mdl = MmCreateMdl (NULL, Buffer, PAGE_SIZE);
        PoAssert( PO_ERROR, Mdl );
        if( !Mdl ) {
            // 'Event' hasn't been set so no cleanup needed.
            return;
        }
        MmBuildMdlForNonPagedPool (Mdl);

        if (GetStats) {
            Status = IoPageRead(PopHiberFile.FileObject,
                                Mdl,
                                &ByteOffset,
                                &Event,
                                &IoStatus);
            PoAssert( PO_ERROR, NT_SUCCESS(Status) );
            
            if (NT_SUCCESS(Status)) {
                KeWaitForSingleObject(&Event, Executive, KernelMode, FALSE, NULL);
                if (NT_SUCCESS(IoStatus.Status)) {
                    UNICODE_STRING          UnicodeString;
                    OBJECT_ATTRIBUTES       ObjectAttributes;
                    HANDLE                  Handle;
                    ULONG                   Data;
                    PPO_MEMORY_IMAGE        MemImage = (PPO_MEMORY_IMAGE)Buffer;

                    RtlInitUnicodeString(&UnicodeString,
                                         L"\\Registry\\Machine\\System\\CurrentControlSet\\Control\\Session Manager\\Power");
                    InitializeObjectAttributes(&ObjectAttributes,
                                               &UnicodeString,
                                               OBJ_CASE_INSENSITIVE | OBJ_KERNEL_HANDLE,
                                               NULL,
                                               NULL);
                    Status = ZwOpenKey(&Handle,
                                       KEY_READ | KEY_WRITE,
                                       &ObjectAttributes);
                    PoAssert( PO_ERROR, NT_SUCCESS(Status) );
                    
                    if (NT_SUCCESS(Status)) {
                        RtlInitUnicodeString(&UnicodeString, L"HiberElapsedTime");
                        Data = MemImage->PerfInfo.ElapsedTime;
                        Status = ZwSetValueKey(Handle,
                                      &UnicodeString,
                                      0,
                                      REG_DWORD,
                                      &Data,
                                      sizeof(Data));
                        PoAssert( PO_ERROR, NT_SUCCESS(Status) );
                        
                        RtlInitUnicodeString(&UnicodeString, L"HiberIoTime");
                        Data = MemImage->PerfInfo.IoTime;
                        Status = ZwSetValueKey(Handle,
                                      &UnicodeString,
                                      0,
                                      REG_DWORD,
                                      &Data,
                                      sizeof(Data));
                        PoAssert( PO_ERROR, NT_SUCCESS(Status) );
                        
                        RtlInitUnicodeString(&UnicodeString, L"HiberCopyTime");
                        Data = MemImage->PerfInfo.CopyTime;
                        Status = ZwSetValueKey(Handle,
                                      &UnicodeString,
                                      0,
                                      REG_DWORD,
                                      &Data,
                                      sizeof(Data));
                        PoAssert( PO_ERROR, NT_SUCCESS(Status) );

                        RtlInitUnicodeString(&UnicodeString, L"HiberCopyBytes");
                        Data = MemImage->PerfInfo.BytesCopied;
                        Status = ZwSetValueKey(Handle,
                                      &UnicodeString,
                                      0,
                                      REG_DWORD,
                                      &Data,
                                      sizeof(Data));
                        PoAssert( PO_ERROR, NT_SUCCESS(Status) );

                        RtlInitUnicodeString(&UnicodeString, L"HiberPagesWritten");
                        Data = MemImage->PerfInfo.PagesWritten;
                        Status = ZwSetValueKey(Handle,
                                      &UnicodeString,
                                      0,
                                      REG_DWORD,
                                      &Data,
                                      sizeof(Data));
                        PoAssert( PO_ERROR, NT_SUCCESS(Status) );

                        RtlInitUnicodeString(&UnicodeString, L"HiberPagesProcessed");
                        Data = MemImage->PerfInfo.PagesProcessed;
                        Status = ZwSetValueKey(Handle,
                                      &UnicodeString,
                                      0,
                                      REG_DWORD,
                                      &Data,
                                      sizeof(Data));
                        PoAssert( PO_ERROR, NT_SUCCESS(Status) );

                        RtlInitUnicodeString(&UnicodeString, L"HiberDumpCount");
                        Data = MemImage->PerfInfo.DumpCount;
                        Status = ZwSetValueKey(Handle,
                                      &UnicodeString,
                                      0,
                                      REG_DWORD,
                                      &Data,
                                      sizeof(Data));
                        PoAssert( PO_ERROR, NT_SUCCESS(Status) );

                        RtlInitUnicodeString(&UnicodeString, L"HiberFileRuns");
                        Data = MemImage->PerfInfo.FileRuns;
                        Status = ZwSetValueKey(Handle,
                                      &UnicodeString,
                                      0,
                                      REG_DWORD,
                                      &Data,
                                      sizeof(Data));
                        PoAssert( PO_ERROR, NT_SUCCESS(Status) );

                        ZwClose(Handle);
                    }
                }
            }
        }

        RtlZeroMemory (Buffer, PAGE_SIZE);
        KeClearEvent(&Event);

        IoSynchronousPageWrite (
            PopHiberFile.FileObject,
            Mdl,
            &ByteOffset,
            &Event,
            &IoStatus
            );

        KeWaitForSingleObject(&Event, Executive, KernelMode, FALSE, NULL);
        ExFreePool (Mdl);
        ExFreePool (Buffer);
    }
}


VOID
PopZeroHiberFile(
    IN HANDLE FileHandle,
    IN PFILE_OBJECT FileObject
    )
/*++

Routine Description:

    Zeroes out a hibernation file completely. This is to prevent
    any leakage of data out of the hiberfile once it has been
    deleted.

Arguments:

    FileHandle - Supplies the file handle to be zeroed.

    FileObject - Supplies the file object to be zeroed.
Return Value:

    None.

--*/

{
    IO_STATUS_BLOCK IoStatusBlock;
    FILE_STANDARD_INFORMATION FileInfo;
    LARGE_INTEGER Offset;
    ULONGLONG Remaining;
    ULONG Size;
    PVOID Zeroes;
    NTSTATUS Status;
    PMDL Mdl;
    KEVENT Event;

    PAGED_CODE();

    KeInitializeEvent(&Event, NotificationEvent, FALSE);

    //
    // Get the size of the file to be zeroed
    //
    Status = ZwQueryInformationFile(FileHandle,
                                    &IoStatusBlock,
                                    &FileInfo,
                                    sizeof(FileInfo),
                                    FileStandardInformation);
    if (NT_SUCCESS(Status)) {

        //
        // Allocate a bunch of memory to use as zeroes
        //
        Zeroes = ExAllocatePoolWithTag(NonPagedPool,
                                       POP_ZERO_CHUNK_SIZE,
                                       'rZoP');
        if (Zeroes) {
            RtlZeroMemory(Zeroes, POP_ZERO_CHUNK_SIZE);
            Mdl = MmCreateMdl(NULL, Zeroes, POP_ZERO_CHUNK_SIZE);
            if (Mdl) {

                MmBuildMdlForNonPagedPool (Mdl);
                Offset.QuadPart = 0;
                Remaining = FileInfo.AllocationSize.QuadPart;
                Size = POP_ZERO_CHUNK_SIZE;
                while (Remaining) {
                    if (Remaining < POP_ZERO_CHUNK_SIZE) {
                        Size = (ULONG)Remaining;
                        Mdl = MmCreateMdl(Mdl, Zeroes, Size);
                        MmBuildMdlForNonPagedPool(Mdl);
                    }

                    KeClearEvent(&Event);
                    Status = IoSynchronousPageWrite(FileObject,
                                                    Mdl,
                                                    &Offset,
                                                    &Event,
                                                    &IoStatusBlock);
                    if (NT_SUCCESS(Status)) {
                        KeWaitForSingleObject(&Event, Executive, KernelMode, FALSE, NULL);
                        Status = IoStatusBlock.Status;
                    }
                    if (!NT_SUCCESS(Status)) {
                        PoPrint (PO_HIBERNATE | PO_ERROR,
                                 ("PopZeroHiberFile: Write of size %lx at offset %I64x failed %08lx\n",
                                  Size,
                                  Offset.QuadPart,
                                  Status));
                    }

                    Offset.QuadPart += Size;
                    Remaining -= Size;
                }

                ExFreePool (Mdl);
            }
            ExFreePool(Zeroes);
        }
    }

}


PVOID
XPRESS_CALL
PopAllocateHiberContextCallback(
    PVOID context,
    int CompressionWorkspaceSize
    )
/*++

Routine Description:

    Called by XpressEncodeCreate to allocate XpressEncodeStream.

Arguments:

    context     - HiberContext
    CompressionWorkspaceSize - size of block to allocate

Return Value:

    Pointer to allocated memory or NULL if no enough memory

--*/
{
   // Allocate the memory required for the engine's workspace
   return PopAllocateOwnMemory (context, CompressionWorkspaceSize, 'Xprs');
}

PVOID
PopAllocateOwnMemory(
    IN PPOP_HIBER_CONTEXT HiberContext,
    IN ULONG Bytes,
    IN ULONG Tag
    )
/*++

Routine Description:

    Called to allocate memory that will not be hibernated

Arguments:

    HiberContext - Pointer to POP_HIBER_CONTEXT structure
    Bytes        - size of memory block in bytes that
                   may be not aligned on page boundary

Return Value:

    Address of memory block or NULL if failed (status will be set in this case)

--*/
{
    PVOID Ptr;
    ULONG Pages;

    // Get # of full pages
    Pages = (Bytes + (PAGE_SIZE-1)) >> PAGE_SHIFT;

    // Allocate memory
    Ptr = PopAllocatePages (HiberContext, Pages);

    // Check for error
    if (Ptr == NULL) {
        HiberContext->Status = STATUS_INSUFFICIENT_RESOURCES;
    } else {
        // Do not hibernate this memory
        PoSetHiberRange (HiberContext,
                         PO_MEM_DISCARD,
                         Ptr,
                         Pages << PAGE_SHIFT,
                         Tag);
    }

    return(Ptr);
}


NTSTATUS
PopAllocateHiberContext (
    VOID
    )
/*++

Routine Description:

    Called to allocate an initial hibernation context structure.

    N.B. The power policy lock must be held

Arguments:

    None

Return Value:

    Status

--*/
{
    PPOP_HIBER_CONTEXT          HiberContext;
    ULONG                       i;
    PDUMP_INITIALIZATION_CONTEXT     DumpInit = NULL;
    PFN_NUMBER                  NoPages;
    PFN_NUMBER                  Length;
    PLIST_ENTRY                 Link;
    PPOP_MEMORY_RANGE           Range;
    NTSTATUS                    Status;

    PAGED_CODE();

    //
    // Allocate space to hold the hiber context
    //

    Status = STATUS_SUCCESS;
    HiberContext = PopAction.HiberContext;
    if (!HiberContext) {
        HiberContext = ExAllocatePoolWithTag (NonPagedPool,
                                              sizeof (POP_HIBER_CONTEXT),
                                              POP_HMAP_TAG);
        if (!HiberContext) {
            return STATUS_INSUFFICIENT_RESOURCES;
        }
        RtlZeroMemory (HiberContext, sizeof(*HiberContext));
        PopAction.HiberContext = HiberContext;

        InitializeListHead (&HiberContext->ClonedRanges);
        KeInitializeSpinLock (&HiberContext->Lock);
    }

    //
    // Determine what type of hiber context for this operation
    // is needed
    //

    if (PopAction.SystemState == PowerSystemHibernate) {

        //
        // For a hibernate operation, the context is written
        // to the hibernation file, pages need to be set aside
        // for the loaders use, and any pages not needed to
        // be written to the hibernation file should also be
        // set aside
        //

        HiberContext->WriteToFile = TRUE;
        HiberContext->ReserveLoaderMemory = TRUE;
        HiberContext->ReserveFreeMemory = TRUE;
        HiberContext->VerifyOnWake = FALSE;

    } else if (PopSimulate & POP_CRC_MEMORY) {

        //
        // We want to checksum all of RAM during this sleep
        // operation.  We don't want to reserve any pages for
        // anything else since the goal here is to likely look
        // for somesort of corruption of failure.
        //

        HiberContext->WriteToFile = FALSE;
        HiberContext->ReserveLoaderMemory = FALSE;
        HiberContext->ReserveFreeMemory = FALSE;
        HiberContext->VerifyOnWake = TRUE;

    } else {

        //
        // A hiber context is not needed for this sleep
        //

        PopFreeHiberContext (TRUE);
        return STATUS_SUCCESS;
    }

    //
    // If there's an error in the current context, then we're done
    //

    if (!NT_SUCCESS(HiberContext->Status)) {
        goto Done;
    }

    //
    // If writting to hibernation file, get a dump driver stack
    //

    if (HiberContext->WriteToFile) {

        //
        // Get a dump stack
        //

        if (!HiberContext->DumpStack) {
            if (!PopHiberFile.FileObject) {
                Status = STATUS_NO_SUCH_FILE;
                goto Done;
            }

            Status = IoGetDumpStack ((PWCHAR)PopDumpStackPrefix,
                                     &HiberContext->DumpStack,
                                     DeviceUsageTypeHibernation,
                                     (POP_IGNORE_UNSUPPORTED_DRIVERS & PopSimulate));

            if (!NT_SUCCESS(Status)) {
                goto Done;
            }

            DumpInit = &HiberContext->DumpStack->Init;

            //
            // N.B. For further performance improvements it may be possible
            //      to set DumpInit->StallRoutine to a custom routine
            //      in order to do some processing while the dump driver
            //      is waiting pointlessly before performing some hardware
            //      related action (such as ISR calls).
            //


        }

        //
        // Create a link file for the loader to locate the hibernation file
        //

        Status = PopCreateHiberLinkFile (HiberContext);
        if (!NT_SUCCESS(Status)) {
            goto Done;
        }

        //
        // Get any hibernation flags that must be visible to the osloader
        //
        HiberContext->HiberFlags = PopGetHiberFlags();
    }

    //
    // Build a map of memory
    //

    if (HiberContext->MemoryMap.Buffer == NULL) {
        PULONG                      BitmapBuffer;
        ULONG                       PageCount;

        //
        // Initialize a bitmap describing all of physical memory.
        // For now this bitmap covers from 0-MmHighestPhysicalPage.
        // To support sparse memory maps more efficiently, we could break
        // this up into a bitmap for each memory block run. Probably
        // not a big deal, a single bitmap costs us 4K per 128MB on x86.
        //
        // Note that CLEAR bits in the bitmap represent what to write out.
        // This is because of the way the bitmap interfaces are defined.
        //
        PageCount = (ULONG)((MmHighestPhysicalPage + 32) & ~31L);

        PERFINFO_HIBER_ADJUST_PAGECOUNT_FOR_BBTBUFFER(&PageCount);

        BitmapBuffer = ExAllocatePoolWithTag(NonPagedPool, PageCount/8, POP_HMAP_TAG);
        if (BitmapBuffer == NULL) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto Done;
        }

        RtlInitializeBitMap(&HiberContext->MemoryMap, BitmapBuffer, PageCount);
        RtlSetAllBits(&HiberContext->MemoryMap);

        for (i=0; i < MmPhysicalMemoryBlock->NumberOfRuns; i++) {
            PopPreserveRange(HiberContext,
                             MmPhysicalMemoryBlock->Run[i].BasePage,
                             MmPhysicalMemoryBlock->Run[i].PageCount,
                             POP_MEM_TAG);
        }

        PERFINFO_HIBER_HANDLE_BBTBUFFER_RANGE(HiberContext);

        //
        // Handle kernel debugger's section
        //

        if (!KdPitchDebugger) {
            PoSetHiberRange (HiberContext,
                             PO_MEM_CLONE,
                             (PVOID) &KdTimerDifference,
                             0,
                             POP_DEBUGGER_TAG);
        }

        //
        // Get Mm hibernation ranges and info
        //

        MmHibernateInformation (HiberContext,
                                &HiberContext->HiberVa,
                                &HiberContext->HiberPte);

        //
        // Get hal hibernation ranges
        //

        HalLocateHiberRanges (HiberContext);

        //
        // Get the dump drivers stack hibernation ranges
        //

        if (HiberContext->DumpStack) {
            IoGetDumpHiberRanges (HiberContext, HiberContext->DumpStack);
        }

        //
        // Allocate pages for cloning
        //

        NoPages = 0;
        Link = HiberContext->ClonedRanges.Flink;
        while (Link != &HiberContext->ClonedRanges) {
            Range = CONTAINING_RECORD (Link, POP_MEMORY_RANGE, Link);
            Link = Link->Flink;
            NoPages += Range->EndPage - Range->StartPage;
        }

        //
        // Add more for ranges which are expected to appear later
        //

        NoPages += 40 + ((KERNEL_LARGE_STACK_SIZE >> PAGE_SHIFT) + 2) * KeNumberProcessors;
        Length = NoPages << PAGE_SHIFT;

        //
        // Allocate pages to hold clones
        //

        PopGatherMemoryForHibernate (HiberContext, NoPages, &HiberContext->Spares, TRUE);

        //
        // Slurp one page for doing non-aligned IOs
        //

        HiberContext->IoPage = PopAllocatePages (HiberContext, 1);
    }

    if (!NT_SUCCESS(HiberContext->Status)) {
        goto Done;
    }

    //
    // If the context will be written to disk, then we will
    // want to use compression.
    //

    if(HiberContext->WriteToFile) {

        // Initialize XPRESS compression engine

        HiberContext->CompressionWorkspace =
            (PVOID) XpressEncodeCreate (XPRESS_MAX_SIZE,
                                        (PVOID)HiberContext,
                                        PopAllocateHiberContextCallback,
                                        0);

        if(!HiberContext->CompressionWorkspace) {
            // Not enough memory -- failure
            HiberContext->Status = STATUS_INSUFFICIENT_RESOURCES;
            goto Done;
        }

        //
        // Allocate a buffer to use for compression
        //
        // N.B. This is actually the space alloted for a compressed page set fragment
        //      (a collection
        //      of compressed buffers that will be written out together in an optimal fashion).
        //
        //      We add 2 pages to this fragment size in order to
        //      allow the compression of any given page
        //      (and thus the addition of its compressed buffers to the fragment) to overrun the
        //      compression buffer without causing any great havoc.
        //
        //      See PopAddPagesToCompressedPageSet and PopEndCompressedPageSet for details.
        //

        HiberContext->CompressedWriteBuffer =
            PopAllocateOwnMemory(HiberContext, (POP_COMPRESSED_PAGE_SET_SIZE + 2) << PAGE_SHIFT, 'Wbfr');
        if(!HiberContext->CompressedWriteBuffer) {
            goto Done;
        }

        // Allocate space for compressed data
        HiberContext->CompressionBlock =
            PopAllocateOwnMemory (HiberContext, sizeof (COMPRESSION_BLOCK), 'Cblk');
        if(!HiberContext->CompressionBlock)
            goto Done;

        // Set first output pointer
        ((PCOMPRESSION_BLOCK) HiberContext->CompressionBlock)->Ptr =
            ((PCOMPRESSION_BLOCK) HiberContext->CompressionBlock)->Buffer;

        // Allocate delayed IO buffer
        HiberContext->DmaIO = NULL;

        {
            PUCHAR Ptr;
            ULONG Size = (sizeof (DmaIoPtr[0]) + IO_DUMP_WRITE_DATA_SIZE + (PAGE_SIZE-1)) & ~(PAGE_SIZE-1);

            Ptr = PopAllocateOwnMemory (HiberContext, Size + IOREGION_BUFF_SIZE , 'IObk');
            if (Ptr != NULL) {
                // Memory layout:
                // 1. DumpLocalData (temp data for WritePendingRouting preserved between Start/Resume/Finish calls)
                // 2. DmaIoPtr itself
                // 3. Buffers themselves

                RtlZeroMemory (Ptr, Size);   // Clean IO and DumpLocalData
                HiberContext->DmaIO = (DMA_IOREGIONS *) (Ptr + IO_DUMP_WRITE_DATA_SIZE);

                DmaIoPtr->DumpLocalData = Ptr;
                Ptr += Size;

                DmaIoPtr->Free.Beg =
                DmaIoPtr->Free.Ptr =
                DmaIoPtr->Used.Ptr =
                DmaIoPtr->Busy.Ptr =
                DmaIoPtr->Used.Beg =
                DmaIoPtr->Busy.Beg = Ptr;

                DmaIoPtr->Free.End =
                DmaIoPtr->Used.End =
                DmaIoPtr->Busy.End = Ptr + IOREGION_BUFF_SIZE;

                DmaIoPtr->Free.Size = IOREGION_BUFF_SIZE;

                DmaIoPtr->DmaInitialized = FALSE;
                DmaIoPtr->UseDma = TRUE;
            }
        }

    }

    //
    // If the context is going to be written to disk, then
    // get the map of the hibernation file
    //

    if (HiberContext->WriteToFile && !PopHiberFile.NonPagedMcb) {

        //
        // Since this writes to the physical sectors of the disk
        // verify the check on the MCB array before doing it
        //

        if (PopHiberFile.McbCheck != PoSimpleCheck (0, PopHiberFile.PagedMcb, PopHiberFile.McbSize)) {
            Status = STATUS_INTERNAL_ERROR;
            goto Done;
        }

        //
        // Move the MCB array to nonpaged pool
        //

        PopHiberFile.NonPagedMcb = ExAllocatePoolWithTag (NonPagedPool,
                                                          PopHiberFile.McbSize,
                                                          POP_HIBR_TAG);

        if (!PopHiberFile.NonPagedMcb) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto Done;
        }

        memcpy (PopHiberFile.NonPagedMcb, PopHiberFile.PagedMcb, PopHiberFile.McbSize);

        //
        // Dump driver stack needs an 8 page memory block
        //

        DumpInit->MemoryBlock = PopAllocateOwnMemory (HiberContext,
                                                    IO_DUMP_MEMORY_BLOCK_PAGES << PAGE_SHIFT,
                                                    'memD');
        if (!DumpInit->MemoryBlock) {
            goto Done;
        }

        //
        // Remove common buffer pages from save area
        //

        if (DumpInit->CommonBufferSize & (PAGE_SIZE-1)) {
            PopInternalAddToDumpFile( DumpInit, sizeof(DUMP_INITIALIZATION_CONTEXT), NULL, NULL, NULL, NULL );
            PopInternalAddToDumpFile( HiberContext, sizeof(POP_HIBER_CONTEXT), NULL, NULL, NULL, NULL );
            KeBugCheckEx( INTERNAL_POWER_ERROR,
                          0x102,
                          POP_HIBER,
                          (ULONG_PTR)DumpInit,
                          (ULONG_PTR)HiberContext );
        }

        for (i=0; i < 2; i++) {
            if (DumpInit->CommonBuffer[i]) {
                PoSetHiberRange (HiberContext,
                                 PO_MEM_DISCARD,
                                 DumpInit->CommonBuffer[i],
                                 DumpInit->CommonBufferSize,
                                 POP_COMMON_BUFFER_TAG);
            }
        }
    }

    //
    // From here on, no new pages are added to the map.
    //

    if (HiberContext->ReserveLoaderMemory && !HiberContext->LoaderMdl) {

        //
        // Have Mm remove enough pages from memory to allow the
        // loader space when reloading the image, and remove them
        // from the hiber context memory map.
        //

        PopGatherMemoryForHibernate (
               HiberContext,
               MmHiberPages,
               &HiberContext->LoaderMdl,
               TRUE
               );
    }

Done:
    if (!NT_SUCCESS(Status)  &&  NT_SUCCESS(HiberContext->Status)) {
        HiberContext->Status = Status;
    }

    if (!NT_SUCCESS(HiberContext->Status)) {
        PopFreeHiberContext (FALSE);
    }
    return HiberContext->Status;
}

VOID
PopFreeHiberContext (
    IN BOOLEAN FreeAll
    )
/*++

Routine Description:

    Releases all resources allocated in the hiber context

    N.B. The power policy lock must be held

Arguments:

    ContextBlock    - If TRUE, the hiber context structure is
                      freed as well

Return Value:

    None.

--*/
{
    PPOP_HIBER_CONTEXT          HiberContext;
    PPOP_MEMORY_RANGE           Range;

    HiberContext = PopAction.HiberContext;
    if (!HiberContext) {
        return ;
    }

    //
    // Return pages gathered from mm
    //

    PopReturnMemoryForHibernate (HiberContext, FALSE, &HiberContext->LoaderMdl);
    PopReturnMemoryForHibernate (HiberContext, TRUE,  &HiberContext->Clones);
    PopReturnMemoryForHibernate (HiberContext, FALSE, &HiberContext->Spares);

    //
    // Free the cloned range list elements
    //

    while (!IsListEmpty(&HiberContext->ClonedRanges)) {
        Range = CONTAINING_RECORD (HiberContext->ClonedRanges.Flink, POP_MEMORY_RANGE, Link);
        RemoveEntryList (&Range->Link);
        ExFreePool (Range);
    }

    if (HiberContext->MemoryMap.Buffer) {
        ExFreePool(HiberContext->MemoryMap.Buffer);
        HiberContext->MemoryMap.Buffer = NULL;
    }

    //
    // Free hiber file Mcb info
    //

    if (PopHiberFile.NonPagedMcb) {
        ExFreePool (PopHiberFile.NonPagedMcb);
        PopHiberFile.NonPagedMcb = NULL;
    }

    //
    // If this is a total free, free the header
    //

    if (FreeAll) {
        //
        // Free resources used by dump driver
        //

        if (HiberContext->DumpStack) {
            IoFreeDumpStack (HiberContext->DumpStack);
        }

        //
        // If there's a link file, remove it
        //

        if (HiberContext->LinkFile) {
            ZwClose(HiberContext->LinkFileHandle);
        }

        //
        // Sanity check all gathered pages have been returned to Mm
        //

        if (HiberContext->PagesOut) {
            PopInternalAddToDumpFile( HiberContext, sizeof(POP_HIBER_CONTEXT), NULL, NULL, NULL, NULL );
            KeBugCheckEx( INTERNAL_POWER_ERROR,
                          0x103,
                          POP_HIBER,
                          (ULONG_PTR)HiberContext,
                          0 );

        }

        //
        // If this is a wake, clear the signature in the image
        //

        if (HiberContext->Status == STATUS_WAKE_SYSTEM) {
            if (PopSimulate & POP_ENABLE_HIBER_PERF) {
                PopClearHiberFileSignature(TRUE);
            } else {
                PopClearHiberFileSignature(FALSE);
            }
        }

        //
        // Free hiber context structure itself
        //

        PopAction.HiberContext = NULL;
        ExFreePool (HiberContext);
    }
}

ULONG
PopGatherMemoryForHibernate (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PFN_NUMBER           NoPages,
    IN PMDL                 *MdlList,
    IN BOOLEAN              Wait
    )
/*++

Routine Description:

    Gathers NoPages from the system for hibernation work.  The
    gathered pages are put onto the supplied list.

Arguments:

    HiberContext    - The hiber context structure

    NoPages         - Number of pages to gather

    MdlList         - Head of Mdl list to enqueue the allocated pages

    Wait            - TRUE if caller can wait for the pages.

Return Value:

    On failure FALSE and if Wait was set the HiberContext error is
    set; otheriwse, TRUE


--*/
{
    ULONG                   Result;
    PPFN_NUMBER             PhysPage;
    ULONG                   i;
    ULONG_PTR               Length;
    PMDL                    Mdl;
    ULONG                   PageCount;

    Result = 0;
    Length = NoPages << PAGE_SHIFT;
    Mdl = ExAllocatePoolWithTag (NonPagedPool,
                                 MmSizeOfMdl (NULL, Length),
                                 POP_HMAP_TAG);

    if (Mdl) {
        //
        // Call Mm to gather some pages, and keep track of how many
        // we have out
        //

        MmInitializeMdl(Mdl, NULL, Length);
        
        //
        // Set these here just in case MmGatherMemoryForHibernate
        // wants to customize the flags.
        //
        Mdl->MdlFlags |= MDL_MAPPING_CAN_FAIL;
        Mdl->MdlFlags |= MDL_PAGES_LOCKED;        
        Result = MmGatherMemoryForHibernate (Mdl, Wait);

    }

    if (Result) {

        HiberContext->PagesOut += NoPages;
        PhysPage = MmGetMdlPfnArray( Mdl );
        for (i=0; i < NoPages; i += PageCount) {

            //
            // Combine contiguous pages into a single call
            // to PopDiscardRange.
            //
            for (PageCount = 1; (i+PageCount) < NoPages; PageCount++) {
                if (PhysPage[i+PageCount-1]+1 != PhysPage[i+PageCount]) {
                    break;
                }
            }
            PopDiscardRange(HiberContext, PhysPage[i], PageCount, 'htaG');
        }

        Mdl->Next = *MdlList;
        *MdlList = Mdl;

    } else {

        if (Mdl) {
            ExFreePool (Mdl);
        }

        if (Wait  &&  NT_SUCCESS(HiberContext->Status)) {
            HiberContext->Status =  STATUS_INSUFFICIENT_RESOURCES;
        }
    }

    return Result;
}


VOID
PopReturnMemoryForHibernate (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN BOOLEAN              Unmap,
    IN OUT PMDL             *MdlList
    )
/*++

Routine Description:

    Returns pages allocated from PopGatherMemoryForHibernate to
    the system.

Arguments:

    HiberContext    - The hiber context structure

    MdlList         - Head of Mdl list of pages to free

Return Value:

    None

--*/
{
    PMDL            Mdl;

    while (*MdlList) {
        Mdl = *MdlList;
        *MdlList = Mdl->Next;

        HiberContext->PagesOut -= Mdl->ByteCount >> PAGE_SHIFT;
        if (Unmap) {
            MmUnmapLockedPages (Mdl->MappedSystemVa, Mdl);
        }

        MmReturnMemoryForHibernate (Mdl);
        ExFreePool (Mdl);
    }
}



VOID
PoSetHiberRange (
    IN PVOID        Map,
    IN ULONG        Flags,
    IN PVOID        StartVa,
    IN ULONG_PTR    Length,
    IN ULONG        Tag
    )
/*++

Routine Description:

    Sets the virtual range to the type supplied.  If the length of
    the range is zero, the entire section for the address specified
    is set.

    Ranges are expanded to their page boundries.  (E.g., starting
    addresses are rounded down, and ending addresses are rounded up)


Arguments:

    HiberContext   - The map to set the range in

    Type        - Type field for the range

    Start       - The starting address for the range in question

    Length      - The length of the range, or 0 to include an entire section


Return Value:

    None.
    On failure, faulure status is updated in the HiberContext structure.

--*/
{
    ULONG_PTR               Start;
    PFN_NUMBER              StartPage;
    PFN_NUMBER              EndPage;
    PFN_NUMBER              FirstPage, PhysPage;
    PFN_NUMBER              RunLen;
    PHYSICAL_ADDRESS        PhysAddr;
    NTSTATUS                Status;
    PPOP_HIBER_CONTEXT      HiberContext;
    ULONG                   SectionLength;


    HiberContext = Map;

    //
    // If no length, include the entire section which the datum resides in
    //

    if (Length == 0) {
        Status = MmGetSectionRange (StartVa, &StartVa, &SectionLength);
        if (!NT_SUCCESS(Status)) {
            PoPrint (PO_HIBERNATE, ("PoSetHiberRange: Section for %08x not found - skipped\n", StartVa));
            PopInternalError (POP_HIBER);
        }
        Length = SectionLength;
    }

    //
    // Turn PO_MEM_CL_OR_NCHK into just PO_MEM_CLONE
    //
    if (Flags & PO_MEM_CL_OR_NCHK) {
        Flags &= ~PO_MEM_CL_OR_NCHK;
        Flags |= PO_MEM_CLONE;
    }

    Start = (ULONG_PTR) StartVa;
    if (Flags & PO_MEM_PAGE_ADDRESS) {

        //
        // Caller passed a physical page range
        //

        Flags &= ~PO_MEM_PAGE_ADDRESS;
        PopSetRange (HiberContext,
                     Flags,
                     (PFN_NUMBER)Start,
                     (PFN_NUMBER)Length,
                     Tag);

    } else {

        //
        // Round to page boundries
        //

        StartPage = (PFN_NUMBER)(Start >> PAGE_SHIFT);
        EndPage = (PFN_NUMBER)((Start + Length + (PAGE_SIZE-1) & ~(PAGE_SIZE-1)) >> PAGE_SHIFT);

        //
        // Set all pages in the range
        //

        while (StartPage < EndPage) {
            PhysAddr = MmGetPhysicalAddress((PVOID) (StartPage << PAGE_SHIFT));
            FirstPage = (PFN_NUMBER) (PhysAddr.QuadPart >> PAGE_SHIFT);

            //
            // For how long the run is
            //

            for (RunLen=1; StartPage + RunLen < EndPage; RunLen += 1) {
                PhysAddr = MmGetPhysicalAddress ((PVOID) ((StartPage + RunLen) << PAGE_SHIFT) );
                PhysPage = (PFN_NUMBER) (PhysAddr.QuadPart >> PAGE_SHIFT);
                if (FirstPage+RunLen != PhysPage) {
                    break;
                }
            }

            //
            // Set this run
            //

            PopSetRange (HiberContext, Flags, FirstPage, RunLen, Tag);
            StartPage += RunLen;
        }
    }
}



VOID
PopCloneStack (
    IN PPOP_HIBER_CONTEXT  HiberContext
    )
/*++

Routine Description:

    Sets the current stack in the memory map to be a cloned range

Arguments:

    HiberContext   - The map to set the range in

Return Value:

    None.
    On failure, faulure status is updated in the HiberContext structure.

--*/
{
    PKTHREAD        Thread;
    KIRQL           OldIrql;
    ULONG_PTR       LowLimit;
    ULONG_PTR       HighLimit;

    KeAcquireSpinLock (&HiberContext->Lock, &OldIrql);

    //
    // Add local stack to clone or disable check list
    //
    RtlpGetStackLimits(&LowLimit, &HighLimit);

    Thread = KeGetCurrentThread();
    PoSetHiberRange (HiberContext,
                     PO_MEM_CLONE,
                     (PVOID)LowLimit,
                     HighLimit - LowLimit,
                     POP_STACK_TAG);

    //
    // Put local processors PCR & PRCB in clone list
    //

    PoSetHiberRange (HiberContext,
                     PO_MEM_CLONE,
                     (PVOID) KeGetPcr(),
                     sizeof (KPCR),
                     POP_PCR_TAG );

    PoSetHiberRange (HiberContext,
                     PO_MEM_CLONE,
                     KeGetCurrentPrcb(),
                     sizeof (KPRCB),
                     POP_PCRB_TAG );

    KeReleaseSpinLock (&HiberContext->Lock, OldIrql);
}


VOID
PopPreserveRange(
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PFN_NUMBER           StartPage,
    IN PFN_NUMBER           PageCount,
    IN ULONG                Tag
    )
/*++

Routine Description:

    Adds a physical memory range to the list of ranges to be preserved.

Arguments:

    HiberContext - Supplies the hibernation context

    StartPage - Supplies the beginning of the range

    PageCount - Supplies the length of the range

    Tag - supplies a tag to be used.

Return Value:

    None.

--*/

{
    //
    // If this range is outside the area covered by our bitmap, then we
    // will just clone it instead.
    //
    if (StartPage + PageCount > HiberContext->MemoryMap.SizeOfBitMap) {
        PoPrint (PO_HIBERNATE,
                 ("PopPreserveRange: range %08lx, length %lx is outside bitmap of size %lx\n",
                 StartPage,
                 PageCount,
                 HiberContext->MemoryMap.SizeOfBitMap));
        PopCloneRange(HiberContext, StartPage, PageCount, Tag);
        return;
    }

    PoPrint(PO_HIBERNATE,
            ("PopPreserveRange - setting page %08lx - %08lx, Tag %.4s\n",
             StartPage,
             StartPage + PageCount,
             &Tag));
    RtlClearBits(&HiberContext->MemoryMap, (ULONG)StartPage, (ULONG)PageCount);
}


VOID
PopDiscardRange(
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PFN_NUMBER           StartPage,
    IN PFN_NUMBER           PageCount,
    IN ULONG                Tag
    )
/*++

Routine Description:

    Removes a physical memory range from the list of ranges to be preserved.

Arguments:

    HiberContext - Supplies the hibernation context

    StartPage - Supplies the beginning of the range

    PageCount - Supplies the length of the range

    Tag - supplies a tag to be used.

Return Value:

    None.

--*/

{
    PFN_NUMBER sp;
    PFN_NUMBER count;

#if !DBG
    UNREFERENCED_PARAMETER (Tag);
#endif

    //
    // If this range is outside the area covered by our bitmap, then
    // it's not going to get written anyway.
    //
    if (StartPage <= HiberContext->MemoryMap.SizeOfBitMap) {
        sp = StartPage;
        count = PageCount;
        if (sp + count > HiberContext->MemoryMap.SizeOfBitMap) {
            //
            // trim PageCount
            //
            count = HiberContext->MemoryMap.SizeOfBitMap - sp;
        }

        PoPrint(PO_HIBERNATE,
                ("PopDiscardRange - removing page %08lx - %08lx, Tag %.4s\n",
                 StartPage,
                 StartPage + PageCount,
                 &Tag));
        RtlSetBits(&HiberContext->MemoryMap, (ULONG)sp, (ULONG)count);
    }

}


VOID
PopCloneRange(
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PFN_NUMBER           StartPage,
    IN PFN_NUMBER           PageCount,
    IN ULONG                Tag
    )
/*++

Routine Description:

    Adds a physical memory range from the list of ranges to be cloned.
    This means removing it from the list to be written and adding
    an entry in the clone list.

Arguments:

    HiberContext - Supplies the hibernation context

    StartPage - Supplies the beginning of the range

    PageCount - Supplies the length of the range

    Tag - supplies a tag to be used.

Return Value:

    None.

--*/

{
    PLIST_ENTRY Link;
    PPOP_MEMORY_RANGE Range;
    PFN_NUMBER EndPage;

    PoPrint(PO_HIBERNATE,
            ("PopCloneRange - cloning page %08lx - %08lx, Tag %.4s\n",
             StartPage,
             StartPage + PageCount,
             &Tag));
    PopDiscardRange(HiberContext, StartPage, PageCount, Tag);

    EndPage = StartPage + PageCount;

    //
    // Go through the range list. If we find an adjacent range, coalesce.
    // Otherwise, insert a new range entry in sorted order.
    //
    Link = HiberContext->ClonedRanges.Flink;
    while (Link != &HiberContext->ClonedRanges) {
        Range = CONTAINING_RECORD (Link, POP_MEMORY_RANGE, Link);

        //
        // Check for an overlapping or adjacent range.
        //
        if (((StartPage >= Range->StartPage) && (StartPage <= Range->EndPage)) ||
            ((EndPage   >= Range->StartPage) && (EndPage   <= Range->EndPage)) ||
            ((StartPage <= Range->StartPage) && (EndPage   >= Range->EndPage))) {

            PoPrint(PO_HIBERNATE,
                    ("PopCloneRange - coalescing range %lx - %lx (%.4s) with range %lx - %lx\n",
                     StartPage,
                     EndPage,
                     &Tag,
                     Range->StartPage,
                     Range->EndPage));

            //
            // Coalesce this range.
            //
            if (StartPage < Range->StartPage) {
                Range->StartPage = StartPage;
            }
            if (EndPage > Range->EndPage) {
                Range->EndPage = EndPage;
            }
            return;
        }

        if (Range->StartPage >= StartPage) {
            //
            // We have found a range greater than the current one. Insert the new range
            // in this position.
            //
            break;
        }

        Link = Link->Flink;
    }

    //
    // An adjacent range was not found. Allocate a new entry and insert
    // it in front of the Link entry.
    //
    Range = ExAllocatePoolWithTag (NonPagedPool,
                                   sizeof (POP_MEMORY_RANGE),
                                   POP_HMAP_TAG);
    if (!Range) {
        if (NT_SUCCESS(HiberContext->Status)) {
            HiberContext->Status = STATUS_INSUFFICIENT_RESOURCES;
        }
        return ;
    }
    Range->Tag = Tag;
    Range->StartPage = StartPage;
    Range->EndPage = EndPage;
    InsertTailList(Link, &Range->Link);

    ++HiberContext->ClonedRangeCount;

    return;
}


ULONG
PopGetRangeCount(
    IN PPOP_HIBER_CONTEXT HiberContext
    )
/*++

Routine Description:

    Counts the number of ranges to be written out. This includes
    the number of cloned ranges on the cloned range list and the
    number of runs in the memory map.

Arguments:

    HiberContext - Supplies the hibernation context.

Return Value:

    Number of ranges to be written out.

--*/

{
    ULONG RunCount=0;
    ULONG NextPage=0;
    ULONG Length;

    while (NextPage < HiberContext->MemoryMap.SizeOfBitMap) {
        Length = RtlFindNextForwardRunClear(&HiberContext->MemoryMap,
                                            NextPage,
                                            &NextPage);
        NextPage += Length;
        ++RunCount;
    }

    return(RunCount + HiberContext->ClonedRangeCount);
}

VOID
PopSetRange (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN ULONG                Flags,
    IN PFN_NUMBER           StartPage,
    IN PFN_NUMBER           PageCount,
    IN ULONG                Tag
    )
/*++

Routine Description:

    Sets the specified physical range in the memory map

Arguments:

    HiberContext   - The map to set the range in

    Type        - Type to set the range too

    StartPage   - The first page of the range

    PageCount   - The length of the range in pages

Return Value:

    None.
    On failure, faulure status is updated in the HiberContext structure.

--*/
{
    PoPrint (PO_HIBERNATE,
             ("PopSetRange: Ty %04x  Sp %08x Len %08x  %.4s\n",
               Flags,
               StartPage,
               PageCount,
               &Tag));

    if (HiberContext->MapFrozen) {
        PopInternalAddToDumpFile( HiberContext, sizeof(POP_HIBER_CONTEXT), NULL, NULL, NULL, NULL );
        KeBugCheckEx( INTERNAL_POWER_ERROR,
                      0x104,
                      POP_HIBER,
                      (ULONG_PTR)HiberContext,
                      0 );
    }
    //
    // Make sure flags which should have been cleared by now aren't still set.
    //
    ASSERT(!(Flags & (PO_MEM_PAGE_ADDRESS | PO_MEM_CL_OR_NCHK)));

    if (Flags & PO_MEM_DISCARD) {
        PopDiscardRange(HiberContext, StartPage, PageCount, Tag);
    } else if (Flags & PO_MEM_CLONE) {
        PopCloneRange(HiberContext, StartPage, PageCount, Tag);
    } else if (Flags & PO_MEM_PRESERVE) {
        PopPreserveRange(HiberContext, StartPage, PageCount, Tag);
    } else {
        ASSERT(FALSE);
        PopInternalAddToDumpFile( HiberContext, sizeof(POP_HIBER_CONTEXT), NULL, NULL, NULL, NULL );
        KeBugCheckEx( INTERNAL_POWER_ERROR,
                      0x105,
                      POP_HIBER,
                      (ULONG_PTR)HiberContext,
                      0 );
    }
}


VOID
PopResetRangeEnum(
    IN PPOP_HIBER_CONTEXT   HiberContext
    )
/*++

Routine Description:

    Resets the range enumerator to start at the first range.

Arguments:

    HiberContext - Supplies the hibernation context

Return Value:

    None

--*/

{
    HiberContext->NextCloneRange = HiberContext->ClonedRanges.Flink;
    HiberContext->NextPreserve = 0;
}


VOID
PopGetNextRange(
    IN PPOP_HIBER_CONTEXT HiberContext,
    OUT PPFN_NUMBER StartPage,
    OUT PPFN_NUMBER EndPage,
    OUT PVOID *CloneVa
    )
/*++

Routine Description:

    Enumerates the next range to be written to the hibernation file

Arguments:

    HiberContext - Supplies the hibernation context.

    StartPage - Returns the starting physical page to be written.

    EndPage - Returns the ending physical page (non-inclusive) to be written

    CloneVa - If the range is to be cloned, returns the cloned virtual address
              If the range is not cloned, returns NULL

Return Value:

    NTSTATUS

--*/

{
    PPOP_MEMORY_RANGE Range;
    ULONG Length;
    ULONG StartIndex;

    if (HiberContext->NextCloneRange != &HiberContext->ClonedRanges) {
        //
        // Return the next cloned range
        //
        Range = CONTAINING_RECORD(HiberContext->NextCloneRange, POP_MEMORY_RANGE, Link);
        HiberContext->NextCloneRange = HiberContext->NextCloneRange->Flink;

        *StartPage = Range->StartPage;
        *EndPage   = Range->EndPage;
        *CloneVa   = Range->CloneVa;

        ASSERT(Range->CloneVa != NULL);

    } else {

        //
        // We have enumerated all the clone ranges, return the next preserved range
        //
        Length = RtlFindNextForwardRunClear(&HiberContext->MemoryMap,
                                            (ULONG)HiberContext->NextPreserve,
                                            &StartIndex);
        *StartPage = StartIndex;
        *EndPage = *StartPage + Length;
        HiberContext->NextPreserve = *EndPage;
        *CloneVa = NULL;
    }

    return;
}

PVOID
PopAllocatePages (
    IN PPOP_HIBER_CONTEXT   HiberContext,
    IN PFN_NUMBER           NoPages
    )
/*++

Routine Description:

    Allocates memory pages from system with virtual mappings.
    Pages are kept on a list and are automatically freed by
    PopFreeHiberContext.

Arguments:

    NoPages - No of pages to allocate

    Flags   - Flags for the returned pages in the physical memory map


Return Value:

    Virtual address of the requested pages

--*/
{
    PUCHAR          Buffer=NULL;
    PMDL            Mdl;
    ULONG           SpareCount;

    PoPrint( PO_NOTIFY, ("PopAllocatePages: Enter, requesting %d pages.\r\n", NoPages));

    //
    // In the future, we should add code here that checks to see if the requested
    // NoPages is bigger than POP_FREE_ALLOCATE_SIZE.  We've created a whole
    // bunch of MDLs that are all of size POP_FREE_ALLOCATE_SIZE.  If the user
    // is requesting something bigger, we'll never find an MDL in the spare
    // list that's suitable, thus fail the hibernation.
    //
    // In this case, we could go grovel our Spares, looking for MDLs that
    // are sitting right next to each other (i.e. describing consecutive
    // memory), then combine the MDLs into one bigger MDL.  If that's
    // big enough, us it,  If not, start scanning again.
    //

    for (; ;) {
        //
        // If page is available in mapped clone page list, get it
        //

        if (NoPages <= HiberContext->NoClones) {
            
            Buffer = HiberContext->NextClone;
            HiberContext->NoClones  -= NoPages;
            HiberContext->NextClone += NoPages << PAGE_SHIFT;
            PoPrint( PO_NOTIFY, ("    Take this allocation out of the HiberContext clones list (0x%x pages left there).\r\n", HiberContext->NoClones));            
            break;
        }



        //
        // Need more virtual address space
        //

        if (HiberContext->Spares) {


            //
            // Turn spares into virtually mapped pages. Try to limit the
            // number of pages being mapped so we don't run out of PTEs
            // on large memory machines.
            //
            // If they want more than PO_MAX_MAPPED_CLONES, tough.
            // If they want less than PO_MAX_MAPPED_CLONES, only give
            // them what they're asking for.
            //
            if ((NoPages << PAGE_SHIFT) >= PO_MAX_MAPPED_CLONES) {
                SpareCount = PO_MAX_MAPPED_CLONES;
            } else {
                SpareCount = (ULONG) (NoPages << PAGE_SHIFT);
            }

            Mdl = HiberContext->Spares;

            PoPrint( PO_NOTIFY, ("    See if we can use one of the Spare MDLs.\r\n"));            
            PoPrint( PO_NOTIFY, ("    I think we need 0x%x byes\r\n", SpareCount));            
            PoPrint( PO_NOTIFY, ("    Spare MDL byteCount: 0x%x\r\n", Mdl->ByteCount));            
            
            if (Mdl->ByteCount > SpareCount) {

                //
                // Split out a smaller MDL from the spare since it is larger
                // than we really need.
                //

                Mdl = PopSplitMdl(Mdl, SpareCount >> PAGE_SHIFT);
                if (Mdl == NULL) {
                    PoPrint( PO_NOTIFY, ("    We split the Spare MDL and failed!!!\r\n"));            
                    break;
                }

                PoPrint( PO_NOTIFY, ("        We split the Spare MDL.\r\n"));

            } else {

                //
                // Map the entire spare MDL
                //
                HiberContext->Spares = Mdl->Next;
                PoPrint( PO_NOTIFY, ("        Use the entire Spare MDL.\r\n"));

            }
            Mdl->MdlFlags |= MDL_MAPPING_CAN_FAIL;
            Mdl->MdlFlags |= MDL_PAGES_LOCKED;
            
            PoPrint( PO_NOTIFY, ("    Mdl->ByteCount: 0x%x\r\n", Mdl->ByteCount));
            
            HiberContext->NextClone = MmMapLockedPages (Mdl, KernelMode);
            if (HiberContext->NextClone == NULL) {


                PoPrint( PO_NOTIFY, ("    MmMapLockedPages FAILED!!!\r\n"));
                //
                // Put the MDL back on the spare list so it gets cleaned up
                // correctly by PopFreeHiberContext.
                //
                Mdl->Next = HiberContext->Spares;
                HiberContext->Spares = Mdl;
                break;
            }
            HiberContext->NoClones  = Mdl->ByteCount >> PAGE_SHIFT;
            Mdl->Next = HiberContext->Clones;
            HiberContext->Clones = Mdl;

        } else {
            
            ULONG           result;

            //
            // No spares, allocate more
            //
            PoPrint(PO_NOTIFY, ("PopAllocatePages: No Spare MDLs left.  Go allocate more.") );
            result = PopGatherMemoryForHibernate (HiberContext,
                                                  NoPages*2,
                                                  &HiberContext->Spares,
                                                  TRUE);

            if (!result) {
                PoAssert(PO_ERROR, FALSE && ("PopAllocatePages: PopGatherMemoryForHibernate failed!!  We're about to fail hibernation") );
                break;
            }
        }
    }

    //
    // If there's a failure, mark it now
    //

    if (!Buffer  &&  NT_SUCCESS(HiberContext->Status)) {
        HiberContext->Status = STATUS_INSUFFICIENT_RESOURCES;
    }
    
    PoPrint( PO_NOTIFY, ("PopAllocatePages: Exit (0x%x)\r\n", PtrToUlong(Buffer)));

    return Buffer;
}


ULONG
PopSimpleRangeCheck (
    PPOP_MEMORY_RANGE       Range
    )
/*++

Routine Description:

    Computes a checksum for the supplied range

Arguments:

    Range   - The range to compute the checksum for

Return Value:

    The checksum value

--*/
{
    PFN_NUMBER              sp, ep;
    ULONG                   Check;
    DUMP_MDL                DumpMdl;
    PMDL                    Mdl;

    sp = Range->StartPage;
    ep = Range->EndPage;
    Mdl = (PMDL) DumpMdl;

    if (Range->CloneVa) {
        return PoSimpleCheck (0, Range->CloneVa, (ep-sp) << PAGE_SHIFT);
    }

    Check = 0;
    while (sp < ep) {
        PopCreateDumpMdl (Mdl, sp, ep);
        Check = PoSimpleCheck (Check, Mdl->MappedSystemVa, Mdl->ByteCount);
        sp += Mdl->ByteCount >> PAGE_SHIFT;
    }

    return Check;
}

VOID
PopCreateDumpMdl (
    IN OUT PMDL     Mdl,
    IN PFN_NUMBER   StartPage,
    IN PFN_NUMBER   EndPage
    )
/*++

Routine Description:

    Builds a dump MDl for the supplied starting address for
    as many pages as can be mapped, or until EndPage is hit.

Arguments:

    StartPage   - The first page to map

    EndPage     - The ending page

Return Value:

    Mdl

--*/
{
    PFN_NUMBER  Pages;
    PPFN_NUMBER PhysPage;

    // mapping better make sense
    if (StartPage >= EndPage) {
        PopInternalError (POP_HIBER);
    }

    Pages = EndPage - StartPage;
    if (Pages > POP_MAX_MDL_SIZE) {
        Pages = POP_MAX_MDL_SIZE;
    }

    MmInitializeMdl(Mdl, NULL, (Pages << PAGE_SHIFT));

    PhysPage = MmGetMdlPfnArray( Mdl );
    while (Pages) {
        *PhysPage++ = StartPage++;
        Pages -= 1;
    }

    MmMapMemoryDumpMdl (Mdl);
    Mdl->MdlFlags |= MDL_MAPPED_TO_SYSTEM_VA;

    // byte count must be a multiple of page size
    if (Mdl->ByteCount & (PAGE_SIZE-1)) {
        PopInternalAddToDumpFile( Mdl, sizeof(MDL), NULL, NULL, NULL, NULL );
        KeBugCheckEx( INTERNAL_POWER_ERROR,
                      0x106,
                      POP_HIBER,
                      (ULONG_PTR)Mdl,
                      0 );
    }
}

VOID
PopHiberComplete (
    IN NTSTATUS             Status,
    IN PPOP_HIBER_CONTEXT   HiberContext
    )
{
    //
    // If the return from the hal is STATUS_DEVICE_DOES_NOT_EXIST, then
    // the hal doesn't know how to power off the machine.
    //

    if (Status == STATUS_DEVICE_DOES_NOT_EXIST) {

       if (InbvIsBootDriverInstalled()) {

            // Display system shut down screen

            PUCHAR Bitmap1, Bitmap2;

            Bitmap1 = InbvGetResourceAddress(3); // shutdown bitmap
            Bitmap2 = InbvGetResourceAddress(5); // logo bitmap

            InbvSolidColorFill(190,279,468,294,0);
            if (Bitmap1 && Bitmap2) {
                InbvBitBlt(Bitmap1, 215, 282);
                InbvBitBlt(Bitmap2, 217, 111);
            }

        } else {
            InbvDisplayString ((PUCHAR)"State saved, power off the system\n");
        }

        // If reseting, set the flag and return
        if (PopSimulate & POP_RESET_ON_HIBER) {
            HiberContext->Reset = TRUE;
            return ;
        }

        // done... wait for power off
        for (; ;) ;
    }

    //
    // If the image is complete or the sleep completed without error,
    // then the checksums are valid
    //

    if ((NT_SUCCESS(Status) ||
         HiberContext->MemoryImage->Signature == PO_IMAGE_SIGNATURE) &&
         HiberContext->VerifyOnWake) {

    }

    //
    // Release the dump PTEs
    //

    MmReleaseDumpAddresses (POP_MAX_MDL_SIZE);

    //
    // Hiber no longer in process
    //

    PoHiberInProgress = FALSE;
    HiberContext->Status = Status;
}

NTSTATUS
PopBuildMemoryImageHeader (
    IN PPOP_HIBER_CONTEXT  HiberContext,
    IN SYSTEM_POWER_STATE  SystemState
    )
/*++

Routine Description:

    Converts the memory map range list to a memory image structure
    with a range list array.  This is done to build the initial image
    of the header to be written into the hibernation file, and to get
    the header into one chunk of pool which is not in any other
    listed range list

Arguments:

    HiberContext    -

    SystemState     -

Return Value:

    Status

--*/
{
    PPOP_MEMORY_RANGE       Range;
    PPO_MEMORY_IMAGE        MemImage;
    PLIST_ENTRY             Link;
    PFN_NUMBER              Length;
    PFN_NUMBER              StartPage;
    ULONG                   StartIndex;
    ULONG                   Index;
    PPO_MEMORY_RANGE_ARRAY  Table;
    ULONG                   TablePages;
    ULONG                   NeededPages;
    ULONG                   NoPages, i;

    UNREFERENCED_PARAMETER (SystemState);

    //
    // Allocate memory image structure
    //

    MemImage = PopAllocatePages (HiberContext, 1);
    if (!MemImage) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    PoSetHiberRange (HiberContext,
                     PO_MEM_CLONE,
                     MemImage,
                     sizeof(*MemImage),
                     POP_MEMIMAGE_TAG);

    RtlZeroMemory(MemImage, PAGE_SIZE);
    HiberContext->MemoryImage = MemImage;
    MemImage->PageSize = PAGE_SIZE;
    MemImage->LengthSelf = sizeof(*MemImage);
    MemImage->PageSelf = (PFN_NUMBER) MmGetPhysicalAddress(MemImage).QuadPart >> PAGE_SHIFT;
    KeQuerySystemTime (&MemImage->SystemTime);
    MemImage->InterruptTime = KeQueryInterruptTime();
    MemImage->HiberVa = HiberContext->HiberVa;
    MemImage->HiberPte = HiberContext->HiberPte;
    MemImage->NoHiberPtes = POP_MAX_MDL_SIZE;
    MemImage->FeatureFlags = KeFeatureBits;
    MemImage->ImageType  = KeProcessorArchitecture;
    MemImage->HiberFlags = HiberContext->HiberFlags;
    if (HiberContext->LoaderMdl) {
        MemImage->NoFreePages = HiberContext->LoaderMdl->ByteCount >> PAGE_SHIFT;
    }

    //
    // Allocate storage for clones
    //

    Link = HiberContext->ClonedRanges.Flink;
    while (Link != &HiberContext->ClonedRanges) {
        Range = CONTAINING_RECORD (Link, POP_MEMORY_RANGE, Link);
        Link = Link->Flink;

        //
        // Allocate space to make a copy of this clone
        //

        Length = Range->EndPage - Range->StartPage;
        Range->CloneVa = PopAllocatePages(HiberContext, Length);
        if (!Range->CloneVa) {
            PoPrint (PO_HIBERNATE, ("PopBuildImage: Could not allocate clone for %08x - %08x\n",
                        Range->StartPage,
                        Range->EndPage));
            return(STATUS_INSUFFICIENT_RESOURCES);
        }
    }

    //
    // We need to build the restoration map of the pages which need to
    // be saved.  These table pages can't be checksum in the normal
    // way as they hold the checksums for the rest of memory, so they
    // are allocated as ranges with no checksum and then checksums
    // are explicitly added in each page.  However, allocating these
    // pages may change the memory map, so we need to loop until we've
    // got enough storage for the restoration tables allocated in the
    // memory map to contain the tables, etc..
    //

    TablePages = 0;

    for (; ;) {
        //
        // Compute table pages needed, if we have enough allocated
        // then freeze the memory map and build them
        //

        NoPages = (PopGetRangeCount(HiberContext) +  PO_ENTRIES_PER_PAGE - 1) / PO_ENTRIES_PER_PAGE;
        if (NoPages <= TablePages) {
            break;
        }

        //
        // Allocate more table pages
        //
        NeededPages = NoPages - TablePages;
        Table = PopAllocatePages(HiberContext, NeededPages);
        if (!Table) {
            return STATUS_INSUFFICIENT_RESOURCES;
        }
        for (i=0; i<NeededPages; i++) {
            Table[0].Link.EntryCount = 0;
            Table[0].Link.NextTable = 0;
            Table[0].Link.CheckSum = 1;
            Table[0].Link.Next = HiberContext->TableHead;
            HiberContext->TableHead = Table;
            Table = (PPO_MEMORY_RANGE_ARRAY)((ULONG_PTR)Table + PAGE_SIZE);
        }
        TablePages += NeededPages;
    }

    //
    // Freeze the memory map
    //

    HiberContext->MapFrozen = TRUE;

    //
    // Fill in the ranges on the table pages
    //

    Table = HiberContext->TableHead;
    Index = 0;

    //
    // Add the cloned ranges first.
    //
    Link = HiberContext->ClonedRanges.Flink;
    while (Link != &HiberContext->ClonedRanges) {
        Range = CONTAINING_RECORD (Link, POP_MEMORY_RANGE, Link);
        Link = Link->Flink;

        PoPrint (PO_HIBER_MAP, ("PopSave: Cloned Table %08x - %08x\n",
                    Range->StartPage,
                    Range->EndPage));

        Index += 1;
        if (Index >= PO_MAX_RANGE_ARRAY) {
            //
            // Table is full, next
            //

            Table[0].Link.EntryCount = PO_MAX_RANGE_ARRAY-1;
            Table = Table[0].Link.Next;
            if (!Table) {
                PopInternalError (POP_HIBER);
            }
            Index = 1;
        }

        Table[Index].Range.PageNo    = 0;
        Table[Index].Range.StartPage = Range->StartPage;
        Table[Index].Range.EndPage   = Range->EndPage;
        Table[Index].Range.CheckSum  = 0;
    }

    //
    // Now add the ranges to be preserved
    //
    Length = RtlFindFirstRunClear(&HiberContext->MemoryMap, &StartIndex);
    StartPage = StartIndex;
    while (StartPage < HiberContext->MemoryMap.SizeOfBitMap) {
        Index += 1;
        if (Index >= PO_MAX_RANGE_ARRAY) {
            //
            // Table is full, next
 