TRBLOCK_H__
#define __ATTRBLOCK_H__

#include "licbase.h"        // to get KIDLEN
// ---------------------------------------------
// forward declarations
class CAttrSubBlock_List;
class CAttrSubBlock;

// ---------------------------------------------
// enums

typedef enum 
{
    SubBlock_Uninitialized  = -1,   // haven't gotten to it yet
    SubBlock_XDSClass0      = 0,    // reseve a bunch of blocks for XDS packets
    SubBlock_XDSClass1      = 1,    
    SubBlock_XDSClass2      = 2,    
    SubBlock_XDSClass3      = 3,
    SubBlock_XDSClass4      = 4,
    SubBlock_XDSClass5      = 5,
    SubBlock_XDSClass6      = 6,
    SubBlock_XDSClass7      = 7,
    SubBlock_XDSClass8      = 8,
    SubBlock_XDSClass9      = 9,
    SubBlock_XDSClassA      = 10,
    SubBlock_XDSClassB      = 11,
    SubBlock_XDSClassC      = 12,
    SubBlock_XDSClassD      = 13,
    SubBlock_XDSClassE      = 14,
    SubBlock_XDSClassF      = 15,   // end class, probably never sent

    SubBlock_PackedV1Data   = 20,   // inefficent to store multiple subblocks, store as one big packed

    SubBlock_PackedRating   = 100,
    SubBlock_EncryptMethod  = 101,
    SubBlock_DRM_KID        = 102,

    SubBlock_Test1          = 64,
    SubBlock_Test2          = 65,
    SubBlock_Test3          = 66,
    SubBlock_Test4          = 67,
    
//    SubBlock_GuidBlock      = 200,      // store by guid
//    SubBlock_IPersistStream = 201,    // for future expansion

    SubBlock_Last           = 255   // last valid subblock type

} EnAttrSubBlock_Class;

typedef struct                 //   simple little continuity test subblock
{
    DWORD                   m_cSampleID;        // continuity counter
    DWORD                   m_cSampleSize;      // true size of the sample
    DWORD                   m_dwFirstDataWord;  // first 4 bytes of the sample... 
} Test2_SubBlock;


typedef struct                 //   simple little continuity test subblock
{
    DWORD                   m_EncryptionMethod;        
    BYTE                    m_KID[KIDLEN+1];      
    StoredTvRating          m_StoredTvRating;
} EncDec_PackedV1Data;


// ----------------------------------------------------
class CAttrSubBlock_List;

class CAttrSubBlock
{
public:
    CAttrSubBlock();
    ~CAttrSubBlock();

    HRESULT Get(
        EnAttrSubBlock_Class    *pEnSubBlock_Class, 
        LONG                    *pSubBlock_SubClass,
        BSTR                    *pBstrOut
        );

    HRESULT Set(
        EnAttrSubBlock_Class    enSubBlock_Class, 
        LONG                    subBlock_SubClass,
        BSTR                    bstrIn
        );

   HRESULT Get(
       EnAttrSubBlock_Class     *pEnSubBlock_Class, 
       LONG                     *pSubBlock_SubClass,        // can be a 'value'
       LONG                     *pcbData,
       BYTE                     **ppbData                   // May be null if just want to determine size. Felease with CoTaskMemFree()
       );

   HRESULT Set(
       EnAttrSubBlock_Class     enSubBlock_Class, 
       LONG                     lSubBlock_SubClass,        // can be a 'value'
       LONG                     cbData,
       BYTE                     *pbData           
       );

    LONG CAttrSubBlock::ByteLength()
    {
        return sizeof(CAttrSubBlock)     // don't really need Pointer data here, but easier
               + SysStringByteLen(m_spbsData.m_str);        // want byte length, not # characters                
    }
protected:
    friend  CAttrSubBlock_List;

    BOOL    IsEqual(
                    EnAttrSubBlock_Class    enSubBlock
                    )
    {
        return enSubBlock == m_enSubBlock_Class;
    }

    BOOL    IsEqual(EnAttrSubBlock_Class    enSubBlock,
                    LONG                    subBlock_SubClass
                    )
    {
        return         enSubBlock == m_enSubBlock_Class &&
                subBlock_SubClass == m_subBlock_SubClass;
    }

  private:
    EnAttrSubBlock_Class    m_enSubBlock_Class;          
    LONG                    m_subBlock_SubClass;        // can be overwritten with data if only one LONG long
    VARIANT                 m_varData;      // todo - use this instead
 
    CComBSTR                m_spbsData;     // todo - make this go away
    
    CAttrSubBlock            *m_pNext ;  // simple list structure
};


        // -----------------------------------------------

class CAttrSubBlock_List       
{
private:
       
    CAttrSubBlock * 
    NewObj_ (
        )
    {
        return new CAttrSubBlock ;
    }

	void
	Recycle_(CAttrSubBlock *pObj)
	{
		delete pObj;
	}

    CAttrSubBlock * PopListHead_();
    CAttrSubBlock * GetIndexed_(IN LONG iIndex); 
    CAttrSubBlock * FindInList_(IN EnAttrSubBlock_Class enClass);
    CAttrSubBlock * FindInList_(IN EnAttrSubBlock_Class enClass, IN LONG subClass);
    CAttrSubBlock * FindInList_(IN GUID &guid);

    HRESULT InsertInList_(IN  CAttrSubBlock *    pNew);
    HRESULT DeleteFromList_(IN  CAttrSubBlock * pToDelete);
public:
    CAttrSubBlock_List();
    ~CAttrSubBlock_List();


    void Reset();           // clear entire list

    HRESULT                 // will error if already there
    Add(
        IN  EnAttrSubBlock_Class    enSubBlock,
        IN  LONG                    subBlock_SubClass,
        IN  BSTR                    bstrIn
        ) ;

    HRESULT                 // will error if already there
    Add(
        IN  EnAttrSubBlock_Class    enSubBlock,
        IN  LONG                    lValue
        ) ;
    
    HRESULT                 // will error if already there
    Add(
        IN  EnAttrSubBlock_Class    enSubBlock,
        IN  LONG                    lValue,
        IN  LONG                    cBytes,
        IN  BYTE                   *pbBytes
        ) ;

    HRESULT                 // will error if already there
    Replace(
        IN  EnAttrSubBlock_Class    enSubBlock,
        IN  LONG                    subBlock_SubClass,
        IN  BSTR                    bstrIn
        ) ;


    HRESULT                 // will error if already there
    Replace(
        IN  EnAttrSubBlock_Class    enSubBlock,
        IN  LONG                    lValue
        ) ;
    
    HRESULT
    Replace(
        IN  EnAttrSubBlock_Class    enSubBlock,
        IN  LONG                    lValue,
        IN  LONG                    cBytes,
        IN  BYTE                   *pbBytes
        ) ;

    HRESULT
    Get(
        IN  EnAttrSubBlock_Class    enSubBlock,
        IN  LONG                    subBlock_SubClass,
        OUT BSTR                    *pbstrOut
        );

    HRESULT
    Get(
        IN  EnAttrSubBlock_Class    enSubBlock,
        OUT LONG                    *plValue
        );

    HRESULT
    Get(
        IN  EnAttrSubBlock_Class    enSubBlock,
        IN  LONG                    subBlock_SubClass,      // fixed subclass
        OUT LONG                    *pcBytes,
        OUT BYTE                    **pbBytes
        );

    HRESULT
    Get(
        IN  EnAttrSubBlock_Class    enSubBlock,
        OUT LONG                    *plValue,               // variable subclass
        OUT LONG                    *pcBytes,
        OUT BYTE                    **pbBytes
        );

    HRESULT                 // returns S_FALSE if not there to delete
    Delete(
        IN  EnAttrSubBlock_Class    enSubBlock,
        IN  LONG                    subBlock_SubClass
        ) ;

    HRESULT                 
    Delete(
        IN  EnAttrSubBlock_Class    enSubBlock
        ) ;
    
        // -------------------------
    HRESULT
    GetIndexed(
        IN  LONG                    iIndex,
        OUT EnAttrSubBlock_Class    *pEnSubBlock,
        OUT LONG                    *pSubBlock_SubClass,
        OUT BSTR                    *pBstrOut
        ) ;

    LONG GetCount()            { return m_cAttributes ; }
    LONG GetBlockByteLength();                                 // total length of the block in bytes

       
                // returns complete list in one giant block
    HRESULT 
    GetAsOneBlock(
        OUT BSTR                    *pBstrOut
        ) ;

    HRESULT     // given a block, converts it into a list of blocks (in place)
    SetAsOneBlock(
        IN  BSTR                    bstrIn
        ); 

private:
    CAttrSubBlock   *m_pAttrListHead;  // inefficent impelementation for large numbers, but good enough for now
    long            m_cAttributes;
};

#endif //__ATTRBLOCK_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\etfilter\etfilter_res.h ===
//{{NO_DEPENDENCIES}}
// Microsoft Developer Studio generated include file.
// Used by ETFilter_res.rc
//
#define IDS_ETFILTER_ENCPROPNAME        101
#define IDS_ETFILTER_TAGSPROPNAME       102
#define IDD_ETFILTER_ENCPROPPAGE        106
#define IDD_ETFILTER_TAGSPROPPAGE       107
#define IDC_STATIC                      -1

// Next default values for new objects
// 
#ifdef APSTUDIO_INVOKED
#ifndef APSTUDIO_READONLY_SYMBOLS
#define _APS_NEXT_RESOURCE_VALUE        101
#define _APS_NEXT_COMMAND_VALUE         32768
#define _APS_NEXT_CONTROL_VALUE         400
#define _APS_NEXT_SYMED_VALUE           400
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\etfilter\etfiltprops.h ===
// ---------------------------------------------------------------
// ETFiltProps.h
//
// ---------------------------------------------------------------


#ifndef __ETFILTPROPS_H__
#define __ETFILTPROPS_H__

#define ET_PROPPAGE_ENC_NAME "EncypterX"
#define ET_PROPPAGE_TAG_NAME "TagsX"

// ----------------------------------
//  forward declarations
// ----------------------------------

class CETFilterEncProperties;
class CETFilterTagProperties;

// ----------------------------------
// ----------------------------------

	


class CETFilterEncProperties : 
	public CBasePropertyPage 
{
 
public:
   CETFilterEncProperties(IN  TCHAR		*pClassName,
							IN  IUnknown	*lpUnk, 
							OUT HRESULT		*phr);
	~CETFilterEncProperties();


    HRESULT
    OnActivate (
        ) ;

    HRESULT
    OnApplyChanges (
        ) ;

    HRESULT
    OnConnect (
        IN  IUnknown *  pIUnknown
        ) ;

    HRESULT
    OnDeactivate (
        ) ;

    HRESULT
    OnDisconnect (
        ) ;

    INT_PTR
    OnReceiveMessage (
        IN  HWND    hwnd,
        IN  UINT    uMsg,
        IN  WPARAM  wParam,
        IN  LPARAM  lParam
            ) ;

	DECLARE_IUNKNOWN ;

    static
    CUnknown *
    WINAPI
    CreateInstance (
        IN  IUnknown *  pIUnknown,
        IN  HRESULT *   pHr
        ) ;

private:
   void UpdateFields();

   IETFilter		*m_pIETFilter;
   HWND				m_hwnd ;
};
	
				// ---------------------------


class CETFilterTagProperties : 
	public CBasePropertyPage 
{
 
public:
   CETFilterTagProperties(IN  TCHAR		*pClassName,
							IN  IUnknown	*lpUnk, 
							OUT HRESULT		*phr);
	~CETFilterTagProperties();


    HRESULT
    OnActivate (
        ) ;

    HRESULT
    OnApplyChanges (
        ) ;

    HRESULT
    OnConnect (
        IN  IUnknown *  pIUnknown
        ) ;

    HRESULT
    OnDeactivate (
        ) ;

    HRESULT
    OnDisconnect (
        ) ;

    INT_PTR
    OnReceiveMessage (
        IN  HWND    hwnd,
        IN  UINT    uMsg,
        IN  WPARAM  wParam,
        IN  LPARAM  lParam
            ) ;

	DECLARE_IUNKNOWN ;

    static
    CUnknown *
    WINAPI
    CreateInstance (
        IN  IUnknown *  pIUnknown,
        IN  HRESULT *   pHr
        ) ;

private:
   void UpdateFields();

   IETFilter		*m_pIETFilter;
   HWND				m_hwnd ;

};

#endif //__ETFILTPROPS_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\drmencdec.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        DRM.h

    Abstract:

        Drm definitions

    Author:

        John Bradstreet (johnbrad)

    Revision History:

        27-Mar-2002    created

--*/

#ifndef __ENCDEC_DRM_H__
#define __ENCDEC_DRM_H__

#ifdef BUILD_WITH_DRM

#include "des.h"                // all include files from the DRMInc directory
#include "sha.h"
#include "pkcrypto.h"
#include "drmerr.h"
#include "drmstub.h"
#include "drmutil.h"
#include "license.h"

#endif //BUILD_WITH_DRM


#endif  // __ENCDEC_DRM_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\keys_7001.h ===
// Keys_7001.h : DRM cert.
//
//          Note - this is a test cert, it shouldn't appear in released code
//

#ifndef __KEYS_7001_H__
#define __KEYS_7001_H__

const BYTE abCert7001[] =
{
	0x00, 0x01, 0x00, 0x00, 0x34, 0x00, 0x00, 0x00, 
	0x84, 0x46, 0xA8, 0xEF, 0x21, 0xEF, 0xF3, 0x9E, 
	0xE3, 0xB1, 0x01, 0x31, 0x8F, 0x91, 0x3B, 0x61, 
	0x26, 0xAA, 0xD5, 0x4F, 0x50, 0xCC, 0x2C, 0x68, 
	0x40, 0x55, 0xB4, 0x80, 0x3A, 0x46, 0x4A, 0xC4, 
	0x26, 0x90, 0xCA, 0xE9, 0xC0, 0x65, 0x15, 0x4F, 
	0xFD, 0x6A, 0x75, 0x30, 0x14, 0x0A, 0x7A, 0xF8, 
	0x1A, 0x50, 0x4B, 0x1D, 0xDF, 0x83, 0x4A, 0x9F, 
	0xC5, 0x3D, 0x88, 0x37, 0x81, 0xCE, 0x3E, 0xDC, 
	0xA4, 0x5F, 0xE9, 0x29, 0x62, 0x48, 0x28, 0xA5, 
	0xDD, 0x08, 0x27, 0x60, 0x27, 0x76, 0xA8, 0x6F, 
	0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x03, 0xE8, 
	0x00, 0x00, 0x1B, 0x59
};

const BYTE abPVK7001[] =
{
	0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 
	0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 
	0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 
	0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 
	0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 
	0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 
	0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 
	0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 
	0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 
	0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 
	0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 
	0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 
	0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 
	0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 
	0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 
	0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 
	0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 
	0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 
	0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 
	0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 
	0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 
	0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 
	0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 
	0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 
	0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 
	0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 
	0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 
	0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 
	0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 
	0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 
	0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 
	0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 
	0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 
	0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 
	0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 
	0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 
	0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 
	0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 
	0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 
	0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 
	0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 
	0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 
	0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 
	0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 
	0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 
	0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 
	0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 
	0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 
	0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 
	0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 
	0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 
	0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 
	0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 
	0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 
	0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 
	0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 
	0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 
	0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 
	0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 
	0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 
	0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 
	0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 
	0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 
	0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 
	0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 
	0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 
	0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 
	0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 
	0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 
	0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 
	0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 
	0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 
	0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0x57, 0xCF, 0xAC, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x1A, 0x5D, 
	0xCE, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0x07, 0xCD, 0x3C, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x65, 
	0x0A, 0x2A, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0x74, 0xDC, 0x70, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x70, 0x96, 
	0x29, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0x2C, 0xE7, 0x69, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0x51, 0xEA, 0xBD, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0x6D, 0xA1, 0xEF, 
	0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0x58, 0xE8, 0x95, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 
	0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 
	0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 
	0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 
	0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x72, 0x22, 0x6F, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x51, 0x49, 0x21, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x14, 0x48, 0x01, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x26, 0x2D, 0x86, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x56, 
	0x3E, 0x28, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 
	0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 
	0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 
	0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x4E, 0x26, 0x2D, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0x64, 0xFA, 0x3E, 
	0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x22, 0x81, 0x5B, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x58, 0x4C, 
	0x6F, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 
	0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 
	0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0x95, 0x32, 0x86, 0x72, 
	0x41, 0x37, 0xC8, 0xCB, 0x9D, 0x31, 0xBE, 0x6C, 
	0xF7, 0xB1, 0xCA, 0x62, 0xD4, 0x69, 0x37, 0x70, 
	0x8A, 0x87, 0x2F, 0x1D, 0xDA, 0x7D, 0x58, 0x8A, 
	0x7D, 0x9F, 0xDC, 0xE2, 0x8E, 0xE3, 0x3A, 0x04, 
	0xF8, 0x54, 0xC1, 0x10, 0xBA, 0x97, 0xFE, 0xF0, 
	0x58, 0xEC, 0xB5, 0x8D, 0x06, 0x7C, 0xD0, 0x48, 
	0x79, 0x54, 0x22, 0xB3, 0x3F, 0xED, 0xAA, 0x00, 
	0x29, 0x89, 0x9F, 0x7B, 0x0E, 0xD3, 0x49, 0x89, 
	0x79, 0x6D, 0x41, 0xCF, 0x30, 0x07, 0x23, 0x90, 
	0x96, 0xEF, 0xFF, 0x44, 0x9F, 0x61, 0xF5, 0x16, 
	0x31, 0x88, 0xD7, 0xDE, 0x5D, 0xE0, 0x8F, 0xE2, 
	0xA2, 0x9C, 0x8A, 0x97, 0xB8, 0x02, 0x93, 0x1E, 
	0xCD, 0xF0, 0x12, 0xFE, 0x87, 0x2A, 0x55, 0x6C, 
	0x9B, 0x0E, 0xAD, 0xA4, 0xEC, 0xA1, 0xD4, 0x84, 
	0xB6, 0x30, 0xFD, 0x93, 0x4F, 0x03, 0x34, 0x17, 
	0xE2, 0x71, 0x68, 0x44, 0xFD, 0xD0, 0x13, 0x25, 
	0x92, 0x61, 0x58, 0x7F, 0x55, 0xF6, 0x11, 0x67, 
	0xB7, 0x24, 0x6F, 0x50, 0x59, 0x77, 0x90, 0x1E, 
	0xFE, 0x26, 0x56, 0x9E, 0xCE, 0xEE, 0x16, 0xFA, 
	0x26, 0xEE, 0x6B, 0x3E, 0x05, 0xC4, 0x23, 0x76, 
	0x7D, 0x64, 0x7F, 0x5B, 0xBD, 0x7E, 0x4C, 0x65, 
	0xCF, 0xD7, 0x60, 0x0E, 0xCA, 0xBA, 0xAE, 0x1B, 
	0x0E, 0x15, 0xD5, 0x7E, 0x88, 0x28, 0x59, 0x68, 
	0x9F, 0xA1, 0x1C, 0x6E, 0x1A, 0xC2, 0x92, 0x6D, 
	0x7F, 0x90, 0x53, 0xFD, 0xD5, 0x42, 0x2A, 0x3B, 
	0xEE, 0x41, 0xD0, 0x2F, 0xA1, 0x89, 0x69, 0x7D, 
	0xC5, 0xEA, 0x7D, 0xC4, 0xEB, 0x7A, 0xC9, 0x4D, 
	0xB3, 0x4F, 0x76, 0xF4, 0xED, 0xC0, 0xB7, 0xAD, 
	0x4D, 0xAA, 0x25, 0xCF, 0x23, 0x13, 0xAB, 0xA7, 
	0xE7, 0x3F, 0x9B, 0x30, 0xF2, 0x06, 0x72, 0xA7, 
	0x6A, 0xBD, 0xEC, 0x42, 0x66, 0xFE, 0x0F, 0xA2, 
	0x15, 0x11, 0x43, 0xA7, 0x3F, 0x8B, 0x00, 0x14
};


#endif //__KEYS_7001_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\encdectrace.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        EncDecTrace.h

    Abstract:

        This module contains tracing wrappers for DirectShow's, with standard
            levels, etc..

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#ifndef _EncDec__EncDecTrace_h
#define _EncDec__EncDecTrace_h

//  standard levels
#define TRACE_ENTER_LEAVE_LEVEL             9
#define TRACE_ERROR_LEVEL                   3
#define CONSTRUCTOR_DESTRUCTOR_LEVEL        (TRACE_ENTER_LEAVE_LEVEL - 1)

//  ============================================================================
//  LOG_AREA_
//
//  These definitions broadly categorize related areas, so they can be turned
//   on with minimum/none frivolous, non-related tracing.

//  CONSTRUCTOR_DESTRUCTOR
//      falls into the memory management area
//
//      levels:
//          all 1: CONSTRUCTOR_DESTRUCTOR_LEVEL (defined above)
//          3
//          4
//          5
#define LOG_AREA_CONSTRUCTOR_DESTRUCTOR     LOG_MEMORY


//	AREA_DSHOW
//		falls into standard trace area
//
//      levels:
//          1   * filtergraph state changes
//              * read controller init
//              * dynamic format changes
//          2   * segment-related
//          3
//          4
//          5
//          6
//          7
//          8   * media sample traffic
//              * timestamps
#define LOG_AREA_DSHOW                      LOG_TRACE

///#define LOG_AREA_QQQ                        LOG_ERROR


// -- broadcast event messages
#define LOG_AREA_BROADCASTEVENTS	        LOG_CUSTOM1
//
//		levels
//			1	- bad errors
//			2	- errors
//			3	- connection, removal
//			5	- send events
//          6   - get events
//			8	- individual events

// -- DRM related error messages
#define LOG_AREA_DRM			            LOG_CUSTOM2
//
//		levels
//			1	- bad errors
//			2	- errors
//			3	- normal
//		    5   - license values and key generation


// -- XDS Codec messages
#define LOG_AREA_XDSCODEC					LOG_CUSTOM3
//
//		levels
//			1	- bad errors
//			2	- errors
//			3	- normal - new ratings
//			5	- normal - all ratings
//			8	- individual XDS BytePairs
//          9   - 


// -- encrypter messages
#define LOG_AREA_ENCRYPTER					LOG_CUSTOM4
//
//		levels
//			1	- bad errors
//			2	- errors
//			3	- normal
//			5	- 
//			8	- individual packets
//          9   - packet state

#define LOG_AREA_DECRYPTER					LOG_CUSTOM5
//
//		levels
//			1	- bad errors
//			2	- errors
//			3	- normal
//			5	- 
//			8	- individual packets
//          9   - packet state


#define LOG_AREA_TIME                       LOG_TIMING
//
//		levels
//			1	- 
//			2	- 
//			3	- filter stats on pause
//			5	- 

// ------------------

#ifdef DEBUG

#define TRACE_0(ds,l,fmt)                    DbgLog((ds,l,fmt))
#define TRACE_1(ds,l,fmt,a)                  DbgLog((ds,l,fmt,a))
#define TRACE_2(ds,l,fmt,a,b)                DbgLog((ds,l,fmt,a,b))
#define TRACE_3(ds,l,fmt,a,b,c)              DbgLog((ds,l,fmt,a,b,c))
#define TRACE_4(ds,l,fmt,a,b,c,d)            DbgLog((ds,l,fmt,a,b,c,d))
#define TRACE_5(ds,l,fmt,a,b,c,d,e)          DbgLog((ds,l,fmt,a,b,c,d,e))
#define TRACE_6(ds,l,fmt,a,b,c,d,e,f)        DbgLog((ds,l,fmt,a,b,c,d,e,f))
#define TRACE_7(ds,l,fmt,a,b,c,d,e,f,g)      DbgLog((ds,l,fmt,a,b,c,d,e,f,g))
#define TRACE_8(ds,l,fmt,a,b,c,d,e,f,g,h)    DbgLog((ds,l,fmt,a,b,c,d,e,f,g,h))

#else

#define TRACE_0(ds,l,fmt)                    0
#define TRACE_1(ds,l,fmt,a)                  0
#define TRACE_2(ds,l,fmt,a,b)                0
#define TRACE_3(ds,l,fmt,a,b,c)              0
#define TRACE_4(ds,l,fmt,a,b,c,d)            0
#define TRACE_5(ds,l,fmt,a,b,c,d,e)          0
#define TRACE_6(ds,l,fmt,a,b,c,d,e,f)        0
#define TRACE_7(ds,l,fmt,a,b,c,d,e,f,g)      0
#define TRACE_8(ds,l,fmt,a,b,c,d,e,f,g,h)    0

#endif

//  ---------------------------------------------------------------------------
//  error
//  ---------------------------------------------------------------------------

#define TRACE_ERROR()                       TRACE_2(LOG_ERROR,TRACE_ERROR_LEVEL,TEXT("ERROR: %s(%u)"),TEXT(__FILE__), __LINE__)
#define TRACE_ERROR_0(fmt)                  TRACE_2(LOG_ERROR,TRACE_ERROR_LEVEL,TEXT("ERROR: %s(%u); ") fmt,TEXT(__FILE__), __LINE__)
#define TRACE_ERROR_1(fmt,a)                TRACE_3(LOG_ERROR,TRACE_ERROR_LEVEL,TEXT("ERROR: %s(%u); ") fmt,TEXT(__FILE__), __LINE__,a)
#define TRACE_ERROR_2(fmt,a,b)              TRACE_4(LOG_ERROR,TRACE_ERROR_LEVEL,TEXT("ERROR: %s(%u); ") fmt,TEXT(__FILE__), __LINE__,a,b)
#define TRACE_ERROR_3(fmt,a,b,c)            TRACE_5(LOG_ERROR,TRACE_ERROR_LEVEL,TEXT("ERROR: %s(%u); ") fmt,TEXT(__FILE__), __LINE__,a,b,c)
#define TRACE_ERROR_4(fmt,a,b,c,d)          TRACE_6(LOG_ERROR,TRACE_ERROR_LEVEL,TEXT("ERROR: %s(%u); ") fmt,TEXT(__FILE__), __LINE__,a,b,c,d)
#define TRACE_ERROR_5(fmt,a,b,c,d,e)        TRACE_7(LOG_ERROR,TRACE_ERROR_LEVEL,TEXT("ERROR: %s(%u); ") fmt,TEXT(__FILE__), __LINE__,a,b,c,d,e)
#define TRACE_ERROR_6(fmt,a,b,c,d,e,f)      TRACE_8(LOG_ERROR,TRACE_ERROR_LEVEL,TEXT("ERROR: %s(%u); ") fmt,TEXT(__FILE__), __LINE__,a,b,c,d,e,f)

#define ERROR_SPEW(v,op,c)                  TRACE_ERROR_5(TEXT("(%s = 0x%08xh) %s (%s = 0x%08xh)"),TEXT(#v),v,TEXT(#op),TEXT(#c),c)
#define ERROR_SPEW_EX(v,op,c,m)             TRACE_ERROR_6(TEXT("(%s = 0x%08xh) %s (%s = 0x%08xh); %s"),TEXT(#v),v,TEXT(#op),TEXT(#c),c,m)
#define ERROR_RET(v,op,c)                   if ((v) op (c)) { ERROR_SPEW(v,op,c); return ; }
#define ERROR_RET_VAL(v,op,c,r)             if ((v) op (c)) { ERROR_SPEW(v,op,c); return (r) ; }
#define ERROR_RET_EX(v,op,c,m)              if ((v) op (c)) { ERROR_SPEW_EX(v,op,c,m); return ; }
#define ERROR_RET_VAL_EX(v,op,c,r,m)        if ((v) op (c)) { ERROR_SPEW_EX(v,op,c,m); return (r) ; }

//  ---------------------------------------------------------------------------
//  constructor / destructor
//  ---------------------------------------------------------------------------

#define TRACE_CONSTRUCTOR(fmt)              TRACE_1(LOG_AREA_CONSTRUCTOR_DESTRUCTOR,CONSTRUCTOR_DESTRUCTOR_LEVEL,TEXT("[%08xh] CONSTRUCTOR : ") fmt TEXT("::") fmt, this)
#define TRACE_DESTRUCTOR(fmt)               TRACE_1(LOG_AREA_CONSTRUCTOR_DESTRUCTOR,CONSTRUCTOR_DESTRUCTOR_LEVEL,TEXT("[%08xh] DESTRUCTOR  : ") fmt TEXT("::~") fmt, this)

//  ---------------------------------------------------------------------------
//  enter
//  ---------------------------------------------------------------------------
#define TRACE_ENTER_0(fmt)                  TRACE_0(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("ENTER : ") fmt)
#define TRACE_ENTER_1(fmt,a)                TRACE_1(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("ENTER : ") fmt,a)
#define TRACE_ENTER_2(fmt,a,b)              TRACE_2(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("ENTER : ") fmt,a,b)
#define TRACE_ENTER_3(fmt,a,b,c)            TRACE_3(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("ENTER : ") fmt,a,b,c)
#define TRACE_ENTER_4(fmt,a,b,c,d)          TRACE_4(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("ENTER : ") fmt,a,b,c,d)
#define TRACE_ENTER_5(fmt,a,b,c,d,e)        TRACE_5(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("ENTER : ") fmt,a,b,c,d,e)
#define TRACE_ENTER_6(fmt,a,b,c,d,e,f)      TRACE_6(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("ENTER : ") fmt,a,b,c,d,e,f)

//  ---------------------------------------------------------------------------
//  object enter
//  ---------------------------------------------------------------------------
#define O_TRACE_ENTER_0(fmt)                TRACE_ENTER_1(TEXT("[%08xh] ") fmt, this)
#define O_TRACE_ENTER_1(fmt,a)              TRACE_ENTER_2(TEXT("[%08xh] ") fmt, this,a)
#define O_TRACE_ENTER_2(fmt,a,b)            TRACE_ENTER_3(TEXT("[%08xh] ") fmt, this,a,b)
#define O_TRACE_ENTER_3(fmt,a,b,c)          TRACE_ENTER_4(TEXT("[%08xh] ") fmt, this,a,b,c)
#define O_TRACE_ENTER_4(fmt,a,b,c,d)        TRACE_ENTER_5(TEXT("[%08xh] ") fmt, this,a,b,c,d)
#define O_TRACE_ENTER_5(fmt,a,b,c,d,e)      TRACE_ENTER_6(TEXT("[%08xh] ") fmt, this,a,b,c,d,e)

//  ---------------------------------------------------------------------------
//  leave
//  ---------------------------------------------------------------------------
#define TRACE_LEAVE_0(fmt)                  TRACE_0(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("LEAVE : ") fmt)
#define TRACE_LEAVE_1(fmt,a)                TRACE_1(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("LEAVE : ") fmt,a)
#define TRACE_LEAVE_2(fmt,a,b)              TRACE_2(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("LEAVE : ") fmt,a,b)
#define TRACE_LEAVE_3(fmt,a,b,c)            TRACE_3(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("LEAVE : ") fmt,a,b,c)
#define TRACE_LEAVE_4(fmt,a,b,c,d)          TRACE_4(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("LEAVE : ") fmt,a,b,c,d)
#define TRACE_LEAVE_5(fmt,a,b,c,d,e)        TRACE_5(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("LEAVE : ") fmt,a,b,c,d,e)
#define TRACE_LEAVE_6(fmt,a,b,c,d,e,f)      TRACE_6(LOG_TRACE,TRACE_ENTER_LEAVE_LEVEL,TEXT("LEAVE : ") fmt,a,b,c,d,e,f)

//  ---------------------------------------------------------------------------
//  object leave
//  ---------------------------------------------------------------------------
#define O_TRACE_LEAVE_0(fmt)                TRACE_LEAVE_1(TEXT("[%08xh] ") fmt, this)
#define O_TRACE_LEAVE_1(fmt,a)              TRACE_LEAVE_2(TEXT("[%08xh] ") fmt, this,a)
#define O_TRACE_LEAVE_2(fmt,a,b)            TRACE_LEAVE_3(TEXT("[%08xh] ") fmt, this,a,b)
#define O_TRACE_LEAVE_3(fmt,a,b,c)          TRACE_LEAVE_4(TEXT("[%08xh] ") fmt, this,a,b,c)
#define O_TRACE_LEAVE_4(fmt,a,b,c,d)        TRACE_LEAVE_5(TEXT("[%08xh] ") fmt, this,a,b,c,d)
#define O_TRACE_LEAVE_5(fmt,a,b,c,d,e)      TRACE_LEAVE_6(TEXT("[%08xh] ") fmt, this,a,b,c,d,e)

#endif  //  _EncDec__EncDecTrace_h
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\keys_7003.h ===
// Keys_7003.h : DRM cert.
//
//          This cert should only be used by callers of EncDec
//      (secure servers).  This file should eventually be 'published'..
//      where 

#ifndef __KEYS_7003_H__
#define __KEYS_7003_H__

const BYTE abCert7003[] = 
//BYTE appcert[sizeof(APPCERT)] = 
{
	0x00, 0x01, 0x00, 0x00, 0x34, 0x00, 0x00, 0x00, 
	0x02, 0xA5, 0x4C, 0x64, 0x95, 0x10, 0xBC, 0x48, 
	0x8E, 0xCE, 0x8E, 0x22, 0x71, 0x57, 0xCF, 0x9F, 
	0xDE, 0x98, 0xAD, 0x7D, 0xFC, 0x6A, 0xBB, 0xA9, 
	0x9F, 0xCB, 0x80, 0xBB, 0xEE, 0xFE, 0xF4, 0xD6, 
	0xB8, 0x67, 0x23, 0x1F, 0xD7, 0x9C, 0xFA, 0x5F, 
	0x9C, 0x27, 0x41, 0x11, 0x95, 0xAC, 0x51, 0xE5, 
	0xF7, 0x28, 0x78, 0x5D, 0x5A, 0x51, 0x9C, 0xEE, 
	0xBB, 0xF7, 0x69, 0x2C, 0xDE, 0x98, 0x6E, 0x40, 
	0x9B, 0x61, 0xDB, 0xC5, 0xDC, 0xB3, 0x85, 0x42, 
	0x6D, 0xEF, 0xB9, 0xF0, 0x9D, 0xCE, 0x00, 0x85, 
	0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x03, 0xE8, 
	0x00, 0x00, 0x1B, 0x5B
};
//=======================================================

const BYTE abPVK7003[] =
// BYTE Obf[OBFBYTESLEN] = 
{
	0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 
	0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 
	0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 
	0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 
	0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 
	0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 
	0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 
	0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 
	0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 
	0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 
	0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 
	0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 
	0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 
	0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 
	0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 
	0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 
	0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 
	0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 
	0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 
	0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 
	0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 
	0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 
	0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 
	0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 
	0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 
	0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 
	0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 
	0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 
	0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 
	0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 
	0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 
	0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 
	0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 
	0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 
	0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 
	0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 
	0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 
	0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 
	0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 
	0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 
	0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 
	0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 
	0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 
	0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 
	0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 
	0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 
	0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 
	0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 
	0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 
	0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 
	0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 
	0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 
	0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 
	0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 
	0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 
	0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 
	0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 
	0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 
	0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 
	0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 
	0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 
	0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 
	0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 
	0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 
	0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 
	0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 
	0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 
	0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 
	0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 
	0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 
	0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 
	0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 
	0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 
	0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 
	0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 
	0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 
	0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 
	0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 
	0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 
	0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 
	0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 
	0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 
	0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 
	0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 
	0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 
	0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 
	0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 
	0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 
	0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 
	0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 
	0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 
	0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 
	0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 
	0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 
	0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 
	0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 
	0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 
	0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 
	0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 
	0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 
	0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 
	0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 
	0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 
	0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 
	0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 
	0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 
	0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 
	0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 
	0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 
	0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 
	0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 
	0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 
	0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 
	0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0x58, 
	0xE8, 0xE1, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 
	0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 
	0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 
	0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 
	0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 
	0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 
	0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 
	0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 
	0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 
	0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 
	0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 
	0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 
	0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 
	0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 
	0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 
	0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 
	0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 
	0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 
	0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 
	0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 
	0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 
	0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 
	0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 
	0xC3, 0xDC, 0x72, 0x22, 0xDA, 0x0A, 0xE5, 0xCF, 
	0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 
	0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 
	0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 
	0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x51, 0x49, 
	0x36, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 
	0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 
	0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 
	0xEA, 0x61, 0x14, 0x48, 0x0D, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 
	0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 
	0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 
	0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 
	0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 
	0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x26, 0x2D, 
	0x36, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x56, 0x3E, 0x81, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 
	0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 
	0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 
	0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 
	0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 
	0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 
	0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x4E, 0x26, 
	0xA3, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 
	0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 
	0x75, 0xE5, 0x64, 0xFA, 0x89, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 
	0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 
	0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x22, 
	0x81, 0xFD, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x58, 0x4C, 0x33, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x54, 0x8F, 0x27, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x0D, 0x37, 0x9E, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x5E, 0x02, 0x61, 
	0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 
	0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 
	0x9E, 0xC4, 0xC5, 0xD5, 0x7D, 0xC3, 0xB9, 0x22, 
	0x1A, 0x0A, 0xE5, 0x57, 0xCF, 0xFA, 0x5F, 0x76, 
	0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 
	0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 
	0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 
	0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 
	0x3E, 0x1A, 0x5D, 0x90, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x1C, 0x8B, 0x6B, 
	0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 
	0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x96, 0x70, 0xD3, 0x77, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0x95, 0x32, 
	0x86, 0x72, 0x41, 0x37, 0xC8, 0xCB, 0x9D, 0x31, 
	0xBE, 0x6C, 0xF7, 0xB1, 0xCA, 0x62, 0x6B, 0x39, 
	0x3D, 0xF1, 0xA4, 0x06, 0x1F, 0x2E, 0xC2, 0xCF, 
	0x96, 0xD5, 0x16, 0x57, 0x96, 0x72, 0xAF, 0x96, 
	0x62, 0x56, 0x81, 0x53, 0xF8, 0x74, 0xA1, 0x0C, 
	0x80, 0x6A, 0x47, 0x60, 0x06, 0x6C, 0xE2, 0xFB, 
	0xDE, 0x9D, 0x07, 0xE7, 0x34, 0x0C, 0xEC, 0x64, 
	0x12, 0xFB, 0xBD, 0x59, 0x3D, 0x32, 0x31, 0x93, 
	0xFF, 0x87, 0x28, 0xF2, 0x36, 0x10, 0xB5, 0xCF, 
	0x90, 0x6D, 0x73, 0x50, 0x68, 0x6F, 0xD3, 0x70, 
	0x96, 0xAE, 0x72, 0x52, 0x26, 0xDE, 0x16, 0x8E, 
	0x2A, 0x25, 0x37, 0xBD, 0x3E, 0x25, 0xA4, 0xB6, 
	0xA3, 0xBD, 0x69, 0x92, 0x7D, 0xD4, 0xDB, 0x91, 
	0x11, 0xDA, 0xDE, 0xC3, 0xAC, 0xED, 0x3C, 0x08, 
	0xC1, 0xBF, 0x3F, 0x8C, 0xD6, 0x45, 0x8F, 0xD8, 
	0xAB, 0x29, 0x9A, 0x8C, 0xFC, 0xEC, 0x8F, 0x81, 
	0xCE, 0x7C, 0x53, 0x29, 0xAA, 0x7C, 0x13, 0x9D, 
	0xB5, 0x6D, 0x26, 0xE9, 0xA3, 0x6B, 0x86, 0xEF, 
	0x91, 0xE5, 0x05, 0x6D, 0x78, 0x65, 0xAF, 0x90, 
	0x9B, 0x4E, 0xD4, 0xFC, 0x3E, 0x70, 0xC1, 0x0B, 
	0x84, 0x55, 0x6A, 0x46, 0xC8, 0x39, 0x93, 0x9B, 
	0xB8, 0x6A, 0x2B, 0x4B, 0x45, 0x58, 0x74, 0x2D, 
	0x4D, 0x42, 0xF4, 0x3D, 0x3C, 0x28, 0x06, 0xEF, 
	0x92, 0xE4, 0x08, 0xD1, 0xAF, 0x56, 0xD4, 0xCC, 
	0xA0, 0xFD, 0x28, 0xBB, 0xD2, 0xC4, 0x0C, 0xC0, 
	0x28, 0x6F, 0x86, 0xBE, 0x5B, 0xA1, 0x00, 0xF2, 
	0xBE, 0x86, 0x77, 0x09, 0xA5, 0xAA, 0x15, 0xDF, 
	0xA7, 0x97, 0x28, 0x5E, 0xC9, 0xDB, 0xF4, 0x7A, 
	0xFE, 0xE3, 0xCD, 0xA4, 0xC6, 0x93, 0x39, 0xE5, 
	0x15, 0x5D, 0x5D, 0xDF, 0x90, 0x7A, 0x0A, 0x0A, 
	0xDE, 0x0B, 0x66, 0xEA, 0xEF, 0x85, 0xBE, 0xF4, 
	0x6F, 0x71, 0x06, 0x71, 0x43, 0x9C, 0xFC, 0xC1, 
	0x89, 0xDA, 0xA8, 0x2E, 0x93, 0xFE, 0x86, 0x2B, 
	0x56, 0x6D, 0x01, 0xDA, 0x0B, 0xFE, 0xE9, 0xFB, 
	0xAC, 0x6A, 0xBE, 0xE9, 0x47, 0xC8, 0x37, 0xFE, 
	0xC9, 0xB4, 0xE7, 0x45, 0x62, 0x9D, 0x6E, 0x1B, 
	0xC1, 0xFA, 0x05, 0xA8, 0x3E, 0xEA, 0xDE, 0x31, 
	0x0B, 0x87, 0xC7, 0x87, 0xAB, 0x70, 0xEC, 0xF1, 
	0xEB, 0xF3, 0x50, 0x90, 0x0D, 0xAA, 0xD8, 0x1D, 
	0x83, 0xD2, 0x47, 0x25, 0x42, 0xE5, 0x4C, 0x28, 
	0x0D, 0xB3, 0x04, 0x27, 0xF3, 0x35, 0xAA, 0xE9, 
	0x0C, 0x02, 0x1B, 0x96, 0x8D, 0x2C, 0x8A, 0x6B, 
	0x4A, 0x2C, 0x07, 0x54, 0xC6, 0xDA, 0x26, 0x16, 
	0x77, 0x76, 0x05, 0xDC, 0xD6, 0x67, 0xD2, 0x3C, 
	0xFD, 0x99, 0x16, 0xD9, 0xE0, 0xC1, 0x17, 0x80, 
	0x07, 0xDE, 0x3C, 0x33, 0x1C, 0x30, 0x00, 0x14
};

#endif //__KEYS_7003_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\encdecall.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        inc/EncDecAll.h

    Abstract:

        This module is the main header for all ts/dvr

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#ifndef __EncDec__EncDecAll_h
#define __EncDec__EncDecAll_h

// ATl

#define _ATL_APARTMENT_THREADED
#define _ATL_STATIC_REGISTRY

#include <memory>

#include <strmif.h>
#include <streams.h>        // CBaseOutputPin, CBasePin, CCritSec, ...

#include <atlbase.h>		// CComQIPtr

//  dshow

#include <dvdmedia.h>       //  MPEG2VIDEOINFO

#include "EncDecTrace.h"	// tracing macros

#define	DBG_NEW
#ifdef	DBG_NEW
	#include "crtdbg.h"
   #define DEBUG_NEW	new( _CLIENT_BLOCK, __FILE__, __LINE__)
#else
   #define DEBUG_NEW	new
#endif // _DEBUG

#ifdef INITGUID_FOR_ENCDEC
#include <initguid.h>         // do this after all the above includes... else lots of redefinitions
#endif
#include "EncDec.h"         // Compiled from IDL file.  Holds PackedTvRating definition
#include "PackTvRat.h"
#include "TimeIt.h"

    // passed between Encrypter and Decrypter filters (and stored in the file)
typedef enum
{
    Encrypt_None        = 0,
    Encrypt_XOR_Even    = 1,
    Encrypt_XOR_Odd     = 2,
    Encrypt_XOR_DogFood = 3,
    Encrypt_DRMv1       = 4
} Encryption_Method;   

    // also passed between Encrypter and Decrypter filters (and stored in the file)
typedef struct      
{
    PackedTvRating          m_PackedRating;     // the actual rating
    long                    m_cPacketSeqID;     // N'th rating we got (incremented by new rating)
    long                    m_cCallSeqID;       // which version of the rating (incrmented by encrypter)
    long                    m_dwFlags;          // Flags (is Fresh, ...)  If not defined, bits should be zero
} StoredTvRating;

const int StoredTVRat_Fresh  = 0x1;             // set of rating when its an update of a duplicate one

const int   kStoredTvRating_Version = 1001;      // version number (major minor)

const int kMinPacketSizeForDRMEncrypt = 17;      // avoid encrypting really short packets (if 2, don't do CC packets)

        // 100 nano-second units to useful sizes.
const   int kMicroSecsToUnits   = 10;
const   int kMilliSecsToUnits   = 10000;
const   int kSecsToUnits        = 10000000;

extern TCHAR * EventIDToString(const GUID &pGuid);      // in DTFilter.cpp



#endif  //  __EncDec__EncDecAll_h
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\keys_7002.h ===
// Keys_7002.h : DRM cert.
//
//          This is EncDec's cert.  It should only be used in EncDec.dll
//

#ifndef __KEYS_7002_H__
#define __KEYS_7002_H__

const BYTE abCert7002[] = 
//BYTE appcert[sizeof(APPCERT)] = 
{
	0x00, 0x01, 0x00, 0x00, 0x34, 0x00, 0x00, 0x00, 
	0x59, 0x32, 0xD1, 0x76, 0xEF, 0x76, 0xAB, 0xF1, 
	0x18, 0xD2, 0x50, 0xC4, 0x3D, 0x11, 0xD6, 0x78, 
	0x25, 0x45, 0x83, 0x52, 0xAF, 0x27, 0x32, 0x50, 
	0xDC, 0xD8, 0xAB, 0x0D, 0x35, 0xDF, 0x48, 0xB7, 
	0x85, 0xDA, 0x6A, 0xB5, 0x6A, 0x7A, 0x98, 0x07, 
	0x8A, 0x57, 0xE8, 0xA5, 0xF1, 0x81, 0x0E, 0xF9, 
	0xFC, 0x00, 0x5A, 0x8B, 0xF4, 0x12, 0xEF, 0xE8, 
	0xBD, 0xE0, 0x4F, 0x80, 0x78, 0x71, 0x21, 0xAD, 
	0x76, 0x1F, 0x67, 0x03, 0x1B, 0xAB, 0xA4, 0xDC, 
	0xDE, 0x5D, 0x2D, 0xE6, 0x3B, 0x8A, 0x56, 0x5E, 
	0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x03, 0xE8, 
	0x00, 0x00, 0x1B, 0x5A
};
//=======================================================
const BYTE abPVK7002[] =
//BYTE Obf[OBFBYTESLEN] = 
{
	0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 
	0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 
	0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 
	0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 
	0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 
	0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 
	0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 
	0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 
	0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 
	0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 
	0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 
	0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 
	0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 
	0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 
	0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 
	0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 
	0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 
	0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 
	0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 
	0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 
	0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 
	0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 
	0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 
	0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 
	0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 
	0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 
	0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 
	0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 
	0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 
	0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 
	0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 
	0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 
	0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 
	0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 
	0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 
	0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 
	0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 
	0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 
	0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 
	0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 
	0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 
	0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 
	0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 
	0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 
	0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 
	0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 
	0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 
	0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 
	0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 
	0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 
	0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 
	0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 
	0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 
	0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 
	0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 
	0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 
	0x0A, 0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 
	0xDC, 0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 
	0x27, 0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 
	0x8D, 0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 
	0xBC, 0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 
	0xC3, 0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 
	0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 
	0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 
	0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 
	0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 
	0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 
	0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 
	0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 
	0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 
	0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 
	0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 
	0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 
	0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 
	0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 
	0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 
	0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 
	0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 
	0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 
	0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 
	0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 
	0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 
	0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 
	0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 
	0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 
	0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 
	0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 
	0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 
	0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 
	0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 
	0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 
	0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 
	0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 
	0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 
	0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 
	0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 
	0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 
	0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 
	0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 
	0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 
	0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 
	0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x26, 
	0x2D, 0xD1, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x56, 0x3E, 0x62, 
	0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 0xEB, 
	0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 0xBF, 
	0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 
	0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 0x4E, 
	0x26, 0xCA, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0x64, 0xFA, 0x91, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 0x3A, 0x05, 
	0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 0x8E, 
	0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 0xD3, 
	0x22, 0x81, 0x63, 0x61, 0x48, 0x8F, 0x3E, 0x45, 
	0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 0x55, 
	0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 0xD1, 
	0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 0x59, 
	0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 0x58, 
	0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 0xF4, 
	0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 0xEE, 
	0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 0x9E, 
	0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 0x0A, 
	0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 0xC1, 
	0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 0x85, 
	0x43, 0x70, 0x90, 0x4E, 0x37, 0x65, 0x62, 0xDE, 
	0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 0x7A, 0x98, 
	0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 0x5D, 0x07, 
	0x9C, 0x17, 0x3E, 0x7D, 0x58, 0x4C, 0x73, 0x3A, 
	0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 0x4C, 
	0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 0x96, 
	0xD3, 0x81, 0xEA, 0x61, 0x48, 0x54, 0x8F, 0xA7, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 
	0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x02, 0xBE, 
	0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 0x47, 
	0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 0xB9, 
	0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 0xDC, 0x22, 0x1A, 
	0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 0x76, 0x62, 0xE3, 
	0xC1, 0x7D, 0xB5, 0xFA, 0x66, 0x7C, 0x5E, 0xB8, 
	0x85, 0x43, 0x70, 0x90, 0x4E, 0x0D, 0x37, 0x1F, 
	0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 0x4D, 0xF0, 
	0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 0xC8, 0x3E, 
	0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 0x4C, 0x63, 
	0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 0xCA, 0xEA, 
	0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 0x45, 0xCF, 
	0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 0x8F, 0x3E, 
	0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 0x8D, 0xFA, 
	0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 0xB2, 0xBF, 
	0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 0xB0, 0x03, 
	0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 0x9F, 0xCD, 
	0x58, 0xAC, 0x29, 0x01, 0x27, 0x24, 0x5E, 0x02, 
	0x76, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 0xEF, 0xC8, 
	0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 0x27, 0xA1, 
	0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0x7D, 0xC3, 0x20, 
	0x22, 0x1A, 0x0A, 0xE5, 0x57, 0xCF, 0x1E, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x1A, 0x5D, 0x35, 0x9C, 0x17, 0x3E, 
	0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 
	0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 
	0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 
	0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 
	0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 
	0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 0x04, 
	0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 0xD1, 
	0x9F, 0x07, 0xCD, 0x68, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x65, 0x0A, 0xB8, 0xCF, 0xD8, 
	0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 
	0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 
	0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 
	0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 
	0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 
	0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 
	0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 
	0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0x74, 0xDC, 0x74, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 
	0x5F, 0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 
	0x66, 0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 
	0x4E, 0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 
	0x61, 0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 
	0x57, 0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 
	0x7D, 0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 
	0x05, 0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 
	0xFA, 0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x70, 0x96, 0x9E, 0x81, 0xEA, 0x61, 
	0x48, 0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 
	0x19, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 
	0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0x2C, 0xE7, 
	0xCB, 0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 
	0xDE, 0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0xEA, 0x0A, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0xFA, 0x66, 
	0x7C, 0x5E, 0xB8, 0x85, 0x43, 0x70, 0x90, 0x4E, 
	0x37, 0x65, 0x62, 0xDE, 0x60, 0xAA, 0xFB, 0x61, 
	0x4D, 0xF0, 0x7A, 0x98, 0x49, 0x0B, 0x91, 0x57, 
	0xC8, 0x3E, 0x5D, 0x07, 0x9C, 0x17, 0x3E, 0x7D, 
	0x4C, 0x63, 0x3A, 0x05, 0x5C, 0x8B, 0x49, 0x05, 
	0xCA, 0xEA, 0x4C, 0x8E, 0xA7, 0x75, 0xE5, 0xFA, 
	0x45, 0xCF, 0x96, 0xD3, 0x81, 0xEA, 0x61, 0x48, 
	0x8F, 0x3E, 0x45, 0xEB, 0x7B, 0xC8, 0xE7, 0x19, 
	0x8D, 0xFA, 0x55, 0xBF, 0x7B, 0xE8, 0x2E, 0xDE, 
	0xB2, 0xBF, 0xD1, 0x2D, 0xA5, 0x51, 0xEA, 0x35, 
	0x04, 0xB0, 0x03, 0x59, 0x26, 0x15, 0x78, 0xDC, 
	0xD1, 0x9F, 0xCD, 0x58, 0xAC, 0x29, 0x01, 0x27, 
	0x24, 0x02, 0xBE, 0xF4, 0xD6, 0xA3, 0xFE, 0x8D, 
	0xEF, 0xC8, 0x47, 0xEE, 0x45, 0x99, 0xFF, 0xBC, 
	0x27, 0xA1, 0xB9, 0x9E, 0xC4, 0xC5, 0xD5, 0xC3, 
	0xDC, 0x22, 0x1A, 0x0A, 0xE5, 0xCF, 0xD8, 0x5F, 
	0x76, 0x62, 0xE3, 0xC1, 0x7D, 0xB5, 0x95, 0x32, 
	0x86, 0x72, 0x41, 0x37, 0xC8, 0xCB, 0x9D, 0x31, 
	0xBE, 0x6C, 0xF7, 0xB1, 0xCA, 0x62, 0x6B, 0x39, 
	0x3D, 0xF1, 0xA4, 0x06, 0x1F, 0x2E, 0xC2, 0xCF, 
	0x96, 0xD5, 0x7F, 0xEC, 0x5F, 0x4A, 0x8D, 0xDB, 
	0x0F, 0x60, 0x8B, 0x1A, 0x36, 0xB8, 0x74, 0x54, 
	0xF1, 0x47, 0x96, 0x04, 0xB5, 0xCB, 0xC7, 0x08, 
	0x5F, 0x55, 0xB5, 0x84, 0x75, 0xA3, 0x70, 0x4E, 
	0xC2, 0xA7, 0x8A, 0x9D, 0x7F, 0x6F, 0x0F, 0x9C, 
	0xE7, 0x09, 0x9F, 0xE1, 0xAA, 0x61, 0x94, 0xAB, 
	0x0F, 0x81, 0xCF, 0x7B, 0x56, 0x8D, 0xE1, 0x6D, 
	0x24, 0x38, 0x70, 0x57, 0xA7, 0x61, 0xC5, 0x78, 
	0xBA, 0xF3, 0xA1, 0xA4, 0xE6, 0xDA, 0xFE, 0x0A, 
	0xDA, 0xA7, 0x2F, 0xF9, 0xCA, 0xE4, 0x85, 0x21, 
	0x2B, 0x60, 0x96, 0x42, 0xDF, 0x1E, 0x20, 0x69, 
	0x88, 0x54, 0xC5, 0xDB, 0x8C, 0xB0, 0x39, 0x57, 
	0xD8, 0xFC, 0xA6, 0xA3, 0xB6, 0x0A, 0xEF, 0xF8, 
	0x7E, 0x2F, 0x81, 0xA9, 0xD6, 0x50, 0x1C, 0xB5, 
	0xD5, 0x57, 0x7B, 0xF3, 0xBD, 0x22, 0x40, 0x18, 
	0x80, 0xA0, 0x43, 0x14, 0x1D, 0xCF, 0x55, 0xAF, 
	0x24, 0x9F, 0xEE, 0x35, 0xDB, 0x1F, 0x50, 0x07, 
	0x96, 0x50, 0xD1, 0x01, 0x37, 0x14, 0xE7, 0xD3, 
	0xA1, 0xCA, 0xF4, 0x75, 0xCF, 0xDE, 0x8D, 0x15, 
	0x6D, 0x4D, 0xF6, 0x41, 0xA0, 0xF6, 0x62, 0x4B, 
	0x5B, 0xA8, 0xC6, 0x62, 0x03, 0xA1, 0x10, 0xE2, 
	0xA3, 0x9B, 0x24, 0xCB, 0x5A, 0xA8, 0x2D, 0x94, 
	0x96, 0x57, 0x97, 0x71, 0xAE, 0x30, 0x2D, 0x31, 
	0x2B, 0xCC, 0xF7, 0x3F, 0x09, 0x8F, 0x8C, 0x5F, 
	0xBE, 0x4C, 0xB0, 0xEC, 0xA5, 0x38, 0xBB, 0xA7, 
	0x55, 0x9E, 0x35, 0x89, 0xA3, 0x44, 0xE2, 0xEA, 
	0xEF, 0x1E, 0x8C, 0x65, 0x83, 0x24, 0x28, 0x65, 
	0x8F, 0x4B, 0x6B, 0x96, 0xDF, 0x0D, 0xCA, 0xB8, 
	0xB0, 0xB0, 0xE0, 0xB0, 0x28, 0x6A, 0x57, 0x1E, 
	0xEA, 0xD4, 0x06, 0x67, 0x1A, 0x8D, 0xFC, 0x52, 
	0x53, 0x69, 0xA9, 0xE4, 0xAB, 0x2F, 0x61, 0x62, 
	0xA8, 0x64, 0xF6, 0xE4, 0x95, 0xAA, 0x10, 0x19, 
	0x37, 0xB7, 0xDC, 0xEC, 0xB5, 0x26, 0xD4, 0xED, 
	0xE4, 0x5E, 0xAD, 0xF6, 0xFF, 0x14, 0x6A, 0x1A, 
	0xF5, 0x94, 0x80, 0x39, 0x78, 0x1C, 0xC6, 0xC4, 
	0xD6, 0xC4, 0xDD, 0x88, 0x4F, 0x66, 0x9D, 0xA4, 
	0x80, 0xA5, 0x0B, 0xE7, 0x9C, 0x3F, 0x4A, 0x1A, 
	0x1B, 0x39, 0x82, 0x45, 0x07, 0xF7, 0x24, 0x23, 
	0x9D, 0x21, 0x69, 0x21, 0xB9, 0x06, 0xF5, 0x57, 
	0xBC, 0x17, 0xB1, 0x3D, 0xB9, 0x11, 0xEB, 0xCD, 
	0x42, 0xF5, 0x3C, 0xD6, 0x25, 0xAF, 0xDC, 0x4E, 
	0xEF, 0x7B, 0x30, 0x7F, 0xAB, 0x39, 0xEF, 0x40, 
	0x6A, 0xFA, 0xAE, 0x66, 0x2B, 0xE3, 0xAD, 0xC6, 
	0x31, 0x68, 0xF7, 0x4B, 0x30, 0x37, 0x5A, 0x6C, 
	0x68, 0x75, 0x33, 0xAB, 0xE8, 0x74, 0x9A, 0xDF, 
	0x75, 0x62, 0xE5, 0xBF, 0xE8, 0x48, 0xC5, 0x3C, 
	0xF7, 0xD2, 0xA9, 0xF4, 0x9B, 0xDD, 0x79, 0x5E, 
	0xE9, 0xBB, 0x87, 0xA7, 0xA7, 0x81, 0x73, 0xD8, 
	0x07, 0xCE, 0x4C, 0x85, 0x7D, 0x37, 0x44, 0xB5, 
	0x16, 0xE4, 0xD6, 0x9C, 0xD1, 0xEB, 0x80, 0x90, 
	0x55, 0xFB, 0xD7, 0xD7, 0x97, 0x70, 0x18, 0xC6, 
	0x5C, 0x3E, 0x97, 0x65, 0x89, 0xEB, 0x95, 0x46, 
	0x41, 0xC0, 0x3F, 0x8A, 0x41, 0x73, 0x8B, 0x55, 
	0x93, 0x3F, 0x13, 0xB8, 0x32, 0x61, 0xCA, 0x40, 
	0x28, 0x70, 0x1C, 0x28, 0x95, 0x2D, 0x27, 0x9D, 
	0x89, 0x01, 0x4E, 0xC8, 0x73, 0x07, 0x00, 0x14
};

#endif __KEYS_7002_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\drmrootcert.h ===
// Appcert Root Pubkey
//
const BYTE abEncDecCertRoot[] =
{
    0xD8, 0xF9, 0x9B, 0x8B, 0xDA, 0xC3, 0xEF, 0x2B,
    0x4B, 0x85, 0x14, 0x0F, 0xC4, 0xD1, 0xEA, 0x15,
    0xD5, 0x3B, 0x6D, 0x51, 0x36, 0xDB, 0xF0, 0x4E,
    0x64, 0x12, 0x2B, 0xE0, 0x7E, 0x9F, 0x01, 0x15,
    0xD1, 0x8D, 0x85, 0x8E, 0xF8, 0xA6, 0xD7, 0x7E
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\packtvrat.h ===
// --------------------------------------------------
//  PackTvRat.h
//
//		TvRating is a private but well defined 'wire' format
//		for XDS ratings infomation.  It is persisted in the PVR
//		buffer.
//
//		This file contains methods for convering between the
//		3-part (system, rating, attribute) format and the packed format.
//
//		Copyright (c) 2002, Microsoft		
// ----------------------------------------------------


#ifndef __PACKTvRat_H__
#define __PACKTvRat_H__

	// totally private rating system that's persisted as a 'PackedTvRating' in the
	//   pvr file. Can't change once the first file gets saved.  
typedef struct 
{
	byte s_System;
	byte s_Level;
	byte s_Attributes;
	byte s_Reserved;
} struct_PackedTvRating;

	// union to help convering
typedef union  
{
	PackedTvRating			pr;
	struct_PackedTvRating	sr; 
} UTvRating;


HRESULT 
UnpackTvRating(
			IN	PackedTvRating              TvRating,
			OUT	EnTvRat_System              *pEnSystem,
			OUT	EnTvRat_GenericLevel        *pEnLevel,
			OUT	LONG                    	*plbffEnAttributes  // BfEnTvRat_GenericAttributes
			);


HRESULT
PackTvRating(
			IN	EnTvRat_System              enSystem,
			IN	EnTvRat_GenericLevel        enLevel,
			IN	LONG                        lbfEnAttributes, // BfEnTvRat_GenericAttributes
			OUT PackedTvRating              *pTvRating
			);

// development only code, remove eventually
HRESULT
RatingToString( IN	EnTvRat_System          enSystem,
				IN	EnTvRat_GenericLevel    enLevel,
				IN	LONG                    lbfEnAttributes, // BfEnTvRat_GenericAttributes	
				IN  TCHAR	                *pszBuff,        // allocated by caller
				IN  int		                cBuff);		     // size of above buffer must be >= 64        // 

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\xdscodec\xdscodec_res.h ===
//{{NO_DEPENDENCIES}}
// Microsoft Developer Studio generated include file.
// Used by XDSCODEC_res.rc
//

#define IDS_XDSCODEC_PROPNAME			301
#define IDS_XDSCODEC_TAGSPROPNAME       302
#define IDD_XDSCODEC_PROPPAGE			306
#define IDD_XDSCODEC_TAGSPROPPAGE       307
#define IDC_STATIC                      -1

// Next default values for new objects
// 
#ifdef APSTUDIO_INVOKED
#ifndef APSTUDIO_READONLY_SYMBOLS
#define _APS_NEXT_RESOURCE_VALUE        310
#define _APS_NEXT_COMMAND_VALUE         32768
#define _APS_NEXT_CONTROL_VALUE         310
#define _APS_NEXT_SYMED_VALUE           310
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\xdscodec\xdscodecprops.h ===
// ---------------------------------------------------------------
// XDSCodecProps.h
//
// ---------------------------------------------------------------


#ifndef __XDSCodecProps_H__
#define __XDSCodecProps_H__

#define XDS_PROPPAGE_NAME		"Codec"
#define XDS_PROPPAGE_TAG_NAME	"Tags"

// ----------------------------------
//  forward declarations
// ----------------------------------

class CXDSCodecProperties;
class CXDSCodecTagProperties;

// ----------------------------------
// ----------------------------------

class CXDSCodecProperties : 
	public CBasePropertyPage 
{
 
public:
   CXDSCodecProperties(IN  TCHAR		*pClassName,
							IN  IUnknown	*lpUnk, 
							OUT HRESULT		*phr);
	~CXDSCodecProperties();


    HRESULT
    OnActivate (
        ) ;

    HRESULT
    OnApplyChanges (
        ) ;

    HRESULT
    OnConnect (
        IN  IUnknown *  pIUnknown
        ) ;

    HRESULT
    OnDeactivate (
        ) ;

    HRESULT
    OnDisconnect (
        ) ;

    INT_PTR
    OnReceiveMessage (
        IN  HWND    hwnd,
        IN  UINT    uMsg,
        IN  WPARAM  wParam,
        IN  LPARAM  lParam
            ) ;

	DECLARE_IUNKNOWN ;

    static
    CUnknown *
    WINAPI
    CreateInstance (
        IN  IUnknown *  pIUnknown,
        IN  HRESULT *   pHr
        ) ;

private:
   void UpdateFields();

   IXDSCodec		*m_pIXDSCodec;
   HWND				m_hwnd ;
};
	
				// ---------------------------


class CXDSCodecTagProperties : 
	public CBasePropertyPage 
{
 
public:
   CXDSCodecTagProperties(IN  TCHAR		*pClassName,
							IN  IUnknown	*lpUnk, 
							OUT HRESULT		*phr);
	~CXDSCodecTagProperties();


    HRESULT
    OnActivate (
        ) ;

    HRESULT
    OnApplyChanges (
        ) ;

    HRESULT
    OnConnect (
        IN  IUnknown *  pIUnknown
        ) ;

    HRESULT
    OnDeactivate (
        ) ;

    HRESULT
    OnDisconnect (
        ) ;

    INT_PTR
    OnReceiveMessage (
        IN  HWND    hwnd,
        IN  UINT    uMsg,
        IN  WPARAM  wParam,
        IN  LPARAM  lParam
            ) ;

	DECLARE_IUNKNOWN ;

    static
    CUnknown *
    WINAPI
    CreateInstance (
        IN  IUnknown *  pIUnknown,
        IN  HRESULT *   pHr
        ) ;

private:
   void UpdateFields();

   IXDSCodec		*m_pIXDSCodec;
   HWND				m_hwnd ;

};

#endif //__XDSCodecProps_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\xdscodec\xdscodec.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        XDSCodec.h

    Abstract:

        This module contains the Encrypter/Tagger filter declarations

    Author:

        John Bradstreet (johnbrad)

    Revision History:

        07-Mar-2002    created

--*/

#ifndef __EncDec__XDSCodec_h
#define __EncDec__XDSCodec_h


#include <tuner.h>		// needed for IBroadcastEvent
#include <ks.h>
#include <ksmedia.h>
#include <bdatypes.h>
#include <bdamedia.h>	// EVENTID_TuningChanged, XDS_RatingsPacket

#include "XDSCodec_res.h"

#include "TvRatings.h"

#define XDS_CODEC_NAME  "XDS Codec"
#define XDS_INPIN_NAME	"XDS (CCDecoder)"


extern AMOVIESETUP_FILTER   g_sudXDSCodec;

		// forward declarations
class CXDSCodec;
class CXDSCodecInput;

//  --------------------------------------------------------------------
//  class CXDSCodecInput
//  --------------------------------------------------------------------

class CXDSCodecInput :
    public CBaseInputPin
{
    CXDSCodec *                 m_pHostXDSCodec ;

    CCritSec                    m_StreamingLock;

    void FilterLock_ ()         { m_pLock -> Lock () ;      }
    void FilterUnlock_ ()       { m_pLock -> Unlock () ;    }

    public :

        CXDSCodecInput (
            IN  TCHAR *         pszPinName,
            IN  CXDSCodec *		pXDSCodec,
            IN  CCritSec *      pFilterLock,
            OUT HRESULT *       phr
            ) ;

        //  --------------------------------------------------------------------
        //  CBasePin methods

        HRESULT
		GetMediaType(
			IN int	iPosition, 
			OUT CMediaType *pMediaType
			);


        HRESULT
        CheckMediaType (
            IN  const CMediaType *
            ) ;

        HRESULT
        CompleteConnect (
            IN  IPin *  pIPin
            ) ;

        HRESULT
        BreakConnect (
            ) ;

        //  --------------------------------------------------------------------
        //  CBaseInputPin methods

        STDMETHODIMP
        Receive (
            IN  IMediaSample * pIMediaSample
            ) ;

        STDMETHODIMP
        BeginFlush (
            ) ;

        STDMETHODIMP
        EndFlush (
            ) ;

        //  --------------------------------------------------------------------
        //  class methods

        HRESULT
            StreamingLock (
            );

        HRESULT
            StreamingUnlock (
            );
        
        HRESULT
        SetAllocatorProperties (
            IN  ALLOCATOR_PROPERTIES *  ppropInputRequest
            ) ;

		HRESULT
		SetNumberBuffers(		// question - verify it doesn't conflict with Allocator stuff
			long cBuffers,
			long cbBuffer,
			long cbAlign, 
			long cbPrefix
		);


};

//  --------------------------------------------------------------------
//  class CXDSCodec
//  --------------------------------------------------------------------

class CXDSCodec :
    public CBaseFilter,             //  dshow base class
	public ISpecifyPropertyPages,
	public IXDSCodec,
	public IBroadcastEvent
{
    CXDSCodecInput  *		 m_pInputPin ;
    CCritSec                 m_PropertyLock;       // only locks changing parameters... Most inner lock

    BOOL
    CompareConnectionMediaType_ (
        IN  const AM_MEDIA_TYPE *   pmt,
        IN  CBasePin *              pPin
        ) ;

    BOOL
    CheckInputMediaType_ (
        IN  const AM_MEDIA_TYPE *   pmt
        ) ;

    public :

        CXDSCodec (
            IN  TCHAR *     pszFilterName,
            IN  IUnknown *  punkControlling,
            IN  REFCLSID    rCLSID,
            OUT HRESULT *   phr
            ) ;

        ~CXDSCodec () ;

        static
        CUnknown *
        CreateInstance (
            IN  IUnknown *  punk,
            OUT HRESULT *   phr
            ) ;


        STDMETHODIMP
        NonDelegatingQueryInterface (
            IN  REFIID  riid,
            OUT void ** ppv
            ) ;


        DECLARE_IUNKNOWN ;

		// =====================================================================
		// Worker methods

		BOOL IsInputPinConnected();

				// called by the parsers
		HRESULT GoNewXDSRatings(IMediaSample * pMediaSample, PackedTvRating TvRat);
		HRESULT GoDuplicateXDSRatings(IMediaSample * pMediaSample, PackedTvRating TvRat);
		HRESULT GoNewXDSPacket(IMediaSample * pMediaSample,  long pktClass, long pktType, BSTR bstrXDSPkt);

				// the  crux of the whole system
		HRESULT	ParseXDSBytePair(IMediaSample * mediaSample, BYTE byte1, BYTE byte2);	// parser our data

				// tell folk we got something...
		HRESULT FireBroadcastEvent(IN const GUID &eventID);

				// reinit XDS parser state (for discontinuties), and kickoff event
		HRESULT	ResetToDontKnow(IN IMediaSample *pSample);

		void DoTuneChanged();

		// =====================================================================
		//		IXDSCodec

		STDMETHODIMP 
		get_XDSToRatObjOK(
			OUT HRESULT *pHrCoCreateRetVal	
			);

		STDMETHODIMP 
		put_CCSubstreamService(				// will return S_FALSE if unable to set
			IN long SubstreamMask
			);

		STDMETHODIMP 
		get_CCSubstreamService(
			OUT long *pSubstreamMask
			);

		STDMETHODIMP 
		GetContentAdvisoryRating(
			OUT PackedTvRating *pRat,			// long
			OUT long *pPktSeqID, 
			OUT long *pCallSeqID,
			OUT REFERENCE_TIME *pTimeStart,	// time this sample started
			OUT REFERENCE_TIME *pTimeEnd 
			);

  
		STDMETHODIMP GetXDSPacket(
			OUT long *pXDSClassPkt,				// ENUM EnXDSClass		
			OUT long *pXDSTypePkt, 
			OUT BSTR *pBstrCCPkt, 
			OUT long *pPktSeqID, 
			OUT long *pCallSeqID,
			OUT REFERENCE_TIME *pTimeStart,	// time this sample started
			OUT REFERENCE_TIME *pTimeEnd 
			);

        //  ====================================================================
        //  pure virtual methods in base class

        int
        GetPinCount (
            ) ;

        CBasePin *
        GetPin (
            IN  int
            ) ;

        STDMETHODIMP
        Pause (
            ) ;

        STDMETHODIMP
        Stop (
            ) ;

        //  ====================================================================
        //  class methods

		HRESULT 
		SetSubstreamChannel(
				DWORD dwChanType	// bitfield of:  KS_CC_SUBSTREAM_SERVICE_CC1, _CC2,_CC3, _CC4,  _T1, _T2, _T3 _T4 And/Or _XDS;
		);


        HRESULT
        DeliverBeginFlush (
            ) ;

        HRESULT
        DeliverEndFlush (
            ) ;


		HRESULT
		GetXDSMediaType (
			IN  PIN_DIRECTION  PinDir,
			int iPosition,
			OUT CMediaType *  pmt
			);

        BOOL
        CheckXDSMediaType (
            IN  PIN_DIRECTION,          //  caller
            IN  const CMediaType *
            ) ;

        HRESULT
        Process (
            IN  IMediaSample *
            ) ;

        HRESULT
        OnCompleteConnect (
            IN  PIN_DIRECTION           //  caller
            ) ;

        HRESULT
        OnBreakConnect (
            IN  PIN_DIRECTION           //  caller
            ) ;

        HRESULT
        UpdateAllocatorProperties (
            IN  ALLOCATOR_PROPERTIES *
            ) ;

	//  ISpecifyPropertyPages  --------------------------------------------

		STDMETHODIMP 
		GetPages (
			CAUUID * pPages
        ) ;

	// IBroadcastEvent  ------------------------------

        STDMETHOD(Fire)(GUID eventID);     // this comes from the Graph's events - call our own method

	// ------------------------------

private:
	HRESULT						HookupGraphEventService();
	HRESULT						UnhookGraphEventService();
	CComPtr<IBroadcastEvent>	m_spBCastEvents;

	HRESULT						RegisterForBroadcastEvents();
	HRESULT						UnRegisterForBroadcastEvents();
	enum {kBadCookie = -1};
	DWORD						m_dwBroadcastEventsCookie;
	
    BOOL                        m_fJustDiscontinuous;   // latch to detect sequential discontinuity samples

	CComQIPtr<ITuner>			m_spTuner;			
	//CComQIPtr<IMSVidTuner>		m_spVidTuner;

	DWORD						m_dwSubStreamMask;

	CComPtr<IXDSToRat>			m_spXDSToRat;

	HRESULT						m_hrXDSToRatCoCreateRetValue;

		// Sequence Counters
	long						m_cTvRatPktSeq;
	long						m_cTvRatCallSeq;
	PackedTvRating				m_TvRating;
	REFERENCE_TIME				m_TimeStartRatPkt;
	REFERENCE_TIME				m_TimeEndRatPkt;

	long						m_cXDSPktSeq;
	long						m_cXDSCallSeq;
	long						m_XDSClassPkt;
	long						m_XDSTypePkt;
	CComBSTR					m_spbsXDSPkt;
	REFERENCE_TIME				m_TimeStartXDSPkt;
	REFERENCE_TIME				m_TimeEndXDSPkt;

             // times of last packet recieved for non-packet (tune) events
    REFERENCE_TIME              m_TimeStart_LastPkt;
    REFERENCE_TIME              m_TimeEnd_LastPkt;

                // Stats
    DWORD                       m_cRestarts;
    DWORD                       m_cPackets;             // number of byte-pairs given to parse
    DWORD                       m_cRatingsDetected;     // times parsed a Rating 
    DWORD                       m_cRatingsFailures;     // parse errors
    DWORD                       m_cRatingsChanged;      // times ratings changed
    DWORD                       m_cRatingsDuplicate;    // times same ratings duplicated
    DWORD                       m_cUnratedChanged;      // times changed into 'unrated' rating
    DWORD                       m_cRatingsGets;         // times rating values requested
    DWORD                       m_cXDSGets;             // times XDS Packet values requested

    void    InitStats()
    {
            m_cPackets = m_cUnratedChanged = m_cRatingsDetected = m_cRatingsChanged = m_cRatingsDuplicate = m_cRatingsFailures = 0;
            m_cRatingsGets = m_cXDSGets = 0;
            m_cRestarts++;
    }
} ;

#endif  //  __EncDec__XDSCodec_h
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\timeit.h ===
//--------------------------------------------------
// timeit.h
//        
// 	Tiny little C++ timing utilities
//
//	There are two ways to use these:
//	
//	1)	Create a named Timeit object in a scope.  When scope goes out of context,
//		the time inside that scope is printed out.
//
//				{
//					Timeit("Scope A");			// <--- Note, you must "name" the timer in the constructor
//					{							//		else it isn't automatically started..
//						Timeit("Scope B");
//					}
//				}
//
// >>               T-0 Scope B       1 Calls    0.00021 Total   0.00021 Avg
// >>               T-0 Scope A       1 Calls    0.00221 Total   0.00221 Avg
//
//		
//		The advantage of this method is it's really easy... Just don't forget to name each timer.
//
//	2)	Create an unnamed TimeIt object (or use a 'false' 2'nd argument to the constructor)
//		Give it a name, and give it explicit Start(),Stop(),Continue() instructions.
//		When desired, call TimeitPrintAll() to dump info to a stream or a file.
//
//				Timeit	tt[20];
//				char szFoo[20];
//				for(int j = 0; j < 20; j++) {				// optionally, tag each timer
//					sprintf(szFoo,"My Tag %d\n",j);
//					tt[j]->SetTag(szFoo);
//				}
//				for(int i0 = 0; i0 < 10; i0++) {			tt[0].Start();
//				   for(int i1 = 0; i1 < 10; i1++) {		    tt[1].Start()
//					  for(int i2 = 0; i2 < 10; i2++) {		tt[2].Start();
//					     for(int i3 = 0; i3 < 10; i2++) {	tt[3].Start();
//							...
//							...								tt[3].Stop();
//						 }									tt[2].Stop();
//					  }										tt[1].Stop();
//					}										tt[0].Stop();
//				}
//				TimeitPrintAll(stdout);						// dump the complete list
//
// >>       T-0 My Tag 0       10 Calls    0.15433 Total   0.01543 Avg
// >>       T-1 My Tag 1      100 Calls    0.15357 Total   0.00154 Avg
// >>       T-2 My Tag 2     1000 Calls    0.14598 Total   0.00015 Avg
// >>       T-3 My Tag 3    10000 Calls    0.06882 Total   0.00001 Avg
//
//		The advantage of this second method is that timers can go in and out of scope,
//		and that all I/O associated with dumping results is left to the very end.  
//
//		It would perhaps be useful to put N timers into some global file, some constants to ID them,
//		and some U/I method to call TimeitPrintAll() and the ->Restart() methods. 
//
//--------------------------------------------------

#ifndef __TIMEIT_H__
#define __TIMEIT_H__

#include <atlbase.h>
#include <time.h>
#include <winbase.h>
#include <math.h>


inline double 
ToDouble(const LARGE_INTEGER &li)
{
	double r = li.HighPart;
	r = ldexp(r,32);
	r += li.LowPart;
	return r;
}

inline __int64 
To__int64(const LARGE_INTEGER &li)
{
	__int64 *pr64 = (__int64 *) &li;
	return *pr64;
}

inline void QueryPerformanceCounter(__int64 *pliVal)
{
	QueryPerformanceCounter((LARGE_INTEGER *) pliVal);
}

inline void QueryPerformanceFrequency(__int64 *pliVal)
{
	QueryPerformanceFrequency((LARGE_INTEGER *) pliVal);
}


// ------------------------------------------------------------------------
//		the real class
// ------------------------------------------------------------------------
//#include <iostream.h>

class Timeit
{
	public:
		Timeit(bool fAutoRun=true)			                // constructor	
						{Init(fAutoRun);}
		~Timeit();											// destructor

		void	Start();									// start the timer, or restart it and increasing timer count
		void	Stop();										// stop the timer
		void	Continue();									// restart a timer, not increasing the timer count
		void	Restart();									// stop timer if running set all counts and times back to zero 
        void    Clear();

		unsigned int	CTimes()		{return m_ctimes;}
		double	AvgTime();
		double	TotalTime();

	private:	
		void			Init(bool fAutoRun=true);

		unsigned int	m_ctimer;		// timer ID
		bool			m_fAutoRun;		// true if start on construction, print on destruct
		bool			m_frunning;		// currently running?

		__int64			m_i64start;
		__int64			m_i64total;
		__int64			m_i64lastdel;

		unsigned int	m_ctimes;		// count of times it started
		char 		   *m_psztag;		// tag to label this timer
};

        
            // quick little class that uses it's constructor/destructor to start/stop the clock
class TimeitC
{
public:
    TimeitC(Timeit *pT) 
    {
        m_pT = pT;
        if(m_pT) m_pT->Start();
    }
    ~TimeitC()
    {
        if(m_pT) m_pT->Stop();
    }
private:
    Timeit *m_pT;
};
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\regkey.h ===
// Copyright (c) 1999  Microsoft Corporation.  All Rights Reserved.
#if _MSC_VER > 1000
#pragma once
#endif

#ifndef REGKEY_H
#include <tchar.h>

//
// Registry usage:
//
// HKLM = HKEY_LOCAL_MACHINE
// HKCU = HKEY_CURRENT_USER
//
// HKLM\Software\Microsoft\Windows\\CurrentVersion\Remove View\Service\Content Security\...							
//
//
//-----------------------------------------------------------------------------

#define DEF_ENCDEC_BASE         _T("SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Media Center\\Service\\Content Security")
#define DEF_KID_VAR             _T("Key Identifier")
#define DEF_KIDHASH_VAR         _T("Key Hash")
#define DEF_CSFLAGS_VAR         _T("CS Flags")  // define here, shouldn't appear at all in non-special versions
#define DEF_RATFLAGS_VAR        _T("Ratings Flags")

#define DEF_CSFLAGS_INITVAL     -1                // initial value to not write

#ifdef SUPPORT_REGISTRY_KEY_TO_TURN_OFF_CS     // use to turn off DRM for debugging 
#define DEF_CS_DEBUG_DOGFOOD_ENC_VAL        0x0     // always use dogfood encryption
#define DEF_CS_DEBUG_DRM_ENC_VAL            0x1     // always use DRM encryption
#define DEF_CS_DEBUG_NO_ENC_VAL             0x2

#define DEF_CS_DONT_AUTHENTICATE_SERVER     0x00   
#define DEF_CS_DO_AUTHENTICATE_SERVER       0x10    // CheckIfSecureServer() never called if not set

#define DEF_CS_DONT_AUTHENTICATE_FILTERS    0x000  //  ??? InitializeAsSecureClient ??? 
#define DEF_CS_DO_AUTHENTICATE_FILTERS      0x100
#endif

#ifdef SUPPORT_REGISTRY_KEY_TO_TURN_OFF_RATINGS     // use to turn off DRM for debugging 
#define DEF_DONT_DO_RATINGS_BLOCK           0x0
#define DEF_DO_RATINGS_BLOCK                0x1
#endif

//-----------------------------------------------------------------------------
extern HRESULT Get_EncDec_RegEntries(BSTR *pbsKID, 
                                     DWORD *pcbHashBytes, BYTE **ppbHash, 
                                     DWORD *pdwCSFlags, 
                                     DWORD *pdwRatFlags);
extern HRESULT Set_EncDec_RegEntries(BSTR bsKID, 
                                     DWORD cbHashBytes, BYTE *pbHash,
                                     DWORD dwCSFlags=DEF_CSFLAGS_INITVAL, 
                                     DWORD dwRatFlags=DEF_CSFLAGS_INITVAL);
extern HRESULT Remove_EncDec_RegEntries();

//-----------------------------------------------------------------------------
// OpenRegKey
//
// Opens a registry HKEY.  There are several overloads of this function
// that basically just provide defaults for the arguments to this function.
//
// Please use the overload that defaults as much as possible.
//
// The registry key is a combination of the following four parts.
//
//   HKEY hkeyRoot       = Optional root hkey.
//                         Default: HKEY_LOCAL_MACHINE
//
//   LPCTSTR szKey       = Optional key to be set.
//                         Default: DEF_REG_BASE
//
//   LPCTSTR szSubKey1
//   LPCTSTR szSubKey2   = Optional sub keys that are concatenated after
//                         szKey to form the full key.
//                         Backward slashes are added as necessary.
//
//                         Default: NULL
//
//   Note: if only one or two strings are specified they are assumed to be
//         szSubKey1 and szSubKey2.
//         i.e. szKey defaults to DEF_REG_BASE before szSubKey1 and
//         szSubKey2 default to NULL.
//
//         If szKey, szSubKey1, and szSubKey2 are NULL then this will open
//         a duplicate of hkeyRoot.
//
// The only required argument is the destination for the returned HKEY.
//
//   HKEY *pkey  = The returned HKEY.
//                 Remember to use RegCloseKey(*pkey) when you are finished
//                 with this registry key.
//
// The last two arguments are optional.
//
//   REGSAM sam  = Desired access mask.
//                 Default: KEY_ALL_ACCESS
//
//   BOOL fCreate = TRUE if the key should be created.
//                  Default: FALSE
//
// Returns:
//     ERROR_SUCCESS or an error code.
//-----------------------------------------------------------------------------
long OpenRegKey(HKEY hkeyRoot, LPCTSTR szKey, LPCTSTR szSubKey1,
        LPCTSTR szSubKey2, HKEY *pkey,
        REGSAM sam = KEY_ALL_ACCESS, BOOL fCreate = FALSE);

inline long OpenRegKey(LPCTSTR szKey, 
                       LPCTSTR szSubKey1, 
                       LPCTSTR szSubKey2,
                       HKEY *pkey, 
                       REGSAM sam = KEY_ALL_ACCESS, 
                       BOOL fCreate = FALSE)
{
     return OpenRegKey(HKEY_LOCAL_MACHINE, szKey, szSubKey1, szSubKey2, pkey,
             sam, fCreate);
}

//-----------------------------------------------------------------------------
// GetRegValue,		SetRegValue
// GetRegValueSZ,	SetRegValueSZ
//
// Gets data from the registry.  There are numerous overloads of this function
// that basically just provide defaults for the arguments to this function.
//
// Please use the overload that defaults as much as possible.
//
// The registry key/value is a combination of the following five parts.
// The first four are the same as in OpenRegKey().
//
//   HKEY hkeyRoot
//   LPCTSTR szKey
//   LPCTSTR szSubKey1
//   LPCTSTR szSubKey2
//
//   LPCTSTR szValueName = The name of the value to be set.
//                         If it is NULL then the default value for the key
//                         will be set.
//
//                         Default: none
//
// There are four ways to specify where the data to be returned
// depending on the type of data in the registry.
//
// REG_BINARY
//
//   BYTE *pb      = Out: The data is copied to this location.
//   DWORD *pcb    = In:  Maximum size of the returned data (in bytes).
//                   Out: Actual size of the data (in bytes).
//
// REG_SZ
//
//   TCHAR *psz    = Out: The string is copied to this location.
//   DWORD *pcb    = In:  Maximum size of the returned data (in bytes).
//                   Out: Actual size of the data (in bytes).
//                   Includes the null terminator.
//
// REG_DWORD
//
//   DWORD *pdw    = Out: The data is copied to this location.
//                   The length is assumed to be sizeof(DWORD).
//
// All other types
//
//   DWORD dwType  = The data type.
//   BYTE *pb      = Pointer to the data.
//   DWORD *pcb    = In:  Maximum size of the returned data (in bytes).
//                   Out: Actual size of the data (in bytes).
//                   Includes the null terminator if the data is a string type.
//
// Returns:
//     ERROR_SUCCESS or an error code.
//-----------------------------------------------------------------------------
long GetRegValue(HKEY hkeyRoot, LPCTSTR szKey, LPCTSTR szSubKey1,
        LPCTSTR szSubKey2, LPCTSTR szValueName,
        DWORD dwType, BYTE *pb, DWORD *pcb);

//-----------------------------------------------------------------------------
// REG_BINARY variants
//-----------------------------------------------------------------------------
inline long GetRegValue(LPCTSTR szKey, 
                        LPCTSTR szSubKey1, 
                        LPCTSTR szSubKey2,
                        LPCTSTR szValueName, 
                        BYTE *pb, DWORD *pcb)
{
    return GetRegValue(HKEY_LOCAL_MACHINE, szKey, szSubKey1, szSubKey2,
            szValueName,
            REG_BINARY, pb, pcb);
}


//-----------------------------------------------------------------------------
// REG_SZ variants
//-----------------------------------------------------------------------------
inline long GetRegValueSZ(LPCTSTR szKey, 
                          LPCTSTR szSubKey1, 
                          LPCTSTR szSubKey2,
                          LPCTSTR szValueName, 
                          TCHAR *psz, DWORD *pcb)
{
    return GetRegValue(HKEY_LOCAL_MACHINE, szKey, szSubKey1, szSubKey2,
            szValueName, REG_SZ, (BYTE *) psz, pcb);
}

//-----------------------------------------------------------------------------
// REG_DWORD variants
//-----------------------------------------------------------------------------
inline long GetRegValue(LPCTSTR szKey,      // DEF_REG_BASE
                        LPCTSTR szSubKey1,  //  second NULL
                        LPCTSTR szSubKey2,  // first NULL
                        LPCTSTR szValueName, 
                        DWORD *pdw)
{
    DWORD cb = sizeof(DWORD);

    return GetRegValue(HKEY_LOCAL_MACHINE, szKey, szSubKey1, szSubKey2,
            szValueName, REG_DWORD, (BYTE *) pdw, &cb);
}

//-----------------------------------------------------------------------------
// SetRegValue
// SetRegValueSZ
//
// Sets data into the registry.  There are numerous overloads of this function
// that basically just provide defaults for the arguments to this function.
//
// Please use the overload that defaults as much as possible.
//
// The registry key/value is a combination of the following five parts.
// The first four are the same as in OpenRegKey().
//
//   HKEY hkeyRoot
//   LPCTSTR szKey
//   LPCTSTR szSubKey1
//   LPCTSTR szSubKey2
//
//   LPCTSTR szValueName = The name of the value to be set.
//                         If it is NULL then the default value for the key
//                         will be set.
//
//                         Default: none
//
// There are four ways to specify the data to be set into the registry
// depending on the type of data being stored.
//
// REG_BINARY
//
//   BYTE *pb      = Pointer to the data.
//   DWORD cb      = Actual size of the data (in bytes).
//
// REG_SZ		(SetRegValueSZ)
//
//   TCHAR *psz    = The data is written as type REG_SZ.
//                   The length is calculated as (_tcsclen(psz) +1) * sizeof(TCHAR).
//
// REG_DWORD
//
//   DWORD dw      = The data is written as type DWORD.
//                   The length is calculated as sizeof(DWORD).
//
// All other types
//
//   DWORD dwType  = The data type.
//   BYTE *pb      = Pointer to the data.
//   DWORD cb      = Actual size of the data in bytes.
//
// Returns:
//     ERROR_SUCCESS or an error code.
//-----------------------------------------------------------------------------
long SetRegValue(HKEY hkeyRoot, LPCTSTR szKey, LPCTSTR szSubKey1,
        LPCTSTR szSubKey2, LPCTSTR szValueName,
        DWORD dwType, const BYTE *pb, DWORD cb);

//-----------------------------------------------------------------------------
// REG_BINARY variants
//-----------------------------------------------------------------------------
inline long SetRegValue(LPCTSTR szKey, LPCTSTR szSubKey1, LPCTSTR szSubKey2,
        LPCTSTR szValueName, const BYTE *pb, DWORD cb)
{
    return SetRegValue(HKEY_LOCAL_MACHINE, szKey, szSubKey1, szSubKey2,
            szValueName, REG_BINARY, pb, cb);
}

//-----------------------------------------------------------------------------
// REG_SZ variants
//-----------------------------------------------------------------------------
inline long 
SetRegValueSZ(LPCTSTR szKey,            // DEF_REG_BASE
              LPCTSTR szSubKey1,        //   or NULL(2)
              LPCTSTR szSubKey2,        //   or NULL(1)
              LPCTSTR szValueName, 
              const TCHAR *psz)
{
    return SetRegValue(HKEY_LOCAL_MACHINE,
                       szKey, szSubKey1, szSubKey2, szValueName,
                       REG_SZ, (const BYTE *) psz, (_tcsclen(psz) + 1) * sizeof(TCHAR));
}

//-----------------------------------------------------------------------------
// REG_DWORD variants
//-----------------------------------------------------------------------------
inline long SetRegValue(LPCTSTR szKey, LPCTSTR szSubKey1, LPCTSTR szSubKey2,
        LPCTSTR szValueName, DWORD dw)
{
    return SetRegValue(HKEY_LOCAL_MACHINE,
            szKey, szSubKey1, szSubKey2, szValueName,
            REG_DWORD, (BYTE *) &dw, sizeof(DWORD));
}



#endif // REGKEY_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\inc\vsplabl20.h ===
#ifndef	_VSPLABL_H
#define	_VSPLABL_H
//
// VSPWeb labels and macros
//
// 11/30/99
//

// Ignore unreferenced labels.
#pragma warning (disable : 4102)


//
// Macros for defining arrays of pointers to protected data.
//
// NOTE:
//	Vulcan will not allow enumeration of relocations with a data
//  unless it has been accessed. The macros TOUCH_SCP_DATA()
//  and TOUCH_DATA can be used to access the data without
//  altering it.
//

#define SCP_DATA(SegNum1, SegNum2, CryptMethod, Significance) \
void const *ScpProtectedData_##SegNum1##_##SegNum2##_##CryptMethod##_##Significance##_00_00

#define SCP_DATA_ARRAY(SegNum1, SegNum2, CryptMethod, Significance) \
ScpProtectedData_##SegNum1##_##SegNum2##_##CryptMethod##_##Significance##_00_00

#define	SCP_PROTECTED_DATA_LIST	"ScpProtectedData"

#define TOUCH_SCP_DATA(SegNum1, SegNum2, CryptMethod, Significance) { \
_asm	push	EAX \
_asm	lea		EAX, ScpProtectedData_##SegNum1##_##SegNum2##_##CryptMethod##_##Significance##_00_00 \
_asm	pop		EAX }

#define	TOUCH_DATA( x ) {	\
_asm	push	EAX			\
_asm	lea		EAX,x		\
_asm	pop		EAX	}


//
// Macros for defining arrays of pointers to encrypted data.
//
// If the values for Significance, Proximity, Redundance are
// all set to zero the SCP tool will treat a segment as an
// encrypted segment and will not insert random verification
// calls and instead use manually inserted labels for locations
// where calls for encryption and decryption should be inserted.
//

#define SCP_ENCRYPTED_DATA(SegNum1, SegNum2, CryptMethod) \
void const *ScpProtectedData_##SegNum1##_##SegNum2##_##CryptMethod##_0xffffffff_00_00

#define TOUCH_SCP_ENCRYPTED_DATA(SegNum1, SegNum2, CryptMethod) TOUCH_SCP_DATA(SegNum1, SegNum2, CryptMethod, 0xffffffff) 

#define	CRYPTO_PREFIX		"CRYPTO_SEGMENT_HERE"
#define ENCRYPT_DATA_PREFIX "CRYPTO_SEGMENT_HERE_ENCRYT_"
#define DECRYPT_DATA_PREFIX "CRYPTO_SEGMENT_HERE_DECRYPT_"

#define ENCRYPT_DATA( SegNum1, SegNum2, FUNCTION_UNIQUE )	CRYPTO_SEGMENT_HERE_ENCRYT_##SegNum1##_##SegNum2##_##FUNCTION_UNIQUE##:
#define DECRYPT_DATA( SegNum1, SegNum2, FUNCTION_UNIQUE )	CRYPTO_SEGMENT_HERE_DECRYPT_##SegNum1##_##SegNum2##_##FUNCTION_UNIQUE##:

#define	HARD_CODED_CLEANUP_CALL_PREFIX	"CRYPTO_CLEANUP_HERE_"
#define CRYPTO_CLEANUP( FunctionUnique ) CRYPTO_CLEANUP_HERE_##FunctionUnique: { _asm mov eax,eax }
#define HARD_CODED_CLEANUP_CALL_PREFIX_LEN 20


//
// Macros for defining verification call placement.
//

#define SCP_VERIFY_CALL_PLACEMENT(MarkerId) \
SCP_VERIFY_CALL_PLACEMENT_##MarkerId##:

//
// VSPWeb macros for verified segments outside functions
//
// New issues introduced by VC7 as used in the Whistler build environment:
//
// 1. Unlike VC6, VC7 removes all "dead" code even when compiling with /Zi
// (to produce PDBs).
//
// 2. VC7 removes duplicate functions (i.e., functions containing code
// VC7 considers identical).  Such functions need not actually be
// identical; for example, VC7 considers the following equivalent and
// throws one out:
//
// _declspec(naked) void foo() {
//   __asm lea eax, FOO_LABEL;
//   FOO_LABEL:__asm ret;
// }
//
// _declspec(naked) void bar() {
//   __asm lea eax, BAR_LABEL;
//   BAR_LABEL:__asm ret;
// }
//
// VC7 eliminates one of these despite attempts to reference them
// separately in live code; e.g., the following two instructions
// will be identical:
//  __asm cmp eax, foo;
//  __asm cmp eax, bar;
//
// The macros below were changed to handle this.  Each generated function
// now contains different code, created using the unique segment IDs of
// each segment.  Additionally, using the TOUCH_SCP_SEG_FUN macro in
// live code is now necessary to ensure VC7 keeps these functions.
//
// NOTE: This makes it easier for the cracker to locate segments by their
// IDs.  We should replace this temporary solution with something better.
//

#define BEGIN_FUNC_PREFIX       "Begin_Vspweb_Scp_Segment_"
#define BEGIN_FUNC_PREFIX_LEN   25

#define END_FUNC_PREFIX         "End_Vspweb_Scp_Segment_"
#define END_FUNC_PREFIX_LEN     23

#define BEGIN_VSPWEB_SCP_SEGMENT(SegNum1, SegNum2, CryptMethod, Significance, Proximity, Redundance) \
_declspec(naked) void Begin_Vspweb_Scp_Segment_##SegNum1##_##SegNum2() \
{ \
__asm { \
	__asm mov eax, SegNum1 \
	} \
BEGIN_SCP_SEGMENT_##SegNum1##_##SegNum2##_##CryptMethod##_##Significance##_##Proximity##_##Redundance: \
__asm { \
    __asm mov ebx, SegNum2 \
    __asm ret \
	} \
} 

#define END_VSPWEB_SCP_SEGMENT(SegNum1, SegNum2) \
_declspec(naked) void End_Vspweb_Scp_Segment_##SegNum1##_##SegNum2() \
{ \
__asm { \
	__asm mov ecx, SegNum1 \
	} \
END_SCP_SEGMENT_##SegNum1##_##SegNum2: \
__asm { \
    __asm mov edx, SegNum2 \
    __asm ret \
	} \
} 

// This macro "touches" the functions generated by the above macros,
// and must be placed somewhere within live code for each verified
// segment defined by the above.
#define TOUCH_SCP_SEG_FUN(SegNum1, SegNum2) \
  void End_Vspweb_Scp_Segment_##SegNum1##_##SegNum2(); \
  void Begin_Vspweb_Scp_Segment_##SegNum1##_##SegNum2(); \
  __asm { \
    __asm cmp eax, Begin_Vspweb_Scp_Segment_##SegNum1##_##SegNum2 \
    __asm cmp eax, End_Vspweb_Scp_Segment_##SegNum1##_##SegNum2 \
} 

#if 0
//
// some hacks to make sure some VSP library functions are included in the
// application to be protected (to avoid these functions from being dynamically
// linked)
//
// Note: These are no longer necessary because the relevant code is injected
// automatically.
//

// Put this in some source file.
#define VSPWEB_DECL_SETUP \
extern "C" { \
extern void __cdecl DoComparison01(void *, void *, int); \
extern void __cdecl DoVerification01(void *, void *, void *, void *, BYTE, BYTE, BYTE, int);  \
extern void __cdecl DoVerification02(BYTE, void *, void *, void *, void *, BYTE, BYTE, int); \
extern void __cdecl DoVerification03(void *, void *, void *, BYTE, BYTE, BYTE, int, void *); \
extern void __cdecl DoVerification04(void *, void *, void *, BYTE, BYTE, BYTE, int, void *); \
extern void __cdecl DoVerification05(void *, void *, void *, void *, BYTE, BYTE, BYTE, int); \
}

// Put this in one live function.
#define VSPWEB_SETUP \
{ \
	__asm cmp eax, DoComparison01 \
	__asm cmp ebx, DoVerification01 \
	__asm cmp ebx, DoVerification02 \
	__asm cmp ebx, DoVerification03 \
	__asm cmp ebx, DoVerification04 \
	__asm cmp ebx, DoVerification05 \
}
#endif

#define	CRYPT_METHOD_AUTO	0
#define	SCP_AUTO_MAC_LIST	"AutoCheckSums"
#define	SCP_TOTAL_AUTO_MACS	"TotalAutoCheckSums"


#endif // #indef	_VSPLABL_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\xdscodec\xdscodecprops.cpp ===
//==========================================================================;
//  XDSCodecProps.cpp
//
//			Property Sheet for XDS Codec Filter
//
// Copyright (c) 2002  Microsoft Corporation.  All Rights Reserved.
//	------------------------------------------------------------------------

#include "EncDecAll.h"
#include "EncDec.h"				//  compiled from From IDL file
#include "XDSCodec.h"			
#include "XDSCodecProps.h"

#ifdef _DEBUG
#define new DEBUG_NEW
#undef THIS_FILE
static char THIS_FILE[] = __FILE__;
#endif


//
// Filter property page code
//
CUnknown * WINAPI 
CXDSCodecProperties::CreateInstance(LPUNKNOWN lpunk, HRESULT *phr)
{
    CUnknown *punk = new CXDSCodecProperties(_T(XDS_PROPPAGE_NAME),
											  lpunk, 
											  phr);
    if (punk == NULL) {
        *phr = E_OUTOFMEMORY;
    }

    return punk;
}

CXDSCodecProperties::CXDSCodecProperties(
			IN  TCHAR		*   pClassName,
			IN	IUnknown	*	pIUnknown, 
			HRESULT			*	phr)
    : CBasePropertyPage(pClassName, 
						pIUnknown,
						IDD_XDSCODEC_PROPPAGE, 
						IDS_XDSCODEC_PROPNAME
						),
    m_hwnd(NULL),
	m_pIXDSCodec(NULL)
{
	ASSERT(phr);
	*phr = S_OK;

/*	INITCOMMONCONTROLSEX icce;					// needs Comctl32.dll
	icce.dwSize = sizeof(INITCOMMONCONTROLSEX);
	icce.dwICC = ICC_INTERNET_CLASSES;
	BOOL fOK = InitCommonControlsEx(&icce);
	if(!fOK)
		*phr = E_FAIL;
*/
	return;
}

CXDSCodecProperties::~CXDSCodecProperties()
{
	return;
}

HRESULT CXDSCodecProperties::OnConnect(IUnknown *pUnknown) 
{
	ASSERT(!m_pIXDSCodec);  // pUnk is to CCCTFilter, not CDShowCCTFilter...
    HRESULT hr = CBasePropertyPage::OnConnect (pUnknown) ;

	if(!FAILED(hr))
		hr = pUnknown->QueryInterface(IID_IXDSCodec, (void**) &m_pIXDSCodec);

	if(FAILED(hr)) {
		m_pIXDSCodec = NULL;
		return hr;
	}
	return S_OK;
}

HRESULT CXDSCodecProperties::OnDisconnect() 
{
  HRESULT hr = S_OK;
  if (m_pIXDSCodec)
	  m_pIXDSCodec->Release(); 
   m_pIXDSCodec = NULL;

   return CBasePropertyPage::OnDisconnect () ;
}

HRESULT CXDSCodecProperties::OnActivate(void)
{
   UpdateFields();
   return S_OK;
}

#define _SETBUT(buttonIDC, grfFlag)	SetDlgItemTextW(m_hwnd, (buttonIDC), (lGrfHaltFlags & (grfFlag)) ? L"Stopped" : L"Running");

void CXDSCodecProperties::UpdateFields() 
{
	if(!m_pIXDSCodec) return;		// haven't inited yet....
	
/*	long lGrfHaltFlags;
	m_pIXDSCodec->get_HaltFlags(&lGrfHaltFlags);

	NCCT_Mode lgrfCCMode;
	m_pIXDSCodec->get_CCMode(&lgrfCCMode);
*/

/*
	HWND hCBox = GetDlgItem(m_hwnd, IDC_COMBO_CCMODE);
	if(0 == hCBox)
		return;

	int iItemSelected = -1;

    SendMessage(hCBox, CB_RESETCONTENT, 0, 0);		// initalize the list

	int iItem = 0;
	if(lgrfCCMode == NCC_Mode_CC1) iItemSelected = iItem;
	SendMessage(hCBox, CB_INSERTSTRING,  -1, (LPARAM) _T("CC1"));
	SendMessage(hCBox, CB_SETITEMDATA, iItem, (LPARAM) NCC_Mode_CC1); iItem++;

	int cItems = (int) SendMessage(hCBox, CB_GETCOUNT, 0, 0);			

		// Place the word in the selection field. 
    SendMessage(hCBox,CB_SETCURSEL,	  iItemSelected<0 ? 0 : iItemSelected, 0);			// reselect the first one... (should be IPSinks!)
*/
	}

HRESULT CXDSCodecProperties::OnDeactivate(void)
{
    return CBasePropertyPage::OnDeactivate () ;
}


HRESULT CXDSCodecProperties::OnApplyChanges(void)
{
   return CBasePropertyPage::OnApplyChanges () ;
}


INT_PTR 
CXDSCodecProperties::OnReceiveMessage( HWND hwnd
                                , UINT uMsg
                                , WPARAM wParam
                                , LPARAM lParam)
{
    switch (uMsg) {

    case WM_INITDIALOG:
    {
        ASSERT (m_hwnd == NULL) ;
        m_hwnd = hwnd ;
        break;
    }

    //  see ::OnDeactivate()'s comment block
    case WM_DESTROY :
    {
        m_hwnd = NULL ;
        break ;
    }

    case WM_COMMAND:

        if (HIWORD(wParam) == EN_KILLFOCUS) {
//           m_bDirty = TRUE;
 //          if (m_pPageSite)
 //              m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
        }

/*
		if(LOWORD(wParam) == IDC_COMBO_CCMODE)
		{
			HWND hCBox = GetDlgItem(hwnd, IDC_COMBO_CCMODE);
			if(0 == hCBox)
				break;
			long iItem = SendMessage(hCBox, CB_GETCURSEL, 0, 0);
			long iVal  = SendMessage(hCBox, CB_GETITEMDATA, iItem, 0);
			if(iVal != lgrfCCMode)
			{
				NCCT_Mode cMode = (NCCT_Mode) iVal;
				m_pIXDSCodec->put_CCMode(cMode);
			}
		}
*/
    }	// end uMsg switch

   return CBasePropertyPage::OnReceiveMessage (
                                hwnd,
                                uMsg,
                                wParam,
                                lParam
                                ) ;
}

// ---------------------------------------------------------------------------
//
// Tag property page code
//
CUnknown * WINAPI 
CXDSCodecTagProperties::CreateInstance(LPUNKNOWN lpunk, HRESULT *phr)
{
    CUnknown *punk = new CXDSCodecTagProperties(_T(XDS_PROPPAGE_TAG_NAME),
											  lpunk, 
											  phr);
    if (punk == NULL) {
        *phr = E_OUTOFMEMORY;
    }

    return punk;
}

CXDSCodecTagProperties::CXDSCodecTagProperties(
			IN  TCHAR		*   pClassName,
			IN	IUnknown	*	pIUnknown, 
			HRESULT			*	phr)
    : CBasePropertyPage(pClassName, 
						pIUnknown,
						IDD_XDSCODEC_TAGSPROPPAGE, 
						IDS_XDSCODEC_TAGSPROPNAME
						),
    m_hwnd(NULL),
	m_pIXDSCodec(NULL)
{
    TRACE_CONSTRUCTOR (TEXT ("CXDSCodecTagProperties")) ;
	
	ASSERT(phr);
	*phr = S_OK;

/*	INITCOMMONCONTROLSEX icce;					// needs Comctl32.dll
	icce.dwSize = sizeof(INITCOMMONCONTROLSEX);
	icce.dwICC = ICC_INTERNET_CLASSES;
	BOOL fOK = InitCommonControlsEx(&icce);
	if(!fOK)
		*phr = E_FAIL;
*/
	return;
}


CXDSCodecTagProperties::~CXDSCodecTagProperties()
{
	return;
}

HRESULT CXDSCodecTagProperties::OnConnect(IUnknown *pUnknown) 
{
	ASSERT(!m_pIXDSCodec);
	HRESULT hr = pUnknown->QueryInterface(IID_IXDSCodec, (void**) &m_pIXDSCodec);
	if (FAILED(hr)) {
		m_pIXDSCodec = NULL;
		return hr;
	}

	return S_OK;
}

HRESULT CXDSCodecTagProperties::OnDisconnect() 
{
	if (!m_pIXDSCodec)
      return E_UNEXPECTED;
   m_pIXDSCodec->Release(); 
   m_pIXDSCodec = NULL;
   return S_OK;
}

HRESULT CXDSCodecTagProperties::OnActivate(void)
{
   UpdateFields();
   return S_OK;
}

void CXDSCodecTagProperties::UpdateFields() 
{
	HRESULT hr=S_OK;
	

	if(!m_pIXDSCodec)
		return;
/*

	CComBSTR bstrFakeStats;
	hr = m_pIXDSCodec->GetStats(&bstrFakeStats);		// hacky way to send a fixed length string
	if(FAILED(hr))
		return;

	if(NULL == bstrFakeStats.m_str)
		return;

	CCTStats *pcctStats = (CCTStats *) bstrFakeStats.m_str;

	SetDlgItemInt(m_hwnd, IDC_TS_CB0,					pcctStats->m_cbData[0],	true);
	SetDlgItemInt(m_hwnd, IDC_TS_CB1,					pcctStats->m_cbData[1],	true);

*/
}

HRESULT CXDSCodecTagProperties::OnDeactivate(void)
{
	return S_OK;
}


HRESULT CXDSCodecTagProperties::OnApplyChanges(void)
{
	return S_OK;
}


INT_PTR CXDSCodecTagProperties::OnReceiveMessage( HWND hwnd
                                , UINT uMsg
                                , WPARAM wParam
                                , LPARAM lParam)
{
	HRESULT hr = S_OK;

    switch (uMsg) {
    case WM_INITDIALOG:
    {
        ASSERT (m_hwnd == NULL) ;
        m_hwnd = hwnd ;
        const UINT uWait = 1000;
        SetTimer(m_Dlg, 1, uWait, NULL);
        break;
    }

    //  see ::OnDeactivate()'s comment block
    case WM_DESTROY :
    {
        m_hwnd = NULL;
        KillTimer(m_Dlg, 1);
        break ;
    }

    case WM_TIMER:
    {
        UpdateFields();
        break;
    }

    case WM_COMMAND:
	{
        if (HIWORD(wParam) == EN_KILLFOCUS) {
		}

/*		if(LOWORD(wParam) == IDC_ETTAGS_RESET)
		{

			if(!m_pIXDSCodec)
				break;

			try {
				hr = m_pIXDSCodec->InitStats();		// set them all to zero...
			}
			catch(const _com_error& e)
			{
			//	printf("Error 0x%08x): %s\n", e.Error(), e.ErrorMessage());
				hr = e.Error();
			}

			if(!FAILED(hr))
				UpdateFields();
		}
*/
		break;
	}

	default:
		break;

	}
	return CBasePropertyPage::OnReceiveMessage (
                                hwnd,
                                uMsg,
                                wParam,
                                lParam
                                ) ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\encdec\xdscodec\xdscodec.cpp ===
/*++

    Copyright (c) 2002 Microsoft Corporation

    Module Name:

        XDSCodec.cpp

    Abstract:

        This module contains the Encrypter/Tagger filter code.

    Author:

        J.Bradstreet (johnbrad)

    Revision History:

        07-Mar-2002    created

--*/

#include "EncDecAll.h"

//#include "XDSCodecutil.h"
#include "XDSCodec.h"
#include <bdaiface.h>

#include "PackTvRat.h"      

#ifdef EHOME_WMI_INSTRUMENTATION
#include <dxmperf.h>
#endif

//  disable so we can use 'this' in the initializer list
#pragma warning (disable:4355)

#ifdef _DEBUG
#define new DEBUG_NEW
#undef THIS_FILE
static char THIS_FILE[] = __FILE__;
#endif
//  ============================================================================

//  ============================================================================

AMOVIESETUP_MEDIATYPE g_sudXDSCodecInType  =
{
    &MEDIATYPE_AUXLine21Data,       // MajorType (KSDATAFORMAT_TYPE_AUXLine21Data)
    &MEDIASUBTYPE_NULL              // MinorType (KSDATAFORMAT_SUBTYPE_Line21_BytePair)
} ;


AMOVIESETUP_PIN
g_sudXDSCodecPins[] =
{
    {
        _TEXT(XDS_INPIN_NAME),          // pin name
        TRUE,                           // bRendered
        FALSE,                          // bOutput
        FALSE,                          // bZero,
        FALSE,                          // bMany,
        &CLSID_NULL,                    // clsConnectsToFilter (CCDecoder filter)
        L"CC",                          // strConnectsToPin
        1,                              // nTypes
        &g_sudXDSCodecInType            // lpTypes
    }
};

AMOVIESETUP_FILTER
g_sudXDSCodec = {
        &CLSID_XDSCodec,
        _TEXT(XDS_CODEC_NAME),
        MERIT_DO_NOT_USE,
        1,                              //  1 pin registered
        g_sudXDSCodecPins
};

//  ============================================================================
CUnknown *
WINAPI
CXDSCodec::CreateInstance (
    IN   IUnknown * punkControlling,
    OUT  HRESULT *   phr
    )
{
    CXDSCodec *    pCXDSCodec ;

    if (true /*::CheckOS ()*/)
    {
        pCXDSCodec = new CXDSCodec (
                                TEXT(XDS_CODEC_NAME),
                                punkControlling,
                                CLSID_XDSCodec,
                                phr
                                ) ;
        if (!pCXDSCodec ||
            FAILED (* phr))
        {

            (* phr) = (FAILED (* phr) ? (* phr) : E_OUTOFMEMORY) ;
            delete pCXDSCodec; pCXDSCodec=NULL;
        }


                // try to create the XDS parser here.
    }
    else {
        //  wrong OS
        pCXDSCodec = NULL ;
    }


    ASSERT (SUCCEEDED (* phr)) ;

    return pCXDSCodec ;

}

//  ============================================================================

CXDSCodecInput::CXDSCodecInput (
    IN  TCHAR *         pszPinName,
    IN  CXDSCodec *  pXDSCodec,
    IN  CCritSec *      pFilterLock,
    OUT HRESULT *       phr
    ) : CBaseInputPin       (NAME ("CXDSCodecInput"),
                             pXDSCodec,
                             pFilterLock,
                             phr,
                             pszPinName
                             ),
    m_pHostXDSCodec   (pXDSCodec)
{
    TRACE_CONSTRUCTOR (TEXT ("CXDSCodecInput")) ;
}


HRESULT
CXDSCodecInput::GetMediaType(
            IN int  iPosition,
            OUT CMediaType *pMediaType
            )
{
    ASSERT(m_pHostXDSCodec);

    HRESULT hr;
    hr = m_pHostXDSCodec->GetXDSMediaType (PINDIR_INPUT, iPosition, pMediaType) ;
    

    return hr;
}

HRESULT
CXDSCodecInput::StreamingLock ()      // always grab the PinLock before the Filter lock...
{
    m_StreamingLock.Lock();
    return S_OK;
}

HRESULT
CXDSCodecInput::StreamingUnlock ()
{
    m_StreamingLock.Unlock();
    return S_OK;
}


HRESULT
CXDSCodecInput::CheckMediaType (
    IN  const CMediaType *  pmt
    )
{
    BOOL    f ;
    ASSERT(m_pHostXDSCodec);

    f = m_pHostXDSCodec -> CheckXDSMediaType (m_dir, pmt) ;


    return (f ? S_OK : S_FALSE) ;
}

HRESULT
CXDSCodecInput::CompleteConnect (
    IN  IPin *  pIPin
    )
{
    HRESULT hr ;
    TRACE_0(LOG_AREA_XDSCODEC, 5, "CXDSCodecInput::CompleteConnect");

    hr = CBaseInputPin::CompleteConnect (pIPin) ;
    if (SUCCEEDED (hr)) {
        hr = m_pHostXDSCodec -> OnCompleteConnect (m_dir) ;

        int cBuffers  = 32;
        int cbBuffers = 10;     // should only need 2 bytes here...
        if(!FAILED(hr)) hr = SetNumberBuffers(cBuffers,cbBuffers,4,6);      // align, cbPrefix
    } else {
        TRACE_0(LOG_AREA_XDSCODEC, 2, _T("CXDSCodecInput::CompleteConnect - Failed to connect"));
    }


    return hr ;
}

HRESULT
CXDSCodecInput::BreakConnect (
    )
{
    HRESULT hr ;
    TRACE_0(LOG_AREA_XDSCODEC, 5, "CXDSCodecInput::BreakConnect");

    hr = CBaseInputPin::BreakConnect () ;
    if (SUCCEEDED (hr)) {
        hr = m_pHostXDSCodec -> OnBreakConnect (m_dir) ;
    }

    return hr ;
}

HRESULT
CXDSCodecInput::SetAllocatorProperties (
    IN  ALLOCATOR_PROPERTIES *  ppropInputRequest
    )
{
    HRESULT hr ;

    if (IsConnected ()) {
        ASSERT (m_pAllocator) ;
        hr = m_pAllocator -> GetProperties (ppropInputRequest) ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    return hr ;
}

STDMETHODIMP
CXDSCodecInput::Receive (
    IN  IMediaSample * pIMediaSample
    )
{
    HRESULT hr ;

    {
        CAutoLock  cLock(&m_StreamingLock);       // we want this streaming lock here!

#ifdef EHOME_WMI_INSTRUMENTATION
        PERFLOG_STREAMTRACE( 1, PERFINFO_STREAMTRACE_ENCDEC_XDSCODECINPUT,
            0, 0, 0, 0, 0 );
#endif
        hr = CBaseInputPin::Receive (pIMediaSample) ;

        if (S_OK == hr)         // Receive returns S_FALSE if flushing...
        {
            hr = m_pHostXDSCodec -> Process (pIMediaSample) ;
        }
    }

    return hr ;
}

STDMETHODIMP
CXDSCodecInput::BeginFlush (
    )
{
    HRESULT hr = S_OK;
    CAutoLock  cLock(m_pLock);           // grab the filter lock..

  // First, make sure the Receive method will fail from now on.
    hr = CBaseInputPin::BeginFlush () ;
    if( FAILED( hr ) )
    {
        return hr;
    }

    // There aren't any  downstream filters to release samples. So we
    // won't need to flush anything...

    // At this point, the Receive method can't be blocked. Make sure
    // it finishes, by taking the streaming lock. (Not necessary if this
    // is the last step.)
    {
        CAutoLock  cLock2(&m_StreamingLock);
    }

    return hr ;
}

STDMETHODIMP
CXDSCodecInput::EndFlush (
    )
{
    HRESULT hr ;

    CAutoLock  cLock(m_pLock);                  // grab the filter lock


/*    if (SUCCEEDED (hr)) {                    // no output pins, no need to call
        hr = m_pHostXDSCodec -> DeliverEndFlush () ;
    }
*/
        // The CBaseInputPin::EndFlush method resets the m_bFlushing flag to FALSE,
        // which allows the Receive method to start receiving samples again.
        // This should be the last step in EndFlush, because the pin must not receive any
        // samples until flushing is complete and all downstream filters are notified.

    hr = CBaseInputPin::EndFlush () ;

    return hr ;
}



HRESULT 
CXDSCodecInput::SetNumberBuffers(long cBuffers,long cbBuffer,long cbAlign, long cbPrefix)
{
    TRACE_0(LOG_AREA_XDSCODEC, 5, "CXDSCodecInput::SetNumberBuffers");
    HRESULT hr = S_OK;
    
    ALLOCATOR_PROPERTIES aPropsReq, aPropsActual;
    aPropsReq.cBuffers = cBuffers;
    aPropsReq.cbBuffer = cbBuffer;
    aPropsReq.cbAlign  = cbAlign;
    aPropsReq.cbPrefix = cbPrefix;

    IMemAllocator *pAllocator = NULL;
    hr = GetAllocator(&pAllocator);

    if(NULL == pAllocator) return E_NOINTERFACE;
    if(FAILED(hr)) return hr;
    
    hr = pAllocator->SetProperties(&aPropsReq, &aPropsActual);
    if(pAllocator)
        pAllocator->Release();

    return hr;
}
//  ============================================================================

//  ============================================================================

CXDSCodec::CXDSCodec (
    IN  TCHAR *     pszFilterName,
    IN  IUnknown *  punkControlling,
    IN  REFCLSID    rCLSID,
    OUT HRESULT *   phr
    ) : CBaseFilter (pszFilterName,
                     punkControlling,
                     new CCritSec,
                     rCLSID
                     ),
         m_pInputPin                    (NULL),
         m_dwBroadcastEventsCookie      (kBadCookie),
         m_cTvRatPktSeq                 (0),
         m_cTvRatCallSeq                (0),
         m_cXDSPktSeq                   (0),
         m_cXDSCallSeq                  (0),
         m_dwSubStreamMask              (KS_CC_SUBSTREAM_SERVICE_XDS),
         m_TvRating                     (0),
         m_XDSClassPkt                  (0),
         m_XDSTypePkt                   (0),
         m_hrXDSToRatCoCreateRetValue   (CLASS_E_CLASSNOTAVAILABLE),
         m_fJustDiscontinuous           (false),
         m_TimeStartRatPkt              (0),
         m_TimeEndRatPkt                (0),
         m_TimeStartXDSPkt              (0),
         m_TimeEndXDSPkt                (0),
         m_TimeStart_LastPkt            (0),
         m_TimeEnd_LastPkt              (0)
{
     LONG                i ;

    TRACE_CONSTRUCTOR (TEXT ("CXDSCodec")) ;

    if (!m_pLock) {
        (* phr) = E_OUTOFMEMORY ;
        goto cleanup ;
    }

    InitStats();

    m_pInputPin = new CXDSCodecInput (
                        TEXT (XDS_INPIN_NAME),
                        this,
                        m_pLock,
                        phr
                        ) ;
    if (!m_pInputPin ||
        FAILED (* phr)) {

        (* phr) = (m_pInputPin ? (* phr) : E_OUTOFMEMORY) ;
        goto cleanup ;
    }


                // attempt to create the 3rd party ratings parser

    try {
        m_hrXDSToRatCoCreateRetValue =
            CoCreateInstance(CLSID_XDSToRat,        // CLSID
                             NULL,                  // pUnkOut
                             CLSCTX_INPROC_SERVER,
                             IID_IXDSToRat,     // riid
                             (LPVOID *) &m_spXDSToRat);

    } catch (HRESULT hr) {
        m_hrXDSToRatCoCreateRetValue = hr;
    }

    TRACE_1(LOG_AREA_XDSCODEC, 2, _T("CXDSCodec::CoCreate XDSToRat object - hr = 0x%08x"),m_hrXDSToRatCoCreateRetValue) ;

//  HRESULT hr = RegisterForBroadcastEvents();  // don't really care if fail here,  try in Connect if haven't

    //  success
    ASSERT (SUCCEEDED (* phr)) ;
    ASSERT (m_pInputPin) ;

cleanup :

    return ;
}

CXDSCodec::~CXDSCodec (
    )
{
    delete m_pInputPin ;    m_pInputPin = NULL;
    delete m_pLock;         m_pLock = NULL;
}

STDMETHODIMP
CXDSCodec::NonDelegatingQueryInterface (
    IN  REFIID  riid,
    OUT void ** ppv
    )
{

        // IXDSCodec :allows the filter to be configured...
    if (riid == IID_IXDSCodec) {

        return GetInterface (
                    (IXDSCodec *) this,
                    ppv
                    ) ;

        // IXDSCodecConfig :allows the filter to be configured...
   } else if (riid == IID_IXDSCodecConfig) {    
        return GetInterface (
                    (IXDSCodecConfig *) this,
                    ppv
                    ) ;

        // ISpecifyPropertyPages: allows an app to enumerate property pages
    } else if (riid == IID_ISpecifyPropertyPages) {

        return GetInterface (
                    (ISpecifyPropertyPages *) this,
                    ppv
                    ) ;

        // IBroadcastEvents: allows the filter to receive events broadcast
        //                   from XDS and Tuner filters
    } else if (riid == IID_IBroadcastEvent) {

        return GetInterface (
                    (IBroadcastEvent *) this,
                    ppv
                    ) ;

    }

    return CBaseFilter::NonDelegatingQueryInterface (riid, ppv) ;
}

int
CXDSCodec::GetPinCount ( )
{
    int i ;

    i = 1;          // just 1 pin

    return i ;
}

CBasePin *
CXDSCodec::GetPin (
    IN  int iIndex
    )
{
    CBasePin *  pPin ;

    if (iIndex == 0) {
        pPin = m_pInputPin ;
    }
    else
    {
        pPin = NULL ;
    }

    return pPin ;
}

BOOL
CXDSCodec::CompareConnectionMediaType_ (
    IN  const AM_MEDIA_TYPE *   pmt,
    IN  CBasePin *              pPin
    )
{
    BOOL        f ;
    HRESULT     hr ;
    CMediaType  cmtConnection ;
    CMediaType  cmtCompare ;

    ASSERT (pPin -> IsConnected ()) ;

    hr = pPin -> ConnectionMediaType (& cmtConnection) ;
    if (SUCCEEDED (hr)) {
        cmtCompare = (* pmt) ;
        f = (cmtConnection == cmtCompare ? TRUE : FALSE) ;
    }
    else {
        f = FALSE ;
    }

    return f ;
}

HRESULT
CXDSCodec::GetXDSMediaType (
    IN  PIN_DIRECTION       PinDir,
    int iPosition,
    OUT CMediaType *  pmt
    )
{
    if(NULL == pmt)
        return E_POINTER;

    if(iPosition > 0)
        return VFW_S_NO_MORE_ITEMS;

    if (PinDir == PINDIR_INPUT)
    {
        CMediaType cmt(&KSDATAFORMAT_TYPE_AUXLine21Data);
        cmt.SetSubtype(&KSDATAFORMAT_SUBTYPE_Line21_BytePair);
        *pmt = cmt;
        return S_OK;
    }

    return S_FALSE ;
}

BOOL
CXDSCodec::CheckInputMediaType_ (
    IN  const AM_MEDIA_TYPE *   pmt
    )
{
    BOOL    f = true;
    HRESULT hr = S_OK;

    if (KSDATAFORMAT_TYPE_AUXLine21Data      == pmt->majortype &&
        KSDATAFORMAT_SUBTYPE_Line21_BytePair == pmt->subtype)
        return true;
    else
        return false;
}


BOOL
CXDSCodec::CheckXDSMediaType (
                              IN  PIN_DIRECTION       PinDir,
                              IN  const CMediaType *  pmt
                              )
{
    BOOL    f  = false;

    if (PinDir == PINDIR_INPUT) {
        f = CheckInputMediaType_ (pmt) ;
    }

    return f ;
}

STDMETHODIMP
CXDSCodec::Pause (
                  )
{
    HRESULT                 hr ;
    ALLOCATOR_PROPERTIES    AllocProp ;

    O_TRACE_ENTER_0 (TEXT("CXDSCodec::Pause ()")) ;

    CAutoLock  cLock(m_pLock);          // grab the filter lock...

    int start_state = m_State;
    hr = CBaseFilter::Pause () ;

    if (start_state == State_Stopped) {
        TRACE_0(LOG_AREA_XDSCODEC, 2,L"CXDSCodec:: Stop -> Pause");
        if (SUCCEEDED (hr)) {
        }

      InitStats();
      m_fJustDiscontinuous = false;

    } else {
        TRACE_0(LOG_AREA_XDSCODEC, 2,L"CXDSCodec:: Run -> Pause");

        TRACE_3(LOG_AREA_TIME, 3, L"CXDSCodec:: Stats: %d XDS samples %d Ratings, %d Parse Failures",
            m_cPackets, m_cRatingsDetected, m_cRatingsFailures);

        TRACE_4(LOG_AREA_TIME, 3, L"                   %d Changed %d Duplicate Ratings, %d Unrated, %d Data Pulls",
            m_cRatingsChanged, m_cRatingsDuplicate, m_cUnratedChanged, m_cRatingsGets);

    }

    m_TimeStart_LastPkt = 0;        // just for safety, reinit these
    m_TimeEnd_LastPkt = 0;          //  (someone will probably find this isn't right)

    return hr ;
}


STDMETHODIMP
CXDSCodec::Stop (
                  )
{
    HRESULT                 hr ;

    O_TRACE_ENTER_0 (TEXT("CXDSCodec::Stop ()")) ;

    TRACE_0(LOG_AREA_ENCRYPTER, 2,L"CXDSCodec:: Stop");
    hr = CBaseFilter::Stop() ;

    // Make sure the streaming thread has returned from IMemInputPin::Receive(), IPin::EndOfStream() and
    // IPin::NewSegment() before returning,
    m_pInputPin->StreamingLock();
    m_pInputPin->StreamingUnlock();

    return hr;
}


HRESULT
CXDSCodec::Process (
                    IN  IMediaSample *  pIMediaSample
                    )
{

    HRESULT hr = S_OK;

    if(pIMediaSample == NULL)
        return E_POINTER;

    pIMediaSample->GetTime(&m_TimeStart_LastPkt, &m_TimeEnd_LastPkt);

    if(S_OK == pIMediaSample->IsDiscontinuity())
    {
        if(!m_fJustDiscontinuous)    // latch value to reduce effects of sequential Discontinuity samples
        {                            // (they occur on every sample when VBI even field doesn't contain CC data)

            TRACE_0(LOG_AREA_XDSCODEC,  3, _T("CXDSCodec::Process - Discontinuity"));

            ResetToDontKnow(pIMediaSample);     // reset and kick off event
            m_fJustDiscontinuous = true;
        }
        return S_OK;    
    } else {
        m_fJustDiscontinuous = false;
    }

    if(pIMediaSample->GetActualDataLength() == 0)       // no data
        return S_OK;

    if(pIMediaSample->GetActualDataLength() != 2)
    {
        TRACE_1(LOG_AREA_XDSCODEC,  2,
            _T("CXDSCodec:: Unexpected Length of CC data (%d != 2 bytes)"),
            pIMediaSample->GetActualDataLength() );
        return E_UNEXPECTED;
    }

    PBYTE pbData;
    hr = pIMediaSample->GetPointer(&pbData);
    if (FAILED(hr))
    {
        TRACE_1(LOG_AREA_XDSCODEC,  3,   _T("CXDSCodec:: Empty Buffer for CC data, hr = 0x%08x"),hr);
        return hr;
    }

    BYTE byte0 = pbData[0];
    BYTE byte1 = pbData[1];
    DWORD dwType = 0;                   // todo - default to some useful value

    // todo - parse the data
    //        then send messages whe we get something interesting

#if xxxDEBUG
    static int cCalls = 0;
    TCHAR szBuff[256];
    _stprintf(szBuff, _T("0x%08x 0x%02x 0x%02x (%c %c)\n"),
        cCalls++, byte0&0x7f, byte1&0x7f,
        isprint(byte0&0x7f) ? byte0&0x7f : '?',
        isprint(byte1&0x7f) ? byte1&0x7f : '?' );
    OutputDebugString(szBuff);
#endif
    // strip off the high bit...
    ParseXDSBytePair(pIMediaSample, byte0 & 0x7f, byte1 & 0x7f);

    return hr ;
}




HRESULT
CXDSCodec::OnCompleteConnect (
                              IN  PIN_DIRECTION   PinDir
                              )
{
    if (PinDir == PINDIR_INPUT) {
        //  time to display the output pin
        // IncrementPinVersion () ;

        // say we only want the XDS channel
        //      SetSubstreamChannel(KS_CC_SUBSTREAM_SERVICE_XDS);

        SetSubstreamChannel(m_dwSubStreamMask);

        if(kBadCookie == m_dwBroadcastEventsCookie)
        {
            HRESULT hr;
            hr = RegisterForBroadcastEvents();  // shouldn't fail here,
        }
    }

    return S_OK ;
}

HRESULT
CXDSCodec::OnBreakConnect (
                           IN  PIN_DIRECTION   PinDir
                           )
{
    HRESULT hr = S_OK ;

    if (PinDir == PINDIR_INPUT) {
        IncrementPinVersion () ;
    }

    if(kBadCookie != m_dwBroadcastEventsCookie)
        UnRegisterForBroadcastEvents();

    UnhookGraphEventService();      // must do here since need graph pointer, can't do in destructor

    return  hr;
}

HRESULT
CXDSCodec::UpdateAllocatorProperties (
    IN  ALLOCATOR_PROPERTIES *  ppropInputRequest
    )
{
    HRESULT hr ;

    if (m_pInputPin -> IsConnected ()) {
        hr = m_pInputPin -> SetAllocatorProperties (ppropInputRequest) ;
    }
    else {
        hr = S_OK ;
    }

    return hr ;
}

HRESULT
CXDSCodec::DeliverBeginFlush (
    )
{
    HRESULT hr = S_OK ;     // do nothing, should remove

    return hr ;
}

HRESULT
CXDSCodec::DeliverEndFlush (
    )
{
    HRESULT hr = S_OK;

    return hr ;
}


// ------------------------------------
STDMETHODIMP
CXDSCodec::GetPages (
    CAUUID * pPages
    )
{

    HRESULT hr = S_OK;

#ifdef _DEBUG
        pPages->cElems = 2 ;
#else
        pPages->cElems = 1 ;
#endif
        pPages->pElems = (GUID *) CoTaskMemAlloc(pPages->cElems * sizeof GUID) ;

        if (pPages->pElems == NULL)
        {
            pPages->cElems = 0;
            return E_OUTOFMEMORY;
        }
        if(pPages->cElems > 0)
            (pPages->pElems)[0] = CLSID_XDSCodecProperties;
        if(pPages->cElems > 1)
            (pPages->pElems)[1] = CLSID_XDSCodecTagProperties;

    return hr;
}


typedef struct
{
    KSPROPERTY                          m_ksThingy;
    VBICODECFILTERING_CC_SUBSTREAMS     ccSubStreamMask;
} KSPROPERTY_VBICODECFILTERING_CC_SUBSTREAMS;

// dwFiltType is bitfield made up of:
//  KS_CC_SUBSTREAM_SERVICE_CC1, _CC2,_CC3, _CC4,  _T1, _T2, _T3 _T4 And/Or _XDS;

HRESULT
CXDSCodec::SetSubstreamChannel(DWORD dwSubStreamChannels)
{
    TRACE_0(LOG_AREA_XDSCODEC,  5, _T("CXDSCodec::SetSubstreamChannel"));
    HRESULT hr;

    // -- wonder if I should do this here:  CAutoLock  cLock(m_pLock);

    if(0 != (dwSubStreamChannels &
              ~(KS_CC_SUBSTREAM_SERVICE_CC1 |
                KS_CC_SUBSTREAM_SERVICE_CC2 |
                KS_CC_SUBSTREAM_SERVICE_CC3 |
                KS_CC_SUBSTREAM_SERVICE_CC4 |
                KS_CC_SUBSTREAM_SERVICE_T1 |
                KS_CC_SUBSTREAM_SERVICE_T2 |
                KS_CC_SUBSTREAM_SERVICE_T3 |
                KS_CC_SUBSTREAM_SERVICE_T4 |
                KS_CC_SUBSTREAM_SERVICE_XDS)))
        return E_INVALIDARG;

    try {

        IPin *pPinCCDecoder;
        hr = m_pInputPin->ConnectedTo(&pPinCCDecoder);      
        if(FAILED(hr))
            return hr;
        if(NULL == pPinCCDecoder)
            return S_FALSE;

        PIN_INFO pinInfo;
        hr = pPinCCDecoder->QueryPinInfo(&pinInfo);
        if (SUCCEEDED(hr)) {
            
            IBaseFilter *pFilt = pinInfo.pFilter;
            
            // Triggers are just on the T2 stream of closed captioning.
            //  Tell the nice CC filter to only give us that stream out of the 9 possible

            
            IKsPropertySet *pksPSet = NULL;

            HRESULT hr2 = pPinCCDecoder->QueryInterface(IID_IKsPropertySet, (void **) &pksPSet);
            if(!FAILED(hr2))
            {
                DWORD rgdwData[20];
                DWORD cbMax = sizeof(rgdwData);
                DWORD cbData;
                hr2 = pksPSet->Get(KSPROPSETID_VBICodecFiltering,
                                    KSPROPERTY_VBICODECFILTERING_SUBSTREAMS_DISCOVERED_BIT_ARRAY,
                                    NULL, 0,
                                    (BYTE *) rgdwData, cbMax, &cbData);
                if(FAILED(hr2))
                {
                    TRACE_1(LOG_AREA_XDSCODEC,  1,
                            _T("CXDSCodec::SetSubstreamChannel  Error Getting CC Filtering, hr = 0x%08x"),hr2);
                    return hr2;
                }

                
                TRACE_1(LOG_AREA_XDSCODEC, 3,
                          _T("CXDSCodec::SetSubstreamChannel  Setting CC Filtering to 0x%04x"),dwSubStreamChannels );


                KSPROPERTY_VBICODECFILTERING_CC_SUBSTREAMS ksThing = {0};
                ksThing.ccSubStreamMask.SubstreamMask = dwSubStreamChannels;
                                                                        // ring3 to ring0 propset call
                hr2 = pksPSet->Set(KSPROPSETID_VBICodecFiltering,
                                     KSPROPERTY_VBICODECFILTERING_SUBSTREAMS_REQUESTED_BIT_ARRAY,
                                     &ksThing.ccSubStreamMask,
                                     sizeof(ksThing) - sizeof(KSPROPERTY),
                                     &ksThing,
                                     sizeof(ksThing));
            
                if(FAILED(hr2))
                {
                    TRACE_1(LOG_AREA_XDSCODEC,  1,
                            _T("CXDSCodec:: Error Setting CC Filtering, hr = 0x%08x"),hr2);
                }

            } else {
                TRACE_1(LOG_AREA_XDSCODEC,  1,
                        _T("CXDSCodec:: Error Getting CC's IKsPropertySet, hr = 0x%08x"),hr2);

            }
            if(pksPSet)
                pksPSet->Release();

            if(pinInfo.pFilter)
                pinInfo.pFilter->Release();
        }
    } catch (HRESULT hrCatch) {
        TRACE_1(LOG_AREA_XDSCODEC,  1,
                  _T("CXDSCodec::SetSubstreamChannel Threw Badly - (hr=0x%08x) Giving Up"),hrCatch );
        hr = hrCatch;
    } catch (...) {
        TRACE_0(LOG_AREA_XDSCODEC,  1,
                  _T("CXDSCodec::SetSubstreamChannel Threw Badly - Giving Up") );

        hr = E_FAIL;
    }

    return hr;
}



//  -------------------------------------------------------------------
//  helper methods
//  -------------------------------------------------------------------
BOOL
CXDSCodec::IsInputPinConnected()
{
    if(NULL == m_pInputPin) return false;

    IPin *pPinCCDecoder;
    HRESULT hr = m_pInputPin->ConnectedTo(&pPinCCDecoder);      
    if(FAILED(hr))
        return false;
    if(NULL == pPinCCDecoder)
        return false;

    // eventually more here to detect if it's connected to the CCDecoder

    return true;
}


        // Saves state and sends events...
        //   assumes calling code is blocking duplicate packets

HRESULT
CXDSCodec::GoNewXDSRatings(IMediaSample * pMediaSample,  PackedTvRating TvRating)
{

#ifdef DEBUG
    {
        //  4) store nice unpacked version of it too
        EnTvRat_System              enSystem;
        EnTvRat_GenericLevel        enLevel;
        LONG                        lbfEnAttrs;

        UnpackTvRating(TvRating, &enSystem, &enLevel, &lbfEnAttrs);

        TCHAR tbuff[128];
        tbuff[0] = 0;
        static int cCalls = 0;

        REFERENCE_TIME tStart=0, tEnd=0;
        if(NULL != pMediaSample)
            pMediaSample->GetTime(&tStart, &tEnd);

        RatingToString(enSystem, enLevel, lbfEnAttrs, tbuff, sizeof(tbuff)/sizeof(tbuff[0]));
        TRACE_3(LOG_AREA_XDSCODEC, 3,  L"CXDSCodec::GoNewXDSRatings. Rating %s, Seq (%d), time %d msec",
            tbuff, m_cTvRatPktSeq+1, tStart);

                    // extra doc
//      _tcsncat(tbuff,L"\n",sizeof(tbuff)/sizeof(tbuff[0]) - _tcslen(tbuff));
//      OutputDebugString(tbuff);
    }
#endif

        // copy all the values
   {
        CAutoLock cLock(&m_PropertyLock);    // lock these
        m_TvRating = TvRating;
        
            // increment our sequence counts
        m_cTvRatPktSeq++;
        m_cTvRatCallSeq = 0;

            // save the times (if can't get a media time due to Happauge bug, try our best to approximate it)
        if(NULL == pMediaSample ||
            S_OK != pMediaSample->GetTime(&m_TimeStartRatPkt, &m_TimeEndRatPkt))
        {
            // current time w.r.t. base time (m_tStart)
            REFERENCE_TIME refTimeNow=0;
            HRESULT hr2 = m_pClock->GetTime(&refTimeNow);

            if(S_OK == hr2)
            {
                m_TimeStartRatPkt = refTimeNow - m_tStart;          // fake a time
                m_TimeEndRatPkt   = m_TimeStartRatPkt + 10000;
            }
            else        // couldn't even fake it...
            {
                m_TimeStartRatPkt = m_TimeStart_LastPkt;
                m_TimeEndRatPkt   = m_TimeEnd_LastPkt;
            }
        }
   }

        // signal the broadcast events
    HRESULT hr = FireBroadcastEvent(EVENTID_XDSCodecNewXDSRating);
    return S_OK;
}

HRESULT
CXDSCodec::GoDuplicateXDSRatings(IMediaSample * pMediaSample,  PackedTvRating TvRating)
{

#ifdef DEBUG
    {
        //  4) store nice unpacked version of it too
        EnTvRat_System              enSystem;
        EnTvRat_GenericLevel        enLevel;
        LONG                        lbfEnAttrs;

        UnpackTvRating(TvRating, &enSystem, &enLevel, &lbfEnAttrs);

        TCHAR tbuff[128];
        tbuff[0] = 0;
        static int cCalls = 0;

        REFERENCE_TIME tStart=0, tEnd=0;
        if(NULL != pMediaSample)
            pMediaSample->GetTime(&tStart, &tEnd);

        RatingToString(enSystem, enLevel, lbfEnAttrs, tbuff, sizeof(tbuff)/sizeof(tbuff[0]));
        TRACE_3(LOG_AREA_XDSCODEC, 6,  L"CXDSCodec::GoDuplicateXDSRatings. Rating %s, Seq (%d), time %d msec",
            tbuff, m_cTvRatPktSeq+1, tStart);

                    // extra doc
//      _tcsncat(tbuff,L"\n",sizeof(tbuff)/sizeof(tbuff[0]) - _tcslen(tbuff));
//      OutputDebugString(tbuff);
    }
#endif

        // copy all the values
   {
        CAutoLock cLock(&m_PropertyLock);    // lock these
        ASSERT(m_TvRating == TvRating);      // assert it's really a duplicate
        
            // increment our sequence counts
//      m_cTvRatPktSeq++;
//      m_cTvRatCallSeq = 0;

        REFERENCE_TIME tStart;

            // save the end time (if can't get a media time due to Happauge bug, try our best to approximate it)
        if(NULL == pMediaSample ||
            S_OK != pMediaSample->GetTime(&tStart, &m_TimeEndRatPkt))
        {
            // current time w.r.t. base time (m_tStart)
            REFERENCE_TIME refTimeNow=0;
            HRESULT hr2 = m_pClock->GetTime(&refTimeNow);

            if(S_OK == hr2)
            {
//                m_TimeStartRatPkt = refTimeNow - m_tStart;          // fake a time
                m_TimeEndRatPkt   = m_TimeStartRatPkt + 10000;
            }
            else        // couldn't even fake it...
            {
//                m_TimeStartRatPkt = m_TimeStart_LastPkt;
                m_TimeEndRatPkt   = m_TimeEnd_LastPkt;
            }
        }
   }

        // signal the broadcast events
    HRESULT hr = FireBroadcastEvent(EVENTID_XDSCodecDuplicateXDSRating);
    return S_OK;
}


HRESULT
CXDSCodec::GoNewXDSPacket(IMediaSample * pMediaSample, long pktClass, long pktType, BSTR bstrXDSPkt)
{
        // copy all the values
    {
        CAutoLock cLock(&m_PropertyLock);    // lock these
        m_XDSClassPkt = pktClass;
        m_XDSTypePkt = pktType;
        m_spbsXDSPkt = bstrXDSPkt;      // Question, should copy here?

            // increment our sequence counts
        m_cXDSPktSeq++;
        m_cXDSCallSeq = 0;

            // save the times
        if(pMediaSample)
            pMediaSample->GetMediaTime(&m_TimeStartXDSPkt, &m_TimeEndXDSPkt);
        else {
            m_TimeStartXDSPkt = 0;
            m_TimeEndXDSPkt = 0;
        }
    }

        // signal the broadcast events
        // TODO - write this code

    return S_OK;
}


            // doesn't actually parse, calls the XDSToRat object to do the work.
HRESULT
CXDSCodec::ParseXDSBytePair(IMediaSample *  mediaSample,
                            BYTE byte1,
                            BYTE byte2)
{
    HRESULT hr = S_OK;

    m_cPackets++;

        // call the 3rd party parser...
    if(m_spXDSToRat != NULL)
    {
        EnTvRat_System          enSystem;
        EnTvRat_GenericLevel    enLevel;
        LONG                    lbfAttrs; // BfEnTvRat_GenericAttributes

        BYTE byte1M = byte1 & 0x7f; // strip off parity bit (should we check it?)
        BYTE byte2M = byte2 & 0x7f;
        TRACE_4 (LOG_AREA_XDSCODEC, 9,  _T("CXDSCodec::ParseXDSBytePair : 0x%02x 0x%02x (%c %c)"),
            byte1M, byte2M,
            isprint(byte1M) ? byte1M : '?',
            isprint(byte2M) ? byte2M : '?'
            );

        hr = m_spXDSToRat->ParseXDSBytePair(byte1, byte2, &enSystem, &enLevel, &lbfAttrs );
        if(hr == S_OK)      // S_FALSE means it didn't find a new one
        {
            m_cRatingsDetected++;

            TRACE_3 (LOG_AREA_XDSCODEC, 7,  _T("CXDSCodec::ParseXDSBytePair- Rating (0x%02x 0x%02x) Sys:%d Lvl:%d Attr:0x%08x"),
                (DWORD) enSystem, (DWORD) enLevel, lbfAttrs);
            PackedTvRating TvRating;
            hr = PackTvRating(enSystem, enLevel, lbfAttrs, &TvRating);

            if(TvRating != m_TvRating)      // do I want this test here or in the Go method... Might as well have here?
            {
                m_cRatingsChanged++;
                GoNewXDSRatings(mediaSample, TvRating);
            }
            else if (enSystem != TvRat_SystemDontKnow)
            {
                m_cRatingsDuplicate++;
                GoDuplicateXDSRatings(mediaSample, TvRating);     // found a duplicate.  Just send a broadcast event...
            }
        }
        else if(hr != S_FALSE)
        {
            m_cRatingsFailures++;
        }

    }

    // TODO: add generic XDS parse code here
    // GoNewXDSPacket();

    return S_OK;
}


        // mediaSample provided for timestamp, will work without it, but not a good idaa
HRESULT
CXDSCodec::ResetToDontKnow(IMediaSample *  mediaSample)
{
                    // clean up state in the decoder
    if(m_spXDSToRat)
        m_spXDSToRat->Init();

                    //
    PackedTvRating TvRatingDontKnow;
    PackTvRating(TvRat_SystemDontKnow, TvRat_LevelDontKnow, BfAttrNone, &TvRatingDontKnow);

            // store state, and kick off event
    if(TvRatingDontKnow != m_TvRating)
    {
        m_cUnratedChanged++;
        GoNewXDSRatings(mediaSample, TvRatingDontKnow);
    }

    return S_OK;
}

        // sent on a broadcast TuneChanged event...
void
CXDSCodec::DoTuneChanged()
{
                    // really want to do call ResetToDontKnow here,
                    // but don't have a media sample to give us a timestamp
                    // so instead, just clean up state in the decoder
    if(m_spXDSToRat)
        m_spXDSToRat->Init();

                    // for completeness, fire a broadcast event
                    //   saying we don't know the rating

    PackedTvRating TvRatingDontKnow;
    PackTvRating(TvRat_SystemDontKnow, TvRat_LevelDontKnow, BfAttrNone, &TvRatingDontKnow);

    GoNewXDSRatings(NULL, TvRatingDontKnow);

    // actually, probably get a discontinuity here which
    //  does same thing, but this is more fun (e.g. exact)
}

// ---------------------------------------------------------------
//  IBroadcastEvent

STDMETHODIMP
CXDSCodec::Fire(GUID eventID)     // this comes from the Graph's events - call our own method
{
    TRACE_1 (LOG_AREA_BROADCASTEVENTS, 6,  _T("CXDSCodec:: Fire(get) : %s"),
               EventIDToString(eventID));
    if (eventID == EVENTID_TuningChanged)
    {
        DoTuneChanged();
    }
    return S_OK;            // doesn't matter what we return on an event...
}

//  -------------------------------------------------------------------
//  IXDSCodec
//  -------------------------------------------------------------------

STDMETHODIMP
CXDSCodec::get_XDSToRatObjOK(
    OUT HRESULT *pHrCoCreateRetVal
    )
{
    if(NULL == pHrCoCreateRetVal)
        return E_POINTER;

    {
        CAutoLock cLock(&m_PropertyLock);    // lock these
        *pHrCoCreateRetVal = m_hrXDSToRatCoCreateRetValue;
    }
    return S_OK;
}


STDMETHODIMP
CXDSCodec::put_CCSubstreamService(          // will return S_FALSE if unable to set
    IN long SubstreamMask
    )
{
    HRESULT hr = S_OK;

    if(IsInputPinConnected())                   // can't change if connected
        return S_FALSE;
    
    if(0 != (SubstreamMask &
              ~(KS_CC_SUBSTREAM_SERVICE_CC1 |
                KS_CC_SUBSTREAM_SERVICE_CC2 |
                KS_CC_SUBSTREAM_SERVICE_CC3 |
                KS_CC_SUBSTREAM_SERVICE_CC4 |
                KS_CC_SUBSTREAM_SERVICE_T1 |
                KS_CC_SUBSTREAM_SERVICE_T2 |
                KS_CC_SUBSTREAM_SERVICE_T3 |
                KS_CC_SUBSTREAM_SERVICE_T4 |
                KS_CC_SUBSTREAM_SERVICE_XDS)))
        return E_INVALIDARG;

    return S_FALSE;             // can't change yet

    if(!FAILED(hr))
    {
        CAutoLock cLock(&m_PropertyLock);    // lock these
        m_dwSubStreamMask = (DWORD) SubstreamMask;
    }

    TRACE_1 (LOG_AREA_XDSCODEC, 3,  _T("CXDSCodec:: put_CCSubstreamService : 0x%08x"),SubstreamMask);
    
    return hr;
}

STDMETHODIMP
CXDSCodec::get_CCSubstreamService(
    OUT long *pSubstreamMask
    )
{
    if(NULL == pSubstreamMask)
        return E_POINTER;

  {
     CAutoLock cLock(&m_PropertyLock);    // lock these
    *pSubstreamMask = m_dwSubStreamMask;
  }
    return S_OK;
}

            // TODO - need to add the TimeStamp here too

STDMETHODIMP
CXDSCodec::GetContentAdvisoryRating(
    OUT PackedTvRating  *pRat,              // long
    OUT long            *pPktSeqID,
    OUT long            *pCallSeqID,
    OUT REFERENCE_TIME  *pTimeStart,        // time this sample started
    OUT REFERENCE_TIME  *pTimeEnd
    )
{   
            // humm, should we allow NULL values here and simply not return data?
    if(NULL == pRat || NULL == pPktSeqID || NULL == pCallSeqID)
        return E_POINTER;

    if(NULL == pTimeStart || NULL == pTimeEnd)
        return E_POINTER;

    {
        CAutoLock cLock(&m_PropertyLock);    // lock these
        *pRat       = m_TvRating;
        *pPktSeqID  = m_cTvRatPktSeq;
        *pCallSeqID = m_cTvRatCallSeq++;

        *pTimeStart = m_TimeStartRatPkt;                
        *pTimeEnd   = m_TimeEndRatPkt;

        m_cRatingsGets++;
    }

    TRACE_3 (LOG_AREA_XDSCODEC, 5,  _T("CXDSCodec:: GetContentAdvisoryRating : Call %d, Seq %d/%d"),
        m_cRatingsGets, m_cTvRatPktSeq, m_cTvRatCallSeq-1 );

    return S_OK;
}


STDMETHODIMP
CXDSCodec::GetXDSPacket(
    OUT long           *pXDSClassPkt,       // ENUM EnXDSClass      
    OUT long           *pXDSTypePkt,
    OUT BSTR           *pBstrXDSPkt,
    OUT long           *pPktSeqID,
    OUT long           *pCallSeqID,
    OUT REFERENCE_TIME *pTimeStart,         // time this sample started
    OUT REFERENCE_TIME *pTimeEnd
    )
{
    HRESULT hr;
    if(NULL == pXDSClassPkt || NULL == pXDSTypePkt ||
       NULL == pBstrXDSPkt ||
       NULL == pPktSeqID || NULL == pCallSeqID)
        return E_POINTER;

    if(NULL == pTimeStart || NULL == pTimeEnd)
        return E_POINTER;

  {
        CAutoLock cLock(&m_PropertyLock);    // lock these

        *pXDSClassPkt   = m_XDSClassPkt;
        *pXDSTypePkt    = m_XDSTypePkt;
        hr = m_spbsXDSPkt.CopyTo(pBstrXDSPkt);
        *pPktSeqID       = m_cXDSPktSeq;

        if(!FAILED(hr))
            *pCallSeqID = m_cXDSCallSeq++;
        else
            *pCallSeqID = -1;

        *pTimeStart = m_TimeStartXDSPkt;                
        *pTimeEnd   = m_TimeEndXDSPkt;

        m_cXDSGets++;
  }

    TRACE_3 (LOG_AREA_XDSCODEC, 3,  _T("CXDSCodec:: GetXDSPacket : Call %d, Seq %d/%d"),
        m_cXDSGets, m_cXDSPktSeq, m_cXDSCallSeq-1 );
    return hr;
}

// ---------------------------------------------------------------------
// XDSEvent Service
//
//      Hookup needed to send events
//      Register also needed to receive events
// ---------------------------------------------------------------------

HRESULT
CXDSCodec::FireBroadcastEvent(IN const GUID &eventID)
{
    HRESULT hr = S_OK;

    if(m_spBCastEvents == NULL)
    {
        hr = HookupGraphEventService();
        if(FAILED(hr)) return hr;
    }

    if(m_spBCastEvents == NULL)
        return E_FAIL;              // wasn't able to create it

    TRACE_1 (LOG_AREA_BROADCASTEVENTS, 5,  _T("CXDSCodec:: FireBroadcastEvent - %s"),
        EventIDToString(eventID));

    return m_spBCastEvents->Fire(eventID);
}


HRESULT
CXDSCodec::HookupGraphEventService()
{
                        // basically, just makes sure we have the broadcast event service object
                        //   and if it doesn't exist, it creates it..
    HRESULT hr = S_OK;
    TRACE_0(LOG_AREA_BROADCASTEVENTS, 3, _T("CXDSCodec:: HookupGraphEventService")) ;

    if (!m_spBCastEvents)
    {
        CComQIPtr<IServiceProvider> spServiceProvider(m_pGraph);
        if (spServiceProvider == NULL) {
            TRACE_0 (LOG_AREA_BROADCASTEVENTS, 1, _T("CXDSCodec:: Can't get service provider interface from the graph"));
            return E_NOINTERFACE;
        }
        hr = spServiceProvider->QueryService(SID_SBroadcastEventService,
                                             IID_IBroadcastEvent,
                                             reinterpret_cast<LPVOID*>(&m_spBCastEvents));
        if (FAILED(hr) || !m_spBCastEvents)
        {
            hr = m_spBCastEvents.CoCreateInstance(CLSID_BroadcastEventService, 0, CLSCTX_INPROC_SERVER);
            if (FAILED(hr)) {
                TRACE_0 (LOG_AREA_BROADCASTEVENTS, 1,  _T("CXDSCodec:: Can't create BroadcastEventService"));
                return E_UNEXPECTED;
            }
            CComQIPtr<IRegisterServiceProvider> spRegisterServiceProvider(m_pGraph);
            if (spRegisterServiceProvider == NULL) {
                TRACE_0 (LOG_AREA_BROADCASTEVENTS, 1,  _T("CXDSCodec:: Can't QI Graph for RegisterServiceProvider"));
                return E_UNEXPECTED;
            }
            hr = spRegisterServiceProvider->RegisterService(SID_SBroadcastEventService, m_spBCastEvents);
            if (FAILED(hr)) {
                   // deal with unlikely race condition case here, if can't register, perhaps someone already did it for us
                TRACE_1 (LOG_AREA_BROADCASTEVENTS, 2,  _T("CXDSCodec:: Rare Warning - Can't register BroadcastEventService in Service Provider. hr = 0x%08x"), hr);
                hr = spServiceProvider->QueryService(SID_SBroadcastEventService,
                                                     IID_IBroadcastEvent,
                                                     reinterpret_cast<LPVOID*>(&m_spBCastEvents));
                if(FAILED(hr))
                {
                    TRACE_1 (LOG_AREA_BROADCASTEVENTS, 1,  _T("CXDSCodec:: Can't reget BroadcastEventService in Service Provider. hr = 0x%08x"), hr);
                    return hr;
                }
            }
        }

        TRACE_2(LOG_AREA_BROADCASTEVENTS, 4, _T("CXDSCodec::HookupGraphEventService - Service Provider 0x%08x, Service 0x%08x"),
            spServiceProvider, m_spBCastEvents) ;

    }

    return hr;
}


HRESULT
CXDSCodec::UnhookGraphEventService()
{
    HRESULT hr = S_OK;

    if(m_spBCastEvents != NULL)
        m_spBCastEvents = NULL;     // null this out, will release object reference to object above
                                    //   the filter graph will release final reference to created object when it goes away

    return hr;
}


            // ---------------------------------------------

            // XDS filter may not actually need to receive XDS events...
            //  but we'll leave the code in here for now.
            
HRESULT
CXDSCodec::RegisterForBroadcastEvents()
{
    HRESULT hr = S_OK;
    TRACE_0(LOG_AREA_BROADCASTEVENTS, 3, _T("CXDSCodec::RegisterForBroadcastEvents"));

    if(m_spBCastEvents == NULL)
        hr = HookupGraphEventService();


//  _ASSERT(m_spBCastEvents != NULL);       // failed hooking to HookupGraphEventService
    if(m_spBCastEvents == NULL)
    {
        TRACE_0(LOG_AREA_BROADCASTEVENTS, 3,  _T("CXDSCodec::RegisterForBroadcastEvents- Warning - Broadcast Event Service not yet created"));
        return hr;
    }

                /* IBroadcastEvent implementing event receiving object*/
    if(kBadCookie != m_dwBroadcastEventsCookie)
    {
        TRACE_0(LOG_AREA_BROADCASTEVENTS, 3, _T("CXDSCodec::Already Registered for Broadcast Events"));
        return E_UNEXPECTED;
    }

    CComQIPtr<IConnectionPoint> spConnectionPoint(m_spBCastEvents);
    if(spConnectionPoint == NULL)
    {
        TRACE_0(LOG_AREA_BROADCASTEVENTS, 1, _T("CXDSCodec::Can't QI Broadcast Event service for IConnectionPoint"));
        return E_NOINTERFACE;
    }


    CComPtr<IUnknown> spUnkThis;
    this->QueryInterface(IID_IUnknown, (void**)&spUnkThis);

    hr = spConnectionPoint->Advise(spUnkThis,  &m_dwBroadcastEventsCookie);
//  hr = spConnectionPoint->Advise(static_cast<IBroadcastEvent*>(this),  &m_dwBroadcastEventsCookie);
    if (FAILED(hr)) {
        TRACE_1(LOG_AREA_BROADCASTEVENTS, 1, _T("CXDSCodec::Can't advise event notification. hr = 0x%08x"),hr);
        return E_UNEXPECTED;
    }
    TRACE_2(LOG_AREA_BROADCASTEVENTS, 3, _T("CXDSCodec::RegisterForBroadcastEvents - Advise 0x%08x on CP 0x%08x"),spUnkThis,spConnectionPoint);

    return hr;
}


HRESULT
CXDSCodec::UnRegisterForBroadcastEvents()
{
    HRESULT hr = S_OK;
    TRACE_0(LOG_AREA_BROADCASTEVENTS, 3,  _T("CXDSCodec::UnRegisterForBroadcastEvents"));

    if(kBadCookie == m_dwBroadcastEventsCookie)
    {
        TRACE_0(LOG_AREA_BROADCASTEVENTS, 3, _T("CXDSCodec::Not Yet Registered for Tune Events"));
        return S_FALSE;
    }

    CComQIPtr<IConnectionPoint> spConnectionPoint(m_spBCastEvents);
    if(spConnectionPoint == NULL)
    {
        TRACE_0(LOG_AREA_BROADCASTEVENTS, 1, _T("CXDSCodec:: Can't QI Broadcast Event service for IConnectionPoint "));
        return E_NOINTERFACE;
    }

    hr = spConnectionPoint->Unadvise(m_dwBroadcastEventsCookie);
    m_dwBroadcastEventsCookie = kBadCookie;

    if(!FAILED(hr))
        TRACE_0(LOG_AREA_BROADCASTEVENTS, 3, _T("CXDSCodec:: - Successfully Unregistered for Broadcast Events"));
    else
        TRACE_1(LOG_AREA_BROADCASTEVENTS, 3, _T("CXDSCodec:: - Failed Unregistering for Broadcast events - hr = 0x%08x"),hr);
        
    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\h\ftype.h ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*
    Find the type of a file based on its check bytes in the registry :

    A set of values : offset, length, mask, checkbyte
    indexed by the major type and subtype.

    To pass ALL the checkbytes must match under mask for at least ONE
    of the checkbyte lists under the subtype key

    A negative offset means an offset from the end of the file

    See GetClassFile for a similar scheme

    HKEY_CLASSES_ROOT
        Media Type
            {Major Type clsid}
                {Subtype clsid}
                    Source Filter = REG_SZ {Source filter clsid}
                    0 = REG_SZ 0, 4, F0FFFFFF, 10345678, 100, 4, , 11110000
                    1 = REG_SZ -4, 4, , 87654321

    URL names (names beginning with a protocol and :) will use the following
    structure: if the extension is found in Extensions, that clsid will be
    used else the Source Filter for that protocol.
    HKEY_CLASSES_ROOT
        <protocol>
            Source Filter = REG_SZ {Source filter clsid}
            Extensions
                <.ext> = REG_SZ {Source filter clsid}
    if no class id is found, we will attempt to open them and parse them
    as for local files.

*/

/*  Define the key name under which we store the data */

#define MEDIATYPE_KEY TEXT("Media Type")

/*  Define the value name for the source filter clsid */

#define SOURCE_VALUE (TEXT("Source Filter"))

// name of the key under which extensions are stored
// each extension is a named value including the . with the value being
// the class id eg
//    .mpg = REG_SZ {e436ebb6-524f-11ce-9f53-0020af0ba770}
#define EXTENSIONS_KEY TEXT("Extensions")

/*  Function to get the media type of a file */

STDAPI GetMediaTypeFile(LPCTSTR lpszFile,     // Name of file
                        GUID   *Type,         // Type (returned)
                        GUID   *Subtype,      // Subtype (returned)
                        CLSID  *clsidSource); // Clsid of source filter

/*  Add a file type entry to the registry */

STDAPI SetMediaTypeFile(const GUID  *Type,         // Media Major Type
                        const GUID  *Subtype,      //
                        const CLSID *clsidSource,  // Source filter
                        LPCTSTR      lpszMaskAndData,
                        DWORD        dwIndex = 0);

/*  Remove all the entries for a particular media type */

STDAPI DeleteMediaTypeFile(const GUID *Type, const GUID *Subtype);

/*  Register a file extension - must include leading "." */
HRESULT RegisterExtension(LPCTSTR lpszExt, const GUID *Subtype);


//  Add a protocol handler
HRESULT AddProtocol(LPCTSTR lpszProtocol, const CLSID *pclsidHandler);
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\h\rdr.h ===
// Copyright (c) Microsoft Corporation 1996. All Rights Reserved
#ifndef __RDR_H__
#define __RDR_H__
/*

    File:  reader.h

    Description:

        Mini file reader class to grovel the mpeg file

*/


/*  Class to pump bytes at ParseBytes

    This aims at the maximum contiguous bytes in a 64K buffer,
    but we can vary the size we read

    Abstract base class.
*/

class CReader
{
public:
    CReader();
    virtual ~CReader();

    virtual HRESULT  Seek(LONGLONG llPos);
    virtual PBYTE    GetCurrent(LONG& lLengthValid, LONGLONG& llPos) const;
    virtual HRESULT  ReadMore();
    virtual void     Advance(LONG lAdvance);
    virtual LONGLONG GetSize(LONGLONG *pllAvailable = NULL);
    virtual HRESULT  Init(
			LONG lBufferSize,
			LONG lReadSize,
			BOOL bSeekable,
			LONGLONG llFileSize
			);
    BOOL IsSeekable() {
	return m_bSeekable;
    };

    // override these functions to provide access to the actual stream
    // or data source
protected:
    virtual HRESULT SeekDevice(
			LONGLONG llPos,
			LONGLONG* llNewPos) PURE;
    virtual HRESULT ReadFromDevice(
			PVOID pBuffer,
			DWORD cbToRead,
			DWORD* cbActual) PURE;

    // derived classes can use this info
    LONGLONG  m_llPosition;		// position at start of buffer
    LONGLONG  m_llSize;			// total file length
    BOOL      m_bSeekable;		// false if not a seekable source

private:
    LONG      m_lBufferSize;
    LONG      m_lReadSize;
    PBYTE     m_pbBuffer;
    LONG      m_lValid;
};

// implementation of CReader that reads from an IStream
class CReaderFromStream : public CReader
{
private:
    IStream * m_pStream;


public:
    CReaderFromStream();
    ~CReaderFromStream();

    HRESULT Init(IStream *pStream, LONG lBufferSize, LONG lReadSize, BOOL bSeekable);

protected:
    HRESULT SeekDevice(LONGLONG llPos, LONGLONG* llNewPos);
    HRESULT ReadFromDevice(PVOID pBuffer, DWORD cbToRead, DWORD* cbActual);
};


// implementation of CReader that reads from an IAsyncReader interface
class CReaderFromAsync : public CReader
{
private:
    IAsyncReader * m_pReader;
    LONGLONG m_llNextRead;

public:
    CReaderFromAsync();
    ~CReaderFromAsync();

    HRESULT Init(IAsyncReader *pReader, LONG lBufferSize, LONG lReadSize, BOOL bSeekable);

protected:
    HRESULT SeekDevice(LONGLONG llPos, LONGLONG* llNewPos);
    HRESULT ReadFromDevice(PVOID pBuffer, DWORD cbToRead, DWORD* cbActual);
    LONGLONG GetSize(LONGLONG *pllAvailable = NULL);
};



#endif //__RDR_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\h\creg.h ===
// Copyright (c) 1995 - 1996  Microsoft Corporation.  All Rights Reserved.

/*
    Registry access classes :

    CEnumKey
    CEnumValue
*/

class CKey
{
public:
    CKey(HKEY hKey,
         LPCTSTR lpszKeyName,
         HRESULT *phr,
         BOOL bCreate = FALSE,
         REGSAM Access = MAXIMUM_ALLOWED);
    ~CKey();
    virtual BOOL Next() { return FALSE; };
    HKEY KeyHandle() const { return m_hKey; };
    void Reset() { m_dwIndex = 0; };

protected:
    HKEY  m_hKey;
    DWORD m_dwIndex;
    TCHAR m_szName[30];
    LPTSTR m_lpszName;

    /*  Information from RegQueryInfoKey */
    DWORD m_cSubKeys;
    DWORD m_cbMaxSubkeyLen;
    DWORD m_cValues;
    DWORD m_cbMaxValueNameLen;
    DWORD m_cbMaxValueLen;
};

class CEnumKey : public CKey
{
public:
    CEnumKey(HKEY hKey,
             LPCTSTR lpszKeyName,
             HRESULT *phr,
             BOOL bCreate = FALSE,
             REGSAM Access = KEY_READ);
    ~CEnumKey();
    BOOL Next();
    LPCTSTR KeyName() const { return m_lpszName; };
};

class CEnumValue : public CKey
{
public:
    CEnumValue(HKEY hKey,
               LPCTSTR lpszKeyName,
               HRESULT *phr,
               BOOL bCreate = FALSE,
               REGSAM Access = MAXIMUM_ALLOWED);
    ~CEnumValue();
    BOOL Next();
    BOOL Next(DWORD dwType);                        // Next of this type (skips rest)
    BOOL Read(DWORD dwType, LPCTSTR lpszValueName); // Goto a particular value
    LPCTSTR ValueName() const { return m_lpszName; };
    DWORD ValueType() const { return m_dwType; };
    DWORD ValueLength() const { return m_cbLen; };
    LPBYTE Data() const { return m_lpbData; };

private:
    DWORD  m_dwType;
    DWORD  m_cbLen;
    LPBYTE m_lpbData;
    BYTE   m_bData[30];
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\colour.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// This filter implements popular colour space conversions, May 1995

#include <streams.h>
#include <colour.h>
#include <limits.h>
#include <viddbg.h>
#include "stdpal.h"

// This filter converts decompressed images into different colour spaces. We
// support five basic RGB colour space formats so that other filters are able
// to produce their data in its native format. Of course having an additional
// filter to do the colour conversion is less efficient that doing it in band
// during, for example, the video decompression. This filter can be used with
// the video specific output pin to enable simple access to the frame buffer.
// Where appropriate a filter could be handed a YUV decompression surface and
// write directly to the frame buffer, if part of the window becomes occluded
// then the output pin switches to a memory buffer that we'll colour convert
// The list of colour conversions we support (by CLSID) are as follows:
//
// MEDIASUBTYPE_RGB8
// MEDIASUBTYPE_RGB565
// MEDIASUBTYPE_RGB555
// MEDIASUBTYPE_RGB24
// MEDIASUBTYPE_RGB32
// MEDIASUBTYPE_ARGB32
//
// This filter does not have a worker thread so it executes the colour space
// conversion on the calling thread. It is meant to be as lightweight as is
// possible so we do very little type checking on connection over and above
// ensuring we understand the types involved. The assumption is that when the
// type eventually gets through to an end point (probably the video renderer
// supplied) it will do a thorough type checking and reject bad streams.
//
// We have very strict rules on handling palettised formats. If we connect to
// a source filter with a true colour format, then we can provide any output
// format the downstream filter requires. If a format can be provided by the
// source directly then we go into pass through mode.
#if 0	// we can now
// If we connect our input
// with MEDIASUBTYPE_RGB8 then we cannot provide eight bit output. This is to
// avoid having to copy palette changes from input to output formats. In any
// case there is no need to have the colour space convertor in the graph for
// this kind of transform. Also, if we connect our input with eight bit then
// we do not do pass through as our source might change the input palette on
// a true colour format which we would make it hard to update our input with.
#endif


//  NOTE on passthrough mode.  We support a special allocator which
//  can either allocate samples itself and do the convert and copy, or
//  it can allocate samples directly from the downstream filter if the
//  upstream pin can supply the type directly.
//  When the second case is detected the passthrough flag is set and
//  Receive() passes through the samples directly.
//  Passthrough only operates when out special allocator is used.


// MORE NOTES by ehr: This filter has a "special" allocator that's always
// instantiated, but only sometimes used. If the upstream filter asks us
// for an allocator, and we haven't been notified of one yet, we pass back
// a reference to our special one. If the upstream filter just tells us
// what our allocator is, our special one is still instantiated, but never used.

//
// List of CLSIDs and creator functions for class factory

#ifdef FILTER_DLL
CFactoryTemplate g_Templates[1] = {
    {L"", &CLSID_Colour, CColour::CreateInstance}
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);

STDAPI DllRegisterServer()
{
  return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
  return AMovieDllRegisterServer2( FALSE );
}
#endif


// This goes in the factory template table to create new instances

CUnknown *CColour::CreateInstance(LPUNKNOWN pUnk,HRESULT *phr)
{
    return new CColour(NAME("Colour space convertor"),pUnk,phr);
}


// Setup data

const AMOVIESETUP_MEDIATYPE
sudColourPinTypes[] =
{
    {
        &MEDIATYPE_Video,           // Major
        &MEDIASUBTYPE_RGB8          // Subtype
    },
    {
        &MEDIATYPE_Video,           // Major
        &MEDIASUBTYPE_RGB555        // Subtype
    },
    {
        &MEDIATYPE_Video,           // Major
        &MEDIASUBTYPE_RGB565        // Subtype
    },
    {
        &MEDIATYPE_Video,           // Major
        &MEDIASUBTYPE_RGB24         // Subtype
    },
    {
        &MEDIATYPE_Video,           // Major
        &MEDIASUBTYPE_RGB32         // Subtype
    },
    {
        &MEDIATYPE_Video,           // Major
        &MEDIASUBTYPE_ARGB32      // Subtype
    }

};

const AMOVIESETUP_PIN
sudColourPin[] =
{
    { L"Input",                 // Name of the pin
      FALSE,                    // Is pin rendered
      FALSE,                    // Is an Output pin
      FALSE,                    // Ok for no pins
      FALSE,                    // Can we have many
      &CLSID_NULL,              // Connects to filter
      NULL,                     // Name of pin connect
      NUMELMS(sudColourPinTypes), // Number of pin types
      sudColourPinTypes },     // Details for pins

    { L"Output",                // Name of the pin
      FALSE,                    // Is pin rendered
      TRUE,                     // Is an Output pin
      FALSE,                    // Ok for no pins
      FALSE,                    // Can we have many
      &CLSID_NULL,              // Connects to filter
      NULL,                     // Name of pin connect
      NUMELMS(sudColourPinTypes), // Number of pin types
      sudColourPinTypes }      // Details for pins
};

const AMOVIESETUP_FILTER
sudColourFilter =
{
    &CLSID_Colour,              // CLSID of filter
    L"Color Space Converter",   // Filter name
    MERIT_UNLIKELY + 1,         // Filter merit
    2,                          // Number of pins
    sudColourPin                // Pin information
};


// Constructor initialises the base transform class. We have our own memory
// allocator that is used to pass through samples so that we can operate in
// a don't copy mode when the source can supply the destination directly. We
// do this by setting the data pointer in our samples to be the destinations.
// This is somewhat like the DirectDraw flipping surfaces where the interface
// remains the same but the memory pointer changes. We also have an input pin
// that needs to cooperate in this pass through operation. The input pin is a
// member variable of the class rather than a dynamically created pin object

#pragma warning(disable:4355)

CColour::CColour(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr) :
    CTransformFilter(pName,pUnk,CLSID_Colour),
    m_ColourAllocator(NAME("Allocator"),this,phr,&m_csReceive),
    m_ColourInputPin(NAME("Input Pin"),this,&m_csReceive,phr,L"Input"),
    m_TypeList(NAME("Colour type list"),DEFAULTCACHE,FALSE,FALSE),
    m_pConvertor(NULL),
    m_bPassThrough(FALSE),
    m_bPassThruAllowed(TRUE),
    m_bOutputConnected(FALSE),
    m_TypeIndex(-1),
    m_pOutSample(NULL),
    m_fReconnecting(FALSE)
{
    ASSERT(phr);
}


// Destructor MUST set the transform m_pInput pointer before the base class
// is called because we have the pin as a member variable rather than as a
// dynamically created object (see the main colour space conversion class
// definition) - Fortunately our destructor is called before the base class

CColour::~CColour()
{
    ASSERT(m_mtOut.IsValid() == FALSE);
    ASSERT(m_pOutSample == NULL);
    ASSERT(m_pConvertor == NULL);
    ASSERT(m_bOutputConnected == FALSE);

    InitTypeList( );

    m_pInput = NULL;
}


// If the output type is being changed perhaps to switch to using DirectDraw
// then we create a new one. Creating one of our convertor objects also has
// it committed so it is ready for streaming. Likewise if the input format
// has changed then we also recreate a convertor object. We always create a
// new convertor when the input format is RGB8 because the palette may have
// been changed in which case we will need to build new colour lookup tables

HRESULT CColour::PrepareTransform(IMediaSample *pIn,IMediaSample *pOut)
{
    NOTE("Entering PrepareTransform");
    AM_MEDIA_TYPE *pMediaType;
    CAutoLock cAutoLock(&m_csReceive);
    BOOL bInputConvertor = FALSE;
    BOOL bOutputConvertor = FALSE;

    // Make sure some kipper hasn't called us at the wrong time

    if (m_pConvertor == NULL) {
        NOTE("No converted object");
        return VFW_E_WRONG_STATE;
    }

    // Has the output type changed

    pOut->GetMediaType(&pMediaType);
    if (pMediaType) {
        NOTE("Output format changed");
        SetMediaType(PINDIR_OUTPUT,(CMediaType *)pMediaType);
        DeleteMediaType(pMediaType);
        bOutputConvertor = TRUE;
    }

    // Likewise check the input format

    AM_SAMPLE2_PROPERTIES * const pProps = m_pInput->SampleProps();
    if (pProps->dwSampleFlags & AM_SAMPLE_TYPECHANGED) {
        NOTE("Input format changed");
        m_pInput->SetMediaType((CMediaType *)pProps->pMediaType);
        bInputConvertor = TRUE;
    }

    // Make sure palette changes happen

    if (bInputConvertor == TRUE) {
        if (*m_pInput->CurrentMediaType().Subtype() == MEDIASUBTYPE_RGB8) {
            NOTE("Palette forced");
            DeleteConvertorObject();
        }
    }

    // Do we need a new convertor

    if (bInputConvertor || bOutputConvertor) {
        NOTE("Creating convertor");
        CreateConvertorObject();
    }
    return NOERROR;
}


// Convert this input sample to a different colour space format. On choosing
// a transform for this filter to perform we initialise the m_Convertor field
// to address an object that does the transforms for us. So now that we have
// received a media sample we call the derived object's transform function
// We may be called from our input pin depending whose allocator we're using

HRESULT CColour::Transform(IMediaSample *pIn,IMediaSample *pOut)
{
    NOTE("Entering Transform");
    CAutoLock cAutoLock(&m_csReceive);
    BYTE *pInputImage = NULL;
    BYTE *pOutputImage = NULL;
    HRESULT hr = NOERROR;

    // Manage dynamic format changes

    hr = PrepareTransform(pIn,pOut);
    if (FAILED(hr)) {
        return hr;
    }

    // Retrieve the output image pointer

    hr = pOut->GetPointer(&pOutputImage);
    if (FAILED(hr)) {
        NOTE("No output");
        return hr;
    }

    // And the input image buffer as well

    hr = pIn->GetPointer(&pInputImage);
    if (FAILED(hr)) {
        NOTE("No input");
        return hr;
    }
    return m_pConvertor->Transform(pInputImage,pOutputImage);
}


// Given any source GUID subtype we scan the list of available transforms for
// the conversion at index position iIndex. The number of transforms that are
// available for any given type can be found from CountTransforms. NOTE the
// iIndex parameter is ZERO based so that it fits easily with GetMediaType

const GUID *CColour::FindOutputType(const GUID *pInputType,INT iIndex)
{
    NOTE("Entering FindOutputType");
    ASSERT(pInputType);
    const GUID *pVideoSubtype;
    INT iPosition = 0;

    while (iPosition < TRANSFORMS) {
        pVideoSubtype = TypeMap[iPosition].pInputType;
        if (IsEqualGUID(*pVideoSubtype,*pInputType)) {
            if (iIndex-- == 0) {
                return TypeMap[iPosition].pOutputType;
            }
        }
        iPosition++;
    }
    return NULL;
}


// Check that we can transform from this input to this output subtype, all we
// do is to scan the list of available transforms and look for an entry that
// contains both the input and output type. Most people don't care where in
// list the transform is but some require the table position for use later

INT CColour::FindTransform(const GUID *pInputType,const GUID *pOutputType)
{
    NOTE("Entering FindTransform");
    ASSERT(pOutputType);
    ASSERT(pInputType);
    INT iPosition = TRANSFORMS;

    ASSERT(IsEqualGUID(*pInputType,GUID_NULL) == FALSE);
    ASSERT(IsEqualGUID(*pOutputType,GUID_NULL) == FALSE);

    while (iPosition--) {
        if (IsEqualGUID(*(TypeMap[iPosition].pInputType),*pInputType)) {
            if (IsEqualGUID(*(TypeMap[iPosition].pOutputType),*pOutputType)) {
                return iPosition;
            }
        }
    }
    return (-1);
}


// This function is handed a media type object and it looks after making sure
// that it is superficially correct. This doesn't amount to a whole lot more
// than making sure the type is right and that the media format block exists
// So we delegate full type checking to the downstream filter that uses it

HRESULT CColour::CheckVideoType(const AM_MEDIA_TYPE *pmt)
{
    NOTE("Entering CheckVideoType");

    // Check the major type is digital video

    if (pmt->majortype != MEDIATYPE_Video) {
        NOTE("Major type not MEDIATYPE_Video");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Check this is a VIDEOINFO type

    if (pmt->formattype != FORMAT_VideoInfo) {
        NOTE("Format not a VIDEOINFO");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Quick sanity check on the input format

    if (pmt->cbFormat < SIZE_VIDEOHEADER) {
        NOTE("Format too small for a VIDEOINFO");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
    return NOERROR;
}


// Check if we can support type mtIn which amounts to scanning our available
// list of transforms and seeing if there are any available. The formats we
// can supply is entirely dependent on the formats the source filter is able
// to provide us with. For that reason we cannot unfortunately simply pass
// the source filter's enumerator through to the downstream filter. This can
// be done by simpler in place transform filters and others like the tee

HRESULT CColour::CheckInputType(const CMediaType *pmtIn)
{
    NOTE("Entering CheckInputType");
    ASSERT(pmtIn);

    // Quick sanity check on the input format

    HRESULT hr = CheckVideoType(pmtIn);
    if (FAILED(hr)) {
        NOTE("Type failed");
        return hr;
    }

    DisplayType(TEXT("Input type offered"),pmtIn);

    // See if there is a conversion available

    if (FindOutputType(pmtIn->Subtype(),FALSE) == NULL) {
        NOTE("No conversion available");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
    return NOERROR;
}


// Check if you can support the transform from this input to this output, we
// check we like the output type and then see if we can find a transform for
// this pair. Because we do all conversions between all input and outputs we
// should never need to reconnect our input pin. Therefore having completed
// an input pin connection we only have to check that there's a transform we
// can use from the current input pin format to the proposed output type

HRESULT CColour::CheckTransform(const CMediaType *pmtIn,const CMediaType *pmtOut)
{
    VIDEOINFO *pTargetInfo = (VIDEOINFO *) pmtOut->Format();
    VIDEOINFO *pSourceInfo = (VIDEOINFO *) pmtIn->Format();
    NOTE("Entering CheckTransform");

    // Quick sanity check on the output format

    HRESULT hr = CheckVideoType(pmtOut);
    if (FAILED(hr)) {
        return hr;
    }

#if 0	// we can now
    // We cannot transform between palettised formats
    if (*pmtIn->Subtype() == MEDIASUBTYPE_RGB8) {
        if (*pmtOut->Subtype() == MEDIASUBTYPE_RGB8) {
            NOTE("Can't convert palettised");
            return VFW_E_TYPE_NOT_ACCEPTED;
        }
    }
#endif

    // Is there a transform available from the input to the output. If there
    // is no transform then we might still supply the type if the source can
    // supply it directly. However we only agree to pass through media types
    // once an output connection has been established otherwise we reject it
    if (FindTransform(pmtIn->Subtype(),pmtOut->Subtype()) == (-1)) {
        if (m_ColourInputPin.CanSupplyType(pmtOut) == S_OK) {
            if (m_bOutputConnected == TRUE) {
                NOTE("Source will provide transform");
                return NOERROR;
            }
        }
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Create a source rectangle if it's empty

    RECT SourceRect = pTargetInfo->rcSource;
    if (IsRectEmpty(&SourceRect) == TRUE) {
        SourceRect.right = pSourceInfo->bmiHeader.biWidth;
        SourceRect.bottom = ABSOL(pSourceInfo->bmiHeader.biHeight);
        SourceRect.left = SourceRect.top = 0;
        NOTERC("(Expanded) Source",SourceRect);
    } else {
	// Check that source rectange is within source
	if (SourceRect.right > pSourceInfo->bmiHeader.biWidth ||
	    SourceRect.bottom > ABSOL(pSourceInfo->bmiHeader.biHeight)) {

	    NOTERC("Source rect bigger than source bitmap!",SourceRect);

	    return VFW_E_TYPE_NOT_ACCEPTED;
	}
    }

    // Create a destination rectangle if it's empty

    RECT TargetRect = pTargetInfo->rcTarget;
    if (IsRectEmpty(&TargetRect) == TRUE) {
        TargetRect.right = pTargetInfo->bmiHeader.biWidth;
        TargetRect.bottom = ABSOL(pTargetInfo->bmiHeader.biHeight);
        TargetRect.left = TargetRect.top = 0;
        NOTERC("(Expanded) Target",TargetRect);
    } else {
	// Check that source rectange is within source
	if (TargetRect.right > pTargetInfo->bmiHeader.biWidth ||
	    TargetRect.bottom > ABSOL(pTargetInfo->bmiHeader.biHeight)) {

	    NOTERC("Target rect bigger than target bitmap!",TargetRect);
	    return VFW_E_TYPE_NOT_ACCEPTED;
	}
    }

    // Check we are not stretching nor compressing the image

    if (WIDTH(&SourceRect) == WIDTH(&TargetRect)) {
        if (HEIGHT(&SourceRect) == HEIGHT(&TargetRect)) {
            NOTE("No stretch");
            return NOERROR;
        }
    }

    return VFW_E_TYPE_NOT_ACCEPTED;
}


// Return our preferred media types (in order) for the output pin. The input
// pin assumes that since we are a transform we have no preferred types. We
// create an output media type by copying the input format and the adjusting
// it according to the output subtype. Since all inputs can be converted to
// all outputs we know there is a fixed number of different possible outputs
// which in turn means we can simply hard code the subtypes GUIDs for them.
// We also return the non RGB formats that our source filter proposes so when
// we are running we can pass these straight through with a minimal overhead

HRESULT CColour::GetMediaType(int iPosition, CMediaType *pmtOut)
{
    NOTE("Entering GetMediaType");
    ASSERT(pmtOut);
    GUID SubType;

    // Is this asking for a source proposed format

    if (iPosition < m_TypeList.GetCount()) {
        *pmtOut = *(GetListMediaType(iPosition));
        DisplayType(NAME("  Proposing source type"),pmtOut);
        return NOERROR;
    }

    // Quick sanity check on the output type index

    iPosition -= m_TypeList.GetCount();
    if (iPosition >= 6) {
        NOTE("Exceeds types supplied");
        return VFW_S_NO_MORE_ITEMS;
    }

    *pmtOut = m_pInput->CurrentMediaType();

    // Select the appropriate output subtype - this filter also does straight
    // pass through with and without scan line re-ordering. If we are passing
    // through eight bit palettised formats then we keep the source format as
    // we will not be using our dithering code (and therefore not our palette)

    switch (iPosition) {
        case 0: SubType = MEDIASUBTYPE_ARGB32;   break;
        case 1: SubType = MEDIASUBTYPE_RGB32;   break;
        case 2: SubType = MEDIASUBTYPE_RGB24;   break;
        case 3: SubType = MEDIASUBTYPE_RGB565;  break;
        case 4: SubType = MEDIASUBTYPE_RGB555;  break;
        case 5: SubType = MEDIASUBTYPE_RGB8;    break;
    }

    return PrepareMediaType(pmtOut,&SubType);
}


// Given that the input media type did not have a palette we have supply our
// default dithering palette. We can only transform to one specific palette
// because our dithering algorithm uses a known mapping between RGB elements
// and fixed palette positions. The video renderer will look after switching
// us back to DIBs when the palette in the window isn't an identity palette

VIDEOINFO *CColour::PreparePalette(CMediaType *pmtOut)
{
    NOTE("Entering PreparePalette");

    // Allocate enough room for a full colour palette

    pmtOut->ReallocFormatBuffer(SIZE_VIDEOHEADER + SIZE_PALETTE);
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtOut->Format();
    if (pVideoInfo == NULL) {
        NOTE("No format");
        return NULL;
    }

    ASSERT(PALETTISED(pVideoInfo) == TRUE);

    // If we are converting 8 bit to 8 bit, we want to offer on our output,
    // the same palette as the input palette.  If we are converting true
    // colour to 8 bit, we want to offer our stock dither palette

    LPBITMAPINFOHEADER lpbiIn = HEADER(m_pInput->CurrentMediaType().Format());
    LPBITMAPINFOHEADER lpbiOut = HEADER(pVideoInfo);
    ASSERT(lpbiIn);
    if (lpbiIn->biBitCount == 8) {
	//DbgLog((LOG_TRACE,3,TEXT("OFFERING 8 BIT of the SAME PALETTE")));
	int cb = lpbiIn->biClrUsed ? lpbiIn->biClrUsed * sizeof(RGBQUAD) :
						256 * sizeof(RGBQUAD);
	CopyMemory(lpbiOut, lpbiIn, sizeof(BITMAPINFOHEADER) + cb);

    } else {
	//DbgLog((LOG_TRACE,3,TEXT("OFFERING 8 BIT of my DITHER PALETTE")));

        // Initialise the palette entries in the header

        pVideoInfo->bmiHeader.biClrUsed = STDPALCOLOURS;
        pVideoInfo->bmiHeader.biClrImportant = STDPALCOLOURS;
        NOTE("Adding system device colours to dithered");

        // Get the standard system colours

        PALETTEENTRY apeSystem[OFFSET];
        HDC hDC = GetDC(NULL);
        if (NULL == hDC) {
            return NULL;
        }
        GetSystemPaletteEntries(hDC,0,OFFSET,apeSystem);
        ReleaseDC(NULL,hDC);

        // Copy the first ten VGA system colours

        for (LONG Index = 0;Index < OFFSET;Index++) {
            pVideoInfo->bmiColors[Index].rgbRed = apeSystem[Index].peRed;
            pVideoInfo->bmiColors[Index].rgbGreen = apeSystem[Index].peGreen;
            pVideoInfo->bmiColors[Index].rgbBlue = apeSystem[Index].peBlue;
            pVideoInfo->bmiColors[Index].rgbReserved = 0;
        }

        // Copy the palette we dither to one colour at a time

        for (Index = OFFSET;Index < STDPALCOLOURS;Index++) {
            pVideoInfo->bmiColors[Index].rgbRed = StandardPalette[Index].rgbRed;
            pVideoInfo->bmiColors[Index].rgbGreen =
						StandardPalette[Index].rgbGreen;
            pVideoInfo->bmiColors[Index].rgbBlue =
						StandardPalette[Index].rgbBlue;
            pVideoInfo->bmiColors[Index].rgbReserved = 0;
        }
    }
    return pVideoInfo;
}


// The output media type is sixteen bit true colour so we allocate sufficient
// space for the bit masks if not already there and then set them accordingly
// We get the subtype from the media type object to know whether it is RGB555
// or RGB565 representation, RGB555 bit fields are implicit if it's BI_RGB

VIDEOINFO *CColour::PrepareTrueColour(CMediaType *pmtOut)
{
    NOTE("Entering PrepareTrueColour");
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtOut->Format();
    ASSERT(pVideoInfo->bmiHeader.biBitCount == iTRUECOLOR);

    // Make sure the format is long enough, so reallocate the format buffer
    // in place using one of the CMediaType member functions. The pointer
    // that is returned is the new format or NULL if we ran out of memory

    pVideoInfo->bmiHeader.biCompression = BI_BITFIELDS;
    ULONG Length = pmtOut->FormatLength();

    if (Length < SIZE_MASKS + SIZE_VIDEOHEADER) {
        pmtOut->ReallocFormatBuffer(SIZE_MASKS + SIZE_VIDEOHEADER);
        pVideoInfo = (VIDEOINFO *) pmtOut->Format();
        if (pVideoInfo == NULL) {
            NOTE("No format");
            return NULL;
        }
    }

    // Set the new bit fields masks (compression is already BI_RGB)

    const DWORD *pBitMasks = bits555;
    if (IsEqualGUID(*pmtOut->Subtype(),MEDIASUBTYPE_RGB565) == TRUE) {
        NOTE("Setting masks");
        pBitMasks = bits565;
    }

    pVideoInfo->dwBitMasks[iRED] = pBitMasks[iRED];
    pVideoInfo->dwBitMasks[iGREEN] = pBitMasks[iGREEN];
    pVideoInfo->dwBitMasks[iBLUE] = pBitMasks[iBLUE];
    return pVideoInfo;
}


// When we prepare an output media type we take a copy of the input format as
// a point of reference so that image dimensions for example remain constant
// Depending on the type of transform we are doing we must also update the
// headers to keep synchronised with the changing type. We may also have to
// allocate more format memory if the type now requires masks for example

HRESULT CColour::PrepareMediaType(CMediaType *pmtOut,const GUID *pSubtype)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtOut->Format();
    pmtOut->SetSubtype(pSubtype);
    NOTE("Entering PrepareMediaType");

    // Initialise the BITMAPINFOHEADER details

    pVideoInfo->bmiHeader.biCompression = BI_RGB;
    pVideoInfo->bmiHeader.biBitCount = GetBitCount(pSubtype);
    pVideoInfo->bmiHeader.biSizeImage = GetBitmapSize(&pVideoInfo->bmiHeader);
    pVideoInfo->bmiHeader.biClrUsed = 0;
    pVideoInfo->bmiHeader.biClrImportant = 0;
    ASSERT(pVideoInfo->bmiHeader.biBitCount);
    pmtOut->SetSampleSize(pVideoInfo->bmiHeader.biSizeImage);

    // Make any true colour adjustments

    if (pVideoInfo->bmiHeader.biBitCount == 16) {
        pVideoInfo = PrepareTrueColour(pmtOut);
        if (pVideoInfo == NULL) {
            NOTE("No colour type");
            return E_OUTOFMEMORY;
        }
    }

    // First of all we check that the new output type requires a palette and
    // if so then we give it out fixed palette, this is the case even if it
    // comes with a palette attached (as some codecs provide) because we can
    // only dither to our own special fixed palette that we can optimise

    if (pVideoInfo->bmiHeader.biBitCount == 8) {
        pVideoInfo = PreparePalette(pmtOut);
        if (pVideoInfo == NULL) {
            NOTE("No palette type");
            return E_OUTOFMEMORY;
        }
    }

    // The colour convertor filter shows DIB format images by default
    // Do this last since some of the things we called remunge the
    // data

    if (pVideoInfo->bmiHeader.biHeight < 0) {
        pVideoInfo->bmiHeader.biHeight = -pVideoInfo->bmiHeader.biHeight;
        NOTE("Height in source video is negative (top down DIB)");
    }

    return NOERROR;
}


// Called to prepare the allocator's count of buffers and sizes, we don't care
// who provides the allocator so long as it will give us a media sample. The
// output format we produce is not temporally compressed so in principle we
// could use any number of output buffers but it doesn't appear to gain much
// performance and does add to the overall memory footprint of the system

HRESULT CColour::DecideBufferSize(IMemAllocator *pAllocator,
                                  ALLOCATOR_PROPERTIES *pProperties)
{
    NOTE("Entering DecideBufferSize");
    ASSERT(pAllocator);
    ASSERT(pProperties);
    HRESULT hr = NOERROR;

    pProperties->cBuffers = COLOUR_BUFFERS;
    pProperties->cbBuffer = m_mtOut.GetSampleSize();
    ASSERT(pProperties->cbBuffer);

    // Ask the allocator to reserve us some sample memory, NOTE the function
    // can succeed (that is return NOERROR) but still not have allocated the
    // memory that we requested, so we must check we got whatever we wanted

    ALLOCATOR_PROPERTIES Actual;
    hr = pAllocator->SetProperties(pProperties,&Actual);
    if (FAILED(hr)) {
        NOTE("Properties failed");
        return hr;
    }

    // Did we get the buffering requirements

    if (Actual.cbBuffer >= (LONG) m_mtOut.GetSampleSize()) {
        if (Actual.cBuffers >= COLOUR_BUFFERS) {
            NOTE("Request ok");
            return NOERROR;
        }
    }
    return VFW_E_SIZENOTSET;
}

inline BOOL CColour::IsUsingFakeAllocator( )
{
    if( m_ColourInputPin.Allocator() == (IMemAllocator *)&m_ColourAllocator )
    {
        return TRUE;
    }
    return FALSE;
}

// Called when the filter goes into a running or paused state. By this point
// the input and output pins must have been connected with valid media types
// We use these media types to find a position in the transform table. That
// position will be used to create the appropriate convertor object. When
// the convertor object is created it will also be committed ready to work

HRESULT CColour::StartStreaming()
{
    NOTE("Entering StartStreaming");
    CAutoLock cAutoLock(&m_csReceive);

    // Have we already got a convertor

    if (m_pConvertor) {
        NOTE("Already active");
        return NOERROR;
    }

    m_bPassThrough = FALSE;

    // Can we start off in pass through mode
    // This only works if we're using our own allocator
    // otherwise the video renderer might get samples from an allocator
    // it doesn't understand

    if( IsUsingFakeAllocator( ) )
    {
        if( m_ColourInputPin.CanSupplyType(&m_mtOut) == S_OK )
        {
            m_bPassThrough = m_bPassThruAllowed;
        }
    }
    return CreateConvertorObject();
}


// Creates an object to do the conversion work. We may be called while we are
// streaming to recreate a convertor object based on a changed output format.
// For several of the convertors the create and commit is very expensive so
// we check that the new object required is not the same as the current. If
// it is the same then we simply reinitialise the rectangles as they may be
// different. If the convertor object has changed then we create a new one

HRESULT CColour::CreateConvertorObject()
{
    VIDEOINFO *pIn = (VIDEOINFO *) m_pInput->CurrentMediaType().Format();
    VIDEOINFO *pOut = (VIDEOINFO *) m_mtOut.Format();
    NOTE("Entering CreateConvertorObject");

    // Create an object to do the conversions

    INT TypeIndex = FindTransform(m_pInput->CurrentMediaType().Subtype(),m_mtOut.Subtype());
    if (TypeIndex == (-1)) {
        NOTE("No transform available");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // This handles dynamic format changes efficiently

    if (m_pConvertor) {
        if (m_TypeIndex == TypeIndex) {
            m_pConvertor->InitRectangles(pIn,pOut);
            NOTE("Using sample convertor");
            return NOERROR;
        }
    }

    DeleteConvertorObject();

    // Use the static creation function
    m_pConvertor = TypeMap[TypeIndex].pConvertor(pIn,pOut);
    if (m_pConvertor == NULL) {
        NOTE("Create failed");
        ASSERT(m_pConvertor);
        return E_OUTOFMEMORY;
    }

    // the converter defaults to NOT filling in the alpha channel,
    // if it's not the directdraw color convertor
    //
    if( ( *m_mtOut.Subtype( ) == MEDIASUBTYPE_ARGB32 ) && ( *m_pInput->CurrentMediaType( ).Subtype( ) != MEDIASUBTYPE_ARGB32 ) )
    {
        m_pConvertor->SetFillInAlpha( );
    }

    // Commit the convertor

    m_TypeIndex = TypeIndex;
    m_pConvertor->Commit();
    NOTE("Commit convertor");
    return NOERROR;
}


// Destroys any object created to do the conversions

HRESULT CColour::DeleteConvertorObject()
{
    NOTE("Entering DeleteConvertorObject");

    // Do we have a convertor created

    if (m_pConvertor == NULL) {
        NOTE("None made");
        return NOERROR;
    }

    // Decommit and free the object

    m_pConvertor->Decommit();
    delete m_pConvertor;
    NOTE("Delete convertor");

    // Reset the convertor state

    m_pConvertor = NULL;
    m_TypeIndex = (-1);
    return NOERROR;
}


// Called when a media type is set on either of our pins. The convertors find
// it much easier to handle strides and offsets if they can be sure that the
// source and destination rectangles in the output format have been fully set
// This function fills them out if they have been left empty. We don't really
// care about the source type rectangles so we just zero fill both of them

HRESULT CColour::SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt)
{
    NOTE("Entering SetMediaType");
    CAutoLock cAutoLock(&m_csReceive);

    // Take a copy of the input type

    if (direction == PINDIR_INPUT) {
        return NOERROR;
    }

    // Return the VIDEOINFO after the copy

    VIDEOINFO *pSource = (VIDEOINFO *) m_pInput->CurrentMediaType().Format();

    m_mtOut = *pmt;

    // Likewise set the output rectangles

    VIDEOINFO *pTarget = (VIDEOINFO *) m_mtOut.Format();
    if (IsRectEmpty(&pTarget->rcSource)) {
        pTarget->rcSource.left = pTarget->rcSource.top = 0;
        pTarget->rcSource.right = pSource->bmiHeader.biWidth;
        pTarget->rcSource.bottom = ABSOL(pSource->bmiHeader.biHeight);
        NOTE("Output source rectangle was empty");
    }

    // Make sure the destination is filled out

    if (IsRectEmpty(&pTarget->rcTarget)) {
        pTarget->rcTarget.left = pTarget->rcTarget.top = 0;
        pTarget->rcTarget.right = pTarget->bmiHeader.biWidth;
        pTarget->rcTarget.bottom = ABSOL(pTarget->bmiHeader.biHeight);
        NOTE("Output destination rectangle was empty");
    }
    return NOERROR;
}


// Called when one of our pins is disconnected

HRESULT CColour::BreakConnect(PIN_DIRECTION dir)
{
    NOTE("Entering BreakConnect");
    CAutoLock cAutoLock(&m_csReceive);
    DeleteConvertorObject();

    if (dir == PINDIR_OUTPUT) {
        m_bOutputConnected = FALSE;
        m_mtOut.SetType(&GUID_NULL);
        NOTE("Reset output format");
        return NOERROR;
    }

    ASSERT(dir == PINDIR_INPUT);
    return NOERROR;
}


// We override this virtual transform function to return our own base input
// class. The reason we do this is because we want more control over what
// happens when Receive is called. If we are doing a real pass through with
// no buffer copy then when Receive is called we pass it straight to the
// sink filter. This also requires some manipulation with the allocators

CBasePin *CColour::GetPin(int n)
{
    NOTE("Entering GetPin");

    if (m_pInput == NULL) {
        HRESULT hr = S_OK;

        m_pOutput = (CTransformOutputPin *) new CColourOutputPin(
            NAME("Transform output pin"),
            this,            // Owner filter
            &hr,             // Result code
            L"XForm Out");   // Pin name

        // Can't fail
        ASSERT(SUCCEEDED(hr));

        // Only set the input pin pointer if we have an output pin
        if (m_pOutput != NULL)
            m_pInput = &m_ColourInputPin;
    }

    // Return the appropriate pin
    if (n == 0)
        return m_pInput;
    else if (n == 1)
        return m_pOutput;
    else
        return NULL;
}


// This colour space filter offers all permutations of the RGB formats. It is
// therefore never really valid to try and connect a convertor to another one
// The reason why this might be harmful is when trying to make a connection
// between filters that really can't be made (for example MPEG decoder and
// audio renderer), the filtergraph chains up a number of colour convertors
// to try and make the connection. This speeds up failure connection times.

HRESULT CColour::CheckConnect(PIN_DIRECTION dir,IPin *pPin)
{
    PIN_INFO PinInfo;
    ASSERT(pPin);
    CLSID Clsid;

    // Only applicable to output pins

    if (dir == PINDIR_INPUT) {
        return NOERROR;
    }

    ASSERT(dir == PINDIR_OUTPUT);
    pPin->QueryPinInfo(&PinInfo);
    PinInfo.pFilter->GetClassID(&Clsid);
    QueryPinInfoReleaseFilter(PinInfo);

    // Are we connecting to a colour filter

    if (Clsid == CLSID_Colour) {
        return E_FAIL;
    }
    return NOERROR;
}


// There is one slight snag to the colour convertion filter. The source may
// be able to give us any number of different formats, if when we get round
// to completing the output pin connection we find the source could supply
// the output type directly then we reconnect the pin. By agreeing the same
// type for input and output we are most likely to be able to pass through

HRESULT CColour::CompleteConnect(PIN_DIRECTION dir,IPin *pReceivePin)
{
    NOTE("Entering CompleteConnect");
    CAutoLock cAutoLock(&m_csReceive);
    ASSERT(m_pConvertor == NULL);
    ASSERT(m_TypeIndex == (-1));

    // Need this for reconnecting

    if (m_pGraph == NULL) {
        NOTE("No filtergraph");
        return E_UNEXPECTED;
    }

	// Load the non RGB formats the source supplies

    if (dir == PINDIR_INPUT) {
	m_fReconnecting = FALSE;	// the reconnect is obviously over
        NOTE("Loading media types from source filter");
        LoadMediaTypes(m_ColourInputPin.GetConnected());
        if (m_bOutputConnected == TRUE) {
            NOTE("Reconnecting output pin");
            m_pGraph->Reconnect(m_pOutput);
        }
        return NOERROR;
    }

    return NOERROR;
}

// Separated from the normal CompleteConnect because we want this to
// execute after the NotifyAllocator negotiation, and the
// CTransformOutputPin base class calls us before
// NotifyAllocator. This is a temporary work-around for the VMR which
// is changing the connection type during NotifyAllocator breaking
// reconnects.
// 
HRESULT CColour::OutputCompleteConnect(IPin *pReceivePin)
{
    NOTE("Entering CompleteConnect");
    CAutoLock cAutoLock(&m_csReceive);
    ASSERT(m_pConvertor == NULL);
    ASSERT(m_TypeIndex == (-1));

    // Need this for reconnecting

    if (m_pGraph == NULL) {
        NOTE("No filtergraph");
        return E_UNEXPECTED;
    }

    m_bOutputConnected = TRUE;

    // Reconnect our input pin  to match with the output format
    if (*m_pInput->CurrentMediaType().Subtype() != *m_mtOut.Subtype()) {
        if (m_ColourInputPin.CanSupplyType(&m_mtOut) == NOERROR) {
            NOTE("Reconnecting input pin");
	    // !!! If the reconnect fails, we'll never let our input accept
	    // types other than the output type, but that's not a big deal,
	    // this code worked like that for 1.0
	    m_fReconnecting = TRUE;	// this will make our input only accept
					// a type that matches our output

            //  Pass the type to the reconnect.
            //  Sometimes when we get to the Connect call our caller
            //  doesn't know what type to use and in fact we don't bother
            //  to enumerate our output type in GetMediaType
            ReconnectPin(m_pInput, &m_mtOut);
        }
    }
    return NOERROR;


}


// Constructor for our colour space allocator

CColourAllocator::CColourAllocator(TCHAR *pName,
                                   CColour *pColour,
                                   HRESULT *phr,
                                   CCritSec *pLock) :
    CMemAllocator(pName,NULL,phr),
    m_pColour(pColour),
    m_pLock(pLock)
{
    ASSERT(pColour);
    ASSERT(m_pLock);
    m_fEnableReleaseCallback = FALSE;
}


// Overriden to increment the owning object's reference count

STDMETHODIMP_(ULONG) CColourAllocator::NonDelegatingAddRef()
{
    NOTE("Entering allocator AddRef");
    return m_pColour->AddRef();
}


// Overriden to decrement the owning object's reference count

STDMETHODIMP_(ULONG) CColourAllocator::NonDelegatingRelease()
{
    NOTE("Entering allocator Release");
    return m_pColour->Release();
}


// If the sample was released without calling Receive then we must release the
// output buffer we were holding ready for the transform. If we are not using
// our allocator then this should never be called. If we are passing through
// and the source filter releases its sample then it will be released directly
// into the downstream filters allocator rather than ours. This should not be
// a problem because we hold no resources when we pass back the output sample

STDMETHODIMP CColourAllocator::ReleaseBuffer(IMediaSample *pSample)
{
    NOTE("Entering ReleaseBuffer");
    CheckPointer(pSample,E_POINTER);
    CAutoLock cAutoLock(m_pLock);

    // Release the output buffer we were going to use

    if (m_pColour->m_pOutSample) {
        NOTE("Output buffer needs releasing");
        m_pColour->m_pOutSample->Release();
        m_pColour->m_pOutSample = NULL;
    }
    return CMemAllocator::ReleaseBuffer(pSample);
}


// Ask the output sample for its media type. This will return NULL if it is
// the same as the previous buffer. If it is non NULL then the target filter
// is asking us to change the output format. We only change when non NULL
// otherwise we would have to compare types on all the samples. If we can't
// get the source filter to supply the type directly then we will have to do
// a conversion ourselves. Because the buffer may be discarded as preroll we
// must create a new convertor object whenever we switch out of pass through

BOOL CColourAllocator::ChangeType(IMediaSample *pIn,IMediaSample *pOut)
{
    NOTE("Entering ChangeType");
    AM_MEDIA_TYPE *pMediaType;

    // Has the output format been changed

    pOut->GetMediaType(&pMediaType);
    if (pMediaType == NULL) {
        NOTE("Output format is unchanged");
        return m_pColour->m_bPassThrough;
    }

    CMediaType cmt(*pMediaType);
    DeleteMediaType(pMediaType);
    NOTE("Trying output format");

    // It's changed but can the source supply it directly

    if (m_pColour->m_ColourInputPin.CanSupplyType(&cmt) == S_OK) {
        NOTE("Passing output sample back");
        m_pColour->m_bPassThrough = m_pColour->m_bPassThruAllowed;
        return TRUE;
    }

    // Reset the source format if necessary

    if (m_pColour->m_bPassThrough == TRUE) {
        pIn->SetMediaType(&m_pColour->m_pInput->CurrentMediaType());
        NOTE("Reset format for source filter");
    }

    // Create a new convertor object

    NOTE("Forcing update after output changed");
    m_pColour->SetMediaType(PINDIR_OUTPUT,&cmt);
    m_pColour->CreateConvertorObject();
    m_pColour->m_bPassThrough = FALSE;

    return FALSE;
}

// ehr:  This is only called when our own special allocator is being used on the
// input pin. We IMMEDIATELY get an output buffer from the output pin.
// (This will either be an allocator that we created ourselves, or the downstream
// filter's allocator) (In any case, it's a place to put bits). Then we check
// and see if we can receive the bits directly into this (output) buffer. If so,
// we pass back the output's buffer to fill. If we cannot receive
// directly into the output buffer, we pass back the buffer we allocated in this
// fake allocator.

// This is an implementation of GetBuffer we have for our own allocator. What
// we do when asked for a buffer is to immediately get an output buffer from
// the target filter. Having got that we can then assertain whether we can
// act as a pass through filter and simply pass the output buffer back to the
// source filter to fill. If we can't pass through then we store the output
// buffer in the filter and when delivered the input sample do the transform

STDMETHODIMP CColourAllocator::GetBuffer(IMediaSample **ppBuffer,
                                         REFERENCE_TIME *pStart,
                                         REFERENCE_TIME *pEnd,
                                         DWORD dwFlags)
{
    CheckPointer(ppBuffer,E_POINTER);
    IMediaSample *pInput, *pOutput;
    NOTE("Entering GetBuffer");
    HRESULT hr = NOERROR;
    *ppBuffer = NULL;


    // Get a normal buffer from the colour allocator

    hr = CBaseAllocator::GetBuffer(&pInput,pStart,pEnd,0);
    if (FAILED(hr) || pInput == NULL) {
        NOTE("No input buffer");
        return VFW_E_STATE_CHANGED;
    }

    // If our allocator (used by our input pin) has more than 1 buffer,
    // calling our output pin's allocator's GetBuffer (like we're about to
    // do) may HANG!  Chances are, downstream is a video renderer, with only
    // 1 buffer, so if we have >1 buffer for our input, and the upstream filter
    // decides to call GetBuffer >1 times (which the proxy does) we will HANG
    // blocked forever trying to get multiple buffers at a time from the
    // video renderer.
    // If the notify interface is set we have to return the buffer
    // immediately so don't try passthru

    if (m_lCount > 1) {
        *ppBuffer = pInput;
        return hr;
    }

    // Then get an output buffer from the downstream filter

    hr = m_pColour->m_pOutput->GetDeliveryBuffer(&pOutput,pStart,pEnd,dwFlags);
    if (FAILED(hr) || pOutput == NULL) {
        NOTE("No output buffer");
        pInput->Release();
        return VFW_E_STATE_CHANGED;
    }

    CAutoLock cAutoLock(m_pLock);

    // Handle dynamic format changes and set the output buffers

    if (ChangeType(pInput,pOutput) == TRUE) {
        NOTE("Passing through");
        *ppBuffer = pOutput;
        pInput->Release();
        return NOERROR;
    }

    // Pass back the downstream buffer

    NOTE("Returning transform buffer");
    m_pColour->m_pOutSample = pOutput;
    *ppBuffer = pInput;
    return NOERROR;
}


STDMETHODIMP CColourAllocator::SetProperties(
    	    ALLOCATOR_PROPERTIES* pRequest,
    	    ALLOCATOR_PROPERTIES* pActual)
{
    //  Don't support more than 1 buffer or passthrough won't work
    if (pRequest->cBuffers > 1) {
        return E_INVALIDARG;
    }
    HRESULT hr = CMemAllocator::SetProperties(pRequest, pActual);
    ASSERT(FAILED(hr) || m_lCount <= 1);
    return hr;
}

// Constructor for our colour space conversion input pin

CColourInputPin::CColourInputPin(TCHAR *pObjectName,
                                 CColour *pColour,
                                 CCritSec *pLock,
                                 HRESULT *phr,
                                 LPCWSTR pName) :

    CTransformInputPin(pObjectName,pColour,phr,pName),
    m_pColour(pColour),
    m_pLock(pLock)
{
    ASSERT(pObjectName);
    ASSERT(m_pColour);
    ASSERT(phr);
    ASSERT(pName);
    ASSERT(m_pLock);
}


// Can the source pin supply a format directly. We can't pass through eight
// bit formats because managing palette changes by a source filter is too
// hard to do. In any case the value of this filter in the DirectDraw cases
// is to dither when the source cannot but pass through true colour formats
// when we switch surfaces in the renderer (without involving a data copy)

HRESULT CColourInputPin::CanSupplyType(const AM_MEDIA_TYPE *pMediaType)
{
    NOTE("Entering CanSupplyType");

    // Is the input pin connected

    if (m_Connected == NULL) {
        NOTE("Not connected");
        return VFW_E_NOT_CONNECTED;
    }

#if 0	// we can now
    // We cannot pass through palettised formats
    if (pMediaType->subtype == MEDIASUBTYPE_RGB8) {
        NOTE("Cannot pass palettised");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
#endif

#if 0	// what was this???
    // We cannot pass through if the source is palettised
    if (*CurrentMediaType().Subtype() == MEDIASUBTYPE_RGB8) {
        NOTE("Source format palettised");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
#endif

    return m_Connected->QueryAccept(pMediaType);
}


#ifdef MEANINGLESS_DRIVEL
// If we have our input pin reconnected while the output is connected we are
// very picky about which formats we accept. Basicly we only accept the same
// subtype as the output. This covers over a problem in pass through filters
// where they don't try to match input and output formats when they reconnect
// their input pins, all they do is QueryAccept on the downstream filter. As
// we accept just about anything we have to do the format matching for them.
#else
// !!! Don't listen to the above paragraph.  Here's what's really going on.
// We would love to be connected in a pass-through mode, without changing
// the format.  Let's say you connect two filters through a colour converter,
// and it just so happens they connect with RGB32 being transformed to RGB24.
// It just so happens that if we had insisted on making the filter before us
// produce RGB24, it would have, so we could have been clever and connected
// as RGB24 to RGB24 (pass through) but we didn't.  So we get around that by,
// everytime we finish connecting our output, forcing a reconnect of our
// input.  And the reconnect of our input will only allow the same format as
// the output.  So what happens is, you connect a filter to the input of the
// colour converter, and it will pick an input at random, say RGB32.  Now you
// connect the output to somebody who only accepts 24 bit.  This will,
// behind your back, check to see if the filter before the converter can
// supply 24 bit RGB.  If so, it will trigger a reconnect of the input pin
// (behind your back) and this code below will only allow the reconnect
// to be made with RGB24.  Voila.  You will, by default, get the converter
// in a pass through mode instead of a converting mode whenever possible.

// The bad thing about this method is that if somebody has a graph connected
// where a colour converter is transforming (say, RGB32 to RGB24) and you
// disconnect the input pin and reconnect it, it will FAIL to reconnect
// unless the filter before it can supply RGB24 because it will think it's
// in the wierd mode described above.

// So to make everything work, if we're reconnecting our input, we'll accept
// any type if the source cannot supply the output format, but only the
// output type if the source can supply it.
#endif

HRESULT CColourInputPin::CheckMediaType(const CMediaType *pmtIn)
{
    CheckPointer(pmtIn,E_POINTER);
    CAutoLock cAutoLock(m_pLock);
    CMediaType OutputType;
    NOTE("Entering CheckMediaType");

    // Has the output pin been created yet

    if (m_pColour->m_pOutput == NULL) {
        NOTE("No output pin instantiated yet");
        return CTransformInputPin::CheckMediaType(pmtIn);
    }

    // Do we have an output pin connection at the moment

    if (CurrentMediaType().IsValid() == TRUE) {
        if (m_pColour->m_mtOut.IsValid() == TRUE) {
	    // If we are in our "reconnecting" mode, we're only supposed to
	    // accept a format that matches our output
            if (*pmtIn->Subtype() != *m_pColour->m_mtOut.Subtype() &&
				m_pColour->m_fReconnecting) {
#if 0	// we allow 8->8 now
                	(*m_pColour->m_mtOut.Subtype() == MEDIASUBTYPE_RGB8)
#endif
                    NOTE("Formats don't yet match");
                    return VFW_E_TYPE_NOT_ACCEPTED;
            }
        }
    }
    return CTransformInputPin::CheckMediaType(pmtIn);
}



// This overrides the CBaseInputPin virtual method to return an allocator we
// have derived from CMemAllocator so we can control calls made to GetBuffer
// When NotifyAllocator is called it sets the current allocator in the base
// input pin class (m_pAllocator), this is what GetAllocator should return
// unless it is NULL in which case we return the allocator we would like

STDMETHODIMP CColourInputPin::GetAllocator(IMemAllocator **ppAllocator)
{
    CheckPointer(ppAllocator,E_POINTER);
    CAutoLock cAutoLock(m_pLock);
    NOTE("Entering GetAllocator");

    // Has an allocator been set yet in the base class

    if (m_pAllocator == NULL) {
        NOTE("Allocator not yet instantiated");
        m_pAllocator = &m_pColour->m_ColourAllocator;
        m_pAllocator->AddRef();
    }

    // Store and AddRef the allocator

    m_pAllocator->AddRef();
    *ppAllocator = m_pAllocator;
    NOTE("AddRef on allocator");
    return NOERROR;
}


// When we do a transform from input sample to output we also copy the source
// properties to the output buffer. This ensures that things like time stamps
// get propogated downstream. The other properties we are interested in are
// the preroll, sync point, discontinuity and the actual output data length
// These are already placed if we pass the output buffer back to the source

void CColourInputPin::CopyProperties(IMediaSample *pSrc,IMediaSample *pDst)
{
    // Copy the start and end times

    REFERENCE_TIME TimeStart,TimeEnd;
    if (pSrc->GetTime(&TimeStart,&TimeEnd) == NOERROR) {
	pDst->SetTime(&TimeStart,&TimeEnd);
    }

    // Copy the associated media times (if set)

    LONGLONG MediaStart,MediaEnd;
    if (pSrc->GetMediaTime(&MediaStart,&MediaEnd) == NOERROR) {
        pDst->SetMediaTime(&MediaStart,&MediaEnd);
    }

    // Copy the Sync point property

    HRESULT hr = pSrc->IsSyncPoint();
    BOOL IsSync = (hr == S_OK ? TRUE : FALSE);
    pDst->SetSyncPoint(IsSync);

    // Copy the preroll property

    hr = pSrc->IsPreroll();
    BOOL IsPreroll = (hr == S_OK ? TRUE : FALSE);
    pDst->SetPreroll(IsPreroll);

    // Copy the discontinuity property

    hr = pSrc->IsDiscontinuity();
    BOOL IsBreak = (hr == S_OK ? TRUE : FALSE);
    pDst->SetDiscontinuity(IsBreak);
    pDst->SetActualDataLength(pDst->GetSize());
}


// We override this from the base transform class input pin because we want
// to pass through samples. If the downstream filter asks for a media type
// and the source filter can supply it directly then so long as the source
// is using our allocator we will pass through samples without us touching
// them (and therefore NOT copying the data from input to output). By doing
// this we can act as a null filter when appropriate but also do conversions
// as and when required (maybe the sink filter lost its DirectDraw surface)

STDMETHODIMP CColourInputPin::Receive(IMediaSample *pSample)
{
    CheckPointer(pSample,E_POINTER);
    CAutoLock cAutoLock(m_pLock);
    NOTE("Entering Receive");

    // Is this sample just passing through? Only two places change this flag:
    // StartStreaming( ), and ChangeType( ). ChangeType is checked every time
    // the input allocator's GetBuffer is called.
    // !!! can we optimize that?

    if (m_pColour->m_bPassThrough == TRUE)
    {
        NOTE("Sample received was a pass through");
        HRESULT hr = CheckStreaming();
        if (S_OK == hr)
        {
            hr =  m_pColour->m_pOutput->Deliver(pSample);
        }
        return hr;
    }

    // Check for type changes and streaming for optimizing cases

    if (m_pColour->m_pOutSample != NULL) {
        HRESULT hr = CBaseInputPin::Receive(pSample);
        if (S_OK != hr) {
            return hr;
        }
    }


    // Default behaviour if not using our input pin allocator

    if (m_pColour->m_pOutSample == NULL) {
        NOTE("Passing to base transform class");
        return CTransformInputPin::Receive(pSample);
    }

    // Call the colour conversion filter to do the transform

    NOTE("Sample was not a pass through (doing transform)");
    CopyProperties(pSample,m_pColour->m_pOutSample);
    m_pColour->Transform(pSample,m_pColour->m_pOutSample);
    HRESULT hr = m_pColour->m_pOutput->Deliver(m_pColour->m_pOutSample);

    // Release the output sample

    NOTE("Delivered the sample");
    m_pColour->m_pOutSample->Release();
    m_pColour->m_pOutSample = NULL;
    return hr;
}


// Simply ask the enumerator for the next media type and return a pointer to
// the memory allocated by the interface. Whoever calls this function should
// release the media type when they are finished using the DeleteMediaType

AM_MEDIA_TYPE *CColour::GetNextMediaType(IEnumMediaTypes *pEnumMediaTypes)
{
    NOTE("Entering GetNextMediaType");
    ASSERT(pEnumMediaTypes);
    AM_MEDIA_TYPE *pMediaType = NULL;
    ULONG ulMediaCount = 0;
    HRESULT hr = NOERROR;

    // Retrieve the next media type

    hr = pEnumMediaTypes->Next(1,&pMediaType,&ulMediaCount);
    if (hr != NOERROR) {
        return NULL;
    }

    // Quick sanity check on the returned values

    ASSERT(ulMediaCount == 1);
    ASSERT(pMediaType);
    return pMediaType;
}


// Scan the list deleting the media types in turn

void CColour::InitTypeList()
{
    NOTE("Entering InitTypeList");
    POSITION pos = m_TypeList.GetHeadPosition();
    while (pos) {
        AM_MEDIA_TYPE *pMediaType = m_TypeList.GetNext(pos);
        DeleteMediaType(pMediaType);
    }
    m_TypeList.RemoveAll();
}


// The colour conversion filter exposes five typical media types, namely RGB8
// RGB555/565/24 and RGB32 or ARGB32. We can also act as a pass through filter so that
// we effectively do nothing and add no copy overhead. This does however mean
// that the list of media types we support through our enumerator must include
// the NON RGB formats of our source filter - this method loads these formats

HRESULT CColour::FillTypeList(IEnumMediaTypes *pEnumMediaTypes)
{
    NOTE("Entering FillTypeList");
    ASSERT(pEnumMediaTypes);
    IPin *pPin;

    // Reset the current enumerator position

    HRESULT hr = pEnumMediaTypes->Reset();
    if (FAILED(hr)) {
        NOTE("Reset failed");
        return hr;
    }

    // Get the output pin we are connecting with

    hr = m_pInput->ConnectedTo(&pPin);
    if (FAILED(hr)) {
        NOTE("No pin");
        return hr;
    }

    // When we retrieve each source filter type from it's enumerator we check
    // that it is useful, meaning we can provide some transforms with it, if
    // not then we must make sure we delete it with the global task allocator

    AM_MEDIA_TYPE *pMediaType = NULL;
    while (TRUE) {

        // Retrieve the next media type from the enumerator

        pMediaType = GetNextMediaType(pEnumMediaTypes);
        if (pMediaType == NULL) {
            NOTE("No more types");
            pPin->Release();
            return NOERROR;
        }

        // BEWARE QueryAccept returns S_FALSE on failure

        hr = pPin->QueryAccept(pMediaType);
        if (hr != S_OK) {
            NOTE("Source rejected type");
            DeleteMediaType(pMediaType);
            continue;
        }

        // Check this is a video format

        hr = CheckVideoType(pMediaType);
        if (FAILED(hr)) {
            NOTE("Source rejected type");
            DeleteMediaType(pMediaType);
            continue;
        }

        // Is this a RGB format (either BI_RGB or BI_BITFIELDS)

        VIDEOINFO *pVideoInfo = (VIDEOINFO *) pMediaType->pbFormat;
        if (pVideoInfo->bmiHeader.biCompression == BI_RGB ||
                pVideoInfo->bmiHeader.biCompression == BI_BITFIELDS) {
                    DeleteMediaType(pMediaType);
                    NOTE("Format is RGB");
                    continue;
        }

        // Add the media type to the list

        POSITION pos = m_TypeList.AddTail(pMediaType);
        if (pos == NULL) {
            NOTE("AddTail failed");
            DeleteMediaType(pMediaType);
            pPin->Release();
            return E_OUTOFMEMORY;
        }
    }
}


// This is called when the input pin has it's media type set so that we can
// enumerate all the media types available from the connecting output pin
// These are used to prode the media types we can provide as output as that
// list is dependant on the source types combined with the transforms we do

HRESULT CColour::LoadMediaTypes(IPin *pPin)
{
    NOTE("Entering LoadMediaTypes");

    ASSERT(pPin);
    HRESULT hr;
    InitTypeList();

    IEnumMediaTypes *pEnumMediaTypes = NULL;

    // Query the output pin we are connecting to for a media type enumerator
    // which we use to provide a complete list of all the possible formats
    // that we can supply based on the different transforms we implement */

    hr = pPin->EnumMediaTypes(&pEnumMediaTypes);
    if (FAILED(hr)) {
        return hr;
    }

    ASSERT(pEnumMediaTypes);
    FillTypeList(pEnumMediaTypes);
    pEnumMediaTypes->Release();
    return NOERROR;
}


// Return the media type stored at this zero based position in the list

AM_MEDIA_TYPE *CColour::GetListMediaType(INT Position)
{
    NOTE("Entering GetListMediaType");
    AM_MEDIA_TYPE *pMediaType = NULL;
    Position += 1;

    // Scan the list from the start

    POSITION pos = m_TypeList.GetHeadPosition();
    while (Position--) {
        pMediaType = m_TypeList.GetNext(pos);
    }
    ASSERT(pMediaType);
    return pMediaType;
}

CColourOutputPin::CColourOutputPin(
    TCHAR * pObjectName,
    CColour * pFilter,
    HRESULT * phr,
    LPCWSTR pName )
: CTransformOutputPin( pObjectName, pFilter, phr, pName )
, m_pColour( pFilter )
{
}

HRESULT
CColourOutputPin::DecideAllocator(IMemInputPin *pPin, IMemAllocator **ppAlloc)
{
    HRESULT hr = NOERROR;
    *ppAlloc = NULL;

    // get downstream prop request
    // the derived class may modify this in DecideBufferSize, but
    // we assume that he will consistently modify it the same way,
    // so we only get it once
    ALLOCATOR_PROPERTIES prop;
    ZeroMemory(&prop, sizeof(prop));

    // whatever he returns, we assume prop is either all zeros
    // or he has filled it out.
    pPin->GetAllocatorRequirements(&prop);

    // if he doesn't care about alignment, then set it to 1
    if (prop.cbAlign == 0) {
        prop.cbAlign = 1;
    }

    /* Try the allocator provided by the input pin */

    // what is the read-only state of our input pin's allocator?
    //
    BOOL ReadOnly = m_pColour->m_pInput->IsReadOnly( );

    // preset the passthrough allowance to true.
    //
    m_pColour->m_bPassThruAllowed = TRUE;

    // if we're using some upstream guy's allocator, then we can never
    // "fake it out" and provide a passthru, so we don't have to worry
    // about whether to pass a ReadOnly flag downstream.
    //
    if( !m_pColour->IsUsingFakeAllocator( ) )
    {
        // well, we thought we were readonly, but
        // we're really not, so reset the readonly flag.
        //
        ReadOnly = FALSE;

        // never allow passthrough
        //
        m_pColour->m_bPassThruAllowed = FALSE;
    }

    hr = pPin->GetAllocator(ppAlloc);
    if (SUCCEEDED(hr))
    {
        // downstream pin provided an allocator to stuff things
        // into. We must inform the downstream allocator of the input
        // pin's ReadOnly status because once in a while, the "fake" allocator
        // on our input pin may pass back the output allocator's buffer, and
        // we want it to have the same properties.
        //
	hr = DecideBufferSize(*ppAlloc, &prop);

	if (SUCCEEDED(hr))
        {
	    hr = pPin->NotifyAllocator(*ppAlloc, ReadOnly );
	    if (SUCCEEDED(hr))
            {
                return NOERROR;
	    }
            // the downstream pin didn't like being told to be
            // read only, so change flag to never allow passthrough mode
            // and then ask the pin again if it will accept read/write
            // mode. This time it should work.
            //
            m_pColour->m_bPassThruAllowed = FALSE;
	    hr = pPin->NotifyAllocator(*ppAlloc, FALSE);
	    if (SUCCEEDED(hr))
            {
                return NOERROR;
	    }
	}
    }

    /* If the GetAllocator failed we may not have an interface */

    if (*ppAlloc) {
	(*ppAlloc)->Release();
	*ppAlloc = NULL;
    }

    /* Try the output pin's allocator by the same method */

    hr = InitAllocator(ppAlloc);
    if (SUCCEEDED(hr))
    {
        // note - the properties passed here are in the same
        // structure as above and may have been modified by
        // the previous call to DecideBufferSize
	hr = DecideBufferSize(*ppAlloc, &prop);

	if (SUCCEEDED(hr))
        {
	    hr = pPin->NotifyAllocator(*ppAlloc, ReadOnly);
	    if (SUCCEEDED(hr))
            {
                return NOERROR;
	    }
            // the downstream pin didn't like being told to be
            // read only, so change flag to never allow passthrough mode
            // and then ask the pin again if it will accept read/write
            // mode. This time it should work.
            //
            m_pColour->m_bPassThruAllowed = FALSE;
	    hr = pPin->NotifyAllocator(*ppAlloc, FALSE);
	    if (SUCCEEDED(hr))
            {
                return NOERROR;
	    }
	}
    }

    /* Likewise we may not have an interface to release */

    if (*ppAlloc) {
	(*ppAlloc)->Release();
	*ppAlloc = NULL;
    }
    return hr;
}

HRESULT CColourOutputPin::CompleteConnect(IPin *pReceivePin)
{
    HRESULT hr = CTransformOutputPin::CompleteConnect(pReceivePin);
    if(SUCCEEDED(hr))
    {
        hr = m_pColour->OutputCompleteConnect(pReceivePin);
    }

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\h\stats.h ===
// Copyright (c) 1999  Microsoft Corporation.  All Rights Reserved.
//  Stats class stuff
//  This is essentially a collection of stats events

class CStats;

extern CStats g_Stats;

class CStat
{
public:
    LPWSTR m_szName;
    long    m_lCount;
    double m_dTotal;
    double m_dSumSq;
    double m_dMin;
    double m_dMax;
    double m_dLast;
    double m_dMultiplier;
    CStat(LPCWSTR lpszName);
    ~CStat();
    void Reset();
};

typedef CStat *PCSTAT;

// Array of stats
class CStats
{
public:
    CStats();
    ~CStats();

    void Init();

    //  Helper - get QueryPerformanceCounter multiplier for
    //  QPF->milliseconds
    double GetQPFMultiplier();

    long Find(LPCWSTR lpszStatName, bool bCrate = true);
    void Reset();
    bool NewValue(LPCWSTR lpszName, double dValue);
    bool NewValue(LPCWSTR lpszName, LONGLONG dValue);
    bool NewValue(long iStat, double dValue);
    double GetTime();
    void SetMultiplier(long iStat, double dMultiplier);

    //  Use this one to avoid the conversion inline in code
    bool NewValue(long iStat, LONGLONG llValue);
    HRESULT GetValues(
        long iStat,
        BSTR *szName,
        long *lCount,
        double *dLast,
        double *dAverage,
        double *dStdDev,
        double *dMin,
        double *dMax);

    class CAutoLock
    {
    public:
        CAutoLock(CRITICAL_SECTION *cs)
        {
            EnterCriticalSection(cs);
            m_cs = cs;
        }
        ~CAutoLock()
        {
            LeaveCriticalSection(m_cs);
        }
        CRITICAL_SECTION *m_cs;
    };

public:
    CStat **m_ppStats;
    long m_nEntries;
    enum { ALLOCATION_SIZE = 16 };
    CRITICAL_SECTION m_cs;
    double m_QPFMultiplier;
};

class CAutoTimer
{
public:
    CAutoTimer(LPCWSTR lpszStat, LPCWSTR lpszExtra = NULL) :
       m_iStat(-1)
    {
        if (lpszExtra) {
            int iLen = lstrlenWInternal(lpszStat);
            WCHAR *psz = (WCHAR *)_alloca(sizeof(WCHAR) * (iLen + lstrlenWInternal(lpszExtra) + 1));
            CopyMemory(psz, lpszStat, sizeof(WCHAR) * iLen);
            lstrcpyWInternal(psz + iLen, lpszExtra);
            m_iStat = g_Stats.Find(psz);
        } else {
            m_iStat = g_Stats.Find(lpszStat);
        }
        if (m_iStat >= 0) {
            m_dTime = g_Stats.GetTime();
        }
    }
    ~CAutoTimer()
    {
        if (m_iStat >= 0) {
            g_Stats.NewValue(m_iStat, g_Stats.GetTime() - m_dTime);
        }
    }
private:
    long     m_iStat;
    double   m_dTime;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\h\callback.h ===
// Copyright (c) 1996 - 1998  Microsoft Corporation.  All Rights Reserved.

#ifndef __CALLBACK_H__
#define __CALLBACK_H__


// Definition of a class that provides asynchronous callbacks at a specific
// reference time.
//
// Objects that do not normally have a worker thread would use this to create
// a worker thread on demand for those occasions when it needs to trigger
// an asynchronous event, or when it wants several pieces to share the
// same worker thread in a controlled way.
//
// Callbacks are synchronised with the caller's critsec (passed in) so that
// cancellation and shutdown can be handled cleanly.
// The critsec passed in will be held across all advise calls and when handling
// the list of advises.
//
// It should not be held during a call to the destructor.

// Simplistic design is based the assumption that there will rarely be more
// than one or two advises on the list.

// Periodic callbacks are supported

// your callback function looks like this
typedef void (*CCallbackAdvise)(DWORD_PTR dwUserToken);



class CCallbackThread
{

public:
    CCallbackThread(CCritSec* pCritSec);
    ~CCallbackThread();

    // please call fnAdvise(dwUserToken) at time rtCallback.
    //
    // Returns:
    // HRESULT == Success
    //              pdwToken will be filled in with the token to pass to Cancel
    //         == FAILURE
    //              pdwToken is unchanged
    HRESULT Advise(
        CCallbackAdvise fnAdvise,
        DWORD_PTR dwUserToken,
        REFERENCE_TIME rtCallbackAt,
        DWORD_PTR* pdwToken
        );

    // please call fnAdvise(dwUserToken) every rtPeriod, or when
    // hEvent is signalled.  (hEvent is optional)
    //
    // WARNING: ONLY one user specified event handle can be active
    // at one time.  Subsequent calls to AdvisePeriodicWithEvent passing a
    // a hEvent will result in E_FAIL while the previous advise with an
    // hEvent is active.  THIS IS AN IMPLEMENTATION RESTRICTION which
    // may be lifted in future.
    //
    // If you do not want to use hEvent, pass NULL.
    //
    // Returns:
    // HRESULT == Success
    //              pdwToken will be filled in with the token to pass to Cancel
    //         == FAILURE
    //              pdwToken is unchanged

    HRESULT AdvisePeriodicWithEvent(
        CCallbackAdvise fnAdvise,
        DWORD_PTR dwUserToken,
        REFERENCE_TIME rtPeriod,
        HANDLE hEvent,
        DWORD_PTR* pdwToken
        );

    HRESULT ServiceClockSchedule(
        CBaseReferenceClock * pClock,
        CAMSchedule * pSchedule,
        DWORD * pdwToken
        );

    // cancel the requested callback. dwToken is a token
    // returned from Advise or AdvisePeriodicWithEvent
    HRESULT Cancel(DWORD_PTR dwToken);

    // pass in the clock to be used. Must call SetSyncSource(NULL) before
    // the clock object goes away (this is a weak reference)
    HRESULT SetSyncSource(IReferenceClock*);

    void CancelAllAdvises();

protected:
    HANDLE m_hThread;
    CCritSec* m_pCritSec;
    CAMEvent m_evSignalThread;
    BOOL     m_fAbort;
    CAMEvent m_evAdvise;
    IReferenceClock* m_pClock;
    DWORD_PTR m_dwAdvise;

    // some special members to deal with timeGetTime (TGT) periodic event.
    DWORD   m_dwTGTCallbackToken ;  // token used to identify TGT callback
    DWORD_PTR m_dwTGTUserToken ;      // token passed in by app.
    DWORD   m_dwNextTGTCallback ;   // next callback time for TGT.
    DWORD   m_dwTGTCallbackPeriod ; // millisecs till next callback
    CCallbackAdvise m_fnTGTCallback;// the TGT callback function


    // m_dwScheduleCookie == 0 <=> none of these are in use
    CBaseReferenceClock * m_pBaseClock;
    CAMSchedule     * m_pSchedule;
    HANDLE        m_hScheduleEvent;
    DWORD         m_dwScheduleCookie;

    class CAdviseItem   {
        CCallbackAdvise m_fnAdvise;
        DWORD_PTR m_dwUserToken;
        REFERENCE_TIME m_rtCallbackAt;
        REFERENCE_TIME m_rtPeriod;
        DWORD   m_dwAdviseFlags ;
    public:

        // Constructor can take a periodic time - or not
        CAdviseItem(CCallbackAdvise, DWORD_PTR, REFERENCE_TIME, REFERENCE_TIME=0, DWORD flags=0);

        REFERENCE_TIME Time() {
            return m_rtCallbackAt;
        };

        REFERENCE_TIME Period() {   
            return m_rtPeriod;
        };

        DWORD AdviseFlags() {   
            return m_dwAdviseFlags;
        };

        void SetTime (REFERENCE_TIME rt) {
            m_rtCallbackAt = rt ;
        } ;


// defines for m_dwAdviseFlags

#define ADVISE_PERIODIC_EXEMPT_FROM_RT 1     // the periodic advise is exempt from


        // If the advise is Periodic, update the time by one interval and return TRUE.
        // If the advise is not periodic, return FALSE
        BOOL UpdateTime(REFERENCE_TIME rtNow) {
            if (0 == m_rtPeriod) {
                return FALSE;
            }
            m_rtCallbackAt = m_rtPeriod + rtNow;
            return TRUE;
        };

        void Dispatch();
    };

    HANDLE m_evUser;

    CGenericList<CAdviseItem> m_Items;

    // make sure the thread is running
    HRESULT EnsureThread();

    // start the thread running (called from EnsureThread)
    HRESULT StartThread();

    // stop the thread and wait for it to exit. should not hold
    // critsec when doing this.
    void CloseThread();

    static DWORD InitialThreadProc(void *);
    DWORD ThreadProc(void);

    // dispatch any ripe advises
    void ProcessRequests(void);

    // dispatch due to user event being signalled
    void ProcessUserSignal(void);

    // get the earliest time in the list
    // returns S_FALSE if nothing in list otherwise S_OK
    HRESULT GetSoonestAdvise(REFERENCE_TIME& rrtFirst);

    // set up an advise on the clock
    HRESULT SetAdvise();

    // cancel any advise on the clock
    void CancelAdvise(void);
};


#endif // __CALLBACK_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\colour.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// This filter implements popular colour space conversions, May 1995

#ifndef __COLOUR__
#define __COLOUR__

extern const AMOVIESETUP_FILTER sudColourFilter;

// Forward declarations

class CColour;
class CColourAllocator;
class CColourInputPin;

#include <convert.h>

// We provide our own allocator for the input pin. We do this so that when a
// downstream filter asks if we can supply a given format we can see if our
// source will provide it directly - in which case we are effectively a null
// filter in the middle doing nothing. To handle this type changing requires
// an allocator. All we have to override is GetBuffer to manage which buffer
// to return (ours or the downstream filters if we are passing through) and
// also to handle released samples which haven't been passed to the input pin

class CColourAllocator : public CMemAllocator
{
    CColour *m_pColour;     // Main colour filter
    CCritSec *m_pLock;      // The receive lock

public:

    CColourAllocator(TCHAR *pName,
                     CColour *pColour,
                     HRESULT *phr,
                     CCritSec *pLock);

    // Overriden to delegate reference counts to the filter

    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();

    BOOL ChangeType(IMediaSample *pIn,IMediaSample *pOut);
    STDMETHODIMP ReleaseBuffer(IMediaSample *pSample);
    STDMETHODIMP GetBuffer(IMediaSample **ppBuffer,
                           REFERENCE_TIME *pStart,
                           REFERENCE_TIME *pEnd,
                           DWORD dwFlags);
    STDMETHODIMP SetProperties(
		    ALLOCATOR_PROPERTIES* pRequest,
		    ALLOCATOR_PROPERTIES* pActual);

};


// To help with returning our own allocator we must provide our own input pin
// instead of using the transform class. We override the input pin so that we
// can return our own allocator when GetAllocator is called. It also lets us
// handle Receive being called. If we are handed back a sample that we just
// passed through from the downstream filter then we only have to deliver it
// rather than do any colour conversion. We must cooperate with the allocator
// to do this switching - in particular the state of variable m_bPassThrough

class CColourInputPin : public CTransformInputPin
{
    CColour *m_pColour;     // Main colour filter
    CCritSec *m_pLock;      // The receive lock

public:

    CColourInputPin(TCHAR *pObjectName,     // DEBUG only string
                    CColour *pColour,       // Main colour filter
                    CCritSec *pLock,        // The receive lock
                    HRESULT *phr,           // Quartz return code
                    LPCWSTR pName);         // Actual pin name

    STDMETHODIMP GetAllocator(IMemAllocator **ppAllocator);
    STDMETHODIMP Receive(IMediaSample *pSample);
    HRESULT CheckMediaType(const CMediaType *pmtIn);
    HRESULT CanSupplyType(const AM_MEDIA_TYPE *pMediaType);
    void CopyProperties(IMediaSample *pSrc,IMediaSample *pDst);
    IMemAllocator *Allocator() const { return m_pAllocator; }
};

class CColourOutputPin : public CTransformOutputPin
{
    CColour * m_pColour;

public:

    CColourOutputPin(
        TCHAR *pObjectName,
        CColour * pTransformFilter,
        HRESULT * phr,
        LPCWSTR pName);

    HRESULT DecideAllocator(IMemInputPin *pPin, IMemAllocator **ppAlloc);
    HRESULT CompleteConnect(IPin *pReceivePin);
};

// This is the basic colour conversion filter, we inherit from the base class
// defined CTransformFilter so that it can look after most of the framework
// involved with setting up connections, providing media type enumerators and
// other generally boring hassle. This filter does all conversions from any
// input to any output which makes it much easier to agree input and output
// formats and to change them dynamically (such us when using DirectDraw) as
// we can guarantee never to have to reconnect the input pin. If we were not
// symmetrical we may have to reconnect the input to be able to provide some
// output formats (which is very hard to do when we are already streaming)

class CColour : public CTransformFilter
{
    friend class CColourAllocator;
    friend class CColourInputPin;
    friend class CColourOutputPin;

    // Typed media type list derived from the generic list template
    typedef CGenericList<AM_MEDIA_TYPE> CTypeList;

    CConvertor *m_pConvertor;               // Does the transform functions
    INT m_TypeIndex;                        // Current convertor position
    CColourAllocator m_ColourAllocator;     // Our own derived allocator
    CColourInputPin m_ColourInputPin;       // Our specialised input pin
    BOOL m_bPassThrough;                    // Are we just passing through
    BOOL m_bPassThruAllowed;                // can we go into pass-through?
    IMediaSample *m_pOutSample;             // Output buffer sample pointer
    BOOL m_bOutputConnected;                // Is the output really done
    CTypeList m_TypeList;                   // List of source media types
    CMediaType m_mtOut;                     // And likewise the output type
    BOOL m_fReconnecting;		    // reconnecting our input pin?

    // Prepare an output media type for the enumerator

    void DisplayVideoType(TCHAR *pDescription,const CMediaType *pmt);
    VIDEOINFO *PreparePalette(CMediaType *pmtOut);
    VIDEOINFO *PrepareTrueColour(CMediaType *pmtOut);
    HRESULT PrepareMediaType(CMediaType *pmtOut,const GUID *pSubtype);
    const GUID *FindOutputType(const GUID *pInputType,INT iIndex);
    INT FindTransform(const GUID *pInputType,const GUID *pOutputType);
    HRESULT CheckVideoType(const AM_MEDIA_TYPE *pmt);
    BOOL IsUsingFakeAllocator( );

    // Load and manage the list of YUV source formats

    AM_MEDIA_TYPE *GetNextMediaType(IEnumMediaTypes *pEnumMediaTypes);
    HRESULT FillTypeList(IEnumMediaTypes *pEnumMediaTypes);
    AM_MEDIA_TYPE *GetListMediaType(INT Position);
    HRESULT LoadMediaTypes(IPin *pPin);
    void InitTypeList();

public:

    // Constructor and destructor

    CColour(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr);
    ~CColour();

    // This goes in the factory template table to create new instances
    static CUnknown *CreateInstance(LPUNKNOWN pUnk,HRESULT *phr);

    // Manage type checking and the format conversions

    HRESULT CheckInputType(const CMediaType *pmtIn);
    HRESULT CheckTransform(const CMediaType *pmtIn,const CMediaType *pmtOut);
    HRESULT BreakConnect(PIN_DIRECTION dir);
    HRESULT CheckConnect(PIN_DIRECTION dir,IPin *pPin);
    HRESULT CompleteConnect(PIN_DIRECTION dir,IPin *pReceivePin);
    HRESULT OutputCompleteConnect(IPin *pReceivePin);
    HRESULT Transform(IMediaSample *pIn,IMediaSample *pOut);
    HRESULT PrepareTransform(IMediaSample *pIn,IMediaSample *pOut);
    HRESULT StartStreaming();

    // Prepare the allocator's count of buffers and sizes
    HRESULT DecideBufferSize(IMemAllocator *pAllocator,
                             ALLOCATOR_PROPERTIES *pProperties);

    // Overriden to manage the media type negotiation

    HRESULT GetMediaType(int iPosition,CMediaType *pmtOut);
    HRESULT SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt);
    HRESULT CreateConvertorObject();
    HRESULT DeleteConvertorObject();
    CBasePin *GetPin(int n);
};

#endif // __COLOUR__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\convert.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This filter implements popular colour space conversions, May 1995

#include <streams.h>
#include <colour.h>

// Constructor for a conversion to the given subtype. This base class is used
// by all the output type specific transform methods to initialise our state
// To keep the transforms as fast as possible we store the BITMAPINFOHEADER
// from the VIDEOINFO media format before starting (see the HEADER macro)
// The base class also looks after calculating strides and offsets so that we
// can source and target images from DCI/DirectDraw surfaces. Furthermore the
// base class handles alignment so that we can stream pixels very efficiently
// when they are DWORD aligned but handle the pixels at line ends that aren't

// The m_SrcStride will be set so that when added to the input image pointer
// will reference the first byte of the top scan line of the source. Likewise
// m_DstStride is set to when added to the output image pointer will point to
// the first byte of the output image top scan line. The source can then be
// transformed to the output and each of the scan line pointers moved on by
// m_SrcStride or m_DstStride respectively (these strides may be negative).
// Therefore both the source and target images can be upside down oriented

// We can handle input RGB images either top down or bottom up and can output
// both top down and bottom up so there are a total of four permutations of
// input and output image. InitRectangles looks after setting up the strides
// and offsets in all cases. Note that we always offer bottom up (DIB format)
// images to start with. The destination and source rectangles are stored as
// absolute values so they should not reflect any orientation of the image

CConvertor::CConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut) :

    m_pInputInfo(pIn),                  // Input image format VIDEOINFO
    m_pOutputInfo(pOut),                // And likewise format to go to
    m_pInputHeader(HEADER(pIn)),        // Extract the input header
    m_pOutputHeader(HEADER(pOut)),      // Also get the output header
    m_bCommitted(FALSE),                // Has the convertor been committed
    m_SrcOffset(0),                     // Source original offset
    m_SrcStride(0),                     // Length in bytes of a scan line
    m_DstStride(0),                     // Likewise offset into target
    m_DstOffset(0),                     // And the length of each line
    m_bAligned(FALSE),                  // Are the rectangles aligned
    m_bSetAlpha(FALSE)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Destructor

CConvertor::~CConvertor()
{
    ASSERT(m_bCommitted == FALSE);
}


// Change the alignment explicitely

void CConvertor::ForceAlignment(BOOL bAligned)
{
    m_bAligned = bAligned;
}


// To handle DirectDraw and DCI surfaces we have to be able to convert into
// upside down buffers and into buffers with different source and destination
// rectangles. This resets the four most interesting fields namely the source
// stride and offset - and the destination stride and offset. The derived
// classes can then use these fields during the colour space transformations

void CConvertor::InitRectangles(VIDEOINFO *pIn,VIDEOINFO *pOut)
{
    // Reset the VIDEOINFO state pointers

    m_bAligned = FALSE;
    m_pInputInfo = pIn;
    m_pOutputInfo = pOut;
    m_pInputHeader = HEADER(pIn);
    m_pOutputHeader = HEADER(pOut);

    // Check the source rectangle is ok and calculate the source stride

    ASSERT(m_pOutputInfo->rcSource.top <= m_pOutputInfo->rcSource.bottom);
    ASSERT(IsRectEmpty(&m_pOutputInfo->rcSource) == FALSE);
    m_SrcStride = DIBWIDTHBYTES(*m_pInputHeader);
    m_SrcStride = (m_pInputHeader->biHeight > 0) ? (-m_SrcStride) : m_SrcStride;

    // Set the source offset to reference the top scan line of the image

    m_SrcOffset = (m_pInputHeader->biHeight > 0) ? m_pInputHeader->biHeight : 1;
    m_SrcOffset = (m_SrcOffset - 1) * DIBWIDTHBYTES(*m_pInputHeader);
    m_SrcOffset += m_pOutputInfo->rcSource.top * m_SrcStride;
    m_SrcOffset += m_pOutputInfo->rcSource.left * m_pInputHeader->biBitCount / 8;

    // Likewise do the same for the destination rectangle and stride

    ASSERT(m_pOutputInfo->rcTarget.top <= m_pOutputInfo->rcTarget.bottom);
    ASSERT(IsRectEmpty(&m_pOutputInfo->rcTarget) == FALSE);
    m_DstStride = DIBWIDTHBYTES(*m_pOutputHeader);
    m_DstStride = (m_pOutputHeader->biHeight > 0) ? (-m_DstStride) : m_DstStride;

    // Calculate the offset to the top scan line of the image

    m_DstOffset = (m_pOutputHeader->biHeight > 0) ? m_pOutputHeader->biHeight : 1;
    m_DstOffset = (m_DstOffset - 1) * DIBWIDTHBYTES(*m_pOutputHeader);
    m_DstOffset += m_pOutputInfo->rcTarget.top * m_DstStride;
    m_DstOffset += m_pOutputInfo->rcTarget.left * m_pOutputHeader->biBitCount / 8;

    // Are the source and destination rectangles aligned

    if ((WIDTH(&pOut->rcTarget) & 3) == 0)
        if ((WIDTH(&pOut->rcSource) & 3) == 0)
            if ((pOut->rcSource.left & 3) == 0)
                if ((pOut->rcTarget.left & 3) == 0)
                    m_bAligned = TRUE;
}


// This is the base class implementation of commit

HRESULT CConvertor::Commit()
{
    InitRectangles(m_pInputInfo,m_pOutputInfo);
    m_bCommitted = TRUE;

    // Setup the dither table if not already done

    if (m_pInputHeader->biBitCount > 8) {
        if (m_pOutputHeader->biBitCount == 8) {
            InitDitherMap();
        }
    }
    return NOERROR;
}


// Clean up any resources held for the last commit called. Like the Commit
// this function is used by all the decommit functions regardless of their
// specific transform type just to clean up any common state that we have

HRESULT CConvertor::Decommit()
{
    m_bCommitted = FALSE;
    return NOERROR;
}


// This is called when we commit the memory for colour to palette transforms
// Since the lookup table for this transform is only 12kb we have it defined
// in the module statically negating the need for dynamic memory allocation
// We implement a simple ordered dithering algorithm as explained in Graphics
// Gems II page 72 and 509, published by Academic Press, author James Arvo
// This uses a spatial dithering algorithm although we use a smaller four by
// four magic square rather than sixteen by sixteen in the book to keep the
// size of the lookup table down with only a marginal loss in image quality

BYTE g_DitherMap[3][4][4][256];
DWORD g_DitherInit;

const INT g_magic4x4[4][4] = {  0,  45,   9,  41,
                               35,  16,  25,  19,
                               38,   6,  48,   3,
                               22,  29,  13,  32 };
void InitDitherMap()
{
    INT x,y,z,t,ndiv51,nmod51;
    if (g_DitherInit) return;

    // Calculate the RED, GREEN and BLUE table entries

    for (x = 0;x < 4;x++) {
        for (y = 0;y < 4;y++) {
            for (z = 0;z < 256;z++) {
                t = g_magic4x4[x][y];
                ndiv51 = (z & 0xF8) / 51; nmod51 = (z & 0xF8) % 51;
                g_DitherMap[0][x][y][z] = (ndiv51 + (nmod51 > t));
                g_DitherMap[2][x][y][z] = 36 * (ndiv51 + (nmod51 > t)) + OFFSET;
                ndiv51 = (z & 0xFC) / 51; nmod51 = (z & 0xFC) % 51;
                g_DitherMap[1][x][y][z] = 6 * (ndiv51 + (nmod51 > t));
            }
        }
    }
    g_DitherInit++;
}


// This is a generic conversion class. The conversion it does is to simply
// invert the scan lines so that the output can be placed directly onto a
// DirectDraw surface. We work with all the input formats RGB32/24/555/565
// and 8 bit palettised. If the input and output buffer formats are the
// same then our pins look after just passing the samples straight through

CDirectDrawConvertor::CDirectDrawConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CDirectDrawConvertor::CreateInstance(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut)
{
    return new CDirectDrawConvertor(pIn,pOut);
}


// Simple buffer copy that inverts the scan line order. This also works if
// the input scan lines are in the right order, but it will obviously add
// an additional image copy that slows us down considerably. This should
// be compiled with intrinsics enabled so that CopyMemory will eventually
// be preprocessed down to a machine instruction on Intel cloned machines
// If you take a 320x240x32 bpp image and read it in a DWORD at a time and
// then write each out it takes approximately 38ms on a 486-66 and 20ms on
// a P5-90. Using CopyMemory is much faster bit still takes quite a while.

HRESULT CDirectDrawConvertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    ASSERT(m_pInputHeader->biBitCount == m_pOutputHeader->biBitCount);

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    LONG Width = WIDTH(&m_pOutputInfo->rcTarget) * m_pOutputHeader->biBitCount / 8;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {
        CopyMemory((PVOID)pOutput,(PVOID)pInput,Width);
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}

CMemoryCopyAlphaConvertor::CMemoryCopyAlphaConvertor (VIDEOINFO *pIn,VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


CConvertor *CMemoryCopyAlphaConvertor ::CreateInstance(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut)
{
    return new CMemoryCopyAlphaConvertor (pIn,pOut);
}


HRESULT CMemoryCopyAlphaConvertor ::Transform(BYTE *pInput,BYTE *pOutput)
{
    ASSERT(m_pInputHeader->biBitCount == m_pOutputHeader->biBitCount);

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget);

    if( m_bSetAlpha )
    {
        LONG Width = WIDTH(&m_pOutputInfo->rcTarget);

        pInput += m_SrcOffset;
        pOutput += m_DstOffset;

        while (Height--) {
            unsigned long * po = (unsigned long*) pOutput;
            unsigned long * pi = (unsigned long*) pInput;
            long W = Width;
            while( W-- ) {
                *po = *pi | unsigned long( 0xFF000000 );
                po++;
                pi++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) * m_pOutputHeader->biBitCount / 8;

        pInput += m_SrcOffset;
        pOutput += m_DstOffset;

        while (Height--) {
            CopyMemory((PVOID)pOutput,(PVOID)pInput,Width);
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }

    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\rgb16.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB 16 colour space conversions, May 1995

#include <streams.h>
#include <colour.h>

// We do RGB555 and RGB565 formats converted to RGB8,RGB24,and RGB32. We also
// convert RGB555 to RGB565 and vica versa although they are unlikely ever to
// be used because the formats are so similar any self respecting codec will
// do both formats themselves. The RGB555 and RGB565 to 8 bit uses a dither
// table we create and initialise when the filter is instantiated. The other
// conversions require reading the data and rearranging the pixel bits. Only
// the dithering conversions have aligned optimised versions (in which the
// source and target rectangles as well as their sizes must be DWORD aligned)


// Constructor for RGB565 to RGB24 colour conversions

CRGB565ToRGB24Convertor::CRGB565ToRGB24Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB565ToRGB24Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB565ToRGB24Convertor(pIn,pOut);
}


// Constructor for RGB555 to RGB24 colour conversions

CRGB555ToRGB24Convertor::CRGB555ToRGB24Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB555ToRGB24Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB555ToRGB24Convertor(pIn,pOut);
}


// This converts an input RGB555 image into an output RGB24 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB555ToRGB24Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB555 = (WORD *) pInput;
        BYTE *pRGB24 = pOutput;

        while (--Width) {
            DWORD Pixel = *pRGB555++;
            pRGB24[0] = (UCHAR) ((Pixel & 0x001F) << 3);
            pRGB24[1] = (UCHAR) ((Pixel & 0x03E0) >> 2);
            pRGB24[2] = (UCHAR) ((Pixel & 0x7C00) >> 7);
            pRGB24 += 3;
        }
        pOutput += m_DstStride;
        pInput += m_SrcStride;
    }
    return NOERROR;
}


// This converts an input RGB565 image into an output RGB24 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB565ToRGB24Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB565 = (WORD *) pInput;
        BYTE *pRGB24 = pOutput;

        while (--Width) {
            DWORD Pixel = *pRGB565++;
            pRGB24[0] = (UCHAR) ((Pixel & 0x001F) << 3);
            pRGB24[1] = (UCHAR) ((Pixel & 0x07E0) >> 3);
            pRGB24[2] = (UCHAR) ((Pixel & 0xF800) >> 8);
            pRGB24 += 3;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor for RGB565 to RGB8 colour conversions

CRGB565ToRGB8Convertor::CRGB565ToRGB8Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB565ToRGB8Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB565ToRGB8Convertor(pIn,pOut);
}


// This converts an input RGB565 pixel image into a dithered RGB8 palettised
// image, we scan through the image converting each pixel in turn using the
// ordered dithering algorithm that selects output pixels dependant on their
// coordinate position in the source image. This makes a rough approximation
// to full error propogation but without the heavy computational overhead

#define DITH565(x,y,rgb)                                     \
    (g_DitherMap[0][((x)&3)][((y)&3)][(((rgb)>>8)&0xF8)] +   \
     g_DitherMap[1][((x)&3)][((y)&3)][(((rgb)>>3)&0xFC)] +   \
     g_DitherMap[2][((x)&3)][((y)&3)][(((rgb)<<3)&0xF8)])

HRESULT CRGB565ToRGB8Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB565 = (WORD *) pInput;
        BYTE *pRGB8 = pOutput;

        while (--Width) {
            DWORD RGB565 = *pRGB565++;
            *pRGB8++ = DITH565(Width,Height,RGB565);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB565 to RGB8 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we write four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC

HRESULT CRGB565ToRGB8Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB565 = (DWORD *) pInput;
        DWORD *pRGB8 = (DWORD *) pOutput;

        while (--Width) {

            // Read the two DWORDs that hold four sixteen bit pixels

            DWORD RGB565a = *pRGB565++;
            DWORD RGB565b = *pRGB565++;

            // Construct a DWORD containing four palettised pixels

            *pRGB8++ = (DITH565(0,Height,RGB565a)) |
                       (DITH565(1,Height,(RGB565a >> 16)) << 8) |
                       (DITH565(2,Height,RGB565b) << 16) |
                       (DITH565(3,Height,(RGB565b >> 16)) << 24);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor for RGB565 to RGB555 colour conversions

CRGB565ToRGB555Convertor::CRGB565ToRGB555Convertor(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB565ToRGB555Convertor::CreateInstance(VIDEOINFO *pIn,
                                                     VIDEOINFO *pOut)
{
    return new CRGB565ToRGB555Convertor(pIn,pOut);
}


// This converts an input RGB565 image into an output RGB555 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB565ToRGB555Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB565 = (WORD *) pInput;
        WORD *pRGB555 = (WORD *) pOutput;

        while (--Width) {
            *pRGB555++ = (*pRGB565 & 0x1F) | ((*pRGB565 & 0xFFC0) >> 1);
            pRGB565++;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor for RGB555 to RGB565 colour conversions

CRGB555ToRGB565Convertor::CRGB555ToRGB565Convertor(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB555ToRGB565Convertor::CreateInstance(VIDEOINFO *pIn,
                                                     VIDEOINFO *pOut)
{
    return new CRGB555ToRGB565Convertor(pIn,pOut);
}


// This converts an input RGB555 image into an output RGB565 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB555ToRGB565Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB555 = (WORD *) pInput;
        WORD *pRGB565 = (WORD *) pOutput;

        while (--Width) {
            *pRGB565++ = (*pRGB555 & 0x1F) | ((*pRGB555 & 0x7FE0) << 1);
            pRGB555++;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor for RGB565 to RGB32 colour conversions

CRGB565ToRGB32Convertor::CRGB565ToRGB32Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB565ToRGB32Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB565ToRGB32Convertor(pIn,pOut);
}


// This converts an input RGB565 image into an output RGB32 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB565ToRGB32Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    if( m_bSetAlpha )
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            WORD *pRGB565 = (WORD *) pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = 0xFF000000 | // white in the alpha
                            ((*pRGB565 & 0x001F) << 3) |
                            ((*pRGB565 & 0x07E0) << 5) |
                            ((*pRGB565 & 0xF800) << 8);
                pRGB565++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            WORD *pRGB565 = (WORD *) pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = ((*pRGB565 & 0x001F) << 3) |
                            ((*pRGB565 & 0x07E0) << 5) |
                            ((*pRGB565 & 0xF800) << 8);
                pRGB565++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    return NOERROR;
}


// Constructor for RGB555 to RGB32 colour conversions

CRGB555ToRGB32Convertor::CRGB555ToRGB32Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB555ToRGB32Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB555ToRGB32Convertor(pIn,pOut);
}


// This converts an input RGB555 image into an output RGB32 format. We could
// use a large lookup table for this but the large number of memory accesses
// as well as the not insignificant footprint meant that we normally better
// off doing a little arithmetic in the CPU to calculate the colour values

HRESULT CRGB555ToRGB32Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    if( m_bSetAlpha )
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            WORD *pRGB555 = (WORD *) pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = 0xFF000000 |
                            ((*pRGB555 & 0x001F) << 3) |
                            ((*pRGB555 & 0x03E0) << 6) |
                            ((*pRGB555 & 0x7C00) << 9);
                pRGB555++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            WORD *pRGB555 = (WORD *) pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = ((*pRGB555 & 0x001F) << 3) |
                            ((*pRGB555 & 0x03E0) << 6) |
                            ((*pRGB555 & 0x7C00) << 9);
                pRGB555++;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    return NOERROR;
}


// Constructor for RGB555 to RGB8 colour conversions

CRGB555ToRGB8Convertor::CRGB555ToRGB8Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB555ToRGB8Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB555ToRGB8Convertor(pIn,pOut);
}


// This converts an input RGB555 pixel image into a dithered RGB8 palettised
// image, we scan through the image converting each pixel in turn using the
// ordered dithering algorithm that selects output pixels dependant on their
// coordinate position in the source image. This makes a rough approximation
// to full error propogation but without the heavy computational overhead

#define DITH555(x,y,rgb)                                       \
    (g_DitherMap[0][((x)&3)][((y)&3)][(((rgb)>>7)&0xF8)] +     \
     g_DitherMap[1][((x)&3)][((y)&3)][(((rgb)>>2)&0xF8)] +     \
     g_DitherMap[2][((x)&3)][((y)&3)][(((rgb)<<3)&0xF8)])

HRESULT CRGB555ToRGB8Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB555 = (WORD *) pInput;
        BYTE *pRGB8 = pOutput;

        while (--Width) {
            DWORD RGB555 = *pRGB555++;
            *pRGB8++ = DITH555(Width,Height,RGB555);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB555 to RGB8 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we write four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC

HRESULT CRGB555ToRGB8Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB555 = (DWORD *) pInput;
        DWORD *pRGB8 = (DWORD *) pOutput;

        while (--Width) {

            // Read the two DWORDs that hold four sixteen bit pixels

            DWORD RGB555a = *pRGB555++;
            DWORD RGB555b = *pRGB555++;

            // Construct a DWORD containing four palettised pixels

            *pRGB8++ = (DITH555(0,Height,RGB555a)) |
                       (DITH555(1,Height,(RGB555a >> 16)) << 8) |
                       (DITH555(2,Height,RGB555b) << 16) |
                       (DITH555(3,Height,(RGB555b >> 16)) << 24);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\convert.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This filter implements popular colour space conversions, May 1995

#ifndef __CONVERT__
#define __CONVERT__

const INT COLOUR_BUFFERS = 1;   // Use just the one output sample buffer
const INT STDPALCOLOURS = 226;  // Number of colours in standard palette
const INT OFFSET = 10;          // First ten colours are used by Windows

#define WIDTH(x) ((*(x)).right - (*(x)).left)
#define HEIGHT(x) ((*(x)).bottom - (*(x)).top)
extern const INT magic4x4[4][4];
extern BYTE g_DitherMap[3][4][4][256];
extern DWORD g_DitherInit;

void InitDitherMap();

// In general the transforms have much in common with the framework they live
// in, so we have a generic (abstract) base class that each and every one of
// the specific transforms derives from. To their derived class they add an
// implementation of Transform, perhaps overriding Commit to allocate lookup
// tables they require (and Decommit to clean them up). They may also add
// other private member variables for mapping and colour lookup tables

class CConvertor {
protected:

    VIDEOINFO *m_pInputInfo;             // Input media type information
    VIDEOINFO *m_pOutputInfo;            // Output type information
    BITMAPINFOHEADER *m_pInputHeader;    // Input bitmap header
    BITMAPINFOHEADER *m_pOutputHeader;   // Output bitmap header
    BOOL m_bCommitted;                   // Have we been committed
    LONG m_SrcOffset;                    // Source original offset
    LONG m_SrcStride;                    // Length in bytes of a scan line
    LONG m_DstStride;                    // Likewise offset into target
    LONG m_DstOffset;                    // And the length of each line
    BOOL m_bAligned;                     // Are our rectangles aligned
    BOOL m_bSetAlpha;

public:

    // Constructor and destructor

    CConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    virtual ~CConvertor();

    // These are the methods that do the work

    void ForceAlignment(BOOL bAligned);
    void InitRectangles(VIDEOINFO *pIn,VIDEOINFO *pOut);
    virtual HRESULT Commit();
    virtual HRESULT Decommit();
    virtual HRESULT Transform(BYTE *pInput,BYTE *pOutput) PURE;

    void SetFillInAlpha( ) { m_bSetAlpha = TRUE; }
};

// These header files define the type specific transform classes

#include "rgb32.h"
#include "rgb24.h"
#include "rgb16.h"
#include "rgb8.h"

// This class acts as a low cost pass through convertor where all it does is
// to rearrange the scan lines from bottom up order (as defined for DIBs) to
// top down that DirectDraw surfaces use. This allows a file source filter
// to be connected to the renderer with a minimum of work to gain access to
// DirectDraw. Doing this scan line inversion introduces a memory copy but
// that is balanced by the saving from not having to use GDI to draw after.
// This class works across all DIB formats (eg RGB32/24/565/555 and 8 bit)

class CDirectDrawConvertor : public CConvertor {
public:

    CDirectDrawConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};

class CMemoryCopyAlphaConvertor : public CConvertor {
public:

    CMemoryCopyAlphaConvertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};

// We keep a default dithering palette and some lookup tables in a section of
// shared memory (shared between all loadings of this DLL) but we cannot just
// include the header file into all the source files as the tables will all be
// defined multiple times (and produce linker warnings), so we extern them in
// here and then the main source file really includes the full definitions

extern const RGBQUAD StandardPalette[];
extern const BYTE RedScale[];
extern const BYTE BlueScale[];
extern const BYTE GreenScale[];
extern const BYTE PalettePad[];

// This is the list of colour space conversions that thie filter supports.
// The memory for the GUIDS is actually allocated in the DLL curtosy of the
// colour source file that includes initguid which causes DEFINE_GUID to
// actually allocate memory. The table is scanned to provide possible media
// types for the media type enumerator and also to check we can support a
// transform - WARNING the list of transforms must match with TRANSFORMS

typedef CConvertor *(*PCONVERTOR)(VIDEOINFO *pIn,VIDEOINFO *pOut);

const struct {
    const GUID *pInputType;     // Source video media subtype
    const GUID *pOutputType;    // Output media subtype
    PCONVERTOR pConvertor;      // Object implementing transforms
} TypeMap[] = {

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_ARGB32,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB32, // just does a memcopy, yuck
      CMemoryCopyAlphaConvertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB565,
      CRGB32ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB555,
      CRGB32ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB24,
      CRGB32ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_ARGB32,    &MEDIASUBTYPE_RGB8,
      CRGB32ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB32,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_ARGB32, // does a memcpy with alpha fill
      CMemoryCopyAlphaConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB24,
      CRGB32ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB565,
      CRGB32ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB555,
      CRGB32ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB32,    &MEDIASUBTYPE_RGB8,
      CRGB32ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB32,
      CRGB24ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_ARGB32,
      CRGB24ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB24,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB565,
      CRGB24ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB555,
      CRGB24ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB24,    &MEDIASUBTYPE_RGB8,
      CRGB24ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB32,
      CRGB565ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_ARGB32,
      CRGB565ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB24,
      CRGB565ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB565,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB555,
      CRGB565ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB565,   &MEDIASUBTYPE_RGB8,
      CRGB565ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB32,
      CRGB555ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_ARGB32,
      CRGB555ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB24,
      CRGB555ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB565,
      CRGB555ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB555,
      CDirectDrawConvertor::CreateInstance,

      &MEDIASUBTYPE_RGB555,   &MEDIASUBTYPE_RGB8,
      CRGB555ToRGB8Convertor::CreateInstance,


      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB32,
      CRGB8ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_ARGB32,
      CRGB8ToRGB32Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB24,
      CRGB8ToRGB24Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB565,
      CRGB8ToRGB565Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB555,
      CRGB8ToRGB555Convertor::CreateInstance,

      &MEDIASUBTYPE_RGB8,     &MEDIASUBTYPE_RGB8,
      CDirectDrawConvertor::CreateInstance };

const INT TRANSFORMS = sizeof(TypeMap) / sizeof(TypeMap[0]);

#endif // __CONVERT__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\rgb24.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB24 colour space conversions, May 1995

#ifndef __RGB24__
#define __RGB24__


// We have three lookup tables that both the RGB555 and RGB565 transforms will
// share. They have their own specific commit functions that set the tables up
// appropriately but they share the overall committing and decommitting of the
// memory. They also share the same transform function as once the tables are
// initialise the actual conversion work just involves looking up values

class CRGB24ToRGB16Convertor : public CConvertor {
protected:

    DWORD *m_pRGB16RedTable;
    DWORD *m_pRGB16GreenTable;
    DWORD *m_pRGB16BlueTable;

public:

    // Constructor and destructor

    CRGB24ToRGB16Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    ~CRGB24ToRGB16Convertor();

    HRESULT Commit();
    HRESULT Decommit();
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
};


// This class looks after doing RGB24 to RGB16 (565 colour bit representation)
// conversions. We use the base class Commit, Decommit and Transform functions
// to manage the lookup tables. We override the virtual Commit function to
// initialise the lookup tables appropriately once they have been allocated

class CRGB24ToRGB565Convertor : public CRGB24ToRGB16Convertor {
public:

    CRGB24ToRGB565Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Commit();
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// This class looks after doing RGB24 to RGB16 (555 colour bit representation)
// conversions. We use the base class Commit, Decommit and Transform functions
// to manage the lookup tables. We override the virtual Commit function to
// initialise the lookup tables appropriately once they have been allocated

class CRGB24ToRGB555Convertor : public CRGB24ToRGB16Convertor {
public:

    CRGB24ToRGB555Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Commit();
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// RGB24 to RGB32 colour space conversions

class CRGB24ToRGB32Convertor : public CConvertor {
public:
    CRGB24ToRGB32Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// The RGB24 to RGB8 conversion class uses a 12kb lookup table that is used
// to map an incoming RGB triplet to it's closest matching palette index with
// an approximation to full error diffusion built in. The four indices to the
// table are colour index (red, green or blue), the current row modulo four
// and likewise the column value modulo four and the RGB value respectively

class CRGB24ToRGB8Convertor : public CConvertor {

public:
    CRGB24ToRGB8Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};

#endif // __RGB24__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\rgb24.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB 24 colour space conversions, May 1995

#include <streams.h>
#include <colour.h>

// We do RGB24 to RGB8,RGB555,RGB565 and RGB32 colour space conversions here
// The only really interesting conversion here is RGB24 to RGB8 which uses
// the global dithering table created and initialised when we instantiate
// the filter. The RGB24 to RGB8 transform has an alignment optimised version
// that can be used when the source and destination rectangles and also their
// respective widths are aligned on DWORD boundaries. None of the others have
// any alignment optimisation. The RGB24 to 16 and 32 bit formats are fairly
// straightforward but are very expensive simply because of the amount of
// data being passed across the bus. It is therefore relatively unlikely that
// these will be used for video but might be used for still image transforms


// Constructor

CRGB24ToRGB16Convertor::CRGB24ToRGB16Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut),
    m_pRGB16RedTable(NULL),
    m_pRGB16GreenTable(NULL),
    m_pRGB16BlueTable(NULL)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Destructor

CRGB24ToRGB16Convertor::~CRGB24ToRGB16Convertor()
{
    ASSERT(m_pRGB16RedTable == NULL);
    ASSERT(m_pRGB16GreenTable == NULL);
    ASSERT(m_pRGB16BlueTable == NULL);
}


// We have three lookup tables that both the RGB555 and RGB565 transforms will
// share. They have their own specific commit functions that set the tables up
// appropriately but they share the overall committing and decommitting of the
// memory. They also share the same transform function as once the tables are
// initialised the actual conversion work just involves looking up values

HRESULT CRGB24ToRGB16Convertor::Commit()
{
    CConvertor::Commit();

    // Allocate the memory for the lookup tables

    m_pRGB16RedTable = new DWORD[256];
    m_pRGB16GreenTable = new DWORD[256];
    m_pRGB16BlueTable = new DWORD[256];

    // Check they were all allocated correctly

    if (m_pRGB16BlueTable == NULL || m_pRGB16RedTable == NULL || m_pRGB16GreenTable == NULL) {
        Decommit();
        return E_OUTOFMEMORY;
    }
    return NOERROR;
}


// This is called when we finish transforming RGB24 to RGB16 images, we must
// call the global decommit function and then delete the lookup tables which
// we use. Some or all of these may not be present if an error has occured

HRESULT CRGB24ToRGB16Convertor::Decommit()
{
    CConvertor::Decommit();

    // Delete the RED lookup table

    if (m_pRGB16RedTable) {
        delete[] m_pRGB16RedTable;
        m_pRGB16RedTable = NULL;
    }

    // Delete the GREEN lookup table

    if (m_pRGB16GreenTable) {
        delete[] m_pRGB16GreenTable;
        m_pRGB16GreenTable = NULL;
    }

    // Delete the BLUE lookup table

    if (m_pRGB16BlueTable) {
        delete[] m_pRGB16BlueTable;
        m_pRGB16BlueTable = NULL;
    }
    return NOERROR;
}


// Transform the input RGB24 image to an output RGB16 16 bit image. This is
// a tight loop taking each three byte triplet and converting the individual
// colour components to their 16 bit representation and then combining them
// We use the same function to convert to both RGB555 and RGB565, we can do
// this because we have separate commit methods that build different tables

HRESULT CRGB24ToRGB16Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        WORD *pRGB16 = (WORD *) pOutput;
        BYTE *pRGB24 = pInput;

        while (--Width) {

            *pRGB16++ = (WORD) (m_pRGB16BlueTable[pRGB24[0]] |
                                m_pRGB16GreenTable[pRGB24[1]] |
                                m_pRGB16RedTable[pRGB24[2]]);
            pRGB24 += 3;

        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// RGB24 to RGB565 constructor

CRGB24ToRGB565Convertor::CRGB24ToRGB565Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CRGB24ToRGB16Convertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB24ToRGB565Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB24ToRGB565Convertor(pIn,pOut);
}


// This allocates the memory for transforming RGB24 to RGB16 images. We have
// three lookup tables (one for each colour component). When we parse out the
// individual colours in a pixel value we look up in the table using them as
// an index to find out what their representation is in the output format

HRESULT CRGB24ToRGB565Convertor::Commit()
{
    // Initialise the lookup tables

    HRESULT hr = CRGB24ToRGB16Convertor::Commit();
    if (FAILED(hr)) {
        return hr;
    }

    // For each possible byte value we insert a lookup table entry for it so
    // that when we come to convert a colour component value we know exactly
    // what it should be changed to and where in the output WORD it goes

    for (DWORD Position = 0;Position < 256;Position++) {

        DWORD FiveBitAdjust = Position;
        DWORD SixBitAdjust = Position;

        // Adjust the values according to the number of bits that will be left
        // after we start dropping some of their trailing bits. This is either
        // five or six bits, the adjustment stops the output image darkening

        ADJUST(FiveBitAdjust,4);
        ADJUST(SixBitAdjust,2);

        m_pRGB16RedTable[Position] = (FiveBitAdjust >> 3) << 11;
        m_pRGB16GreenTable[Position] = (SixBitAdjust >> 2) << 5;
        m_pRGB16BlueTable[Position] = FiveBitAdjust >> 3;
    }
    return NOERROR;
}


// RGB24 to RGB555 constructor

CRGB24ToRGB555Convertor::CRGB24ToRGB555Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CRGB24ToRGB16Convertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB24ToRGB555Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB24ToRGB555Convertor(pIn,pOut);
}


// This allocates the memory for transforming RGB24 to RGB555 images. We have
// three lookup tables (one for each colour component). When we parse out the
// individual colours in a pixel value we look up in the table using them as
// an index to find out what their representation is in the output format

HRESULT CRGB24ToRGB555Convertor::Commit()
{
    // Initialise the lookup tables

    HRESULT hr = CRGB24ToRGB16Convertor::Commit();
    if (FAILED(hr)) {
        return hr;
    }

    // For each possible byte value we insert a lookup table entry for it so
    // that when we come to convert a colour component value we know exactly
    // what it should be changed to and where in the output WORD it goes

    for (DWORD Position = 0;Position < 256;Position++) {

        // This is going to be an eight bit value transformed into a five
        // bit value so we see if the 0x100 bit is set and if so we round
        // the value up, this stops the output transformed image darkening

        DWORD FiveBitAdjust = Position;
        ADJUST(FiveBitAdjust,4);

        m_pRGB16RedTable[Position] = (FiveBitAdjust >> 3) << 10;
        m_pRGB16GreenTable[Position] = (FiveBitAdjust >> 3) << 5;
        m_pRGB16BlueTable[Position] = FiveBitAdjust >> 3;
    }
    return NOERROR;
}


CConvertor *CRGB24ToRGB32Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB24ToRGB32Convertor(pIn,pOut);
}


// Constructor

CRGB24ToRGB32Convertor::CRGB24ToRGB32Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Transform the input RGB24 image to an output RGB32 image

HRESULT CRGB24ToRGB32Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    if( m_bSetAlpha )
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            DWORD *pRGB32 = (DWORD *) pOutput;
            BYTE *pRGB24 = pInput;

            while (--Width) {
                *pRGB32++ = 0xFF000000 | pRGB24[0] | (pRGB24[1] << 8) | (pRGB24[2] << 16); // alpha
                pRGB24 += 3;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            DWORD *pRGB32 = (DWORD *) pOutput;
            BYTE *pRGB24 = pInput;

            while (--Width) {
                *pRGB32++ = pRGB24[0] | (pRGB24[1] << 8) | (pRGB24[2] << 16);
                pRGB24 += 3;
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    return NOERROR;
}


// Constructor for RGB24 to RGB8 colour conversions

CRGB24ToRGB8Convertor::CRGB24ToRGB8Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB24ToRGB8Convertor::CreateInstance(VIDEOINFO *pIn,
                                                  VIDEOINFO *pOut)
{
    return new CRGB24ToRGB8Convertor(pIn,pOut);
}


// This converts an input RGB24 pixel image into a dithered RGB8 palettised
// image, we scan through the image converting each pixel in turn using the
// ordered dithering algorithm that selects output pixels dependant on their
// coordinate position in the source image. This makes a rough approximation
// to full error propogation but without the heavy computational overhead

#define DITH24(x,y,r,g,b)                    \
    (g_DitherMap[0][((x)&3)][((y)&3)][r] +   \
     g_DitherMap[1][((x)&3)][((y)&3)][g] +   \
     g_DitherMap[2][((x)&3)][((y)&3)][b])

HRESULT CRGB24ToRGB8Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        BYTE *pRGB24 = pInput;
        BYTE *pRGB8 = pOutput;

        while (--Width) {
            *pRGB8++ = DITH24(Width,Height,pRGB24[2],pRGB24[1],pRGB24[0]);
            pRGB24 += 3;
        }
        pOutput += m_DstStride;
        pInput += m_SrcStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB24 to RGB8 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we write four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC
// NOTE RGB24 pixels are stored in the buffer on BLUE, GREEN, RED byte order
// So if you have a pointer to a RGB24 triplet and you cast it to a pointer
// to a DWORD then the blue colour component is the least significant byte

HRESULT CRGB24ToRGB8Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB24 = (DWORD *) pInput;
        DWORD *pRGB8 = (DWORD *) pOutput;

        while (--Width) {

            // Three DWORDs gets us four RGB24 pixels

            DWORD RGB24a = *pRGB24++;
            DWORD RGB24b = *pRGB24++;
            DWORD RGB24c = *pRGB24++;

            // Construct four palettised pixels from the three DWORD inputs
            // After reading the three DWORDs the colour components can be
            // found layed out within the DWORDs as follows. To extract the
            // colour components typically requires a shift and an AND with
            // 0xFF since the DITH24 macro takes values not exceeding 0xFF

            //   DWORD        LSB         LSB+1       LSB+2         MSB
            //     0       Blue[0]      Green[0]      Red[0]     Blue[1]
            //     1      Green[1]        Red[1]     Blue[2]    Green[2]
            //     2        Red[2]       Blue[3]    Green[3]      Red[3]

            *pRGB8++ = (DITH24(0,Height,((BYTE)(RGB24a >> 16)),
                                        ((BYTE)(RGB24a >> 8)),
                                        (RGB24a & 0xFF))) |

                       (DITH24(1,Height,((BYTE)(RGB24b >> 8)),
                                        ((BYTE) RGB24b),
                                        (RGB24a >> 24)) << 8) |

                       (DITH24(2,Height,((BYTE) RGB24c),
                                        (RGB24b >> 24),
                                        ((BYTE)(RGB24b >> 16))) << 16) |

                       (DITH24(3,Height,(RGB24c >> 24),
                                        ((BYTE)(RGB24c >> 16)),
                                        ((BYTE)(RGB24c >> 8))) << 24);
        }
        pOutput += m_DstStride;
        pInput += m_SrcStride;
    }
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\rgb16.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB16 colour space conversions, May 1995

#ifndef __RGB16__
#define __RGB16__

// This does a similar transform from RGB565 pixel representation to RGB24, as
// for the previous colour conversion we use no lookup tables as the transform
// is very simple, involving little more than an AND to retrieve each colour
// component and then a right shift to align the bits in the byte position

class CRGB565ToRGB24Convertor : public CConvertor {
public:

    CRGB565ToRGB24Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// This class converts between RGB555 pixel representation and RGB24, RGB24
// uses one byte per colour component whereas RGB555 uses five bits per pixel
// but they are packed together into a WORD with one bit remaining unused

class CRGB555ToRGB24Convertor : public CConvertor {
public:

    CRGB555ToRGB24Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// The RGB565 to RGB8 conversion class uses a 12kb lookup table that is used
// to map an incoming RGB triplet to it's closest matching palette index with
// an approximation to full error diffusion built in. The four indices to the
// table are colour index (red, green or blue), the current row modulo four
// and likewise the column value modulo four and the RGB value respectively

class CRGB565ToRGB8Convertor : public CConvertor {
public:
    CRGB565ToRGB8Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};


// Cheap conversion from RGB565 to RGB555 formats

class CRGB565ToRGB555Convertor : public CConvertor {
public:

    CRGB565ToRGB555Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// Another cheap conversion from RGB555 to RGB565 formats

class CRGB555ToRGB565Convertor : public CConvertor {
public:

    CRGB555ToRGB565Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// Conversion from RGB565 to RGB32 formats

class CRGB565ToRGB32Convertor : public CConvertor {
public:

    CRGB565ToRGB32Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// Conversion from RGB555 to RGB32 formats

class CRGB555ToRGB32Convertor : public CConvertor {
public:

    CRGB555ToRGB32Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// The RGB555 to RGB8 conversion class uses a 12kb lookup table that is used
// to map an incoming RGB triplet to it's closest matching palette index with
// an approximation to full error diffusion built in. The four indices to the
// table are colour index (red, green or blue), the current row modulo four
// and likewise the column value modulo four and the RGB value respectively

class CRGB555ToRGB8Convertor : public CConvertor {
public:
    CRGB555ToRGB8Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};

#endif // __RGB16__


=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\rgb32.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB 32 colour space conversions, November 1995

#include <streams.h>
#include <colour.h>

// We do RGB32 to RGB8,RGB555,RGB565 and RGB24 colour space conversions here
// The only really interesting conversion here is RGB32 to RGB8 which uses
// the global dithering table created and initialised when we instantiate
// the filter. The RGB32 to RGB8 transform has an alignment optimised version
// that can be used when the source and destination rectangles and also their
// respective widths are aligned on DWORD boundaries. None of the others have
// any alignment optimisation. The RGB32 to 16 and 24 bit formats are fairly
// straightforward but are very expensive simply because of the amount of
// data being passed across the bus. It is therefore relatively unlikely that
// these will be used for video but might be used for still image transforms


// Constructor for RGB32 to RGB8 colour conversions

CRGB32ToRGB8Convertor::CRGB32ToRGB8Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB32ToRGB8Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB32ToRGB8Convertor(pIn,pOut);
}


// This converts an input RGB32 pixel image into a dithered RGB8 palettised
// image, we scan through the image converting each pixel in turn using the
// ordered dithering algorithm that selects output pixels dependant on their
// coordinate position in the source image. This makes a rough approximation
// to full error propogation but without the heavy computational overhead

#define DITH32(x,y,rgb)                                      \
    (g_DitherMap[0][((x)&3)][((y)&3)][(BYTE)((rgb)>>16)] +   \
     g_DitherMap[1][((x)&3)][((y)&3)][(BYTE)((rgb)>>8)] +    \
     g_DitherMap[2][((x)&3)][((y)&3)][(BYTE)((rgb))])

HRESULT CRGB32ToRGB8Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        BYTE *pRGB8 = pOutput;

        while (--Width) {
            DWORD RGB32 = *pRGB32++;
            *pRGB8++ = DITH32(Width,Height,RGB32);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB32 to RGB8 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we write four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC

HRESULT CRGB32ToRGB8Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        DWORD *pRGB8 = (DWORD *) pOutput;

        while (--Width) {

            // Read in four RGB32 pixels at once

            DWORD RGB32a = *pRGB32++;
            DWORD RGB32b = *pRGB32++;
            DWORD RGB32c = *pRGB32++;
            DWORD RGB32d = *pRGB32++;

            // Colour convert all four and write in a single DWORD out

            *pRGB8++ = (DITH32(0,Height,RGB32a)) |
                       (DITH32(1,Height,RGB32b) << 8) |
                       (DITH32(2,Height,RGB32c) << 16) |
                       (DITH32(3,Height,RGB32d) << 24);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Creator function for RGB32 to RGB24 formats

CConvertor *CRGB32ToRGB24Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB32ToRGB24Convertor(pIn,pOut);
}


// Constructor

CRGB32ToRGB24Convertor::CRGB32ToRGB24Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Transform the input RGB24 image to an output RGB32 image

HRESULT CRGB32ToRGB24Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        BYTE *pRGB24 = pOutput;

        while (--Width) {
            DWORD RGB32 = *pRGB32++;
            pRGB24[0] = (BYTE) RGB32;
            pRGB24[1] = (BYTE) (RGB32 >> 8);
            pRGB24[2] = (BYTE) (RGB32 >> 16);
            pRGB24 += 3;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Creator function for RGB32 to RGB565 formats

CConvertor *CRGB32ToRGB565Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB32ToRGB565Convertor(pIn,pOut);
}


// Constructor

CRGB32ToRGB565Convertor::CRGB32ToRGB565Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Transform the input RGB32 image to an output RGB565 image

HRESULT CRGB32ToRGB565Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        WORD *pRGB565 = (WORD *) pOutput;

        while (--Width) {
            *pRGB565++ = (WORD) ((((BYTE) *pRGB32) >> 3) |
                                (((*pRGB32 & 0xFF00) >> 10) << 5) |
                                (((*pRGB32 & 0xFF0000) >> 19) << 11));
            pRGB32++;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Creator function for RGB32 to RGB555 formats

CConvertor *CRGB32ToRGB555Convertor::CreateInstance(VIDEOINFO *pIn,
                                                    VIDEOINFO *pOut)
{
    return new CRGB32ToRGB555Convertor(pIn,pOut);
}


// Constructor

CRGB32ToRGB555Convertor::CRGB32ToRGB555Convertor(VIDEOINFO *pIn,
                                                 VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Transform the input RGB32 image to an output RGB555 image

HRESULT CRGB32ToRGB555Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        DWORD *pRGB32 = (DWORD *) pInput;
        WORD *pRGB555 = (WORD *) pOutput;

        while (--Width) {
            *pRGB555++ = (WORD) ((((BYTE) *pRGB32) >> 3) |
                                (((*pRGB32 & 0xFF00) >> 11) << 5) |
                                (((*pRGB32 & 0xFF0000) >> 19) << 10));
            pRGB32++;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\rgb32.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file implements RGB32 colour space conversions, May 1995

#ifndef __RGB32__
#define __RGB32__


// The RGB32 to RGB8 conversion class uses a 12kb lookup table that is used
// to map an incoming RGB triplet to it's closest matching palette index with
// an approximation to full error diffusion built in. The four indices to the
// table are colour index (red, green or blue), the current row modulo four
// and likewise the column value modulo four and the RGB value respectively

class CRGB32ToRGB8Convertor : public CConvertor {

public:
    CRGB32ToRGB8Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};


// RGB32 to RGB24 colour space conversions

class CRGB32ToRGB24Convertor : public CConvertor {
public:
    CRGB32ToRGB24Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// RGB32 to RGB565 colour space conversions

class CRGB32ToRGB565Convertor : public CConvertor {
public:
    CRGB32ToRGB565Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};


// RGB32 to RGB555 colour space conversions

class CRGB32ToRGB555Convertor : public CConvertor {
public:
    CRGB32ToRGB555Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
};

#endif // __RGB32__


=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\stdpal.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This file contains the standard video dithering palette, May 1995

#ifndef __STDPAL__
#define __STDPAL__

// The first thing to note is that this header file is only included by the
// main colour conversion source file, the variables we define in here are
// defined as extern in the main header file. This avoids getting any linker
// warnings as we would be defining the static variables multiple times. We
// have a default palette and a number of lookup tables defined in here which
// are put in a shared memory block to reduce the overall memory footprint

#pragma data_seg(".sdata")

// This is the palette we use when converting true colour formats to palette
// formats. We cannot dither to an arbitrary palette provided through the
// application as it takes too long to build conversion tables and to do the
// mapping. This fixed palette has the standard ten leading VGA entries in
// order to make it an identity palette. Then follows in BLUE GREEN RED order
// the definitions for 216 palette entries. Basicly we split the range for a
// colour component from 0 to 255 into a level of 0 to 5. An obvious way to
// do this would be to divide by 51. We then have three colour components in
// the range 0 to 5. So each value in that range represents 51 values in the
// original, we then fill out a palette with all the permutations of the value
// 51 and it's multiples, to which you will see there are 216 possibilities.
//
// Now the ordering of the palette entries becomes important. The blue values
// (on the left) are always increasing, so we have all the zero values first
// followed by all the 51s and so on. Then within any blue range we do the
// same for the green, so they are always increasing in the same way. And
// finally for the red values on the far right we also do this. This allows
// us to calculate with a very simple equation the palette index that maps
// from a RGB level (remember each is 0 to 5 now) to the ordinal position.
//
// Given three colour element values R, G and B in the range 0 to 5.
// The start of the blue section is at B * 36.
// The start of the green section is at G * 6.
// The position of the red entry is at R.
//
// And putting them all together gives us  Index = (B * 36) + (G * 6) + R
//
// As it turns out this computation can be done even more directly by having
// a lookup table that maps from an 8 bit RGB value directly into the palette
// index, the table is normally built when we go into a streaming state (it
// doesn't take all that long). NOTE We don't ever map to the VGA colours

const RGBQUAD StandardPalette[STDPALCOLOURS] =
{
    // These are the first ten standard VGA colours WARNING RGBQUAD defines
    // the fields in BGR ordering NOT RGB ! The odd looking entries further
    // down are entered to ensure that we get an identity palette with GDI
    // If we entered an all zero palette entry for example it would be taken
    // out and GDI would use a slow internal mapping table to generate it

    {   0,   0,   0 },     // 0 Sys Black
    {   0,   0, 128 },     // 1 Sys Dk Red
    {   0, 128,   0 },     // 2 Sys Dk Green
    {   0, 128, 128 },     // 3 Sys Dk Yellow
    { 128,   0,   0 },     // 4 Sys Dk Blue
    { 128,   0, 128 },     // 5 Sys Dk Violet
    { 128, 128,   0 },     // 6 Sys Dk Cyan
    { 192, 192, 192 },     // 7 Sys Lt Grey
    { 192, 220, 192 },     // 8 Sys 8
    { 240, 202, 166 },     // 9 Sys 9

    {   1,   1,   1 },
    {   1,   1,  51 },
    {   1,   1, 102 },
    {   1,   1, 153 },
    {   1,   1, 204 },
    {   1,   1, 254 },
    {   1,  51,   1 },
    {   1,  51,  51 },
    {   1,  51, 102 },
    {   1,  51, 153 },
    {   1,  51, 204 },
    {   1,  51, 254 },
    {   1, 102,   1 },
    {   1, 102,  51 },
    {   1, 102, 102 },
    {   1, 102, 153 },
    {   1, 102, 204 },
    {   1, 102, 254 },
    {   1, 153,   1 },
    {   1, 153,  51 },
    {   1, 153, 102 },
    {   1, 153, 153 },
    {   1, 153, 204 },
    {   1, 153, 254 },
    {   1, 204,   1 },
    {   1, 204,  51 },
    {   1, 204, 102 },
    {   1, 204, 153 },
    {   1, 204, 204 },
    {   1, 204, 254 },
    {   1, 254,   1 },
    {   1, 254,  51 },
    {   1, 254, 102 },
    {   1, 254, 153 },
    {   1, 254, 204 },
    {   1, 254, 254 },

    {  51,   1,   1 },
    {  51,   1,  51 },
    {  51,   1, 102 },
    {  51,   1, 153 },
    {  51,   1, 204 },
    {  51,   1, 254 },
    {  51,  51,   1 },
    {  51,  51,  51 },
    {  51,  51, 102 },
    {  51,  51, 153 },
    {  51,  51, 204 },
    {  51,  51, 254 },
    {  51, 102,   1 },
    {  51, 102,  51 },
    {  51, 102, 102 },
    {  51, 102, 153 },
    {  51, 102, 204 },
    {  51, 102, 254 },
    {  51, 153,   1 },
    {  51, 153,  51 },
    {  51, 153, 102 },
    {  51, 153, 153 },
    {  51, 153, 204 },
    {  51, 153, 254 },
    {  51, 204,   1 },
    {  51, 204,  51 },
    {  51, 204, 102 },
    {  51, 204, 153 },
    {  51, 204, 204 },
    {  51, 204, 254 },
    {  51, 254,   1 },
    {  51, 254,  51 },
    {  51, 254, 102 },
    {  51, 254, 153 },
    {  51, 254, 204 },
    {  51, 254, 254 },

    { 102,   1,   1 },
    { 102,   1,  51 },
    { 102,   1, 102 },
    { 102,   1, 153 },
    { 102,   1, 204 },
    { 102,   1, 254 },
    { 102,  51,   1 },
    { 102,  51,  51 },
    { 102,  51, 102 },
    { 102,  51, 153 },
    { 102,  51, 204 },
    { 102,  51, 254 },
    { 102, 102,   1 },
    { 102, 102,  51 },
    { 102, 102, 102 },
    { 102, 102, 153 },
    { 102, 102, 204 },
    { 102, 102, 254 },
    { 102, 153,   1 },
    { 102, 153,  51 },
    { 102, 153, 102 },
    { 102, 153, 153 },
    { 102, 153, 204 },
    { 102, 153, 254 },
    { 102, 204,   1 },
    { 102, 204,  51 },
    { 102, 204, 102 },
    { 102, 204, 153 },
    { 102, 204, 204 },
    { 102, 204, 254 },
    { 102, 254,   1 },
    { 102, 254,  51 },
    { 102, 254, 102 },
    { 102, 254, 153 },
    { 102, 254, 204 },
    { 102, 254, 254 },

    { 153,   1,   1 },
    { 153,   1,  51 },
    { 153,   1, 102 },
    { 153,   1, 153 },
    { 153,   1, 204 },
    { 153,   1, 254 },
    { 153,  51,   1 },
    { 153,  51,  51 },
    { 153,  51, 102 },
    { 153,  51, 153 },
    { 153,  51, 204 },
    { 153,  51, 254 },
    { 153, 102,   1 },
    { 153, 102,  51 },
    { 153, 102, 102 },
    { 153, 102, 153 },
    { 153, 102, 204 },
    { 153, 102, 254 },
    { 153, 153,   1 },
    { 153, 153,  51 },
    { 153, 153, 102 },
    { 153, 153, 153 },
    { 153, 153, 204 },
    { 153, 153, 254 },
    { 153, 204,   1 },
    { 153, 204,  51 },
    { 153, 204, 102 },
    { 153, 204, 153 },
    { 153, 204, 204 },
    { 153, 204, 254 },
    { 153, 254,   1 },
    { 153, 254,  51 },
    { 153, 254, 102 },
    { 153, 254, 153 },
    { 153, 254, 204 },
    { 153, 254, 254 },

    { 204,   1,   1 },
    { 204,   1,  51 },
    { 204,   1, 102 },
    { 204,   1, 153 },
    { 204,   1, 204 },
    { 204,   1, 254 },
    { 204,  51,   1 },
    { 204,  51,  51 },
    { 204,  51, 102 },
    { 204,  51, 153 },
    { 204,  51, 204 },
    { 204,  51, 254 },
    { 204, 102,   1 },
    { 204, 102,  51 },
    { 204, 102, 102 },
    { 204, 102, 153 },
    { 204, 102, 204 },
    { 204, 102, 254 },
    { 204, 153,   1 },
    { 204, 153,  51 },
    { 204, 153, 102 },
    { 204, 153, 153 },
    { 204, 153, 204 },
    { 204, 153, 254 },
    { 204, 204,   1 },
    { 204, 204,  51 },
    { 204, 204, 102 },
    { 204, 204, 153 },
    { 204, 204, 204 },
    { 204, 204, 254 },
    { 204, 254,   1 },
    { 204, 254,  51 },
    { 204, 254, 102 },
    { 204, 254, 153 },
    { 204, 254, 204 },
    { 204, 254, 254 },

    { 254,   1,   1 },
    { 254,   1,  51 },
    { 254,   1, 102 },
    { 254,   1, 153 },
    { 254,   1, 204 },
    { 254,   1, 254 },
    { 254,  51,   1 },
    { 254,  51,  51 },
    { 254,  51, 102 },
    { 254,  51, 153 },
    { 254,  51, 204 },
    { 254,  51, 254 },
    { 254, 102,   1 },
    { 254, 102,  51 },
    { 254, 102, 102 },
    { 254, 102, 153 },
    { 254, 102, 204 },
    { 254, 102, 254 },
    { 254, 153,   1 },
    { 254, 153,  51 },
    { 254, 153, 102 },
    { 254, 153, 153 },
    { 254, 153, 204 },
    { 254, 153, 254 },
    { 254, 204,   1 },
    { 254, 204,  51 },
    { 254, 204, 102 },
    { 254, 204, 153 },
    { 254, 204, 204 },
    { 254, 204, 254 },
    { 254, 254,   1 },
    { 254, 254,  51 },
    { 254, 254, 102 },
    { 254, 254, 153 },
    { 254, 254, 204 },
    { 254, 254, 254 },
};

#pragma data_seg()

#endif // __STDPAL__


=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\rgb8.cpp ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// This file implements RGB 8 colour space conversions, May 1995

#include <streams.h>
#include <colour.h>

// The file implements RGB8 (palettised) formats to RGB555,RGB565,RGB24 and
// RGB32 types. Some filters can only deal with palettised types (like the
// sample colour contrast filter) so having a good true colour conversion is
// reasonably worthwhile. For these formats we have an alignment optimised
// transforms for RGB8 to RGB555,RGB565 and RGB24. To use these the source
// and target rectangles and the widths must be aligned on DWORD boundaries.
// Because RGB555 and RGB565 are so similar we use common code for the two
// colour space conversions but the convertor objects have different Commit
// methods that build a lookup table differently for their respective types


// Generic RGB8 to RGB16 Constructor initialises base class

CRGB8ToRGB16Convertor::CRGB8ToRGB16Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut),
    m_pRGB16Table(NULL)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// Destructor just checks the table has been deleted

CRGB8ToRGB16Convertor::~CRGB8ToRGB16Convertor()
{
    ASSERT(m_pRGB16Table == NULL);
}


// This allocates the memory for transforming RGB8 to RGB16 images. We have
// a single lookup table that is indexed by the palette value, this maps the
// palette index whose actual colours are defined by the input palette into
// an output 16 bit representation which also includes a colour adjustment

HRESULT CRGB8ToRGB16Convertor::Commit()
{
    CConvertor::Commit();
    m_pRGB16Table = new DWORD[256];

    // Check it was allocated correctly

    if (m_pRGB16Table == NULL) {
        Decommit();
        return E_OUTOFMEMORY;
    }

    return NOERROR;
}


// This is called when we complete transforming RGB8 to RGB16 images, we must
// call the global decommit function and then delete the lookup table which we
// created in the commit, the table may not be present if an error occured

HRESULT CRGB8ToRGB16Convertor::Decommit()
{
    CConvertor::Decommit();

    // Delete the lookup table

    if (m_pRGB16Table) {
        delete[] m_pRGB16Table;
        m_pRGB16Table = NULL;
    }
    return NOERROR;
}


// Transform the input RGB8 image to an output RGB16 16 bit image. This is a
// tight loop taking each palette value and using it as an index to the table
// we initialised during the commit, this produces the output representation
// The table includes an adjustment that stops the image coming out slightly
// duller which it would do when we start dropping the trailing bits off

HRESULT CRGB8ToRGB16Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform

    if (m_bAligned == TRUE) {
        return TransformAligned(pInput,pOutput);
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        BYTE *pRGB8 = pInput;
        WORD *pRGB16 = (WORD *) pOutput;

        while (--Width) {
            *pRGB16++ = (WORD) m_pRGB16Table[*pRGB8++];
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB8 to RGB16 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we read four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC

HRESULT CRGB8ToRGB16Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB8 = (DWORD *) pInput;
        DWORD *pRGB16 = (DWORD *) pOutput;

        while (--Width) {

            DWORD RGB8 = *pRGB8++;

            *pRGB16++ = m_pRGB16Table[(BYTE)RGB8] |
                        (m_pRGB16Table[(BYTE)(RGB8 >> 8)] << 16);
            *pRGB16++ = m_pRGB16Table[(BYTE)(RGB8 >> 16)] |
                        (m_pRGB16Table[(BYTE)(RGB8 >> 24)] << 16);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor

CRGB8ToRGB565Convertor::CRGB8ToRGB565Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CRGB8ToRGB16Convertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB8ToRGB565Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB8ToRGB565Convertor(pIn,pOut);
}


// This is a specific commit function for RGB8 to RGB565 transformations, we
// create a lookup table for mapping the input palette values into an output
// 16 bit representation. We create a lookup table partly for speed and also
// so that we can account for the loss in bits. In fact many capture devices
// produce palettes where the there are only first five bits in the colours

HRESULT CRGB8ToRGB565Convertor::Commit()
{
    // Allocate the lookup table memory

    HRESULT hr = CRGB8ToRGB16Convertor::Commit();
    if (FAILED(hr)) {
        return hr;
    }

    // This creates the palette index lookup table

    ASSERT(m_pInputHeader->biBitCount == 8); // valid assertion?
    DWORD cClrUsed = m_pInputHeader->biClrUsed ? m_pInputHeader->biClrUsed : 256;
    for (DWORD Position = 0;Position < cClrUsed;Position++) {

        // Get the current palette colours ready for adjustment

        DWORD RedAdjust = m_pInputInfo->bmiColors[Position].rgbRed;
        DWORD GreenAdjust = m_pInputInfo->bmiColors[Position].rgbGreen;
        DWORD BlueAdjust = m_pInputInfo->bmiColors[Position].rgbBlue;

        // For the red and blue values we transform eight bit palette colours
        // into five bit output values by cutting off the trailing three bits
        // to stop this making the output duller we round the values first
        // Likewise for the green but we only allow for two bits dropped

        ADJUST(RedAdjust,4);
        ADJUST(BlueAdjust,4);
        ADJUST(GreenAdjust,2);

        m_pRGB16Table[Position] = ((RedAdjust >> 3) << 11) |
                                  ((GreenAdjust >> 2) << 5) |
                                  ((BlueAdjust >> 3));
    }
    return NOERROR;
}


// Constructor

CRGB8ToRGB555Convertor::CRGB8ToRGB555Convertor(VIDEOINFO *pIn,
                                               VIDEOINFO *pOut) :
    CRGB8ToRGB16Convertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB8ToRGB555Convertor::CreateInstance(VIDEOINFO *pIn,
                                                   VIDEOINFO *pOut)
{
    return new CRGB8ToRGB555Convertor(pIn,pOut);
}


// This is a specific commit function for RGB8 to RGB555 transformations, we
// create a lookup table for mapping the input palette values into an output
// 16 bit representation. We create a lookup table partly for speed and also
// so that we can account for the loss in bits. In fact many capture devices
// produce palettes where the there are only first five bits in the colours

HRESULT CRGB8ToRGB555Convertor::Commit()
{
    // Allocate the lookup table memory

    HRESULT hr = CRGB8ToRGB16Convertor::Commit();
    if (FAILED(hr)) {
        return hr;
    }

    // This creates the palette index lookup table

    ASSERT(m_pInputHeader->biBitCount == 8); // valid assertion?
    DWORD cClrUsed = m_pInputHeader->biClrUsed ? m_pInputHeader->biClrUsed : 256;
    for (DWORD Position = 0;Position < cClrUsed;Position++) {

        // Get the current palette colours ready for adjustment

        DWORD RedAdjust = m_pInputInfo->bmiColors[Position].rgbRed;
        DWORD GreenAdjust = m_pInputInfo->bmiColors[Position].rgbGreen;
        DWORD BlueAdjust = m_pInputInfo->bmiColors[Position].rgbBlue;

        // For all the three colour components we transform eight bit palette
        // colours into five bit output values by cutting off the trailing
        // three bits, this stops the output appearing duller by rounding

        ADJUST(RedAdjust,4);
        ADJUST(BlueAdjust,4);
        ADJUST(GreenAdjust,4);

        m_pRGB16Table[Position] = ((RedAdjust >> 3) << 10) |
                                  ((GreenAdjust >> 3) << 5) |
                                  ((BlueAdjust >> 3));
    }
    return NOERROR;
}


// Constructor

CRGB8ToRGB24Convertor::CRGB8ToRGB24Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB8ToRGB24Convertor::CreateInstance(VIDEOINFO *pIn,
                                                  VIDEOINFO *pOut)
{
    return new CRGB8ToRGB24Convertor(pIn,pOut);
}


// This transforms a RGB8 input image to a RGB24 output image. We could have
// done this by having a large lookup table whose index is the palette value
// and whose output would be the RGB24 triplet, however it seems to gain so
// little over copying the three colours independantly that I didn't bother

HRESULT CRGB8ToRGB24Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Can we do an alignment optimised transform?

    if (m_bAligned == TRUE) {
        if (S_OK == TransformAligned(pInput,pOutput))
	    return S_OK;
    }

    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    while (--Height) {

        LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
        BYTE *pRGB8 = pInput;
        BYTE *pRGB24 = pOutput;

        while (--Width) {

            pRGB24[0] = m_pInputInfo->bmiColors[*pRGB8].rgbBlue;
            pRGB24[1] = m_pInputInfo->bmiColors[*pRGB8].rgbGreen;
            pRGB24[2] = m_pInputInfo->bmiColors[*pRGB8].rgbRed;

            pRGB8++;
            pRGB24 += 3;
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// This does the same colour space conversion as the RGB8 to RGB24 convertor
// except that it goes a little faster. The way it does this is by reading
// and writing DWORDs into memory. For example we read four of the dithered
// palettised pixels at once. The relies on the source and target pointers
// being aligned correctly otherwise we will start geting exceptions on RISC
// This assumes that the rgbReserved field in the RGBQUAD palette colours is
// set to zero (as it should be), otherwise the transform will have to do so

HRESULT CRGB8ToRGB24Convertor::TransformAligned(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    // All the reserved fields should be set zero, or this function won't work!

    ASSERT(m_pInputHeader->biBitCount == 8); // !!! valid assertion?
    DWORD cClrUsed = m_pInputHeader->biClrUsed ? m_pInputHeader->biClrUsed : 256;
    for (DWORD i = 0;i < cClrUsed;i++) {
        //ASSERT(m_pInputInfo->bmiColors[i].rgbReserved == 0);
        if (m_pInputInfo->bmiColors[i].rgbReserved != 0)
	    return S_FALSE;
    }

    while (--Height) {

        LONG Width = (WIDTH(&m_pOutputInfo->rcTarget) >> 2) + 1;
        DWORD *pRGB8 = (DWORD *) pInput;
        DWORD *pRGB24 = (DWORD *) pOutput;

        while (--Width) {

            // Read four palettised pixels and get their RGBQUAD values

            DWORD RGB8 = *pRGB8++;
            DWORD RGB24a = *((DWORD *)&m_pInputInfo->bmiColors[(BYTE)RGB8]);
            DWORD RGB24b = *((DWORD *)&m_pInputInfo->bmiColors[(BYTE)(RGB8 >> 8)]);
            DWORD RGB24c = *((DWORD *)&m_pInputInfo->bmiColors[(BYTE)(RGB8 >> 16)]);
            DWORD RGB24d = *((DWORD *)&m_pInputInfo->bmiColors[(BYTE)(RGB8 >> 24)]);

            // Construct three DWORDs for the four RGB24 pixels

            *pRGB24++ = (RGB24a) | (RGB24b << 24);
            *pRGB24++ = (RGB24b >> 8) | (RGB24c << 16);
            *pRGB24++ = (RGB24c >> 16) | (RGB24d << 8);
        }
        pInput += m_SrcStride;
        pOutput += m_DstStride;
    }
    return NOERROR;
}


// Constructor

CRGB8ToRGB32Convertor::CRGB8ToRGB32Convertor(VIDEOINFO *pIn,
                                             VIDEOINFO *pOut) :
    CConvertor(pIn,pOut)
{
    ASSERT(pIn);
    ASSERT(pOut);
}


// This goes in the table of available lookups to create a transform object
// derived from the base CConvertor class that does the type specific work.
// We initialise the constructor with the fields that it will need to do the
// conversion work and return a pointer to the object or NULL if it failed

CConvertor *CRGB8ToRGB32Convertor::CreateInstance(VIDEOINFO *pIn,
                                                  VIDEOINFO *pOut)
{
    return new CRGB8ToRGB32Convertor(pIn,pOut);
}


// This transforms a RGB8 input image to a RGB32 output image. As luck would
// have it transforming a palettised image to a 32 bit format is easy since
// the palette RGBQUADs are in exactly the same format as the 32 pixels are
// represented by. Therefore we can just copy the four bytes into the output
// buffer for each pixel. We assume that the output buffer is DWORD aligned

HRESULT CRGB8ToRGB32Convertor::Transform(BYTE *pInput,BYTE *pOutput)
{
    // Adjust the height to allow for an immediate decrement

    LONG Height = HEIGHT(&m_pOutputInfo->rcTarget) + 1;
    pInput += m_SrcOffset;
    pOutput += m_DstOffset;

    if( m_bSetAlpha )
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            BYTE *pRGB8 = pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = 0xFF000000 | *((DWORD *) &m_pInputInfo->bmiColors[*pRGB8++]); // alpha
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    else
    {
        while (--Height) {

            LONG Width = WIDTH(&m_pOutputInfo->rcTarget) + 1;
            BYTE *pRGB8 = pInput;
            DWORD *pRGB32 = (DWORD *) pOutput;

            while (--Width) {
                *pRGB32++ = *((DWORD *) &m_pInputInfo->bmiColors[*pRGB8++]);
            }
            pInput += m_SrcStride;
            pOutput += m_DstStride;
        }
    }
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\colour\rgb8.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This filter implements RGB 8 colour space conversions, May 1995

#ifndef __RGB8__
#define __RGB8__

// Round up values before chopping bits off them, this is done when we convert
// RGB colour component values into RGB 16 bit representation where they have
// fewer bits per pixel (such as RGB555). The rounding allows for the reduced
// accuracy otherwise the bit chopping gives the output image less contrast

#define ADJUST(Colour,Adjust)                      \
    if (Colour & Adjust) {                         \
        Colour = min(255,(Colour + Adjust));       \
    }


// We use a special lookup table that both the RGB555 and RGB565 transforms
// share. They have their own specific commit functions that set the tables up
// appropriately but they share the overall committing and decommitting of the
// memory. They also share the same transform function as once the tables are
// initialise the actual conversion work just involves looking up values

class CRGB8ToRGB16Convertor : public CConvertor {
protected:

    DWORD *m_pRGB16Table;

public:

    // Constructor and destructor

    CRGB8ToRGB16Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    ~CRGB8ToRGB16Convertor();

    HRESULT Commit();
    HRESULT Decommit();
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};


// This class looks after doing RGB8 to RGB16 (565 colour bit representation)
// conversions. We use the base class Commit, Decommit and Transform functions
// to manage the lookup tables. We override the virtual Commit function to
// initialise the lookup tables appropriately once they have been allocated

class CRGB8ToRGB565Convertor : public CRGB8ToRGB16Convertor {
public:

    CRGB8ToRGB565Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Commit();
};


// This class looks after doing RGB8 to RGB16 (555 colour bit representation)
// conversions. We use the base class Commit, Decommit and Transform functions
// to manage the lookup tables. We override the virtual Commit function to
// initialise the lookup tables appropriately once they have been allocated

class CRGB8ToRGB555Convertor : public CRGB8ToRGB16Convertor {
public:

    CRGB8ToRGB555Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Commit();
};


// This class looks after doing RGB8 to RGB24 colour conversions. We use the
// base class Commit and Decommit since we have no lookup tables (all that is
// really involved is memory copying) but we override the Transform method

class CRGB8ToRGB24Convertor : public CConvertor {
public:

    CRGB8ToRGB24Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
    HRESULT TransformAligned(BYTE *pInput,BYTE *pOutput);
};


// RGB8 to true colour RGB32 pixel format

class CRGB8ToRGB32Convertor : public CConvertor {
public:

    CRGB8ToRGB32Convertor(VIDEOINFO *pIn,VIDEOINFO *pOut);
    static CConvertor *CreateInstance(VIDEOINFO *pIn,VIDEOINFO *pOut);
    HRESULT Transform(BYTE *pInput,BYTE *pOutput);
};

#endif // __RGB8 __
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\dither\dither.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This implements VGA colour dithering, April 1996, Anthony Phillips

#ifndef __DITHER__
#define __DITHER__

extern const AMOVIESETUP_FILTER sudDitherFilter;

// These are the cosmic VGA colours

const RGBQUAD VGAColours[] =
{
     {0x00, 0x00, 0x00},
     {0x00, 0x00, 0x80},
     {0x00, 0x80, 0x00},
     {0x00, 0x80, 0x80},
     {0x80, 0x00, 0x00},
     {0x80, 0x00, 0x80},
     {0x80, 0x80, 0x00},
     {0xc0, 0xc0, 0xc0},
     {0x80, 0x80, 0x80},
     {0x00, 0x00, 0xff},
     {0x00, 0xff, 0x00},
     {0x00, 0xff, 0xff},
     {0xff, 0x00, 0x00},
     {0xff, 0x00, 0xff},
     {0xff, 0xff, 0x00},
     {0xff, 0xff, 0xff}
};

// An RGB24 to VGA system colour dithering transform filter

class CDither : public CTransformFilter
{
public:

    CDither(TCHAR *pName,LPUNKNOWN pUnk);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk,HRESULT *phr);

    // Manage type checking and the VGA colour conversion

    HRESULT CheckVideoType(const CMediaType *pmtIn);
    HRESULT CheckInputType(const CMediaType *pmtIn);
    HRESULT CheckTransform(const CMediaType *pmtIn,const CMediaType *pmtOut);
    HRESULT GetMediaType(int iPosition,CMediaType *pmtOut);
    HRESULT SetMediaType(PIN_DIRECTION direction, const CMediaType *pmt);
    HRESULT Transform(IMediaSample *pIn,IMediaSample *pOut);


    // Prepare the allocator's count of buffers and sizes
    HRESULT DecideBufferSize(IMemAllocator *pAllocator,
                             ALLOCATOR_PROPERTIES *pProperties);

private:
    BYTE    m_DitherTable[256 * 8 * 8];
    BOOL    m_fInit;
    UINT    m_wWidthSrc;
    UINT    m_wWidthDst;
    int     m_DstXE;
    int     m_DstYE;

    HRESULT SetInputPinMediaType(const CMediaType *pmt);
    void SetOutputPinMediaType(const CMediaType *pmt);

    BOOL    DitherDeviceInit(LPBITMAPINFOHEADER lpbi);
    void    Dither8(LPBYTE lpDst, LPBYTE lpSrc);
};

#endif // __DITHER__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\modex\fullscr.cpp ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Implements a fullscreen interface, Anthony Phillips, March 1996

#include <streams.h>
#include <windowsx.h>
#include <string.h>
#include <limits.h>
#include <vidprop.h>
#include <modex.h>
#include <viddbg.h>

// The IFullScreenVideo interface allows an application to control a full
// screen renderer. The Modex renderer supports this interface. When we
// are connected we load the display modes DirectDraw has made available
// The number of modes available can be obtained through CountModes. Then
// information on each individual mode is available by calling GetModeInfo
// and IsModeAvailable. An application may enable and disable any modes
// by calling the SetEnabled flag with OATRUE or OAFALSE (not C/C++ TRUE
// and FALSE values) - the current value may be queried by IsModeEnabled

// A more generic way of setting the modes enabled that is easier to use
// when writing applications is the clip loss factor. This defines the
// amount of video that can be lost when deciding which display mode to
// use. Assuming the decoder cannot compress the video then playing an
// MPEG file (say 352x288) into a 320x200 display will lose over 40% of
// the image. The clip loss factor specifies the upper range permissible.
// To allow typical MPEG video to be played in 320x200 it defaults to 50%

// These are the display modes that we support. New modes can just be added
// in the right place and should work straight away. When selecting the mode
// to use we start at the top and work our way down. Not only must the mode
// be available but the amount of video lost by clipping if it is to be used
// (assuming the filter can't compress the video) must not exceed the clip
// lost factor. The display modes enabled (which may not be available) and
// the clip loss factor can all be changed by the IFullScreenVideo interface

struct {

    LONG Width;            // Width of the display mode
    LONG Height;           // Likewise the mode height
    LONG Depth;            // Number of bits per pixel
    BOOL b565;             // For 16 bit modes, is this 565 or 555?

} aModes[MAXMODES] = {
    { 320,  200,  16 },
    { 320,  200,  8  },
    { 320,  240,  16 },
    { 320,  240,  8  },
    { 640,  400,  16 },
    { 640,  400,  8  },
    { 640,  480,  16 },
    { 640,  480,  8  },
    { 800,  600,  16 },
    { 800,  600,  8  },
    { 1024, 768,  16 },
    { 1024, 768,  8  },
    { 1152, 864,  16 },
    { 1152, 864,  8  },
    { 1280, 1024, 16 },
    { 1280, 1024, 8  }
};

double myfabs(double x)
{
    if (x >= 0)
        return x;
    else
        return -x;
}

// Constructor

CModexVideo::CModexVideo(CModexRenderer *pRenderer,
                         TCHAR *pName,
                         HRESULT *phr) :

    CUnknown(pName,pRenderer->GetOwner()),
    m_ClipFactor(CLIPFACTOR),
    m_pRenderer(pRenderer),
    m_pDirectDraw(NULL),
    m_ModesAvailable(0),
    m_ModesEnabled(0),
    m_CurrentMode(0),
    m_hwndDrain(NULL),
    m_Monitor(MONITOR),
    m_bHideOnDeactivate(FALSE)
{
    ASSERT(pRenderer);
    ASSERT(phr);
    InitialiseModes();
}


// Destructor

CModexVideo::~CModexVideo()
{
    ASSERT(m_pDirectDraw == NULL);
}


// This is a private helper method to install us with the DirectDraw driver
// we should be using. All our methods except GetCurrentMode may be called
// when we're not connected. Calling GetCurrentMode when not connected will
// return VFW_E_NOT_CONNECTED. We use this to enumerate the display modes
// available of the current display card. We do not AddRef nor release the
// interface as the lifetime of the interface is controlled by the filter

HRESULT CModexVideo::SetDirectDraw(IDirectDraw *pDirectDraw)
{
    NOTE("Entering SetDirectDraw");
    CAutoLock Lock(this);
    m_pDirectDraw = pDirectDraw;
    m_ModesAvailable = 0;
    m_CurrentMode = 0;

    // Are we being reset

    if (m_pDirectDraw == NULL) {
        NOTE("No driver");
        return NOERROR;
    }

    // Enumerate all the available display modes

    m_pDirectDraw->EnumDisplayModes((DWORD) 0,        // Surface count
                                    NULL,             // No template
                                    (PVOID) this,     // Allocator object
                                    ModeCallBack);    // Callback method


    // WARNING: Platform Specific hacks here: The modex mode 320x240x8 is available on every
    // video card on win95 platform. However the modex modes are only available on NT5.0 on higher.
    if ((g_osInfo.dwPlatformId == VER_PLATFORM_WIN32_WINDOWS) ||
	((g_osInfo.dwPlatformId == VER_PLATFORM_WIN32_NT) && (g_osInfo.dwMajorVersion >= 5)))
	m_bAvailable[3] = TRUE;

    // Check there is at least one mode available

    if (m_ModesAvailable == 0) {
        NOTE("No Modes are available");
        return VFW_E_NO_MODEX_AVAILABLE;
    }
    return NOERROR;
}


// Called once for each display mode available. We are interested in scanning
// the list of available display modes so that during connection we can find
// out if the source filter will be able to supply us with a suitable format
// If none of the modes we support are available (see the list at the top)
// then we return VFW_E_NO_MODEX_AVAILABLE from CompleteConnect. If one of
// them is available but the source can't provide the type then we return a
// different error code (E_FAIL) so that a colour convertor is put inbetween

HRESULT CALLBACK ModeCallBack(LPDDSURFACEDESC pSurfaceDesc,LPVOID lParam)
{
    CModexVideo *pVideo = (CModexVideo *) lParam;
    NOTE("Entering ModeCallBack");
    TCHAR FormatString[128];

    wsprintf(FormatString,TEXT("%dx%dx%d (%d bytes)"),
             pSurfaceDesc->dwWidth,
             pSurfaceDesc->dwHeight,
             pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount,
             pSurfaceDesc->lPitch);

    DbgLog((LOG_TRACE,5,FormatString));

    // Yet more platform specific hacks - On Windows/NT 4 the stride is not
    // calculated correctly based on the bit depth but just returns a pixel
    // stride. We can try and detect this if the surface width matches the
    // stride and the bit count is greater than eight. The stride should be
    // greater than the surface width in all cases except if its palettised

    LONG lStride = pSurfaceDesc->lPitch;
    if (pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount > 8) {
        if (lStride == LONG(pSurfaceDesc->dwWidth)) {
            LONG lBytes = pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount / 8;
            lStride = pSurfaceDesc->dwWidth * lBytes;
        }
    }

    // Scan the supported list looking for a match

    for (int Loop = 0;Loop < MAXMODES;Loop++) {
        if (pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount == (DWORD) aModes[Loop].Depth) {
            if (pSurfaceDesc->dwWidth == (DWORD) aModes[Loop].Width) {
                if (pSurfaceDesc->dwHeight == (DWORD) aModes[Loop].Height) {
                    NOTE("Surface is supported");
                    pVideo->m_bAvailable[Loop] = TRUE;
                    pVideo->m_ModesAvailable++;
                    pVideo->m_Stride[Loop] = lStride;
		    // Is it a 555 or 565 mode?
		    // !!! Some buggy ddraw drivers may give 0 for bitmasks,
		    // and I'm assuming that means 555... if there's a buggy
		    // driver that means 565, I'm doing the wrong thing, but
		    // every DDraw app will probably be broken
		    if (aModes[Loop].Depth == 16 &&
				pSurfaceDesc->ddpfPixelFormat.dwRBitMask ==
				0x0000f800) {
			aModes[Loop].b565 = TRUE;
		    } else {
			aModes[Loop].b565 = FALSE;
		    }
                }
            }
        }
    }
    return S_FALSE;     // Return NOERROR to stop enumerating
}


// Reset the display modes enabled and available

void CModexVideo::InitialiseModes()
{
    NOTE("Entering InitialiseModes");
    m_ModesEnabled = MAXMODES;
    for (int Loop = 0;Loop < MAXMODES;Loop++) {
        m_bAvailable[Loop] = FALSE;
        m_bEnabled[Loop] = TRUE;
        m_Stride[Loop] = 0;
    }
    LoadDefaults();
}


// Increment the owning object reference count

STDMETHODIMP_(ULONG) CModexVideo::NonDelegatingAddRef()
{
    NOTE("ModexVideo NonDelegatingAddRef");
    return m_pRenderer->AddRef();
}


// Decrement the owning object reference count

STDMETHODIMP_(ULONG) CModexVideo::NonDelegatingRelease()
{
    NOTE("ModexVideo NonDelegatingRelease");
    return m_pRenderer->Release();
}


// Expose the IModexVideo interface we implement

STDMETHODIMP CModexVideo::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    NOTE("ModexVideo NonDelegatingQueryInterface");

    // We return the IFullScreenVideo interfaces

    if (riid == IID_IFullScreenVideo) {
        NOTE("Returning IFullScreenVideo interface");
        return GetInterface((IFullScreenVideo *)this,ppv);
    } else if (riid == IID_IFullScreenVideoEx) {
        NOTE("Returning IFullScreenVideoEx interface");
        return GetInterface((IFullScreenVideoEx *)this,ppv);
    }
    return m_pRenderer->QueryInterface(riid,ppv);
}


// Return the number of modes we support

STDMETHODIMP CModexVideo::CountModes(long *pModes)
{
    NOTE("Entering CountModes");
    CheckPointer(pModes,E_POINTER);
    CAutoLock Lock(this);
    *pModes = MAXMODES;
    return NOERROR;
}


// Return the width, height and depth for the given mode index. The modes are
// indexed starting at zero. We have a table containing the available display
// modes whose size is MAXMODES (saves us dynamically allocating the arrays)
// If we get as far as returning the dimensions then we check to see if the
// mode is going to be useable (must be available and enabled) and if so we
// return NOERROR. Otherwise we return S_FALSE which might save further calls
// by the application to IsEnabled/IsAvailable to determine this information

STDMETHODIMP CModexVideo::GetModeInfo(long Mode,long *pWidth,long *pHeight,long *pDepth)
{
    NOTE("Entering GetModeInfo");
    CheckPointer(pWidth,E_POINTER);
    CheckPointer(pHeight,E_POINTER);
    CheckPointer(pDepth,E_POINTER);
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }

    // Load the display dimensions

    *pWidth = aModes[Mode].Width;
    *pHeight = aModes[Mode].Height;
    *pDepth = aModes[Mode].Depth;

    return (m_bAvailable[Mode] || m_bEnabled[Mode] ? NOERROR : S_FALSE);
}

// and now the version that works... and tells you if a 16 bit mode is 565

STDMETHODIMP CModexVideo::GetModeInfoThatWorks(long Mode,long *pWidth,long *pHeight,long *pDepth, BOOL *pb565)
{
    NOTE("Entering GetModeInfoThatWorks");
    CheckPointer(pWidth,E_POINTER);
    CheckPointer(pHeight,E_POINTER);
    CheckPointer(pDepth,E_POINTER);
    CheckPointer(pb565,E_POINTER);
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }

    // Load the display dimensions

    *pWidth = aModes[Mode].Width;
    *pHeight = aModes[Mode].Height;
    *pDepth = aModes[Mode].Depth;
    *pb565 = aModes[Mode].b565;

    return (m_bAvailable[Mode] || m_bEnabled[Mode] ? NOERROR : S_FALSE);
}


// Return the mode the allocator is going to use

STDMETHODIMP CModexVideo::GetCurrentMode(long *pMode)
{
    NOTE("Entering GetCurrentMode");
    CheckPointer(m_pDirectDraw,VFW_E_NOT_CONNECTED);
    CheckPointer(pMode,E_POINTER);
    CAutoLock Lock(this);

    *pMode = m_CurrentMode;
    return NOERROR;
}


// Returns NOERROR (S_OK) if the mode supplied is available

STDMETHODIMP CModexVideo::IsModeAvailable(long Mode)
{
    NOTE("Entering IsModeAvailable");
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }
    return (m_bAvailable[Mode] ? NOERROR : S_FALSE);
}


// Returns NOERROR (S_OK) if the mode suppiled is enabled

STDMETHODIMP CModexVideo::IsModeEnabled(long Mode)
{
    NOTE("Entering IsModeEnabled");
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }
    return (m_bEnabled[Mode] ? NOERROR : S_FALSE);
}


// Disables the given mode used when selecting the surface

STDMETHODIMP CModexVideo::SetEnabled(long Mode,long bEnabled)
{
    NOTE("Entering SetEnabled");
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return E_INVALIDARG;
    }

    // Check the flag passed in is valid

    if (bEnabled != OATRUE) {
        if (bEnabled != OAFALSE) {
            NOTE("Invalid enabled");
            return E_INVALIDARG;
        }
    }
    m_bEnabled[Mode] = (bEnabled == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Return the amount of video permissible to clip off

STDMETHODIMP CModexVideo::GetClipFactor(long *pClipFactor)
{
    NOTE("Entering GetClipFactor");
    CheckPointer(pClipFactor,E_POINTER);
    CAutoLock Lock(this);

    *pClipFactor = m_ClipFactor;
    return NOERROR;
}


// Set the amount of video permissible to clip off

STDMETHODIMP CModexVideo::SetClipFactor(long ClipFactor)
{
    NOTE("Entering SetClipFactor");
    CAutoLock Lock(this);

    // Check the value is a percentage

    if (ClipFactor < 0 || ClipFactor > 100) {
        NOTE("Invalid clip factor");
        return E_INVALIDARG;
    }
    m_ClipFactor = ClipFactor;
    return NOERROR;
}


// Set the target window for posting on our messages

STDMETHODIMP CModexVideo::SetMessageDrain(HWND hwnd)
{
    NOTE("Entering SetMessageDrain");
    CAutoLock Lock(this);
    m_hwndDrain = (HWND) hwnd;
    return NOERROR;
}


// Return the current window message sink

STDMETHODIMP CModexVideo::GetMessageDrain(HWND *hwnd)
{
    NOTE("Entering GetMessageDrain");
    CheckPointer(hwnd,E_POINTER);
    CAutoLock Lock(this);
    *hwnd = m_hwndDrain;
    return NOERROR;
}


// Set the default monitor to play fullscreen on

STDMETHODIMP CModexVideo::SetMonitor(long Monitor)
{
    NOTE("Entering SetMonitor");
    CAutoLock Lock(this);

    // Check the monitor passed in is valid

    if (Monitor != 0) {
        NOTE("Invalid monitor");
        return E_INVALIDARG;
    }
    return NOERROR;
}


// Return whether we will we hide the window when iconic

STDMETHODIMP CModexVideo::GetMonitor(long *Monitor)
{
    NOTE("Entering GetMonitor");
    CheckPointer(Monitor,E_POINTER);
    *Monitor = m_Monitor;
    return NOERROR;
}


// Store the enabled settings in WIN.INI for simplicity

STDMETHODIMP CModexVideo::SetDefault()
{
    NOTE("Entering SetDefault");
    CAutoLock Lock(this);
    TCHAR Profile[PROFILESTR];
    TCHAR KeyName[PROFILESTR];

    // Save the current clip loss factor

    wsprintf(Profile,TEXT("%d"),m_ClipFactor);
    NOTE1("Saving clip factor %d",m_ClipFactor);
    WriteProfileString(TEXT("Quartz"),TEXT("ClipFactor"),Profile);

    // Save a key for each of our supported display modes

    for (int Loop = 0;Loop < MAXMODES;Loop++) {
        wsprintf(KeyName,TEXT("%dx%dx%d"),aModes[Loop].Width,aModes[Loop].Height,aModes[Loop].Depth);
        wsprintf(Profile,TEXT("%d"),m_bEnabled[Loop]);
        NOTE2("Saving mode setting %s (enabled %d)",KeyName,m_bEnabled[Loop]);
        WriteProfileString(TEXT("Quartz"),KeyName,Profile);
    }
    return NOERROR;
}


// Load the enabled modes and the clip factor. Neither the window caption nor
// the hide when iconic flag are stored as persistent properties. They appear
// in the property sheet partly as a test application but also for the user
// to fiddle with. Therefore the application has ultimate control over these
// when using the Modex renderer or can let the user adjust them. The plug in
// distributor uses these properties so that it can switch back into a window

HRESULT CModexVideo::LoadDefaults()
{
    NOTE("Entering LoadDefaults");
    CAutoLock Lock(this);
    TCHAR KeyName[PROFILESTR];
    m_ModesEnabled = 0;

    // Load the permissible clip loss factor

    m_ClipFactor = GetProfileInt(TEXT("Quartz"),TEXT("ClipFactor"),CLIPFACTOR);
    NOTE1("Clip factor %d",m_ClipFactor);

    // Load the key for each of our supported display modes

    for (int Loop = 0;Loop < MAXMODES;Loop++) {
        wsprintf(KeyName,TEXT("%dx%dx%d"),aModes[Loop].Width,aModes[Loop].Height,aModes[Loop].Depth);
        m_bEnabled[Loop] = GetProfileInt(TEXT("Quartz"),KeyName,TRUE);
        NOTE2("Loaded setting for mode %s (enabled %d)",KeyName,m_bEnabled[Loop]);
        if (m_bEnabled[Loop] == TRUE) { m_ModesEnabled++; }
    }

    return NOERROR;
}


// Should the window be hidden when deactivated

STDMETHODIMP CModexVideo::HideOnDeactivate(long Hide)
{
    NOTE("Entering HideOnDeactivate");
    CAutoLock Lock(this);

    // Check this is a valid automation boolean type

    if (Hide != OATRUE) {
        if (Hide != OAFALSE) {
            return E_INVALIDARG;
        }
    }
    m_bHideOnDeactivate = (Hide == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Will we hide the window when deactivated

STDMETHODIMP CModexVideo::IsHideOnDeactivate()
{
    NOTE("Entering IsHideOnDeactivate");
    CAutoLock Lock(this);
    return (m_bHideOnDeactivate ? S_OK : S_FALSE);
}


#include <atlconv.h>
// Change the title of the Modex window

STDMETHODIMP CModexVideo::SetCaption(BSTR strCaption)
{
    NOTE("Entering SetCaption");
    CheckPointer(strCaption,E_POINTER);
    CAutoLock Lock(this);
    HWND hwnd = m_pRenderer->m_ModexWindow.GetWindowHWND();

    USES_CONVERSION;
    SetWindowText(hwnd,W2T(strCaption));
    return NOERROR;
}


// Get the title of the Modex window

STDMETHODIMP CModexVideo::GetCaption(BSTR *pstrCaption)
{
    NOTE("Entering GetCaption");
    CheckPointer(pstrCaption,E_POINTER);
    CAutoLock Lock(this);

    TCHAR Caption[CAPTION];

    // Convert the ASCII caption to a UNICODE string

    HWND hwnd = m_pRenderer->m_ModexWindow.GetWindowHWND();
    GetWindowText(hwnd,Caption,CAPTION);
    USES_CONVERSION;
    *pstrCaption = T2BSTR(Caption);
    return *pstrCaption ? S_OK : E_OUTOFMEMORY;
}


// Return the stride for any given display mode

LONG CModexVideo::GetStride(long Mode)
{
    NOTE("Entering GetStride");
    CAutoLock Lock(this);

    // Check the mode is in our range

    if (Mode < 0 || Mode >= MAXMODES) {
        NOTE("Invalid mode");
        return LONG(0);
    }
    return m_Stride[Mode];
}

// this functions computes the order in which are to be tried. The criteria
// it uses are the following (in order) :
// 1) First since stretched video looks better than shrunk video, so modes in which
// both dimensions are getting stretched are given preferrence over ones in which
// dimension is getting stretched which are preferred over ones in which both
// dimensions are getting shrunk. Note that this criterion is really only relavant
// when the decoder is doing the stretching. Otherwise we always clip.
// 2) Second criterion is the amount by which we will have to scale/clip. Lesser this
// amount, the better it is.
// 3) Third, we prefer higher depth(16 bit) modes over lower depth (8 bit) ones.
void CModexVideo::OrderModes()
{
    double dEpsilon = 0.001;
    DWORD dwNativeWidth, dwNativeHeight;
    DWORD dwMode, dwMode1, dwMode2;
    VIDEOINFO *pVideoInfo = NULL;
    int i, j;
    BOOL bSorted;

    struct
    {
        DWORD dwStretchGrade;
        double dScaleAmount;
        DWORD dwDepth;
    } ModeProperties[MAXMODES];

    pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();

    dwNativeWidth = pVideoInfo->bmiHeader.biWidth;
    dwNativeHeight = pVideoInfo->bmiHeader.biHeight;

    // initialize the array to an invalid value
    for (i = 0, j = 0; i < MAXMODES; i++)
    {
        m_ModesOrder[i] = MAXMODES;
    }

    // take out the modes which are not available or not allowed
    for (i = 0, j = 0; i < MAXMODES; i++)
    {
        if (m_bAvailable[i] && m_bEnabled[i])
        {
            m_ModesOrder[j] = i;
            ASSERT(i >= 0 && i < MAXMODES);
            j++;
        }
    }
    m_dwNumValidModes = j;
    ASSERT(m_dwNumValidModes <= MAXMODES);


    if (m_dwNumValidModes == 0)
        return;

    // Now calculate the mode properties for the valid modes
    for (i = 0; i < MAXMODES; i++)
    {
        RECT rcTarget;
        DWORD dwTargetWidth, dwTargetHeight;

        // get the target rect which will maintain the aspect ratio
        m_pRenderer->m_ModexAllocator.ScaleToSurface(pVideoInfo, &rcTarget,
            aModes[i].Width, aModes[i].Height);

        dwTargetWidth = rcTarget.right - rcTarget.left;
        dwTargetHeight = rcTarget.bottom - rcTarget.top;

        // we assign points for stretching of width and heigth. Makes it easy to
        // change this rule later on
        ModeProperties[i].dwStretchGrade =
            ((dwTargetWidth  >= dwNativeWidth ) ? 1 : 0) +
            ((dwTargetHeight >= dwNativeHeight) ? 1 : 0);

        // calculate the factor by which we need to stretch/shrink and then make this
        // value relative to zero
        ModeProperties[i].dScaleAmount = (double) (dwTargetWidth * dwTargetHeight);
        ModeProperties[i].dScaleAmount /= (double) (dwNativeWidth * dwNativeHeight);
        ModeProperties[i].dScaleAmount = myfabs(ModeProperties[i].dScaleAmount - 1);

        ModeProperties[i].dwDepth = aModes[i].Depth;
    }



    // Now sort the modes such that the modes in which we have to stretch
    // are preferred than the ones in which we have to shrink.
    do
    {
        bSorted = TRUE;
        for (i = 0; i < (int)m_dwNumValidModes-1; i++)
        {
            dwMode1 = m_ModesOrder[i];
            dwMode2 = m_ModesOrder[i+1];

            ASSERT(dwMode1 < MAXMODES);
            ASSERT(dwMode2 < MAXMODES);

            // if the second is better than the first then swap
            if (ModeProperties[dwMode2].dwStretchGrade > ModeProperties[dwMode1].dwStretchGrade)
            {
                m_ModesOrder[i] = dwMode2;
                m_ModesOrder[i+1] = dwMode1;
                bSorted = FALSE;
            }
        }
    }
    while(!bSorted);

    // Now if the above criterion is the same then sort such that those modes which
    // have to be scaled less are preferred over those in which have to be scaled more
    do
    {
        bSorted = TRUE;
        for (i = 0; i < (int)m_dwNumValidModes-1; i++)
        {
            dwMode1 = m_ModesOrder[i];
            dwMode2 = m_ModesOrder[i+1];

            ASSERT(dwMode1 < MAXMODES);
            ASSERT(dwMode2 < MAXMODES);

            // if the second is better than the first then swap
            // since the ScaleAmount is a double, we use dEpsilon
            if ((ModeProperties[dwMode2].dwStretchGrade == ModeProperties[dwMode1].dwStretchGrade) &&
                (ModeProperties[dwMode2].dScaleAmount < ModeProperties[dwMode1].dScaleAmount-dEpsilon))
            {
                m_ModesOrder[i] = dwMode2;
                m_ModesOrder[i+1] = dwMode1;
                bSorted = FALSE;
            }
        }
    }
    while(!bSorted);

    // Now if the above criterion is the same then sort such that those modes which
    // are 16 bit are preferred over 8 bit (better quality that way).
    do
    {
        bSorted = TRUE;
        for (i = 0; i < (int)m_dwNumValidModes-1; i++)
        {
            dwMode1 = m_ModesOrder[i];
            dwMode2 = m_ModesOrder[i+1];

            ASSERT(dwMode1 < MAXMODES);
            ASSERT(dwMode2 < MAXMODES);
            // if the second is better than the first then swap
            // since the ScaleAmount is a double, two ScaleAmounts are considered
            // equal, if they are within dEpsilon.
            if ((ModeProperties[dwMode2].dwStretchGrade == ModeProperties[dwMode1].dwStretchGrade) &&
                (myfabs(ModeProperties[dwMode2].dScaleAmount - ModeProperties[dwMode1].dScaleAmount) < dEpsilon) &&
                (ModeProperties[dwMode2].dwDepth > ModeProperties[dwMode1].dwDepth))
            {
                m_ModesOrder[i] = dwMode2;
                m_ModesOrder[i+1] = dwMode1;
                bSorted = FALSE;
            }
        }
    }
    while(!bSorted);

    // generate some debug spew
    DbgLog((LOG_TRACE, 1, TEXT("Mode preferrence order ->")));
    for (i = 0; i < (int)m_dwNumValidModes; i++)
    {
        dwMode = m_ModesOrder[i];
        ASSERT(dwMode < MAXMODES);
        DbgLog((LOG_TRACE, 1, TEXT("%d Width=%d, Height=%d, Depth=%d"),
            i, aModes[dwMode].Width, aModes[dwMode].Height, aModes[dwMode].Depth));
    }

    // assert that all the other values are invalid
    for (i = m_dwNumValidModes; i < MAXMODES; i++)
    {
        ASSERT(m_ModesOrder[i] == MAXMODES);
    }

} // end of function OrderModes()

// Set the accelerator table we should dispatch messages with

STDMETHODIMP CModexVideo::SetAcceleratorTable(HWND hwnd,HACCEL hAccel)
{
    NOTE2("SetAcceleratorTable HWND %x HACCEL %x",hwnd,hAccel);
    CAutoLock Lock(this);
    m_pRenderer->m_ModexWindow.SetAcceleratorInfo(hwnd,hAccel);
    return NOERROR;
}


// Return the accelerator table we are dispatching messages with

STDMETHODIMP CModexVideo::GetAcceleratorTable(HWND *phwnd,HACCEL *phAccel)
{
    NOTE("GetAcceleratorTable");
    CheckPointer(phAccel,E_POINTER);
    CheckPointer(phwnd,E_POINTER);

    CAutoLock Lock(this);
    m_pRenderer->m_ModexWindow.GetAcceleratorInfo(phwnd,phAccel);
    return NOERROR;
}


// We always currently keep pixel aspect ratio

STDMETHODIMP CModexVideo::KeepPixelAspectRatio(long KeepAspect)
{
    NOTE1("KeepPixelAspectRatio %d",KeepAspect);
    if (KeepAspect == OAFALSE) {
        NOTE("Not supported");
        return E_NOTIMPL;
    }
    return (KeepAspect == OATRUE ? S_OK : E_INVALIDARG);
}


// We always currently keep pixel aspect ratio

STDMETHODIMP CModexVideo::IsKeepPixelAspectRatio(long *pKeepAspect)
{
    CheckPointer(pKeepAspect,E_POINTER);
    NOTE("IsKeepPixelAspectRatio");
    *pKeepAspect = OATRUE;

    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\modex\allocate.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements a Modex buffer allocator, Anthony Phillips, January 1996

#include <streams.h>
#include <windowsx.h>
#include <vidprop.h>
#include <modex.h>
#include <render.h>
#include <viddbg.h>
#include <amaudio.h>

// This implements a specialist allocator for the Modex renderer. Because we
// use a special display mode where neither us nor GDI can touch the display
// (since it's in a weird planar format when set to 320x240x8) we can only
// use our own allocator, this prevents us from being connected to someone
// like the infinite tee filter. When we are activated (either through pause
// or run) we load DirectDraw and allocate our surfaces, these are either a
// set of three triple buffered surfaces or just a pair. We try to create the
// surfaces in VRAM first but if that fails we drop back into system memory.
//
// We also use 320x200x8 (another Modex display mode) but most video content
// is 320x240 or larger (such as typically 352x240 in an MPEG case) so going
// to the smaller mode may lose considerably more of the image. However we
// will pick 320x200 by default (because we initialise the clip loss factor
// to 25%). For 352x288 images the clip is a bit less than 25%. If the image
// is larger than the 320x240 mode we ask the source to compress the image.
// If it cannot do this then we ask it for a central portion so dropping an
// equal amount of the picture off the left and right edges as well as the
// top and bottom where appropriate. If the image is smaller than the display
// mode then we ask it to centre the video in the surface we'll be providing
// or failing that we will decode into an offscreen surface and stretch that
//
// Most of the work is done during connection and activation. When we have a
// CompleteConnect called we check that the source filter can provide a type
// we will be able to display in any of the modes we support. If not we will
// reject the call, this may lead to having a colour space convertor put in
// between us so that it can do the clipping or necessary colour conversion
//
// When we are activated we switch display modes to the mode we agreed during
// the connection and then create the surfaces (the VRAM may not be available
// until we have switched modes). If we manage to create the surfaces then we
// are done otherwise we have to reject the activation. Since we are a full
// screen exclusive mode application which should get complete VRAM access
// and we can drop back to using system memory buffers if insufficient VRAM
// is available we should in most common situations always be able to pause
//
// Our implementation of GetBuffer looks after switching between GDI buffers
// and DirectDraw surfaces when it notices that either we are not activated
// any more (by the user hitting ALT-TAB) or we have lost the surface through
// a similar mechanism. We use GDI buffers for the source to dump their video
// in just through convenience, we don't actually draw the buffers we receive


// Constructor

CModexAllocator::CModexAllocator(CModexRenderer *pRenderer,
                                 CModexVideo *pModexVideo,
                                 CModexWindow *pModexWindow,
                                 CCritSec *pLock,
                                 HRESULT *phr) :

    CImageAllocator(pRenderer,NAME("Modex Allocator"),phr),
    m_pModexVideo(pModexVideo),
    m_pModexWindow(pModexWindow),
    m_pInterfaceLock(pLock),
    m_pRenderer(pRenderer),
    m_pDirectDraw(NULL),
    m_pFrontBuffer(NULL),
    m_pBackBuffer(NULL),
    m_pDrawPalette(NULL),
    m_bModeChanged(FALSE),
    m_cbSurfaceSize(0),
    m_bModexSamples(FALSE),
    m_bIsFrontStale(TRUE),
    m_ModeWidth(0),
    m_ModeHeight(0),
    m_ModeDepth(0),
    m_bTripleBuffered(FALSE),
    m_bOffScreen(FALSE),
    m_pDrawSurface(NULL)
{
    ASSERT(m_pRenderer);
    ASSERT(m_pModexVideo);
    ASSERT(m_pModexWindow);
    ASSERT(phr);

    m_fDirectDrawVersion1 = m_LoadDirectDraw.IsDirectDrawVersion1();

    // Allocate and zero fill the output format

    m_SurfaceFormat.AllocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    if (pVideoInfo) {
        ZeroMemory((PVOID)pVideoInfo,sizeof(VIDEOINFO));
    }
}


// Check our DirectDraw buffers have been released

CModexAllocator::~CModexAllocator()
{
    ASSERT(m_bCommitted == FALSE);
    ASSERT(m_pFrontBuffer == NULL);
    ASSERT(m_pDrawSurface == NULL);
    ASSERT(m_pDirectDraw == NULL);
}


// Overriden to increment the owning object's reference count

STDMETHODIMP_(ULONG) CModexAllocator::NonDelegatingAddRef()
{
    NOTE("Entering NonDelegatingAddRef");
    return m_pRenderer->AddRef();
}


// Overriden to decrement the owning object's reference count

STDMETHODIMP_(ULONG) CModexAllocator::NonDelegatingRelease()
{
    NOTE("Entering NonDelegatingRelease");
    return m_pRenderer->Release();
}


// Prepare the allocator by checking the input parameters. The Modex renderer
// only ever works with one buffer so we change the input count accordingly
// If the source filter requires more than one buffer to operate then they
// cannot be connected to us. We also update the buffer size so that it does
// not exceed the size of the video image that it will contain in the future

STDMETHODIMP CModexAllocator::CheckSizes(ALLOCATOR_PROPERTIES *pRequest)
{
    NOTE("Entering CheckSizes");

    // Check we have a valid connection

    if (m_pMediaType == NULL) {
        return VFW_E_NOT_CONNECTED;
    }

    // We always create a DirectDraw surface with the source format

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pMediaType->Format();
    if ((DWORD) pRequest->cbBuffer < pVideoInfo->bmiHeader.biSizeImage) {
        return E_INVALIDARG;
    }

    // Reject buffer prefixes

    if (pRequest->cbPrefix > 0) {
        return E_INVALIDARG;
    }

    pRequest->cbBuffer = pVideoInfo->bmiHeader.biSizeImage;
    pRequest->cBuffers = 1;
    return NOERROR;
}


// Agree the number of media sample buffers and their sizes. The base class
// this allocator is derived from allows samples to be aligned only on byte
// boundaries NOTE the buffers are not allocated until the Commit is called
// Because the samples we return are DirectDraw surfaces we only allow one
// sample ever to be allocated, so reset the incoming sample count to one.
// If the source must have more than one sample then it can't connect to us

STDMETHODIMP CModexAllocator::SetProperties(ALLOCATOR_PROPERTIES *pRequest,
                                            ALLOCATOR_PROPERTIES *pActual)
{
    ALLOCATOR_PROPERTIES Adjusted = *pRequest;
    NOTE("Entering SetProperties");

    // Check the parameters fit with the current connection

    HRESULT hr = CheckSizes(&Adjusted);
    if (FAILED(hr)) {
        return hr;
    }
    return CBaseAllocator::SetProperties(&Adjusted,pActual);
}


// The base CImageAllocator class calls this virtual method to actually make
// the samples. It is deliberately virtual so that we can override to create
// more specialised sample objects. On our case our samples are derived from
// CImageSample but add the DirectDraw guff. We return a CImageSample object
// which is easy enough because the CVideoSample class is derived from that

CImageSample *CModexAllocator::CreateImageSample(LPBYTE pData,LONG Length)
{
    NOTE("Entering CreateImageSample");
    HRESULT hr = NOERROR;
    CVideoSample *pSample;

    // Allocate the new sample and check the return codes

    pSample = new CVideoSample((CModexAllocator*) this,    // Base allocator
                               NAME("Video sample"),       // DEBUG name
                               (HRESULT *) &hr,            // Return code
                               (LPBYTE) pData,             // DIB address
                               (LONG) Length);             // Size of DIB

    if (pSample == NULL || FAILED(hr)) {
        delete pSample;
        return NULL;
    }
    return pSample;
}


// Called when the format changes for the source video. Modex only works with
// eight bit palettised formats so we always have to create a palette through
// DirectDraw. All we have to do is hand it 256 colours even if we don't have
// that many and let it create an IDirectDrawPalette object. If we don't have
// DirectDraw loaded yet then we defer the palette object creation until later

HRESULT CModexAllocator::UpdateDrawPalette(const CMediaType *pMediaType)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pMediaType->Format();
    VIDEOINFO *pSurfaceInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    NOTE("Entering UpdateDrawPalette");
    PALETTEENTRY ColourTable[256];
    CAutoLock cVideoLock(this);

    // Do we have created our surfaces yet

    if (m_pFrontBuffer == NULL) {
        NOTE("No DirectDraw");
        return NOERROR;
    }

    // Does this surface require a palette

    if (m_ModeDepth != 8) {
        NOTE("No palette");
        return NOERROR;
    }

    // We should have a palette to extract

    if (PALETTISED(pVideoInfo) == FALSE) {
        ASSERT(!TEXT("No source palette"));
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Initialise the palette colours if default used

    ULONG PaletteColours = pVideoInfo->bmiHeader.biClrUsed;
    if (pVideoInfo->bmiHeader.biClrUsed == 0) {
        PaletteColours = PALETTE_ENTRIES(pVideoInfo);
    }

    // Copy the palette colours into our output format

    CopyMemory((PVOID) pSurfaceInfo->bmiColors,
               (PVOID) pVideoInfo->bmiColors,
               PaletteColours * sizeof(RGBQUAD));

    ASSERT(*pMediaType->Subtype() == MEDIASUBTYPE_RGB8);
    ASSERT(pVideoInfo->bmiHeader.biClrUsed <= 256);
    ASSERT(pVideoInfo->bmiHeader.biCompression == BI_RGB);
    ASSERT(pVideoInfo->bmiHeader.biBitCount == 8);
    ZeroMemory((PVOID) ColourTable,sizeof(ColourTable));

    // Copy the colours into a PALETTEENTRY array

    for (WORD i = 0;i < PaletteColours;i++) {
        ColourTable[i].peRed = (BYTE) pVideoInfo->bmiColors[i].rgbRed;
        ColourTable[i].peGreen = (BYTE) pVideoInfo->bmiColors[i].rgbGreen;
        ColourTable[i].peBlue = (BYTE) pVideoInfo->bmiColors[i].rgbBlue;
        ColourTable[i].peFlags = (BYTE) PC_NOCOLLAPSE;
    }

    // Are we updating the colours in an existing palette
    if (m_pDrawPalette) return m_pDrawPalette->SetEntries(0,0,256,ColourTable);

    // Create the palette object for the colour table

    HRESULT hr = m_pDirectDraw->CreatePalette(DDPCAPS_8BIT,
                                              ColourTable,
                                              &m_pDrawPalette,
                                              (IUnknown *) NULL);
    if (FAILED(hr)) {
        NOTE("No palette");
        return hr;
    }
    return m_pFrontBuffer->SetPalette(m_pDrawPalette);
}


// Called when we have a sample delivered to our input pin

void CModexAllocator::OnReceive(IMediaSample *pMediaSample)
{
    NOTE("Entering CModexAllocator OnReceive");
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    pVideoSample->SetDirectInfo(NULL,NULL,0,NULL);

    // Set up the surface we should be unlocking
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();

    // We may have switched to using DIBSECTION samples

    if (m_bModexSamples == TRUE) {
        pSurface->Unlock(NULL);
        m_bIsFrontStale = FALSE;
    }
}


// Return TRUE if we are using DirectDraw at the moment

BOOL CModexAllocator::GetDirectDrawStatus()
{
    NOTE("GetDirectDrawStatus");
    CAutoLock cVideoLock(this);
    return m_bModexSamples;
}


// Overriden from CBaseAllocator and called when the final reference count
// is released on a media sample so that it can be added to the tail of the
// allocator free list. We intervene at this point to make sure that if the
// display was locked when GetBuffer was called that it is always unlocked
// regardless of whether the source calls Receive on our input pin or not

STDMETHODIMP CModexAllocator::ReleaseBuffer(IMediaSample *pMediaSample)
{
    NOTE("Entering ReleaseBuffer");

    CheckPointer(pMediaSample,E_POINTER);
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    BYTE *pBuffer = pVideoSample->GetDirectBuffer();
    pVideoSample->SetDirectInfo(NULL,NULL,0,NULL);

    // Set up the surface we should be unlocking
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();

    // Is this a preroll sample (still locked)

    if (pBuffer != NULL) {
        ASSERT(pSurface);
        pSurface->Unlock(NULL);
        m_bIsFrontStale = TRUE;
    }
    return CBaseAllocator::ReleaseBuffer(pMediaSample);
}


// We override the IMemAllocator GetBuffer function so that after retrieving
// the next sample from the free queue we prepare it with a pointer to the
// DirectDraw surface. If the lock fails then we have probably been switched
// away from using ALT-TAB so the best thing to do is to return an error to
// to the source filter. When the sample is subsequently delivered to our
// input pin or released we will reset the DirectDraw information held by it

STDMETHODIMP CModexAllocator::GetBuffer(IMediaSample **ppSample,
                                        REFERENCE_TIME *pStartTime,
                                        REFERENCE_TIME *pEndTime,
                                        DWORD dwFlags)
{
    CheckPointer(ppSample,E_POINTER);
    NOTE("Entering GetBuffer");
    HRESULT hr;

    // Synchronise by getting a sample from the base class queue

    hr = CBaseAllocator::GetBuffer(ppSample,pStartTime,pEndTime,dwFlags);
    if (FAILED(hr)) {
        return hr;
    }

    CAutoLock cVideoLock(this);
    NOTE("Locked Modex allocator");

    // Keep trying to use our DirectDraw surfaces

    hr = StartDirectAccess(*ppSample,dwFlags);
    if (FAILED(hr)) {
        return StopUsingDirectDraw(ppSample);
    }
    return NOERROR;
}


// Called to switch back to using normal DIBSECTION buffers. We may be called
// when we are not using DirectDraw anyway in which case we do nothing except
// setting the type back to NULL (just in case it has a DirectDraw type). If
// the type has to be changed back then we do not query it with the source as
// it should always accept it - even if when changed it has to seek forwards

HRESULT CModexAllocator::StopUsingDirectDraw(IMediaSample **ppSample)
{
    NOTE("Entering StopUsingDirectDraw");
    IMediaSample *pSample = *ppSample;

    // Is there anything to do

    if (m_bModexSamples == FALSE) {
        pSample->SetMediaType(NULL);
        return NOERROR;
    }

    m_bModexSamples = FALSE;
    pSample->SetMediaType(&m_pRenderer->m_mtIn);
    pSample->SetDiscontinuity(TRUE);
    NOTE("Attached original type to sample");

    return NOERROR;
}


// Return the surface we should be using as primary lock destination

inline LPDIRECTDRAWSURFACE CModexAllocator::GetDirectDrawSurface()
{
    if (m_pDrawSurface == NULL) {
        return m_pBackBuffer;
    }
    return m_pDrawSurface;
}


// This tries to lock the backing surface for the source filter to use as an
// output buffer. We may be called in a number of situations. Firstly of all
// when we are switching into using Modex samples for the first time after
// some break in which case we must set the output format type on it. We may
// also get in here to find the surface has gone in which case we return an
// error code and leave GetBuffer to switch the source back to using a DIB
// buffer. We don't do anything with the DIB buffer but it's easy to handle

HRESULT CModexAllocator::StartDirectAccess(IMediaSample *pMediaSample,DWORD dwFlags)
{
    NOTE("Entering StartDirectAccess");

    // Initialise the size field in the DDSURFACEDESC structure

    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);

    // Check we still have a surface

    if (m_pFrontBuffer == NULL) {
        NOTE("No front buffer");
        return E_UNEXPECTED;
    }

    // What state is the display in

    if (m_bModeChanged == FALSE) {
        NOTE("No display change");
        return E_UNEXPECTED;
    }

    // Handle our window being switched away from

    if (m_pFrontBuffer->IsLost() == DDERR_SURFACELOST) {
        NOTE("Surface is lost");
        return E_UNEXPECTED;
    }

    // Only copy if the back buffer is needed

    if (dwFlags & AM_GBF_NOTASYNCPOINT) {
        if (m_pDrawSurface == NULL) {
            PrepareBackBuffer(m_pBackBuffer);
        }
    }

    // Set up the surface we should be locking
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();

    // Lock the surface to get the buffer pointer

    HRESULT hr = pSurface->Lock((RECT *) NULL,    // Target rectangle
                                &SurfaceDesc,     // Return information
                                DDLOCK_WAIT,      // Wait for surface
                                (HANDLE) NULL);   // Don't use event
    if (FAILED(hr)) {
        NOTE1("No lock %lx",hr);
        return hr;
    }

    // Does this sample need the output format attached

    if (m_bModexSamples == FALSE) {
        NOTE("Attaching DirectDraw type to sample");
        pVideoSample->SetMediaType(&m_SurfaceFormat);
        pVideoSample->SetDiscontinuity(TRUE);
        m_bModexSamples = TRUE;
    }

    // Display some surface information

    NOTE1("Stride %d",SurfaceDesc.lPitch);
    NOTE1("Width %d",SurfaceDesc.dwWidth);
    NOTE1("Height %d",SurfaceDesc.dwHeight);
    NOTE1("Surface %x",SurfaceDesc.lpSurface);
    BYTE *pBuffer = (PBYTE) SurfaceDesc.lpSurface;

    // Initialise the sample with the DirectDraw information

    pVideoSample->SetDirectInfo(pSurface,           // The surface
                                m_pDirectDraw,      // DirectDraw
                                m_cbSurfaceSize,    // Buffer size
                                pBuffer);           // Data buffer
    return NOERROR;
}


// In Modex the triple and double buffered surfaces aren't real flip surfaces
// but are made to look that way, amy attempt to lock the front buffer or blt
// from front to back fails. When we are using the normal 640x480 mode but
// with double and triple buffered surfaces this isn't the case as they are
// real surfaces. This means that we may have to look after keeping the back
// buffer upto date with the contents as most decompressors need that image
// We always try to do the BltFast and just ignore any failure return codes

HRESULT CModexAllocator::PrepareBackBuffer(LPDIRECTDRAWSURFACE pSurface)
{
    VIDEOINFO *pSurfaceInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    RECT DestinationRect = pSurfaceInfo->rcTarget;
    NOTE("Entering PrepareBackBuffer");
    ASSERT(m_pDrawSurface == NULL);

    // Which surface is most upto date

    ASSERT(pSurface);
    if (m_bIsFrontStale == TRUE) {
        NOTE("Front is stale");
        return NOERROR;
    }

    // Are we even in a DirectDraw mode

    if (m_bModexSamples == FALSE) {
        NOTE("Not upto date");
        return NOERROR;
    }

    ASSERT(m_pFrontBuffer);
    ASSERT(m_pDirectDraw);
    NOTERC("Modex",DestinationRect);

    // If in system memory then only one buffer is created

    if (m_SurfaceCaps.dwCaps & DDSCAPS_SYSTEMMEMORY) {
        NOTE("Front buffer emulated");
        return NOERROR;
    }

    // Modex has emulated flipping surfaces

    if (m_SurfaceCaps.dwCaps & DDSCAPS_MODEX) {
        NOTE("Front buffer is Modex");
        return NOERROR;
    }

    // Update the back buffer with the current image

    HRESULT hr = pSurface->BltFast(DestinationRect.left,   // Target left
    				               DestinationRect.top,	   // And the left
                 	       	       m_pFrontBuffer,         // Image source
			       	               &DestinationRect,       // Source rectangle
			                       DDBLTFAST_WAIT);        // No completion

    NOTE1("Blt returned %lx",hr);
    return NOERROR;
}


// Zero fill the DirectDraw surface we are passed

HRESULT CModexAllocator::ResetBackBuffer(LPDIRECTDRAWSURFACE pSurface)
{
    NOTE("Entering ResetDirectDrawSurface");
    DDBLTFX ddbltfx;
    ddbltfx.dwSize = sizeof(DDBLTFX);
    ddbltfx.dwFillColor = 0;
    return pSurface->Blt(NULL,NULL,NULL,DDBLT_COLORFILL | DDBLT_WAIT,&ddbltfx);
}


// Create a single primary (not page flipped) for drawing with

HRESULT CModexAllocator::CreatePrimary()
{
    NOTE("Entering CreatePrimary");
    ASSERT(m_bTripleBuffered == FALSE);
    ASSERT(m_pDrawSurface == NULL);
    ASSERT(m_pFrontBuffer == NULL);
    ASSERT(m_pDirectDraw);
    DDSURFACEDESC SurfaceDesc;

    // Initialise the primary surface descriptor
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS;
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE;

    // Ask DirectDraw to create the surface

    HRESULT hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pFrontBuffer,NULL);
    if (FAILED(hr)) {
        NOTE1("No primary %lx",hr);
        return hr;
    }

    // Get the primary surface capabilities

    hr = m_pFrontBuffer->GetCaps(&m_SurfaceCaps);
    if (FAILED(hr)) {
        NOTE("No caps");
        return hr;
    }
    return NOERROR;
}


// Create an RGB offscreen surface that matches the current display mode. We
// will try and get it in video memory first assuming the display isn't bank
// switch (because stretching between banks is awful). Failing that we will
// try and get it in system memory (so we should always succeed in creation)
// We also need a front buffer (primary surface) to act as the blting target

HRESULT CModexAllocator::CreateOffScreen(BOOL bCreatePrimary)
{
    NOTE("Entering CreateOffScreen");
    ASSERT(m_pDirectDraw);
    ASSERT(m_pDrawSurface == NULL);
    DDSURFACEDESC SurfaceDesc;

    // Create a single primary surface

    if (bCreatePrimary == TRUE) {
        HRESULT hr = CreatePrimary();
        if (FAILED(hr)) {
            return hr;
        }
    }

    // We should have a primary surface by now

    ASSERT(m_pBackBuffer || m_bOffScreen);
    ASSERT(m_pFrontBuffer);
    ASSERT(m_pDrawSurface == NULL);
    ASSERT(m_pDirectDraw);

    // We need both the original type and the surface format

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    VIDEOINFO *pInputInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);

    // Set the surface description of the offscreen

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH;
    SurfaceDesc.dwHeight = pInputInfo->bmiHeader.biHeight;
    SurfaceDesc.dwWidth = pInputInfo->bmiHeader.biWidth;
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_VIDEOMEMORY;

    // Check the primary surface is not bank switched

    if (m_SurfaceCaps.dwCaps & DDCAPS_BANKSWITCHED) {
        NOTE("Primary surface is bank switched");
        SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN;
    }

    // Store the masks in the DDSURFACEDESC

    const DWORD *pBitMasks = m_pRenderer->m_Display.GetBitMasks(pVideoInfo);
    SurfaceDesc.ddpfPixelFormat.dwRGBBitCount = pHeader->biBitCount;
    SurfaceDesc.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
    SurfaceDesc.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
    SurfaceDesc.ddpfPixelFormat.dwBBitMask = pBitMasks[2];

    // It appears that DirectDraw ignores any true colours masks

    NOTE1("Bit count %d",SurfaceDesc.ddpfPixelFormat.dwRGBBitCount);
    NOTE1("Red mask %x",SurfaceDesc.ddpfPixelFormat.dwRBitMask);
    NOTE1("Green mask %x",SurfaceDesc.ddpfPixelFormat.dwGBitMask);
    NOTE1("Blue mask %x",SurfaceDesc.ddpfPixelFormat.dwBBitMask);
    NOTE1("Width %d",SurfaceDesc.dwWidth);
    NOTE1("Height %d",SurfaceDesc.dwHeight);
    NOTE1("Flags %d",SurfaceDesc.ddsCaps.dwCaps);

    // Create the offscreen drawing surface

    HRESULT hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pDrawSurface,NULL);
    if (FAILED(hr)) {
        SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN;
        hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pDrawSurface,NULL);
        if (FAILED(hr)) {
            NOTE1("No surface %lx",hr);
            return hr;
        }
    }

    NOTE("Created DirectDraw offscreen surface");
    NOTE1("Back buffer %x",m_pBackBuffer);
    NOTE1("Front buffer %x",m_pFrontBuffer);

    // Ask DirectDraw for a description of the surface

    m_SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    hr = m_pDrawSurface->GetSurfaceDesc(&m_SurfaceDesc);
    if (FAILED(hr)) {
        NOTE("No description");
        return hr;
    }

    UpdateSurfaceFormat();

    // Overwrite with the real surface capabilities

    hr = m_pDrawSurface->GetCaps(&m_SurfaceCaps);
    if (FAILED(hr)) {
        NOTE("No caps");
        return hr;
    }
    return UpdateDrawPalette(m_pMediaType);
}


// There are two problems with agreeing a format before creating the surfaces
// The first is that we don't know whether the surface will be RGB565 or 555
// when we specify a 16bit surface. The second problem is that we don't know
// the stride for the surface. For most surfaces it will normally be the new
// display width but it doesn't have to be. Therefore after actually changing
// modes and creating the surfaces we update the format we give to the source

HRESULT CModexAllocator::UpdateSurfaceFormat()
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    NOTE1("Updating format (stride %d)",m_SurfaceDesc.lPitch);

    // When we connect and decide upon using a true colour format we check
    // the source filter can provide both RGB565 and RGB555 varieties as
    // we don't know until we actually create the surface what they'll be
    // At this point we have created the surface so we must initialise the
    // output surface format with the bit fields and also the media subtype

    if (*m_SurfaceFormat.Subtype() == MEDIASUBTYPE_RGB565) {
        pVideoInfo->dwBitMasks[0] = m_SurfaceDesc.ddpfPixelFormat.dwRBitMask;
        pVideoInfo->dwBitMasks[1] = m_SurfaceDesc.ddpfPixelFormat.dwGBitMask;
        pVideoInfo->dwBitMasks[2] = m_SurfaceDesc.ddpfPixelFormat.dwBBitMask;
        const GUID SubType = GetBitmapSubtype(&pVideoInfo->bmiHeader);
        m_SurfaceFormat.SetSubtype(&SubType);
    }

    // Update the DirectDraw capabilities structures

    ASSERT(m_pDirectDraw);
    m_DirectCaps.dwSize = sizeof(DDCAPS);
    m_DirectSoftCaps.dwSize = sizeof(DDCAPS);

    // Load the hardware and emulation capabilities

    HRESULT hr = m_pDirectDraw->GetCaps(&m_DirectCaps,&m_DirectSoftCaps);
    if (FAILED(hr)) {
        return hr;
    }

    // Display the hardware and emulated alignment restrictions

    NOTE1("Target size alignment %d",m_DirectCaps.dwAlignSizeDest);
    NOTE1("Target boundary alignment %d",m_DirectCaps.dwAlignBoundaryDest);
    NOTE1("Source size alignment %d",m_DirectCaps.dwAlignSizeSrc);
    NOTE1("Source boundary alignment %d",m_DirectCaps.dwAlignBoundarySrc);
    NOTE1("Emulated Source size alignment %d",m_DirectSoftCaps.dwAlignSizeDest);
    NOTE1("Emulated boundary alignment %d",m_DirectSoftCaps.dwAlignBoundaryDest);
    NOTE1("Emulated Target size alignment %d",m_DirectSoftCaps.dwAlignSizeSrc);
    NOTE1("Emulated boundary alignment %d",m_DirectSoftCaps.dwAlignBoundarySrc);

    // If we're stretching force the alignment to no less than DWORDs
    //     this is done for pure performance on the basis that if
    //         we are stretching nobody is going to notice it

    if (m_DirectCaps.dwAlignBoundarySrc < 4) m_DirectCaps.dwAlignBoundarySrc = 4;
    if (m_DirectCaps.dwAlignSizeSrc < 4) m_DirectCaps.dwAlignSizeSrc = 4;
    if (m_DirectCaps.dwAlignBoundaryDest < 4) m_DirectCaps.dwAlignBoundaryDest = 4;
    if (m_DirectCaps.dwAlignSizeDest < 4) m_DirectCaps.dwAlignSizeDest = 4;

    // The stride may be different to our approximate calculation
    pHeader->biWidth = m_SurfaceDesc.lPitch / (pHeader->biBitCount / 8);
    SetSurfaceSize(pVideoInfo);
    NOTE1("Resulting surface size %d",pHeader->biSizeImage);

    // Make sure the source and target are aligned
    if (m_pDrawSurface) AlignRectangles(&m_ScaledSource,&m_ScaledTarget);

    // Will the source filter provide this format

    hr = QueryAcceptOnPeer(&m_SurfaceFormat);
    if (hr != NOERROR) {
        NOTE("Update failed");
        return hr;
    }
    return NOERROR;
}


// Called to allocate the DirectDraw surfaces. We only use primary flipping
// surfaces so we try to create them first in video memory. If we can't get
// any VRAM buffered surface we try again without specifying VRAM and we'll
// get back a system memory surface. That won't use hardware page flipping
// but at least we'll run. Because we run fullscreen exclusive we can limit
// ourselves to dealing with primary surfaces only and not other types. We
// have to recreate the flipping surfaces each time we change display mode
// as it may not be until then that the necessary video memory will be free

HRESULT CModexAllocator::CreateSurfaces()
{
    NOTE("Entering CreateSurfaces");
    ASSERT(m_pDirectDraw);
    HRESULT hr = NOERROR;
    m_bModexSamples = FALSE;

    // Did we agree to stretch an offscreen surface
    if (m_bOffScreen == TRUE)
        if (m_ModeWidth > AMSCAPS_MUST_FLIP)
            return CreateOffScreen(TRUE);

    // Start with triple buffered primary flipping surfaces

    ZeroMemory(&m_SurfaceDesc,sizeof(DDSURFACEDESC));
    m_SurfaceDesc.dwSize = sizeof(m_SurfaceDesc);
    m_SurfaceDesc.dwFlags = DDSD_CAPS | DDSD_BACKBUFFERCOUNT;
    m_SurfaceDesc.dwBackBufferCount = 2;

    m_SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE |
                                   DDSCAPS_FLIP |
                                   DDSCAPS_COMPLEX |
                                   DDSCAPS_VIDEOMEMORY;

    // Try to get a triple or double buffered surface in VRAM

    hr = m_pDirectDraw->CreateSurface(&m_SurfaceDesc,&m_pFrontBuffer,NULL);
    if (FAILED(hr)) {
        NOTE1("No triple VRAM buffered %lx",hr);
        m_SurfaceDesc.dwBackBufferCount = 1;
        hr = m_pDirectDraw->CreateSurface(&m_SurfaceDesc,&m_pFrontBuffer,NULL);
    }

    // Try double buffered surfaces in normal system memory

    if (FAILED(hr)) {
        NOTE1("No double VRAM buffered %lx",hr);
        m_SurfaceDesc.ddsCaps.dwCaps &= ~DDSCAPS_VIDEOMEMORY;
        hr = m_pDirectDraw->CreateSurface(&m_SurfaceDesc,&m_pFrontBuffer,NULL);
        if (FAILED(hr)) {
            NOTE1("No double system buffered %lx",hr);
            return hr;
        }
    }

    // Have we got triple buffered surfaces

    m_bTripleBuffered = FALSE;
    if (m_SurfaceDesc.dwBackBufferCount == 2) {
        m_bTripleBuffered = TRUE;
    }

    // Get a pointer to the back buffer

    NOTE1("Triple Buffered (%d)",m_bTripleBuffered);
    DDSCAPS SurfaceCaps;
    ZeroMemory(&SurfaceCaps,sizeof(DDSCAPS));
    SurfaceCaps.dwCaps = DDSCAPS_BACKBUFFER;

    hr = m_pFrontBuffer->GetAttachedSurface(&SurfaceCaps,&m_pBackBuffer);
    if (FAILED(hr)) {
        NOTE("No attached surface");
        return hr;
    }

    // Get the front buffer capabilities

    hr = m_pFrontBuffer->GetCaps(&m_SurfaceCaps);
    if (FAILED(hr)) {
        return hr;
    }

    // Did we agree to use an offscreen surface
    if (m_bOffScreen) return CreateOffScreen(FALSE);

    // Ask DirectDraw for a description of the surface

    m_SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    hr = m_pFrontBuffer->GetSurfaceDesc(&m_SurfaceDesc);
    if (FAILED(hr)) {
        ReleaseSurfaces();
        return hr;
    }

    UpdateSurfaceFormat();

    // If we are going to a low resolution display mode and we have got here
    // then we are going to decode direct to the back buffer and flip it. If
    // we cannot do that then we might be able to decode to an offscreen and
    // stretch that to the back buffer to subsequently flip. This is useful
    // for small videos where stretching upto larger display modes looks bad

    return UpdateDrawPalette(m_pMediaType);
}


// When we complete a connection we decide which surface to use depending on
// the source filter capabilities. We use 640x480x16 surfaces as they offer
// better quality than palettised formats, unforunately without creating the
// surface we have no way to know what kind of surface it is (RGB555/RGB565)
// So what we do is when we ask the source if it can supply a format we ask
// it first of all in RGB565 format and it it agrees then we also ask it in
// RGB555 format. This means that whatever the surface turns out to be when
// we actually allocate it during activation we know the source can supply it

HRESULT CModexAllocator::QuerySurfaceFormat(CMediaType *pmt)
{
    NOTE("Entering QuerySurfaceFormat");

    // Will the source filter provide this format

    HRESULT hr = QueryAcceptOnPeer(&m_SurfaceFormat);
    if (hr != NOERROR) {
        NOTE("Query failed");
        return hr;
    }

    // We only catch the RGB565 formats

    if (*pmt->Subtype() == MEDIASUBTYPE_RGB8) {
        NOTE("Format is RGB8");
        return NOERROR;
    }

    NOTE("Trying RGB555 format");
    CMediaType TrueColour(*pmt);

    // Change the bit fields to be RGB555 compatible

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) TrueColour.Format();
    TrueColour.SetSubtype(&MEDIASUBTYPE_RGB555);
    pVideoInfo->dwBitMasks[0] = bits555[0];
    pVideoInfo->dwBitMasks[1] = bits555[1];
    pVideoInfo->dwBitMasks[2] = bits555[2];

    return QueryAcceptOnPeer(&TrueColour);
}


// Make sure we keep the pixel aspect ratio when filling the display. We do
// this by scaling the vertical and horizontal dimensions of the video into
// the surface size. Whichever vertice needs scaling most becomes the scale
// factor - both axis are then adjusted accordingly. Depending on the video
// this can leave black stripes at the display top/bottom or the left/right
// We return the total number of pixels that will be displayed if accepted

LONG CModexAllocator::ScaleToSurface(VIDEOINFO *pInputInfo,
                                     RECT *pTargetRect,
                                     LONG SurfaceWidth,
                                     LONG SurfaceHeight)
{
    BITMAPINFOHEADER *pInputHeader = HEADER(pInputInfo);
    NOTE("Entering ScaleToSurface");
    LONG Width = pInputHeader->biWidth;
    LONG Height = pInputHeader->biHeight;
	double dPixelAspectRatio, dResolutionRatio;
	
	// The only assumption being made here is that the movie was authored for
	// a display aspect ratio of 4:3 (this a display of 4:3 can be assumed to have
	// square pixels).
	// Our aim is to find the new ResolutionRatio
	// since the ResultionRatio * PixelAspectRatio = PictureAspectRatio (a constant)
	// Thus 4/3 * 1 = newPixelAspectRatio * SurfaceWidth/SurfaceHeight
	// the variables dPixelAspectRatio and dResolutionRatio pertain to the current
	// display mode. Note the whole reason of doing this is modes like 640/400, where
	// the pixel-aspect-ratio becomes different from 4:3
	dPixelAspectRatio = (4.0/3.0)  / ( ((double)SurfaceWidth) / ((double)SurfaceHeight) );

	dResolutionRatio = ( ((double)Width) / ((double)Height) ) / (dPixelAspectRatio);

	// So now we just have to find two numbers, x and y such that
	// x <= SurfaceWidth && y <= SurfaceHeight &&  (x / y = dResolutionRatio) &&
	// (x == SurfaceHeight || y == SurfaceWidth)

    NOTE2("Screen size (%dx%d)",SurfaceWidth,SurfaceHeight);
    NOTE2("Video size (%dx%d)",Width,Height);
    NOTE1("Pixel aspect ratio scale (x1000) (%d)",LONG(dPixelAspectRatio*1000));

    // This calculates the ideal destination video position
    LONG ScaledWidth = min(SurfaceWidth,LONG((double(SurfaceHeight) * dResolutionRatio)));
    LONG ScaledHeight = min(SurfaceHeight,LONG((double(SurfaceWidth) / dResolutionRatio)));

    // Set the ideal scaled dimensions in the destination
    pTargetRect->left = (SurfaceWidth - ScaledWidth) / 2;
    pTargetRect->top = (SurfaceHeight - ScaledHeight) / 2;
    pTargetRect->right = pTargetRect->left + ScaledWidth;
    pTargetRect->bottom = pTargetRect->top + ScaledHeight;

    NOTE4("Scaled video (left %d top %d right %d bottom %d)",
            pTargetRect->left, pTargetRect->top,
              pTargetRect->right, pTargetRect->bottom);

    return (ScaledWidth * ScaledHeight);
}


// It's unlikely that the video source will match the new display dimensions
// we will be using exactly. Therefore we ask the source filter to size the
// video appropriately. If it cannot and if the source is smaller than the
// display we position it in the middle, if it's larger then we clip an equal
// amount off either end (ie the left and right and/or the top and bottom) so
// that the picture is still centred as best we can. If the source still does
// not accept the format then it cannot supply any type compatible with Modex

HRESULT CModexAllocator::AgreeDirectDrawFormat(LONG Mode)
{
    NOTE("Entering AgreeDirectDrawFormat");
    LONG Width, Height, Depth;
    LONG Stride = m_pModexVideo->GetStride(Mode);
    m_pModexVideo->GetModeInfo(Mode,&Width,&Height,&Depth);

    // We need the input and output VIDEOINFO descriptors

    VIDEOINFO *pInputInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    VIDEOINFO *pOutputInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    BITMAPINFOHEADER *pInputHeader = HEADER(pInputInfo);
    BITMAPINFOHEADER *pOutputHeader = HEADER(pOutputInfo);
    LONG Pixels = ScaleToSurface(pInputInfo,&m_ScaledTarget,Width,Height);

    // To start with we will use all the available video
    pOutputInfo->rcSource.left = pOutputInfo->rcSource.top = 0;
    pOutputInfo->rcSource.right = pInputHeader->biWidth;
    pOutputInfo->rcSource.bottom = pInputHeader->biHeight;
    pOutputInfo->rcTarget = m_ScaledTarget;

    // Will the source filter provide this format

    HRESULT hr = QuerySurfaceFormat(&m_SurfaceFormat);
    if (hr == NOERROR) {
        NOTE("Source can stretch");
        return NOERROR;
    }

    // The source and target rectangles are calculated differently depending
    // on whether the video width and height are smaller or larger than the
    // primary surface (remember we know the source filter can't stretch to
    // fit the surface exactly so we will clip the video). The formula for
    // working out the source and destination video rectangles is defined by
    // the following calculations. They also make sure the left coordinates
    // are always positioned on DWORD boundaries to maximise our performance

    if (pInputHeader->biWidth <= Width) {
        pOutputInfo->rcSource.right = pInputHeader->biWidth;
        pOutputInfo->rcSource.left = 0;
        LONG ExcessSurface = Width - pInputHeader->biWidth;
        pOutputInfo->rcTarget.left = (ExcessSurface / 2) & ~ 3;
        pOutputInfo->rcTarget.right = pOutputInfo->rcTarget.left;
        pOutputInfo->rcTarget.right += pInputHeader->biWidth;
    }

    // Is the video width smaller or larger than the surface

    if (pInputHeader->biWidth > Width) {
        pOutputInfo->rcTarget.right = Width;
        pOutputInfo->rcTarget.left = 0;
        LONG ExcessVideo = pInputHeader->biWidth - Width;
        pOutputInfo->rcSource.left = (ExcessVideo / 2) & ~3;
        pOutputInfo->rcSource.right = pOutputInfo->rcSource.left;
        pOutputInfo->rcSource.right += Width;
    }

    // Is the video height smaller or larger than the surface. BEWARE because
    // all DirectDraw surfaces are top down (not bottom up like DIBs) we keep
    // the output height as a negative value. Therefore whenever we use it in
    // these calculations we must make sure we use an absolute positive value

    if (pInputHeader->biHeight <= (-pOutputHeader->biHeight)) {
        pOutputInfo->rcSource.top = 0;
        pOutputInfo->rcSource.bottom = pInputHeader->biHeight;
        LONG ExcessSurface = (-pOutputHeader->biHeight) - pInputHeader->biHeight;
        pOutputInfo->rcTarget.top = ExcessSurface / 2;
        pOutputInfo->rcTarget.bottom = pOutputInfo->rcTarget.top;
        pOutputInfo->rcTarget.bottom += pInputHeader->biHeight;
    }

    // Is the video width smaller or larger than the surface

    if (pInputHeader->biHeight > (-pOutputHeader->biHeight)) {
        pOutputInfo->rcTarget.top = 0;
        pOutputInfo->rcTarget.bottom = (-pOutputHeader->biHeight);
        LONG ExcessVideo = pInputHeader->biHeight - (-pOutputHeader->biHeight);
        pOutputInfo->rcSource.top = ExcessVideo / 2;
        pOutputInfo->rcSource.bottom = pOutputInfo->rcSource.top;
        pOutputInfo->rcSource.bottom += (-pOutputHeader->biHeight);
    }

    // Check we are not losing more than the allowed clip loss

    LONG InputSize = pInputHeader->biWidth * pInputHeader->biHeight;
    LONG OutputSize = WIDTH(&pOutputInfo->rcSource) * HEIGHT(&pOutputInfo->rcSource);
    LONG ClippedVideo = 100 - (OutputSize * 100 / InputSize);
    LONG ClipLoss = m_pModexVideo->GetClipLoss();
    LONG TargetSize = WIDTH(&pOutputInfo->rcTarget) * HEIGHT(&pOutputInfo->rcTarget);
    LONG LostTarget = 100 - ((TargetSize * 100) / Pixels);

    NOTE("Checking display mode for allowed clipping");
    NOTE1("Original input image size %d",InputSize);
    NOTE1("Clipped output source size %d",OutputSize);
    NOTE1("Current clip loss factor %d",ClipLoss);
    NOTE1("Percentage of video lost to clipping %d",ClippedVideo);
    NOTE1("Total pixels displayed if stretched %d",Pixels);
    NOTE1("Pixels used from clipped destination %d",TargetSize);
    NOTE1("Difference from stretched video %d",LostTarget);

    // Inspect the percentage of total image we are losing

    if ( (ClippedVideo <= ClipLoss) &&
         (LostTarget <= ClipLoss)) {
        hr = QuerySurfaceFormat(&m_SurfaceFormat);
        if (hr == NOERROR) {
            NOTE("Source can clip");
            return NOERROR;
        }
    }
	else {
		return VFW_E_NO_ACCEPTABLE_TYPES;
	}

    // Update the surface format with an approximate stride


    LONG ScreenWidth = GetSystemMetrics( SM_CXSCREEN );
    pOutputHeader->biWidth = ScreenWidth;
    pOutputHeader->biHeight = -pInputHeader->biHeight;
    SetSurfaceSize(pOutputInfo);

	// ok the source cannot clip, so lets clip using ddraw
	// This sets up the scaled source and destination
	m_ScaledSource = pOutputInfo->rcSource;
	m_ScaledTarget = pOutputInfo->rcTarget;

    // Initialise the source and destination rectangles

    pOutputInfo->rcSource.left = 0; pOutputInfo->rcSource.top = 0;
    pOutputInfo->rcSource.right = pInputHeader->biWidth;
    pOutputInfo->rcSource.bottom = pInputHeader->biHeight;
    pOutputInfo->rcTarget.left = 0; pOutputInfo->rcTarget.top = 0;
    pOutputInfo->rcTarget.right = pInputHeader->biWidth;
    pOutputInfo->rcTarget.bottom = pInputHeader->biHeight;



    // Will the source filter provide this format

    hr = QuerySurfaceFormat(&m_SurfaceFormat);
    if (hr == NOERROR) {
        NOTE("Offscreen ok");
        return VFW_S_RESERVED;
    }
    return VFW_E_NO_ACCEPTABLE_TYPES;
}


// Check this media type is acceptable to our input pin. All we do is to call
// QueryAccept on the source's output pin. To get this far we have locked the
// object so there should be no way for our pin to have become disconnected

HRESULT CModexAllocator::QueryAcceptOnPeer(CMediaType *pMediaType)
{
    NOTE("Entering QueryAcceptOnPeer");

    DisplayType(TEXT("Proposing output type"),pMediaType);
    IPin *pPin = m_pRenderer->m_ModexInputPin.GetPeerPin();
    ASSERT(m_pRenderer->m_ModexInputPin.IsConnected() == TRUE);
    return pPin->QueryAccept(pMediaType);
}


// If this is a normal uncompressed DIB format then set the size of the image
// as usual with the DIBSIZE macro. Otherwise the DIB specification says that
// the width of the image will be set in the width as a count of bytes so we
// just multiply that by the absolute height to get the total number of bytes
// This trickery is all handled by a utility function in the SDK base classes

void CModexAllocator::SetSurfaceSize(VIDEOINFO *pVideoInfo)
{
    NOTE("Entering SetSurfaceSize");

    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    pVideoInfo->bmiHeader.biSizeImage = GetBitmapSize(pHeader);
    m_cbSurfaceSize = pVideoInfo->bmiHeader.biSizeImage;

    NOTE("Setting surface size based on video");
    NOTE1("  Width %d",pHeader->biWidth);
    NOTE1("  Height %d",pHeader->biHeight);
    NOTE1("  Depth %d",pHeader->biBitCount);
    NOTE1("  Size %d",pHeader->biSizeImage);
}


// Initialise our output type based on the DirectDraw surface. As DirectDraw
// only deals with top down display devices so we must convert the height of
// the surface into a negative height. This is because DIBs use a positive
// height to indicate a bottom up image. We must also initialise the other
// VIDEOINFO fields to represent a normal video format. Because we know the
// surface formats we will be using we can call this with the target sizes
// to initialise an output format, that can then be used to check the source
// filter will provide the format before we change display modes. This helps
// to prevent doing a lot of unnecessary display changes as we reject modes

HRESULT CModexAllocator::InitDirectDrawFormat(int Mode)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    NOTE("Entering InitDirectDrawFormat");
    LONG Width, Height, Depth;
    BOOL b565;
    LONG Stride = m_pModexVideo->GetStride(Mode);

    m_pModexVideo->GetModeInfoThatWorks(Mode,&Width,&Height,&Depth,&b565);

    pVideoInfo->bmiHeader.biSize          = sizeof(BITMAPINFOHEADER);
    pVideoInfo->bmiHeader.biWidth         = Stride / (Depth / 8);
    pVideoInfo->bmiHeader.biHeight        = -Height;
    pVideoInfo->bmiHeader.biPlanes        = 1;
    pVideoInfo->bmiHeader.biBitCount      = (WORD) Depth;
    pVideoInfo->bmiHeader.biCompression   = BI_RGB;
    pVideoInfo->bmiHeader.biXPelsPerMeter = 0;
    pVideoInfo->bmiHeader.biYPelsPerMeter = 0;
    pVideoInfo->bmiHeader.biClrUsed       = 0;
    pVideoInfo->bmiHeader.biClrImportant  = 0;

    SetSurfaceSize(pVideoInfo);

    // Complete the VIDEOINFO structure

    SetRectEmpty(&pVideoInfo->rcSource);
    SetRectEmpty(&pVideoInfo->rcTarget);
    pVideoInfo->dwBitRate = 0;
    pVideoInfo->dwBitErrorRate = 0;
    pVideoInfo->AvgTimePerFrame = 0;

    // must set up destination rectangle if stride != width
    if (pVideoInfo->bmiHeader.biWidth != Width) {
	pVideoInfo->rcTarget.right = Width;
	pVideoInfo->rcTarget.bottom = Height;
    }

    // And finish it off with the other media type fields

    m_SurfaceFormat.SetSampleSize(pVideoInfo->bmiHeader.biSizeImage);
    m_SurfaceFormat.SetType(&MEDIATYPE_Video);
    m_SurfaceFormat.SetSubtype(&MEDIASUBTYPE_RGB8);
    m_SurfaceFormat.SetFormatType(&FORMAT_VideoInfo);
    m_SurfaceFormat.SetTemporalCompression(FALSE);

    // For true colour 565 format tell the source there are bit fields

    if (pVideoInfo->bmiHeader.biBitCount == 16) {
	if (b565 == TRUE) {
            m_SurfaceFormat.SetSubtype(&MEDIASUBTYPE_RGB565);
            pVideoInfo->bmiHeader.biCompression = BI_BITFIELDS;
            pVideoInfo->dwBitMasks[0] = bits565[0];
            pVideoInfo->dwBitMasks[1] = bits565[1];
            pVideoInfo->dwBitMasks[2] = bits565[2];
	} else {
            m_SurfaceFormat.SetSubtype(&MEDIASUBTYPE_RGB555);
	}
    }

    // Is this a palettised format

    if (PALETTISED(pVideoInfo) == FALSE) {
        return NOERROR;
    }

    // Copy the palette entries into the surface format

    VIDEOINFO *pInput = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    ASSERT(pInput->bmiHeader.biClrUsed);
    LONG Bytes = pInput->bmiHeader.biClrUsed * sizeof(RGBQUAD);
    CopyMemory(pVideoInfo->bmiColors,pInput->bmiColors,Bytes);
    pVideoInfo->bmiHeader.biClrUsed = pInput->bmiHeader.biClrUsed;

    return NOERROR;
}


// Overlay the image time stamps on the picture. Access to this method is
// serialised by the caller (who should also lock the object). We display
// the sample start and end times on the video using TextOut on an HDC we
// get from the DirectDraw surface (which must be released before ending)
// We put the times in the middle of the picture so that each successive
// image that is decompressed will overwrite the previous time otherwise
// we can be displaying the times on top of each other in the clipped area

HRESULT CModexAllocator::DisplaySampleTimes(IMediaSample *pSample)
{
    NOTE("Entering DisplaySampleTimes");

    TCHAR szTimes[TIMELENGTH];      // Format the time stamps
    CRefTime StartSample;           // Start time for sample
    CRefTime EndSample;             // And likewise it's end
    HDC hdcSurface;                 // Used for drawing
    SIZE Size;                      // Size of text output

    // Get a device context for the drawing surface
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();

    // This allows us to draw on top of the video
    if (pSurface->GetDC(&hdcSurface) != DD_OK) {
        return E_FAIL;
    }

    // Format the sample time stamps

    pSample->GetTime((REFERENCE_TIME *) &StartSample,
                     (REFERENCE_TIME *) &EndSample);

    wsprintf(szTimes,TEXT("%08d : %08d"),
             StartSample.Millisecs(),
             EndSample.Millisecs());

    ASSERT(lstrlen(szTimes) < TIMELENGTH);
    SetBkMode(hdcSurface,TRANSPARENT);
    SetTextColor(hdcSurface,RGB(255,255,255));

    // Put the times in the middle of the video picture

    GetTextExtentPoint32(hdcSurface,szTimes,lstrlen(szTimes),&Size);
    INT xPos = (m_SurfaceDesc.dwWidth - Size.cx) / 2;
    INT yPos = (m_SurfaceDesc.dwHeight - Size.cy) / 2;
    TextOut(hdcSurface,xPos,yPos,szTimes,lstrlen(szTimes));
    return pSurface->ReleaseDC(hdcSurface);
}


// When using a hardware offscreen draw surface we will normally wait for the
// monitor scan line to move past the destination rectangle before drawing so
// that we avoid tearing where possible. Of course not all display cards can
// support this feature and even those that do will see a performance drop of
// about 10% because we sit polling (oh for a generic PCI monitor interrupt)

void CModexAllocator::WaitForScanLine()
{
    ASSERT(m_pFrontBuffer);
    ASSERT(m_pDrawSurface);
    HRESULT hr = NOERROR;
    DWORD dwScanLine;

    // Some display cards like the ATI Mach64 support reporting of the scan
    // line they are processing. However not all drivers are setting the
    // DDCAPS_READSCANLINE capability flag so we just go ahead and ask for
    // it anyway. We allow for 10 scan lines above the top of our rectangle
    // so that we have a little time to thunk down and set the draw call up

    #define SCANLINEFUDGE 10
    while (TRUE) {

    	hr = m_pDirectDraw->GetScanLine(&dwScanLine);
        if (FAILED(hr)) {
            NOTE("No scan line");
            break;
        }

        NOTE1("Scan line returned %lx",dwScanLine);

    	if ((LONG) dwScanLine + SCANLINEFUDGE >= 0) {
            if ((LONG) dwScanLine <= m_ModeHeight) {
                NOTE("Scan inside");
                continue;
            }
        }
        break;
    }
}


// Lots more similar code to the normal video renderer, this time we are used
// when drawing offscreen surfaces. In which case we must make sure the pixel
// aspect ratio is maintained. To do this we stretch the video horizontally
// and vertically as appropriate. This might leave the target rectangle badly
// aligned so we shrink the source and target rectangles in to match alignment

BOOL CModexAllocator::AlignRectangles(RECT *pSource,RECT *pTarget)
{
    NOTE("Entering AlignRectangles");

    DWORD SourceLost = 0;           // Pixels to shift source left by
    DWORD TargetLost = 0;           // Likewise for the destination
    DWORD SourceWidthLost = 0;      // Chop pixels off the width
    DWORD TargetWidthLost = 0;      // And also for the destination

    BOOL bMatch = (WIDTH(pSource) == WIDTH(pTarget) ? TRUE : FALSE);

    // Shift the source rectangle to align it appropriately

    if (m_DirectCaps.dwAlignBoundarySrc) {
        SourceLost = pSource->left % m_DirectCaps.dwAlignBoundarySrc;
        if (SourceLost) {
            SourceLost = m_DirectCaps.dwAlignBoundarySrc - SourceLost;
            if ((DWORD)WIDTH(pSource) > SourceLost) {
                NOTE1("Source left %d",SourceLost);
                pSource->left += SourceLost;
            }
        }
    }

    // Shift the destination rectangle to align it appropriately

    if (m_DirectCaps.dwAlignBoundaryDest) {
        TargetLost = pTarget->left % m_DirectCaps.dwAlignBoundaryDest;
        if (TargetLost) {
            TargetLost = m_DirectCaps.dwAlignBoundaryDest - TargetLost;
            if ((DWORD)WIDTH(pTarget) > TargetLost) {
                NOTE1("Target left %d",TargetLost);
                pTarget->left += TargetLost;
            }
        }
    }

    // We may have to shrink the source rectangle size to align it

    if (m_DirectCaps.dwAlignSizeSrc) {
        SourceWidthLost = WIDTH(pSource) % m_DirectCaps.dwAlignSizeSrc;
        if (SourceWidthLost) {
            if ((DWORD)WIDTH(pSource) > SourceWidthLost) {
                pSource->right -= SourceWidthLost;
                NOTE1("Source width %d",SourceWidthLost);
            }
        }
    }

    // We may have to shrink the target rectangle size to align it

    if (m_DirectCaps.dwAlignSizeDest) {
        TargetWidthLost = WIDTH(pTarget) % m_DirectCaps.dwAlignSizeDest;
        if (TargetWidthLost) {
            if ((DWORD)WIDTH(pTarget) > TargetWidthLost) {
                pTarget->right -= TargetWidthLost;
                NOTE1("Target width %d",TargetWidthLost);
            }
        }
    }

    // If the source and destination originally differed then we're done

    if (bMatch == FALSE) {
        NOTE("No match");
        return TRUE;
    }

    // If the source and destination were originally the same size and they
    // now differ then we try to make them match. If the source is larger
    // than the destination then we shrink it down but only if the source
    // rectangle width we end up with is still aligned correctly otherwise
    // we won't have got anywhere (we do the same in the opposite case)

    LONG Difference = WIDTH(pSource) - WIDTH(pTarget);
    if (Difference == 0) {
        NOTE("No difference");
        return TRUE;
    }

    // Is the destination bigger than the source or vica versa

    if (Difference < 0) {
        RECT AdjustTarget = *pTarget;
        AdjustTarget.right += Difference; // NOTE Difference < 0
        if (WIDTH(&AdjustTarget) > 0) {
            if ((m_DirectCaps.dwAlignSizeDest == 0) ||
                (WIDTH(&AdjustTarget) % m_DirectCaps.dwAlignSizeDest) == 0) {
                    pTarget->right = AdjustTarget.right;
                    TargetWidthLost -= Difference; // NOTE Difference < 0
            }
        }
    } else {
        RECT AdjustSource = *pSource;
        AdjustSource.right -= Difference; // NOTE Difference > 0
        if (WIDTH(&AdjustSource) > 0) {
            if ((m_DirectCaps.dwAlignSizeDest == 0) ||
                (WIDTH(&AdjustSource) % m_DirectCaps.dwAlignSizeDest) == 0) {
                    pSource->right = AdjustSource.right;
                    SourceWidthLost += Difference; // NOTE Difference > 0
            }
        }
    }

    NOTE1("Alignment difference %d",Difference);
    NOTE1("  Source left %d",SourceLost);
    NOTE1("  Source width %d",SourceWidthLost);
    NOTE1("  Target left %d",TargetLost);
    NOTE1("  Target width %d",TargetWidthLost);

    return TRUE;
}


// Ask DirectDraw to blt the surface to the screen. We will try and wait for
// the scan line to move out of the way as in fullscreen mode we have a very
// good chance of tearing otherwise. We start off by using all of the source
// and destination but shrink the right hand side down so that it is aligned
// according to the hardware restrictions (so that the blt won't ever fail)

HRESULT CModexAllocator::DrawSurface(LPDIRECTDRAWSURFACE pBuffer)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    LPDIRECTDRAWSURFACE pSurface = (pBuffer ? pBuffer : m_pFrontBuffer);
    NOTE1("Entering DrawSurface (Back buffer %x)",pBuffer);

    ASSERT(m_pDirectDraw);
    ASSERT(m_pFrontBuffer);
    ASSERT(m_pDrawSurface);
    WaitForScanLine();

    // Draw the offscreen surface and wait for it to complete

    HRESULT hr = pSurface->Blt(&m_ScaledTarget,  // Target rectangle
                               m_pDrawSurface,   // Source surface
                               &m_ScaledSource,  // Source rectangle
                               DDBLT_WAIT,       // Wait to complete
                               NULL);            // No effects flags

    NOTE1("Blt returned %lx",hr);
    NOTERC("Source",m_ScaledSource);
    NOTERC("Target",m_ScaledTarget);

    return (pBuffer ? S_OK : VFW_S_NO_MORE_ITEMS);
}


// Called to actually draw the sample. We use the hardware blter to prepare
// the back buffer with the upto date contents when it is locked so now we
// flip it to the primary display. When we issue the flip we do not require
// it to complete so we don't wait for it (we don't send a DDFLIP_WAIT flag)
// We don't restore surfaces in here as that tends to activate the window if
// it's minimised, so we leave the restore for when we get a WM_ACTIVATEAPP
// although we still do the flip so that hopefully the buffers are arranged

HRESULT CModexAllocator::DoRenderSample(IMediaSample *pMediaSample)
{
    NOTE("Entering DoRenderSample");
    CAutoLock cVideoLock(this);
    CVideoSample *pVideoSample;

    // Have we already flipped this surface

    pVideoSample = (CVideoSample *) pMediaSample;
    if (pVideoSample->GetDrawStatus() == FALSE) {
        NOTE("Flipped");
        return TRUE;
    }

    pVideoSample->SetDrawStatus(FALSE);

    // Have we switched to normal DIBSECTION samples

    if (m_bModexSamples == FALSE) {
        NOTE("Not Modex sample");
        return NOERROR;
    }

    // has the window been minimised

    HWND hwnd = m_pModexWindow->GetWindowHWND();
    if (IsIconic(hwnd) || m_bModeChanged == FALSE) {
        NOTE("Mode not changed");
        m_bIsFrontStale = TRUE;
        return NOERROR;
    }

    #ifdef DEBUG
    DisplaySampleTimes(pMediaSample);
    #endif

    // Are we stretching an offscreen surface

    if (m_bOffScreen == TRUE) {
        HRESULT hr = DrawSurface(m_pBackBuffer);
        if (hr == VFW_S_NO_MORE_ITEMS) {
            return NOERROR;
        }
    }

    ASSERT(m_pDirectDraw);
    ASSERT(m_pFrontBuffer);
    ASSERT(m_pBackBuffer);

    // Flip the back buffer to the visible primary

    HRESULT hr = DDERR_WASSTILLDRAWING;
    while (hr == DDERR_WASSTILLDRAWING) {
        hr = m_pFrontBuffer->Flip(NULL,(DWORD) 0);
        if (hr == DDERR_WASSTILLDRAWING) {
            if (m_bTripleBuffered == FALSE) break;
            Sleep(DDGFS_FLIP_TIMEOUT);
        }
    }
    return NOERROR;
}


// Release any DirectDraw flipping primary surfaces we are currently holding
// we may be called at any time especially when something goes badly wrong
// and we need to clean up before returning, so we can't guarantee that
// our state is consistent so free only those that we have really allocated
// NOTE DirectDraw has a feature with flipping surfaces, GetAttachedSurface
// returns a DirectDraw surface interface that isn't AddRef'd, hence when we
// destroy all the surfaces we reset the interface instead of releasing it

void CModexAllocator::ReleaseSurfaces()
{
    NOTE("Entering ReleaseSurfaces");
    CAutoLock cVideoLock(this);
    m_pBackBuffer = NULL;
    m_bIsFrontStale = TRUE;
    m_bTripleBuffered = FALSE;

    // Release the DirectDraw flipping surfaces

    if (m_pFrontBuffer) {
        m_pFrontBuffer->Release();
        m_pFrontBuffer = NULL;
    }

    // Release any single backbuffer surface

    if (m_pDrawSurface) {
        m_pDrawSurface->Release();
        m_pDrawSurface = NULL;
    }

    // Free any palette object we made

    if (m_pDrawPalette) {
        m_pDrawPalette->Release();
        m_pDrawPalette = NULL;
    }
}


// Called to release any DirectDraw instance we have

void CModexAllocator::ReleaseDirectDraw()
{
    NOTE("Entering ReleaseDirectDraw");
    CAutoLock cVideoLock(this);
    ReleaseSurfaces();

    // Release any DirectDraw provider interface

    if (m_pDirectDraw) {
        m_pDirectDraw->Release();
        m_pDirectDraw = NULL;
    }
    m_LoadDirectDraw.ReleaseDirectDraw();
}


// The fullscreen renderer relies on some bug fixes in DirectDraw 2.0 so we
// will only allow connections if we detect that library. In DirectDraw 2.0
// we may also have multiple objects per process so we can load DirectDraw
// as we're created and unload when destroyed. This also lets us know which
// display modes the DirectDraw can support and which it can't - we should
// always be able to get hold of 320x240x8 and 640x480x8 regardless of card

HRESULT CModexAllocator::LoadDirectDraw()
{
    NOTE("Entering LoadDirectDraw");
    ASSERT(m_pDirectDraw == NULL);
    ASSERT(m_pFrontBuffer == NULL);
    HRESULT hr = NOERROR;

    // We rely on some DirectDraw 2 features

    if (m_fDirectDrawVersion1) {
        NOTE("Version incorrect");
        return E_UNEXPECTED;
    }

    // Ask the loader to create an instance

    // !!! BROKEN on multiple monitors
    hr = m_LoadDirectDraw.LoadDirectDraw(NULL);
    if (FAILED(hr)) {
        NOTE("No DirectDraw");
        return hr;
    }

    // Get the IDirectDraw instance

    m_pDirectDraw = m_LoadDirectDraw.GetDirectDraw();
    if (m_pDirectDraw == NULL) {
        NOTE("No instance");
        return E_FAIL;
    }

    // Initialise our capabilities structures
    m_DirectCaps.dwSize = sizeof(DDCAPS);
    m_DirectSoftCaps.dwSize = sizeof(DDCAPS);

    // Load the hardware and emulation capabilities

    hr = m_pDirectDraw->GetCaps(&m_DirectCaps,&m_DirectSoftCaps);
    if (FAILED(hr)) {
        ReleaseDirectDraw();
        return hr;
    }

    // Load the available display modes

    hr = m_pModexVideo->SetDirectDraw(m_pDirectDraw);
    if (FAILED(hr)) {
        ReleaseDirectDraw();
        return VFW_E_NO_MODEX_AVAILABLE;
    }
    return NOERROR;
}


// When we decode to use a true colour mode we need to know whether or not we
// will get the buffers in display memory or not. To know that without doing
// the actual surface allocation we guess using the available display memory
// The total video memory available from DirectDraw does not include the mode
// we are currently in so when we change mode we will hopefully release some
// more memory, so going from 1024x768x8 to 640x480x16 gives us 172,032 bytes

BOOL CModexAllocator::CheckTotalMemory(int Mode)
{
    NOTE1("Checking memory (mode %d)",Mode);
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    LONG Width, Height, Depth;

    // Find the display mode dimensions

    m_pDirectDraw->GetDisplayMode(&SurfaceDesc);
    m_pModexVideo->GetModeInfo(Mode,&Width,&Height,&Depth);
    DWORD RequiredMemory = Width * Height * Depth / 8;

    // Calculate the total theoretical display memory

    DWORD TotalMemory = (SurfaceDesc.ddpfPixelFormat.dwRGBBitCount / 8) *
                            SurfaceDesc.dwWidth * SurfaceDesc.dwHeight +
                                m_DirectCaps.dwVidMemTotal;

    return (RequiredMemory > TotalMemory ? FALSE : TRUE);
}


// Initialises the display dimensions to be those of the mode we'll use. We
// use eight bit palettised and sixteen bit true colour depending what the
// source filter and display capabilities are. We would prefer to use 16 bit
// surfaces as they offer better quality but there may be insufficient VRAM
// We try to check the condition of whether when we change mode we'll be able
// to get the surfaces in VRAM or not. If there looks to be too little VRAM
// available then we use the palettised mode. We always try to use the Modex
// low resolution modes (which can be either 8/16 bits) ahead of the others

HRESULT CModexAllocator::InitTargetMode(int Mode)
{
    NOTE("Entering InitTargetMode");
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    HRESULT hr = NOERROR;

    // Check this surface is available and enabled

    if (m_pModexVideo->IsModeAvailable(Mode) == S_FALSE ||
            m_pModexVideo->IsModeEnabled(Mode) == S_FALSE ||
                CheckTotalMemory(Mode) == FALSE) {
                    NOTE("Not acceptable");
                    return E_INVALIDARG;
                }

    // Next create a format for this surface

    hr = InitDirectDrawFormat(Mode);
    if (FAILED(hr)) {
        return hr;
    }

    // We have initialised a media type that represents the display mode to
    // use. We must now setup the source and target video rectangles, we do
    // this separately because in any given mode we have a choice of whether
    // to stretch (or compress) the video into the display dimensions or to
    // clip (or blank out) the border depending on the relative video size

    hr = AgreeDirectDrawFormat(Mode);
    if (FAILED(hr)) {
        return hr;
    }

    // Are we going to stretch offscreen
    m_bOffScreen = FALSE;
    if (hr == VFW_S_RESERVED)
        m_bOffScreen = TRUE;

    m_pModexVideo->GetModeInfo(Mode,&m_ModeWidth,&m_ModeHeight,&m_ModeDepth);

    NOTE("Agreed display mode...");
    NOTE1("Width %d",m_ModeWidth);
    NOTE1("Height %d",m_ModeHeight);
    NOTE1("Depth %d",m_ModeDepth);

    m_pModexVideo->SetMode(Mode);
    return NOERROR;
}


// We initialise an output format for the display modes we provide and check
// the source filter can supply a type of video that can be drawn with. If
// the source filter is not DirectDraw enabled or doesn't have the necessary
// capabilities then we do not complete the connection. This means that an
// application knows during connection whether it can connect a filter to a
// Modex renderer or if a colour space convertor needs to be put in between

HRESULT CModexAllocator::NegotiateSurfaceFormat()
{
    NOTE("Entering NegotiateSurfaceFormat");
    CAutoLock cVideoLock(this);
    ASSERT(m_bModeChanged == FALSE);
    long DisplayModes;

    // Did we manage to load DirectDraw

    if (m_pDirectDraw == NULL) {
        NOTE("No instance");
        return E_FAIL;
    }

    // Initialise the fullscreen object

    m_pModexVideo->SetDirectDraw(m_pDirectDraw);
    m_pModexVideo->CountModes(&DisplayModes);
    ASSERT(!m_fDirectDrawVersion1);

	// Compute the order in which the modes are to be tried
    m_pModexVideo->OrderModes();

	// if no valid modes, then return failure
	if (m_pModexVideo->m_dwNumValidModes == 0)
		return E_FAIL;

    // See if we can find a surface to use

    for (DWORD Loop = 0;Loop < m_pModexVideo->m_dwNumValidModes; Loop++) {
		DWORD dwMode = m_pModexVideo->m_ModesOrder[Loop];
        HRESULT hr = InitTargetMode(dwMode);
        if (hr == NOERROR) {
            return NOERROR;
        }
    }
    return E_FAIL;
}




// this function is used to call SetFocusWindow(hwnd) on every filter supporting
// IAMDirectSound in the graph. The reason is if in the same process, if
// SetCooperativeLevel is level on DiurectSound and DirectDraw(requesting exclusive
// mode) then the two hwnds have to be the same.
void CModexAllocator::DistributeSetFocusWindow(HWND hwnd)
{
	// We want to get a pointer to IFilterGraph, so get the Filter_Info structure
	FILTER_INFO Filter_Info;
	IFilterGraph *pFilterGraph = NULL;
	IEnumFilters *pEnumFilters = NULL;
	IAMDirectSound *pAMDS = NULL;
	IBaseFilter *pFilter = NULL;
	ULONG lFilters_Fetched = 0;
	HRESULT hr = NOERROR;

	// get the FilterInfo structure from the renderer
	hr = m_pFilter->QueryFilterInfo(&Filter_Info);
	if (FAILED(hr))
	{
		DbgLog((LOG_ERROR,0,TEXT("m_pFilter->QueryFilterInfo failed")));
		goto CleanUp;
	}

	// ge the pointer to IFilterGraph
	pFilterGraph = Filter_Info.pGraph;
	ASSERT(pFilterGraph);

	// get the pointer to IEnumFilters
	hr = pFilterGraph->EnumFilters(&pEnumFilters);
    if(FAILED(hr))
    {
		DbgLog((LOG_TRACE, 0, TEXT("QueryInterface  for IID_IEnumFilters failed.")));
		goto CleanUp;
    }

	pEnumFilters->Reset();
	do
	{	
		lFilters_Fetched = 0;
		hr = pEnumFilters->Next(1, &pFilter, &lFilters_Fetched);
	
		if (FAILED(hr) || (lFilters_Fetched != 1))
			break;

		ASSERT(pFilter);

		// call SetFocusWindow on every filter supporting IAMDirectSound
		hr = pFilter->QueryInterface(IID_IAMDirectSound, (void**)&pAMDS);
		if(SUCCEEDED(hr) && pAMDS)
		{
			pAMDS->SetFocusWindow(hwnd, TRUE);
		}

		if (pAMDS)
		{
			pAMDS->Release();
			pAMDS = NULL;
		}

		if (pFilter)
		{
			pFilter->Release();
			pFilter = NULL;
		}
	}
	while (1);

CleanUp:
	if (pFilter)
	{
		pFilter->Release();
		pFilter = NULL;
	}

	if (pEnumFilters)
	{
		pEnumFilters->Release();
		pEnumFilters = NULL;
	}

	if (pFilterGraph)
	{
		pFilterGraph->Release();
		pFilterGraph = NULL;
	}

}

// Used to create the surfaces from DirectDraw. We only use primary flipping
// surfaces (triple/double in video RAM and also system memory). We also set
// the display mode according to the display variables we initialised during
// the CompleteConnect call. We don't need to initialise an output format as
// we also did that when we worked out which display mode to use, since the
// mode we use is also dependant on the formats the source filter can supply

HRESULT CModexAllocator::Active()
{
    // Show the window before locking up

    NOTE("Activating allocator");
    HWND hwnd = m_pModexWindow->GetWindowHWND();

    // Match the display size to the window

    MoveWindow(hwnd,(int) 0,(int) 0,
               GetSystemMetrics(SM_CXSCREEN),
               GetSystemMetrics(SM_CYSCREEN),
               (BOOL) FALSE);
    ShowWindow(hwnd,SW_SHOWNORMAL);
    SetForegroundWindow(hwnd);
    UpdateWindow(hwnd);
    CAutoLock cVideoLock(this);

    // Make us the fullscreen exclusive application

    HRESULT hr = m_pDirectDraw->SetCooperativeLevel(hwnd,DDSCL_EXCLUSIVE |
                                                         DDSCL_FULLSCREEN |
                                                         DDSCL_ALLOWREBOOT |
                                                         DDSCL_ALLOWMODEX);
    NOTE2("SetCooperativeLevel EXCLUSIVE %x returned %lx", hwnd, hr);
#if 0
    if (hr == DDERR_HWNDALREADYSET)
        hr = S_OK;
    NOTE2("SetCooperativeLevel %x returned %lx", hwnd, hr);
#endif
    if (FAILED(hr)) {
        return hr;
    }

    // Enumerate the modes again
    NegotiateSurfaceFormat();

    // Change the display mode as we just agreed

    hr = m_pDirectDraw->SetDisplayMode(m_ModeWidth,m_ModeHeight,m_ModeDepth);
    NOTE1("SetDisplayMode returned %lx", hr);
    if (FAILED(hr)) {
        return hr;
    }

    NOTE("Changed display modes");
    m_bModeChanged = TRUE;
    NOTE("Creating surfaces");

    // Create the primary flipping surfaces

    hr = CreateSurfaces();
    if (FAILED(hr)) {
        return hr;
    }
    return BlankDisplay();
}


// Reset the back buffer and blank the display

HRESULT CModexAllocator::BlankDisplay()
{
    LPDIRECTDRAWSURFACE pSurface = GetDirectDrawSurface();
    if (pSurface == NULL) return NOERROR;
    NOTE("Entering BlankDisplay");
    ResetBackBuffer(pSurface);

    // Draw or flip the blank backbuffer

    if (m_pBackBuffer == NULL) return DrawSurface(NULL);
    if (m_pDrawSurface) ResetBackBuffer(m_pBackBuffer);
    HRESULT hr = m_pFrontBuffer->Flip(NULL,DDFLIP_WAIT);
    NOTE1("Flip to blank display returned %lx",hr);

    ResetBackBuffer(m_pBackBuffer);
    while (m_pFrontBuffer->GetFlipStatus(DDGFS_ISFLIPDONE) ==
        DDERR_WASSTILLDRAWING) {
            NOTE("Waiting for flip to complete");
    }
    return NOERROR;
}


// Called when we receive WM_ACTIVATEAPP messages. If we have a surface and it
// is lost (the user probably tabbed away from the window using ALT-TAB) then
// we restore the video memory for it. Calling restore on a lost surface has
// much the same affect as recreating the surfaces but is much more efficient

HRESULT CModexAllocator::OnActivate(BOOL bActive)
{
    // Don't lock allocator if being hidden

    if (bActive == FALSE) {
        NOTE("Deactivated");
        return NOERROR;
    }

    NOTE("Entering OnActivate");
    CAutoLock cVideoLock(this);
    ASSERT(bActive == TRUE);

    // Is the mode changing

    if (m_bModeChanged == FALSE) {
        NOTE("Deactivating");
        return NOERROR;
    }

    // Restore the front buffer

    if (m_pFrontBuffer) {
        if (m_pFrontBuffer->IsLost() != DD_OK) {
            NOTE("Restoring surface");
            m_pFrontBuffer->Restore();
        }
    }

    // Do we have a stretching offscreen

    if (m_pDrawSurface) {
        if (m_pDrawSurface->IsLost() != DD_OK) {
            NOTE("Restoring offscreen");
            m_pDrawSurface->Restore();
        }
    }
    return BlankDisplay();
}


// Restore the display mode and GDI surface. Most times the user will stop us
// by hitting ALT-TAB back to the main application and pressing Stop. When we
// get in here to be deactivated it does mean that the window could be in a
// minimised state and the surface will have been restored. In that case we
// do not short circuit DirectDraw and leave it to sort the display mode out

HRESULT CModexAllocator::Inactive()
{
    HWND hwnd = m_pModexWindow->GetWindowHWND();

    // It is dangerous to leave ourselves locked when we restore the display
    // mode because that along with the ShowWindow(SW_HIDE) can cause a host
    // of messages to be sent to us. Amongst these is WM_ACTIVATEAPP which
    // causes a callback to this allocator. Therefore we unlock before doing
    // the restore and hide - and use m_bModeChanged to make us thread safe
    {
        NOTE("Entering Inactive");
        CAutoLock cVideoLock(this);

        // Have we got anything to undo

        if (m_bModeChanged == FALSE) {
            NOTE("No mode to restore");
            ShowWindow(hwnd,SW_HIDE);
            return NOERROR;
        }

        ASSERT(m_pDirectDraw);
        m_bModeChanged = FALSE;
        NOTE("Restoring display mode");
    }

    // Restore the palette before changing display modes

    if (m_pFrontBuffer) {
        HRESULT hr = BlankDisplay();
        hr = m_pFrontBuffer->SetPalette(NULL);
        if (hr == DDERR_SURFACELOST) {
            m_pFrontBuffer->Restore();
            m_pFrontBuffer->SetPalette(NULL);
        }
    }

    // Switch back to the normal display

    m_pDirectDraw->RestoreDisplayMode();
    m_pDirectDraw->FlipToGDISurface();
    ShowWindow(hwnd,SW_HIDE);
    NOTE("Restored GDI display mode");

    // Restore the exclusive level for this window
    HRESULT hr = m_pDirectDraw->SetCooperativeLevel(hwnd,DDSCL_NORMAL);
    NOTE2("SetCooperativeLevel NORMAL %x returned %lx", hwnd, hr);

    ReleaseSurfaces();

    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\dither\dither.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// This implements VGA colour dithering, April 1996, Anthony Phillips

#include <streams.h>
#include <initguid.h>
#include <dither.h>
#include <limits.h>

// This is a VGA colour dithering filter. When ActiveMovie is installed it
// may be done on a system set with a 16 colour display mode. Without this
// we would not be able to show any video as none of the AVI/MPEG decoders
// can dither to 16 colours. As a quick hack we dither to 16 colours but
// we only use the black, white and grey thereby doing a halftoned dither

// This filter does not have a worker thread so it executes the colour space
// conversion on the calling thread. It is meant to be as lightweight as is
// possible so we do very little type checking on connection over and above
// ensuring we understand the types involved. The assumption is that when the
// type eventually gets through to an end point (probably the video renderer
// supplied) it will do a thorough type checking and reject bad streams.

// List of CLSIDs and creator functions for class factory

#ifdef FILTER_DLL
CFactoryTemplate g_Templates[1] = {
    { L""
    , &CLSID_Dither
    , CDither::CreateInstance
    , NULL
    , &sudDitherFilter }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
#endif


// This goes in the factory template table to create new instances

CUnknown *CDither::CreateInstance(LPUNKNOWN pUnk,HRESULT *phr)
{
    return new CDither(NAME("VGA Ditherer"),pUnk);
}


// Setup data

const AMOVIESETUP_MEDIATYPE
sudDitherInputPinTypes =
{
    &MEDIATYPE_Video,           // Major
    &MEDIASUBTYPE_RGB8          // Subtype
};
const AMOVIESETUP_MEDIATYPE
sudDitherOutpinPinTypes =
{
    &MEDIATYPE_Video,           // Major
    &MEDIASUBTYPE_RGB4          // Subtype
};

const AMOVIESETUP_PIN
sudDitherPin[] =
{
    { L"Input",                 // Name of the pin
      FALSE,                    // Is pin rendered
      FALSE,                    // Is an Output pin
      FALSE,                    // Ok for no pins
      FALSE,                    // Can we have many
      &CLSID_NULL,              // Connects to filter
      NULL,                     // Name of pin connect
      1,                        // Number of pin types
      &sudDitherInputPinTypes}, // Details for pins

    { L"Output",                // Name of the pin
      FALSE,                    // Is pin rendered
      TRUE,                     // Is an Output pin
      FALSE,                    // Ok for no pins
      FALSE,                    // Can we have many
      &CLSID_NULL,              // Connects to filter
      NULL,                     // Name of pin connect
      1,                        // Number of pin types
      &sudDitherOutpinPinTypes} // Details for pins
};

const AMOVIESETUP_FILTER
sudDitherFilter =
{
    &CLSID_Dither,              // CLSID of filter
    L"VGA 16 Color Ditherer",   // Filter name
    MERIT_UNLIKELY,             // Filter merit
    2,                          // Number of pins
    sudDitherPin                // Pin information
};


#pragma warning(disable:4355)

// Constructor initialises base transform class
CDither::CDither(TCHAR *pName,LPUNKNOWN pUnk) :

    CTransformFilter(pName,pUnk,CLSID_Dither),
    m_fInit(FALSE)
{
}


// Do the actual transform into the VGA colours

HRESULT CDither::Transform(IMediaSample *pIn,IMediaSample *pOut)
{
    NOTE("Entering Transform");
    BYTE *pInput = NULL;
    BYTE *pOutput = NULL;
    HRESULT hr = NOERROR;
    AM_MEDIA_TYPE   *pmt;

    if (!m_fInit) {
        return E_FAIL;
    }

    // Retrieve the output image pointer

    hr = pOut->GetPointer(&pOutput);
    if (FAILED(hr)) {
        NOTE("No output");
        return hr;
    }

    // And the input image buffer as well

    hr = pIn->GetPointer(&pInput);
    if (FAILED(hr)) {
        NOTE("No input");
        return hr;
    }

    //
    // If the media type has changed then pmt is NOT NULL
    //

    pOut->GetMediaType(&pmt);
    if (pmt != NULL) {
        CMediaType cmt(*pmt);
        DeleteMediaType(pmt);
        SetOutputPinMediaType(&cmt);
    }

    pIn->GetMediaType(&pmt);
    if (pmt != NULL) {
        CMediaType cmt(*pmt);
        DeleteMediaType(pmt);
        hr = SetInputPinMediaType(&cmt);
        if (FAILED(hr)) {
            return hr;
        }
    }

    Dither8(pOutput, pInput);

    return NOERROR;
}


// This function is handed a media type object and it looks after making sure
// that it is superficially correct. This doesn't amount to a whole lot more
// than making sure the type is right and that the media format block exists
// So we delegate type checking to the downstream filter that really draws it

HRESULT CDither::CheckVideoType(const CMediaType *pmt)
{
    NOTE("Entering CheckVideoType");

    // Check the major type is digital video

    if (pmt->majortype != MEDIATYPE_Video) {
        NOTE("Major type not MEDIATYPE_Video");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Check this is a VIDEOINFO type

    if (pmt->formattype != FORMAT_VideoInfo) {
        NOTE("Format not a VIDEOINFO");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Quick sanity check on the input format

    if (pmt->cbFormat < SIZE_VIDEOHEADER) {
        NOTE("Format too small for a VIDEOINFO");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
    return NOERROR;
}


// Check we like the look of this input format

HRESULT CDither::CheckInputType(const CMediaType *pmtIn)
{
    NOTE("Entering CheckInputType");

    // Is the input type MEDIASUBTYPE_RGB8

    if (pmtIn->subtype != MEDIASUBTYPE_RGB8) {
        NOTE("Subtype not MEDIASUBTYPE_RGB8");
        return VFW_E_TYPE_NOT_ACCEPTED;
    }
    return CheckVideoType(pmtIn);
}


// Can we do this input to output transform. We will only be called here if
// the input pin is connected. We cannot stretch nor compress the image and
// the only allowed output format is MEDIASUBTYPE_RGB4. There is no point us
// doing pass through like the colour space convertor because DirectDraw is
// not available in any VGA display modes - it works with a minimum of 8bpp

HRESULT CDither::CheckTransform(const CMediaType *pmtIn,const CMediaType *pmtOut)
{
    VIDEOINFO *pTrgInfo = (VIDEOINFO *) pmtOut->Format();
    VIDEOINFO *pSrcInfo = (VIDEOINFO *) pmtIn->Format();
    NOTE("Entering CheckTransform");

    // Quick sanity check on the output format

    HRESULT hr = CheckVideoType(pmtOut);
    if (FAILED(hr)) {
        return hr;
    }

    // Check the output format is VGA colours

    if (*pmtOut->Subtype() != MEDIASUBTYPE_RGB4) {
        NOTE("Output not VGA");
        return E_INVALIDARG;
    }

    // See if we can use direct draw

    if (IsRectEmpty(&pTrgInfo->rcSource) == TRUE) {
        ASSERT(IsRectEmpty(&pTrgInfo->rcTarget) == TRUE);
        if (pSrcInfo->bmiHeader.biWidth == pTrgInfo->bmiHeader.biWidth) {
            if (pSrcInfo->bmiHeader.biHeight == pTrgInfo->bmiHeader.biHeight) {
                return S_OK;
            }
        }
        return VFW_E_TYPE_NOT_ACCEPTED;
    }


    // Create a source rectangle if it's empty

    RECT Source = pTrgInfo->rcSource;
    if (IsRectEmpty(&Source) == TRUE) {
        NOTE("Source rectangle filled in");
        Source.left = Source.top = 0;
        Source.right = pSrcInfo->bmiHeader.biWidth;
        Source.bottom = ABSOL(pSrcInfo->bmiHeader.biHeight);
    }

    // Create a destination rectangle if it's empty

    RECT Target = pTrgInfo->rcTarget;
    if (IsRectEmpty(&Target) == TRUE) {
        NOTE("Target rectangle filled in");
        Target.left = Target.top = 0;
        Target.right = pSrcInfo->bmiHeader.biWidth;
        Target.bottom = ABSOL(pSrcInfo->bmiHeader.biHeight);
    }

    // Check we are not stretching nor compressing the image

    if (WIDTH(&Source) == WIDTH(&Target)) {
        if (HEIGHT(&Source) == HEIGHT(&Target)) {
            NOTE("No stretch");
            return NOERROR;
        }
    }
    return VFW_E_TYPE_NOT_ACCEPTED;
}


// We offer only one output format which is MEDIASUBTYPE_RGB4. The VGA colours
// are fixed in time and space forever so we just copy the 16 colours onto the
// end of the output VIDEOINFO we construct. We set the image size field to be
// the actual image size rather than the default zero so that when we come to
// deciding and allocating buffering we can use this to specify the image size

HRESULT CDither::GetMediaType(int iPosition,CMediaType *pmtOut)
{
    NOTE("Entering GetMediaType");
    CMediaType InputType;
    ASSERT(pmtOut);

    // We only offer one format

    if (iPosition) {
        NOTE("Exceeds types supplied");
        return VFW_S_NO_MORE_ITEMS;
    }

    // Allocate and zero fill the output format

    pmtOut->ReallocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtOut->Format();
    if (pVideoInfo == NULL) {
        NOTE("No type memory");
        return E_OUTOFMEMORY;
    }

    // Reset the output format and install the palette

    ZeroMemory((PVOID) pVideoInfo,sizeof(VIDEOINFO));
    m_pInput->ConnectionMediaType(&InputType);
    VIDEOINFO *pInput = (VIDEOINFO *) InputType.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);

    // Copy the system colours from the VGA palette

    for (LONG Index = 0;Index < 16;Index++) {
        pVideoInfo->bmiColors[Index].rgbRed = VGAColours[Index].rgbRed;
        pVideoInfo->bmiColors[Index].rgbGreen = VGAColours[Index].rgbGreen;
        pVideoInfo->bmiColors[Index].rgbBlue = VGAColours[Index].rgbBlue;
        pVideoInfo->bmiColors[Index].rgbReserved = 0;
    }

    // Copy these fields from the source format

    pVideoInfo->rcSource = pInput->rcSource;
    pVideoInfo->rcTarget = pInput->rcTarget;
    pVideoInfo->dwBitRate = pInput->dwBitRate;
    pVideoInfo->dwBitErrorRate = pInput->dwBitErrorRate;
    pVideoInfo->AvgTimePerFrame = pInput->AvgTimePerFrame;

    pHeader->biSize = sizeof(BITMAPINFOHEADER);
    pHeader->biWidth = pInput->bmiHeader.biWidth;
    pHeader->biHeight = pInput->bmiHeader.biHeight;
    pHeader->biPlanes = pInput->bmiHeader.biPlanes;
    pHeader->biBitCount = 4;
    pHeader->biCompression = BI_RGB;
    pHeader->biXPelsPerMeter = 0;
    pHeader->biYPelsPerMeter = 0;
    pHeader->biClrUsed = 16;
    pHeader->biClrImportant = 16;
    pHeader->biSizeImage = GetBitmapSize(pHeader);

    pmtOut->SetType(&MEDIATYPE_Video);
    pmtOut->SetSubtype(&MEDIASUBTYPE_RGB4);
    pmtOut->SetFormatType(&FORMAT_VideoInfo);
    pmtOut->SetSampleSize(pHeader->biSizeImage);
    pmtOut->SetTemporalCompression(FALSE);

    return NOERROR;
}


// Called to prepare the allocator's count of buffers and sizes, we don't care
// who provides the allocator so long as it will give us a media sample. The
// output format we produce is not temporally compressed so in principle we
// could use any number of output buffers but it doesn't appear to gain much
// performance and does add to the overall memory footprint of the system

HRESULT CDither::DecideBufferSize(IMemAllocator *pAllocator,
                                  ALLOCATOR_PROPERTIES *pProperties)
{
    NOTE("Entering DecideBufferSize");
    CMediaType OutputType;
    ASSERT(pAllocator);
    ASSERT(pProperties);
    HRESULT hr = NOERROR;

    m_pOutput->ConnectionMediaType(&OutputType);
    pProperties->cBuffers = 1;
    pProperties->cbBuffer = OutputType.GetSampleSize();
    ASSERT(pProperties->cbBuffer);

    // Ask the allocator to reserve us some sample memory, NOTE the function
    // can succeed (that is return NOERROR) but still not have allocated the
    // memory that we requested, so we must check we got whatever we wanted

    ALLOCATOR_PROPERTIES Actual;
    hr = pAllocator->SetProperties(pProperties,&Actual);
    if (FAILED(hr)) {
        NOTE("Properties failed");
        return hr;
    }

    // Did we get the buffering requirements

    if (Actual.cbBuffer >= (LONG) OutputType.GetSampleSize()) {
        if (Actual.cBuffers >= 1) {
            NOTE("Request ok");
            return NOERROR;
        }
    }
    return VFW_E_SIZENOTSET;
}


// Called when the media type is set for one of our pins

HRESULT CDither::SetMediaType(PIN_DIRECTION direction,const CMediaType *pmt)
{
    HRESULT hr = S_OK;

    if (direction == PINDIR_INPUT) {
        ASSERT(*pmt->Subtype() == MEDIASUBTYPE_RGB8);
        hr = SetInputPinMediaType(pmt);
    }
    else {
        ASSERT(*pmt->Subtype() == MEDIASUBTYPE_RGB4);
        SetOutputPinMediaType(pmt);
    }
    return hr;
}


HRESULT CDither::SetInputPinMediaType(const CMediaType *pmt)
{
    VIDEOINFO *pInput = (VIDEOINFO *)pmt->pbFormat;
    BITMAPINFOHEADER *pbiSrc = HEADER(pInput);

    m_fInit = DitherDeviceInit(pbiSrc);
    if (!m_fInit) {
        return E_OUTOFMEMORY;
    }

    ASSERT(pbiSrc->biBitCount == 8);
    m_wWidthSrc = (pbiSrc->biWidth + 3) & ~3;

    return S_OK;
}


void CDither::SetOutputPinMediaType(const CMediaType *pmt)
{
    VIDEOINFO *pOutput = (VIDEOINFO *)pmt->pbFormat;
    BITMAPINFOHEADER *pbiDst = HEADER(pOutput);

    ASSERT(pbiDst->biBitCount == 4);

    m_wWidthDst = ((pbiDst->biWidth * 4) + 7) / 8;
    m_wWidthDst = (m_wWidthDst + 3) & ~3;

    m_DstXE = pbiDst->biWidth;
    m_DstYE = pbiDst->biHeight;
}


// Dither to the colors of the display driver

BOOL CDither::DitherDeviceInit(LPBITMAPINFOHEADER lpbi)
{
    HBRUSH      hbr = (HBRUSH) NULL;
    HDC         hdcMem = (HDC) NULL;
    HDC         hdc = (HDC) NULL;
    HBITMAP     hbm = (HBITMAP) NULL;
    HBITMAP     hbmT = (HBITMAP) NULL;
    int         i;
    int         nColors;
    LPBYTE      lpDitherTable;
    LPRGBQUAD   prgb;
    BYTE        biSave[sizeof(BITMAPINFOHEADER) + 256 * sizeof(RGBQUAD)];
    LPBITMAPINFOHEADER lpbiOut = (LPBITMAPINFOHEADER)&biSave;

    NOTE("DitherDeviceInit called");

    //
    // we dont need to re-init the dither table, unless it is not ours then
    // we should free it.
    //
    lpDitherTable = (LPBYTE)GlobalAllocPtr(GHND, 256*8*4);
    if (lpDitherTable == NULL)
    {
        return FALSE;
    }

    hdc = GetDC(NULL);
    if ( ! hdc )
        goto ErrorExit;
    hdcMem = CreateCompatibleDC(hdc);
    if ( ! hdcMem )
        goto ErrorExit;
    hbm  = CreateCompatibleBitmap(hdc, 256*8, 8);
    if ( ! hbm )
        goto ErrorExit;

    hbmT = (HBITMAP)SelectObject(hdcMem, (HBITMAP)hbm);

    if ((nColors = (int)lpbi->biClrUsed) == 0)
        nColors = 1 << (int)lpbi->biBitCount;

    prgb = (LPRGBQUAD)(lpbi+1);

    for (i=0; i<nColors; i++)
    {
        hbr = CreateSolidBrush(RGB(prgb[i].rgbRed,
                                   prgb[i].rgbGreen,
                                   prgb[i].rgbBlue));
        if ( hbr )
        {
            hbr = (HBRUSH)SelectObject(hdcMem, hbr);
            PatBlt(hdcMem, i*8, 0, 8, 8, PATCOPY);
            hbr = (HBRUSH)SelectObject(hdcMem, hbr);
            DeleteObject(hbr);
        }
    }

    SelectObject(hdcMem, hbmT);
    DeleteDC(hdcMem);

    lpbiOut->biSize           = sizeof(BITMAPINFOHEADER);
    lpbiOut->biPlanes         = 1;
    lpbiOut->biBitCount       = 4;
    lpbiOut->biWidth          = 256*8;
    lpbiOut->biHeight         = 8;
    lpbiOut->biCompression    = BI_RGB;
    lpbiOut->biSizeImage      = 256*8*4;
    lpbiOut->biXPelsPerMeter  = 0;
    lpbiOut->biYPelsPerMeter  = 0;
    lpbiOut->biClrUsed        = 0;
    lpbiOut->biClrImportant   = 0;
    GetDIBits(hdc, hbm, 0, 8, lpDitherTable,
              (LPBITMAPINFO)lpbiOut, DIB_RGB_COLORS);

    DeleteObject(hbm);
    ReleaseDC(NULL, hdc);

    for (i = 0; i < 256*8*4; i++) {

        BYTE twoPels = lpDitherTable[i];

        m_DitherTable[(i * 2) + 0] = (BYTE)((twoPels & 0xF0) >> 4);
        m_DitherTable[(i * 2) + 1] = (BYTE)(twoPels & 0x0F);
    }

    GlobalFreePtr(lpDitherTable);
    return TRUE;
ErrorExit:
    if ( NULL != hdcMem && NULL != hbmT )
        SelectObject(hdcMem, hbmT);
    if ( NULL != hdcMem )
        DeleteDC(hdcMem);
    if ( hbm )
        DeleteObject(hbm);
    if ( hdc )
        ReleaseDC(NULL, hdc);
    if ( lpDitherTable )
        GlobalFreePtr(lpDitherTable);
    return FALSE;
}


#define DODITH8(px, _x_) (m_DitherTable)[yDith + (px) * 8 + (_x_)]

// Call this to actually do the dither.

void CDither::Dither8(LPBYTE lpDst,LPBYTE lpSrc)
{
    int     x,y;
    BYTE    *pbS;
    BYTE    *pbD;
    DWORD   dw;

    NOTE("Dither8");

    for (y=0; y < m_DstYE; y++) {

        int yDith = (y & 7) * 256 * 8;

        pbD = lpDst;
        pbS = lpSrc;

        // write one DWORD (one dither cell horizontally) at once

        for (x=0; x + 8 <= m_DstXE; x += 8) {

            dw  = DODITH8(*(pbS + 6), 6);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 7), 7);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 4), 4);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 5), 5);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 2), 2);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 3), 3);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 0), 0);
            dw <<= 4;

            dw |= DODITH8(*(pbS + 1), 1);
            *((DWORD UNALIGNED *) pbD) = dw;

            pbS += 8;
            pbD += 4;
        }

	// clean up remainder (less than 8 bytes per row)
        int EvenPelsLeft = ((m_DstXE - x) & ~1);
        int OddPelLeft   = ((m_DstXE - x) &  1);

        for (x = 0; x < EvenPelsLeft; x += 2) {
            *pbD++ = (DODITH8(*pbS++, x  ) << 4) |
                      DODITH8(*pbS++, x+1);
        }

        if (OddPelLeft) {
            *pbD++ = (DODITH8(*pbS++, x) << 4);
        }

        lpSrc += m_wWidthSrc;
        lpDst += m_wWidthDst;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\ddmm.h ===
/*==========================================================================
 *
 *  Copyright (c) 1995 - 1998  Microsoft Corporation.  All Rights Reserved.
 *
 *  File:       ddmm.cpp
 *  Content:    Routines for using DirectDraw on a multimonitor system
 *
 ***************************************************************************/

#ifdef __cplusplus
extern "C" {            /* Assume C declarations for C++ */
#endif  /* __cplusplus */

typedef HRESULT (*PDRAWCREATE)(IID *,LPDIRECTDRAW *,LPUNKNOWN);
typedef HRESULT (*PDRAWENUM)(LPDDENUMCALLBACKA,LPVOID);

INT_PTR DeviceFromWindow(HWND hwnd, LPSTR szDevice, RECT*prc);

#ifdef __cplusplus
}
#endif	/* __cplusplus */
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\direct.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements the COverlay class, Anthony Phillips, February 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>
#include <viddbg.h>

// This object implements the IOverlay interface which in certain places uses
// information stored in the owning renderer object, such as the connection
// established flag and the media type. Therefore the interface methods must
// lock the complete object before starting. However other internal threads
// may call us to set our internal state, such as a notification that the
// media type connection has changed (and therefore possibly the palette).
// In which case we cannot lock the entire object so we have our own private
// critical section that ALL the objects methods lock before commencing
//
// There is some complication with providing two transport interfaces to the
// video renderer. Because we get told of the media type to use for a filter
// connection after it tries to get hold of a transport interface we always
// provide both interfaces (IMemInputPin and IOverlay). However if the media
// type is MEDIASUBTYPE_Overlay we do not permit IMemInputPin calls. If the
// connection is for normal media samples then the source filter cannot call
// this interface at all (this prevents conflicts we may get with palettes)


// Constructor NOTE we set the owner of the object to be NULL (through the
// CUnknown constructor call) and then override all of the non delegating
// IUnknown methods. Within the AddRef and Release we delegate the reference
// counting to the owning renderer. We return IOverlay interfaces from the
// QueryInterface and route any other interface requests to the input pin

COverlay::COverlay(CRenderer *pRenderer,    // Main video renderer
                   CDirectDraw *pDirectDraw,
                   CCritSec *pLock,         // Object to lock with
                   HRESULT *phr) :          // Constructor return

    CUnknown(NAME("Overlay object"),NULL),
    m_pInterfaceLock(pLock),
    m_dwInterests(ADVISE_NONE),
    m_pRenderer(pRenderer),
    m_hPalette(NULL),
    m_bFrozen(FALSE),
    m_hHook(NULL),
    m_pDirectDraw(pDirectDraw),
    m_pNotify(NULL),
    m_DefaultCookie(INVALID_COOKIE_VALUE),
    m_bMustRemoveCookie(FALSE)
{
    ASSERT(m_pRenderer);
    ASSERT(m_pInterfaceLock);
    ResetColourKeyState();
    SetRectEmpty(&m_TargetRect);
}


// Destructor

COverlay::~COverlay()
{
    // Remove any palette left around

    if (m_hPalette) {
        NOTE("Deleting palette");
        EXECUTE_ASSERT(DeleteObject(m_hPalette));
        m_hPalette = NULL;
    }

    // update the overlay colorkey cookie counter

    if (m_bMustRemoveCookie) {
        // m_DefaultCookie should contain a valid cookie
        // value if m_bMustRemoveCookie is TRUE.
        ASSERT(m_DefaultCookie != INVALID_COOKIE_VALUE);

        RemoveCurrentCookie(m_DefaultCookie);
    }

    // Release any notification link

    if (m_pNotify) {
        NOTE("Releasing link");
        m_pNotify->Release();
        m_pNotify = NULL;
    }
}


// Check we connected to use the IOverlay transport

HRESULT COverlay::ValidateOverlayCall()
{
    NOTE("Entering ValidateOverlayCall");

    // Check we are connected otherwise reject the call

    if (m_pRenderer->m_InputPin.IsConnected() == FALSE) {
        NOTE("Pin is not connected");
        return VFW_E_NOT_CONNECTED;
    }

    // Is this a purely overlay connection

    GUID SubType = *(m_pRenderer->m_mtIn.Subtype());
    if (SubType != MEDIASUBTYPE_Overlay) {
        NOTE("Not an overlay connection");
        return VFW_E_NOT_OVERLAY_CONNECTION;
    }
    return NOERROR;
}


// This resets the colour key information

void COverlay::ResetColourKeyState()
{
    NOTE("Entering ResetColourKey");

    m_bColourKey = FALSE;
    m_WindowColour = 0;
    m_ColourKey.KeyType = CK_NOCOLORKEY;
    m_ColourKey.PaletteIndex = 0;			
    m_ColourKey.LowColorValue = 0;
    m_ColourKey.HighColorValue = 0;
}


// Initialise a default colour key. We will have got the next available RGB
// colour from a shared memory segment when we were constructed. The shared
// memory segment is also used by the video DirectDraw overlay object. Once
// we have a COLORREF we will need it mapped to an actual palette index. If
// we are on a true colour device which has no palette then it returns zero

void COverlay::InitDefaultColourKey(COLORKEY *pColourKey)
{
    COLORREF DefaultColourKey;
    NOTE("Entering InitDefaultColourKey");
    // We have not gotten this yet - we can't do it in our constructor since
    // the monitor name is not valid yet
    if (INVALID_COOKIE_VALUE == m_DefaultCookie) {
        HRESULT hr = GetNextOverlayCookie(m_pRenderer->m_achMonitor, &m_DefaultCookie);
        if (SUCCEEDED(hr)) {
            m_bMustRemoveCookie = TRUE;
        } else {
            // This cookie value is used by the Video Renderer 
            // if GetNextOverlayCookie() fails.
            m_DefaultCookie = DEFAULT_COOKIE_VALUE;
        }

        // m_DefaultCookie should contain a valid cookie value because
        // GetNextOverlayCookie() sets m_DefaultCookie to a valid 
        // cookie value if it succeeds.  If GetNextOverlayCookie() 
        // fails, m_DefaultCookie is set to DEFAULT_COOKIE_VALUE
        // which is also a valid cookie value.
        ASSERT(INVALID_COOKIE_VALUE != m_DefaultCookie);
    }

    DefaultColourKey = GetColourFromCookie(m_pRenderer->m_achMonitor, m_DefaultCookie);

    pColourKey->KeyType = CK_NOCOLORKEY;
    pColourKey->LowColorValue = DefaultColourKey;
    pColourKey->HighColorValue = DefaultColourKey;
    pColourKey->PaletteIndex = GetPaletteIndex(DefaultColourKey);
}


// Return the default colour key that we could use, this sets up a colour key
// that has a palette index range from zero to zero and a RGBQUAD true colour
// space range also from zero to zero. If we're ending up using this then we
// are guaranteed that one of these could be mapped to the video display

STDMETHODIMP COverlay::GetDefaultColorKey(COLORKEY *pColorKey)
{
    NOTE("Entering GetDefaultColorKey");
    CheckPointer(pColorKey,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);

    // Get a default key and set the type

    NOTE("Returning default colour key");
    InitDefaultColourKey(pColorKey);
    pColorKey->KeyType = CK_INDEX | CK_RGB;
    return NOERROR;
}


// Get the current colour key the renderer is using. The window colour key
// we store (m_ColourKey) defines the actual requirements the filter asked
// for when it called SetColorKey. We return the colour key that we are
// using in the window (and which we calculated from the requirements)

STDMETHODIMP COverlay::GetColorKey(COLORKEY *pColorKey)
{
    NOTE("Entering GetColorKey");
    CheckPointer(pColorKey,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);
    return GetWindowColourKey(pColorKey);
}


// This returns a COLORKEY structure based on the current colour key we have
// calculated (held in m_WindowColour). GDI uses reserved bits in the flags
// field to indicate if this is a palette index or RGB colour. If we are not
// using a colour key then we return an error E_FAIL to the caller, NOTE the
// default window colour key can be obtained by calling GetDefaultColorKey

HRESULT COverlay::GetWindowColourKey(COLORKEY *pColourKey)
{
    NOTE("Entering GetWindowColourKey");
    InitDefaultColourKey(pColourKey);

    // Are we using an overlay colour key

    if (m_bColourKey == FALSE) {
        NOTE("No colour key defined");
        return VFW_E_NO_COLOR_KEY_SET;
    }

    // Is the colour key a palette entry, we cannot work out the palette index
    // they asked for from the COLORREF value we store as it only contains the
    // map into the system palette so we go back to the initial requirements

    if (m_WindowColour & PALETTEFLAG) {
        NOTE("Palette index colour key");
        pColourKey->KeyType = CK_INDEX;
        pColourKey->PaletteIndex = m_ColourKey.PaletteIndex;
        return NOERROR;
    }

    ASSERT(m_WindowColour & TRUECOLOURFLAG);
    NOTE("True colour colour key defined");

    // This must be a standard RGB colour, for the sake of simplicity we take
    // off the GDI reserved bits that identify this as a true colour value

    pColourKey->KeyType = CK_RGB;
    pColourKey->LowColorValue = m_WindowColour & ~TRUECOLOURFLAG;
    pColourKey->HighColorValue = m_WindowColour & ~TRUECOLOURFLAG;

    return NOERROR;
}


// Check the colour key can be changed doing a quick parameter check and also
// see if there was a palette installed (through SetKeyPalette) which would
// conflict with us making one. If there is a custom colour palette installed
// then the source filter must remove it first. NOTE also if we have a palette
// installed (not a colour key one) then we know that we won't ever be able to
// find a true colour colour key so it is valid to return an error code

HRESULT COverlay::CheckSetColourKey(COLORKEY *pColourKey)
{
    NOTE("Entering CheckSetColourKey");

    // Check overlay calls are allowed

    HRESULT hr = ValidateOverlayCall();
    if (FAILED(hr)) {
        return hr;
    }

    // Is there a palette installed

    if (m_bColourKey == FALSE) {
        if (m_hPalette) {
            NOTE("Palette already set");
            return VFW_E_PALETTE_SET;
        }
    }

    // Check the colour key parameter is valid

    if (pColourKey == NULL) {
        NOTE("NULL pointer");
        return E_INVALIDARG;
    }

    return NOERROR;
}


// Set the colour key the renderer is to use for painting the window, first
// of all check the colour key can be set. If the source filter has already
// successfully called SetKeyPalette to make a custom set of colours then
// this will fail as they should remove it first. We then look for either a
// true colour or a palette index that will match one of their requirements

STDMETHODIMP COverlay::SetColorKey(COLORKEY *pColorKey)
{
    NOTE("Entering SetColorKey");

    CheckPointer(pColorKey,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);

    // Check the colour key can be changed

    HRESULT hr = CheckSetColourKey(pColorKey);
    if (FAILED(hr)) {
        return hr;
    }

    // Are we having the colour key turned off (CK_NOCOLORKEY is 0)

    if (pColorKey->KeyType == 0) {
        ResetColourKeyState();
        InstallPalette(NULL);
        m_pRenderer->m_VideoWindow.PaintWindow(TRUE);
        return NOERROR;
    }

    // Look after the colour key negotiation

    hr = MatchColourKey(pColorKey);
    if (FAILED(hr)) {
        return hr;
    }

    NOTE("Notifying colour key");
    NotifyChange(ADVISE_COLORKEY);
    return GetColorKey(pColorKey);
}


// Find a colour key that can be used by the filter. We may be asked to unset
// any colour key use (the key type is CK_NOCOLORKEY) in which case we reset
// the colour key state and release any palette resource we were holding. If
// we are being asked to set a new colour key then we go into the negotiation
// process, this tries to satisfy the colour key requirements based on the
// current video display format. If it has a choice of creating a colour key
// based on a palette index, or on a RGB colour it will pick the index

HRESULT COverlay::MatchColourKey(COLORKEY *pColourKey)
{
    NOTE("Entering MatchColourKey");

    HPALETTE hPalette = NULL;       // New palette we may create
    COLORREF OverlayColour = 0;   	// Overlay colour for window
    HRESULT hr = NOERROR;           // General OLE return code

    // Find a suitable colour key

    hr = NegotiateColourKey(pColourKey,&hPalette,&OverlayColour);
    if (FAILED(hr)) {
        NOTE("No match");
        return hr;
    }

    InstallColourKey(pColourKey,OverlayColour);

    // We set the hPalette field to NULL before starting. If we get to here
    // and it hasn't been changed we still call the function. The function
    // not only installs a new palette if available but cleans up resources
    // we used for any previous colour key (including any colour palette)

    NOTE("Installing colour key");
    InstallPalette(hPalette);
    m_pRenderer->m_VideoWindow.PaintWindow(TRUE);
    return NOERROR;
}


// This is passed a colour key that the connected filter would like us to
// honour. This can be a range of RGB true colours or a particular palette
// index. We match it's requirements against the device capabilities and
// fill in the input parameters with the chosen colour and return NOERROR

HRESULT COverlay::NegotiateColourKey(COLORKEY *pColourKey,
                                     HPALETTE *phPalette,
                                     COLORREF *pColourRef)
{
    NOTE("Entering NegotiateColourKey");

    VIDEOINFO *pDisplay;        // Video display format
    HRESULT hr = NOERROR;       // General OLE return code

    pDisplay = (VIDEOINFO *) m_pRenderer->m_Display.GetDisplayFormat();

    // Try and find a palette colour key

    if (pColourKey->KeyType & CK_INDEX) {
        hr = NegotiatePaletteIndex(pDisplay,pColourKey,phPalette,pColourRef);
        if (SUCCEEDED(hr)) {
            NOTE("No palette");
            return hr;
        }
    }

    // Try and find a true colour match

    if (pColourKey->KeyType & CK_RGB) {
        hr = NegotiateTrueColour(pDisplay,pColourKey,pColourRef);
        if (SUCCEEDED(hr)) {
            NOTE("No true colour");
            return hr;
        }
    }
    return VFW_E_NO_COLOR_KEY_FOUND;
}


// Create a palette that references the system palette directly. This is used
// by MPEG boards the overlay their video where they see an explicit palette
// index so we cannot use a normal PALETTEENTRY as it will be mapped to the
// current system palette, where what we really want is to draw using our
// palette index value regardless of what colour will appear on the screen

HRESULT COverlay::NegotiatePaletteIndex(VIDEOINFO *pDisplay,
                                        COLORKEY *pColourKey,
                                        HPALETTE *phPalette,
                                        COLORREF *pColourRef)
{
    NOTE("Entering NegotiatePaletteIndex");
    LOGPALETTE LogPal;

    // Is the display set to use a palette

    if (PALETTISED(pDisplay) == FALSE) {
        NOTE("Not palettised");
        return E_INVALIDARG;
    }

    // Is the palette index too large for the video display

    if (pColourKey->PaletteIndex >= PALETTE_ENTRIES(pDisplay)) {
        NOTE("Too many colours");
        return E_INVALIDARG;
    }

    // The palette index specified in the input parameters becomes the source
    // of the new colour key. Instead of it being a logical value referencing
    // a colour in the palette it becomes an absolute device value so when we
    // draw with this palette index it is really that value that appears in
    // the frame buffer regardless of what colour it may actually appear as

    LogPal.palPalEntry[0].peRed = (UCHAR) pColourKey->PaletteIndex;
    LogPal.palPalEntry[0].peGreen = 0;
    LogPal.palPalEntry[0].peBlue = 0;
    LogPal.palPalEntry[0].peFlags = PC_EXPLICIT;

    LogPal.palVersion = PALVERSION;
    LogPal.palNumEntries = 1;

    *phPalette = CreatePalette(&LogPal);
    if (*phPalette == NULL) {
        NOTE("Palette failed");
        return E_FAIL;
    }
    *pColourRef = PALETTEINDEX(0);
    return NOERROR;
}


// The filter would like to use a RGB true colour value picked from a range
// of values defined in the colour key. If video display is palettised then
// we try and pick an entry that matches the colour. If the video display is
// true colour then we find an intersection of the two colour spaces

HRESULT COverlay::NegotiateTrueColour(VIDEOINFO *pDisplay,
                                      COLORKEY *pColourKey,
                                      COLORREF *pColourRef)
{
    NOTE("Entering NegotiateTrueColour");

    // Must be a true colour device

    if (PALETTISED(pDisplay) == TRUE) {
        NOTE("Palettised");
        return E_INVALIDARG;
    }

    // Get the colour bit field masks for the display, this should always
    // succeed as the information we use in this call is checked when the
    // display object is initially constructed. It returns the masks that
    // are needed to calculate the valid range of values for each colour

    DWORD MaskRed, MaskGreen, MaskBlue;
    EXECUTE_ASSERT(m_pRenderer->m_Display.GetColourMask(&MaskRed,
                                                        &MaskGreen,
                                                        &MaskBlue));

    // We take each colour component range in turn and shift the values right
    // and AND them with 0xFF so that we have their undivided attention. We
    // then loop between the low and high values trying to find one which
    // the display would accept. This is done by an AND with the display
    // bit field mask, if the resulting value is still in the source filter
    // desired range then we have a hit. The value is stored in the output
    // array until we have done all three when we then create the COLORREF

    DWORD RGBShift[] = { 0, 8, 16 };
    DWORD DisplayMask[] = { MaskRed, MaskGreen, MaskBlue };
    DWORD ColourMask[] = { INFINITE, INFINITE, INFINITE };

    DWORD MinColour, MaxColour;
    for (INT iColours = iRED;iColours <= iBLUE;iColours++) {

        // Extract the minimum and maximum colour component values

        MinColour = (pColourKey->LowColorValue >> RGBShift[iColours]) & 0xFF;
        MaxColour = (pColourKey->HighColorValue >> RGBShift[iColours]) & 0xFF;

        // Check they are the right way round

        if (MinColour > MaxColour) {
            return E_INVALIDARG;
        }

        // See if any of them are acceptable by the display format
        for (DWORD Value = MinColour;Value <= MaxColour;Value++) {

            DWORD ColourTest = Value & DisplayMask[iColours];
            if (ColourTest >= MinColour) {
                if (ColourTest <= MaxColour) {
                    ColourMask[iColours] = ColourTest;
                    break;
                }
            }
        }

        // If no colour in the source filter's range could be matched against
        // the display requirements then the colour value will be INFINITE

        if (ColourMask[iColours] == INFINITE) {
            return E_FAIL;
        }
    }

    // We now have three valid colours in the ColourMask array so all we have
    // to do is combine them into a COLORREF the GDI defined macro. The macro
    // PALETTERGB sets a reserved bit in the most significant byte which GDI
    // uses to identify the colour as a COLORREF rather than a RGB triplet

    *pColourRef = PALETTERGB(ColourMask[iRED],
                             ColourMask[iGREEN],
                             ColourMask[iBLUE]);
    return NOERROR;
}


// Install the new colour key details

HRESULT COverlay::InstallColourKey(COLORKEY *pColourKey,COLORREF Colour)
{
    NOTE("Entering InstallColourKey");

    m_bColourKey = TRUE;              // We are using an overlay colour key
    m_ColourKey = *pColourKey;        // These are the original requirements
    m_WindowColour = Colour;          // This is the actual colour selected

    return NOERROR;
}


// This is called to install a new palette into the video window but it also
// looks after freeing any previous palette resources so the input parameter
// may be NULL. In this case we simply install the standard VGA palette. We
// delete the old palette once the new has been installed using DeleteObject
// which should in principle never fail hence the EXECUTE_ASSERT round it

HRESULT COverlay::InstallPalette(HPALETTE hPalette)
{
    NOTE("Entering InstallPalette");
    BOOL bInstallSystemPalette = FALSE;

    // Is there any palette work required

    if (m_hPalette == NULL) {
        if (hPalette == NULL) {
            return NOERROR;
        }
    }

    // If we have no new palette then install a standard VGA

    if (hPalette == NULL) {
        hPalette = (HPALETTE) GetStockObject(DEFAULT_PALETTE);
        bInstallSystemPalette = TRUE;
        NOTE("Installing VGA palette");
    }

    // We have a new palette to install and possibly a previous one to delete
    // this will lock the window object critical section and then install and
    // realise our new palette. The locking stops any window thread conflicts
    // but we must be careful not to cause any messages to be sent across as
    // the window thread may be waiting to enter us to handle a WM_PAINT call

    m_pRenderer->m_VideoWindow.SetKeyPalette(hPalette);
    if (m_hPalette) {
        EXECUTE_ASSERT(DeleteObject(m_hPalette));
        NOTE("Deleting palette");
        m_hPalette = NULL;
    }

    // If we installed a VGA palette then we do not own it

    if (bInstallSystemPalette == TRUE) {
        hPalette = NULL;
    }
    m_hPalette = hPalette;
    return NOERROR;
}


// The clipping rectangles we retrieved from DCI will be for the entire client
// rectangle not just for the current destination video area. We scan through
// the list intersecting each with the video rectangle. This is complicated as
// we must remove any empty rectangles and shunt further ones down the list

HRESULT COverlay::AdjustForDestination(RGNDATA *pRgnData)
{
    NOTE("Entering AdjustForDestination");

    ASSERT(pRgnData);       // Don't call with NULL regions
    DWORD Output = 0;       // Total number of rectangles
    RECT ClipRect;          // Intersection of the clips

    RECT *pBoundRect = &(pRgnData->rdh.rcBound);
    RECT *pRectArray = (RECT *) pRgnData->Buffer;

    for (DWORD Count = 0;Count < pRgnData->rdh.nCount;Count++) {
        if (IntersectRect(&ClipRect,&pRectArray[Count],pBoundRect)) {
            pRectArray[Output++] = ClipRect;
        }
    }

    // Complete the RGNDATAHEADER structure

    pRgnData->rdh.nCount = Output;
    pRgnData->rdh.nRgnSize = Output * sizeof(RECT);
    pRgnData->rdh.iType = RDH_RECTANGLES;
    return NOERROR;
}


// The gets the video area clipping rectangles and the RGNDATAHEADER that is
// used to decribe them. The clip list is variable length so we allocate the
// memory which the caller should free it when finished (using CoTaskMemFree)
// An overlay source filter will want the clip list for the window client area
// not for the window as a whole including borders and captions so we call an
// API provided in DCI that returns the clip list based on a device context

HRESULT COverlay::GetVideoClipInfo(RECT *pSourceRect,
                                   RECT *pDestinationRect,
                                   RGNDATA **ppRgnData)
{
    NOTE("Entering GetVideoClipInfo");
    GetVideoRect(pDestinationRect);
    m_pRenderer->m_DrawVideo.GetSourceRect(pSourceRect);
    ASSERT(CritCheckIn(this));

    // Do they want the clip list as well

    if (ppRgnData == NULL) {
        return NOERROR;
    }


    DWORD dwSize;
    LPDIRECTDRAWCLIPPER lpClipper;

    lpClipper = m_pDirectDraw->GetOverlayClipper();
    if (!lpClipper) {
        NOTE("No clipper");
        return E_OUTOFMEMORY;
    }

    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    lpClipper->SetHWnd(0, hwnd);

    lpClipper->GetClipList(NULL, NULL, &dwSize);
    ASSERT(dwSize >= sizeof(RGNDATAHEADER));

    *ppRgnData = (RGNDATA *)QzTaskMemAlloc(dwSize);
    if (*ppRgnData == NULL) {
        NOTE("No clip memory");
        return E_OUTOFMEMORY;
    }

    lpClipper->GetClipList(NULL, *ppRgnData, &dwSize);

    IntersectRect(&(*ppRgnData)->rdh.rcBound, &(*ppRgnData)->rdh.rcBound,
                  (RECT *)pDestinationRect);

    return AdjustForDestination(*ppRgnData);
}


// Return the destination rectangle in display coordinates rather than the
// window coordinates we keep it in. This means getting the screen offset
// of where the window's client area starts and adding this to the target
// rectangle. This may produce an invalid destination rectangle if we're
// in the process of either being minimised or being restored for an icon

HRESULT COverlay::GetVideoRect(RECT *pVideoRect)
{
    NOTE("Entering GetVideoRect");
    ASSERT(pVideoRect);

    // Handle window state changes and iconic windows.  If we have been
    // made a child window of another window and that window has been
    // made "minimized" our window will not have the iconic style.  So we
    // have to navigate up to the top level window and check to see
    // if it has been made iconic.

    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    HWND hwndParent = hwnd;

    for ( ;; ) {

        if (IsIconic(hwndParent)) {
            SetRectEmpty(pVideoRect);
            return NOERROR;
        }

        HWND hwndT = GetParent(hwndParent);
        if (hwndT == (HWND)NULL) break;
        hwndParent = hwndT;
    }


    // Get the client corner in screen coordinates

    POINT TopLeftCorner;
    TopLeftCorner.x = TopLeftCorner.y = 0;
    EXECUTE_ASSERT(ClientToScreen(hwnd,&TopLeftCorner));
    m_pRenderer->m_DrawVideo.GetTargetRect(pVideoRect);


    // Add the actual display offset to the destination

    pVideoRect->top += TopLeftCorner.y;
    pVideoRect->bottom += TopLeftCorner.y;
    pVideoRect->left += TopLeftCorner.x;
    pVideoRect->right += TopLeftCorner.x;

    return NOERROR;
}


// This is used by source filters to retrieve the clipping information for a
// video window. We may be called when the window is currently frozen but all
// we do is to return the clipping information available through DCI and let
// it worry about any serialisation problems with other windows moving about

STDMETHODIMP COverlay::GetClipList(RECT *pSourceRect,
                                   RECT *pDestinationRect,
                                   RGNDATA **ppRgnData)
{
    NOTE("Entering GetClipList");

    // Return E_INVALIDARG if any of the pointers are NULL

    CheckPointer(pSourceRect,E_POINTER);
    CheckPointer(pDestinationRect,E_POINTER);
    CheckPointer(ppRgnData,E_POINTER);

    // Now we can go ahead and handle the clip call

    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);
    return GetVideoClipInfo(pSourceRect,pDestinationRect,ppRgnData);
}


// This returns the current source and destination video rectangles. Source
// rectangles can be updated through this IBasicVideo interface as can the
// destination. The destination rectangle we store is in window coordinates
// and is typically updated when the window is sized. We provide a callback
// OnPositionChanged that notifies the source when either of these changes

STDMETHODIMP COverlay::GetVideoPosition(RECT *pSourceRect,
                                        RECT *pDestinationRect)
{
    NOTE("Entering GetVideoPosition");
    CheckPointer(pSourceRect,E_POINTER);
    CheckPointer(pDestinationRect,E_POINTER);

    // Lock the overlay and renderer objects

    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);
    return GetVideoClipInfo(pSourceRect,pDestinationRect,NULL);
}


// When we create a new advise link we must prime the newly connected object
// with the overlay information which includes the clipping information, any
// palette information for the current connection and the video colour key
// When we are handed the IOverlayNotify interface we hold a reference count
// on that object so that it won't go away until the advise link is stopped

STDMETHODIMP COverlay::Advise(IOverlayNotify *pOverlayNotify,DWORD dwInterests)
{
    NOTE("Entering Advise");

    // Check the pointers provided are non NULL

    CheckPointer(pOverlayNotify,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);

    // Is there an advise link already defined

    if (m_pNotify) {
        NOTE("Advise link already set");
        return VFW_E_ADVISE_ALREADY_SET;
    }

    // Check they want at least one kind of notification

    if ((dwInterests & ADVISE_ALL) == 0) {
        NOTE("ADVISE_ALL failed");
        return E_INVALIDARG;
    }

    // Initialise our overlay notification state

    m_pNotify = pOverlayNotify;
    m_pNotify->AddRef();
    m_dwInterests = dwInterests;
    OnAdviseChange(TRUE);
    NotifyChange(ADVISE_ALL);
    return NOERROR;
}


// This is called when an advise link is installed or removed on the video
// renderer. If an advise link is being installed then the bAdviseAdded
// parameter is TRUE otherwise it is FALSE. We are only really interested
// when either we had a previous notification client or we are going to
// have no notification client as that starts and stops global hooking

BOOL COverlay::OnAdviseChange(BOOL bAdviseAdded)
{
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    NOTE("Entering OnAdviseChange");
    NOTE2("Advised %d Interests %d",bAdviseAdded,m_dwInterests);

    // We need to reset ourselves after closing the link

    if (bAdviseAdded == FALSE) {
        NOTE("Removing global window hook");
        PostMessage(hwnd,WM_UNHOOK,0,0);
        ResetColourKeyState();
        InstallPalette(NULL);
        m_pRenderer->m_VideoWindow.PaintWindow(TRUE);
    }

    // Do we need to stop any update timer

    if (bAdviseAdded == FALSE) {
        if (m_dwInterests & ADVISE_POSITION) {
            StopUpdateTimer();
            NOTE("Stopped timer");
        }
        return TRUE;
    }

    // Should we install a global hook

    if (m_dwInterests & ADVISE_CLIPPING) {
        NOTE("Requesting global hook");
        PostMessage(hwnd,WM_HOOK,0,0);
    }

    // Do we need to start an update timer

    if (m_dwInterests & ADVISE_POSITION) {
        StartUpdateTimer();
        NOTE("Started timer");
    }
    return TRUE;
}


// Close the advise link with the renderer. Remove the associated link with
// the source, we release the interface pointer the filter gave us during
// the advise link creation. This may be the last reference count held on
// that filter and cause it to be deleted NOTE we call OnAdviseChange so
// that the overlay state is updated which may stop the global message hook

STDMETHODIMP COverlay::Unadvise()
{
    NOTE("Entering Unadvise");
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);

    // Do we have an advise link setup

    if (m_pNotify == NULL) {
        return VFW_E_NO_ADVISE_SET;
    }



    // Release the notification interface

    m_pNotify->Release();
    m_pNotify = NULL;
    OnAdviseChange(FALSE);
    m_dwInterests = ADVISE_NONE;
    return NOERROR;
}


// Overriden to say what interfaces we support

STDMETHODIMP COverlay::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    NOTE("Entering NonDelegatingQueryInterface");

    // We return IOverlay and delegate everything else to the pin

    if (riid == IID_IOverlay) {
        return GetInterface((IOverlay *)this,ppv);
    }
    return m_pRenderer->m_InputPin.QueryInterface(riid,ppv);
}


// Overriden to increment the owning object's reference count

STDMETHODIMP_(ULONG) COverlay::NonDelegatingAddRef()
{
    NOTE("Entering NonDelegatingAddRef");
    return m_pRenderer->AddRef();
}


// Overriden to decrement the owning object's reference count

STDMETHODIMP_(ULONG) COverlay::NonDelegatingRelease()
{
    NOTE("Entering NonDelegatingRelease");
    return m_pRenderer->Release();
}


// This is called when we receive WM_PAINT messages in the window object. We
// always get first chance to handle these messages, if we have an IOverlay
// connection and the source has installed a colour key then we fill the
// window with it and return TRUE. Returning FALSE means we did not handle
// the paint message and someone else will have to do the default filling

BOOL COverlay::OnPaint()
{
    NOTE("Entering OnPaint");
    CAutoLock cAutoLock(this);
    RECT TargetRect;

    // If we receive a paint message and we are currently frozen then it's a
    // fair indication that somebody on top of us moved away without telling
    // us to thaw out. So start our video window and update any prospective
    // source filter with the clipping notifications. if we are currently
    // streaming then we do not repaint the window as it causes the window
    // to flash as another video frame will be displayed over it shortly

    m_pRenderer->m_Overlay.ThawVideo();
    if (m_bColourKey == FALSE) {
        NOTE("Handling no colour key defined");
        DWORD Mask = ADVISE_CLIPPING | ADVISE_POSITION;
        return (m_dwInterests & Mask ? TRUE : FALSE);
    }

    // Paint our colour key in the window

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    m_pRenderer->m_DrawVideo.GetTargetRect(&TargetRect);
    COLORREF BackColour = SetBkColor(hdc,m_WindowColour);
    ExtTextOut(hdc,0,0,ETO_OPAQUE,&TargetRect,NULL,0,NULL);
    SetBkColor(hdc,BackColour);

    return TRUE;
}


// Get the system palette we have currently realised. It is possible that a
// source filter may be interested in the current system palette. For example
// a hardware board could do on board conversion from true colour images that
// it produces during decompresses to the current system palette realised. We
// allocate the memory for the palette entries which the caller will release

STDMETHODIMP COverlay::GetPalette(DWORD *pdwColors,PALETTEENTRY **ppPalette)
{
    NOTE("Entering GetPalette");

    CheckPointer(pdwColors,E_POINTER);
    CheckPointer(ppPalette,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    CAutoLock cVideoLock(this);
    return GetDisplayPalette(pdwColors,ppPalette);
}


// This allocates memory for and retrieves the current system palette. This is
// called by the GetPalette interface function and also when we want to update
// any notification clients of a system palette change. In either case whoever
// calls this function is responsible for deleting the memory we allocate

HRESULT COverlay::GetDisplayPalette(DWORD *pColors,PALETTEENTRY **ppPalette)
{
    NOTE("Entering GetDisplayPalette");

    // Does the current display device setting use a palette

    const VIDEOINFO *pDisplay = m_pRenderer->m_Display.GetDisplayFormat();
    if (PALETTISED(pDisplay) == FALSE) {
        NOTE("No palette for this display");
        return VFW_E_NO_PALETTE_AVAILABLE;
    }

    // See how many entries the palette has

    *pColors = PALETTE_ENTRIES(pDisplay);
    ASSERT(*pColors);

    // Allocate the memory for the system palette NOTE because the memory for
    // the palette is being passed over an interface to another object which
    // may or may not have been written in C++ we must use CoTaskMemAlloc

    *ppPalette = (PALETTEENTRY *) QzTaskMemAlloc(*pColors * sizeof(RGBQUAD));
    if (*ppPalette == NULL) {
        NOTE("No memory");
        *pColors = FALSE;
        return E_OUTOFMEMORY;
    }

    // Get the system palette using the window's device context

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    UINT uiReturn = GetSystemPaletteEntries(hdc,0,*pColors,*ppPalette);
    ASSERT(uiReturn == *pColors);

    return NOERROR;
}


// A source filter may want to install their own palette into the video window
// Before allowing them to do so we must ensure this is a palettised display
// device, that we don't have a media sample connection (which would install
// it's own palette and therefore conflict) and also that there is no colour
// key selected which also requires a special palette to be installed

HRESULT COverlay::CheckSetPalette(DWORD dwColors,PALETTEENTRY *pPaletteColors)
{
    NOTE("Entering CheckSetPalette");
    const VIDEOINFO *pDisplay;

    // Check overlay calls are allowed

    HRESULT hr = ValidateOverlayCall();
    if (FAILED(hr)) {
        return hr;
    }

    // Is the display set to use a palette

    pDisplay = (VIDEOINFO *) m_pRenderer->m_Display.GetDisplayFormat();
    if (PALETTISED(pDisplay) == FALSE) {
        NOTE("No palette for this display");
        return VFW_E_NO_DISPLAY_PALETTE;
    }

    // Check the number of colours makes sense

    if (dwColors > PALETTE_ENTRIES(pDisplay)) {
        NOTE("Too many palette colours");
        return VFW_E_TOO_MANY_COLORS;
    }

    // Are we using an overlay colour key - another alternative would be to
    // disregard the colour key palette and install the new one over the top
    // However it is probably more intuitive to make them remove the key

    if (m_bColourKey == TRUE) {
        NOTE("Colour key conflict");
        return VFW_E_COLOR_KEY_SET;
    }
    return NOERROR;
}


// A source filter may want to install it's own palette, for example an MPEG
// decoder may send palette information in a private bit stream and use that
// to dither on palettised displays. This function lets them install their
// LOGICAL palette, which is to say we create a logical palette from their
// colour selection and install it in our video window. If they want to know
// which of those colours and available they can query using GetPalette

STDMETHODIMP COverlay::SetPalette(DWORD dwColors,PALETTEENTRY *pPaletteColors)
{
    NOTE("Entering SetPalette");

    CAutoLock cInterfaceLock(m_pInterfaceLock);

    {
        CAutoLock cVideoLock(this);
        HPALETTE hPalette = NULL;

        // Make sure we can set a palette

        HRESULT hr = CheckSetPalette(dwColors,pPaletteColors);
        if (FAILED(hr)) {
            return hr;
        }

        // Creates a palette or just returns NULL if we are removing it

        hPalette = MakePalette(dwColors,pPaletteColors);
        InstallPalette(hPalette);
    }

    // The overlay object's lock cannot be held when calling 
    // CBaseWindow::PaintWindow() because this thread and the 
    // window thread could deadlock.
    m_pRenderer->m_VideoWindow.PaintWindow(TRUE);
    return NOERROR;
}


// This is called when we have been asked to install a custom colour palette
// for the source overlay filter. We copy the palette colours provided into
// a LOGPALETTE structure and then hand it to GDI for creation. If an error
// occurs we return NULL which we also do if they are setting no palette

HPALETTE COverlay::MakePalette(DWORD dwColors,PALETTEENTRY *pPaletteColors)
{
    NOTE("Entering MakePalette");
    LOGPALETTE *pPalette;
    HPALETTE hPalette;

    // Are we removing an installed palette - the source filter is forced to
    // do this if during processing (after installing a palette) it decides
    // it would like to use a colour key after all (also uses a palette)

    if (dwColors == 0 || pPaletteColors == NULL) {
        return NULL;
    }

    // We have to create a LOGPALETTE structure with the palette information
    // but rather than hassle around figuring out how much memory we really
    // need take a brute force approach and allocate the maximum possible

    pPalette = (LOGPALETTE *) new BYTE[sizeof(LOGPALETTE) + SIZE_PALETTE];
    if (pPalette == NULL) {
        NOTE("No memory");
        return NULL;
    }

    // Setup the version and the colour information

    pPalette->palVersion = PALVERSION;
    pPalette->palNumEntries = (WORD) dwColors;

    CopyMemory((PVOID) pPalette->palPalEntry,
               (PVOID) pPaletteColors,
               dwColors * sizeof(PALETTEENTRY));

    // Create the palette and delete the memory we allocated

    hPalette = CreatePalette(pPalette);
    delete[] pPalette;
    return hPalette;
}


// This is called when somebody detects a change in one or more of the states
// we keep our clients informed about, for example somebody realising their
// palette and therefore changing the system palette. The AdviseChanges field
// determines which of the four types of notification states has changed and
// the bPrimeOnly is TRUE when we want to just prime those new advise links
// If we are notifying the source of clip changes then we will be called via
// an interthread SendMessage to our window procedure by a global window hook

HRESULT COverlay::NotifyChange(DWORD AdviseChanges)
{
    NOTE1("Entering NotifyChange (%d)",AdviseChanges);

    RGNDATA *pRgnData = NULL;       // Contains clipping information
    PALETTEENTRY *pPalette = NULL;  // Pointer to list of colours
    DWORD dwColours;                // Number of palette colours
    COLORKEY ColourKey;             // The windows overlay colour
    RECT SourceRect;                // Section of video to use
    RECT DestinationRect;           // Where video is on the screen
    HRESULT hr = NOERROR;           // General OLE return code

    CAutoLock cVideoLock(this);

    // Is there a notification client

    if (m_pNotify == NULL) {
        NOTE("No client");
        return NOERROR;
    }

    // Do they want to know when the video rectangles change. These callbacks
    // do not occur in sync with the window moving like they do with the clip
    // changes, essentially we pass on information as we receive WM_MOVE etc
    // window messages. This is suitable for overlay cards that don't write
    // directly into the display and so don't mind being a little out of step

    if (AdviseChanges & ADVISE_POSITION & m_dwInterests) {
        hr = GetVideoClipInfo(&SourceRect,&DestinationRect,NULL);
        if (SUCCEEDED(hr)) {
            m_pNotify->OnPositionChange(&SourceRect,&DestinationRect);
            m_TargetRect = DestinationRect;
            NOTERC("Update destination",DestinationRect);
        }
    }

    // Do they want window clipping notifications, this is used by filters
    // doing direct inlay frame buffer video who want to know the actual
    // window clipping information which defines the video placement NOTE
    // ignore clipping changes while we are frozen as they cannot start
    // displaying video while the window size or position is changing

    if (AdviseChanges & ADVISE_CLIPPING & m_dwInterests) {
        hr = GetVideoClipInfo(&SourceRect,&DestinationRect,&pRgnData);
        if (SUCCEEDED(hr)) {
            m_pNotify->OnClipChange(&SourceRect,
                                    &DestinationRect,
                                    pRgnData);
        }
    }

    // Do they want system palette changes, it is possible that a filter
    // using a colour key to do overlay video will want to select it's
    // colour on a palettised display by choosing one from the current
    // system palette in which case it will be interested in this call

    if (AdviseChanges & ADVISE_PALETTE & m_dwInterests) {
        hr = GetDisplayPalette(&dwColours,&pPalette);
        if (SUCCEEDED(hr)) {
            m_pNotify->OnPaletteChange(dwColours,pPalette);
        }
    }

    // Do they want overlay colour key changes, this is the simplest form
    // of direct frame buffer video where a filter uses a colour key to
    // spot where it should be displaying it's video. Most cards that
    // use this also want to know the video window bounding rectangle

    if (AdviseChanges & ADVISE_COLORKEY & m_dwInterests) {
        hr = GetWindowColourKey(&ColourKey);
        if (SUCCEEDED(hr)) {
            m_pNotify->OnColorKeyChange(&ColourKey);
        }
    }

    // Release the memory allocated

    QzTaskMemFree(pRgnData);
    QzTaskMemFree(pPalette);
    return NOERROR;
}


// This is called when we need to temporarily freeze the video, for example
// when the window size is being changed (ie the clipping area is changing)
// We send the attached notification interface a clip change message where
// the new clipping area is a NULL set of rectangles. When the glitch ends
// our ThawVideo method will be called so we can reset the window clip list

HRESULT COverlay::FreezeVideo()
{
    static RECT Empty = {0,0,0,0};
    NOTE("Entering FreezeVideo");
    RGNDATAHEADER RgnData;
    CAutoLock cVideoLock(this);

    // Have we already been frozen or do we have no link

    if (m_bFrozen == TRUE || m_pNotify == NULL) {
        NOTE("No freeze");
        return NOERROR;
    }

    // Is the advise link interested in clip changes

    if ((m_dwInterests & ADVISE_CLIPPING) == 0) {
        NOTE("No ADVISE_CLIPPING");
        return NOERROR;
    }

    // Simulate a NULL clipping area for the video

    RgnData.dwSize = sizeof(RGNDATAHEADER);
    RgnData.iType = RDH_RECTANGLES;
    RgnData.nCount = 0;
    RgnData.nRgnSize = 0;
    SetRectEmpty(&RgnData.rcBound);
    m_bFrozen = TRUE;

    return m_pNotify->OnClipChange(&Empty,&Empty,(RGNDATA *)&RgnData);
}


// See if the video is currently frozen

BOOL COverlay::IsVideoFrozen()
{
    NOTE("Entering IsVideoFrozen");
    CAutoLock cVideoLock(this);
    return m_bFrozen;
}


// This is called after the video window has been temporarily frozen such as
// during the window size being changed. All we have to do is reset the flag
// and have each notification interface called with the real clipping list
// If a source filter set it's advise link when the video window was frozen
// then this will be the first time it will receive any clipping messages
// NOTE we found with some experimentation that we should always thaw the
// video when this method is called (normally via our WM_PAINT processing)
// regardless of whether or not we think that the video is currently stopped

HRESULT COverlay::ThawVideo()
{
    NOTE("Entering ThawVideo");
    CAutoLock cVideoLock(this);

    // Are we already thawed
    if (m_bFrozen == FALSE) {
        NOTE("No thaw");
        return NOERROR;
    }

    m_bFrozen = FALSE;
    NotifyChange(ADVISE_CLIPPING);
    return NOERROR;
}


// Return the window handle we are using. We don't do the usual checks when
// an IOverlay method is called as we always make the handle available. The
// reason being so that the MCI driver can get a hold of it by enumerating
// the pins on the renderer, calling QueryInterface for IOverlay and then
// calling this GetWindowHandle. This does mean that many other applications
// could do this but hopefully they will use the IVideoWindow to control us

STDMETHODIMP COverlay::GetWindowHandle(HWND *pHwnd)
{
    NOTE("Entering GetWindowHandle");
    CheckPointer(pHwnd,E_POINTER);
    *pHwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    return NOERROR;
}


// If the source filter using IOverlay is looking for ADVISE_POSITION changes
// then we set an update timer. Each time it fires we get the current target
// rectangle and if it has changed we update the source. We cannot guarantee
// receieving WM_MOVE messages to do this as we may be a child window. We use
// a timer identifier of INFINITE which our DirectDraw code also uses as times

void COverlay::StartUpdateTimer()
{
    NOTE("Entering StartUpdateTimer");
    CAutoLock cVideoLock(this);

    // Start a timer with INFINITE as its identifier
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(SetTimer(hwnd,INFINITE,200,NULL));
}


// Complements StartUpdateTimer, will be called when a source filter calls us
// to stop an advise link with ADVISE_POSITION. We just kill the timer. If we
// get any WM_TIMER messages being fired late they will just be ignored. The
// timer is set with a period of 200 milliseconds and as mentioned before the
// ADVISE_POSITION is only suitable for deferred window update notifications

void COverlay::StopUpdateTimer()
{
    NOTE("Entering StopUpdateTimer");
    CAutoLock cVideoLock(this);
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(KillTimer(hwnd,INFINITE));
}


// Called when we get a WM_TIMER during an overlay transport connection. We
// look at the current destination rectangle and if it has changed then we
// update the source filter. The process of updating the source overlay also
// brings m_TargetRect upto date. We share a timer with our DirectDraw code
// but the two can never be used at the same time and so this should be safe

BOOL COverlay::OnUpdateTimer()
{
    NOTE("Entering OnUpdateTimer");
    CAutoLock cVideoLock(this);
    RECT SourceRect, TargetRect;

    // Is there a notification client

    if (m_pNotify == NULL) {
        NOTE("No client");
        return NOERROR;
    }

    // Do they want to know when the video rectangles change. These callbacks
    // do not occur in sync with the window moving like they do with the clip
    // changes, essentially we pass on information as we receive WM_MOVE etc
    // window messages. This is suitable for overlay cards that don't write
    // directly into the display and so don't mind being a little out of step

    if (m_dwInterests & ADVISE_POSITION) {

        HRESULT hr = GetVideoClipInfo(&SourceRect,&TargetRect,NULL);
        if (FAILED(hr)) {
            return FALSE;
        }

        // Only update when something changes unknown to us

        if (EqualRect(&m_TargetRect,&TargetRect) == TRUE) {
            NOTE("Rectangles match");
            return TRUE;
        }
        NotifyChange(ADVISE_POSITION);
    }
    return TRUE;
}


// When we have an ADVISE_CLIPPING advise link setup we cannot install hooks
// on that thread as it may go away later on and take the hook along with it
// Therefore we post a custom message (WM_HOOK and WM_UNHOOK) to our window
// which will then call us back here to do the real dirty work. We can't do
// a SendMessage as it would violate the lock hierachy for the overlay object

void COverlay::OnHookMessage(BOOL bHook)
{
    NOTE1("OnHookMessage called (%d)",bHook);
    if (m_pRenderer->m_VideoWindow.WindowExists()) {
        HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
        CAutoLock cVideoLock(this);

        if (bHook == TRUE) {
            NOTE("Installing global hook");
            m_hHook = InstallGlobalHook(hwnd);
            NOTE("Installed global hook");
            NotifyChange(ADVISE_ALL);
        } else {
            if (m_hHook) RemoveGlobalHook(hwnd,m_hHook);
            m_hHook = NULL;
            NOTE("Removed global hook");
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\allocate.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements the CVideoAllocator class, Anthony Phillips, January 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>

// This implements a DCI/DirectDraw enabled allocator along with a specialised
// sample class that it uses. We override Free and Alloc to allocate surfaces
// based on DCI and DirectDraw. The majority of the work is done in GetBuffer
// where we dynamically switch the source between buffer types. When and where
// we switch types depends on the surface being used, the state the filter is
// in and the current environment. For example primary surfaces are not used
// when we are paused however overlays are. If the window is complex clipped
// then we don't use primary surfaces but we can use overlays when there is a
// colour key available (some of this policy is decided by the direct object)


// Constructor must initialise the base image allocator

CVideoAllocator::CVideoAllocator(CRenderer *pRenderer,      // Main renderer
                                 CDirectDraw *pDirectDraw,  // DirectDraw code
                                 CCritSec *pLock,           // Object to lock
                                 HRESULT *phr) :            // Return code

    CImageAllocator(pRenderer,NAME("Video Allocator"),phr),
    m_pDirectDraw(pDirectDraw),
    m_pRenderer(pRenderer),
    m_pInterfaceLock(pLock),
    m_bDirectDrawStatus(FALSE),
    m_bDirectDrawAvailable(FALSE),
    m_pMediaSample(NULL),
    m_bPrimarySurface(FALSE),
    m_bVideoSizeChanged(TRUE),
    m_fWasOnWrongMonitor(FALSE),
    m_fForcePrepareForMultiMonitorHack(FALSE),
    m_bNoDirectDraw(FALSE)
{
    ASSERT(pDirectDraw);
    ASSERT(m_pInterfaceLock);
    ASSERT(m_pRenderer);
}


// Check our DIB buffers and DirectDraw surfaces have been released

CVideoAllocator::~CVideoAllocator()
{
    ASSERT(m_bCommitted == FALSE);
}


// Called from destructor and also from base class to free resources. We must
// NOT reset the m_bDirectDrawStatus flag here because the current DirectDraw
// state is persistent across any state changes. Therefore when we next give
// out a buffer we will carry on as usual, and more importantly if we cannot
// offer a DirectDraw buffer we will make sure we change the output type back

void CVideoAllocator::Free()
{
    NOTE("Entering Free resources");

    // Reset our DirectDraw state

    m_pDirectDraw->ReleaseSurfaces();
    m_pDirectDraw->StopRefreshTimer();
    m_bDirectDrawAvailable = FALSE;
    m_bPrimarySurface = FALSE;
    m_bVideoSizeChanged = TRUE;

    CImageAllocator::Free();
}


// Overriden to allocate DirectDraw resources

HRESULT CVideoAllocator::Alloc(void)
{
    NOTE("Allocating video resources");

    // Check we don't have an overlay connection

    if (*m_pRenderer->m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Allocate samples for overlay");
        return VFW_E_NOT_SAMPLE_CONNECTION;
    }

    // Check the base allocator says it's ok to continue

    HRESULT hr = CImageAllocator::Alloc();
    if (FAILED(hr)) {
        return hr;
    }
    return InitDirectAccess(&m_pRenderer->m_mtIn);
}


// The base CImageAllocator class calls this virtual method to actually make
// the samples. It is deliberately virtual so that we can override to create
// more specialised sample objects. On our case our samples are derived from
// CImageSample but add the DirectDraw guff. We return a CImageSample object
// which is easy enough because the CVideoSample class is derived from that

CImageSample *CVideoAllocator::CreateImageSample(LPBYTE pData,LONG Length)
{
    HRESULT hr = NOERROR;
    CVideoSample *pSample;
    NOTE("Creating sample");

    // Allocate the new sample and check the return codes

    pSample = new CVideoSample((CImageAllocator*) this,    // Base allocator
                               NAME("Video sample"),       // DEBUG name
                               (HRESULT *) &hr,            // Return code
                               (LPBYTE) pData,             // DIB address
                               (LONG) Length);             // Size of DIB

    if (pSample == NULL || FAILED(hr)) {
        delete pSample;
        return NULL;
    }
    return pSample;
}


// This is called when we go active (paused or running). We have negotiated a
// media type to use which may or may not have direct DCI/DirectDraw surface
// support. The connection phase looks after trying to agree a type that does
// have hardware accelleration. So when we get here we try and get hold of a
// surface, if there isn't one then we will render using DIBSECTION buffers

HRESULT CVideoAllocator::InitDirectAccess(CMediaType *pmtIn)
{
    ASSERT(m_pRenderer->m_InputPin.IsConnected() == TRUE);
    ASSERT(m_bDirectDrawAvailable == FALSE);
    ASSERT(m_bPrimarySurface == FALSE);
    NOTE("Initialising DCI/DirectDraw");

    if (m_bNoDirectDraw) {
        m_bDirectDrawAvailable = FALSE;
        return NOERROR;
    }

    // We use the connected output pin to query media types

    IPin *pOutputPin = m_pRenderer->m_InputPin.GetConnected();
    if (m_lCount == 1) {
        if (FindSpeedyType(pOutputPin) == TRUE) {
            NOTE("Found DCI/DirectDraw surface");
            m_bDirectDrawAvailable = TRUE;
        }
    }
    return NOERROR;
}


// This is passed a media type from QueryAccept. We return TRUE if it matches
// the current output surface format, otherwise FALSE.

BOOL CVideoAllocator::IsSurfaceFormat(const CMediaType *pmtIn)
{
    NOTE("IsSurfaceFormat");
    CAutoLock cVideoLock(this);

    // Do we have any surfaces available at all

    if (m_bDirectDrawAvailable == FALSE) {
        NOTE("No surface");
        return FALSE;
    }

    // Compare against the current output format

    CMediaType *pmtOut = m_pDirectDraw->GetSurfaceFormat();
    if (*pmtOut == *pmtIn) {
        NOTE("Matches surface");
        return TRUE;
    }
    return FALSE;
}


// Asks if we have a sample waiting to be scheduled

BOOL CVideoAllocator::IsSamplePending()
{
    NOTE("Entering SamplePending");
    CAutoLock cVideoLock(this);

    // Do we have a sample waiting

    if (m_pMediaSample == NULL) {
        NOTE("No current sample");
        return FALSE;
    }
    return TRUE;
}


// If we schedule the sample before returning the buffer (like overlays and
// primary surfaces) then when we pause the source will decode an image, it
// then calls GetBuffer again where it will be blocked in WaitForRenderTime
// When we start running we can't just release the thread because the next
// image will appear immediately. Therefore we take the pending sample that
// is registered in GetBuffer and send it through the scheduling code again

HRESULT CVideoAllocator::StartStreaming()
{
    CAutoLock cVideoLock(this);
    if (m_pMediaSample == NULL) {
        NOTE("No run sample");
        return NOERROR;
    }

    // Schedule the sample for subsequent release

    if (m_pRenderer->ScheduleSample(m_pMediaSample) == FALSE) {
        ASSERT(m_pRenderer->CancelNotification() == S_FALSE);
        NOTE("First image scheduled is VFW_E_SAMPLE_REJECTED");
        m_pRenderer->GetRenderEvent()->Set();
    }
    return NOERROR;
}


// This overrides the IMemAllocator GetBuffer interface function. We return
// standard DIBSECTION and DCI/DirectDraw buffers. We manage switching the
// source filter between surface types and the synchronisation required for
// surfaces where the filling is effectively the drawing (examples include
// primary and overlay surfaces). We cannot return DCI/DirectDraw buffers
// if either of the time stamps are NULL as we use them for synchronisation

STDMETHODIMP CVideoAllocator::GetBuffer(IMediaSample **ppSample,
                                        REFERENCE_TIME *pStartTime,
                                        REFERENCE_TIME *pEndTime,
                                        DWORD dwFlags)
{
    CheckPointer(ppSample,E_POINTER);
    BOOL bWaitForDraw = FALSE;
    HRESULT hr = NOERROR;

    //NOTE("CVideoAllocator::GetBuffer");

    // We always need a buffer to start with if only to synchronise correctly
    // By enforcing DCI/DirectDraw access with connections that have a single
    // buffer we know we won't be doing any of this when the source still has
    // a buffer waiting to be drawn along our normal software draw code path

    hr = CBaseAllocator::GetBuffer(ppSample,pStartTime,pEndTime,dwFlags);
    if (hr != NOERROR) {
        //NOTE("BASE CLASS ERROR!");
        return hr;
    }

    // If we have allocated and are using a sync on fill surface then we set
    // a timer notification before the WaitForDrawTime call. After the wait
    // we may find we can no longer use the surface but that is unavoidable
    // the alternative would be to check the surface format before and after
    // the wait which would double our cost since we must check clipping etc

    {
        CAutoLock cInterfaceLock(m_pInterfaceLock);
        CAutoLock cVideoLock(this);

    // !!! FULLSCREEN PLAYBACK ON MULTIMON IS HOSED - wrong monitor, wrong colours,
    //     and it hangs

        // We are not on the monitor we are using h/w acceleration for (on
        // a multi-monitor system) so BAD things happen if we try to use
        // DDraw.

        INT_PTR ID;
        if (m_pRenderer->IsWindowOnWrongMonitor(&ID)) {

            m_fWasOnWrongMonitor = TRUE;

            // We know now that we are at least partially on a monitor other
            // than the one we're using hardware for
            //
            // ID == 0 means we are spanning monitors and we should fall back
            // to software
            // ID != 0 means we are wholly on another monitor and should start
            // using h/w for that monitor

            // InterlockedExchange() does not work on multiprocessor x86 systems and on non-x86
            // systems if m_pRenderer->m_fDisplayChangePosted is not aligned on a 32 bit boundary.
            ASSERT((DWORD_PTR)&m_pRenderer->m_fDisplayChangePosted == ((DWORD_PTR)&m_pRenderer->m_fDisplayChangePosted & ~3));
            
            // The video renderer only wants to send one WM_DISPLAYCHANGE message when 
            // the window is being moved to a new monitor.  Performance suffers if the
            // video renderer sends multiple WM_DISPLAYCHANGE messages.
            if (ID && !InterlockedExchange(&m_pRenderer->m_fDisplayChangePosted,TRUE)) {

                DbgLog((LOG_TRACE,3,TEXT("Window is on a DIFFERENT MONITOR!")));
                DbgLog((LOG_TRACE,3,TEXT("Reset the world!")));
                PostMessage(m_pRenderer->m_VideoWindow.GetWindowHWND(),
                            WM_DISPLAYCHANGE, 0, 0);
            }

            if (m_bDirectDrawStatus) {

                DbgLog((LOG_TRACE,3,TEXT("Window is on the WRONG MONITOR!")));
                DbgLog((LOG_TRACE,3,TEXT("Falling back to software")));

                if (StopUsingDirectDraw(ppSample,dwFlags) == FALSE) {
                    ASSERT(*ppSample == NULL);
                    DbgLog((LOG_ERROR,1,TEXT("*** Could not STOP!")));
                    NOTE("Could not reset format");
                    return VFW_E_CHANGING_FORMAT;
                }
            }

            return NOERROR;
        }

        // Last time we were on the wrong monitor.  Now we aren't.  We should
        // try and get DirectDraw back now!
        if (m_fWasOnWrongMonitor) {
            m_fForcePrepareForMultiMonitorHack = TRUE;
        }
        m_fWasOnWrongMonitor = FALSE;

        // DirectDraw can only be used if the time stamps are valid. A source
        // may call us with NULL time stamps when it wants to switch back to
        // DIBs. It could do this if it wants to make a palette change. The
        // next time the source sends valid time stamps we will make sure it
        // gets back into using the surface by marking the status as changed

	// NOTE, though, that we only really need time stamps if we're doing
	// sync on fill (overlay w/o flipping or primary surface)

        if ((pStartTime == NULL || pEndTime == NULL) &&
        			m_bDirectDrawStatus == TRUE &&
				m_pDirectDraw->SyncOnFill() == TRUE) {
            //NOTE("*** NO TIME STAMPS!");
            if (StopUsingDirectDraw(ppSample,dwFlags) == FALSE) {
                ASSERT(*ppSample == NULL);
                NOTE("Could not reset format");
		//DbgLog((LOG_ERROR,1,TEXT("*** NULL TIME STAMPS!")));
                return VFW_E_CHANGING_FORMAT;
            }
            return NOERROR;
        }

        // Have the sample scheduled if we wait before the fill. If we are in
        // a paused state then we do not schedule the sample for drawing but
        // we must only return a buffer if we are still waiting for the first
        // one through. Otherwise we stall the source filter thread by making
        // it sit in WaitForDrawTime without an advise time set on the clock

        if (m_bDirectDrawStatus == TRUE) {
            if (m_pDirectDraw->SyncOnFill() == TRUE) {
                bWaitForDraw = m_pRenderer->CheckReady();
                if (m_pRenderer->GetRealState() == State_Running) {
                    (*ppSample)->SetDiscontinuity((dwFlags & AM_GBF_PREVFRAMESKIPPED) != 0);
                    (*ppSample)->SetTime(pStartTime,pEndTime);
                    bWaitForDraw = m_pRenderer->ScheduleSample(*ppSample);
                    (*ppSample)->SetDiscontinuity(FALSE);
                    (*ppSample)->SetTime(NULL,NULL);
                }
            }
        }

        // Store the interface if we wait

        if (bWaitForDraw == TRUE) {
            NOTE("Registering sample");
            m_pMediaSample = (*ppSample);
        }
    }

    // Have the sample scheduled for drawing, if the scheduling decides we
    // should drop this image there is little we can do about it. We can't
    // return S_FALSE as it will never send more data to us. Therefore all
    // we can do is decode it and wait for the quality management to start

    if (bWaitForDraw == TRUE) {
        hr = m_pRenderer->WaitForRenderTime();
    }

    // We must wait for the rendering time without the objects locked so that
    // state changes can get in and release us in WaitForRenderTime. After we
    // return we must relock the objects. If we find the surface unavailable
    // then we must switch back to DIBs. Alternatively we may find that while
    // we are using DIBs now that we can switch into a DCI/DirectDraw buffer

    {
        CAutoLock cInterfaceLock(m_pInterfaceLock);
        CAutoLock cVideoLock(this);
        m_pMediaSample = NULL;

        // Did the state change while waiting

        if (hr == VFW_E_STATE_CHANGED) {
            NOTE("State has changed");
            (*ppSample)->Release();
            *ppSample = NULL;
            return VFW_E_STATE_CHANGED;
        }

        // Check they are still ok with the current environment

        if (PrepareDirectDraw(*ppSample,dwFlags,
                m_fForcePrepareForMultiMonitorHack) == TRUE) {
            m_fForcePrepareForMultiMonitorHack = FALSE;
            if (m_pDirectDraw->InitVideoSample(*ppSample,dwFlags) == TRUE) {
                NOTE("In direct mode");
                return NOERROR;
            }
        }

        // Switch the source filter away from DirectDraw

        if (StopUsingDirectDraw(ppSample,dwFlags) == FALSE) {
            NOTE("Failed to switch back");
            ASSERT(*ppSample == NULL);
	    //DbgLog((LOG_ERROR,1,TEXT("*** GET BUFFER PROBLEM")));
            return VFW_E_CHANGING_FORMAT;
        }
        return NOERROR;
    }
}


// This is called when we have determined the source filter can stretch their
// video according to the media passed passed in. We swap the current format
// with the main renderer and then create a new DIBSECTION for the sample. If
// anything fails it is hard to back out so we just abort playback completely
// The new buffer format must also be attached to the sample for the codec to
// process. The samples we supply allow the buffer and its size to be changed

BOOL CVideoAllocator::UpdateImage(IMediaSample **ppSample,CMediaType *pBuffer)
{
    NOTE("Entering UpdateImage");
    DIBDATA *pOriginal,Updated;
    m_pRenderer->m_mtIn = *pBuffer;

    // Update the buffer size held by the allocator

    BITMAPINFOHEADER *pHeader = HEADER(pBuffer->Format());
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pBuffer->Format();
    CVideoSample *pVideoSample = (CVideoSample *) *ppSample;
    m_lSize = pVideoInfo->bmiHeader.biSizeImage;

    // Create the updated DIB with the new dimensions

    HRESULT hr = CreateDIB(m_lSize,Updated);
    if (FAILED(hr)) {
        pVideoSample->Release();
        (*ppSample) = NULL;
        return FALSE;
    }

    // Swap over to the updated DIBSECTION resource

    pOriginal = pVideoSample->GetDIBData();
    EXECUTE_ASSERT(DeleteObject(pOriginal->hBitmap));
    EXECUTE_ASSERT(CloseHandle(pOriginal->hMapping));
    pVideoSample->SetDIBData(&Updated);
    pVideoSample->SetMediaType(pBuffer);
    pVideoSample->UpdateBuffer(m_lSize,Updated.pBase);
    NOTE("Stretching video to match window");

    return TRUE;
}


// When the window becomes stretched we would normally use GDI to stretch the
// video to match it. However the source filter codec may be able to stretch
// the video which may be much more efficient. Also, if the current video GDI
// format is palettised then the codec may also be able to stretch before the
// dithering rather than us stretch the already dithering image which is ugly

BOOL CVideoAllocator::MatchWindowSize(IMediaSample **ppSample,DWORD dwFlags)
{
    CVideoWindow *pVideoWindow = &m_pRenderer->m_VideoWindow;
    ASSERT(m_bDirectDrawStatus == FALSE);
    NOTE("Entering MatchWindowSize");
    RECT TargetRect;

    // Try to change only on a key frame

    if (dwFlags & AM_GBF_NOTASYNCPOINT) {
        NOTE("AM_GBF_NOTASYNCPOINT");
        return TRUE;
    }

    // Is it a typical video decoder

    if (m_lCount > 1) {
        NOTE("Too many buffers");
        return TRUE;
    }

    // Has the video size changed

    if (m_bVideoSizeChanged == FALSE) {
        NOTE("No video change");
        return TRUE;
    }

    // Check we are using the default source rectangle

    if (pVideoWindow->IsDefaultSourceRect() == S_FALSE) {
        NOTE("Not default source");
        return TRUE;
    }

    // Only do this if the destination looks reasonably normal

    pVideoWindow->GetTargetRect(&TargetRect);
    if (WIDTH(&TargetRect) < 32 || HEIGHT(&TargetRect) < 32) {
        NOTE("Target odd shape");
        return TRUE;
    }

    // Does the target rectangle match the current format

    BITMAPINFOHEADER *pInputHeader;
    pInputHeader = HEADER(m_pRenderer->m_mtIn.Format());
    m_bVideoSizeChanged = FALSE;

    if (pInputHeader->biWidth == WIDTH(&TargetRect)) {
        if (pInputHeader->biHeight == HEIGHT(&TargetRect)) {
            NOTE("Sizes match");
            return TRUE;
        }
    }

    // Create an output format based on the current target

    CMediaType Buffer = m_pRenderer->m_mtIn;
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) Buffer.Format();
    pVideoInfo->bmiHeader.biWidth = WIDTH(&TargetRect);
    pVideoInfo->bmiHeader.biHeight = HEIGHT(&TargetRect);
    pVideoInfo->bmiHeader.biSizeImage = GetBitmapSize(HEADER(pVideoInfo));

    NOTE("Asking source filter to stretch");
    NOTE1("Width (%d)",pVideoInfo->bmiHeader.biWidth);
    NOTE1("Height (%d)",pVideoInfo->bmiHeader.biHeight);
    NOTE1("Depth (%d)",pVideoInfo->bmiHeader.biBitCount);

    // Will the source filter do the stretching

    if (QueryAcceptOnPeer(&Buffer) != S_OK) {
        NOTE("Rejected");
        return TRUE;
    }
    return UpdateImage(ppSample,&Buffer);
}


// Called to switch back to using normal DIBSECTION buffers. We may be called
// when we are not using DirectDraw anyway in which case we do nothing except
// setting the type back to NULL (just in case it has a DirectDraw type). If
// the type has to be changed back then we do not query it with the source as
// it should always accept it - even if when changed it has to seek forwards

BOOL CVideoAllocator::StopUsingDirectDraw(IMediaSample **ppSample,DWORD dwFlags)
{
    NOTE("Entering StopUsingDirectDraw");
    IMediaSample *pSample = (*ppSample);

    // Is there anything to do

    if (m_bDirectDrawStatus == FALSE) {
        pSample->SetMediaType(NULL);
        NOTE("Matching window size");
        return MatchWindowSize(ppSample,dwFlags);
    }

    DbgLog((LOG_TRACE,3,TEXT("StopUsingDirectDraw")));

    // Hide any overlay surface we have

    m_pDirectDraw->HideOverlaySurface();
    m_bDirectDrawStatus = FALSE;
    pSample->SetMediaType(&m_pRenderer->m_mtIn);
    pSample->SetDiscontinuity(TRUE);
    NOTE("Attached original output format");

    return MatchWindowSize(ppSample,dwFlags);
}


// Called when the GetBuffer wants to know if we can return something better
// than the normal run of the mill media sample. We see that DCI/DirectDraw
// is available and if so ensure the source can handle the clipping and/or
// stretching requirements. If we're being transitioned into paused then we
// return a DIB buffer if we are using the primary surface as there is no
// advantage to using surfaces and we may end up doing pointless EC_REPAINTs

BOOL CVideoAllocator::PrepareDirectDraw(IMediaSample *pSample,DWORD dwFlags,
                    BOOL fForcePrepareForMultiMonitorHack)
{
    FILTER_STATE State = m_pRenderer->GetRealState();
    NOTE("Entering PrepareDirectDraw");
    CMediaType *pSurface;
    BOOL bFormatChanged;

    // Do we have any surfaces available at all

    if (m_bDirectDrawAvailable == FALSE) {
        return FALSE;
    }

    // Can only switch on a key frame

    if (m_bDirectDrawStatus == FALSE) {
        if (dwFlags & AM_GBF_NOTASYNCPOINT) {
            NOTE("AM_GBF_NOTASYNCPOINT");
            return FALSE;
        }
    }

    // Is it worth returning a DirectDraw surface buffer

    if (State == State_Paused) {
        if (m_pDirectDraw->AvailableWhenPaused() == FALSE) {
            NOTE("Paused block");
            return FALSE;
        }
    }

    // Check we can still get an output surface format

    pSurface = m_pDirectDraw->UpdateSurface(bFormatChanged);
    if (pSurface == NULL) {
        NOTE("No format");
        return FALSE;
    }

    // Has the format changed from last time

    if (bFormatChanged == FALSE && !fForcePrepareForMultiMonitorHack) {
        NOTE("Format is unchanged");
        return m_bDirectDrawStatus;
    }

    // Query the format with the source

    if (QueryAcceptOnPeer(pSurface) != S_OK) {
        NOTE("Query failed");
        return FALSE;
    }

    DbgLog((LOG_TRACE,3,TEXT("Start using DirectDraw")));

    NOTE("Attaching DCI/DD format");
    pSample->SetMediaType(pSurface);
    pSample->SetDiscontinuity(TRUE);
    m_bDirectDrawStatus = TRUE;

    return TRUE;
}


// Check this media type is acceptable to our input pin. All we do is to call
// QueryAccept on the source's output pin. To get this far we have locked the
// object so there should be no way for our pin to have become disconnected

HRESULT CVideoAllocator::QueryAcceptOnPeer(CMediaType *pMediaType)
{
    DisplayType(TEXT("Proposing output type"),pMediaType);
    IPin *pPin = m_pRenderer->m_InputPin.GetPeerPin();
    ASSERT(m_pRenderer->m_InputPin.IsConnected() == TRUE);
    return pPin->QueryAccept(pMediaType);
}


// Called when we get our DCI/DirectDraw sample delivered, we return TRUE to
// say this is a DCI/DirectDraw sample so don't pass it to the window object
// Return VFW_E_SAMPLE_REJECTED if it isn't a hardware buffer, NOERROR if it
// is a hardware buffer ready for real drawing or VFW_S_NO_MORE_ITEMS if it
// is a hardware buffer that has been finished with (like primary surfaces)
// We also have to handle the unlock failing, the only thing this amounts to
// is making sure the overlay got shown if we are going into a paused state

HRESULT CVideoAllocator::OnReceive(IMediaSample *pMediaSample)
{
    NOTE("Entering OnReceive");

    // Ask the DirectDraw object to unlock the sample first

    if (m_pDirectDraw->ResetSample(pMediaSample,FALSE) == FALSE) {
        NOTE("Sample not DCI/DirectDraw");
        return VFW_E_SAMPLE_REJECTED;
    }

    // Are we finished with this sample

    if (m_pDirectDraw->SyncOnFill() == FALSE) {
        NOTE("Not SyncOnFill");
        return NOERROR;
    }

    // Pretend we actually had to do something

    CAutoLock cInterfaceLock(m_pInterfaceLock);
    ASSERT(m_pRenderer->m_InputPin.IsConnected());
    m_pRenderer->OnDirectRender(pMediaSample);
    m_pRenderer->SetRepaintStatus(TRUE);

    // Now that we have unlocked the DirectDraw surface we can complete the
    // handling of sync on fill buffers (such as overlay surfaces). Since
    // we do not hand the sample onto the window object we must make sure
    // that paused state transitions complete and that the scheduling code
    // is given enough information for it's quality management decisions

    if (m_pRenderer->GetRealState() != State_Paused) {
        NOTE("Returning VFW_S_NO_MORE_ITEMS");
        return VFW_S_NO_MORE_ITEMS;
    }

    // We may run into a problem showing the overlay surface (perhaps someone
    // else got in first and grabbed the only available visible overlay). So
    // we check it actually got shown after unlocking and if it was not then
    // we immediately send a repaint. This works because the only surfaces we
    // use which are sync on fill are primary and the overlays (not flipping)

    if (m_bPrimarySurface == FALSE) {
        if (m_pDirectDraw->IsOverlayEnabled() == FALSE) {
            NOTE("Overlay was not shown");
            m_pRenderer->SendRepaint();
            return VFW_S_NO_MORE_ITEMS;
        }
    }

    NOTE("Pause state completed");
    m_pRenderer->Ready();
    return VFW_S_NO_MORE_ITEMS;
}


// Overriden so that we don't always release DirectDraw when stopped

STDMETHODIMP CVideoAllocator::Decommit()
{
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Should we block the allocator from doing a decommit

    if (m_pRenderer->m_DirectDraw.IsOverlayEnabled() == FALSE) {
        NOTE("Decommitting base allocator");
        return CBaseAllocator::Decommit();
    }

    NOTE("Blocking the decommit");

    CAutoLock cVideoLock(this);
    m_bDecommitInProgress = TRUE;
    m_bCommitted = FALSE;
    return NOERROR;
}


// Overriden from CBaseAllocator and called when the final reference count
// is released on a media sample so that it can be added to the tail of the
// allocator free list. We intervene at this point to make sure that if the
// display was locked when GetBuffer was called that it is always unlocked
// regardless of whether the source calls Receive on our input pin or not

STDMETHODIMP CVideoAllocator::ReleaseBuffer(IMediaSample *pMediaSample)
{
    CheckPointer(pMediaSample,E_POINTER);
    NOTE("Entering ReleaseBuffer");
    m_pDirectDraw->ResetSample(pMediaSample,TRUE);
    BOOL bRelease = FALSE;

    // If there is a pending Decommit, then we need to complete it by calling
    // Free() when the last buffer is placed on the free list. If there is an
    // overlay surface still showing (either true overlay or flipping) then
    // we do not free now as that would release all the DirectDraw surfaces
    // and remove the overlay with it (which we always want to keep visible)
    {
        CAutoLock cVideoLock(this);
        m_lFree.Add((CMediaSample*)pMediaSample);
        NotifySample();

        // If the overlay is visible then don't free our resources

        if (m_bDecommitInProgress == TRUE) {
            if (m_lFree.GetCount() == m_lAllocated) {
                if (m_pRenderer->m_DirectDraw.IsOverlayEnabled() == FALSE) {
                    NOTE("Free allocator resources");
                    ASSERT(m_bCommitted == FALSE);
                    CVideoAllocator::Free();
                    bRelease = TRUE;
                    m_bDecommitInProgress = FALSE;
                }
            }
        }
    }

    if (m_pNotify) {
        //
        // Note that this is not synchronized with setting up a notification
        // method.
        //
        m_pNotify->NotifyRelease();
    }
    if (bRelease) {
        Release();
    }
    return NOERROR;
}


// This is called when our input pin connects to an output pin. We search the
// formats that pin provides and see if there are any that may have hardware
// accelleration through DCI/DirectDraw. If we find a possible format then we
// create the surface (actually done by the DirectDraw object). The DirectDraw
// object will also create an output format that represents the surface which
// we use to call QueryAccept on the output pin to see if it will accept it

BOOL CVideoAllocator::FindSpeedyType(IPin *pReceivePin)
{
    IEnumMediaTypes *pEnumMediaTypes;
    AM_MEDIA_TYPE *pMediaType = NULL;
    CMediaType cMediaType;
    BOOL bFound = FALSE;
    CMediaType *pmtOut;
    ULONG ulFetched;
    ASSERT(pReceivePin);

    // Find a media type enumerator for the output pin

    HRESULT hr = pReceivePin->EnumMediaTypes(&pEnumMediaTypes);
    if (FAILED(hr)) {
        return FALSE;
    }

    NOTE("Searching for direct format");
    ASSERT(pEnumMediaTypes);
    m_pDirectDraw->ReleaseSurfaces();

    // First, try flipping overlay surfaces with all the types
    pEnumMediaTypes->Reset();
    while (TRUE) {

        // Get the next media type from the enumerator

        hr = pEnumMediaTypes->Next(1,&pMediaType,&ulFetched);
        if (FAILED(hr) || ulFetched != 1) {
            break;
        }

        ASSERT(pMediaType);
        cMediaType = *pMediaType;
        DeleteMediaType(pMediaType);

        // Find a hardware accellerated surface for this media type. We do a
        // few checks first, to see the format block is a VIDEOINFO (so it's
        // a video type), and that the format is sufficiently large. We also
        // check that the source filter can actually supply this type. After
        // that we then go looking for a suitable DCI/DirectDraw surface

        NOTE1("Enumerated %x", HEADER(cMediaType.Format())->biCompression);

        const GUID *pFormatType = cMediaType.FormatType();
        if (*pFormatType == FORMAT_VideoInfo) {
            if (cMediaType.FormatLength() >= SIZE_VIDEOHEADER) {
                if (pReceivePin->QueryAccept(&cMediaType) == S_OK) {
            // TRUE ==> Find only flipping surfaces
                    if (m_pDirectDraw->FindSurface(&cMediaType, TRUE) == TRUE) {
                        pmtOut = m_pDirectDraw->GetSurfaceFormat();
                        if (QueryAcceptOnPeer(pmtOut) == S_OK) {
                            bFound = TRUE; break;
                        }
                    }
                }
            }
        }
        m_pDirectDraw->ReleaseSurfaces();
    }

    // If that failed, try non-flipping surface types with all the formats
    pEnumMediaTypes->Reset();
    while (!bFound) {

        // Get the next media type from the enumerator

        hr = pEnumMediaTypes->Next(1,&pMediaType,&ulFetched);
        if (FAILED(hr) || ulFetched != 1) {
            break;
        }

        ASSERT(pMediaType);
        cMediaType = *pMediaType;
        DeleteMediaType(pMediaType);

        // Find a hardware accellerated surface for this media type. We do a
        // few checks first, to see the format block is a VIDEOINFO (so it's
        // a video type), and that the format is sufficiently large. We also
        // check that the source filter can actually supply this type. After
        // that we then go looking for a suitable DCI/DirectDraw surface

        NOTE1("Enumerated %x", HEADER(cMediaType.Format())->biCompression);

        const GUID *pFormatType = cMediaType.FormatType();
        if (*pFormatType == FORMAT_VideoInfo) {
            if (cMediaType.FormatLength() >= SIZE_VIDEOHEADER) {
                if (pReceivePin->QueryAccept(&cMediaType) == S_OK) {
            // FALSE ==> Find only non-flipping surfaces
                    if (m_pDirectDraw->FindSurface(&cMediaType,FALSE) == TRUE) {
                        pmtOut = m_pDirectDraw->GetSurfaceFormat();
                        if (QueryAcceptOnPeer(pmtOut) == S_OK) {
                            bFound = TRUE; break;
                        }
                    }
                }
            }
        }
        m_pDirectDraw->ReleaseSurfaces();
    }

    pEnumMediaTypes->Release();

    // If we found a surface then great, when we start streaming for real our
    // allocator is reset (and likewise the DirectDraw object status as well)
    // UpdateSurface will return TRUE and we will check the type is still ok
    // If we could not find anything then we try and create a primary surface
    // This we keep around all the time and continually ask the source if it
    // likes it when the status changes (such as the window being stretched)
    // Asking the source now if it likes the primary won't work because it
    // may have been stretched by one pixel but is just about to be resized

    if (bFound == TRUE) {
        DisplayType(TEXT("Surface available"),pmtOut);
        return TRUE;
    }

    // Switch to using a DCI/DirectDraw primary surface

    if (m_pDirectDraw->FindPrimarySurface(&m_pRenderer->m_mtIn) == FALSE) {
        NOTE("No primary surface");
        return FALSE;
    }

    NOTE("Using primary surface");
    m_bPrimarySurface = TRUE;
    return TRUE;
}


// When we pause we want to know whether there is a DCI/DirectDraw sample due
// back in at any time (or indeed may be waiting in WaitForDrawTime). Our
// m_bDirectDrawStatus has exactly these semantics as it is FALSE when we've
// returned a DIBSECTION buffer and TRUE for direct surfaces. It is reset to
// FALSE in the constructor so we're ok when using someone else's allocator

BOOL CVideoAllocator::GetDirectDrawStatus()
{
    CAutoLock cVideoLock(this);
    return m_bDirectDrawStatus;
}


// Set our DirectDraw status to FALSE when disconnected. We cannot do this
// when we are decommitted because the current buffer format is persistent
// regardless of what the allocator is doing. The only time we can be sure
// that the media type will be reset between us is when we're disconnected

void CVideoAllocator::ResetDirectDrawStatus()
{
    CAutoLock cVideoLock(this);
    m_bDirectDrawStatus = FALSE;
}


// Overriden to increment the owning object's reference count

STDMETHODIMP_(ULONG) CVideoAllocator::NonDelegatingAddRef()
{
    return m_pRenderer->AddRef();
}


// Overriden to decrement the owning object's reference count

STDMETHODIMP_(ULONG) CVideoAllocator::NonDelegatingRelease()
{
    return m_pRenderer->Release();
}


// If you derive a class from CMediaSample that has extra variables and entry
// points then there are three alternate solutions. The first is to create a
// memory buffer larger than actually required by the sample and store your
// information either at the beginning of it or at the end, the former being
// moderately safer allowing for misbehaving transform filters. You can then
// adjust the buffer address when you create the base media sample. This does
// however break up the memory allocated to the samples into separate blocks.

// The second solution is to implement a class derived from CMediaSample and
// support additional interface(s) that convey your private data. This means
// defining a custom interface. The final alternative is to create a class
// that inherits from CMediaSample and adds the private data structures, when
// you get an IMediaSample check to see if your allocator is being used, and
// if it is then cast the IMediaSample pointer into one of your derived ones

#pragma warning(disable:4355)

CVideoSample::CVideoSample(CImageAllocator *pVideoAllocator,
                           TCHAR *pName,
                           HRESULT *phr,
                           LPBYTE pBuffer,
                           LONG length) :

    CImageSample(pVideoAllocator,pName,phr,pBuffer,length),
    m_AggDirectDraw(NAME("DirectDraw"),this),
    m_AggDrawSurface(NAME("DirectDrawSurface"),this),
    m_pSurfaceBuffer(NULL),
    m_bDrawStatus(TRUE),
    m_pDrawSurface(NULL),
    m_pDirectDraw(NULL),
    m_SurfaceSize(0)
{
    ASSERT(pBuffer);
}


// Overriden to expose IDirectDraw and IDirectDrawSurface

STDMETHODIMP CVideoSample::QueryInterface(REFIID riid,void **ppv)
{
    if (riid == IID_IDirectDraw && m_pDirectDraw) {
        return m_AggDirectDraw.NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IDirectDrawSurface && m_pDrawSurface) {
        return m_AggDrawSurface.NonDelegatingQueryInterface(riid,ppv);
    }
    return CMediaSample::QueryInterface(riid, ppv);
}


// When our allocator decides to hand out DCI/DirectDraw surfaces it sets the
// data pointer in the media sample just before it hands it to the source. We
// override the GetPointer to return this pointer if set. When it returns the
// sample to the input pin (as it always should do) we will reset it to NULL
// The sample also needs the DirectDraw provider and surface interfaces along
// with the buffer size we these pieces of information are also provided here

void CVideoSample::SetDirectInfo(IDirectDrawSurface *pDrawSurface,
                                 IDirectDraw *pDirectDraw,
                                 LONG SurfaceSize,
                                 BYTE *pSurface)
{
    m_pDirectDraw = pDirectDraw;        // Associated IDirectDraw object
    m_pDrawSurface = pDrawSurface;      // IDirectDrawSurface interface
    m_pSurfaceBuffer = pSurface;        // Actual data buffer pointer
    m_SurfaceSize = SurfaceSize;        // Size of the surface we have
    m_bDrawStatus = TRUE;               // Can this sample be rendered

    // Set the interfaces in the aggregation objects
    m_AggDirectDraw.SetDirectDraw(m_pDirectDraw);
    m_AggDrawSurface.SetDirectDrawSurface(m_pDrawSurface);
}


// Return a pointer to the DCI/DirectDraw surface, this is called by our DIB
// allocator to find out of this sample was a DCI/DirectDraw sample or just
// a normal memory based one. The surface is set through SetDirectSurface

BYTE *CVideoSample::GetDirectBuffer()
{
    return m_pSurfaceBuffer;
}


// Overrides the IMediaSample interface function to return the DCI/DirectDraw
// surface pointer. If it hasn't been set then we return the normal memory
// pointer. If this sample marks a change from one to the other then it will
// also have had an updated media type attached to describe the changeover

STDMETHODIMP CVideoSample::GetPointer(BYTE **ppBuffer)
{
    CheckPointer(ppBuffer,E_POINTER);

    if (m_pSurfaceBuffer) {
        *ppBuffer = m_pSurfaceBuffer;
        return NOERROR;
    }
    return CMediaSample::GetPointer(ppBuffer);
}


// This is some painful special case handling for flipping surfaces. These
// can only be drawn once and once alone per sample otherwise you flip back
// into view the previous image. Therefore to make like easier it is useful
// to be able to ask a video allocated sample whether it can be drawn again

void CVideoSample::SetDrawStatus(BOOL bStatus)
{
    m_bDrawStatus = bStatus;
}


// We always initialise the draw status to TRUE, this is only reset to FALSE
// once a real flip has been executed for this sample. Therefore the decision
// to draw a DirectDraw sample or not can be made entirely on what the draw
// status currently is (all non flipping samples this will always be TRUE)

BOOL CVideoSample::GetDrawStatus()
{
    return m_bDrawStatus;
}


// Allow for dynamic buffer size changes

STDMETHODIMP CVideoSample::SetActualDataLength(LONG lActual)
{
    //  Break into the kernel debugger since the surface will be locked
    //  here
    // Sorry, this is a valid thing to happen
    // KASSERT(lActual > 0);

    if (lActual > (m_pSurfaceBuffer ? m_SurfaceSize : m_cbBuffer)) {
        NOTE("Data length too large");
        return VFW_E_BUFFER_OVERFLOW;
    }
    m_lActual = lActual;
    return NOERROR;
}


// Return the size of the current buffer

STDMETHODIMP_(LONG) CVideoSample::GetSize()
{
    if (m_pSurfaceBuffer) {
        return m_SurfaceSize;
    }
    return CMediaSample::GetSize();
}


// We try to match the DIB buffer with the window size so that the codec can
// do the stretching where possible. When we allocate the new buffer we must
// install it in the sample - this method allows the video allocator to set
// the new buffer pointer and also its size. We will only do this when there
// are no images outstanding so the codec can't be using it at the same time

void CVideoSample::UpdateBuffer(LONG cbBuffer,BYTE *pBuffer)
{
    ASSERT(cbBuffer);
    ASSERT(pBuffer);
    m_pBuffer = pBuffer;
    m_cbBuffer = cbBuffer;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\modex\modex.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements a Modex renderer filter, Anthony Phillips, January 1996

#include <streams.h>
#include <windowsx.h>
#include <string.h>
#include <vidprop.h>
#include <modex.h>
#include <viddbg.h>

// This is a fullscreen DirectDraw video renderer. We use Modex which is a
// facilitity provided by DirectDraw which allows an application to change
// to different display modes (we currently use 320x200x8/16, 320x240x8/16
// 640x480x8/16 and 640x400x8/16). Most VGA cards which DirectDraw runs on
// have Modex facilities available. We work like any other video renderer
// except that when we go active we switch display modes and render video
// into the different mode using DirectDraw primary flipping surfaces. If
// Modex is not available then we reject any attempts to complete connect
// and we will not let the video window be opened out of a minimised state
//
// As well as true Modex modes we also use larger display modes such as the
// 640x480x8/16 if the source can't provide a Modex type (also with primary
// flipping surfaces in fullscreen exclusive mode). These require a little
// more work on our part because we have to notice when we're switched away
// from so that we can stop using the surfaces, in Modex when we're switched
// away from we lose the surfaces (calling them returns DDERR_SURFACELOST)
//
// The main filter object inherits from the base video renderer class so that
// it gets the quality management implementation and the IQualProp property
// stuff (so that we can monitor frame rates and so on). We have a specialist
// allocator that hands out DirectDraw buffers. The allocator is build on the
// SDK CImageAllocator base class. This may seem a little strange since we
// can never draw DIB images when in Modex. We use the DIBSECTION buffer when
// the fullscreen window is switched away from so that we can continue giving
// the source filter a buffer to decompress into (the DirectDraw surface is
// no longer available after switching). When we switch back to fullscreen
// we restore the DirectDraw surfaces and switch the source filter back again

#ifdef FILTER_DLL
#include <initguid.h>
#endif

// List of class IDs and creator functions for the class factory. This
// provides the link between the OLE entry point in the DLL and an object
// being created. The class factory will call the static CreateInstance
// function when it is asked to create a CLSID_ModexRenderer COM object

#ifdef FILTER_DLL
CFactoryTemplate g_Templates[] = {
    {L"", &CLSID_ModexRenderer,      CModexRenderer::CreateInstance},
    {L"", &CLSID_QualityProperties,  CQualityProperties::CreateInstance},
    {L"", &CLSID_ModexProperties,    CModexProperties::CreateInstance}
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
STDAPI DllRegisterServer()
{
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    return AMovieDllRegisterServer2( FALSE );
}
#endif


// This goes in the factory template table to create new filter instances

CUnknown *CModexRenderer::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    return new CModexRenderer(NAME("Modex Video Renderer"),pUnk,phr);
}


// Setup data

const AMOVIESETUP_MEDIATYPE
sudModexPinTypes =
{
    &MEDIATYPE_Video,           // Major type
    &MEDIASUBTYPE_NULL          // And subtype
};

const AMOVIESETUP_PIN
sudModexPin =
{
    L"Input",                   // Name of the pin
    TRUE,                       // Is pin rendered
    FALSE,                      // Is an Output pin
    FALSE,                      // Ok for no pins
    FALSE,                      // Can we have many
    &CLSID_NULL,                // Connects to filter
    L"Output",                  // Name of pin connect
    1,                          // Number of pin types
    &sudModexPinTypes           // Details for pins
};

const AMOVIESETUP_FILTER
sudModexFilter =
{
    &CLSID_ModexRenderer,       // CLSID of filter
    L"Full Screen Renderer",    // Filter name
    MERIT_DO_NOT_USE,           // Filter merit
    1,                          // Number pins
    &sudModexPin                // Pin details
};


// This is the constructor for the main Modex renderer filter class. We keep
// an input pin that derives from the base video renderer pin class. We also
// have a DirectDraw enabled allocator that handles the Modex interactions.
// When using Modex we also need a window that gains exclusive mode access
// so we also initialise an object derived from the SDK CBaseWindow class

#pragma warning(disable:4355)

CModexRenderer::CModexRenderer(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr) :

    CBaseVideoRenderer(CLSID_ModexRenderer,pName,pUnk,phr),
    m_ModexInputPin(this,&m_InterfaceLock,NAME("Modex Pin"),phr,L"Input"),
    m_ModexAllocator(this,&m_ModexVideo,&m_ModexWindow,&m_InterfaceLock,phr),
    m_ModexWindow(this,NAME("Modex Window"),phr),
    m_ModexVideo(this,NAME("Modex Video"),phr),
    m_bActive(FALSE)
{
    m_msgFullScreen = RegisterWindowMessage(FULLSCREEN);
    m_msgNormal = RegisterWindowMessage(NORMAL);
    m_msgActivate = RegisterWindowMessage(ACTIVATE);
    m_ModexWindow.PrepareWindow();
    m_ModexAllocator.LoadDirectDraw();
}


// Destructor must set the input pin pointer to NULL before letting the base
// class in, this is because the base class deletes its pointer working with
// the assumption that the object was dynamically allocated. For convenience
// we statically create the input pin as part of the overall Modex renderer

CModexRenderer::~CModexRenderer()
{
    m_pInputPin = NULL;
    m_ModexVideo.SetDirectDraw(NULL);
    m_ModexWindow.DoneWithWindow();
    m_ModexAllocator.ReleaseDirectDraw();
}


// We only accept palettised video formats to start with

HRESULT CModexRenderer::CheckMediaType(const CMediaType *pmtIn)
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    NOTE("QueryAccept on input pin");

	// since m_Display.CheckMediaType() does not let direct-draw
	// surfaces pass through, this test should be made first.

    // Does this format match the DirectDraw surface format

    if (m_ModexAllocator.IsDirectDrawLoaded() == TRUE) {
        CMediaType *pSurface = m_ModexAllocator.GetSurfaceFormat();
        if (*pmtIn->Subtype() != MEDIASUBTYPE_RGB8) {
	    if (*pmtIn == *pSurface) {
		NOTE("match found");
		return NOERROR;
	    }
	}
	else {
	    BOOL bFormatsMatch = FALSE;
	    DWORD dwCompareSize = 0;

	    bFormatsMatch = (IsEqualGUID(pmtIn->majortype, pSurface->majortype) == TRUE) &&
			    (IsEqualGUID(pmtIn->subtype, pSurface->subtype) == TRUE) &&
			    (IsEqualGUID(pmtIn->formattype, pSurface->formattype) == TRUE);

	    // in the palettized case we not want to compare palette entries. Furthermore we do not 
	    // want to compare the values of biClrUsed OR biClrImportant
	    ASSERT(pmtIn->cbFormat >= sizeof(VIDEOINFOHEADER));
	    ASSERT(pSurface->cbFormat >= sizeof(VIDEOINFOHEADER));
            dwCompareSize = FIELD_OFFSET(VIDEOINFOHEADER, bmiHeader.biClrUsed);
	    ASSERT(dwCompareSize < sizeof(VIDEOINFOHEADER));
	    bFormatsMatch = bFormatsMatch && (memcmp(pmtIn->pbFormat, pSurface->pbFormat, dwCompareSize) == 0);
	    if (bFormatsMatch) {
		return NOERROR;
	    }
	}
    }

	// Is this format eight bit palettised

    if (*pmtIn->Subtype() == MEDIASUBTYPE_RGB8) {
        return m_Display.CheckMediaType(pmtIn);
    }

    return E_INVALIDARG;
}


// We only support one input pin and it is numbered zero

CBasePin *CModexRenderer::GetPin(int n)
{
    ASSERT(n == 0);
    if (n != 0) {
        return NULL;
    }

    // Assign the input pin if not already done so

    if (m_pInputPin == NULL) {
        m_pInputPin = &m_ModexInputPin;
    }
    return m_pInputPin;
}


// Overriden to say what interfaces we support and where

STDMETHODIMP CModexRenderer::NonDelegatingQueryInterface(REFIID riid,void **ppv)
{
    if (riid == IID_ISpecifyPropertyPages) {
        return GetInterface((ISpecifyPropertyPages *)this, ppv);
    } else if (riid == IID_IFullScreenVideo) {
        return m_ModexVideo.NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IFullScreenVideoEx) {
        return m_ModexVideo.NonDelegatingQueryInterface(riid,ppv);
    }
    return CBaseVideoRenderer::NonDelegatingQueryInterface(riid,ppv);
}


// Return the CLSIDs for the property pages we support

STDMETHODIMP CModexRenderer::GetPages(CAUUID *pPages)
{
    CheckPointer(pPages,E_POINTER);
    NOTE("Entering GetPages");
    pPages->cElems = 1;

    // Are we allowed to expose the display modes property page

    HKEY hk;
    DWORD dwValue = 0, cb = sizeof(DWORD);
    TCHAR ach[80] = {'C','L','S','I','D','\\'};
    REFGUID rguid = CLSID_ModexProperties;
    wsprintf(&ach[6], TEXT("{%08lX-%04X-%04X-%02X%02X-%02X%02X%02X%02X%02X%02X}"),
	    rguid.Data1, rguid.Data2, rguid.Data3,
	    rguid.Data4[0], rguid.Data4[1],
	    rguid.Data4[2], rguid.Data4[3],
	    rguid.Data4[4], rguid.Data4[5],
	    rguid.Data4[6], rguid.Data4[7]);

    if (!RegOpenKey(HKEY_CLASSES_ROOT, ach, &hk)) {
        if (!RegQueryValueEx(hk, TEXT("ShowMe"), NULL, NULL, (LPBYTE)&dwValue, &cb) &&
								dwValue) {
	    pPages->cElems = 2;
            NOTE("Using property page");
	}
    }

    // allocate enough room for the varying number of pages

    pPages->pElems = (GUID *) QzTaskMemAlloc(pPages->cElems * sizeof(GUID));
    if (pPages->pElems == NULL) {
        return E_OUTOFMEMORY;
    }

    // We may not be returning CLSID_ModexProperties

    pPages->pElems[0] = CLSID_QualityProperties;
    if (pPages->cElems > 1) {
    	pPages->pElems[1] = CLSID_ModexProperties;
    }
    return NOERROR;
}


// Pass the DirectDraw sample onto the allocator to deal with

HRESULT CModexRenderer::DoRenderSample(IMediaSample *pMediaSample)
{
    return m_ModexAllocator.DoRenderSample(pMediaSample);
}


// If we are not streaming then display a poster image and also have any
// state transition completed. Transitions to paused states don't fully
// complete until the first image is available for drawing. Any GetState
// calls on IMediaFilter will return State_Intermediate until complete

void CModexRenderer::OnReceiveFirstSample(IMediaSample *pMediaSample)
{
    NOTE("OnReceiveFirstSample");
    DoRenderSample(pMediaSample);
}


// Overriden so that when we try to complete a connection we check that the
// source filter can provide a format we can use in our display modes. If
// the source is not DirectDraw enabled then we would have to change mode
// to say 320x240, find they can't supply a clipped version of their video
// and reject the Pause call. What applications really want is to have the
// connection rejected if we detect the source won't be able to handle it

HRESULT CModexRenderer::CompleteConnect(IPin *pReceivePin)
{
    NOTE("Entering Modex CompleteConnect");
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    CBaseVideoRenderer::CompleteConnect(pReceivePin);

    // Pass the video window handle upstream
    HWND hwnd = m_ModexWindow.GetWindowHWND();
    NOTE1("Sending EC_NOTIFY_WINDOW %x",hwnd);
    SendNotifyWindow(pReceivePin,hwnd);

    return m_ModexAllocator.NegotiateSurfaceFormat();
}


// Called when a connection is broken

HRESULT CModexRenderer::BreakConnect()
{
    NOTE("Entering Modex BreakConnect");
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    CBaseVideoRenderer::BreakConnect();
    m_ModexWindow.InactivateWindow();

    // The window is not used when disconnected
    IPin *pPin = m_ModexInputPin.GetConnected();
    if (pPin) SendNotifyWindow(pPin,NULL);

    return NOERROR;
}


// Helper function to copy a palette out of any kind of VIDEOINFO (ie it may
// be s DirectDraw sample) into a palettised VIDEOINFO. We use this changing
// palettes on DirectDraw samples as a source filter can attach a palette to
// any buffer (eg Modex) and hand it back. We make a new palette out of that
// format and then copy the palette colours into the current connection type

HRESULT CModexRenderer::CopyPalette(const CMediaType *pSrc,CMediaType *pDest)
{
    // Reset the destination palette before starting

    VIDEOINFO *pDestInfo = (VIDEOINFO *) pDest->Format();
    pDestInfo->bmiHeader.biClrUsed = 0;
    pDestInfo->bmiHeader.biClrImportant = 0;
    ASSERT(PALETTISED(pDestInfo) == TRUE);

    // Does the source contain a palette

    const VIDEOINFO *pSrcInfo = (VIDEOINFO *) pSrc->Format();
    if (ContainsPalette((VIDEOINFOHEADER *)pSrcInfo) == FALSE) {
        NOTE("No source palette");
        return S_FALSE;
    }

    // The number of colours may be zero filled

    DWORD PaletteEntries = pSrcInfo->bmiHeader.biClrUsed;
    if (PaletteEntries == 0) {
        NOTE("Setting maximum colours");
        PaletteEntries = iPALETTE_COLORS;
    }

    // Make sure the destination has enough room for the palette

    ASSERT(pSrcInfo->bmiHeader.biClrUsed <= iPALETTE_COLORS);
    ASSERT(pSrcInfo->bmiHeader.biClrImportant <= PaletteEntries);
    ASSERT(pDestInfo->bmiColors == GetBitmapPalette((VIDEOINFOHEADER *)pDestInfo));
    pDestInfo->bmiHeader.biClrUsed = PaletteEntries;
    pDestInfo->bmiHeader.biClrImportant = pSrcInfo->bmiHeader.biClrImportant;
    ULONG BitmapSize = GetBitmapFormatSize(HEADER(pSrcInfo));

    if (pDest->FormatLength() < BitmapSize) {
        NOTE("Reallocating destination");
        pDest->ReallocFormatBuffer(BitmapSize);
    }

    // Now copy the palette colours across

    CopyMemory((PVOID) pDestInfo->bmiColors,
               (PVOID) GetBitmapPalette((VIDEOINFOHEADER *)pSrcInfo),
               PaletteEntries * sizeof(RGBQUAD));

    return NOERROR;
}


// We store a copy of the media type used for the connection in the renderer
// because it is required by many different parts of the running renderer
// This can be called when we come to draw a media sample that has a format
// change with it since we delay the completion to maintain synchronisation
// This must also handle Modex DirectDraw media samples and palette changes

HRESULT CModexRenderer::SetMediaType(const CMediaType *pmt)
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    NOTE("Entering Modex SetMediaType");

    // Is this a DirectDraw sample with a format change

    if (m_ModexAllocator.GetDirectDrawStatus() == TRUE) {
        NOTE("Copying palette into DIB format");
        CopyPalette(pmt,&m_mtIn);
        m_ModexAllocator.NotifyMediaType(&m_mtIn);
        return m_ModexAllocator.UpdateDrawPalette(pmt);
    }

    m_mtIn = *pmt;

    // Expand the palette provided in the media type

    m_mtIn.ReallocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mtIn.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    m_Display.UpdateFormat(pVideoInfo);

    // Notify the application of the video dimensions

    NotifyEvent(EC_VIDEO_SIZE_CHANGED,
                MAKELPARAM(pHeader->biWidth,pHeader->biHeight),
                MAKEWPARAM(0,0));

    // Update the palette and source format

    NOTE("Updating Modex allocator with format");
    m_ModexAllocator.NotifyMediaType(&m_mtIn);
    return m_ModexAllocator.UpdateDrawPalette(&m_mtIn);
}


// Reset the keyboard state for this thread

void CModexRenderer::ResetKeyboardState()
{
    BYTE KeyboardState[256];
    GetKeyboardState(KeyboardState);
    KeyboardState[VK_MENU] = FALSE;
    KeyboardState[VK_SHIFT] = FALSE;
    KeyboardState[VK_CONTROL] = FALSE;
    SetKeyboardState(KeyboardState);
}


// Called by the base filter class when we are paused or run

HRESULT CModexRenderer::Active()
{
    NOTE("Entering Modex Active");
    LRESULT Result;

    // Are we already activated

    if (m_bActive == TRUE) {
        NOTE("Already Active");
        return NOERROR;
    }

    // Activate the allocator

    SetRepaintStatus(FALSE);
    HWND hwnd = m_ModexWindow.GetWindowHWND();

	// call SetFocusWindow on all DSound Renderers
	m_ModexAllocator.DistributeSetFocusWindow(hwnd);

    Result = SendMessage(hwnd,m_msgFullScreen,0,0);
    m_bActive = TRUE;

    // Check the allocator activated

    if (Result == (LRESULT) 0) {
        Inactive();
        return E_FAIL;
    }
    return CBaseVideoRenderer::Active();
}


// Called when the filter is stopped

HRESULT CModexRenderer::Inactive()
{
    NOTE("Entering Modex Inactive");

    // Are we already deactivated

    if (m_bActive == FALSE) {
        NOTE("Already Inactive");
        return NOERROR;
    }

    // Deactivate the allocator

    SetRepaintStatus(TRUE);
    m_bActive = FALSE;
    HWND hwnd = m_ModexWindow.GetWindowHWND();

    //  If we're already on the window thread we can inactivate
    //  the allocator here
    //  If we're on another thread avoid a bug in DirectDraw
    //  by posting a message to ourselves
    //  The problem occurs because DirectDraw calls ShowWindow
    //  in response to WM_ACTIVATEAPP (they hooked our window proc
    //  inside SetCooperativeLevel) and ShowWindow allows through
    //  this message if we send it via SendMessage.  Unfortunately
    //  at this point DirectDraw holds its critical section so we
    //  deadlock with the player thread when it tries to call
    //  Lock (player thread has allocator CS, tries to get DDraw CS,
    //  window thread has DDraw CS, tries to get allocator CS).
    if (GetWindowThreadProcessId(hwnd, NULL) ==
            GetCurrentThreadId()) {
        DbgLog((LOG_TRACE, 2, TEXT("Inactive on window thread")));
     	m_ModexAllocator.Inactive();
    } else {
        SendMessage(hwnd,m_msgNormal,0,0);
        m_evWaitInactive.Wait();
	}
	
	// call SetFocusWindow on all DSound Renderers
	m_ModexAllocator.DistributeSetFocusWindow(NULL);
    
    CBaseVideoRenderer::Inactive();

    return NOERROR;
}


// Called when we receive WM_ACTIVATEAPP messages. DirectDraw seems to arrange
// through its window hooking that we get notified of activation and likewise
// deactivation as the user tabs away from the window. If we have any surfaces
// created we will have lost them during deactivation so we take this chance
// to restore them - the restore will reclaim the video memory that they need

HRESULT CModexRenderer::OnActivate(HWND hwnd,WPARAM wParam)
{
    NOTE("In WM_ACTIVATEAPP method");
    IBaseFilter *pFilter = NULL;
    BOOL bActive = (BOOL) wParam;

    // Have we been activated yet

    if (m_bActive == FALSE) {
        NOTE("Not activated");
        return NOERROR;
    }

    // Extra window activation checks

    if (bActive == TRUE) {
        NOTE("Restoring window...");
        m_ModexWindow.RestoreWindow();
        NOTE("Restored window");
    }

    // Tell the plug in distributor what happened

    QueryInterface(IID_IBaseFilter,(void **) &pFilter);
    NotifyEvent(EC_ACTIVATE,wParam,(LPARAM) pFilter);
    NOTE1("Notification of EC_ACTIVATE (%d)",bActive);

    // Pass on EC_FULLSCREEN_LOST event codes
    if (bActive == FALSE)
        NotifyEvent(EC_FULLSCREEN_LOST,0,(LPARAM) pFilter);

    pFilter->Release();

    // Should we deactivate ourselves immediately

    if (m_ModexVideo.HideOnDeactivate() == TRUE) {
        if (bActive == FALSE) {
            NOTE("Deactivating");
            return Inactive();
        }
    }

    // No new data to paint with so signal the filtergraph that another image
    // is required, this has the filtergraph component set the whole graph to
    // a paused state which causes us to receive an image. This function must
    // be asynchronous otherwise the window will stop responding to the user

    if (bActive == TRUE) {
    	NOTE("Sending Repaint");
        SendRepaint();
    }
    return m_ModexAllocator.OnActivate(bActive);
}


// Constructor for our derived input pin class. We override the base renderer
// pin class so that we can control the allocator negotiation. This rendering
// filter only operates in Modex so we can only draw buffers provided by our
// allocator. If the source insists on using its allocator then we cannot do
// a connection. We must also make sure that when we have samples delivered
// to our input pin that we hand them to our allocator to unlock the surface

CModexInputPin::CModexInputPin(CModexRenderer *pRenderer,
                               CCritSec *pInterfaceLock,
                               TCHAR *pObjectName,
                               HRESULT *phr,
                               LPCWSTR pPinName) :

    CRendererInputPin(pRenderer,phr,pPinName),
    m_pRenderer(pRenderer),
    m_pInterfaceLock(pInterfaceLock)
{
    ASSERT(m_pRenderer);
    ASSERT(pInterfaceLock);
}


// This overrides the CBaseInputPin virtual method to return our allocator
// When NotifyAllocator is called it sets the current allocator in the base
// input pin class (m_pAllocator), this is what GetAllocator should return
// unless it is NULL in which case we return the allocator we would like

STDMETHODIMP CModexInputPin::GetAllocator(IMemAllocator **ppAllocator)
{
    CheckPointer(ppAllocator,E_POINTER);
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    NOTE("Entering GetAllocator");

    // Has an allocator been set yet in the base class

    if (m_pAllocator == NULL) {
        m_pAllocator = &m_pRenderer->m_ModexAllocator;
        m_pAllocator->AddRef();
    }

    m_pAllocator->AddRef();
    *ppAllocator = m_pAllocator;
    return NOERROR;
}


// The COM specification says any two IUnknown pointers to the same object
// should always match which provides a way for us to see if they are using
// our allocator or not. Since we are only really interested in equality
// and our object always hands out the same IMemAllocator interface we can
// just see if the pointers match. We must always use our Modex allocator

STDMETHODIMP
CModexInputPin::NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly)
{
    NOTE("Entering NotifyAllocator");
    CAutoLock cInterfaceLock(m_pInterfaceLock);
    if (pAllocator == &m_pRenderer->m_ModexAllocator) {
        return CBaseInputPin::NotifyAllocator(pAllocator,bReadOnly);
    }
    return E_FAIL;
}


// We have been delivered a sample that holds the DirectDraw surface lock so
// we pass it onto the allocator to deal with before handing to the renderer
// It would be bad to leave the surface locked while the sample is queued by
// the renderer as it locks out any other threads from accessing the surface

STDMETHODIMP CModexInputPin::Receive(IMediaSample *pSample)
{
    CheckPointer(pSample,E_POINTER);
    NOTE("Pin received a sample");
    m_pRenderer->m_ModexAllocator.OnReceive(pSample);
    return m_pRenderer->Receive(pSample);
}


// Constructor for our window class. To access DirectDraw Modex we supply it
// with a window, this is granted exclusive mode access rights. DirectDraw
// hooks the window and manages a lot of the functionality associated with
// handling Modex. For example when you switch display modes it maximises
// the window, when the user hits ALT-TAB the window is minimised. When the
// user then clicks on the minimised window the Modex is likewise restored

CModexWindow::CModexWindow(CModexRenderer *pRenderer,   // Delegates locking
                           TCHAR *pName,                // Object description
                           HRESULT *phr) :              // OLE failure code
    m_pRenderer(pRenderer),
    m_hAccel(NULL),
    m_hwndAccel(NULL)
{
    ASSERT(m_pRenderer);
}


// it is going to create the window to get our window and class styles. The
// return code is the class name and must be allocated in static storage. We
// specify a normal window during creation although the window styles as well
// as the extended styles may be changed by the application via IVideoWindow

LPTSTR CModexWindow::GetClassWindowStyles(DWORD *pClassStyles,
                                          DWORD *pWindowStyles,
                                          DWORD *pWindowStylesEx)
{
    NOTE("Entering GetClassWindowStyles");

    *pClassStyles = CS_HREDRAW | CS_VREDRAW | CS_BYTEALIGNCLIENT | CS_DBLCLKS;
    *pWindowStyles = WS_POPUP | WS_CLIPCHILDREN;
    *pWindowStylesEx = WS_EX_TOPMOST;
    return MODEXCLASS;
}


// When we change display modes to 640x480 DirectDraw seems to switch us to a
// software cursor. When we start flipping the primary surfaces we can end up
// leaving a trail of previous mouse positions as it is moved. The solution
// is to hide the mouse when it is needed and the window is in exclusive mode

LRESULT CModexWindow::OnSetCursor()
{
    NOTE("Entering OnSetCursor");

    // Pass to default processing if iconic

    if (IsIconic(m_hwnd) == TRUE) {
        NOTE("Not hiding cursor");
        return (LRESULT) 0;
    }

    NOTE("Hiding software cursor");
    SetCursor(NULL);
    return (LRESULT) 1;
}


// When the fullscreen mode is activated we restore our window

LRESULT CModexWindow::RestoreWindow()
{
    NOTE("Entering RestoreWindow");

    // Is the window currently minimised

    if (GetForegroundWindow() != m_hwnd || IsIconic(m_hwnd)) {
        NOTE("Window is iconic");
        return (LRESULT) 1;
    }

    NOTE("Making window fullscreen");

    SetWindowPos(m_hwnd,NULL,(LONG) 0,(LONG) 0,
                 GetSystemMetrics(SM_CXSCREEN),
                 GetSystemMetrics(SM_CYSCREEN),
                 SWP_NOACTIVATE | SWP_NOZORDER);

    UpdateWindow(m_hwnd);
    return (LRESULT) 1;
}


// Used to blank the window after a mode change

void CModexWindow::OnPaint()
{
    NOTE("Entering OnPaint");
    RECT ClientRect;
    PAINTSTRUCT ps;
    BeginPaint(m_hwnd,&ps);
    EndPaint(m_hwnd,&ps);

    GetClientRect(m_hwnd,&ClientRect);
    COLORREF BackColour = SetBkColor(m_hdc,VIDEO_COLOUR);
    ExtTextOut(m_hdc,0,0,ETO_OPAQUE,&ClientRect,NULL,0,NULL);
    SetBkColor(m_hdc,BackColour);
}


// This is the derived class window message handler

LRESULT CModexWindow::OnReceiveMessage(HWND hwnd,          // Window handle
                                       UINT uMsg,          // Message ID
                                       WPARAM wParam,      // First parameter
                                       LPARAM lParam)      // Other parameter
{
    if (::PossiblyEatMessage(m_pRenderer->m_ModexVideo.GetMessageDrain(),
                             uMsg,
                             wParam,
                             lParam)) {
        return 0;
    }
    // Due to a bug in DirectDraw we must call SetCooperativeLevel and also
    // SetDisplayMode on the window thread, otherwise it gets confused and
    // blocks us from completing the display change successfully. Therefore
    // when we're activated we send a message to the window to go fullscreen
    // The return value is used by the main renderer to know if we succeeded

    if (uMsg == m_pRenderer->m_msgFullScreen) {
        m_pRenderer->ResetKeyboardState();
     	HRESULT hr = m_pRenderer->m_ModexAllocator.Active();
    	return (FAILED(hr) ? (LRESULT) 0 : (LRESULT) 1);
    }

    // And likewise we also deactivate the renderer from fullscreen mode on
    // the window thread rather than the application thread. Otherwise we
    // get a load of confusing WM_ACTIVATEAPP messages coming through that
    // cause us to believe we have been restored from a minimised state and
    // so send repaints and also restore surfaces we are currently releasing

    if (uMsg == m_pRenderer->m_msgNormal) {
     	NOTE("Restoring on WINDOW thread");
     	m_pRenderer->m_ModexAllocator.Inactive();
        m_pRenderer->m_evWaitInactive.Set();
        return (LRESULT) 1;
    }

    // DirectDraw holds it's critical section while it sends us an activate
    // message - if the decoder thread is about to call DirectDraw it will
    // have the allocator lock and may deadlock trying to enter DirectDraw
    // The solution is to post activation messages back to ourselves using
    // a custom message so they can be handled without the DirectDraw lock

    if (uMsg == m_pRenderer->m_msgActivate) {
     	NOTE("Activation message received");
     	m_pRenderer->OnActivate(hwnd,wParam);
        return (LRESULT) 0;
    }

    switch (uMsg)
    {
        // Use ALT-ENTER as a means of deactivating

        case WM_SYSKEYDOWN:
            if (wParam == VK_RETURN) {
                NOTE("ALT-ENTER selected");
                m_pRenderer->m_ModexAllocator.Inactive();
            }
            return (LRESULT) 0;

        // Handle WM_CLOSE by aborting the playback

        case WM_CLOSE:
            m_pRenderer->NotifyEvent(EC_USERABORT,0,0);
            NOTE("Sent an EC_USERABORT to graph");
            return (LRESULT) 1;

        // See if we are still the fullscreen window

        case WM_ACTIVATEAPP:
            PostMessage(hwnd,m_pRenderer->m_msgActivate,wParam,lParam);
            return (LRESULT) 0;

        // Paint the background black

        case WM_PAINT:
            OnPaint();
            return (LRESULT) 0;

        // Disable cursors when fullscreen active

        case WM_SETCURSOR:
            if (OnSetCursor() == 1) {
                return (LRESULT) 1;
            }
    }
    return CBaseWindow::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


#if 0
// This is the windows message loop for our worker thread. It does a loop
// processing and dispatching messages until it receives a WM_QUIT message
// which will normally be generated through the owning object's destructor
// We override this so that we can pass messages on in fullscreen mode to
// another window - that window is set through the SetMessageDrain method

HRESULT CModexWindow::MessageLoop()
{
    HANDLE hEvent = (HANDLE) m_SyncWorker;
    MSG Message;
    DWORD dwResult;

    while (TRUE) {

        // Has the close down event been signalled

        dwResult = MsgWaitForMultipleObjects(1,&hEvent,FALSE,INFINITE,QS_ALLINPUT);
        if (dwResult == WAIT_OBJECT_0) {
            HWND hwnd = m_hwnd;
            UninitialiseWindow();
            DestroyWindow(hwnd);
            return NOERROR;
        }

        // Dispatch the message to the window procedure

        if (dwResult == WAIT_OBJECT_0 + 1) {
            while (PeekMessage(&Message,NULL,0,0,PM_REMOVE)) {
                if ((m_hAccel == NULL) || (TranslateAccelerator(m_hwndAccel,m_hAccel,&Message) == FALSE)) {
                    SendToDrain(&Message);
                    TranslateMessage(&Message);
                    DispatchMessage(&Message);
                }
            }
        }
    }
    return NOERROR;
}
#endif


// This checks to see whether the window has a drain. When we are playing in
// fullscreen an application can register itself through IFullScreenVideo to
// get any mouse and keyboard messages we get sent. This might allow it to
// support seeking hot keys for example without switching back to a window.
// We pass these messages on untranslated returning TRUE if we're successful

BOOL CModexWindow::SendToDrain(PMSG pMessage)
{
    HWND hwndDrain = m_pRenderer->m_ModexVideo.GetMessageDrain();

    if (hwndDrain != NULL)
    {
        switch (pMessage->message)
        {
            case WM_CHAR:
            case WM_DEADCHAR:
            case WM_KEYDOWN:
            case WM_KEYUP:
            case WM_LBUTTONDBLCLK:
            case WM_LBUTTONDOWN:
            case WM_LBUTTONUP:
            case WM_MBUTTONDBLCLK:
            case WM_MBUTTONDOWN:
            case WM_MBUTTONUP:
            case WM_MOUSEACTIVATE:
            case WM_MOUSEMOVE:
            case WM_NCHITTEST:
            case WM_NCLBUTTONDBLCLK:
            case WM_NCLBUTTONDOWN:
            case WM_NCLBUTTONUP:
            case WM_NCMBUTTONDBLCLK:
            case WM_NCMBUTTONDOWN:
            case WM_NCMBUTTONUP:
            case WM_NCMOUSEMOVE:
            case WM_NCRBUTTONDBLCLK:
            case WM_NCRBUTTONDOWN:
            case WM_NCRBUTTONUP:
            case WM_RBUTTONDBLCLK:
            case WM_RBUTTONDOWN:
            case WM_RBUTTONUP:

                PostMessage(hwndDrain,
                            pMessage->message,
                            pMessage->wParam,
                            pMessage->lParam);

                return TRUE;
        }
    }
    return FALSE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\direct.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Defines the COverlay class, Anthony Phillips, February 1995

#ifndef __OVERLAY__
#define __OVERLAY__

// Define a class which implements the IOverlay interface. A client may ask
// for one and only one advise link to be maintained that we will call when
// any of the window details change. When setting the advise link we'll be
// given an IOverlayNotify interface to call and we will also be told which
// notifications it is interested in. This class looks after
// the window clipping notifications and we have a number of private member
// functions that the renderer's objects may call to provide us with the
// rest of the information needed such as the window handle and media type

const DWORD PALETTEFLAG = 0x1000000;
const DWORD TRUECOLOURFLAG = 0x2000000;

class COverlay : public IOverlay, public CUnknown, public CCritSec
{
    // To support overlays the renderer may have to paint the video window
    // when areas become exposed using a specific colour. We get a default
    // key colour when we start. The next available key colour is kept in
    // a shared memory segment to try and reduce the risk of conflicts. If
    // we're asked to install a colour key we may have to create a palette

    LONG m_DefaultCookie;             // Default colour key cookie for us to use
    COLORREF m_WindowColour;          // Our actual overlay window colour
    COLORKEY m_ColourKey;             // Initial colour key requirements
    BOOL m_bColourKey;                // Are we using a colour key
    BOOL m_bFrozen;                   // Have we frozen the video
    CRenderer *m_pRenderer;           // Controlling renderer object
    IOverlayNotify *m_pNotify;        // Interface to call clients
    DWORD m_dwInterests;              // Callbacks interested in
    HPALETTE m_hPalette;              // A colour key palette handle
    CCritSec *m_pInterfaceLock;       // Main renderer interface lock
    HHOOK m_hHook;                    // Handle to window message hook
    RECT m_TargetRect;                // Last known good destination
    BOOL m_bMustRemoveCookie;         // TRUE if the cookie value must be released
                                      // by calling RemoveCurrentCookie().  Otherwise
                                      // FALSE.
                                      
    CDirectDraw *m_pDirectDraw;

private:

    HRESULT ValidateOverlayCall();
    BOOL OnAdviseChange(BOOL bAdviseAdded);
    HRESULT AdjustForDestination(RGNDATA *pRgnData);
    HRESULT GetVideoRect(RECT *pVideoRect);

    // Return the clipping details for the video window

    HRESULT GetVideoClipInfo(RECT *pSourceRect,
                             RECT *pDestinationRect,
                             RGNDATA **ppRgnData);

    // Set our internal colour key state

    void ResetColourKeyState();

    HRESULT InstallColourKey(COLORKEY *pColourKey,COLORREF Colour);
    HRESULT InstallPalette(HPALETTE hPalette);

    // These create and manage a suitable colour key

    HRESULT GetWindowColourKey(COLORKEY *pColourKey);
    HRESULT CheckSetColourKey(COLORKEY *pColourKey);
    HRESULT MatchColourKey(COLORKEY *pColourKey);
    HRESULT CheckSetPalette(DWORD dwColors,PALETTEENTRY *pPaletteColors);
    HPALETTE MakePalette(DWORD dwColors,PALETTEENTRY *pPaletteColors);
    HRESULT GetDisplayPalette(DWORD *pColors,PALETTEENTRY **ppPalette);

    // Main function for calculating an overlay colour key
    HRESULT NegotiateColourKey(COLORKEY *pColourKey,
                               HPALETTE *phPalette,
                               COLORREF *pColourRef);

    // Find a system palette entry for a colour key
    HRESULT NegotiatePaletteIndex(VIDEOINFO *pDisplay,
                                  COLORKEY *pColourKey,
                                  HPALETTE *phPalette,
                                  COLORREF *pColourRef);

    // Find a RGB true colour to use as a colour key
    HRESULT NegotiateTrueColour(VIDEOINFO *pDisplay,
                                COLORKEY *pColourKey,
                                COLORREF *pColourRef);
public:

    // Constructor and destructor

    COverlay(CRenderer *pRenderer,      // Main renderer object
             CDirectDraw *pDirectDraw,
             CCritSec *pLock,           // Object to use for lock
             HRESULT *phr);             // General OLE return code

    virtual ~COverlay();

    HRESULT NotifyChange(DWORD AdviseChanges);

    BOOL OnPaint();
    HRESULT FreezeVideo();
    HRESULT ThawVideo();
    BOOL IsVideoFrozen();
    void StartUpdateTimer();
    void StopUpdateTimer();
    BOOL OnUpdateTimer();
    void OnHookMessage(BOOL bHook);
    void InitDefaultColourKey(COLORKEY *pColourKey);

public:

    DECLARE_IUNKNOWN

    // Overriden to provide our own IUnknown interface

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);
    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();

    // These manage the palette negotiation

    STDMETHODIMP GetPalette(
        DWORD *pdwColors,                   // Number of colours present
        PALETTEENTRY **ppPalette);          // Where to put palette data

    STDMETHODIMP SetPalette(
        DWORD dwColors,                     // Number of colours available
        PALETTEENTRY *pPaletteColors);      // Colours to use for palette

    // These manage the colour key negotiation

    STDMETHODIMP GetDefaultColorKey(COLORKEY *pColorKey);
    STDMETHODIMP GetColorKey(COLORKEY *pColorKey);
    STDMETHODIMP SetColorKey(COLORKEY *pColorKey);
    STDMETHODIMP GetWindowHandle(HWND *pHwnd);

    // The IOverlay interface allocates the memory for the clipping rectangles
    // as it is variable in length. The filter calling this method should free
    // the memory when it has finished using them by calling OLE CoTaskMemFree

    STDMETHODIMP GetClipList(RECT *pSourceRect,
                             RECT *pDestinationRect,
                             RGNDATA **ppRgnData);

    // The calls to OnClipChange happen in sync with the window. So it is
    // called with an empty clip list before the window moves to freeze
    // the video, and then when the window has stabilised it is called
    // again with the new clip list. The OnPositionChange callback is for
    // overlay cards that don't want the expense of synchronous clipping
    // updates and just want to know when the source or destination video
    // positions change. They will NOT be called in sync with the window
    // but at some point after the window has changed (basicly in time
    // with WM_SIZE etc messages received). This is therefore suitable
    // for overlay cards that don't inlay their data to the frame buffer

    STDMETHODIMP GetVideoPosition(RECT *pSourceRect,
                                  RECT *pDestinationRect);

    // This provides synchronous clip changes so that the client is called
    // before the window is moved to freeze the video, and then when the
    // window has stabilised it is called again to start playback again.
    // If the window rect is all zero then the window is invisible, the
    // filter must take a copy of the information if it wants to keep it

    STDMETHODIMP Advise(
        IOverlayNotify *pOverlayNotify,     // Notification interface
        DWORD dwInterests);                 // Callbacks interested in

    STDMETHODIMP Unadvise();
};

#endif // __OVERLAY__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\allocate.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements a DirectDraw allocator, Anthony Phillips, January 1995

#ifndef __ALLOCATE__
#define __ALLOCATE__

// This class inherits from CImageSample and is overriden to store DirectDraw
// information. In particular these samples change dynamically so that if we
// have access to a surface then the allocator changes the format with the
// source filter and then initialises us with a pointer to the locked surface
// The m_bDrawStatus flag indicates whether a flipping surface has been done

class CVideoSample : public CImageSample
{
    IDirectDrawSurface *m_pDrawSurface;   // The DirectDraw surface instance
    IDirectDraw *m_pDirectDraw;           // The actual DirectDraw provider
    LONG m_SurfaceSize;                   // Size of DCI/DirectDraw buffer
    BYTE *m_pSurfaceBuffer;               // Pointer to DCI/DirectDraw buffer
    BOOL m_bDrawStatus;                   // Can this sample be rendered flag
    CAggDirectDraw m_AggDirectDraw;       // Aggregates IDirectDraw interface
    CAggDrawSurface m_AggDrawSurface;     // Likewise with IDirectDrawSurface

public:

    // Constructor

    CVideoSample(CImageAllocator *pVideoAllocator,
                 TCHAR *pName,
                 HRESULT *phr,
                 LPBYTE pBuffer,
                 LONG length);

    STDMETHODIMP QueryInterface(REFIID riid,void **ppv);

    // Maintain the DCI/DirectDraw state

    void SetDirectInfo(IDirectDrawSurface *pDrawSurface,
                       IDirectDraw *pDirectDraw,
                       LONG SurfaceSize,
                       BYTE *pSurface);

    void UpdateBuffer(LONG cbBuffer,BYTE *pBuffer);
    BYTE *GetDirectBuffer();
    void SetDrawStatus(BOOL bStatus);
    BOOL GetDrawStatus();

    // Override these IMediaSample functions

    STDMETHODIMP GetPointer(BYTE **ppBuffer);
    STDMETHODIMP_(LONG) GetSize();
    STDMETHODIMP SetActualDataLength(LONG lActual);
};


// This is an allocator derived from the CImageAllocator utility class that
// allocates sample buffers in shared memory. The number and size of these
// are determined when the output pin calls Prepare on us. The shared memory
// blocks are used in subsequent calls to GDI CreateDIBSection, once that
// has been done the output pin can fill the buffers with data which will
// then be handed to GDI through BitBlt calls and thereby remove one copy

class CVideoAllocator : public CImageAllocator
{
    CRenderer *m_pRenderer;             // The owning renderer object
    CDirectDraw *m_pDirectDraw;         // DirectDraw helper object
    BOOL m_bDirectDrawStatus;           // What type are we using now
    BOOL m_bDirectDrawAvailable;        // Are we allowed to go direct
    BOOL m_bPrimarySurface;             // Are we using the primary
    CCritSec *m_pInterfaceLock;         // Main renderer interface lock
    IMediaSample *m_pMediaSample;       // Sample waiting for rendering
    BOOL m_bVideoSizeChanged;           // Signals a change in video size
    BOOL m_bNoDirectDraw;

    // Used to create and delete samples

    HRESULT Alloc();
    void Free();

    // Look after the state changes when switching sample types

    HRESULT QueryAcceptOnPeer(CMediaType *pMediaType);
    HRESULT InitDirectAccess(CMediaType *pmtIn);
    BOOL PrepareDirectDraw(IMediaSample *pSample,DWORD dwFlags,
					BOOL fForcePrepareForMultiMonitorHack);
    BOOL UpdateImage(IMediaSample **ppSample,CMediaType *pBuffer);
    BOOL MatchWindowSize(IMediaSample **ppSample,DWORD dwFlags);
    BOOL StopUsingDirectDraw(IMediaSample **ppSample,DWORD dwFlags);
    BOOL FindSpeedyType(IPin *pReceivePin);
    CImageSample *CreateImageSample(LPBYTE pData,LONG Length);

public:

    // Constructor and destructor

    CVideoAllocator(CRenderer *pRenderer,       // Main renderer object
                    CDirectDraw *pDirectDraw,   // DirectDraw hander code
                    CCritSec *pLock,            // Object to use for lock
                    HRESULT *phr);              // Constructor return code

    ~CVideoAllocator();

    // Overriden to delegate reference counts to the filter

    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();

    // Handle returning DCI/DirectDraw surfaces at the right time

    STDMETHODIMP GetBuffer(IMediaSample **ppSample,
                           REFERENCE_TIME *pStartTime,
                           REFERENCE_TIME *pEndTime,
                           DWORD dwFlags);

    STDMETHODIMP ReleaseBuffer(IMediaSample *pMediaSample);
    HRESULT OnReceive(IMediaSample *pMediaSample);
    BOOL IsSurfaceFormat(const CMediaType *pmtIn);
    HRESULT StartStreaming();
    BOOL GetDirectDrawStatus();
    void ResetDirectDrawStatus();
    BOOL IsSamplePending();
    STDMETHODIMP Decommit();

    // Called when the destination changes

    void OnDestinationChange() {
        NOTE("Destination changed");
        m_bVideoSizeChanged = TRUE;
    }

    // Lets the renderer know if DirectDraw is available

    BOOL IsDirectDrawAvailable() {
        NOTE("IsDirectDrawAvailable");
        CAutoLock cVideoLock(this);
        return m_bDirectDrawAvailable;
    };

    void NoDirectDraw(BOOL fDraw) {
        CAutoLock cVideoLock(this);
        m_bNoDirectDraw = fDraw;
    }

    BOOL m_fWasOnWrongMonitor;
    BOOL m_fForcePrepareForMultiMonitorHack;

    // KsProxy hack to disable NotifyRelease when just handling WM_PAINT
    IMemAllocatorNotifyCallbackTemp * InternalGetAllocatorNotifyCallback() {
       return m_pNotify;
    };

    void InternalSetAllocatorNotifyCallback(IMemAllocatorNotifyCallbackTemp * pNotify) {
       m_pNotify = pNotify;
    };

    //  Check all samples are returned
    BOOL AnySamplesOutstanding() const
    {
        return m_lFree.GetCount() != m_lAllocated;
    }

    BOOL UsingDDraw() const
    {
        return m_bDirectDrawStatus;
    }

};

#endif // __ALLOCATE__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\modex\modex.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Implements a Modex renderer filter, Anthony Phillips, January 1996

#ifndef __MODEX__
#define __MODEX__

extern const AMOVIESETUP_FILTER sudModexFilter;

// Forward declarations

class CModexRenderer;
class CModexInputPin;
class CModexWindow;
class CModexAllocator;
class CModexVideo;

#define MODEXCLASS TEXT("ModexRenderer")
#define FULLSCREEN TEXT("FullScreen")
#define NORMAL TEXT("NORMAL")
#define ACTIVATE TEXT("ACTIVATE")
#define DDGFS_FLIP_TIMEOUT 1
#define AMSCAPS_MUST_FLIP 320

// This class implements the IFullScreenVideoEx interface that allows someone
// to query a full screen enabled video renderer for the display modes they
// support and enable or disable them on a mode by mode basis. The selection
// the make is for this particular instance only although through SetDefault
// they can be made the global default. We only currently support the use of
// the primary display monitor (monitor number 0) asking for anything else
// will return an error. When the renderer is fullscreen we can be asked to
// forward any messages we receive to another window with the message drain

class CModexVideo : public IFullScreenVideoEx, public CUnknown, public CCritSec
{
    friend class CModexAllocator;

    LPDIRECTDRAW m_pDirectDraw;           // DirectDraw service provider
    CModexRenderer *m_pRenderer;          // Main video renderer object
    DWORD m_ModesOrder[MAXMODES];		  // Order in which modes should be tried
    DWORD m_dwNumValidModes;			  // number of modes to be tried
    BOOL m_bAvailable[MAXMODES];          // Which modes are available
    BOOL m_bEnabled[MAXMODES];            // And the modes we have enabled
    LONG m_Stride[MAXMODES];              // Stride for each display mode
    DWORD m_ModesAvailable;               // Number of modes supported
    DWORD m_ModesEnabled;                 // Total number made available
    LONG m_CurrentMode;                   // Current display mode selected
    LONG m_ClipFactor;                    // Amount of video we can clip
    LONG m_Monitor;                       // Current monitor for playback
    HWND m_hwndDrain;                     // Where to send window messages
    BOOL m_bHideOnDeactivate;             // Should we hide when switched

    void InitialiseModes();

    friend HRESULT CALLBACK ModeCallBack(LPDDSURFACEDESC pSurfaceDesc,LPVOID lParam);
    friend class CModexRenderer;

public:

    // Constructor and destructor

    CModexVideo(CModexRenderer *pRenderer,
                TCHAR *pName,
                HRESULT *phr);

    ~CModexVideo();
    DECLARE_IUNKNOWN;

    // Accessor functions for IFullScreenVideo interfaces

    void SetMode(LONG Mode) { m_CurrentMode = Mode; };
    LONG GetClipLoss() { return m_ClipFactor; };
    IDirectDraw *GetDirectDraw() { return m_pDirectDraw; };
    HWND GetMessageDrain() { return m_hwndDrain; };
    BOOL HideOnDeactivate() { return m_bHideOnDeactivate; };

    // Access information about our display modes

    HRESULT SetDirectDraw(IDirectDraw *pDirectDraw);
    HRESULT LoadDefaults();
    LONG GetStride(long Mode);
    void OrderModes();

    // Manage the interface IUnknown

    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    // These are the base IFullScreenVideo methods

    STDMETHODIMP CountModes(long *pModes);
    STDMETHODIMP GetModeInfo(long Mode,long *pWidth,long *pHeight,long *pDepth);
    STDMETHODIMP GetCurrentMode(long *pMode);
    STDMETHODIMP IsModeAvailable(long Mode);
    STDMETHODIMP IsModeEnabled(long Mode);
    STDMETHODIMP SetEnabled(long Mode,long bEnabled);
    STDMETHODIMP GetClipFactor(long *pClipFactor);
    STDMETHODIMP SetClipFactor(long ClipFactor);
    STDMETHODIMP SetMessageDrain(HWND hwnd);
    STDMETHODIMP GetMessageDrain(HWND *hwnd);
    STDMETHODIMP SetMonitor(long Monitor);
    STDMETHODIMP GetMonitor(long *Monitor);
    STDMETHODIMP HideOnDeactivate(long Hide);
    STDMETHODIMP IsHideOnDeactivate();
    STDMETHODIMP SetCaption(BSTR strCaption);
    STDMETHODIMP GetCaption(BSTR *pstrCaption);
    STDMETHODIMP SetDefault();

    // These are the extended IFullScreenVideoEx methods

    STDMETHODIMP SetAcceleratorTable(HWND hwnd,HACCEL hAccel);
    STDMETHODIMP GetAcceleratorTable(HWND *phwnd,HACCEL *phAccel);
    STDMETHODIMP KeepPixelAspectRatio(long KeepAspect);
    STDMETHODIMP IsKeepPixelAspectRatio(long *pKeepAspect);

    // And this is a GetModeInfo that tells us if a 16 bit mode is 565 or not

    STDMETHODIMP GetModeInfoThatWorks(long Mode,long *pWidth,long *pHeight,long *pDepth, BOOL *pb565);

};


// This is an allocator derived from the CImageAllocator utility class that
// allocates sample buffers in shared memory. The number and size of these
// are determined when the output pin calls Prepare on us. The shared memory
// blocks are used in subsequent calls to GDI CreateDIBSection, once that
// has been done the output pin can fill the buffers with data which will
// then be handed to GDI through BitBlt calls and thereby remove one copy

class CModexAllocator : public CImageAllocator
{
    CModexRenderer *m_pRenderer;          // Main video renderer object
    CModexVideo *m_pModexVideo;           // Handles our IFullScreenVideo
    CModexWindow *m_pModexWindow;         // DirectDraw exclusive window
    CCritSec *m_pInterfaceLock;           // Main renderer interface lock
    DDCAPS m_DirectCaps;                  // Actual hardware capabilities
    DDCAPS m_DirectSoftCaps;              // Capabilities emulated for us
    DDSURFACEDESC m_SurfaceDesc;	  // Describes the front buffer
    BOOL m_bTripleBuffered;               // Can we triple buffer flips
    DDSCAPS m_SurfaceCaps;		  // And likewise its capabilities
    LPDIRECTDRAW m_pDirectDraw;           // DirectDraw service provider
    LPDIRECTDRAWSURFACE m_pFrontBuffer;   // DirectDraw primary surface
    LPDIRECTDRAWSURFACE m_pBackBuffer;    // Back buffer flipping surface
    LPDIRECTDRAWPALETTE m_pDrawPalette;   // The palette for the surface
    LPDIRECTDRAWSURFACE m_pDrawSurface;   // Single backbuffer for stretch
    CLoadDirectDraw m_LoadDirectDraw;     // Handles loading DirectDraw
    LONG m_ModeWidth;                     // Width we will change mode to
    LONG m_ModeHeight;                    // Likewise the display height
    LONG m_ModeDepth;                     // And finally the target depth
    BOOL m_bOffScreen;                    // Are we stretching an offscreen
    SIZE m_Screen;                        // Current display mode size
    BOOL m_bModeChanged;                  // Have we changed display mode
    CMediaType m_SurfaceFormat;           // Holds current output format
    LONG m_cbSurfaceSize;                 // Accurate size of our surface
    BOOL m_bModexSamples;                 // Are we using Modex samples
    BOOL m_bIsFrontStale;                 // Are we prerolling some images
    BOOL m_fDirectDrawVersion1;           // Is this DDraw version 1?
    RECT m_ScaledTarget;                  // Scaled destination rectangle
    RECT m_ScaledSource;                  // Likewise aligned source details

public:

    // Constructor and destructor

    CModexAllocator(CModexRenderer *pRenderer,
                    CModexVideo *pModexVideo,
                    CModexWindow *pModexWindow,
                    CCritSec *pLock,
                    HRESULT *phr);

    ~CModexAllocator();

    // Help with managing DirectDraw surfaces

    HRESULT LoadDirectDraw();
    void ReleaseDirectDraw();
    void ReleaseSurfaces();
    HRESULT CreateSurfaces();
    HRESULT CreatePrimary();
    HRESULT CreateOffScreen(BOOL bCreatePrimary);

    // Initialise the surface we will be using

    void SetSurfaceSize(VIDEOINFO *pVideoInfo);
    CImageSample *CreateImageSample(LPBYTE pData,LONG Length);
    HRESULT InitDirectDrawFormat(int Mode);
    BOOL CheckTotalMemory(int Mode);
    HRESULT InitTargetMode(int Mode);
    HRESULT AgreeDirectDrawFormat(LONG Mode);
    HRESULT QueryAcceptOnPeer(CMediaType *pMediaType);
    HRESULT NegotiateSurfaceFormat();
    HRESULT QuerySurfaceFormat(CMediaType *pmt);
    BOOL GetDirectDrawStatus();

    // Make sure the pixel aspect ratio is kept

    LONG ScaleToSurface(VIDEOINFO *pInputInfo,
                        RECT *pTargetRect,
                        LONG SurfaceWidth,
                        LONG SurfaceHeight);

    // Lets the renderer know if DirectDraw is loaded

    BOOL IsDirectDrawLoaded() {
        CAutoLock cVideoLock(this);
        return (m_pDirectDraw == NULL ? FALSE : TRUE);
    };

    // Return the static format for the surface

    CMediaType *GetSurfaceFormat() {
        CAutoLock cVideoLock(this);
        return &m_SurfaceFormat;
    };

    // Install our samples with DirectDraw information

    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();
    STDMETHODIMP CheckSizes(ALLOCATOR_PROPERTIES *pRequest);
    STDMETHODIMP ReleaseBuffer(IMediaSample *pMediaSample);

    STDMETHODIMP GetBuffer(IMediaSample **ppSample,
                           REFERENCE_TIME *pStartTime,
                           REFERENCE_TIME *pEndTime,
                           DWORD dwFlags);

    STDMETHODIMP SetProperties(ALLOCATOR_PROPERTIES *pRequest,
                               ALLOCATOR_PROPERTIES *pActual);

    // Used to manage samples as we are processing data

    HRESULT DoRenderSample(IMediaSample *pMediaSample);
    HRESULT DisplaySampleTimes(IMediaSample *pMediaSample);
    HRESULT DrawSurface(LPDIRECTDRAWSURFACE pBuffer);
    void WaitForScanLine();
    BOOL AlignRectangles(RECT *pSource,RECT *pTarget);
    HRESULT UpdateDrawPalette(const CMediaType *pMediaType);
    HRESULT UpdateSurfaceFormat();
    void OnReceive(IMediaSample *pMediaSample);
    HRESULT StopUsingDirectDraw(IMediaSample **ppSample);
    HRESULT StartDirectAccess(IMediaSample *pMediaSample,DWORD dwFlags);
    HRESULT ResetBackBuffer(LPDIRECTDRAWSURFACE pSurface);
    HRESULT PrepareBackBuffer(LPDIRECTDRAWSURFACE pSurface);
    LPDIRECTDRAWSURFACE GetDirectDrawSurface();

    // Called when the filter changes state

    HRESULT OnActivate(BOOL bActive);
    HRESULT BlankDisplay();
    HRESULT Active();
    HRESULT Inactive();
    HRESULT BreakConnect();

	void DistributeSetFocusWindow(HWND hwnd);
};


// Derived class for our windows. To access DirectDraw Modex we supply it
// with a window, this is granted exclusive mode access rights. DirectDraw
// hooks the window and manages a lot of the functionality associated with
// handling Modex. For example when you switch display modes it maximises
// the window, when the user hits ALT-TAB the window is minimised. When the
// user then clicks on the minimised window the Modex is likewise restored

class CModexWindow : public CBaseWindow
{
protected:

    CModexRenderer *m_pRenderer;    // Owning sample renderer object
    HACCEL m_hAccel;                // Handle to application translators
    HWND m_hwndAccel;               // Where to translate messages to

public:

    CModexWindow(CModexRenderer *pRenderer,     // Delegates locking to
                 TCHAR *pName,                  // Object description
                 HRESULT *phr);                 // OLE failure code

    // Message handling methods

    BOOL SendToDrain(PMSG pMessage);
    LRESULT RestoreWindow();
    LRESULT OnSetCursor();
    void OnPaint();

    // Set the window and accelerator table to use
    void SetAcceleratorInfo(HWND hwnd,HACCEL hAccel) {
        m_hwndAccel = hwnd;
        m_hAccel = hAccel;
    };

    // Return the window and accelerator table we're using
    void GetAcceleratorInfo(HWND *phwnd,HACCEL *phAccel) {
        *phwnd = m_hwndAccel;
        *phAccel = m_hAccel;
    };

    // Overriden to return our window and class styles
    LPTSTR GetClassWindowStyles(DWORD *pClassStyles,
                                DWORD *pWindowStyles,
                                DWORD *pWindowStylesEx);

    // Method that gets all the window messages
    LRESULT OnReceiveMessage(HWND hwnd,          // Window handle
                             UINT uMsg,          // Message ID
                             WPARAM wParam,      // First parameter
                             LPARAM lParam);     // Other parameter
};


// This class supports the renderer input pin. We have to override the base
// class input pin because we provide our own special allocator which hands
// out buffers based on DirectDraw surfaces. We have a limitation which is
// that we only connect to source filters that agree to use our allocator.
// This stops us from connecting to the tee for example. The reason being
// that the buffers we hand out don't have any emulation capabilities but
// are based solely on DirectDraw surfaces, to draw someone else's sample
// into a ModeX window would be difficult to do (in fact I don't know how)

class CModexInputPin : public CRendererInputPin
{
    CModexRenderer *m_pRenderer;        // The renderer that owns us
    CCritSec *m_pInterfaceLock;         // Main critical section lock

public:

    // Constructor

    CModexInputPin(
        CModexRenderer *pRenderer,      // The main Modex renderer
        CCritSec *pInterfaceLock,       // Main critical section
        TCHAR *pObjectName,             // Object string description
        HRESULT *phr,                   // OLE failure return code
        LPCWSTR pPinName);              // This pins identification

    // Returns the pin currently connected to us
    IPin *GetPeerPin() {
        return m_Connected;
    };

    // Manage our DirectDraw video allocator

    STDMETHODIMP GetAllocator(IMemAllocator **ppAllocator);
    STDMETHODIMP NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly);
    STDMETHODIMP Receive(IMediaSample *pSample);
};


// This is the COM object that represents a Modex video rendering filter. It
// supports IBaseFilter and IMediaFilter and has a single input stream (pin)
// We support interfaces through a number of nested classes which are made
// as part of the complete object and initialised during our construction.
// By deriving from CBaseVideoRenderer we get all the quality management we
// need and can override the virtual methods to control the type negotiation
// We have two windows, one that we register with DirectDraw to be the top
// most exclusive mode window and another for use when not in fullscreen mode

class CModexRenderer : public ISpecifyPropertyPages, public CBaseVideoRenderer
{
public:

    // Constructor and destructor

    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    CModexRenderer(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr);
    ~CModexRenderer();

    // Implement the ISpecifyPropertyPages interface

    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void **);
    STDMETHODIMP GetPages(CAUUID *pPages);

    CBasePin *GetPin(int n);

    HRESULT SetMediaType(const CMediaType *pmt);
    HRESULT CompleteConnect(IPin *pReceivePin);
    HRESULT CheckMediaType(const CMediaType *pmtIn);
    HRESULT DoRenderSample(IMediaSample *pMediaSample);
    HRESULT CopyPalette(const CMediaType *pSrc,CMediaType *pDest);
    void OnReceiveFirstSample(IMediaSample *pMediaSample);
    HRESULT OnActivate(HWND hwnd,WPARAM wParam);
    HRESULT BreakConnect();
    HRESULT Active();
    HRESULT Inactive();
    void ResetKeyboardState();

public:

    CModexAllocator m_ModexAllocator;   // Our DirectDraw surface allocator
    CModexInputPin m_ModexInputPin;     // Implements pin based interfaces
    CImageDisplay m_Display;            // Manages the video display type
    CMediaType m_mtIn;                  // Source connection media type
    CModexWindow m_ModexWindow;         // Does the actual video rendering
    CModexVideo m_ModexVideo;           // Handles our IFullScreenVideoEx
    BOOL m_bActive;                     // Has the filter been activated
    UINT m_msgFullScreen;               // Sent to window to go fullscreen	
    UINT m_msgNormal;                   // And likewise used to deactivate
    CAMEvent m_evWaitInactive;          // Wait for this after PostMessage
                                        // for m_msgNormal
    UINT m_msgActivate;                 // Activation posted back to ourselves
};

#endif // __MODEX__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\ddmm.cpp ===
/*==========================================================================
 *
 *  Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.
 *
 *  File:       ddmm.cpp
 *  Content:    Routines for using DirectDraw on a multimonitor system
 *
 ***************************************************************************/

//#define WIN32_LEAN_AND_MEAN
//#define WINVER 0x0400
//#define _WIN32_WINDOWS 0x0400
#include <streams.h>
#include <ddraw.h>
#include "ddmm.h"

#define COMPILE_MULTIMON_STUBS
#include "MultMon.h"  // our version of multimon.h include ChangeDisplaySettingsEx

/*
 *  OneMonitorCallback
 */
BOOL CALLBACK OneMonitorCallback(HMONITOR hMonitor, HDC hdc, LPRECT prc, LPARAM lParam)
{
    HMONITOR *phMonitorFound = (HMONITOR *)lParam;

    MONITORINFOEX mi;
    mi.cbSize = sizeof(mi);
    GetMonitorInfo(hMonitor, &mi);

    //
    // look for this monitor among all the display devices,
    // reject this monitor if it is not part of the desktop or
    // if it is a NetMeeting mirroring monitor.
    //

    BOOL rc = TRUE;
    for (DWORD iDevNum = 0; rc; iDevNum++) {

        DISPLAY_DEVICE DisplayDevice;
        DisplayDevice.cb = sizeof(DisplayDevice);
        rc = EnumDisplayDevices(NULL, iDevNum, &DisplayDevice, 0);

        //
        // Does this device match the current monitor ?
        //

        if (rc && (0 == lstrcmpi(DisplayDevice.DeviceName, mi.szDevice))) {

            if (!(DisplayDevice.StateFlags & DISPLAY_DEVICE_ATTACHED_TO_DESKTOP)) {
               return TRUE;
            }

            if (DisplayDevice.StateFlags & DISPLAY_DEVICE_MIRRORING_DRIVER) {
                return TRUE;
            }

            // This monitor is OK so break out the loop
            break;
        }
    }

    //
    // If rc is FALSE then we did not find this monitor among the
    // attached display devices.  This should NOT happen.
    //

    ASSERT(rc == TRUE);


    if (*phMonitorFound == 0)
        *phMonitorFound = hMonitor;
    else
        *phMonitorFound = (HMONITOR)INVALID_HANDLE_VALUE;

    return TRUE;
}

/*
 *  OneMonitorFromWindow
 *
 *  similar to the Win32 function MonitorFromWindow, except
 *  only returns a HMONITOR if a window is on a single monitor.
 *
 *  if the window handle is NULL, the primary monitor is returned
 *  if the window is not visible returns NULL
 *  if the window is on a single monitor returns its HMONITOR
 *  if the window is on more than on monitor returns INVALID_HANDLE_VALUE
 */
HMONITOR OneMonitorFromWindow(HWND hwnd)
{
    HMONITOR hMonitor = NULL;
    RECT rc;

    if (hwnd)
    {
        GetClientRect(hwnd, &rc);
        ClientToScreen(hwnd, (LPPOINT)&rc);
        ClientToScreen(hwnd, (LPPOINT)&rc+1);
    }
    else
    {
	// Todd, looky here
        SetRect(&rc,0,0,10,10);
        //SetRectEmpty(&rc);
    }

    EnumDisplayMonitors(NULL, &rc, OneMonitorCallback, (LPARAM)&hMonitor);
    return hMonitor;
}

#include <atlconv.h>

/*
 * DeviceFromWindow
 *
 * find the direct draw device that should be used for a given window
 *
 * the return code is a "unique id" for the device, it should be used
 * to determine when your window moves from one device to another.
 *
 *      case WM_MOVE:
 *          if (MyDevice != DirectDrawDeviceFromWindow(hwnd,NULL,NULL))
 *          {
 *              // handle moving to a new device.
 *          }
 *
 */
INT_PTR DeviceFromWindow(HWND hwnd, LPSTR szDevice, RECT *prc)
{
    HMONITOR hMonitor;

    if (GetSystemMetrics(SM_CMONITORS) <= 1)
    {
        if (prc) SetRect(prc,0,0,GetSystemMetrics(SM_CXSCREEN),GetSystemMetrics(SM_CYSCREEN));
        if (szDevice) lstrcpyA(szDevice, "DISPLAY");
        return -1;
    }

    hMonitor = OneMonitorFromWindow(hwnd);

    if (hMonitor == NULL || hMonitor == INVALID_HANDLE_VALUE)
    {
	if (prc) SetRectEmpty(prc);
	if (szDevice) *szDevice=0;
        return 0;
    }
    else
    {
	if (prc != NULL || szDevice != NULL)
	{
	    MONITORINFOEX mi;
	    mi.cbSize = sizeof(mi);
	    GetMonitorInfo(hMonitor, &mi);
	    if (prc) *prc = mi.rcMonitor;
	    USES_CONVERSION;
	    if (szDevice) lstrcpyA(szDevice, T2A(mi.szDevice));
	}
        return (INT_PTR)hMonitor;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\hook.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Implements global message hooking, Anthony Phillips, April 1995

#define WM_FREEZE WM_USER           // Stop playing while clipping changes
#define WM_THAW (WM_USER + 1)       // Finished moving the window so restart
#define WM_HOOK (WM_USER + 2)       // Start global hooking of messages
#define WM_UNHOOK (WM_USER + 3)     // Likewise have any hook terminated
#define WM_ONPALETTE (WM_USER + 4)  // Post back WM_PALETTECHANGED messages
#define MAX_OVERLAYS 5              // No more than five overlays at once
#define OCR_ARROW_DEFAULT 100       // Default Windows OEM arrow cursor
#define DDGFS_FLIP_TIMEOUT 1        // Time we sleep for between flips
#define INVALID_COOKIE_VALUE -1     // Valid cookie values are between 0 and 
                                    // (MAX_OVERLAYS - 1).  For more information,
                                    // see the code for GetNextOverlayCookie() 
                                    // and GetColourFromCookie().
#define DEFAULT_COOKIE_VALUE 0      // This cookie value is used by the
                                    // Video Renderer if GetNextOverlayCookie() 
                                    // fails.
extern HINSTANCE g_hInst;           // Module instance handle for hooking

// Global memory block for interprocess communication

typedef struct {
    LONG OverlayCookieUsage[MAX_OVERLAYS];
    HWND VideoWindow[MAX_OVERLAYS];
    LONG WindowInUse[MAX_OVERLAYS];
} VIDEOMEMORY;

// Called at process attachment time

void OnProcessAttachment(BOOL bLoading,const CLSID *rclsid);
void OnProcessDetach();
void OnProcessAttach();

// These are called while we are hooking messages

void OnWindowPosChanging(CWPSTRUCT *pMessage);
void OnWindowCompletion(HWND hCurrent);
void OnWindowPosChanged(CWPSTRUCT *pMessage);
void OnExitSizeMove(CWPSTRUCT *pMessage);

LRESULT CALLBACK GlobalHookProc(INT nCode,WPARAM wParam,LPARAM lParam);
HHOOK InstallGlobalHook(HWND hwnd);
HRESULT RemoveGlobalHook(HWND hwnd,HHOOK hHook);
HRESULT GetNextOverlayCookie(LPSTR szDevice, LONG* plNextCookie);
void RemoveCurrentCookie(LONG lCurrentCookie);
COLORREF GetColourFromCookie(LPSTR szDevice, LONG lCookie);
DWORD GetPaletteIndex(COLORREF Colour);
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\dvideo.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements DirectDraw surface support, Anthony Phillips, August 1995

// This class implements IDirectDrawVideo as a control interface that allows
// an application to specify which types of DirectDraw surfaces we will
// use. It also allows the application to query the surface and provider's
// capabilities so that, for example, it can find out that the window needs
// to be aligned on a four byte boundary. The main filter exposes the control
// interface rather than it being obtained through one of the pin objects.
//
// This class supports a public interface that tries to abstract the details
// of using DirectDraw. The idea is that after connection the allocator
// will scan each of the media types the source supplies and see if any of
// them could be hardware accellerated. For each type it calls FindSurface
// with the format as input, if it succeeds then it has a surface created.
// To find out a type for this surface it calls GetSurfaceFormat, this will
// have the logical bitmap set in it and should be passed to the source to
// check it will accept this buffer type. If an error occurs at any time the
// allocator will call ReleaseSurfaces to clean up. If no surface is found
// the allocator may still open a primary surface using FindPrimarySurface.
//
// It will probably keep the primary surface around all the time as a source
// may be very temperamental as to what buffer type it'll accept. For example
// if the output size is stretched by one pixel the source may reject it but
// resizing the window back again may now make it acceptable. Therefore the
// allocator keeps a primary surface around and keeps asking the source if
// it will accept the buffer type whenever the surface status changes (which
// would be the case if the window was stretched or perhaps became clipped).
//
// The allocator can find out if the surface status has changed by calling
// UpdateDrawStatus, this returns FALSE if no change has happened since the
// last call. This provides a relatively fast way of seeing if anything has
// changed. The allocator may want to force the UpdateDrawStatus to return
// TRUE (eg after state changes) in which case it can call SetStatusChanged.
//
// The SyncOnFill returns TRUE if the current surface should not be handed
// out until the draw time arrives. If it returns FALSE then it should be
// returned from GetBuffer as soon as possible. In the later case the draw
// will typically happen later after the sample has been passed through the
// window object (just as if it was a DIBSECTION buffer). There is a hook
// in DRAW.CPP that detects whether the sample is a DirectDraw buffer and
// if so will call our DrawImage method with the sample to be rendered.
//
// Actual access to the surface is gained by calling LockSurface and should
// be unlocked by calling UnlockSurface. The display may be locked between
// lock and unlocks so calling ANY GDI/USER API may hang the system. The
// only easy way to debug problems is to log to a file and use that as a
// tracing mechansism, use the base class DbgLog logging facilities either
// sent to a file (may miss the last few lines) or set up a remote terminal
//
// Finally there are a number of notification functions that various parts
// of the video renderer call into this DirectDraw object for. These include
// setting the source and destination rectangle. We must also be told when
// we do not have the foreground palette as we must stop handing access to
// the primary surface (if we are on a palettised display device). When we
// are using overlay surfaces we need to know when the window position is
// changed so that we can reposition the overlay, we could do this each time
// an image arrives but that makes it look bad on low frame rate movies

#ifndef __DVIDEO__
#define __DVIDEO__

class CDirectDraw : public IDirectDrawVideo, public CUnknown, public CCritSec
{
    DDCAPS m_DirectCaps;                     // Actual hardware capabilities
    DDCAPS m_DirectSoftCaps;                 // Capabilities emulated for us
    LPDIRECTDRAW m_pDirectDraw;              // DirectDraw service provider
    LPDIRECTDRAW m_pOutsideDirectDraw;       // Provided by somebody else
    LPDIRECTDRAWSURFACE m_pDrawPrimary;      // DirectDraw primary surface
    LPDIRECTDRAWSURFACE m_pOverlaySurface;   // DirectDraw overlay surface
    LPDIRECTDRAWSURFACE m_pOffScreenSurface; // DirectDraw overlay surface
    LPDIRECTDRAWSURFACE m_pBackBuffer;       // Back buffer flipping surface
    LPDIRECTDRAWCLIPPER m_pDrawClipper;      // Used to handle the clipping
    LPDIRECTDRAWCLIPPER m_pOvlyClipper;      // Used to handle the clipping
    CLoadDirectDraw m_LoadDirectDraw;        // Handles loading DirectDraw

    BYTE *m_pDrawBuffer;                     // Real primary surface pointer
    CRenderer *m_pRenderer;                  // Owning renderer core object
    CCritSec *m_pInterfaceLock;              // Main renderer interface lock
    CMediaType m_SurfaceFormat;              // Holds current output format
    DWORD m_Switches;                        // Surface types enabled
    COLORREF m_BorderColour;                 // Current window border colour
    DWORD m_SurfaceType;                     // Holds the surface type in use
    COLORREF m_KeyColour;                    // Actual colour key colour
    LONG m_cbSurfaceSize;                    // Accurate size of our surface

    // Before our video allocator locks a DirectDraw surface it will call our
    // UpdateDrawStatus to check it is still available. That calls GetClipBox
    // to get the bounding video rectangle. If it is complex clipped and we
    // have no clipper nor colour key available then we have to switch back
    // to DIBs. In that situation m_bWindowLock is set to indicate not that
    // we are clipped but that the current clipping situation forced us out

    BOOL m_bIniEnabled;                      // Responds to WIN.INI setting
    BOOL m_bWindowLock;                      // Window environment lock out
    BOOL m_bOverlayVisible;                  // Have we shown the overlay
    BOOL m_bUsingColourKey;                  // Are we using a colour key
    BOOL m_bTimerStarted;                    // Do we have a refresh timer
    BOOL m_bColourKey;                       // Allocated a colour key
    BOOL m_bSurfacePending;                  // Try again when window changes
    BOOL m_bColourKeyPending;                // Set when we hit a key problem
    BOOL m_bCanUseScanLine;		     // Can we use the current line
    BOOL m_bCanUseOverlayStretch;	     // Same for overlay stretches
    BOOL m_bUseWhenFullScreen;		     // Use us when going fullscreen
    BOOL m_bOverlayStale;                    // Is the front buffer stale
    BOOL m_bTripleBuffered;                  // Do we have triple buffered

    // We adjust the source and destination rectangles so that they are
    // aligned according to the hardware restrictions. This allows us
    // to keep using DirectDraw rather than swapping back to software

    DWORD m_SourceLost;                      // Pixels to shift source left by
    DWORD m_TargetLost;                      // Likewise for the destination
    DWORD m_SourceWidthLost;                 // Chop pixels off the width
    DWORD m_TargetWidthLost;                 // And also for the destination
    BOOL m_DirectDrawVersion1;               // Is this DDraw ver. 1.0?
    RECT m_TargetRect;                       // Target destination rectangle
    RECT m_SourceRect;                       // Source image rectangle
    RECT m_TargetClipRect;                   // Target destination clipped
    RECT m_SourceClipRect;                   // Source rectangle clipped

    // Create and initialise a format for a DirectDraw surface

    BOOL InitOnScreenSurface(CMediaType *pmtIn);
    BOOL InitOffScreenSurface(CMediaType *pmtIn,BOOL bPageFlipped);
    BOOL InitDrawFormat(LPDIRECTDRAWSURFACE pSurface);
    BOOL CreateRGBOverlay(CMediaType *pmtIn);
    BOOL CreateRGBOffScreen(CMediaType *pmtIn);
    BOOL CreateYUVOverlay(CMediaType *pmtIn);
    BOOL CreateYUVOffScreen(CMediaType *pmtIn);
    BOOL CreateRGBFlipping(CMediaType *pmtIn);
    BOOL CreateYUVFlipping(CMediaType *pmtIn);
    DWORD GetMediaType(CMediaType *pmt);
    BYTE *LockDirectDrawPrimary();
    BYTE *LockPrimarySurface();
    BOOL ClipPrepare(LPDIRECTDRAWSURFACE pSurface);
    BOOL InitialiseColourKey(LPDIRECTDRAWSURFACE pSurface);
    BOOL InitialiseClipper(LPDIRECTDRAWSURFACE pSurface);
    void SetSurfaceSize(VIDEOINFO *pVideoInfo);
    LPDIRECTDRAWSURFACE GetDirectDrawSurface();
    BOOL LoadDirectDraw();

    // Used while processing samples

    BOOL DoFlipSurfaces(IMediaSample *pMediaSample);
    BOOL AlignRectangles(RECT *pSource,RECT *pTarget);
    BOOL CheckOffScreenStretch(RECT *pSource,RECT *pTarget);
    BOOL CheckStretch(RECT *pSource,RECT *pTarget);
    BOOL UpdateDisplayRectangles(RECT *pClipRect);
    BOOL UpdateRectangles(RECT *pSource,RECT *pTarget);
    void DrawColourKey(COLORREF WindowColour);
    void BlankDestination();
    BOOL FillBlankAreas();
    BYTE *LockSurface(DWORD dwFlags);
    BOOL UnlockSurface(BYTE *pSurface,BOOL bPreroll);
    BOOL CheckWindowLock();
    void ResetRectangles();

    // Helps with managing overlay and flipping surfaces

    BOOL ShowOverlaySurface();
    COLORREF GetRealKeyColour();
    BOOL ShowColourKeyOverlay();
    void OnColourKeyFailure();
    BOOL CheckCreateOverlay();

public:

    // Constructor and destructor

    CDirectDraw(CRenderer *pRenderer,  // Main video renderer
                CCritSec *pLock,       // Object to use for lock
                IUnknown *pUnk,        // Aggregating COM object
                HRESULT *phr);         // Constructor return code

    ~CDirectDraw();

    DECLARE_IUNKNOWN

    // Expose our IDirectDrawVideo interface
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    // Called by the window control object

    BOOL OnPaint(IMediaSample *pMediaSample);
    BOOL OnTimer();
    BOOL OnUpdateTimer();
    void SetBorderColour(COLORREF Colour);
    void SetSourceRect(RECT *pSourceRect);
    void SetTargetRect(RECT *pTargetRect);

    // Setup and release DirectDraw

    BOOL FindSurface(CMediaType *pmtIn, BOOL fFindFlip);
    BOOL FindPrimarySurface(CMediaType *pmtIn);
    BOOL FindDirectDrawPrimary(CMediaType *pmtIn);
    void SetSurfacePending(BOOL bPending);
    BOOL IsSurfacePending();
    BOOL InitDirectDraw(BOOL fIOverlay = false);
    void ReleaseDirectDraw();
    void ReleaseSurfaces();

    // Used while actually processing samples

    BOOL InitVideoSample(IMediaSample *pMediaSample,DWORD dwFlags);
    BOOL ResetSample(IMediaSample *pMediaSample,BOOL bPreroll);
    CMediaType *UpdateSurface(BOOL &bFormatChanged);
    BOOL DrawImage(IMediaSample *pMediaSample);

    // DirectDraw status information

    BOOL CheckEmptyClip(BOOL bWindowLock);
    BOOL CheckComplexClip();
    BOOL SyncOnFill();
    void StartUpdateTimer();
    void StopUpdateTimer();
    BOOL AvailableWhenPaused();
    void WaitForFlipStatus();
    void WaitForScanLine();
    BOOL PrepareBackBuffer();

    // We need extra help for overlays

    BOOL HideOverlaySurface();
    BOOL IsOverlayEnabled();
    void OverlayIsStale();
    BOOL IsOverlayComplete();
    void StartRefreshTimer();
    void StopRefreshTimer();
    BOOL UpdateOverlaySurface();

    LPDIRECTDRAWCLIPPER GetOverlayClipper();

    // Can we use a software cursor over the window

    BOOL InSoftwareCursorMode() {
        CAutoLock cVideoLock(this);
        return !m_bOverlayVisible;
    }

    // Return the static format for the surface

    CMediaType *GetSurfaceFormat() {
        ASSERT(m_bIniEnabled == TRUE);
        return &m_SurfaceFormat;
    };

public:

    // Called indirectly by our IVideoWindow interface

    HRESULT GetMaxIdealImageSize(long *pWidth,long *pHeight);
    HRESULT GetMinIdealImageSize(long *pWidth,long *pHeight);

    // Implement the IDirectDrawVideo interface

    STDMETHODIMP GetSwitches(DWORD *pSwitches);
    STDMETHODIMP SetSwitches(DWORD Switches);
    STDMETHODIMP GetCaps(DDCAPS *pCaps);
    STDMETHODIMP GetEmulatedCaps(DDCAPS *pCaps);
    STDMETHODIMP GetSurfaceDesc(DDSURFACEDESC *pSurfaceDesc);
    STDMETHODIMP GetFourCCCodes(DWORD *pCount,DWORD *pCodes);
    STDMETHODIMP SetDirectDraw(LPDIRECTDRAW pDirectDraw);
    STDMETHODIMP GetDirectDraw(LPDIRECTDRAW *ppDirectDraw);
    STDMETHODIMP GetSurfaceType(DWORD *pSurfaceType);
    STDMETHODIMP SetDefault();
    STDMETHODIMP UseScanLine(long UseScanLine);
    STDMETHODIMP CanUseScanLine(long *UseScanLine);
    STDMETHODIMP UseOverlayStretch(long UseOverlayStretch);
    STDMETHODIMP CanUseOverlayStretch(long *UseOverlayStretch);
    STDMETHODIMP UseWhenFullScreen(long UseWhenFullScreen);
    STDMETHODIMP WillUseFullScreen(long *UseFullScreen);
};

#endif // __DVIDEO__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\dvideo.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements DirectDraw surface support, Anthony Phillips, August 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>

// This class abstracts all the DCI and DirectDraw surface implementation. We
// present an interface to the allocator so that it can supply us with media
// types and ask if we can accellerate them. Typically it will connect to a
// source filter and then enumerate the available types again and see if one
// is available that offers hardware assisted drawing (primary surface access
// also falls into this category). Once we've worked out we can do something
// we supply the caller with a type that describes the surface, they use this
// to call QueryAccept on the source pin to check they can switch types. The
// assumption is that since they already connected with some type that should
// the surface become unavailable at some later stage we can swap back again.
//
// Primary surfaces are dealt with slightly differently as a fall back option
// This is because the format changes so dynamically (for example the window
// being moved) that the allocator cannot really get a format when it starts
// running and QueryAccept on the source. What it does do is if it cannot get
// a relatively static surface type then it creates a primary surface with us
// This it keeps around all the time and each time the format changes it asks
// the source if it will now accept it. The assumption being that the other
// surface types like overlays do not really change much during streaming.
//
// We keep four rectangles internally as member variables. We have a source
// and destination rectangle (in window coordinates) provided by the window
// object. We also keep a real source and destination rectangle for the video
// position on the actual display (calling our UpdateSurface updates these)
// These display rectangles are used to position the overlay and also update
// the output format that represents the primary surface when using them.
//
// Both Win95 and Windows NT have DCI support so we statically link to that
// library, however it is unclear if the DirectDraw will always be available
// so we dynamically link there. Once we have loaded the DirectDraw library
// we keep a module reference count open on it until we are later decommited.
//
// We offer a Lock and an Unlock method to get access to the actual buffer we
// provide, the allocator will normally call UpdateSurface to check we can
// still offer the buffer and indeed whether the source will accept it. There
// is a small window between calling UpdateSurface and actually locking it
// when the window state could change but it should be a fairly small chance
//
// If we get back a DDERR_SURFACELOST return code we treat it like any other
// hard error from DirectDraw - we do not call restore on the surface since
// it can cause the surface stride to change which is too difficult to handle
// For the most part that error is returned when the display mode is changed
// in which case we'll handle the WM_DISPLAYCHANGE message by having our pin
// reconnected which in turn has the DirectDraw surfaces allocated from fresh

static const TCHAR SWITCHES[] = TEXT("AMovieDraw");
static const TCHAR SCANLINE[] = TEXT("ScanLine");
static const TCHAR STRETCH[] = TEXT("Stretch");
static const TCHAR FULLSCREEN[] = TEXT("FullScreen");

#define ASSERT_FLIP_COMPLETE(hr) ASSERT(hr != DDERR_WASSTILLDRAWING)

// Constructor

CDirectDraw::CDirectDraw(CRenderer *pRenderer,  // Main video renderer
                         CCritSec *pLock,       // Object to use for lock
                         IUnknown *pUnk,        // Aggregating COM object
                         HRESULT *phr) :        // Constructor return code

    CUnknown(NAME("DirectDraw object"),pUnk),

    m_pInterfaceLock(pLock),            // Main interface critical section
    m_pRenderer(pRenderer),             // Pointer to the video renderer
    m_pOutsideDirectDraw(NULL),         // Externally provided DirectDraw
    m_pDirectDraw(NULL),                // IDirectDraw interface we're using
    m_pOverlaySurface(NULL),            // Visible overlay surface interface
    m_pOffScreenSurface(NULL),          // Offscreen plain interface pointer
    m_pBackBuffer(NULL),                // Backbuffer for flipping surfaces
    m_pDrawBuffer(NULL),                // Pointer to actual locked buffer
    m_pDrawPrimary(NULL),               // Interface to DirectDraw primary
    m_bIniEnabled(TRUE),                // Can we use DCI/DirectDraw flag
    m_bWindowLock(TRUE),                // Are we locked out from the window
    m_bSurfacePending(FALSE),           // Waiting for a window change flag
    m_bColourKeyPending(FALSE),         // Likewise before using colour keys
    m_Switches(AMDDS_ALL),              // Which surfaces can we allocate
    m_SourceLost(0),                    // Pixels lost on left source edge
    m_TargetLost(0),                    // Likewise pixels lost on target
    m_SourceWidthLost(0),               // Pixels lost from width of source
    m_TargetWidthLost(0),               // And same but for the destination
    m_pDrawClipper(NULL),               // IClipper interface for DirectDraw
    m_pOvlyClipper(NULL),               // Clipper used for IOverlay connections
    m_bOverlayVisible(FALSE),           // Is the overlay currently visible
    m_bTimerStarted(FALSE),             // Have we started an overlay timer
    m_SurfaceType(AMDDS_NONE),          // Bit setting for current surface
    m_bColourKey(FALSE),                // Can we use a colour if necessary
    m_KeyColour(VIDEO_COLOUR),          // Which COLORREF to use for the key
    m_bUsingColourKey(FALSE),           // Are we actually using a colour key
    m_cbSurfaceSize(0),                 // Size of surface in use in bytes
    m_bCanUseScanLine(TRUE),            // Can we use the current scan line
    m_bUseWhenFullScreen(FALSE),        // Always use us when fullscreen
    m_bOverlayStale(FALSE),             // Is the front overlay out of date
    m_bCanUseOverlayStretch(TRUE),      // Likewise for overlay stretching
    m_bTripleBuffered(FALSE),           // Have we triple buffered overlays
    m_DirectDrawVersion1(FALSE)         // Are we running DDraw ver 1.0?
{
    ASSERT(m_pRenderer);
    ASSERT(m_pInterfaceLock);
    ASSERT(phr);
    ASSERT(pUnk);

    ResetRectangles();

    // If DVA = 0 in WIN.INI, don't use DCI/DirectDraw surface access as PSS
    // tells people to use this if they have video problems so don't change
    // On NT the value is in the REGISTRY rather than a old type INI file in
    //
    //  HKEY_CURRENT_USER\SOFTWARE\Microsoft\Multimedia\Drawdib
    //      REG_DWORD dva 1      DCI/DirectDraw enabled
    //      REG_DWORD dva 0      DCI/DirectDraw disabled
    //
    // This value can also be set through the Video For Windows configuration
    // dialog (control panel, drivers, or via media player on an open file)
    // For the time being we default to having DCI/DirectAccess turned ON

    if (GetProfileInt(TEXT("DrawDib"),TEXT("dva"),TRUE) == FALSE) {
        m_bIniEnabled = FALSE;
    }

    // Load any saved DirectDraw switches

    DWORD Default = AMDDS_ALL;
    m_Switches = GetProfileInt(TEXT("DrawDib"),SWITCHES,Default);
    m_bCanUseScanLine = GetProfileInt(TEXT("DrawDib"),SCANLINE,TRUE);
    m_bCanUseOverlayStretch = GetProfileInt(TEXT("DrawDib"),STRETCH,TRUE);
    m_bUseWhenFullScreen = GetProfileInt(TEXT("DrawDib"),FULLSCREEN,FALSE);

    // Allocate and zero fill the output format

    m_SurfaceFormat.AllocFormatBuffer(sizeof(VIDEOINFO));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    if (pVideoInfo) {
        ZeroMemory((PVOID)pVideoInfo,sizeof(VIDEOINFO));
    } else {
        *phr = E_OUTOFMEMORY;
    }
}


// Destructor

CDirectDraw::~CDirectDraw()
{
    ASSERT(m_bTimerStarted == FALSE);
    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pOffScreenSurface == NULL);

    // Release any outside DirectDraw interface

    if (m_pOutsideDirectDraw) {
        m_pOutsideDirectDraw->Release();
        m_pOutsideDirectDraw = NULL;
    }

    // Clean up but should already be done

    StopRefreshTimer();
    ReleaseSurfaces();
    ReleaseDirectDraw();
}


// Overriden to say what interfaces we support

STDMETHODIMP CDirectDraw::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    NOTE("Entering NonDelegatingQueryInterface");

    // We return IDirectDrawVideo and delegate everything else

    if (riid == IID_IDirectDrawVideo) {
        return GetInterface((IDirectDrawVideo *)this,ppv);
    }
    return CUnknown::NonDelegatingQueryInterface(riid,ppv);
}


// When we are asked to create a surface for a given media type we need to
// know whether it is RGB/YUV or possibly neither. This helper method will
// return the AMDDS_YUV bits set if it's YUV, likewise AMDDS_RGB if it is
// an RGB format or AMDDS_NONE if we detected neither. The RGB/YUV type of
// the image is decided on the biCompression field in the BITMAPINFOHEADER

DWORD CDirectDraw::GetMediaType(CMediaType *pmt)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    DWORD MediaType = AMDDS_YUV | AMDDS_RGB;
    NOTE("Entering GetMediaType");

    // We only recognise the GDI defined RGB formats

    if (pHeader->biCompression > BI_BITFIELDS) {
        NOTE("Not a RGB format");
        MediaType &= ~AMDDS_RGB;
    } else {
        NOTE("Not a YUV format");
        MediaType &= ~AMDDS_YUV;
    }

    // If we are on a true colour device we allow connection to palettised
    // formats since the display card can almost always handle these well
    // If this has happened then we can't write into an offscreen surface
    // This means that on a true colour device we wouldn't show a surface
    // that required a palette as switching video formats is too difficult

    if (m_pRenderer->m_Display.GetDisplayDepth() > pHeader->biBitCount) {
        NOTE("Bit depth mismatch");
        MediaType &= ~AMDDS_RGB;
    }

    // Check the compression type and GUID match

    FOURCCMap FourCCMap(pmt->Subtype());
    if (pHeader->biCompression != FourCCMap.GetFOURCC()) {
        NOTE("Subtypes don't match");
        MediaType &= ~AMDDS_YUV;
    }
    return MediaType;
}


// Check we can use direct frame buffer access, we are provided a media type
// that represents the input format and we should try and find a surface to
// accellerate the rendering of it using DCI/DirectDraw. The format that we
// return representing the surface is relatively static so the allocator will
// normally query this with the source filter so if it will accept it. We do
// not return primary surfaces (use FindPrimarySurface instead) through this
// as the type is so dynamic it is better done while we're actually running

// We much prefer flipping overlay surfaces to other types (no tearing, lower
// CPU usage) so we look separately for flipping surfaces and others using
// the fFindFlip flag

BOOL CDirectDraw::FindSurface(CMediaType *pmtIn, BOOL fFindFlip)
{
    NOTE("Entering FindSurface");
    CAutoLock cVideoLock(this);
    DWORD MediaType = GetMediaType(pmtIn);

    // Has someone stolen our surface

    if (m_pDrawPrimary) {
        if (m_pDrawPrimary->IsLost() != DD_OK) {
            NOTE("Lost primary");
            ReleaseDirectDraw();
            InitDirectDraw();
        }
    }

    // Is DCI/DirectDraw enabled

    if (m_bIniEnabled == FALSE || m_pDirectDraw == NULL) {
        NOTE("No DirectDraw available");
        return FALSE;
    }

    // Are there YUV flipping surfaces available

    if (fFindFlip && (m_Switches & AMDDS_YUVFLP)) {
        if (MediaType & AMDDS_YUVFLP) {
            if (CreateYUVFlipping(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_YUVFLP;
                NOTE("Found AMDDS_YUVFLP surface");
                return TRUE;
            }
        }
    }

    // Is there a non RGB overlay surface available

    if (!fFindFlip && (m_Switches & AMDDS_YUVOVR)) {
        if (MediaType & AMDDS_YUVOVR) {
            if (CreateYUVOverlay(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_YUVOVR;
                NOTE("Found AMDDS_YUVOVR surface");
                return TRUE;
            }
        }
    }

    // Are there RGB flipping surfaces available

    if (fFindFlip && (m_Switches & AMDDS_RGBFLP)) {
        if (MediaType & AMDDS_RGBFLP) {
            if (CreateRGBFlipping(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_RGBFLP;
                NOTE("Found AMDDS_RGBFLP surface");
                return TRUE;
            }
        }
    }

    // Is there an RGB overlay surface available

    if (!fFindFlip && (m_Switches & AMDDS_RGBOVR)) {
        if (MediaType & AMDDS_RGBOVR) {
            if (CreateRGBOverlay(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_RGBOVR;
                NOTE("Found AMDDS_RGBOVR surface");
                return TRUE;
            }
        }
    }

    // Is there a non RGB offscreen surface available

    if (!fFindFlip && (m_Switches & AMDDS_YUVOFF)) {
        if (MediaType & AMDDS_YUVOFF) {
            if (CreateYUVOffScreen(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_YUVOFF;
                NOTE("Found AMDDS_YUVOFF surface");
                return TRUE;
            }
        }
    }

    // Create an offscreen RGB drawing surface

    if (!fFindFlip && (m_Switches & AMDDS_RGBOFF)) {
        if (MediaType & AMDDS_RGBOFF) {
            if (CreateRGBOffScreen(pmtIn) == TRUE) {
                m_SurfaceType = AMDDS_RGBOFF;
                NOTE("Found AMDDS_RGBOFF surface");
                return TRUE;
            }
        }
    }
    return FALSE;
}


// This is called when the allocator wants to fall back on using the primary
// surface (probably because nothing better is available). If we can open a
// primary surface either through DCI or DirectDraw we return TRUE otherwise
// we return FALSE. We also create a format that represents the screen but
// it's of little use to query with the source until the window is shown

BOOL CDirectDraw::FindPrimarySurface(CMediaType *pmtIn)
{
    NOTE("Entering FindPrimarySurface");
    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pOffScreenSurface == NULL);
    ASSERT(m_pBackBuffer == NULL);

    const VIDEOINFO *pInput = (VIDEOINFO *) pmtIn->Format();

    // Don't use primary surfaces for low frame rate
    if (pInput->AvgTimePerFrame > (UNITS / 2)) {
        return FALSE;
    }


    CAutoLock cVideoLock(this);

    // Is DCI/DirectDraw enabled

    if (m_bIniEnabled == FALSE) {
        NOTE("INI disabled");
        return FALSE;
    }

    // If we are on a true colour device we allow connection to palettised
    // formats since the display card can almost always handle these well
    // If this has happened then we can't write onto the primary surface
    // This is very quick so it is best done before the following checking

    if (m_pRenderer->m_Display.GetDisplayDepth() != pInput->bmiHeader.biBitCount) {
        NOTE("Bit depth mismatch");
        return FALSE;
    }

    // We have an input media type that we would like to have put directly on
    // the DCI/DirectDraw primary surface. This means the pixel formats must
    // match exactly. The easiest way to do this is to call our check type as
    // that ensures the bit masks match on true colour displays for example

    HRESULT hr = m_pRenderer->m_Display.CheckMediaType(pmtIn);
    if (FAILED(hr)) {
        NOTE("CheckMediaType failed");
        return FALSE;
    }

    // Try first for a DirectDraw primary

    if (FindDirectDrawPrimary(pmtIn) == TRUE) {
        m_SurfaceType = AMDDS_PS;
        NOTE("AMDDS_PS surface");
        return TRUE;
    }

    return FALSE;
}


// This initialises a DirectDraw primary surface. We do not allow access to
// the primary surface if it is bank switched because out MPEG and AVI video
// decoders are block based and therefore touch multiple scan lines at once
// We must also look after re-initialising DirectDraw if we have had a game
// running in which case it will have stolen our surfaces in exclusive mode

BOOL CDirectDraw::FindDirectDrawPrimary(CMediaType *pmtIn)
{
    // Has someone stolen our surface

    // !!! I don't know why, but for some reason the current bit depth may
    // not match the primary bit depth anymore, so we need a new primary
    // or we'll blow up, but the surface isn't lost!

    if (m_pDrawPrimary) {
    	if (m_pDrawPrimary->IsLost() != DD_OK ||
			HEADER(m_SurfaceFormat.Format())->biBitCount !=
			HEADER(pmtIn->Format())->biBitCount) {
        	NOTE("Primary lost");
        	ReleaseDirectDraw();
        	InitDirectDraw();
        }
    }

    // Have we loaded DirectDraw successfully

    if (m_pDrawPrimary == NULL) {
        NOTE("No DirectDraw primary");
        return FALSE;
    }

    // Check we are not bank switched

    if (m_DirectCaps.dwCaps & DDCAPS_BANKSWITCHED) {
        NOTE("Primary surface is bank switched");
        return FALSE;
    }

    // Prepare an output format for the surface

    if (m_Switches & AMDDS_PS) {
        if (InitDrawFormat(m_pDrawPrimary) == TRUE) {
            NOTE("Primary available");
            return InitOnScreenSurface(pmtIn);
        }
    }
    return FALSE;
}


// Resets the source and destination rectangles

void CDirectDraw::ResetRectangles()
{
    NOTE("Reset display rectangles");
    SetRectEmpty(&m_TargetRect);
    SetRectEmpty(&m_SourceRect);
    SetRectEmpty(&m_TargetClipRect);
    SetRectEmpty(&m_SourceClipRect);
}


// If we are using the primary surface (either DCI or DirectDraw) and we are
// on a palettised device then we must make sure we have a one to one mapping
// for the source filter's palette colours. If not then we switch into using
// DIBs and leave GDI to map from our logical palette and the display device
// We have to do this for every frame because we canot guarantee seeing the
// palette change messages, if for example, we have been made a child window
// We return TRUE if we have got a palette lock otherwise we'll return FALSE

BOOL CDirectDraw::CheckWindowLock()
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    NOTE("Entering CheckWindowLock");

    // Check we are using a palettised surface

    if (PALETTISED(pVideoInfo) == FALSE) {
        NOTE("No lock to check");
        return FALSE;
    }

    // It could be an eight bit YUV format

    if (pHeader->biCompression) {
        NOTE("Not BI_RGB type");
        return FALSE;
    }

    ASSERT(pHeader->biClrUsed > 0);
    ASSERT(pHeader->biClrUsed <= 256);
    ASSERT(pHeader->biBitCount == 8);
    ASSERT(pHeader->biCompression == 0);

    // Compare as many colours as they have requested

    PALETTEENTRY apeSystem[256];
    WORD SystemColours,Entries = (WORD) pHeader->biClrUsed;
    WORD ColourBytes = Entries * sizeof(PALETTEENTRY);
    RGBQUAD *pVideo = pVideoInfo->bmiColors;

    // Check the number of logical palette entries

    // Get a DC on the right monitor - it's ugly, but this is the way you have
    // to do it
    HDC hdcScreen;
    if (m_pRenderer->m_achMonitor == NULL ||
		lstrcmpiA(m_pRenderer->m_achMonitor, "DISPLAY") == 0)
        hdcScreen = CreateDCA("DISPLAY", NULL, NULL, NULL);
    else
        hdcScreen = CreateDCA(NULL, m_pRenderer->m_achMonitor, NULL, NULL);
    if ( ! hdcScreen )
        return FALSE;
    GetSystemPaletteEntries(hdcScreen,0,Entries,&apeSystem[0]);
    SystemColours = (WORD)GetDeviceCaps(hdcScreen,SIZEPALETTE);
    DeleteDC(hdcScreen);

    // We can't use more colours than the device has available

    if (Entries > SystemColours) {
        NOTE("Too many colours");
        return TRUE;
    }

    // Check each RGBQUAD against the system palette entry

    for (WORD Count = 0;Count < Entries;Count++) {
        if (apeSystem[Count].peRed != pVideo[Count].rgbRed ||
                apeSystem[Count].peGreen != pVideo[Count].rgbGreen ||
                    apeSystem[Count].peBlue != pVideo[Count].rgbBlue) {
                        return TRUE;
        }
    }
    return FALSE;
}


// If the screen is locked then some window is being moved around which stops
// us from getting clipping information. In this case if we have a clipper or
// an overlay surface then we just assume all is still well and carry with it
// Otherwise we could be using the primary surface and write on other windows
// or desktop. If the screen isn't locked then our video window is occluded

BOOL CDirectDraw::CheckEmptyClip(BOOL bWindowLock)
{
    NOTE("Entering CheckEmptyClip");

    // Is the overlay currently visible

    if (m_bOverlayVisible == FALSE) {
        if (m_pOverlaySurface) {
            return FALSE;
        }
    }

    // Get the screen clipping rectangle

    RECT ClipRect;
    HDC hDC = GetDC(NULL);
    if ( ! hDC )
        return FALSE;
    INT Result = GetClipBox(hDC,&ClipRect);
    ReleaseDC(NULL,hDC);

    // Special cased for overlays and clippers

    if (m_pOverlaySurface || m_pDrawClipper) {
        if (Result == NULLREGION) {
            if (bWindowLock == FALSE) {
                NOTE("Empty clip ok");
                return TRUE;
            }
        }
    }
    return FALSE;
}


// If we have a complex clip region then we can still use the surface if we
// have a clipper (in which case the display driver will handle the clipping
// problem) or can switch to using a colour key (so that the presence of the
// key colour looks after the correct positioning). These are allocated when
// the surface is made. Otherwise we return FALSE to say switch back to DIBs

BOOL CDirectDraw::CheckComplexClip()
{
    NOTE("Entering CheckComplexClip");

    // Do we have a clipper or colour key

    if (m_pDrawClipper == NULL) {
        if (m_bColourKey == FALSE) {
            NOTE("CheckComplexClip failed");
            return FALSE;
        }
    }
    return (m_bColourKeyPending == TRUE ? FALSE : TRUE);
}


// This is the core method for controlling DCI/DirectDraw surfaces. Each time
// the video allocator is preparing to access a surface it calls this to find
// out if the surface is available. Our main purpose is to update the display
// rectangles and return NULL if we detect a situation where the surface can
// not be accessed for whatever reason. The allocator is also interested in
// knowing not just whether the surface is available but also if the format
// that represents it has changed, we handle this through an extra parameter

CMediaType *CDirectDraw::UpdateSurface(BOOL &bFormatChanged)
{
    NOTE("Entering UpdateSurface");
    CAutoLock cVideoLock(this);
    BOOL bWindowLock = m_bWindowLock;
    m_bWindowLock = TRUE;
    bFormatChanged = TRUE;
    RECT ClipRect;

    // See if the palette stops us using the surface

    if (CheckWindowLock() == TRUE) {
        NOTE("Window locked");
        return NULL;
    }

    // Check the current bounding clip rectangle

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    INT Result = GetClipBox(hdc,&ClipRect);
    if (Result == ERROR) {
        NOTE("Clip error");
        return NULL;
    }

    // Can we cope with an empty clip rectangle

    if (Result == NULLREGION) {
        NOTE("Handling NULLREGION clipping");
        m_bWindowLock = !CheckEmptyClip(bWindowLock);
        bFormatChanged = m_bWindowLock;
        return (m_bWindowLock ? NULL : &m_SurfaceFormat);
    }

    // And how about complex clipping situations

    if (Result == COMPLEXREGION) {
        if (CheckComplexClip() == FALSE) {
            NOTE("In COMPLEXREGION lock");
            return NULL;
        }
    }

    m_bWindowLock = FALSE;

    // Update the source and destination rectangles and also position the
    // overlay surface if need be. If any of our methods after the call to
    // GetClipBox fail then they can mark our window as locked and we will
    // return NULL down below. This will switch the allocator back to DIBs

    bFormatChanged = UpdateDisplayRectangles(&ClipRect);
    if (Result == COMPLEXREGION) {
        // don't do anything if the overlay can do clipping without overlays
        if (m_bOverlayVisible == TRUE && m_bColourKey) {
            if (ShowColourKeyOverlay() == FALSE) {
                NOTE("Colour key failed");
                m_bWindowLock = TRUE;
                return NULL;
            }
        }
    }

    // Either of these force a format renegotiation

    if (bWindowLock) {
        bFormatChanged = TRUE;
    }
    return (m_bSurfacePending || m_bWindowLock ? NULL : &m_SurfaceFormat);
}


// Lots of older display cards have alignment restrictions on the source and
// destination rectangle left offset and their overall size (widths). If we
// do not do something about this then we will have to swap back to using DIB
// formats more often. Therefore what we do is to shrink the image within the
// actual required source and destination rectangles to meet the restrictions

// This may in turn mean that the hardware has to do some stretching which it
// may not be capable of, but then we wouldn't have used it anyway so we have
// hardly lost much. We have to shrink the video within the allowed playback
// area rather than shifting otherwise we may write on any windows underneath

BOOL CDirectDraw::AlignRectangles(RECT *pSource,RECT *pTarget)
{
    NOTE("Entering AlignRectangles");

    DWORD SourceLost = 0;           // Pixels to shift source left by
    DWORD TargetLost = 0;           // Likewise for the destination
    DWORD SourceWidthLost = 0;      // Chop pixels off the width
    DWORD TargetWidthLost = 0;      // And also for the destination

    BOOL bMatch = (WIDTH(pSource) == WIDTH(pTarget) ? TRUE : FALSE);
    ASSERT(m_pOverlaySurface || m_pOffScreenSurface);

    // Shift the source rectangle to align it appropriately

    if (m_DirectCaps.dwAlignBoundarySrc) {
        SourceLost = pSource->left % m_DirectCaps.dwAlignBoundarySrc;
        if (SourceLost) {
            SourceLost = m_DirectCaps.dwAlignBoundarySrc - SourceLost;
            if ((DWORD)WIDTH(pSource) > SourceLost) {
                NOTE1("Source left %d",SourceLost);
                pSource->left += SourceLost;
            }
        }
    }

    // Shift the destination rectangle to align it appropriately

    if (m_DirectCaps.dwAlignBoundaryDest) {
        TargetLost = pTarget->left % m_DirectCaps.dwAlignBoundaryDest;
        if (TargetLost) {
            TargetLost = m_DirectCaps.dwAlignBoundaryDest - TargetLost;
            if ((DWORD)WIDTH(pTarget) > TargetLost) {
                NOTE1("Target left %d",TargetLost);
                pTarget->left += TargetLost;
            }
        }
    }

    // We may have to shrink the source rectangle size to align it

    if (m_DirectCaps.dwAlignSizeSrc) {
        SourceWidthLost = WIDTH(pSource) % m_DirectCaps.dwAlignSizeSrc;
        if (SourceWidthLost) {
            if ((DWORD)WIDTH(pSource) > SourceWidthLost) {
                pSource->right -= SourceWidthLost;
                NOTE1("Source width %d",SourceWidthLost);
            }
        }
    }

    // We may have to shrink the target rectangle size to align it

    if (m_DirectCaps.dwAlignSizeDest) {
        TargetWidthLost = WIDTH(pTarget) % m_DirectCaps.dwAlignSizeDest;
        if (TargetWidthLost) {
            if ((DWORD)WIDTH(pTarget) > TargetWidthLost) {
                pTarget->right -= TargetWidthLost;
                NOTE1("Target width %d",TargetWidthLost);
            }
        }
    }

    // Update the state variables

    m_SourceLost = SourceLost;
    m_TargetLost = TargetLost;
    m_SourceWidthLost = SourceWidthLost;
    m_TargetWidthLost = TargetWidthLost;

    // If the source and destination originally differed then we're done

    if (bMatch == FALSE) {
        NOTE("No match");
        return TRUE;
    }

    // If the source and destination were originally the same size and they
    // now differ then we try to make them match. If the source is larger
    // than the destination then we shrink it down but only if the source
    // rectangle width we end up with is still aligned correctly otherwise
    // we won't have got anywhere (we do the same in the opposite case)

    LONG Difference = WIDTH(pSource) - WIDTH(pTarget);
    if (Difference == 0) {
        NOTE("No difference");
        return TRUE;
    }

    // Is the destination bigger than the source or vica versa

    if (Difference < 0) {
        RECT AdjustTarget = *pTarget;
        AdjustTarget.right += Difference; // NOTE Difference < 0
        if (WIDTH(&AdjustTarget) > 0) {
            if ((m_DirectCaps.dwAlignSizeDest == 0) ||
                (WIDTH(&AdjustTarget) % m_DirectCaps.dwAlignSizeDest) == 0) {
                    pTarget->right = AdjustTarget.right;
                    m_TargetWidthLost -= Difference; // NOTE Difference < 0
            }
        }
    } else {
        RECT AdjustSource = *pSource;
        AdjustSource.right -= Difference; // NOTE Difference > 0
        if (WIDTH(&AdjustSource) > 0) {
            if ((m_DirectCaps.dwAlignSizeDest == 0) ||
                (WIDTH(&AdjustSource) % m_DirectCaps.dwAlignSizeDest) == 0) {
                    pSource->right = AdjustSource.right;
                    m_SourceWidthLost += Difference; // NOTE Difference > 0
            }
        }
    }

    NOTE1("Alignment difference %d",Difference);
    NOTE1("  Source left %d",m_SourceLost);
    NOTE1("  Source width %d",m_SourceWidthLost);
    NOTE1("  Target left %d",m_TargetLost);
    NOTE1("  Target width %d",m_TargetWidthLost);

    return TRUE;
}


// If we're using an offscreen surface then we will be asking the display to
// do the drawing through its hardware. If however we are bank switched then
// we shouldn't stretch between video memory since it causes back thrashing
// We also don't use DirectDraw to stretch if the hardware can't do it as it
// is really slow, we are much better off using the optimised GDI stretching

BOOL CDirectDraw::CheckOffScreenStretch(RECT *pSource,RECT *pTarget)
{
    NOTE("Entering CheckOffScreenStretch");

    // If no offscreen stretching is needed then we're all set

    if (WIDTH(pTarget) == WIDTH(pSource)) {
        if (HEIGHT(pTarget) == HEIGHT(pSource)) {
            NOTE("No stretch");
            return TRUE;
        }
    }

    // We should not stretch bank switched offscreen surfaces

    if (m_DirectCaps.dwCaps & DDCAPS_BANKSWITCHED) {
        NOTE("DDCAPS_BANKSWITCHED lock");
        return FALSE;
    }

    // Don't let DirectDraw stretch as it is really slow

    if (m_DirectCaps.dwCaps & DDCAPS_BLTSTRETCH) {
        NOTE("DDCAPS_BLTSTRETCH stretch");
        return TRUE;
    }
    return FALSE;
}


// We provide the minimum and maximum ideal window sizes through IVideoWindow
// An application should use this interface to work out what size the video
// window should be sized to. If the window is either too small or too large
// with respect to any DirectDraw overlay surface in use then we switch back
// to DIBs. S3 boards for example have a variety of overlay stretch factors
// when set in different display modes. We also check the source and target
// rectangles are aligned and sized according to any DirectDraw restrictions

BOOL CDirectDraw::CheckStretch(RECT *pSource,RECT *pTarget)
{
    ASSERT(m_pOverlaySurface || m_pOffScreenSurface);
    DWORD WidthTarget = WIDTH(pTarget);
    DWORD WidthSource = WIDTH(pSource);
    NOTE("Entering CheckStretch");

    // Check we don't fault if these are empty

    if (WidthSource == 0 || WidthTarget == 0) {
        NOTE("Invalid rectangles");
        return FALSE;
    }

    // Separate tests for offscreen surfaces

    if (m_pOverlaySurface == NULL) {
        NOTE("Checking offscreen stretch");
        ASSERT(m_pOffScreenSurface);
        return CheckOffScreenStretch(pSource,pTarget);
    }

    // Can the hardware handle overlay stretching

    if ((m_DirectCaps.dwCaps & DDCAPS_OVERLAYSTRETCH) == 0) {
        if (WidthTarget != WidthSource) {
            if (HEIGHT(pSource) != HEIGHT(pTarget)) {
                if (m_pOverlaySurface) {
                    NOTE("No DDCAPS_OVERLAYSTRETCH");
                    return FALSE;
                }
            }
        }
    }

    DWORD StretchWidth = WIDTH(pTarget) * 1000 / WIDTH(pSource);

    // See if our video isn't being stretched enough

    if (m_DirectCaps.dwMinOverlayStretch) {
        if (StretchWidth < m_DirectCaps.dwMinOverlayStretch) {
            if (m_bCanUseOverlayStretch == TRUE) {
            	NOTE("Fails minimum stretch");
            	return FALSE;
            }
        }
    }

    // Alternatively it may be stretched too much

    if (m_DirectCaps.dwMaxOverlayStretch) {
        if (StretchWidth > m_DirectCaps.dwMaxOverlayStretch) {
            if (m_bCanUseOverlayStretch == TRUE) {
            	NOTE("Fails maximum stretch");
            	return FALSE;
            }
        }
    }

    // Check the rectangle size and alignments

    if (m_DirectCaps.dwAlignBoundarySrc == 0 ||
        (pSource->left % m_DirectCaps.dwAlignBoundarySrc) == 0) {
        if (m_DirectCaps.dwAlignSizeSrc == 0 ||
            (WIDTH(pSource) % m_DirectCaps.dwAlignSizeSrc) == 0) {
            if (m_DirectCaps.dwAlignBoundaryDest == 0 ||
                (pTarget->left % m_DirectCaps.dwAlignBoundaryDest) == 0) {
                if (m_DirectCaps.dwAlignSizeDest == 0 ||
                    (WIDTH(pTarget) % m_DirectCaps.dwAlignSizeDest) == 0) {
                        NOTE("Stretch and alignment ok");
                        return TRUE;
                }
            }
        }
    }

    // Show why the source and/or destination rectangles failed

    if (m_DirectCaps.dwAlignBoundarySrc)
        NOTE1("Source extent %d",(pSource->left % m_DirectCaps.dwAlignBoundarySrc));
    if (m_DirectCaps.dwAlignSizeSrc)
        NOTE1("Source size extent %d",(WIDTH(pSource) % m_DirectCaps.dwAlignSizeSrc));
    if (m_DirectCaps.dwAlignBoundaryDest)
        NOTE1("Target extent %d",(pTarget->left % m_DirectCaps.dwAlignBoundaryDest));
    if (m_DirectCaps.dwAlignSizeDest)
        NOTE1("Target size extent %d",(WIDTH(pTarget) % m_DirectCaps.dwAlignSizeDest));

    return FALSE;
}


// Update the source and target rectangles for the DCI/DirectDraw surface. We
// return FALSE if the update caused no change, otherwise we return TRUE. For
// offscreen and overlay surfaces a change in source or target rectangles has
// no effect on the type we request on the source filter because the area we
// invoke UpdateOverlay or blt with is handled solely through DirectDraw. The
// method is passed in a clipping rectangle for the destination device context
// that should be used to calculate the actual visible video playback surface
// NOTE we update the m_SourceClipRect and m_TargetClipRect member variables

BOOL CDirectDraw::UpdateDisplayRectangles(RECT *pClipRect)
{
    NOTE("Entering UpdateDisplayRectangles");
    RECT TargetClipRect,SourceClipRect;
    ASSERT(pClipRect);

    // The clipping rectangle is in window coordinates

    if (IntersectRect(&TargetClipRect,&m_TargetRect,pClipRect) == FALSE) {
        NOTE("Intersect lock");
        m_bWindowLock = TRUE;
        return TRUE;
    }

    // Find in screen coordinates the corner of the client rectangle

    POINT ClientCorner = {0,0};
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(ClientToScreen(hwnd,&ClientCorner));

    // We want the offset from the start of this monitor, not (0,0) !
    ClientCorner.x -= m_pRenderer->m_rcMonitor.left;
    ClientCorner.y -= m_pRenderer->m_rcMonitor.top;

    // We use the source and destination sizes many times

    ASSERT(IsRectEmpty(&m_SourceRect) == FALSE);
    LONG SrcWidth = WIDTH(&m_SourceRect);
    LONG SrcHeight = HEIGHT(&m_SourceRect);
    LONG DstWidth = WIDTH(&m_TargetRect);
    LONG DstHeight = HEIGHT(&m_TargetRect);
    LONG xOffset = m_TargetRect.left + ClientCorner.x;
    LONG yOffset = m_TargetRect.top + ClientCorner.y;

    // Adjust the destination rectangle to be in device coordinates

    TargetClipRect.left += ClientCorner.x;
    TargetClipRect.right += ClientCorner.x;
    TargetClipRect.top += ClientCorner.y;
    TargetClipRect.bottom += ClientCorner.y;

    // From the target section visible calculate the source required

    SourceClipRect.left = m_SourceRect.left +
        ((TargetClipRect.left - xOffset) * SrcWidth / DstWidth);
    SourceClipRect.right = m_SourceRect.left +
        ((TargetClipRect.right - xOffset) * SrcWidth / DstWidth);
    SourceClipRect.top = m_SourceRect.top +
        ((TargetClipRect.top - yOffset) * SrcHeight / DstHeight);
    SourceClipRect.bottom = m_SourceRect.top +
        ((TargetClipRect.bottom - yOffset) * SrcHeight / DstHeight);

    // Check we have a valid source rectangle

    if (IsRectEmpty(&SourceClipRect)) {
        NOTE("Source is empty");
        m_bWindowLock = TRUE;
        return TRUE;
    }

    // Adjust rectangles to maximise surface usage

    if (m_pOverlaySurface || m_pOffScreenSurface) {
        AlignRectangles(&SourceClipRect,&TargetClipRect);
        if (CheckStretch(&SourceClipRect,&TargetClipRect) == FALSE) {
            NOTE("Setting window lock");
            m_bWindowLock = TRUE;
            return TRUE;
        }
    }
    return UpdateRectangles(&SourceClipRect,&TargetClipRect);
}


// We are passed in the new source and target rectangles clipped according to
// the visible area of video in the display device (they should not be empty)
// If they match the current display rectangles then we'll return FALSE as no
// format negotiation needs to take place. If we have an overlay or offscreen
// surface then likewise no format negotiation needs to take place as all the
// handling of which surface areas to use is taken care of through DirectDraw

BOOL CDirectDraw::UpdateRectangles(RECT *pSource,RECT *pTarget)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    NOTE("Entering UpdateRectangles");

    // Check the target is DWORD aligned for primary surfaces

    if (GetDirectDrawSurface() == NULL) {
        if ((pTarget->left * pHeader->biBitCount / 8) & 3) {
            NOTE("Not DWORD aligned");
            m_bWindowLock = TRUE;
            return TRUE;
        }
    }

    // Are both the source and target rectangles the same

    if (EqualRect(&m_SourceClipRect,pSource)) {
        if (EqualRect(&m_TargetClipRect,pTarget)) {
            NOTE("Rectangles match");
            return FALSE;
        }
    }

    // Switch back if we were waiting for a change

    BOOL bSurfacePending = IsSurfacePending();
    DbgLog((LOG_TRACE,3,TEXT("SourceClipRect = (%d,%d,%d,%d)"),
		pSource->left, pSource->top, pSource->right, pSource->bottom));
    DbgLog((LOG_TRACE,3,TEXT("TargetClipRect = (%d,%d,%d,%d)"),
		pTarget->left, pTarget->top, pTarget->right, pTarget->bottom));
    m_SourceClipRect = *pSource;
    m_TargetClipRect = *pTarget;
    SetSurfacePending(FALSE);

    // Offscreen surfaces are not affected

    if (GetDirectDrawSurface()) {
        NOTE("Is an offscreen");
        UpdateOverlaySurface();
        return bSurfacePending;
    }

    // Update the surface format rectangles

    pVideoInfo->rcSource = m_SourceClipRect;
    NOTERC("Primary source",m_SourceClipRect);
    pVideoInfo->rcTarget = m_TargetClipRect;
    NOTERC("Primary target",m_TargetClipRect);
    return TRUE;
}


// Called to free any DCI/DirectDraw resources we are currently holding. We
// get the surface pointer passed back in because DirectDraw wants it back
// since it is possible to lock a surface simultaneously with a number of
// different destination rectangles although we just lock the whole thing
// WARNING the surface should be unlocked before the video critical section
// is unlocked, there is a small chance of us seeing an invalid state but
// there is a very big chance of hanging if we have to wait for the lock

BOOL CDirectDraw::UnlockSurface(BYTE *pSurface,BOOL bPreroll)
{
    NOTE("Entering UnlockSurface");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(pSurface);

    // Is it just the primary that needs unlocking

    if (GetDirectDrawSurface() == NULL) {
        NOTE("Unlocking DirectDraw primary");
        m_pDrawPrimary->Unlock(m_pDrawBuffer);
        m_pDrawBuffer = NULL;
        return TRUE;
    }

    // Unlock the surface and update the overlay position - on Cirrus CL5440
    // cards in 1024x768x8 bit mode we can lock the overlay surface but when
    // we return to do the unlock DirectDraw barfs at the pointer and leaves
    // the surface locked! The answer is just to pass a NULL surface pointer

    GetDirectDrawSurface()->Unlock(NULL);
    if (bPreroll == TRUE) {
        NOTE("Preroll");
        return TRUE;
    }

    // If this is a normal overlay then have it displayed

    if (m_pBackBuffer == NULL) {
        NOTE("Showing overlay surface");
        return ShowOverlaySurface();
    }
    return TRUE;
}


// Return the current DirectDraw surface we're using. We return NULL if we
// are using the DCI/DirectDraw primary surface. So if the caller wants to
// know the DirectDraw surface so that it can lock or unlock it they will
// have to check the return code for NULL and set the surface pointer to be
// m_pDrawPrimary. With flipping surfaces we always return the back buffer

LPDIRECTDRAWSURFACE CDirectDraw::GetDirectDrawSurface()
{
    NOTE("Entering GetDirectDrawSurface");

    // Do we have an offscreen surface

    if (m_pOffScreenSurface) {
        return m_pOffScreenSurface;
    }

    // Do we have a flipping surface

    if (m_pBackBuffer) {
        return m_pBackBuffer;
    }
    return m_pOverlaySurface;
}


// The video allocator calls this when it is ready to lock the surface. The
// IMediaSample we are given is cast to a CVideoSample and then we can lock
// the surface which may return NULL if it cannot be done. In which case we
// return FALSE so that the allocator knows to switch back to DIBs. Assuming
// all went well we can initialise the video sample with the surface pointer
// as well as the two DirectDraw interfaces it exposes and the surface size

BOOL CDirectDraw::InitVideoSample(IMediaSample *pMediaSample,DWORD dwFlags)
{
    NOTE("Entering InitVideoSample");
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    BYTE *pSurface = LockSurface(dwFlags);
    ASSERT(m_bIniEnabled == TRUE);

    // Last chance to do something else

    if (pSurface == NULL) {
        return FALSE;
    }

    // Set the DirectDraw surface we are using

    LPDIRECTDRAWSURFACE pDrawSurface = GetDirectDrawSurface();
    if (pDrawSurface == NULL) {
        pDrawSurface = m_pDrawPrimary;
    }

    // Set the DirectDraw instance for the sample

    LPDIRECTDRAW pDirectDraw = NULL;
    if (pDrawSurface) {
        ASSERT(m_pDirectDraw);
        pDirectDraw = m_pDirectDraw;
    }

    // Initialise the sample with the DirectDraw interfaces

    pVideoSample->SetDirectInfo(pDrawSurface,          // Surface interface
                                pDirectDraw,           // DirectDraw object
                                m_cbSurfaceSize,       // Size of the buffer
                                (BYTE *) pSurface);    // Pointer to surface
    return TRUE;
}


// Called when the video sample is delivered to our pin or released - it may
// not be a DCI/DirectDraw enabled sample, we know if it is because it holds
// a direct surface pointer available via GetDirectBuffer. If it is a direct
// buffer then we must unlock the surface. None of this requires this object
// to be locked because we don't want to contend locks with surfaces locked

BOOL CDirectDraw::ResetSample(IMediaSample *pMediaSample,BOOL bPreroll)
{
    NOTE1("Entering ResetSample (Preroll sample %d)",bPreroll);
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    BYTE *pSurface = pVideoSample->GetDirectBuffer();
    pVideoSample->SetDirectInfo(NULL,NULL,0,NULL);

    // Is this a hardware DCI/DirectDraw buffer

    if (pSurface == NULL) {
        NOTE("Not hardware");
        return FALSE;
    }

    // Unlock the hardware surface

    NOTE("Unlocking DirectDraw");
    UnlockSurface(pSurface,bPreroll);
    m_bOverlayStale = bPreroll;

    return TRUE;
}


// When using a hardware offscreen draw surface we will normally wait for the
// monitor scan line to move past the destination rectangle before drawing so
// that we avoid tearing where possible. Of course not all display cards can
// support this feature and even those that do will see a performance drop of
// about 10% because we sit polling (oh for a generic PCI monitor interrupt)

void CDirectDraw::WaitForScanLine()
{
    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pBackBuffer == NULL);
    ASSERT(m_pOffScreenSurface);
    HRESULT hr = NOERROR;
    DWORD dwScanLine;

    // Some display cards like the ATI Mach64 support reporting of the scan
    // line they are processing. However not all drivers are setting the
    // DDCAPS_READSCANLINE capability flag so we just go ahead and ask for
    // it anyway. We allow for 10 scan lines above the top of our rectangle
    // so that we have a little time to thunk down and set the draw call up

    #define SCANLINEFUDGE 10
    while (m_bCanUseScanLine == TRUE) {

    	hr = m_pDirectDraw->GetScanLine(&dwScanLine);
        if (FAILED(hr)) {
            NOTE("No scan line");
            break;
        }

        NOTE1("Scan line returned %lx",dwScanLine);

    	if ((LONG) dwScanLine + SCANLINEFUDGE >= m_TargetClipRect.top) {
            if ((LONG) dwScanLine <= m_TargetClipRect.bottom) {
                NOTE("Scan inside");
                continue;
            }
        }
        break;
    }
}


// When issuing flips asynchrously we must sometimes wait for previous flips
// to complete before sending another. When triple buffering we do this just
// before the flip call. For double buffered we do this before locking the
// surface to decode the next frame. We should get better performance from
// triple buffering as the flip should be picked up at the next monitor sync

void CDirectDraw::WaitForFlipStatus()
{
    if (m_pBackBuffer == NULL) return;
    ASSERT(m_pOffScreenSurface == NULL);
    ASSERT(m_pDrawPrimary);
    ASSERT(m_pOverlaySurface);
    ASSERT(m_pDirectDraw);

    while (m_pBackBuffer->GetFlipStatus(DDGFS_ISFLIPDONE) ==
        DDERR_WASSTILLDRAWING) Sleep(DDGFS_FLIP_TIMEOUT);
}


// This is called just before we lock the DirectDraw surface, if we are using
// a complex overlay set, either double or triple buffered then we must copy
// the current upto date overlay into the back buffer beforehand. If however
// the flags on the GetBuffer call indicate that the buffer is not key frame
// then we don't bother doing this - which is the case for all MPEG pictures

BOOL CDirectDraw::PrepareBackBuffer()
{
    NOTE("Preparing backbuffer");
    if (m_pBackBuffer == NULL) {
        return TRUE;
    }

    // Check the overlay has not gone stale

    if (m_bOverlayStale == TRUE) {
        NOTE("Overlay is stale");
        return TRUE;
    }

    // Finally copy the overlay to the back buffer

    HRESULT hr = m_pBackBuffer->BltFast((DWORD) 0, (DWORD) 0,  // Target place
                                        m_pOverlaySurface,     // Image source
                                        (RECT *) NULL,         // All source
                                        DDBLTFAST_WAIT |       // Wait finish
                                        DDBLTFAST_NOCOLORKEY); // Copy type
    ASSERT_FLIP_COMPLETE(hr);

    if (FAILED(hr)) {
        DbgLog((LOG_TRACE, 1, TEXT("BltFast failed code %8.8X"), hr));
    }

    if (FAILED(hr)) {
        //  Give up on the back buffers
        m_pBackBuffer = NULL;
    }


    return TRUE;
}


// Begins access to the DCI/DirectDraw surface. This is a public entry point
// used by our video allocator when the time arrives for the next frame to be
// decompressed. If we tell it the sync should happen on the fill then it'll
// wait until the sample display time arrives before calling us. If we tell
// it the buffer should sync'ed on the draw it calls us as soon as possible

BYTE *CDirectDraw::LockSurface(DWORD dwFlags)
{
    NOTE("Entering LockSurface");
    ASSERT(m_bIniEnabled == TRUE);
    CAutoLock cVideoLock(this);

    // Are we using the primary surface

    if (GetDirectDrawSurface() == NULL) {
        return LockPrimarySurface();
    }

    ASSERT(m_pDirectDraw);
    ASSERT(m_pDrawPrimary);
    HRESULT hr = NOERROR;

    // For complex overlays prepare the back buffer

    if (dwFlags & AM_GBF_NOTASYNCPOINT) {
        if (PrepareBackBuffer() == FALSE) {
            NOTE("Prepare failed");
            return NULL;
        }
    }

    // Reset the size field in the DDSURFACEDESC structure

    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    IDirectDrawSurface *pSurface = GetDirectDrawSurface();
    NOTE1("Locking offscreen surface %lx",pSurface);

    // Lock the surface to get the buffer pointer

    hr = pSurface->Lock((RECT *) NULL,    // Target rectangle
                        &SurfaceDesc,     // Return information
                        DDLOCK_WAIT,      // Wait for surface
                        (HANDLE) NULL);   // Don't use event


    // make sure the pitch is valid here
    if (SurfaceDesc.lPitch <= -1)
    {
	pSurface->Unlock(NULL);
	DbgLog((LOG_ERROR, 0, TEXT("inside LockSurface, Pitch = %d"), SurfaceDesc.lPitch));
	return NULL;
    }

    ASSERT_FLIP_COMPLETE(hr);

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        StartUpdateTimer();
        return NULL;
    }

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        NOTE1("Lock failed %hx",hr);
        SetSurfacePending(TRUE);
        return NULL;
    }

    // Display some surface information

    NOTE1("Stride %d",SurfaceDesc.lPitch);
    NOTE1("Width %d",SurfaceDesc.dwWidth);
    NOTE1("Height %d",SurfaceDesc.dwHeight);
    NOTE1("Surface %x",SurfaceDesc.lpSurface);
    return (PBYTE) SurfaceDesc.lpSurface;
}


// Internal method to lock the DirectDraw primary surface only. We're called
// by LockPrimarySurface. If you lock a specific region with DCI the pointer
// returned is always the start of the frame buffer. In DirectDraw we get a
// pointer to the start of the actual rectangle. To make the two consistent
// we back the pointer up from DirectDraw to get to the start of the surface
// We must pass in valid rectangles so that any software cursors are handled

BYTE *CDirectDraw::LockDirectDrawPrimary()
{
    NOTE("Entering LockDirectDrawPrimary");
    ASSERT(m_pDirectDraw);
    ASSERT(m_pDrawPrimary);
    HRESULT hr = NOERROR;

    // Reset the size field in the DDSURFACEDESC structure

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    NOTE1("Locking primary surface %lx",m_pDrawPrimary);

    // Lock the DirectDraw primary surface to get the pointer

    hr = m_pDrawPrimary->Lock(&pVideoInfo->rcTarget,  // Our target rectangle
                              &SurfaceDesc,           // Surface descriptor
                              DDLOCK_WAIT,            // Wait until available
                              (HANDLE) NULL);         // Don't signal event

    // make sure the pitch is valid here
    if (SurfaceDesc.lPitch <= -1)
    {
	m_pDrawPrimary->Unlock(SurfaceDesc.lpSurface);
	DbgLog((LOG_ERROR, 0, TEXT("inside LockDirectDrawPrimary, Pitch = %d"), SurfaceDesc.lPitch));
	return NULL;
    }

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        StartUpdateTimer();
        return NULL;
    }

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        NOTE1("Lock failed %hx",hr);
        SetSurfacePending(TRUE);
        return NULL;
    }

    // Back the pointer up to the start of the buffer

    NOTE("Locked primary surface successfully");
    LPBYTE pFrameBuffer = (PBYTE) SurfaceDesc.lpSurface;
    DWORD Stride = DIBWIDTHBYTES(pVideoInfo->bmiHeader);
    pFrameBuffer -= (Stride * pVideoInfo->rcTarget.top);
    DWORD BytesPixel = (SurfaceDesc.ddpfPixelFormat.dwRGBBitCount / 8);
    if (m_DirectDrawVersion1) BytesPixel = 1;
    pFrameBuffer -= (pVideoInfo->rcTarget.left * BytesPixel);
    m_pDrawBuffer = (PBYTE) SurfaceDesc.lpSurface;

    NOTE1("Frame Buffer %x",(PBYTE) SurfaceDesc.lpSurface);
    NOTE1("Stride of surface %d",Stride);
    NOTE1("Lines to skip %d",pVideoInfo->rcTarget.top);
    NOTE1("Pixels in from left edge %d",pVideoInfo->rcTarget.left);
    NOTE1("Resulting frame buffer %x",pFrameBuffer);
    NOTE1("DirectDraw version 1? = %d",m_DirectDrawVersion1);

    return pFrameBuffer;
}


// Returns a pointer to the first pixel of the primary surface (either DCI or
// DirectDraw). If we are on a bank switched DCI enabled display then we have
// to construct the linear frame buffer pointer from a segment and offset. We
// call through the DCIMAN32 entry points to get access to the surface as we
// cannot always call from a Win32 program straight to kernel drives. When we
// call DCICreatePrimary it fills the methods with either 0xFFFFFFFF or zero

BYTE *CDirectDraw::LockPrimarySurface()
{
    NOTE("Entering LockPrimarySurface");
    ASSERT(m_pDrawPrimary);

    return LockDirectDrawPrimary();
}


// Update the overlay surface to position it correctly. We split out updating
// the overlay position into this function because it is so expensive to call
// In particular it is easy to consume more than 12% of the CPU playing back
// on BrookTree and S3 cards if you dumbly call UpdateOverlay for each frame
// Therefore we only call it when something really happens to the destination
// or source rectangles. If we update a little late then we don't lose much
// as overlay surfaces don't scribble their images into the real frame buffer

BOOL CDirectDraw::UpdateOverlaySurface()
{
    NOTE("Entering UpdateOverlaySurface");
    HRESULT hr = NOERROR;
    CAutoLock cVideoLock(this);

    // Do we have a visible overlay surface

    if (m_bOverlayVisible == FALSE ||
            m_pOverlaySurface == NULL ||
                m_bWindowLock == TRUE) {

        return TRUE;
    }

    NOTE("Painting window");
    OnPaint(NULL);
    DWORD Flags = DDOVER_SHOW;
    WaitForFlipStatus();

    // Set the approprate flags to maintain our state

    if (m_bUsingColourKey) {
        Flags |= DDOVER_KEYDEST;
        NOTE("Set DDOVER_KEYDEST");
    }

    // Position the overlay with the current source and destination

    //DbgLog((LOG_TRACE,1,TEXT("UpdateOverlaySurface is SHOWing the overlay")));
    hr = m_pOverlaySurface->UpdateOverlay(&m_SourceClipRect,  // Video source
                                          m_pDrawPrimary,     // Main surface
                                          &m_TargetClipRect,  // Sink position
                                          (DWORD) Flags,      // Flag settings
                                          NULL);              // No effects
    ASSERT_FLIP_COMPLETE(hr);

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        HideOverlaySurface();
        StartUpdateTimer();
        return FALSE;
    }

    NOTE1("Update overlay returned %lx",hr);
    NOTERC("Source",m_SourceClipRect);
    NOTERC("Target",m_TargetClipRect);

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        SetSurfacePending(TRUE);
        HideOverlaySurface();
        NOTE("Update failed");
        return FALSE;
    }

    // There seems to be a slight snag with using non colour keyed overlays
    // on BrookTree cards. If you call UpdateOverlay in quick succession it
    // misses some of them out thereby leaving the overlay positioned wrong
    // The simplest solution is to wait each time for the vertical refresh

    m_pDirectDraw->WaitForVerticalBlank(DDWAITVB_BLOCKEND,NULL);
    return TRUE;
}


// This function has the overlay shown if not already done. If we're showing
// the overlay surface for the first time then clear the target rectangle
// in the video window underneath. Otherwise it flashes up the wrong image
// when we are dragging the window around and then finally hide the overlay.
// After we have shown the overlay we look to see if we are complex clipped
// and if so then we try to switch to colour keys. This may fail if colour
// keys are not available in which case we continue using overlays anyway

BOOL CDirectDraw::ShowOverlaySurface()
{
    NOTE("Entering ShowOverlaySurface");
    CAutoLock cVideoLock(this);
    HRESULT hr = NOERROR;

    // Are we using an overlay surface

    if (m_pOverlaySurface == NULL ||
            m_bWindowLock == TRUE ||
                m_bOverlayVisible == TRUE) {
                    return TRUE;
    }

    WaitForFlipStatus();

    // Position the overlay with the current source and destination

    //DbgLog((LOG_TRACE,1,TEXT("ShowOverlaySurface is SHOWing the overlay!")));
    hr = m_pOverlaySurface->UpdateOverlay(&m_SourceClipRect,  // Video source
                                          m_pDrawPrimary,     // Main surface
                                          &m_TargetClipRect,  // Sink position
                                          DDOVER_SHOW,        // Show overlay
                                          NULL);              // No effects
    ASSERT_FLIP_COMPLETE(hr);

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        StartUpdateTimer();
        return FALSE;
    }

    NOTE1("Show overlay returned %lx",hr);
    NOTERC("Source",m_SourceClipRect);
    NOTERC("Target",m_TargetClipRect);

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        NOTE("Overlay not shown");
        SetSurfacePending(TRUE);
        return FALSE;
    }

    m_bOverlayVisible = TRUE;
    NOTE("Painting window");
    OnPaint(NULL);

    // This helps out the BrookTree DirectDraw guys whose driver only clips
    // to DWORD boundaries when colour keys aren't being used. So when the
    // hardware signals colour keys have no overhead we always install one
    // For other DirectDraw drivers using colour keys has an implicit cost

    // only do this if we're using colour key and not a clipper
    if (m_bColourKey) {
        return ShowColourKeyOverlay();
    }
    return TRUE;
}



// When a DirectDraw object is created we allocate a RGB triplet for us to
// use for any colour keys we need. However that RGB values isn't the same
// as the RGB value that is represented in the frame buffer once the colour
// key has been painted. We therefore lock the primary surface and get the
// actual pixel value out of the frame buffer. We can then use this to pass
// to DirectDraw as the real colour key. By doing this we take into account
// the mapping between the logical RGB value and what actually gets drawn

COLORREF CDirectDraw::GetRealKeyColour()
{
    NOTE("Entering GetRealKeyColour");
    DDSURFACEDESC SurfaceDesc;
    COLORREF RealColour;
    HDC hdc;

    // Get a screen device context

    HRESULT hr = m_pDrawPrimary->GetDC(&hdc);
    if (FAILED(hr)) {
        NOTE("No screen HDC");
        return INFINITE;
    }

    // Set the colour key and then read it back

    COLORREF CurrentPixel = GetPixel(hdc,0,0);
    SetPixel(hdc,0,0,m_KeyColour);
    EXECUTE_ASSERT(GdiFlush());
    m_pDrawPrimary->ReleaseDC(hdc);
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);

    hr = m_pDrawPrimary->Lock((RECT *) NULL,    // Lock all the surface
                              &SurfaceDesc,     // Surface description
                              DDLOCK_WAIT,      // Poll until available
                              (HANDLE) NULL);   // No event to signal
    if (FAILED(hr)) {
        NOTE("Lock failed");
        return INFINITE;
    }

    // Read the pixel value and knock off any extraneous bits

    RealColour = *(DWORD *) SurfaceDesc.lpSurface;
    DWORD Depth = SurfaceDesc.ddpfPixelFormat.dwRGBBitCount;
    if (SurfaceDesc.ddpfPixelFormat.dwRGBBitCount < 32) {
        RealColour &= ((1 << Depth) - 1);
    }
    m_pDrawPrimary->Unlock(SurfaceDesc.lpSurface);

    // Reset the pixel value we tested with

    if (m_pDrawPrimary->GetDC(&hdc) == DD_OK) {
        SetPixel(hdc,0,0,CurrentPixel);
        m_pDrawPrimary->ReleaseDC(hdc);
    }
    return RealColour;
}


// Called once the overlay has been shown and we detect a that the window has
// become complex clipped to try and switch to using a colour key. We get a
// colour to use from our shared memory block although that does not specify
// what colour really got painted. To this end we read the pixel from the top
// left hand corner of the video playback area and use that as the colour key
// If setting a colour fails then we must repaint the window background black

BOOL CDirectDraw::ShowColourKeyOverlay()
{
    NOTE("Entering ShowColourKeyOverlay");
    CAutoLock cVideoLock(this);
    HRESULT hr = NOERROR;

    // Are we already using a colour key

    if (m_bUsingColourKey == TRUE) {
        return TRUE;
    }

    // Check we can go ahead and install a colour key

    if (m_bColourKey == FALSE || m_bColourKeyPending == TRUE ||
            m_pOverlaySurface == NULL ||
                m_bWindowLock == TRUE) {
                    return FALSE;
    }

    // Have the colour key background painted

    m_bUsingColourKey = TRUE;
    OnPaint(NULL);
    WaitForFlipStatus();

    // Can we get a real colour key value

    COLORREF KeyColour = GetRealKeyColour();
    if (KeyColour == INFINITE) {
        return FALSE;
    }

    DDCOLORKEY DDColorKey = { KeyColour,0 };

    // Tell the primary surface what to expect

    //DbgLog((LOG_TRACE,3,TEXT("Setting our colour key now")));
    hr = m_pDrawPrimary->SetColorKey(DDCKEY_DESTOVERLAY,&DDColorKey);
    if (FAILED(hr)) {
        NOTE("SetColorKey failed");
        OnColourKeyFailure();
        return FALSE;
    }

    // Update the overlay with the colour key enabled flag

    //DbgLog((LOG_TRACE,1,TEXT("ShowColourKeyOverlay is SHOWing the overlay!")));
    hr = m_pOverlaySurface->UpdateOverlay(&m_SourceClipRect,  // Video source
                                          m_pDrawPrimary,     // Main surface
                                          &m_TargetClipRect,  // Sink position
                                          DDOVER_KEYDEST |    // A colour key
                                          DDOVER_SHOW,        // Show overlay
                                          NULL);              // No effects
    ASSERT_FLIP_COMPLETE(hr);

    if (FAILED(hr)) {
        NOTE("UpdateOverlay failed");
        OnColourKeyFailure();
        return FALSE;
    }

    return TRUE;
}


// Some display cards say they can do overlay colour keying but when put to
// the test fail it with DDERR_NOCOLORKEYHW. The Cirrus 5440 is an example
// of this as it can only colour key when it is stretched (typically by two)
// When we get a colour key failure we set the overlay pending and disable
// DirectDraw, when we subsequently set the surface as enabled we check the
// DDCAPS_COLOURKEY and enable colour keys again. By doing this every time
// we may do too much format switching - but we will always use colour keys

void CDirectDraw::OnColourKeyFailure()
{
    NOTE("Entering OnColourKeyFailure");
    m_bWindowLock = TRUE;
    m_bColourKeyPending = TRUE;

    // Repaint the window background

    if (m_bUsingColourKey) {
        NOTE("Colour key was set");
        m_bUsingColourKey = FALSE;
        OnPaint(NULL);
    }
}


// Lets people know if an overlay surface is visible and enabled. On S3 cards
// which have both MPEG decompression and DirectDraw the MPEG driver silently
// steals the overlay surface when the MPEG is started. This is ok when we're
// running because the surface lock will fail. However when paused or stopped
// we poll in here a few times a second to check the surface is still with us
// so we take this opportunity to hide the overlay and have a new sample sent

BOOL CDirectDraw::IsOverlayEnabled()
{
    NOTE("Entering IsOverlayEnabled");

    CAutoLock cVideoLock(this);
    if (m_bOverlayVisible == FALSE) {
        NOTE("Overlay invisible");
        return FALSE;
    }

    // Reset the size field in the DDSURFACEDESC structure

    ASSERT(m_pOverlaySurface);
    NOTE("Checking surface loss");
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);

    // Lock the surface to get the buffer pointer

    HRESULT hr = m_pOverlaySurface->Lock((RECT *) NULL,  // Target rectangle
                                         &SurfaceDesc,   // Return information
                                         DDLOCK_WAIT,    // Wait for surface
                                         (HANDLE) NULL); // Don't use event
    ASSERT_FLIP_COMPLETE(hr);

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        HideOverlaySurface();
        return FALSE;
    }

    // Unlock the entire surface

    if (SUCCEEDED(hr)) {
        NOTE("Unlocking overlay surface");
        m_pOverlaySurface->Unlock(NULL);
    }
    return TRUE;
}


// Called during paused state transitions

BOOL CDirectDraw::IsOverlayComplete()
{
    NOTE("Entering IsOverlayComplete");

    CAutoLock cVideoLock(this);
    if (IsOverlayEnabled() == FALSE) {
        NOTE("Overlay not enabled");
        return FALSE;
    }
    return (m_bOverlayStale == TRUE ? FALSE : TRUE);
}


// Marks the overlay as being stale

void CDirectDraw::OverlayIsStale()
{
    NOTE("Overlay is stale");
    CAutoLock cVideoLock(this);

    // Make sure we continue to return surfaces

    if (IsOverlayEnabled() == TRUE) {
        m_bOverlayStale = TRUE;
    }
}


// Hides any overlay surface we are using - also reset the m_bOverlayVisible
// flag we keep so that everyone will know the overlay is hidden (hence the
// locking of our critical section just to be safe). We can be called dumbly
// even if we are not using overlays at all just to keep our code simple

BOOL CDirectDraw::HideOverlaySurface()
{
    NOTE("Entering HideOverlaySurface");
    CAutoLock cVideoLock(this);

    // Is the overlay already hidden

    if (m_bOverlayVisible == FALSE) {
        return TRUE;
    }

    // Reset our state and draw a normal background

    ASSERT(m_pOverlaySurface);
    m_bUsingColourKey = FALSE;
    m_bOverlayVisible = FALSE;
    BlankDestination();
    WaitForFlipStatus();

    // Hide the overlay with the DDOVER_HIDE flag

    //DbgLog((LOG_TRACE,1,TEXT("HIDEing the overlay")));
    m_pOverlaySurface->UpdateOverlay(NULL,  // Video source
                                     m_pDrawPrimary,     // Main surface
                                     NULL,  		 // Sink position
                                     DDOVER_HIDE,      	 // Hide overlay
                                     NULL);              // No other effects

    return TRUE;
}


// If this is a normal uncompressed DIB format then set the size of the image
// as usual with the DIBSIZE macro. Otherwise the DIB specification says that
// the width of the image will be set in the width as a count of bytes so we
// just multiply that by the absolute height to get the total number of bytes
// This trickery is all handled by a utility function in the SDK base classes

void CDirectDraw::SetSurfaceSize(VIDEOINFO *pVideoInfo)
{
    NOTE("Entering SetSurfaceSize");

    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    pVideoInfo->bmiHeader.biSizeImage = GetBitmapSize(pHeader);
    m_cbSurfaceSize = pVideoInfo->bmiHeader.biSizeImage;
}


// Initialise our output type based on the DirectDraw surface. As DirectDraw
// only deals with top down display devices so we must convert the height of
// the surface returned in the DDSURFACEDESC into a negative height. This is
// because DIBs use a positive height to indicate a bottom up image. We also
// initialise the other VIDEOINFO fields in the same way as for DCI access

BOOL CDirectDraw::InitDrawFormat(LPDIRECTDRAWSURFACE pSurface)
{
    COLORKEY ColourKey;
    NOTE("Entering InitDrawFormat");

    m_pRenderer->m_Overlay.InitDefaultColourKey(&ColourKey);
    m_KeyColour = ColourKey.LowColorValue;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_SurfaceFormat.Format();
    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);

    // Ask the surface for a description

    HRESULT hr = pSurface->GetSurfaceDesc(&SurfaceDesc);
    if (FAILED(hr)) {
        NOTE("GetSurfaceDesc failed");
        return FALSE;
    }

    ASSERT(SurfaceDesc.ddpfPixelFormat.dwRGBBitCount);

    // Convert a DDSURFACEDESC into a BITMAPINFOHEADER (see notes later). The
    // bit depth of the surface can be retrieved from the DDPIXELFORMAT field
    // in the DDSURFACEDESC. The documentation is a little misleading because
    // it says the field is permutations of DDBD_*'s however in this case the
    // field is initialised by DirectDraw to be the actual surface bit depth

    pVideoInfo->bmiHeader.biSize          = sizeof(BITMAPINFOHEADER);
    pVideoInfo->bmiHeader.biWidth         = SurfaceDesc.lPitch * 8;

    // For some weird reason if the format is not a standard bit depth the
    // width field in the BITMAPINFOHEADER should be set to the number of
    // bytes instead of the width in pixels. This supports odd YUV formats
    // like IF09 which uses 9bpp (the /= 8 cancels out the above multiply)

    int bpp = SurfaceDesc.ddpfPixelFormat.dwRGBBitCount;
    if (bpp == 8 || bpp == 16 || bpp == 24 || bpp == 32)
        pVideoInfo->bmiHeader.biWidth     /= bpp;
    else
        pVideoInfo->bmiHeader.biWidth     /= 8;

    pVideoInfo->bmiHeader.biHeight        = -((LONG) SurfaceDesc.dwHeight);
    pVideoInfo->bmiHeader.biPlanes        = 1;
    pVideoInfo->bmiHeader.biBitCount      = (USHORT) SurfaceDesc.ddpfPixelFormat.dwRGBBitCount;
    pVideoInfo->bmiHeader.biCompression   = SurfaceDesc.ddpfPixelFormat.dwFourCC;
    pVideoInfo->bmiHeader.biXPelsPerMeter = 0;
    pVideoInfo->bmiHeader.biYPelsPerMeter = 0;
    pVideoInfo->bmiHeader.biClrUsed       = 0;
    pVideoInfo->bmiHeader.biClrImportant  = 0;

    SetSurfaceSize(pVideoInfo);

    // For true colour RGB formats tell the source there are bit fields

    if (pVideoInfo->bmiHeader.biCompression == BI_RGB) {
        if (pVideoInfo->bmiHeader.biBitCount == 16 ||
            pVideoInfo->bmiHeader.biBitCount == 32) {
                pVideoInfo->bmiHeader.biCompression = BI_BITFIELDS;
        }
    }

    // The RGB bit fields are in the same place as for YUV formats

    if (pVideoInfo->bmiHeader.biCompression != BI_RGB) {
        pVideoInfo->dwBitMasks[0] = SurfaceDesc.ddpfPixelFormat.dwRBitMask;
        pVideoInfo->dwBitMasks[1] = SurfaceDesc.ddpfPixelFormat.dwGBitMask;
        pVideoInfo->dwBitMasks[2] = SurfaceDesc.ddpfPixelFormat.dwBBitMask;
    }

    // Complete the rest of the VIDEOINFO fields

    SetRectEmpty(&pVideoInfo->rcSource);
    SetRectEmpty(&pVideoInfo->rcTarget);
    pVideoInfo->dwBitRate = 0;
    pVideoInfo->dwBitErrorRate = 0;
    pVideoInfo->AvgTimePerFrame = 0;

    // And finish it off with the other media type fields

    const GUID SubTypeGUID = GetBitmapSubtype(&pVideoInfo->bmiHeader);
    m_SurfaceFormat.SetSampleSize(pVideoInfo->bmiHeader.biSizeImage);
    m_SurfaceFormat.SetType(&MEDIATYPE_Video);
    m_SurfaceFormat.SetSubtype(&SubTypeGUID);
    m_SurfaceFormat.SetTemporalCompression(FALSE);
    m_SurfaceFormat.SetFormatType(&FORMAT_VideoInfo);

    return TRUE;
}


// Initialise a video media type based on the DCI primary surface. We set all
// the VIDEOINFO fields as if the surface was a logical bitmap they draw to
// (which it is although it has some special properties). Some displays see
// the primary surface as a smaller viewport on larger physical bitmap so the
// stride they return is larger than the width, therefore we set the width to
// be the stride. We should also set the height negative if it is a top down
// display as DIBs think a positive height means a standard bottom up image

#define ABS(x) (x < 0 ? -x : x)


// Release any DirectDraw offscreen surface or DCI provider we are currently
// holding, we may be called at any time especially when something goes badly
// wrong and we need to clean up before returning, so we can't guarantee that
// our state is consistent so free only those that we have really allocated
// NOTE DirectDraw has a feature with flipping surfaces, GetAttachedSurface
// returns a DirectDraw surface interface that isn't AddRef'd, hence when we
// destroy all the surfaces we reset the interface instead of releasing it

void CDirectDraw::ReleaseSurfaces()
{
    NOTE("Entering ReleaseSurfaces");
    CAutoLock cVideoLock(this);
    WaitForFlipStatus();
    HideOverlaySurface();

    // Reset our internal surface state

    m_bColourKey = FALSE;
    m_SurfaceType = AMDDS_NONE;
    m_cbSurfaceSize = 0;
    m_bWindowLock = TRUE;
    m_bOverlayStale = FALSE;
    m_bColourKeyPending = FALSE;
    m_bTripleBuffered = FALSE;

    // Release any interfaces we obtained

    if (m_pOffScreenSurface) m_pOffScreenSurface->Release();
    if (m_pOverlaySurface) m_pOverlaySurface->Release();
    if (m_pDrawClipper) m_pDrawClipper->Release();
    if (m_pOvlyClipper) m_pOvlyClipper->Release();

    // Reset them so we don't release them again

    m_pOverlaySurface = NULL;
    m_pBackBuffer = NULL;
    m_pOffScreenSurface = NULL;
    m_pDrawClipper = NULL;
    m_pOvlyClipper = NULL;
}


// Called to release any DirectDraw provider we previously loaded. We may be
// called at any time especially when something goes horribly wrong and when
// we need to clean up before returning so we can't guarantee that all state
// variables are consistent so free only those really allocated. After we've
// initialised DirectDraw during CompleteConnect we keep the driver instance
// around along with a primary surface until we are disconnected. All other
// surfaces including DCI are allocated and freed in sync with the allocator

void CDirectDraw::ReleaseDirectDraw()
{
    NOTE("Entering ReleaseDirectDraw");
    CAutoLock cVideoLock(this);
    SetSurfacePending(FALSE);

    // Release the DirectDraw primary surface

    if (m_pDrawPrimary) {
        NOTE("Releasing primary");
        m_pDrawPrimary->Release();
        m_pDrawPrimary = NULL;
    }

    // Release any DirectDraw provider interface

    if (m_pDirectDraw) {
        NOTE("Releasing DirectDraw");
        m_pDirectDraw->Release();
        m_pDirectDraw = NULL;
    }
    m_LoadDirectDraw.ReleaseDirectDraw();
    //DbgLog((LOG_TRACE,1,TEXT("RELEASING m_pDirectDraw")));
}


// DirectDraw 1.0 can only be loaded once per process, attempts to load it a
// second time return DDERR_DIRECTDRAWALREADYCREATED. We typically have a
// filter graph full of independant objects controlled by an application all
// of which may want to make use of DirectDraw. Therefore this is a serious
// restriction for us. To load DirectDraw we use a helper class in the SDK
// that manages loading and unloading the library and creating the instances

BOOL CDirectDraw::LoadDirectDraw()
{
    NOTE("Entering LoadDirectDraw");
    HRESULT hr = NOERROR;

    // Is DirectDraw already loaded

    if (m_pDirectDraw) {
        NOTE("Loaded");
        return TRUE;
    }

    // Ask the loader to create an instance of DirectDraw using hardware for
    // whichever monitor the window is on (for a multi monitor system)
    // For good ol' Win95, it'll use normal DDraw
    hr = m_LoadDirectDraw.LoadDirectDraw(m_pRenderer->m_achMonitor);
    if (FAILED(hr)) {
        NOTE("No DirectDraw");
        return FALSE;
    }

    // Get the IDirectDraw instance

    m_pDirectDraw = m_LoadDirectDraw.GetDirectDraw();
    //DbgLog((LOG_TRACE,1,TEXT("m_pDirectDraw = %x"), m_pDirectDraw));
    if (m_pDirectDraw == NULL) {
        NOTE("No instance");
        return FALSE;
    }

    // we must be loaded to get the real version
    m_DirectDrawVersion1 = m_LoadDirectDraw.IsDirectDrawVersion1();

    return TRUE;
}


// This function loads the DirectDraw DLL dynamically, this is so the video
// renderer can still be loaded and executed where DirectDraw is unavailable
// We use the DirectDraw plug in distributor that the filtergraph implements
// and then having successfully loaded and initialised the DLL we ask it for
// an IDirectDraw interface with which we query it's capabilities and then
// subsequently create a primary surface as all DirectDraw operations use it

BOOL CDirectDraw::InitDirectDraw(BOOL fIOverlay)
{
    NOTE("Entering InitDirectDraw");
    ASSERT(m_pDirectDraw == NULL);
    ASSERT(m_pDrawPrimary == NULL);

    // Check we are allowed to load DirectDraw

    if (m_bIniEnabled == FALSE || m_Switches == AMDDS_NONE) {
        return FALSE;
    }

    // We may have initialised m_pDirectDraw from an IDirectDraw interface
    // we have been provided with externally from an application. In that
    // case we simply AddRef the interface (to allow for the Release we do
    // in ReleaseDirectDraw) and then try to create a primary surface. We
    // will also set cooperation levels on the driver that could conflict
    // with one already set so we check for an error DDERR_HWNDALREADYSET

    if (m_pOutsideDirectDraw) {
        m_pDirectDraw = m_pOutsideDirectDraw;
        NOTE("Using external DirectDraw");
        m_pDirectDraw->AddRef();
    }

    // Try to load DirectDraw if not already done so

    if (LoadDirectDraw() == FALSE) {
        return FALSE;
    }

    // Initialise our capabilities structures

    ASSERT(m_pDirectDraw);
    m_DirectCaps.dwSize = sizeof(DDCAPS);
    m_DirectSoftCaps.dwSize = sizeof(DDCAPS);

    // Load the hardware and emulation capabilities

    HRESULT hr = m_pDirectDraw->GetCaps(&m_DirectCaps,&m_DirectSoftCaps);
    //
    // If we are connected through IOverlay we just need the clipper.
    // The clipper does not depend on any DDraw h/w.
    //
    if (FAILED(hr) || ((m_DirectCaps.dwCaps & DDCAPS_NOHARDWARE) && !fIOverlay)) {
        NOTE("No hardware");
        ReleaseDirectDraw();
        return FALSE;
    }

    // Set the cooperation level on the surface to be shared

    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    hr = m_pDirectDraw->SetCooperativeLevel(hwnd,DDSCL_NORMAL);
    if (FAILED(hr)) {
        NOTE("Level failed");
        ReleaseDirectDraw();
        return FALSE;
    }

    // Initialise the primary surface descriptor
    if (!fIOverlay) {

        DDSURFACEDESC SurfaceDesc;
        SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
        SurfaceDesc.dwFlags = DDSD_CAPS;
        SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE;

        hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pDrawPrimary,NULL);
        if (FAILED(hr)) {
            NOTE("No DD primary");
            ReleaseDirectDraw();
            return FALSE;
        }
    }
    return TRUE;
}



// When we get a DirectDraw error we don't disable all use of the surfaces as
// the error could be caused by any number of obscure reasons, examples being
// we are running in a fullscreen DOS box, we might have asked for an overlay
// to be stretched to much or too little and so on. Therefore we set a flag
// m_bSurfacePending that inhibits the surface being used until the window is
// next updated (ie either the source or destination rectangles are altered)

void CDirectDraw::SetSurfacePending(BOOL bPending)
{
    NOTE("Entering SetSurfacePending");
    m_bSurfacePending = bPending;

    // Can we enable colour keys again

    if (m_bSurfacePending == FALSE) {
        if (m_DirectCaps.dwCaps & DDCAPS_COLORKEY) {
            if (m_pOverlaySurface) {
                m_bColourKeyPending = FALSE;
            }
        }
    }
}


// Return the current surface pending flag

BOOL CDirectDraw::IsSurfacePending()
{
    return m_bSurfacePending;
}


// Update the current destination rectangle

void CDirectDraw::SetTargetRect(RECT *pTargetRect)
{
    NOTE("Entering SetTargetRect");
    ASSERT(pTargetRect);
    CAutoLock cVideoLock(this);
    m_TargetRect = *pTargetRect;
}


// Update the current source rectangle

void CDirectDraw::SetSourceRect(RECT *pSourceRect)
{
    NOTE("Entering SetSourceRect");
    ASSERT(pSourceRect);
    CAutoLock cVideoLock(this);
    m_SourceRect = *pSourceRect;
}


// Create an offscreen RGB drawing surface. This is very similar to the code
// required to create an overlay surface although I keep it separate so that
// it is simpler to change and therefore for them to diverge in the future
// At the moment the only difference is setting the DDSURFACEDESC dwCaps to
// DDSCAPS_OFFSCREENPLAIN instead of overlay although we still ask it to be
// placed in video memory, the surface is returned in m_pOffScreenSurface

BOOL CDirectDraw::CreateRGBOffScreen(CMediaType *pmtIn)
{
    NOTE("Entering CreateRGBOffScreen");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(m_pDrawPrimary);
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Can this display driver handle drawing in hardware

    if ((m_DirectCaps.dwCaps & DDCAPS_BLT) == 0) {
        NOTE("No DDCAPS_BLT");
        return FALSE;
    }

    // Check the format is acceptable to the renderer

    hr = m_pRenderer->m_Display.CheckMediaType(pmtIn);
    if (FAILED(hr)) {
        NOTE("CheckMediaType failed");
        return FALSE;
    }

    // Set the surface description of the offscreen

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_VIDEOMEMORY;

    // Store the masks in the DDSURFACEDESC

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwRGBBitCount = pHeader->biBitCount;
    SurfaceDesc.ddpfPixelFormat.dwFourCC = BI_RGB;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_RGB;
    const DWORD *pBitMasks = m_pRenderer->m_Display.GetBitMasks(pVideoInfo);
    SurfaceDesc.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
    SurfaceDesc.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
    SurfaceDesc.ddpfPixelFormat.dwBBitMask = pBitMasks[2];

    // ATI seems to want this to be 0
    SurfaceDesc.ddpfPixelFormat.dwRGBAlphaBitMask = 0;

    // Create the offscreen drawing surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOffScreenSurface,NULL);
    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }
    return InitOffScreenSurface(pmtIn,FALSE);
}


// Create an offscreen YUV drawing surface. This is very similar to the code
// required to create an overlay surface although I keep it separate so that
// it is simpler to change and therefore for them to diverge in the future
// At the moment the only difference is setting the DDSURFACEDESC dwCaps to
// DDSCAPS_OFFSCREENPLAIN instead of overlay although we still ask it to be
// placed in video memory, the surface is returned in m_pOffScreenSurface

BOOL CDirectDraw::CreateYUVOffScreen(CMediaType *pmtIn)
{
    NOTE("Entering CreateYUVOffScreen");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(m_pDrawPrimary);
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Can this display driver handle drawing in hardware

    if ((m_DirectCaps.dwCaps & DDCAPS_BLTFOURCC) == 0) {
        NOTE("No DDCAPS_BLTFOURCC");
        return FALSE;
    }

    // Set the surface description of the offscreen

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_VIDEOMEMORY;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = pHeader->biCompression;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
    SurfaceDesc.ddpfPixelFormat.dwYUVBitCount = pHeader->biBitCount;

    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOffScreenSurface,NULL);
    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }
    return InitOffScreenSurface(pmtIn,FALSE);
}


// This creates a RGB overlay surface for doing the drawing. To use these we
// require a true colour type to be supplied and also a DirectDraw primary
// surface to act as the overlay target. The data we put on the overlay does
// not touch the frame buffer but is merged on the way to the display when a
// vertical refresh is done (which typically occur some 60 times a second)

BOOL CDirectDraw::CreateRGBOverlay(CMediaType *pmtIn)
{
    NOTE("Entering CreateRGBOverlay");
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Standard overlay creation tests

    if (CheckCreateOverlay() == FALSE) {
        NOTE("No overlays");
        return FALSE;
    }

    // Set the surface description of the overlay

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY | DDSCAPS_VIDEOMEMORY;
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = BI_RGB;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_RGB;
    SurfaceDesc.ddpfPixelFormat.dwRGBBitCount = pHeader->biBitCount;

    // Store the masks in the DDSURFACEDESC

    const DWORD *pBitMasks = m_pRenderer->m_Display.GetBitMasks(pVideoInfo);
    SurfaceDesc.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
    SurfaceDesc.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
    SurfaceDesc.ddpfPixelFormat.dwBBitMask = pBitMasks[2];

    // ATI seems to want this to be 0
    SurfaceDesc.ddpfPixelFormat.dwRGBAlphaBitMask = 0;

    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }
    return InitOffScreenSurface(pmtIn,FALSE);
}


// This creates a non RGB overlay surface. We must be supplied with a format
// that has the FOURCC code set in the biCompression field in the header. We
// also require a primary surface to act as the overlay target. This surface
// type is vital for doing MPEG colour conversions efficiently (such as YUV
// to RGB). The data we put on the overlay does not touch the frame buffer
// but is merged on the way to the display when a vertical refresh is done

BOOL CDirectDraw::CreateYUVOverlay(CMediaType *pmtIn)
{
    NOTE("Entering CreateYUVOverlay");
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Standard overlay creation tests

    if (CheckCreateOverlay() == FALSE) {
        NOTE("No overlays");
        return FALSE;
    }

    // Set the surface description of the overlay

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY | DDSCAPS_VIDEOMEMORY;
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = pHeader->biCompression;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
    SurfaceDesc.ddpfPixelFormat.dwYUVBitCount = pHeader->biBitCount;

    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }
    return InitOffScreenSurface(pmtIn,FALSE);
}


// Create a set of three flipping surfaces. Flipping surfaces comprise an
// overlay front buffer which is just a normal overlay surface, backed up
// with two further offscreen surfaces in video memory. While the overlay
// is visible we will decompress into a back offscreen buffer and flip it
// to the front when completed. The flip happens after the vertical blank
// which guarantees it won't tear since the scan line isn't anywhere near

BOOL CDirectDraw::CreateRGBFlipping(CMediaType *pmtIn)
{
    NOTE("Entering CreateRGBFlipping");
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Standard overlay creation tests

    if (CheckCreateOverlay() == FALSE) {
        NOTE("No overlays");
        return FALSE;
    }

    // Set the surface description of the overlay

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT |
                          DDSD_BACKBUFFERCOUNT;

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;
    SurfaceDesc.dwBackBufferCount = 2;

    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY |
                                 DDSCAPS_VIDEOMEMORY |
                                 DDSCAPS_FLIP |
                                 DDSCAPS_COMPLEX;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = BI_RGB;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_RGB;
    SurfaceDesc.ddpfPixelFormat.dwRGBBitCount = pHeader->biBitCount;

    // Store the masks in the DDSURFACEDESC

    const DWORD *pBitMasks = m_pRenderer->m_Display.GetBitMasks(pVideoInfo);
    SurfaceDesc.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
    SurfaceDesc.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
    SurfaceDesc.ddpfPixelFormat.dwBBitMask = pBitMasks[2];

    // ATI seems to want this to be 0
    SurfaceDesc.ddpfPixelFormat.dwRGBAlphaBitMask = 0;


    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    if (hr == DDERR_OUTOFVIDEOMEMORY) {
        SurfaceDesc.dwBackBufferCount = 1;
        hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    }

    // General error processing now

    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }

    // Have we got triple buffered overlays

    m_bTripleBuffered = FALSE;
    if (SurfaceDesc.dwBackBufferCount == 2) {
        m_bTripleBuffered = TRUE;
    }
    return InitOffScreenSurface(pmtIn,TRUE);
}


// Create a set of three flipping surfaces. Flipping surfaces comprise an
// overlay front buffer which is just a normal overlay surface, backed up
// with two further offscreen surfaces in video memory. While the overlay
// is visible we will decompress into a back offscreen buffer and flip it
// to the front when completed. The flip happens after the vertical blank
// which guarantees it won't tear since the scan line isn't anywhere near

BOOL CDirectDraw::CreateYUVFlipping(CMediaType *pmtIn)
{
    NOTE("Entering CreateYUVFlipping");
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;

    // Standard overlay creation tests

    if (CheckCreateOverlay() == FALSE) {
        NOTE("No overlays");
        return FALSE;
    }

    VIDEOINFO * const pVideoInfo = (VIDEOINFO *) pmtIn->Format();
    BITMAPINFOHEADER * const pHeader = HEADER(pVideoInfo);

    // Don't flip for motion compensation surfaces
    // This bypasses a bug in the current ATI Rage Pro driver
    if (pHeader->biCompression == MAKEFOURCC('M', 'C', '1', '2')) {
        NOTE("Don't flip for motion compensation surfaces");
        return FALSE;
    }

    // Set the surface description of the overlay

    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    SurfaceDesc.dwFlags = DDSD_CAPS |
                          DDSD_HEIGHT |
                          DDSD_WIDTH |
                          DDSD_PIXELFORMAT |
                          DDSD_BACKBUFFERCOUNT;

    SurfaceDesc.dwHeight = pHeader->biHeight;
    SurfaceDesc.dwWidth = pHeader->biWidth;
    SurfaceDesc.dwBackBufferCount = 2;

    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY |
                                 DDSCAPS_VIDEOMEMORY |
                                 DDSCAPS_FLIP |
                                 DDSCAPS_COMPLEX;

    SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    SurfaceDesc.ddpfPixelFormat.dwFourCC = pHeader->biCompression;
    SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
    SurfaceDesc.ddpfPixelFormat.dwYUVBitCount = pHeader->biBitCount;

    // Create the offscreen overlay surface

    hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    if (hr == DDERR_OUTOFVIDEOMEMORY) {
        SurfaceDesc.dwBackBufferCount = 1;
        hr = m_pDirectDraw->CreateSurface(&SurfaceDesc,&m_pOverlaySurface,NULL);
    }

    // General error processing now

    if (FAILED(hr)) {
        NOTE("No surface");
        return FALSE;
    }

    // Have we got triple buffered overlays

    m_bTripleBuffered = FALSE;
    if (SurfaceDesc.dwBackBufferCount == 2) {
        m_bTripleBuffered = TRUE;
    }
    return InitOffScreenSurface(pmtIn,TRUE);
}


// Store the current clipped rectangles for the surface. We set all surfaces
// with empty source and target clipping rectangles. When initially created
// the clipped rectangles will be all zero. These will be updated when the
// allocator next calls UpdateSurface.

BOOL CDirectDraw::InitOnScreenSurface(CMediaType *pmtIn)
{
    NOTE("Entering InitOnScreenSurface");
    VIDEOINFO *pOutput = (VIDEOINFO *) m_SurfaceFormat.Format();
    VIDEOINFO *pInput = (VIDEOINFO *) pmtIn->Format();
    pOutput->rcSource = m_SourceClipRect;
    pOutput->rcTarget = m_TargetClipRect;

    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pBackBuffer == NULL);
    ASSERT(m_pDrawPrimary);
    ASSERT(m_pOffScreenSurface == NULL);

    // Is this a palettised format

    if (PALETTISED(pOutput) == FALSE) {
        return TRUE;
    }

    // pInput and pOutput should either be both paletized formats or
    // unpaletized formats.  However, it's possible the two formats
    // can differ.  For more information, see bug 151387 - "STRESS:
    // XCUH: unhandled exception hit in T3Call.exe" in the Windows
    // Bugs database.
    if (PALETTISED(pInput) == FALSE) {
        return FALSE;
    }

    // The number of colours may default to zero

    pOutput->bmiHeader.biClrUsed = pInput->bmiHeader.biClrUsed;
    if (pOutput->bmiHeader.biClrUsed == 0) {
        DWORD Maximum  = (1 << pOutput->bmiHeader.biBitCount);
        NOTE1("Setting maximum colours (%d)",Maximum);
        pOutput->bmiHeader.biClrUsed = Maximum;
    }

    // Copy the palette entries into the surface format

    ASSERT(pOutput->bmiHeader.biClrUsed <= iPALETTE_COLORS);
    LONG Bytes = pOutput->bmiHeader.biClrUsed * sizeof(RGBQUAD);
    CopyMemory(pOutput->bmiColors,pInput->bmiColors,Bytes);

    return TRUE;
}


// Handle some of the tedium to do with overlay and page flipped surfaces. We
// are passed in a flag that says if the surfaces created were page flipping
// If they are then we need the backbuffer interface to acts as the source in
// BltFast operations and also for the Flip calls. If anything fails we will
// release any surfaces created and return FALSE, otherwise we'll return TRUE

BOOL CDirectDraw::InitOffScreenSurface(CMediaType *pmtIn,BOOL bPageFlipped)
{
    NOTE("Entering InitOverlaySurface");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(m_pDrawPrimary);
    HRESULT hr = NOERROR;


    // Either an overlay or an offscreen surface

    IDirectDrawSurface *pSurface = m_pOverlaySurface;
    if (m_pOverlaySurface == NULL) {
        pSurface = m_pOffScreenSurface;
        ASSERT(m_pOffScreenSurface);
        ASSERT(bPageFlipped == FALSE);
    }

#ifdef DEBUG
    DDSURFACEDESC ddsd;
    ddsd.dwSize = sizeof(ddsd);
    pSurface->GetSurfaceDesc(&ddsd);
    if (!(ddsd.ddsCaps.dwCaps & DDSCAPS_VIDEOMEMORY)) {
        DbgLog((LOG_TRACE, 0, TEXT("Surface is non-video memory")));
    }
#endif

    // Initialise a media type describing our output format

    if (InitDrawFormat(pSurface) == FALSE) {
        ReleaseSurfaces();
        return FALSE;
    }

    // Go in search of the backbuffer

    if (bPageFlipped == TRUE) {
        ASSERT(m_pBackBuffer == NULL);
        DDSCAPS SurfaceCaps;
        SurfaceCaps.dwCaps = DDSCAPS_BACKBUFFER;

        // Get the normal back buffer surface

        hr = pSurface->GetAttachedSurface(&SurfaceCaps,&m_pBackBuffer);
        if (FAILED(hr)) {
            ReleaseSurfaces();
            return FALSE;
        }
    }

    NOTE("Preparing source and destination rectangles");
    VIDEOINFO *pOutput = (VIDEOINFO *) m_SurfaceFormat.Format();
    VIDEOINFO *pInput = (VIDEOINFO *) pmtIn->Format();

    // Initialise the source and destination rectangles

    pOutput->rcSource.left = 0; pOutput->rcSource.top = 0;
    pOutput->rcSource.right = pInput->bmiHeader.biWidth;
    pOutput->rcSource.bottom = pInput->bmiHeader.biHeight;
    pOutput->rcTarget.left = 0; pOutput->rcTarget.top = 0;
    pOutput->rcTarget.right = pInput->bmiHeader.biWidth;
    pOutput->rcTarget.bottom = pInput->bmiHeader.biHeight;

    ClipPrepare(pSurface);

    // Is this a palettised format

    if (PALETTISED(pOutput) == FALSE) {
        NOTE("No palette");
        return TRUE;
    }

    // pInput and pOutput should either be both paletized formats or
    // unpaletized formats.  However, it's possible the two formats
    // can differ.  For more information, see bug 151387 - "STRESS:
    // XCUH: unhandled exception hit in T3Call.exe" in the Windows
    // Bugs database.
    if (PALETTISED(pInput) == FALSE) {
        return FALSE;
    }

    // It could be an eight bit YUV format

    if (pOutput->bmiHeader.biCompression) {
        NOTE("Not BI_RGB type");
        return FALSE;
    }

    ASSERT(m_pOverlaySurface == NULL);
    ASSERT(m_pBackBuffer == NULL);
    ASSERT(bPageFlipped == FALSE);
    ASSERT(m_pOffScreenSurface);

    // The number of colours may default to zero

    pOutput->bmiHeader.biClrUsed = pInput->bmiHeader.biClrUsed;
    if (pOutput->bmiHeader.biClrUsed == 0) {
        DWORD Maximum  = (1 << pOutput->bmiHeader.biBitCount);
        NOTE1("Setting maximum colours (%d)",Maximum);
        pOutput->bmiHeader.biClrUsed = Maximum;
    }

    // Copy the palette entries into the surface format

    ASSERT(pOutput->bmiHeader.biClrUsed <= iPALETTE_COLORS);
    LONG Bytes = pOutput->bmiHeader.biClrUsed * sizeof(RGBQUAD);
    CopyMemory(pOutput->bmiColors,pInput->bmiColors,Bytes);

    return TRUE;
}


// Check we can create an overlay surface (also applies to flipping surfaces)
// We check the display hardware has overlay capabilities (it's difficult to
// see how they could be emulated). We also check that the current number of
// visible overlays hasn't been exceeded otherwise we will fail when it comes
// to showing it later, so we would rather pick a different surface up front

BOOL CDirectDraw::CheckCreateOverlay()
{
    NOTE("Entering CheckCreateOverlay");
    ASSERT(m_bIniEnabled == TRUE);
    ASSERT(m_pDrawPrimary);

    // Can this display driver handle overlay in hardware, if it cannot then
    // there is little point in using this as it may end up with the driver
    // doing a software colour conversion which could be better done by the
    // source filter (such as in band during the real video decompression)

    if ((m_DirectCaps.dwCaps & DDCAPS_OVERLAY) == 0) {
        NOTE("No DDCAPS_OVERLAY");
        return FALSE;
    }

    // Don't reload the caps as we update them internally, for example if
    // we fail trying to use a colour key we take off the DDCAPS_COLORKEY
    // flags from the DDCAPS we store. Therefore when we retrieve them we
    // bring them into local storage to check the visible overlays count

    DDCAPS DDCaps,DDECaps;
    DDCaps.dwSize = sizeof(DDCAPS);
    DDECaps.dwSize = sizeof(DDCAPS);
    m_pDirectDraw->GetCaps(&DDCaps,&DDECaps);

    // Do we have maximum number of overlays already

    if (DDCaps.dwCurrVisibleOverlays >= DDCaps.dwMaxVisibleOverlays) {
        NOTE("No overlays left");
        return FALSE;
    }
    return TRUE;
}


// After we have allocated and initialised our DirectDraw surface we try and
// set it up so that should we become clipped we can carry on using it. For
// this to happen we have two options, firstly install an IDirectDrawClipper
// for the surface so that DirectDraw will handle the clipping rectangles.
// Otherwise we'll try and install a colour key which lets the hardware know
// where to place the video. Failing both of those we return FALSE, in which
// case we should still use the surface although if and when we do become
// clipped we will have to switch back to using normal memory based DIBs

BOOL CDirectDraw::ClipPrepare(LPDIRECTDRAWSURFACE pSurface)
{
    NOTE("Entering ClipPrepare");

    // First of all try and create a clipper

    if (InitialiseClipper(pSurface) && !m_pOverlaySurface) {
        NOTE("Clipper");
        return TRUE;
    }

    // Failing that try and use a colour key

    if (InitialiseColourKey(pSurface)) {
        NOTE("Colour key");
        return TRUE;
    }
    return FALSE;
}


// This checks that the hardware is capable of supporting colour keys and if
// so allocates the next available colour. The next colour is obtained from
// the hook module because it looks after the shared memory block we create.
// The shared memory block is used so that overlays in different processes
// do not conflict with the same colour (especially when they overlap). We
// set the m_bColourKey flag to TRUE if we plan on using a colour key. Note
// however that we do not start using colour keys until we become clipped

BOOL CDirectDraw::InitialiseColourKey(LPDIRECTDRAWSURFACE pSurface)
{
    NOTE("Entering InitialiseColourKey");

    ASSERT(m_bUsingColourKey == FALSE);
    ASSERT(m_bColourKey == FALSE);
    ASSERT(m_pDirectDraw);
    ASSERT(pSurface);

    // Can the overlay/blting hardware do the clipping

    if (m_DirectCaps.dwCaps & DDCAPS_COLORKEY) {
        if (m_pOverlaySurface) {
            NOTE("DDCAPS_COLORKEY on");
            m_bColourKey = TRUE;
            return TRUE;
        }
    }
    return FALSE;
}


// Create a clipper interface and attach it to the surface. DirectDraw says
// that a clipper may be attached to both offscreen and overlay surfaces so
// we'll try regardless. If we cannot create a clipper or fail to attach it
// correctly then we still go ahead but just swap away from DirectDraw when
// the window becomes complex clipped. We return TRUE if we found a clipper
// and initialised it correctly, otherwise we return FALSE as the calling
// code may be able to install a colour key instead if we become clipped

BOOL CDirectDraw::InitialiseClipper(LPDIRECTDRAWSURFACE pSurface)
{
    NOTE("Entering InitialiseClipper");

    ASSERT(m_bUsingColourKey == FALSE);
    ASSERT(m_bColourKey == FALSE);
    ASSERT(m_pDrawClipper == NULL);
    ASSERT(m_pDirectDraw);
    ASSERT(pSurface);

    // DirectDraw can be difecult sometimes, for example an overlay surface may
    // not support clipping. So you would think the surface would reject the
    // SetClipper call below, but oh no you have check a capabilities flag
    // in the DDCAPS structure which depends on the type of surface in use.
    // For offscreen surfaces (only) DirectDraw will emulate clipping by only
    // sending the rectangles that are really required down to the driver

    DDSURFACEDESC SurfaceDesc;
    SurfaceDesc.dwSize = sizeof(DDSURFACEDESC);
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();

    // Ask the surface for a description

    HRESULT hr = pSurface->GetSurfaceDesc(&SurfaceDesc);
    if (FAILED(hr)) {
        NOTE("No description");
        return FALSE;
    }

    // Can the overlay hardware do the clipping

    if (SurfaceDesc.ddsCaps.dwCaps & DDSCAPS_OVERLAY) {
        if (m_DirectCaps.dwCaps & DDCAPS_OVERLAYCANTCLIP) {
            NOTE("DDSCAPS_OVERLAY/DDCAPS_OVERLAYCANTCLIP");
            return FALSE;
        }
    }

    // Create the IDirectDrawClipper interface

    hr = m_pDirectDraw->CreateClipper((DWORD)0,&m_pDrawClipper,NULL);
    if (FAILED(hr)) {
        NOTE("No clipper");
        return FALSE;
    }

    // Give the clipper the video window handle

    hr = m_pDrawClipper->SetHWnd((DWORD)0,hwnd);
    if (SUCCEEDED(hr)) {
        hr = m_pDrawPrimary->SetClipper(m_pDrawClipper);
        if (SUCCEEDED(hr)) {
            NOTE("Set clipper");
            return TRUE;
        }
    }

    // Release the clipper object

    m_pDrawClipper->Release();
    m_pDrawClipper = NULL;
    return FALSE;
}


// This is called when the window gets a WM_PAINT message. The IMediaSample we
// are handed may or may not be NULL depending whether or not the window has
// an image waiting to be drawn. We return TRUE if we handle the paint call or
// FALSE if someone else must do the work. If we are using flipping or overlay
// surfaces then we have nothing to do but we will have handled the paint

BOOL CDirectDraw::OnPaint(IMediaSample *pMediaSample)
{
    NOTE("Entering OnPaint");
    CAutoLock cVideoLock(this);

    // Assuming we get through the following check we will know that we have
    // either an offscreen, overlay or flipping surface. If it's an offscreen
    // surface then we try to draw it again, it that fails we return FALSE,
    // otherwise we return TRUE to say it was handled correctly. If we have a
    // flipping surface then if it hasn't been flipped yet we do so and make
    // sure the overlay is made visible. If for any reason this can't be done
    // (perhaps the window is complex clipped) then we also return FALSE.
    //
    // If we have an overlay surface and it's visible then we blank out the
    // background underneath the overlay (which we also do when handling the
    // flipping surfaces), we then return TRUE as it was handled correctly.
    // If the overlay was not visible we know that the sample interface will
    // be NULL (as they are never passed through to the window object) so we
    // drop through to the bottom and also return FALSE from this method.
    //
    // Returning FALSE when we're not streaming may eventually have the window
    // object send an EC_REPAINT to the filter graph, this has the whole graph
    // stopped and paused again. The stop has the worker threads returned to
    // their filters, the pause has them send a new frame again. And that time
    // through we get another chance to return a different kind of buffer


    FillBlankAreas();

    // Fill the video background

    if (m_bOverlayVisible == TRUE) {
        // Paint the colour key if necessary
        BOOL bFormatChanged;
        if (UpdateSurface(bFormatChanged) == NULL) {
            return FALSE;
        }

        COLORREF WindowColour = VIDEO_COLOUR;
        if (m_bUsingColourKey == TRUE) {
            NOTE("Using colour key");
            WindowColour = m_KeyColour;
        }
        DrawColourKey(WindowColour);
        if (m_pBackBuffer == NULL) {
            NOTE("No flip");
            return TRUE;
        }
    }

    // Do we have a valid surface to draw

    if (m_pBackBuffer == NULL) {
        if (m_pOffScreenSurface == NULL) {
            NOTE("No offscreen");
            return FALSE;
        }
    }

    // Do we have an image to render

    if (pMediaSample == NULL) {
        NOTE("No sample to draw");
        return m_bOverlayVisible;
    }
    return DrawImage(pMediaSample);
}


// This is used to paint overlay colour keys. We are called when we receive
// WM_PAINT messages although we do not use any device context obtained via
// BeginPaint. The area we fill is the clipped screen area calculated in a
// previous call to UpdateSurface and includes any alignment losses we have
// The clipped area must first be converted into client window coordinates

void CDirectDraw::DrawColourKey(COLORREF WindowColour)
{
    NOTE("Entering DrawColourKey");

    // Draw the current destination rectangle
    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    RECT BlankRect = m_TargetClipRect;
    // translate from device to screen co-ordinates
    BlankRect.left += m_pRenderer->m_rcMonitor.left;
    BlankRect.top += m_pRenderer->m_rcMonitor.top;
    BlankRect.right += m_pRenderer->m_rcMonitor.left;
    BlankRect.bottom += m_pRenderer->m_rcMonitor.top;
    MapWindowPoints((HWND) NULL,hwnd,(LPPOINT) &BlankRect,(UINT) 2);
    COLORREF BackColour = SetBkColor(hdc,WindowColour);
    ExtTextOut(hdc,0,0,ETO_OPAQUE,&BlankRect,NULL,0,NULL);
    SetBkColor(hdc,BackColour);
}


// This is called when we hide overlay surfaces so that we can blank out in
// black the entire target rectangle. We cannot use DrawColourKey for this
// because it only draws on the clipped display area which doesn't include
// sections of video dropped from the left and right for alignment reasons

void CDirectDraw::BlankDestination()
{
    NOTE("Entering BlankDestination");

    // Blank out the current destination rectangle

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    COLORREF BackColour = SetBkColor(hdc,VIDEO_COLOUR);
    ExtTextOut(hdc,0,0,ETO_OPAQUE,&m_TargetRect,NULL,0,NULL);
    SetBkColor(hdc,BackColour);
}


// Flip the back buffer to bring it to the front. We cannot call DrawImage
// more than once for each flipping surface sample otherwise we will flip
// the previous image back to the front again. Therefore WM_PAINT messages
// have to be handled very carefully (review the OnPaint method). If the
// flip fails then it is more likely that a hard error has occured so we
// will disable DirectDraw until it's enabled by a subsequent state change

BOOL CDirectDraw::DoFlipSurfaces(IMediaSample *pMediaSample)
{
    NOTE("Entering DoFlipSurfaces");
    ASSERT(m_pOverlaySurface);
    HRESULT hr = NOERROR;
    CVideoSample *pVideoSample;

    // Have we already flipped this surface

    pVideoSample = (CVideoSample *) pMediaSample;
    if (pVideoSample->GetDrawStatus() == FALSE) {
        NOTE("(Already flipped)");
        return m_bOverlayVisible;
    }

    pVideoSample->SetDrawStatus(FALSE);

    // Flip the back buffer to the visible primary

    hr = DDERR_WASSTILLDRAWING;
    while (hr == DDERR_WASSTILLDRAWING) {
        hr = m_pOverlaySurface->Flip(NULL,(DWORD) 0);
        if (hr == DDERR_WASSTILLDRAWING) {
            if (m_bTripleBuffered == FALSE) break;
            Sleep(DDGFS_FLIP_TIMEOUT);
        }
    }

    // If the flip didn't complete then we're ok

    if (hr == DDERR_WASSTILLDRAWING) {
        NOTE("Flip left pending");
        return ShowOverlaySurface();
    }

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        HideOverlaySurface();
        StartUpdateTimer();
        return FALSE;
    }

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        NOTE("Flip failed");
        SetSurfacePending(TRUE);
        HideOverlaySurface();
        return FALSE;
    }
    return ShowOverlaySurface();
}


// Used to really draw an image that has been put on an offscreen or overlay
// flipping DirectDraw surface (either RGB or YUV). Overlay surfaces should
// already have been dealt with in the OnPaint method so we should only be
// here if we have an offscreen or flipping surfaces. The flipping surfaces
// are dealt with separately as they have to prepare the back buffer with
// the current contents but offscreen surfaces only need a sample blt call

BOOL CDirectDraw::DrawImage(IMediaSample *pMediaSample)
{
    ASSERT(m_pOffScreenSurface || m_pBackBuffer);
    CAutoLock cVideoLock(this);
    NOTE("Entering DrawImage");
    BOOL bFormatChanged;
    HRESULT hr = NOERROR;

    // Flip the overlay and update its position
    if (m_pBackBuffer) return DoFlipSurfaces(pMediaSample);

    // Check all is still well with the window

    if (UpdateSurface(bFormatChanged) == NULL) {
        NOTE("No draw");
        return FALSE;
    }

    FillBlankAreas();
    WaitForScanLine();

    // Draw the offscreen surface and wait for it to complete

//    DbgLog((LOG_TRACE,3,TEXT("BLT to (%d,%d,%d,%d)"),
//		m_TargetClipRect.left, m_TargetClipRect.top,
//		m_TargetClipRect.right, m_TargetClipRect.bottom));
    hr = m_pDrawPrimary->Blt(&m_TargetClipRect,     // Target rectangle
                             m_pOffScreenSurface,   // Source surface
                             &m_SourceClipRect,     // Source rectangle
                             DDBLT_WAIT,            // Wait to complete
                             NULL);                 // No effects flags

    // Is the surface otherwise engaged

    if (hr == DDERR_SURFACEBUSY) {
        NOTE("Surface is busy");
        StartUpdateTimer();
        return FALSE;
    }

    // Handle real DirectDraw errors

    if (FAILED(hr)) {
        SetSurfacePending(TRUE);
        return FALSE;
    }
    return TRUE;
}


// When we adjust the destination rectangle so that it is aligned according
// to the cruddy display hardware we can leave thin strips of exposed area
// down the left and right hand side. This function fills these areas with
// the current border colour (set through the IVideoWindow interface). The
// left/right sections lost are updated when the allocator or timer thread
// calls UpdateSurface which in turn will call our AlignRectangles method

BOOL CDirectDraw::FillBlankAreas()
{
    NOTE("Entering FillBlankAreas");
    RECT BlankRect;

    // Short circuit if nothing to do

    if (m_TargetLost == 0) {
        if (m_TargetWidthLost == 0) {
            NOTE("No fill");
            return TRUE;
        }
    }

    // Create a coloured brush to paint the window

    HDC hdc = m_pRenderer->m_VideoWindow.GetWindowHDC();
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    COLORREF Colour = m_pRenderer->m_VideoWindow.GetBorderColour();
    COLORREF BackColour = SetBkColor(hdc,Colour);
    POINT WindowOffset = { m_TargetClipRect.left, m_TargetClipRect.top };
    ScreenToClient(hwnd,&WindowOffset);

    // Look after the left edge of exposed window

    BlankRect.left = WindowOffset.x - m_TargetLost;
    BlankRect.right = WindowOffset.x;
    BlankRect.top = WindowOffset.y;
    BlankRect.bottom = WindowOffset.y + HEIGHT(&m_TargetRect);
    if (m_TargetLost) ExtTextOut(hdc,0,0,ETO_OPAQUE,&BlankRect,NULL,0,NULL);

    // Now paint the strip down the right hand side

    BlankRect.left = WindowOffset.x + WIDTH(&m_TargetClipRect);
    BlankRect.right = BlankRect.left + m_TargetWidthLost;
    if (m_TargetWidthLost) ExtTextOut(hdc,0,0,ETO_OPAQUE,&BlankRect,NULL,0,NULL);

    // Flush the painted areas out

    EXECUTE_ASSERT(GdiFlush());
    SetBkColor(hdc,BackColour);
    return TRUE;
}


// When using overlay and flipping surfaces we have an update timer which is
// used to ensure that the overlay is always correctly positioned regardless
// of whether we are paused or stopped. This could also be useful when we're
// dealing with low frame rate movies (like MPEG arf arf) - in which case we
// might not get frames through often enough to update the overlay position

BOOL CDirectDraw::OnTimer()
{
    CAutoLock cVideoLock(this);
    NOTE("Entering OnTimer");
    CMediaType *pMediaType;
    BOOL bFormatChanged;

    // Ignore late WM_TIMER messages

    if (m_bTimerStarted == FALSE) {
        NOTE("Late timer");
        return TRUE;
    }

    // Is there an overlay surface to check

    if (m_bOverlayVisible == FALSE) {
        NOTE("Not visible");
        return TRUE;
    }

    // Check all is still well with the overlay

    if (IsOverlayEnabled() == FALSE) {
        NOTE("Not enabled");
        return FALSE;
    }

    // Is the window locked or the format changed

    pMediaType = UpdateSurface(bFormatChanged);
    if (pMediaType == NULL || bFormatChanged) {
        NOTE("Format changed");
        HideOverlaySurface();
        return FALSE;
    }
    return TRUE;
}


// When we see a DDERR_SURFACEBUSY error we start an update timer so that on
// one second periods we try and switch back into DirectDraw. By using the
// timer we can avoid polling on the surface which causes lots of expensive
// format changes. All we do is see if their is a surface change pending and
// if so we reset the flag and make sure next time through we change formats

BOOL CDirectDraw::OnUpdateTimer()
{
    NOTE("Entering OnUpdateTimer");
    CAutoLock cVideoLock(this);
    StopUpdateTimer();

    // Is there a surface change pending

    if (IsSurfacePending() == TRUE) {
        NOTE("Try surface again");
        SetSurfacePending(FALSE);
    }
    return TRUE;
}


// We need to know whether to synchronise on filling the buffer typically a
// primary surface or on the drawing operation as with a flipping surface.
// We return TRUE if we should sync on the fill otherwise we return FALSE.
// We use DCI and DirectDraw primary surfaces but they are handled the same.
//
//      Surface Type         SyncOnFill
//
//      Flipping                FALSE
//      OffScreen               FALSE
//      Overlay                 TRUE
//      Primary                 TRUE
//
// Flipping surfaces are just two overlay surfaces attached together, there
// is one being shown at any given time and another being used as a target
// for the source filter to decompress its next image onto. When we get the
// buffer back we swap the visible buffer and copy the current image across

BOOL CDirectDraw::SyncOnFill()
{
    NOTE("Entering SyncOnFill");
    CAutoLock cVideoLock(this);
    ASSERT(m_bIniEnabled == TRUE);

    if (m_pOffScreenSurface == NULL) {
        if (m_pBackBuffer == NULL) {
            NOTE("SyncOnFill");
            return TRUE;
        }
    }
    return FALSE;
}


// Return TRUE if we should hand out the current surface type in use when we
// are paused. This doesn't stop the renderer holding onto images stored in
// these surfaces as they may already have been delivered. But should we get
// an error subsequently drawing it (perhaps during a WM_PAINT message) then
// we may be able to stop it doing it again (and save wasted EC_REPAINTs)

BOOL CDirectDraw::AvailableWhenPaused()
{
    NOTE("Entering AvailableWhenPaused");

    // Do we have a clipper for any offscreen surface

    if (m_pOffScreenSurface) {
        if (m_pDrawClipper) {
            NOTE("Available");
            return TRUE;
        }
    }

    // Only supported on overlay surfaces

    if (m_pOverlaySurface) {
        NOTE("Overlay");
        return TRUE;
    }
    return FALSE;
}


// When we are paused or stopped we use a Windows timer to have our overlay
// position updated periodically. Our window thread passes on WM_TIMER's to
// our OnTimer method. When we are running we rely on the source calling us
// in Receive sufficiently often to be able to update the overlay while we
// en unlocking the DirectDraw surface. Note that we do NOT receive WM_TIMER
// messages while Windows is processing a window drag and move by the user
// so to try and use them while running for this is pointless (and wasteful)

void CDirectDraw::StartRefreshTimer()
{
    NOTE("Entering StartRefreshTimer");
    CAutoLock cVideoLock(this);

    if (m_pOverlaySurface) {
        if (m_bTimerStarted == FALSE) {
            ASSERT(m_pRenderer->m_InputPin.IsConnected() == TRUE);
            HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
            EXECUTE_ASSERT(SetTimer(hwnd,(UINT_PTR)hwnd,300,NULL));
            NOTE("Starting refresh timer");
            m_bTimerStarted = TRUE;
        }
    }
}


// Kill any update timer used to refresh the overlay position. I'm not sure
// that by the time we are asked to kill any outstanding timer that the DD
// surfaces have not been released (and m_pOverlaySurface is therefore NULL)
// To cover this possibility I simply always try to kill my timer regardless
// and ignore any failed return code. Note that the timer ID we identify our
// timer with matches the HWND (so we don't need to store the ID anywhere)

void CDirectDraw::StopRefreshTimer()
{
    NOTE("Entering StopRefreshTimer");
    CAutoLock cVideoLock(this);

    if (m_bTimerStarted == TRUE) {
        HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
        EXECUTE_ASSERT(KillTimer(hwnd,(UINT_PTR) hwnd));
        NOTE("Timer was killed");
        m_bTimerStarted = FALSE;
    }
}


// This is similar to the StartRefreshTime but is used completely differently
// When we get back a DDERR_SURFACEBUSY error from a DirectDraw call it is
// telling us that the screen is busy probably in a DOS box. In this case we
// don't want to only set the surface pending as we would have to wait for a
// window movement before switching back. Therefore we set a one second timer
// and when it triggers we try and force a format switch back into DirectDraw

void CDirectDraw::StartUpdateTimer()
{
    NOTE("Entering StartUpdateTimer");
    CAutoLock cVideoLock(this);
    SetSurfacePending(TRUE);

    // Start a timer with INFINITE as its identifier

    ASSERT(m_pRenderer->m_InputPin.IsConnected() == TRUE);
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(SetTimer(hwnd,INFINITE,1000,NULL));
}


// This complements the StartUpdateTimer method. We use this timer to try and
// periodically force ourselves back into DirectDraw if we detected a DOS box
// condition (something returned DDERR_SURFACEBUSY). When the timer fires we
// typically try and switch back and if it subsequently fails we just repeat
// the process by preparing another update timer for a second in the future

void CDirectDraw::StopUpdateTimer()
{
    NOTE("Entering StopUpdateTimer");
    CAutoLock cVideoLock(this);
    HWND hwnd = m_pRenderer->m_VideoWindow.GetWindowHWND();
    EXECUTE_ASSERT(KillTimer(hwnd,INFINITE));
}


// Return the maximum ideal image size taking into account DirectDraw. We are
// passed in the current video dimensions which we may update as appropriate.
// We only need to adjust the image dimensions if we have an overlay surface
// being used as DirectDraw may specify a minimum and maximum size to stretch
// The amount to stretch is dependant upon the display resolution being used
// For example on an S3 card at 800x600x16 it is typically x2 but on the same
// display card set to 640x480x16 it is x1 (ie no stretching required). This
// is because the stretching is a way of working around bandwidth limitations

HRESULT CDirectDraw::GetMaxIdealImageSize(long *pWidth,long *pHeight)
{
    NOTE("Entering GetMaxIdealImageSize");
    CAutoLock cVideoLock(this);

    // Should we always be used fullscreen

    if (m_bUseWhenFullScreen == TRUE) {
        NOTE("Force fullscreen");
        return S_FALSE;
    }

    // Some S3 cards (in particular the Vision968 chipset) cannot stretch
    // by more than four. However, DirectDraw offers no way to find this
    // limitation out so we just hardwire the top limit we're allowed to
    // stretch the video by when going from the offscreen to the primary

    if (m_DirectCaps.dwCaps & DDCAPS_BLTSTRETCH) {
    	if (m_pOffScreenSurface) {
            NOTE("Hardwiring limit to four");
            *pWidth <<= 2; *pHeight <<= 2;
            return NOERROR;
        }
    }

    // Have we allocated an overlay surface

    if (m_pOverlaySurface == NULL) {
        NOTE("No overlay");
        return NOERROR;
    }

    // Does this overlay have any requirements

    if (m_DirectCaps.dwMaxOverlayStretch == 0) {
        NOTE("No maximum stretch");
        return S_FALSE;
    }

    // Scale both dimensions to account for the requirements
    *pWidth = (*pWidth * m_DirectCaps.dwMaxOverlayStretch) / 1000;
    *pHeight = (*pHeight * m_DirectCaps.dwMaxOverlayStretch) / 1000;

    return NOERROR;
}


// Return the minimum ideal image size taking into account DirectDraw. We are
// passed in the current video dimensions which we may update as appropriate.
// We only need to adjust the image dimensions if we have an overlay surface
// being used as DirectDraw may specify a minimum and maximum size to stretch
// The amount to stretch is dependant upon the display resolution being used
// For example on an S3 card at 800x600x16 it is typically x2 but on the same
// display card set to 640x480x16 it is x1 (ie no stretching required). This
// is because the stretching is a way of working around bandwidth limitations

HRESULT CDirectDraw::GetMinIdealImageSize(long *pWidth,long *pHeight)
{
    NOTE("Entering GetMinIdealImageSize");
    CAutoLock cVideoLock(this);

    // Should we always be used fullscreen

    if (m_bUseWhenFullScreen == TRUE) {
        NOTE("Force fullscreen");
        return S_FALSE;
    }

    // Do we have a stretchable offscreen surface

    if (m_DirectCaps.dwCaps & DDCAPS_BLTSTRETCH) {
    	if (m_pOffScreenSurface) {
            NOTE("OffScreen stretch");
            return S_FALSE;
        }
    }

    // Have we allocated an overlay surface

    if (m_pOverlaySurface == NULL) {
        NOTE("No overlay");
        return NOERROR;
    }

    // Does this overlay have any requirements

    if (m_DirectCaps.dwMinOverlayStretch == 0) {
        NOTE("No minimum stretch");
        return S_FALSE;
    }

    // Scale both dimensions to account for the requirements

    *pWidth = (*pWidth * m_DirectCaps.dwMinOverlayStretch) / 1000;
    *pHeight = (*pHeight * m_DirectCaps.dwMinOverlayStretch) / 1000;
    return NOERROR;
}


// Return the current switches

STDMETHODIMP CDirectDraw::GetSwitches(DWORD *pSwitches)
{
    NOTE("Entering GetSwitches");

    // Do the usual checking and locking stuff

    CheckPointer(pSwitches,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    ASSERT(pSwitches);
    *pSwitches = m_Switches;
    return NOERROR;
}


// Set the surface types we can use

STDMETHODIMP CDirectDraw::SetSwitches(DWORD Switches)
{
    NOTE("Entering SetSwitches");

    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);
    m_Switches = Switches;

    // Indicate we may already have a surface

    if (m_pRenderer->m_InputPin.IsConnected() == TRUE) {
        return S_FALSE;
    }
    return NOERROR;
}


// Return the capabilities of the hardware

STDMETHODIMP CDirectDraw::GetCaps(DDCAPS *pCaps)
{
    NOTE("Entering GetCaps");

    // Do the usual checking and locking stuff

    CheckPointer(pCaps,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Do we have DirectDraw loaded

    if (m_pDirectDraw == NULL) {
        return E_FAIL;
    }
    *pCaps = m_DirectCaps;
    return NOERROR;
}


// Return the software emulated capabilities

STDMETHODIMP CDirectDraw::GetEmulatedCaps(DDCAPS *pCaps)
{
    NOTE("Entering GetEmulatedCaps");

    // Do the usual checking and locking stuff

    CheckPointer(pCaps,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Do we have DirectDraw loaded

    if (m_pDirectDraw == NULL) {
        return E_FAIL;
    }
    *pCaps = m_DirectSoftCaps;
    return NOERROR;
}


// Return the capabilities of the current surface

STDMETHODIMP CDirectDraw::GetSurfaceDesc(DDSURFACEDESC *pSurfaceDesc)
{
    NOTE("Entering GetSurfaceDesc");
    CheckPointer(pSurfaceDesc,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);


    // Do we have any DirectDraw surface

    if (m_pDrawPrimary == NULL) {
        return E_FAIL;
    }

    pSurfaceDesc->dwSize = sizeof(DDSURFACEDESC);

    // Set the DirectDraw surface we are using

    LPDIRECTDRAWSURFACE pDrawSurface = GetDirectDrawSurface();
    if (pDrawSurface == NULL) {
        pDrawSurface = m_pDrawPrimary;
    }
    return pDrawSurface->GetSurfaceDesc(pSurfaceDesc);
}


// Return the FOURCC codes our provider supplies

STDMETHODIMP CDirectDraw::GetFourCCCodes(DWORD *pCount,DWORD *pCodes)
{
    NOTE("Entering GetFourCCCodes");
    CheckPointer(pCount,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Do we have a DirectDraw object

    if (m_pDirectDraw == NULL) {
        return E_FAIL;
    }
    return m_pDirectDraw->GetFourCCCodes(pCount,pCodes);
}


// This allows an application to set the DirectDraw instance we should use
// We provide this because DirectDraw only allows one instance of it to be
// opened per process, therefore an application (such as a game) would call
// this if it wants us to be able to use DirectDraw simultaneously. We hold
// the reference counted interface until destroyed or until called with a
// NULL or different interface. Calling this may not release the interface
// completely as there might still be surfaces allocated that depend on it

STDMETHODIMP CDirectDraw::SetDirectDraw(LPDIRECTDRAW pDirectDraw)
{
    NOTE("Entering SetDirectDraw");
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Should we release the current driver

    if (m_pOutsideDirectDraw) {
        NOTE("Releasing outer DirectDraw");
        m_pOutsideDirectDraw->Release();
        m_pOutsideDirectDraw = NULL;
    }

    // Do we have a replacement driver

    if (pDirectDraw == NULL) {
        NOTE("No driver");
        return NOERROR;
    }

    // Store a reference counted interface

    m_pOutsideDirectDraw = pDirectDraw;
    m_pOutsideDirectDraw->AddRef();
    return NOERROR;
}


// Set the current switch settings as the default

STDMETHODIMP CDirectDraw::SetDefault()
{
    NOTE("Entering SetDefault");

    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);
    TCHAR Profile[PROFILESTR];

    // Store the current DirectDraw switches

    wsprintf(Profile,TEXT("%d"),m_Switches);
    WriteProfileString(TEXT("DrawDib"),SWITCHES,Profile);
    wsprintf(Profile,TEXT("%d"),m_bCanUseScanLine);
    WriteProfileString(TEXT("DrawDib"),SCANLINE,Profile);
    wsprintf(Profile,TEXT("%d"),m_bCanUseOverlayStretch);
    WriteProfileString(TEXT("DrawDib"),STRETCH,Profile);
    wsprintf(Profile,TEXT("%d"),m_bUseWhenFullScreen);
    WriteProfileString(TEXT("DrawDib"),FULLSCREEN,Profile);

    return NOERROR;
}


// Return the IDirectDraw interface we are currently using - with a reference
// count added as is usual when returning COM interfaces. If we are not using
// DirectDraw at the moment but have been provided with an IDirectDraw driver
// interface to use then we will return that (also suitably AddRef'd). If we
// are not using DirectDraw and also no outside driver then we return NULL

STDMETHODIMP CDirectDraw::GetDirectDraw(LPDIRECTDRAW *ppDirectDraw)
{
    NOTE("Entering GetDirectDraw");

    // Do the usual checking and locking stuff

    CheckPointer(ppDirectDraw,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Are we using an externally provided interface

    if (m_pOutsideDirectDraw) {
        NOTE("Returning outer DirectDraw");
        *ppDirectDraw = m_pOutsideDirectDraw;
        m_pOutsideDirectDraw->AddRef();
        return NOERROR;
    }

    // Fill in the DirectDraw driver interface

    *ppDirectDraw = m_pDirectDraw;
    if (m_pDirectDraw) {
        NOTE("Reference counting");
        m_pDirectDraw->AddRef();
    }
    return NOERROR;
}


// Returns the current surface type

STDMETHODIMP CDirectDraw::GetSurfaceType(DWORD *pSurfaceType)
{
    NOTE("Entering GetSurfaceType");

    // Do the usual checking and locking stuff

    CheckPointer(pSurfaceType,E_POINTER);
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    *pSurfaceType = m_SurfaceType;
    return NOERROR;
}


// Tells if we are allowed to use the current scan line property when doing
// draw calls from offscreen surfaces. On some machines using the scan line
// can reduce tearing but at the expense of performance in frames delivered
// We therefore allow the user to decide on their preferences through here

STDMETHODIMP CDirectDraw::UseScanLine(long UseScanLine)
{
    NOTE("Entering UseScanLine");
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Check this is a valid automation boolean type

    if (UseScanLine != OATRUE) {
        if (UseScanLine != OAFALSE) {
            return E_INVALIDARG;
        }
    }
    m_bCanUseScanLine = (UseScanLine == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Return whether or not we would use the current scan line

STDMETHODIMP CDirectDraw::CanUseScanLine(long *UseScanLine)
{
    CheckPointer(UseScanLine,E_POINTER);
    NOTE("Entering CanUseScanLine");
    CAutoLock Lock(this);
    *UseScanLine = (m_bCanUseScanLine ? OATRUE : OAFALSE);
    return NOERROR;
}


// We normally honout the minimum and maximum overlay stretching limitations
// that the driver reports, however on some displays they are not reported
// entirely accurately which often leads us to not use YUV overlays when we
// could be (which in turn makes us look worse than the competition). So we
// allow applications to change our default behaviour when checking overlays

STDMETHODIMP CDirectDraw::UseOverlayStretch(long UseOverlayStretch)
{
    NOTE("Entering UseOverlayStretch");
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Check this is a valid automation boolean type

    if (UseOverlayStretch != OATRUE) {
        if (UseOverlayStretch != OAFALSE) {
            return E_INVALIDARG;
        }
    }
    m_bCanUseOverlayStretch = (UseOverlayStretch == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Return whether or not we honour the overlay stretching limits

STDMETHODIMP CDirectDraw::CanUseOverlayStretch(long *UseOverlayStretch)
{
    CheckPointer(UseOverlayStretch,E_POINTER);
    NOTE("Entering CanUseOverlayStretch");
    CAutoLock Lock(this);
    *UseOverlayStretch = (m_bCanUseOverlayStretch ? OATRUE : OAFALSE);
    return NOERROR;
}


// Allow applications to always use the window in fullscreen mode

STDMETHODIMP CDirectDraw::UseWhenFullScreen(long UseWhenFullScreen)
{
    NOTE("Entering UseWhenFullScreen");
    CAutoLock cVideoLock(m_pInterfaceLock);
    CAutoLock cInterfaceLock(this);

    // Check this is a valid automation boolean type

    if (UseWhenFullScreen != OATRUE) {
        if (UseWhenFullScreen != OAFALSE) {
            return E_INVALIDARG;
        }
    }
    m_bUseWhenFullScreen = (UseWhenFullScreen == OATRUE ? TRUE : FALSE);
    return NOERROR;
}


// Return S_OK if we will force ourselves to be used fullscreen

STDMETHODIMP CDirectDraw::WillUseFullScreen(long *UseFullScreen)
{
    CheckPointer(UseFullScreen,E_POINTER);
    NOTE("Entering WillUseFullScreen");
    CAutoLock Lock(this);
    *UseFullScreen = (m_bUseWhenFullScreen ? OATRUE : OAFALSE);
    return NOERROR;
}


LPDIRECTDRAWCLIPPER CDirectDraw::GetOverlayClipper()
{
    CAutoLock cVideoLock(this);
    HRESULT hr;

    if (m_pOvlyClipper == NULL) {
        hr = m_pDirectDraw->CreateClipper(0, &m_pOvlyClipper, NULL);
        if (FAILED(hr) ) {
            m_pOvlyClipper = NULL;
        }
    }

    return m_pOvlyClipper;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\render.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Main video renderer header file, Anthony Phillips, January 1995

#ifndef __RENDER__
#define __RENDER__

// Include the global header files

#include <dciman.h>
#include <dciddi.h>
#include <ddraw.h>
#include <viddbg.h>

// Forward declarations

class CRenderer;
class CVideoWindow;
class CVideoSample;
class CVideoAllocator;
class COverlay;
class CControlWindow;
class CControlVideo;
class CDirectDraw;
class CRendererMacroVision;

// Include the rendering header files

#include "vidprop.h"        // Video renderer property pages
#include "dvideo.h"         // Implements DirectDraw surfaces
#include "allocate.h"       // A shared DIB section allocator
#include "direct.h"         // The renderer overlay extensions
#include "window.h"         // An object to maintain a window
#include "hook.h"           // Hooks window clipping messages
#include "VRMacVis.h"       // The MacroVision support object
#include "image.h"          // The main controlling COM object

#endif // __RENDER__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\image.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements the CRenderer class, Anthony Phillips, January 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>
#include <limits.h>
#include <measure.h>

#ifdef FILTER_DLL
#include <initguid.h>
#endif

#include "ddmm.h"
#include "MultMon.h"  // our version of multimon.h include ChangeDisplaySettingsEx
#include "dvdmedia.h"  // for MacroVision prop set, id

// (Threading model) We can have upto three different threads accessing us
// at the same time. The first is the application (or filter graph) thread
// that changes our state, looks after connections and calls the control
// interfaces. All these interfaces are serialised through the main video
// critical section handed out to the implementation objects at creation.
//
// The second is a thread spun off to poll messages from the window queue,
// this is packaged up in an object with it's own critical section. All the
// parts of the video renderer that change properties on the video window
// (such as it's palette) call into the window object via a public entry
// method and lock the object before making the changes. In certain places
// the window thread has to call out into another one of our objects (like
// the overlay object), unfortunately the overlay object also likes to call
// into the window object which leads to a possible deadlock condition. The
// solution is to lock the overlay object first and then lock the window
// (ALWAYS in that order). For example, in the WM_PAINT processing it first
// calls the overlay object and afterwards grabs it's own critical section.
//
// The third is the source filter thread that calls Receive on our input pin
// Calls to Receive should be serialised on a single thread. The thread waits
// until the image it contains is due for drawing. The causes some difficult
// problems with state change synchronisation. When we have a thread inside
// of us and stop we set an event in the window object via CanReceiveSamples
// so that it's wait is aborted and it can return to the source. We don't
// wait for the worker thread to return before completing the stop.
//
// So we could in theory stop us and the start us running (or other very fast
// state transitions) before the worker thread has completed. Fortunately we
// know this won't happen because the entire filter graph must be transitioned
// to each state before another one can be executed. So when we stop we know
// the worker thread must be back at the source before it will fully stop. If
// this wasn't the case we would have to have an event that was reset when a
// worker thread arrived and set when it exited so we could wait on it, this
// would introduce a Set and Reset for every image we ever wanted to render.
//
// We have a fair number of critical sections to help manage all the threads
// that can be bouncing around the filter. The order that these locks are
// gained in is absolutely critical. If locks are gained in the wrong order
// we will inevitably deadlock. The hierachy of locks is as follows,
//
//      - Main renderer interface lock (sdk RENBASE.H)   (Highest)
//      - IOverlay class lock (DIRECT.H)                     |
//      - Base renderer sample lock (sdk RENBASE.H)          |
//      - Window thread lock (WINDOW.H)                      |
//      - DirectDraw video allocator (ALLOCATE.H)            |
//      - DirectVideo (DVIDEO.H) critical section            |
//      - Display base class (sdk WINUTIL.H)             (Lowest)
//
// Therefore if for example you are executing a function in the window object
// with the window lock gained, and you need to call the overlay object which
// locks it's critical section, then you must UNLOCK the window lock before
// calling. This is because the overlay object can also call into the window
// object. If it has it's lock when it calls the window object, and you have
// the window lock as you call into the overlay then we'll deadlock. There
// does not appear to be a design whereby objects only call in one direction
// (ie don't call each other) - in part this is because of the very complex
// threading interactions that can occur - so my advise is to be careful!


// List of class IDs and creator functions for the class factory. This
// provides the link between the OLE entry point in the DLL and an object
// being created. The class factory will call the static CreateInstance
// function when it is asked to create a CLSID_VideoRenderer COM object

#ifdef FILTER_DLL
CFactoryTemplate g_Templates[] = {
    {L"", &CLSID_VideoRenderer,CRenderer::CreateInstance,OnProcessAttachment},
    {L"", &CLSID_DirectDrawProperties,CVideoProperties::CreateInstance},
    {L"", &CLSID_QualityProperties,CQualityProperties::CreateInstance},
    {L"", &CLSID_PerformanceProperties,CPerformanceProperties::CreateInstance}
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
STDAPI DllRegisterServer()
{
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    return AMovieDllRegisterServer2( FALSE );
}
#endif

// helper to let VMR create this filter without including all our
// header files
CUnknown *CRenderer_CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    return CRenderer::CreateInstance(pUnk, phr);
}

// This goes in the factory template table to create new filter instances

CUnknown *CRenderer::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    return new CRenderer(NAME("Video renderer"),pUnk,phr);
}

// this is needed for rendering output of the ovmixer. perhaps we
// could change it to subtype=overlay and raise the merit to speed up
// things

// Setup data

const AMOVIESETUP_MEDIATYPE
sudVideoPinTypes =
{
    &MEDIATYPE_Video,           // Major type
    &MEDIASUBTYPE_NULL          // And subtype
};

const AMOVIESETUP_PIN
sudVideoPin =
{
    L"Input",                   // Name of the pin
    TRUE,                       // Is pin rendered
    FALSE,                      // Is an Output pin
    FALSE,                      // Ok for no pins
    FALSE,                      // Can we have many
    &CLSID_NULL,                // Connects to filter
    NULL,                       // Name of pin connect
    1,                          // Number of pin types
    &sudVideoPinTypes           // Details for pins
};

const AMOVIESETUP_FILTER
sudVideoFilter =
{
    &CLSID_VideoRenderer,       // Filter CLSID
    L"Video Renderer",          // Filter name
    MERIT_UNLIKELY,             // Filter merit
    1,                          // Number pins
    &sudVideoPin                // Pin details
};

// Constructor for the main renderer class. This was originally written to
// instantiate only the contained interfaces and not the class that looks
// after the window. This kind of late binding proved to be very buggy and
// difficult to maintain. For these reasons the constructor now creates all
// it's classes during construction. This means that as soon as a renderer
// object is created so will the window that it uses, this is unlikely to
// prove much of an overhead and indeed reduces the latency when the client
// starts streaming as the window is already initialised and ready to accept
// video images. We do however create the window object dynamically, albeit
// in the constructor. This is so that when we come to the destructor we can
// destroy the window and it's thread before anything. We therefore know
// that no more window messages will be retrieved and dispatched to various
// nested objects while we are processing any of the objects destructors

#pragma warning(disable:4355)

CRenderer::CRenderer(TCHAR *pName,
                     LPUNKNOWN pUnk,
                     HRESULT *phr) :

    CBaseVideoRenderer(CLSID_VideoRenderer,pName,pUnk,phr),
    m_VideoWindow(this,&m_InterfaceLock,GetOwner(),phr),
    m_VideoAllocator(this,&m_DirectDraw,&m_InterfaceLock,phr),
    m_Overlay(this,&m_DirectDraw,&m_InterfaceLock,phr),
    m_InputPin(this,&m_InterfaceLock,phr,L"Input"),
    m_DirectDraw(this,&m_InterfaceLock,GetOwner(),phr),
    m_ImagePalette(this,&m_VideoWindow,&m_DrawVideo),
    m_DrawVideo(this,&m_VideoWindow),
    m_fDisplayChangePosted(false),
    m_hEndOfStream(NULL),
    m_StepEvent(NULL),
    m_lFramesToStep(-1),
    m_nNumMonitors(GetSystemMetrics(SM_CMONITORS)),
    m_nMonitor(-1)
{
    // Store the video input pin
    m_pInputPin = &m_InputPin;

    // Reset the video size

    m_VideoSize.cx = 0;
    m_VideoSize.cy = 0;

    // Initialise the window and control interfaces

    HRESULT hr = m_VideoWindow.PrepareWindow();
    if (FAILED(hr)) {
        *phr = hr;
        return;
    }

    m_DrawVideo.SetDrawContext();
    m_VideoWindow.SetControlWindowPin(&m_InputPin);
    m_VideoWindow.SetControlVideoPin(&m_InputPin);

    // We have a window, figure out what monitor it's on (multi-monitor)
    // NULL means we aren't running with multiple monitors
    GetCurrentMonitor();

    // Now that we know what monitor we're on, setup for using it
    m_Display.RefreshDisplayType(m_achMonitor);

    //
    // Frame stepping stuff
    //
    // -ve == normal playback
    // +ve == frames to skips
    //  0 == time to block
    //
    m_StepEvent = CreateEvent(NULL, FALSE, FALSE, NULL);

    // CreateEvent() returns NULL if an error occurs.
    if (NULL == m_StepEvent) {
        *phr = AmGetLastErrorToHResult();
        return;
    }
}


// Close down the window before deleting the nested classes

CRenderer::~CRenderer()
{
    m_VideoWindow.InactivateWindow();
    m_Overlay.OnHookMessage(FALSE);
    m_VideoWindow.DoneWithWindow();
    m_pInputPin = NULL;

    if (m_StepEvent)
    {
        CloseHandle(m_StepEvent);
    }
}

STDMETHODIMP CRenderer::DrawVideoImageBegin()
{
    CAutoLock cSampleLock(&m_RendererLock);

    if (m_State != State_Stopped) {
        return VFW_E_WRONG_STATE;
    }

    m_VideoAllocator.NoDirectDraw(TRUE);
    return NOERROR;
}

STDMETHODIMP CRenderer::DrawVideoImageEnd()
{
    CAutoLock cSampleLock(&m_RendererLock);

    if (m_State != State_Stopped) {
        return VFW_E_WRONG_STATE;
    }

    m_VideoAllocator.NoDirectDraw(FALSE);
    return NOERROR;
}


STDMETHODIMP CRenderer::DrawVideoImageDraw(HDC hdc, LPRECT lprcSrc, LPRECT lprcDst)
{
    for (; ; )
    {
        {
            CAutoLock cSampleLock(&m_RendererLock);

            if (m_State != State_Running) {
                return VFW_E_WRONG_STATE;
            }

            if (m_VideoAllocator.GetDirectDrawStatus()) {
                return VFW_E_WRONG_STATE;
            }

            if (!m_DrawVideo.UsingImageAllocator()) {
                return VFW_E_WRONG_STATE;
            }

            if (m_pMediaSample != NULL) {
                m_ImagePalette.DrawVideoImageHere(hdc,
                                                  m_pMediaSample,
                                                  lprcSrc, lprcDst);
                return NOERROR;
            }

            //  Call the base class to avoid locking issues
            IMediaSample *pMediaSample;
            HRESULT hr;

            hr = m_VideoAllocator.CBaseAllocator::GetBuffer(&pMediaSample,
                                                            NULL, NULL,
                                                            AM_GBF_NOWAIT);
            if (SUCCEEDED(hr)) {
                m_ImagePalette.DrawVideoImageHere(hdc, pMediaSample,
                                                  lprcSrc, lprcDst);
                pMediaSample->Release();
                return NOERROR;
            }

            if (hr != VFW_E_TIMEOUT) {
                return E_FAIL;
            }
        }

        Sleep(1);
    }

    return E_FAIL;
}

#if 0
HRESULT
CRenderer::CopySampleBits(
    IMediaSample *pMediaSample,
    LPBYTE* ppDib
    )
{
    LPBYTE lpBits;
    HRESULT hr = pMediaSample->GetPointer(&lpBits);
    if (FAILED(hr)) {
        return hr;
    }

    LPBITMAPINFOHEADER lpbi = HEADER(m_mtIn.Format());
    if (lpbi) {

        ULONG ulSizeHdr;
        LPBITMAPINFOHEADER lpbiDst;

        if (lpbi->biCompression == BI_BITFIELDS) {
            ulSizeHdr = lpbi->biSize + (3 * sizeof(DWORD));
        }
        else {
            ulSizeHdr = lpbi->biSize + (int)(lpbi->biClrUsed * sizeof(RGBQUAD));
        }

        *ppDib = (LPBYTE)CoTaskMemAlloc(ulSizeHdr + DIBSIZE(*lpbi));

        if (*ppDib) {
            CopyMemory(*ppDib, lpbi, ulSizeHdr);
            CopyMemory(*ppDib + ulSizeHdr, lpBits, DIBSIZE(*lpbi));
            return NOERROR;
        }
    }

    return E_FAIL;

}

STDMETHODIMP CRenderer::DrawVideoImageGetBits(LPBYTE* ppDib)
{
    for (; ; )
    {
        {
            CAutoLock cSampleLock(&m_RendererLock);

            if (m_State != State_Running) {
                return VFW_E_WRONG_STATE;
            }

            if (m_VideoAllocator.GetDirectDrawStatus()) {
                return VFW_E_WRONG_STATE;
            }

            if (!m_DrawVideo.UsingImageAllocator()) {
                return VFW_E_WRONG_STATE;
            }

            if (m_pMediaSample != NULL) {
                return CopySampleBits(m_pMediaSample, ppDib);
            }

            //  Call the base class to avoid locking issues
            IMediaSample *pMediaSample;
            HRESULT hr;

            hr = m_VideoAllocator.CBaseAllocator::GetBuffer(&pMediaSample,
                                                            NULL, NULL,
                                                            AM_GBF_NOWAIT);
            if (SUCCEEDED(hr)) {
                hr = CopySampleBits(pMediaSample, ppDib);
                pMediaSample->Release();
                return hr;
            }

            if (hr != VFW_E_TIMEOUT) {
                return E_FAIL;
            }
        }

        Sleep(1);
    }

    return E_FAIL;
}
#endif


// what device is this window on?
INT_PTR CRenderer::GetCurrentMonitor()
{
    // This can change dynamically
    m_nNumMonitors = GetSystemMetrics(SM_CMONITORS);

    m_nMonitor = DeviceFromWindow(m_VideoWindow.GetWindowHWND(), m_achMonitor,
                                  &m_rcMonitor);
    DbgLog((LOG_TRACE,3,TEXT("Establishing current monitor = %s"),
            m_achMonitor));
    // 0 means spanning monitors or off in hyperspace, otherwise it is a
    // unique id for each monitor
    return m_nMonitor;
}


// Has the window moved at least partially onto a monitor other than the
// monitor we have a DDraw object for?  ID will be the hmonitor of the
// monitor it is on, or 0 if it spans
BOOL CRenderer::IsWindowOnWrongMonitor(INT_PTR *pID)
{

    // There is only 1 monitor.
    if (m_nNumMonitors == 1) {
        if (pID)
            *pID = m_nMonitor;
        return FALSE;
    }

    HWND hwnd = m_VideoWindow.GetWindowHWND();

    // If the window is on the same monitor as last time, this is the quickest
    // way to find out.  This is called every frame, remember
    RECT rc;
    GetWindowRect(hwnd, &rc);
    if (rc.left >= m_rcMonitor.left && rc.right <= m_rcMonitor.right &&
        rc.top >= m_rcMonitor.top && rc.bottom <= m_rcMonitor.bottom) {
        if (pID)
            *pID = m_nMonitor;
        return FALSE;
    }

    // Find out for real. This is called every frame, but only when we are
    // partially off our main monitor, so that's not so bad.
    INT_PTR ID = DeviceFromWindow(hwnd, NULL, NULL);
    if (pID)
        *pID = ID;
    //DbgLog((LOG_TRACE,3,TEXT("Current Monitor %d   New Monitor %d"), m_DDrawID, ID));
    return (m_nMonitor != ID);
}


// Overriden to say what interfaces we support and where

STDMETHODIMP CRenderer::NonDelegatingQueryInterface(REFIID riid,void **ppv)
{
    // Do we have this interface

    if (riid == IID_ISpecifyPropertyPages) {
        return GetInterface((ISpecifyPropertyPages *)this, ppv);
    } else if (riid == IID_IKsPropertySet) {
        return GetInterface((IKsPropertySet *)this, ppv);
    } else if (riid == IID_IDrawVideoImage) {
        return GetInterface((IDrawVideoImage *)this, ppv);
    } else if (riid == IID_IBasicVideo || riid == IID_IBasicVideo2) {
        return m_VideoWindow.NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IVideoWindow) {
        return m_VideoWindow.NonDelegatingQueryInterface(riid,ppv);
    } else if (riid == IID_IDirectDrawVideo) {
        return m_DirectDraw.NonDelegatingQueryInterface(riid,ppv);
    }
    return CBaseVideoRenderer::NonDelegatingQueryInterface(riid,ppv);
}


// Return the CLSIDs for the property pages we support

STDMETHODIMP CRenderer::GetPages(CAUUID *pPages)
{
    CheckPointer(pPages,E_POINTER);

#if 0
    // By default, we don't want to provide the DirectDraw and performance
    // property pages, they'll just confuse a novice user. Likewise the
    // fullscreen property page that selects display modes won't be shown

    HKEY hk;
    BOOL fShowDDrawPage = FALSE, fShowPerfPage = FALSE;
    DWORD dwValue = 0, cb = sizeof(DWORD);
    TCHAR ach[80] = {'C','L','S','I','D','\\'};
    REFGUID rguid = CLSID_DirectDrawProperties;
    wsprintf(&ach[6], "{%08lX-%04X-%04X-%02X%02X-%02X%02X%02X%02X%02X%02X}",
            rguid.Data1, rguid.Data2, rguid.Data3,
            rguid.Data4[0], rguid.Data4[1],
            rguid.Data4[2], rguid.Data4[3],
            rguid.Data4[4], rguid.Data4[5],
            rguid.Data4[6], rguid.Data4[7]);

    if (!RegOpenKey(HKEY_CLASSES_ROOT, ach, &hk)) {
        if (!RegQueryValueEx(hk, "ShowMe", NULL, NULL, (LPBYTE)&dwValue, &cb) &&
                             dwValue)
            fShowDDrawPage = TRUE;
        RegCloseKey(hk);
    }

    // Next look after the performance property page

    REFGUID rguid2 = CLSID_PerformanceProperties;
    wsprintf(&ach[6], "{%08lX-%04X-%04X-%02X%02X-%02X%02X%02X%02X%02X%02X}",
            rguid2.Data1, rguid2.Data2, rguid2.Data3,
            rguid2.Data4[0], rguid2.Data4[1],
            rguid2.Data4[2], rguid2.Data4[3],
            rguid2.Data4[4], rguid2.Data4[5],
            rguid2.Data4[6], rguid2.Data4[7]);

    if (!RegOpenKey(HKEY_CLASSES_ROOT, ach, &hk)) {
        if (!RegQueryValueEx(hk, "ShowMe", NULL, NULL, (LPBYTE)&dwValue, &cb) &&
                             dwValue)
            fShowPerfPage = TRUE;
        RegCloseKey(hk);
    }
#endif

    // Allocate the memory for the GUIDs

    pPages->cElems = 1;
    pPages->pElems = (GUID *) QzTaskMemAlloc(3 * sizeof(GUID));
    if (pPages->pElems == NULL) {
        return E_OUTOFMEMORY;
    }

    // Fill in the array with the property page GUIDs

    pPages->pElems[0] = CLSID_QualityProperties;
#if 0
    if (fShowDDrawPage)
#endif
        pPages->pElems[pPages->cElems++] = CLSID_DirectDrawProperties;
#if 0
    if (fShowPerfPage)
#endif
        pPages->pElems[pPages->cElems++] = CLSID_PerformanceProperties;

    return NOERROR;
}


// This is called when we can establish a connection to prepare for running
// We store a copy of the media type used for the connection in the renderer
// because it is required by many different parts of the running renderer
// This can be called when we come to draw a media sample that has a format
// change with it since we delay the completion to maintain synchronisation

HRESULT CRenderer::SetMediaType(const CMediaType *pmt)
{
    // CAutoLock cInterfaceLock(&m_InterfaceLock);
    ASSERT(CritCheckIn(&m_InterfaceLock));
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    const GUID SubType = *pmt->Subtype();
    m_Display.UpdateFormat(pVideoInfo);
    ASSERT(CritCheckOut(&m_RendererLock));

    // Is this an overlay connection being set

    if (*pmt->Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Setting overlay format");
        return SetOverlayMediaType(pmt);
    }

    // Look after DirectDraw samples separately

    if (m_VideoAllocator.GetDirectDrawStatus()) {
        NOTE("Setting DirectDraw format");
        return SetDirectMediaType(pmt);
    }

    if (m_bInReceive) {
        m_VideoWindow.SetRealize(FALSE);
    }
    // Change palettes using the current format
    m_ImagePalette.PreparePalette(pmt, &m_mtIn, m_achMonitor);
    m_VideoWindow.SetRealize(TRUE);

    m_mtIn = *pmt;

    // Complete the format change in the other objects
    m_DrawVideo.NotifyMediaType(&m_mtIn);
    m_VideoAllocator.NotifyMediaType(&m_mtIn);

    // Update the DirectDraw format with palette changes

    if (m_VideoAllocator.IsDirectDrawAvailable() == TRUE) {
        NOTE("Storing palette in DirectDraw format");
        CMediaType *pDirect = m_DirectDraw.GetSurfaceFormat();
        m_ImagePalette.CopyPalette(pmt,pDirect);
    }
    return NOERROR;
}


// Handles setting of a media type from a DirectDraw sample. If we get a type
// change on a DCI/DirectDraw sample then we can extract palette changes from
// them. If the colours do really differ then we need to create a new palette
// and update the original DIB format. We must also update the surface format
// so that everything remains in sync - there is a base class function called
// CopyPalette that looks after copying palette colours between media formats

HRESULT CRenderer::SetDirectMediaType(const CMediaType *pmt)
{
    NOTE("SetDirectMediaType");

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    if (ContainsPalette((VIDEOINFOHEADER *)pVideoInfo) == FALSE) {
        NOTE("No palette");
        return NOERROR;
    }

    // Check that we already have a palette

    if (*m_mtIn.Subtype() != MEDIASUBTYPE_RGB8) {
        ASSERT(!TEXT("Invalid format"));
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    // Update the current palette and copy the colours

    if (m_ImagePalette.PreparePalette(pmt, &m_mtIn, m_achMonitor) != NOERROR) {
        NOTE("No palette change");
        return NOERROR;
    }

    // Copy the palette into the renderer formats

    ASSERT(m_VideoAllocator.IsDirectDrawAvailable());
    m_ImagePalette.CopyPalette(pmt,&m_mtIn);
    CMediaType *pDirect = m_DirectDraw.GetSurfaceFormat();
    m_ImagePalette.CopyPalette(pmt,pDirect);

    return NOERROR;
}


// Handles setting of an overlay media type

HRESULT CRenderer::SetOverlayMediaType(const CMediaType *pmt)
{
    NOTE("SetOverlayMediaType");
    m_mtIn = *pmt;
    m_ImagePalette.RemovePalette();
    m_VideoWindow.OnUpdateRectangles();
    return NOERROR;
}

HRESULT CRenderer::ResetForDfc()
{
    // Free any palette resources
    m_ImagePalette.RemovePalette();
    // m_mtIn.ResetFormatBuffer();

    // Destroy DCI/DirectDraw surfaces
    m_DirectDraw.ReleaseSurfaces();
    m_DirectDraw.ReleaseDirectDraw();
    m_VideoAllocator.Decommit();
    m_VideoAllocator.ResetDirectDrawStatus();

    return S_OK;
}


// This is called when a connection or an attempted connection is terminated
// and lets us to reset the connection flag held by the base class renderer
// The filter object may be hanging onto an image to use for refreshing the
// video window so that must be freed (the allocator decommit may be waiting
// for that image to return before completing) then we must also uninstall
// any palette we were using, reset anything set with the control interfaces
// then set our overall state back to disconnected ready for the next time

HRESULT CRenderer::BreakConnect()
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    // Check we are in a valid state

    HRESULT hr = CBaseVideoRenderer::BreakConnect();
    if (FAILED(hr)) {
        return hr;
    }

    // The window is not used when disconnected
    IPin *pPin = m_InputPin.GetConnected();
    if (pPin) SendNotifyWindow(pPin,NULL);


    // Free any palette resources
    m_ImagePalette.RemovePalette();
    m_mtIn.ResetFormatBuffer();

    // Destroy DCI/DirectDraw surfaces
    m_DirectDraw.ReleaseSurfaces();
    m_DirectDraw.ReleaseDirectDraw();
    m_VideoAllocator.Decommit();
    m_VideoAllocator.ResetDirectDrawStatus();

    // Now deactivate Macrovision, if it was activated
    if (m_MacroVision.GetCPHWND())
    {
        m_MacroVision.SetMacroVision(m_MacroVision.GetCPHWND(), 0) ;  // clear MV from display
        m_MacroVision.StopMacroVision(m_MacroVision.GetCPHWND()) ;    // reset CP key
    }

    return NOERROR;
}


// Overriden to check for overlay connections

HRESULT CRenderer::BeginFlush()
{
    NOTE("Entering BeginFlush");

    {
        CAutoLock cInterfaceLock(&m_InterfaceLock);

        //  Cancel frame stepping or we'll hang
        CancelStep();
        m_hEndOfStream = 0;
    }

    // This is valid for media samples only

    if (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Overlay");
        return NOERROR;
    }
    return CBaseVideoRenderer::BeginFlush();
}


// Overriden to check for overlay connections

HRESULT CRenderer::EndFlush()
{
    NOTE("Entering EndFlush");

    // Make sure the overlay gets updated
    m_DirectDraw.OverlayIsStale();

    // This is valid for media samples only

    if (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Overlay");
        return NOERROR;
    }
    return CBaseVideoRenderer::EndFlush();
}


// Pass EOS to the video renderer window object that sets a flag so that no
// more data will be accepted from the pin until either we transition to a
// stopped state or are flushed. It also lets it know whether it will have
// an image soon for refreshing. When we go to a stopped state we clear any
// end of stream flag set so we must make sure to reject this if received

HRESULT CRenderer::EndOfStream()
{
    {
        CAutoLock cInterfaceLock(&m_InterfaceLock);
        if (m_hEndOfStream) {
            EXECUTE_ASSERT(SetEvent(m_hEndOfStream));
            return S_OK;
        }
    }

    NOTE("Entering EndOfStream");
    CBaseVideoRenderer::EndOfStream();
    m_DirectDraw.StartRefreshTimer();
    return NOERROR;
}

HRESULT CRenderer::NotifyEndOfStream(HANDLE hNotifyEvent)
{
    CAutoLock l(&m_InterfaceLock);
    m_hEndOfStream = hNotifyEvent;
    return S_OK;
}



// This is the last thing called by both Connect and ReceiveConnect when they
// have finished their connection protocol. This point provides us a suitable
// time to reset our state such as enabling DCI/DirectDraw and clearing any
// run time error that may have been left over from the previous connection
// We don't load DirectDraw for overlay connections since they don't need it

HRESULT CRenderer::CompleteConnect(IPin *pReceivePin)
{
    m_DrawVideo.ResetPaletteVersion();
    NOTE("Entering CompleteConnect");

    // This enables us to send EC_REPAINT events again

    HRESULT hr = CBaseVideoRenderer::CompleteConnect(pReceivePin);
    if (FAILED(hr)) {
        return hr;
    }

    // Pass the video window handle upstream
    HWND hwnd = m_VideoWindow.GetWindowHWND();
    NOTE1("Sending EC_NOTIFY_WINDOW %x",hwnd);
    SendNotifyWindow(pReceivePin,hwnd);

//  // Don't load DirectDraw for overlay connections
//
//  We have to load DirectDraw of MEDIASUBTYPE_Overlay because we
//  have replaced the DCI clipper with the DirectDraw clipper
//
//  if (*m_mtIn.Subtype() != MEDIASUBTYPE_Overlay) {
        NOTE("Initialising DirectDraw");
        m_DirectDraw.InitDirectDraw(*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay);
//  }

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_mtIn.Format();

    // Has the video size changed between connections

    if (pVideoInfo->bmiHeader.biWidth == m_VideoSize.cx) {
        if (pVideoInfo->bmiHeader.biHeight == m_VideoSize.cy) {
            NOTE("No size change");
            return NOERROR;
        }
    }

    // Set properties for the current video

    m_VideoSize.cx = pVideoInfo->bmiHeader.biWidth;
    m_VideoSize.cy = pVideoInfo->bmiHeader.biHeight;
    m_VideoWindow.SetDefaultSourceRect();
    m_VideoWindow.SetDefaultTargetRect();
    m_VideoWindow.OnVideoSizeChange();

    // Notify the video window of the CompleteConnect
    m_VideoWindow.CompleteConnect();
    m_VideoWindow.ActivateWindow();

    return NOERROR;
}


HRESULT CRenderer::CheckMediaTypeWorker(const CMediaType *pmt)
{
    // Does the media type contain a NULL format

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    if (pVideoInfo == NULL) {
        NOTE("NULL format");
        return E_INVALIDARG;
    }

    // Just check the format if not using our allocator

    if (m_DrawVideo.UsingImageAllocator() == FALSE) {
        NOTE("Checking display format");
        return m_Display.CheckMediaType(pmt);
    }

    // Is this a query on the DirectDraw format

    if (m_VideoAllocator.IsSurfaceFormat(pmt) == TRUE) {
        NOTE("Matches surface");
        return NOERROR;
    }
    HRESULT hr = m_Display.CheckMediaType(pmt);
    if (FAILED(hr)) {
        DbgLog((LOG_TRACE, 2, TEXT("CheckMediaType returned %8.8X"), hr));
    }
    return hr;
}

BOOL CRenderer::LockedDDrawSampleOutstanding()
{
    if (m_DrawVideo.UsingImageAllocator()) {

        if (m_VideoAllocator.UsingDDraw()) {

            return m_VideoAllocator.AnySamplesOutstanding();
        }
    }

    return FALSE;
}

// Check that we can support a given proposed type. QueryAccept is also used
// as a trigger to change our buffer formats. If we are called with a format
// that matches the current DirectDraw format then we force a renegotiation
// when GetBuffer is next called. This can be used to delay switching into
// DirectDraw. Alternatively we may be called with the current DIB format in
// which case we also use it as a trigger to generate a format renegotiation

HRESULT CRenderer::CheckMediaType(const CMediaType *pmt)
{
    //
    // If there is a locked DDraw sample outstanding
    // don't take the renderer lock because we will
    // deadlock if a TransIP filter is up stream of us.
    //

    if (LockedDDrawSampleOutstanding()) {
        return CheckMediaTypeWorker(pmt);
    }
    else {
        CAutoLock cInterfaceLock(&m_InterfaceLock);
        return CheckMediaTypeWorker(pmt);
    }
}

//  Helper to step a frame
void CRenderer::FrameStep()
{
    CAutoLock cFrameStepStateLock(&m_FrameStepStateLock);
    if (m_lFramesToStep == 1) {
        m_lFramesToStep--;
        m_FrameStepStateLock.Unlock();
        NotifyEvent(EC_STEP_COMPLETE, FALSE, 0);
        DWORD dw = WaitForSingleObject(m_StepEvent, INFINITE);
        m_FrameStepStateLock.Lock();
        ASSERT(m_lFramesToStep != 0);
    }
}

//  Helper to cancel frame step
void CRenderer::CancelStep()
{
    CAutoLock cFrameStepStateLock(&m_FrameStepStateLock);

    //
    // cancel any outstanding steps
    //
    long l = m_lFramesToStep;
    m_lFramesToStep = -1;

    if (l == 0) {

        SetEvent(m_StepEvent);
    }
}


bool CRenderer::IsFrameStepEnabled()
{
    CAutoLock cFrameStepStateLock(&m_FrameStepStateLock);
    return (m_lFramesToStep >= 0);
}


// These implement the remaining IMemInputPin virtual method. We are called
// by the output pin from the connected filter when a sample is ready. All we
// do after some checking is pass the sample on to the object looking after
// the window which does the timing, synchronisation and presentation of the
// image. We need to AddRef the sample if we are to hold it beyond the end of
// this function, sample reference counting is managed by the window object

HRESULT CRenderer::Receive(IMediaSample *pSample)
{
    if (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("Receive called for overlay");
        return VFW_E_NOT_SAMPLE_CONNECTION;
    }

    HRESULT hr = VFW_E_SAMPLE_REJECTED;


    // When we receive a sample we must pass it to our allocator first since
    // it may be a DCI/DirectDraw sample that has the display locked. If it
    // isn't then we pass it to our base pin class so that it can reject it
    // if we are currently flushing, it will also check the type to see if it
    // is being changed dynamically. Our allocator OnReceive method returns
    // an error if the sample still requires further processing (drawing)

    // Pass to our allocator in case it's DCI/DirectDraw

    if (m_DrawVideo.UsingImageAllocator() == TRUE) {
        hr = m_VideoAllocator.OnReceive(pSample);
    }

    // DEADLOCK Do NOT lock the renderer before having our allocator free
    // the display (if it's a DCI/DirectDraw sample). This is because a
    // state change might get in while you are waiting to get the lock.
    // State changes show and hide the video window which will wait until
    // the display is unlocked but that can't happen because the source
    // thread can't get in while the state change thread has the lock

    //
    // Frame step
    //
    // This code acts as a gate - for a frame step of N frames
    // it discards N-1 frames and then lets the Nth frame thru the
    // the gate to be renderer in the normal way i.e. at the correct
    // time.  The next time Receive is called the gate is shut and
    // the thread blocks.  The gate only opens again when the step
    // is cancelled or another frame step request comes in.
    //
    // StEstrop - Thu 10/21/1999
    //

    {
        //
        // do we have frames to discard ?
        //

        CAutoLock cLock(&m_FrameStepStateLock);
        if (m_lFramesToStep > 1) {
            m_lFramesToStep--;
            if (m_lFramesToStep > 0) {
                return NOERROR;
            }
        }
    }

    // Have we finished with this sample - this is the case when
    // we are in sync-on-fill mode.  In which case the sample has
    // already been made visible, so we just need to complete the
    // frame steping part of the procedure.

    if (hr == VFW_S_NO_MORE_ITEMS) {

        // Store the media times from this sample
        if (m_pPosition)
            m_pPosition->RegisterMediaTime(pSample);

        FrameStep();
        return NOERROR;
    }
    hr = CBaseVideoRenderer::Receive(pSample);
    FrameStep();

    return hr;
}


// Use the image just delivered to display a poster frame

void CRenderer::OnReceiveFirstSample(IMediaSample *pMediaSample)
{
    DoRenderSample(pMediaSample);
}


// A filter can have four discrete states, namely Stopped, Running, Paused,
// Intermediate. We show the window in Paused, Running states and optionally
// in Stopped state. We are in an intermediate state if we are currently
// trying to pause but haven't yet got the first sample (or if we have been
// flushed in paused state and therefore still have to wait for an image)
//
// This class contains an event called m_evComplete which is signalled when
// the current state is completed and is not signalled when we are waiting to
// complete the last state transition. As mentioned above the only time we
// use this at the moment is when we wait for a media sample in paused state
// If while we are waiting we receive an end of stream notification from the
// source filter then we know no data is imminent so we can reset the event
// This means that when we transition to paused the source filter must call
// end of stream on us or send us an image otherwise we'll hang indefinately
//
// We create ourselves a window and two drawing device contexts right at the
// start and only delete them when the whole filter is finally released. This
// is because a window is not a large nor exclusive holder of system resources
//
// When a connection is made we create any palette required and install them
// into the drawing device contexts. We may require these resources when we
// are stopped as we could be embedded in a compound document (in which case
// we would probably use their window) and have to display a poster image


// The auto show flag is used to have the window shown automatically when we
// change state. We do this only when moving to paused or running, when there
// is no outstanding EC_USERABORT set and when the window is not already up
// This can be changed through the IVideoWindow interface AutoShow property.
// If the window is not currently visible then we are showing it because of
// a state change to paused or running, in which case there is no point in
// the video window sending an EC_REPAINT as we're getting an image anyway

void CRenderer::AutoShowWindow()
{
    HWND hwnd = m_VideoWindow.GetWindowHWND();
    NOTE("AutoShowWindow");

    if (m_VideoWindow.IsAutoShowEnabled() == TRUE) {
        if (m_bAbort == FALSE) {
            if (IsWindowVisible(hwnd) == FALSE) {
                NOTE("Executing AutoShowWindow");
                SetRepaintStatus(FALSE);
                m_VideoWindow.PerformanceAlignWindow();
                m_VideoWindow.DoShowWindow(SW_SHOWNORMAL);
                m_VideoWindow.DoSetWindowForeground(TRUE);
            }
        }
    }
}


// If we are being pausing and there's no sample waiting then don't complete
// the transition and return S_FALSE until the first one arrives. However if
// the m_bAbort flag has been set (perhaps the user closed the window) then
// all samples are rejected so there is no point waiting for one. If we do
// have an image then return S_OK (NOERROR). At the moment we'll only return
// VFW_S_STATE_INTERMEDIATE from GetState if an incomplete pause has occured

// Here are some reasons why we should complete a state change
//      The input pin is not connected
//      The user aborted a playback
//      We have an overlay connection
//      We have sent an end of stream
//      There is a fresh sample pending
//      The overlay surface is showing

HRESULT CRenderer::CompleteStateChange(FILTER_STATE OldState)
{
    NOTE("CompleteStateChange");

    // Allow us to be paused when disconnected or windowless

    if (m_InputPin.IsConnected() == FALSE || m_bAbort) {
        NOTE("Not connected");
        Ready();
        return S_OK;
    }

    // Ready if we have an overlay connection

    GUID SubType = *m_mtIn.Subtype();
    if (SubType == MEDIASUBTYPE_Overlay) {
        NOTE("Overlay");
        Ready();
        return S_OK;
    }

    // Have we run off the end of stream

    if (IsEndOfStream() == TRUE) {
        NOTE("End of stream");
        Ready();
        return S_OK;
    }

    // Complete the state change if we have a sample

    if (m_VideoAllocator.IsSamplePending() == FALSE) {
        if (m_DirectDraw.IsOverlayComplete() == FALSE) {
            if (HaveCurrentSample() == FALSE) {
                NOTE("No data");
                NotReady();
                return S_FALSE;
            }
        }
    }

    // Check the previous state

    if (OldState == State_Stopped) {
        NOTE("Stopped");
        NotReady();
        return S_FALSE;
    }

    Ready();
    return S_OK;
}

// Override Inactive() to avoid freeing the sample if we own the
// allocator - this makes repaints easier
HRESULT CRenderer::Inactive()
{
    //  Do part of what the base class does
    if (m_pPosition) {
        m_pPosition->ResetMediaTime();
    }

    //  don't free the sample if it's our allocator
    if (&m_VideoAllocator != m_InputPin.Allocator())
    {
        ClearPendingSample();
    }
    return S_OK;
}

// Overrides the filter interface Stop method, after stopping the base class
// (which calls Inactive on all the CBasePin objects) we stop worker threads
// from waiting in our object, then we stop streaming thereby cancelling any
// clock advisory connection and signal that our state change is completed
// We also decommit the allocator we're using so that threads waiting in the
// GetBuffer will be released, any further Receive calls will be rejected

STDMETHODIMP CRenderer::Stop()
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    NOTE("Changing state to stopped");

#if 0  // Video Renderer resets MV bit ONLY in the destructor
    //
    // Release the copy protection key now
    //
    if (! m_MacroVision.StopMacroVision(m_VideoWindow.GetWindowHWND()) )
    {
        DbgLog((LOG_ERROR, 0, TEXT("WARNING: Stopping copy protection failed"))) ;
        return E_UNEXPECTED ; // ??
    }
#endif // #if 0

    CancelStep();
    CBaseVideoRenderer::Stop();
    m_DirectDraw.StartRefreshTimer();

    return NOERROR;
}


// Overrides the filter interface Pause method. In paused states we accept
// samples from the source filter but we won't draw them. So we clear any
// refresh image hanging on from a previous stopped state, inform the video
// window that worker threads are now acceptable and also put the window in
// the foreground. If we haven't an image at the moment then we signal that
// our paused state transition is incomplete, this event will be reset on
// subsequent receipt of an image or if the source sends us end of stream

// When we come out of a stopped state we will release any sample we hold so
// that seeks while stopped actually get to the screen (note we release the
// sample before calling CompleteStateChange). If we have an overlay we must
// also mark it as stale for the same reason. Fortunately when we're stopped
// everyone is reset to the current position so we will get the same frame
// sent to us each time we are paused rather than edging gradually forwards

STDMETHODIMP CRenderer::Pause()
{
    {
        CAutoLock cInterfaceLock(&m_InterfaceLock);
        if (m_State == State_Paused) {
            NOTE("Paused state already set");
            return CompleteStateChange(State_Paused);
        }
	
        // Are we just going through the motions
	
        if (m_pInputPin->IsConnected() == FALSE) {
            NOTE("No pin connection");
            m_State = State_Paused;
            return CompleteStateChange(State_Paused);
        }
	
        // Make sure the overlay gets updated
        if (m_State == State_Stopped) {
            m_hEndOfStream = NULL;
            m_DirectDraw.OverlayIsStale();
        }
	
        CBaseVideoRenderer::Pause();
	
        // We must start the refresh timer after we've committed the allocator
        // Otherwise the DirectDraw code looks to see what surfaces have been
        // allocated, and in particular to see if we're using overlays, finds
        // that none have been created and so won't bother starting the timer
	
        m_DirectDraw.StartRefreshTimer();
    }
    //  DON'T hold the lock while doing these window operations
    //  If we do then we can hang if the window thread ever grabs it
    //  because some of these operation do SendMessage to our window
    //  (it's that simple - think about it)
    //  This should be safe because all this stuff really only references
    //  m_hwnd which doesn't change for the lifetime of this object
    AutoShowWindow();
    return (CheckReady() ? S_OK : S_FALSE);
}


// When we start running we do everything in the base class. If we are using
// overlays then we release the source thread as it is probably waiting. The
// base class doesn't do this in StartStreaming because we don't have samples
// for sync on fill surfaces (remember they do their wait in GetBuffer). We
// must mark the status as changed as we may have used a different format in
// paused mode (for primary surfaces we typically drop back to drawing DIBs)

STDMETHODIMP CRenderer::Run(REFERENCE_TIME StartTime)
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    if (m_State == State_Running) {
        NOTE("State set");
        return NOERROR;
    }

    // Send EC_COMPLETE if we're not connected

    if (m_pInputPin->IsConnected() == FALSE) {
        NOTE("No pin connection");
        m_State = State_Running;
        NotifyEvent(EC_COMPLETE,S_OK,0);
        return NOERROR;
    }

    NOTE("Changing state to running");
    CBaseVideoRenderer::Run(StartTime);
    m_DirectDraw.StopRefreshTimer();
    m_VideoAllocator.StartStreaming();

    AutoShowWindow();

    return NOERROR;
}

// We only support one input pin and it is numbered zero

CBasePin *CRenderer::GetPin(int n)
{
    ASSERT(m_pInputPin);
    ASSERT(n == 0);
    return m_pInputPin;
}


// This is called with an IMediaSample interface on the image to be drawn. We
// decide on the drawing mechanism based on who's allocator we are using and
// whether the buffer should be handed to DirectDraw or not. We may be called
// indirectly when the window wants an image repainted by WM_PAINT messages
// We can't realise our palette here because this could be the source thread

HRESULT CRenderer::DoRenderSample(IMediaSample *pMediaSample)
{
    CAutoLock cWindowLock(m_VideoWindow.LockWindowUpdate());

    // Hand the buffer to GDI if not DirectDraw

    if (m_VideoAllocator.GetDirectDrawStatus() == FALSE) {
        m_DrawVideo.DrawImage(pMediaSample);
        return NOERROR;
    }

    // Have DirectDraw render the sample

    m_DrawVideo.NotifyStartDraw();
    CVideoSample *pVideoSample = (CVideoSample *) pMediaSample;
    ASSERT(pVideoSample->GetDirectBuffer() == NULL);
    m_DirectDraw.DrawImage(pMediaSample);
    m_DrawVideo.NotifyEndDraw();

    return NOERROR;
}


// Called when we receive a WM_TIMER message - we cannot synchronise with any
// state changes as the window thread cannot ever capture the interface lock
// Therefore we just call the methods and take our chances. We use a timer in
// two ways, first to update overlay positions when paused, and second to try
// and switch back to using DirectDraw periodically after going to a DOS box

BOOL CRenderer::OnTimer(WPARAM wParam)
{
    NOTE("OnTimer");

    // This is used to update overlay transports

    if (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("IOverlay timer");
        return m_Overlay.OnUpdateTimer();
    }

    // See if the surface is still busy

    if (wParam == INFINITE) {
        NOTE("Surface busy timer");
        return m_DirectDraw.OnUpdateTimer();
    }

    // Update any overlay surface we have

    if (IsStreaming() == FALSE) {
        if (m_DirectDraw.OnTimer() == FALSE) {
            NOTE("Timer repaint");
            SendRepaint();
        }
    }
    return TRUE;
}


// This is called when we receive a WM_PAINT message which informs us some of
// the window's client area has become exposed. If we have a connected source
// filter doing colour key work then we always repaint the background window.
// The invalid window region is validated before we are called, we must make
// sure to do this validation before drawing otherwise we will not paint the
// window correctly. If we send an EC_REPAINT to the filter graph we set an
// event so that we don't send another until correct receipt of a new sample

// Without the event we can get into an awful state where the filtergraph is
// executing a repaint by stopping and then pausing us. The pause clears any
// image we have held onto. Then another WM_PAINT comes in, it sees that no
// image is available and sends another EC_REPAINT! This cycles through in a
// race condition until hopefully the user stops dragging another window over
// ours. The mass of EC_REPAINTs causes wild disk thrashing as we seek over
// and over again trying to set the correct start position and play a frame

BOOL CRenderer::OnPaint(BOOL bMustPaint)
{
    // Can the overlay object do anything with the paint

    if (m_Overlay.OnPaint() == TRUE) {
        return TRUE;
    }

    // The overlay object did not paint it's colour therefore we go through
    // here and lock ourselves up so that we see if we have a DIB sample to
    // draw with. If we have no sample then if we are not streaming we will
    // notify the filtergraph with an EC_REPAINT, this causes the graph to
    // be paused so we will get an image through to use in further paints

    CAutoLock cSampleLock(&m_RendererLock);

    // If we're not using DirectDraw grab the sample and repaint it if
    // we can
    if (!m_VideoAllocator.GetDirectDrawStatus()) {
        if (m_pMediaSample == NULL) {
            if (m_DrawVideo.UsingImageAllocator()) {
                IMediaSample *pSample;

                //  Call the base class to avoid locking issues
                m_VideoAllocator.CBaseAllocator::GetBuffer(&pSample, NULL, NULL, AM_GBF_NOWAIT);
                if (pSample) {
                    BOOL bResult = (S_OK == DoRenderSample(pSample));


                    // Disable NotifyRelease for Ksproxy
                    IMemAllocatorNotifyCallbackTemp * TempNotify = m_VideoAllocator.InternalGetAllocatorNotifyCallback();
                    m_VideoAllocator.InternalSetAllocatorNotifyCallback((IMemAllocatorNotifyCallbackTemp *) NULL);

                    pSample->Release();

                    // Re-enable NotifyRelease for Ksproxy
                    m_VideoAllocator.InternalSetAllocatorNotifyCallback(TempNotify);

                    return bResult;
                }
            }
        } else {
            return (DoRenderSample(m_pMediaSample) == S_OK);
        }
    } else {
        // Can the DirectDraw object do anything useful
	
        if (m_DirectDraw.OnPaint(m_pMediaSample) == TRUE) {
            return TRUE;
        }
    }


    // Fill the target area with the current background colour

    BOOL bOverlay = (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay);
    if (IsStreaming() == FALSE || m_bAbort || IsEndOfStream() || bOverlay || bMustPaint) {
        m_VideoWindow.EraseVideoBackground();
    }

    // No new data to paint with so signal the filtergraph that another image
    // is required, this has the filtergraph component set the whole graph to
    // a paused state which causes us to receive an image. This function must
    // be asynchronous otherwise the window will stop responding to the user

    if (!IsFrameStepEnabled()) {
        SendRepaint();
    }
    return TRUE;
}


// Filter input pin constructor

CVideoInputPin::CVideoInputPin(CRenderer *pRenderer,   // Main video renderer
                               CCritSec *pLock,        // Object to lock with
                               HRESULT *phr,           // Constructor code
                               LPCWSTR pPinName) :     // Actual pin name

    CRendererInputPin(pRenderer,phr,pPinName),
    m_pInterfaceLock(pLock),
    m_pRenderer(pRenderer)
{
    ASSERT(m_pRenderer);
    ASSERT(m_pInterfaceLock);
    SetReconnectWhenActive(true);
}

STDMETHODIMP
CVideoInputPin::ReceiveConnection(
    IPin * pConnector,          // this is the pin who we will connect to
    const AM_MEDIA_TYPE *pmt    // this is the media type we will exchange
)
{
    CAutoLock lck(m_pLock); // This is the interface lock.

    ASSERT(pConnector);
    if(pConnector != m_Connected)
    {
        // We have a window, figure out what monitor it's on (multi-monitor)
        // NULL means we aren't running with multiple monitors
        m_pRenderer->GetCurrentMonitor();

        // Now that we know what monitor we're on, setup for using it
        m_pRenderer->m_Display.RefreshDisplayType(m_pRenderer->m_achMonitor);

        return CRendererInputPin::ReceiveConnection(pConnector, pmt);
    }

    else

    {
        CMediaType cmt(*pmt);
        HRESULT hr = CheckMediaType(&cmt);
        ASSERT(hr == S_OK);
        if(hr == S_OK)
        {
            hr =  m_pRenderer->ResetForDfc();
            if(SUCCEEDED(hr))
            {
                hr = m_pRenderer->SetMediaType(&cmt);
            }
            if(SUCCEEDED(hr))
            {
                VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();

                // Has the video size changed between connections

                if (pVideoInfo->bmiHeader.biWidth == m_pRenderer->m_VideoSize.cx &&
                    pVideoInfo->bmiHeader.biHeight == m_pRenderer->m_VideoSize.cy)
                {
                        NOTE("No size change");
                }
                else
                {
                    // Set properties for the current video
                    //
                    //
                    // !!! doesn't seem to do anything
                    //
                    //

                    m_pRenderer->m_VideoSize.cx = pVideoInfo->bmiHeader.biWidth;
                    m_pRenderer->m_VideoSize.cy = pVideoInfo->bmiHeader.biHeight;
                    m_pRenderer->m_VideoWindow.SetDefaultSourceRect();
                    m_pRenderer->m_VideoWindow.SetDefaultTargetRect();
                    m_pRenderer->m_VideoWindow.OnVideoSizeChange();
                }
            }
        }
        else
        {
            DbgBreak("??? CheckMediaType failed in dfc ReceiveConnection.");
            hr = E_UNEXPECTED;
        }

        return hr;
    }
}


// Overrides the CRendererInputPin virtual method to return our allocator
// we create to pass shared memory DIB buffers that GDI can directly access
// When NotifyAllocator is called it sets the current allocator in the base
// input pin class (m_pAllocator), this is what GetAllocator should return
// unless it is NULL in which case we return the allocator we would like

STDMETHODIMP CVideoInputPin::GetAllocator(IMemAllocator **ppAllocator)
{
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Check we don't have an overlay connection

    if (*m_pRenderer->m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("GetAllocator for overlay");
        return VFW_E_NOT_SAMPLE_CONNECTION;
    }

    // Has an allocator been set yet in the base class

    if (m_pAllocator == NULL) {
        m_pAllocator = &m_pRenderer->m_VideoAllocator;
        m_pAllocator->AddRef();
    }

    m_pAllocator->AddRef();
    *ppAllocator = m_pAllocator;
    return NOERROR;
}


// Notify us which allocator the output pin has decided that we should use
// The COM specification says any two IUnknown pointers to the same object
// should always match which provides a way for us to see if they are using
// our DIB allocator or not. Since we are only really interested in equality
// and our object always hands out the same IMemAllocator interface we can
// just see if the pointers match. If they are we set a flag in the main
// renderer as the window needs to know whether it can do fast rendering

STDMETHODIMP
CVideoInputPin::NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly)
{
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Check we don't have an overlay connection

    if (*m_pRenderer->m_mtIn.Subtype() == MEDIASUBTYPE_Overlay) {
        NOTE("NotifyAllocator on overlay");
        return VFW_E_NOT_SAMPLE_CONNECTION;
    }

    // Make sure the base class gets a look

    HRESULT hr = CRendererInputPin::NotifyAllocator(pAllocator,bReadOnly);
    if (FAILED(hr)) {
        return hr;
    }

    // Whose allocator is the source going to use

    m_pRenderer->m_DrawVideo.NotifyAllocator(FALSE);
    if (pAllocator == &m_pRenderer->m_VideoAllocator) {
        m_pRenderer->m_DrawVideo.NotifyAllocator(TRUE);
    }

    return NOERROR;
}


// Overriden to expose our IOverlay pin transport

STDMETHODIMP CVideoInputPin::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    if (riid == IID_IOverlay) {
        return m_pRenderer->m_Overlay.QueryInterface(riid,ppv);
    } else
    if (riid == IID_IPinConnection) {
        return GetInterface((IPinConnection *)this, ppv);
    } else {
        return CBaseInputPin::NonDelegatingQueryInterface(riid,ppv);
    }
}

//  Do you accept this type chane in your current state?
STDMETHODIMP CVideoInputPin::DynamicQueryAccept(const AM_MEDIA_TYPE *pmt)
{
    //return E_FAIL;
    CheckPointer(pmt, E_POINTER);

    //  BUGBUG - what locking should we do?
    CMediaType cmt(*pmt);
    HRESULT hr = m_pRenderer->CheckMediaType(&cmt);
    if (SUCCEEDED(hr) && hr != S_OK ||
        (hr == E_FAIL) ||
        (hr == E_INVALIDARG)) {
        hr = VFW_E_TYPE_NOT_ACCEPTED;
    }

    return hr;
}

//  Set event when EndOfStream receive - do NOT pass it on
//  This condition is cancelled by a flush or Stop
STDMETHODIMP CVideoInputPin::NotifyEndOfStream(HANDLE hNotifyEvent)
{
    return m_pRenderer->NotifyEndOfStream(hNotifyEvent);
}

STDMETHODIMP CVideoInputPin::DynamicDisconnect()
{
    CAutoLock cObjectLock(m_pLock);
    return CBasePin::DisconnectInternal();
}

//  Are you an 'end pin'
STDMETHODIMP CVideoInputPin::IsEndPin()
{
    return S_OK;
}

// This is overriden from the base draw class to change the source rectangle
// that we do the drawing with. For example a renderer may ask a decoder to
// stretch the video from 320x240 to 640x480, in which case the rectangle we
// see in here will still be 320x240, although the source we really want to
// draw with should be scaled up to 640x480. The base class implementation of
// this method does nothing but return the same rectangle as it is passed in

CDrawVideo::CDrawVideo(CRenderer *pRenderer,CBaseWindow *pBaseWindow) :
    CDrawImage(pBaseWindow),
    m_pRenderer(pRenderer)
{
    ASSERT(pBaseWindow);
    ASSERT(m_pRenderer);
}


// We override this from the base class to accomodate codec stretching. What
// happens is that the native video size remains constant in the m_VideoSize
// but the bitmap size changes in the actual video format. When we come to
// draw the image we must scale the logical source rectangle to account for
// the larger or smaller real bitmap (and also round against the dimensions)

RECT CDrawVideo::ScaleSourceRect(const RECT *pSource)
{
    NOTE("Entering ScaleSourceRect");
    RECT Source = *pSource;

    // Is the codec providing a stretched video format

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    if (pVideoInfo->bmiHeader.biWidth == m_pRenderer->m_VideoSize.cx) {
        if (pVideoInfo->bmiHeader.biHeight == m_pRenderer->m_VideoSize.cy) {
            NOTE("No codec stretch");
            SetStretchMode();
            return Source;
        }
    }

    // Make sure we don't round beyond the actual bitmap dimensions

    Source.left = (Source.left * pVideoInfo->bmiHeader.biWidth);
    Source.left = min((Source.left / m_pRenderer->m_VideoSize.cx),pVideoInfo->bmiHeader.biWidth);
    Source.right = (Source.right * pVideoInfo->bmiHeader.biWidth);
    Source.right = min((Source.right / m_pRenderer->m_VideoSize.cx),pVideoInfo->bmiHeader.biWidth);
    Source.top = (Source.top * pVideoInfo->bmiHeader.biHeight);
    Source.top = min((Source.top / m_pRenderer->m_VideoSize.cy),pVideoInfo->bmiHeader.biHeight);
    Source.bottom = (Source.bottom * pVideoInfo->bmiHeader.biHeight);
    Source.bottom = min((Source.bottom / m_pRenderer->m_VideoSize.cy),pVideoInfo->bmiHeader.biHeight);
    NOTERC("Scaled source",Source);

    // Calculate the stretching requirements each time through

    LONG SourceWidth = Source.right - Source.left;
    LONG SinkWidth = m_TargetRect.right - m_TargetRect.left;
    LONG SourceHeight = Source.bottom - Source.top;
    LONG SinkHeight = m_TargetRect.bottom - m_TargetRect.top;

    m_bStretch = TRUE;
    if (SourceWidth == SinkWidth) {
        if (SourceHeight == SinkHeight) {
            NOTE("No stretching");
            m_bStretch = FALSE;
        }
    }
    return Source;
}


#ifdef DEBUG

// Display a palette composed of an array of RGBQUAD structures

void CRenderer::DisplayGDIPalette(const CMediaType *pmt)
{
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) pmt->Format();
    DWORD dwColours = pVideoInfo->bmiHeader.biClrUsed;
    NOTE1("DisplayGDIPalette (%d colours)",dwColours);
    TCHAR strLine[256];

    // The number of colours may be zero to mean all available
    if (dwColours == 0) dwColours = (1 << pVideoInfo->bmiHeader.biBitCount);

    for (DWORD dwLoop = 0;dwLoop < dwColours;dwLoop++) {

        wsprintf(strLine,TEXT("%d) Red %d Green %d Blue %d"),dwLoop,
                 pVideoInfo->bmiColors[dwLoop].rgbRed,
                 pVideoInfo->bmiColors[dwLoop].rgbGreen,
                 pVideoInfo->bmiColors[dwLoop].rgbBlue);

        DbgLog((LOG_TRACE, 5, strLine));
    }
}

#endif // DEBUG


// Overriden to realise the palette before drawing. We have to do this for
// every image because Windows gets confused with us only realising on the
// window thread (there appears to be some thread specific state in GDI)
// Fortunately the realisation doesn't cause a thread switch so it should
// be relatively cheap (cheaper than sending a WM_QUERYNEWPALETTE anyway)

void CRenderer::PrepareRender()
{
    // Realise the palette on this thread
    m_VideoWindow.DoRealisePalette();

    // Calculate the top level parent window

//  HWND hwndTopLevel = hwnd;
//  while (hwnd = GetParent(hwndTopLevel)) {
//      hwndTopLevel = hwnd;
//  }
//
//  NOTE1("IsForegroundWindow %d",(GetForegroundWindow() == hwnd));
//  NOTE1("Foreground window %d",GetForegroundWindow());
//  NOTE1("Active window %d",GetActiveWindow());
//  BOOL bTopLevel = (GetForegroundWindow() == hwndTopLevel);
//  NOTE1("Foreground parent %d",bTopLevel);

}



// --------------------------------------------------------------------
//  IKsPropertySet interface methods -- mainly for MacroVision support
// --------------------------------------------------------------------

//
// Set() is supported only for _CopyProt prop set and MACROVISION id.
//
STDMETHODIMP
CRenderer::Set(
    REFGUID guidPropSet,
    DWORD dwPropID,
    LPVOID pInstanceData,
    DWORD cbInstanceLength,
    LPVOID pPropData,
    DWORD cbPropData
    )
{
    DbgLog((LOG_TRACE, 5, TEXT("CRenderer::Set()"))) ;


    if (guidPropSet == AM_KSPROPSETID_FrameStep)
    {
        if (dwPropID != AM_PROPERTY_FRAMESTEP_STEP &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANCEL &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANSTEP &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANSTEPMULTIPLE)
        {
            return E_PROP_ID_UNSUPPORTED;
        }

        switch (dwPropID) {
        case AM_PROPERTY_FRAMESTEP_STEP:
            if (cbPropData < sizeof(AM_FRAMESTEP_STEP))
            {
                return E_INVALIDARG;
            }

            if (1 != ((AM_FRAMESTEP_STEP *)pPropData)->dwFramesToStep)
            {
                return E_INVALIDARG;
            }
            else
            {
                CAutoLock cInterfaceLock(&m_InterfaceLock);
                CAutoLock cFrameStepStateLock(&m_FrameStepStateLock);

                long l = m_lFramesToStep;
                m_lFramesToStep = ((AM_FRAMESTEP_STEP *)pPropData)->dwFramesToStep;

                //
                // If we are currently blocked on the frame step event
                // release the receive thread so that we can get another
                // frame
                //

                if (l == 0) {

                    SetEvent(m_StepEvent);
                }
            }
            return S_OK;


        case AM_PROPERTY_FRAMESTEP_CANCEL:
            {
                CAutoLock cLock(&m_InterfaceLock);

                CancelStep();
            }
            return S_OK;

        case AM_PROPERTY_FRAMESTEP_CANSTEP:
            if (*m_mtIn.Subtype() != MEDIASUBTYPE_Overlay)
                return S_OK;

        case AM_PROPERTY_FRAMESTEP_CANSTEPMULTIPLE:
            return S_FALSE;
        }
    }


    if (guidPropSet != AM_KSPROPSETID_CopyProt)
        return E_PROP_SET_UNSUPPORTED ;

    if (dwPropID != AM_PROPERTY_COPY_MACROVISION)
        return E_PROP_ID_UNSUPPORTED ;

    if (pPropData == NULL)
        return E_INVALIDARG ;

    if (cbPropData < sizeof(DWORD))
        return E_INVALIDARG ;

    if (m_MacroVision.SetMacroVision(m_VideoWindow.GetWindowHWND(),
									 *((LPDWORD)pPropData)))
        return NOERROR ;
    else
        return VFW_E_COPYPROT_FAILED ;
}


//
// Get() not supported for now.
//
STDMETHODIMP
CRenderer::Get(
    REFGUID guidPropSet,
    DWORD dwPropID,
    LPVOID pInstanceData,
    DWORD cbInstanceLength,
    LPVOID pPropData,
    DWORD cbPropData,
    DWORD *pcbReturned
    )
{
    DbgLog((LOG_TRACE, 5, TEXT("CRenderer::Get()"))) ;
    return E_NOTIMPL ;
}


//
// Only supports Macrovision property -- returns S_OK for Set only.
//
STDMETHODIMP
CRenderer::QuerySupported(
    REFGUID guidPropSet,
    DWORD dwPropID,
    ULONG *pTypeSupport
    )
{
    DbgLog((LOG_TRACE, 5, TEXT("CRenderer::QuerySupported()"))) ;


    if (guidPropSet == AM_KSPROPSETID_FrameStep)
    {

        BOOL bOverlay = (*m_mtIn.Subtype() == MEDIASUBTYPE_Overlay);

        if (bOverlay) {
            return E_PROP_ID_UNSUPPORTED;
        }

        if (dwPropID != AM_PROPERTY_FRAMESTEP_STEP &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANCEL)
        {
            return E_PROP_ID_UNSUPPORTED;
        }

        if (pTypeSupport)
        {
            *pTypeSupport = KSPROPERTY_SUPPORT_SET ;
        }

        return S_OK;
    }

    if (guidPropSet != AM_KSPROPSETID_CopyProt)
        return E_PROP_SET_UNSUPPORTED ;

    if (dwPropID != AM_PROPERTY_COPY_MACROVISION)
        return E_PROP_ID_UNSUPPORTED ;

    if (pTypeSupport)
        *pTypeSupport = KSPROPERTY_SUPPORT_SET ;

    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\image.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Defines the main COM renderer object, Anthony Phillips, January 1995

#ifndef __IMAGE__
#define __IMAGE__


extern const AMOVIESETUP_FILTER sudVideoFilter;

// This class supports the renderer input pin. This class has three principle
// things to do. The first is to pass on to the main renderer object calls to
// things like CheckMediaType, and to process other calls like SetMediaType
// and CompleteConnect. It also routes calls to Receive to either the main
// object or the DirectDraw object depending what type of sample it was given
// The last thing it must also do it so handle the flushing and end of stream
// calls that the source filter makes on us, it also hands these on to the
// main object since this is where the samples are queued and then rendered

class CVideoInputPin :
    public CRendererInputPin,
    public IPinConnection
{
    CRenderer   *m_pRenderer;           // The renderer that owns us
    CBaseFilter *m_pFilter;             // The filter we are owned by
    CCritSec    *m_pInterfaceLock;      // Main renderer interface lock

public:
        DECLARE_IUNKNOWN;

    // Constructor

    CVideoInputPin(CRenderer *pRenderer,       // Used to delegate locking
                   CCritSec *pLock,            // Object to use for lock
                   HRESULT *phr,               // OLE failure return code
                   LPCWSTR pPinName);          // This pins identification

    // Overriden to say what interfaces we support and where
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void **);

    // Override ReceiveConnection to update the monitor and display info
    STDMETHODIMP ReceiveConnection(
        IPin * pConnector,      // this is the pin who we will connect to
        const AM_MEDIA_TYPE *pmt    // this is the media type we will exchange
    );

    // Manage our DirectDraw/DIB video allocator

    STDMETHODIMP GetAllocator(IMemAllocator **ppAllocator);
    STDMETHODIMP NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly);

    // Returns the pin currently connected to us
    IPin *GetPeerPin() {
        return m_Connected;
    };

    //  IPinConnection stuff
    //  Do you accept this type chane in your current state?
    STDMETHODIMP DynamicQueryAccept(const AM_MEDIA_TYPE *pmt);

    //  Set event when EndOfStream receive - do NOT pass it on
    //  This condition is cancelled by a flush or Stop
    STDMETHODIMP NotifyEndOfStream(HANDLE hNotifyEvent);

    //  Are you an 'end pin'
    STDMETHODIMP IsEndPin();

    STDMETHODIMP DynamicDisconnect();
};


// This is overriden from the base draw class to change the source rectangle
// that we do the drawing with. For example a renderer may ask a decoder to
// stretch the video from 320x240 to 640x480, in which case the rectangle we
// see in here will still be 320x240, although the source we really want to
// draw with should be scaled up to 640x480. The base class implementation of
// this method does nothing but return the same rectangle as it is passed in

class CDrawVideo : public CDrawImage
{
    CRenderer *m_pRenderer;

public:
    CDrawVideo(CRenderer *pRenderer,CBaseWindow *pBaseWindow);
    RECT ScaleSourceRect(const RECT *pSource);
};


// This is the COM object that represents a simple rendering filter. It
// supports IBaseFilter and IMediaFilter and a single input stream (pin)
// The classes that support these interfaces have nested scope NOTE the
// nested class objects are passed a pointer to their owning renderer
// when they are created but they should not use it during construction

class CRenderer :
    public ISpecifyPropertyPages,
    public CBaseVideoRenderer,
    public IKsPropertySet,
    public IDrawVideoImage
{
public:

    DECLARE_IUNKNOWN

    // Constructor and destructor

    CRenderer(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr);
    virtual ~CRenderer();
    CBasePin *GetPin(int n);

    void AutoShowWindow();
    BOOL OnPaint(BOOL bMustPaint);
    BOOL OnTimer(WPARAM wParam);
    void PrepareRender();

    STDMETHODIMP Stop();
    STDMETHODIMP Pause();
    STDMETHODIMP Run(REFERENCE_TIME StartTime);

    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void **);
    STDMETHODIMP GetPages(CAUUID *pPages);

    HRESULT CompleteConnect(IPin *pReceivePin);
    HRESULT SetMediaType(const CMediaType *pmt);
    HRESULT Receive(IMediaSample *pSample);
    HRESULT CheckMediaType(const CMediaType *pmt);
    HRESULT BreakConnect();
    HRESULT NotifyEndOfStream(HANDLE hNotifyEvent);
    HRESULT EndOfStream();
    HRESULT BeginFlush();
    HRESULT EndFlush();
    HRESULT SetOverlayMediaType(const CMediaType *pmt);
    HRESULT SetDirectMediaType(const CMediaType *pmt);
    HRESULT DoRenderSample(IMediaSample *pMediaSample);
    void OnReceiveFirstSample(IMediaSample *pMediaSample);
    HRESULT CompleteStateChange(FILTER_STATE OldState);
    HRESULT Inactive();


    BOOL LockedDDrawSampleOutstanding();
    HRESULT CheckMediaTypeWorker(const CMediaType *pmt);

    // Which monitor are we on, for a multiple monitor system?
    INT_PTR GetCurrentMonitor();

    // has our window moved at least partly onto another monitor than the one
    // we think we're on?
    // ID == 0 means it spans 2 monitors now
    // ID != 0 means it's wholly on monitor ID
    BOOL IsWindowOnWrongMonitor(INT_PTR *pID);

    HRESULT ResetForDfc();

    LONG m_fDisplayChangePosted; // don't send too many and slow performance

#ifdef DEBUG
    // Used to display debug prints of palette arrays
    void DisplayGDIPalette(const CMediaType *pmt);
#endif // DEBUG

    //
    // IKsPropertySet interface methods
    //
    STDMETHODIMP Set(REFGUID guidPropSet, DWORD PropID, LPVOID pInstanceData,
                     DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData) ;
    STDMETHODIMP Get(REFGUID guidPropSet, DWORD PropID, LPVOID pInstanceData,
                     DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData,
                     DWORD *pcbReturned) ;
    STDMETHODIMP QuerySupported(REFGUID guidPropSet, DWORD PropID, DWORD *pTypeSupport) ;

    //
    // IDrawVideoImage
    //
    STDMETHODIMP DrawVideoImageBegin();
    STDMETHODIMP DrawVideoImageEnd();
    STDMETHODIMP DrawVideoImageDraw(HDC hdc, LPRECT lprcSrc, LPRECT lprcDst);

    
    LONG GetVideoWidth();
    LONG GetVideoHeight();

public:

    // Member variables for the image renderer object. This class supports
    // a number of interfaces by delegating to member classes we initialise
    // during construction. We have a specialised input pin derived from
    // CBaseInputPin that does some extra video rendering work. The base pin
    // normally stores the media type for any given connection but we take
    // the type proposed and normalise it so that it is easier to manipulate
    // when we do type checking. This normalised type is stored in m_mtIn
    // In general the classes that do the work hold the member variables
    // that they use but this represents a useful place to put filter wide
    // information that more than one interface or nested class uses

    CDrawVideo m_DrawVideo;             // Handles drawing our images
    CImagePalette m_ImagePalette;       // Manages our window's palette
    CVideoWindow m_VideoWindow;         // Looks after a rendering window
    CVideoAllocator m_VideoAllocator;   // Our DirectDraw allocator
    COverlay m_Overlay;                 // IOverlay interface
    CVideoInputPin m_InputPin;          // IPin based interfaces
    CImageDisplay m_Display;            // Manages the video display type
    CDirectDraw m_DirectDraw;           // Handles DirectDraw surfaces
    CMediaType m_mtIn;                  // Source connection media type
    SIZE m_VideoSize;                   // Size of current video stream
    RECT m_rcMonitor;                   // rect of current monitor
    int m_nNumMonitors;                 // rect of current monitor
    char m_achMonitor[CCHDEVICENAME];   // device name of current monitor
    INT_PTR m_nMonitor;                 // unique int for each monitor
    HANDLE  m_hEndOfStream;

    CRendererMacroVision m_MacroVision ; // MacroVision implementation object

    //
    // Frame Step stuff
    //
    CCritSec    m_FrameStepStateLock;   // This lock protects m_lFramesToStep.  It should 
                                        // always be held when the program accesses 
                                        // m_lFramesToStep.  The program should not send 
                                        // windows messages, wait for events or attempt to 
                                        // acquire other locks while it is holding this lock.
    HANDLE      m_StepEvent;
    LONG        m_lFramesToStep;        // -ve (-1)  == normal playback
                                        // +ve (>=0) == frames to skips
    void        FrameStep();
    void        CancelStep();
    bool        IsFrameStepEnabled();

};

inline LONG CRenderer::GetVideoWidth()
{
    // The m_VideoSize is only valid if the input pin is connected.
    ASSERT(m_pInputPin->IsConnected());

    return m_VideoSize.cx;
}

inline LONG CRenderer::GetVideoHeight()
{
    // The m_VideoSize is only valid if the input pin is connected.
    ASSERT(m_pInputPin->IsConnected());

    // The height can be negative if the Video Renderer is using 
    // the top-down DIB format.
    return abs(m_VideoSize.cy);
}

#endif // __IMAGE__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\vrmacvis.cpp ===
// Copyright (c) 1997 - 1999  Microsoft Corporation.  All Rights Reserved.
//
// VRMacVis.cpp:  Video Renderer's Macrovision support code
//

#include <streams.h>
#include <windowsx.h>

#include <atlconv.h>
#include "render.h"
#include "MultMon.h"  // our version of multimon.h include ChangeDisplaySettingsEx

CRendererMacroVision::CRendererMacroVision(void)
{
    DbgLog((LOG_TRACE, 5, TEXT("CRendererMacroVision::CRendererMacroVision()"))) ;
    m_dwCPKey = 0 ;
    m_hWndCP  = NULL ;
    m_hMon    = NULL ;
}


CRendererMacroVision::~CRendererMacroVision(void)
{
    DbgLog((LOG_TRACE, 5, TEXT("CRendererMacroVision::~CRendererMacroVision()"))) ;
    ASSERT(0 == m_dwCPKey  &&  NULL == m_hWndCP  &&  NULL == m_hMon) ;
}


BOOL
CRendererMacroVision::StopMacroVision(HWND hWnd)
{
    DbgLog((LOG_TRACE, 5, TEXT("CRendererMacroVision::StopMacroVision(0x%p)"),
            (void *) hWnd)) ;

    if (0 == m_dwCPKey)
    {
        DbgLog((LOG_TRACE, 3, TEXT("Copy prot key was not acquired. Nothing to release."))) ;
        return TRUE ;  // success, what else?
    }

    if (NULL == m_hWndCP)
    {
        DbgLog((LOG_ERROR, 0, TEXT("WARNING: No hWnd available while MV bit was already set."))) ;
        return TRUE ;  // FALSE??
    }

    LONG             lRet ;
    VIDEOPARAMETERS  VidParams ;
    DEVMODEA         DevMode ;
    DISPLAY_DEVICE   dd ;
    ZeroMemory(&dd, sizeof(dd)) ;
    dd.cb = sizeof(dd) ;

    // If we have come here then Macrovision is ON, and that means we must have
    // a valid monitor handle.  Let's use that rather than finding it via
    // MonitorFromWindow() call, which seems to fail at this stage (specially
    // when the player app is closed).
    ASSERT(m_hMon) ;
    HMONITOR hMon = m_hMon ;
    if (NULL == hMon)
    {
        DbgLog((LOG_ERROR, 0, TEXT("Cached monitor handle is NULL!!!"))) ;
        return FALSE ;
    }

    MONITORINFOEX  mi ;
    mi.cbSize = sizeof(mi) ;
    if (! GetMonitorInfo(hMon, &mi) )
    {
        DbgLog((LOG_ERROR, 0, TEXT("GetMonitorInfo() failed (Error: %ld)"),
                GetLastError())) ;
        return FALSE ;
    }
    DbgLog((LOG_TRACE, 3, TEXT("DeviceName: '%s'"), mi.szDevice)) ;
    ZeroMemory(&DevMode, sizeof(DevMode)) ;
    DevMode.dmSize = sizeof(DevMode) ;

    ZeroMemory(&VidParams, sizeof(VidParams)) ;
    VidParams.Guid      = guidVidParam ;
    VidParams.dwCommand = VP_COMMAND_GET ;

    USES_CONVERSION;
    lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                   CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                   &VidParams) ;
    if (DISP_CHANGE_SUCCESSFUL != lRet)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ChangeDisplaySettingsEx(_GET) failed (%ld)"), lRet)) ;
        return FALSE ;
    }

    if (! ( (VidParams.dwFlags & VP_FLAGS_COPYPROTECT) &&
            (VidParams.dwCPType & VP_CP_TYPE_APS_TRIGGER) &&
            (VidParams.dwTVStandard & VidParams.dwCPStandard) ) )
    {
        // How did we acquire CP key in teh first place?
        DbgLog((LOG_ERROR, 0,
            TEXT("Copy prot weird error case (dwFlags=0x%lx, dwCPType=0x%lx, dwTVStandard=0x%lx, dwCPStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwCPType, VidParams.dwTVStandard, VidParams.dwCPStandard)) ;
        return FALSE ;
    }

    VidParams.dwCommand    = VP_COMMAND_SET ;
    VidParams.dwFlags      = VP_FLAGS_COPYPROTECT ;
    VidParams.dwCPType     = VP_CP_TYPE_APS_TRIGGER ;
    VidParams.dwCPCommand  = VP_CP_CMD_DEACTIVATE ;
    VidParams.dwCPKey      = m_dwCPKey ;
    VidParams.bCP_APSTriggerBits = (BYTE) 0 ;  // some value
    lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                   CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                   &VidParams) ;
    if (DISP_CHANGE_SUCCESSFUL != lRet)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ChangeDisplaySettingsEx() failed (%ld)"), lRet)) ;
        return FALSE ;
    }

    DbgLog((LOG_TRACE, 1, TEXT("Macrovision deactivated on key %lu"), m_dwCPKey)) ;
    m_dwCPKey = 0 ;     // no CP set now
    m_hWndCP  = NULL ;  // don't need hWnd anymore
    m_hMon    = NULL ;  // don't need hMon anymore

    return TRUE ;
}


//
// This function applies Macrovision based on the input parameter dwCPBits.
// hWnd is the handle of the window in which content is played back.
//
// Returns TRUE on success and FALSE on any failure.
//
BOOL
CRendererMacroVision::SetMacroVision(HWND hWnd, DWORD dwCPBits)
{
    DbgLog((LOG_TRACE, 5, TEXT("CRendererMacroVision::SetMacroVision(0x%p, 0x%lx)"),
            (void*) hWnd, dwCPBits)) ;

    //
    // If MV is currently not set at all and the new CP bits is 0 (which happens
    // when from the Nav we reset the MV bits on start / stop of playback), we
    // don't really need to do anything -- MV not started and doesn't need to be
    // started.  So just leave queitly...
    //
    if (0 == m_dwCPKey  &&  // no key acquired so far
        0 == dwCPBits)      // MV CPBits is 0
    {
        DbgLog((LOG_TRACE, 1, TEXT("Copy prot is not enabled now and new CP bits is 0 -- so skip it."))) ;
        return TRUE ;  // we don't need to do anything, so success.
    }

    //
    // May be we need to actually do something here
    //
    LONG             lRet ;
    VIDEOPARAMETERS  VidParams ;
    DEVMODEA         DevMode ;
    DISPLAY_DEVICE   dd ;
    ZeroMemory(&dd, sizeof(dd)) ;
    dd.cb = sizeof(dd) ;

    HMONITOR hMon = MonitorFromWindow(hWnd, MONITOR_DEFAULTTONULL) ;
    if (NULL == hMon)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("MonitorFromWindow(0x%p, ..) returned NULL (Error: %ld)"),
                (void*)hWnd, GetLastError())) ;
        return FALSE ;
    }

    MONITORINFOEX  mi ;
    mi.cbSize = sizeof(mi) ;
    if (! GetMonitorInfo(hMon, &mi) )
    {
        DbgLog((LOG_ERROR, 0, TEXT("GetMonitorInfo() failed (Error: %ld)"),
                GetLastError())) ;
        return FALSE ;
    }
    DbgLog((LOG_TRACE, 3, TEXT("DeviceName: '%s'"), mi.szDevice)) ;

    ZeroMemory(&DevMode, sizeof(DevMode)) ;
    DevMode.dmSize = sizeof(DevMode) ;

    ZeroMemory(&VidParams, sizeof(VidParams)) ;
    VidParams.Guid      = guidVidParam ;
    VidParams.dwCommand = VP_COMMAND_GET ;

    USES_CONVERSION;
    lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                   CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                   &VidParams) ;
    if (DISP_CHANGE_SUCCESSFUL != lRet)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ChangeDisplaySettingsEx(_GET) failed (%ld)"), lRet)) ;
        return FALSE ;
    }

    if (0 == VidParams.dwFlags ||
        VP_TV_STANDARD_WIN_VGA == VidParams.dwTVStandard)
    {
        DbgLog((LOG_TRACE, 1, TEXT("** Copy protection NOT required (dwFlags=0x%lx, dwTVStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwTVStandard));
        return TRUE ;
    }

    //
    // Check to see if
    // a) the device supports copy prot
    // b) CP type is APS trigger
    // c) current TV standard and CP standard have commonality.
    // If so, apply copy prot. Otherwise error.
    //
    if ( (VidParams.dwFlags & VP_FLAGS_COPYPROTECT) &&
         (VidParams.dwCPType & VP_CP_TYPE_APS_TRIGGER) &&
         (VidParams.dwTVStandard & VidParams.dwCPStandard) )
    {
        DbgLog((LOG_TRACE, 3,
            TEXT("** Copy prot needs to be applied (dwFlags=0x%lx, dwCPType=0x%lx, dwTVStandard=0x%lx, dwCPStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwCPType, VidParams.dwTVStandard, VidParams.dwCPStandard)) ;

        VidParams.dwCommand = VP_COMMAND_SET ;          // do we have to set it again??
        VidParams.dwFlags   = VP_FLAGS_COPYPROTECT ;
        VidParams.dwCPType  = VP_CP_TYPE_APS_TRIGGER ;
        VidParams.bCP_APSTriggerBits = (BYTE) (dwCPBits & 0xFF) ;

        // Check if we already have a copy prot key; if not, get one now
        if (0 == m_dwCPKey)  // no key acquired so far
        {
            // Acquire a new key (that also aplies it, so no separate Set reqd)
            VidParams.dwCPCommand = VP_CP_CMD_ACTIVATE ;
            VidParams.dwCPKey     = 0 ;
            lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                           CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                           &VidParams) ;
            if (DISP_CHANGE_SUCCESSFUL != lRet)
            {
                DbgLog((LOG_ERROR, 0,
                    TEXT("** ChangeDisplaySettingsEx() failed (%ld) to activate copy prot"), lRet)) ;
                return FALSE ;
            }

            m_dwCPKey = VidParams.dwCPKey ;
            DbgLog((LOG_TRACE, 3, TEXT("** Copy prot activated. Key value is %lu"), m_dwCPKey)) ;
        }
        else  // key already acquired
        {
            // apply the copy prot bits specified in the content
            VidParams.dwCPCommand = VP_CP_CMD_CHANGE ;
            VidParams.dwCPKey     = m_dwCPKey ;
            DbgLog((LOG_TRACE, 5, TEXT("** Going to call ChangeDisplaySettingsEx(_SET)..."))) ;
            lRet = ChangeDisplaySettingsExA(T2A(mi.szDevice), &DevMode, NULL,
                                           CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                           &VidParams) ;
            if (DISP_CHANGE_SUCCESSFUL != lRet)
            {
                DbgLog((LOG_ERROR, 0,
                    TEXT("** ChangeDisplaySettingsEx() failed (%ld) to set copy prot bits (%lu)"),
                    lRet, dwCPBits)) ;
                return FALSE ;
            }
            else
                DbgLog((LOG_TRACE, 3, TEXT("** Copy prot bits (0x%lx) applied"), dwCPBits)) ;
        }
    }
    else
    {
        DbgLog((LOG_ERROR, 0,
            TEXT("** Copy prot error case (dwFlags=0x%lx, dwCPType=0x%lx, dwTVStandard=0x%lx, dwCPStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwCPType, VidParams.dwTVStandard, VidParams.dwCPStandard)) ;
        return FALSE ;
    }

    m_hWndCP = hWnd ;  // latest hWnd on which MV bit was set
    m_hMon   = hMon ;  // latest hMon on which MV bit was set

    return TRUE ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\hook.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements global message hooking, Anthony Phillips, April 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>

// We keep in shared memory a list of overlay windows who want to be informed
// of events that effect their clipping rectangles. For each window handle we
// also keep a flag that says whether the position is in use or not, this is
// actually required to ensure multi processor safe exclusion to any given
// array position. The array is opened and initialised if need be in shared
// memory when the DLL gets attached to each process (ie DllMain gets called
// with a DLL_PROCESS_ATTACH and likewise with a DLL_PROCESS_DETACH message)

HANDLE g_hVideoMemory = NULL;
VIDEOMEMORY *g_pVideoMemory = NULL;

// This is called when we see WM_WINDOWPOSCHANGING messages for any window in
// the system. We use these as a way of detecting clip changes and freeze all
// video renderers until we subsequently receive a WM_EXITSIZEMOVE or one of
// the WM_WINDOWPOSCHANGED messages. We cannot be more selective about which
// windows are to be frozen as the rectangles sent to us are often confusing

void OnWindowPosChanging(CWPSTRUCT *pMessage)
{
    WINDOWPOS *pwp = (WINDOWPOS *) pMessage->lParam;

    // This combination gets sent during window creation
    if (pwp->flags == (SWP_NOACTIVATE | SWP_NOREDRAW | SWP_NOZORDER)) {
        OnWindowCompletion(pMessage->hwnd); return;
    }

    NOTE1("Hooked WM_WINDOWPOSCHANGING Flags %d",pwp->flags);

    // Cycle through the windows affected by our change

    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++) {

        HWND hwnd = g_pVideoMemory->VideoWindow[Pos];
        if (hwnd == NULL) {
            continue;
        }

        SendMessage(hwnd,WM_FREEZE,0,0);

        // Handle atomic Z order changes in Windows
        if (pwp->flags == (SWP_NOSIZE | SWP_NOMOVE)) {
            InvalidateRect(hwnd,NULL,TRUE);
        }
    }
}


// This is called when either we receive a WM_WINDOWPOSCHANGED message or a
// WM_EXITSIZEMOVE both of which cause us to scan the list of overlay windows
// and thaw out all windows immediately. We would like to be more selective
// but the parameters to WM_WINDOWPOSCHANGING are not exact enough to be able
// to do this. So we freeze at the start and thaw at the end of each change

void OnWindowCompletion(HWND hCurrent)
{
    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++) {

        // Read the next window handle from the shared array

        HWND hwnd = g_pVideoMemory->VideoWindow[Pos];
        if (hwnd == NULL) {
            continue;
        }
        SendMessage(hwnd,WM_THAW,0,0);
    }
}


// Handles the WM_WINDOWPOSCHANGED message

void OnWindowPosChanged(CWPSTRUCT *pMessage)
{
    OnWindowCompletion(pMessage->hwnd);
}


// Handles the WM_EXITSIZEMOVE message

void OnExitSizeMove(CWPSTRUCT *pMessage)
{
    OnWindowCompletion(pMessage->hwnd);
}


// When we install a system wide hook procedure this DLL will be mapped into
// EVERY process space in the system that has one or more window threads, we
// will be called when any of those threads retrieves a message from the
// queues. What we do is filter out those messages that effect the clipping
// information of the overlay windows and send them messages to freeze (and
// thaw as is appropriate) their video while windows are changing position

LRESULT CALLBACK GlobalHookProc(INT nCode,
                                WPARAM wParam,
                                LPARAM lParam)
{
    CWPSTRUCT *pMessage = (CWPSTRUCT *) lParam;
    if (g_pVideoMemory == NULL) {
        return FALSE;
    }

    switch (pMessage->message) {

        case WM_EXITSIZEMOVE:
            OnExitSizeMove(pMessage);
            break;

        case WM_WINDOWPOSCHANGED:
            OnWindowPosChanged(pMessage);
            break;

        case WM_WINDOWPOSCHANGING:
            OnWindowPosChanging(pMessage);
            break;
    }
    return FALSE;
}


// When we start an overlay session we must add our window handle to the list
// held in global memory so that we receive and updates that might effect our
// clipping list. To do this we scan through the list looking for a position
// that is not currently used, this can be done in a multi processor safe way
// without using a global critical section by calling InterlockedExchange

HHOOK InstallGlobalHook(HWND hwnd)
{
    ASSERT(hwnd);

    // Before hooking add our window to the global array

    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++) {

        LONG Usage = InterlockedExchange(&g_pVideoMemory->WindowInUse[Pos],TRUE);

        if (Usage == FALSE) {
            ASSERT(g_pVideoMemory->VideoWindow[Pos] == NULL);
            g_pVideoMemory->VideoWindow[Pos] = hwnd;
            break;
        }
    }

    // Did we find a space in the array

    if (Pos == MAX_OVERLAYS) {
        return NULL;
    }

    // Start hooking messages for the entire system, this causes the renderer
    // DLL to be mapped into every process that has one or more windows and
    // will be called whenever a window thread tries to retrieve a message

    return SetWindowsHookEx(WH_CALLWNDPROC,   // Type of message hook
                            GlobalHookProc,   // Global hook procedure
                            g_hInst,          // Module instance handle
                            (DWORD) 0);       // Global message hook
}


// When we want to remove our window from the hooking process we must scan the
// list for our handle. It is possible that someone else on a different thread
// or more likely a different processor can change the window handle while we
// are inspecting it. This isn't critical as none of the values we will ever
// actually see will match the system wide unique window handle we maintain

HRESULT RemoveGlobalHook(HWND hwnd,HHOOK hHook)
{
    // Is this a real window hook

    if (hHook == NULL) {
        return NOERROR;
    }

    // Before unhooking remove our window from the global array

    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++) {
        if (g_pVideoMemory->VideoWindow[Pos] == hwnd) {
            g_pVideoMemory->VideoWindow[Pos] = NULL;
            InterlockedExchange(&g_pVideoMemory->WindowInUse[Pos],FALSE);
            break;
        }
    }

    UnhookWindowsHookEx(hHook);
    return NOERROR;
}


// Called when the DLL that we're built in (either IMAGE.DLL or the overall
// QUARTZ.DLL for the main SDK runtimes) gets loaded into a process. We take
// this opportunity to create or delete the shared memory block that we use
// for interprocess communication. The block of memory is used in two ways,
// firstly to hold a list of video windows that want to be informed of clip
// changes in the system. Secondly it is used so that DirectDraw overlays
// can each allocate and use different colour keys to maintain Z ordering

void OnProcessAttachment(BOOL bLoading,const CLSID *rclsid)
{
    // Create/open the video mutex object

    HANDLE VideoMutex = CreateMutex(NULL,FALSE,WindowClassName);
    if (VideoMutex == NULL) {
        return;
    }

    WaitForSingleObject(VideoMutex,INFINITE);

    if (bLoading == TRUE) {
        OnProcessAttach();
    } else {
        OnProcessDetach();
    }

    EXECUTE_ASSERT(ReleaseMutex(VideoMutex));
    EXECUTE_ASSERT(CloseHandle(VideoMutex));
}


// Called when the DLL is detached from a process. We can't be sure that the
// process completed the attach so the state variables may or may not be set
// correctly. Furthermore just to be on the safe side we grab ownership of
// the video mutex so that we can ensure serialisation of the attachments

void OnProcessDetach()
{
    // Release the shared memory resources

    if (g_pVideoMemory) {
        UnmapViewOfFile((PVOID)g_pVideoMemory);
        g_pVideoMemory = NULL;
    }
    if (g_hVideoMemory) {
        CloseHandle(g_hVideoMemory);
        g_hVideoMemory = NULL;
    }
}


// Called when this DLL is attached to another process. We open a mutex so we
// can synchronise with other processes asking for immediate ownership of it.
// We can then map the shared memory block into our process and if we created
// the block (ie the first people in) then we also initialise it with zeroes.
// All that's then left to do is release and close the video mutex handle

void OnProcessAttach()
{
    // Create a named shared memory block

    /// !!! fails if a service is using quartz. might have been useful
    g_hVideoMemory = CreateFileMapping(hMEMORY,              // Memory block
                                       NULL,                 // Security flags
                                       PAGE_READWRITE,       // Page protection
                                       (DWORD) 0,            // High size
                                       sizeof(VIDEOMEMORY),  // Low order size
                                       TEXT("VIDEOMEMORY")); // Mapping name

    // We must now map the shared memory block into this process address space
    // The CreateFileMapping call sets the last thread error code to zero if
    // we actually created the memory block, if someone else got in first and
    // created it GetLastError returns ERROR_ALREADY_EXISTS. We are ensured
    // that nobody can get to the uninitialised memory block because we use
    // a cross process mutex critical section. The mutex is also used by the
    // window object (we use the same name) to synchronise window creation

    DWORD Status = GetLastError();

    if (g_hVideoMemory) {

        g_pVideoMemory = (VIDEOMEMORY *) MapViewOfFile(g_hVideoMemory,
                                                       FILE_MAP_ALL_ACCESS,
                                                       (DWORD) 0,
                                                       (DWORD) 0,
                                                       (DWORD) 0);
        if (g_pVideoMemory) {
            if (Status == ERROR_SUCCESS) {
                ZeroMemory((PVOID)g_pVideoMemory,sizeof(VIDEOMEMORY));
            }
        }
    }
}


// As described earlier the video renderer opens a shared memory block for a
// global hook procedure code to use. And since the hook is the main user of
// the memory block it is created and destroyed in this module. The block is
// however useful for other interprocess communication. In particular when we
// are using overlays in different processes we really want them to allocate
// different colour keys to maintain Z ordering when they overlay. For this
// reason we have a function that gets the next colour from the memory. The
// colour is one of either magenta (the default), green, red, cyan or yellow
// if we are on a palettised display or a shade of black if on a true colour

COLORREF KeyColours[] = {
    RGB(255,0,255),  RGB(16,0,16),      // Magenta
    RGB(0,255,0),    RGB(0,16,0),       // Green
    RGB(255,0,0),    RGB(16,0,0),       // Red
    RGB(0,255,255),  RGB(0,16,16),      // Cyan
    RGB(255,255,0),  RGB(16,16,0)       // Yellow
};

// use the monitor/device given
HRESULT GetNextOverlayCookie(LPSTR szDevice, LONG* plNextCookie)
{
    // The caller should pass in a valid pointer.
    ASSERT(NULL != plNextCookie);
    ValidateReadWritePtr(plNextCookie, sizeof(LONG));

    // Make sure the caller does not use a random value.
    *plNextCookie = INVALID_COOKIE_VALUE;

    LONG lMinUsedCookie = 0, lMinUsage = 1000;

    NOTE("Returning next available key colour");

    // Create/open the video mutex object

    if(g_pVideoMemory == 0) {
        NOTE("No shared memory");
        return E_FAIL;
    }

    HANDLE VideoMutex = CreateMutex(NULL,FALSE,WindowClassName);
    if (VideoMutex == NULL) {
        NOTE("No video mutex");
        return E_FAIL;
    }

    WaitForSingleObject(VideoMutex,INFINITE);

    // Now we have an exclusive lock allocate the next cookie
    for (LONG Pos = 0;Pos < MAX_OVERLAYS;Pos++)
    {
        if (g_pVideoMemory->OverlayCookieUsage[Pos] < lMinUsage)
        {
            lMinUsage = g_pVideoMemory->OverlayCookieUsage[Pos];
            lMinUsedCookie = Pos;
        }
    }
    g_pVideoMemory->OverlayCookieUsage[lMinUsedCookie]++;

    // Store our cookie value before unlocking

    EXECUTE_ASSERT(ReleaseMutex(VideoMutex));
    EXECUTE_ASSERT(CloseHandle(VideoMutex));

    // Valid cookie values are between 0 and (MAX_OVERLAYS - 1).
    ASSERT((0 <= lMinUsedCookie) && (lMinUsedCookie < MAX_OVERLAYS));

    *plNextCookie = lMinUsedCookie;

    return S_OK;
}

void RemoveCurrentCookie(LONG lCurrentCookie)
{
    // Valid cookie values are between 0 and (MAX_OVERLAYS - 1).
    ASSERT(lCurrentCookie >= 0 && lCurrentCookie < MAX_OVERLAYS);

    if (NULL != g_pVideoMemory) {
        ASSERT(g_pVideoMemory->OverlayCookieUsage[lCurrentCookie] > 0);
        InterlockedDecrement(&g_pVideoMemory->OverlayCookieUsage[lCurrentCookie]);
    }
}

COLORREF GetColourFromCookie(LPSTR szDevice, LONG lCookie)
{
    // Valid cookie values are between 0 and (MAX_OVERLAYS - 1).
    ASSERT((0 <= lCookie) && (lCookie < MAX_OVERLAYS));

    // get a DC for the monitor we care about
    DbgLog((LOG_TRACE,3,TEXT("Overlay CKey getting DC for device %s"), szDevice));
    HDC hdcScreen;
    if (szDevice == NULL || lstrcmpiA(szDevice, "DISPLAY") == 0)
        hdcScreen = CreateDCA("DISPLAY", NULL, NULL, NULL);
    else
        hdcScreen = CreateDCA(NULL, szDevice, NULL, NULL);
    if ( ! hdcScreen )
        return 0;

    // Are we in a palettised display device mode?
    INT Type = GetDeviceCaps(hdcScreen,RASTERCAPS);
    Type = (Type & RC_PALETTE ? 0 : 1);
    DeleteDC(hdcScreen);

    DWORD KeyColoursIndex = (lCookie << 1) + Type;

    // Make sure the index is valid.
    ASSERT(KeyColoursIndex < NUMELMS(KeyColours));

    return KeyColours[KeyColoursIndex];
}

// The overlay transport also uses the shared memory segment to allocate its
// colour keys. However when it is running on a palettised display it needs
// the actual palette index for any given RGB colour it is allocated. So it
// calls this method with a previously allocated colour to get an index. The
// entries in the index must equate with the entries in the RGB colour table

DWORD KeyIndex[] = { 253, 250, 249, 254, 251 };

DWORD GetPaletteIndex(COLORREF Colour)
{
    NOTE("Searching for palette index");
    for (int Count = 0;Count < MAX_OVERLAYS;Count++) {
        if (KeyColours[Count << 1] == Colour) {
            NOTE1("Index %d",Count);
            return KeyIndex[Count];
        }
    }
    return 0;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\vidprop\viddbg.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved
// Define some common video debug macros, Anthony Phillips, May 1995

#ifndef __VIDDBG__
#define __VIDDBG__

#ifdef __VIDFLTR__

#undef NOTE
#undef NOTE1
#undef NOTE2
#undef NOTE3
#undef NOTE4
#undef NOTE5

#define NOTE(_x_)             DbgLog((LOG_TRACE,0,TEXT(_x_)));
#define NOTE1(_x_,a)          DbgLog((LOG_TRACE,0,TEXT(_x_),a));
#define NOTE2(_x_,a,b)        DbgLog((LOG_TRACE,0,TEXT(_x_),a,b));
#define NOTE3(_x_,a,b,c)      DbgLog((LOG_TRACE,0,TEXT(_x_),a,b,c));
#define NOTE4(_x_,a,b,c,d)    DbgLog((LOG_TRACE,0,TEXT(_x_),a,b,c,d));
#define NOTE5(_x_,a,b,c,d,e)  DbgLog((LOG_TRACE,0,TEXT(_x_),a,b,c,d,e));

#endif // __VIDFLTR__

#define NOTERC(info,rc)                  \
    NOTE1("(%s rectangle)",TEXT(info));  \
    NOTE1("  Left %d",rc.left);          \
    NOTE1("  Top %d",rc.top);            \
    NOTE1("  Right %d",rc.right);        \
    NOTE1("  Bottom %d",rc.bottom);      \

#endif // __VIDDBG__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\vrmacvis.h ===
// Copyright (c) 1997 - 1998  Microsoft Corporation.  All Rights Reserved.
//
// VRMacVis.h: Video Renderer's MacroVision support code header
//

#ifndef __VRMACVIS_H__
#define __VRMACVIS_H__


//
// The magic GUID for Macrovision etc enabling (from winuser.h). It has 
// not been given a name there and so is used here directly.
//
static const GUID guidVidParam = 
    {0x2c62061, 0x1097, 0x11d1, {0x92, 0xf, 0x0, 0xa0, 0x24, 0xdf, 0x15, 0x6e}} ;

//
// Combination of all the VP_TV_XXX flags (w/o _WIN_VGA) gives 0x7FFF
//
#define ValidTVStandard(dw)  (dw & 0x7FFF)

//
// MacroVision implementation wrapped in a class for Video Renderer
//
class CRendererMacroVision {

    public:
        CRendererMacroVision(void) ;
        ~CRendererMacroVision(void) ;

        BOOL  SetMacroVision(HWND hWnd, DWORD dwCPBits) ;
        BOOL  StopMacroVision(HWND hWnd) ;
        HWND  GetCPHWND(void)   { return m_hWndCP ; }

    private:
        DWORD  m_dwCPKey ;
        HWND   m_hWndCP ;
        HMONITOR m_hMon ;
} ;

#endif // __VRMACVIS_H__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\vidprop\vidprop.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Video renderer property pages, Anthony Phillips, January 1996

#ifndef __VIDPROP__
#define __VIDPROP__

#define IDS_VID1     201        // Format Selection
#define IDS_VID2     202        // Invalid clip percentage
#define IDS_VID3     203        // Non RGB FOURCC codes supported
#define IDS_VID4     204        // No FOURCC codes available
#define IDS_VID5     205        // Total video memory
#define IDS_VID6     206        // Free video memory
#define IDS_VID7     207        // Max number of visible overlays
#define IDS_VID8     208        // Current number of visible overlays
#define IDS_VID9     209        // Number of FOURCC codes
#define IDS_VID10    210        // Source rectangle alignment
#define IDS_VID11    211        // Source rectangle byte size
#define IDS_VID12    212        // Destination rectangle alignment
#define IDS_VID13    213        // Destination rectangle size
#define IDS_VID14    214        // Stride alignment
#define IDS_VID15    215        // Min overlay stretch factor
#define IDS_VID16    216        // Max overlay stretch factor
#define IDS_VID17    217        // Min live video stretch factor
#define IDS_VID18    218        // Max live video stretch factor
#define IDS_VID19    219        // Min hardware codec stretch factor
#define IDS_VID20    220        // Max hardware codec stretch factor
#define IDS_VID21    221        // 1 bit per pixel
#define IDS_VID22    222        // 2 bits per pixel
#define IDS_VID23    223        // 4 bits per pixel
#define IDS_VID24    224        // 8 bits per pixel
#define IDS_VID25    225        // 16 bits per pixel
#define IDS_VID26    226        // 32 bits per pixel
#define IDS_VID27    227        // Switches may not take effect
#define IDS_VID28    228        // (Surface capabilities)
#define IDS_VID29    229        // (Emulation capabilities)
#define IDS_VID30    230        // (Hardware capabilities)
#define IDS_VID31    231        // Disconnected
#define IDS_VID32    232        // DCI primary surface
#define IDS_VID33    233        // Switch Setting Status
#define IDS_VID34    234        // FullScreen Video Renderer

#define IDS_VID50    250        // DirectDraw
#define IDS_VID51    251        // Display Modes
#define IDS_VID52    252        // Quality
#define IDS_VID53    253        // Performance

#define LoadVideoString(x) StringFromResource(m_Resource,x)
extern const TCHAR TypeFace[];  // = TEXT("TERMINAL");
extern const TCHAR FontSize[];  // = TEXT("8");
extern const TCHAR ListBox[];   // = TEXT("listbox");

// Property page built on top of the IDirectDrawVideo interface

#define IDD_VIDEO               100     // Dialog box resource identifier
#define DD_DCIPS                101     // Enable DCI primary surface
#define DD_PS                   102     // DirectDraw primary surface
#define DD_RGBOVR               103     // Enable RGB overlays
#define DD_YUVOVR               104     // NON RGB (eg YUV) overlays
#define DD_RGBOFF               105     // RGB offscreen surfaces
#define DD_YUVOFF               106     // NON RGB (eg YUV) offscreen
#define DD_RGBFLP               107     // RGB flipping surfaces
#define DD_YUVFLP               108     // Likewise YUV flipping surfaces
#define FIRST_DD_BUTTON         101     // First DirectDraw check button
#define LAST_DD_BUTTON          108     // Last DirectDraw check button
#define DD_HARDWARE             109     // DirectDraw hardware description
#define DD_SOFTWARE             110     // Emulated software capabilities
#define DD_SURFACE              111     // Current surface information
#define DD_LIST                 112     // Listbox containing details

class CVideoProperties : public CBasePropertyPage
{
    IDirectDrawVideo *m_pDirectDrawVideo; // Interface held on renderer
    TCHAR m_Resource[STR_MAX_LENGTH];     // Loads international strings
    HFONT m_hFont;                        // Special smaller listbox font
    HWND m_hwndList;                      // Custom list box control
    DWORD m_Switches;                     // DirectDraw switches enabled

    // Display the DirectDraw capabilities

    void DisplayBitDepths(DWORD dwCaps);
    void DisplayCapabilities(DDCAPS *pCaps);
    void DisplaySurfaceCapabilities(DDSCAPS ddsCaps);
    void DisplayFourCCCodes();
    void UpdateListBox(DWORD Id);
    void SetDrawSwitches();
    void GetDrawSwitches();
    INT GetHeightFromPointsString(LPCTSTR szPoints);

public:

    CVideoProperties(LPUNKNOWN lpUnk,HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);

    INT_PTR OnReceiveMessage(HWND hwnd,UINT uMsg,WPARAM wParam,LPARAM lParam);
    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
    HRESULT OnDeactivate();
    HRESULT OnApplyChanges();
};


// Property page built from a renderer IQualProp interface

#define IDD_QUALITY             150     // Dialog resource
#define IDD_Q1                  151     // Frames played
#define IDD_Q2                  152     // Frames dropped
#define IDD_Q4                  154     // Frame rate
#define IDD_Q5                  155     // Frame jitter
#define IDD_Q6                  156     // Sync offset
#define IDD_Q7                  157     // Sync deviation
#define FIRST_Q_BUTTON          171     // First button
#define LAST_Q_BUTTON           177     // Last button
#define IDD_QDRAWN              171     // Frames played
#define IDD_QDROPPED            172     // Frames dropped
#define IDD_QAVGFRM             174     // Average frame rate achieved
#define IDD_QJITTER             175     // Average frame jitter
#define IDD_QSYNCAVG            176     // Average sync offset
#define IDD_QSYNCDEV            177     // Std dev sync offset

class CQualityProperties : public CBasePropertyPage
{
    IQualProp *m_pQualProp;         // Interface held on the renderer
    int m_iDropped;                 // Number of frames dropped
    int m_iDrawn;                   // Count of images drawn
    int m_iSyncAvg;                 // Average sync value
    int m_iSyncDev;                 // And standard deviation
    int m_iFrameRate;               // Total frame rate average
    int m_iFrameJitter;             // Measure of frame jitter

    static BOOL CALLBACK QualityDialogProc(HWND hwnd,
                                           UINT uMsg,
                                           WPARAM wParam,
                                           LPARAM lParam);
    void SetEditFieldData();
    void DisplayStatistics(void);

public:

    CQualityProperties(LPUNKNOWN lpUnk, HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);

    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
};


// Property page to allow customisation of performance properties

#define IDD_PERFORMANCE         200     // Property dialog resource
#define IDD_SCANLINE            201     // Honour the scan line
#define IDD_OVERLAY             202     // Use overlay limitations
#define IDD_FULLSCREEN          203     // Use when made fullscreen

class CPerformanceProperties : public CBasePropertyPage
{
    IDirectDrawVideo *m_pDirectDrawVideo; 	// Interface held on renderer
    LONG m_WillUseFullScreen;                   // Use when made fullscreen
    LONG m_CanUseScanLine;               	// Can honour the scan line
    LONG m_CanUseOverlayStretch;                // Use overlay stretching

public:

    CPerformanceProperties(LPUNKNOWN lpUnk,HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);

    INT_PTR OnReceiveMessage(HWND hcwnd,UINT uMsg,WPARAM wParam,LPARAM lParam);
    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
    HRESULT OnApplyChanges();
};


// Property page allowing selection of preferred display modes

#define IDD_MODEX               500     // Dialog box resource identifier
#define MODEX_CHOSEN_TEXT       501     // Static description for chosen
#define MODEX_CHOSEN_EDIT       502     // Non editable display string
#define MODEX_CLIP_TEXT         503     // Static description for clip
#define MODEX_CLIP_EDIT         504     // Non editable display string
#define FIRST_MODEX_BUTTON      501     // First actual property button
#define LAST_MODEX_BUTTON       540     // And last available display mode
#define FIRST_MODEX_MODE        510     // First available mode check box
#define FIRST_MODEX_TEXT        511     // First static text description
#define MODEX_320x200x16        510     // Not sure if this is available
#define MODEX_320x200x8         512     // Palettised bottom most mode
#define MODEX_320x240x16        514     // Modex and also as a normal mode
#define MODEX_320x240x8         516     // Can get this both as a true
#define MODEX_640x400x16        518     // 640x400 modes with flipping
#define MODEX_640x400x8         520     // Can still get the 640x480 and
#define MODEX_640x480x16        522     // a lot more hardware bandwidth
#define MODEX_640x480x8         524     // surfaces although they use up
#define MODEX_800x600x16        526     // normal ddraw mode
#define MODEX_800x600x8         528     // normal ddraw mode
#define MODEX_1024x768x16       530     // normal ddraw mode
#define MODEX_1024x768x8        532     // normal ddraw mode
#define MODEX_1152x864x16       534     // normal ddraw mode
#define MODEX_1152x864x8        536     // normal ddraw mode
#define MODEX_1280x1024x16      538     // normal ddraw mode
#define MODEX_1280x1024x8       540     // normal ddraw mode


#define MAXMODES                 16     // Number of modes supported
#define CLIPFACTOR               25     // Initial default clip factor
#define MONITOR                   0     // Default to the primary display

class CModexProperties : public CBasePropertyPage
{
    IFullScreenVideo *m_pModexVideo;      // Renderer handling interface
    TCHAR m_Resource[STR_MAX_LENGTH];     // Loads international strings
    LONG m_CurrentMode;                   // Current display mode chosen
    LONG m_ClipFactor;                    // Allowed clip percentage
    BOOL m_bAvailableModes[MAXMODES];     // List of mode availability
    BOOL m_bEnabledModes[MAXMODES];       // And whether they're enabled
    BOOL m_bInActivation;                 // Are we currently activating

public:

    CModexProperties(LPUNKNOWN lpUnk,HRESULT *phr);
    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);
    INT_PTR OnReceiveMessage(HWND hwnd,UINT uMsg,WPARAM wParam,LPARAM lParam);

    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
    HRESULT OnApplyChanges();
    HRESULT UpdateVariables();
    HRESULT LoadProperties();
    HRESULT DisplayProperties();
    HRESULT SaveProperties();
};

#endif // __VIDPROP__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\vidprop\vidprop.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Video renderer property pages, Anthony Phillips, January 1996

#include <streams.h>
#include "vidprop.h"
#include <tchar.h>

// This class implements a property page for the video renderers. It uses the
// IDirectDrawVideo control interface exposed by the video renderer. Through
// this interface we can enable and disable specific DCI/DirectDraw features
// such as the use of overlay and offscreen surfaces. It also gives access
// to the capabilities of the DirectDraw provider. This can be used by the
// application if it wants to make sure the video window is aligned so that
// we can use overlay surfaces (for example). It also provides information
// so that it could find out we have a YUV offscreen surface available that
// can convert to RGB16 for example in which case it may want to change the
// display mode before we start running. We are handed an IUnknown interface
// pointer to the video renderer through the SetObjects interface function

const TCHAR TypeFace[]      = TEXT("TERMINAL");
const TCHAR FontSize[]      = TEXT("8");
const TCHAR ListBox[]       = TEXT("listbox");


// Constructor

CVideoProperties::CVideoProperties(LPUNKNOWN pUnk,HRESULT *phr) :
    CBasePropertyPage(NAME("Video Page"),pUnk,IDD_VIDEO,IDS_VID50),
    m_hwndList(NULL),
    m_hFont(NULL),
    m_pDirectDrawVideo(NULL),
    m_Switches(AMDDS_NONE)
{
    ASSERT(phr);
}


// Create a video properties object

CUnknown *CVideoProperties::CreateInstance(LPUNKNOWN lpUnk,HRESULT *phr)
{
    return new CVideoProperties(lpUnk,phr);
}


// Update the dialog box property page with the current settings

void CVideoProperties::SetDrawSwitches()
{
    Button_SetCheck(GetDlgItem(m_Dlg,DD_DCIPS),(m_Switches & AMDDS_DCIPS ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_PS),(m_Switches & AMDDS_PS ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_RGBOVR),(m_Switches & AMDDS_RGBOVR ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_YUVOVR),(m_Switches & AMDDS_YUVOVR ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_RGBOFF),(m_Switches & AMDDS_RGBOFF ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_YUVOFF),(m_Switches & AMDDS_YUVOFF ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_RGBFLP),(m_Switches & AMDDS_RGBFLP ? TRUE : FALSE));
    Button_SetCheck(GetDlgItem(m_Dlg,DD_YUVFLP),(m_Switches & AMDDS_YUVFLP ? TRUE : FALSE));
}


// Update the renderer with the current dialog box property page settings

#define GETSWITCH(x,flag,sw) {if (x == TRUE) sw |= flag;}

void CVideoProperties::GetDrawSwitches()
{
    m_Switches = AMDDS_NONE;

    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_DCIPS)),AMDDS_DCIPS,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_PS)),AMDDS_PS,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_RGBOVR)),AMDDS_RGBOVR,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_YUVOVR)),AMDDS_YUVOVR,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_RGBOFF)),AMDDS_RGBOFF,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_YUVOFF)),AMDDS_YUVOFF,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_RGBFLP)),AMDDS_RGBFLP,m_Switches);
    GETSWITCH(Button_GetCheck(GetDlgItem(m_Dlg,DD_YUVFLP)),AMDDS_YUVFLP,m_Switches);
}


// Update the contents of the list box

void CVideoProperties::UpdateListBox(DWORD Id)
{
    DDSURFACEDESC SurfaceDesc;
    HRESULT hr = NOERROR;
    DDCAPS DirectCaps;

    ListBox_ResetContent(m_hwndList);

    // Do they want to see the hardware capabilities

    if (Id == DD_HARDWARE) {
        hr = m_pDirectDrawVideo->GetCaps(&DirectCaps);
        ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID30));
        if (hr == NOERROR) {
            DisplayCapabilities(&DirectCaps);
        }
    }

    // Are they after the software emulation capabilities

    if (Id == DD_SOFTWARE) {
        hr = m_pDirectDrawVideo->GetEmulatedCaps(&DirectCaps);
        ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID29));
        if (hr == NOERROR) {
            DisplayCapabilities(&DirectCaps);
        }
    }

    // Finally is it the surface information they want

    if (Id == DD_SURFACE) {
        hr = m_pDirectDrawVideo->GetSurfaceDesc(&SurfaceDesc);
        ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID28));
        if (hr == S_FALSE) {
            ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID32));
        } else if (hr == NOERROR) {
            DisplaySurfaceCapabilities(SurfaceDesc.ddsCaps);
        }
    }
}


// Handles the messages for our property window

INT_PTR CVideoProperties::OnReceiveMessage(HWND hwnd,
                                        UINT uMsg,
                                        WPARAM wParam,
                                        LPARAM lParam)
{
    switch (uMsg) {

        case WM_INITDIALOG:

            m_hwndList = GetDlgItem(hwnd,DD_LIST);
            return (LRESULT) 1;

        case WM_COMMAND:

            // User changed capabilities list box

            switch (LOWORD(wParam)) {
                case DD_SOFTWARE:
                case DD_HARDWARE:
                case DD_SURFACE:
                    UpdateListBox(LOWORD(wParam));
                    return (LRESULT) 0;
            }

            // Has the user clicked on one of the check boxes

            if (LOWORD(wParam) >= FIRST_DD_BUTTON) {
                if (LOWORD(wParam) <= LAST_DD_BUTTON) {
                    m_bDirty = TRUE;
                    GetDrawSwitches();
                    if (m_pPageSite) {
                        m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
                    }
                }
            }
            return (LRESULT) 1;
    }
    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


// Tells us the object that should be informed of the property changes

HRESULT CVideoProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pDirectDrawVideo == NULL);

    // Ask the renderer for it's IDirectDrawVideo control interface

    HRESULT hr = pUnknown->QueryInterface(IID_IDirectDrawVideo,(void **) &m_pDirectDrawVideo);
    if (FAILED(hr)) {
        return E_NOINTERFACE;
    }

    ASSERT(m_pDirectDrawVideo);
    m_pDirectDrawVideo->GetSwitches(&m_Switches);
    return NOERROR;
}


// Release any IDirectDrawVideo interface we have

HRESULT CVideoProperties::OnDisconnect()
{
    // Release the interface

    if (m_pDirectDrawVideo == NULL) {
        return E_UNEXPECTED;
    }

    m_pDirectDrawVideo->Release();
    m_pDirectDrawVideo = NULL;
    return NOERROR;
}


// Create the window we will use to edit properties

HRESULT CVideoProperties::OnActivate()
{
    // Create a small font for the capabilities - that is LOCALIZABLE

    NONCLIENTMETRICS ncm;
    ncm.cbSize = sizeof(NONCLIENTMETRICS);
    SystemParametersInfo(SPI_GETNONCLIENTMETRICS, sizeof(ncm), &ncm, 0);
    m_hFont = CreateFontIndirect(&ncm.lfStatusFont);

    Button_SetCheck(GetDlgItem(m_Dlg,DD_HARDWARE),TRUE);
    SetWindowFont(m_hwndList,m_hFont,TRUE);
    UpdateListBox(DD_HARDWARE);
    SetDrawSwitches();
    return NOERROR;
}


// Return the height this point size

INT CVideoProperties::GetHeightFromPointsString(LPCTSTR szPoints)
{
    HDC hdc;
    INT height;

    hdc = GetDC(NULL);
    if ( hdc )
        height = GetDeviceCaps(hdc, LOGPIXELSY );
    else
        height = 72;
    height = MulDiv(-_ttoi(szPoints), height, 72);
    if ( hdc )
        ReleaseDC(NULL, hdc);

    return height;
}


// Destroy the property page dialog

HRESULT CVideoProperties::OnDeactivate(void)
{
    DeleteObject(m_hFont);
    return NOERROR;
}


// Apply any changes so far made

HRESULT CVideoProperties::OnApplyChanges()
{
    TCHAR szExtra[STR_MAX_LENGTH];
    ASSERT(m_pDirectDrawVideo);
    ASSERT(m_pPageSite);

    // Apply the changes to the video renderer

    if (m_pDirectDrawVideo->SetSwitches(m_Switches) == S_FALSE) {
        MessageBox(m_hwnd,StringFromResource(szExtra,IDS_VID27),
                   LoadVideoString(IDS_VID33),
                   MB_OK | MB_ICONEXCLAMATION | MB_APPLMODAL);
    }
    return m_pDirectDrawVideo->SetDefault();
}


// For a variety of capabilities the driver can nominate certain bit depths as
// restrictions or capabilities, these may be so, for example, because it can
// handle only certain video memory bandwidths (all the bit fields have BBDB_
// prefixing them) In other situations this field can hold the real bit depth
// as an integer value such as when we create a DirectDraw primary surface

void CVideoProperties::DisplayBitDepths(DWORD dwCaps)
{
    if (dwCaps & DDBD_1) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID21));
    if (dwCaps & DDBD_2) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID22));
    if (dwCaps & DDBD_4) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID23));
    if (dwCaps & DDBD_8) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID24));
    if (dwCaps & DDBD_16) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID25));
    if (dwCaps & DDBD_32) ListBox_AddString(m_hwndList,LoadVideoString(IDS_VID26));
}


// The DDCAPS field contains all the capabilities of the driver and in general
// the surfaces it can provide although these may not be available when you
// come to request them. The capabilities are all defined through sets of bit
// fields, split into general driver, colour keys, special effects, palette,
// and stereo vision. Each set of capabilities also has specific bit depth
// restrictions assigned to it. Finally there are a bunch of miscellaneous
// capabilities and informational fields like the video memory on the card

void CVideoProperties::DisplayCapabilities(DDCAPS *pCaps)
{
    TCHAR String[PROFILESTR];

    // Deal with the driver specific capabilities

    if (pCaps->dwCaps & DDCAPS_3D) ListBox_AddString(m_hwndList,TEXT("DDCAPS_3D"));
    if (pCaps->dwCaps & DDCAPS_ALIGNBOUNDARYDEST) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNBOUNDARYDEST"));
    if (pCaps->dwCaps & DDCAPS_ALIGNSIZEDEST) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNSIZEDEST"));
    if (pCaps->dwCaps & DDCAPS_ALIGNBOUNDARYSRC) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNBOUNDARYSRC"));
    if (pCaps->dwCaps & DDCAPS_ALIGNSIZESRC) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNSIZESRC"));
    if (pCaps->dwCaps & DDCAPS_ALIGNSTRIDE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALIGNSTRIDE"));
    if (pCaps->dwCaps & DDCAPS_BANKSWITCHED) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BANKSWITCHED"));
    if (pCaps->dwCaps & DDCAPS_BLT) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLT"));
    if (pCaps->dwCaps & DDCAPS_BLTCOLORFILL) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTCOLORFILL"));
    if (pCaps->dwCaps & DDCAPS_BLTQUEUE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTQUEUE"));
    if (pCaps->dwCaps & DDCAPS_BLTFOURCC) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTFOURCC"));
    if (pCaps->dwCaps & DDCAPS_BLTSTRETCH) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTSTRETCH"));
    if (pCaps->dwCaps & DDCAPS_GDI) ListBox_AddString(m_hwndList,TEXT("DDCAPS_GDI"));
    if (pCaps->dwCaps & DDCAPS_OVERLAY) ListBox_AddString(m_hwndList,TEXT("DDCAPS_OVERLAY"));
    if (pCaps->dwCaps & DDCAPS_OVERLAYCANTCLIP) ListBox_AddString(m_hwndList,TEXT("DDCAPS_OVERLAYCANTCLIP"));
    if (pCaps->dwCaps & DDCAPS_OVERLAYFOURCC) ListBox_AddString(m_hwndList,TEXT("DDCAPS_OVERLAYFOURCC"));
    if (pCaps->dwCaps & DDCAPS_OVERLAYSTRETCH) ListBox_AddString(m_hwndList,TEXT("DDCAPS_OVERLAYSTRETCH"));
    if (pCaps->dwCaps & DDCAPS_PALETTE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_PALETTE"));
    if (pCaps->dwCaps & DDCAPS_READSCANLINE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_READSCANLINE"));
//    if (pCaps->dwCaps & DDCAPS_STEREOVIEW) ListBox_AddString(m_hwndList,TEXT("DDCAPS_STEREOVIEW"));
    if (pCaps->dwCaps & DDCAPS_VBI) ListBox_AddString(m_hwndList,TEXT("DDCAPS_VBI"));
    if (pCaps->dwCaps & DDCAPS_ZBLTS) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ZBLTS"));
    if (pCaps->dwCaps & DDCAPS_ZOVERLAYS) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ZOVERLAYS"));
    if (pCaps->dwCaps & DDCAPS_COLORKEY) ListBox_AddString(m_hwndList,TEXT("DDCAPS_COLORKEY"));
    if (pCaps->dwCaps & DDCAPS_ALPHA) ListBox_AddString(m_hwndList,TEXT("DDCAPS_ALPHA"));
    if (pCaps->dwCaps & DDCAPS_NOHARDWARE) ListBox_AddString(m_hwndList,TEXT("DDCAPS_NOHARDWARE"));
    if (pCaps->dwCaps & DDCAPS_BLTDEPTHFILL) ListBox_AddString(m_hwndList,TEXT("DDCAPS_BLTDEPTHFILL"));
    if (pCaps->dwCaps & DDCAPS_CANCLIP) ListBox_AddString(m_hwndList,TEXT("DDCAPS_CANCLIP"));
    if (pCaps->dwCaps & DDCAPS_CANCLIPSTRETCHED) ListBox_AddString(m_hwndList,TEXT("DDCAPS_CANCLIPSTRETCHED"));
    if (pCaps->dwCaps & DDCAPS_CANBLTSYSMEM) ListBox_AddString(m_hwndList,TEXT("DDCAPS_CANBLTSYSMEM"));

    // Have a wee peek at the colour key capabilities

    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTBLT) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTBLT"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTBLTCLRSPACE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTBLTCLRSPACE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTBLTCLRSPACEYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTBLTCLRSPACEYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTBLTYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTBLTYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAY) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAY"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAYCLRSPACE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAYCLRSPACE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAYCLRSPACEYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAYCLRSPACEYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAYONEACTIVE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAYONEACTIVE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_DESTOVERLAYYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_DESTOVERLAYYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCBLT) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCBLT"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCBLTCLRSPACE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCBLTCLRSPACE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCBLTCLRSPACEYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCBLTCLRSPACEYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCBLTYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCBLTYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAY) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAY"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAYCLRSPACE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAYCLRSPACE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAYCLRSPACEYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAYCLRSPACEYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAYONEACTIVE) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAYONEACTIVE"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_SRCOVERLAYYUV) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_SRCOVERLAYYUV"));
    if (pCaps->dwCKeyCaps & DDCKEYCAPS_NOCOSTOVERLAY) ListBox_AddString(m_hwndList,TEXT("DDCKEYCAPS_NOCOSTOVERLAY"));

    // Driver specific effects and stretching capabilities

    if (pCaps->dwFXCaps & DDFXCAPS_BLTARITHSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTARITHSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTARITHSTRETCHYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTARITHSTRETCHYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTMIRRORLEFTRIGHT) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTMIRRORLEFTRIGHT"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTMIRRORUPDOWN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTMIRRORUPDOWN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTROTATION) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTROTATION"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTROTATION90) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTROTATION90"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSHRINKX) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSHRINKX"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSHRINKXN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSHRINKXN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSHRINKY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSHRINKY"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSHRINKYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSHRINKYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSTRETCHX) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSTRETCHX"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSTRETCHXN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSTRETCHXN"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_BLTSTRETCHYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTSTRETCHYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYARITHSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYARITHSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYARITHSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYARITHSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSHRINKX) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSHRINKX"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSHRINKXN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSHRINKXN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSHRINKY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSHRINKY"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSHRINKYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSHRINKYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSTRETCHX) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSTRETCHX"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSTRETCHXN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSTRETCHXN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSTRETCHY) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSTRETCHY"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYSTRETCHYN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYSTRETCHYN"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYMIRRORLEFTRIGHT) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYMIRRORLEFTRIGHT"));
    if (pCaps->dwFXCaps & DDFXCAPS_OVERLAYMIRRORUPDOWN) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYMIRRORUPDOWN"));

    // Alpha channel driver specific capabilities

    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHAEDGEBLEND) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHAEDGEBLEND"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHAPIXELS) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHAPIXELS"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHAPIXELSNEG) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHAPIXELSNEG"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHASURFACES) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHASURFACES"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_BLTALPHASURFACESNEG) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_BLTALPHASURFACESNEG"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHAEDGEBLEND) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHAEDGEBLEND"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHAPIXELS) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHAPIXELS"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHAPIXELSNEG) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHAPIXELSNEG"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHASURFACES) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHASURFACES"));
    if (pCaps->dwFXAlphaCaps & DDFXALPHACAPS_OVERLAYALPHASURFACESNEG) ListBox_AddString(m_hwndList,TEXT("DDFXCAPS_OVERLAYALPHASURFACESNEG"));

    // Palette capabilities

    if (pCaps->dwPalCaps & DDPCAPS_4BIT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_4BIT"));
    if (pCaps->dwPalCaps & DDPCAPS_8BITENTRIES) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_8BITENTRIES"));
    if (pCaps->dwPalCaps & DDPCAPS_8BIT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_8BIT"));
    if (pCaps->dwPalCaps & DDPCAPS_INITIALIZE) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_INITIALIZE"));
    if (pCaps->dwPalCaps & DDPCAPS_PRIMARYSURFACE) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_PRIMARYSURFACE"));
//    if (pCaps->dwPalCaps & DDPCAPS_PRIMARYSURFACELEFT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_PRIMARYSURFACELEFT"));
    if (pCaps->dwPalCaps & DDPCAPS_VSYNC) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_VSYNC"));
    if (pCaps->dwPalCaps & DDPCAPS_1BIT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_1BIT"));
    if (pCaps->dwPalCaps & DDPCAPS_2BIT) ListBox_AddString(m_hwndList,TEXT("DDPCAPS_2BIT"));

    // Stereo vision capabilities (very useful for video)

//    if (pCaps->dwSVCaps & DDSVCAPS_ENIGMA) ListBox_AddString(m_hwndList,TEXT("DDSVCAPS_ENIGMA"));
//    if (pCaps->dwSVCaps & DDSVCAPS_FLICKER) ListBox_AddString(m_hwndList,TEXT("DDSVCAPS_FLICKER"));
//    if (pCaps->dwSVCaps & DDSVCAPS_REDBLUE) ListBox_AddString(m_hwndList,TEXT("DDSVCAPS_REDBLUE"));
//    if (pCaps->dwSVCaps & DDSVCAPS_SPLIT) ListBox_AddString(m_hwndList,TEXT("DDSVCAPS_SPLIT"));

    // Show bit depth restrictions and limitations

    ListBox_AddString(m_hwndList,TEXT("dwAlphaBltConstBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaBltConstBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaBltPixelBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaBltPixelBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaBltSurfaceBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaBltSurfaceBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaOverlayConstBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaOverlayConstBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaOverlayPixelBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaOverlayPixelBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwAlphaOverlaySurfaceBitDepths"));
    DisplayBitDepths(pCaps->dwAlphaOverlaySurfaceBitDepths);
    ListBox_AddString(m_hwndList,TEXT("dwZBufferBitDepths"));
    DisplayBitDepths(pCaps->dwZBufferBitDepths);

    // And a bunch of other random guff

    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID5),pCaps->dwVidMemTotal);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID6),pCaps->dwVidMemFree);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID7),pCaps->dwMaxVisibleOverlays);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID8),pCaps->dwCurrVisibleOverlays);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID9),pCaps->dwNumFourCCCodes);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID10),pCaps->dwAlignBoundarySrc);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID11),pCaps->dwAlignSizeSrc);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID12),pCaps->dwAlignBoundaryDest);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID13),pCaps->dwAlignSizeDest);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID14),pCaps->dwAlignStrideAlign);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID15),pCaps->dwMinOverlayStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID16),pCaps->dwMaxOverlayStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID17),pCaps->dwMinLiveVideoStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID18),pCaps->dwMaxLiveVideoStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID19),pCaps->dwMinHwCodecStretch);
    ListBox_AddString(m_hwndList,String);
    wsprintf(String,TEXT("%s %d"),LoadVideoString(IDS_VID20),pCaps->dwMaxHwCodecStretch);
    ListBox_AddString(m_hwndList,String);

    DisplayFourCCCodes();
}


// Display the non RGB surfaces they support

void CVideoProperties::DisplayFourCCCodes()
{
    TCHAR String[PROFILESTR];
    HRESULT hr = NOERROR;
    DWORD *pArray;
    DWORD Codes;

    // Find out how many codes there are

    hr = m_pDirectDrawVideo->GetFourCCCodes(&Codes,NULL);
    if (FAILED(hr)) {
        wsprintf(String,LoadVideoString(IDS_VID4));
        ListBox_AddString(m_hwndList,String);
        return;
    }

    // Show how many FOURCC codes we have

    wsprintf(String,TEXT("%s (%d)"),LoadVideoString(IDS_VID3),Codes);
    ListBox_AddString(m_hwndList,String);
    NOTE1("Display cards supports %d FOURCCs",Codes);

    // Does it support any codes

    if (Codes == 0) {
        return;
    }

    // Allocate some memory for the codes

    pArray = new DWORD[Codes];
    if (pArray == NULL) {
        return;
    }

    m_pDirectDrawVideo->GetFourCCCodes(&Codes,pArray);

    // Dump each of the codes in turn

    DWORD szFcc[2];         // null terminated fcc
    szFcc[1] = 0;
    for (DWORD Loop = 0;Loop < Codes;Loop++) {
        szFcc[0] = pArray[Loop];
        wsprintf(String,TEXT(" %d %4.4hs"),Loop+1,szFcc);
        ListBox_AddString(m_hwndList,String);
    }
    delete[] pArray;
}


// These describe the surface capabilities available

void CVideoProperties::DisplaySurfaceCapabilities(DDSCAPS ddsCaps)
{
    if (ddsCaps.dwCaps & DDSCAPS_ALPHA) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_ALPHA"));
    if (ddsCaps.dwCaps & DDSCAPS_BACKBUFFER) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_BACKBUFFER"));
    if (ddsCaps.dwCaps & DDSCAPS_COMPLEX) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_COMPLEX"));
    if (ddsCaps.dwCaps & DDSCAPS_FLIP) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_FLIP"));
    if (ddsCaps.dwCaps & DDSCAPS_FRONTBUFFER) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_FRONTBUFFER"));
    if (ddsCaps.dwCaps & DDSCAPS_OFFSCREENPLAIN) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_OFFSCREENPLAIN"));
    if (ddsCaps.dwCaps & DDSCAPS_OVERLAY) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_OVERLAY"));
    if (ddsCaps.dwCaps & DDSCAPS_PALETTE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_PALETTE"));
    if (ddsCaps.dwCaps & DDSCAPS_PRIMARYSURFACE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_PRIMARYSURFACE"));
//    if (ddsCaps.dwCaps & DDSCAPS_PRIMARYSURFACELEFT) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_PRIMARYSURFACELEFT"));
    if (ddsCaps.dwCaps & DDSCAPS_SYSTEMMEMORY) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_SYSTEMMEMORY"));
    if (ddsCaps.dwCaps & DDSCAPS_TEXTURE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_TEXTURE"));
    if (ddsCaps.dwCaps & DDSCAPS_3DDEVICE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_3DDEVICE"));
    if (ddsCaps.dwCaps & DDSCAPS_VIDEOMEMORY) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_VIDEOMEMORY"));
    if (ddsCaps.dwCaps & DDSCAPS_VISIBLE) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_VISIBLE"));
    if (ddsCaps.dwCaps & DDSCAPS_WRITEONLY) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_WRITEONLY"));
    if (ddsCaps.dwCaps & DDSCAPS_ZBUFFER) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_ZBUFFER"));
    if (ddsCaps.dwCaps & DDSCAPS_OWNDC) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_OWNDC"));
    if (ddsCaps.dwCaps & DDSCAPS_LIVEVIDEO) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_LIVEVIDEO"));
    if (ddsCaps.dwCaps & DDSCAPS_HWCODEC) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_HWCODEC"));
    if (ddsCaps.dwCaps & DDSCAPS_MODEX) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_MODEX"));
    if (ddsCaps.dwCaps & DDSCAPS_MIPMAP) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_MIPMAP"));
    if (ddsCaps.dwCaps & DDSCAPS_ALLOCONLOAD) ListBox_AddString(m_hwndList,TEXT("DDSCAPS_ALLOCONLOAD"));
}


// This class implements a property page dialog for the video renderer. We
// expose certain statistics from the quality management implementation. In
// particular we have two edit fields that show the number of frames we have
// actually drawn and the number of frames that we dropped. The number of
// frames we dropped does NOT represent the total number dropped in any play
// back sequence (as expressed through MCI status frames skipped) since the
// quality management protocol may have negotiated with the source filter for
// it to send fewer frames in the first place. Dropping frames in the source
// filter is nearly always a more efficient mechanism when we are flooded


// Constructor

CQualityProperties::CQualityProperties(LPUNKNOWN pUnk,HRESULT *phr) :
    CBasePropertyPage(NAME("Quality Page"),pUnk,IDD_QUALITY,IDS_VID52),
    m_pQualProp(NULL)
{
    ASSERT(phr);
}


// Create a quality properties object

CUnknown *CQualityProperties::CreateInstance(LPUNKNOWN lpUnk, HRESULT *phr)
{
    return new CQualityProperties(lpUnk, phr);
}


// Give us the filter to communicate with

HRESULT CQualityProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pQualProp == NULL);

    // Ask the renderer for it's IQualProp interface

    HRESULT hr = pUnknown->QueryInterface(IID_IQualProp,(void **)&m_pQualProp);
    if (FAILED(hr)) {
        return E_NOINTERFACE;
    }

    ASSERT(m_pQualProp);

    // Get quality data for our page

    m_pQualProp->get_FramesDroppedInRenderer(&m_iDropped);
    m_pQualProp->get_FramesDrawn(&m_iDrawn);
    m_pQualProp->get_AvgFrameRate(&m_iFrameRate);
    m_pQualProp->get_Jitter(&m_iFrameJitter);
    m_pQualProp->get_AvgSyncOffset(&m_iSyncAvg);
    m_pQualProp->get_DevSyncOffset(&m_iSyncDev);
    return NOERROR;
}


// Release any IQualProp interface we have

HRESULT CQualityProperties::OnDisconnect()
{
    // Release the interface

    if (m_pQualProp == NULL) {
        return E_UNEXPECTED;
    }

    m_pQualProp->Release();
    m_pQualProp = NULL;
    return NOERROR;
}


// Set the text fields in the property page

HRESULT CQualityProperties::OnActivate()
{
    SetEditFieldData();
    return NOERROR;
}


// Initialise the property page fields

void CQualityProperties::SetEditFieldData()
{
    ASSERT(m_pQualProp);
    TCHAR buffer[50];

    wsprintf(buffer,TEXT("%d"), m_iDropped);
    SendDlgItemMessage(m_Dlg, IDD_QDROPPED, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d"), m_iDrawn);
    SendDlgItemMessage(m_Dlg, IDD_QDRAWN, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d.%02d"), m_iFrameRate/100, m_iFrameRate%100);
    SendDlgItemMessage(m_Dlg, IDD_QAVGFRM, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d"), m_iFrameJitter);
    SendDlgItemMessage(m_Dlg, IDD_QJITTER, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d"), m_iSyncAvg);
    SendDlgItemMessage(m_Dlg, IDD_QSYNCAVG, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
    wsprintf(buffer,TEXT("%d"), m_iSyncDev);
    SendDlgItemMessage(m_Dlg, IDD_QSYNCDEV, WM_SETTEXT, 0, (LPARAM) (LPSTR) buffer);
}


// We allow users to customise how the video filter optimises its performance
// This comes down to three difference options. The first is whether or not we
// use the current scan line before drawing offscreen surfaces, if we do then
// we will reduce tearing but at the cost of frame throughput. The second one
// is whether we honour the minimum and maximum overlay stretch limits. Some
// drivers still look ok even when we apparently violate the restrictions. The
// final property is whether we should always use the renderer window when we
// are made fullscreen - in which case we can guarantee the video will stretch
// fullscreen rather than perhaps being placed in the centre of the display if
// the fullscreen renderer couldn't get anyone (ie source filters) to stretch


// Constructor

CPerformanceProperties::CPerformanceProperties(LPUNKNOWN pUnk,HRESULT *phr) :
    CBasePropertyPage(NAME("Performance Page"),pUnk,IDD_PERFORMANCE,IDS_VID53),
    m_pDirectDrawVideo(NULL),
    m_WillUseFullScreen(OAFALSE),
    m_CanUseScanLine(OATRUE),
    m_CanUseOverlayStretch(OATRUE)
{
    ASSERT(phr);
}


// Create a quality properties object

CUnknown *CPerformanceProperties::CreateInstance(LPUNKNOWN lpUnk, HRESULT *phr)
{
    return new CPerformanceProperties(lpUnk, phr);
}


// Give us the filter to communicate with

HRESULT CPerformanceProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pDirectDrawVideo == NULL);

    // Ask the renderer for it's IDirectDrawVideo control interface

    HRESULT hr = pUnknown->QueryInterface(IID_IDirectDrawVideo,(void **) &m_pDirectDrawVideo);
    if (FAILED(hr)) {
        return E_NOINTERFACE;
    }

    ASSERT(m_pDirectDrawVideo);

    // Get performance properties for our page

    m_pDirectDrawVideo->CanUseScanLine(&m_CanUseScanLine);
    m_pDirectDrawVideo->CanUseOverlayStretch(&m_CanUseOverlayStretch);
    m_pDirectDrawVideo->WillUseFullScreen(&m_WillUseFullScreen);
    return NOERROR;
}


// Release any IQualProp interface we have

HRESULT CPerformanceProperties::OnDisconnect()
{
    // Release the interface

    if (m_pDirectDrawVideo == NULL) {
        return E_UNEXPECTED;
    }

    m_pDirectDrawVideo->Release();
    m_pDirectDrawVideo = NULL;
    return NOERROR;
}


// Set the check box fields in the property page

HRESULT CPerformanceProperties::OnActivate()
{
    BOOL bSetCheck = (m_CanUseScanLine == OATRUE ? TRUE : FALSE);
    Button_SetCheck(GetDlgItem(m_Dlg,IDD_SCANLINE),bSetCheck);
    bSetCheck = (m_CanUseOverlayStretch == OATRUE ? TRUE : FALSE);
    Button_SetCheck(GetDlgItem(m_Dlg,IDD_OVERLAY),bSetCheck);
    bSetCheck = (m_WillUseFullScreen == OATRUE ? TRUE : FALSE);
    Button_SetCheck(GetDlgItem(m_Dlg,IDD_FULLSCREEN),bSetCheck);

    return NOERROR;
}


// Apply any changes so far made

HRESULT CPerformanceProperties::OnApplyChanges()
{
    TCHAR m_Resource[STR_MAX_LENGTH];
    TCHAR szExtra[STR_MAX_LENGTH];
    ASSERT(m_pDirectDrawVideo);
    ASSERT(m_pPageSite);

    // Set the OLE automation compatible properties

    m_pDirectDrawVideo->UseScanLine(m_CanUseScanLine);
    m_pDirectDrawVideo->UseOverlayStretch(m_CanUseOverlayStretch);
    m_pDirectDrawVideo->UseWhenFullScreen(m_WillUseFullScreen);

    MessageBox(m_hwnd,StringFromResource(szExtra,IDS_VID27),
               LoadVideoString(IDS_VID33),
               MB_OK | MB_ICONEXCLAMATION | MB_APPLMODAL);

    return m_pDirectDrawVideo->SetDefault();
}


// Handles the messages for our property window

INT_PTR CPerformanceProperties::OnReceiveMessage(HWND hwnd,
                                              UINT uMsg,
                                              WPARAM wParam,
                                              LPARAM lParam)
{
    switch (uMsg) {

        case WM_COMMAND:

            // Has the user clicked on one of the check boxes

            if (LOWORD(wParam) >= IDD_SCANLINE) {
                if (LOWORD(wParam) <= IDD_FULLSCREEN) {
                    m_bDirty = TRUE;
                    if (m_pPageSite) {
                        m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
                    }
                    HWND hDlg = GetDlgItem(hwnd,IDD_SCANLINE);
                    m_CanUseScanLine = (Button_GetCheck(hDlg) ? OATRUE : OAFALSE);
                    hDlg = GetDlgItem(hwnd,IDD_OVERLAY);
                    m_CanUseOverlayStretch = (Button_GetCheck(hDlg) ? OATRUE : OAFALSE);
                    hDlg = GetDlgItem(hwnd,IDD_FULLSCREEN);
                    m_WillUseFullScreen = (Button_GetCheck(hDlg) ? OATRUE : OAFALSE);

                }
            }
            return (LRESULT) 1;
    }
    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\window.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Implements the CVideoWindow class, Anthony Phillips, January 1995

#include <streams.h>
#include <windowsx.h>
#include <render.h>
#include <limits.h>
#include <measure.h>
#include <mmsystem.h>
#include <dvdmedia.h> // VIDEOINFO2

//  When we are constructed we create a window and a separate thread to look
//  after it. We also create two device contexts for the window, one for the
//  window client area and another compatible with this for offscreen drawing.
//  Only source formats that match the display device format will be accepted,
//  other formats have to be converted through colour transformation filters.
//  The only exception to this being true colour devices which will normally
//  handle four and eight bit palettised images very efficiently.
//
//  When a connection has been made the output pin may ask us for an allocator
//  We provide an allocator that gives out one or more memory buffers that are
//  shared with GDI. These are created through CreateDIBSection. That requires
//  us to give it the connected source media type format BITMAPINFO structure.
//
//  When we come to rendering the images we have two separate code paths, one
//  for samples allocated with our shared memory allocator and another for the
//  normal memory buffers. As it turns out the shared memory allocator does
//  only marginally faster. However our memory allocator can also return DCI
//  and DirectDraw surfaces which can be drawn by display card hardware. DCI
//  and DirectDraw buffers may still need drawing (although not always as
//  in the case of primary surfaces) and if they do they also get sent to us
//  for synchronising. Our Render method will call the DirectDraw object if
//  it sees a DirectDraw sample, otherwise it passes it to our draw object.
//
//  For shared memory buffers we select the DIB data into the offscreen device
//  context which will also always have the source palette realized in it then
//  we BitBlt from that device context into the window device context. For the
//  normal non shared memory samples we simply call SetDIBitsToDevice and also
//  StretchDIBitsToDevice), GDI first maps the buffer into it's address space
//  (thereby making the buffer shared) and then copies it to the screen.


// Constructor

#pragma warning(disable:4355)

CVideoWindow::CVideoWindow(CRenderer *pRenderer,      // The owning renderer
                           CCritSec *pLock,           // Object to lock with
                           LPUNKNOWN pUnk,            // Owning object
                           HRESULT *phr) :            // OLE return code


    CBaseControlWindow(pRenderer,pLock,NAME("Window object"),pUnk,phr),
    CBaseControlVideo(pRenderer,pLock,NAME("Window object"),pUnk,phr),
    m_pRenderer(pRenderer),
    m_pInterfaceLock(pLock),
    m_bTargetSet(FALSE),
    m_pFormat(NULL),
    m_FormatSize(0)
{
    ASSERT(m_pRenderer);
    ASSERT(m_pInterfaceLock);

    // Create a default arrow cursor

    m_hCursor = (HCURSOR) LoadImage((HINSTANCE) NULL,
                                    MAKEINTRESOURCE(OCR_ARROW_DEFAULT),
                                    IMAGE_CURSOR,0,0,0);
}


// Must destroy the window before this destructor

CVideoWindow::~CVideoWindow()
{
    ASSERT(m_hwnd == NULL);
    ASSERT(m_hdc == NULL);
    ASSERT(m_MemoryDC == NULL);
    DestroyCursor(m_hCursor);
    if (m_pFormat)
        QzTaskMemFree(m_pFormat);
}


// Overriden to say what interfaces we support

STDMETHODIMP CVideoWindow::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    if (riid == IID_IVideoWindow) {
        return CBaseControlWindow::NonDelegatingQueryInterface(riid,ppv);
    } else {
        ASSERT(riid == IID_IBasicVideo || riid == IID_IBasicVideo2);
        return CBaseControlVideo::NonDelegatingQueryInterface(riid,ppv);
    }
}


// Return the default client rectangle we would like

RECT CVideoWindow::GetDefaultRect()
{
    CAutoLock cWindowLock(&m_WindowLock);

    // Create a rectangle from the video dimensions

    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();
    BITMAPINFOHEADER *pHeader = HEADER(pVideoInfo);
    SIZE VideoSize = m_pRenderer->m_VideoSize;
    RECT DefaultRect = {0,0,VideoSize.cx,VideoSize.cy};

    return DefaultRect;
}


// We are called when the user moves the cursor over the window client area
// If we are fullscreen then we should hide the pointer so that it matches
// the fullscreen renderer behaviour. We also set a default cursor if we're
// DirectDraw overlays as software cursors won't be visible. This means we
// change the cursor as the mouse is moved but at least a cursor is visible

BOOL CVideoWindow::OnSetCursor(LPARAM lParam)
{
    // The base class that implements IVideoWindow looks after a flag that
    // says whether or not the cursor should be hidden. If so we hide the
    // cursor and return TRUE. Otherwise we pass to DefWindowProc to show
    // the cursor as normal. This is used when our window is stretched up
    // fullscreen to imitate the Modex filter that always hides the cursor

    if (IsCursorHidden() == TRUE) {
        SetCursor(NULL);
        return TRUE;
    }

    // Are DirectDraw colour key overlays visible

    if ((m_pRenderer->m_DirectDraw.InSoftwareCursorMode() == FALSE) ||
        (*m_pRenderer->m_mtIn.Subtype() == MEDIASUBTYPE_Overlay))
    {
        if (LOWORD(lParam) == HTCLIENT) {
            SetCursor(m_hCursor);
            return TRUE;
        }
    }
    return FALSE;
}


// We override the virtual CBaseWindow OnReceiveMessage call to handle more
// of the Windows messages. The base class handles some stuff like WM_CLOSE
// messages amongst others which we are also interested in. We don't need
// to use WM_SIZE and WM_MOVE messages to position source filters through
// IOverlay (with ADVISE_POSITION) as we poll with timers now. This is done
// because as a child window we cannot be guaranteed to see those messages
// Our global hook sends us WM_FREEZE and WM_THAW messages synchronously as
// it detects window changes in the system that might affect our clip list

LRESULT CVideoWindow::OnReceiveMessage(HWND hwnd,         // Window handle
                                       UINT uMsg,         // Message ID
                                       WPARAM wParam,     // First parameter
                                       LPARAM lParam)     // Other parameter
{
    IBaseFilter *pFilter = NULL;

    switch (uMsg) {

        // Handle cursors when fullscreen and in overlay mode

        case WM_SETCURSOR:

            if (OnSetCursor(lParam) == TRUE) {
                NOTE("Cursor handled");
                return (LRESULT) 0;
            }
            break;

        // We pass on WM_ACTIVATEAPP messages to the filtergraph so that the
        // IVideoWindow plug in distributor can switch us out of fullscreen
        // mode where appropriate. These messages may also be used by the
        // resource manager to keep track of which renderer has the focus

        case WM_ACTIVATEAPP:
        case WM_ACTIVATE:
        case WM_NCACTIVATE:
        case WM_MOUSEACTIVATE:
        {
            BOOL bActive = TRUE;
            IBaseFilter * const pFilter = m_pRenderer;
            switch (uMsg) {
            case WM_ACTIVATEAPP:
            case WM_NCACTIVATE:
                bActive = (BOOL)wParam;
                break;
            case WM_ACTIVATE:
                bActive = LOWORD(wParam) != WA_INACTIVE;
                break;
            }
            NOTE1("Notification of EC_ACTIVATE (%d)",bActive);
            m_pRenderer->NotifyEvent(EC_ACTIVATE,bActive,
                                     (LPARAM) pFilter);
            NOTE("EC_ACTIVATE signalled to filtergraph");

            break;
        }

        // When we detect a display change we send an EC_DISPLAY_CHANGED
        // message along with our input pin. The filtergraph will stop
        // everyone and reconnect our input pin. When being reconnected
        // we can then accept the media type that matches the new display
        // mode since we may no longer be able to draw the current format

        case WM_DISPLAYCHANGE:

            NOTE("Notification of WM_DISPLAYCHANGE");

            if (m_pRenderer->IsFrameStepEnabled()) {
                return (LRESULT)0;
            }

            m_pRenderer->OnDisplayChange();
            m_pRenderer->m_DirectDraw.HideOverlaySurface();

            // InterlockedExchange() does not work on multiprocessor x86 systems and on non-x86
            // systems if m_pRenderer->m_fDisplayChangePosted is not aligned on a 32 bit boundary.
            ASSERT((DWORD_PTR)&m_pRenderer->m_fDisplayChangePosted == ((DWORD_PTR)&m_pRenderer->m_fDisplayChangePosted & ~3));
            
            InterlockedExchange(&m_pRenderer->m_fDisplayChangePosted, FALSE); // ok again
            return (LRESULT) 0;

        // Timers are used to have DirectDraw overlays positioned

        case WM_TIMER:

            m_pRenderer->OnTimer(wParam);
            return (LRESULT) 0;

        case WM_ERASEBKGND:

            OnEraseBackground();
            return (LRESULT) 1;

        // Global system hooks are created on a specific thread, so if we get
        // an advise link created and it needs a global system hook then we
        // should install the hook on the window thread rather. The Advise
        // code can't send us a message for locking reasons so it posts us a
        // custom message to either hook the system and likewise stop a hook

        case WM_HOOK:

            OnHookMessage(TRUE);
            return (LRESULT) 1;

        case WM_UNHOOK:

            OnHookMessage(FALSE);
            return (LRESULT) 1;

        // This is a custom message send synchronously from our global hook
        // procedure when it detects that the clipping is going to change
        // on our video window - we should temporarily freeze the window

        case WM_FREEZE:

            OnWindowFreeze();
            return (LRESULT) 0;

        // This is complementary to the custom WM_FREEZE message and is sent
        // when the global hook procedure we installed detects that it is
        // now safe to resume playing the video temporarily frozen earlier

        case WM_THAW:

            OnWindowThaw();
            return (LRESULT) 0;

        case WM_SIZE:

            OnSize(LOWORD(lParam),HIWORD(lParam));
            OnUpdateRectangles();
            return (LRESULT) 0;

        // Used to delay palette change handling

        case WM_ONPALETTE:

            OnPalette();
            return (LRESULT) 0;

        // This tells us some of the window's client area has become exposed
        // If our connected filter is doing overlay work then we repaint the
        // background so that it will pick up the window clip changes. Those
        // filters will probably use an ADVISE_POSITION overlay notification

        case WM_PAINT:

            DoRealisePalette();
            OnPaint();
            return (LRESULT) 0;
    }
    return CBaseWindow::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


// Used when the palette changes to clear the window

void CVideoWindow::EraseVideoBackground()
{
    NOTE("EraseVideoBackground");
    RECT TargetRect;

    GetTargetRect(&TargetRect);
    COLORREF BackColour = SetBkColor(m_hdc,VIDEO_COLOUR);
    ExtTextOut(m_hdc,0,0,ETO_OPAQUE,&TargetRect,NULL,0,NULL);
    SetBkColor(m_hdc,BackColour);
}


// This erases the background of the video window that does not have any video
// being put in it. During normal processing we ignore paint messages because
// we will soon be putting the next frame over the top of it, however we may
// have the destination rectangle set by the IVideoWindow control interface
// such that there are areas left untouched - this method erases over them
// We must lock the critical section as the control interface may change it

void CVideoWindow::OnEraseBackground()
{
    NOTE("Entering OnErasebackground");

    RECT ClientRect, TargetRect;
    EXECUTE_ASSERT(GetClientRect(m_hwnd,&ClientRect));
    CAutoLock cWindowLock(&m_WindowLock);
    GetTargetRect(&TargetRect);

    // Find that missing region

    HRGN ClientRgn = CreateRectRgnIndirect(&ClientRect);
    HRGN VideoRgn = CreateRectRgnIndirect(&TargetRect);
    HRGN EraseRgn = CreateRectRgn(0,0,0,0);
    HBRUSH hBrush = (HBRUSH) NULL;
    COLORREF Colour;

    if ( ( ! ClientRgn ) || ( ! VideoRgn ) || ( ! EraseRgn ) )
        goto Exit;

    CombineRgn(EraseRgn,ClientRgn,VideoRgn,RGN_DIFF);

    // Create a coloured brush to paint the window

    Colour = GetBorderColour();
    hBrush = CreateSolidBrush(Colour);
    FillRgn(m_hdc,EraseRgn,hBrush);

Exit:
    if ( ClientRgn ) DeleteObject( ClientRgn );
    if ( VideoRgn ) DeleteObject( VideoRgn );
    if ( EraseRgn ) DeleteObject( EraseRgn );
    if ( hBrush ) DeleteObject( hBrush );
}


// Pass the hook message onto the overlay object

void CVideoWindow::OnHookMessage(BOOL bHook)
{
    NOTE("Entering OnHookMessage");
    m_pRenderer->m_Overlay.OnHookMessage(bHook);
}


// This is called when we receive the custom WM_FREEZE message

void CVideoWindow::OnWindowFreeze()
{
    NOTE("Entering FreezeVideo");
    m_pRenderer->m_Overlay.FreezeVideo();
}


// This is called when we receive the custom WM_THAW message

void CVideoWindow::OnWindowThaw()
{
    NOTE("Entering OnWindowThaw");
    m_pRenderer->m_Overlay.ThawVideo();
}


// Initialise the draw object with the changed dimensions, we lock ourselves
// because the destination rectangle can be set via the IVideoWindow control
// interface. If the control interface has set a destination rectangle then
// we don't change it, otherwise we update the rectangle to match the window
// dimensions (in this case the left and top values should always be zero)

BOOL CVideoWindow::OnSize(LONG Width,LONG Height)
{
    NOTE("Entering OnSize");

    CAutoLock cWindowLock(&m_WindowLock);
    if (m_bTargetSet == TRUE) {
        NOTE("Target set");
        return FALSE;
    }

    // Create a target rectangle for the window

    RECT TargetRect = {0,0,Width,Height};
    CBaseWindow::OnSize(Width,Height);
    m_pRenderer->m_DrawVideo.SetTargetRect(&TargetRect);
    m_pRenderer->m_DirectDraw.SetTargetRect(&TargetRect);

    return TRUE;
}


// This method handles the WM_CLOSE message

BOOL CVideoWindow::OnClose()
{
    NOTE("Entering OnClose");

    m_pRenderer->m_DirectDraw.HideOverlaySurface();
    m_pRenderer->SetAbortSignal(TRUE);
    m_pRenderer->NotifyEvent(EC_USERABORT,0,0);
    return CBaseWindow::OnClose();
}


// If the palette has changed then update any overlay notification. If we see
// a palette change message then we should realise our palette again - unless
// it was us who caused it in the first place. We must also draw the current
// image again making sure that if we have no sample then we do at least blank
// out the background otherwise the window may be left with the wrong colours

void CVideoWindow::OnPalette()
{
    if (IsWindowVisible(m_hwnd) == TRUE) {
        NOTE("Handling OnPalette");
        m_pRenderer->OnPaint(TRUE);
    }
    m_pRenderer->m_Overlay.NotifyChange(ADVISE_PALETTE);
}


// Post a WM_ONPALETTE back to ourselves to avoid the window lock

LRESULT CVideoWindow::OnPaletteChange(HWND hwnd,UINT Message)
{
    NOTE("Entering OnPaletteChange");

    // Firstly is the window closing down
    if (m_hwnd == NULL || hwnd == NULL) {
        return (LRESULT) 0;
    }

    // Should we realise our palette again
    if (Message == WM_QUERYNEWPALETTE || hwnd != m_hwnd) {
        //  It seems that even if we're invisible that we can get asked
        //  to realize our palette and this can cause really ugly side-effects
        //  Seems like there's another bug but this masks it a least for the
        //  shutting down case.
        if (!IsWindowVisible(m_hwnd)) {
            DbgLog((LOG_TRACE, 1, TEXT("Realizing when invisible!")));
            return (LRESULT) 0;
        }
        DoRealisePalette(Message != WM_QUERYNEWPALETTE);
    }

    // Should we redraw the window with the new palette
    if (Message == WM_PALETTECHANGED) {
        PostMessage(m_hwnd,WM_ONPALETTE,0,0);
    }
    return (LRESULT) 1;
}


// This is called when we receive a WM_PAINT message

BOOL CVideoWindow::OnPaint()
{
    NOTE("Entering OnPaint");
    PAINTSTRUCT ps;
    BeginPaint(m_hwnd,&ps);
    EndPaint(m_hwnd,&ps);
    return m_pRenderer->OnPaint(FALSE);
}


// The base control video class calls this method when it changes either
// the source or destination rectangles. We update the overlay object as
// so that it notifies the source of the rectangle clip change and then
// invalidate the window so that the video is displayed in the new place

HRESULT CVideoWindow::OnUpdateRectangles()
{
    NOTE("Entering OnUpdateRectangles");
    m_pRenderer->m_Overlay.NotifyChange(ADVISE_CLIPPING | ADVISE_POSITION);
    m_pRenderer->m_VideoAllocator.OnDestinationChange();
    PaintWindow(TRUE);
    return NOERROR;
}


// When we call PrepareWindow in our constructor it will call this method as
// it is going to create the window to get our window and class styles. The
// return code is the class name and must be allocated in static storage. We
// specify a normal window during creation although the window styles as well
// as the extended styles may be changed by the application via IVideoWindow

LPTSTR CVideoWindow::GetClassWindowStyles(DWORD *pClassStyles,
                                          DWORD *pWindowStyles,
                                          DWORD *pWindowStylesEx)
{
    *pClassStyles = CS_HREDRAW | CS_VREDRAW | CS_BYTEALIGNCLIENT | CS_DBLCLKS;
    *pWindowStyles = WS_OVERLAPPEDWINDOW | WS_CLIPCHILDREN;
    *pWindowStylesEx = (DWORD) 0;
    return WindowClassName;
}


// Return the minimum ideal image size for the current video. This may differ
// to the actual video dimensions because we may be using DirectDraw hardware
// that has specific stretching requirements. For example the Cirrus Logic
// cards have a minimum stretch factor depending on the overlay surface size

STDMETHODIMP
CVideoWindow::GetMinIdealImageSize(long *pWidth,long *pHeight)
{
    CheckPointer(pWidth,E_POINTER);
    CheckPointer(pHeight,E_POINTER);
    FILTER_STATE State;
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Must not be stopped for this to work correctly

    m_pRenderer->GetState(0,&State);
    if (State == State_Stopped) {
        return VFW_E_WRONG_STATE;
    }

    GetVideoSize(pWidth,pHeight);

    // Is this a purely overlay connection

    GUID SubType = *(m_pRenderer->m_mtIn.Subtype());
    if (SubType == MEDIASUBTYPE_Overlay) {
        return S_FALSE;
    }
    return m_pRenderer->m_DirectDraw.GetMinIdealImageSize(pWidth,pHeight);
}


// Return the maximum ideal image size for the current video. This may differ
// to the actual video dimensions because we may be using DirectDraw hardware
// that has specific stretching requirements. For example the Cirrus Logic
// cards have a maximum stretch factor depending on the overlay surface size

STDMETHODIMP
CVideoWindow::GetMaxIdealImageSize(long *pWidth,long *pHeight)
{
    CheckPointer(pWidth,E_POINTER);
    CheckPointer(pHeight,E_POINTER);
    FILTER_STATE State;
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    // Must not be stopped for this to work correctly

    m_pRenderer->GetState(0,&State);
    if (State == State_Stopped) {
        return VFW_E_WRONG_STATE;
    }

    GetVideoSize(pWidth,pHeight);

    // Is this a purely overlay connection

    GUID SubType = *(m_pRenderer->m_mtIn.Subtype());
    if (SubType == MEDIASUBTYPE_Overlay) {
        return S_FALSE;
    }
    return m_pRenderer->m_DirectDraw.GetMaxIdealImageSize(pWidth,pHeight);
}

STDMETHODIMP
CVideoWindow::GetPreferredAspectRatio(long *plAspectX, long *plAspectY)
{
    if (plAspectX == NULL || plAspectY == NULL) {
        return E_POINTER;
    }

    CAutoLock cInterfaceLock(m_pInterfaceLock);

    //  See if the connected pin offers any aspect ratio - otherwise just
    //  return the regular stuff
    IPin *pPin = m_pRenderer->m_InputPin.GetConnected();
    if (pPin == NULL) {
        return VFW_E_NOT_CONNECTED;
    }
    IEnumMediaTypes *pEnum;
    bool fFoundVideoWidthAndHeight = false;
    if (SUCCEEDED(pPin->EnumMediaTypes(&pEnum))) {
        AM_MEDIA_TYPE *pmt;
        DWORD dwFound;
        if (S_OK == pEnum->Next(1, &pmt, &dwFound)) {
            if (pmt->formattype == FORMAT_VideoInfo2) {
                VIDEOINFOHEADER2 *pVideoInfo2 =
                    (VIDEOINFOHEADER2 *)pmt->pbFormat;
                *plAspectX = (long)pVideoInfo2->dwPictAspectRatioX;
                *plAspectY = (long)pVideoInfo2->dwPictAspectRatioY;
                fFoundVideoWidthAndHeight = true;
            }
            DeleteMediaType(pmt);
        }
        pEnum->Release();
    } 

    if (!fFoundVideoWidthAndHeight)
    {
        // Just return the normal values
        *plAspectX = m_pRenderer->GetVideoWidth();
        *plAspectY = m_pRenderer->GetVideoHeight();
    }
    return S_OK;
}


// Return a copy of the current image in the video renderer. The base control
// class implements a helper mathod that takes an IMediaSample interface and
// assuming it is a normal linear buffer copies the relevant section of the
// video into the output buffer provided. The method takes into account any
// source rectangle already specified by calling our GetSourceRect function

HRESULT CVideoWindow::GetStaticImage(long *pVideoSize,long *pVideoImage)
{
    NOTE("Entering GetStaticImage");
    IMediaSample *pMediaSample;
    RECT SourceRect;

    // Is there an image available

    pMediaSample = m_pRenderer->GetCurrentSample();
    if (pMediaSample == NULL) {
        return E_UNEXPECTED;
    }

    // Check the image isn't a DirectDraw sample

    if (m_pRenderer->m_VideoAllocator.GetDirectDrawStatus() == TRUE) {
        pMediaSample->Release();
        return E_FAIL;
    }

    // Find a scaled source rectangle for the current bitmap

    m_pRenderer->m_DrawVideo.GetSourceRect(&SourceRect);
    SourceRect = m_pRenderer->m_DrawVideo.ScaleSourceRect(&SourceRect);
    VIDEOINFO *pVideoInfo = (VIDEOINFO *) m_pRenderer->m_mtIn.Format();

    // Call the base class helper method to do the work

    HRESULT hr = CopyImage(pMediaSample,        // Buffer containing image
        (VIDEOINFOHEADER *)pVideoInfo,          // Type representing bitmap
                           pVideoSize,          // Size of buffer for DIB
                           (BYTE*) pVideoImage, // Data buffer for output
                           &SourceRect);        // Current source position

    pMediaSample->Release();
    return hr;
}


// The IVideoWindow control interface use this to reset the video destination
// We reset the flag that indicates whether we have a destination rectangle
// set explicitly or not, and then initialise the rectangle with the client
// window dimensions. These fields are used by the window thread when it does
// the drawing and also when it processes WM_SIZE messages (hence the lock)

HRESULT CVideoWindow::SetDefaultTargetRect()
{
    CAutoLock cWindowLock(&m_WindowLock);
    RECT TargetRect;

    // Update the draw objects

    EXECUTE_ASSERT(GetClientRect(m_hwnd,&TargetRect));
    m_pRenderer->m_DrawVideo.SetTargetRect(&TargetRect);
    m_pRenderer->m_DirectDraw.SetTargetRect(&TargetRect);
    m_bTargetSet = FALSE;
    return NOERROR;
}


// Return S_OK if using the default target otherwise S_FALSE

HRESULT CVideoWindow::IsDefaultTargetRect()
{
    CAutoLock cWindowLock(&m_WindowLock);
    return (m_bTargetSet ? S_FALSE : S_OK);
}


// This sets the destination rectangle for the real video. The rectangle may
// be larger or smaller than the video window is and may be offset into it as
// well so we rely on the drawing operations to clip (such as the StretchBlt)

HRESULT CVideoWindow::SetTargetRect(RECT *pTargetRect)
{
    CAutoLock cWindowLock(&m_WindowLock);
    m_bTargetSet = TRUE;

    // Update the draw objects
    m_pRenderer->m_DrawVideo.SetTargetRect(pTargetRect);
    m_pRenderer->m_DirectDraw.SetTargetRect(pTargetRect);

    return NOERROR;
}


// This complements the SetTargetRect method to return the rectangle in use
// as the destination. If we have had no rectangle explicitly set then we
// will return the client window size as updated in the WM_SIZE messages

HRESULT CVideoWindow::GetTargetRect(RECT *pTargetRect)
{
    CAutoLock cWindowLock(&m_WindowLock);
    m_pRenderer->m_DrawVideo.GetTargetRect(pTargetRect);
    return NOERROR;
}


// Reset the source rectangle to be all the available video

HRESULT CVideoWindow::SetDefaultSourceRect()
{
    CAutoLock cWindowLock(&m_WindowLock);
    SIZE VideoSize = m_pRenderer->m_VideoSize;
    RECT SourceRect = {0,0,VideoSize.cx,VideoSize.cy};

    // Update the draw objects

    m_pRenderer->m_DrawVideo.SetSourceRect(&SourceRect);
    m_pRenderer->m_DirectDraw.SetSourceRect(&SourceRect);
    return NOERROR;
}


// Return S_OK if using the default source otherwise S_FALSE

HRESULT CVideoWindow::IsDefaultSourceRect()
{
    RECT SourceRect;

    // Does the source match the native video size

    SIZE VideoSize = m_pRenderer->m_VideoSize;
    CAutoLock cWindowLock(&m_WindowLock);
    m_pRenderer->m_DrawVideo.GetSourceRect(&SourceRect);

    // Check the coordinates match the video dimensions

    if (SourceRect.right == VideoSize.cx) {
        if (SourceRect.bottom == VideoSize.cy) {
            if (SourceRect.left == 0) {
                if (SourceRect.top == 0) {
                    return S_OK;
                }
            }
        }
    }
    return S_FALSE;
}


// This is called when we want to change the section of the image to draw. We
// use this information in the drawing operation calls later on. We must also
// see if the source and destination rectangles have the same dimensions. If
// not then we must stretch during the drawing rather than doing a pixel copy

HRESULT CVideoWindow::SetSourceRect(RECT *pSourceRect)
{
    CAutoLock cWindowLock(&m_WindowLock);
    m_pRenderer->m_DrawVideo.SetSourceRect(pSourceRect);
    m_pRenderer->m_DirectDraw.SetSourceRect(pSourceRect);
    return NOERROR;
}


// This complements the SetSourceRect method

HRESULT CVideoWindow::GetSourceRect(RECT *pSourceRect)
{
    CAutoLock cWindowLock(&m_WindowLock);
    m_pRenderer->m_DrawVideo.GetSourceRect(pSourceRect);
    return NOERROR;
}


// We must override this to return a VIDEOINFO representing the video format
// The base class cannot call IPin ConnectionMediaType to get this format as
// dynamic type changes when using DirectDraw have the format show the image
// bitmap in terms of logical positions within a frame buffer surface, so a
// video might be returned as 1024x768 pixels, instead of the native 320x240

VIDEOINFOHEADER *CVideoWindow::GetVideoFormat()
{
    if (m_FormatSize < (int)m_pRenderer->m_mtIn.FormatLength()) {
        m_FormatSize = m_pRenderer->m_mtIn.FormatLength();
        if (m_pFormat)
            QzTaskMemFree(m_pFormat);
        m_pFormat = (VIDEOINFOHEADER *)QzTaskMemAlloc(m_FormatSize);
        if (m_pFormat == NULL) {
            m_FormatSize = 0;
            return NULL;
        }
    }
    CopyMemory((PVOID)m_pFormat, (PVOID)m_pRenderer->m_mtIn.Format(),
                            m_pRenderer->m_mtIn.FormatLength());
    m_pFormat->bmiHeader.biWidth = m_pRenderer->m_VideoSize.cx;
    m_pFormat->bmiHeader.biHeight = m_pRenderer->m_VideoSize.cy;
    return m_pFormat;
}


// The overlay object has on occasion to create a palette that will be used
// for colour keyed overlay source filters. However it wants to install the
// palette with it's critical section locked. Therefore it can't realise it
// as well otherwise it may end up deadlocking with an inter thread message
// sent to the window. So we install the palette but delay the realisation
// until later (by posting a WM_QUERYNEWPALETTE to the video window thread)

void CVideoWindow::SetKeyPalette(HPALETTE hPalette)
{
    // We must own the window lock during the change
    CAutoLock cWindowLock(&m_WindowLock);
    CAutoLock cPaletteLock(&m_PaletteLock);

    ASSERT(hPalette);
    m_hPalette = hPalette;

    // Select the palette into the device contexts
    SelectPalette(m_hdc,m_hPalette,m_bBackground);
    SelectPalette(m_MemoryDC,m_hPalette,m_bBackground);
    PostMessage(m_hwnd,WM_QUERYNEWPALETTE,0,0);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\vidprop\modectl.cpp ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Implements a Modex property page, Anthony Phillips, February 1996

#include <streams.h>
#include <string.h>
#include <vidprop.h>

// This implements a display mode property page for the modex renderer. We
// communicate with the Modex renderer through the IFullScreenVideo control
// interface it implements and defined in the ActiveMovie SDK. The property
// page has one group box that shows the display modes available (if the
// display card does not support a given mode then we disable the checkbox)
// Although the fullscreen video interface allows the modes a renderer to
// support to dynamically change we use private knowledge of the modes the
// Modex renderer has enabled to construct a property page. The renderer
// enables 320x200x8/16, 320x240x8/16, 640x400x8/16 and 640x480,8/16 modes


// Constructor

CModexProperties::CModexProperties(LPUNKNOWN pUnk,HRESULT *phr) :
    CBasePropertyPage(NAME("Modex Page"),pUnk,IDD_MODEX,IDS_VID51),
    m_pModexVideo(NULL),
    m_CurrentMode(INFINITE),
    m_bInActivation(FALSE),
    m_ClipFactor(0)
{
    ASSERT(phr);
}


// Create a modex properties object

CUnknown *CModexProperties::CreateInstance(LPUNKNOWN lpUnk,HRESULT *phr)
{
    return new CModexProperties(lpUnk,phr);
}


// Load the current default property settings from the renderer

HRESULT CModexProperties::LoadProperties()
{
    NOTE("Loading properties");
    ASSERT(m_pModexVideo);
    BOOL bSetMode;

    m_pModexVideo->GetClipFactor(&m_ClipFactor);

    // What is the current mode chosen

    HRESULT hr = m_pModexVideo->GetCurrentMode(&m_CurrentMode);
    if (hr == VFW_E_NOT_CONNECTED) {
        m_CurrentMode = INFINITE;
    }

    // Store in the array a flag for each display mode

    for (LONG ModeCount = 0;ModeCount < MAXMODES;ModeCount++) {
        bSetMode = (m_pModexVideo->IsModeEnabled(ModeCount) == NOERROR ? TRUE : FALSE);
        m_bEnabledModes[ModeCount] = bSetMode;
        bSetMode = (m_pModexVideo->IsModeAvailable(ModeCount) == NOERROR ? TRUE : FALSE);
        m_bAvailableModes[ModeCount] = bSetMode;
    }
    return NOERROR;
}


// Load the current default property settings from the controls

HRESULT CModexProperties::UpdateVariables()
{
    NOTE("Updating variables");
    ASSERT(m_pModexVideo);
    HWND hwndDialog;

    // See which display modes are enabled

    for (LONG ModeCount = 0;ModeCount < MAXMODES;ModeCount++) {
        hwndDialog = GetDlgItem(m_Dlg,FIRST_MODEX_MODE + (ModeCount << 1));
        m_bEnabledModes[ModeCount] = Button_GetCheck(hwndDialog);
    }
    m_ClipFactor = (LONG) GetDlgItemInt(m_Dlg,MODEX_CLIP_EDIT,NULL,TRUE);
    return NOERROR;
}


// Initialise the check boxes in the property page

HRESULT CModexProperties::DisplayProperties()
{
    NOTE("Setting properties");
    LONG Width,Height,Depth;
    ASSERT(m_pModexVideo);
    BOOL bSetMode = FALSE;
    TCHAR Format[PROFILESTR];

    // Make a description for the current display mode chosen

    if (m_CurrentMode == INFINITE) {
        SendDlgItemMessage(m_Dlg,MODEX_CHOSEN_EDIT,WM_SETTEXT,0,(LPARAM) LoadVideoString(IDS_VID31));
    } else {
        m_pModexVideo->GetModeInfo(m_CurrentMode,&Width,&Height,&Depth);
        wsprintf(Format,TEXT("%dx%dx%d"),Width,Height,Depth);
        SendDlgItemMessage(m_Dlg,MODEX_CHOSEN_EDIT,WM_SETTEXT,0,(LPARAM) Format);
    }

    // Set the current clip percentage factor

    NOTE("Setting clip percentage");
    wsprintf(Format,TEXT("%d"),m_ClipFactor);
    SendDlgItemMessage(m_Dlg,MODEX_CLIP_EDIT,WM_SETTEXT,0,(LPARAM) Format);

    // Set the check box for each available display mode

    for (LONG ModeCount = 0;ModeCount < MAXMODES;ModeCount++) {
        HWND hwndDialog = GetDlgItem(m_Dlg,FIRST_MODEX_MODE + (ModeCount << 1));
        Button_SetCheck(hwndDialog,m_bEnabledModes[ModeCount]);
        hwndDialog = GetDlgItem(m_Dlg,FIRST_MODEX_TEXT + (ModeCount << 1));
        EnableWindow(hwndDialog,m_bAvailableModes[ModeCount]);
    }
    return NOERROR;
}


// Save the current property page settings

HRESULT CModexProperties::SaveProperties()
{
    TCHAR szExtra[STR_MAX_LENGTH];
    NOTE("Saving properties");
    ASSERT(m_pModexVideo);

    // Try and save the current clip factor

    HRESULT hr = m_pModexVideo->SetClipFactor(m_ClipFactor);
    if (FAILED(hr)) {
        MessageBox(m_hwnd,StringFromResource(szExtra,IDS_VID2),
                   LoadVideoString(IDS_VID1),
                   MB_OK | MB_ICONEXCLAMATION | MB_APPLMODAL);
    }

    // Get the check box setting for each available mode

    for (LONG ModeCount = 0;ModeCount < MAXMODES;ModeCount++) {
        BOOL bSetMode = m_bEnabledModes[ModeCount];
        m_pModexVideo->SetEnabled(ModeCount,(bSetMode == TRUE ? OATRUE : OAFALSE));
    }
    return m_pModexVideo->SetDefault();
}


// Handles the messages for our property window

INT_PTR CModexProperties::OnReceiveMessage(HWND hwnd,
                                        UINT uMsg,
                                        WPARAM wParam,
                                        LPARAM lParam)
{
    switch (uMsg) {

        case WM_COMMAND:

            // Are we setting the values to start with

            if (m_bInActivation == TRUE) {
                return (LRESULT) 1;
            }

            // Has the user clicked on one of the controls

            if (HIWORD(wParam) == BN_CLICKED || HIWORD(wParam) == EN_CHANGE) {
                if (LOWORD(wParam) >= FIRST_MODEX_BUTTON) {
                    if (LOWORD(wParam) <= LAST_MODEX_BUTTON) {
                        UpdateVariables();
                        m_bDirty = TRUE;
                        if (m_pPageSite) {
                            m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
                        }
                    }
                }
            }
            return (LRESULT) 1;
    }
    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


// Tells us the object that should be informed of the property changes. This
// is used to get the IFullScreenVideo interface the Modex renderer supports
// We are passed the IUnknown for the filter we are being attached to. If it
// doesn't support the full screen interface then we return an error which
// should stop us being shown. The application will also look after calling
// SetPageSite(NULL) and also SetObjects(0,NULL) when the page is destroyed

HRESULT CModexProperties::OnConnect(IUnknown *pUnknown)
{
    NOTE("Property SetObjects");
    ASSERT(m_pModexVideo == NULL);
    NOTE("Asking for interface");

    // Ask the renderer for it's IFullScreenVideo control interface

    HRESULT hr = pUnknown->QueryInterface(IID_IFullScreenVideo,(void **) &m_pModexVideo);
    if (FAILED(hr)) {
        NOTE("No IFullScreenVideo");
        return E_NOINTERFACE;
    }

    ASSERT(m_pModexVideo);
    LoadProperties();
    return NOERROR;
}


// Release any IFullScreenVideo interface we have

HRESULT CModexProperties::OnDisconnect()
{
    // Release the interface

    if (m_pModexVideo == NULL) {
        NOTE("Nothing to release");
        return E_UNEXPECTED;
    }

    NOTE("Releasing interface");
    m_pModexVideo->Release();
    m_pModexVideo = NULL;
    return NOERROR;
}


// Initialise the dialog box controls

HRESULT CModexProperties::OnActivate()
{
    NOTE("Property activate");
    m_bInActivation = TRUE;
    DisplayProperties();
    m_bInActivation = FALSE;
    return NOERROR;
}


// Apply any changes so far made

HRESULT CModexProperties::OnApplyChanges()
{
    NOTE("Property Apply");
    SaveProperties();
    return NOERROR;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image\video\window.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Defines a window management object, Anthony Phillips, January 1995

#ifndef __WINDOW__
#define __WINDOW__

// This class looks after the management of a video window. When the window
// object is first created the constructor spawns off a worker thread that
// does all the window work. The original thread waits until it is signaled
// to continue. The worker thread firstly registers the window class if it
// is not already done. Then it creates a window and sets it's size to match
// the video dimensions (the dimensions are returned through GetDefaultRect)

// Notice that the worker thread MUST be the thread that creates the window
// as it is the one who calls GetMessage. When it has done all this it will
// signal the original thread which lets it continue, this ensures a window
// is created and valid before the constructor returns. The thread's start
// address is the WindowMessageLoop function. The thread's parameter we pass
// it is the CBaseWindow this pointer for the window object that created it

#define WindowClassName TEXT("VideoRenderer")

// The window class name isn't used only as a class name for the base window
// classes, it is also used by the overlay selection code as a name to base
// a mutex creation on. Basicly it has a shared memory block where the next
// available overlay colour is returned from. The creation and preparation
// of the shared memory must be serialised through all ActiveMovie instances


class CVideoWindow : public CBaseControlWindow, public CBaseControlVideo
{
    CRenderer *m_pRenderer;             // The owning renderer object
    BOOL m_bTargetSet;                  // Do we use the default rectangle
    CCritSec *m_pInterfaceLock;         // Main renderer interface lock
    HCURSOR m_hCursor;                  // Used to display a normal cursor
    VIDEOINFOHEADER *m_pFormat;		// holds our video format
    int m_FormatSize;			// length of m_pFormat

    // Overriden method to handle window messages
    LRESULT OnReceiveMessage(HWND hwnd,      // Window handle
                             UINT uMsg,      // Message ID
                             WPARAM wParam,  // First parameter
                             LPARAM lParam); // Other parameter

    // Window message handlers

    void OnHookMessage(BOOL bHook);
    void OnWindowFreeze();
    void OnWindowThaw();
    void OnEraseBackground();
    BOOL OnClose();
    LRESULT OnPaletteChange(HWND hwnd, UINT Message);
    void OnPalette();
    BOOL OnPaint();
    BOOL OnSetCursor(LPARAM lParam);
    BOOL OnSize(LONG Width, LONG Height);

public:

    CVideoWindow(CRenderer *pRenderer,      // The owning renderer
                 CCritSec *pLock,           // Object to use for lock
                 LPUNKNOWN pUnk,            // Owning object
                 HRESULT *phr);             // OLE return code

    ~CVideoWindow();

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    // Return the minimum and maximum ideal sizes
    STDMETHODIMP GetMinIdealImageSize(long *pWidth,long *pHeight);
    STDMETHODIMP GetMaxIdealImageSize(long *pWidth,long *pHeight);

    //  IBasicVideo2
    STDMETHODIMP GetPreferredAspectRatio(long *plAspectX, long *plAspectY);

    LPTSTR GetClassWindowStyles(DWORD *pClassStyles,        // Class styles
                                DWORD *pWindowStyles,       // Window styles
                                DWORD *pWindowStylesEx);    // Extended styles

    // These are called by the renderer control interfaces

    HRESULT SetDefaultTargetRect();
    HRESULT IsDefaultTargetRect();
    HRESULT SetTargetRect(RECT *pTargetRect);
    HRESULT GetTargetRect(RECT *pTargetRect);
    HRESULT SetDefaultSourceRect();
    HRESULT IsDefaultSourceRect();
    HRESULT SetSourceRect(RECT *pSourceRect);
    HRESULT GetSourceRect(RECT *pSourceRect);
    HRESULT OnUpdateRectangles();
    HRESULT GetStaticImage(long *pVideoSize,long *pVideoImage);
    VIDEOINFOHEADER *GetVideoFormat();
    RECT GetDefaultRect();
    void SetKeyPalette(HPALETTE hPalette);
    void EraseVideoBackground();

    // Synchronise with decoder thread
    CCritSec *LockWindowUpdate() {
        return (&m_WindowLock);
    };
};

#endif // __WINDOW__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\alloclib\alloclib.cpp ===
/******************************Module*Header*******************************\
* Module Name: AllocLib
*
*
*
*
* Created: Fri 03/10/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <d3d.h>
#include <limits.h>
#include <malloc.h>

#include "vmrp.h"
#include "AllocLib.h"

/////////////////////////////////////////////////////////////////////////////
//
// Utility functions for rectangles
//
/////////////////////////////////////////////////////////////////////////////

/*****************************Private*Routine******************************\
* EqualSizeRect
*
* returns true if the size of rc1 is the same as rc2.  Note that the
* position of the two rectangles may be different
*
* History:
* Thu 04/27/2000 - StEstrop - Created
*
\**************************************************************************/
bool
EqualSizeRect(
    const RECT* lpRc1,
    const RECT* lpRc2
    )
{
    return HEIGHT(lpRc1) == HEIGHT(lpRc2) && WIDTH(lpRc1) == WIDTH(lpRc2);
}

/*****************************Private*Routine******************************\
* ContainedRect
*
* returns true if rc1 is fully contained within rc2
*
* History:
* Thu 05/04/2000 - StEstrop - Created
*
\**************************************************************************/
bool
ContainedRect(
    const RECT* lpRc1,
    const RECT* lpRc2
    )
{
    return !(lpRc1->left   < lpRc2->left  ||
             lpRc1->right  > lpRc2->right ||
             lpRc1->top    < lpRc2->top   ||
             lpRc1->bottom > lpRc2->bottom);

}

/*****************************Private*Routine******************************\
* LetterBoxDstRect
*
* Takes a src rectangle and constructs the largest possible destination
* rectangle within the specifed destination rectangle such that
* the video maintains its current shape.
*
* This function assumes that pels are the same shape within both the src
* and dst rectangles.
*
* History:
* Tue 05/02/2000 - StEstrop - Created
*
\**************************************************************************/
void
LetterBoxDstRect(
    LPRECT lprcLBDst,
    const RECT& rcSrc,
    const RECT& rcDst,
    LPRECT lprcBdrTL,
    LPRECT lprcBdrBR
    )
{
    // figure out src/dest scale ratios
    int iSrcWidth  = WIDTH(&rcSrc);
    int iSrcHeight = HEIGHT(&rcSrc);

    int iDstWidth  = WIDTH(&rcDst);
    int iDstHeight = HEIGHT(&rcDst);

    int iDstLBWidth;
    int iDstLBHeight;

    //
    // work out if we are Column or Row letter boxing
    //

    if (MulDiv(iSrcWidth, iDstHeight, iSrcHeight) <= iDstWidth) {

        //
        // column letter boxing - we add border color bars to the
        // left and right of the video image to fill the destination
        // rectangle.
        //
        iDstLBWidth  = MulDiv(iDstHeight, iSrcWidth, iSrcHeight);
        iDstLBHeight = iDstHeight;
    }
    else {

        //
        // row letter boxing - we add border color bars to the top
        // and bottom of the video image to fill the destination
        // rectangle
        //
        iDstLBWidth  = iDstWidth;
        iDstLBHeight = MulDiv(iDstWidth, iSrcHeight, iSrcWidth);
    }


    //
    // now create a centered LB rectangle within the current destination rect
    //

    lprcLBDst->left   = rcDst.left + ((iDstWidth - iDstLBWidth) / 2);
    lprcLBDst->right  = lprcLBDst->left + iDstLBWidth;

    lprcLBDst->top    = rcDst.top + ((iDstHeight - iDstLBHeight) / 2);
    lprcLBDst->bottom = lprcLBDst->top + iDstLBHeight;

    //
    // Fill out the border rects if asked to do so
    //

    if (lprcBdrTL) {

        if (rcDst.top != lprcLBDst->top) {
            // border is on the top
            SetRect(lprcBdrTL, rcDst.left, rcDst.top,
                    lprcLBDst->right, lprcLBDst->top);
        }
        else {
            // border is on the left
            SetRect(lprcBdrTL, rcDst.left, rcDst.top,
                    lprcLBDst->left, lprcLBDst->bottom);
        }
    }

    if (lprcBdrBR) {

        if (rcDst.top != lprcLBDst->top) {
            // border is on the bottom
            SetRect(lprcBdrBR, lprcLBDst->left,
                    lprcLBDst->bottom, rcDst.right, rcDst.bottom);
        }
        else {
            // border is on the right
            SetRect(lprcBdrBR, lprcLBDst->right,
                    lprcLBDst->top, rcDst.right, rcDst.bottom);
        }
    }
}


/*****************************Private*Routine******************************\
* AspectRatioCorrectSize
*
* Corrects the supplied size structure so that it becomes the same shape
* as the specified aspect ratio, the correction is always applied in the
* horizontal axis
*
* History:
* Tue 05/02/2000 - StEstrop - Created
*
\**************************************************************************/
void
AspectRatioCorrectSize(
    LPSIZE lpSizeImage,
    const SIZE& sizeAr
    )
{
    int cxAR = sizeAr.cx * 1000;
    int cyAR = sizeAr.cy * 1000;

    long lCalcX = MulDiv(lpSizeImage->cx, cyAR, lpSizeImage->cy);

    if (lCalcX != cxAR) {
        lpSizeImage->cx = MulDiv(lpSizeImage->cy, cxAR, cyAR);
    }
}



/*****************************Private*Routine******************************\
* GetBitMasks
*
* Return the bit masks for the true colour VIDEOINFO or VIDEOINFO2 provided
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
const DWORD*
GetBitMasks(
    const BITMAPINFOHEADER *pHeader
    )
{
    AMTRACE((TEXT("GetBitMasks")));
    static DWORD FailMasks[] = {0, 0, 0};
    const DWORD *pdwBitMasks = NULL;

    ASSERT(pHeader);

    if (pHeader->biCompression != BI_RGB)
    {
        pdwBitMasks = (const DWORD *)((LPBYTE)pHeader + pHeader->biSize);
    }
    else {
        ASSERT(pHeader->biCompression == BI_RGB);
        switch (pHeader->biBitCount) {
        case 16:
            pdwBitMasks = bits555;
            break;

        case 24:
            pdwBitMasks = bits888;
            break;

        case 32:
            pdwBitMasks = bits888;
            break;

        default:
            pdwBitMasks = FailMasks;
            break;
        }
    }

    return pdwBitMasks;
}

/******************************Public*Routine******************************\
* FixupMediaType
*
* DShow filters have the habit of sometimes not setting the src and dst
* rectangles, in this case we should imply that the these rectangles
* should be the same width and height as the bitmap in the media format.
*
* History:
* Tue 08/22/2000 - StEstrop - Created
*
\**************************************************************************/
void
FixupMediaType(
    AM_MEDIA_TYPE* pmt
    )
{
    AMTRACE((TEXT("FixupMediaType")));

    LPRECT lprc;
    LPBITMAPINFOHEADER lpbi = GetbmiHeader(pmt);

    if (lpbi) {

        lprc = GetTargetRectFromMediaType(pmt);
        if (lprc && IsRectEmpty(lprc)) {
            SetRect(lprc, 0, 0, abs(lpbi->biWidth), abs(lpbi->biHeight));
        }

        lprc = GetSourceRectFromMediaType(pmt);
        if (lprc && IsRectEmpty(lprc)) {
            SetRect(lprc, 0, 0, abs(lpbi->biWidth), abs(lpbi->biHeight));
        }
    }
}



/******************************Public*Routine******************************\
* GetTargetRectFromMediaType
*
*
*
* History:
* Mon 06/26/2000 - StEstrop - Created
*
\**************************************************************************/
LPRECT
GetTargetRectFromMediaType(
    const AM_MEDIA_TYPE *pMediaType
    )
{
    AMTRACE((TEXT("GetTargetRectFromMediaType")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        return NULL;
    }

    if (!(pMediaType->pbFormat))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType->pbFormat is NULL")));
        return NULL;
    }

    LPRECT lpRect = NULL;
    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        lpRect = &(((VIDEOINFOHEADER*)(pMediaType->pbFormat))->rcTarget);
    }
    else if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
             (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        lpRect = &(((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->rcTarget);
    }

    return lpRect;

}

/******************************Public*Routine******************************\
* GetTargetScaleFromMediaType(
*
*   Check the mediatype for the PAD_4x3 or PAD_16x9 flags and compute the stretch.
*
*   If the flags are present, then we need to pad the image to 4x3 or 16x9.
*   We accomplish this by stretching the destination region then compressing
*   the target rectangle.  For example, to pad a 16x9 into a 4x3 area (and maintain
*   the width), we need to place the image in an area that is 16x9/4x3 = 4/3 times
*   taller.  Then we 'unstretch' the video by the inverse 3/4 to return it to a 16x9
*   image in the 4x3 area.
*
*   Similarly, if we want to place a 4x3 image in a 16x9 area, we need to pad the
*   sides (and keep the same height).  So we stretch the output area horizontally
*   by 16x9/4x3 then compress the target image rectangle by 4x3/16x9.
*
* History:
* Tue 03/14/2000 - GlennE - Created
*
\**************************************************************************/

void
GetTargetScaleFromMediaType(
    const AM_MEDIA_TYPE *pMediaType,
    TargetScale* pScale
    )
{
    pScale->fX = 1.0F;
    pScale->fY = 1.0F;

    if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        const VIDEOINFOHEADER2& header = *(VIDEOINFOHEADER2*)(pMediaType->pbFormat);

        // fit source into the target area by reducing its size

        LONG lTargetARWidth;
        LONG lTargetARHeight;
        LONG lSourceARWidth = header.dwPictAspectRatioX;
        LONG lSourceARHeight = header.dwPictAspectRatioY;

        if( header.dwControlFlags & AMCONTROL_PAD_TO_16x9 ) {
            lTargetARWidth = 16;
            lTargetARHeight = 9;
        } else if( header.dwControlFlags & AMCONTROL_PAD_TO_4x3 ) {
            lTargetARWidth = 4;
            lTargetARHeight = 3;
        } else {
            // lTargetARWidth = lSourceARWidth;
            // lTargetARHeight = lSourceARHeight;
            // leave at 1.0 x/y
            return;
        }
        // float TargetRatio = float(lTargetARWidth)/lTargetARHeight;
        // float SourceRatio = float(lSourceARWidth)/lSourceARHeight;

        // if( Target > Source ) --> lTargetARWidth/lTargetARHeight > lSourceARWidth/lSourceARHeight
        //                  .... or after clearing fractions (since all positive)
        //                       --> lTargetARWidth * lSourceARHeight > lSourceARWidth * lTargetARHeight

        LONG TargetWidth = lTargetARWidth * lSourceARHeight;
        LONG SourceWidth = lSourceARWidth * lTargetARHeight;

        if( TargetWidth > SourceWidth ) {
            // wider, pad width
            // Assume heights equal, pad sides.  Pad fraction = ratio of ratios
            pScale->fX = float(SourceWidth) / TargetWidth;
            pScale->fY = 1.0F;
        } else if (TargetWidth < SourceWidth ) {
            // taller, pad height
            // Assume widths equal, pad top/bot.  Pad fraction = ratio of ratios
            pScale->fX = 1.0F;
            pScale->fY = float(TargetWidth) / SourceWidth;
        } else { // equal
            // no change
        }
    }
}

/******************************Public*Routine******************************\
* GetSourceRectFromMediaType
*
*
*
* History:
* Mon 06/26/2000 - StEstrop - Created
*
\**************************************************************************/
LPRECT
GetSourceRectFromMediaType(
    const AM_MEDIA_TYPE *pMediaType
    )
{
    AMTRACE((TEXT("GetSourceRectFromMediaType")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        return NULL;
    }

    if (!(pMediaType->pbFormat))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType->pbFormat is NULL")));
        return NULL;
    }

    LPRECT lpRect = NULL;
    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        lpRect = &(((VIDEOINFOHEADER*)(pMediaType->pbFormat))->rcSource);
    }
    else if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
             (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        lpRect = &(((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->rcSource);
    }

    return lpRect;

}

/*****************************Private*Routine******************************\
* GetbmiHeader
*
* Returns the bitmap info header associated with the specified CMediaType.
* Returns NULL if the CMediaType is not either of FORMAT_VideoInfo or
* FORMAT_VideoInfo2.
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
LPBITMAPINFOHEADER
GetbmiHeader(
    const AM_MEDIA_TYPE *pMediaType
    )
{
    AMTRACE((TEXT("GetbmiHeader")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        return NULL;
    }

    if (!(pMediaType->pbFormat))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType->pbFormat is NULL")));
        return NULL;
    }

    LPBITMAPINFOHEADER lpHeader = NULL;
    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        lpHeader = &(((VIDEOINFOHEADER*)(pMediaType->pbFormat))->bmiHeader);
    }
    else if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
             (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        lpHeader = &(((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->bmiHeader);
    }

    return lpHeader;
}

/*****************************Private*Routine******************************\
* AllocVideoMediaType
*
* This comes in useful when using the IEnumMediaTypes interface so
* that you can copy a media type, you can do nearly the same by creating
* a CMediaType object but as soon as it goes out of scope the destructor
* will delete the memory it allocated (this takes a copy of the memory)
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
AllocVideoMediaType(
    const AM_MEDIA_TYPE *pmtSource,
    AM_MEDIA_TYPE** ppmt
    )
{
    AMTRACE((TEXT("AllocVideoMediaType")));
    DWORD dwFormatSize = 0;
    BYTE *pFormatPtr = NULL;
    AM_MEDIA_TYPE *pMediaType = NULL;
    HRESULT hr = NOERROR;

    if (pmtSource->formattype == FORMAT_VideoInfo)
        dwFormatSize = sizeof(VIDEOINFO);
    else if (pmtSource->formattype == FORMAT_VideoInfo2)
        dwFormatSize = sizeof(TRUECOLORINFO) + sizeof(VIDEOINFOHEADER2) + 4;

    // actually this should be sizeof sizeof(VIDEOINFO2) once we define that

    pMediaType = (AM_MEDIA_TYPE *)CoTaskMemAlloc(sizeof(AM_MEDIA_TYPE));
    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("Out of memory!!")));
        return E_OUTOFMEMORY;
    }

    pFormatPtr = (BYTE *)CoTaskMemAlloc(dwFormatSize);
    if (!pFormatPtr)
    {
        CoTaskMemFree((PVOID)pMediaType);
        DbgLog((LOG_ERROR, 1, TEXT("Out of memory!!")));
        return E_OUTOFMEMORY;
    }

    *pMediaType = *pmtSource;
    pMediaType->cbFormat = dwFormatSize;
    CopyMemory(pFormatPtr, pmtSource->pbFormat, pmtSource->cbFormat);

    pMediaType->pbFormat = pFormatPtr;
    *ppmt = pMediaType;
    return S_OK;
}


/*****************************Private*Routine******************************\
* ConvertSurfaceDescToMediaType
*
* Helper function converts a DirectDraw surface to a media type.
* The surface description must have:
*   Height
*   Width
*   lPitch
*   PixelFormat
*
* Initialise our output type based on the DirectDraw surface. As DirectDraw
* only deals with top down display devices so we must convert the height of
* the surface returned in the DDSURFACEDESC into a negative height. This is
* because DIBs use a positive height to indicate a bottom up image. We also
* initialise the other VIDEOINFO fields although they're hardly ever needed
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
ConvertSurfaceDescToMediaType(
    const LPDDSURFACEDESC2 pSurfaceDesc,
    const AM_MEDIA_TYPE* pTemplateMediaType,
    AM_MEDIA_TYPE** ppMediaType
    )
{
    AMTRACE((TEXT("ConvertSurfaceDescToMediaType")));
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pbmiHeader = NULL;
    *ppMediaType = NULL;

    if ((pTemplateMediaType->formattype != FORMAT_VideoInfo ||
        pTemplateMediaType->cbFormat < sizeof(VIDEOINFOHEADER)) &&
        (pTemplateMediaType->formattype != FORMAT_VideoInfo2 ||
        pTemplateMediaType->cbFormat < sizeof(VIDEOINFOHEADER2)))
    {
        return NULL;
    }

    hr = AllocVideoMediaType(pTemplateMediaType, ppMediaType);
    if (FAILED(hr)) {
        return hr;
    }

    pbmiHeader = GetbmiHeader((const CMediaType*)*ppMediaType);
    if (!pbmiHeader)
    {
        FreeMediaType(**ppMediaType);
        DbgLog((LOG_ERROR, 1, TEXT("pbmiHeader is NULL, UNEXPECTED!!")));
        return E_FAIL;
    }

    //
    // Convert a DDSURFACEDESC2 into a BITMAPINFOHEADER (see notes later). The
    // bit depth of the surface can be retrieved from the DDPIXELFORMAT field
    // in the DDpSurfaceDesc-> The documentation is a little misleading because
    // it says the field is permutations of DDBD_*'s however in this case the
    // field is initialised by DirectDraw to be the actual surface bit depth
    //

    pbmiHeader->biSize = sizeof(BITMAPINFOHEADER);

    if (pSurfaceDesc->dwFlags & DDSD_PITCH)
    {
        pbmiHeader->biWidth = pSurfaceDesc->lPitch;

        // Convert the pitch from a byte count to a pixel count.
        // For some weird reason if the format is not a standard bit depth the
        // width field in the BITMAPINFOHEADER should be set to the number of
        // bytes instead of the width in pixels. This supports odd YUV formats
        // like IF09 which uses 9bpp.
        //

        int bpp = pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount;
        if (bpp == 8 || bpp == 16 || bpp == 24 || bpp == 32)
        {
            pbmiHeader->biWidth /= (bpp / 8); // Divide by number of BYTES per pixel.
        }
    }
    else
    {
        pbmiHeader->biWidth = pSurfaceDesc->dwWidth;
        // BUGUBUG -- Do something odd here with strange YUV pixel formats?
        // Or does it matter?
    }

    pbmiHeader->biHeight        = -(LONG)pSurfaceDesc->dwHeight;
    pbmiHeader->biPlanes        = 1;
    pbmiHeader->biBitCount      = (USHORT)pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount;
    pbmiHeader->biCompression   = pSurfaceDesc->ddpfPixelFormat.dwFourCC;
    pbmiHeader->biClrUsed       = 0;
    pbmiHeader->biClrImportant  = 0;


    // For true colour RGB formats tell the source there are bit
    // fields. But preserve BI_RGB from source (pTemplateMediaType) if
    // it's the standard mask.
    if (pbmiHeader->biCompression == BI_RGB)
    {
        BITMAPINFOHEADER *pbmiHeaderTempl = GetbmiHeader(pTemplateMediaType);
        if (pbmiHeader->biBitCount == 16 || pbmiHeader->biBitCount == 32)
        {
            if(pbmiHeaderTempl->biCompression == BI_BITFIELDS ||

               pbmiHeader->biBitCount == 32 &&
               !(0x00FF0000 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                 0x0000FF00 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                 0x000000FF == pSurfaceDesc->ddpfPixelFormat.dwBBitMask) ||

               pbmiHeader->biBitCount == 16 &&
               !((0x1f<<10) == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                 (0x1f<< 5) == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                 (0x1f<< 0) == pSurfaceDesc->ddpfPixelFormat.dwBBitMask))
            {
                pbmiHeader->biCompression = BI_BITFIELDS;
            }
        }
    }

    if (pbmiHeader->biBitCount <= iPALETTE)
    {
        pbmiHeader->biClrUsed = 1 << pbmiHeader->biBitCount;
    }

    pbmiHeader->biSizeImage = DIBSIZE(*pbmiHeader);



    // The RGB bit fields are in the same place as for YUV formats
    if (pbmiHeader->biCompression != BI_RGB)
    {
        DWORD *pdwBitMasks = NULL;
        pdwBitMasks = (DWORD*)GetBitMasks(pbmiHeader);
        ASSERT(pdwBitMasks);
        // GetBitMasks only returns the pointer to the actual bitmasks
        // in the mediatype if biCompression == BI_BITFIELDS
        pdwBitMasks[0] = pSurfaceDesc->ddpfPixelFormat.dwRBitMask;
        pdwBitMasks[1] = pSurfaceDesc->ddpfPixelFormat.dwGBitMask;
        pdwBitMasks[2] = pSurfaceDesc->ddpfPixelFormat.dwBBitMask;
    }

    // And finish it off with the other media type fields
    // The sub-type can fall into one of the following categories.
    //
    // 1. Some kind of DX7 D3D render target - with or without ALPHA
    // 2. Some kind of Alpha format - RGB or YUV
    // 3. Standard 4CC (YUV)
    // 4. Standard RGB

    (*ppMediaType)->subtype = GetBitmapSubtype(pbmiHeader);

    //
    // Look for 3D devices
    //
    if (pSurfaceDesc->ddsCaps.dwCaps & DDSCAPS_3DDEVICE) {

        //
        // We only support RGB Render Targets for now.
        //

        if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_RGB) {

            if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_ALPHAPIXELS) {

                switch (pbmiHeader->biBitCount) {
                case 32:
                    ASSERT(0x00FF0000 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                           0x0000FF00 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                           0x000000FF == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                    (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB32_D3D_DX7_RT;
                    break;

                case 16:
                    switch (pSurfaceDesc->ddpfPixelFormat.dwRGBAlphaBitMask) {
                    case 0X8000:
                        ASSERT((0x1f<<10) == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                               (0x1f<< 5) == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                               (0x1f<< 0) == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                        (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB1555_D3D_DX7_RT;
                        break;

                    case 0XF000:
                        ASSERT(0x0F00 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                               0x00F0 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                               0x000F == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                        (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB4444_D3D_DX7_RT;
                        break;
                    }
                }
            }
            else {

                switch (pbmiHeader->biBitCount) {
                case 32:
                    (*ppMediaType)->subtype = MEDIASUBTYPE_RGB32_D3D_DX7_RT;
                    break;

                case 16:
                    (*ppMediaType)->subtype = MEDIASUBTYPE_RGB16_D3D_DX7_RT;
                    break;
                }
            }
        }

    }

    //
    // Look for per-pixel alpha formats
    //

    else if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_ALPHAPIXELS) {

        //
        // Is it RGB ?
        //

        if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_RGB) {

            switch (pbmiHeader->biBitCount) {
            case 32:
                ASSERT(0x00FF0000 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                       0x0000FF00 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                       0x000000FF == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB32;
                break;

            case 16:
                switch (pSurfaceDesc->ddpfPixelFormat.dwRGBAlphaBitMask) {
                case 0X8000:
                    ASSERT((0x1f<<10) == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                           (0x1f<< 5) == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                           (0x1f<< 0) == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                    (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB1555;
                    break;

                case 0XF000:
                    ASSERT(0x0f00 == pSurfaceDesc->ddpfPixelFormat.dwRBitMask &&
                           0x00f0 == pSurfaceDesc->ddpfPixelFormat.dwGBitMask &&
                           0x000f == pSurfaceDesc->ddpfPixelFormat.dwBBitMask);
                    (*ppMediaType)->subtype = MEDIASUBTYPE_ARGB4444;
                    break;
                }
            }
        }

        //
        // Is it YUV ?
        //

        else if (pSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_FOURCC) {

            switch (pbmiHeader->biBitCount) {
            case 32:
                ASSERT(0xFF000000 == pSurfaceDesc->ddpfPixelFormat.dwYUVAlphaBitMask &&
                       0x00FF0000 == pSurfaceDesc->ddpfPixelFormat.dwYBitMask &&
                       0x0000FF00 == pSurfaceDesc->ddpfPixelFormat.dwUBitMask &&
                       0x000000FF == pSurfaceDesc->ddpfPixelFormat.dwVBitMask);
                (*ppMediaType)->subtype = MEDIASUBTYPE_AYUV;
                break;
            }
        }
    }

    (*ppMediaType)->lSampleSize = pbmiHeader->biSizeImage;

    // set the src and dest rects if necessary
    if ((*ppMediaType)->formattype == FORMAT_VideoInfo)
    {
        VIDEOINFOHEADER *pVideoInfo = (VIDEOINFOHEADER *)(*ppMediaType)->pbFormat;
        VIDEOINFOHEADER *pSrcVideoInfo = (VIDEOINFOHEADER *)pTemplateMediaType->pbFormat;

        // if the surface allocated is different than the size specified by the decoder
        // then use the src and dest to ask the decoder to clip the video
        if ((abs(pVideoInfo->bmiHeader.biHeight) != abs(pSrcVideoInfo->bmiHeader.biHeight)) ||
            (abs(pVideoInfo->bmiHeader.biWidth) != abs(pSrcVideoInfo->bmiHeader.biWidth)))
        {
            if (IsRectEmpty(&(pVideoInfo->rcSource)))
            {
                pVideoInfo->rcSource.left = pVideoInfo->rcSource.top = 0;
                pVideoInfo->rcSource.right = abs(pSrcVideoInfo->bmiHeader.biWidth);
                pVideoInfo->rcSource.bottom = abs(pSrcVideoInfo->bmiHeader.biHeight);
            }
            if (IsRectEmpty(&(pVideoInfo->rcTarget)))
            {
                pVideoInfo->rcTarget.left = pVideoInfo->rcTarget.top = 0;
                pVideoInfo->rcTarget.right = abs(pSrcVideoInfo->bmiHeader.biWidth);
                pVideoInfo->rcTarget.bottom = abs(pSrcVideoInfo->bmiHeader.biHeight);
            }
        }
    }
    else if ((*ppMediaType)->formattype == FORMAT_VideoInfo2)
    {
        VIDEOINFOHEADER2 *pVideoInfo2 = (VIDEOINFOHEADER2 *)(*ppMediaType)->pbFormat;
        VIDEOINFOHEADER2 *pSrcVideoInfo2 = (VIDEOINFOHEADER2 *)pTemplateMediaType->pbFormat;

        // if the surface allocated is different than the size specified by the decoder
        // then use the src and dest to ask the decoder to clip the video
        if ((abs(pVideoInfo2->bmiHeader.biHeight) != abs(pSrcVideoInfo2->bmiHeader.biHeight)) ||
            (abs(pVideoInfo2->bmiHeader.biWidth) != abs(pSrcVideoInfo2->bmiHeader.biWidth)))
        {
            if (IsRectEmpty(&(pVideoInfo2->rcSource)))
            {
                pVideoInfo2->rcSource.left = pVideoInfo2->rcSource.top = 0;
                pVideoInfo2->rcSource.right = abs(pSrcVideoInfo2->bmiHeader.biWidth);
                pVideoInfo2->rcSource.bottom = abs(pSrcVideoInfo2->bmiHeader.biHeight);
            }

            if (IsRectEmpty(&(pVideoInfo2->rcTarget)))
            {
                pVideoInfo2->rcTarget.left = pVideoInfo2->rcTarget.top = 0;
                pVideoInfo2->rcTarget.right = abs(pSrcVideoInfo2->bmiHeader.biWidth);
                pVideoInfo2->rcTarget.bottom = abs(pSrcVideoInfo2->bmiHeader.biHeight);
            }
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* VMRCopyFourCC
*
*
*
* History:
* Fri 01/19/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
VMRCopyFourCC(
    LPDIRECTDRAWSURFACE7 lpDst,
    LPDIRECTDRAWSURFACE7 lpSrc
    )
{
    bool fDstLocked = false;
    bool fSrcLocked = false;

    DDSURFACEDESC2 ddsdS = {sizeof(DDSURFACEDESC2)};
    DDSURFACEDESC2 ddsdD = {sizeof(DDSURFACEDESC2)};
    HRESULT hr = E_FAIL;

    __try {

        CHECK_HR(hr = lpDst->Lock(NULL, &ddsdD, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL));
        fDstLocked = true;

        CHECK_HR(hr = lpSrc->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL));
        fSrcLocked = true;

        ASSERT(ddsdS.ddpfPixelFormat.dwFourCC == ddsdD.ddpfPixelFormat.dwFourCC);
        ASSERT(ddsdS.ddpfPixelFormat.dwRGBBitCount == ddsdD.ddpfPixelFormat.dwRGBBitCount);
        ASSERT(ddsdS.lPitch == ddsdD.lPitch);

        LPBYTE pSrc = (LPBYTE)ddsdS.lpSurface;
        LPBYTE pDst = (LPBYTE)ddsdD.lpSurface;

        switch (ddsdS.ddpfPixelFormat.dwFourCC) {

        // planar 4:2:0 formats
        case mmioFOURCC('Y','V','1','2'):
        case mmioFOURCC('I','4','2','0'):
        case mmioFOURCC('I','Y','U','V'): {

                LONG lSize  = (3 * ddsdS.lPitch * ddsdS.dwHeight) / 2;
                CopyMemory(pDst, pSrc, lSize);
            }
            break;

        // RGB formats - fall thru to packed YUV case
        case 0:
            ASSERT((ddsdS.dwFlags & DDPF_RGB) == DDPF_RGB);

        // packed 4:2:2 formats
        case mmioFOURCC('Y','U','Y','2'):
        case mmioFOURCC('U','Y','V','Y'): {

                LONG lSize  = ddsdS.lPitch * ddsdS.dwHeight;
                CopyMemory(pDst, pSrc, lSize);
            }
            break;
        }

    }
    __finally {

        if (fDstLocked) {
            lpDst->Unlock(NULL);
        }

        if (fSrcLocked) {
            lpSrc->Unlock(NULL);
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* AlphaPalPaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
AlphaPalPaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("AlphaPalPaintSurfaceBlack")));

    DDBLTFX ddFX;
    ZeroMemory(&ddFX, sizeof(ddFX));
    ddFX.dwSize = sizeof(ddFX);
    return pDDrawSurface->Blt(NULL, NULL, NULL, DDBLT_COLORFILL | DDBLT_WAIT, &ddFX);
}


/*****************************Private*Routine******************************\
* YV12PaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
YV12PaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("YV12PaintSurfaceBlack")));
    HRESULT hr = NOERROR;
    DDSURFACEDESC2 ddsd;

    // now lock the surface so we can start filling the surface with black
    ddsd.dwSize = sizeof(ddsd);
    hr = pDDrawSurface->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL);
    if (hr == DD_OK)
    {
        DWORD y;
        LPBYTE pDst = (LPBYTE)ddsd.lpSurface;
        LONG  OutStride = ddsd.lPitch;
        DWORD VSize = ddsd.dwHeight;
        DWORD HSize = ddsd.dwWidth;

        // Y Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x10);     // 1 line at a time
            pDst += OutStride;
        }

        HSize /= 2;
        VSize /= 2;
        OutStride /= 2;

        // Cb Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        // Cr Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        pDDrawSurface->Unlock(NULL);
    }

    return hr;
}

/*****************************Private*Routine******************************\
* NV12PaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
NV12PaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("NV12PaintSurfaceBlack")));
    HRESULT hr = NOERROR;
    DDSURFACEDESC2 ddsd;

    // now lock the surface so we can start filling the surface with black
    ddsd.dwSize = sizeof(ddsd);
    hr = pDDrawSurface->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL);
    if (hr == DD_OK)
    {
        DWORD y;
        LPBYTE pDst = (LPBYTE)ddsd.lpSurface;
        LONG  OutStride = ddsd.lPitch;
        DWORD VSize = ddsd.dwHeight;
        DWORD HSize = ddsd.dwWidth;

        // Y Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x10);     // 1 line at a time
            pDst += OutStride;
        }

        VSize /= 2;

        // Cb and Cr components are interleaved together
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        pDDrawSurface->Unlock(NULL);
    }

    return hr;
}


/*****************************Private*Routine******************************\
* IMC1andIMC3PaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
IMC1andIMC3PaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("IMC1andIMC3PaintSurfaceBlack")));

    // DDBLTFX ddFX;
    // INITDDSTRUCT(ddFX);
    // //                    V U Y A
    // ddFX.dwFillColor = 0x80801000;
    // return pDDrawSurface->Blt(NULL, NULL, NULL, DDBLT_COLORFILL, &ddFX);

    HRESULT hr = NOERROR;
    DDSURFACEDESC2 ddsd;

    // now lock the surface so we can start filling the surface with black
    ddsd.dwSize = sizeof(ddsd);


    hr = pDDrawSurface->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL);
    if (hr == DD_OK)
    {
        DWORD y;
        LPBYTE pDst = (LPBYTE)ddsd.lpSurface;
        LONG  OutStride = ddsd.lPitch;
        DWORD VSize = ddsd.dwHeight;
        DWORD HSize = ddsd.dwWidth;

        // Y Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x10);     // 1 line at a time
            pDst += OutStride;
        }

        HSize /= 2;
        VSize /= 2;

        // Cb Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        // Cr Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        pDDrawSurface->Unlock(NULL);
    }

    return hr;
}


/******************************Public*Routine******************************\
* YUV16PaintSurfaceBlack
*
*
*
* History:
* Wed 09/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
YUV16PaintSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pdds,
    DWORD dwBlack
    )
{
    AMTRACE((TEXT("YUV16PaintSurfaceBlack")));
    HRESULT hr = NOERROR;
    DDSURFACEDESC2 ddsd;

    // now lock the surface so we can start filling the surface with black
    ddsd.dwSize = sizeof(ddsd);

    for ( ;; ) {

        hr = pdds->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL);

        if (hr == DD_OK || hr != DDERR_WASSTILLDRAWING) {
            break;
        }

        Sleep(1);
    }

    if (hr == DD_OK)
    {
        DWORD y, x;
        LPDWORD pDst = (LPDWORD)ddsd.lpSurface;
        LONG  OutStride = ddsd.lPitch;

        for (y = 0; y < ddsd.dwHeight; y++) {

            for (x = 0; x < ddsd.dwWidth / 2; x++) {
                pDst[x] = dwBlack;
            }

            // Dont forget that the stride is a byte count
            *((LPBYTE*)&pDst) += OutStride;
        }

        pdds->Unlock(NULL);
    }

    return hr;
}


/*****************************Private*Routine******************************\
* BlackPaintProc
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
BlackPaintProc(
    LPDIRECTDRAWSURFACE7 pDDrawSurface,
    DDSURFACEDESC2* lpddSurfaceDesc
    )
{
    AMTRACE((TEXT("BlackPaintProc")));

    //
    // If the surface is YUV take care of the types that we
    // know the pixel format for.  Those surfaces that we don't know
    // about will get painted '0' which may be bright green for
    // YUV surfaces.
    //

    if (lpddSurfaceDesc->ddpfPixelFormat.dwFlags & DDPF_FOURCC) {

        //
        // compute the black value if the fourCC code is suitable,
        // otherwise can't handle it
        //

        switch (lpddSurfaceDesc->ddpfPixelFormat.dwFourCC) {

        case mmioFOURCC('I','A','4','4'):
        case mmioFOURCC('A','I','4','4'):
            return AlphaPalPaintSurfaceBlack(pDDrawSurface);

        case mmioFOURCC('I','M','C','1'):
        case mmioFOURCC('I','M','C','3'):
            return IMC1andIMC3PaintSurfaceBlack(pDDrawSurface);

        case mmioFOURCC('Y','V','1','2'):
        case mmioFOURCC('I','4','2','0'):
        case mmioFOURCC('I','Y','U','V'):
            return YV12PaintSurfaceBlack(pDDrawSurface);

        case mmioFOURCC('N','V','1','2'):
        case mmioFOURCC('N','V','2','1'):
            return NV12PaintSurfaceBlack(pDDrawSurface);

        case mmioFOURCC('Y','U','Y','2'):
            return YUV16PaintSurfaceBlack(pDDrawSurface, 0x80108010);

        case mmioFOURCC('U','Y','V','Y'):
            return YUV16PaintSurfaceBlack(pDDrawSurface, 0x10801080);
        }

        return E_FAIL;
    }

    DDBLTFX ddFX;
    INITDDSTRUCT(ddFX);
    return pDDrawSurface->Blt(NULL, NULL, NULL, DDBLT_COLORFILL, &ddFX);
}



/*****************************Private*Routine******************************\
* PaintSurfaceBlack
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
PaintDDrawSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    )
{
    AMTRACE((TEXT("PaintDDrawSurfaceBlack")));

    LPDIRECTDRAWSURFACE7 *ppDDrawSurface = NULL;
    DDSCAPS2 ddSurfaceCaps;
    DDSURFACEDESC2 ddSurfaceDesc;
    DWORD dwAllocSize;
    DWORD i = 0, dwBackBufferCount = 0;

    // get the surface description
    INITDDSTRUCT(ddSurfaceDesc);
    HRESULT hr = pDDrawSurface->GetSurfaceDesc(&ddSurfaceDesc);
    if (SUCCEEDED(hr)) {

        if (ddSurfaceDesc.dwFlags & DDSD_BACKBUFFERCOUNT) {
            dwBackBufferCount = ddSurfaceDesc.dwBackBufferCount;
        }

        hr = BlackPaintProc(pDDrawSurface, &ddSurfaceDesc);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,1,
                    TEXT("pDDrawSurface->Blt failed, hr = 0x%x"), hr));
            return hr;
        }

        if (dwBackBufferCount > 0) {

            dwAllocSize = (dwBackBufferCount + 1) * sizeof(LPDIRECTDRAWSURFACE);
            ppDDrawSurface = (LPDIRECTDRAWSURFACE7*)_alloca(dwAllocSize);

            ZeroMemory(ppDDrawSurface, dwAllocSize);
            ZeroMemory(&ddSurfaceCaps, sizeof(ddSurfaceCaps));
            ddSurfaceCaps.dwCaps = DDSCAPS_FLIP | DDSCAPS_COMPLEX;

            if( DDSCAPS_OVERLAY & ddSurfaceDesc.ddsCaps.dwCaps ) {
                ddSurfaceCaps.dwCaps |= DDSCAPS_OVERLAY;
            }

            for (i = 0; i < dwBackBufferCount; i++) {

                LPDIRECTDRAWSURFACE7 pCurrentDDrawSurface = NULL;
                if (i == 0) {
                    pCurrentDDrawSurface = pDDrawSurface;
                }
                else {
                    pCurrentDDrawSurface = ppDDrawSurface[i];
                }
                ASSERT(pCurrentDDrawSurface);


                //
                // Get the back buffer surface and store it in the
                // next (in the circular sense) entry
                //

                hr = pCurrentDDrawSurface->GetAttachedSurface(
                        &ddSurfaceCaps,
                        &ppDDrawSurface[i + 1]);

                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR,1,
                            TEXT("Function pDDrawSurface->GetAttachedSurface ")
                            TEXT("failed, hr = 0x%x"), hr ));
                    break;
                }

                ASSERT(ppDDrawSurface[i+1]);

                //
                // Peform a DirectDraw colorfill BLT
                //

                hr = BlackPaintProc(ppDDrawSurface[i + 1], &ddSurfaceDesc);
                if (FAILED(hr)) {
                    DbgLog((LOG_ERROR,1,
                            TEXT("ppDDrawSurface[i + 1]->Blt failed, ")
                            TEXT("hr = 0x%x"), hr));
                    break;
                }
            }
        }
    }

    if (ppDDrawSurface) {
        for (i = 0; i < dwBackBufferCount + 1; i++) {
            if (ppDDrawSurface[i]) {
                ppDDrawSurface[i]->Release();
            }
        }
    }

    if (hr != DD_OK) {
        DbgLog((LOG_ERROR, 1, TEXT("PaintSurfaceBlack failed")));
        hr = S_OK;
    }

    return hr;
}


/*****************************Private*Routine******************************\
* GetImageAspectRatio
*
*
*
* History:
* Tue 03/07/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetImageAspectRatio(
    const AM_MEDIA_TYPE* pMediaType,
    long* lpARWidth,
    long* lpARHeight
    )
{
    AMTRACE((TEXT("GetImageAspectRatio")));

    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        VIDEOINFOHEADER* pVideoInfo = (VIDEOINFOHEADER*)(pMediaType->pbFormat);

        long Width;
        long Height;

        LPRECT lprc = &pVideoInfo->rcTarget;
        if (IsRectEmpty(lprc)) {
            Width  = abs(pVideoInfo->bmiHeader.biWidth);
            Height = abs(pVideoInfo->bmiHeader.biHeight);
        }
        else {
            Width  = WIDTH(lprc);
            Height = HEIGHT(lprc);
        }

        *lpARWidth = Width;
        *lpARHeight = Height;

        return S_OK;
    }

    if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        const VIDEOINFOHEADER2& header = *(VIDEOINFOHEADER2*)(pMediaType->pbFormat);


        if( header.dwControlFlags & AMCONTROL_PAD_TO_16x9 ) {
            *lpARWidth = 16;
            *lpARHeight = 9;
        } else if( header.dwControlFlags & AMCONTROL_PAD_TO_4x3 ) {
            *lpARWidth = 4;
            *lpARHeight = 3;
        } else {
            *lpARWidth = header.dwPictAspectRatioX;
            *lpARHeight = header.dwPictAspectRatioY;
        }
        return S_OK;
    }

    DbgLog((LOG_ERROR, 1, TEXT("MediaType does not contain AR info!!")));
    return E_FAIL;

}


/*****************************Private*Routine******************************\
* D3DEnumDevicesCallback7
*
*
*
* History:
* Wed 07/19/2000 - StEstrop - Created
*
\**************************************************************************/

HRESULT CALLBACK
D3DEnumDevicesCallback7(
    LPSTR lpDeviceDescription,
    LPSTR lpDeviceName,
    LPD3DDEVICEDESC7 lpD3DDeviceDesc,
    LPVOID lpContext
    )
{
    AMTRACE((TEXT("D3DEnumDevicesCallback7")));
    DWORD* ps = (DWORD*)lpContext;

    if (lpD3DDeviceDesc->deviceGUID == IID_IDirect3DHALDevice) {

        if (lpD3DDeviceDesc->dpcTriCaps.dwTextureCaps & D3DPTEXTURECAPS_TRANSPARENCY) {
            *ps |= TXTR_SRCKEY;
        }

        if (!(lpD3DDeviceDesc->dpcTriCaps.dwTextureCaps & D3DPTEXTURECAPS_NONPOW2CONDITIONAL)) {
            *ps |= TXTR_POWER2;
        }

        if (lpD3DDeviceDesc->dwDevCaps & D3DDEVCAPS_TEXTURENONLOCALVIDMEM) {
            *ps |= (TXTR_AGPYUVMEM | TXTR_AGPRGBMEM);
        }
    }

    return (HRESULT) D3DENUMRET_OK;
}


/*****************************Private*Routine******************************\
* GetTextureCaps
*
*
*
* History:
* Wed 07/19/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetTextureCaps(
    LPDIRECTDRAW7 pDD,
    DWORD* ptc
    )
{
    AMTRACE((TEXT("GetTextureCaps")));
    LPDIRECT3D7 pD3D = NULL;

    DDCAPS_DX7 ddCaps;
    INITDDSTRUCT(ddCaps);

    *ptc = 0;
    HRESULT hr = pDD->GetCaps((LPDDCAPS)&ddCaps, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = pDD->QueryInterface(IID_IDirect3D7, (LPVOID *)&pD3D);

    if (SUCCEEDED(hr)) {
        pD3D->EnumDevices(D3DEnumDevicesCallback7, (LPVOID)ptc);
    }

    //
    // Only turn on the AGPYUV flag if we can Blt from it as well
    // as texture
    //

    const DWORD dwCaps = (DDCAPS_BLTFOURCC | DDCAPS_BLTSTRETCH);
    if ((dwCaps & ddCaps.dwNLVBCaps) != dwCaps) {
        *ptc &= ~TXTR_AGPYUVMEM;
    }

    RELEASE(pD3D);
    return hr;
}

/*****************************Private*Routine******************************\
* DDColorMatch
*
* convert a RGB color to a pysical color.
* we do this by leting GDI SetPixel() do the color matching
* then we lock the memory and see what it got mapped to.
*
* Static function since only called from DDColorMatchOffscreen
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
DWORD
DDColorMatch(
    IDirectDrawSurface7 *pdds,
    COLORREF rgb,
    HRESULT& hr
    )
{
    AMTRACE((TEXT("DDColorMatch")));
    COLORREF rgbT;
    HDC hdc;
    DWORD dw = CLR_INVALID;
    DDSURFACEDESC2 ddsd;

    //  use GDI SetPixel to color match for us
    if (rgb != CLR_INVALID && pdds->GetDC(&hdc) == DD_OK)
    {
        rgbT = GetPixel(hdc, 0, 0);             // save current pixel value
        SetPixel(hdc, 0, 0, rgb);               // set our value
        pdds->ReleaseDC(hdc);
    }

    // now lock the surface so we can read back the converted color
    ddsd.dwSize = sizeof(ddsd);
    while( (hr = pdds->Lock(NULL, &ddsd, 0, NULL)) == DDERR_WASSTILLDRAWING) {
        // yield to the next thread (or return if we're the highest priority)
        Sleep(0);
    }
    if (hr == DD_OK)
    {
        // get DWORD
        dw  = *(DWORD *)ddsd.lpSurface;

        // mask it to bpp
        if (ddsd.ddpfPixelFormat.dwRGBBitCount < 32)
            dw &= (1 << ddsd.ddpfPixelFormat.dwRGBBitCount)-1;
        pdds->Unlock(NULL);
    }

    //  now put the color that was there back.
    if (rgb != CLR_INVALID && pdds->GetDC(&hdc) == DD_OK)
    {
        SetPixel(hdc, 0, 0, rgbT);
        pdds->ReleaseDC(hdc);
    }

    return dw;
}

/******************************Public*Routine******************************\
* GetInterlaceFlagsFromMediaType
*
* Get the InterlaceFlags from the mediatype. If the format is VideoInfo,
* it returns the flags as zero.
*
* History:
* Mon 01/08/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetInterlaceFlagsFromMediaType(
    const AM_MEDIA_TYPE *pMediaType,
    DWORD *pdwInterlaceFlags
    )
{
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pHeader = NULL;

    AMTRACE((TEXT("GetInterlaceFlagsFromMediaType")));

    __try {

        if (!pMediaType)
        {
            DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
            hr = E_INVALIDARG;
            __leave;
        }

        if (!pdwInterlaceFlags)
        {
            DbgLog((LOG_ERROR, 1, TEXT("pdwInterlaceFlags is NULL")));
            hr = E_INVALIDARG;
            __leave;
        }

        // get the header just to make sure the mediatype is ok
        pHeader = GetbmiHeader(pMediaType);
        if (!pHeader)
        {
            DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
            hr = E_INVALIDARG;
            __leave;
        }

        if (pMediaType->formattype == FORMAT_VideoInfo)
        {
            *pdwInterlaceFlags = 0;
        }
        else if (pMediaType->formattype == FORMAT_VideoInfo2)
        {
            *pdwInterlaceFlags = ((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->dwInterlaceFlags;
        }
    }
    __finally {
    }

    return hr;
}

/*****************************Private*Routine******************************\
* NeedToFlipOddEven
*
* given the interlace flags and the type-specific flags, this function
* determines whether we are supposed to display the sample in bob-mode or not.
* It also tells us, which direct-draw flag are we supposed to use when
* flipping. When displaying an interleaved frame, it assumes we are
* talking about the field which is supposed to be displayed first.
*
* History:
* Mon 01/08/2001 - StEstrop - Created (from the OVMixer original)
*
\**************************************************************************/
BOOL
NeedToFlipOddEven(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags,
    DWORD *pdwFlipFlag,
    BOOL bUsingOverlays
    )
{
    AMTRACE((TEXT("NeedToFlipOddEven")));

    BOOL bDisplayField1 = TRUE;
    BOOL bField1IsOdd = TRUE;
    BOOL bNeedToFlipOddEven = FALSE;
    DWORD dwFlipFlag = 0;

    __try {

        // if not interlaced content, mode is not bob
        // if not using overlay nothing to do either
        if (!(dwInterlaceFlags & AMINTERLACE_IsInterlaced) || !bUsingOverlays)
        {
            __leave;
        }
        // if sample have a single field, then check the field pattern
        if ((dwInterlaceFlags & AMINTERLACE_1FieldPerSample) &&
            (((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField1Only) ||
             ((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField2Only)))
        {
            bNeedToFlipOddEven = FALSE;
            __leave;
        }

        if (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOnly) ||
            (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOrWeave) &&
             (!(dwTypeSpecificFlags & AM_VIDEO_FLAG_WEAVE))))
        {
            // first determine which field do we want to display here
            if (dwInterlaceFlags & AMINTERLACE_1FieldPerSample)
            {
                // if we are in 1FieldPerSample mode, check which field is it
                ASSERT(((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1) ||
                    ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD2));
                bDisplayField1 = ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1);
            }
            else
            {
                // ok the sample is an interleaved frame
                ASSERT((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_INTERLEAVED_FRAME);
                bDisplayField1 = (dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD1FIRST);
            }

            bField1IsOdd = (dwInterlaceFlags & AMINTERLACE_Field1First);

            // if we displaying field 1 and field 1 is odd or we are displaying field2 and field 2 is odd
            // then use DDFLIP_ODD. Exactly the opposite for DDFLIP_EVEN
            if ((bDisplayField1 && bField1IsOdd) || (!bDisplayField1 && !bField1IsOdd))
                dwFlipFlag = DDFLIP_ODD;
            else
                dwFlipFlag = DDFLIP_EVEN;

            bNeedToFlipOddEven = TRUE;
        }
    }
    __finally {
        if (pdwFlipFlag) {
            *pdwFlipFlag = dwFlipFlag;
        }
    }

    return bNeedToFlipOddEven;
}

/******************************Public*Routine******************************\
* GetVideoDescFromMT
*
*
*
* History:
* 3/15/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetVideoDescFromMT(
    LPDXVA_VideoDesc lpVideoDesc,
    const AM_MEDIA_TYPE *pMT
    )
{
    LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pMT);
    DXVA_VideoDesc& VideoDesc = *lpVideoDesc;

    //
    // we can't create a valid VideoDesc from RGB content.
    //
    if (lpHdr->biCompression <= BI_BITFIELDS) {
        return E_FAIL;
    }

    VideoDesc.Size = sizeof(DXVA_VideoDesc);
    VideoDesc.SampleWidth = abs(lpHdr->biWidth);
    VideoDesc.SampleHeight = abs(lpHdr->biHeight);


    //
    // determine the sample format from the interlace flags
    // the MT interlace flags are a total disater!
    //

    if (pMT->formattype == FORMAT_VideoInfo)
    {
        VideoDesc.SampleFormat = DXVA_SampleProgressiveFrame;
    }
    else if (pMT->formattype == FORMAT_VideoInfo2)
    {
        DWORD& dwInterlaceFlags =
            ((VIDEOINFOHEADER2*)(pMT->pbFormat))->dwInterlaceFlags;

        if (dwInterlaceFlags & AMINTERLACE_IsInterlaced) {

            if (dwInterlaceFlags & AMINTERLACE_1FieldPerSample) {

                if (dwInterlaceFlags & AMINTERLACE_Field1First) {
                    VideoDesc.SampleFormat= DXVA_SampleFieldSingleEven;
                }
                else {
                    VideoDesc.SampleFormat= DXVA_SampleFieldSingleOdd;
                }
            }
            else {

                if (dwInterlaceFlags & AMINTERLACE_Field1First) {
                    VideoDesc.SampleFormat= DXVA_SampleFieldInterleavedEvenFirst;
                }
                else {
                    VideoDesc.SampleFormat= DXVA_SampleFieldInterleavedOddFirst;
                }
            }
        }
        else {
            VideoDesc.SampleFormat = DXVA_SampleProgressiveFrame;
        }
    }


    VideoDesc.d3dFormat = lpHdr->biCompression;

    //
    // Work out the frame rate from AvgTimePerFrame - there are 10,000,000
    // ref time ticks in a single second.
    //
    DWORD rtAvg = (DWORD)GetAvgTimePerFrame(pMT);

    //
    // look for the "interesting" cases ie 23.97, 24, 25, 29.97, 50 and 59.94
    //
    switch (rtAvg) {
    case 166833:    // 59.94    NTSC
        VideoDesc.InputSampleFreq.Numerator   = 60000;
        VideoDesc.InputSampleFreq.Denominator = 1001;
        break;

    case 200000:    // 50.00    PAL
        VideoDesc.InputSampleFreq.Numerator   = 50;
        VideoDesc.InputSampleFreq.Denominator = 1;
        break;

    case 333667:    // 29.97    NTSC
        VideoDesc.InputSampleFreq.Numerator   = 30000;
        VideoDesc.InputSampleFreq.Denominator = 1001;
        break;

    case 400000:    // 25.00    PAL
        VideoDesc.InputSampleFreq.Numerator   = 25;
        VideoDesc.InputSampleFreq.Denominator = 1;
        break;

    case 416667:    // 24.00    FILM
        VideoDesc.InputSampleFreq.Numerator   = 24;
        VideoDesc.InputSampleFreq.Denominator = 1;
        break;

    case 417188:    // 23.97    NTSC again
        VideoDesc.InputSampleFreq.Numerator   = 24000;
        VideoDesc.InputSampleFreq.Denominator = 1001;
        break;

    default:
        VideoDesc.InputSampleFreq.Numerator   = 10000000;
        VideoDesc.InputSampleFreq.Denominator = rtAvg;
        break;
    }


    if (VideoDesc.SampleFormat == DXVA_SampleFieldInterleavedEvenFirst ||
        VideoDesc.SampleFormat == DXVA_SampleFieldInterleavedOddFirst) {

        VideoDesc.OutputFrameFreq.Numerator   =
            2 * VideoDesc.InputSampleFreq.Numerator;
    }
    else {
        VideoDesc.OutputFrameFreq.Numerator   =
            VideoDesc.InputSampleFreq.Numerator;
    }
    VideoDesc.OutputFrameFreq.Denominator =
        VideoDesc.InputSampleFreq.Denominator;

    return S_OK;
}

/******************************Public*Routine******************************\
* IsSingleFieldPerSample
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
IsSingleFieldPerSample(
    DWORD dwFlags
    )
{
    const DWORD dwSingleField =
                (AMINTERLACE_IsInterlaced | AMINTERLACE_1FieldPerSample);

    return (dwSingleField == (dwSingleField & dwFlags));
}

/******************************Public*Routine******************************\
* GetAvgTimePerFrame
*
*
*
* History:
* Tue 03/26/2002 - StEstrop - Created
*
\**************************************************************************/
REFERENCE_TIME
GetAvgTimePerFrame(
    const AM_MEDIA_TYPE *pMT
    )
{
    if (pMT->formattype == FORMAT_VideoInfo)
    {
        VIDEOINFOHEADER* pVIH = (VIDEOINFOHEADER*)pMT->pbFormat;
        return pVIH->AvgTimePerFrame;

    }
    else if (pMT->formattype == FORMAT_VideoInfo2)
    {
        VIDEOINFOHEADER2* pVIH2 = (VIDEOINFOHEADER2*)pMT->pbFormat;
        return pVIH2->AvgTimePerFrame;

    }
    return (REFERENCE_TIME)0;
}


/******************************Public*Routine******************************\
* MapPool
*
*
*
* History:
* Wed 03/27/2002 - StEstrop - Created
*
\**************************************************************************/
DWORD
MapPool(
    DWORD Pool
    )
{
    switch (Pool) {
    case D3DPOOL_DEFAULT:
    case D3DPOOL_LOCALVIDMEM:
        Pool = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM | DDSCAPS_OFFSCREENPLAIN;
        break;

    case D3DPOOL_NONLOCALVIDMEM:
        Pool = DDSCAPS_VIDEOMEMORY | DDSCAPS_NONLOCALVIDMEM | DDSCAPS_OFFSCREENPLAIN;
        break;

    case D3DPOOL_MANAGED:
    case D3DPOOL_SYSTEMMEM:
    case D3DPOOL_SCRATCH:
    default:
        Pool = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_SYSTEMMEMORY;
        break;
    }

    return Pool;
}

/******************************Public*Routine******************************\
* MapInterlaceFlags
*
*
*
* History:
* Tue 03/26/2002 - StEstrop - Created
*
\**************************************************************************/
DXVA_SampleFormat
MapInterlaceFlags(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags
    )
{
    if (!(dwInterlaceFlags & AMINTERLACE_IsInterlaced)) {
        return DXVA_SampleProgressiveFrame;
    }

    BOOL bDisplayField1;

    if (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOnly) ||
        (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOrWeave) &&
         (!(dwTypeSpecificFlags & AM_VIDEO_FLAG_WEAVE))))
    {
        // first determine which field do we want to display here
        if (dwInterlaceFlags & AMINTERLACE_1FieldPerSample)
        {
            // if we are in 1FieldPerSample mode, check which field is it
            ASSERT(((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1) ||
                ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD2));
            bDisplayField1 = ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1);
            if (bDisplayField1) {
                return DXVA_SampleFieldSingleEven;
            }
            else {
                return DXVA_SampleFieldSingleOdd;
            }
        }
        else
        {
            // ok the sample is an interleaved frame
            ASSERT((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_INTERLEAVED_FRAME);
            bDisplayField1 = (dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD1FIRST);
            if (bDisplayField1) {
                return DXVA_SampleFieldInterleavedEvenFirst;
            }
            else {
                return DXVA_SampleFieldInterleavedOddFirst;
            }
        }
    }
    return DXVA_SampleProgressiveFrame;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\apcurrimg.cpp ===
/******************************Module*Header*******************************\
* Module Name: apCurrImg.cpp
*
* Collection of functions dedicated to retrieve the currently displayed image.
*
* Created: Sat 10/14/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"



/*****************************Private*Routine******************************\
* CopyRGBSurfToDIB
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyRGBSurfToDIB(
    LPBYTE* lpDib,
    LPDIRECTDRAWSURFACE7 lpRGBSurf
    )
{
    HRESULT hr = E_FAIL;
    LPBITMAPINFOHEADER lpbih = NULL;
    DDSURFACEDESC2 ddsd = {sizeof(ddsd)};

    __try {

        CHECK_HR(hr = lpRGBSurf->GetSurfaceDesc(&ddsd));

        ULONG ulBits = ddsd.dwWidth * ddsd.ddpfPixelFormat.dwRGBBitCount;
        ULONG ulStrideSrc = WIDTHBYTES(ulBits);

        ULONG ulStrideDst = ddsd.dwWidth * 4;
        ULONG ulSize = sizeof(BITMAPINFOHEADER) +
                        (ulStrideDst * ddsd.dwHeight);

        lpbih = (LPBITMAPINFOHEADER)CoTaskMemAlloc(ulSize);
        if (lpbih == NULL) {
            hr = E_OUTOFMEMORY;
            __leave;
        }

        lpbih->biSize = sizeof(BITMAPINFOHEADER);
        lpbih->biWidth = (LONG)ddsd.dwWidth;
        lpbih->biHeight = (LONG)ddsd.dwHeight;
        lpbih->biPlanes = 1;
        lpbih->biBitCount = 32;
        lpbih->biCompression = BI_RGB;
        lpbih->biSizeImage = ulStrideDst * ddsd.dwHeight;
        lpbih->biXPelsPerMeter = 0;
        lpbih->biYPelsPerMeter = 0;
        lpbih->biClrUsed = 0;
        lpbih->biClrImportant = 0;

        LPBYTE lpSrc;
        LPDWORD lpdwDst = ((LPDWORD)((LPBYTE)(lpbih) + (int)(lpbih)->biSize));

        //
        // We want an upside down DIB so offset the start of the
        // dst pointer to the last scan line.
        //
        lpdwDst += ((ddsd.dwHeight - 1) * ddsd.dwWidth);

        CHECK_HR(hr = lpRGBSurf->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK, NULL));

        switch (ddsd.ddpfPixelFormat.dwRGBBitCount) {
        case 32:
            lpSrc = (LPBYTE)ddsd.lpSurface;
            for (DWORD y = 0; y < ddsd.dwHeight; y++) {

                CopyMemory(lpdwDst, lpSrc, ddsd.dwWidth * 4);

                lpdwDst -= ddsd.dwWidth;
                lpSrc += ddsd.lPitch;
            }
            break;


        case 24:
            lpSrc = (LPBYTE)ddsd.lpSurface;
            for (DWORD y = 0; y < ddsd.dwHeight; y++) {

                LPBYTE lpSrcTmp = lpSrc;
                LPBYTE lpDstTmp = (LPBYTE)lpdwDst;

                for (DWORD x = 0; x < ddsd.dwWidth; x++) {

                    *lpDstTmp++ = *lpSrcTmp++;
                    *lpDstTmp++ = *lpSrcTmp++;
                    *lpDstTmp++ = *lpSrcTmp++;
                    *lpDstTmp++ = 0; // This is the alpha byte
                }

                lpdwDst -= ddsd.dwWidth;
                lpSrc += ddsd.lPitch;
            }
            break;


        case 16:
            if (ddsd.ddpfPixelFormat.dwGBitMask == 0x7E0) {

                // 5:6:5
                lpSrc = (LPBYTE)ddsd.lpSurface;
                for (DWORD y = 0; y < ddsd.dwHeight; y++) {

                    LPBYTE lpSrcTmp = (LPBYTE)lpSrc;
                    RGBQUAD dw = {0, 0, 0, 0};

                    for (DWORD x = 0; x < ddsd.dwWidth; x++) {

                        WORD w = MAKEWORD(lpSrcTmp[0], lpSrcTmp[1]);
                        lpSrcTmp += 2;

                        dw.rgbRed   = ((w & 0xF800) >>  8);
                        dw.rgbGreen = ((w & 0x07E0) >>  3);
                        dw.rgbBlue  = ((w & 0x001F) <<  3);


                        lpdwDst[x] = *((LPDWORD)&dw);
                    }

                    lpdwDst -= ddsd.dwWidth;
                    lpSrc += ddsd.lPitch;
                }
            }
            else {

                // 5:5:5
                lpSrc = (LPBYTE)ddsd.lpSurface;
                for (DWORD y = 0; y < ddsd.dwHeight; y++) {

                    LPBYTE lpSrcTmp = (LPBYTE)lpSrc;
                    RGBQUAD dw = {0, 0, 0, 0};

                    for (DWORD x = 0; x < ddsd.dwWidth; x++) {

                        WORD w = MAKEWORD(lpSrcTmp[0], lpSrcTmp[1]);
                        lpSrcTmp += 2;

                        dw.rgbRed   = ((w & 0x7C00) >>  7);
                        dw.rgbGreen = ((w & 0x03E0) >>  2);
                        dw.rgbBlue  = ((w & 0x001F) <<  3);

                        lpdwDst[x] = *((LPDWORD)&dw);
                    }

                    lpdwDst -= ddsd.dwWidth;
                    lpSrc += ddsd.lPitch;
                }
            }
            break;
        }

        CHECK_HR(hr = lpRGBSurf->Unlock(NULL));
    }
    __finally {

        if (hr != DD_OK) {
            CoTaskMemFree(lpbih);
            lpbih = NULL;
        }

        *lpDib = (LPBYTE)lpbih;
    }

    return hr;
}


/*****************************Private*Routine******************************\
* Clamp
*
* Converts a floating point number to a byte value clamping to range 0-255.
*
* History:
* Tue 01/02/2001 - StEstrop - Created
*
\**************************************************************************/
__inline BYTE Clamp(float clr)
{
    clr += 0.5f;

    if (clr < 0.0f) {
        return (BYTE)0;
    }

    if (clr > 255.0f) {
        return (BYTE)255;
    }

    return (BYTE)clr;
}


/*****************************Private*Routine******************************\
* ConvertYCrCbToRGB
*
* This equation was taken from Video Demystified (2nd Edition)
* by Keith Jack, page 43.
*
*
* History:
* Tue 01/02/2001 - StEstrop - Created
*
\**************************************************************************/
__inline RGBQUAD
ConvertYCrCbToRGB(
    int y,
    int cr,
    int cb
    )
{
    RGBQUAD rgbq;

    float r = (1.1644f * (y-16)) + (1.5960f * (cr-128));
    float g = (1.1644f * (y-16)) - (0.8150f * (cr-128)) - (0.3912f * (cb-128));
    float b = (1.1644f * (y-16))                        + (2.0140f * (cb-128));


    rgbq.rgbBlue  = Clamp(b);
    rgbq.rgbGreen = Clamp(g);
    rgbq.rgbRed   = Clamp(r);
    rgbq.rgbReserved = 0; // Alpha

    return rgbq;
}


/*****************************Private*Routine******************************\
* CopyIMCXSurf
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyIMCXSurf(
    LPDIRECTDRAWSURFACE7 lpRGBSurf,
    BOOL fInterleavedCbCr,
    BOOL fCbFirst
    )
{
    HRESULT hr;
    DWORD y, x;

    DDSURFACEDESC2 ddsdS = {sizeof(ddsdS)};
    DDSURFACEDESC2 ddsdT = {sizeof(ddsdT)};

    hr = m_pDDSDecode->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = lpRGBSurf->Lock(NULL, &ddsdT, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        m_pDDSDecode->Unlock(NULL);
        return hr;
    }

    LPBYTE lpBitsY = (LPBYTE)ddsdS.lpSurface;
    LPBYTE lpBitsCb;
    LPBYTE lpBitsCr;

    if (fInterleavedCbCr) {

        if (fCbFirst) {
            lpBitsCb = lpBitsY  + (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCr = lpBitsCb + (ddsdS.lPitch / 2);
        }
        else {
            lpBitsCr = lpBitsY  + (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCb = lpBitsCr + (ddsdS.lPitch / 2);
        }
    }
    else {
        if (fCbFirst) {
            lpBitsCb = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCr = lpBitsCb + ((ddsdS.dwHeight * ddsdS.lPitch) / 2);
        }
        else {
            lpBitsCr = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCb = lpBitsCr + ((ddsdS.dwHeight * ddsdS.lPitch) / 2);
        }
    }


    LONG   lStrideCbCr = ddsdS.lPitch;
    LPBYTE lpDibBits = (LPBYTE)(LPBYTE)ddsdT.lpSurface;

    for (y = 0; y < ddsdS.dwHeight; y += 2) {

        LPBYTE lpLineY1 = lpBitsY;
        LPBYTE lpLineY2 = lpBitsY + ddsdS.lPitch;
        LPBYTE lpLineCr = lpBitsCr;
        LPBYTE lpLineCb = lpBitsCb;

        LPBYTE lpDibLine1 = lpDibBits;
        LPBYTE lpDibLine2 = lpDibBits + ddsdT.lPitch;

        for (x = 0; x < ddsdS.dwWidth; x += 2) {

            int  y0 = (int)lpLineY1[0];
            int  y1 = (int)lpLineY1[1];
            int  y2 = (int)lpLineY2[0];
            int  y3 = (int)lpLineY2[1];
            int  cb = (int)lpLineCb[0];
            int  cr = (int)lpLineCr[0];

            RGBQUAD r = ConvertYCrCbToRGB(y0, cr, cb);
            lpDibLine1[0] = r.rgbBlue;
            lpDibLine1[1] = r.rgbGreen;
            lpDibLine1[2] = r.rgbRed;
            lpDibLine1[3] = 0; // Alpha


            r = ConvertYCrCbToRGB(y1, cr, cb);
            lpDibLine1[4] = r.rgbBlue;
            lpDibLine1[5] = r.rgbGreen;
            lpDibLine1[6] = r.rgbRed;
            lpDibLine1[7] = 0; // Alpha


            r = ConvertYCrCbToRGB(y2, cr, cb);
            lpDibLine2[0] = r.rgbBlue;
            lpDibLine2[1] = r.rgbGreen;
            lpDibLine2[2] = r.rgbRed;
            lpDibLine2[3] = 0; // Alpha

            r = ConvertYCrCbToRGB(y3, cr, cb);
            lpDibLine2[4] = r.rgbBlue;
            lpDibLine2[5] = r.rgbGreen;
            lpDibLine2[6] = r.rgbRed;
            lpDibLine2[7] = 0; // Alpha

            lpLineY1 += 2;
            lpLineY2 += 2;
            lpLineCr += 1;
            lpLineCb += 1;

            lpDibLine1 += 8;
            lpDibLine2 += 8;
        }

        lpDibBits += (2 * ddsdT.lPitch);
        lpBitsY   += (2 * ddsdS.lPitch);
        lpBitsCr  += lStrideCbCr;
        lpBitsCb  += lStrideCbCr;
    }

    lpRGBSurf->Unlock(NULL);
    m_pDDSDecode->Unlock(NULL);

    return S_OK;
}


/*****************************Private*Routine******************************\
* CopyYV12Surf
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyYV12Surf(
    LPDIRECTDRAWSURFACE7 lpRGBSurf,
    BOOL fInterleavedCbCr,
    BOOL fCbFirst
    )
{
    HRESULT hr;
    DWORD y, x;

    DDSURFACEDESC2 ddsdS = {sizeof(ddsdS)};
    DDSURFACEDESC2 ddsdT = {sizeof(ddsdT)};

    hr = m_pDDSDecode->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = lpRGBSurf->Lock(NULL, &ddsdT, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        m_pDDSDecode->Unlock(NULL);
        return hr;
    }

    LPBYTE lpBitsY = (LPBYTE)ddsdS.lpSurface;
    LPBYTE lpBitsCr;
    LPBYTE lpBitsCb;
    int    iCbCrInc;
    LONG   lStrideCbCr;

    if (fInterleavedCbCr) {

        lStrideCbCr = ddsdS.lPitch;
        iCbCrInc = 2;
        if (fCbFirst) {
            // NV12
            lpBitsCb = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCr = lpBitsCb + 1;
        }
        else {
            // NV21
            lpBitsCr = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCb = lpBitsCr + 1;
        }
    }
    else {

        lStrideCbCr = ddsdS.lPitch / 2;
        iCbCrInc = 1;

        if (fCbFirst) {
            // IYUV
            lpBitsCb = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCr = lpBitsCb + ((ddsdS.dwHeight * ddsdS.lPitch) / 4);
        }
        else {
            // YV12
            lpBitsCr = lpBitsY  +  (ddsdS.dwHeight * ddsdS.lPitch);
            lpBitsCb = lpBitsCr + ((ddsdS.dwHeight * ddsdS.lPitch) / 4);
        }
    }


    LPBYTE lpDibBits = (LPBYTE)(LPBYTE)ddsdT.lpSurface;

    for (y = 0; y < ddsdS.dwHeight; y += 2) {

        LPBYTE lpLineY1 = lpBitsY;
        LPBYTE lpLineY2 = lpBitsY + ddsdS.lPitch;
        LPBYTE lpLineCr = lpBitsCr;
        LPBYTE lpLineCb = lpBitsCb;

        LPBYTE lpDibLine1 = lpDibBits;
        LPBYTE lpDibLine2 = lpDibBits + ddsdT.lPitch;

        for (x = 0; x < ddsdS.dwWidth; x += 2) {

            int  y0 = (int)lpLineY1[0];
            int  y1 = (int)lpLineY1[1];
            int  y2 = (int)lpLineY2[0];
            int  y3 = (int)lpLineY2[1];
            int  cb = (int)lpLineCb[0];
            int  cr = (int)lpLineCr[0];

            RGBQUAD r = ConvertYCrCbToRGB(y0, cr, cb);
            lpDibLine1[0] = r.rgbBlue;
            lpDibLine1[1] = r.rgbGreen;
            lpDibLine1[2] = r.rgbRed;
            lpDibLine1[3] = 0; // Alpha


            r = ConvertYCrCbToRGB(y1, cr, cb);
            lpDibLine1[4] = r.rgbBlue;
            lpDibLine1[5] = r.rgbGreen;
            lpDibLine1[6] = r.rgbRed;
            lpDibLine1[7] = 0; // Alpha


            r = ConvertYCrCbToRGB(y2, cr, cb);
            lpDibLine2[0] = r.rgbBlue;
            lpDibLine2[1] = r.rgbGreen;
            lpDibLine2[2] = r.rgbRed;
            lpDibLine2[3] = 0; // Alpha

            r = ConvertYCrCbToRGB(y3, cr, cb);
            lpDibLine2[4] = r.rgbBlue;
            lpDibLine2[5] = r.rgbGreen;
            lpDibLine2[6] = r.rgbRed;
            lpDibLine2[7] = 0; // Alpha

            lpLineY1 += 2;
            lpLineY2 += 2;
            lpLineCr += iCbCrInc;
            lpLineCb += iCbCrInc;

            lpDibLine1 += 8;
            lpDibLine2 += 8;
        }

        lpDibBits += (2 * ddsdT.lPitch);
        lpBitsY   += (2 * ddsdS.lPitch);
        lpBitsCr  += lStrideCbCr;
        lpBitsCb  += lStrideCbCr;
    }

    lpRGBSurf->Unlock(NULL);
    m_pDDSDecode->Unlock(NULL);

    return S_OK;
}



/*****************************Private*Routine******************************\
* CopyYUY2Surf
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyYUY2Surf(
    LPDIRECTDRAWSURFACE7 lpRGBSurf
    )
{
    HRESULT hr;
    DWORD y, x;

    DDSURFACEDESC2 ddsdS = {sizeof(ddsdS)};
    DDSURFACEDESC2 ddsdT = {sizeof(ddsdT)};

    hr = m_pDDSDecode->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = lpRGBSurf->Lock(NULL, &ddsdT, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        m_pDDSDecode->Unlock(NULL);
        return hr;
    }

    LPBYTE lpBits = (LPBYTE)ddsdS.lpSurface;
    LPBYTE lpLine;

    LPBYTE lpDibLine = (LPBYTE)(LPBYTE)ddsdT.lpSurface;
    LPBYTE lpDib;

    for (y = 0; y < ddsdS.dwHeight; y++) {

        lpLine = lpBits;
        lpDib = lpDibLine;

        for (x = 0; x < ddsdS.dwWidth; x += 2) {

            int  y0 = (int)lpLine[0];
            int  cb = (int)lpLine[1];
            int  y1 = (int)lpLine[2];
            int  cr = (int)lpLine[3];

            RGBQUAD r = ConvertYCrCbToRGB(y0, cr, cb);
            lpDib[0] = r.rgbBlue;
            lpDib[1] = r.rgbGreen;
            lpDib[2] = r.rgbRed;
            lpDib[3] = 0; // Alpha


            r = ConvertYCrCbToRGB(y1, cr, cb);
            lpDib[4] = r.rgbBlue;
            lpDib[5] = r.rgbGreen;
            lpDib[6] = r.rgbRed;
            lpDib[7] = 0; // Alpha

            lpLine += 4;
            lpDib  += 8;
        }

        lpBits    += ddsdS.lPitch;
        lpDibLine += ddsdT.lPitch;
    }

    lpRGBSurf->Unlock(NULL);
    m_pDDSDecode->Unlock(NULL);

    return S_OK;
}



/*****************************Private*Routine******************************\
* CopyUYVYSurf
*
*
*
* History:
* Sat 10/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CopyUYVYSurf(
    LPDIRECTDRAWSURFACE7 lpRGBSurf
    )
{
    HRESULT hr;
    DWORD y, x;

    DDSURFACEDESC2 ddsdS = {sizeof(ddsdS)};
    DDSURFACEDESC2 ddsdT = {sizeof(ddsdT)};

    hr = m_pDDSDecode->Lock(NULL, &ddsdS, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        return hr;
    }

    hr = lpRGBSurf->Lock(NULL, &ddsdT, DDLOCK_NOSYSLOCK, NULL);
    if (hr != DD_OK) {
        m_pDDSDecode->Unlock(NULL);
        return hr;
    }

    LPBYTE lpBits = (LPBYTE)ddsdS.lpSurface;
    LPBYTE lpLine;

    LPBYTE lpDibLine = (LPBYTE)(LPBYTE)ddsdT.lpSurface;
    LPBYTE lpDib;

    for (y = 0; y < ddsdS.dwHeight; y++) {

        lpLine = lpBits;
        lpDib = lpDibLine;

        for (x = 0; x < ddsdS.dwWidth; x += 2) {

            int  cb = (int)lpLine[0];
            int  y0 = (int)lpLine[1];
            int  cr = (int)lpLine[2];
            int  y1 = (int)lpLine[3];

            RGBQUAD r = ConvertYCrCbToRGB(y0, cr, cb);
            lpDib[0] = r.rgbBlue;
            lpDib[1] = r.rgbGreen;
            lpDib[2] = r.rgbRed;
            lpDib[3] = 0; // Alpha


            r = ConvertYCrCbToRGB(y1, cr, cb);
            lpDib[4] = r.rgbBlue;
            lpDib[5] = r.rgbGreen;
            lpDib[6] = r.rgbRed;
            lpDib[7] = 0; // Alpha

            lpLine += 4;
            lpDib  += 8;
        }

        lpBits    += ddsdS.lPitch;
        lpDibLine += ddsdT.lPitch;
    }

    lpRGBSurf->Unlock(NULL);
    m_pDDSDecode->Unlock(NULL);

    return S_OK;
}



/*****************************Private*Routine******************************\
* CreateRGBShadowSurface
*
*
* History:
* Mon 08/02/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CreateRGBShadowSurface(
    LPDIRECTDRAWSURFACE7* lplpDDS,
    DWORD dwBitsPerPel,
    BOOL fSysMem,
    DWORD dwWidth,
    DWORD dwHeight
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::CreateRGBShadowSurface")));

    DDSURFACEDESC2 ddsd;
    INITDDSTRUCT(ddsd);

    ddsd.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);
    switch (dwBitsPerPel) {
    case 0:
        {
            DDSURFACEDESC2 ddsdP;
            INITDDSTRUCT(ddsdP);
            HRESULT hRet = m_lpCurrMon->pDDSPrimary->GetSurfaceDesc(&ddsdP);
            if (hRet != DD_OK) {
                return hRet;
            }
            ddsd.ddpfPixelFormat = ddsdP.ddpfPixelFormat;
        }
        break;

    case 32:
        ddsd.ddpfPixelFormat.dwRGBBitCount = 32;
        ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
        ddsd.ddpfPixelFormat.dwRBitMask = 0x00FF0000;
        ddsd.ddpfPixelFormat.dwGBitMask = 0x0000FF00;
        ddsd.ddpfPixelFormat.dwBBitMask = 0x000000FF;
        break;

    case 24:
        ddsd.ddpfPixelFormat.dwRGBBitCount = 24;
        ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
        ddsd.ddpfPixelFormat.dwRBitMask = 0x00FF0000;
        ddsd.ddpfPixelFormat.dwGBitMask = 0x00000FF0;
        ddsd.ddpfPixelFormat.dwBBitMask = 0x000000FF;
        break;

    case 16:
        ddsd.ddpfPixelFormat.dwRGBBitCount = 16;
        ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
        ddsd.ddpfPixelFormat.dwRBitMask = 0xF800;
        ddsd.ddpfPixelFormat.dwGBitMask = 0x07e0;
        ddsd.ddpfPixelFormat.dwBBitMask = 0x001F;
        break;
    }

    if (fSysMem) {
        ddsd.ddsCaps.dwCaps = DDSCAPS_SYSTEMMEMORY | DDSCAPS_OFFSCREENPLAIN;
    }
    else {
        ddsd.ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                              DDSCAPS_OFFSCREENPLAIN;
    }

    ddsd.dwFlags = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH | DDSD_PIXELFORMAT;
    ddsd.dwWidth = dwWidth;
    ddsd.dwHeight = dwHeight;

    // Attempt to create the surface with theses settings
    return m_lpCurrMon->pDD->CreateSurface(&ddsd, lplpDDS, NULL);
}




/*****************************Private*Routine******************************\
* HandleYUVSurface
*
* Copies the current YUV image into a shadow RGB system memory surface.
* The RGB shadow surface can be in either video or system memory.
*
* History:
* Tue 12/26/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::HandleYUVSurface(
    const DDSURFACEDESC2& ddsd,
    LPDIRECTDRAWSURFACE7* lplpRGBSurf
    )
{
    HRESULT hr = DD_OK;
    LPDIRECTDRAWSURFACE7 lpRGBSurf = NULL;

    *lplpRGBSurf = NULL;

    if (((ddsd.ddsCaps.dwCaps & DDSCAPS_OVERLAY) != DDSCAPS_OVERLAY) &&
        (m_lpCurrMon->ddHWCaps.dwCaps & DDCAPS_BLTFOURCC)) {

        //
        // Try to allocate an RGB shadow surface, in the array
        // below 0 means use the RGB format of the monitor
        //

        const DWORD dwNumBits = 4;
        const DWORD dwBits[dwNumBits] = {32,24,16,0};

        for (const DWORD* lpBits = dwBits;
             lpBits < &dwBits[dwNumBits]; lpBits++) {

            hr = CreateRGBShadowSurface(&lpRGBSurf, *lpBits,
                                        FALSE,
                                        m_VideoSizeAct.cx,
                                        m_VideoSizeAct.cy);
            if (hr == DD_OK) {

                RECT r = {0, 0, m_VideoSizeAct.cx, m_VideoSizeAct.cy};

                hr = lpRGBSurf->Blt(&r, m_pDDSDecode,
                                    &r, DDBLT_WAIT, NULL);

                if (hr == DD_OK) {
                    *lplpRGBSurf = lpRGBSurf;
                    return hr;
                }
                else {
                    RELEASE(lpRGBSurf);
                }
            }
        }
    }

    //
    // Still here - this must be a low-end graphics card or a poorly
    // featured driver.  We are using a YUV surface but we
    // can't perform a color space converting blt or we
    // have run out of video memory.
    //

    hr = CreateRGBShadowSurface(&lpRGBSurf, 32, TRUE,
                                m_VideoSizeAct.cx,
                                m_VideoSizeAct.cy);
    if (hr == DD_OK) {

        switch (ddsd.ddpfPixelFormat.dwFourCC) {

        case mmioFOURCC('I','M','C','1'):
            hr = CopyIMCXSurf(lpRGBSurf, FALSE, FALSE);
            break;

        case mmioFOURCC('I','M','C','2'):
            hr = CopyIMCXSurf(lpRGBSurf, TRUE, FALSE);
            break;

        case mmioFOURCC('I','M','C','3'):
            hr = CopyIMCXSurf(lpRGBSurf, FALSE, TRUE);
            break;

        case mmioFOURCC('I','M','C','4'):
            hr = CopyIMCXSurf(lpRGBSurf, TRUE, TRUE);
            break;

        case mmioFOURCC('Y','V','1','2'):
            hr = CopyYV12Surf(lpRGBSurf, FALSE, FALSE);
            break;

        case mmioFOURCC('I','Y','U','V'):
            hr = CopyYV12Surf(lpRGBSurf, FALSE, TRUE);
            break;

        case mmioFOURCC('N','V','1','2'):
            hr = CopyYV12Surf(lpRGBSurf, TRUE, TRUE);
            break;

        case mmioFOURCC('N','V','2','1'):
            hr = CopyYV12Surf(lpRGBSurf, TRUE, FALSE);
            break;

        case mmioFOURCC('Y','U','Y','2'):
            hr = CopyYUY2Surf(lpRGBSurf);
            break;

        case mmioFOURCC('U','Y','V','Y'):
            hr = CopyUYVYSurf(lpRGBSurf);
            break;

        default:
            hr = E_FAIL;
            break;
        }

        if (hr == DD_OK) {
            *lplpRGBSurf = lpRGBSurf;
        }
        else {
            RELEASE(lpRGBSurf);
        }
    }

    return hr;
}



/******************************Public*Routine******************************\
* GetCurrentImage
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetCurrentImage(
    BYTE** lpDib
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetCurrentImage")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(lpDib)) {
        DbgLog((LOG_ERROR, 1, TEXT("GetCurrentImage: Bad pointer")));
        return E_POINTER;
    }

    if (!m_lpCurrMon ||
        !m_lpCurrMon->pDDSPrimary ||
        !SurfaceAllocated())
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("GetCurrentImage: Display system not initialized")));
        return E_FAIL;
    }

    *lpDib = NULL;
    HRESULT hr = E_FAIL;
    DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
    LPDIRECTDRAWSURFACE7 lpRGBSurf = NULL;

    __try {

        CHECK_HR(hr = m_pDDSDecode->GetSurfaceDesc(&ddsd));

        if (ddsd.ddpfPixelFormat.dwFlags & DDPF_FOURCC) {

            CHECK_HR(hr = HandleYUVSurface(ddsd, &lpRGBSurf));
        }
        else {

            lpRGBSurf = m_pDDSDecode;
            lpRGBSurf->AddRef();
        }

        CHECK_HR(hr = CopyRGBSurfToDIB(lpDib, lpRGBSurf));

    }
    __finally {

        RELEASE(lpRGBSurf);
    }

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\ap.cpp ===
/******************************Module*Header*******************************\
* Module Name: AP.cpp
*
* The default DShow allocator presenter
*
*
* Created: Wed 02/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#ifdef FILTER_DLL
#include <initguid.h>
#endif
#include "VMRuuids.h"

#include "apobj.h"
#include "MediaSType.h"

#if defined(CHECK_FOR_LEAKS)
#include "ifleak.h"
#endif

#ifndef DECLSPEC_SELECTANY
#if (_MSC_VER >= 1100)
#define DECLSPEC_SELECTANY  __declspec(selectany)
#else
#define DECLSPEC_SELECTANY
#endif
#endif

EXTERN_C const GUID DECLSPEC_SELECTANY IID_IDirectDraw7 =
{
    0x15e65ec0, 0x3b9c, 0x11d2,
    {
        0xb9, 0x2f, 0x00, 0x60, 0x97, 0x97, 0xea, 0x5b
    }
};



#ifdef FILTER_DLL

STDAPI DllRegisterServer()
{
    AMTRACE((TEXT("DllRegisterServer")));
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    AMTRACE((TEXT("DllUnregisterServer")));
    return AMovieDllRegisterServer2( FALSE );
}

CFactoryTemplate g_Templates[] = {
    {
        L"",
        &CLSID_AllocPresenter,
        CAllocatorPresenter::CreateInstance,
        CAllocatorPresenter::InitClass,
        NULL
    },
    {
        L"",
        &CLSID_AllocPresenterDDXclMode,
        CAllocatorPresenter::CreateInstanceDDXclMode,
        NULL,
        NULL
    }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
#endif


/******************************Public*Routine******************************\
* CreateInstance
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CUnknown*
CAllocatorPresenter::CreateInstance(
    LPUNKNOWN pUnk,
    HRESULT *phr
    )
{
    AMTRACE((TEXT("CVMRFilter::CreateInstance")));
    return new CAllocatorPresenter(pUnk, phr, FALSE);
}


/******************************Public*Routine******************************\
* CreateInstanceDDXclMode
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CUnknown*
CAllocatorPresenter::CreateInstanceDDXclMode(
    LPUNKNOWN pUnk,
    HRESULT *phr
    )
{
    AMTRACE((TEXT("CVMRFilter::CreateInstanceDDXclMode")));
    return new CAllocatorPresenter(pUnk, phr, TRUE);
}


/******************************Public*Routine******************************\
* InitClass
*
*
*
* History:
* Thu 12/14/2000 - StEstrop - Created
*
\**************************************************************************/

#if defined(CHECK_FOR_LEAKS)
// the one and only g_IFLeak object.
CInterfaceLeak  g_IFLeak;

void
CAllocatorPresenter::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
    if (bLoading) {
        DbgLog((LOG_TRACE, 0, TEXT("AP Thunks: Loaded") ));
        g_IFLeak.Init();
    }
    else {
        DbgLog((LOG_TRACE, 0, TEXT("AP Thunks: Unloaded") ));
        g_IFLeak.Term();
    }
}
#else
void
CAllocatorPresenter::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
}
#endif


/******************************Public*Routine******************************\
* CAllocatorPresenter
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CAllocatorPresenter::CAllocatorPresenter(
    LPUNKNOWN pUnk,
    HRESULT *phr,
    BOOL fDDXclMode
    )
    : CUnknown(NAME("Allocator Presenter"), pUnk)
    , m_lpCurrMon(NULL)
    , m_lpNewMon(NULL)
    , m_hwndClip(NULL)
    , m_clrBorder(RGB(0, 0, 0))
    , m_clrKey(RGB(16,0,16))
    , m_dwMappedColorKey(CLR_INVALID)
    , m_bMonitorStraddleInProgress(FALSE)
    , m_bStreaming(FALSE)
    , m_pSurfAllocatorNotify(NULL)
    , m_bDirectedFlips(FALSE)
    , m_bFlippable(false)
    , m_bUsingOverlays(false)
    , m_bOverlayVisible(false)
    , m_bDisableOverlays(false)
    , m_dwRenderingPrefs(RenderPrefs_AllowOverlays)
    , m_dwARMode(VMR_ARMODE_NONE)
    , m_pDDSDecode(NULL)
    , m_dwInterlaceFlags(0)
    , m_bSysMem(FALSE)
    , m_bDecimating(FALSE)
    , m_MMTimerId(0)
    , m_fDDXclMode(fDDXclMode)
{
    AMTRACE((TEXT("CAllocatorPresenter::CAllocatorPresenter")));

    ZeroMemory(&m_VideoSizeAct, sizeof(m_VideoSizeAct));
    ZeroMemory(&m_ARSize, sizeof(m_ARSize));

    ZeroMemory(&m_rcDstDesktop, sizeof(m_rcDstDesktop));

    ZeroMemory(&m_rcDstApp, sizeof(m_rcDstApp));
    ZeroMemory(&m_rcSrcApp, sizeof(m_rcSrcApp));

    ZeroMemory(&m_rcBdrTL, sizeof(m_rcBdrTL));
    ZeroMemory(&m_rcBdrBR, sizeof(m_rcBdrBR));

#ifdef DEBUG
    m_SleepTime = GetProfileIntA("VMR", "WaitForScanLine", 0);
#else
    m_SleepTime = 0;
#endif

    if (!m_fDDXclMode) {

        HRESULT hr = m_monitors.InitializeDisplaySystem( m_hwndClip );
        if (SUCCEEDED(hr)) {

            VMRGUID GUID;
            GetDefaultMonitor(&GUID);
            SetMonitor(&GUID);

            if (!m_lpCurrMon) {
                DbgLog((LOG_ERROR, 1, TEXT("No Primary monitor set !!")));
                *phr = E_FAIL;
            }
        }
        else {
            DbgLog((LOG_ERROR, 1, TEXT("Cannot initialize display system !!")));
            *phr = hr;
        }
    }

    const DWORD HEART_BEAT_TICK = 250;  // 250 mSec qtr second
    if (m_fDDXclMode) {
        m_uTimerID = SetTimer(NULL, 0, HEART_BEAT_TICK, GetTimerProc());
    }
    else {
        m_uTimerID = CompatibleTimeSetEvent(HEART_BEAT_TICK, HEART_BEAT_TICK / 2,
                                            CAllocatorPresenter::APHeartBeatTimerProc,
                                            (DWORD_PTR)this, TIME_PERIODIC);
    }
}

/******************************Public*Routine******************************\
* CAllocatorPresenter
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CAllocatorPresenter::~CAllocatorPresenter()
{
    AMTRACE((TEXT("CAllocatorPresenter::~CAllocatorPresenter")));

    if (m_uTimerID) {
        if (m_fDDXclMode) {
            KillTimer(NULL, m_uTimerID);
        }
        else {
            timeKillEvent((DWORD)m_uTimerID);
        }
    }

    RELEASE(m_pSurfAllocatorNotify);
}


/******************************Public*Routine******************************\
* NonDelegatingQueryInterface
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::NonDelegatingQueryInterface(
    REFIID riid,
    void ** ppv)
{
    AMTRACE((TEXT("CAlocatorPresenter::NonDelegatingQueryInterface")));

    HRESULT hr = E_NOINTERFACE;
    *ppv = NULL;

    if (riid == IID_IVMRSurfaceAllocator) {
        hr = GetInterface(static_cast<IVMRSurfaceAllocator*>(this), ppv);
    }
    else if (riid == IID_IVMRWindowlessControl) {
        hr = GetInterface(static_cast<IVMRWindowlessControl*>(this), ppv);
    }
    else if (riid == IID_IVMRImagePresenter) {
        hr = GetInterface(static_cast<IVMRImagePresenter*>(this), ppv);
    }
    else if (riid == IID_IVMRImagePresenterExclModeConfig) {
        if (m_fDDXclMode) {
            hr = GetInterface(static_cast<IVMRImagePresenterExclModeConfig*>(this), ppv);
        }
    }
    else if (riid == IID_IVMRImagePresenterConfig) {
        if (!m_fDDXclMode) {
            hr = GetInterface(static_cast<IVMRImagePresenterConfig*>(this), ppv);
        }
    }
    else if (riid == IID_IVMRMonitorConfig) {
        hr = GetInterface(static_cast<IVMRMonitorConfig*>(this), ppv);
    }
    else {
        hr = CUnknown::NonDelegatingQueryInterface(riid, ppv);
    }

#if defined(CHECK_FOR_LEAKS)
    if (hr == S_OK) {
        _pIFLeak->AddThunk((IUnknown **)ppv, "AP Object",  riid);
    }
#endif
    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\apobj.cpp ===
/******************************Module*Header*******************************\
* Module Name: APObj.cpp
*
*
*
*
* Created: Mon 01/24/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"


/*****************************Private*Routine******************************\
* StretchCapsOK
*
*
*
* History:
* Tue 06/05/2001 - StEstrop - Created
*
\**************************************************************************/
BOOL
StretchCapsOK(
    DDCAPS_DX7* lpCaps,
    BOOL fRGB
    )
{
    BOOL fBltOk = TRUE;
    DWORD dwCaps = 0;
    const DWORD dwFXCaps =  DDFXCAPS_BLTSHRINKX | DDFXCAPS_BLTSHRINKX  |
                            DDFXCAPS_BLTSTRETCHX | DDFXCAPS_BLTSTRETCHY;

    if (fRGB) {
        dwCaps = DDCAPS_BLTSTRETCH;
    }
    else {
        dwCaps = (DDCAPS_BLTFOURCC | DDCAPS_BLTSTRETCH);
    }

   fBltOk &= ((dwCaps   & lpCaps->dwCaps)   == dwCaps);
   fBltOk &= ((dwFXCaps & lpCaps->dwFXCaps) == dwFXCaps);


   return fBltOk;
}


/******************************Private*Routine******************************\
* ClipRectPair
*
* Clip a destination rectangle & update the scaled source accordingly
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
void
CAllocatorPresenter::ClipRectPair(
    RECT& rdSrc,
    RECT& rdDest,
    const RECT& rdDestWith
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::ClipRectPair")));

    // figure out src/dest scale ratios
    int iSrcWidth  = WIDTH(&rdSrc);
    int iSrcHeight = HEIGHT(&rdSrc);

    int iDestWidth  = WIDTH(&rdDest);
    int iDestHeight = HEIGHT(&rdDest);

    // clip destination (and adjust the source when we change the destination)

    // see if we have to clip horizontally
    if( iDestWidth ) {
        if( rdDestWith.left > rdDest.left ) {
            int iDelta = rdDestWith.left - rdDest.left;
            rdDest.left += iDelta;
            int iDeltaSrc = MulDiv(iDelta, iSrcWidth, iDestWidth);
            rdSrc.left += iDeltaSrc;
        }

        if( rdDestWith.right < rdDest.right ) {
            int iDelta = rdDest.right-rdDestWith.right;
            rdDest.right -= iDelta;
            int iDeltaSrc = MulDiv(iDelta, iSrcWidth, iDestWidth);
            rdSrc.right -= iDeltaSrc;
        }
    }
    // see if we have to clip vertically
    if( iDestHeight ) {
        if( rdDestWith.top > rdDest.top ) {
            int iDelta = rdDestWith.top - rdDest.top;
            rdDest.top += iDelta;
            int iDeltaSrc = MulDiv(iDelta, iSrcHeight, iDestHeight );
            rdSrc.top += iDeltaSrc;
        }

        if( rdDestWith.bottom < rdDest.bottom ) {
            int iDelta = rdDest.bottom-rdDestWith.bottom;
            rdDest.bottom -= iDelta;
            int iDeltaSrc = MulDiv(iDelta, iSrcHeight, iDestHeight );
            rdSrc.bottom -= iDeltaSrc;
        }
    }
}




/******************************Local*Routine******************************\
* DDColorMatchOffscreen
*
* convert a RGB color to a pysical color.
* we do this by leting GDI SetPixel() do the color matching
* then we lock the memory and see what it got mapped to.
*
* Static function since only called from MapColorToMonitor
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
DWORD
DDColorMatchOffscreen(
    IDirectDraw7 *pdd,
    COLORREF rgb,
    HRESULT& hr
    )
{
    AMTRACE((TEXT("DDColorMatchOffscreen")));
    DDSURFACEDESC2 ddsd;

    INITDDSTRUCT(ddsd);
    ddsd.dwFlags = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH;
    ddsd.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN;
    ddsd.dwWidth = 16;
    ddsd.dwHeight = 16;

    IDirectDrawSurface7* pdds;
    hr = pdd->CreateSurface(&ddsd, &pdds, NULL);
    if (hr != DD_OK) {
        return 0;
    }

    DWORD dw = DDColorMatch( pdds, rgb, hr);
    pdds->Release();
    return dw;
}


/******************************Private*Routine******************************\
* MapColorToMonitor
*
*
*
* History:
* Wed 04/05/2000 - GlennE - Created
*
\**************************************************************************/
DWORD
CAllocatorPresenter::MapColorToMonitor(
    CAMDDrawMonitorInfo& monitor,
    COLORREF clr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::MapColorToMonitor")));
    DWORD dwColor = CLR_INVALID;
    if( monitor.pDD ) {
        HRESULT hr;
        dwColor = DDColorMatchOffscreen(monitor.pDD, clr, hr);
    } else {
        DbgLog((LOG_ERROR, 1, TEXT("can't map color!")));
    }

    return dwColor;
}


/*****************************Private*Routine******************************\
* UpdateRectangles
*
* Updates m_rcDstDesktop and m_rcSrcVideo according to the current m_rcDstApp,
* m_rcSrcApp and m_dwARMode mode values.
*
* Returns a mask identifying any size or position changes that have occurred.
* This info can be used to determine if UpdateOverlay needs to be called or
* if a WM_PAINT message needs to be generated.  If no new rectangle parameters
* passed in the function just remaps the current SRC and DST rectangles into
* movie and desktop co-ordinates respectively and then determines if any
* movement or resizing has taken place.  This function is called when apps
* call SetVideoPosition and each time GetNextSurface and PresentImage is
* called.
*
* History:
* Mon 05/01/2000 - StEstrop - Created
*
\**************************************************************************/
DWORD
CAllocatorPresenter::UpdateRectangles(
    LPRECT lprcNewSrc,
    LPRECT lprcNewDst
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::UpdateRectangles")));
    DWORD dwRetFlags = UR_NOCHANGE;

    RECT rcSrc = m_rcSrcApp;
    if (lprcNewSrc) {
        m_rcSrcApp = *lprcNewSrc;
    }

    if (lprcNewDst) {
        m_rcDstApp = *lprcNewDst;
    }

    //
    // Process the destination rectangle
    //

    m_rcDstDskIncl = m_rcDstApp;
    MapWindowRect(m_hwndClip, HWND_DESKTOP, &m_rcDstDskIncl);

    RECT rcDst;
    if (m_dwARMode == VMR_ARMODE_LETTER_BOX) {

        SIZE im = {WIDTH(&m_rcSrcApp), HEIGHT(&m_rcSrcApp)};
        AspectRatioCorrectSize(&im, m_ARSize);

        RECT Src = {0, 0, im.cx, im.cy};
        LetterBoxDstRect(&rcDst, Src, m_rcDstApp, &m_rcBdrTL, &m_rcBdrBR);
    }
    else {
        rcDst = m_rcDstApp;
    }
    MapWindowRect(m_hwndClip, HWND_DESKTOP, &rcDst);

    if (!EqualSizeRect(&m_rcDstDesktop, &rcDst)){

        dwRetFlags |= UR_SIZE;
    }

    if (!EqualRect(&m_rcDstDesktop, &rcDst)) {
        dwRetFlags |= UR_MOVE;
    }

    m_rcDstDesktop = rcDst;


    //
    // Process the source rectangle - for now don't make any adjustments
    //

    if (!EqualSizeRect(&m_rcSrcApp, &rcSrc)) {
        dwRetFlags |= UR_SIZE;
    }

    if (!EqualRect(&m_rcSrcApp, &rcSrc)) {
        dwRetFlags |= UR_MOVE;
    }

    return dwRetFlags;
}



/////////////////////////////////////////////////////////////////////////////
// CAllocatorPresenter
//
/////////////////////////////////////////////////////////////////////////////

/******************************Public*Routine******************************\
* CAllocatorPresenter::PrepareSurface
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::PrepareSurface(
    DWORD_PTR dwUserID,
    LPDIRECTDRAWSURFACE7 lpSample,
    DWORD dwSampleFlags
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::PrepareSurface")));
    CAutoLock Lock(&m_ObjectLock);

    if (!lpSample) {
        DbgLog((LOG_ERROR, 1, TEXT("PrepareSurface: lpSample is NULL!!")));
        return E_POINTER;
    }

    if (!m_lpCurrMon) {
        DbgLog((LOG_ERROR, 1,
                TEXT("PrepareSurface: Don't have a current monitor")));
        return E_FAIL;
    }

    if (!SurfaceAllocated()) {

        if (MonitorChangeInProgress()) {

            DbgLog((LOG_ERROR, 1,
                    TEXT("PrepareSurface: Backbuffer is NULL ")
                    TEXT("during monitor change")));
        }
        else {

            // Need something better here
            DbgLog((LOG_ERROR, 1,
                    TEXT("PrepareSurface: Backbuffer surface is NULL!!")));
        }

        return E_FAIL;
    }

    //
    // Have we moved onto a different monitor ?
    //

    CAMDDrawMonitorInfo* lpNewMon;
    if (IsDestRectOnWrongMonitor(&lpNewMon)) {

        DbgLog((LOG_TRACE, 1,
                TEXT("Moved to new monitor %s"), lpNewMon->szDevice));

        //
        // tell the DShow filter about the monitor change and
        // then return S_FALSE to the mixer component.
        //

        if (m_lpNewMon != lpNewMon) {
            if (m_pSurfAllocatorNotify) {
                m_pSurfAllocatorNotify->ChangeDDrawDevice(lpNewMon->pDD,
                                                          lpNewMon->hMon);
            }

            m_lpNewMon = lpNewMon;
        }

        return S_FALSE;

    }

    ASSERT(SurfaceAllocated());

    //
    // if deocoder needs the last frame, copy it from the visible surface
    // to the back buffer
    //
    HRESULT hr = S_OK;
    if (dwSampleFlags & AM_GBF_NOTASYNCPOINT) {

        hr = lpSample->Blt(NULL, m_pDDSDecode,
                           NULL, DDBLT_WAIT, NULL);

        if (hr == E_NOTIMPL) {
            hr = VMRCopyFourCC(lpSample, m_pDDSDecode);
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* AllocateSurface
*
*
*
* History:
* Fri 02/18/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::AllocateSurface(
    DWORD_PTR dwUserID,
    VMRALLOCATIONINFO* lpAllocInfo,
    DWORD* lpdwBuffer,
    LPDIRECTDRAWSURFACE7* lplpSurface
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::AllocateSurface")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr;

    if (ISBADREADPTR(lpAllocInfo)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid VMRALLOCATIONINFO pointer")));
        return E_POINTER;
    }

    DWORD dwFlags               = lpAllocInfo->dwFlags;
    LPBITMAPINFOHEADER lpHdr    = lpAllocInfo->lpHdr;
    LPDDPIXELFORMAT lpPixFmt    = lpAllocInfo->lpPixFmt;
    LPSIZE lpAspectRatio        = &lpAllocInfo->szAspectRatio;
    DWORD dwMinBuffers          = lpAllocInfo->dwMinBuffers;
    DWORD dwMaxBuffers          = lpAllocInfo->dwMaxBuffers;

    if (ISBADREADPTR(lpHdr)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid BITMAPINFOHEADER pointer")));
        return E_POINTER;
    }

    const DWORD AMAP_INVALID_FLAGS = ~(AMAP_PIXELFORMAT_VALID | AMAP_3D_TARGET |
                                       AMAP_ALLOW_SYSMEM | AMAP_FORCE_SYSMEM |
                                       AMAP_DIRECTED_FLIP | AMAP_DXVA_TARGET);

    if (dwFlags & AMAP_INVALID_FLAGS) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid flags")));
        return E_INVALIDARG;
    }

    const DWORD AMAP_SYSMEM_FLAGS = (AMAP_ALLOW_SYSMEM | AMAP_FORCE_SYSMEM);
    if (AMAP_SYSMEM_FLAGS == (dwFlags & AMAP_SYSMEM_FLAGS)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("AMAP_ALLOW_SYSMEM can't be used with AMAP_FORCE_SYSMEM);")));
        return E_INVALIDARG;
    }

    if (ISBADREADPTR(lpAspectRatio)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid aspect ratio pointer")));
        return E_POINTER;
    }

    if (ISBADWRITEPTR(lplpSurface)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid LPDIRECTDRAWSURFACE7 pointer")));
        return E_POINTER;
    }

    if (ISBADREADWRITEPTR(lpdwBuffer)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid DWORD buffer pointer")));
        return E_POINTER;
    }

    if (dwMinBuffers == 0 || dwMaxBuffers == 0) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid (min or max) buffer value")));
        return E_INVALIDARG;
    }

    if (dwMinBuffers > dwMaxBuffers) {
        DbgLog((LOG_ERROR, 1, TEXT("Min buffer value greater than max")));
        return E_INVALIDARG;
    }

    if (dwMaxBuffers > MAX_ALLOWED_BUFFER) {
        DbgLog((LOG_ERROR, 1, TEXT("Can't allocate more than %d buffers"),
                MAX_ALLOWED_BUFFER ));
        return E_INVALIDARG;
    }

    if (dwFlags & AMAP_PIXELFORMAT_VALID) {
        if (ISBADREADPTR(lpPixFmt)) {
            DbgLog((LOG_ERROR, 1, TEXT("Invalid DDPIXELFORMAT pointer")));
            return E_POINTER;
        }
    }
    else {
        lpPixFmt = NULL;
    }


    if (lpAspectRatio->cx < 1 || lpAspectRatio->cy < 1) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid aspect ratio parameter") ));
        return E_INVALIDARG;
    }

    //
    // Do we have a monitor/display change event in progress ?  If
    // so we need to create the surface using the new DDraw Object and
    // then switch the m_lpCurrMon member variable to the new monitor.
    //

    if (MonitorChangeInProgress()) {
        m_lpCurrMon = m_lpNewMon;
    }

    if (!FoundCurrentMonitor()) {
        return E_FAIL;
    }

    //
    // Make sure the bitmapinfo header is valid and big enough
    //
    VIDEOINFO vi;
    if (dwFlags & AMAP_3D_TARGET) {

        CopyMemory(&vi.bmiHeader, lpHdr, lpHdr->biSize);
        lpHdr = &vi.bmiHeader;

        if (dwFlags & (AMAP_FORCE_SYSMEM | AMAP_ALLOW_SYSMEM)) {
            DbgLog((LOG_ERROR, 1, TEXT("Can't mix 3D target with sysmem flags")));
            return E_INVALIDARG;
        }

        //
        // Are we being asked to use the same format as the current monitor ?
        //
        if (lpHdr->biCompression == BI_RGB && lpHdr->biBitCount == 0) {

            lpHdr->biBitCount = m_lpCurrMon->DispInfo.bmiHeader.biBitCount;
            lpHdr->biCompression = m_lpCurrMon->DispInfo.bmiHeader.biCompression;

            if (lpHdr->biCompression == BI_BITFIELDS) {

                const DWORD *pMonMasks = GetBitMasks(&m_lpCurrMon->DispInfo.bmiHeader);
                DWORD *pBitMasks = (DWORD *)((LPBYTE)lpHdr + lpHdr->biSize);
                pBitMasks[0] = pMonMasks[0];
                pBitMasks[1] = pMonMasks[1];
                pBitMasks[2] = pMonMasks[2];
            }
        }
    }

    hr = AllocateSurfaceWorker(dwFlags, lpHdr, lpPixFmt, lpAspectRatio,
                               dwMinBuffers, dwMaxBuffers,
                               lpdwBuffer, lplpSurface,
                               lpAllocInfo->dwInterlaceFlags,
                               &lpAllocInfo->szNativeSize);

    if (SUCCEEDED(hr)) {

        if (MonitorChangeInProgress()) {
            m_lpNewMon = NULL;
        }

        m_bDirectedFlips = (AMAP_DIRECTED_FLIP == (dwFlags & AMAP_DIRECTED_FLIP));
    }

    return hr;
}


/*****************************Private*Routine******************************\
* TryAllocOverlaySurface
*
*
*
* History:
* Tue 10/03/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::TryAllocOverlaySurface(
    LPDIRECTDRAWSURFACE7* lplpSurf,
    DWORD dwFlags,
    DDSURFACEDESC2* pddsd,
    DWORD dwMinBuffers,
    DWORD dwMaxBuffers,
    DWORD* lpdwBuffer
    )
{
    HRESULT hr = S_OK;
    LPDIRECTDRAWSURFACE7 lpSurface7 = NULL;

    m_bFlippable = FALSE;

    pddsd->dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT |
                     DDSD_PIXELFORMAT | DDSD_BACKBUFFERCOUNT;

    pddsd->ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                            DDSCAPS_OVERLAY | DDSCAPS_FLIP | DDSCAPS_COMPLEX;

    if (dwFlags & AMAP_3D_TARGET) {
        pddsd->ddsCaps.dwCaps |= DDSCAPS_3DDEVICE;
    }

    //
    // If we are in DX-VA mode - indicated by the presence of the
    // AMAP_DXVA_TARGET flag - honour the buffer allocation numbers.
    // Otherwise, always add EXTRA_OVERLAY_BUFFERS to allocation.
    //

    DWORD dwMinBuff = dwMinBuffers;
    DWORD dwMaxBuff = dwMaxBuffers;

    if (AMAP_DXVA_TARGET != (dwFlags & AMAP_DXVA_TARGET))
    {
        //dwMinBuff += (EXTRA_OVERLAY_BUFFERS - 1);
        dwMaxBuff +=  EXTRA_OVERLAY_BUFFERS;
    }

    for (DWORD dwTotalBufferCount =  dwMaxBuff;
         dwTotalBufferCount >= dwMinBuff; dwTotalBufferCount--) {

        // CleanUp stuff from the last loop
        RELEASE(lpSurface7);
        m_bUsingOverlays = true;

        pddsd->dwBackBufferCount = dwTotalBufferCount - 1;
        if (dwTotalBufferCount == 1) {
            pddsd->dwFlags &= ~DDSD_BACKBUFFERCOUNT;
            pddsd->ddsCaps.dwCaps &= ~(DDSCAPS_FLIP | DDSCAPS_COMPLEX);
        }

        hr = m_lpCurrMon->pDD->CreateSurface(pddsd, &lpSurface7, NULL);

        if (hr == DD_OK) {

            SetColorKey(m_clrKey);
            hr = CheckOverlayAvailable(lpSurface7);

            if (SUCCEEDED(hr)) {

                DbgLog((LOG_TRACE, 1,
                        TEXT("Overlay Surface is %4.4hs %dx%d, %d bits"),
                        (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                            ? "RGB "
                            : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                        pddsd->dwWidth,
                        pddsd->dwHeight,
                        pddsd->ddpfPixelFormat.dwRGBBitCount));

                m_bFlippable = (dwTotalBufferCount > 1);
                *lpdwBuffer = dwTotalBufferCount;

                DbgLog((LOG_TRACE, 1, TEXT("EC_VMR_RENDERDEVICE_SET::VMR_RENDER_DEVICE_OVERLAY")));

                if (m_pSurfAllocatorNotify) {
                    m_pSurfAllocatorNotify->NotifyEvent(
                            EC_VMR_RENDERDEVICE_SET,
                            VMR_RENDER_DEVICE_OVERLAY,
                            0);
                }
                break;
            }
            else {
                RELEASE(lpSurface7);
                m_bUsingOverlays = false;

                DbgLog((LOG_ERROR, 1,
                        TEXT("Overlay is already in use hr = 0x%X"), hr));
            }
        }
        else {
            m_bUsingOverlays = false;
            DbgLog((LOG_ERROR, 1,
                    TEXT("CreateSurface %4.4hs failed in Video memory, ")
                    TEXT("BufferCount = %d, hr = 0x%X"),
                    (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                        ? "RGB "
                        : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                    dwTotalBufferCount, hr));
        }
    }

    *lplpSurf = lpSurface7;
    return hr;
}

/*****************************Private*Routine******************************\
* TryAllocOffScrnDXVASurface
*
*
*
* History:
* Tue 10/03/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::TryAllocOffScrnDXVASurface(
    LPDIRECTDRAWSURFACE7* lplpSurf,
    DWORD dwFlags,
    DDSURFACEDESC2* pddsd,
    DWORD dwMinBuffers,
    DWORD dwMaxBuffers,
    DWORD* lpdwBuffer
    )
{
    HRESULT hr = S_OK;
    LPDIRECTDRAWSURFACE7 lpSurface7 = NULL;

    m_bFlippable = FALSE;

    pddsd->dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT |
                     DDSD_PIXELFORMAT | DDSD_BACKBUFFERCOUNT;

    pddsd->ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                            DDSCAPS_OFFSCREENPLAIN | DDSCAPS_FLIP |
                            DDSCAPS_COMPLEX;

    if (dwFlags & AMAP_3D_TARGET) {
        pddsd->ddsCaps.dwCaps |= DDSCAPS_3DDEVICE;
    }

    DWORD dwMinBuff = dwMinBuffers;
    DWORD dwMaxBuff = dwMaxBuffers;

    for (DWORD dwTotalBufferCount =  dwMaxBuff;
         dwTotalBufferCount >= dwMinBuff; dwTotalBufferCount--) {

        // CleanUp stuff from the last loop
        RELEASE(lpSurface7);
        pddsd->dwBackBufferCount = dwTotalBufferCount - 1;

        hr = m_lpCurrMon->pDD->CreateSurface(pddsd, &lpSurface7, NULL);

        if (hr == DD_OK) {

            DbgLog((LOG_TRACE, 1,
                    TEXT("DX-VA offscreen surface is %4.4hs %dx%d, %d bits"),
                    (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                        ? "RGB "
                        : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                    pddsd->dwWidth,
                    pddsd->dwHeight,
                    pddsd->ddpfPixelFormat.dwRGBBitCount));

            ASSERT(dwTotalBufferCount > 1);
            m_bFlippable = TRUE;
            *lpdwBuffer = dwTotalBufferCount;
            if (m_pSurfAllocatorNotify) {
                DbgLog((LOG_TRACE, 1, TEXT("EC_VMR_RENDERDEVICE_SET::VMR_RENDER_DEVICE_VIDMEM")));
                m_pSurfAllocatorNotify->NotifyEvent(
                        EC_VMR_RENDERDEVICE_SET,
                        VMR_RENDER_DEVICE_VIDMEM,
                        0);
            }
            break;
        }
        else {
            DbgLog((LOG_ERROR, 1,
                    TEXT("CreateSurface %4.4hs failed in Video memory, ")
                    TEXT("BufferCount = %d, hr = 0x%X"),
                    (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                        ? "RGB "
                        : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                    dwTotalBufferCount, hr));
        }
    }

    *lplpSurf = lpSurface7;
    return hr;
}


/*****************************Private*Routine******************************\
* TryAllocOffScrnSurface
*
*
*
* History:
* Tue 10/03/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::TryAllocOffScrnSurface(
    LPDIRECTDRAWSURFACE7* lplpSurf,
    DWORD dwFlags,
    DDSURFACEDESC2* pddsd,
    DWORD dwMinBuffers,
    DWORD dwMaxBuffers,
    DWORD* lpdwBuffer,
    BOOL fAllowBackBuffer
    )
{
    HRESULT hr = S_OK;
    LPDIRECTDRAWSURFACE7 lpSurf7FB = NULL;
    DWORD dwTotalBufferCount = 0;

    ASSERT(*lplpSurf == NULL);

    //
    // Setup the surface descriptor and try to allocate the
    // front buffer.
    //

    *lpdwBuffer = 0;
    pddsd->dwBackBufferCount = 0;
    pddsd->dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT | DDSD_PIXELFORMAT;

    if (dwFlags & AMAP_FORCE_SYSMEM) {
        pddsd->ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_SYSTEMMEMORY;
        m_bSysMem = TRUE;
    }
    else {
        pddsd->ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                                DDSCAPS_OFFSCREENPLAIN;
        m_bSysMem = FALSE;
    }

    if (dwFlags & AMAP_3D_TARGET) {
        ASSERT(!(dwFlags & AMAP_FORCE_SYSMEM));
        pddsd->ddsCaps.dwCaps |= DDSCAPS_3DDEVICE;
    }

    hr = m_lpCurrMon->pDD->CreateSurface(pddsd, &lpSurf7FB, NULL);

    if (hr != DD_OK) {
        m_bSysMem = FALSE;
        DbgLog((LOG_ERROR, 1,
                TEXT("CreateSurface %4.4hs failed in Video memory, ")
                TEXT("hr = 0x%X"),
                (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                    ? "RGB " : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC, hr));
        return hr;
    }

    //
    // Now try to allocate the back buffers
    //

    DbgLog((LOG_TRACE, 1,
            TEXT("OffScreen Surface is %4.4hs %dx%d, %d bits"),
            (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                ? "RGB "
                : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
            pddsd->dwWidth,
            pddsd->dwHeight,
            pddsd->ddpfPixelFormat.dwRGBBitCount));

    //
    // FORCE_SYSMEM is not used by the VMR - it gets set by people
    // who override the AllocateSurface method "or in" the FORCE_SYSMEM
    // flag and then pass the call onto us.
    //
    // We do not allocate shadow buffers in this case as the app is not
    // aware of their presence and probably does not know what to do with
    // them.
    //

    DWORD dwMinBuff;
    DWORD dwMaxBuff;

    if (fAllowBackBuffer) {

        dwMinBuff = dwMinBuffers + 1;
        dwMaxBuff = dwMaxBuffers + 1;

        if (dwMinBuffers <= EXTRA_OFFSCREEN_BUFFERS + 1) {
            dwMinBuff = dwMinBuffers + EXTRA_OFFSCREEN_BUFFERS;
        }

        if (dwMaxBuffers <= EXTRA_OFFSCREEN_BUFFERS + 1) {
            dwMaxBuff = dwMaxBuffers + EXTRA_OFFSCREEN_BUFFERS;
        }
    }
    else {

        dwMinBuff = dwMinBuffers;
        dwMaxBuff = dwMaxBuffers;
    }

    dwTotalBufferCount = 1;

    __try {

        LPDIRECTDRAWSURFACE7 lpSurf7 = lpSurf7FB;

        for ( ; dwTotalBufferCount < dwMaxBuff; dwTotalBufferCount++) {

            LPDIRECTDRAWSURFACE7 lpSurf7_2 = NULL;
            hr = m_lpCurrMon->pDD->CreateSurface(pddsd, &lpSurf7_2, NULL);
            if (hr != DD_OK)
                __leave;


            LPDIRECTDRAWSURFACE4 lp4FB;
            lpSurf7->QueryInterface(IID_IDirectDrawSurface4, (LPVOID*)&lp4FB);

            LPDIRECTDRAWSURFACE4 lp4BB;
            lpSurf7_2->QueryInterface(IID_IDirectDrawSurface4, (LPVOID*)&lp4BB);

            hr = lp4FB->AddAttachedSurface(lp4BB);

            RELEASE(lp4FB);
            RELEASE(lp4BB);

            lpSurf7 = lpSurf7_2;
            RELEASE(lpSurf7_2);

            if (hr != DD_OK)
                __leave;

            DbgLog((LOG_TRACE, 1,
                    TEXT("Attached OffScreen Surface %4.4hs %dx%d, %d bits"),
                    (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                        ? "RGB "
                        : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                    pddsd->dwWidth,
                    pddsd->dwHeight,
                    pddsd->ddpfPixelFormat.dwRGBBitCount));
        }
    }
    __finally {

        if (hr != DD_OK) {

            if (dwTotalBufferCount >= dwMinBuff) {
                hr = DD_OK;
            }
            else {

                DbgLog((LOG_ERROR, 1,
                        TEXT("CreateSurface %4.4hs failed in Video memory, ")
                        TEXT("BufferCount = %d, hr = 0x%X"),
                        (pddsd->ddpfPixelFormat.dwFlags == DDPF_RGB)
                            ? "RGB "
                            : (LPSTR)&pddsd->ddpfPixelFormat.dwFourCC,
                        dwTotalBufferCount, hr));

                m_bSysMem = FALSE;
                dwTotalBufferCount = 0;
                RELEASE(lpSurf7FB);
            }
        }

        if (hr == DD_OK) {

            ASSERT(dwTotalBufferCount >= dwMinBuff);

            *lpdwBuffer = dwTotalBufferCount;
            m_bFlippable = (dwTotalBufferCount > 1);

            DbgLog((LOG_TRACE, 1, TEXT("EC_VMR_RENDERDEVICE_SET::VMR_RENDER_DEVICE_VIDMEM or VMR_RENDER_DEVICE_SYSMEM")));

            if (m_pSurfAllocatorNotify) {
                m_pSurfAllocatorNotify->NotifyEvent(
                        EC_VMR_RENDERDEVICE_SET,
                        (dwFlags & AMAP_FORCE_SYSMEM)
                            ? VMR_RENDER_DEVICE_SYSMEM : VMR_RENDER_DEVICE_VIDMEM,
                        0);
            }
        }
    }

    *lplpSurf = lpSurf7FB;
    return hr;
}


/*****************************Private*Routine******************************\
* AllocateSurfaceWorker
*
*
*
* History:
* Wed 03/08/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::AllocateSurfaceWorker(
    DWORD dwFlags,
    LPBITMAPINFOHEADER lpHdr,
    LPDDPIXELFORMAT lpPixFmt,
    LPSIZE lpAspectRatio,
    DWORD dwMinBuffers,
    DWORD dwMaxBuffers,
    DWORD* lpdwBuffer,
    LPDIRECTDRAWSURFACE7* lplpSurface,
    DWORD dwInterlaceFlags,
    LPSIZE lpszNativeSize
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::AllocateSampleWorker")));

    if (!lpHdr) {
        DbgLog((LOG_ERROR, 1,
                TEXT("Can't get bitmapinfoheader from media type!!")));
        return E_INVALIDARG;
    }

    ASSERT(!SurfaceAllocated());

    HRESULT hr = E_FAIL;
    LPDIRECTDRAWSURFACE7 lpSurface7 = NULL;

    //
    // Setup the DDSURFACEDESC2 structure - then...
    //
    // if RenderPrefs_ForceOffscreen isn't set try to create an overlay surface
    // the try to allocate 2 back buffers for this surface.
    //
    // if we can't create an overlay surface then try regular offscreen
    // surfaces, but only if RenderPrefs_ForceOverlays isn't set.  When using
    // offscreen surfaces we try to allocate at least 1 back buffer.
    //

    DDSURFACEDESC2 ddsd;
    INITDDSTRUCT(ddsd);

    ddsd.dwWidth = abs(lpHdr->biWidth);
    ddsd.dwHeight = abs(lpHdr->biHeight);

    //
    // define the pixel format
    //

    if (lpPixFmt) {

        ddsd.ddpfPixelFormat = *lpPixFmt;
    }
    else {

        ddsd.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);

        if (lpHdr->biCompression <= BI_BITFIELDS &&
            m_lpCurrMon->DispInfo.bmiHeader.biBitCount <= lpHdr->biBitCount)
        {
            ddsd.ddpfPixelFormat.dwFourCC = BI_RGB;
            ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
            ddsd.ddpfPixelFormat.dwRGBBitCount = lpHdr->biBitCount;

            if (dwFlags & AMAP_3D_TARGET) {
                ddsd.ddsCaps.dwCaps |= DDSCAPS_3DDEVICE;
            }
            // Store the masks in the DDSURFACEDESC
            const DWORD *pBitMasks = GetBitMasks(lpHdr);
            ASSERT(pBitMasks);
            ddsd.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
            ddsd.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
            ddsd.ddpfPixelFormat.dwBBitMask = pBitMasks[2];
        }
        else if (lpHdr->biCompression > BI_BITFIELDS)
        {
            ddsd.ddpfPixelFormat.dwFourCC = lpHdr->biCompression;
            ddsd.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
            ddsd.ddpfPixelFormat.dwYUVBitCount = lpHdr->biBitCount;
        }
        else
        {
            DbgLog((LOG_ERROR, 1, TEXT("Supplied mediatype not suitable ")
                    TEXT("for either YUV or RGB surfaces")));
            return E_FAIL;
        }
    }

    //
    // The VMR (or a plugged in Allocator Presenter) may want us
    // to always use system memory surfaces.  This would be required
    // if for example you wanted GDI to process the video before it
    // was rendered.
    //

    if (dwFlags & AMAP_FORCE_SYSMEM) {

        //
        // We can only allow YUV sysmem surfaces if we can BltFOURCC
        // from them
        //
	if (lpHdr->biCompression > BI_BITFIELDS && !CanBltFourCCSysMem()) {
            return VFW_E_DDRAW_CAPS_NOT_SUITABLE;
	}

        //
        // We can only allow RGB sysmem surfaces that match the
        // current display format.
        //
        if (lpHdr->biCompression <= BI_BITFIELDS &&
            m_lpCurrMon->DispInfo.bmiHeader.biBitCount != lpHdr->biBitCount) {
            return DDERR_INCOMPATIBLEPRIMARY;
        }

        hr = TryAllocOffScrnSurface(&lpSurface7, AMAP_FORCE_SYSMEM, &ddsd,
                                        dwMinBuffers, dwMaxBuffers,
                                        lpdwBuffer, FALSE);
    }
    else {

        //
        //  Now try to create the overlay
        //

        if (!(m_dwRenderingPrefs & RenderPrefs_ForceOffscreen)) {

            hr = TryAllocOverlaySurface(&lpSurface7, dwFlags, &ddsd,
                                        dwMinBuffers, dwMaxBuffers, lpdwBuffer);
        }


        //
        // If we could not create the overlay check to see if we are only allowed
        // to use overlays.  If so, fail the call.
        //
        if ((hr != DD_OK) || (m_dwRenderingPrefs & RenderPrefs_ForceOffscreen)) {

            if (m_dwRenderingPrefs & RenderPrefs_ForceOverlays) {

                DbgLog((LOG_ERROR, 1,
                        TEXT("RenderPrefs_ForceOverlays is set and ")
                        TEXT("failed tp create an overlay hr = 0x%X"), hr));
                return hr;
            }

            //
            // If we are using offscreen surfaces we have to be a little
            // more restrictive with what we try to allocate.  Basically,
            // if we can BLT_STRETCH we don't try to allocate video memory
            // surfaces.
            //
            // We allow creating FOURCC surfaces if we can BLT_FOURCC and
            // BLT_STRETCH.
            //
            // If we are creating an RGB surface then its format must
            // match the that of the display.
            //

            if (lpHdr->biCompression > BI_BITFIELDS) {
                if (!StretchCapsOK(&m_lpCurrMon->ddHWCaps, FALSE)) {
                    DbgLog((LOG_ERROR, 1,
                            TEXT("Can't BLT_FOURCC | BLT_STRETCH!!")));
                    return VFW_E_DDRAW_CAPS_NOT_SUITABLE;
                }
            }
            else {

                LPBITMAPINFOHEADER lpMon = &m_lpCurrMon->DispInfo.bmiHeader;
                if (lpHdr->biBitCount != lpMon->biBitCount) {

                    DbgLog((LOG_ERROR, 1,
                            TEXT("RGB bit count does not match the display")));
                    return DDERR_INCOMPATIBLEPRIMARY;
                }

                //
                // Some decoders get confused about RGB32.  They think
                // that BI_RGB is the correct value to use.  It should be
                // BIT_BITFIELDS - but we will let them off with a error
                // message written to the debugger.
                //
                if (lpHdr->biCompression != lpMon->biCompression) {

                    if (lpHdr->biBitCount != 32) {
                        DbgLog((LOG_ERROR, 1,
                                TEXT("RGB bit field type does not match the display")));
                        return DDERR_INCOMPATIBLEPRIMARY;
                    }
                    else {
                        DbgLog((LOG_ERROR, 1,
                                TEXT("RGB32 should have BI_BITFIELDS set")));
                    }
                }
            }

            //
            // Only allow creating offscreen surfaces in video memory
            // if the VGA can stretch them in h/w.  Otherwise fall thru
            // to system memory surface creation if the caller allows it.
            //
            if (StretchCapsOK(&m_lpCurrMon->ddHWCaps,
                             (lpHdr->biCompression <= BI_BITFIELDS))) {

                if (dwFlags & AMAP_DXVA_TARGET) {
                    hr = TryAllocOffScrnDXVASurface(&lpSurface7, dwFlags, &ddsd,
                                                    dwMinBuffers, dwMaxBuffers,
                                                    lpdwBuffer);
                }
                else {
                    hr = TryAllocOffScrnSurface(&lpSurface7, dwFlags, &ddsd,
                                                dwMinBuffers, dwMaxBuffers,
                                                lpdwBuffer, TRUE);
                }
            }
            else {
                hr = VFW_E_DDRAW_CAPS_NOT_SUITABLE;
            }
        }


        //
        // If we could not create an offscreen video memory surface
        // see if we can get a offscreen system memory surface.
        //
        if ((hr != DD_OK) && (dwFlags & AMAP_ALLOW_SYSMEM)) {

            //
            // We can only allow sysmem surfaces that match the
            // current display format.
            //
            if (lpHdr->biCompression <= BI_BITFIELDS &&
                m_lpCurrMon->DispInfo.bmiHeader.biBitCount == lpHdr->biBitCount) {

                hr = TryAllocOffScrnSurface(&lpSurface7, AMAP_FORCE_SYSMEM, &ddsd,
                                            dwMinBuffers, dwMaxBuffers,
                                            lpdwBuffer, TRUE);
            }
            else {
                hr = VFW_E_DDRAW_CAPS_NOT_SUITABLE;
            }
        }
    }


    if (hr == DD_OK) {

        m_ARSize = *lpAspectRatio;
        m_VideoSizeAct = *lpszNativeSize;

        m_bDecimating = (dwFlags & AMAP_3D_TARGET) &&
                        (m_VideoSizeAct.cx == (2*abs(lpHdr->biWidth))) &&
                        (m_VideoSizeAct.cy == (2*abs(lpHdr->biHeight)));

        m_dwInterlaceFlags = dwInterlaceFlags;
        m_dwUpdateOverlayFlags = GetUpdateOverlayFlags(m_dwInterlaceFlags,
                                                       AM_VIDEO_FLAG_WEAVE);

        if (IsSingleFieldPerSample(m_dwInterlaceFlags)) {
            m_VideoSizeAct.cy *= 2;
        }
        SetRect(&m_rcSrcApp, 0, 0, m_VideoSizeAct.cx, m_VideoSizeAct.cy);

        PaintDDrawSurfaceBlack(lpSurface7);
    }


    *lplpSurface = lpSurface7;
    m_pDDSDecode = lpSurface7;

    return hr;
}


/******************************Public*Routine******************************\
* FreeSurfaces
*
*
*
* History:
* Fri 02/18/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::FreeSurface(
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::FreeSurface")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_bUsingOverlays) {
        HideOverlaySurface();
    }

    m_bDirectedFlips = false;
    m_bFlippable = false;
    m_bUsingOverlays = false;
    m_bOverlayVisible = false;
    m_bDisableOverlays = false;
    m_bSysMem = FALSE;
    m_dwInterlaceFlags = 0;

    RELEASE(m_pDDSDecode);

    return S_OK;
}

/*****************************Private*Routine******************************\
* WaitForScanLine()
*
* When using a hardware offscreen draw surface we will normally wait for the
* monitor scan line to move past the destination rectangle before drawing so
* that we avoid tearing where possible. Of course not all display cards can
* support this feature and even those that do will see a performance drop of
* about 10% because we sit polling (oh for a generic PCI monitor interrupt)
*
* History:
* Thu 03/30/2000 - StEstrop - Created
*
\**************************************************************************/
void
CAllocatorPresenter::WaitForScanLine(
    const RECT& rcDst
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::WaitForScanLine")));

    HRESULT hr = NOERROR;
    DWORD dwScanLine;

    if (m_SleepTime == -1) {
        return;
    }

    //
    // Some display cards like the ATI Mach64 support reporting of the scan
    // line they are processing. However not all drivers are setting the
    // DDCAPS_READSCANLINE capability flag so we just go ahead and ask for
    // it anyway. We allow for 10 scan lines above the top of our rectangle
    // so that we have a little time to thunk down and set the draw call up
    //

    #define SCANLINEFUDGE 10
    for ( ;; ) {

        hr = m_lpCurrMon->pDD->GetScanLine(&dwScanLine);
        if (FAILED(hr)) {
            DbgLog((LOG_TRACE, 3, TEXT("No scan line")));
            break;
        }

        NOTE1("Scan line returned %lx",dwScanLine);

        if ((LONG)dwScanLine + SCANLINEFUDGE >= rcDst.top) {
            if ((LONG) dwScanLine <= rcDst.bottom) {
                DbgLog((LOG_TRACE, 3, TEXT("Scan inside")));
                if (m_SleepTime >= 0) {
                    Sleep(m_SleepTime);
                }
                continue;
            }
        }

        break;
    }
}

/******************************Public*Routine******************************\
* SetXlcModeDDObjAndPrimarySurface
*
*
*
* History:
* Wed 04/04/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetXlcModeDDObjAndPrimarySurface(
    LPDIRECTDRAW7 lpDD,
    LPDIRECTDRAWSURFACE7 lpPS
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetXlcModeDDObjAndPrimarySurface")));
    CAutoLock Lock(&m_ObjectLock);

    if (!m_fDDXclMode) {
        return E_NOTIMPL;
    }

    if (lpDD == NULL) {
        DbgLog((LOG_ERROR, 1, TEXT("NULL DDraw device") ));
        return E_POINTER;
    }

    if (lpPS == NULL) {
        DbgLog((LOG_ERROR, 1, TEXT("NULL Primary Surface") ));
        return E_POINTER;
    }

    m_monitors.TerminateDisplaySystem();

    m_lpNewMon = NULL;
    m_lpCurrMon = NULL;

    HRESULT hr = m_monitors.InitializeXclModeDisplaySystem(m_hwndClip, lpDD, lpPS);
    if (SUCCEEDED(hr)) {
        VMRGUID guid;
        ZeroMemory(&guid, sizeof(guid));
        hr = SetMonitor(&guid);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetXlcModeDDObjAndPrimarySurface
*
*
*
* History:
* Wed 04/04/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetXlcModeDDObjAndPrimarySurface(
    LPDIRECTDRAW7* lpDDObj,
    LPDIRECTDRAWSURFACE7* lpPrimarySurf
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetXlcModeDDObjAndPrimarySurface")));
    CAutoLock Lock(&m_ObjectLock);

    if (!m_fDDXclMode) {
        return E_NOTIMPL;
    }

    if (lpDDObj == NULL) {
        DbgLog((LOG_ERROR, 1, TEXT("NULL DDraw device") ));
        return E_POINTER;
    }

    if (lpPrimarySurf == NULL) {
        DbgLog((LOG_ERROR, 1, TEXT("NULL Primary Surface") ));
        return E_POINTER;
    }

    *lpDDObj = m_lpCurrMon->pDD;
    if (*lpDDObj) {
        (*lpDDObj)->AddRef();
    }

    *lpPrimarySurf = m_lpCurrMon->pDDSPrimary;
    if (*lpPrimarySurf) {
        (*lpPrimarySurf)->AddRef();
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* SetRenderingPrefs
*
*
*
* History:
* Fri 02/18/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetRenderingPrefs(
    DWORD dwRenderingPrefs
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetRenderingPrefs")));
    CAutoLock Lock(&m_ObjectLock);
    if ( dwRenderingPrefs & ~(RenderPrefs_Mask ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid rendering prefs")));
        return E_INVALIDARG;
    }
    m_dwRenderingPrefs = dwRenderingPrefs;
    return S_OK;
}


/******************************Public*Routine******************************\
* GetRenderingPrefs
*
*
*
* History:
* Fri 02/18/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetRenderingPrefs(
    DWORD* lpdwRenderingPrefs
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetRenderingPrefs")));
    CAutoLock Lock(&m_ObjectLock);
    *lpdwRenderingPrefs = m_dwRenderingPrefs;
    return S_OK;
}


/*****************************Private*Routine******************************\
* ValidatePresInfoStruc
*
*
*
* History:
* Mon 02/19/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
ValidatePresInfoStruc(
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    AMTRACE((TEXT("ValidatePresInfoStruc")));

    //
    // Validate the lpPresInfo ptr.
    //
    if (ISBADREADPTR(lpPresInfo)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid VMRPRESENTATIONINFO pointer")));
        return E_POINTER;
    }

    //
    // Validate the flags are good
    //
    const DWORD dwInvalidFlags = ~(VMRSample_SyncPoint | VMRSample_Preroll |
                                   VMRSample_Discontinuity |
                                   VMRSample_TimeValid);

    if (lpPresInfo->dwFlags & dwInvalidFlags) {
        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid dwFlags parameter") ));
        return E_INVALIDARG;
    }

    //
    // Validate the time stamps are good
    //
    if (lpPresInfo->dwFlags & VMRSample_TimeValid) {

        if (lpPresInfo->rtEnd < lpPresInfo->rtStart) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("CAllocatorPresenter::PresentImage: ")
                    TEXT("rtEnd time before rtStart time") ));
            return E_INVALIDARG;
        }
    }

    //
    // Validate the AR is good
    //
    if (lpPresInfo->szAspectRatio.cx < 1 ||
        lpPresInfo->szAspectRatio.cy < 1) {

        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid aspect ratio parameter") ));
        return E_INVALIDARG;
    }

    //
    // The Src and Dst rects arn't used just yet so make sure they
    // are zero'ed out (and therefore empty).
    //
    if (lpPresInfo->rcSrc.left != 0 && lpPresInfo->rcSrc.top != 0 &&
        lpPresInfo->rcSrc.right != 0 && lpPresInfo->rcSrc.bottom != 0) {

        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid rcSrc parameter") ));
        return E_INVALIDARG;
    }

    if (lpPresInfo->rcDst.left != 0 && lpPresInfo->rcDst.top != 0 &&
        lpPresInfo->rcDst.right != 0 && lpPresInfo->rcDst.bottom != 0) {

        DbgLog((LOG_ERROR, 1,
                TEXT("CAllocatorPresenter::PresentImage: ")
                TEXT("Invalid rcDst parameter") ));
        return E_INVALIDARG;
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* PresentImage
*
* This function is called to present the specifed video image to the
* screen.  It is vital that the image is presented in a timely manner.
* Therefore all parameter validation will only be performed on the DEBUG
* build, see ValidPresInfo above.
*
* History:
* Fri 02/18/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::PresentImage(
    DWORD_PTR dwUserID,
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::PresentImage")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr;

    hr = ValidatePresInfoStruc(lpPresInfo);
    if (FAILED(hr)) {
        return hr;
    }

    m_ARSize = lpPresInfo->szAspectRatio;
    m_dwInterlaceFlags = lpPresInfo->dwInterlaceFlags;
    BOOL bNeedToFlipOddEven = NeedToFlipOddEven(m_dwInterlaceFlags,
                                                lpPresInfo->dwTypeSpecificFlags,
                                                &m_dwCurrentField,
                                                m_bUsingOverlays);

    DWORD dwNewFlags = GetUpdateOverlayFlags(m_dwInterlaceFlags,
                                             lpPresInfo->dwTypeSpecificFlags);
    if (dwNewFlags != m_dwUpdateOverlayFlags) {

        m_dwUpdateOverlayFlags = dwNewFlags;
        if (m_bUsingOverlays) {
            UpdateOverlaySurface();
        }
    }

    hr = PresentImageWorker(lpPresInfo->lpSurf, lpPresInfo->dwFlags, true);

    if (hr == S_OK) {

        if (bNeedToFlipOddEven &&
            !IsSingleFieldPerSample(m_dwInterlaceFlags)) {

            //
            // work out the start time of the other field and
            // the schedule the sample to be delivered on the
            // MM timer thread.
            //

            if (lpPresInfo->dwFlags & VMRSample_TimeValid) {
                lpPresInfo->rtStart = (lpPresInfo->rtStart + lpPresInfo->rtEnd) / 2;
            }

            // call the sync object
            hr = ScheduleSampleUsingMMThread(lpPresInfo);
        }
    }
    else {

        DbgLog((LOG_ERROR, 1,
                TEXT("Error %#X from CAllocatorPresenter::PresentImage"),
                hr));
    }
    return hr;
}

/*****************************Private*Routine******************************\
* StretchBltSysMemDDSurfToDesktop
*
*
*
* History:
* Mon 02/26/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
StretchBltSysMemDDSurfToDesktop(
    HWND hwndClip,
    LPDIRECTDRAWSURFACE7 lpSample,
    LPRECT lpDst,
    LPRECT lpSrc
    )
{

    HRESULT hr = S_OK;

    if (!IsRectEmpty(lpDst)) {

        HDC hdcDst, hdcSrc;
        bool fDst = FALSE;
        bool fSrc = FALSE;

        __try {

            hdcDst = GetDC(hwndClip);
            if (!hdcDst) {
                LONG lRet = GetLastError();
                hr = AmHresultFromWin32(lRet);
                __leave;
            }
            fDst = TRUE;

            CHECK_HR(hr = lpSample->GetDC(&hdcSrc));
            fSrc = TRUE;


            SetStretchBltMode(hdcDst, COLORONCOLOR);
            SetStretchBltMode(hdcSrc, COLORONCOLOR);

            MapWindowRect(HWND_DESKTOP, hwndClip, lpDst);

            if (!StretchBlt(hdcDst, lpDst->left, lpDst->top,
                       WIDTH(lpDst), HEIGHT(lpDst),
                       hdcSrc, lpSrc->left, lpSrc->top,
                       WIDTH(lpSrc), HEIGHT(lpSrc),
                       SRCCOPY)) {

                LONG lRet = GetLastError();
                hr = AmHresultFromWin32(lRet);
                __leave;
            }
        }
        __finally {

            if (fDst) {
                ReleaseDC(hwndClip, hdcDst);
            }
            if (fSrc) {
                lpSample->ReleaseDC(hdcSrc);
            }
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* BltImageToPrimary
*
*
*
* History:
* Wed 09/27/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::BltImageToPrimary(
    LPDIRECTDRAWSURFACE7 lpSample,
    LPRECT lpDst,
    LPRECT lpSrc
    )
{
    HRESULT hr = S_OK;

    if (IsSingleFieldPerSample(m_dwInterlaceFlags)) {
        lpSrc->top /= 2;
        lpSrc->bottom /= 2;
    }

    if (m_bSysMem && !CanBltSysMem()) {
        hr = StretchBltSysMemDDSurfToDesktop(m_hwndClip, lpSample, lpDst, lpSrc);
        if (hr != DD_OK) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("SYSMEM Blt to the primary failed err= %#X"), hr));
        }
    }
    else {
        OffsetRect(lpDst,
                   -m_lpCurrMon->rcMonitor.left,
                   -m_lpCurrMon->rcMonitor.top);

        if (!IsRectEmpty(lpDst)) {

            WaitForScanLine(*lpDst);
            hr = m_lpCurrMon->pDDSPrimary->Blt(lpDst, lpSample,
                                               lpSrc, DDBLT_WAIT, NULL);

            if (hr != DD_OK) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("Blt to the primary failed err= %#X"), hr));
            }
        }
    }

    return S_OK;
}



/******************************Public*Routine******************************\
* PresentImageWorker
*
* Important - this function returns S_FALSE if and only if there is a
* monitor change or display change in progress.  It is important that this
* value is returned to the VMR.
*
* History:
* Fri 02/18/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PresentImageWorker(
    LPDIRECTDRAWSURFACE7 lpSample,
    DWORD dwSampleFlags,
    BOOL fFlip
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::PresentImageWorker")));
    CAutoLock Lock(&m_ObjectLock);

    //
    // It is valid for us to be called with lpSample equal to NULL
    // but only during a Monitor change in response to a WM_PAINT message
    //
    if (!lpSample) {
        ASSERT(MonitorChangeInProgress());
        return S_FALSE;
    }

    //
    // Check that we actually have a target monitor to present too.
    // If we don't this is a runtime error from which we cannot
    // recover.  Playback must stop now.
    //
    if (!m_lpCurrMon) {
        DbgLog((LOG_ERROR, 1, TEXT("PresentImageWorker: No monitor set!")));
        return E_FAIL;
    }

    DWORD dwUR = UpdateRectangles(NULL, NULL);

    RECT TargetRect = m_rcDstDesktop;
    RECT SourceRect = m_rcSrcApp;

    ClipRectPair(SourceRect, TargetRect, m_lpCurrMon->rcMonitor);

    if (m_bDecimating) {
        SourceRect.left    /= 2;
        SourceRect.top     /= 2;
        SourceRect.right   /= 2;
        SourceRect.bottom  /= 2;
    }


    HRESULT hr = S_OK;
    if (m_bUsingOverlays) {

        if (m_bDisableOverlays) {
            BltImageToPrimary(lpSample, &TargetRect, &SourceRect);
        }

        if (dwUR || !m_bOverlayVisible) {
            hr = UpdateOverlaySurface();
            if (SUCCEEDED(hr) && !m_bDisableOverlays) {
                hr = PaintColorKey();
            }
        }

        if (fFlip) {
            FlipSurface(lpSample);
        }
    }
    else {

        hr = BltImageToPrimary(lpSample, &TargetRect, &SourceRect);
        if (fFlip) {
            FlipSurface(lpSample);
        }
    }

    PaintBorder();
    PaintMonitorBorder();

    return S_OK;
}

/******************************Public*Routine******************************\
* StartPresenting
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::StartPresenting(
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::StartPresenting")));
    CAutoLock Lock(&m_ObjectLock);
    m_bStreaming = TRUE;
    return S_OK;
}

/******************************Public*Routine******************************\
* StopPresenting
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::StopPresenting(
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::StopPresenting")));
    CAutoLock Lock(&m_ObjectLock);
    m_bStreaming = FALSE;
    CancelMMTimer();
    return S_OK;
}


/******************************Public*Routine******************************\
* AdviseNotify
*
*
*
* History:
* Mon 02/21/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::AdviseNotify(
    IVMRSurfaceAllocatorNotify* lpIVMRSurfaceAllocatorNotify
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::AdviseNotify")));
    CAutoLock Lock(&m_ObjectLock);

    RELEASE(m_pSurfAllocatorNotify);

    if (lpIVMRSurfaceAllocatorNotify) {
        lpIVMRSurfaceAllocatorNotify->AddRef();
    }

    m_pSurfAllocatorNotify = lpIVMRSurfaceAllocatorNotify;

    if (m_pSurfAllocatorNotify) {
        m_pSurfAllocatorNotify->SetDDrawDevice(m_lpCurrMon->pDD,
                                               m_lpCurrMon->hMon);
    }
    return S_OK;
}


/******************************Public*Routine******************************\
* GetNativeVideoSize
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetNativeVideoSize(
    LONG* lpWidth,
    LONG* lpHeight,
    LONG* lpARWidth,
    LONG* lpARHeight
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetNativeVideoSize")));
    CAutoLock Lock(&m_ObjectLock);
    if (!(lpWidth || lpHeight || lpARWidth || lpARHeight)) {
        DbgLog((LOG_ERROR, 1, TEXT("all input parameters are NULL!!")));
        return E_POINTER;
    }

    if (lpWidth) {
        *lpWidth = m_VideoSizeAct.cx;
    }

    if (lpHeight) {
        *lpHeight = m_VideoSizeAct.cy;
    }

    if (lpARWidth) {
        *lpARWidth = m_ARSize.cx;
    }

    if (lpARHeight) {
        *lpARHeight = m_ARSize.cy;
    }

    return S_OK;
}

/******************************Public*Routine******************************\
* GetMinIdealVideoSize
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetMinIdealVideoSize(
    LONG* lWidth,
    LONG* lHeight
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetMinIdealVideoSize")));
    CAutoLock Lock(&m_ObjectLock);

    if ( ISBADWRITEPTR(lWidth) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }
    if ( ISBADWRITEPTR(lHeight) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }
    if (!FoundCurrentMonitor()) {
        return E_FAIL;
    }

    GetNativeVideoSize(lWidth, lHeight, NULL, NULL);

    if (m_bUsingOverlays) {

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKY) {
            if (m_lpCurrMon->ddHWCaps.dwMinOverlayStretch != 0) {
                *lHeight = MulDiv(*lHeight,
                                 (int)m_lpCurrMon->ddHWCaps.dwMinOverlayStretch,
                                 1000);
            }
            else {
                *lHeight = 1;
            }
        }

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKX) {
            if (m_lpCurrMon->ddHWCaps.dwMinOverlayStretch != 0) {
                *lWidth = MulDiv(*lWidth,
                                (int)m_lpCurrMon->ddHWCaps.dwMinOverlayStretch,
                                1000);
            }
            else {
                *lWidth = 1;
            }
        }
    }
    else {

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_BLTSHRINKY) {
            *lHeight = 1;
        }

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_BLTSHRINKX) {
            *lWidth = 1;
        }
    }

    return S_OK;
}

/******************************Public*Routine******************************\
* GetMaxIdealVideoSize
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetMaxIdealVideoSize(
    LONG* lWidth,
    LONG* lHeight
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetMaxIdealVideoSize")));
    CAutoLock Lock(&m_ObjectLock);

    if ( ISBADWRITEPTR(lWidth) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }
    if ( ISBADWRITEPTR(lHeight) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }
    if (!FoundCurrentMonitor()) {
        return E_FAIL;
    }

    GetNativeVideoSize(lWidth, lHeight, NULL, NULL);

    if (m_bUsingOverlays) {

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_OVERLAYSTRETCHY) {
            *lHeight = MulDiv(*lHeight,
                              (int)m_lpCurrMon->ddHWCaps.dwMaxOverlayStretch,
                              1000);
        }

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_OVERLAYSTRETCHX) {
            *lWidth = MulDiv(*lWidth,
                             (int)m_lpCurrMon->ddHWCaps.dwMaxOverlayStretch,
                             1000);
        }
    }
    else {

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_BLTSTRETCHY) {
            *lHeight = HEIGHT(&m_lpCurrMon->rcMonitor) + 1;
        }

        if (m_lpCurrMon->ddHWCaps.dwFXCaps & DDFXCAPS_BLTSTRETCHX) {
            *lWidth = WIDTH(&m_lpCurrMon->rcMonitor) + 1;
        }
    }

    return S_OK;
}


/*****************************Private*Routine******************************\
* CheckDstRect
*
* Check the target rectangle has some valid coordinates, which amounts to
* little more than checking the destination rectangle isn't empty.
*
*
* History:
* Fri 01/26/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CheckDstRect(
    const LPRECT lpDSTRect
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::CheckDstRect")));

    DbgLog((LOG_TRACE, 4, TEXT("DST: %d %d %d %d"),
            lpDSTRect->left, lpDSTRect->top,
            lpDSTRect->right, lpDSTRect->bottom));

    // These overflow the WIDTH and HEIGHT checks

    if (lpDSTRect->left > lpDSTRect->right ||
        lpDSTRect->top > lpDSTRect->bottom)
    {
        return E_INVALIDARG;
    }

    // Check the rectangle has valid coordinates

    if (WIDTH(lpDSTRect) < 0 || HEIGHT(lpDSTRect) < 0)
    {
        return E_INVALIDARG;
    }

    return S_OK;
}


/*****************************Private*Routine******************************\
* CheckSrcRect
*
* We must check the source rectangle against  the actual video dimensions
* otherwise when we come to draw the pictures we get errors from DDraw.
*
* History:
* Fri 01/26/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CheckSrcRect(
    const LPRECT lpSRCRect
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::CheckSrcRect")));

    DbgLog((LOG_TRACE, 4, TEXT("SRC: %d %d %d %d"),
            lpSRCRect->left, lpSRCRect->top,
            lpSRCRect->right, lpSRCRect->bottom));

    LONG Width, Height;
    HRESULT hr = E_INVALIDARG;

    __try {

        CHECK_HR(hr = GetNativeVideoSize(&Width, &Height, NULL, NULL));

        if ((lpSRCRect->left > lpSRCRect->right) ||
            (lpSRCRect->left < 0) ||
            (lpSRCRect->top  > lpSRCRect->bottom) ||
            (lpSRCRect->top  < 0))
        {
            hr = E_INVALIDARG;
            __leave;
        }

        if (lpSRCRect->right > Width || lpSRCRect->bottom > Height)
        {
            hr = E_INVALIDARG;
            __leave;
        }
    }
    __finally {
    }

    return hr;
}

/******************************Public*Routine******************************\
* SetVideoPosition
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetVideoPosition(
    const LPRECT lpSRCRect,
    const LPRECT lpDSTRect
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetVideoPosition")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (!lpSRCRect && !lpDSTRect) {
        return E_POINTER;
    }

    if (lpDSTRect) {
        hr = CheckDstRect(lpDSTRect);
        if (FAILED(hr)) {
            return hr;
        }
    }

    if (lpSRCRect) {
        hr = CheckSrcRect(lpSRCRect);
        if (FAILED(hr)) {
            return hr;
        }
    }

    if (m_lpCurrMon && m_lpCurrMon->pDDSPrimary) {

        DWORD dwUR = UpdateRectangles(lpSRCRect, lpDSTRect);

        //
        // if the video SRC or DST sizes have changed make sure the clipping
        // window's contents are still valid.
        //

        if ((dwUR & UR_SIZE) && (m_hwndClip != NULL)) {
            InvalidateRect(m_hwndClip, &m_rcDstApp, FALSE);
        }

        if (!MonitorChangeInProgress() && m_bUsingOverlays && (dwUR & UR_MOVE)) {

            //
            // If we're using overlays, but there's some restriction on
            // the shrink/alignment then switch off the overlay and blit
            // to the primary
            //

            m_bDisableOverlays =
                !(m_dwRenderingPrefs & RenderPrefs_ForceOverlays) &&
                ShouldDisableOverlays(m_lpCurrMon->ddHWCaps, m_rcSrcApp,
                                      m_rcDstDesktop);

            hr = UpdateOverlaySurface();
            if( SUCCEEDED( hr ) && !m_bDisableOverlays ) {
                hr = PaintColorKey();
            }
        }
    }
    else {
        hr = VFW_E_BUFFER_NOTSET;
    }

    return hr;
}

/******************************Public*Routine******************************\
* GetVideoPosition
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetVideoPosition(
    LPRECT lpSRCRect,
    LPRECT lpDSTRect
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetVideoPosition")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = VFW_E_BUFFER_NOTSET;
    if (m_lpCurrMon && m_lpCurrMon->pDDSPrimary) {

        hr = E_POINTER;

        if (lpSRCRect) {
            *lpSRCRect = m_rcSrcApp;
            hr = S_OK;
        }

        if (lpDSTRect) {
            *lpDSTRect = m_rcDstApp;
            hr = S_OK;
        }
    }
    return hr;
}


/******************************Public*Routine******************************\
* CAllocatorPresenter::GetAspectRatioMode
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetAspectRatioMode(
    DWORD* lpAspectRatioMode
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetAspectRationMode")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (!lpAspectRatioMode) {
        hr = E_POINTER;
    }

    if (SUCCEEDED(hr)) {
        *lpAspectRatioMode = m_dwARMode;
    }

    return hr;
}


/******************************Public*Routine******************************\
* CAllocatorPresenter::SetAspectRatioMode
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetAspectRatioMode(
    DWORD AspectRatioMode
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetAspectRationMode")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (AspectRatioMode != VMR_ARMODE_LETTER_BOX &&
        AspectRatioMode != VMR_ARMODE_NONE) {

        hr = E_INVALIDARG;
    }

    if (SUCCEEDED(hr)) {
        if (AspectRatioMode != m_dwARMode) {

            //
            // We can get away with repaint the dest rect
            // before setting the new mode becuase InvalidateRect
            // isn't synchronous.
            //

            InvalidateRect(m_hwndClip, &m_rcDstApp, FALSE);
        }

        m_dwARMode = AspectRatioMode;
    }

    return hr;
}


/******************************Public*Routine******************************\
* SetVideoClippingWindow
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetVideoClippingWindow(
    HWND hwnd
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetVideoClippingWindow")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = E_INVALIDARG;

    if ( ! IsWindow(hwnd) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid HWND")));
        return E_INVALIDARG;
    }

    for (DWORD i = 0; i < m_monitors.Count(); i++) {
        LPDIRECTDRAWSURFACE7 pPriSurf = m_monitors[i].pDDSPrimary;
        if ( pPriSurf ) {

            LPDIRECTDRAWCLIPPER lpDDClipper;
            hr = pPriSurf->GetClipper(&lpDDClipper);
            if (SUCCEEDED(hr)) {
                lpDDClipper->SetHWnd(0, hwnd);
                lpDDClipper->Release();
            }
        }
    }

    m_hwndClip = hwnd;

    return hr;
}


/******************************Public*Routine******************************\
* CAllocatorPresenter::RepaintVideo
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::RepaintVideo(
    HWND hwnd,
    HDC hdc
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::RepaintVideo")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = VFW_E_BUFFER_NOTSET;

    if (m_lpCurrMon && m_lpCurrMon->pDDSPrimary && SurfaceAllocated()) {

        hr = PresentImageWorker(m_pDDSDecode, 0, FALSE);

        PaintBorder();

        if (m_bUsingOverlays && !m_bDisableOverlays) {
            PaintColorKey();
        }

        PaintMonitorBorder();
    }

    return hr;
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::PaintBorder
*
*
*
* History:
* Wed 04/03/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PaintBorder()
{
    AMTRACE((TEXT("CAllocatorPresenter::PaintBorder")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_dwRenderingPrefs & RenderPrefs_DoNotRenderColorKeyAndBorder) {
        return S_OK;
    }

    if (m_dwARMode != VMR_ARMODE_LETTER_BOX) {
        return S_OK;
    }

    HRESULT hr = S_OK;
    RECT TargetRect;

    DDBLTFX ddFX;
    INITDDSTRUCT(ddFX);
    ddFX.dwFillColor = m_lpCurrMon->dwMappedBdrClr;

    RECT rcTmp = m_rcBdrTL;
    MapWindowRect(m_hwndClip, HWND_DESKTOP, &rcTmp);
    IntersectRect(&TargetRect, &rcTmp, &m_lpCurrMon->rcMonitor);


    if (!IsRectEmpty(&TargetRect)) {
        ASSERT( NULL != m_lpCurrMon->pDDSPrimary );
        OffsetRect(&TargetRect,
                   -m_lpCurrMon->rcMonitor.left,
                   -m_lpCurrMon->rcMonitor.top);

        hr = m_lpCurrMon->pDDSPrimary->Blt(&TargetRect, NULL, NULL,
                                           DDBLT_COLORFILL | DDBLT_WAIT,
                                           &ddFX);
        if (hr != DD_OK) {
            return hr;
        }
    }

    rcTmp = m_rcBdrBR;
    MapWindowRect(m_hwndClip, HWND_DESKTOP, &rcTmp);
    IntersectRect(&TargetRect, &rcTmp, &m_lpCurrMon->rcMonitor);

    if (!IsRectEmpty(&TargetRect)) {
        ASSERT( NULL != m_lpCurrMon->pDDSPrimary );
        OffsetRect(&TargetRect,
                   -m_lpCurrMon->rcMonitor.left,
                   -m_lpCurrMon->rcMonitor.top);

        hr = m_lpCurrMon->pDDSPrimary->Blt(&TargetRect, NULL, NULL,
                                           DDBLT_COLORFILL | DDBLT_WAIT,
                                           &ddFX);
    }

    return hr;
}


/*****************************Private*Routine******************************\
* MonitorBorderProc
*
*
*
* History:
* Wed 09/20/2000 - StEstrop - Created
*
\**************************************************************************/
BOOL CALLBACK
CAllocatorPresenter::MonitorBorderProc(
    HMONITOR hMonitor,
    HDC hdcMonitor,
    LPRECT lprcMonitor,
    LPARAM dwData
    )
{
    CAllocatorPresenter* lpThis = (CAllocatorPresenter*)dwData;
    lpThis->PaintMonitorBorderWorker(hMonitor, lprcMonitor);
    return TRUE;
}


/*****************************Private*Routine******************************\
* PaintMonitorBorderWorker
*
*
*
* History:
* Wed 09/20/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PaintMonitorBorderWorker(
    HMONITOR hMonitor,
    LPRECT lprcDst
    )
{
    if (hMonitor != m_lpCurrMon->hMon) {

        CAMDDrawMonitorInfo* lp = m_monitors.FindMonitor(hMonitor);

        // CMonitorArray::FindMonitor() returns NULL if a mirroring display
        // device is installed on the system.  Direct Draw does not enumerate
        // mirroring display devices so the VMR does not create a
        // CAMDDrawMonitorInfo object which corresponded to the device.  This
        // is by design.  However, EnumDisplayMonitors() does enumerate mirroring
        // display devices and it passes handles to these devices to
        // PaintMonitorBorderWorker() (actually EnumDisplayMonitors() calls
        // CAllocatorPresenter::MonitorBorderProc() and MonitorBorderProc() calls
        // PaintMonitorBorderWorker()) .  PaintMonitorBorderWorker() calls
        // FindMonitor() to get the CAMDDrawMonitorInfo object which corresponds
        // to the monitor handle.  FindMonitor() returns NULL if it cannot find
        // a CAMDDrawMonitorInfo object which corresponds to the handle.
        // FindMonitor() cannot find a CAMDDrawMonitorInfo objects for monitors
        // which are not enumerated by Direct Draw and therefore it cannot find
        // a CAMDDrawMonitorInfo object for a mirroring display device.
        if (NULL != lp) {
            DDBLTFX ddFX;
            INITDDSTRUCT(ddFX);
            ddFX.dwFillColor = lp->dwMappedBdrClr;

            RECT TargetRect;
            RECT rcTmp = *lprcDst;
            IntersectRect(&TargetRect, &rcTmp, &lp->rcMonitor);

            if (!IsRectEmpty(&TargetRect)) {
                ASSERT( NULL != lp->pDDSPrimary );
                OffsetRect(&TargetRect, -lp->rcMonitor.left, -lp->rcMonitor.top);

                lp->pDDSPrimary->Blt(&TargetRect, NULL, NULL,
                                     DDBLT_COLORFILL | DDBLT_WAIT,
                                     &ddFX);
            }
        }
    }

    return S_OK;
}

/******************************Public*Routine******************************\
* PaintMonitorBorder
*
* Paints the are of the playback window that falls on a diferent monitor to
* current monitor.  This function only performs painting if we are on a
* multimonitor system and the playback rectangle actually intersects more
* one monitor.
*
* Playback perf may well drop off dramatically!
*
* History:
* Wed 09/20/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PaintMonitorBorder()
{
    AMTRACE((TEXT("CAllocatorPresenter::PaintKey")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_dwRenderingPrefs & RenderPrefs_DoNotRenderColorKeyAndBorder) {
        return S_OK;
    }

    if (m_bMonitorStraddleInProgress|| !m_bStreaming) {
        EnumDisplayMonitors((HDC)NULL, &m_rcDstDskIncl, MonitorBorderProc,
                            (LPARAM)this);
    }

    return S_OK;
}


/******************************Private*Routine******************************\
* CAllocatorPresenter::PaintColorKey
*
*
*
* History:
* Wed 04/03/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::PaintColorKey()
{
    AMTRACE((TEXT("CAllocatorPresenter::PaintColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_dwRenderingPrefs & RenderPrefs_DoNotRenderColorKeyAndBorder) {
        return S_OK;
    }

    if( !IsRectEmpty( &m_rcDstDesktop )) {

        if( m_dwMappedColorKey == CLR_INVALID ) {
            m_dwMappedColorKey = MapColorToMonitor( *m_lpCurrMon, m_clrKey );
        }

        //
        // Peform a DirectDraw colorfill BLT.  DirectDraw will automatically
        // query the attached clipper object, handling occlusion.
        //

        DDBLTFX ddFX;
        INITDDSTRUCT(ddFX);
        ddFX.dwFillColor = m_dwMappedColorKey;

        ASSERT( NULL != m_lpCurrMon->pDDSPrimary );

        RECT TargetRect;
        IntersectRect(&TargetRect, &m_rcDstDesktop, &m_lpCurrMon->rcMonitor);
        HRESULT hr = S_OK;
        if (!IsRectEmpty(&TargetRect)) {

            OffsetRect(&TargetRect,
                       -m_lpCurrMon->rcMonitor.left,
                       -m_lpCurrMon->rcMonitor.top);

            hr = m_lpCurrMon->pDDSPrimary->Blt(&TargetRect, NULL, NULL,
                                               DDBLT_COLORFILL | DDBLT_WAIT,
                                               &ddFX);
        }

        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pPrimarySurface->Blt ")
                    TEXT("{%d, %d, %d, %d} failed, hr = 0x%X"),
                    TargetRect.left, TargetRect.top,
                    TargetRect.right, TargetRect.bottom, hr));
        }

        return hr;
    }
    return S_OK;
}

/******************************Public*Routine******************************\
* CAllocatorPresenter::DisplayModeChanged
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::DisplayModeChanged()
{
    AMTRACE((TEXT("CAllocatorPresenter::DisplayModeChanged")));
    CAutoLock Lock(&m_ObjectLock);

    //
    // DisplayModeChanged() holds this lock because it prevents multiple threads
    // from simultaneously calling it.  It also holds the lock because it prevents
    // a thread from modifing m_monitors while DisplayModeChanged() calls
    // IVMRSurfaceAllocatorNotify::ChangeDDrawDevice().
    //
    CAutoLock DisplayModeChangedLock(&m_DisplayModeChangedLock);

    HRESULT hr = S_OK;
    DbgLog((LOG_TRACE, 1, TEXT("CAllocatorPresenter::DisplayModeChanged")));

    m_monitors.TerminateDisplaySystem();
    m_lpNewMon = NULL;
    m_lpCurrMon = NULL;
    hr = m_monitors.InitializeDisplaySystem( m_hwndClip );

    DbgLog((LOG_TRACE, 1, TEXT("Display system re-initialized")));

    if (SUCCEEDED(hr)) {

        //
        // The docs say that MonitorFromRect will always return a Monitor.
        //

        HMONITOR hMon = MonitorFromRect(&m_rcDstDesktop, MONITOR_DEFAULTTONEAREST);

        //
        // now look for this monitor in our monitor info array
        //

        CAMDDrawMonitorInfo* lpMon = m_monitors.FindMonitor( hMon );
        if (lpMon) {
            m_lpCurrMon = m_lpNewMon = lpMon;
        }
        ASSERT(m_lpCurrMon != NULL);

        if (m_pSurfAllocatorNotify && lpMon) {
            m_ObjectLock.Unlock();
            m_pSurfAllocatorNotify->ChangeDDrawDevice(lpMon->pDD,
                                                      lpMon->hMon);
            m_ObjectLock.Lock();
        }
        return S_OK;
    }

    DbgLog((LOG_ERROR, 1, TEXT("display system re-init failed err: %#X"), hr));

    return hr;
}


/******************************Public*Routine******************************\
* SetBorderColor
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetBorderColor(
    COLORREF Clr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetBorderColor")));
    CAutoLock Lock(&m_ObjectLock);

    // PaintBorder() and PaintMonitorBorder() expect FoundCurrentMonitor()
    // to return true.  Both functions crash if they are called and
    // FoundCurrentMonitor() returns false.
    if (!FoundCurrentMonitor()) {
        return E_FAIL;
    }

    m_clrBorder = Clr;
    for (DWORD i = 0; i < m_monitors.Count(); i++) {
        m_monitors[i].dwMappedBdrClr = MapColorToMonitor(m_monitors[i], Clr);
    }

    PaintBorder();
    PaintMonitorBorder();

    m_pSurfAllocatorNotify->SetBorderColor(Clr);

    return S_OK;
}

/******************************Public*Routine******************************\
* GetBorderColor
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetBorderColor(
    COLORREF* lpClr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetBorderColor")));
    if (!lpClr ) {
        DbgLog((LOG_ERROR, 1, TEXT("border key parameter is NULL!!")));
        return E_POINTER;
    }
    CAutoLock Lock(&m_ObjectLock);
    *lpClr = m_clrBorder;

    return S_OK;
}

/******************************Public*Routine******************************\
* SetColorKey
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetColorKey(
    COLORREF Clr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetColorKey")));
    CAutoLock Lock(&m_ObjectLock);
    m_clrKey = Clr;

    // map now (if possible) to avoid locking the primary later
    HRESULT hr = S_OK;
    ASSERT(m_lpCurrMon);

    if (m_lpCurrMon) {

        m_dwMappedColorKey = MapColorToMonitor(*m_lpCurrMon, Clr);

        if (m_bUsingOverlays) {

            ASSERT(NULL != m_lpCurrMon->pDDSPrimary);

            DDCOLORKEY DDColorKey = {m_dwMappedColorKey, m_dwMappedColorKey};
            hr = m_lpCurrMon->pDDSPrimary->SetColorKey(DDCKEY_DESTOVERLAY,&DDColorKey);
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* GetColorKey
*
*
*
* History:
* Mon 02/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetColorKey(
    COLORREF* lpClr
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetColorKey")));
    if (!lpClr ) {
        DbgLog((LOG_ERROR, 1, TEXT("colour key parameter is NULL!!")));
        return E_POINTER;
    }
    CAutoLock Lock(&m_ObjectLock);
    *lpClr = m_clrKey;
    return S_OK;
}



/*****************************Private*Routine******************************\
* IsDestRectOnWrongMonitor
*
* Has the DstRect moved at least 50% onto a monitor other than the current
* monitor.  If so, pMonitor will be the hMonitor of the monitor the DstRect
* is now on.
*
* History:
* Fri 04/14/2000 - StEstrop - Created
*
\**************************************************************************/
bool
CAllocatorPresenter::IsDestRectOnWrongMonitor(
    CAMDDrawMonitorInfo** lplpNewMon
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::IsDestRectOnWrongMonitor")));

    HMONITOR hMon = m_lpCurrMon->hMon;
    *lplpNewMon = m_lpCurrMon;
    m_bMonitorStraddleInProgress = FALSE;

    if (!IsWindow(m_hwndClip)) {

        DbgLog((LOG_ERROR, 1, TEXT("Playback Window destroyed!")));
        return false;
    }

    if (GetSystemMetrics(SM_CMONITORS) > 1 && !IsIconic(m_hwndClip)) {

        //
        // Look for any part of our destination rect going over
        // another monitor
        //
        if (!IsRectEmpty(&m_rcDstDskIncl) &&
            !ContainedRect(&m_rcDstDskIncl, &m_lpCurrMon->rcMonitor)) {

            m_bMonitorStraddleInProgress = TRUE;
        }

        //
        // If the dstRect is on a different monitor from last time, this is the
        // quickest way to find out.  This is called every frame, remember.
        //
        if (!IsRectEmpty(&m_rcDstDesktop) &&
            !ContainedRect(&m_rcDstDesktop, &m_lpCurrMon->rcMonitor)) {

            //
            // The docs say that MonitorFromRect will always return a Monitor.
            //

            hMon = MonitorFromRect(&m_rcDstDesktop, MONITOR_DEFAULTTONEAREST);

            DbgLog((LOG_TRACE, 2, TEXT("Curr Mon %#X New Mon %#X"),
                    m_lpCurrMon->hMon, hMon));

            //
            // now look for this monitor in our monitor info array
            //

            CAMDDrawMonitorInfo* lpMon = m_monitors.FindMonitor(hMon);
            if( lpMon ) {
                *lplpNewMon = lpMon;
            }
        }
    }

    return  m_lpCurrMon->hMon != hMon;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\aptimer.cpp ===
/******************************Module*Header*******************************\
* Module Name: aptimer.cpp
*
* Heartbeat timer proc for the allocator/presenter.  Takes care of
* surface loss and restoration.  Notifies the VMR of a sucessful
* surface restore (via RestoreDDrawSurfaces on IVMRSurfaceAllocatorNotify).
*
*
* Created: Thu 09/07/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"


/******************************Public*Routine******************************\
* APHeartBeatTimerProc
*
*
*
* History:
* Wed 03/15/2000 - StEstrop - Created
*
\**************************************************************************/
void CALLBACK
CAllocatorPresenter::APHeartBeatTimerProc(
    UINT uID,
    UINT uMsg,
    DWORD_PTR dwUser,
    DWORD_PTR dw1,
    DWORD_PTR dw2
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::APHeartBeatTimerProc")));
    CAllocatorPresenter* lp = (CAllocatorPresenter*)dwUser;
    lp->TimerProc();
}


/*****************************Private*Routine******************************\
* TimerProc
*
* Used to restore lost DDraw surfaces and also to make sure that the
* overlay (if used) is correctly positioned.
*
* History:
* Fri 03/17/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::TimerProc()
{
    AMTRACE((TEXT("CAllocatorPresenter::RestoreSurfaceIfNeeded")));
    CAutoLock Lock(&m_ObjectLock);

    if (m_lpCurrMon && m_lpCurrMon->pDDSPrimary) {

        if (m_lpCurrMon->pDDSPrimary->IsLost() == DDERR_SURFACELOST) {

            DbgLog((LOG_TRACE, 0, TEXT("Surfaces lost")));


            //
            // Restore all the surfaces for each monitor.
            //

            for (DWORD i = 0; i < m_monitors.Count(); i++) {

                if (m_monitors[i].pDD) {
                    HRESULT hr = m_monitors[i].pDD->RestoreAllSurfaces();
                    DbgLog((LOG_TRACE, 0,
                            TEXT("Restore for monitor %i = %#X"), i, hr));
                }
            }


            if (SurfaceAllocated() && m_pSurfAllocatorNotify) {

                DbgLog((LOG_TRACE, 0, TEXT("Notifying VMR")));

                PaintDDrawSurfaceBlack(m_pDDSDecode);

                m_ObjectLock.Unlock();
                m_pSurfAllocatorNotify->RestoreDDrawSurfaces();
                m_ObjectLock.Lock();

                if (m_bUsingOverlays && !m_bDisableOverlays) {

                    UpdateRectangles(NULL, NULL);
                    HRESULT hr = UpdateOverlaySurface();
                    if (SUCCEEDED(hr)) {
                        hr = PaintColorKey();
                    }

                    return S_OK;
                }
            }
        }

        if (SurfaceAllocated() &&
            m_bUsingOverlays && !m_bDisableOverlays) {

            if (UpdateRectangles(NULL, NULL)) {
                HRESULT hr = UpdateOverlaySurface();
                if (SUCCEEDED(hr)) {
                    hr = PaintColorKey();
                }
            }
        }
    }

    return S_OK;
}


/*****************************Private*Routine******************************\
* RenderSampleOnMMThread
*
*
*
* History:
* Wed 01/17/2001 - StEstrop - Created
*
\**************************************************************************/
void CALLBACK
CAllocatorPresenter::RenderSampleOnMMThread(
    UINT uID,
    UINT uMsg,
    DWORD_PTR dwUser,
    DWORD_PTR dw1,
    DWORD_PTR dw2
    )
{
    CAllocatorPresenter* lp = (CAllocatorPresenter*)dwUser;
    CAutoLock Lock(&lp->m_ObjectLock);

    LPDIRECTDRAWSURFACE7 lpDDS = lp->m_pDDSDecode;
    if (uID == lp->m_MMTimerId && lpDDS) {

        DWORD dwFlipFlag = DDFLIP_EVEN;

        if (lp->m_dwCurrentField == DDFLIP_EVEN) {
            dwFlipFlag = DDFLIP_ODD;
        }
        dwFlipFlag |= (DDFLIP_DONOTWAIT | DDFLIP_NOVSYNC);

        HRESULT hr = lpDDS->Flip(lpDDS, dwFlipFlag);
    }
}

/*****************************Private*Routine******************************\
* ScheduleSampleUsingMMThread
*
*
*
* History:
* Wed 01/17/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::ScheduleSampleUsingMMThread(
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    LONG lDelay = (LONG)ConvertToMilliseconds(lpPresInfo->rtEnd - lpPresInfo->rtStart);

    m_PresInfo = *lpPresInfo;
    if (lDelay > 0) {
        DbgLog((LOG_TRACE, 1, TEXT("lDelay = %d"), lDelay));
        m_MMTimerId = CompatibleTimeSetEvent(lDelay,
                                             1,
                                             RenderSampleOnMMThread,
                                             (DWORD_PTR)this,
                                             TIME_ONESHOT);
    }
    else {
        RenderSampleOnMMThread(0, 0, (DWORD_PTR)this, 0, 0);
    }

    return S_OK;
}

/*****************************Private*Routine******************************\
* CancelMMTimer
*
*
*
* History:
* Thu 01/18/2001 - StEstrop - Created
*
\**************************************************************************/
void
CAllocatorPresenter::CancelMMTimer()
{
    // kill the MMthread timer as well
    if (m_MMTimerId)
    {
        timeKillEvent(m_MMTimerId);

        CAutoLock cObjLock(&m_ObjectLock);
        m_MMTimerId = 0;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\apmon.cpp ===
/******************************Module*Header*******************************\
* Module Name: apmon.cpp
*
* Monitor configuration support.
*
*
* Created: Tue 09/19/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>


#include <atlconv.h>
#ifdef FILTER_DLL
LPWSTR WINAPI AtlA2WHelper(LPWSTR lpw, LPCSTR lpa, int nChars)
{
        ASSERT(lpa != NULL);
        ASSERT(lpw != NULL);
        // verify that no illegal character present
        // since lpw was allocated based on the size of lpa
        // don't worry about the number of chars
        lpw[0] = '\0';
        MultiByteToWideChar(CP_ACP, 0, lpa, -1, lpw, nChars);
        return lpw;
}

LPSTR WINAPI AtlW2AHelper(LPSTR lpa, LPCWSTR lpw, int nChars)
{
        ASSERT(lpw != NULL);
        ASSERT(lpa != NULL);
        // verify that no illegal character present
        // since lpa was allocated based on the size of lpw
        // don't worry about the number of chars
        lpa[0] = '\0';
        WideCharToMultiByte(CP_ACP, 0, lpw, -1, lpa, nChars, NULL, NULL);
        return lpa;
}
#endif

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"

extern "C"
const TCHAR chRegistryKey[] = TEXT("Software\\Microsoft\\Multimedia\\")
                              TEXT("ActiveMovie Filters\\Video Mixing Renderer");
const TCHAR szDDrawGUID[] = TEXT("DDraw Connection Device GUID");

/*****************************Private*Routine******************************\
* SetRegistryString
*
*
*
* History:
* Wed 08/18/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
SetRegistryString(
    HKEY hk,
    const TCHAR* pKey,
    const TCHAR* szString
    )
{
    HKEY hKey;
    LONG lRet;

    lRet = RegCreateKey(hk, chRegistryKey, &hKey);
    if (lRet == ERROR_SUCCESS) {

        lRet = RegSetValueEx(hKey, pKey, 0L, REG_SZ,
                             (LPBYTE)szString,
                             sizeof(TCHAR) * lstrlen(szString));
        RegCloseKey(hKey);
    }

    if (lRet == ERROR_SUCCESS) {
        return S_OK;
    }

    return AmHresultFromWin32(lRet);
}


/*****************************Private*Routine******************************\
* GetRegistryString
*
*
*
* History:
* Wed 08/18/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
GetRegistryString(
    HKEY hk,
    const TCHAR* pKey,
    TCHAR* szString,
    PLONG lpLength
    )
{
    HKEY hKey;
    LONG lRet;

    lRet = RegOpenKeyEx(hk, chRegistryKey, 0, KEY_QUERY_VALUE, &hKey);
    if (lRet == ERROR_SUCCESS) {

        DWORD dwType;
        lRet = RegQueryValueEx(hKey, pKey, 0L, &dwType,
                               (LPBYTE)szString, (LPDWORD)lpLength);
        RegCloseKey(hKey);
    }

    if (lRet == ERROR_SUCCESS) {
        return S_OK;
    }

    return AmHresultFromWin32(lRet);
}

/******************************Public*Routine******************************\
* SetMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetMonitor(
    const VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetMonitor")));
    // TBD: Check that we aren't already using a DDraw device
    //if (m_pDirectDraw) {
    //    return VFW_E_ALREADY_CONNECTED;
    //}

    if (ISBADREADPTR(pGUID)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    if (pGUID->pGUID) {
        if (!IsEqualGUID(pGUID->GUID, *pGUID->pGUID)) {
            return E_INVALIDARG;
        }
    }

    CAutoLock Lock(&m_ObjectLock);
    DWORD dwMatchID;

    HRESULT hr = m_monitors.MatchGUID(pGUID->pGUID, &dwMatchID);
    if (hr == S_FALSE) {
        return E_INVALIDARG;
    }

    m_lpCurrMon = &m_monitors[dwMatchID];

    if (pGUID->pGUID) {
        m_ConnectionGUID.pGUID = &m_ConnectionGUID.GUID;
        m_ConnectionGUID.GUID = pGUID->GUID;
    } else {
        m_ConnectionGUID.pGUID = NULL;
        m_ConnectionGUID.GUID = GUID_NULL;
    }

    return S_OK;
}

/******************************Public*Routine******************************\
* GetMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetMonitor(
    VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetMonitor")));
    CAutoLock Lock(&m_ObjectLock);
    if (ISBADWRITEPTR(pGUID))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    // copy GUID and return S_OK;
    *pGUID = m_ConnectionGUID;

    return S_OK;
}

/******************************Public*Routine******************************\
* SetDefaultMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::SetDefaultMonitor(
    const VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::SetDefaultMonitor")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADREADPTR(pGUID))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    if (pGUID->pGUID) {
        if (!IsEqualGUID(pGUID->GUID, *pGUID->pGUID)) {
            return E_INVALIDARG;
        }
    }

    // match the supplied GUID with those DDraw devices available
    DWORD dwMatchID;
    HRESULT hr = m_monitors.MatchGUID(pGUID->pGUID, &dwMatchID);

    // if match not found return E_INVALIDARG
    if (hr == S_FALSE) {
        return E_INVALIDARG;
    }

    // if the caller is trying to make the default device the NULL
    // DDraw device, just delete the registry key.
    if (pGUID->pGUID == NULL) {

        HKEY hKey;
        LONG lRet = RegOpenKeyEx(HKEY_LOCAL_MACHINE,
                                 chRegistryKey, 0,
                                 KEY_SET_VALUE, &hKey);

        if (lRet == ERROR_FILE_NOT_FOUND) {
            lRet = ERROR_SUCCESS;
        }
        else if (lRet == ERROR_SUCCESS) {

            lRet = RegDeleteValue(hKey, szDDrawGUID);
            if (lRet == ERROR_FILE_NOT_FOUND) {
                lRet = ERROR_SUCCESS;
            }
            RegCloseKey(hKey);
        }

        if (lRet == ERROR_SUCCESS)
            return S_OK;

        return AmHresultFromWin32(lRet);
    }

    // convert GUID into string
    LPOLESTR lpsz;
    hr = StringFromCLSID(pGUID->GUID, &lpsz);
    if (FAILED(hr)) {
        return hr;
    }

    // write the string into the registry
    USES_CONVERSION;
    hr = SetRegistryString(HKEY_LOCAL_MACHINE, szDDrawGUID, OLE2T(lpsz));

    CoTaskMemFree(lpsz);

    return hr;
}

/******************************Public*Routine******************************\
* GetDefaultMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetDefaultMonitor(
    VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetDefaultMonitor")));
    CAutoLock Lock(&m_ObjectLock);
    if (ISBADWRITEPTR(pGUID)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    // read string from the registry
    TCHAR   szGUID[64];
    LONG    lLen = 64;
    HRESULT hr = GetRegistryString(HKEY_LOCAL_MACHINE, szDDrawGUID,
                                   szGUID, &lLen);

    // if string not in registry return the default (NULL) DDraw device
    if (FAILED(hr)) {
        pGUID->pGUID = NULL;
        return S_OK;
    }

    // convert string into GUID and return
    pGUID->pGUID = &pGUID->GUID;

    USES_CONVERSION;
    hr = IIDFromString(T2OLE(szGUID), pGUID->pGUID);

    return hr;
}

/******************************Public*Routine******************************\
* GetAvailableMonitors
*
* Allocates and returns an array of VMRMONITORINFO structures, one for
* for each direct draw device attached to a display monitor.
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CAllocatorPresenter::GetAvailableMonitors(
    VMRMONITORINFO* pInfo,
    DWORD dwMaxInfoArraySize,
    DWORD* pdwNumDevices
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetAvailableMonitors")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(pdwNumDevices)) {

        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    if (pInfo) {

        if (0 == dwMaxInfoArraySize) {
            DbgLog((LOG_ERROR, 1, TEXT("Invalid array size of 0")));
            return E_INVALIDARG;
        }

        if (ISBADWRITEARRAY( pInfo, dwMaxInfoArraySize)) {
            DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
            return E_POINTER;
        }
    }
    else {

        // they just want the count
        *pdwNumDevices = m_monitors.Count();
        return S_OK;
    }

    *pdwNumDevices = min(dwMaxInfoArraySize, m_monitors.Count());

    // copy the VRMMONITORINFO portion of each monitor info block
    for (DWORD i = 0; i < *pdwNumDevices; i++)  {

        pInfo[i] = m_monitors[i];

        DDDEVICEIDENTIFIER2 did;
        if (DD_OK == m_monitors[i].pDD->GetDeviceIdentifier(&did, 0)) {

            pInfo[i].liDriverVersion = did.liDriverVersion;
            pInfo[i].dwVendorId = did.dwVendorId;
            pInfo[i].dwDeviceId = did.dwDeviceId;
            pInfo[i].dwSubSysId = did.dwSubSysId;
            pInfo[i].dwRevision = did.dwRevision;
        }
    }

    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\apovly.cpp ===
/******************************Module*Header*******************************\
* Module Name: apovly.cpp
*
* Overlay support functions
*
*
* Created: Tue 09/19/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>
#include <malloc.h>

#include "apobj.h"
#include "AllocLib.h"
#include "MediaSType.h"
#include "vmrp.h"



/*****************************Private*Routine******************************\
* GetUpdateOverlayFlags
*
* given the interlace flags and the type-specific flags, this function
* determines whether we are supposed to display the sample in bob-mode or not.
* It also tells us, which direct-draw flag are we supposed to use when
* flipping. When displaying an interleaved frame, it assumes we are
* talking about the field which is supposed to be displayed first.
*
* History:
* Mon 01/08/2001 - StEstrop - Created (from the OVMixer original)
*
\**************************************************************************/
DWORD
CAllocatorPresenter::GetUpdateOverlayFlags(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::GetUpdateOverlayFlags")));

    //
    // early out if not using overlays.
    //
    if (!m_bUsingOverlays) {
        return 0;
    }

    DWORD dwFlags = DDOVER_SHOW | DDOVER_KEYDEST;
    DWORD dwFlipFlag;

    if (NeedToFlipOddEven(dwInterlaceFlags, dwTypeSpecificFlags,
                          &dwFlipFlag, m_bUsingOverlays))
    {
        dwFlags |= DDOVER_BOB;
        if (!IsSingleFieldPerSample(dwInterlaceFlags))
            dwFlags |= DDOVER_INTERLEAVED;
    }

    return dwFlags;
}


/******************************Private*Routine******************************\
* CAllocatorPresenter::ShouldDisableOverlays
*
* Certain src/dest combinations might not be valid for overlay
* stretching/alignments In these cases, we turn off the overlay and
* stretch blit to the primary
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
bool
CAllocatorPresenter::ShouldDisableOverlays(
    const DDCAPS_DX7& ddCaps,
    const RECT& rcSrc,
    const RECT& rcDest
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::ShouldDisableOverlays")));

    //
    // Unfortunately it is not always possible to Blt from an active
    // overlay.  So this "feature" needs to be disabled.
    //
    return false;

    DWORD dwSrcWidth = WIDTH(&rcSrc);
    DWORD dwSrcHeight = HEIGHT(&rcSrc);

    DWORD dwDestWidth = WIDTH(&rcDest);
    DWORD dwDestHeight = HEIGHT(&rcDest);

    // shrinking horizontally and driver can't arbitrarly shrink in X ?
    if ( 0==(ddCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKX) &&
        dwSrcWidth > dwDestWidth )
    {
        return true;
    }

    // shrinking vertically and driver can't arbitrarly shrink in Y ?
    if ( 0==(ddCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKY) &&
        dwSrcHeight > dwDestHeight ) {

        return true;
    }

    if( dwSrcWidth ) {
        // check to see if we're in the scaling range of the card
        DWORD dwScaleX = (DWORD) MulDiv( 1000, (int) dwDestWidth, (int) dwSrcWidth );
        if (ddCaps.dwMinOverlayStretch && dwScaleX < ddCaps.dwMinOverlayStretch ) {
            return true;
        }
        if (ddCaps.dwMaxOverlayStretch && dwScaleX > ddCaps.dwMaxOverlayStretch ) {
            return true;
        }
    }
    else {
        return true;
    }

    if( dwSrcHeight ) {
        DWORD dwScaleY = (DWORD) MulDiv( 1000, (int) dwDestHeight, (int) dwSrcHeight );

        if (ddCaps.dwMinOverlayStretch && dwScaleY < ddCaps.dwMinOverlayStretch ) {
            return true;
        }
        if (ddCaps.dwMaxOverlayStretch && dwScaleY > ddCaps.dwMaxOverlayStretch ) {
            return true;
        }
    }
    else {
        return true;
    }

    return false;
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::AlignOverlayRects
*
* Adjust src & destination rectangles to hardware alignments
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
void
CAllocatorPresenter::AlignOverlayRects(
    const DDCAPS_DX7& ddCaps,
    RECT& rcSrc,
    RECT& rcDest
    )
{
    // m_bDisableOverlays = !(m_dwRenderingPrefs & RenderPrefs_ForceOverlays) &&

    AMTRACE((TEXT("CAllocatorPresenter::AlignOverlayRects")));

    // precrop if we can't reduce scale
    {
        DWORD dwSrcWidth = WIDTH(&rcSrc);
        DWORD dwDestWidth = WIDTH(&rcDest);

        // shrinking horizontally and driver can't arbitrarly shrink in X ?
        if ((!(ddCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKX)) && dwSrcWidth > dwDestWidth ) {
            // crop n copy at 1:1 scale
            dwSrcWidth = dwDestWidth;
        } else if( ddCaps.dwMinOverlayStretch ) {
            // check to see if we're in the scaling range of the card
            DWORD dwScaleX = (DWORD) MulDiv( 1000, (int) dwDestWidth, (int) dwSrcWidth );
            if ( dwScaleX < ddCaps.dwMinOverlayStretch ) {
                // compute fraction of dest to crop
                // at the minimum:
                // dest = src * (minOverlayStretch_1000/1000)
                // so
                //  src = dest * 1000 / (minOverlayStretch_1000 + eps)
                //
                // The EPS forces the rounding so that we'll be slightly over scale and not
                // underflow under the MinStretch
                dwSrcWidth = MulDiv( dwDestWidth, 1000,  ddCaps.dwMinOverlayStretch+1);
            }
        }

        DWORD dwSrcHeight = HEIGHT(&rcSrc);
        DWORD dwDestHeight = HEIGHT(&rcDest);

        // shrinking vertically and driver can't arbitrarly shrink in Y ?
        if ((!(ddCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKY)) && dwSrcHeight > dwDestHeight ) {
            // crop n copy at 1:1 scale
            dwSrcHeight = dwDestHeight;
        } else if( ddCaps.dwMinOverlayStretch ) {

            // check to see if we're in the scaling range of the card
            DWORD dwScaleY = (DWORD) MulDiv(1000, (int) dwDestHeight, (int)dwSrcHeight);
            if (dwScaleY < ddCaps.dwMinOverlayStretch ) {
                // compute fraction of dest to crop
                // at the minimum:
                // dest = src * (minOverlayStretch_1000/1000)
                // so
                //  src = dest * 1000 / (minOverlayStretch_1000 + eps)
                //
                // The EPS forces the rounding so that we'll be slightly over scale and not
                // underflow under the MinStretch
                dwSrcHeight = MulDiv(dwDestHeight, 1000, ddCaps.dwMinOverlayStretch+1);
            }
        }

        // adjust rectangle to agree with new sizes
        rcSrc.right = rcSrc.left + dwSrcWidth;
        rcSrc.bottom = rcSrc.top + dwSrcHeight;
    }

    // align the dest boundary (remember we can only decrease the DestRect.left).
    // Use of colorkey will make sure that that we are clipped properly.
    if ((ddCaps.dwCaps) & DDCAPS_ALIGNBOUNDARYDEST)
    {
        DWORD dwDelta = rcDest.left & (ddCaps.dwAlignBoundaryDest-1);
        rcDest.left -= dwDelta;
        ASSERT(rcDest.left >= 0);
    }

    // align the dest width (remember we can only increase the DestRect.right).
    // Use of colorkey will make sure that that we are clipped properly.
    if ((ddCaps.dwCaps) & DDCAPS_ALIGNSIZEDEST)
    {
        DWORD dwDelta = (rcDest.right - rcDest.left) & (ddCaps.dwAlignSizeDest-1);
        if (dwDelta != 0)
        {
            rcDest.right += ddCaps.dwAlignBoundaryDest - dwDelta;
        }
    }

    // align the src boundary (remember we can only increase the SrcRect.left)
    if ((ddCaps.dwCaps) & DDCAPS_ALIGNBOUNDARYSRC)
    {
        DWORD dwDelta = rcSrc.left & (ddCaps.dwAlignBoundarySrc-1);
        if (dwDelta != 0)
        {
            rcSrc.left += ddCaps.dwAlignBoundarySrc - dwDelta;
        }
    }

    // align the src width (remember we can only decrease the SrcRect.right)
    if ((ddCaps.dwCaps) & DDCAPS_ALIGNSIZESRC)
    {
        DWORD dwDelta = (rcSrc.right - rcSrc.left) & (ddCaps.dwAlignSizeSrc-1);
        rcSrc.right -= dwDelta;
    }
}


/******************************Private*Routine******************************\
* WaitForFlipStatus
*
* Wait until the flip completes
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
void
CAllocatorPresenter::WaitForFlipStatus()
{
#if 0
    ASSERT( m_lpCurrMon->pOverlayBack );
    while (m_lpCurrMon->pOverlayBack->GetFlipStatus(DDGFS_ISFLIPDONE) == DDERR_WASSTILLDRAWING)
        Sleep(0);
#endif
}

/******************************Private*Routine******************************\
* HideOverlaySurface
*
* Hides the overlay surface
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
void
CAllocatorPresenter::HideOverlaySurface()
{
    AMTRACE((TEXT("CAllocatorPresenter::HideOverlaySurface")));

    // Is the overlay already hidden
    if (m_bOverlayVisible && FoundCurrentMonitor() && SurfaceAllocated()) {

        // Reset our state and draw a normal background

        m_bOverlayVisible = false;
        WaitForFlipStatus();

        // Hide the overlay with the DDOVER_HIDE flag
        m_pDDSDecode->UpdateOverlay(NULL,
                                    m_lpCurrMon->pDDSPrimary,
                                    NULL,  		
                                    DDOVER_HIDE,
                                    NULL);
    }
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::UpdateOverlaySurface
*
* Update the overlay surface to position it correctly.
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::UpdateOverlaySurface()
{
    AMTRACE((TEXT("CAllocatorPresenter::UpdateOverlaySurface")));
    CAutoLock Lock(&m_ObjectLock);

    ASSERT(m_bUsingOverlays);

    if (!m_lpCurrMon) {
        DbgLog((LOG_ERROR, 1, TEXT("No current monitor")));
        return E_FAIL;
    }

    if (!SurfaceAllocated()) {
        DbgLog((LOG_ERROR, 1, TEXT("No overlay surface")));
        return E_FAIL;
    }

    HRESULT hr = NOERROR;

    // Position the overlay with the current source and destination

    RECT rcDest = m_rcDstDesktop;
    RECT rcSrc = m_rcSrcApp;

    // clip destination & adjust source to mirror destination changes
    ClipRectPair(rcSrc, rcDest, m_lpCurrMon->rcMonitor);

    if (IsSingleFieldPerSample(m_dwInterlaceFlags)) {
        rcSrc.top /= 2;
        rcSrc.bottom /= 2;
    }

    if (m_bDecimating) {
        rcSrc.left    /= 2;
        rcSrc.top     /= 2;
        rcSrc.right   /= 2;
        rcSrc.bottom  /= 2;
    }

    if (m_bDisableOverlays || IsRectEmpty(&rcDest)) {

        HideOverlaySurface();

    }
    else if (!IsRectEmpty(&rcSrc)) {

        OffsetRect(&rcDest,
                   -m_lpCurrMon->rcMonitor.left,
                   -m_lpCurrMon->rcMonitor.top);

        // align it
        AlignOverlayRects( m_lpCurrMon->ddHWCaps, rcSrc, rcDest );

        if (!IsRectEmpty(&rcDest) && !IsRectEmpty( &rcSrc)) {

            WaitForFlipStatus();

            hr = m_pDDSDecode->UpdateOverlay(&rcSrc,
                                             m_lpCurrMon->pDDSPrimary,
                                             &rcDest,
                                             m_dwUpdateOverlayFlags,
                                             NULL);
            m_bOverlayVisible = true;
            ASSERT(hr != DDERR_WASSTILLDRAWING);
        }
        else {
            HideOverlaySurface();
        }

    }
    else {

        ASSERT( !"This shouldn't occur" );
        hr = E_FAIL;
    }

    return hr;
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::FlipSurface
*
* Flip the back buffer to the visible primary
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/

HRESULT CAllocatorPresenter::FlipSurface(
    LPDIRECTDRAWSURFACE7 lpSurface
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::FlipSurface")));
    HRESULT hr;

    if (!m_bFlippable)
        return S_OK;

    do  {

        ASSERT( SurfaceAllocated() );

        if (m_bDirectedFlips) {
            hr = m_pDDSDecode->Flip(lpSurface, m_dwCurrentField);
        }
        else {
            hr = m_pDDSDecode->Flip(NULL, m_dwCurrentField);
        }

        if (hr == DDERR_WASSTILLDRAWING) {
            // yield to the next thread
            Sleep(0);
        }

    } while(hr == DDERR_WASSTILLDRAWING);

    if (m_pSurfAllocatorNotify) {
        m_pSurfAllocatorNotify->NotifyEvent(EC_VMR_SURFACE_FLIPPED, hr, 0);
    }

    return hr;
}

/******************************Private*Routine******************************\
* CAllocatorPresenter::CheckOverlayAvailable
*
* Attempt to move the overlay so we can see if we can allocate it.
* We'll try to move it quickly as a small square at 0,0.  The AllocatorPuts
* it there anyways.  The user won't see much since its dest color keyed and
* we haven't painted the colour key yet
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CAllocatorPresenter::CheckOverlayAvailable(
    LPDIRECTDRAWSURFACE7 lpSurface7
    )
{
    AMTRACE((TEXT("CAllocatorPresenter::CheckOverlayAvailable")));
    const DWORD cxVideoSize = 64;// ATI doesn't seem to like 1x1 overlay surfaces
    const DWORD cyVideoSize = 64;

    RECT rcSrc, rcDest;
    SetRect(&rcDest, 0, 0, cxVideoSize, cyVideoSize);
    rcSrc = rcDest;

    AlignOverlayRects(m_lpCurrMon->ddHWCaps, rcSrc, rcDest);
    HRESULT hr = lpSurface7->UpdateOverlay(&rcSrc,
                                           m_lpCurrMon->pDDSPrimary,
                                           &rcDest,
                                           DDOVER_SHOW | DDOVER_KEYDEST,
                                           NULL);
    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\apobj.h ===
/******************************Module*Header*******************************\
* Module Name: APObj.h
*
* Declaration of the CAllocatorPresenter
*
*
* Created: Wed 02/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

#include <ddraw.h>
#include <d3d.h>
#include <dvdmedia.h>
#include "display.h"
#include "vmrp.h"
#include "thunkproc.h"  // for template for MSDVD timer

/////////////////////////////////////////////////////////////////////////////
// CAlocatorPresenter
class CAllocatorPresenter :
    public CUnknown,
    public IVMRSurfaceAllocator,
    public IVMRImagePresenter,
    public IVMRWindowlessControl,
    public IVMRImagePresenterExclModeConfig,
    public IVMRMonitorConfig,
    public CMSDVDTimer<CAllocatorPresenter>
{
public:
    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void**);
    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    static CUnknown *CreateInstanceDDXclMode(LPUNKNOWN, HRESULT *);
    static void InitClass(BOOL bLoading,const CLSID *clsid);

    CAllocatorPresenter(LPUNKNOWN pUnk, HRESULT *phr, BOOL fDDXclMode);
    virtual ~CAllocatorPresenter();


// IVMRImagePresenterConfig and IVMRImagePresenterExclModeConfig
public:
    STDMETHODIMP SetRenderingPrefs(DWORD  dwRenderFlags);
    STDMETHODIMP GetRenderingPrefs(DWORD* lpdwRenderFlags);
    STDMETHODIMP SetXlcModeDDObjAndPrimarySurface(
        LPDIRECTDRAW7 lpDDObj, LPDIRECTDRAWSURFACE7 lpPrimarySurf);
    STDMETHODIMP GetXlcModeDDObjAndPrimarySurface(
        LPDIRECTDRAW7* lpDDObj, LPDIRECTDRAWSURFACE7* lpPrimarySurf);

// IVMRSurfaceAllocator
public:
    STDMETHODIMP AllocateSurface(DWORD_PTR dwUserID,
                                 VMRALLOCATIONINFO* lpAllocInfo,
                                 DWORD* lpdwActualBackBuffers,
                                 LPDIRECTDRAWSURFACE7* lplpSurface);

    STDMETHODIMP FreeSurface(DWORD_PTR dwUserID);
    STDMETHODIMP PrepareSurface(DWORD_PTR dwUserID,
                                LPDIRECTDRAWSURFACE7 lplpSurface,
                                DWORD dwSurfaceFlags);
    STDMETHODIMP AdviseNotify(IVMRSurfaceAllocatorNotify* lpIVMRSurfAllocNotify);

// IVMRImagePresenter
    STDMETHODIMP StartPresenting(DWORD_PTR dwUserID);
    STDMETHODIMP StopPresenting(DWORD_PTR dwUserID);
    STDMETHODIMP PresentImage(DWORD_PTR dwUserID, VMRPRESENTATIONINFO* lpPresInfo);

// IVMRWindowlessControl
public:
    STDMETHODIMP GetNativeVideoSize(LONG* lWidth, LONG* lHeight,
                                    LONG* lARWidth, LONG* lARHeight);
    STDMETHODIMP GetMinIdealVideoSize(LONG* lWidth, LONG* lHeight);
    STDMETHODIMP GetMaxIdealVideoSize(LONG* lWidth, LONG* lHeight);
    STDMETHODIMP SetVideoPosition(const LPRECT lpSRCRect, const LPRECT lpDSTRect);
    STDMETHODIMP GetVideoPosition(LPRECT lpSRCRect,LPRECT lpDSTRect);
    STDMETHODIMP GetAspectRatioMode(DWORD* lpAspectRatioMode);
    STDMETHODIMP SetAspectRatioMode(DWORD AspectRatioMode);

    STDMETHODIMP SetVideoClippingWindow(HWND hwnd);
    STDMETHODIMP RepaintVideo(HWND hwnd, HDC hdc);
    STDMETHODIMP DisplayModeChanged();
    STDMETHODIMP GetCurrentImage(BYTE** lpDib);

    STDMETHODIMP SetBorderColor(COLORREF Clr);
    STDMETHODIMP GetBorderColor(COLORREF* lpClr);
    STDMETHODIMP SetColorKey(COLORREF Clr);
    STDMETHODIMP GetColorKey(COLORREF* lpClr);

// IVMRMonitorConfig
public:
    STDMETHODIMP SetMonitor( const VMRGUID *pGUID );
    STDMETHODIMP GetMonitor( VMRGUID *pGUID );
    STDMETHODIMP SetDefaultMonitor( const VMRGUID *pGUID );
    STDMETHODIMP GetDefaultMonitor( VMRGUID *pGUID );
    STDMETHODIMP GetAvailableMonitors( VMRMONITORINFO* pInfo, DWORD dwMaxInfoArraySize,
                    DWORD* pdwNumDevices );

public:
    static void CALLBACK APHeartBeatTimerProc(UINT uID, UINT uMsg,
                                              DWORD_PTR dwUser,
                                              DWORD_PTR dw1, DWORD_PTR dw2);

    HRESULT TimerProc(); // needs to be called from a timer proc

public: // called by a callback, callback could be friend function instead
    bool            PaintMonitorBorder(
                      HMONITOR hMonitor,  // handle to display monitor
                      HDC hdcMonitor,     // handle to monitor DC
                      LPRECT lprcMonitor); // monitor intersection rectangle)
private:
    void            WaitForScanLine(const RECT& rcDst);

    HRESULT         TryAllocOverlaySurface(LPDIRECTDRAWSURFACE7* lplpSurf,
                                           DWORD dwFlags,
                                           DDSURFACEDESC2* pddsd,
                                           DWORD dwMinBackBuffers,
                                           DWORD dwMaxBackBuffers,
                                           DWORD* lpdwBuffer);

    HRESULT         TryAllocOffScrnDXVASurface(LPDIRECTDRAWSURFACE7* lplpSurf,
                                           DWORD dwFlags,
                                           DDSURFACEDESC2* pddsd,
                                           DWORD dwMinBackBuffers,
                                           DWORD dwMaxBackBuffers,
                                           DWORD* lpdwBuffer);

    HRESULT         TryAllocOffScrnSurface(LPDIRECTDRAWSURFACE7* lplpSurf,
                                           DWORD dwFlags,
                                           DDSURFACEDESC2* pddsd,
                                           DWORD dwMinBackBuffers,
                                           DWORD dwMaxBackBuffers,
                                           DWORD* lpdwBuffer,
                                           BOOL fAllowBackBuffer);

    HRESULT         AllocateSurfaceWorker(DWORD dwFlags,
                                          LPBITMAPINFOHEADER lpHdr,
                                          LPDDPIXELFORMAT lpPixFmt,
                                          LPSIZE lpAspectRatio,
                                          DWORD dwMinBackBuffers,
                                          DWORD dwMaxBackBuffers,
                                          DWORD* lpdwBackBuffer,
                                          LPDIRECTDRAWSURFACE7* lplpSurface,
                                          DWORD dwInterlaceFlags,
                                          LPSIZE lpNativeSize);

    HRESULT         BltImageToPrimary(LPDIRECTDRAWSURFACE7 lpSample,
                                      LPRECT lpDst, LPRECT lpSrc);

    HRESULT         PresentImageWorker(LPDIRECTDRAWSURFACE7 dwSurface,
                                       DWORD dwSurfaceFlags,
                                       BOOL fFlip);

    HRESULT         PaintColorKey();
    HRESULT         PaintBorder();
    HRESULT         PaintMonitorBorder();
    HRESULT         PaintMonitorBorderWorker(HMONITOR hMon, LPRECT lprcDst);
    static BOOL CALLBACK MonitorBorderProc(HMONITOR hMonitor,
                                           HDC hdcMonitor,
                                           LPRECT lprcMonitor,
                                           LPARAM dwData
                                           );

    void            WaitForFlipStatus();
    HRESULT         UpdateOverlaySurface();
    void            HideOverlaySurface();
    HRESULT         FlipSurface(LPDIRECTDRAWSURFACE7 lpSurface);

    static DWORD    MapColorToMonitor( CAMDDrawMonitorInfo& monitor, COLORREF clr );
    static void     ClipRectPair( RECT& rdSrc, RECT& rdDest, const RECT& rdDestWith );
    static void     AlignOverlayRects(const DDCAPS_DX7& ddCaps, RECT& rcSrc, RECT& rcDest);
    static bool     ShouldDisableOverlays(const DDCAPS_DX7& ddCaps, const RECT& rcSrc, const RECT& rcDest);
    HRESULT         CheckOverlayAvailable(LPDIRECTDRAWSURFACE7 lpSurface);

    bool MonitorChangeInProgress() {
        return m_lpNewMon != NULL;
    };
    bool FoundCurrentMonitor();

    bool IsDestRectOnWrongMonitor(CAMDDrawMonitorInfo** lplpNewMon);

    bool CanBltFourCCSysMem();
    bool CanBltSysMem();

    enum {UR_NOCHANGE = 0x00, UR_MOVE = 0x01, UR_SIZE = 0x02};
    DWORD UpdateRectangles(LPRECT lprcNewSrc, LPRECT lprcNewDst);
    HRESULT CheckDstRect(const LPRECT lpDSTRect);
    HRESULT CheckSrcRect(const LPRECT lpSRCRect);

    bool SurfaceAllocated();

private:
    CCritSec                m_ObjectLock;           // Controls access to internals

    // This lock is held when CAllocatorPresenter::DisplayModeChanged() is called.
    // It prevents multiple threads from simultaneously calling DisplayModeChanged().
    // It also prevents a thread from modifing m_monitors while DisplayModeChanged()
    // calls IVMRSurfaceAllocatorNotify::ChangeDDrawDevice().
    CCritSec                m_DisplayModeChangedLock;
    CMonitorArray           m_monitors;
    CAMDDrawMonitorInfo*    m_lpCurrMon;
    CAMDDrawMonitorInfo*    m_lpNewMon;
    BOOL                    m_bMonitorStraddleInProgress;
    BOOL                    m_bStreaming;
    UINT_PTR                m_uTimerID;
    int                     m_SleepTime;
    VMRGUID                 m_ConnectionGUID;
    LPDIRECTDRAWSURFACE7    m_pDDSDecode;

    IVMRSurfaceAllocatorNotify* m_pSurfAllocatorNotify;

    BOOL        m_fDDXclMode;   // true if being used in DDrawXcl mode
    BOOL        m_bDecimating;
    SIZE        m_VideoSizeAct; // actual size of video received from upstream

    SIZE        m_ARSize;       // aspect ratio of this video image

    RECT        m_rcDstDskIncl; // dst rect in desktop co-ordinates including borders
    RECT        m_rcDstDesktop; // dst rect in desktop co-ordinates may have been letterboxed


    RECT        m_rcDstApp;     // dst rect in apps co-ordinates
    RECT        m_rcSrcApp;     // src rect in adjusted video co-ordinates

    RECT        m_rcBdrTL;      // border rect top/left
    RECT        m_rcBdrBR;      // border rect bottom/right

    DWORD       m_dwARMode;
    HWND        m_hwndClip;

    COLORREF    m_clrBorder;
    COLORREF    m_clrKey;

    // true if decode surface can be flipped
    BOOL                m_bFlippable;
    BOOL                m_bSysMem;

    // color key fields for overlays
    BOOL                m_bDirectedFlips;
    BOOL                m_bOverlayVisible;
    BOOL                m_bDisableOverlays;
    BOOL                m_bUsingOverlays;
    DWORD               m_dwMappedColorKey;
    DWORD               m_dwRenderingPrefs;


    // interlace info
    //
    // m_dwInterlaceFlags is passed to us during the AllocateSurface routine.
    // This flag identifies the interlace mode we are currently in.
    //
    // m_dwCurrentField is either 0 (a non-interleaved sample), DDFLIP_ODD
    // or DDFLIP_EVEN.  This is the field that should currently be displayed.
    // If m_dwInterlaceFlags identifies that we are in an interleaved BOB mode,
    // this value will toggle during the "FlipOverlayToSelf" timer event.
    //
    // Note: as yet I have not found a way to show the correct field when in
    // interleaved BOB mode and not using the overlay.
    //
    DWORD               m_dwInterlaceFlags;
    DWORD               m_dwCurrentField;
    DWORD               m_dwUpdateOverlayFlags;
    VMRPRESENTATIONINFO m_PresInfo;
    DWORD               m_MMTimerId;

    DWORD GetUpdateOverlayFlags(DWORD dwInterlaceFlags,
                                DWORD dwTypeSpecificFlags);

    void CancelMMTimer();
    HRESULT ScheduleSampleUsingMMThread(VMRPRESENTATIONINFO* lpPresInfo);

    static void CALLBACK RenderSampleOnMMThread(UINT uID, UINT uMsg,
                                                DWORD_PTR dwUser,
                                                DWORD_PTR dw1, DWORD_PTR dw2);
    //
    // GetCurrentImage helper functions
    //

    HRESULT CreateRGBShadowSurface(
        LPDIRECTDRAWSURFACE7* lplpDDS,
        DWORD dwBitsPerPel,
        BOOL fSysMem,
        DWORD dwWidth,
        DWORD dwHeight
        );

    HRESULT HandleYUVSurface(
        const DDSURFACEDESC2& ddsd,
        LPDIRECTDRAWSURFACE7* lplpRGBSurf
        );

    HRESULT CopyRGBSurfToDIB(LPBYTE* lpDib, LPDIRECTDRAWSURFACE7 lpRGBSurf);

    HRESULT CopyIMCXSurf(LPDIRECTDRAWSURFACE7 lpRGBSurf, BOOL fInterleavedCbCr, BOOL fCbFirst);
    HRESULT CopyYV12Surf(LPDIRECTDRAWSURFACE7 lpRGBSurf, BOOL fInterleavedCbCr, BOOL fCbFirst);

    HRESULT CopyYUY2Surf(LPDIRECTDRAWSURFACE7 lpRGBSurf);
    HRESULT CopyUYVYSurf(LPDIRECTDRAWSURFACE7 lpRGBSurf);

};

inline bool CAllocatorPresenter::FoundCurrentMonitor()
{
    // m_lpCurrMon can be NULL if an error occurs while the CAllocatorPresenter
    // object is being created.  It can also be NULL if the call to
    // InitializeDisplaySystem() in DisplayModeChanged() fails.
    return NULL != m_lpCurrMon;
}

inline bool CAllocatorPresenter::SurfaceAllocated()
{
    return NULL != m_pDDSDecode;
}


inline bool CAllocatorPresenter::CanBltFourCCSysMem()
{
    if (m_lpCurrMon->ddHWCaps.dwSVBCaps & DDCAPS_BLTFOURCC) {
        return CanBltSysMem();
    }
    return false;
}


inline bool CAllocatorPresenter::CanBltSysMem()
{
    if (m_lpCurrMon->ddHWCaps.dwSVBCaps & DDCAPS_BLTSTRETCH) {

        const DWORD caps = DDFXCAPS_BLTSHRINKX | DDFXCAPS_BLTSHRINKX  |
                           DDFXCAPS_BLTSTRETCHX | DDFXCAPS_BLTSTRETCHY;

        if ((m_lpCurrMon->ddHWCaps.dwSVBFXCaps & caps) == caps) {
            return true;
        }
    }
    return false;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\core\imagesyncobj.h ===
// ImageSyncObj.h : Declaration of the CImageSync
#include "vmrp.h"


/////////////////////////////////////////////////////////////////////////////
// CImageSync
class CImageSync :
    public CUnknown,
    public IImageSync,
    public IImageSyncControl,
    public IQualProp
{
public:

    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void**);
    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    static void InitClass(BOOL fLoaded, const CLSID *clsid);

    CImageSync(LPUNKNOWN pUnk, HRESULT *phr) :
        CUnknown(NAME("Image Sync"), pUnk),
        m_bAbort(false),
        m_bStreaming(false),
        m_dwAdvise(0),
        m_bInReceive(false),
        m_ImagePresenter(NULL),
        m_lpEventNotify(NULL),
        m_pClock(NULL),
        m_bQualityMsgValid(false),
        m_bLastQualityMessageRead(false),
        m_bFlushing(false),
        m_bEOS(false),
        m_bEOSDelivered(FALSE),
        m_pSample(NULL),
        m_evComplete(TRUE),
        m_ThreadSignal(TRUE),
        m_State(ImageSync_State_Stopped),
        m_SignalTime(0),
        m_EndOfStreamTimer(0)
    {
        AMTRACE((TEXT("CImageSync::CImageSync")));

        //
        // Frame stepping stuff
        //
        // -ve == normal playback
        // +ve == frames to skips
        //  0 == time to block
        //
        m_lFramesToStep = -1;
        m_StepEvent = CreateEvent(NULL, FALSE, FALSE, NULL);

        ResetStreamingTimes();
        Ready();
    }


    virtual ~CImageSync()
    {
        AMTRACE((TEXT("CImageSync::FinalRelease")));

        if (m_StepEvent) {
            CloseHandle(m_StepEvent);
        }

        if (m_ImagePresenter) {
            m_ImagePresenter->Release();
        }

        if (m_pClock) {
            m_pClock->Release();
        }
    }

// IImageSync
public:
    // return the buffer to the renderer along with time stamps relating to
    // when the buffer should be presented.
    STDMETHODIMP Receive(VMRPRESENTATIONINFO* lpPresInfo);

    // ask for quality control information from the renderer
    STDMETHODIMP GetQualityControlMessage(Quality* pQualityMsg);


// IImageSyncControl
public:

    // ============================================================
    // Synchronisation control
    // ============================================================

    STDMETHODIMP SetImagePresenter(IVMRImagePresenter* lpImagePresenter,
                                   DWORD_PTR dwUID);
    STDMETHODIMP SetReferenceClock(IReferenceClock* lpRefClock);
    STDMETHODIMP SetEventNotify(IImageSyncNotifyEvent* lpEventNotify);

    // ============================================================
    // Image sequence control
    // ============================================================

    STDMETHODIMP BeginImageSequence(REFERENCE_TIME* pStartTime);
    STDMETHODIMP CueImageSequence();
    STDMETHODIMP EndImageSequence();
    STDMETHODIMP GetImageSequenceState(DWORD dwMSecsTimeOut, DWORD* lpdwState);
    STDMETHODIMP BeginFlush();
    STDMETHODIMP EndFlush();
    STDMETHODIMP EndOfStream();
    STDMETHODIMP ResetEndOfStream();
    STDMETHODIMP SetAbortSignal(BOOL bAbort);
    STDMETHODIMP GetAbortSignal(BOOL* lpbAbort);
    STDMETHODIMP RuntimeAbortPlayback();

    // ============================================================
    // Frame Step control
    // ============================================================

    STDMETHODIMP FrameStep(
        DWORD nFramesToStep,
        DWORD dwStepFlags);

    STDMETHODIMP CancelFrameStep();


// IQualProp
public:
    STDMETHODIMP get_FramesDroppedInRenderer(int *cFramesDropped);
    STDMETHODIMP get_FramesDrawn(int *pcFramesDrawn);
    STDMETHODIMP get_AvgFrameRate(int *piAvgFrameRate);
    STDMETHODIMP get_Jitter(int *piJitter);
    STDMETHODIMP get_AvgSyncOffset(int *piAvg);
    STDMETHODIMP get_DevSyncOffset(int *piDev);


private:
    CAMEvent            m_RenderEvent;  // Used to signal timer events
    CAMEvent            m_ThreadSignal; // Signalled to release worker thread
    CAMEvent            m_evComplete;


    HANDLE              m_StepEvent;    // Used to block when frame stepping
    LONG                m_lFramesToStep;

    void Ready()
    {
        AMTRACE((TEXT("CImageSync::Ready")));
        m_evComplete.Set();
    };

    void NotReady()
    {
        AMTRACE((TEXT("CImageSync::Notready")));
        m_evComplete.Reset();
    };

    DWORD_PTR           m_dwAdvise;
    DWORD               m_State;
    BOOL                m_bEOS;         // Any more samples in the stream
    BOOL                m_bEOSDelivered;// Have we delivered an EC_COMPLETE

    // The Renderer lock protects the following variables.
    // This list is not a complete list of the variables 
    // protected by the renderer lock.
    //      - m_bStreaming
    //      - m_bEOSDelivered
    // 
    CCritSec                m_RendererLock; // Controls access to internals
    CCritSec                m_InterfaceLock;// Controls access to the Control interface
    IVMRImagePresenter*     m_ImagePresenter;
    DWORD_PTR               m_dwUserID;
    IImageSyncNotifyEvent*  m_lpEventNotify;
    IReferenceClock*        m_pClock;       // A pointer to the supplied clock
    CRefTime                m_tStart;       // cached start time
    Quality                 m_QualityMsg;   // Saved quality MSG

    BOOL                m_bQualityMsgValid;
    BOOL                m_bLastQualityMessageRead;
    BOOL                m_bInReceive;
    BOOL                m_bAbort;
    BOOL                m_bStreaming;
    BOOL                m_bFlushing;

    REFERENCE_TIME      m_SignalTime;       // Time when we signal EC_COMPLETE
    UINT                m_EndOfStreamTimer; // Used to signal end of stream

    VMRPRESENTATIONINFO*    m_pSample;
    HRESULT SaveSample(VMRPRESENTATIONINFO* pSample);
    HRESULT GetSavedSample(VMRPRESENTATIONINFO** ppSample);

    void ClearSavedSample();
    BOOL HaveSavedSample();
    void FrameStepWorker();


    // CBaseVideoRenderer is a renderer class (see its ancestor class) and
    // it handles scheduling of media samples so that they are drawn at the
    // correct time by the reference clock.  It implements a degradation
    // strategy.  Possible degradation modes are:
    //    Drop frames here (only useful if the drawing takes significant time)
    //    Signal supplier (upstream) to drop some frame(s) - i.e. one-off skip.
    //    Signal supplier to change the frame rate - i.e. ongoing skipping.
    //    Or any combination of the above.
    // In order to determine what's useful to try we need to know what's going
    // on.  This is done by timing various operations (including the supplier).
    // This timing is done by using timeGetTime as it is accurate enough and
    // usually cheaper than calling the reference clock.  It also tells the
    // truth if there is an audio break and the reference clock stops.
    // We provide a number of public entry points (named OnXxxStart, OnXxxEnd)
    // which the rest of the renderer calls at significant moments.  These do
    // the timing.

    // the number of frames that the sliding averages are averaged over.
    // the rule is (1024*NewObservation + (AVGPERIOD-1) * PreviousAverage)/AVGPERIOD
#define AVGPERIOD 4
#define RENDER_TIMEOUT 10000
//  enum { AVGPERIOD = 4, RENDER_TIMEOUT = 10000 };

    // Hungarian:
    //     tFoo is the time Foo in mSec (beware m_tStart from filter.h)
    //     trBar is the time Bar by the reference clock

    //******************************************************************
    // State variables to control synchronisation
    //******************************************************************

    // Control of sending Quality messages.  We need to know whether
    // we are in trouble (e.g. frames being dropped) and where the time
    // is being spent.

    // When we drop a frame we play the next one early.
    // The frame after that is likely to wait before drawing and counting this
    // wait as spare time is unfair, so we count it as a zero wait.
    // We therefore need to know whether we are playing frames early or not.

    int m_nNormal;                  // The number of consecutive frames
                                    // drawn at their normal time (not early)
                                    // -1 means we just dropped a frame.

    BOOL m_bSupplierHandlingQuality;// The response to Quality messages says
                                    // our supplier is handling things.
                                    // We will allow things to go extra late
                                    // before dropping frames.  We will play
                                    // very early after he has dropped one.

    // Control of scheduling, frame dropping etc.
    // We need to know where the time is being spent so as to tell whether
    // we should be taking action here, signalling supplier or what.
    // The variables are initialised to a mode of NOT dropping frames.
    // They will tell the truth after a few frames.
    // We typically record a start time for an event, later we get the time
    // again and subtract to get the elapsed time, and we average this over
    // a few frames.  The average is used to tell what mode we are in.

    // Although these are reference times (64 bit) they are all DIFFERENCES
    // between times which are small.  An int will go up to 214 secs before
    // overflow.  Avoiding 64 bit multiplications and divisions seems
    // worth while.



    // Audio-video throttling.  If the user has turned up audio quality
    // very high (in principle it could be any other stream, not just audio)
    // then we can receive cries for help via the graph manager.  In this case
    // we put in a wait for some time after rendering each frame.
    int m_trThrottle;

    // The time taken to render (i.e. BitBlt) frames controls which component
    // needs to degrade.  If the blt is expensive, the renderer degrades.
    // If the blt is cheap it's done anyway and the supplier degrades.
    int m_trRenderAvg;              // Time frames are taking to blt
    int m_trRenderLast;             // Time for last frame blt
    int m_tRenderStart;             // Just before we started drawing (mSec)
                                    // derived from timeGetTime.

    // When frames are dropped we will play the next frame as early as we can.
    // If it was a false alarm and the machine is fast we slide gently back to
    // normal timing.  To do this, we record the offset showing just how early
    // we really are.  This will normally be negative meaning early or zero.
    int m_trEarliness;

    // Target provides slow long-term feedback to try to reduce the
    // average sync offset to zero.  Whenever a frame is actually rendered
    // early we add a msec or two, whenever late we take off a few.
    // We add or take off 1/32 of the error time.
    // Eventually we should be hovering around zero.  For a really bad case
    // where we were (say) 300mSec off, it might take 100 odd frames to
    // settle down.  The rate of change of this is intended to be slower
    // than any other mechanism in Quartz, thereby avoiding hunting.
    int m_trTarget;

    // The proportion of time spent waiting for the right moment to blt
    // controls whether we bother to drop a frame or whether we reckon that
    // we're doing well enough that we can stand a one-frame glitch.
    int m_trWaitAvg;                // Average of last few wait times
                                    // (actually we just average how early
                                    // we were).  Negative here means LATE.

    // The average inter-frame time.
    // This is used to calculate the proportion of the time used by the
    // three operations (supplying us, waiting, rendering)
    int m_trFrameAvg;               // Average inter-frame time
    int m_trDuration;               // duration of last frame.

    REFERENCE_TIME m_trRememberStampForPerf;  // original time stamp of frame
                                              // with no earliness fudges etc.
    // PROPERTY PAGE
    // This has edit fields that show the user what's happening
    // These member variables hold these counts.

    int m_cFramesDropped;           // cumulative frames dropped IN THE RENDERER
    int m_cFramesDrawn;             // Frames since streaming started seen BY THE
                                    // RENDERER (some may be dropped upstream)

    // Next two support average sync offset and standard deviation of sync offset.
    LONGLONG m_iTotAcc;             // Sum of accuracies in mSec
    LONGLONG m_iSumSqAcc;           // Sum of squares of (accuracies in mSec)

    // Next two allow jitter calculation.  Jitter is std deviation of frame time.
    REFERENCE_TIME m_trLastDraw;    // Time of prev frame (for inter-frame times)
    LONGLONG m_iSumSqFrameTime;     // Sum of squares of (inter-frame time in mSec)
    LONGLONG m_iSumFrameTime;       // Sum of inter-frame times in mSec

    // To get performance statistics on frame rate, jitter etc, we need
    // to record the lateness and inter-frame time.  What we actually need are the
    // data above (sum, sum of squares and number of entries for each) but the data
    // is generated just ahead of time and only later do we discover whether the
    // frame was actually drawn or not.  So we have to hang on to the data
    int m_trLate;                   // hold onto frame lateness
    int m_trFrame;                  // hold onto inter-frame time

    int m_tStreamingStart;          // if streaming then time streaming started
                                    // else time of last streaming session
                                    // used for property page statistics



    // These provide a full video quality management implementation

    HRESULT StartStreaming();
    HRESULT StopStreaming();
    HRESULT SourceThreadCanWait(BOOL bCanWait);
    HRESULT CompleteStateChange(DWORD OldState);

    HRESULT OnStartStreaming();
    HRESULT OnStopStreaming();
    HRESULT OnReceiveFirstSample(VMRPRESENTATIONINFO* pSample);
    HRESULT DoRenderSample(VMRPRESENTATIONINFO* pSample);
    HRESULT Render(VMRPRESENTATIONINFO* pSample);

    void OnRenderStart(VMRPRESENTATIONINFO* pSample);
    void OnRenderEnd(VMRPRESENTATIONINFO* pSample);

    void OnWaitStart();
    void OnWaitEnd();
    void ThrottleWait();
    void WaitForReceiveToComplete();

    // Handle the statistics gathering for our quality management

    void PreparePerformanceData(int trLate, int trFrame);
    void RecordFrameLateness(int trLate, int trFrame);
    HRESULT ResetStreamingTimes();
    HRESULT ReceiveWorker(VMRPRESENTATIONINFO* pSample);
    HRESULT PrepareReceive(VMRPRESENTATIONINFO* pSample);
    HRESULT ScheduleSampleWorker(VMRPRESENTATIONINFO* pSample);
    HRESULT ScheduleSample(VMRPRESENTATIONINFO* pSample);
    HRESULT CheckSampleTimes(VMRPRESENTATIONINFO* pSample,
                             REFERENCE_TIME *ptrStart,
                             REFERENCE_TIME *ptrEnd);

    HRESULT ShouldDrawSampleNow(VMRPRESENTATIONINFO* pSample,
                                REFERENCE_TIME *ptrStart,
                                REFERENCE_TIME *ptrEnd);

    // Lots of end of stream complexities
public:
    void TimerCallback();

private:
    void ResetEndOfStreamTimer();
    HRESULT NotifyEndOfStream();
    HRESULT SendEndOfStream();


    HRESULT SendQuality(REFERENCE_TIME trLate, REFERENCE_TIME trRealStream);
    HRESULT CancelNotification();
    HRESULT WaitForRenderTime();
    void SignalTimerFired();
    BOOL IsEndOfStream() { return m_bEOS; };
    BOOL IsEndOfStreamDelivered();
    BOOL IsStreaming();

    //
    //  Do estimates for standard deviations for per-frame
    //  statistics
    //
    //  *piResult = (llSumSq - iTot * iTot / m_cFramesDrawn - 1) /
    //                            (m_cFramesDrawn - 2)
    //  or 0 if m_cFramesDrawn <= 3
    //
    HRESULT GetStdDev(int nSamples,int *piResult,LONGLONG llSumSq,LONGLONG iTot);
};

inline BOOL CImageSync::IsStreaming()
{
    // The caller must hold the m_RendererLock because this function
    // uses m_bStreaming.
    ASSERT(CritCheckIn(&m_RendererLock));

    return m_bStreaming;
}

inline BOOL CImageSync::IsEndOfStreamDelivered()
{
    // The caller must hold the m_RendererLock because this function
    // uses m_bEOSDelivered.
    ASSERT(CritCheckIn(&m_RendererLock));

    return m_bEOSDelivered;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\core\imagesync.cpp ===
/******************************Module*Header*******************************\
* Module Name: ImageSync.cpp
*
* Implementation of DLL Exports.  This file was create by the ATL wizard !!
*
*
* Created: Wed 01/12/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#ifdef FILTER_DLL
#include <initguid.h>
#include <perfstruct.h>
#endif

#include "imagesyncobj.h"
#include "VMRuuids.h"

#if defined(CHECK_FOR_LEAKS)
#include "ifleak.h"
#endif

#ifdef FILTER_DLL
STDAPI DllRegisterServer()
{
    AMTRACE((TEXT("DllRegisterServer")));
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    AMTRACE((TEXT("DllUnregisterServer")));
    return AMovieDllRegisterServer2( FALSE );
}

CFactoryTemplate g_Templates[] = {
    {
        L"",
        &CLSID_ImageSynchronization,
        CImageSync::CreateInstance,
        CImageSync::InitClass,
        NULL
    }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
#endif

/******************************Public*Routine******************************\
* InitClass
*
*
*
* History:
* Thu 12/14/2000 - StEstrop - Created
*
\**************************************************************************/
#if defined(CHECK_FOR_LEAKS)
// the one and only g_IFLeak object.
CInterfaceLeak  g_IFLeak;

void
CImageSync::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
    if (bLoading) {
        DbgLog((LOG_TRACE, 0, TEXT("ImageSync Thunks: Loaded") ));
        g_IFLeak.Init();
    }
    else {
        DbgLog((LOG_TRACE, 0, TEXT("ImageSync Thunks: Unloaded") ));
        g_IFLeak.Term();
    }
}
#else
void
CImageSync::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
}
#endif

CUnknown* CImageSync::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    AMTRACE((TEXT("CImageSync::CreateInstance")));
    return new CImageSync(pUnk, phr);
}

STDMETHODIMP
CImageSync::NonDelegatingQueryInterface(
    REFIID riid,
    void ** ppv)
{
    AMTRACE((TEXT("CImageSync::NonDelegatingQueryInterface")));

    HRESULT hr = E_NOINTERFACE;
    *ppv = NULL;

    if (riid == IID_IImageSync) {
        hr = GetInterface((IImageSync*)this, ppv);
    }
    else if (riid == IID_IImageSyncControl) {
        hr = GetInterface((IImageSyncControl*)this, ppv);
    }
    else if (riid == IID_IQualProp) {
        hr = GetInterface((IQualProp*)this, ppv);
    }
    else {
        hr = CUnknown::NonDelegatingQueryInterface(riid,ppv);
    }

#if defined(CHECK_FOR_LEAKS)
    if (hr == S_OK) {
        _pIFLeak->AddThunk((IUnknown **)ppv, "Image Sync Object",  riid);
    }
#endif

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\thunkproc.h ===
/*************************************************************************/
/* Copyright (C) 1999 Microsoft Corporation                              */
/* File: ThunkProc.h                                                     */
/* Description: In order to get rid of the thread. Which causes problems */
/* since we have to marshal we use this timer stuff from ATL.            */
/* The basic problem is that we would like to have a timer associated    */
/* with an object and this is a way to do so                             */
/* Author: David Janecek                                                 */
/*************************************************************************/

#ifndef __THUNKPROC_H
#define __THUNKPROC_H

//this nasty stuff was taken from "AtlWin.h"
#if defined(_M_IX86)
#pragma pack(push,1)
struct _TimerProcThunk
{
    DWORD   m_mov;          // mov dword ptr [esp+0x4], pThis (esp+0x4 is hWnd)
    DWORD   m_this;         //
    BYTE    m_jmp;          // jmp WndProc
    DWORD   m_relproc;      // relative jmp
};
#pragma pack(pop)
#elif defined (_M_AMD64)
#pragma pack(push,2)
struct _TimerProcThunk
{
    USHORT  RcxMov;         // mov rcx, pThis
    ULONG64 RcxImm;         //
    USHORT  RaxMov;         // mov rax, target
    ULONG64 RaxImm;         //
    USHORT  RaxJmp;         // jmp target
};
#pragma pack(pop)
#elif defined (_M_IA64)
#pragma pack(push,8)
extern "C" LRESULT CALLBACK _TimerProcThunkProc( HWND hwnd, UINT uMsg, UINT_PTR idEvent, DWORD dwTime);
struct _TimerFuncDesc
{
   void* pfn;
   void* gp;
};
struct _TimerProcThunk
{
   _TimerFuncDesc funcdesc;
   void* pRealTimerProcDesc;
   void* pThis;
};
extern "C" LRESULT CALLBACK _TimerProcThunkProc( HWND hwnd, UINT uMsg, UINT_PTR idEvent, DWORD dwTime);
#pragma pack(pop)
#else
#error Only AMD64, IA64, and X86 supported
#endif

class CTimerProcThunk
{
public:
    _TimerProcThunk thunk;

    void Init(TIMERPROC proc, void* pThis)
    {
#if defined (_M_IX86)
        thunk.m_mov = 0x042444C7;  //C7 44 24 0C
        thunk.m_this = (DWORD)pThis;
        thunk.m_jmp = 0xe9;
        thunk.m_relproc = (int)proc - ((int)this+sizeof(_TimerProcThunk));
#elif defined (_M_AMD64)
        thunk.RcxMov = 0xb948;          // mov rcx, pThis
        thunk.RcxImm = (ULONG64)pThis;  //
        thunk.RaxMov = 0xb848;          // mov rax, target
        thunk.RaxImm = (ULONG64)proc;   // absolute address
        thunk.RaxJmp = 0xe0ff;          // jmp rax
#elif defined (_M_IA64)
        _TimerFuncDesc* pFuncDesc;
        pFuncDesc = (_TimerFuncDesc*)_TimerProcThunkProc;
        thunk.funcdesc.pfn = pFuncDesc->pfn;
        thunk.funcdesc.gp = &thunk.pRealTimerProcDesc;  // Set gp up to point to our thunk data
        thunk.pRealTimerProcDesc = proc;
        thunk.pThis = pThis;
#endif
        // write block from data cache and
        //  flush from instruction cache
        FlushInstructionCache(GetCurrentProcess(), &thunk, sizeof(thunk));
    }
};

template <class T>
class  CMSDVDTimer {
private:
    CTimerProcThunk   m_TimerThunk;
    HWND            m_hwnd;

/*************************************************************************/
/* Function: FakeTimerProc                                               */
/*************************************************************************/
static void CALLBACK FakeTimerProc(HWND hwnd, UINT uMsg, UINT_PTR idEvent, DWORD dwTime){

    CMSDVDTimer* pThis = (CMSDVDTimer*)hwnd;
    pThis->RealTimerProc(pThis->m_hwnd, uMsg, idEvent, dwTime);
}/* end of function FakeTimerProc */

/*************************************************************************/
/* Function: RealTimerProc                                               */
/*************************************************************************/
void RealTimerProc(HWND hwnd, UINT uMsg, UINT_PTR idEvent, DWORD dwTime){

    T* pT = static_cast<T*>(this);

    if(NULL == pT){

        return;
    }/* end of if statement */

    pT->TimerProc();
}/* end of function RealTimerProc */

public:
/*************************************************************************/
/* Function: MyTimerClass                                                */
/*************************************************************************/
CMSDVDTimer(HWND hwnd = (HWND)NULL){

    m_hwnd = hwnd;
    m_TimerThunk.Init(FakeTimerProc, this);
}/* end of function MyTimerClass */

/*************************************************************************/
/* Function: GetTimerProc                                                */
/*************************************************************************/
TIMERPROC GetTimerProc() {

    return (TIMERPROC)&(m_TimerThunk.thunk);
}/* end of function GetTimerProc */

};

#endif // __THUNKPROC_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\ia64\atltmr21.s ===
.global	_TimerProcThunkProc
	.proc	_TimerProcThunkProc
	.align	32

_TimerProcThunkProc:
	// On entry, gp is actually a pointer to the pRealWndProcDesc member of 
	// the _WndProcThunk struct
	alloc	r36=ar.pfs,4,6,4,0
	mov		r37=rp  // Save return address
	mov		r38=gp  // Save gp
	mov		r40=gp  // r40 = &thunk.pRealWndProcDesc
	ld8		r30=[r40],8  // r30 = thunk.pRealWndProcDesc, r40 = &thunk.pThis
	ld8		r42=[r40]  // r42 = pThis
	ld8		r31=[r30],8  // r31 = thunk.pRealWndProcDesc->pfn, r30 = &thunk.pRealWndProcDesc->gp
	ld8		gp=[r30]  // gp = thunk.pRealWndProcDesc->gp
	mov		r43=r33  // r43 = nMsg
	mov		r44=r34  // r44 = wParam
	mov		r45=r35  // r45 = lParam
	mov		b6=r31  // b6 = thunk.pRealWndProcDesc->pfn
	br.call.sptk.many	rp=b6  // Call thunk.pRealWndProcDesc->pfn
	mov		gp=r38  // restore gp
	mov		rp=r37  // restore return address
	mov		ar.pfs=r36  // restore previous function state
	br.ret.sptk.many	rp  // return
	.endp	_TimerProcThunkProc
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\display.cpp ===
/******************************Module*Header*******************************\
* Module Name: display.cpp
*
* Support for DDraw device on Multiple Monitors.
*
*
* Created: Mon 01/24/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <atlconv.h>
#include <limits.h>

#include <ddraw.h>
#include <vmrp.h>

#include "AllocLib.h"
#include "apobj.h"


/* -------------------------------------------------------------------------
** Structure use to pass info to the DDrawEnumEx callback
** -------------------------------------------------------------------------
*/

struct DDRAWINFO {
    DWORD               dwCount;
    DWORD               dwPmiSize;
    HRESULT             hrCallback;
    const GUID*         pGUID;
    CAMDDrawMonitorInfo* pmi;
    HWND                hwnd;
};

const WCHAR  szDisplay[] = L"DISPLAY";
const WCHAR  szDesc[]    = L"Primary Display Driver";


/******************************Public*Routine******************************\
* TermDDrawMonitorInfo
*
*
*
* History:
* 01-17-2000 - StEstrop - Created
*
\**************************************************************************/
void
TermDDrawMonitorInfo(
    CAMDDrawMonitorInfo* pmi
    )
{
    AMTRACE((TEXT("TermDDrawMonitorInfo")));
    RELEASE(pmi->pDDSPrimary);
    RELEASE(pmi->pDD);

    ZeroMemory(pmi, sizeof(VMRMONITORINFO));
}


/******************************Public*Routine******************************\
* InitDDrawMonitorInfo
*
*
*
* History:
* 01-17-2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
InitDDrawMonitorInfo(
    CAMDDrawMonitorInfo* pmi,
    HWND hwnd,
    BOOL fXclMode
    )
{
    AMTRACE((TEXT("InitDDrawMonitorInfo")));

    //
    // Create DirectDraw object
    //

    HRESULT hRet = DD_OK;
    LPDIRECTDRAWCLIPPER lpDrawClipper = NULL;

    __try {

        if (!fXclMode) {

            CHECK_HR(hRet = DirectDrawCreateEx(pmi->guid.pGUID,
                                               (LPVOID *)&pmi->pDD,
                                               IID_IDirectDraw7, NULL));

            CHECK_HR(hRet = pmi->pDD->SetCooperativeLevel(NULL,
                                            DDSCL_FPUPRESERVE | DDSCL_NORMAL));

            //
            // Create the primary surface and the clipper
            //

            DDSURFACEDESC2 ddsd;  // A surface description structure
            INITDDSTRUCT(ddsd);

            ddsd.dwFlags = DDSD_CAPS;
            ddsd.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE;
            CHECK_HR(hRet = pmi->pDD->CreateSurface(&ddsd, &pmi->pDDSPrimary, NULL));
        }

        INITDDSTRUCT(pmi->ddHWCaps);
        CHECK_HR( hRet = pmi->pDD->GetCaps((LPDDCAPS)&pmi->ddHWCaps, NULL) );

        //DDDEVICEIDENTIFIER2 did;
        //CHECK_HR( hRet = pmi->pDD->GetDeviceIdentifier(&did, 0));
        //pmi->liDriverVersion = did.liDriverVersion;
        //pmi->dwVendorId = did.dwVendorId;
        //pmi->dwDeviceId = did.dwDeviceId;
        //pmi->dwSubSysId = did.dwSubSysId;
        //pmi->dwRevision = did.dwRevision;

        CHECK_HR( hRet = pmi->pDD->CreateClipper((DWORD)0, &lpDrawClipper, NULL) );

        if (hwnd)
        {
            CHECK_HR( hRet = lpDrawClipper->SetHWnd(0, hwnd) );
        }

        CHECK_HR( hRet = pmi->pDDSPrimary->SetClipper(lpDrawClipper) );
    }
    __finally {

        //
        // release the local instance of the clipper - if SetClipper succeeded,
        // it got AddRef'd. In case of error, it did not and goes away here
        //

        RELEASE(lpDrawClipper);
        if (hRet != DD_OK) {
            TermDDrawMonitorInfo(pmi);
        }
    }

    return hRet;
}


/*****************************Private*Routine******************************\
* GetAMDDrawMonitorInfo
*
*
*
* History:
* Tue 08/17/1999 - StEstrop - Created
*
\**************************************************************************/
BOOL
GetAMDDrawMonitorInfo(
    const GUID* pGUID,
    LPCWSTR lpDriverDesc,
    LPCWSTR lpDriverName,
    CAMDDrawMonitorInfo* lpmi,
    HMONITOR hm
    )
{
    AMTRACE((TEXT("GetAMDDrawMonitorInfo")));

    MONITORINFOEX miInfoEx;
    miInfoEx.cbSize = sizeof(miInfoEx);

    lstrcpynW(lpmi->szDevice, lpDriverName, NUMELMS(lpmi->szDevice) );
    lstrcpynW(lpmi->szDescription, lpDriverDesc, NUMELMS(lpmi->szDescription) );


    HDC hdcDisplay;

    USES_CONVERSION;
    if (lstrcmpiW(lpDriverName, szDisplay) == 0) {
        hdcDisplay = CreateDC(W2CT(szDisplay), NULL, NULL, NULL);
    }
    else {
        hdcDisplay = CreateDC(NULL, W2CT(lpDriverName), NULL, NULL);
    }

    if (hdcDisplay == NULL) {
        ASSERT(FALSE);
        DbgLog((LOG_ERROR,1,TEXT("Can't get a DC for %hs"), lpDriverName));
        return FALSE;
    } else {
        DbgLog((LOG_TRACE,3,TEXT("Created a DC for %hs"), lpDriverName));
    }

    ZeroMemory(&lpmi->DispInfo, sizeof(lpmi->DispInfo));
    HBITMAP hbm = CreateCompatibleBitmap(hdcDisplay, 1, 1);
    if (!hbm) {
        DbgLog((LOG_ERROR,1,TEXT("Can't create a compatible bitmap for %hs"),
                lpDriverName));
        DeleteDC(hdcDisplay);
        return FALSE;
    }

    lpmi->DispInfo.bmiHeader.biSize = sizeof(BITMAPINFOHEADER);
    GetDIBits(hdcDisplay, hbm, 0, 1, NULL, (BITMAPINFO *)&lpmi->DispInfo, DIB_RGB_COLORS);
    GetDIBits(hdcDisplay, hbm, 0, 1, NULL, (BITMAPINFO *)&lpmi->DispInfo, DIB_RGB_COLORS);

    DeleteObject(hbm);
    DeleteDC(hdcDisplay);

    if (pGUID == NULL) {
        lpmi->hMon = MonitorFromWindow(HWND_DESKTOP, MONITOR_DEFAULTTOPRIMARY);
        lpmi->dwFlags = MONITORINFOF_PRIMARY;
        lpmi->guid.pGUID = NULL;

        SetRect(&lpmi->rcMonitor, 0, 0,
                GetSystemMetrics(SM_CXSCREEN),
                GetSystemMetrics(SM_CYSCREEN));

        lpmi->guid.GUID = GUID_NULL;
    }
    else if (GetMonitorInfo(hm, &miInfoEx)) {
        lpmi->dwFlags = miInfoEx.dwFlags;
        lpmi->rcMonitor = miInfoEx.rcMonitor;
        lpmi->hMon = hm;
        lpmi->guid.pGUID = &lpmi->guid.GUID;
        lpmi->guid.GUID = *pGUID;
    }
    else return FALSE;

    return TRUE;
}



/*****************************Private*Routine******************************\
* DDEnumCallbackEx
*
*
*
* History:
* Fri 08/13/1999 - StEstrop - Created
*
\**************************************************************************/
BOOL WINAPI
DDEnumCallbackExW(
    GUID *pGUID,
    LPWSTR lpDriverDesc,
    LPWSTR lpDriverName,
    LPVOID lpContext,
    HMONITOR  hm
    )
{
    AMTRACE((TEXT("DDEnumCallbackEx")));

    DDRAWINFO* lpDDInfo = (DDRAWINFO*)lpContext;

    if (lpDDInfo->dwCount < lpDDInfo->dwPmiSize) {
        if (GetAMDDrawMonitorInfo(pGUID,
                                  lpDriverDesc,
                                  lpDriverName,
                                  &lpDDInfo->pmi[lpDDInfo->dwCount],
                                  hm))
        {
            lpDDInfo->hrCallback = InitDDrawMonitorInfo(
                &lpDDInfo->pmi[lpDDInfo->dwCount],
                lpDDInfo->hwnd,
                FALSE);

            if (FAILED(lpDDInfo->hrCallback))
            {
                return FALSE;
            }

            lpDDInfo->dwCount++;
        }
    }

    return TRUE;
}

#define CCHDEVICEDESCRIPTION  256

BOOL WINAPI
DDEnumCallbackExA(
    GUID *pGUID,
    LPSTR lpDriverDesc,
    LPSTR lpDriverName,
    LPVOID lpContext,
    HMONITOR  hm
    )
{
    USES_CONVERSION;

    BOOL b = DDEnumCallbackExW(pGUID,
                               A2W(lpDriverDesc),
                               A2W(lpDriverName),
                               lpContext,
                               hm);
    return b;
}

/*****************************Private*Routine******************************\
* InitializeDisplaySystem
*
*
*
* History:
* Mon 01/24/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CMonitorArray::InitializeDisplaySystem(
    HWND hwnd
    )
{
    AMTRACE((TEXT("CMonitorArray::InitializeDisplaySystem")));

    HRESULT hr;
    m_dwNumMonitors = 0;
    if (GetSystemMetrics(SM_CMONITORS) <= 1)
    {
        BOOL ok = GetAMDDrawMonitorInfo(NULL, szDesc, szDisplay,
                                    &m_DDMon[0],
                                    MonitorFromWindow(HWND_DESKTOP,
                                                      MONITOR_DEFAULTTONEAREST));
        if (!ok) {
            return E_FAIL;
        }
        hr = InitDDrawMonitorInfo(&m_DDMon[0], hwnd, FALSE);
        m_dwNumMonitors = 1;
    }
    else {

        DDRAWINFO DDrawInfo;
        DDrawInfo.dwCount = 0;
        DDrawInfo.dwPmiSize = NUMELMS( m_DDMon );
        DDrawInfo.pmi = m_DDMon;
        DDrawInfo.hwnd = hwnd;
        DDrawInfo.hrCallback = S_OK;

        hr = DirectDrawEnumerateExW(DDEnumCallbackExW,
                                    (LPVOID)&DDrawInfo,
                                    DDENUM_ATTACHEDSECONDARYDEVICES);
        if( FAILED(hr)) {
            hr = DirectDrawEnumerateExA(DDEnumCallbackExA,
                                        (LPVOID)&DDrawInfo,
                                        DDENUM_ATTACHEDSECONDARYDEVICES);
        }

        if (SUCCEEDED(hr)) {
            if (SUCCEEDED(DDrawInfo.hrCallback)) {
                m_dwNumMonitors = DDrawInfo.dwCount;
            }
            else {
                hr = DDrawInfo.hrCallback;
            }
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* InitializeXclModeDisplaySystem
*
*
*
* History:
* Thu 04/05/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CMonitorArray::InitializeXclModeDisplaySystem(
    HWND hwnd,
    LPDIRECTDRAW7 lpDD,
    LPDIRECTDRAWSURFACE7 lpPS
    )
{
    AMTRACE((TEXT("CMonitorArray::InitializeXclModeDisplaySystem]")));


    HRESULT hr = S_OK;
    __try {

        DDSURFACEDESC2 ddsd = {sizeof(DDSURFACEDESC2)};
        CHECK_HR(hr = lpDD->GetDisplayMode(&ddsd));

        CAMDDrawMonitorInfo* lpmi = &m_DDMon[0];

        //
        // fix up the monitor stuff
        //
        lpmi->hMon = MonitorFromWindow(hwnd, MONITOR_DEFAULTTOPRIMARY);
        lpmi->dwFlags = 0;
        lpmi->guid.pGUID = NULL;
        SetRect(&lpmi->rcMonitor, 0, 0, ddsd.dwWidth, ddsd.dwHeight);

        LPBITMAPINFOHEADER lpbi = &lpmi->DispInfo.bmiHeader;

        lpbi->biSize = sizeof(lpmi->DispInfo.bmiHeader);
        lpbi->biWidth = ddsd.dwWidth;
        lpbi->biHeight = ddsd.dwHeight;
        lpbi->biHeight = ddsd.dwHeight;
        lpbi->biPlanes = 1;
        lpbi->biBitCount = (WORD)ddsd.ddpfPixelFormat.dwRGBBitCount;
        lpbi->biClrUsed = 0;
        lpbi->biClrImportant = 0;


        lpbi->biCompression = ddsd.ddpfPixelFormat.dwFourCC;
        lpbi->biSizeImage = DIBSIZE(*lpbi);

        if (lpbi->biCompression == BI_RGB) {

            if (lpbi->biBitCount == 16 &&
                ddsd.ddpfPixelFormat.dwGBitMask == 0x7E0) {
                lpbi->biCompression = BI_BITFIELDS;
            }

            if (lpbi->biBitCount == 32) {
                lpbi->biCompression = BI_BITFIELDS;
            }
        }


        if (lpbi->biCompression != BI_RGB) {
            lpmi->DispInfo.dwBitMasks[0] = ddsd.ddpfPixelFormat.dwRBitMask;
            lpmi->DispInfo.dwBitMasks[1] = ddsd.ddpfPixelFormat.dwGBitMask;
            lpmi->DispInfo.dwBitMasks[2] = ddsd.ddpfPixelFormat.dwBBitMask;
        }

        //
        // initialize the DDraw stuff
        //
        lpDD->AddRef();
        lpmi->pDD = lpDD;

        lpPS->AddRef();
        lpmi->pDDSPrimary = lpPS;

        CHECK_HR(hr = InitDDrawMonitorInfo(&m_DDMon[0], hwnd, TRUE));
        m_dwNumMonitors = 1;
    }
    __finally {

        if (FAILED(hr)) {
            TerminateDisplaySystem();
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* FindMonitor
*
* find the current monitor
*
* History:
* Fri 04/25/2000 - GlennE - Created
*
\**************************************************************************/
CAMDDrawMonitorInfo*
CMonitorArray::FindMonitor(
     HMONITOR hMon
    )
{
    AMTRACE((TEXT("CMonitorArray::FindMonitor")));
    for (DWORD i = 0; i < m_dwNumMonitors; i++) {

        if (hMon == m_DDMon[i].hMon ) {
            return &m_DDMon[i];
        }
    }
    DbgLog((LOG_TRACE, 3, TEXT("Find monitor not found") ));
    return NULL;
}

/*****************************Private*Routine******************************\
* MatchGUID
*
*
*
* History:
* Fri 04/25/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CMonitorArray::MatchGUID(
    const GUID* pGUID,
    DWORD* pdwMatchID
    )
{
    AMTRACE((TEXT("CMonitorArray::MatchGUID")));
    for (DWORD i = 0; i < m_dwNumMonitors; i++) {

        const GUID* pMonGUID = m_DDMon[i].guid.pGUID;

        if ((pMonGUID == NULL && pGUID == NULL) ||
            (pMonGUID && pGUID && IsEqualGUID(*pGUID, *pMonGUID))) {

            *pdwMatchID = i;
            return S_OK;
        }
    }

    return S_FALSE;
}

CMonitorArray::CMonitorArray()
: m_dwNumMonitors( 0 )
{
    AMTRACE((TEXT("CMonitorArray::CMonitorArray")));
    ZeroMemory(m_DDMon, sizeof(m_DDMon));
}

/*****************************Private*Routine******************************\
* TerminateDisplaySystem
*
*
*
* History:
* Mon 01/24/2000 - StEstrop - Created
*
\**************************************************************************/
void CMonitorArray::TerminateDisplaySystem()
{
    AMTRACE((TEXT("CMonitorArray::TerminateDisplaySystem")));

    for (DWORD i = 0; i < m_dwNumMonitors; i++) {
        TermDDrawMonitorInfo(&m_DDMon[i]);
    }
    m_dwNumMonitors = 0;
}

CMonitorArray::~CMonitorArray()
{
    AMTRACE((TEXT("CMonitorArray::~CMonitorArray")));
    TerminateDisplaySystem();
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\core\imagesyncctrl.cpp ===
/******************************Module*Header*******************************\
* Module Name: ImageSyncCtrl.cpp
*
* Implements the IImageSyncControl interface of the  core Image Synchronization
* Object - based on DShow base classes CBaseRenderer and CBaseVideoRenderer.
*
*
* Created: Wed 01/12/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "ImageSyncObj.h"



/////////////////////////////////////////////////////////////////////////////
// CImageSync
//
/////////////////////////////////////////////////////////////////////////////

// --------------------------------------------------------------------------
// Some helper inline functions
// --------------------------------------------------------------------------
__inline bool IsDiscontinuity(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_Discontinuity);
}

__inline bool IsTimeValid(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_TimeValid);
}

__inline bool IsSyncPoint(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_SyncPoint);
}


/******************************Public*Routine******************************\
* SetImagePresenter
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::SetImagePresenter(
    IVMRImagePresenter* lpImagePresenter,
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CImageSync::SetImagePresenter")));
    CAutoLock cILock(&m_InterfaceLock);
    CAutoLock cRLock(&m_RendererLock);

    if (lpImagePresenter) {
        lpImagePresenter->AddRef();
    }

    if (m_ImagePresenter) {
        m_ImagePresenter->Release();
    }

    m_ImagePresenter = lpImagePresenter;
    m_dwUserID = dwUserID;

    return S_OK;
}

/******************************Public*Routine******************************\
* SetReferenceClock
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::SetReferenceClock(
    IReferenceClock* lpRefClock
    )
{
    AMTRACE((TEXT("CImageSync::SetReferenceClock")));
    CAutoLock cILock(&m_InterfaceLock);
    CAutoLock cRLock(&m_RendererLock);

    if (lpRefClock) {
        lpRefClock->AddRef();
    }

    if (m_pClock) {
        m_pClock->Release();
    }

    m_pClock = lpRefClock;

    return S_OK;
}

/******************************Public*Routine******************************\
* SetEventNotify
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::SetEventNotify(
    IImageSyncNotifyEvent* lpEventNotify
    )
{
    AMTRACE((TEXT("CImageSync::SetEventNotify")));
    CAutoLock cILock(&m_InterfaceLock);
    CAutoLock cRLock(&m_RendererLock);

    if (lpEventNotify) {
        lpEventNotify->AddRef();
    }

    if (m_lpEventNotify) {
        m_lpEventNotify->Release();
    }

    m_lpEventNotify = lpEventNotify;

    return S_OK;
}


/*****************************Private*Routine******************************\
* ResetStreamingTimes
*
* Reset all times controlling streaming.
* Set them so that
* 1. Frames will not initially be dropped
* 2. The first frame will definitely be drawn (achieved by saying that there
*    has not ben a frame drawn for a long time).
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::ResetStreamingTimes()
{
    AMTRACE((TEXT("CImageSync::ResetStreamingTimes")));
    m_trLastDraw = -1000;     // set up as first frame since ages (1 sec) ago
    m_tStreamingStart = timeGetTime();
    m_trRenderAvg = 0;
    m_trFrameAvg = -1;        // -1000 fps == "unset"
    m_trDuration = 0;         // 0 - value
    m_trRenderLast = 0;
    m_trWaitAvg = 0;
    m_tRenderStart = 0;
    m_cFramesDrawn = 0;
    m_cFramesDropped = 0;
    m_iTotAcc = 0;
    m_iSumSqAcc = 0;
    m_iSumSqFrameTime = 0;
    m_trFrame = 0;          // hygeine - not really needed
    m_trLate = 0;           // hygeine - not really needed
    m_iSumFrameTime = 0;
    m_nNormal = 0;
    m_trEarliness = 0;
    m_trTarget = -300000;  // 30mSec early
    m_trThrottle = 0;
    m_trRememberStampForPerf = 0;

#ifdef PERF
    m_trRememberFrameForPerf = 0;
#endif

    return S_OK;
}



/******************************Public*Routine******************************\
* BeginImageSequence
*
* This is called when we start running so that we can schedule any pending
* image we have with the clock and display any timing information. If we
* don't have any sample but we return straight away.
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::BeginImageSequence(
    REFERENCE_TIME* pStartTime
    )
{
    AMTRACE((TEXT("CImageSync::BeginImageSequence")));
    CAutoLock cILock(&m_InterfaceLock);
    DWORD OldState = m_State;

    if (m_State == ImageSync_State_Playing) {
        return S_OK;
    }

    //
    // We can't begin an image sequence if
    // nothing is cued
    //

    if (m_State == ImageSync_State_Stopped) {
        return VFW_E_WRONG_STATE;
    }


    Ready();

    m_tStart = *pStartTime;
    m_State = ImageSync_State_Playing;

    SourceThreadCanWait(TRUE);


    //
    // There should be no outstanding advise
    //

    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);

    //
    // When we come out of a stopped state we must clear any image we were
    // holding onto for frame refreshing. Since renderers see state changes
    // first we can reset ourselves ready to accept the source thread data
    // Paused or running after being stopped causes the current position to
    // be reset so we're not interested in passing end of stream signals
    //

    if (OldState == ImageSync_State_Stopped) {
        m_bAbort = FALSE;
        ClearSavedSample();
    }

    return StartStreaming();
}


void CALLBACK VMREndOfStreamTimer(UINT uID,        // Timer identifier
		                  UINT uMsg,       // Not currently used
		                  DWORD_PTR dwUser,// User information
		                  DWORD_PTR dw1,   // Windows reserved
			          DWORD_PTR dw2)   // is also reserved
{
    CImageSync* pRenderer = (CImageSync *) dwUser;
    NOTE1("VMREndOfStreamTimer called (%d)",uID);
    pRenderer->TimerCallback();
}

//  Do the timer callback work
void CImageSync::TimerCallback()
{
    //  Lock for synchronization (but don't hold this lock when calling
    //  timeKillEvent)
    CAutoLock cRendererLock(&m_RendererLock);

    // See if we should signal end of stream now

    if (m_EndOfStreamTimer) {
        m_EndOfStreamTimer = 0;
        SendEndOfStream();
    }
}


// If we are at the end of the stream signal the filter graph but do not set
// the state flag back to FALSE. Once we drop off the end of the stream we
// leave the flag set (until a subsequent ResetEndOfStream). Each sample we
// get delivered will update m_SignalTime to be the last sample's end time.
// We must wait this long before signalling end of stream to the filtergraph

#define TIMEOUT_DELIVERYWAIT 50
#define TIMEOUT_RESOLUTION 10

HRESULT CImageSync::SendEndOfStream()
{
    ASSERT(CritCheckIn(&m_RendererLock));

    if (m_bEOS == FALSE || IsEndOfStreamDelivered() || m_EndOfStreamTimer) {
        return NOERROR;
    }

    // If there is no clock then signal immediately
    if (m_pClock == NULL) {
        return NotifyEndOfStream();
    }

    // How long into the future is the delivery time

    REFERENCE_TIME Signal = m_tStart + m_SignalTime;
    REFERENCE_TIME CurrentTime;
    m_pClock->GetTime(&CurrentTime);
    LONG Delay = LONG((Signal - CurrentTime) / 10000);

    // Dump the timing information to the debugger

    NOTE1("Delay until end of stream delivery %d",Delay);
    NOTE1("Current %s",(LPCTSTR)CDisp((LONGLONG)CurrentTime));
    NOTE1("Signal %s",(LPCTSTR)CDisp((LONGLONG)Signal));

    // Wait for the delivery time to arrive

    if (Delay < TIMEOUT_DELIVERYWAIT) {
        return NotifyEndOfStream();
    }

    // Signal a timer callback on another worker thread

    m_EndOfStreamTimer = CompatibleTimeSetEvent((UINT) Delay,        // Period of timer
                                                TIMEOUT_RESOLUTION,  // Timer resolution
                                                VMREndOfStreamTimer, // Callback function
                                                DWORD_PTR(this),     // Used information
                                                TIME_ONESHOT);       // Type of callback
    if (m_EndOfStreamTimer == 0) {
        return NotifyEndOfStream();
    }
    return NOERROR;
}


// Signals EC_COMPLETE to the filtergraph manager

HRESULT CImageSync::NotifyEndOfStream()
{
    CAutoLock cRendererLock(&m_RendererLock);
    ASSERT(!IsEndOfStreamDelivered());
    ASSERT(m_EndOfStreamTimer == 0);

    // Has the filter changed state

    if (!IsStreaming()) {
        ASSERT(m_EndOfStreamTimer == 0);
        return NOERROR;
    }

    // Reset the end of stream timer
    m_EndOfStreamTimer = 0;

    // If we've been using the IMediaPosition interface, set it's start
    // and end media "times" to the stop position by hand.  This ensures
    // that we actually get to the end, even if the MPEG guestimate has
    // been bad or if the quality management dropped the last few frames

    m_bEOSDelivered = TRUE;
    NOTE("Sending EC_COMPLETE...");

    if (m_lpEventNotify) {
        return m_lpEventNotify->NotifyEvent(EC_COMPLETE, 0, 0);
    }

    return E_FAIL;
}


// Reset the end of stream flag, this is typically called when we transfer to
// stopped states since that resets the current position back to the start so
// we will receive more samples or another EndOfStream if there aren't any. We
// keep two separate flags one to say we have run off the end of the stream
// (this is the m_bEOS flag) and another to say we have delivered EC_COMPLETE
// to the filter graph. We need the latter otherwise we can end up sending an
// EC_COMPLETE every time the source changes state and calls our EndOfStream

STDMETHODIMP
CImageSync::ResetEndOfStream()
{
    ResetEndOfStreamTimer();
    CAutoLock cRendererLock(&m_RendererLock);

    m_bEOS = FALSE;
    m_bEOSDelivered = FALSE;
    m_SignalTime = 0;

    return NOERROR;
}


STDMETHODIMP
CImageSync::SetAbortSignal(BOOL fAbort)
{
    m_bAbort = fAbort;
    return NOERROR;
}

STDMETHODIMP
CImageSync::GetAbortSignal(BOOL* lpfAbort)
{
    *lpfAbort = m_bAbort;
    return NOERROR;
}


STDMETHODIMP
CImageSync::RuntimeAbortPlayback()
{
    // This function must hold the renderer lock because it 
    // calls IsStreaming() and IsEndOfStreamDelivered().
    CAutoLock cRendererLock(&m_RendererLock);

    if (IsStreaming() && !IsEndOfStreamDelivered())
    {
        NotifyEndOfStream();
        return S_OK;
    }

    return S_FALSE;
}

// Kills any outstanding end of stream timer

void CImageSync::ResetEndOfStreamTimer()
{
    ASSERT(CritCheckOut(&m_RendererLock));
    if (m_EndOfStreamTimer) {
        timeKillEvent(m_EndOfStreamTimer);
        m_EndOfStreamTimer = 0;
    }
}

/*****************************Private*Routine******************************\
* StartStreaming
*
* This is called when we start running so that we can schedule any pending
* image we have with the clock and display any timing information.
* If we do have a sample then we wait until that has been rendered before we
* signal the filter graph otherwise we may change state before it's done
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::StartStreaming(
    )
{
    AMTRACE((TEXT("CImageSync::StartStreaming")));
    CAutoLock cRLock(&m_RendererLock);

    //
    // StartStreaming already called
    //

    if (IsStreaming()) {
        return S_OK;
    }

    //
    // Reset the streaming times ready for running
    //

    m_bStreaming = TRUE;
    timeBeginPeriod(1);
    OnStartStreaming();


    //
    // There should be no outstanding advise
    //

    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(CancelNotification() == S_FALSE);

    // If we have an EOS and no data then deliver it now

    if (!HaveSavedSample()) {
        // reset m_EOSDelivered in case we got our last eos 
        // and need to resend the EC_COMPLETE immediately
        m_bEOSDelivered = FALSE;
        return SendEndOfStream();
    }


    //
    // Get the saved pending sample and schedule it, if no sample is waiting
    // return straight away.
    //

    VMRPRESENTATIONINFO *pSample;

    HRESULT hr = GetSavedSample(&pSample);

    if (SUCCEEDED(hr)) {

        //
        // Have the data rendered
        //

        ASSERT(pSample);
        hr = ScheduleSample(pSample);

        if (FAILED(hr)) {
            m_RenderEvent.Set();
            hr = S_OK;
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* OnStartStreaming
*
* Reset all times controlling streaming. Note that we're now streaming. We
* don't need to set the rendering event to have the source filter released
* as it is done during the Run processing. When we are run we immediately
* release the source filter thread and draw any image waiting (that image
* may already have been drawn once as a poster frame while we were paused)
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::OnStartStreaming()
{
    AMTRACE((TEXT("CImageSync::OnStartStreaming")));

    if (m_ImagePresenter) {
        m_ImagePresenter->StartPresenting(m_dwUserID);
    }

    ResetStreamingTimes();
    return S_OK;
}


/*****************************Private*Routine******************************\
* OnStopStreaming
*
*
* Called at end of streaming.  Fixes times for property page report
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::OnStopStreaming()
{
    AMTRACE((TEXT("CImageSync::OnStopStreaming")));
    m_tStreamingStart = timeGetTime() - m_tStreamingStart;

    if (m_ImagePresenter) {
        m_ImagePresenter->StopPresenting(m_dwUserID);
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* EndImageSequence
*
* When we end an image sequence the thing we do are:
*
*   Release any thread that may be waiting in Receive
*   Cancel any advise link we set up with the clock
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::EndImageSequence(
    )
{
    AMTRACE((TEXT("CImageSync::EndImageSequence")));
    CAutoLock cRLock(&m_InterfaceLock);

    //
    // Make sure there really is a state change
    //

    if (m_State == ImageSync_State_Stopped) {
        return NOERROR;
    }

    m_State = ImageSync_State_Stopped;


    //
    // Cancel any scheduled rendering
    //
    StopStreaming();
    SourceThreadCanWait(FALSE);
    ResetEndOfStream();
    CancelNotification();

    //
    // There should be no outstanding clock advise
    //
    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);

    Ready();
    WaitForReceiveToComplete();
    m_bAbort = FALSE;
    return S_OK;
}

/*****************************Private*Routine******************************\
* CompleteStateChange
*
* If we're pausing and we have no samples we don't complete the transition
* to State_Paused and we return S_FALSE.
*
* If we do have a sample then return NOERROR.
*
* We will only ever return * VFW_S_STATE_INTERMEDIATE from GetState after
* being paused with no sample * (calling GetState after either being stopped
* or Run will NOT return this)
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::CompleteStateChange(
    DWORD OldState
    )
{
    AMTRACE((TEXT("CImageSync::CompleteStateChange")));

    // Have we run off the end of stream

    if (IsEndOfStream() == TRUE) {
        Ready();
        return S_OK;
    }



    //
    // Make sure we get fresh data after being stopped
    //

    if (HaveSavedSample() == TRUE) {

        if (OldState != ImageSync_State_Stopped) {

            Ready();
            return S_OK;
        }
    }

    NotReady();

    return S_FALSE;
}


/*****************************Private*Routine******************************\
* CueImageSequence
*
* When we pause the filter the things we do are:-
*
*      Allow a threads to wait in Receive
*      Cancel any clock advise link (we may be playing an image sequence)
*      Possibly complete the state change if we have data
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::CueImageSequence(
    )
{
    AMTRACE((TEXT("CImageSync::CueImageSequence")));
    CAutoLock cIk(&m_InterfaceLock);

    DWORD OldState = m_State;

    //
    // Make sure there really is a state change
    //

    if (m_State == ImageSync_State_Cued) {
        return CompleteStateChange(ImageSync_State_Cued);
    }

    //
    // Pause the base filter class
    //
    m_State = ImageSync_State_Cued;

    StopStreaming();
    SourceThreadCanWait(TRUE);
    CancelNotification();
    ResetEndOfStreamTimer();

    //
    // There should be no outstanding advise
    //

    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);


    //
    // When we come out of a stopped state we must clear any image we were
    // holding onto for frame refreshing. Since renderers see state changes
    // first we can reset ourselves ready to accept the source thread data
    // Paused or running after being stopped causes the current position to
    // be reset so we're not interested in passing end of stream signals
    //

    if (OldState == ImageSync_State_Stopped) {
        m_bAbort = FALSE;
        ClearSavedSample();
    }

    return CompleteStateChange(OldState);
}


/******************************Public*Routine******************************\
* GetImageSequenceState
*
* The renderer doesn't complete the full transition to paused states until
* it has got one media sample to render. If you ask it for its state while
* it's waiting it will return the state along with VFW_S_STATE_INTERMEDIATE
*
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::GetImageSequenceState(
    DWORD dwMSecs,
    DWORD *State
    )
{
    AMTRACE((TEXT("CImageSync::GetImageSequenceState")));
    if (!State)
        return E_POINTER;

    if (WaitDispatchingMessages(m_evComplete, dwMSecs) == WAIT_TIMEOUT) {
//  if (WaitForSingleObject(m_evComplete, dwMSecs) == WAIT_TIMEOUT) {
        *State = m_State;
        return VFW_S_STATE_INTERMEDIATE;
    }

    *State = m_State;

    return NOERROR;
}


/******************************Public*Routine******************************\
* BeginFlush
*
* When we are told to flush we should release the source thread
*
* History:
* Wed 03/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::BeginFlush()
{
    AMTRACE((TEXT("CImageSync::BeginFlush")));

    CAutoLock cRendererLock(&m_InterfaceLock);
    {
        if (m_bFlushing) {
            return S_OK;
        }
        m_bFlushing = true;

        CAutoLock cSampleLock(&m_RendererLock);

        if (ImageSync_State_Cued == m_State) {
            NotReady();
        }

        SourceThreadCanWait(FALSE);
        CancelNotification();
        ClearSavedSample();

        //  Wait for Receive to complete
        WaitForReceiveToComplete();
    }

    return ResetEndOfStream();
}


/******************************Public*Routine******************************\
* EndFlush
*
* After flushing the source thread can wait in Receive again
*
* History:
* Wed 03/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::EndFlush()
{
    AMTRACE((TEXT("CImageSync::EndFlush")));

    CAutoLock cRendererLock(&m_InterfaceLock);
    CAutoLock cSampleLock(&m_RendererLock);

    if (!m_bFlushing) {
        return S_OK;
    }
    m_bFlushing = false;

    // There should be no outstanding advise

    ASSERT(CancelNotification() == S_FALSE);
    SourceThreadCanWait(TRUE);
    return S_OK;

}

/******************************Public*Routine******************************\
* EndOfStream
*
*
* Called when the input pin receives an EndOfStream notification. If we have
* not got a sample, then notify EC_COMPLETE now. If we have samples, then set
* m_bEOS and check for this on completing samples. If we're waiting to pause
* then complete the transition to paused state by setting the state event
*
* History:
* Thu 03/30/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::EndOfStream()
{
    AMTRACE((TEXT("CImageSync::EndOfStream")));

    CAutoLock cRendererLock(&m_InterfaceLock);
    CAutoLock cSampleLock(&m_RendererLock);

    // Ignore these calls if we are stopped

    if (m_State == ImageSync_State_Stopped) {
        return S_OK;
    }

    // If we have a sample then wait for it to be rendered

    m_bEOS = TRUE;
    if (HaveSavedSample()) {
        return S_OK;
    }

    //
    // If we are waiting for pause then we are now ready since we cannot now
    // carry on waiting for a sample to arrive since we are being told there
    // won't be any. This sets an event that the GetState function picks up
    //

    Ready();

    //
    // Only signal completion now if we are running otherwise queue it until
    // we do run in StartStreaming. This is used when we seek because a seek
    // causes a pause where early notification of completion is misleading
    //

    if (IsStreaming()) {
        SendEndOfStream();
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* StopStreaming
*
* This is called when we stop streaming so that we can set our internal flag
* indicating we are not now to schedule any more samples arriving. The state
* change methods in the filter implementation take care of cancelling any
* clock advise link we have set up and clearing any pending sample we have
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::StopStreaming()
{
    AMTRACE((TEXT("CImageSync::StopStreaming")));
    CAutoLock cRLock(&m_RendererLock);

    if (IsStreaming()) {
        m_bStreaming = FALSE;
        OnStopStreaming();
        timeEndPeriod(1);
    }

    return S_OK;;
}


/*****************************Private*Routine******************************\
* WaitForReceiveToComplete
*
* Poll waiting for Receive to complete.  This really matters when
* Receive may set the palette and cause window messages
* The problem is that if we don't really wait for a renderer to
* stop processing we can deadlock waiting for a transform which
* is calling the renderer's Receive() method because the transform's
* Stop method doesn't know to process window messages to unblock
* the renderer's Receive processing
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::WaitForReceiveToComplete()
{
    AMTRACE((TEXT("CImageSync::WaitForReceiveToComplete")));
    for (; ; ) {

        if (!m_bInReceive) {
            break;
        }

        //
        //  Receive all interthread sendmessages
        //

        MSG msg;
        PeekMessage(&msg, NULL, WM_NULL, WM_NULL, PM_NOREMOVE);

        Sleep(1);
    }

    //
    // If the wakebit for QS_POSTMESSAGE is set, the PeekMessage call
    // above just cleared the changebit which will cause some messaging
    // calls to block (waitMessage, MsgWaitFor...) now.
    // Post a dummy message to set the QS_POSTMESSAGE bit again
    //

    if (HIWORD(GetQueueStatus(QS_POSTMESSAGE)) & QS_POSTMESSAGE) {

        //  Post dummy message
        PostThreadMessage(GetCurrentThreadId(), WM_NULL, 0, 0);
    }
}

/*****************************Private*Routine******************************\
* SourceThreadCanWait
*
* This is called whenever we change states, we have a manual reset event that
* is signalled whenever we don't won't the source filter thread to wait in us
* (such as in a stopped state) and likewise is not signalled whenever it can
* wait (during paused and running) this function sets or resets the thread
* event. The event is used to stop source filter threads waiting in Receive
*
* History:
* Fri 01/21/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::SourceThreadCanWait(
    BOOL bCanWait
    )
{
    AMTRACE((TEXT("CImageSync::SourceThreadCanWait")));
    if (bCanWait == TRUE) {
        m_ThreadSignal.Reset();
    } else {
        CancelFrameStep();
        m_ThreadSignal.Set();
    }

    return NOERROR;
}



/******************************Public*Routine******************************\
* FrameStep
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::FrameStep(
    DWORD nFramesToStep,
    DWORD dwStepFlags
    )
{
    AMTRACE((TEXT("CImageSync::FrameStep")));
    CAutoLock cLock(&m_InterfaceLock);

    long l = m_lFramesToStep;
    m_lFramesToStep = nFramesToStep;

    //
    // If we are currently blocked on the frame step event
    // release the receive thread so that we can get another
    // frame
    //

    if (l == 0) {
        SetEvent(m_StepEvent);
    }
    return S_OK;
}


/******************************Public*Routine******************************\
* CancelFrameStep
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::CancelFrameStep()
{
    AMTRACE((TEXT("CImageSync::CancelFrameStep")));
    CAutoLock cLock(&m_InterfaceLock);

    //
    // cancel any outstanding steps
    //
    long l = m_lFramesToStep;
    m_lFramesToStep = -1;

    if (l == 0) {
        SetEvent(m_StepEvent);
    }

    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\ap\display.h ===
/******************************Module*Header*******************************\
* Module Name: display.h
*
*
*
*
* Created: Mon 01/24/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

#define AMDDRAWMONITORINFO_PRIMARY_MONITOR          0x0001

typedef struct {
    BITMAPINFOHEADER    bmiHeader;
    union {
        RGBQUAD         bmiColors[iPALETTE_COLORS];
        DWORD           dwBitMasks[iMASK_COLORS];
        TRUECOLORINFO   TrueColorInfo;
    };
} AMDISPLAYINFO;

struct CAMDDrawMonitorInfo : public VMRMONITORINFO
{
    DDCAPS_DX7              ddHWCaps;
    AMDISPLAYINFO           DispInfo;
    LPDIRECTDRAW7           pDD;
    LPDIRECTDRAWSURFACE7    pDDSPrimary;    // DDraw Primary Surface
    DWORD                   dwMappedBdrClr; // Border clr mapped to this monitor
};



#ifndef MAX_MONITORS
#define MAX_MONITORS    4
#endif

class CMonitorArray
{
public:
    CMonitorArray();
    ~CMonitorArray();

    HRESULT                 InitializeDisplaySystem( HWND hwnd );
    HRESULT                 InitializeXclModeDisplaySystem(
                                    HWND hwnd,
                                    LPDIRECTDRAW7 lpDD,
                                    LPDIRECTDRAWSURFACE7 lpPS);

    void                    TerminateDisplaySystem();
    CAMDDrawMonitorInfo*    FindMonitor( HMONITOR hMon );
    HRESULT                 MatchGUID( const GUID* lpGUID, DWORD* pdwMatchID );


    CAMDDrawMonitorInfo&    operator[](int i)
                            { return m_DDMon[i]; }
    DWORD                   Count() const
                            { return m_dwNumMonitors; }
private:
    DWORD                   m_dwNumMonitors;
    CAMDDrawMonitorInfo     m_DDMon[MAX_MONITORS];
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\core\imagesyncqual.cpp ===
/******************************Module*Header*******************************\
* Module Name: ImageSyncQual.cpp
*
* Implements the IQualProp interface of the core Image Synchronization
* Object - based on DShow base classes CBaseRenderer and CBaseVideoRenderer.
*
*
* Created: Wed 01/12/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "resource.h"
#include "ImageSyncObj.h"

// To avoid dragging in the maths library - a cheap
// approximate integer square root.
// We do this by getting a starting guess which is between 1
// and 2 times too large, followed by THREE iterations of
// Newton Raphson.  (That will give accuracy to the nearest mSec
// for the range in question - roughly 0..1000)
//
// It would be faster to use a linear interpolation and ONE NR, but
// who cares.  If anyone does - the best linear interpolation is
// to approximates sqrt(x) by
// y = x * (sqrt(2)-1) + 1 - 1/sqrt(2) + 1/(8*(sqrt(2)-1))
// 0r y = x*0.41421 + 0.59467
// This minimises the maximal error in the range in question.
// (error is about +0.008883 and then one NR will give error .0000something
// (Of course these are integers, so you can't just multiply by 0.41421
// you'd have to do some sort of MulDiv).
// Anyone wanna check my maths?  (This is only for a property display!)

static int isqrt(int x)
{
    int s = 1;
    // Make s an initial guess for sqrt(x)
    if (x > 0x40000000) {
       s = 0x8000;     // prevent any conceivable closed loop
    } else {
	while (s*s<x) {    // loop cannot possible go more than 31 times
	    s = 2*s;       // normally it goes about 6 times
	}
	// Three NR iterations.
	if (x==0) {
	   s= 0; // Wouldn't it be tragic to divide by zero whenever our
		 // accuracy was perfect!
	} else {
	    s = (s*s+x)/(2*s);
	    if (s>=0) s = (s*s+x)/(2*s);
	    if (s>=0) s = (s*s+x)/(2*s);
	}
    }
    return s;
}

/*****************************Private*Routine******************************\
* GetStdDev
*
* Do estimates for standard deviations for per-frame statistics
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::GetStdDev(
    int nSamples,
    int *piResult,
    LONGLONG llSumSq,
    LONGLONG iTot
    )
{
    CheckPointer(piResult,E_POINTER);
    CAutoLock cVideoLock(&m_InterfaceLock);

    if (NULL==m_pClock) {
	*piResult = 0;
	return NOERROR;
    }

    // If S is the Sum of the Squares of observations and
    //    T the Total (i.e. sum) of the observations and there were
    //    N observations, then an estimate of the standard deviation is
    //      sqrt( (S - T**2/N) / (N-1) )

    if (nSamples<=1) {
	*piResult = 0;
    } else {
	LONGLONG x;
	// First frames have bogus stamps, so we get no stats for them
	// So we need 2 frames to get 1 datum, so N is cFramesDrawn-1

	// so we use m_cFramesDrawn-1 here
	x = llSumSq - llMulDiv(iTot, iTot, nSamples, 0);
	x = x / (nSamples-1);
	ASSERT(x>=0);
	*piResult = isqrt((LONG)x);
    }
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_FramesDroppedInRenderer
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_FramesDroppedInRenderer(
    int *pcFramesDropped
    )
{
    CheckPointer(pcFramesDropped,E_POINTER);
    CAutoLock cVideoLock(&m_InterfaceLock);
    *pcFramesDropped = m_cFramesDropped;
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_FramesDrawn
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_FramesDrawn(
    int *pcFramesDrawn
    )
{
    CheckPointer(pcFramesDrawn,E_POINTER);
    CAutoLock cVideoLock(&m_InterfaceLock);
    *pcFramesDrawn = m_cFramesDrawn;
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_AvgFrameRate
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_AvgFrameRate(
    int *piAvgFrameRate
    )
{
    CheckPointer(piAvgFrameRate,E_POINTER);

    CAutoLock cVideoLock(&m_InterfaceLock);
    CAutoLock cRendererLock(&m_RendererLock);

    int t;
    if (IsStreaming()) {
        t = timeGetTime()-m_tStreamingStart;
    } else {
        t = m_tStreamingStart;
    }

    if (t<=0) {
        *piAvgFrameRate = 0;
        ASSERT(m_cFramesDrawn == 0);
    } else {
        // i is frames per hundred seconds
        *piAvgFrameRate = MulDiv(100000, m_cFramesDrawn, t);
    }
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_Jitter
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_Jitter(
    int *piJitter
    )
{
    // First frames have bogus stamps, so we get no stats for them
    // So second frame gives bogus inter-frame time
    // So we need 3 frames to get 1 datum, so N is cFramesDrawn-2
    return GetStdDev(m_cFramesDrawn - 2,
		     piJitter,
		     m_iSumSqFrameTime,
		     m_iSumFrameTime);
}


/******************************Public*Routine******************************\
* get_AvgSyncOffset
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_AvgSyncOffset(
    int *piAvg
    )
{
    CheckPointer(piAvg,E_POINTER);
    CAutoLock cVideoLock(&m_InterfaceLock);

    if (NULL==m_pClock) {
	*piAvg = 0;
	return NOERROR;
    }

    // Note that we didn't gather the stats on the first frame
    // so we use m_cFramesDrawn-1 here
    if (m_cFramesDrawn<=1) {
	*piAvg = 0;
    } else {
	*piAvg = (int)(m_iTotAcc / (m_cFramesDrawn-1));
    }
    return NOERROR;
}


/******************************Public*Routine******************************\
* get_DevSyncOffset
*
*
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::get_DevSyncOffset(
    int *piDev
    )
{
    // First frames have bogus stamps, so we get no stats for them
    // So we need 2 frames to get 1 datum, so N is cFramesDrawn-1
    return GetStdDev(m_cFramesDrawn - 1,
		     piDev,
		     m_iSumSqAcc,
		     m_iTotAcc);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\core\resource.h ===
//{{NO_DEPENDENCIES}}
// Microsoft Developer Studio generated include file.
// Used by ImageSync.rc
//
#define IDS_PROJNAME                    100
#define IDR_IMAGESYNC                   101

// Next default values for new objects
// 
#ifdef APSTUDIO_INVOKED
#ifndef APSTUDIO_READONLY_SYMBOLS
#define _APS_NEXT_RESOURCE_VALUE        201
#define _APS_NEXT_COMMAND_VALUE         32768
#define _APS_NEXT_CONTROL_VALUE         201
#define _APS_NEXT_SYMED_VALUE           102
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\inc\vmrp.h ===
//=====================================================================
//
// vmrp.h
//
// Private header for Video Mixing Renderer
//
// Copyright (C) 2000 by Microsoft Corporation.  All rights reserved.
//
//=====================================================================

#ifndef __INC_VMRP__
#define __INC_VMRP__

#include "dxva.h"

#define MAX_MIXER_PINS              16
#define MAX_MIXER_STREAMS           (MAX_MIXER_PINS)
#define MIN_BUFFERS_TO_ALLOCATE     1

#define MAX_ALLOWED_BUFFER          64
#define EXTRA_OVERLAY_BUFFERS       2
#define EXTRA_OFFSCREEN_BUFFERS     1 // should really be 1 but as yet
                                      // most graphics drivers don't like
                                      // back buffers when the overlay is
                                      // not being requested too.


//
// Private intel mixer render target, IMC3
//
#define MixerPref_RenderTargetIntelIMC3 0x00008100

#ifndef __RELEASE_DEFINED
#define __RELEASE_DEFINED
template<typename T>
__inline void RELEASE( T* &p )
{
    if( p ) {
        p->Release();
        p = NULL;
    }
}
#endif

#ifndef CHECK_HR
    #define CHECK_HR(expr) do { if (FAILED(expr)) __leave; } while(0);
#endif

#if defined(DEBUG)
#define ISBADREADPTR(p) (IsBadReadPtr( (p), (sizeof(*p))))
#define ISBADWRITEPTR(p) (IsBadWritePtr( (p), (sizeof(*p))))
#define ISBADREADARRAY(p,c) (IsBadReadPtr( (p), (c)*(sizeof(*p))))
#define ISBADWRITEARRAY(p,c) (IsBadWritePtr( (p), (c)*(sizeof(*p))))
#else
#define ISBADREADPTR(p) (NULL==(p))
#define ISBADWRITEPTR(p) (NULL==(p))
#define ISBADREADARRAY(p,c) (NULL==(p))
#define ISBADWRITEARRAY(p,c) (NULL==(p))
#endif

#define ISWINDOW(hwnd) (IsWindow(hwnd))
#define ISBADREADWRITEPTR(p) (ISBADREADPTR(p)||ISBADWRITEPTR(p))
#define ISBADREADWRITEARRAY(p,c) (ISBADREADARRAY(p,c)||ISBADWRITEARRAY(p,c))

//  Debug helper
#ifdef DEBUG
class CDispPixelFormat : public CDispBasic
{
public:
    CDispPixelFormat(const DDPIXELFORMAT *pFormat)
    {
        wsprintf(m_String, TEXT("  Flags(0x%8.8X) bpp(%d) 4CC(%4.4hs)"),
                 pFormat->dwFlags,
                 pFormat->dwRGBBitCount,
                 pFormat->dwFlags & DDPF_FOURCC ?
                     (CHAR *)&pFormat->dwFourCC : "None");
    }
    //  Implement cast to (LPCTSTR) as parameter to logger
    operator LPCTSTR()
    {
        return (LPCTSTR)m_pString;
    };
};
#endif // DEBUG


/* -------------------------------------------------------------------------
** VMR file persist helpers
** -------------------------------------------------------------------------
*/
struct VMRStreamInfo {
    float           alpha;
    DWORD           zOrder;
    NORMALIZEDRECT  rect;
};

struct VMRFilterInfo {
    DWORD           dwSize;
    DWORD           dwNumPins;
    VMRStreamInfo   StreamInfo[MAX_MIXER_STREAMS];
};


// internal interfaces used by the VMR
// interface IImageSyncNotifyEvent;
// interface IImageSyncControl;
// interface IImageSync;
// interface IVMRMixerControl;
// interface IVMRMixerStream;


//
// 1DBCA562-5C92-474a-A276-382079164970),
//
DEFINE_GUID(IID_IImageSyncNotifyEvent,
0x1DBCA562, 0x5C92, 0x474a, 0xA2, 0x76, 0x38, 0x20, 0x79, 0x16, 0x49, 0x70);

DECLARE_INTERFACE_(IImageSyncNotifyEvent, IUnknown)
{
    STDMETHOD (NotifyEvent)(THIS_
                            long EventCode,
                            LONG_PTR EventParam1,
                            LONG_PTR EventParam2
                            ) PURE;
};


typedef enum {
        ImageSync_State_Stopped,
        ImageSync_State_Cued,
        ImageSync_State_Playing
} ImageSequenceState;


//
// A67F6A0D-883B-44ce-AA93-87BA3017E19C
//
DEFINE_GUID(IID_IImageSyncControl,
0xA67F6A0D, 0x883B, 0x44ce, 0xAA, 0x93, 0x87, 0xBA, 0x30, 0x17, 0xE1, 0x9C);

DECLARE_INTERFACE_(IImageSyncControl, IUnknown)
{
    // ============================================================
    // Synchronisation control
    // ============================================================

    STDMETHOD (SetImagePresenter)(THIS_
        IVMRImagePresenter* lpImagePresenter,
        DWORD_PTR dwUserID
        ) PURE;

    STDMETHOD (SetReferenceClock)(THIS_
        IReferenceClock* lpRefClock
        ) PURE;

    STDMETHOD (SetEventNotify)(THIS_
        IImageSyncNotifyEvent* lpEventNotify
        ) PURE;


    // ============================================================
    // Image sequence control
    // ============================================================

    STDMETHOD (CueImageSequence)(THIS_
        ) PURE;

    STDMETHOD (BeginImageSequence)(THIS_
        REFERENCE_TIME* baseTime
        ) PURE;

    STDMETHOD (EndImageSequence)(THIS_
        ) PURE;

    STDMETHOD (GetImageSequenceState)(THIS_
        DWORD dwMSecsTimeOut,
        DWORD* lpdwState
        ) PURE;

    STDMETHOD (BeginFlush)(THIS_
        ) PURE;

    STDMETHOD (EndFlush)(THIS_
        ) PURE;

    STDMETHOD (EndOfStream)(THIS_
        ) PURE;

    STDMETHOD (ResetEndOfStream)(THIS_
        ) PURE;

    STDMETHOD (SetAbortSignal)(THIS_
        BOOL bAbort
        ) PURE;

    STDMETHOD (GetAbortSignal)(THIS_
        BOOL* lpbAbort
        ) PURE;

    STDMETHOD (RuntimeAbortPlayback)(THIS_
        ) PURE;

    // ============================================================
    // Frame stepping
    // ============================================================

    STDMETHOD (FrameStep)(THIS_
        DWORD nFramesToStep,
        DWORD dwStepFlags
        ) PURE;

    STDMETHOD (CancelFrameStep)(THIS_
        ) PURE;
};

//
// a38cc06e-5926-48df-9926-571458145e80
//
DEFINE_GUID(IID_IImageSync,
0xa38cc06e, 0x5926, 0x48df, 0x99, 0x26, 0x57, 0x14, 0x58, 0x14, 0x5e, 0x80);

DECLARE_INTERFACE_(IImageSync, IUnknown)
{
    STDMETHOD (Receive)(THIS_
        VMRPRESENTATIONINFO* lpPresInfo
        ) PURE;

    STDMETHOD (GetQualityControlMessage)(THIS_
         Quality* pQualityMsg
        ) PURE;
};


///////////////////////////////////////////////////////////////////////////////
//
// Mixer interfaces
//
///////////////////////////////////////////////////////////////////////////////

//
// 56949f22-aa07-4061-bb8c-10159d8f92e5
//
DEFINE_GUID(IID_IVMRMixerControlInternal,
0x56949f22, 0xaa07, 0x4061, 0xbb, 0x8c, 0x10, 0x15, 0x9d, 0x8f, 0x92, 0xe5);

DECLARE_INTERFACE_(IVMRMixerControlInternal, IUnknown)
{
    STDMETHOD (SetImageCompositor)(THIS_
        IVMRImageCompositor* lpVMRImgCompositor
        ) PURE;

    STDMETHOD (SetBackEndAllocator)(THIS_
        IVMRSurfaceAllocator* lpAllocator,
        DWORD_PTR dwUserID
        ) PURE;

    STDMETHOD (SetBackEndImageSync)(THIS_
        IImageSync* lpImageSync
        ) PURE;
    	
    STDMETHOD (SetNumberOfStreams)(THIS_
        DWORD dwMaxStreams
        ) PURE;

    STDMETHOD (GetNumberOfStreams)(THIS_
        DWORD* pdwMaxStreams
        ) PURE;

    STDMETHOD (DisplayModeChanged)(THIS_) PURE;

    STDMETHOD (WaitForMixerIdle)(THIS_
        DWORD dwTimeOut
        ) PURE;

    STDMETHOD (SetBackgroundColor)(THIS_
        COLORREF clrBorder
        ) PURE;

    STDMETHOD (GetBackgroundColor)(THIS_
        COLORREF* lpClrBorder
        ) PURE;

    STDMETHOD (SetMixingPrefs)(THIS_
        DWORD dwMixerPrefs
        ) PURE;

    STDMETHOD (GetMixingPrefs)(THIS_
        DWORD* pdwMixerPrefs
        ) PURE;

};



typedef enum {
        VMR_SF_NONE                      = 0x00000000,
        VMR_SF_TEXTURE                   = 0x00000001,
} VMR_SF_Flags;

//
// 43062408-3d55-43cc-9415-0daf218db422
//
DEFINE_GUID(IID_IVMRMixerStream,
0x43062408, 0x3d55, 0x43cc, 0x94, 0x15, 0x0d, 0xaf, 0x21, 0x8d, 0xb4, 0x22);

DECLARE_INTERFACE_(IVMRMixerStream, IUnknown)
{
    STDMETHOD (QueueStreamMediaSample)(THIS_
            DWORD dwStreamID,
            IMediaSample* lpSample
            ) PURE;

    STDMETHOD (BeginFlush)(THIS_
            DWORD dwStreamID
            ) PURE;

    STDMETHOD (EndFlush)(THIS_
            DWORD dwStreamID
            ) PURE;

    STDMETHOD (SetStreamMediaType)(THIS_
            DWORD dwStreamID,
            AM_MEDIA_TYPE* pmt,
            DWORD dwSurfFlags,
            LPGUID lpDeinterlaceGUID,
            DXVA_DeinterlaceCaps* lpCaps
            ) PURE;

    STDMETHOD (SetStreamActiveState)(THIS_
            DWORD dwStreamID,
            BOOL fActive
            ) PURE;

    STDMETHOD (GetStreamActiveState)(THIS_
            DWORD dwStreamID,
            BOOL* lpfActive
            ) PURE;

    STDMETHOD (SetStreamColorKey)(THIS_
            DWORD dwStreamID,
            LPDDCOLORKEY lpClrKey
            ) PURE;

    STDMETHOD (GetStreamColorKey)(THIS_
            DWORD dwStreamID,
            LPDDCOLORKEY lpClrKey
            ) PURE;

    STDMETHOD (SetStreamAlpha)(THIS_
            DWORD dwStreamID,
            float Alpha
            ) PURE;

    STDMETHOD (GetStreamAlpha)(THIS_
            DWORD dwStreamID,
            float* pAlpha
            ) PURE;

    STDMETHOD (SetStreamZOrder)(THIS_
            DWORD dwStreamID,
            DWORD dwZ
            ) PURE;

    STDMETHOD (GetStreamZOrder)(THIS_
            DWORD dwStreamID,
            DWORD* pdwZ
            ) PURE;

    STDMETHOD (SetStreamOutputRect)(THIS_
            DWORD dwStreamID,
            const NORMALIZEDRECT *pRect
            ) PURE;

    STDMETHOD (GetStreamOutputRect)(THIS_
            DWORD dwStreamID,
            NORMALIZEDRECT* pRect
            ) PURE;
};


//
// ede80b5c-bad6-4623-b537-65 58 6c 9f 8d fd
//
DEFINE_GUID(IID_IVMRFilterConfigInternal,
0xede80b5c, 0xbad6, 0x4623, 0xb5, 0x37, 0x65, 0x58, 0x6c, 0x9f, 0x8d, 0xfd);

DECLARE_INTERFACE_(IVMRFilterConfigInternal, IUnknown)
{
    STDMETHOD (GetAspectRatioModePrivate)(THIS_
            LPDWORD lpdwARMode
            ) PURE;

    STDMETHOD (SetAspectRatioModePrivate)(THIS_
            DWORD dwARMode
            ) PURE;
};
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\inc\ddva.h ===
/*==========================================================================;
 *
 *  Copyright (c) 1997 - 1998  Microsoft Corporation.  All Rights Reserved.
 *
 *  File:	ddmc.h
 *  Content:	DirectDrawMotionComp include file
 *@@BEGIN_MSINTERNAL
 *  History:
 *   Date	By	Reason
 *   ====	==	======
 *   22-sep-97	smac
 *@@END_MSINTERNAL
 *
 ***************************************************************************/

#ifndef __DDVA_INCLUDED__
#define __DDVA_INCLUDED__
#if defined( _WIN32 )  && !defined( _NO_COM )
#define COM_NO_WINDOWS_H
#include <objbase.h>
#else
#define IUnknown	    void
#undef  CO_E_NOTINITIALIZED
#define CO_E_NOTINITIALIZED 0x800401F0L
#endif

#ifdef __cplusplus
extern "C" {
#endif

/*
 * GUIDS used by DirectDrawVideoAccelerator objects
 */
#if defined( _WIN32 ) && !defined( _NO_COM )
DEFINE_GUID( IID_IDDVideoAcceleratorContainer,	0xACA12120,0x3356,0x11D1,0x8F,0xCF,0x00,0xC0,0x4F,0xC2,0x9B,0x4E );
DEFINE_GUID( IID_IDirectDrawVideoAccelerator,   0xC9B2D740,0x3356,0x11D1,0x8F,0xCF,0x00,0xC0,0x4F,0xC2,0x9B,0x4E );
#endif

/*============================================================================
 *
 * DirectDraw Structures
 *
 * Various structures used to invoke DirectDraw.
 *
 *==========================================================================*/

struct IDirectDraw;
struct IDirectDrawSurface;
struct IDirectDrawPalette;
struct IDirectDrawClipper;

typedef struct IDDVideoAcceleratorContainer		FAR *LPDDVIDEOACCELERATORCONTAINER;
typedef struct IDirectDrawVideoAccelerator		FAR *LPDIRECTDRAWVIDEOACCELERATOR;

typedef struct IDDVideoAcceleratorContainerVtbl DDVIDEOACCELERATORCONTAINERCALLBACKS;
typedef struct IDirectDrawVideoAcceleratorVtbl  DIRECTDRAWVIDEOACCELERATORCALLBACKS;


typedef struct _tag_DDVAUncompDataInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    DWORD                   dwUncompWidth;              // [in]     width of uncompressed data
    DWORD                   dwUncompHeight;             // [in]     height of uncompressed data
    DDPIXELFORMAT           ddUncompPixelFormat;        // [in]     pixel-format of uncompressed data
} DDVAUncompDataInfo, *LPDDVAUncompDataInfo;

typedef struct _tag_DDVAInternalMemInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    DWORD                   dwScratchMemAlloc;          // [out]    amount of scratch memory will the hal allocate for its private use
} DDVAInternalMemInfo, *LPDDVAInternalMemInfo;


typedef struct _tag_DDVACompBufferInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    DWORD                   dwNumCompBuffers;           // [out]    number of buffers reqd for compressed data
    DWORD                   dwWidthToCreate;            // [out]    Width of surface to create
    DWORD                   dwHeightToCreate;           // [out]    Height of surface to create
    DWORD                   dwBytesToAllocate;          // [out]    Total number of bytes used by each surface
    DDSCAPS2                ddCompCaps;                 // [out]    caps to create surfaces to store compressed data
    DDPIXELFORMAT           ddPixelFormat;              // [out]    fourcc to create surfaces to store compressed data
} DDVACompBufferInfo, *LPDDVACompBufferInfo;


// Note that you are NOT allowed to store any pointer in pMiscData
typedef struct _tag_DDVABeginFrameInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    LPDIRECTDRAWSURFACE7    pddDestSurface;             // [in]     destination buffer in which to decoding this frame
    DWORD                   dwSizeInputData;            // [in]     size of other misc data to begin frame
    LPVOID                  pInputData;                 // [in]     pointer to misc data
    DWORD                   dwSizeOutputData;           // [in/out] size of other misc data to begin frame
    LPVOID                  pOutputData;                // [out]    pointer to misc data
} DDVABeginFrameInfo, *LPDDVABeginFrameInfo;

// Note that you are NOT allowed to store any pointer in pMiscData
typedef struct _tag_DDVAEndFrameInfo
{
    DWORD                   dwSize;                     // [in]     size of the struct
    DWORD                   dwSizeMiscData;             // [in]     size of other misc data to begin frame
    LPVOID                  pMiscData;                  // [in]     pointer to misc data
} DDVAEndFrameInfo, *LPDDVAEndFrameInfo;

typedef struct _tag_DDVABUFFERINFO
{
    DWORD                   dwSize;                     // [in]    size of the struct
    LPDIRECTDRAWSURFACE7    pddCompSurface;             // [in]    pointer to buffer containing compressed data
    DWORD                   dwDataOffset;               // [in]    offset of relevant data from the beginning of buffer
    DWORD                   dwDataSize;                 // [in]    size of relevant data
} DDVABUFFERINFO, *LPDDVABUFFERINFO;


/*
 * INTERACES FOLLOW:
 *	IDDVideoAcceleratorContainer
 *	IDirectDrawVideoAccelerator
 */

/*
 * IDDVideoAcceleratorContainer
 */
#if defined( _WIN32 ) && !defined( _NO_COM )
#undef INTERFACE
#define INTERFACE IDDVideoAcceleratorContainer
DECLARE_INTERFACE_( IDDVideoAcceleratorContainer, IUnknown )
{
    /*** IUnknown methods ***/
    STDMETHOD(QueryInterface) (THIS_ REFIID riid, LPVOID FAR * ppvObj) PURE;
    STDMETHOD_(ULONG,AddRef) (THIS)  PURE;
    STDMETHOD_(ULONG,Release) (THIS) PURE;
    /*** IDDVideoAcceleratorContainer methods ***/
    STDMETHOD(CreateVideoAccelerator)(THIS_ LPGUID, LPDDVAUncompDataInfo, LPVOID, DWORD, LPDIRECTDRAWVIDEOACCELERATOR FAR *, IUnknown FAR *) PURE;
    STDMETHOD(GetCompBufferInfo)(THIS_ LPGUID, LPDDVAUncompDataInfo, LPDWORD, LPDDVACompBufferInfo ) PURE;
    STDMETHOD(GetInternalMemInfo)(THIS_ LPGUID, LPDDVAUncompDataInfo, LPDDVAInternalMemInfo ) PURE;
    STDMETHOD(GetVideoAcceleratorGUIDs)(THIS_ LPDWORD, LPGUID ) PURE;
    STDMETHOD(GetUncompFormatsSupported)(THIS_ LPGUID, LPDWORD, LPDDPIXELFORMAT ) PURE;
};

#if !defined(__cplusplus) || defined(CINTERFACE)
#define IVideoAcceleratorContainer_QueryInterface(p, a, b)            (p)->lpVtbl->QueryInterface(p, a, b)
#define IVideoAcceleratorContainer_AddRef(p)                          (p)->lpVtbl->AddRef(p)
#define IVideoAcceleratorContainer_Release(p)                         (p)->lpVtbl->Release(p)
#define IVideoAcceleratorContainer_CreateVideoAccelerator(p,a,b,c,d,e,f)    (p)->lpVtbl->CreateVideoAccelerator(p, a, b, c, d, e, f)
#define IVideoAcceleratorContainer_GetCompBufferInfo(p, a, b, c, d)   (p)->lpVtbl->GetCompBufferInfo(p, a, b, c, d)
#define IVideoAcceleratorContainer_GetInternalMemInfo(p, a, b, c)     (p)->lpVtbl->GetInternalMemInfo(p, a, b, c)
#define IVideoAcceleratorContainer_GetVideoAcceleratorGUIDs(p, a, b)        (p)->lpVtbl->GetVideoAcceleratorGUIDs(p, a, b)
#define IVideoAcceleratorContainer_GetUncompFormatsSupported(p,a,b,c) (p)->GetUncompFormatsSupported(p, a, b, c)
#else
#define IVideoAcceleratorContainer_QueryInterface(p, a, b)            (p)->QueryInterface(a, b)
#define IVideoAcceleratorContainer_AddRef(p)                          (p)->AddRef()
#define IVideoAcceleratorContainer_Release(p)                         (p)->Release()
#define IVideoAcceleratorContainer_CreateVideoAccelerator(p, a, b, c,d,e,f) (p)->CreateVideoAccelerator(a, b, c, d, e, f)
#define IVideoAcceleratorContainer_GetCompBufferInfo(p, a, b, c, d)   (p)->lpVtbl->GetCompBufferInfo(a, b, c, d)
#define IVideoAcceleratorContainer_GetInternalMemInfo(p, a, b, c)     (p)->lpVtbl->GetInternalMemInfo(a, b, c)
#define IVideoAcceleratorContainer_GetVideoAcceleratorGUIDs(p, a, b)        (p)->GetVideoAcceleratorGUIDs(a, b)
#define IVideoAcceleratorContainer_GetUncompFormatsSupported(p,a,b,c) (p)->GetUncompFormatsSupported(a, b, c)
#endif

#endif


/*
 * IDirectDrawVideoAccelerator
 */
#if defined( _WIN32 ) && !defined( _NO_COM )
#undef INTERFACE
#define INTERFACE IDirectDrawVideoAccelerator
DECLARE_INTERFACE_( IDirectDrawVideoAccelerator, IUnknown )
{
    /*** IUnknown methods ***/
    STDMETHOD(QueryInterface) (THIS_ REFIID riid, LPVOID FAR * ppvObj) PURE;
    STDMETHOD_(ULONG,AddRef) (THIS)  PURE;
    STDMETHOD_(ULONG,Release) (THIS) PURE;
    /*** IDirecytDrawVideoAccelerator methods ***/
    STDMETHOD(BeginFrame)(THIS_ LPDDVABeginFrameInfo) PURE;
    STDMETHOD(EndFrame)(THIS_ LPDDVAEndFrameInfo) PURE;
    STDMETHOD(QueryRenderStatus)(THIS_ LPDIRECTDRAWSURFACE7, DWORD)PURE;
    STDMETHOD(Execute)(THIS_
                       DWORD,            // Function
                       LPVOID,           // Input data
                       DWORD,            // Input data length
                       LPVOID,           // Output data
                       DWORD,            // Output data length
                       DWORD,            // Number of buffers
                       LPDDVABUFFERINFO  // Buffer info array
                       ) PURE;
};

//  Flags for QueryRenderStatus
#define DDVA_QUERYRENDERSTATUSF_READ     0x00000001  // Query for read
                                                     // set this bit to 0
                                                     // if query for update

#if !defined(__cplusplus) || defined(CINTERFACE)
#define IVideoAccelerator_QueryInterface(p,a,b)      (p)->lpVtbl->QueryInterface(p,a,b)
#define IVideoAccelerator_AddRef(p)                  (p)->lpVtbl->AddRef(p)
#define IVideoAccelerator_Release(p)                 (p)->lpVtbl->Release(p)
#define IVideoAccelerator_BeginFrame(p,a)            (p)->lpVtbl->BeginFrame(p,a)
#define IVideoAccelerator_EndFrame(p,a)              (p)->lpVtbl->EndFrame(p,a)
#define IVideoAccelerator_QueryRenderStatus(p,a,b)   (p)->lpVtbl->QueryRenderStatus(p,a,b)
#define IVideoAccelerator_RenderMacroBlocks(p,a,b)   (p)->lpVtbl->RenderMacroBlocks(p,a,b)
#else
#define IVideoAccelerator_QueryInterface(p,a,b)      (p)->QueryInterface(a,b)
#define IVideoAccelerator_AddRef(p)                  (p)->AddRef()
#define IVideoAccelerator_Release(p)                 (p)->Release()
#define IVideoAccelerator_BeginFrame(p,a)            (p)->BeginFrame(a)
#define IVideoAccelerator_EndFrame(p,a)              (p)->EndFrame(a)
#define IVideoAccelerator_QueryRenderStatus(p,a,b)   (p)->QueryRenderStatus(a,b)
#define IVideoAccelerator_RenderMacroBlocks(p,a,b)   (p)->RenderMacroBlocks(a,b)
#endif

#endif


#ifdef __cplusplus
};
#endif

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\inc\cvmrmediasample.h ===
/******************************Module*Header*******************************\
* Module Name: CVMRMediaSample.h
*
*
*
*
* Created: Tue 03/21/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

#ifndef CVMRMediaSample_H_INC
#define CVMRMediaSample_H_INC

#include "vmrp.h"

class CVMRMixerQueue;

/* -------------------------------------------------------------------------
** Media sample class
** -------------------------------------------------------------------------
*/
class CVMRMediaSample :
    public CMediaSample,
    public IVMRSurface
{
    friend class CVMRMixerQueue;
    friend class CVMRPinAllocator;

    bool m_bSampleLocked;
    LONG m_lDeltaDecodeSize;
    LPDIRECTDRAWSURFACE7 m_pDDSFB;
    LPDIRECTDRAWSURFACE7 m_pDDS;
    CVMRMediaSample* m_lpMixerQueueNext;
    HANDLE m_hEvent;
    LPBYTE m_lpDeltaDecodeBuffer;
    DWORD m_dwIndex;

    DWORD m_dwNumInSamples;
    DXVA_VideoSample m_DDSrcSamples[MAX_DEINTERLACE_SURFACES];

public:
    CVMRMediaSample(TCHAR *pName, CBaseAllocator *pAllocator, HRESULT *phr,
                    LPBYTE pBuffer = NULL,
                    LONG length = 0,
                    HANDLE hEvent = NULL)
        :   CMediaSample(pName, pAllocator, phr, pBuffer, length),
            m_bSampleLocked(false),
            m_lpDeltaDecodeBuffer(NULL),
            m_lDeltaDecodeSize(0),
            m_pDDS(NULL),
            m_pDDSFB(NULL),
            m_hEvent(hEvent),
            m_lpMixerQueueNext(NULL),
            m_dwNumInSamples(0),
            m_dwIndex(0)
    {
        ZeroMemory(&m_DDSrcSamples, sizeof(m_DDSrcSamples));
    }

    ~CVMRMediaSample() {

        //
        // If we have been given a "Front Buffer" then m_pDDS is an
        // "attached" surface.
        //
        // Release the "attached" surface - this does not make
        // the surface go away because the front buffer still has a
        // reference on the attached surface.  Releasing the front buffer,
        // which is done in the allocator/presenter, releases this for real.
        //

        RELEASE(m_pDDS);
        RELEASE(m_pDDSFB);

        delete m_lpDeltaDecodeBuffer;
    }

    /* Note the media sample does not delegate to its owner */
    STDMETHODIMP QueryInterface(REFIID riid, void **ppv)
    {
        AMTRACE((TEXT("CVMRMediaSample::QueryInterface")));
        if (riid == IID_IVMRSurface) {
            return GetInterface( static_cast<IVMRSurface*>(this), ppv);
        }
        return CMediaSample::QueryInterface(riid, ppv);
    }

    STDMETHODIMP_(ULONG) AddRef()
    {
        AMTRACE((TEXT("CVMRMediaSample::AddRef")));
        return CMediaSample::AddRef();
    }

    STDMETHODIMP_(ULONG) Release()
    {
        AMTRACE((TEXT("CVMRMediaSample::Release")));

        ULONG cRef;

        if (IsDXVASample()) {
            cRef = InterlockedDecrement(&m_cRef);
        }
        else {
            cRef = CMediaSample::Release();
        }

        return cRef;

    }

    void SignalReleaseSurfaceEvent() {
        AMTRACE((TEXT("CVMRMediaSample::SignalReleaseSurfaceEvent")));
        if (m_hEvent != NULL) {
            SetEvent(m_hEvent);
        }
    }

    //
    // Start the delta decode optimization.  If the VGA driver does not
    // support COPY_FOURCC then we should hand out a fake DD surface
    // for the decoder to decode into.  During "Unlock" we lock the real
    // DD surface, copies the fake surface into it and unlock the real
    // surface.  In order to start the process we have to create the
    // fake surface and seed it with the current frame contents.
    //
    HRESULT StartDeltaDecodeState()
    {
        AMTRACE((TEXT("CVMRMediaSample::StartDeltaDecodeState")));
        HRESULT hr = S_OK;

        if (!m_lpDeltaDecodeBuffer) {

            ASSERT(m_lDeltaDecodeSize == 0);
            DDSURFACEDESC2 ddsdS = {sizeof(DDSURFACEDESC2)};

            bool fSrcLocked = false;
            __try {

                CHECK_HR(hr = m_pDDS->Lock(NULL, &ddsdS,
                                           DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL));
                fSrcLocked = true;
                LPBYTE pSrc = (LPBYTE)ddsdS.lpSurface;

                switch (ddsdS.ddpfPixelFormat.dwFourCC) {

                // planar 4:2:0 formats - 12 bits per pixel
                case mmioFOURCC('Y','V','1','2'):
                case mmioFOURCC('I','4','2','0'):
                case mmioFOURCC('I','Y','U','V'):
                case mmioFOURCC('N','V','2','1'):
                case mmioFOURCC('N','V','1','2'): {
                        m_lDeltaDecodeSize  = (3 * ddsdS.lPitch * ddsdS.dwHeight) / 2;
                        m_lpDeltaDecodeBuffer = new BYTE[m_lDeltaDecodeSize];
                        if (!m_lpDeltaDecodeBuffer) {
                            hr = E_OUTOFMEMORY;
                            __leave;
                        }
                        CopyMemory(m_lpDeltaDecodeBuffer, pSrc, m_lDeltaDecodeSize);
                    }
                    break;

                // RGB formats - fall thru to packed YUV case
                case 0:
                        ASSERT((ddsdS.dwFlags & DDPF_RGB) == DDPF_RGB);

                // packed 4:2:2 formats
                case mmioFOURCC('Y','U','Y','2'):
                case mmioFOURCC('U','Y','V','Y'): {
                        m_lDeltaDecodeSize = ddsdS.lPitch * ddsdS.dwHeight;
                        m_lpDeltaDecodeBuffer = new BYTE[m_lDeltaDecodeSize];
                        if (!m_lpDeltaDecodeBuffer) {
                            hr = E_OUTOFMEMORY;
                            __leave;
                        }
                        CopyMemory(m_lpDeltaDecodeBuffer, pSrc, m_lDeltaDecodeSize);
                    }
                    break;
                }
            }
            __finally {

                if (fSrcLocked) {
                    m_pDDS->Unlock(NULL);
                }

                if (FAILED(hr)) {
                    delete m_lpDeltaDecodeBuffer;
                    m_lpDeltaDecodeBuffer = NULL;
                    m_lDeltaDecodeSize = 0;
                }
            }
        }

        return hr;
    }

    void SetSurface(LPDIRECTDRAWSURFACE7 pDDS, LPDIRECTDRAWSURFACE7 pDDSFB = NULL)
    {
        AMTRACE((TEXT("CVMRMediaSample::SetSurface")));

        RELEASE(m_pDDS);
        RELEASE(m_pDDSFB);

        m_pDDS = pDDS;
        m_pDDSFB = pDDSFB;

        //
        // if we have been given a pointer to the Front Buffer then
        // we need to AddRef it here.  This is to ensure that our back buffer
        // does not get deleted when the front buffer is released by the VMR.
        //
        if (pDDSFB) {

            pDDSFB->AddRef();
        }

        //
        // if pDDSFB is null then pDDS is a front buffer - in which case
        // we need to add ref pDDS to keep the surface ref counts consistant
        //

        else {

            if (pDDS) {
                pDDS->AddRef();
            }
        }
    }

    STDMETHODIMP GetSurface(LPDIRECTDRAWSURFACE7* pDDS)
    {
        AMTRACE((TEXT("CVMRMediaSample::GetSurface")));
        if (!pDDS) {
            return E_POINTER;
        }

        if (!m_pDDS) {
            return E_FAIL;
        }

        *pDDS = m_pDDS;
        (*pDDS)->AddRef();

        return S_OK;
    }

    STDMETHODIMP LockSurface(LPBYTE* lplpSample)
    {
        AMTRACE((TEXT("CVMRMediaSample::LockSurface")));

        if (!lplpSample) {
            return E_POINTER;
        }

        if (!m_pDDS) {
            return E_FAIL;
        }

        ASSERT(S_FALSE == IsSurfaceLocked());

        if (m_lpDeltaDecodeBuffer) {
            ASSERT(m_lDeltaDecodeSize != 0);
            m_bSampleLocked = true;
            *lplpSample = m_lpDeltaDecodeBuffer;
            return S_OK;
        }

        //
        // lock the surface
        //

        DDSURFACEDESC2 ddSurfaceDesc;
        INITDDSTRUCT(ddSurfaceDesc);

        HRESULT hr = m_pDDS->Lock(NULL, &ddSurfaceDesc,
                                    DDLOCK_NOSYSLOCK | DDLOCK_WAIT,
                                    (HANDLE)NULL);
        if (SUCCEEDED(hr)) {

            m_bSampleLocked = true;
            *lplpSample = (LPBYTE)ddSurfaceDesc.lpSurface;
            DbgLog((LOG_TRACE, 3, TEXT("Locked Surf: %#X"),
                    ddSurfaceDesc.lpSurface));
        }
        else {

            m_bSampleLocked = false;

            DbgLog((LOG_ERROR, 1,
                    TEXT("m_pDDS->Lock() failed, hr = 0x%x"), hr));
        }

        return hr;
    }

    STDMETHODIMP UnlockSurface()
    {
        AMTRACE((TEXT("CVMRMediaSample::UnlockSurface")));

        if (!m_pDDS) {
            return E_FAIL;
        }

        ASSERT(S_OK == IsSurfaceLocked());

        HRESULT hr = S_OK;
        if (m_lpDeltaDecodeBuffer) {

            ASSERT(m_lDeltaDecodeSize != 0);
            bool fSrcLocked = false;
            DDSURFACEDESC2 ddsdS = {sizeof(DDSURFACEDESC2)};

            __try {

                CHECK_HR(hr = m_pDDS->Lock(NULL, &ddsdS,
                                           DDLOCK_NOSYSLOCK | DDLOCK_WAIT, NULL));
                fSrcLocked = true;
                LPBYTE pDst = (LPBYTE)ddsdS.lpSurface;
                CopyMemory(pDst, m_lpDeltaDecodeBuffer, m_lDeltaDecodeSize);
            }
            __finally {
                if (fSrcLocked) {
                    m_pDDS->Unlock(NULL);
                }
            }

            m_bSampleLocked = false;
            return hr;
        }

        hr = m_pDDS->Unlock(NULL);

        //
        // The surface may not actually be locked even though our flag
        // says it is.  This is because surfaces automatically become "un-locked"
        // when they are lost.  The surface can be lost (and resored) at any moment.
        // If the surface is really unlocked our flag must be updated to reflect the
        // true state of the surface.
        //
        if (hr == DDERR_NOTLOCKED) {
            hr = DD_OK;
        }

        if (SUCCEEDED(hr)) {
            m_bSampleLocked = false;
        }
        else {
            DbgLog((LOG_ERROR, 1,
                    TEXT("m_pDDS->Unlock() failed, hr = 0x%x"), hr));
        }
        return hr;
    }

    STDMETHODIMP IsSurfaceLocked()
    {
        AMTRACE((TEXT("CVMRMediaSample::IsSurfaceLocked")));
        ASSERT(m_pDDS);
        return m_bSampleLocked ? S_OK : S_FALSE;
    }

    BOOL IsDXVASample()
    {
        AMTRACE((TEXT("CVMRMediaSample::IsSurfaceLocked")));
        return  (m_pAllocator == (CBaseAllocator *)-1);
    }

    /*  Hack to get at the list */
    CMediaSample* &Next() { return m_pNext; }

    BOOL HasTypeChanged()
    {
        if (m_dwFlags & 0x80000000) {
            return FALSE;
        }

        if (m_dwFlags & AM_SAMPLE_TYPECHANGED) {
            m_dwFlags |= 0x80000000;
            return TRUE;
        }

        return FALSE;
    }

    HRESULT SetProps(
        const AM_SAMPLE2_PROPERTIES& Props,
        LPDIRECTDRAWSURFACE7 pDDS
        )
    {
        SetSurface(pDDS);

        m_dwStreamId = Props.dwStreamId;
        m_dwFlags = Props.dwSampleFlags;
        m_dwTypeSpecificFlags = Props.dwTypeSpecificFlags;
        m_lActual = Props.lActual;
        m_End   = Props.tStop;
        m_Start = Props.tStart;

        if (m_dwFlags & AM_SAMPLE_TYPECHANGED) {

            m_pMediaType = CreateMediaType(Props.pMediaType);
            if (m_pMediaType == NULL) {
                return E_OUTOFMEMORY;
            }
        }
        else {
            m_pMediaType =  NULL;
        }

        return S_OK;
    }

    void SetIndex(DWORD dwIndx)
    {
        m_dwIndex = dwIndx;
    }

    DWORD GetIndex()
    {
        return m_dwIndex;
    }


    DWORD GetTypeSpecificFlags()
    {
        return m_dwTypeSpecificFlags;
    }

    DWORD GetNumInputSamples()
    {
        return m_dwNumInSamples;
    }

    void SetNumInputSamples(DWORD dwNumInSamples)
    {
        m_dwNumInSamples = dwNumInSamples;
    }

    DXVA_VideoSample* GetInputSamples()
    {
        return &m_DDSrcSamples[0];
    }
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\inc\mediastype.h ===
/******************************Module*Header*******************************\
* Module Name: MediaSType.h
*
*  Definition of VMR unique media sub-types.
*
*
* Created: Wed 03/08/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

// 5860b2bd-619f-4306-a472-9a2f256253b8
DEFINE_GUID(MEDIASUBTYPE_SameAsMonitor,
0x5860b2bd, 0x619f, 0x4306, 0xa4, 0x72, 0x9a, 0x2f, 0x25, 0x62, 0x53, 0xb8);
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\inc\alloclib.h ===
/******************************Module*Header*******************************\
* Module Name: AllocLib.h
*
*
*
*
* Created: Fri 03/10/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/


#ifndef __INC_ALLOCLIB_H__
#define __INC_ALLOCLIB_H__

#include "dxva.h"

#ifndef __ZEROSTRUCT_DEFINED
#define __ZEROSTRUCT_DEFINED
template <typename T>
__inline void ZeroStruct(T& t)
{
    ZeroMemory(&t, sizeof(t));
}
#endif

#ifndef __INITDDSTRUCT_DEFINED
#define __INITDDSTRUCT_DEFINED
template <typename T>
__inline void INITDDSTRUCT(T& dd)
{
    ZeroStruct(dd);
    dd.dwSize = sizeof(dd);
}
#endif

#if 0
template< typename T >
__inline CopyStruct(T& pDest, const T& pSrc)
{
    CopyMemory( &pDest, &pSrc, sizeof(pSrc));
}
#endif

const DWORD*
GetBitMasks(
    const BITMAPINFOHEADER *pHeader
    );

LPBITMAPINFOHEADER
GetbmiHeader(
    const AM_MEDIA_TYPE *pMediaType
    );

void
FixupMediaType(
    AM_MEDIA_TYPE* pmt
    );

LPRECT
GetTargetRectFromMediaType(
    const AM_MEDIA_TYPE *pMediaType
    );

struct TargetScale
{
    float fX;
    float fY;
};

void
GetTargetScaleFromMediaType(
    const AM_MEDIA_TYPE *pMediaType,
    TargetScale* pScale
    );

LPRECT
GetSourceRectFromMediaType(
    const AM_MEDIA_TYPE *pMediaType
    );

HRESULT
ConvertSurfaceDescToMediaType(
    const LPDDSURFACEDESC2 pSurfaceDesc,
    const AM_MEDIA_TYPE* pTemplateMediaType,
    AM_MEDIA_TYPE** ppMediaType
    );


HRESULT
PaintDDrawSurfaceBlack(
    LPDIRECTDRAWSURFACE7 pDDrawSurface
    );

HRESULT
GetImageAspectRatio(
    const AM_MEDIA_TYPE* pMediaType,
    long* lpARWidth,
    long* lpARHeight
    );


bool
EqualSizeRect(
    const RECT* lpRc1,
    const RECT* lpRc2
    );


bool
ContainedRect(
    const RECT* lpRc1,
    const RECT* lpRc2
    );

void
LetterBoxDstRect(
    LPRECT lprcLBDst,
    const RECT& rcSrc,
    const RECT& rcDst,
    LPRECT lprcBdrTL,
    LPRECT lprcBdrBR
    );


void
AspectRatioCorrectSize(
    LPSIZE lpSizeImage,
    const SIZE& sizeAr
    );

enum {
    TXTR_POWER2     = 0x01,
    TXTR_AGPYUVMEM  = 0x02,
    TXTR_AGPRGBMEM  = 0x04,
    TXTR_SRCKEY     = 0x08
};

HRESULT
GetTextureCaps(
    LPDIRECTDRAW7 pDD,
    DWORD* ptc
    );

DWORD
DDColorMatch(
    IDirectDrawSurface7 *pdds,
    COLORREF rgb,
    HRESULT& hr
    );

HRESULT
VMRCopyFourCC(
    LPDIRECTDRAWSURFACE7 lpDst,
    LPDIRECTDRAWSURFACE7 lpSrc
    );


HRESULT
GetInterlaceFlagsFromMediaType(
    const AM_MEDIA_TYPE *pMediaType,
    DWORD *pdwInterlaceFlags
    );

BOOL
NeedToFlipOddEven(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags,
    DWORD *pdwFlipFlag,
    BOOL bUsingOverlays
    );

HRESULT
GetVideoDescFromMT(
    LPDXVA_VideoDesc lpVideoDesc,
    const AM_MEDIA_TYPE *pMT
    );

BOOL
IsSingleFieldPerSample(
    DWORD dwFlags
    );

REFERENCE_TIME
GetAvgTimePerFrame(
    const AM_MEDIA_TYPE *pMT
    );

DWORD
MapPool(
    DWORD Pool
    );

DXVA_SampleFormat
MapInterlaceFlags(
    DWORD dwInterlaceFlags,
    DWORD dwTypeSpecificFlags
    );

#ifdef DEBUG
void __inline DumpDDSAddress(const TCHAR *szText, LPDIRECTDRAWSURFACE7 lpDDS)
{
    DDSURFACEDESC2 ddSurfaceDesc;
    INITDDSTRUCT(ddSurfaceDesc);

    HRESULT hr;

    hr = lpDDS->Lock(NULL, &ddSurfaceDesc, DDLOCK_NOSYSLOCK | DDLOCK_WAIT, (HANDLE)NULL);
    if (hr != DD_OK) {
        DbgLog((LOG_TRACE, 0, TEXT("Lock failed hr = %#X"), hr));
    }

    hr = lpDDS->Unlock(NULL);
    if (hr != DD_OK) {
        DbgLog((LOG_TRACE, 0, TEXT("Unlock failed hr = %#X"), hr));
    }

    DbgLog((LOG_TRACE, 0, TEXT("%s%p"), szText, ddSurfaceDesc.lpSurface));
}
#else
#define DumpDDSAddress( _x_, _y_ )
#endif


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\inc\vmruuids.h ===
#ifndef __VMRuuids_h__
#define __VMRuuids_h__

#ifndef OUR_GUID_ENTRY
    #define OUR_GUID_ENTRY(name, l, w1, w2, b1, b2, b3, b4, b5, b6, b7, b8) \
    DEFINE_GUID(name, l, w1, w2, b1, b2, b3, b4, b5, b6, b7, b8);
#endif


// {99d54f63-1a69-41ae-aa4d-c976eb3f0713}
OUR_GUID_ENTRY(CLSID_AllocPresenter,
0x99d54f63, 0x1a69, 0x41ae, 0xaa, 0x4d, 0xc9, 0x76, 0xeb, 0x3f, 0x07, 0x13)

// {7D8AA343-6E63-4663-BE90-6B80F66540A3}
OUR_GUID_ENTRY(CLSID_ImageSynchronization,
0x7D8AA343, 0x6E63, 0x4663, 0xBE, 0x90, 0x6B, 0x80, 0xF6, 0x65, 0x40, 0xA3)

// {06b32aee-77da-484b-973b-5d64f47201b0}
OUR_GUID_ENTRY(CLSID_VideoMixer,
0x06b32aee, 0x77da, 0x484b, 0x97, 0x3b, 0x5d, 0x64, 0xf4, 0x72, 0x01, 0xb0)

#undef OUR_GUID_ENTRY
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\core\imagesyncren.cpp ===
/******************************Module*Header*******************************\
* Module Name: ImageSyncRen.cpp
*
* Implements the IImageSync interface of the core Image Synchronization
* Object - based on DShow base classes CBaseRenderer and CBaseVideoRenderer.
*
*
* Created: Wed 01/12/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>


#include "ImageSyncObj.h"
#include "resource.h"
#include "dxmperf.h"


/////////////////////////////////////////////////////////////////////////////
// CImageSync
//
/////////////////////////////////////////////////////////////////////////////

// --------------------------------------------------------------------------
// Some helper inline functions
// --------------------------------------------------------------------------
__inline bool IsDiscontinuity(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_Discontinuity);
}

__inline bool IsTimeValid(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_TimeValid);
}

__inline bool IsSyncPoint(DWORD dwSampleFlags)
{
    return 0 != (dwSampleFlags & VMRSample_SyncPoint);
}


/*****************************Private*Routine******************************\
* TimeDiff
*
* Helper function for clamping time differences
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
__inline int TimeDiff(REFERENCE_TIME rt)
{
    AMTRACE((TEXT("TimeDiff")));
    if (rt < - (50 * UNITS))
    {
        return -(50 * UNITS);
    }
    else if (rt > 50 * UNITS)
    {
        return 50 * UNITS;
    }
    else
    {
        return (int)rt;
    }
}


/*****************************Private*Routine******************************\
* DoRenderSample
*
* Here is where the actual presentation occurs.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::DoRenderSample(
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    AMTRACE((TEXT("CImageSync::DoRenderSample")));
    if (m_ImagePresenter) {
        return m_ImagePresenter->PresentImage(m_dwUserID, lpPresInfo);
    }
    return S_FALSE;
}

/*****************************Private*Routine******************************\
* RecordFrameLateness
*
* update the statistics:
* m_iTotAcc, m_iSumSqAcc, m_iSumSqFrameTime, m_iSumFrameTime, m_cFramesDrawn
* Note that because the properties page reports using these variables,
* 1. We need to be inside a critical section
* 2. They must all be updated together.  Updating the sums here and the count
* elsewhere can result in imaginary jitter (i.e. attempts to find square roots
* of negative numbers) in the property page code.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::RecordFrameLateness(
    int trLate,
    int trFrame
    )
{
    AMTRACE((TEXT("CImageSync::RecordFrameLateness")));
    //
    // Record how timely we are.
    //

    int tLate = trLate/10000;

    //
    // Best estimate of moment of appearing on the screen is average of
    // start and end draw times.  Here we have only the end time.  This may
    // tend to show us as spuriously late by up to 1/2 frame rate achieved.
    // Decoder probably monitors draw time.  We don't bother.
    //

//  MSR_INTEGER( m_idFrameAccuracy, tLate );

    //
    // This is a hack - we can get frames that are ridiculously late
    // especially (at start-up) and they sod up the statistics.
    // So ignore things that are more than 1 sec off.
    //

    if (tLate>1000 || tLate<-1000) {

        if (m_cFramesDrawn<=1) {
            tLate = 0;
        } else if (tLate>0) {
            tLate = 1000;
        } else {
            tLate = -1000;
        }
    }

    //
    // The very first frame often has a bogus time, so I'm just
    // not going to count it into the statistics.   ???
    //

    if (m_cFramesDrawn>1) {
        m_iTotAcc += tLate;
        m_iSumSqAcc += (tLate*tLate);
    }

    //
    // calculate inter-frame time.  Doesn't make sense for first frame
    // second frame suffers from bogus first frame stamp.
    //

    if (m_cFramesDrawn>2) {
        int tFrame = trFrame/10000;    // convert to mSec else it overflows

        //
        // This is a hack.  It can overflow anyway (a pause can cause
        // a very long inter-frame time) and it overflows at 2**31/10**7
        // or about 215 seconds i.e. 3min 35sec
        //

        if (tFrame>1000||tFrame<0)
            tFrame = 1000;

        m_iSumSqFrameTime += tFrame*tFrame;
        ASSERT(m_iSumSqFrameTime>=0);
        m_iSumFrameTime += tFrame;
    }

    ++m_cFramesDrawn;

}


/*****************************Private*Routine******************************\
* ThrottleWait
*
*
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::ThrottleWait()
{
    AMTRACE((TEXT("CImageSync::ThrottleWait")));
    if (m_trThrottle > 0) {
        int iThrottle = m_trThrottle/10000;    // convert to mSec
//      MSR_INTEGER( m_idThrottle, iThrottle);
//      DbgLog((LOG_TRACE, 0, TEXT("Throttle %d ms"), iThrottle));
        Sleep(iThrottle);
    } else {
        Sleep(0);
    }
}


/*****************************Private*Routine******************************\
* OnRenderStart
*
* Called just before we start drawing.  All we do is to get the current clock
* time (from the system) and return.  We have to store the start render time
* in a member variable because it isn't used until we complete the drawing
* The rest is just performance logging.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::OnRenderStart(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::OnRenderStart")));

    if (PerflogTracingEnabled()) {
        REFERENCE_TIME rtClock = 0;
        if (NULL != m_pClock) {
            m_pClock->GetTime(&rtClock);
            rtClock -= m_tStart;
        }
        PERFLOG_VIDEOREND(pSample->rtStart, rtClock, lpSurf);
    }

    RecordFrameLateness(m_trLate, m_trFrame);
    m_tRenderStart = timeGetTime();
}


/*****************************Private*Routine******************************\
* OnRenderEnd
*
* Called directly after drawing an image.  We calculate the time spent in the
* drawing code and if this doesn't appear to have any odd looking spikes in
* it then we add it to the current average draw time.  Measurement spikes may
* occur if the drawing thread is interrupted and switched to somewhere else.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::OnRenderEnd(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::OnRenderEnd")));

    //
    // The renderer time can vary erratically if we are interrupted so we do
    // some smoothing to help get more sensible figures out but even that is
    // not enough as figures can go 9,10,9,9,83,9 and we must disregard 83
    //

    // convert mSec->UNITS
    int tr = (timeGetTime() - m_tRenderStart)*10000;

    if (tr < m_trRenderAvg*2 || tr < 2 * m_trRenderLast) {
        // DO_MOVING_AVG(m_trRenderAvg, tr);
        m_trRenderAvg = (tr + (AVGPERIOD-1)*m_trRenderAvg)/AVGPERIOD;
    }

    m_trRenderLast = tr;
    ThrottleWait();
}

/*****************************Private*Routine******************************\
* Render
*
* This is called when a sample comes due for rendering. We pass the sample
* on to the derived class. After rendering we will initialise the timer for
* the next sample, NOTE signal that the last one fired first, if we don't
* do this it thinks there is still one outstanding that hasn't completed
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::Render(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::Render")));

    //
    // If the media sample is NULL then we will have been notified by the
    // clock that another sample is ready but in the mean time someone has
    // stopped us streaming which causes the next sample to be released
    //

    if (pSample == NULL) {
        return S_FALSE;
    }


    //
    // If we havn't been given anything to renderer with we are hosed too.
    //

    if (m_ImagePresenter == NULL) {
        return S_FALSE;
    }


    //
    // Time how long the rendering takes
    //

    OnRenderStart(pSample);
    HRESULT hr = DoRenderSample(pSample);
    OnRenderEnd(pSample);

    return hr;
}



/*****************************Private*Routine******************************\
* SendQuality
*
* Send a message to indicate what our supplier should do about quality.
* Theory:
* What a supplier wants to know is "is the frame I'm working on NOW
* going to be late?".
* F1 is the frame at the supplier (as above)
* Tf1 is the due time for F1
* T1 is the time at that point (NOW!)
* Tr1 is the time that f1 WILL actually be rendered
* L1 is the latency of the graph for frame F1 = Tr1-T1
* D1 (for delay) is how late F1 will be beyond its due time i.e.
* D1 = (Tr1-Tf1) which is what the supplier really wants to know.
* Unfortunately Tr1 is in the future and is unknown, so is L1
*
* We could estimate L1 by its value for a previous frame,
* L0 = Tr0-T0 and work off
* D1' = ((T1+L0)-Tf1) = (T1 + (Tr0-T0) -Tf1)
* Rearranging terms:
* D1' = (T1-T0) + (Tr0-Tf1)
*       adding (Tf0-Tf0) and rearranging again:
*     = (T1-T0) + (Tr0-Tf0) + (Tf0-Tf1)
*     = (T1-T0) - (Tf1-Tf0) + (Tr0-Tf0)
* But (Tr0-Tf0) is just D0 - how late frame zero was, and this is the
* Late field in the quality message that we send.
* The other two terms just state what correction should be applied before
* using the lateness of F0 to predict the lateness of F1.
* (T1-T0) says how much time has actually passed (we have lost this much)
* (Tf1-Tf0) says how much time should have passed if we were keeping pace
* (we have gained this much).
*
* Suppliers should therefore work off:
*    Quality.Late + (T1-T0)  - (Tf1-Tf0)
* and see if this is "acceptably late" or even early (i.e. negative).
* They get T1 and T0 by polling the clock, they get Tf1 and Tf0 from
* the time stamps in the frames.  They get Quality.Late from us.
*
*
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::SendQuality(
    REFERENCE_TIME trLate,
    REFERENCE_TIME trRealStream
    )
{
    AMTRACE((TEXT("CImageSync::SendQuality")));
    Quality q;
    HRESULT hr;

    //
    // If we are the main user of time, then report this as Flood/Dry.
    // If our suppliers are, then report it as Famine/Glut.
    //
    // We need to take action, but avoid hunting.  Hunting is caused by
    // 1. Taking too much action too soon and overshooting
    // 2. Taking too long to react (so averaging can CAUSE hunting).
    //
    // The reason why we use trLate as well as Wait is to reduce hunting;
    // if the wait time is coming down and about to go into the red, we do
    // NOT want to rely on some average which is only telling is that it used
    // to be OK once.
    //

    q.TimeStamp = (REFERENCE_TIME)trRealStream;

    if (m_trFrameAvg < 0) {
        q.Type = Famine;      // guess
    }

    //
    // Is the greater part of the time taken bltting or something else
    //

    else if (m_trFrameAvg > 2*m_trRenderAvg) {
        q.Type = Famine;                        // mainly other
    } else {
        q.Type = Flood;                         // mainly bltting
    }

    q.Proportion = 1000;               // default

    if (m_trFrameAvg < 0) {

        //
        // leave it alone - we don't know enough
        //
    }
    else if ( trLate> 0 ) {

        //
        // try to catch up over the next second
        // We could be Really, REALLY late, but rendering all the frames
        // anyway, just because it's so cheap.
        //

        q.Proportion = 1000 - (int)((trLate)/(UNITS/1000));
        if (q.Proportion<500) {
           q.Proportion = 500;      // don't go daft. (could've been negative!)
        } else {
        }

    }
    else if (m_trWaitAvg > 20000 && trLate < -20000 )
    {
        //
        // Go cautiously faster - aim at 2mSec wait.
        //

        if (m_trWaitAvg>=m_trFrameAvg) {

            //
            // This can happen because of some fudges.
            // The waitAvg is how long we originally planned to wait
            // The frameAvg is more honest.
            // It means that we are spending a LOT of time waiting
            //

            q.Proportion = 2000;    // double.
        } else {
            if (m_trFrameAvg+20000 > m_trWaitAvg) {
                q.Proportion
                    = 1000 * (m_trFrameAvg / (m_trFrameAvg + 20000 - m_trWaitAvg));
            } else {

                //
                // We're apparently spending more than the whole frame time waiting.
                // Assume that the averages are slightly out of kilter, but that we
                // are indeed doing a lot of waiting.  (This leg probably never
                // happens, but the code avoids any potential divide by zero).
                //

                q.Proportion = 2000;
            }
        }

        if (q.Proportion>2000) {
            q.Proportion = 2000;    // don't go crazy.
        }
    }

    //
    // Tell the supplier how late frames are when they get rendered
    // That's how late we are now.
    // If we are in directdraw mode then the guy upstream can see the drawing
    // times and we'll just report on the start time.  He can figure out any
    // offset to apply.  If we are in DIB Section mode then we will apply an
    // extra offset which is half of our drawing time.  This is usually small
    // but can sometimes be the dominant effect.  For this we will use the
    // average drawing time rather than the last frame.  If the last frame took
    // a long time to draw and made us late, that's already in the lateness
    // figure.  We should not add it in again unless we expect the next frame
    // to be the same.  We don't, we expect the average to be a better shot.
    // In direct draw mode the RenderAvg will be zero.
    //

    q.Late = trLate + m_trRenderAvg / 2;

    // log what we're doing
//  MSR_INTEGER(m_idQualityRate, q.Proportion);
//  MSR_INTEGER( m_idQualityTime, (int)q.Late / 10000 );

    //
    // We can't call the supplier directly - they have to call us when
    // Receive returns.  So save this message and return S_FALSE or S_OK
    // depending upon whether the previous quality message was retrieved or
    // not.
    //

    BOOL bLastMessageRead = m_bLastQualityMessageRead;
    m_bLastQualityMessageRead = false;
    m_bQualityMsgValid = true;
    m_QualityMsg = q;

    return bLastMessageRead ? S_OK : S_FALSE;

}

/*****************************Private*Routine******************************\
* PreparePerformanceData
*
* Put data on one side that describes the lateness of the current frame.
* We don't yet know whether it will actually be drawn.  In direct draw mode,
* this decision is up to the filter upstream, and it could change its mind.
* The rules say that if it did draw it must call Receive().  One way or
* another we eventually get into either OnRenderStart or OnDirectRender and
* these both call RecordFrameLateness to update the statistics.
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::PreparePerformanceData(
    int trLate,
    int trFrame
    )
{
    AMTRACE((TEXT("CImageSync::PreparePerformanceData")));
    m_trLate = trLate;
    m_trFrame = trFrame;
}


/******************************Public*Routine******************************\
* ShouldDrawSampleNow
*
* We are called to decide whether the current sample is to be
* be drawn or not.  There must be a reference clock in operation.
*
* Return S_OK if it is to be drawn Now (as soon as possible)
*
* Return S_FALSE if it is to be drawn when it's due
*
* Return an error if we want to drop it
* m_nNormal=-1 indicates that we dropped the previous frame and so this
* one should be drawn early.  Respect it and update it.
* Use current stream time plus a number of heuristics (detailed below)
* to make the decision
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
HRESULT
CImageSync::ShouldDrawSampleNow(
    VMRPRESENTATIONINFO* pSample,
    REFERENCE_TIME *ptrStart,
    REFERENCE_TIME *ptrEnd
    )
{
    AMTRACE((TEXT("CImageSync::ShouldDrawSampleNow")));
    //
    // Don't call us unless there's a clock interface to synchronise with
    //

    ASSERT(m_pClock);

//  MSR_INTEGER(m_idTimeStamp, (int)((*ptrStart)>>32));   // high order 32 bits
//  MSR_INTEGER(m_idTimeStamp, (int)(*ptrStart));         // low order 32 bits

    //
    // We lose a bit of time depending on the monitor type waiting for the next
    // screen refresh.  On average this might be about 8mSec - so it will be
    // later than we think when the picture appears.  To compensate a bit
    // we bias the media samples by -8mSec i.e. 80000 UNITs.
    // We don't ever make a stream time negative (call it paranoia)
    //

    if (*ptrStart>=80000) {
        *ptrStart -= 80000;
        *ptrEnd -= 80000;       // bias stop to to retain valid frame duration
    }

    //
    // Cache the time stamp now.  We will want to compare what we did with what
    // we started with (after making the monitor allowance).
    //

    m_trRememberStampForPerf = *ptrStart;

    //
    // Get reference times (current and late)
    // the real time now expressed as stream time.
    //

    REFERENCE_TIME trRealStream;
    m_pClock->GetTime(&trRealStream);

#ifdef PERF
    //
    // While the reference clock is expensive:
    // Remember the offset from timeGetTime and use that.
    // This overflows all over the place, but when we subtract to get
    // differences the overflows all cancel out.
    //

    m_llTimeOffset = trRealStream-timeGetTime()*10000;
#endif
    trRealStream -= m_tStart;     // convert to stream time (this is a reftime)

    //
    // We have to wory about two versions of "lateness".  The truth, which we
    // try to work out here and the one measured against m_trTarget which
    // includes long term feedback.  We report statistics against the truth
    // but for operational decisions we work to the target.
    // We use TimeDiff to make sure we get an integer because we
    // may actually be late (or more likely early if there is a big time
    // gap) by a very long time.
    //

    const int trTrueLate = TimeDiff(trRealStream - *ptrStart);
    const int trLate = trTrueLate;

//  MSR_INTEGER(m_idSchLateTime, trTrueLate/10000);

    //
    // Send quality control messages upstream, measured against target
    //

    HRESULT hr = SendQuality(trLate, trRealStream);

    //
    // Note: the filter upstream is allowed to this FAIL meaning "you do it".
    //

    m_bSupplierHandlingQuality = (hr==S_OK);

    //
    // Decision time!  Do we drop, draw when ready or draw immediately?
    //

    const int trDuration = (int)(*ptrEnd - *ptrStart);
    {
        //
        // We need to see if the frame rate of the file has just changed.
        // This would make comparing our previous frame rate with the current
        // frame rate difficult.  Hang on a moment though.  I've seen files
        // where the frames vary between 33 and 34 mSec so as to average
        // 30fps.  A minor variation like that won't hurt us.
        //

        int t = m_trDuration/32;
        if (trDuration > m_trDuration+t || trDuration < m_trDuration-t )
        {
            //
            // There's a major variation.  Reset the average frame rate to
            // exactly the current rate to disable decision 9002 for this frame,
            // and remember the new rate.
            //

            m_trFrameAvg = trDuration;
            m_trDuration = trDuration;
        }
    }

//  MSR_INTEGER(m_idEarliness, m_trEarliness/10000);
//  MSR_INTEGER(m_idRenderAvg, m_trRenderAvg/10000);
//  MSR_INTEGER(m_idFrameAvg, m_trFrameAvg/10000);
//  MSR_INTEGER(m_idWaitAvg, m_trWaitAvg/10000);
//  MSR_INTEGER(m_idDuration, trDuration/10000);

#ifdef PERF
    if (S_OK==IsDiscontinuity(dwSampleFlags)) {
        MSR_INTEGER(m_idDecision, 9000);
    }
#endif

    //
    // Control the graceful slide back from slow to fast machine mode.
    // After a frame drop accept an early frame and set the earliness to here
    // If this frame is already later than the earliness then slide it to here
    // otherwise do the standard slide (reduce by about 12% per frame).
    // Note: earliness is normally NEGATIVE
    //

    BOOL bJustDroppedFrame
        = (  m_bSupplierHandlingQuality
          //  Can't use the pin sample properties because we might
          //  not be in Receive when we call this
          && (S_OK == IsDiscontinuity(pSample->dwFlags))// he just dropped one
          )
       || (m_nNormal==-1);                              // we just dropped one

    //
    // Set m_trEarliness (slide back from slow to fast machine mode)
    //

    if (trLate>0) {
        m_trEarliness = 0;   // we are no longer in fast machine mode at all!
    } else if (  (trLate>=m_trEarliness) || bJustDroppedFrame) {
        m_trEarliness = trLate;  // Things have slipped of their own accord
    } else {
        m_trEarliness = m_trEarliness - m_trEarliness/8;  // graceful slide
    }

    //
    // prepare the new wait average - but don't pollute the old one until
    // we have finished with it.
    //

    int trWaitAvg;
    {
        //
        // We never mix in a negative wait.  This causes us to believe
        // in fast machines slightly more.
        //

        int trL = trLate<0 ? -trLate : 0;
        trWaitAvg = (trL + m_trWaitAvg*(AVGPERIOD-1))/AVGPERIOD;
    }


    int trFrame;
    {
        REFERENCE_TIME tr = trRealStream - m_trLastDraw; // Cd be large - 4 min pause!
        if (tr>10000000) {
            tr = 10000000;   // 1 second - arbitrarily.
        }
        trFrame = int(tr);
    }

    //
    // We will DRAW this frame IF...
    //

    if (
          // ...the time we are spending drawing is a small fraction of the total
          // observed inter-frame time so that dropping it won't help much.
          (3*m_trRenderAvg <= m_trFrameAvg)

         // ...or our supplier is NOT handling things and the next frame would
         // be less timely than this one or our supplier CLAIMS to be handling
         // things, and is now less than a full FOUR frames late.
       || ( m_bSupplierHandlingQuality
          ? (trLate <= trDuration*4)
          : (trLate+trLate < trDuration)
          )

          // ...or we are on average waiting for over eight milliseconds then
          // this may be just a glitch.  Draw it and we'll hope to catch up.
       || (m_trWaitAvg > 80000)

          // ...or we haven't drawn an image for over a second.  We will update
          // the display, which stops the video looking hung.
          // Do this regardless of how late this media sample is.
       || ((trRealStream - m_trLastDraw) > UNITS)

    ) {
        HRESULT Result;

        //
        // We are going to play this frame.  We may want to play it early.
        // We will play it early if we think we are in slow machine mode.
        // If we think we are NOT in slow machine mode, we will still play
        // it early by m_trEarliness as this controls the graceful slide back.
        // and in addition we aim at being m_trTarget late rather than "on time".
        //

        BOOL bPlayASAP = FALSE;

        //
        // we will play it AT ONCE (slow machine mode) if...
        //

        // ...we are playing catch-up
        if ( bJustDroppedFrame) {
            bPlayASAP = TRUE;
//          MSR_INTEGER(m_idDecision, 9001);
        }

        //
        // ...or if we are running below the true frame rate
        // exact comparisons are glitchy, for these measurements,
        // so add an extra 5% or so
        //

        else if (  (m_trFrameAvg > trDuration + trDuration/16)

           // It's possible to get into a state where we are losing ground, but
           // are a very long way ahead.  To avoid this or recover from it
           // we refuse to play early by more than 10 frames.

                && (trLate > - trDuration*10)
                ){
            bPlayASAP = TRUE;
//          MSR_INTEGER(m_idDecision, 9002);
        }

        //
        // We will NOT play it at once if we are grossly early.  On very slow frame
        // rate movies - e.g. clock.avi - it is not a good idea to leap ahead just
        // because we got starved (for instance by the net) and dropped one frame
        // some time or other.  If we are more than 900mSec early, then wait.
        //

        if (trLate<-9000000) {
            bPlayASAP = FALSE;
        }

        if (bPlayASAP) {

            m_nNormal = 0;
//          MSR_INTEGER(m_idDecision, 0);

            //
            // When we are here, we are in slow-machine mode.  trLate may well
            // oscillate between negative and positive when the supplier is
            // dropping frames to keep sync.  We should not let that mislead
            // us into thinking that we have as much as zero spare time!
            // We just update with a zero wait.
            //

            m_trWaitAvg = (m_trWaitAvg*(AVGPERIOD-1))/AVGPERIOD;

            //
            // Assume that we draw it immediately.  Update inter-frame stats
            //

            m_trFrameAvg = (trFrame + m_trFrameAvg*(AVGPERIOD-1))/AVGPERIOD;
#ifndef PERF
            //
            // if this is NOT a perf build, then report what we know so far
            // without looking at the clock any more.  This assumes that we
            // actually wait for exactly the time we hope to.  it also reports
            // how close we get to the hacked up time stamps that we now have
            // rather than the ones we originally started with.  It will
            // therefore be a little optimistic.  However it's fast.
            //

            PreparePerformanceData(trTrueLate, trFrame);
#endif
            m_trLastDraw = trRealStream;
            if (m_trEarliness > trLate) {
                m_trEarliness = trLate; // if we are actually early, this is neg
            }
            Result = S_OK;              // Draw it now

        } else {
            ++m_nNormal;

            //
            // Set the average frame rate to EXACTLY the ideal rate.
            // If we are exiting slow-machine mode then we will have caught up
            // and be running ahead, so as we slide back to exact timing we will
            // have a longer than usual gap at this point.  If we record this
            // real gap then we'll think that we're running slow and go back
            // into slow-machine mode and vever get it straight.
            //

            m_trFrameAvg = trDuration;
//          MSR_INTEGER(m_idDecision, 1);

            //
            // Play it early by m_trEarliness and by m_trTarget
            //

            {
                int trE = m_trEarliness;
                if (trE < -m_trFrameAvg) {
                    trE = -m_trFrameAvg;
                }
                *ptrStart += trE;           // N.B. earliness is negative
            }

            int Delay = -trTrueLate;
            Result = Delay<=0 ? S_OK : S_FALSE;  // OK = draw now, FALSE = wait

            m_trWaitAvg = trWaitAvg;

            //
            // Predict when it will actually be drawn and update frame stats
            //

            if (Result==S_FALSE) {   // We are going to wait
                trFrame = TimeDiff(*ptrStart-m_trLastDraw);
                m_trLastDraw = *ptrStart;
            } else {
                // trFrame is already = trRealStream-m_trLastDraw;
                m_trLastDraw = trRealStream;
            }
#ifndef PERF
            int iAccuracy;
            if (Delay>0) {
                // Report lateness based on when we intend to play it
                iAccuracy = TimeDiff(*ptrStart-m_trRememberStampForPerf);
            } else {
                // Report lateness based on playing it *now*.
                iAccuracy = trTrueLate;     // trRealStream-RememberStampForPerf;
            }
            PreparePerformanceData(iAccuracy, trFrame);
#endif
        }
        return Result;
    }

    //
    // We are going to drop this frame!
    // Of course in DirectDraw mode the guy upstream may draw it anyway.
    //

    //
    // This will probably give a large negative wack to the wait avg.
    //

    m_trWaitAvg = trWaitAvg;

#ifdef PERF
    // Respect registry setting - debug only!
    if (m_bDrawLateFrames) {
       return S_OK;                        // draw it when it's ready
    }                                      // even though it's late.
#endif

    //
    // We are going to drop this frame so draw the next one early
    // n.b. if the supplier is doing direct draw then he may draw it anyway
    // but he's doing something funny to arrive here in that case.
    //

//  MSR_INTEGER(m_idDecision, 2);
    m_nNormal = -1;
    return E_FAIL;                         // drop it
}


/*****************************Private*Routine******************************\
* CheckSampleTime
*
* Check the sample times for this samples (note the sample times are
* passed in by reference not value). We return S_FALSE to say schedule this
* sample according to the times on the sample. We also return S_OK in
* which case the object should simply render the sample data immediately
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::CheckSampleTimes(
    VMRPRESENTATIONINFO* pSample,
    REFERENCE_TIME *pStartTime,
    REFERENCE_TIME *pEndTime
    )
{
    AMTRACE((TEXT("CImageSync::CheckSampleTimes")));
    ASSERT(m_dwAdvise == 0);

    //
    // If the stop time for this sample is before or the same as start time,
    // then just ignore it
    //

    if (IsTimeValid(pSample->dwFlags)) {
        if (*pEndTime < *pStartTime) {
            return VFW_E_START_TIME_AFTER_END;
        }
    } else {
        // no time set in the sample... draw it now?
        return S_OK;
    }

    // Can't synchronise without a clock so we return S_OK which tells the
    // caller that the sample should be rendered immediately without going
    // through the overhead of setting a timer advise link with the clock

    if (m_pClock == NULL) {
        return S_OK;
    }

    return ShouldDrawSampleNow(pSample, pStartTime, pEndTime);
}


/*****************************Private*Routine******************************\
* ScheduleSample
*
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::ScheduleSample(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::ScheduleSample")));
    HRESULT hr = ScheduleSampleWorker(pSample);

    if (FAILED(hr)) {
#if defined( EHOME_WMI_INSTRUMENTATION )
        PERFLOG_STREAMTRACE( 1, PERFINFO_STREAMTRACE_VMR_DROPPED_FRAME,
            0, pSample->rtStart, pSample->rtEnd, 0, 0 );
#endif
        ++m_cFramesDropped;
    }

    //
    // m_cFramesDrawn must NOT be updated here.  It has to be updated
    // in RecordFrameLateness at the same time as the other statistics.
    //

    return hr;
}


/*****************************Private*Routine******************************\
* ScheduleSampleWorker
*
* Responsible for setting up one shot advise links with the clock
*
* Returns a filure code (probably VFW_E_SAMPLE_REJECTED) if the sample was
* dropped (not drawn at all).
*
* Returns S_OK if the sample is scheduled to be drawn and in this case also
* arrange for m_RenderEvent to be set at the appropriate time
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
HRESULT
CImageSync::ScheduleSampleWorker(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::ScheduleSampleWorker")));

    //
    // If the samples times arn't valid or if there is no
    // reference clock
    //
    REFERENCE_TIME startTime = pSample->rtStart;
    REFERENCE_TIME endTime   = pSample->rtEnd;

    HRESULT hr = CheckSampleTimes(pSample, &startTime, &endTime);
    if (FAILED(hr)) {
        if (hr != VFW_E_START_TIME_AFTER_END) {
            hr = VFW_E_SAMPLE_REJECTED;
        }
        return hr;
    }

    //
    // If we don't have a reference clock then we cannot set up the advise
    // time so we simply set the event indicating an image to render. This
    // will cause us to run flat out without any timing or synchronisation
    //

    if (hr == S_OK) {
        EXECUTE_ASSERT(SetEvent((HANDLE)m_RenderEvent));
        return S_OK;
    }

    ASSERT(m_dwAdvise == 0);
    ASSERT(m_pClock);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent, 0));

    //
    // We do have a valid reference clock interface so we can ask it to
    // set an event when the image comes due for rendering. We pass in
    // the reference time we were told to start at and also the current
    // stream time which is the offset from the start reference time
    //

#if defined( EHOME_WMI_INSTRUMENTATION )
    PERFLOG_STREAMTRACE(
        1,
        PERFINFO_STREAMTRACE_VMR_BEGIN_ADVISE,
        startTime, m_tStart, 0, 0, 0 );
#endif

    hr = m_pClock->AdviseTime(
            (REFERENCE_TIME)m_tStart,           // Start run time
            startTime,                          // Stream time
            (HEVENT)(HANDLE)m_RenderEvent,      // Render notification
            &m_dwAdvise);                       // Advise cookie

    if (SUCCEEDED(hr)) {
        return S_OK;
    }

    //
    // We could not schedule the next sample for rendering despite the fact
    // we have a valid sample here. This is a fair indication that either
    // the system clock is wrong or the time stamp for the sample is duff
    //

    ASSERT(m_dwAdvise == 0);
    return VFW_E_SAMPLE_REJECTED;
}


/*****************************Private*Routine******************************\
* OnWaitStart()
*
* Called when we start waiting for a rendering event.
* Used to update times spent waiting and not waiting.
*
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
void CImageSync::OnWaitStart()
{
    AMTRACE((TEXT("CImageSync::OnWaitStart")));
#ifdef PERF
    MSR_START(m_idWaitReal);
#endif //PERF
}


/*****************************Private*Routine******************************\
* OnWaitEnd
*
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
void
CImageSync::OnWaitEnd()
{
    AMTRACE((TEXT("CImageSync::OnWaitEnd")));
#ifdef PERF

    MSR_STOP(m_idWaitReal);

    //
    // for a perf build we want to know just exactly how late we REALLY are.
    // even if this means that we have to look at the clock again.
    //

    REFERENCE_TIME trRealStream;  // the real time now expressed as stream time.

    //
    // We will be discarding overflows like mad here!
    // This is wrong really because timeGetTime() can wrap but it's
    // only for PERF
    //

    REFERENCE_TIME tr = timeGetTime()*10000;
    trRealStream = tr + m_llTimeOffset;
    trRealStream -= m_tStart;     // convert to stream time (this is a reftime)

    if (m_trRememberStampForPerf==0) {

        //
        // This is probably the poster frame at the start, and it is not scheduled
        // in the usual way at all.  Just count it.  The rememberstamp gets set
        // in ShouldDrawSampleNow, so this does bogus frame recording until we
        // actually start playing.
        //

        PreparePerformanceData(0, 0);
    }
    else {

        int trLate = (int)(trRealStream - m_trRememberStampForPerf);
        int trFrame = (int)(tr - m_trRememberFrameForPerf);
        PreparePerformanceData(trLate, trFrame);
    }
    m_trRememberFrameForPerf = tr;

#endif //PERF
}


/*****************************Private*Routine******************************\
* WaitForRenderTime
*
* Wait until the clock sets the timer event or we're otherwise signalled. We
* set an arbitrary timeout for this wait and if it fires then we display the
* current renderer state on the debugger. It will often fire if the filter's
* left paused in an application however it may also fire during stress tests
* if the synchronisation with application seeks and state changes is faulty
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
HRESULT
CImageSync::WaitForRenderTime()
{
    AMTRACE((TEXT("CImageSync::WaitForRenderTime")));
    HANDLE WaitObjects[] = { m_ThreadSignal, m_RenderEvent };
    DWORD Result = WAIT_TIMEOUT;

    //
    // Wait for either the time to arrive or for us to be stopped
    //

    OnWaitStart();
    while (Result == WAIT_TIMEOUT) {

        Result = WaitForMultipleObjects(2, WaitObjects, FALSE, RENDER_TIMEOUT);

        //#ifdef DEBUG
        //    if (Result == WAIT_TIMEOUT) DisplayRendererState();
        //#endif

    }
    OnWaitEnd();

    //
    // We may have been awoken without the timer firing
    //

    if (Result == WAIT_OBJECT_0) {
        return VFW_E_STATE_CHANGED;
    }

    SignalTimerFired();
    return S_OK;
}


/*****************************Private*Routine******************************\
* SignalTimerFired
*
* We must always reset the current advise time to zero after a timer fires
* because there are several possible ways which lead us not to do any more
* scheduling such as the pending image being cleared after state changes
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
void
CImageSync::SignalTimerFired()
{
    AMTRACE((TEXT("CImageSync::SignalTimerFired")));
    m_dwAdvise = 0;

#if defined( EHOME_WMI_INSTRUMENTATION )
    PERFLOG_STREAMTRACE(
        1,
        PERFINFO_STREAMTRACE_VMR_END_ADVISE,
        0, 0, 0, 0, 0 );
#endif

}


/*****************************Private*Routine******************************\
* SaveSample
*
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::SaveSample(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::SaveSample")));
    CAutoLock cRendererLock(&m_RendererLock);
    if (m_pSample) {
        return E_FAIL;
    }

    m_pSample = pSample;

    return S_OK;
}


/*****************************Private*Routine******************************\
* GetSavedSample
*
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::GetSavedSample(
    VMRPRESENTATIONINFO** ppSample
    )
{
    AMTRACE((TEXT("CImageSync::GetSavedSample")));
    CAutoLock cRendererLock(&m_RendererLock);
    if (!m_pSample) {

        DbgLog((LOG_TRACE, 1,
                TEXT("CImageSync::GetSavedSample  Sample not available") ));
        return E_FAIL;
    }

    *ppSample = m_pSample;

    return S_OK;
}

/*****************************Private*Routine******************************\
* HaveSavedSample
*
* Checks if there is a sample waiting at the renderer
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
BOOL CImageSync::HaveSavedSample()
{
    AMTRACE((TEXT("CImageSync::HaveSavedSample")));
    CAutoLock cRendererLock(&m_RendererLock);
    DbgLog((LOG_TRACE, 1,
            TEXT("CImageSync::HaveSavedSample = %d"), m_pSample != NULL));
    return m_pSample != NULL;
}

/*****************************Private*Routine******************************\
* ClearSavedSample
*
*
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
void
CImageSync::ClearSavedSample()
{
    AMTRACE((TEXT("CImageSync::ClearSavedSample")));
    CAutoLock cRendererLock(&m_RendererLock);
    m_pSample = NULL;
}


/*****************************Private*Routine******************************\
* CancelNotification
*
* Cancel any notification currently scheduled. This is called by the owning
* window object when it is told to stop streaming. If there is no timer link
* outstanding then calling this is benign otherwise we go ahead and cancel
* We must always reset the render event as the quality management code can
* signal immediate rendering by setting the event without setting an advise
* link. If we're subsequently stopped and run the first attempt to setup an
* advise link with the reference clock will find the event still signalled
*
* History:
* Tue 01/11/2000 - StEstrop - Modified from CBaseRenderer
*
\**************************************************************************/
HRESULT
CImageSync::CancelNotification()
{
    AMTRACE((TEXT("CImageSync::CancelNotification")));
    ASSERT(m_dwAdvise == 0 || m_pClock);
    DWORD_PTR dwAdvise = m_dwAdvise;

    //
    // Have we a live advise link
    //

    if (m_dwAdvise) {
        m_pClock->Unadvise(m_dwAdvise);
        SignalTimerFired();
        ASSERT(m_dwAdvise == 0);
    }

    //
    // Clear the event and return our status
    //

    m_RenderEvent.Reset();

    return (dwAdvise ? S_OK : S_FALSE);
}

/*****************************Private*Routine******************************\
* OnReceiveFirstSample
*
*
*
* History:
* Wed 01/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::OnReceiveFirstSample(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::OnReceiveFirstSample")));
    return DoRenderSample(pSample);
}


/*****************************Private*Routine******************************\
* PrepareReceive
*
* Called when the source delivers us a sample. We go through a few checks to
* make sure the sample can be rendered. If we are running (streaming) then we
* have the sample scheduled with the reference clock, if we are not streaming
* then we have received an sample in paused mode so we can complete any state
* transition. On leaving this function everything will be unlocked so an app
* thread may get in and change our state to stopped (for example) in which
* case it will also signal the thread event so that our wait call is stopped
*
* History:
* Thu 01/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::PrepareReceive(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::PrepareReceive")));
    CAutoLock cILock(&m_InterfaceLock);
    m_bInReceive = TRUE;

    // Check our flushing state

    if (m_bFlushing) {
        m_bInReceive = FALSE;
        return E_FAIL;
    }

    CAutoLock cRLock(&m_RendererLock);

    //
    // Return an error if we already have a sample waiting for rendering
    // source pins must serialise the Receive calls - we also check that
    // no data is being sent after the source signalled an end of stream
    //

    if (HaveSavedSample() || m_bEOS || m_bAbort) {
        Ready();
        m_bInReceive = FALSE;
        return E_UNEXPECTED;
    }

    //
    // Schedule the next sample if we are streaming
    //

    if (IsStreaming()) {

        if (FAILED(ScheduleSample(pSample))) {

            ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
            ASSERT(CancelNotification() == S_FALSE);
            m_bInReceive = FALSE;
            return VFW_E_SAMPLE_REJECTED;
        }

        EXECUTE_ASSERT(S_OK == SaveSample(pSample));
    }

    //
    // else we are not streaming yet, just save the sample and wait in Receive
    // until BeginImageSequence is called.  BeginImageSequence passes a base
    // start time with which we schedule the saved sample.
    //

    else {

        // ASSERT(IsFirstSample(dwSampleFlags));
        EXECUTE_ASSERT(S_OK == SaveSample(pSample));
    }

    // Store the sample end time for EC_COMPLETE handling
    m_SignalTime = pSample->rtEnd;

    return S_OK;
}


/*****************************Private*Routine******************************\
* FrameStepWorker
*
*
*
* History:
* Tue 08/29/2000 - StEstrop - Created
*
\**************************************************************************/
void CImageSync::FrameStepWorker()
{
    AMTRACE((TEXT("CImageSync::FrameStepWorker")));
    CAutoLock cLock(&m_InterfaceLock);

    if (m_lFramesToStep == 1) {
        m_lFramesToStep--;
        m_InterfaceLock.Unlock();
        m_lpEventNotify->NotifyEvent(EC_STEP_COMPLETE, FALSE, 0);
        DWORD dw = WaitForSingleObject(m_StepEvent, INFINITE);
        m_InterfaceLock.Lock();
        ASSERT(m_lFramesToStep != 0);
    }
}


/******************************Public*Routine******************************\
* Receive
*
* Return the buffer to the renderer along with time stamps relating to
* when the buffer should be presented.
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::Receive(
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    AMTRACE((TEXT("CImageSync::Receive")));

    //
    // Frame step hack-o-matic
    //
    // This code acts as a gate - for a frame step of N frames
    // it discards N-1 frames and then lets the Nth frame thru the
    // the gate to be rendered in the normal way i.e. at the correct
    // time.  The next time Receive is called the gate is shut and
    // the thread blocks.  The gate only opens again when the step
    // is cancelled or another frame step request comes in.
    //
    // StEstrop - Thu 10/21/1999
    //

    {
        CAutoLock cLock(&m_InterfaceLock);

        //
        // do we have frames to discard ?
        //

        if (m_lFramesToStep > 1) {
            m_lFramesToStep--;
            if (m_lFramesToStep > 0) {
                return NOERROR;
            }
        }
    }

    return ReceiveWorker(lpPresInfo);
}

/******************************Public*Routine******************************\
* ReceiveWorker
*
* Return the buffer to the renderer along with time stamps relating to
* when the buffer should be presented.
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CImageSync::ReceiveWorker(
    VMRPRESENTATIONINFO* pSample
    )
{
    AMTRACE((TEXT("CImageSync::ReceiveWorker")));

    ASSERT(pSample);

    //
    // Prepare for this Receive call, this may return the VFW_E_SAMPLE_REJECTED
    // error code to say don't bother - depending on the quality management.
    //

    HRESULT hr = PrepareReceive(pSample);
    ASSERT(m_bInReceive == SUCCEEDED(hr));
    if (FAILED(hr)) {
        if (hr == VFW_E_SAMPLE_REJECTED) {
            return S_OK;
        }
        return hr;
    }


    //
    // We special case "first samples"
    //
    BOOL bSampleRendered = FALSE;
    if (m_State == ImageSync_State_Cued) {

        //
        // no need to use InterlockedExchange
        //

        m_bInReceive = FALSE;
        {
            //
            // We must hold both these locks
            //

            CAutoLock cILock(&m_InterfaceLock);

            if (m_State == ImageSync_State_Stopped)
                return S_OK;

            m_bInReceive = TRUE;
            CAutoLock cRLock(&m_RendererLock);
            hr = OnReceiveFirstSample(pSample);
            bSampleRendered = TRUE;
        }
        Ready();
    }

    //
    // Having set an advise link with the clock we sit and wait. We may be
    // awoken by the clock firing or by the CancelRender event.
    //

    if (FAILED(WaitForRenderTime())) {
        m_bInReceive = FALSE;
        return hr;
    }
    DbgLog((LOG_TIMING, 3,
       TEXT("CImageSync::ReceiveWorker WaitForRenderTime completed for this video sample") ));

    m_bInReceive = FALSE;

    //
    // Deal with this sample - We must hold both these locks
    //
    {
        CAutoLock cILock(&m_InterfaceLock);
        if (m_State == ImageSync_State_Stopped)
            return S_OK;

        CAutoLock cRLock(&m_RendererLock);
        if (!bSampleRendered) {
            hr = Render(m_pSample);
        }
    }

    FrameStepWorker();

    {
        CAutoLock cILock(&m_InterfaceLock);
        CAutoLock cRLock(&m_RendererLock);
        //
        // Clean up
        //

        ClearSavedSample();
        SendEndOfStream();
        CancelNotification();
    }

    return hr;
}


/******************************Public*Routine******************************\
* GetQualityControlMessage
*
* ask for quality control information from the renderer
*
* History:
* Tue 01/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CImageSync::GetQualityControlMessage(
    Quality* pQualityMsg
    )
{
    AMTRACE((TEXT("CImageSync::GetQualityControlMessage")));
    CAutoLock cILock(&m_InterfaceLock);
    CAutoLock cRLock(&m_RendererLock);

    if (!pQualityMsg) {
        return E_POINTER;
    }

    if (m_bQualityMsgValid) {
        *pQualityMsg = m_QualityMsg;
        m_bLastQualityMessageRead = TRUE;
        return S_OK;
    }
    else
        return S_FALSE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\mixer\mixerdeinterlace.h ===
/******************************Module*Header*******************************\
* Module Name: mixerDeinterlace.h
*
*
*
*
* Created: Tue 03/12/2002
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2002 Microsoft Corporation
\**************************************************************************/

#include "ddva.h"

class CDeinterlaceDevice {

public:

    CDeinterlaceDevice(LPDIRECTDRAW7 pDD,
                       LPGUID pGuid,
                       DXVA_VideoDesc* lpVideoDescription,
                       HRESULT* phr);
    ~CDeinterlaceDevice();

    HRESULT Blt(REFERENCE_TIME rtTargetFrame,
                LPRECT lprcDstRect,
                LPDIRECTDRAWSURFACE7 lpDDSDstSurface,
                LPRECT lprcSrcRect,
                LPDXVA_VideoSample lpDDSrcSurfaces,
                DWORD dwNumSurfaces,
                FLOAT fAlpha);
private:
    IDirectDrawVideoAccelerator*    m_pIDDVideoAccelerator;
    GUID                            m_Guid;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\mixer\mixerdeinterlace.cpp ===
/******************************Module*Header*******************************\
* Module Name: mixerDeinterlace.cpp
*
*
*
*
* Created: Tue 03/12/2002
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2002 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "vmrp.h"
#include "mixerDeinterlace.h"


/******************************Public*Routine******************************\
* CDeinterlaceDevice
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
CDeinterlaceDevice::CDeinterlaceDevice(
    LPDIRECTDRAW7 pDD,
    LPGUID pGuid,
    DXVA_VideoDesc* lpVideoDescription,
    HRESULT* phr
    ) :
    m_pIDDVideoAccelerator(NULL),
    m_Guid(*pGuid)
{
    DDVAUncompDataInfo UncompInfo = {sizeof(DDVAUncompDataInfo), 0, 0, 0};
    IDDVideoAcceleratorContainer* pIDDVAContainer = NULL;

    HRESULT hr = pDD->QueryInterface(IID_IDDVideoAcceleratorContainer,
                                     (void**)&pIDDVAContainer);
    if (hr == DD_OK) {
        hr = pIDDVAContainer->CreateVideoAccelerator(
                                 pGuid, &UncompInfo,
                                 lpVideoDescription,
                                 sizeof(DXVA_VideoDesc),
                                 &m_pIDDVideoAccelerator,
                                 NULL);
        pIDDVAContainer->Release();
    }

    if (hr != DD_OK) {
        *phr = hr;
    }
}



/******************************Public*Routine******************************\
* ~CDeinterlaceDevice
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
CDeinterlaceDevice::~CDeinterlaceDevice()
{
    RELEASE(m_pIDDVideoAccelerator);
}



/******************************Public*Routine******************************\
* Blt
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CDeinterlaceDevice::Blt(
    REFERENCE_TIME rtTargetFrame,
    LPRECT lprcDstRect,
    LPDIRECTDRAWSURFACE7 lpDDSDstSurface,
    LPRECT lprcSrcRect,
    LPDXVA_VideoSample lpDDSrcSurfaces,
    DWORD NumSourceSurfaces,
    FLOAT Alpha
    )
{
    // lpInput => DXVA_DeinterlaceBlt*
    // lpOuput => NULL /* not currently used */

    DXVA_DeinterlaceBlt blt;
    blt.Size = sizeof(DXVA_DeinterlaceBlt);
    blt.rtTarget = rtTargetFrame;
    blt.DstRect = *lprcDstRect;
    blt.SrcRect = *lprcSrcRect;
    blt.NumSourceSurfaces = NumSourceSurfaces;
    blt.Alpha = Alpha;

    DDVABUFFERINFO* pBuffInfo = new DDVABUFFERINFO[NumSourceSurfaces+1];
    if (pBuffInfo == NULL) {
        return E_OUTOFMEMORY;
    }

    pBuffInfo[0].dwDataOffset   = 0;
    pBuffInfo[0].dwDataSize     = 0;
    pBuffInfo[0].pddCompSurface = lpDDSDstSurface;

    for (DWORD i = 0; i < NumSourceSurfaces; i++) {
        pBuffInfo[i + 1].dwDataOffset   = 0;
        pBuffInfo[i + 1].dwDataSize     = 0;
        pBuffInfo[i + 1].pddCompSurface =
                (LPDIRECTDRAWSURFACE7)lpDDSrcSurfaces[i].lpDDSSrcSurface;
        blt.Source[i] = lpDDSrcSurfaces[i];
    }


    HRESULT hr = m_pIDDVideoAccelerator->Execute(
                    DXVA_DeinterlaceBltFnCode,
                    &blt, sizeof(DXVA_DeinterlaceBlt),
                    NULL, 0,
                    NumSourceSurfaces+1, pBuffInfo);

#ifdef DEBUG
    if (hr != S_OK) {
        DbgLog((LOG_ERROR, 1, TEXT("DeinterlaceBlt failed hr=%#X"), hr));
    }
#endif

    delete [] pBuffInfo;

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\inc\vmrwindow.h ===
// Copyright (c) 1994 - 1998  Microsoft Corporation.  All Rights Reserved.
// Defines a window management object, Anthony Phillips, January 1995

#ifndef __VMRWINDOW__
#define __VMRWINDOW__

#define OCR_ARROW_DEFAULT 100       // Default Windows OEM arrow cursor

// This class looks after the management of a video window. When the window
// object is first created the constructor spawns off a worker thread that
// does all the window work. The original thread waits until it is signaled
// to continue. The worker thread firstly registers the window class if it
// is not already done. Then it creates a window and sets it's size to match
// the video dimensions (the dimensions are returned through GetDefaultRect)

// Notice that the worker thread MUST be the thread that creates the window
// as it is the one who calls GetMessage. When it has done all this it will
// signal the original thread which lets it continue, this ensures a window
// is created and valid before the constructor returns. The thread's start
// address is the WindowMessageLoop function. The thread's parameter we pass
// it is the CBaseWindow this pointer for the window object that created it

#define WindowClassName TEXT("VideoRenderer")
#define VMR_ACTIVATE_WINDOW TEXT("WM_VMR_ACTIVATE_WINDOW")

// The window class name isn't used only as a class name for the base window
// classes, it is also used by the overlay selection code as a name to base
// a mutex creation on. Basicly it has a shared memory block where the next
// available overlay colour is returned from. The creation and preparation
// of the shared memory must be serialised through all ActiveMovie instances

class CVMRFilter;

class CVMRVideoWindow : public CVMRBaseControlWindow, public CVMRBaseControlVideo
{
    CVMRFilter *m_pRenderer;                // The owning renderer object
    BOOL m_bTargetSet;                      // Do we use the default rectangle
    CCritSec *m_pInterfaceLock;             // Main renderer interface lock
    HCURSOR m_hCursor;                      // Used to display a normal cursor
    VIDEOINFOHEADER *m_pFormat;             // holds our video format
    int m_FormatSize;                       // length of m_pFormat
    UINT m_VMRActivateWindow;               // Makes the window WS_EX_TOPMOST

    // Handle the drawing and repainting of the window
    BOOL RefreshImage(COLORREF WindowColour);

    // Overriden method to handle window messages
    LRESULT OnReceiveMessage(HWND hwnd,      // Window handle
                             UINT uMsg,      // Message ID
                             WPARAM wParam,  // First parameter
                             LPARAM lParam); // Other parameter

    // Window message handlers

    void OnEraseBackground();
    BOOL OnClose();
    BOOL OnPaint();
    BOOL OnSetCursor(LPARAM lParam);
    BOOL OnSize(LONG Width, LONG Height);

public:

    CVMRVideoWindow(CVMRFilter *pRenderer,     // The owning renderer
                 CCritSec *pLock,           // Object to use for lock
                 LPUNKNOWN pUnk,            // Owning object
                 HRESULT *phr);             // OLE return code

    ~CVMRVideoWindow();

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    // Return the minimum and maximum ideal sizes
    STDMETHODIMP GetMinIdealImageSize(long *pWidth,long *pHeight);
    STDMETHODIMP GetMaxIdealImageSize(long *pWidth,long *pHeight);

    //  IBasicVideo2
    STDMETHODIMP GetPreferredAspectRatio(long *plAspectX, long *plAspectY);

    LPTSTR GetClassWindowStyles(DWORD *pClassStyles,        // Class styles
                                DWORD *pWindowStyles,       // Window styles
                                DWORD *pWindowStylesEx);    // Extended styles

    HRESULT PrepareWindow();
    HRESULT ActivateWindowAsync(BOOL fAvtivate);

    // These are called by the renderer control interfaces
    HRESULT SetDefaultTargetRect();
    HRESULT IsDefaultTargetRect();
    HRESULT SetTargetRect(RECT *pTargetRect);
    HRESULT GetTargetRect(RECT *pTargetRect);
    HRESULT SetDefaultSourceRect();
    HRESULT IsDefaultSourceRect();
    HRESULT SetSourceRect(RECT *pSourceRect);
    HRESULT GetSourceRect(RECT *pSourceRect);
    HRESULT OnUpdateRectangles();
    HRESULT GetStaticImage(long *pVideoSize,long *pVideoImage);
    VIDEOINFOHEADER *GetVideoFormat();
    RECT GetDefaultRect();
    void EraseVideoBackground();

#ifdef DEBUG
#define FRAME_RATE_TIMER 76872
    void StartFrameRateTimer();
#endif

    // Synchronise with decoder thread
    CCritSec *LockWindowUpdate() {
        return (&m_WindowLock);
    };
};

#endif // __WINDOW__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\mixer\mixerobj.cpp ===
/******************************Module*Header*******************************\
* Module Name: MixerObj.cpp
*
*  Implements the CVideoMixer class
*
*
* Created:
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "vmrp.h"

#include "mixerobj.h"

// IVMRMixerControl

/******************************Public*Routine******************************\
* SetNumberOfStreams
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetNumberOfStreams(
    DWORD dwMaxStreams
    )
{
    AMTRACE((TEXT("CVideoMixer::SetNumberOfStreams")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    DWORD i;

    if ( 0 != m_dwNumStreams ) {
        DbgLog((LOG_ERROR, 1, TEXT("Mixer already configured !!")));
        return E_FAIL;
    }

    __try {

        if (dwMaxStreams > MAX_MIXER_STREAMS) {
            DbgLog((LOG_ERROR, 1, TEXT("Too many Mixer Streams !!")));
            hr = E_INVALIDARG;
            __leave;
        }

        //
        // Allocate an array of stream objects dwMaxStream big and
        // initialize each stream.
        //

        m_ppMixerStreams = new CVideoMixerStream*[dwMaxStreams];
        if (!m_ppMixerStreams) {
            hr = E_OUTOFMEMORY;
            __leave;
        }

        ZeroMemory(m_ppMixerStreams,
                   sizeof(CVideoMixerStream*) * dwMaxStreams);
        for (i = 0; i < dwMaxStreams; i++) {

            HRESULT hrMix = S_OK;
            m_ppMixerStreams[i] = new CVideoMixerStream(i, &hrMix);

            if (!m_ppMixerStreams[i]) {
                hr = E_OUTOFMEMORY;
                __leave;
            }

            if (FAILED(hrMix)) {
                hr = hrMix;
                __leave;
            }
        }

        m_dwNumStreams = dwMaxStreams;

        m_hMixerIdle = CreateEvent(NULL, TRUE, FALSE, NULL);
        if (!m_hMixerIdle) {
            DWORD dwErr = GetLastError();
            hr = HRESULT_FROM_WIN32(dwErr);
            __leave;
        }

        m_hThread = CreateThread(NULL, 0, MixerThreadProc, this, 0, &m_dwThreadID);
        if (!m_hThread) {
            DWORD dwErr = GetLastError();
            hr = HRESULT_FROM_WIN32(dwErr);
            __leave;
        }

    }
    __finally {
        if (FAILED(hr)) {
            for ( i = 0; i < 100; i++ )
            {
                if ( 0 == PostThreadMessage(m_dwThreadID, WM_USER, 0, 0) )
                    Sleep(0);
                else
                    break;
            }
            if (m_ppMixerStreams) {
                for (i = 0; i < dwMaxStreams; i++) {
                    delete m_ppMixerStreams[i];
                }
            }
            delete[] m_ppMixerStreams;
            m_ppMixerStreams = NULL;
            m_dwNumStreams = 0;
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* SetBackEndAllocator
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetBackEndAllocator(
    IVMRSurfaceAllocator* lpAllocator,
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CVideoMixer::SetBackEndAllocator")));
    CAutoLock Lock(&m_ObjectLock);

    RELEASE( m_pBackEndAllocator );

    if (lpAllocator) {
        lpAllocator->AddRef();
    }

    m_pBackEndAllocator = lpAllocator;
    m_dwUserID = dwUserID;


    return S_OK;
}

/******************************Public*Routine******************************\
* SetBackEndImageSync
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetBackEndImageSync(
    IImageSync* lpImageSync
    )
{
    AMTRACE((TEXT("CVideoMixer::SetBackEndImageSync")));
    CAutoLock Lock(&m_ObjectLock);

    RELEASE( m_pImageSync);

    if (lpImageSync) {
        lpImageSync->AddRef();
    }

    m_pImageSync = lpImageSync;


    return S_OK;
}

/******************************Public*Routine******************************\
* SetImageCompositor
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetImageCompositor(
    IVMRImageCompositor* lpImageComp
    )
{
    AMTRACE((TEXT("CVideoMixer::SetImageCompositor")));
    CAutoLock Lock(&m_ObjectLock);

    //
    // Can't plug in new compositors when in IMC3 mode.
    //
    if (SpecialIMC3Mode(m_MixingPrefs)) {
        DbgLog((LOG_ERROR, 1, TEXT("Can't plug in compositors in this mode")));
        return E_FAIL;
    }


    //
    // must always specify a valid compositor
    //
    if (lpImageComp == NULL) {
        return E_POINTER;
    }

    RELEASE(m_pImageCompositor);

    if (lpImageComp) {
        lpImageComp->AddRef();
    }

    m_pImageCompositor = lpImageComp;


    return S_OK;
}

/******************************Public*Routine******************************\
* GetNumberOfStreams
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetNumberOfStreams(
    DWORD* lpdwMaxStreams
    )
{
    AMTRACE((TEXT("CVideoMixer::GetNumberOfStreams")));
    CAutoLock Lock(&m_ObjectLock);

    if (!lpdwMaxStreams) {
        return E_POINTER;
    }

    *lpdwMaxStreams = m_dwNumStreams;
    return S_OK;
}

/******************************Public*Routine******************************\
* DisplayModeChanged
*
*
*
* History:
* Tue 04/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::DisplayModeChanged()
{
    AMTRACE((TEXT("CVideoMixer::DisplayModeChanged")));
    CAutoLock Lock(&m_ObjectLock);

    FreeSurface();

    for (DWORD i = 0; i < m_dwNumStreams; i++) {

        m_ppMixerStreams[i]->BeginFlush();
        m_ppMixerStreams[i]->GetNextStreamSample();
        m_ppMixerStreams[i]->EndFlush();
    }


    return S_OK;
}

/******************************Public*Routine******************************\
* WaitForMixerIdle
*
*
*
* History:
* Tue 09/19/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::WaitForMixerIdle(DWORD dwTimeOut)
{
    AMTRACE((TEXT("CVideoMixer::WaitForMixerIdle")));

    DWORD rc = WaitForSingleObject(m_hMixerIdle, dwTimeOut);

    if (rc == WAIT_OBJECT_0) {
        return S_OK;
    }

    if (rc == WAIT_TIMEOUT) {
        return S_FALSE;
    }

    DWORD dwErr = GetLastError();
    return HRESULT_FROM_WIN32(dwErr);
}



// IVMRMixerStream

/******************************Public*Routine******************************\
* SetStreamSample
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::QueueStreamMediaSample(
    DWORD dwStreamID,
    IMediaSample* lpSample
    )
{
    AMTRACE((TEXT("CVideoMixer::QueueStreamMediaSample")));
    CAutoLock Lock(&m_ObjectLock);
    DbgLog((LOG_TRACE, 2, TEXT("lpSample= %#X"), lpSample));

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->SetStreamSample(lpSample);
    }
    return hr;
}


/*****************************Private*Routine******************************\
* AspectRatioAdjustMediaType
*
*
*
* History:
* Mon 03/27/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
AspectRatioAdjustMediaType(
    CMediaType* pmt
    )
{
    AMTRACE((TEXT("AspectRatioAdjustMediaType")));
    HRESULT hr = S_OK;
    long lX, lY;

    FixupMediaType(pmt);
    hr = GetImageAspectRatio(pmt, &lX, &lY);

    if (SUCCEEDED(hr)) {

        lX *= 1000;
        lY *= 1000;

        LPRECT lprc = GetTargetRectFromMediaType(pmt);
        LPBITMAPINFOHEADER lpHeader = GetbmiHeader(pmt);

        if (lprc && lpHeader) {

            long Width;
            long Height;
            if (IsRectEmpty(lprc)) {
                Width  = abs(lpHeader->biWidth);
                Height = abs(lpHeader->biHeight);
            }
            else {
                Width  = WIDTH(lprc);
                Height = HEIGHT(lprc);
            }

            long lCalcX = MulDiv(Width, lY, Height);

            lpHeader->biHeight = Height;
            lpHeader->biWidth = Width;

            if (lCalcX != lX) {

                lpHeader->biWidth = MulDiv(Height, lX, lY);

            }

            lprc->left = 0;
            lprc->top = 0;
            lprc->right = abs(lpHeader->biWidth);
            lprc->bottom = abs(lpHeader->biHeight);
        }
        else {
            hr = E_INVALIDARG;
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* DecimateMediaType
*
*
*
* History:
* Thu 03/01/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
DecimateMediaType(
    CMediaType* pmt
    )
{
    LPRECT lprcD = GetTargetRectFromMediaType(pmt);
    LPRECT lprcS = GetSourceRectFromMediaType(pmt);
    LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pmt);

    if (lprcD && lprcS && lpHdr) {

        lprcD->left     /= 2;
        lprcD->top      /= 2;
        lprcD->right    /= 2;
        lprcD->bottom   /= 2;

        lprcS->left     /= 2;
        lprcS->top      /= 2;
        lprcS->right    /= 2;
        lprcS->bottom   /= 2;

        lpHdr->biWidth  /= 2;
        lpHdr->biHeight /= 2;
    }

    return S_OK;
}


/*****************************Private*Routine******************************\
* AllocateSurface
*
*
*
* History:
* Wed 05/24/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::AllocateSurface(
    const AM_MEDIA_TYPE* pmt,
    DWORD* lpdwBufferCount,
    AM_MEDIA_TYPE** ppmt
    )
{
    AMTRACE((TEXT("CVideoMixer::AllocateSurface")));

    SIZE AR;
    LPDIRECTDRAWSURFACE7 lpSurface7;
    LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pmt);
    HRESULT hr = S_OK;

    if( !lpHdr ) {
        return E_POINTER;
    }
    __try {

        ASSERT(m_pDD == NULL);
        ASSERT(m_pD3D == NULL);
        ASSERT(m_pD3DDevice == NULL);


        VMRALLOCATIONINFO p;
        CHECK_HR(hr = GetImageAspectRatio(pmt,
                                          &p.szAspectRatio.cx,
                                          &p.szAspectRatio.cy));
        p.dwFlags = AMAP_3D_TARGET;
        p.lpHdr = lpHdr;
        p.lpPixFmt = NULL;
        p.dwMinBuffers = 1;
        p.dwMaxBuffers = 1;
        //p.dwInterlaceFlags = m_dwInterlaceFlags;
        p.dwInterlaceFlags = 0;

        if (m_MixingPrefs & MixerPref_DecimateOutput) {
            p.szNativeSize.cx = 2 * lpHdr->biWidth;
            p.szNativeSize.cy = 2 * lpHdr->biHeight;
        }
        else {
            p.szNativeSize.cx = lpHdr->biWidth;
            p.szNativeSize.cy = lpHdr->biHeight;
        }

        if ((m_MixingPrefs & MixerPref_RenderTargetMask) ==
			 MixerPref_RenderTargetRGB) {

            // We try the current monitor format.

            lpHdr->biBitCount = 0;
            lpHdr->biCompression = BI_RGB;

            CHECK_HR(hr = m_pBackEndAllocator->AllocateSurface(
                                m_dwUserID, &p,
                                lpdwBufferCount,
                                &lpSurface7));
        }
        else if (SpecialIMC3Mode(m_MixingPrefs)) {

            // Try 'IMC3'

            lpHdr->biBitCount = 12;
            DbgLog((LOG_TRACE, 0, TEXT("VMR Mixer trying 'IMC3' render target")));
            lpHdr->biCompression = MAKEFOURCC('I','M','C','3');
            hr = m_pBackEndAllocator->AllocateSurface(m_dwUserID, &p,
                                                      lpdwBufferCount,
                                                      &lpSurface7);
        }
        else if ((m_MixingPrefs & MixerPref_RenderTargetMask) ==
                  MixerPref_RenderTargetYUV420) {

            // We try 'YV12' followed by 'NV12'

            lpHdr->biBitCount = 12;
            DbgLog((LOG_TRACE, 0, TEXT("VMR Mixer trying 'NV12' render target")));
            lpHdr->biCompression = MAKEFOURCC('N','V','1','2');
            hr = m_pBackEndAllocator->AllocateSurface(
                                m_dwUserID, &p,
                                lpdwBufferCount,
                                &lpSurface7);

            if (FAILED(hr)) {
                DbgLog((LOG_TRACE, 0, TEXT("VMR Mixer trying 'YV12' render target")));
                lpHdr->biCompression = MAKEFOURCC('Y','V','1','2');
                hr = m_pBackEndAllocator->AllocateSurface(
                                    m_dwUserID, &p,
                                    lpdwBufferCount,
                                    &lpSurface7);
            }

            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, 1, TEXT("YUV 4:2:0 surface allocation failed")));
                __leave;
            }

        }
        else if ((m_MixingPrefs & MixerPref_RenderTargetMask) ==
                  MixerPref_RenderTargetYUV422) {

            // We try 'YUY2' followed by 'UYVY'

            lpHdr->biBitCount = 16;
            lpHdr->biCompression = MAKEFOURCC('Y','U','Y','2');

            hr = m_pBackEndAllocator->AllocateSurface(
                                m_dwUserID, &p,
                                lpdwBufferCount,
                                &lpSurface7);
            if (FAILED(hr)) {
                lpHdr->biCompression = MAKEFOURCC('U','Y','V','Y');
                CHECK_HR(hr = m_pBackEndAllocator->AllocateSurface(
                                    m_dwUserID, &p,
                                    lpdwBufferCount,
                                    &lpSurface7));
            }
        }
        else if ((m_MixingPrefs & MixerPref_RenderTargetMask) ==
                  MixerPref_RenderTargetYUV444) {

            lpHdr->biBitCount = 32;
            lpHdr->biCompression = MAKEFOURCC('A','Y','U','V');

            CHECK_HR(hr = m_pBackEndAllocator->AllocateSurface(
                                m_dwUserID, &p,
                                lpdwBufferCount,
                                &lpSurface7));
        }
        else {
            ASSERT(!"Invalid Render Target format specified");
        }




        DDSURFACEDESC2 ddSurfaceDesc;
        INITDDSTRUCT(ddSurfaceDesc);
        CHECK_HR(hr = lpSurface7->GetSurfaceDesc(&ddSurfaceDesc));
        //m_fOverlayRT = !!(ddSurfaceDesc.ddsCaps.dwCaps & DDSCAPS_OVERLAY);

        CHECK_HR(hr = ConvertSurfaceDescToMediaType(&ddSurfaceDesc, pmt, ppmt));

        CHECK_HR(hr = m_BufferQueue.InitBufferQueue(lpSurface7));

        CHECK_HR(hr = lpSurface7->GetDDInterface((LPVOID *)&m_pDD));

        INITDDSTRUCT(m_ddHWCaps);
        CHECK_HR(hr = m_pDD->GetCaps((LPDDCAPS)&m_ddHWCaps, NULL));

        CHECK_HR(hr = GetTextureCaps(m_pDD, &m_dwTextureCaps));

        //
        // No 3D stuff required when in IMC3 mode
        //
        if (!SpecialIMC3Mode(m_MixingPrefs)) {

            CHECK_HR(hr = m_pDD->QueryInterface(IID_IDirect3D7, (LPVOID *)&m_pD3D));
            CHECK_HR(hr = m_pD3D->CreateDevice(IID_IDirect3DHALDevice,
                                               m_BufferQueue.GetNextSurface(),
                                               &m_pD3DDevice));

            CHECK_HR(hr = m_pImageCompositor->InitCompositionTarget(
                                    m_pD3DDevice,
                                    m_BufferQueue.GetNextSurface()));
        }
    }
    __finally {

        if (FAILED(hr)) {
            FreeSurface();
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* FreeSurface
*
*
*
* History:
* Wed 05/24/2000 - StEstrop - Created
*
\**************************************************************************/
void
CVideoMixer::FreeSurface(
    )
{
    AMTRACE((TEXT("CVideoMixer::FreeSurface")));


    if (!SpecialIMC3Mode(m_MixingPrefs)) {
        m_pImageCompositor->TermCompositionTarget(
                                 m_pD3DDevice,
                                 m_BufferQueue.GetNextSurface());
    }

    RELEASE(m_pDDSAppImage);
    RELEASE(m_pDDSTextureMirror);

    RELEASE(m_pD3DDevice);
    RELEASE(m_pD3D);
    RELEASE(m_pDD);

    if (m_pBackEndAllocator) {
        m_BufferQueue.TermBufferQueue();
        m_pBackEndAllocator->FreeSurface(m_dwUserID);
    }

    if (m_pmt) {
        DeleteMediaType(m_pmt);
        m_pmt = NULL;
    }
}


HRESULT
CVideoMixer::RecomputeTargetSizeFromAllStreams(
    LONG* plWidth,
    LONG* plHeight
    )
{
    *plWidth = 0;
    *plHeight = 0;

    CMediaType cmt;
    HRESULT hr = S_OK;
    DWORD dwInterlaceFlags = 0;

    for( DWORD j =0; j < m_dwNumStreams; j++ ) {

        hr = m_ppMixerStreams[j]->GetStreamMediaType(&cmt);
        if( FAILED(hr)) {
            FreeMediaType( cmt );
            break;
        }

        //
        // Are we decimating the output ?
        //
        if (m_MixingPrefs & MixerPref_DecimateOutput) {
            DecimateMediaType(&cmt);
        }

        //hr = GetInterlaceFlagsFromMediaType(&cmt, &dwInterlaceFlags);
        //if (SUCCEEDED(hr) && dwInterlaceFlags) {
        //    m_dwInterlaceFlags = dwInterlaceFlags;
        //}

        hr = AspectRatioAdjustMediaType(&cmt);
        if (SUCCEEDED(hr)) {
            LPRECT lprc = GetTargetRectFromMediaType(&cmt);
            *plWidth = max(*plWidth, WIDTH(lprc));
            *plHeight = max(*plHeight, HEIGHT(lprc));
        }
        FreeMediaType( cmt );
    }
    return hr;
}


/*****************************Private*Routine******************************\
* ValidateSpecialCase
*
*
*
* History:
* Thu 06/07/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
ValidateSpecialCase(
    AM_MEDIA_TYPE* pmt,
    DWORD dwMixingPrefs,
    DWORD dwSurfFlags
    )
{
    if (SpecialIMC3Mode(dwMixingPrefs)) {

        LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pmt);
        if (lpHdr->biCompression != '3CMI' &&
            lpHdr->biCompression != '44AI' &&
            lpHdr->biCompression != '44IA') {

            DbgLog((LOG_ERROR, 1,
                    TEXT("We only allow IMC3, AI44 and ")
                    TEXT("IA44 connections in this mode")));
            return  E_FAIL;
        }
    }
    else {

        //
        // We are not in IMC3 mixing mode - in this case we can only
        // blend IA44 and AI44 surfaces if they are textures.
        //

        LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pmt);
        if (lpHdr->biCompression == '44AI' ||
            lpHdr->biCompression == '44IA') {

            if (!(dwSurfFlags & VMR_SF_TEXTURE)) {

                DbgLog((LOG_ERROR, 1,
                        TEXT("We only allow IMC3, AI44 and ")
                        TEXT("IA44 connections in this mode")));
                return E_FAIL;
            }
        }
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* SetStreamMediaType
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamMediaType(
    DWORD dwStreamID,
    AM_MEDIA_TYPE* pmt,
    DWORD dwSurfFlags,
    LPGUID lpDeint,
    DXVA_DeinterlaceCaps* lpCaps
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamMediaType")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = S_OK;

    DbgLog((LOG_TRACE, 1, TEXT("SetStreamMediaType called for stream %d"),
            dwStreamID ));

    if (FAILED(hr = ValidateStream(dwStreamID)))
        return hr;

    if (FAILED(hr = m_ppMixerStreams[dwStreamID]->SetStreamMediaType(pmt, dwSurfFlags )))
        return hr;

    if (pmt == NULL) {

        if (!SpecialIMC3Mode(m_MixingPrefs)) {
            m_ppMixerStreams[dwStreamID]->DestroyDeinterlaceDevice();
        }

        hr = m_pImageCompositor->SetStreamMediaType(dwStreamID, pmt, !!dwSurfFlags);

        //
        // check to see if there are any remaining streams connected,
        // if not free our D3D resources.
        //
        DWORD i;
        for (i = 0; i < m_dwNumStreams; i++) {
            if (m_ppMixerStreams[i]->IsStreamConnected()) {
                break;
            }
        }

        if (i == m_dwNumStreams) {
            DbgLog((LOG_TRACE, 1,
                    TEXT("No more streams connected, FreeSurface called")));
            FreeSurface();
        }
        return hr;
    }

    //
    // If we are in the special IMC3 mixing mode, only allow IMC3, AI44 and IA44
    // media types.  We can't blend anything else.
    //

    if (FAILED(hr = ValidateSpecialCase(pmt, m_MixingPrefs, dwSurfFlags))) {
        return hr;
    }

    __try {

        bool fTextureMirrorWasPresent = false;
        DWORD dwBuffers = 1;
        CMediaType cmt(*pmt);
        cmt.SetSubtype(&MEDIASUBTYPE_SameAsMonitor);

        CHECK_HR(hr = AspectRatioAdjustMediaType(&cmt));

        if (m_MixingPrefs & MixerPref_DecimateOutput) {
            DecimateMediaType(&cmt);
        }

        if (m_pmt == NULL) {

#ifdef DEBUG
            {
                LPBITMAPINFOHEADER lpHdr = GetbmiHeader(&cmt);
                DbgLog((LOG_TRACE, 1, TEXT("Allocating first back end surface %dx%d"),
                        lpHdr->biWidth, lpHdr->biHeight));
            }
#endif

            //GetInterlaceFlagsFromMediaType(&cmt, &m_dwInterlaceFlags);
            CHECK_HR(hr = AllocateSurface(&cmt, &dwBuffers, &m_pmt));
        }
        else {

            DbgLog((LOG_TRACE, 1, TEXT("Backend Surf already allocated") ));

            RECT rcOldTrg = *GetTargetRectFromMediaType(m_pmt);
            LPBITMAPINFOHEADER lpNew = GetbmiHeader(&cmt);

            // Get the size of the old render target
            LONG lOldWidth = WIDTH(&rcOldTrg);
            LONG lOldHeight = HEIGHT(&rcOldTrg);

            //
            // Recompute to determine the new target size from all the
            // connected streams
            //

            LONG lNewWidth, lNewHeight;
            RecomputeTargetSizeFromAllStreams(&lNewWidth, &lNewHeight);

            //
            // Has the render target changed size ?
            //
            if (lNewWidth != lOldWidth || lNewHeight != lOldHeight)
            {
                lpNew->biWidth = lNewWidth;
                lpNew->biHeight = lNewHeight;

                DbgLog((LOG_TRACE, 1, TEXT("Re-allocating backend surf %dx%d"),
                        lNewWidth, lNewHeight));

                fTextureMirrorWasPresent = (NULL != m_pDDSTextureMirror);
                FreeSurface();
                CHECK_HR(hr = AllocateSurface(&cmt, &dwBuffers, &m_pmt));

                LPRECT lpTarget = GetTargetRectFromMediaType(m_pmt);
                lpTarget->right =  lNewWidth;
                lpTarget->bottom = lNewHeight;
            }
        }


        if (fTextureMirrorWasPresent || !(dwSurfFlags & VMR_SF_TEXTURE)) {

            if (!SpecialIMC3Mode(m_MixingPrefs)) {

                LPBITMAPINFOHEADER lpbi = GetbmiHeader(pmt);
                CHECK_HR(hr = AllocateTextureMirror(abs(lpbi->biWidth),
                                                    abs(lpbi->biHeight)));
            }
        }


        if (!SpecialIMC3Mode(m_MixingPrefs) && lpDeint && lpCaps) {

            CHECK_HR(hr = m_ppMixerStreams[dwStreamID]->CreateDeinterlaceDevice(
                            m_pDD, lpDeint, lpCaps, m_dwTextureCaps));
        }

    }
    __finally {

        //
        // If everything succeeded inform the compositor
        //
        if (SUCCEEDED(hr)) {

            hr = m_pImageCompositor->SetStreamMediaType(dwStreamID,pmt,
                                                        !!dwSurfFlags);
        }

        if (FAILED(hr)) {
            // total failure, free everything
            FreeSurface();
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* BeginFlush
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::BeginFlush(
    DWORD dwStreamID
    )
{
    AMTRACE((TEXT("CVideoMixer::BeginFlush")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->BeginFlush();
    }
    return hr;
}


/******************************Public*Routine******************************\
* EndFlush
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::EndFlush(
    DWORD dwStreamID
    )
{
    AMTRACE((TEXT("CVideoMixer::EndFlush")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->EndFlush();
    }
    return hr;
}



/******************************Public*Routine******************************\
* SetStreamActiveState
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamActiveState(
    DWORD dwStreamID,
    BOOL fActive
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamActiveState")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->SetStreamActiveState(fActive);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamActiveState
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamActiveState(
    DWORD dwStreamID,
    BOOL* lpfActive
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamActiveState")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamActiveState(lpfActive);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamColorKey
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamColorKey(
    DWORD dwStreamID,
    LPDDCOLORKEY Clr
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {

        //
        // Add more parameter validation here - clr keying and
        // embedded alpha are not allowed together.
        //
        // Need to check that the h/w actually supports clr keying
        // of textures.
        //
        // 0xFFFFFFFF turns clr keying off.  All other values
        // should be in the range 0 to 0x00FFFFFF
        //

        hr = m_ppMixerStreams[dwStreamID]->SetStreamColorKey(Clr);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamColorKey
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamColorKey(
    DWORD dwStreamID,
    LPDDCOLORKEY lpClr
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR( lpClr ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetStreamColorKey: NULL Clr ptr !!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamColorKey(lpClr);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamAlpha
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamAlpha(
    DWORD dwStreamID,
    float Alpha
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamAlpha")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        if ( Alpha < 0.0f || Alpha > 1.0f )
        {
            DbgLog((LOG_ERROR, 1,
                    TEXT("SetStreamAlpha: Alpha value must be between 0.0 and 1.0")));
            return E_INVALIDARG;
        }
        hr = m_ppMixerStreams[dwStreamID]->SetStreamAlpha(Alpha);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamAlpha
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamAlpha(
    DWORD dwStreamID,
    float* lpAlpha
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamAlpha")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(lpAlpha))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetStreamAlpha: NULL Alpha ptr !!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamAlpha(lpAlpha);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamZOrder
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamZOrder(
    DWORD dwStreamID,
    DWORD ZOrder
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamZOrder")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->SetStreamZOrder(ZOrder);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamZOrder
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamZOrder(
    DWORD dwStreamID,
    DWORD* pdwZOrder
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamZOrder")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(pdwZOrder))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetStreamZOrder: NULL ZOrder ptr!!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamZOrder(pdwZOrder);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamOutputRect
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
* Tue 05/16/2000 - nwilt - renamed to SetStreamOutputRect
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetStreamOutputRect(
    DWORD dwStreamID,
    const NORMALIZEDRECT* prDest
    )
{
    AMTRACE((TEXT("CVideoMixer::SetStreamOutputRect")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADREADPTR(prDest))
    {
        DbgLog((LOG_ERROR, 1, TEXT("SetStreamOutputRect: NULL rect ptr!!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->SetStreamOutputRect(prDest);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamOutputRect
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
* Tue 05/16/2000 - nwilt - renamed to GetStreamOutputRect
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetStreamOutputRect(
    DWORD dwStreamID,
    NORMALIZEDRECT* pOut
    )
{
    AMTRACE((TEXT("CVideoMixer::GetStreamOutputRect")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(pOut))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetStreamOutputRect: NULL rect ptr!!")));
        return E_POINTER;
    }

    HRESULT hr = ValidateStream(dwStreamID);
    if (SUCCEEDED(hr)) {
        hr = m_ppMixerStreams[dwStreamID]->GetStreamOutputRect(pOut);
    }
    return hr;
}


/******************************Public*Routine******************************\
* SetAlphaBitmap
*
*
*
* History:
* Thu 05/04/2000 - nwilt - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetAlphaBitmap( const VMRALPHABITMAP *pIn )
{
    AMTRACE((TEXT("CVideoMixer::SetAlphaBitmap")));
    CAutoLock Lock(&m_ObjectLock);

    if ( ISBADREADPTR( pIn ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad input pointer")));
        return E_POINTER;
    }
    if ( pIn->dwFlags & ~(VMRBITMAP_DISABLE | VMRBITMAP_HDC |
                          VMRBITMAP_ENTIREDDS | VMRBITMAP_SRCCOLORKEY) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid flags")));
        return E_INVALIDARG;
    }
    if ( pIn->dwFlags & VMRBITMAP_DISABLE )
    {
        if ( pIn->dwFlags != VMRBITMAP_DISABLE )
        {
            DbgLog((LOG_ERROR, 1, TEXT("No flags valid with VMRBITMAP_DISABLE")));
            return E_INVALIDARG;
        }
        // early out
        RELEASE( m_pDDSAppImage );
        if (m_hbmpAppImage) {
            DeleteObject( m_hbmpAppImage );
            m_hbmpAppImage = NULL;
        }
        return S_OK;
    }

    if ( ! m_pDD )
    {
        DbgLog((LOG_ERROR, 1, TEXT("DirectDraw object not yet set")));
        return E_FAIL;
    }

    if ( pIn->dwFlags & VMRBITMAP_HDC )
    {
        if ( pIn->dwFlags & VMRBITMAP_ENTIREDDS )
        {
            DbgLog((LOG_ERROR, 1, TEXT("ENTIREDDS not valid with HDC")));
            return E_INVALIDARG;
        }
        if ( NULL == pIn->hdc )
        {
            DbgLog((LOG_ERROR, 1, TEXT("No HDC specified")));
            return E_INVALIDARG;
        }
        if ( NULL != pIn->pDDS )
        {
            DbgLog((LOG_ERROR, 1, TEXT("DirectDraw surface specified even ")
                    TEXT("though VMRBITMAP_HDC set")));
            return E_INVALIDARG;
        }
    }
    else
    {
        if ( NULL != pIn->hdc )
        {
            DbgLog((LOG_ERROR, 1, TEXT("HDC cannot be specified without ")
                    TEXT("setting VMRBITMAP_HDC")));
            return E_INVALIDARG;
        }
        if ( NULL == pIn->pDDS )
        {
            DbgLog((LOG_ERROR, 1, TEXT("DirectDraw surface not specified")));
            return E_INVALIDARG;
        }
    }

    if ( pIn->fAlpha < 0.0f || pIn->fAlpha > 1.0f )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Alpha must be between 0.0 and 1.0")));
        return E_INVALIDARG;
    }

    if (m_hbmpAppImage) {
        DeleteObject( m_hbmpAppImage );
        m_hbmpAppImage = NULL;
    }

    HRESULT hr = S_OK;
    HDC hdcSrc = NULL;
    HDC hdcDest = NULL;
    HBITMAP hbmpNew = NULL;
    UINT Width, Height;

    __try
    {
        DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
        m_dwAppImageFlags = APPIMG_NOIMAGE;

        if (VMRBITMAP_ENTIREDDS & pIn->dwFlags)
        {
            CHECK_HR(hr = pIn->pDDS->GetSurfaceDesc(&ddsd));

            //
            // We only allow ARGB32 and RGB32 DDraw surface types.
            //
            if (ddsd.ddpfPixelFormat.dwRGBBitCount != 32) {
                DbgLog((LOG_ERROR, 1, TEXT("Only 32bit DirectDraw surfacs allowed")));
                hr = E_INVALIDARG;
                __leave;
            }

            if (ddsd.ddpfPixelFormat.dwRGBAlphaBitMask == 0xFF000000) {

                if (pIn->dwFlags & VMRBITMAP_SRCCOLORKEY) {
                    DbgLog((LOG_ERROR, 1, TEXT("Can't mix color keying and per-pixel alpha")));
                    hr = E_INVALIDARG;
                    __leave;
                }

                m_dwAppImageFlags = APPIMG_DDSURFARGB32;
            }
            else {
                m_dwAppImageFlags = APPIMG_DDSURFRGB32;
            }

            m_rcAppImageSrc.left = m_rcAppImageSrc.top = 0;
            m_rcAppImageSrc.right = ddsd.dwWidth;
            m_rcAppImageSrc.bottom = ddsd.dwHeight;
        }
        else {
            m_dwAppImageFlags = APPIMG_HBITMAP;
            m_rcAppImageSrc = pIn->rSrc;
        }

        if (IsRectEmpty(&m_rcAppImageSrc))
        {
            DbgLog((LOG_ERROR, 1, TEXT("Empty source rectangle")));
            hr = E_INVALIDARG;
            __leave;
        }

        Width = m_rcAppImageSrc.right - m_rcAppImageSrc.left;
        Height = m_rcAppImageSrc.bottom - m_rcAppImageSrc.top;

        if (pIn->dwFlags & VMRBITMAP_HDC) {
            hdcSrc = pIn->hdc;
        }
        else {
            CHECK_HR( hr = pIn->pDDS->GetDC( &hdcSrc ) );
        }

        hdcDest = CreateCompatibleDC(NULL);
        if (!hdcDest)
        {
            DbgLog((LOG_ERROR, 1, TEXT("Could not create dest DC")));
            hr = E_OUTOFMEMORY;
            __leave;
        }

        BITMAPINFO bmpinfo;
        LPVOID lpvBits;
        ZeroMemory( &bmpinfo, sizeof(bmpinfo) );
        bmpinfo.bmiHeader.biSize = sizeof(bmpinfo.bmiHeader);
        bmpinfo.bmiHeader.biWidth = Width;
        bmpinfo.bmiHeader.biHeight = Height;
        bmpinfo.bmiHeader.biPlanes = 1;
        bmpinfo.bmiHeader.biBitCount = 32;
        bmpinfo.bmiHeader.biCompression = BI_RGB;
        hbmpNew = CreateDIBSection(hdcDest, &bmpinfo, DIB_RGB_COLORS,
                                   &lpvBits, NULL, 0 );
        if (!hbmpNew)
        {
            DbgLog((LOG_ERROR, 1, TEXT("Could not create DIBsection")));
            hr = E_OUTOFMEMORY;
            __leave;
        }

        HBITMAP hbmpOld = (HBITMAP) SelectObject( hdcDest, hbmpNew );
        if (!BitBlt(hdcDest, 0, 0, Width, Height,
                    hdcSrc, m_rcAppImageSrc.left, m_rcAppImageSrc.top, SRCCOPY))
        {
            DbgLog((LOG_ERROR, 1, TEXT("BitBlt to bitmap surface failed")));
            hr = E_FAIL;
            __leave;
        }

        // successfully copied from source surface to destination
        SelectObject( hdcDest, hbmpOld );
    }
    __finally
    {
        if (NULL != hdcSrc && (!(VMRBITMAP_HDC & pIn->dwFlags))) {
            pIn->pDDS->ReleaseDC( hdcSrc );
        }

        if (hdcDest) {
            DeleteDC(hdcDest);
        }
    }

    if ( S_OK == hr )
    {
        m_hbmpAppImage = hbmpNew;

        // make sure we make a new mirror surface next time we blend
        RELEASE(m_pDDSAppImage);

        // record parameters
        if (pIn->dwFlags & VMRBITMAP_SRCCOLORKEY) {
            m_clrTrans = pIn->clrSrcKey;
        }
        else {
            m_clrTrans = CLR_INVALID;
        }

        m_dwClrTransMapped = (DWORD)-1;
        m_rDest = pIn->rDest;
        m_fAlpha = pIn->fAlpha;
        m_dwWidthAppImage = Width;
        m_dwHeightAppImage = Height;
    }

    return hr;
}

/******************************Public*Routine******************************\
* UpdateAlphaBitmapParameters
*
*
*
* History:
*  - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::UpdateAlphaBitmapParameters(
    PVMRALPHABITMAP pIn
    )
{
    AMTRACE((TEXT("CVideoMixer::UpdateAlphaBitmapParameters")));
    CAutoLock Lock(&m_ObjectLock);


    if (pIn->dwFlags & VMRBITMAP_DISABLE)
    {
        if (pIn->dwFlags != VMRBITMAP_DISABLE)
        {
            DbgLog((LOG_ERROR, 1, TEXT("No flags valid with VMRBITMAP_DISABLE")));
            return E_INVALIDARG;
        }

        // early out
        RELEASE(m_pDDSAppImage);

        if (m_hbmpAppImage) {
            DeleteObject( m_hbmpAppImage );
            m_hbmpAppImage = NULL;
        }

        return S_OK;
    }

    //
    // Update the color key value - we only remap the color key if
    // it has actually changed.
    //
    HRESULT hr = S_OK;
    if (pIn->dwFlags & VMRBITMAP_SRCCOLORKEY) {

        if (m_clrTrans != pIn->clrSrcKey) {

            m_clrTrans = pIn->clrSrcKey;

            if (m_pDDSAppImage) {
                m_dwClrTransMapped = DDColorMatch(m_pDDSAppImage, m_clrTrans, hr);
                if (hr == DD_OK) {
                    DDCOLORKEY key = {m_dwClrTransMapped, m_dwClrTransMapped};
                    hr = m_pDDSAppImage->SetColorKey(DDCKEY_SRCBLT, &key);
                }
            }
            else {
                m_dwClrTransMapped = (DWORD)-1;
            }
        }
    }
    else {

        m_clrTrans = CLR_INVALID;
        m_dwClrTransMapped = (DWORD)-1;
    }

    if (pIn->dwFlags & VMRBITMAP_SRCRECT) {

        if (pIn->rSrc.left >= 0 &&
            pIn->rSrc.top >= 0 &&
            pIn->rSrc.right <= (LONG)m_dwWidthAppImage &&
            pIn->rSrc.bottom <=(LONG)m_dwHeightAppImage) {

            m_rcAppImageSrc = pIn->rSrc;
        }
    }

    m_rDest = pIn->rDest;
    m_fAlpha = pIn->fAlpha;

    return hr;
}

/******************************Public*Routine******************************\
* GetAlphaBitmapParameters
*
*
*
* History:
* Thu 05/04/2000 - nwilt - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetAlphaBitmapParameters( VMRALPHABITMAP *pOut )
{
    AMTRACE((TEXT("CVideoMixer::GetAlphaBitmapParameters")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADWRITEPTR(pOut))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    ZeroMemory(pOut, sizeof(*pOut));
    pOut->rSrc = m_rcAppImageSrc;
    pOut->rDest = m_rDest;
    pOut->fAlpha = m_fAlpha;
    pOut->clrSrcKey = m_clrTrans;

    return S_OK;
}


/******************************Public*Routine******************************\
* SetBackgroundColor
*
*
*
* History:
* Wed 02/28/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetBackgroundColor(
    COLORREF clr
    )
{
    AMTRACE((TEXT("CVideoMixer::SetBackgroundColor")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr;
    LPDIRECTDRAWSURFACE7 lpSurf = m_BufferQueue.GetNextSurface();
    if (lpSurf) {
        m_clrBorder = clr;
        m_dwClrBorderMapped = DDColorMatch(lpSurf, m_clrBorder, hr);
    }
    else {
        hr = E_FAIL;
    }

    return hr;

}

/******************************Public*Routine******************************\
* GetBackgroundColor
*
*
*
* History:
* Wed 02/28/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetBackgroundColor(
    COLORREF* clr
    )
{
    AMTRACE((TEXT("CVideoMixer::GetBackgroundColor")));
    CAutoLock Lock(&m_ObjectLock);

    *clr = m_clrBorder;

    return S_OK;

}

/******************************Public*Routine******************************\
* SetMixingPrefs
*
*
*
* History:
* Fri 03/02/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::SetMixingPrefs(
    DWORD dwMixerPrefs
    )
{
    AMTRACE((TEXT("CVideoMixer::SetMixingPrefs")));
    CAutoLock Lock(&m_ObjectLock);

    //
    // validate the decimation flags
    //
    DWORD dwFlags = (dwMixerPrefs & MixerPref_DecimateMask);
    switch (dwFlags) {
    case MixerPref_NoDecimation:
    case MixerPref_DecimateOutput:
        break;

    default:
        DbgLog((LOG_ERROR, 1,
                TEXT("CVideoMixer::SetMixingPrefs - invalid decimation flags")));
        return E_INVALIDARG;
    }


    //
    // validate the filtering flags
    //
    dwFlags = (dwMixerPrefs & MixerPref_FilteringMask);
    switch (dwFlags) {
    case MixerPref_BiLinearFiltering:
    case MixerPref_PointFiltering:
        break;

    default:
        DbgLog((LOG_ERROR, 1,
                TEXT("CVideoMixer::SetMixingPrefs - invalid filtering flags")));
        return E_INVALIDARG;
    }


    //
    // validate the render target flags
    //
    dwFlags = (dwMixerPrefs & MixerPref_RenderTargetMask);
    switch (dwFlags) {
    case MixerPref_RenderTargetRGB:
    case MixerPref_RenderTargetYUV420:
    case MixerPref_RenderTargetYUV422:
    case MixerPref_RenderTargetYUV444:
    case MixerPref_RenderTargetIntelIMC3:
        break;

    default:
        DbgLog((LOG_ERROR, 1,
                TEXT("CVideoMixer::SetMixingPrefs - invalid filtering flags")));
        return E_INVALIDARG;
    }

    //
    // We are good to go !!
    //

    m_MixingPrefs = dwMixerPrefs;
    return S_OK;
}


/******************************Public*Routine******************************\
* GetMixingPrefs
*
*
*
* History:
* Fri 03/02/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::GetMixingPrefs(
    DWORD* pdwMixerPrefs
    )
{
    AMTRACE((TEXT("CVideoMixer::GetMixingPrefs")));
    CAutoLock Lock(&m_ObjectLock);

    *pdwMixerPrefs = m_MixingPrefs;
    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\inc\vmrwinctrl.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1998  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

// Video control interface base classes, December 1995

#ifndef __VMRWINCTRL__
#define __VMRWINCTRL__

#define ABSOL(x) (x < 0 ? -x : x)
#define NEGAT(x) (x > 0 ? -x : x)

class CVMRFilter;

//  Helper
BOOL WINAPI VMRPossiblyEatMessage(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam);

class CVMRBaseControlWindow : public CBaseVideoWindow, public CBaseWindow
{
protected:

    CVMRFilter  *m_pFilter;            // Pointer to owning media filter
    CCritSec *m_pInterfaceLock;        // Externally defined critical section
    COLORREF m_BorderColour;           // Current window border colour
    BOOL m_bAutoShow;                  // What happens when the state changes
    HWND m_hwndOwner;                  // Owner window that we optionally have
    HWND m_hwndDrain;                  // HWND to post any messages received
    BOOL m_bCursorHidden;              // Should we hide the window cursor

public:

    // Internal methods for other objects to get information out

    HRESULT DoSetWindowStyle(long Style,long WindowLong);
    HRESULT DoGetWindowStyle(long *pStyle,long WindowLong);
    BOOL IsAutoShowEnabled() { return m_bAutoShow; };
    COLORREF GetBorderColour() { return m_BorderColour; };
    HWND GetOwnerWindow() { return m_hwndOwner; };
    BOOL IsCursorHidden() { return m_bCursorHidden; };

    inline BOOL PossiblyEatMessage(UINT uMsg, WPARAM wParam, LPARAM lParam)
    {
        return ::VMRPossiblyEatMessage(m_hwndDrain, uMsg, wParam, lParam);
    }

public:

    CVMRBaseControlWindow(CVMRFilter *pFilter,   // Owning media filter
                       CCritSec *pInterfaceLock,    // Locking object
                       TCHAR *pName,                // Object description
                       LPUNKNOWN pUnk,              // Normal COM ownership
                       HRESULT *phr);               // OLE return code

    // These are the properties we support

    STDMETHODIMP put_Caption(BSTR strCaption);
    STDMETHODIMP get_Caption(BSTR *pstrCaption);
    STDMETHODIMP put_AutoShow(long AutoShow);
    STDMETHODIMP get_AutoShow(long *AutoShow);
    STDMETHODIMP put_WindowStyle(long WindowStyle);
    STDMETHODIMP get_WindowStyle(long *pWindowStyle);
    STDMETHODIMP put_WindowStyleEx(long WindowStyleEx);
    STDMETHODIMP get_WindowStyleEx(long *pWindowStyleEx);
    STDMETHODIMP put_WindowState(long WindowState);
    STDMETHODIMP get_WindowState(long *pWindowState);
    STDMETHODIMP put_BackgroundPalette(long BackgroundPalette);
    STDMETHODIMP get_BackgroundPalette(long *pBackgroundPalette);
    STDMETHODIMP put_Visible(long Visible);
    STDMETHODIMP get_Visible(long *pVisible);
    STDMETHODIMP put_Left(long Left);
    STDMETHODIMP get_Left(long *pLeft);
    STDMETHODIMP put_Width(long Width);
    STDMETHODIMP get_Width(long *pWidth);
    STDMETHODIMP put_Top(long Top);
    STDMETHODIMP get_Top(long *pTop);
    STDMETHODIMP put_Height(long Height);
    STDMETHODIMP get_Height(long *pHeight);
    STDMETHODIMP put_Owner(OAHWND Owner);
    STDMETHODIMP get_Owner(OAHWND *Owner);
    STDMETHODIMP put_MessageDrain(OAHWND Drain);
    STDMETHODIMP get_MessageDrain(OAHWND *Drain);
    STDMETHODIMP get_BorderColor(long *Color);
    STDMETHODIMP put_BorderColor(long Color);
    STDMETHODIMP get_FullScreenMode(long *FullScreenMode);
    STDMETHODIMP put_FullScreenMode(long FullScreenMode);

    // And these are the methods

    STDMETHODIMP SetWindowForeground(long Focus);
    STDMETHODIMP NotifyOwnerMessage(OAHWND hwnd,long uMsg,LONG_PTR wParam,LONG_PTR lParam);
    STDMETHODIMP GetMinIdealImageSize(long *pWidth,long *pHeight);
    STDMETHODIMP GetMaxIdealImageSize(long *pWidth,long *pHeight);
    STDMETHODIMP SetWindowPosition(long Left,long Top,long Width,long Height);
    STDMETHODIMP GetWindowPosition(long *pLeft,long *pTop,long *pWidth,long *pHeight);
    STDMETHODIMP GetRestorePosition(long *pLeft,long *pTop,long *pWidth,long *pHeight);
    STDMETHODIMP HideCursor(long HideCursor);
    STDMETHODIMP IsCursorHidden(long *CursorHidden);
};

// This class implements the IBasicVideo interface

class CVMRBaseControlVideo : public CBaseBasicVideo
{
protected:

    CVMRFilter  *m_pFilter;   // Pointer to owning media filter
    CCritSec *m_pInterfaceLock;         // Externally defined critical section

public:

    // Derived classes must provide these for the implementation

    virtual HRESULT IsDefaultTargetRect() PURE;
    virtual HRESULT SetDefaultTargetRect() PURE;
    virtual HRESULT SetTargetRect(RECT *pTargetRect) PURE;
    virtual HRESULT GetTargetRect(RECT *pTargetRect) PURE;
    virtual HRESULT IsDefaultSourceRect() PURE;
    virtual HRESULT SetDefaultSourceRect() PURE;
    virtual HRESULT SetSourceRect(RECT *pSourceRect) PURE;
    virtual HRESULT GetSourceRect(RECT *pSourceRect) PURE;
    virtual HRESULT GetStaticImage(long *pBufferSize,long *pDIBImage) PURE;

    // Derived classes must override this to return a VIDEOINFO representing
    // the video format. We cannot call IPin ConnectionMediaType to get this
    // format because various filters dynamically change the type when using
    // DirectDraw such that the format shows the position of the logical
    // bitmap in a frame buffer surface, so the size might be returned as
    // 1024x768 pixels instead of 320x240 which is the real video dimensions

    virtual VIDEOINFOHEADER *GetVideoFormat() PURE;

    // Helper functions for creating memory renderings of a DIB image

    HRESULT GetImageSize(VIDEOINFOHEADER *pVideoInfo,
                         LONG *pBufferSize,
                         RECT *pSourceRect);

    HRESULT CopyImage(IMediaSample *pMediaSample,
                      VIDEOINFOHEADER *pVideoInfo,
                      LONG *pBufferSize,
                      BYTE *pVideoImage,
                      RECT *pSourceRect);

    // Override this if you want notifying when the rectangles change
    virtual HRESULT OnUpdateRectangles() { return NOERROR; };
    virtual HRESULT OnVideoSizeChange();

    // Helper methods for checking rectangles
    virtual HRESULT CheckSourceRect(RECT *pSourceRect);
    virtual HRESULT CheckTargetRect(RECT *pTargetRect);

public:

    CVMRBaseControlVideo(CVMRFilter *pFilter,    // Owning media filter
                      CCritSec *pInterfaceLock,     // Serialise interface
                      TCHAR *pName,                 // Object description
                      LPUNKNOWN pUnk,               // Normal COM ownership
                      HRESULT *phr);                // OLE return code

    // These are the properties we support

    STDMETHODIMP get_AvgTimePerFrame(REFTIME *pAvgTimePerFrame);
    STDMETHODIMP get_BitRate(long *pBitRate);
    STDMETHODIMP get_BitErrorRate(long *pBitErrorRate);
    STDMETHODIMP get_VideoWidth(long *pVideoWidth);
    STDMETHODIMP get_VideoHeight(long *pVideoHeight);
    STDMETHODIMP put_SourceLeft(long SourceLeft);
    STDMETHODIMP get_SourceLeft(long *pSourceLeft);
    STDMETHODIMP put_SourceWidth(long SourceWidth);
    STDMETHODIMP get_SourceWidth(long *pSourceWidth);
    STDMETHODIMP put_SourceTop(long SourceTop);
    STDMETHODIMP get_SourceTop(long *pSourceTop);
    STDMETHODIMP put_SourceHeight(long SourceHeight);
    STDMETHODIMP get_SourceHeight(long *pSourceHeight);
    STDMETHODIMP put_DestinationLeft(long DestinationLeft);
    STDMETHODIMP get_DestinationLeft(long *pDestinationLeft);
    STDMETHODIMP put_DestinationWidth(long DestinationWidth);
    STDMETHODIMP get_DestinationWidth(long *pDestinationWidth);
    STDMETHODIMP put_DestinationTop(long DestinationTop);
    STDMETHODIMP get_DestinationTop(long *pDestinationTop);
    STDMETHODIMP put_DestinationHeight(long DestinationHeight);
    STDMETHODIMP get_DestinationHeight(long *pDestinationHeight);

    // And these are the methods

    STDMETHODIMP GetVideoSize(long *pWidth,long *pHeight);
    STDMETHODIMP SetSourcePosition(long Left,long Top,long Width,long Height);
    STDMETHODIMP GetSourcePosition(long *pLeft,long *pTop,long *pWidth,long *pHeight);
    STDMETHODIMP GetVideoPaletteEntries(long StartIndex,long Entries,long *pRetrieved,long *pPalette);
    STDMETHODIMP SetDefaultSourcePosition();
    STDMETHODIMP IsUsingDefaultSource();
    STDMETHODIMP SetDestinationPosition(long Left,long Top,long Width,long Height);
    STDMETHODIMP GetDestinationPosition(long *pLeft,long *pTop,long *pWidth,long *pHeight);
    STDMETHODIMP SetDefaultDestinationPosition();
    STDMETHODIMP IsUsingDefaultDestination();
    STDMETHODIMP GetCurrentImage(long *pBufferSize,long *pVideoImage);
};

#endif // __WINCTRL__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\mixer\mixercomp.cpp ===
/******************************Module*Header*******************************\
* Module Name: mixerComp.cpp
*
* Mixer compositor functions
*
* Created: Tue 10/03/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>

#include "vmrp.h"
#include "mixerobj.h"

#if defined( EHOME_WMI_INSTRUMENTATION )
#include "dxmperf.h"
#endif

/*****************************Private*Routine******************************\
* AllocateTextureMirror
*
* Makes sure the video memory texture is big enough to accommodate the
* input surface.  Frees and reallocates it (bumping to next power of 2)
* if it is not.
*
* Allocates the video memory texture mirror for the first time if it has
* not been allocated yet.
*
* This routine should never be called if the hardware supports YUV texturing.
* SetStreamMediaType checks for DDSCAPS_TEXTURE on the decode surface before
* calling this routine.
*
* History:
* Thu 06/29/2000 - nwilt - Created
*
\**************************************************************************/

// global data structures and static helper function for AllocateTextureMirror
const DDPIXELFORMAT g_rgTextMirFormats[] = {
    { sizeof(DDPIXELFORMAT), DDPF_RGB, 0, 24, 0xff0000, 0xff00,  0xff, 0},
    { sizeof(DDPIXELFORMAT), DDPF_RGB, 0, 32, 0xff0000, 0xff00,  0xff, 0},
    { sizeof(DDPIXELFORMAT), DDPF_RGB, 0, 16, 0x1f<<11, 0x3f<<5, 0x1f, 0},
    { sizeof(DDPIXELFORMAT), DDPF_RGB, 0, 16, 0x1f<<10, 0x1f<<5, 0x1f, 0}
};

const UINT g_cTextMirFormats = sizeof(g_rgTextMirFormats)/sizeof(DDPIXELFORMAT);

UINT NextPow2(UINT i)
{
    UINT ret = 1;
    while ( ret < i )
    {
        ret <<= 1;
    }
    return ret;
}

HRESULT
CVideoMixer::AllocateTextureMirror( DWORD dwWidth, DWORD dwHeight )
{
    HRESULT hr;
    DDSURFACEDESC2 ddsd = {sizeof(ddsd)};

    __try
    {
        if (m_pDDSTextureMirror)
        {
            CHECK_HR(hr = m_pDDSTextureMirror->GetSurfaceDesc(&ddsd));

            //
            // early out if mirror already exists and is large enough
            // to accommodate pDDS
            //

            if (ddsd.dwWidth >= dwWidth && ddsd.dwHeight >= dwHeight) {
                hr = S_OK;
                __leave;
            }

            dwWidth = max(ddsd.dwWidth, dwWidth);
            dwHeight = max(ddsd.dwHeight, dwHeight);
        }
        RELEASE(m_pDDSTextureMirror);

        //
        // bump dimensions out to next power of 2 if the 3D hardware needs
        // it that way
        //

        if (m_dwTextureCaps & TXTR_POWER2) {
            dwWidth = NextPow2(dwWidth);
            dwHeight = NextPow2(dwHeight);
        }

        DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
        ddsd.dwFlags = DDSD_WIDTH | DDSD_HEIGHT | DDSD_CAPS | DDSD_PIXELFORMAT;
        ddsd.dwWidth = dwWidth;
        ddsd.dwHeight = dwHeight;
        ddsd.ddsCaps.dwCaps = DDSCAPS_TEXTURE |
                              DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM;

        //
        // loop over texture formats and return as soon as CreateSurface succeeds
        //

        for (UINT i = 0; i < g_cTextMirFormats; i++ )
        {
            //
            // create texture mirror
            //

            ddsd.ddpfPixelFormat = g_rgTextMirFormats[i];
            hr = m_pDD->CreateSurface(&ddsd, &m_pDDSTextureMirror, NULL);
            if (SUCCEEDED(hr)) {
                break;
            }
        }
    }
    __finally {
    }

    return hr;
}


/*****************************Private*Routine******************************\
* CreateAppImageMirror
*
*
*
* History:
* Tue 10/03/2000 - NWilt - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::CreateAppImageMirror( )
{
    AMTRACE((TEXT("CVideoMixer::CreateAppImageMirror")));
    HRESULT hr;
    LPDIRECTDRAWSURFACE7 pDDS;
    HDC hdcSrc = NULL;
    HDC hdcDest = NULL;
    float fTexWid = 0.0f, fTexHgt = 0.0f;

    __try
    {
        DDSURFACEDESC2 ddsd = {sizeof(ddsd)};

        if (m_dwTextureCaps & TXTR_POWER2) {
            ddsd.dwWidth = NextPow2( m_dwWidthAppImage );
            ddsd.dwHeight = NextPow2( m_dwHeightAppImage );
        }
        else {
            ddsd.dwWidth = m_dwWidthAppImage;
            ddsd.dwHeight = m_dwHeightAppImage;
        }

        // create texture mirror
        ddsd.dwFlags = DDSD_WIDTH | DDSD_HEIGHT | DDSD_CAPS;

        //
        // The following seems to make the NVidia drivers work
        // without making everyone else fail.
        //
        ddsd.ddsCaps.dwCaps = DDSCAPS_TEXTURE;
        ddsd.ddsCaps.dwCaps2 = DDSCAPS2_TEXTUREMANAGE | DDSCAPS2_HINTSTATIC;

        //
        // Take care of DDraw surface app images.
        //
        if (m_dwAppImageFlags & (APPIMG_DDSURFARGB32|APPIMG_DDSURFRGB32)) {

            ddsd.dwFlags |= DDSD_PIXELFORMAT;

            //
            // Slot 1. of the g_rgTextMirFormats is an RGB32 pixel format.
            //

            ddsd.ddpfPixelFormat = g_rgTextMirFormats[1];

            if (m_dwAppImageFlags & APPIMG_DDSURFARGB32) {
                ddsd.ddpfPixelFormat.dwFlags |= DDPF_ALPHAPIXELS;
            }
        }

        hr = m_pDD->CreateSurface( &ddsd, &pDDS, NULL );
        if (SUCCEEDED(hr))
        {
            m_fAppImageTexWid = 1.0F / (float)ddsd.dwWidth;
            m_fAppImageTexHgt = 1.0F / (float)ddsd.dwHeight;

            if (m_clrTrans != CLR_INVALID) {
                m_dwClrTransMapped = DDColorMatch(pDDS, m_clrTrans, hr);
                if (hr == DD_OK) {
                    DDCOLORKEY key = {m_dwClrTransMapped, m_dwClrTransMapped};
                    CHECK_HR(hr = pDDS->SetColorKey(DDCKEY_SRCBLT, &key));
                }
            }
        }


        if (FAILED(hr)) {
            __leave;
        }

        CHECK_HR( hr = pDDS->GetDC( &hdcDest ) );

        hdcSrc = CreateCompatibleDC( hdcDest );
        if (!hdcSrc)
        {
            DbgLog((LOG_ERROR, 1, TEXT("Could not create DC")));
            hr = E_OUTOFMEMORY;
            __leave;
        }

        HBITMAP hbmOld = (HBITMAP)SelectObject(hdcSrc, m_hbmpAppImage);
        if (!hbmOld) {
            DbgLog((LOG_ERROR, 1, TEXT("Selectobject failed copying into app image surface")));
            hr = E_FAIL;
            __leave;
        }

        BOOL fRc = BitBlt(hdcDest, 0, 0, m_dwWidthAppImage, m_dwHeightAppImage,
                          hdcSrc, 0, 0, SRCCOPY);
        SelectObject(hdcSrc, hbmOld);
        if (!fRc)
        {
            DbgLog((LOG_ERROR, 1, TEXT("BitBlt failed copying into app image surface")));
            hr = E_FAIL;
            __leave;
        }
    }
    __finally
    {
        if (hdcSrc)
        {
            DeleteDC(hdcSrc);
        }

        if (hdcDest )
        {
            pDDS->ReleaseDC(hdcDest);
        }
    }

    if ( S_OK == hr )
    {
        RELEASE(m_pDDSAppImage);
        m_pDDSAppImage = pDDS;
    }
    else
    {
        RELEASE( pDDS );
    }
    return hr;
}


/*****************************Private*Routine******************************\
* BlendAppImage
*
*
*
* History:
* Tue 10/03/2000 - NWilt - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::BlendAppImage(
    LPDIRECTDRAWSURFACE7 pDDS,
    LPDIRECT3DDEVICE7 pD3DDevice
    )
{
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr;
    DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
    struct {
        float x, y, z, rhw;
        D3DCOLOR clr;
        float tu, tv;
    } V[4];

    __try {

        if (!m_pDDSAppImage)
        {
            CHECK_HR( hr = CreateAppImageMirror() );
        }

        CHECK_HR( hr = pDDS->GetSurfaceDesc(&ddsd) );

        float fWid = (float)ddsd.dwWidth;
        float fHgt = (float)ddsd.dwHeight;
        BYTE alpha = (BYTE)(255.0f * m_fAlpha);

        // top-left
        V[0].x = (m_rDest.left  *fWid) - 0.5F;
        V[0].y = (m_rDest.top   *fHgt) - 0.5F;
        V[0].z = 0.5f;
        V[0].rhw = 2.0f;
        V[0].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

        // top-right
        V[1].x = (m_rDest.right *fWid) - 0.5F;
        V[1].y = (m_rDest.top   *fHgt) - 0.5F;
        V[1].z = 0.5f;
        V[1].rhw = 2.0f;
        V[1].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

        // bottom-left
        V[2].x = (m_rDest.left  *fWid) - 0.5F;
        V[2].y = (m_rDest.bottom*fHgt) - 0.5F;
        V[2].z = 0.5f;
        V[2].rhw = 2.0f;
        V[2].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

        // bottom-right
        V[3].x = (m_rDest.right *fWid) - 0.5F;
        V[3].y = (m_rDest.bottom*fHgt) - 0.5F;
        V[3].z = 0.5f;
        V[3].rhw = 2.0f;
        V[3].clr = RGBA_MAKE(0xff, 0xff, 0xff, alpha);

        // top-left
        V[0].tu = (float)m_rcAppImageSrc.left * m_fAppImageTexWid;
        V[0].tv = (float)m_rcAppImageSrc.top * m_fAppImageTexHgt;

        // top-rigth
        V[1].tu = (float)m_rcAppImageSrc.right * m_fAppImageTexWid;
        V[1].tv = (float)m_rcAppImageSrc.top * m_fAppImageTexHgt;

        // bottom-left
        V[2].tu = (float)m_rcAppImageSrc.left * m_fAppImageTexWid;
        V[2].tv = (float)m_rcAppImageSrc.bottom * m_fAppImageTexHgt;

        // bottom-right
        V[3].tu = (float)m_rcAppImageSrc.right * m_fAppImageTexWid;
        V[3].tv = (float)m_rcAppImageSrc.bottom * m_fAppImageTexHgt;

        CHECK_HR(hr = pD3DDevice->SetTexture(0, m_pDDSAppImage));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_CULLMODE, D3DCULL_NONE));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_LIGHTING, FALSE));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_BLENDENABLE, TRUE));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_SRCBLEND, D3DBLEND_SRCALPHA));
        CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_DESTBLEND, D3DBLEND_INVSRCALPHA));

        if (m_dwAppImageFlags & APPIMG_DDSURFARGB32)
        {
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP_MODULATE));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAARG2, D3DTA_DIFFUSE));
            CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_ALPHATESTENABLE, TRUE));
            CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_ALPHAREF, 0x10));
            CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_ALPHAFUNC, D3DCMP_GREATER));
            CHECK_HR(hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_COLORKEYENABLE, FALSE));
        }
        else
        {
            CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1));
            CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAARG1, D3DTA_DIFFUSE));
            CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHATESTENABLE, FALSE ) );

            BOOL fKey = (m_clrTrans != CLR_INVALID);
            pD3DDevice->SetRenderState(D3DRENDERSTATE_COLORKEYENABLE, fKey);
        }

        if (m_MixingPrefs & MixerPref_BiLinearFiltering) {
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MAGFILTER, D3DTFG_LINEAR));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MINFILTER, D3DTFN_LINEAR));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MIPFILTER, D3DTFP_LINEAR));
        }
        else {
            // ATi Rage Pro preferes these settings
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MAGFILTER, D3DTFG_POINT));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MINFILTER, D3DTFN_POINT));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MIPFILTER, D3DTFP_POINT));
        }

        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_COLORARG1, D3DTA_TEXTURE));
        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ADDRESS, D3DTADDRESS_CLAMP));

        CHECK_HR(hr = pD3DDevice->BeginScene());
        CHECK_HR(hr = pD3DDevice->DrawPrimitive(D3DPT_TRIANGLESTRIP,
                                                D3DFVF_XYZRHW |
                                                D3DFVF_DIFFUSE | D3DFVF_TEX1,
                                                V, 4, D3DDP_WAIT));
        CHECK_HR(hr = pD3DDevice->EndScene());
        CHECK_HR(hr = pD3DDevice->SetTexture(0, NULL));
    }
    __finally
    {
    }
    return hr;
}


/*****************************Private*Routine******************************\
* CompositeStreams
*
* Prepares the streams ready to call the plugin compositor.
*
* History:
* Wed 07/19/2000 - NWilt    - Created
* Wed 07/19/2000 - StEstrop - made it call the plug-in compositor
*
\**************************************************************************/
HRESULT
CVideoMixer::CompositeStreams(
    LPDIRECTDRAWSURFACE7 pDDSBack,
    LPDIRECT3DDEVICE7 pD3DDevice,
    REFERENCE_TIME rtStart,
    REFERENCE_TIME rtEnd,
    LPDIRECTDRAWSURFACE7 *ppDDSSamples,
    DWORD dwStrmIDs[],
    UINT cStreams
    )
{
    HRESULT hr;
    UINT iMap[MAX_MIXER_STREAMS];
    DWORD dwZ[MAX_MIXER_STREAMS];
    VMRVIDEOSTREAMINFO strmMT[MAX_MIXER_STREAMS];
    ZeroMemory(strmMT, sizeof(strmMT));

    __try {

        // Get the Z-Order for each stream
        UINT i;
        for ( i = 0; i < cStreams; i++ )
        {
            iMap[i] = i;
            m_ppMixerStreams[dwStrmIDs[i]]->GetStreamZOrder( &dwZ[i] );
        }


        // insertion sort in Z such that highest Z gets drawn first
        for ( i = 1; i < cStreams; i++ )
        {
            UINT j = i;
            while ( j > 0 && dwZ[iMap[j-1]] < dwZ[iMap[j]] )
            {
                UINT t = iMap[j-1];
                iMap[j-1] = iMap[j];
                iMap[j] = t;
                j -= 1;
            }
        }

        for ( i = 0; i < cStreams; i++ )
        {
            DDSURFACEDESC2 ddsd = {sizeof(ddsd)};
            UINT k = iMap[i];
            UINT j = dwStrmIDs[k];

            strmMT[i].pddsVideoSurface = ppDDSSamples[k];
            strmMT[i].dwStrmID = j;
            CHECK_HR(hr = ppDDSSamples[k]->GetSurfaceDesc(&ddsd));
            strmMT[i].dwWidth = ddsd.dwWidth;
            strmMT[i].dwHeight = ddsd.dwHeight;

            CHECK_HR(hr = m_ppMixerStreams[j]->GetStreamColorKey(&strmMT[i].ddClrKey));
            CHECK_HR(hr = m_ppMixerStreams[j]->GetStreamAlpha(&strmMT[i].fAlpha));
            CHECK_HR(hr = m_ppMixerStreams[j]->GetStreamOutputRect(&strmMT[i].rNormal));
        }


        CHECK_HR( hr = m_pImageCompositor->CompositeImage(pD3DDevice,
                                                          pDDSBack,
                                                          m_pmt,
                                                          rtStart,
                                                          rtEnd,
                                                          m_dwClrBorderMapped,
                                                          strmMT,
                                                          cStreams) );
    }
    __finally {}


    return hr;
}

/******************************Public*Routine******************************\
* InitCompositionTarget
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::CIIVMRImageCompositor::InitCompositionTarget(
    IUnknown* pD3DDevice,
    LPDIRECTDRAWSURFACE7 pddsRenderTarget
    )
{
    AMTRACE((TEXT("CVideoMixer::CIIVMRImageCompositor::InitCompositionTarget")));
    return S_OK;
}

/******************************Public*Routine******************************\
* TermCompositionTarget
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::CIIVMRImageCompositor::TermCompositionTarget(
    IUnknown* pD3DDevice,
    LPDIRECTDRAWSURFACE7 pddsRenderTarget
    )
{
    AMTRACE((TEXT("CVideoMixer::CIIVMRImageCompositor::TermCompositionTarget")));
    return S_OK;
}

/******************************Public*Routine******************************\
* SetStreamMediaType
*
*
*
* History:
* Wed 02/28/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::CIIVMRImageCompositor::SetStreamMediaType(
    DWORD dwStrmID,
    AM_MEDIA_TYPE *pmt,
    BOOL fTexture
    )
{
    AMTRACE((TEXT("CVideoMixer::CIIVMRImageCompositor::TermCompositionTarget")));

    AM_MEDIA_TYPE *pmtStrm = &StrmProps[dwStrmID].mt;

    FreeMediaType(*pmtStrm);

    if (pmt) {
        CopyMediaType(pmtStrm, pmt);
        FixupMediaType(pmtStrm);
    }
    else {
        ZeroMemory(pmtStrm, sizeof(*pmtStrm));
    }

    StrmProps[dwStrmID].fTexture = fTexture;

    return S_OK;
}


/*****************************Private*Routine******************************\
* CalcSrcAndDstFromMT
*
*
*
* History:
*  - StEstrop - Created
*
\**************************************************************************/
void
CalcSrcAndDstFromMT(
    const AM_MEDIA_TYPE& pmt,
    const RECT& Target,
    LPRECT lpSrc,
    LPRECT lpDst,
    LPRECT lprcBdrTL = NULL,
    LPRECT lprcBdrBR = NULL
    )
{
    RECT Trg = *GetTargetRectFromMediaType(&pmt);
    *lpSrc = *GetSourceRectFromMediaType(&pmt);

    SIZE ar;
    GetImageAspectRatio(&pmt, &ar.cx, &ar.cy);

    SIZE im = {WIDTH(&Trg), HEIGHT(&Trg)};
    AspectRatioCorrectSize(&im, ar);

    RECT Src = {0, 0, im.cx, im.cy};
    LetterBoxDstRect(lpDst, Src, Target, lprcBdrTL, lprcBdrBR);
}


/*****************************Private*Routine******************************\
* OptimizeBackground
*
* Simple optimization.
*
* If the bottom layer of video covers the composition space and
* it has an Alpha value of 1 then just BLT the video image into
* place.  Otherwise we have to clear the back buffer to black and
* blend the video with it.
*
* History:
* Tue 09/12/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::CIIVMRImageCompositor::OptimizeBackground(
    REFERENCE_TIME rtStart,
    LPDIRECTDRAWSURFACE7 pDDSBack,
    LPRECT lpTarget,
    const VMRVIDEOSTREAMINFO* ps,
    DWORD dwMappedBdrClr,
    UINT* uNextStrm
    )
{
    HRESULT hr = DD_OK;
    *uNextStrm = 0;

    CVideoMixerStream* thisStream = m_pObj->m_ppMixerStreams[ps->dwStrmID];

    __try {

        DDSURFACEDESC2 ddsdV = {sizeof(ddsdV)};
        DDSURFACEDESC2 ddsdB = {sizeof(ddsdB)};

        BOOL fBltOk = TRUE;

        CHECK_HR(hr = ps->pddsVideoSurface->GetSurfaceDesc(&ddsdV));
        CHECK_HR(hr = pDDSBack->GetSurfaceDesc(&ddsdB));

        //
        // We have to blend video surfaces that contain embedded alpha
        //
        if (ddsdV.ddpfPixelFormat.dwFlags & DDPF_ALPHAPIXELS) {
            fBltOk = FALSE;
        }

        //
        // if the video surface is RGB it must match the pixel format
        // of the render target otherwise the Blt will fail
        //
        else if (DDPF_RGB == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_RGB)) {

            DDPIXELFORMAT* ddpfB = &ddsdB.ddpfPixelFormat;
            DDPIXELFORMAT* ddpfV = &ddsdV.ddpfPixelFormat;

            fBltOk = (ddpfB->dwRGBBitCount == ddpfV->dwRGBBitCount &&
                      ddpfB->dwRBitMask    == ddpfV->dwRBitMask    &&
                      ddpfB->dwGBitMask    == ddpfV->dwGBitMask    &&
                      ddpfB->dwBBitMask    == ddpfV->dwBBitMask);
        }

        DDCAPS_DX7& ddCaps = m_pObj->m_ddHWCaps;

        //
        // Check the Blt stretching caps.  Make sure the caps we look
        // at match the surface we are blting from ie. VIDMem or AGPMem.
        //
        if (ddsdV.ddsCaps.dwCaps & DDSCAPS_NONLOCALVIDMEM) {

            DWORD dwCaps = 0;
            const DWORD dwFXCaps =  DDFXCAPS_BLTSHRINKX | DDFXCAPS_BLTSHRINKX  |
                                    DDFXCAPS_BLTSTRETCHX | DDFXCAPS_BLTSTRETCHY;

            if (DDPF_RGB == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_RGB)) {
                dwCaps = DDCAPS_BLTSTRETCH;
            }
            else if (DDPF_FOURCC == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_FOURCC)) {
                dwCaps = (DDCAPS_BLTFOURCC | DDCAPS_BLTSTRETCH);
            }

            fBltOk &= ((dwCaps & ddCaps.dwNLVBCaps) == dwCaps);
            fBltOk &= ((dwFXCaps & ddCaps.dwNLVBFXCaps) == dwFXCaps);
        }
        else {

            DWORD dwCaps = 0;
            const DWORD dwFXCaps =  DDFXCAPS_BLTSHRINKX | DDFXCAPS_BLTSHRINKX  |
                                    DDFXCAPS_BLTSTRETCHX | DDFXCAPS_BLTSTRETCHY;

            if (DDPF_RGB == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_RGB)) {
                dwCaps = DDCAPS_BLTSTRETCH;
            }
            else if (DDPF_FOURCC == (ddsdV.ddpfPixelFormat.dwFlags & DDPF_FOURCC)) {
                dwCaps = (DDCAPS_BLTFOURCC | DDCAPS_BLTSTRETCH);
            }

            fBltOk &= ((dwCaps & ddCaps.dwCaps) == dwCaps);
            fBltOk &= ((dwFXCaps & ddCaps.dwFXCaps) == dwFXCaps);
        }

        DDBLTFX ddFX;
        INITDDSTRUCT(ddFX);

        if (SpecialIMC3Mode(m_pObj->m_MixingPrefs)) {
            // we should really convert the rgb background colour
            // specified by the user into an AYUV color here.
            ddFX.dwFillColor = 0x80801000;
        }
        else {
            ddFX.dwFillColor = dwMappedBdrClr;
        }
        AM_MEDIA_TYPE* pmt = &StrmProps[ps->dwStrmID].mt;

        TargetScale postScale;
        GetTargetScaleFromMediaType(pmt, &postScale);


        //
        // only optimize if no custom user rectangle, no anamorphic hacks
        // and Alpha of 1.0
        //

        if (ps->rNormal.left == 0.0F && ps->rNormal.top == 0.0F &&
            ps->rNormal.right == 1.0F && ps->rNormal.bottom == 1.0F &&
            ps->fAlpha == 1.0F && postScale.fX == 1.0F && postScale.fY == 1.0F )
        {
            RECT rcDst, rcSrc, rcBdrTL, rcBdrBR;

            CalcSrcAndDstFromMT(*pmt, *lpTarget, &rcSrc, &rcDst,
                                &rcBdrTL, &rcBdrBR);
            if (fBltOk) {

                //
                // We need to de-interlace this video image if:
                //
                // 1. the stream is interlaced
                // 2. the stream has a deinterlacing device
                // 3. we are not in the special IMC3 mode.
                //

                if (thisStream->IsStreamInterlaced() &&
                    thisStream->CanBeDeinterlaced() &&
                    !SpecialIMC3Mode(m_pObj->m_MixingPrefs)) {

                    if (S_OK == thisStream->DeinterlaceStream(
                                    rtStart, &rcDst, pDDSBack, &rcSrc,
                                    !!(ddsdB.ddpfPixelFormat.dwFlags & DDPF_RGB))) {

                        *uNextStrm = 1; // move on to the next stream
                    }
                }
                else {

                    CHECK_HR(hr = pDDSBack->Blt(&rcDst, ps->pddsVideoSurface,
                                                &rcSrc, DDBLT_WAIT, NULL));
                    *uNextStrm = 1; // move on to the next stream
                }
            }

            if (!IsRectEmpty(&rcBdrTL)) {
                CHECK_HR(hr = pDDSBack->Blt(&rcBdrTL, NULL, NULL,
                                            DDBLT_COLORFILL | DDBLT_WAIT,
                                            &ddFX));
            }

            if (!IsRectEmpty(&rcBdrBR)) {
                CHECK_HR(hr = pDDSBack->Blt(&rcBdrBR, NULL, NULL,
                                            DDBLT_COLORFILL | DDBLT_WAIT,
                                            &ddFX));
            }
        }
        else
        {
            //
            // Clear the back buffer with colorfill Blt, for some reason
            // D3D's Clear introduces rendering artifacts
            //

            CHECK_HR(hr = pDDSBack->Blt(NULL, NULL, NULL,
                                        DDBLT_COLORFILL | DDBLT_WAIT,
                                        &ddFX));
        }
    }
    __finally {}

    return hr;
}

/******************************Public*Routine******************************\
* CenterInverseScale
*
*   Scale the rectangle (about its center) by the given scale
*
* History:
* Tue 03/14/2000 - GlennE - Created
*
\**************************************************************************/
static void CenterScale( NORMALIZEDRECT* prDest,  const TargetScale& scale )
{
    if( scale.fX != 1.0F ) {
        float centerX = (prDest->left+prDest->right)/2;
        float halfWidth = (prDest->right - prDest->left)/2 * scale.fX;

        prDest->left = centerX - halfWidth;
        prDest->right = centerX + halfWidth;
    }
    if( scale.fY != 1.0F ) {
        float centerY = (prDest->top + prDest->bottom)/2;
        float halfHeight = (prDest->bottom - prDest->top)/2 * scale.fY;
        prDest->top = centerY - halfHeight;
        prDest->bottom = centerY + halfHeight;
    }
}

static void CopyRectFromTo( const RECT& from, NORMALIZEDRECT* pTo )
{
    // Note: to float
    pTo->left = float(from.left);
    pTo->top = float(from.top);
    pTo->right = float(from.right);
    pTo->bottom = float(from.bottom);
}

/*****************************Private*Routine******************************\
* SpecialIMC3Composite
*
* A stripped down compositor for IMC3 render targets.
*
* History:
* Tue 05/08/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixer::CIIVMRImageCompositor::SpecialIMC3Composite(
    LPDIRECTDRAWSURFACE7 pDDSBack,
    LPRECT lprcRenderTarget,
    VMRVIDEOSTREAMINFO* pStrmInfo,
    UINT i,
    UINT cStreams
    )
{
    HRESULT hr = S_OK;

    for ( ; i < cStreams; i++, pStrmInfo++) {

        //
        // start with the user rectangle and place an aspect ratio
        // corrected version inside of it.
        //
        NORMALIZEDRECT rDest = pStrmInfo[i].rNormal;

        //
        // Compute letterbox of userTarget
        //
        RECT rcSrc, rcUserDst;
        AM_MEDIA_TYPE* pmt = &StrmProps[pStrmInfo[i].dwStrmID].mt;
        CalcSrcAndDstFromMT(*pmt, *lprcRenderTarget, &rcSrc, &rcUserDst);

        //
        // Copy letterboxed UserTarget back to overall Target image
        //
        NORMALIZEDRECT rLetterboxedDest;
        CopyRectFromTo(rcUserDst, &rLetterboxedDest );

        //
        // We reduce the image within destination rectangle to the
        // internal aspect ratio. The squish is applied to the FINAL
        // displayed image
        //
        TargetScale postScale;
        GetTargetScaleFromMediaType(pmt, &postScale);
        CenterScale(&rLetterboxedDest, postScale);

        // now map the normalized destination to the target
        float fWidth = (rLetterboxedDest.right - rLetterboxedDest.left);
        float fHeight= (rLetterboxedDest.bottom - rLetterboxedDest.top);

        float rdWidth  = (rDest.right - rDest.left);
        float rdHeight = (rDest.bottom - rDest.top);

        // work out the position of the stream
        float fLeft = (rLetterboxedDest.left * rdWidth)  + (WIDTH(lprcRenderTarget)  * rDest.left);
        float fTop  = (rLetterboxedDest.top  * rdHeight) + (HEIGHT(lprcRenderTarget) * rDest.top);

        // work out the size of the stream
        // investigate: should be able to do this using only rDest.right
        float fRight  = fLeft + (fWidth  * rdWidth);
        float fBottom = fTop  + (fHeight * rdHeight);

        RECT rcDst = {(int)fLeft, (int)fTop, (int)fRight, (int)fBottom};
        hr = pDDSBack->Blt(&rcDst, pStrmInfo[i].pddsVideoSurface,
                           &rcSrc, DDBLT_WAIT, NULL);
        if (FAILED(hr)) {
            return hr;
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* CompositeImage
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::CIIVMRImageCompositor::CompositeImage(
    IUnknown* pUnk,
    LPDIRECTDRAWSURFACE7 pDDSBack,
    AM_MEDIA_TYPE* pmtRT,
    REFERENCE_TIME rtStart,
    REFERENCE_TIME rtEnd,
    DWORD dwBkgClr,
    VMRVIDEOSTREAMINFO* pStrmInfo,
    UINT cStreams
    )
{
    AMTRACE((TEXT("CVideoMixer::CIIVMRImageCompositor::CompositeImage")));

    HRESULT hr = S_OK;
    LPDIRECT3DDEVICE7 pD3DDevice = (LPDIRECT3DDEVICE7)pUnk;
    DDSURFACEDESC2 ddsdTextureMirror = { sizeof(ddsdTextureMirror) };
    bool bInScene = false;

    __try {

        //
        // Start by processing the composition background, normally
        // the lowest layer stream completely covers the background.
        // In which case we can Blt it to the composition surface and
        // move on to the next stream.  If there are no more streams
        // then we are done.
        //

        UINT i = 0;
        LPRECT lprcRenderTarget = GetTargetRectFromMediaType(pmtRT);
        ASSERT(lprcRenderTarget);

        //
        // copy the first stream if no special requirements and
        // increment 'i'.  Otherwise black fill the image and
        // leave 'i' at 0.
        //
        CHECK_HR( hr = OptimizeBackground(rtStart, pDDSBack, lprcRenderTarget,
                                          &pStrmInfo[0], dwBkgClr, &i));
        if (i == cStreams) {
            __leave;
        }


        //
        // Special case code to get the Intel i810 and i815 working correctly.
        //

        if (SpecialIMC3Mode(m_pObj->m_MixingPrefs)) {
            hr = SpecialIMC3Composite(pDDSBack, lprcRenderTarget,
                                      pStrmInfo, i, cStreams);
            __leave;
        }

        if (m_pObj->m_pDDSTextureMirror)
            CHECK_HR(hr = m_pObj->m_pDDSTextureMirror->GetSurfaceDesc(&ddsdTextureMirror));

        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_CULLMODE, D3DCULL_NONE));
        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_LIGHTING, FALSE));
        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_BLENDENABLE, TRUE));
        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_SRCBLEND, D3DBLEND_SRCALPHA));
        CHECK_HR(hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_DESTBLEND, D3DBLEND_INVSRCALPHA));

        // use diffuse alpha from vertices, not texture alpha
        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_COLOROP, D3DTOP_SELECTARG1));

        if (m_pObj->m_MixingPrefs & MixerPref_BiLinearFiltering) {
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MAGFILTER, D3DTFG_LINEAR));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MINFILTER, D3DTFN_LINEAR));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MIPFILTER, D3DTFP_LINEAR));
        }
        else {
            // ATi Rage Pro preferes these settings
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MAGFILTER, D3DTFG_POINT));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MINFILTER, D3DTFN_POINT));
            CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_MIPFILTER, D3DTFP_POINT));
        }


        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_COLORARG1, D3DTA_TEXTURE));
        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ADDRESS, D3DTADDRESS_CLAMP));
        CHECK_HR(hr = pD3DDevice->SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_DIFFUSE));


        CHECK_HR(hr = pD3DDevice->BeginScene());
        bInScene = true;

        for ( ; i < cStreams; i++ )
        {
            LPDIRECTDRAWSURFACE7 pDDS;
            float fTexWidRatio;
            float fTexHgtRatio;

            BOOL fTexture = StrmProps[pStrmInfo[i].dwStrmID].fTexture;
            LPDIRECTDRAWSURFACE7 pDDSSrc = pStrmInfo[i].pddsVideoSurface;
            CVideoMixerStream* thisStream =
                m_pObj->m_ppMixerStreams[pStrmInfo[i].dwStrmID];

            //
            // determine if this stream is interlaced, if it is
            // we need to get it de-interlaced before we can do anything
            // with it.  Each stream has its own dedicated de-interlacing
            // device and de-interlace destination surface.  The destination
            // surface could be a texture or a regular offscreen plain
            // surface.
            //

            if (thisStream->IsStreamInterlaced() &&
                thisStream->CanBeDeinterlaced()) {

                if (S_OK == thisStream->DeinterlaceStream(rtStart, NULL, NULL, NULL, FALSE)) {

                    fTexture  = thisStream->IsDeinterlaceDestATexture();
                    pDDSSrc = thisStream->GetDeinterlaceDestSurface();
                }
                else {

                    fTexture = FALSE;
                }
            }

            if (fTexture) {

                pDDS = pDDSSrc;
                fTexWidRatio = 1.0F / (float)pStrmInfo[i].dwWidth;
                fTexHgtRatio = 1.0F / (float)pStrmInfo[i].dwHeight;
            }
            else {

                RECT r = {0, 0, pStrmInfo[i].dwWidth, pStrmInfo[i].dwHeight};

                pDDS = m_pObj->m_pDDSTextureMirror;
                ASSERT(pDDS != NULL);

                CHECK_HR(hr = pDDS->Blt(&r, pDDSSrc, &r, DDBLT_WAIT, NULL));
                fTexWidRatio = 1.0F / (float)ddsdTextureMirror.dwWidth;
                fTexHgtRatio = 1.0F / (float)ddsdTextureMirror.dwHeight;
            }

            CHECK_HR(hr = pD3DDevice->SetTexture(0, pDDS));

            AM_MEDIA_TYPE* pmt = &StrmProps[pStrmInfo[i].dwStrmID].mt;
            if (MEDIASUBTYPE_HASALPHA(*pmt))
            {
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAOP, D3DTOP_MODULATE /*D3DTOP_SELECTARG1 */ ) );
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE ) );
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAARG2, D3DTA_DIFFUSE ) );
                CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHATESTENABLE, TRUE ) );
                CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHAREF, 0x10 ) );
                CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHAFUNC, D3DCMP_GREATER));
                CHECK_HR( hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_COLORKEYENABLE, FALSE));
            }
            else
            {
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1));
                CHECK_HR( hr = pD3DDevice->SetTextureStageState( 0, D3DTSS_ALPHAARG1, D3DTA_DIFFUSE));
                CHECK_HR( hr = pD3DDevice->SetRenderState( D3DRENDERSTATE_ALPHATESTENABLE, FALSE ) );

                BOOL fKey = ((pStrmInfo[i].ddClrKey.dwColorSpaceLowValue != 0xFFFFFFFF) &&
                             (pStrmInfo[i].ddClrKey.dwColorSpaceHighValue != 0xFFFFFFFF));
                CHECK_HR( hr = pD3DDevice->SetRenderState(D3DRENDERSTATE_COLORKEYENABLE, fKey));
                if (fKey) {
                    CHECK_HR(hr = pDDS->SetColorKey(DDCKEY_SRCBLT, &pStrmInfo[i].ddClrKey));
                }
            }

            struct {
                float x, y, z, rhw;
                D3DCOLOR clr;
                float tu, tv;
            } V[4];

            //
            // start with the user rectangle and place an aspect ratio
            // corrected version inside of it.
            //
            NORMALIZEDRECT rDest = pStrmInfo[i].rNormal;

            //
            // Compute letterbox of userTarget
            //
            RECT rcSrc, rcUserDst;
            CalcSrcAndDstFromMT(*pmt, *lprcRenderTarget, &rcSrc, &rcUserDst);

            //
            // Copy letterboxed UserTarget back to overall Target image
            //
            NORMALIZEDRECT rLetterboxedDest;
            CopyRectFromTo(rcUserDst, &rLetterboxedDest );

            //
            // We reduce the image within destination rectangle to the
            // internal aspect ratio. The squish is applied to the FINAL
            // displayed image
            //
            TargetScale postScale;
            GetTargetScaleFromMediaType(pmt, &postScale);
            CenterScale(&rLetterboxedDest, postScale);

            // now map the normalized destination to the target
            float fWidth = (rLetterboxedDest.right - rLetterboxedDest.left);
            float fHeight= (rLetterboxedDest.bottom - rLetterboxedDest.top);

            float rdWidth  = (rDest.right - rDest.left);
            float rdHeight = (rDest.bottom - rDest.top);

            // work out the position of the stream
            float fLeft = (rLetterboxedDest.left * rdWidth)  + (WIDTH(lprcRenderTarget)  * rDest.left);
            float fTop  = (rLetterboxedDest.top  * rdHeight) + (HEIGHT(lprcRenderTarget) * rDest.top);

            // work out the size of the stream
            // investigate: should be able to do this using only rDest.right
            float fRight  = fLeft + (fWidth  * rdWidth);
            float fBottom = fTop  + (fHeight * rdHeight);

            BYTE bAlpha = (BYTE) ((UINT) 0xff * pStrmInfo[i].fAlpha);

            V[0].x = fLeft - 0.5F;
            V[0].y = fTop - 0.5F;
            V[0].z = 0.5f;
            V[0].rhw = 2.0f;
            V[0].clr = RGBA_MAKE(0xff, 0xff, 0xff, bAlpha);

            V[1].x = fRight - 0.5F;
            V[1].y = fTop - 0.5F;
            V[1].z = 0.5f;
            V[1].rhw = 2.0f;
            V[1].clr = RGBA_MAKE(0xff, 0xff, 0xff, bAlpha);

            V[2].x = fLeft - 0.5F;
            V[2].y = fBottom - 0.5F;
            V[2].z = 0.5f;   V[2].rhw = 2.0f;
            V[2].clr = RGBA_MAKE(0xff, 0xff, 0xff, bAlpha);

            V[3].x = fRight - 0.5F;
            V[3].y = fBottom - 0.5F;
            V[3].z = 0.5f;
            V[3].rhw = 2.0f;
            V[3].clr = RGBA_MAKE(0xff, 0xff, 0xff, bAlpha);

            //
            // Setup the SRC info
            //
            V[0].tu = (float)rcSrc.left * fTexWidRatio;
            V[0].tv = (float)rcSrc.top * fTexHgtRatio;

            V[1].tu = (float)rcSrc.right * fTexWidRatio;
            V[1].tv = (float)rcSrc.top * fTexHgtRatio;

            V[2].tu = (float)rcSrc.left * fTexWidRatio;
            V[2].tv = (float)rcSrc.bottom * fTexHgtRatio;

            V[3].tu = (float)rcSrc.right * fTexWidRatio;
            V[3].tv = (float)rcSrc.bottom * fTexHgtRatio;

            CHECK_HR( hr = pD3DDevice->DrawPrimitive(D3DPT_TRIANGLESTRIP,
                                                     D3DFVF_XYZRHW |
                                                     D3DFVF_DIFFUSE |
                                                     D3DFVF_TEX1,
                                                     V, 4, D3DDP_WAIT) );
        }

        CHECK_HR( hr = pD3DDevice->EndScene( ) );
        bInScene = false;
        CHECK_HR( hr = pD3DDevice->SetTexture( 0, NULL ) );
    }
    __finally
    {
        if ( bInScene )
            pD3DDevice->EndScene( );
    }
    return hr;
}

/*****************************Private*Routine******************************\
* ApplyInBandMTChanges
*
* only selected parts of the media type are allowed to change whilst the
* graph is streaming.  We make sure that only those parts are passed on
* to the compositor.
*
* History:
* Thu 04/12/2001 - StEstrop - Created
*
\**************************************************************************/
BOOL
ApplyInBandMTChanges(
    AM_MEDIA_TYPE* pmtDst,
    AM_MEDIA_TYPE* pmtSrc
    )
{
    // the only parts of the media type that can change in band are
    // certain fields in the format block.

    if (pmtSrc->formattype == FORMAT_VideoInfo) {
        ASSERT(pmtDst->formattype == FORMAT_VideoInfo);

        VIDEOINFOHEADER* lpviSrc = (VIDEOINFOHEADER*)pmtSrc->pbFormat;
        VIDEOINFOHEADER* lpviDst = (VIDEOINFOHEADER*)pmtDst->pbFormat;
        DWORD dwCompareSize = FIELD_OFFSET(VIDEOINFOHEADER, bmiHeader);
        if (memcmp(lpviDst, lpviSrc, dwCompareSize) != 0) {
            CopyMemory(lpviDst, lpviSrc, dwCompareSize);
            return TRUE;
        }
    }
    else if (pmtSrc->formattype == FORMAT_VideoInfo2) {
        ASSERT(pmtDst->formattype == FORMAT_VideoInfo2);

        VIDEOINFOHEADER2* lpviSrc = (VIDEOINFOHEADER2*)pmtSrc->pbFormat;
        VIDEOINFOHEADER2* lpviDst = (VIDEOINFOHEADER2*)pmtDst->pbFormat;
        DWORD dwCompareSize = FIELD_OFFSET(VIDEOINFOHEADER2, bmiHeader);
        if (memcmp(lpviDst, lpviSrc, dwCompareSize) != 0) {
            CopyMemory(lpviDst, lpviSrc, dwCompareSize);
            return TRUE;
        }
    }

    return FALSE;
}

/*****************************Private*Routine******************************\
* MixerThread()
*
*
*
* History:
* Fri 03/17/2000 - StEstrop - Created
*
\**************************************************************************/
DWORD
CVideoMixer::MixerThread()
{

    AMTRACE((TEXT("CVideoMixer::MixerThread")));
    HANDLE hActiveStreams[MAX_MIXER_STREAMS];
    DWORD i;
    REFERENCE_TIME rtStartTime = 0;

    for (i = 0; i < m_dwNumStreams; i++) {
        hActiveStreams[i] = m_ppMixerStreams[i]->GetActiveHandle();
    }

    for (; ; ) {

        IMediaSample* lpSample[MAX_MIXER_STREAMS];
        DWORD dwActiveStreamIDs[MAX_MIXER_STREAMS];
        LPDIRECTDRAWSURFACE7 lpSurfSamp[MAX_MIXER_STREAMS];
        REFERENCE_TIME rtEnd[MAX_MIXER_STREAMS];
        LPBITMAPINFOHEADER* lpBmi[MAX_MIXER_STREAMS];
        bool bActualSampleEnd[MAX_MIXER_STREAMS];

        ZeroMemory(lpSurfSamp, sizeof(lpSurfSamp));

        //
        // try to get a sample from each active stream
        //

        HRESULT hr = E_FAIL;
        BOOL fTimeValid = FALSE;

        DWORD nActiveStreams = 0;
        REFERENCE_TIME rtNextEndTime = MAX_REFERENCE_TIME;

        DbgLog((LOG_TRACE, 2, TEXT("\n+++ New Frame +++"),
                nActiveStreams, rtEnd[nActiveStreams]));

        BOOL fFirstStreamInterlaced = FALSE;

        for (i = 0; i < m_dwNumStreams; i++) {

            IMediaSample* lp = m_ppMixerStreams[i]->GetNextStreamSample();

            if (lp) {

                // if (nActiveStreams == 0) {
                //     m_dwTypeSpecificFlags =
                //         ((CVMRMediaSample*)lp)->GetTypeSpecificFlags();
                // }

                lpSample[nActiveStreams] = lp;
                DbgLog((LOG_TRACE, 2, TEXT("Getting Surf from stream %d"), i));
                hr = ((CVMRMediaSample*)lp)->GetSurface( &lpSurfSamp[nActiveStreams] );

                REFERENCE_TIME rtStart;
                hr = lpSample[nActiveStreams]->GetTime(&rtStart,
                                                       &rtEnd[nActiveStreams]);
                bActualSampleEnd[nActiveStreams] = true;

                if (hr == S_OK || hr == VFW_S_NO_STOP_TIME) {

                    DbgLog((LOG_TRACE, 2, TEXT("ET for Stream %d = %I64d"),
                            i, rtEnd[nActiveStreams]));

                    if (rtStart >= 0 && rtEnd[nActiveStreams] > 0) {

                        fTimeValid = TRUE;

                        if (m_ppMixerStreams[i]->IsStreamTwoInterlacedFields() &&
                            m_ppMixerStreams[i]->CanBeDeinterlaced()) {

                            fFirstStreamInterlaced = (nActiveStreams == 0);

                            REFERENCE_TIME rtMid =
                                (rtStart + rtEnd[nActiveStreams]) / 2;

                            // do we need to display the second field?
                            if (rtStartTime < rtMid) {

                                rtEnd[nActiveStreams] = rtMid;
                                bActualSampleEnd[nActiveStreams] = false;
                            }
                        }
                    }
                    else {

                        DbgLog((LOG_ERROR, 0,
                                TEXT("Negative start or end time for Stream %d"), i));

                        rtStart = 0;
                        rtEnd[nActiveStreams] = 0;
                    }
                }
                else {
                    DbgLog((LOG_ERROR, 1,
                            TEXT("Failed to get sample time for Stream %d\n")
                            TEXT("Are you sure this is a live stream?"), i));

                    hr = S_OK;
                    if (fFirstStreamInterlaced) {
                        rtEnd[nActiveStreams] = rtEnd[0];
                        bActualSampleEnd[nActiveStreams] = bActualSampleEnd[0];
                    }
                    else {
                        rtStart = 0;
                        rtEnd[nActiveStreams] = 0;
                    }
                }

                if (rtStartTime == 0) {
                    rtStartTime = rtStart;
                }

                if (rtEnd[nActiveStreams] != 0) {
                    rtNextEndTime = min(rtNextEndTime, rtEnd[nActiveStreams]);
                }

                ASSERT(m_ppMixerStreams[i]->CheckQValid());

                dwActiveStreamIDs[nActiveStreams] = i;
                nActiveStreams++;
            }
        }


        if (!fTimeValid) {
            ASSERT(rtNextEndTime == (REFERENCE_TIME)MAX_REFERENCE_TIME);
            rtNextEndTime = rtStartTime;
        }

        //
        // If none of the streams are active wait for one to become active
        // or a termination command to come in
        //
        if (nActiveStreams == 0) {

            BOOL fContinue = false;
            for (i = 0; i < m_dwNumStreams; i++) {
                if (m_ppMixerStreams[i]->CheckFlushing()) {
                    fContinue = true;
                    break;
                }
            }

            if (fContinue) {
                continue;
            }

            SetEvent(m_hMixerIdle);
            DWORD rc = MsgWaitForMultipleObjects(m_dwNumStreams,
                                                 hActiveStreams,
                                                 FALSE,
                                                 INFINITE,
                                                 QS_POSTMESSAGE );
            ResetEvent(m_hMixerIdle);

            //
            // Have we been asked to terminate ?
            //

            if (rc == (WAIT_OBJECT_0 + m_dwNumStreams)) {
                return 0;
            }

            continue;
        }

        //
        // composite the samples together
        //

        m_ObjectLock.Lock();

        //
        // fix up any media type changes
        //
        for (i = 0; i < nActiveStreams; i++) {

            CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSample[i];
            if (lpVMRSample->HasTypeChanged()) {

                DWORD k = dwActiveStreamIDs[i];
                AM_MEDIA_TYPE *pmt = NULL;

                if (SUCCEEDED(lpVMRSample->GetMediaType(&pmt))) {

                    DWORD dwSurfaceFlags;
                    AM_MEDIA_TYPE mt;

                    if (SUCCEEDED(m_ppMixerStreams[k]->GetStreamMediaType(
                                        &mt, &dwSurfaceFlags))) {

                        if (ApplyInBandMTChanges(&mt, pmt)) {
                            SetStreamMediaType(k, &mt, dwSurfaceFlags, NULL, NULL);
                            //if (i == 0) {
                            //    GetInterlaceFlagsFromMediaType(&mt, &m_dwInterlaceFlags);
                            //}
                        }

                        FreeMediaType(mt);
                    }

                    DeleteMediaType(pmt);
                }
            }
        }

        if (SUCCEEDED(hr)) {

            LPDIRECTDRAWSURFACE7 lpSurf = m_BufferQueue.GetNextSurface();
            if (lpSurf) {

                hr = m_pBackEndAllocator->PrepareSurface(m_dwUserID, lpSurf, 0);
                if (hr == S_OK) {

#if defined( EHOME_WMI_INSTRUMENTATION )
                    PERFLOG_STREAMTRACE(
                        1,
                        PERFINFO_STREAMTRACE_VMR_BEGIN_DEINTERLACE,
                        rtStartTime, 0, 0, 0, 0 );
#endif

                    CompositeStreams(lpSurf, m_pD3DDevice,
                                     rtStartTime, rtNextEndTime,
                                     lpSurfSamp,
                                     dwActiveStreamIDs,
                                     nActiveStreams);

                    if ( m_hbmpAppImage ) {
                        BlendAppImage(lpSurf, m_pD3DDevice);
                    }

                    DWORD_PTR dwSurf = (DWORD_PTR)lpSurf;
                    DWORD dwSampleFlags = 0;

                    if (fTimeValid)  {
                        dwSampleFlags |= VMRSample_TimeValid;
                    }

                    VMRPRESENTATIONINFO m;
                    ZeroMemory(&m, sizeof(m));

                    m.dwFlags = dwSampleFlags;
                    m.lpSurf = lpSurf;
                    m.rtStart = rtStartTime;
                    m.rtEnd = rtNextEndTime;
                    LPRECT lpTrg = GetTargetRectFromMediaType(m_pmt);
                    m.szAspectRatio.cx = WIDTH(lpTrg);
                    m.szAspectRatio.cy = HEIGHT(lpTrg);

                    //m.dwInterlaceFlags = m_dwInterlaceFlags;
                    //m.dwTypeSpecificFlags = m_dwTypeSpecificFlags;

                    m_ObjectLock.Unlock();

#if defined( EHOME_WMI_INSTRUMENTATION )
                    PERFLOG_STREAMTRACE(
                        1,
                        PERFINFO_STREAMTRACE_VMR_END_DEINTERLACE,
                        rtStartTime, 0, 0, 0, 0 );
#endif

                    hr = m_pImageSync->Receive(&m);

                    m_ObjectLock.Lock();

                    if (hr == S_FALSE) {

                        DbgLog((LOG_TRACE, 0,
                                TEXT("S_FALSE returned from SynObj::Receive")));

                        for (i = 0; i < nActiveStreams; i++) {
                            ASSERT(lpSurfSamp[i] != NULL);
                            RELEASE(lpSurfSamp[i]);
                        }
                        nActiveStreams = 0;
                    }

                    if (!m_BufferQueue.GetNextSurface()) {

                        DbgLog((LOG_TRACE, 0,
                                TEXT("Display Change during receive")));
                        //
                        // The stream queues will have already been flushed of samples
                        // and each sample released.  We reset nActiveStreams so that
                        // we don't release the samples a second time.
                        //
                        for (i = 0; i < nActiveStreams; i++) {
                            ASSERT(lpSurfSamp[i] != NULL);
                            RELEASE(lpSurfSamp[i]);
                        }
                        nActiveStreams = 0;
                    }

                    if (hr != S_OK) {

                        DbgLog((LOG_TRACE, 2, TEXT("Sample Rejected")));
                    }

                    rtStartTime = rtNextEndTime;
                }

                else if (hr == S_FALSE) {

                    DbgLog((LOG_TRACE, 0,
                            TEXT("Display Change during Render Target prepare")));

                    //
                    // The stream queues will have already been flushed of samples
                    // and each sample released.  We reset nActiveStreams so that
                    // we don't release the samples a second time.
                    //

                    ASSERT(!m_BufferQueue.GetNextSurface());
                    for (i = 0; i < nActiveStreams; i++) {

                        ASSERT(lpSample[i] != NULL);
                        ASSERT(lpSurfSamp[i] != NULL);
                        RELEASE(lpSurfSamp[i]);

                        if (m_ppMixerStreams[dwActiveStreamIDs[i]]->RemoveNextStreamSample())
                        {
                            CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSample[i];

                            if (lpVMRSample->IsDXVASample()) {
                                lpVMRSample->SignalReleaseSurfaceEvent();
                            }
                            else {
                                lpVMRSample->Release();
                            }
                        }

                    }
                    nActiveStreams = 0;
                }

                else {
                    DbgLog((LOG_ERROR, 1,
                            TEXT("GetNextSurface failed error =%#X"), hr));
                }

                m_BufferQueue.FreeSurface(lpSurf);
            }
            else {

                DbgLog((LOG_TRACE, 0,
                        TEXT("Display Change during stream surface prepare")));
                //
                // The stream queues will have already been flushed of samples
                // and each sample released.  We reset nActiveStreams so that
                // we don't release the samples a second time.
                //
                ASSERT(!m_BufferQueue.GetNextSurface());

                for (i = 0; i < nActiveStreams; i++) {

                    ASSERT(lpSurfSamp[i] != NULL);
                    RELEASE(lpSurfSamp[i]);
                }
                nActiveStreams = 0;
            }

            //
            // tidy up
            //
            DbgLog((LOG_TRACE, 2, TEXT("EndTime = %I64d"), rtNextEndTime));

            for (i = 0; i < nActiveStreams; i++) {

                ASSERT(lpSurfSamp[i] != NULL);
                ASSERT(lpSample[i] != NULL);

                RELEASE(lpSurfSamp[i]);

                //
                // for each stream, work out dead samples and remove them
                // from that streams mixer queue
                //

                if (bActualSampleEnd[i] && rtEnd[i] <= rtNextEndTime) {

                    DbgLog((LOG_TRACE, 2,
                            TEXT("Discarding sample from stream %d with time %I64d"),
                            dwActiveStreamIDs[i], rtNextEndTime));

                    if (m_ppMixerStreams[dwActiveStreamIDs[i]]->RemoveNextStreamSample())
                    {
                        CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSample[i];

                        if (lpVMRSample->IsDXVASample()) {
                            lpVMRSample->SignalReleaseSurfaceEvent();
                        }
                        else {
                            lpVMRSample->Release();
                        }
                    }
                }
            }
        }

        m_ObjectLock.Unlock();
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\mixer\mixer.cpp ===
/******************************Module*Header*******************************\
* Module Name: AP.cpp
*
* The default DShow allocator presenter
*
*
* Created: Wed 02/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#ifdef FILTER_DLL
#include <initguid.h>
#endif

#include "mixerobj.h"
#if defined(CHECK_FOR_LEAKS)
#include "ifleak.h"
#endif

#ifdef FILTER_DLL
DEFINE_GUID(IID_IDirectDraw7,
            0x15e65ec0,0x3b9c,0x11d2,0xb9,0x2f,0x00,0x60,0x97,0x97,0xea,0x5b);

STDAPI DllRegisterServer()
{
    AMTRACE((TEXT("DllRegisterServer")));
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    AMTRACE((TEXT("DllUnregisterServer")));
    return AMovieDllRegisterServer2( FALSE );
}

CFactoryTemplate g_Templates[] = {
    {
        L"",
        &CLSID_VideoMixer,
        CVideoMixer::CreateInstance,
        CVideoMixer::InitClass,
        NULL
    }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);
#endif


/******************************Public*Routine******************************\
* CreateInstance
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CUnknown* CVideoMixer::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    AMTRACE((TEXT("CVMRFilter::CreateInstance")));
    return new CVideoMixer(pUnk, phr);
}


/******************************Public*Routine******************************\
* InitClass
*
*
*
* History:
* Thu 12/14/2000 - StEstrop - Created
*
\**************************************************************************/
#if defined(CHECK_FOR_LEAKS)

// the one and only g_IFLeak object.
CInterfaceLeak  g_IFLeak;

void
CVideoMixer::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
    if (bLoading) {
        DbgLog((LOG_TRACE, 0, TEXT("Mixer Thunks: Loaded\n") ));
        g_IFLeak.Init();
    }
    else {
        DbgLog((LOG_TRACE, 0, TEXT("Mixer Thunks: Unloaded") ));
        g_IFLeak.Term();
    }
}
#else
void
CVideoMixer::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
}
#endif


/******************************Public*Routine******************************\
* MixerThreadProc
*
*
*
* History:
* Wed 03/15/2000 - StEstrop - Created
*
\**************************************************************************/
DWORD WINAPI
CVideoMixer::MixerThreadProc(
    LPVOID lpParameter
    )
{
    CVideoMixer* lp = (CVideoMixer*)lpParameter;
    return lp->MixerThread();
}


/******************************Public*Routine******************************\
* CVideoMixer
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
#pragma warning(disable:4355)
CVideoMixer::CVideoMixer(LPUNKNOWN pUnk, HRESULT *phr)
    : CUnknown(NAME("Video Mixer"), pUnk),
    m_pBackEndAllocator(NULL),
    m_pImageSync(NULL),
    m_ImageCompositor(this),
    m_pImageCompositor(NULL),
    m_hThread(NULL),
    m_hMixerIdle(NULL),
    m_dwThreadID(0),
    m_MixingPrefs(MixerPref_NoDecimation |
                  MixerPref_BiLinearFiltering | MixerPref_RenderTargetRGB),
    m_pmt(NULL),
    m_ppMixerStreams(NULL),
    m_dwNumStreams(0),
    m_pDDSAppImage(NULL),
    m_hbmpAppImage(NULL),
    m_dwWidthAppImage(0),
    m_dwHeightAppImage(0),
    m_pDD(NULL),
    m_pD3D(NULL),
    m_pD3DDevice(NULL),
    m_pDDSTextureMirror(NULL),
    m_dwClrBorderMapped(0),
    m_clrBorder(RGB(0,0,0)),
    m_dwAppImageFlags(APPIMG_NOIMAGE)
//  m_fOverlayRT(FALSE),
//  m_dwInterlaceFlags(0),
//  m_dwTypeSpecificFlags(0)
{
    AMTRACE((TEXT("CVideoMixer::CVideoMixer")));
    HRESULT hr = SetImageCompositor(&m_ImageCompositor);
    if (FAILED(hr)) {
        *phr = hr;
    }

    ZeroMemory(&m_rcAppImageSrc, sizeof(m_rcAppImageSrc));

#ifdef DEBUG
    if (GetProfileIntA("VMR", "Decimate", 0)) {
        m_MixingPrefs |= MixerPref_DecimateOutput;
    }

    if (GetProfileIntA("VMR", "PointFiltering", 0)) {
        m_MixingPrefs &= ~MixerPref_FilteringMask;
        m_MixingPrefs |= MixerPref_PointFiltering;
    }

    //
    // BiLinear takes priority over Point Filtering.
    //
    if (GetProfileIntA("VMR", "BiLinearFiltering", 0)) {
        m_MixingPrefs &= ~MixerPref_FilteringMask;
        m_MixingPrefs |= MixerPref_BiLinearFiltering;
    }

    //
    // Sort out the render target.
    //
    if (GetProfileIntA("VMR", "RT_RGB", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetRGB;
    }
    else if (GetProfileIntA("VMR", "RT_YUV420", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetYUV420;
    }
    else if (GetProfileIntA("VMR", "RT_YUV422", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetYUV422;
    }
    else if (GetProfileIntA("VMR", "RT_YUV444", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetYUV444;
    }
    else if (GetProfileIntA("VMR", "RT_IMC3", 0)) {
        m_MixingPrefs &= ~MixerPref_RenderTargetMask;
        m_MixingPrefs |= MixerPref_RenderTargetIntelIMC3;
    }
#endif

}

/******************************Public*Routine******************************\
* CVideoMixer
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
CVideoMixer::~CVideoMixer()
{
    AMTRACE((TEXT("CVideoMixer::~CVideoMixer")));

    //
    // The mixer object must not be deleted on the mixers own
    // worker thread!
    //
    ASSERT(m_dwThreadID != GetCurrentThreadId());

    if (m_hbmpAppImage) {
        DeleteObject( m_hbmpAppImage );
    }

    RELEASE(m_pDDSTextureMirror);
    RELEASE(m_pDDSAppImage);

    FreeSurface();

    RELEASE(m_pImageCompositor);
    RELEASE(m_pBackEndAllocator);
    RELEASE(m_pImageSync);

    if (m_hThread) {
        for ( int i = 0; i < 100; i++ )
        {
            if ( 0 == PostThreadMessage(m_dwThreadID, WM_USER, 0, 0) )
                Sleep(0);
            else
                break;
        }

        WaitForSingleObject(m_hThread, INFINITE);
        CloseHandle(m_hThread);
    }

    if (m_hMixerIdle) {
        CloseHandle(m_hMixerIdle);
    }

    if (m_ppMixerStreams) {
        for (DWORD i = 0; i < m_dwNumStreams; i++) {
            delete m_ppMixerStreams[i];
        }
    }
    delete[] m_ppMixerStreams;

}


/******************************Public*Routine******************************\
* NonDelegatingQueryInterface
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVideoMixer::NonDelegatingQueryInterface(
    REFIID riid,
    void ** ppv)
{
    AMTRACE((TEXT("CVideoMixer::NonDelegatingQueryInterface")));

    HRESULT hr = E_NOINTERFACE;
    *ppv = NULL;

    if (riid == IID_IVMRMixerControlInternal) {
        hr = GetInterface((IVMRMixerControlInternal *)this, ppv);
    }
    else if (riid == IID_IVMRMixerStream) {
        hr =  GetInterface((IVMRMixerStream *)this, ppv);
    }
    else if (riid == IID_IVMRMixerBitmap) {
        hr = GetInterface((IVMRMixerBitmap *)this, ppv );
    }
    else {
        hr = CUnknown::NonDelegatingQueryInterface(riid,ppv);
    }

#if defined(CHECK_FOR_LEAKS)
    if (hr == S_OK) {
        _pIFLeak->AddThunk((IUnknown **)ppv, "Mixer Object",  riid);
    }
#endif

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\mixer\mixerobj.h ===
/******************************Module*Header*******************************\
* Module Name: MixerObj.h
*
* Declaration of the CVideoMixer
*
*
* Created: Wed 02/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

#include "alloclib.h"
#include "VMRuuids.h"
#include "CVMRMediaSample.h"
#include "MediaSType.h"
#include "vmrp.h"
#include <d3d.h>
#include "mixerDeinterlace.h"

#ifndef MAX_MIXER_STREAMS
#define MAX_MIXER_STREAMS   16
#endif

#define MAX_REFERENCE_TIME (REFERENCE_TIME)9223372036854775807i64

/////////////////////////////////////////////////////////////////////////////
// CVMRMixerBufferQueue
//
// Simple queue of DDraw Surfaces - we get buffers from the front of the
// queue and return them to the end of the queue.  The queue itself is just
// an array of DDraw Surface pointers.  When each buffer is returned we shift
// entire array "up" one notch and then save the returned surface at the end
// of the array.
//
#if ALLOCATOR_IS_USING_DIRECTED_FLIPS
class CVMRMixerBufferQueue
{
private:
    DWORD                   m_dwAllocated;
    LPDIRECTDRAWSURFACE7    *m_lpDDSurf;

public:
    CVMRMixerBufferQueue() : m_dwAllocated(0), m_lpDDSurf(NULL)
    {};

    HRESULT InitBufferQueue(LPDIRECTDRAWSURFACE7 lpDDSurf)
    {
        ASSERT(m_lpDDSurf == NULL);
        ASSERT(m_dwAllocated == 0);

        DWORD dwBuffCount;
        DDSURFACEDESC2 ddSurfaceDesc;
        INITDDSTRUCT(ddSurfaceDesc);

        HRESULT hr = lpDDSurf->GetSurfaceDesc(&ddSurfaceDesc);
        if (FAILED(hr)) {
            return hr;
        }

        dwBuffCount = 1;
        if ((ddSurfaceDesc.dwFlags & DDSD_BACKBUFFERCOUNT) &&
            (ddSurfaceDesc.dwBackBufferCount > 0)) {

            dwBuffCount = ddSurfaceDesc.dwBackBufferCount;
        }

        //
        // allocate the new stuff
        //
        m_lpDDSurf = new LPDIRECTDRAWSURFACE7[dwBuffCount];
        if (!m_lpDDSurf) {
            return E_OUTOFMEMORY;
        }
        ZeroMemory(m_lpDDSurf, sizeof(LPDIRECTDRAWSURFACE7) * dwBuffCount);
        m_dwAllocated = dwBuffCount;


        if ((ddSurfaceDesc.dwFlags & DDSD_BACKBUFFERCOUNT) &&
            (ddSurfaceDesc.dwBackBufferCount > 0)) {

            //
            // fill in the array
            //
            ddSurfaceDesc.ddsCaps.dwCaps &= ~(DDSCAPS_FRONTBUFFER |
                                              DDSCAPS_VISIBLE);

            for (DWORD i = 0; i < dwBuffCount; i++) {

                hr = lpDDSurf->GetAttachedSurface(&ddSurfaceDesc.ddsCaps,
                                                  &m_lpDDSurf[i]);
                if (FAILED(hr)) {
                    break;
                }
                lpDDSurf = m_lpDDSurf[i];
            }
        }
        else {

            ASSERT(m_dwAllocated == 1);
            m_lpDDSurf[0] = lpDDSurf;
        }

        return hr;
    };

    void TermBufferQueue()
    {
        //
        // delete the old stuff
        //
        if (m_lpDDSurf) {

            ASSERT(m_dwAllocated > 0);
            for (DWORD i = 0; i < m_dwAllocated; i++) {
                RELEASE(m_lpDDSurf[i]);
            }
        }

        delete m_lpDDSurf;

        m_lpDDSurf = NULL;
        m_dwAllocated = 0;
    };


    LPDIRECTDRAWSURFACE7 GetNextSurface()
    {
        return m_lpDDSurf[0];
    };

    void FreeSurface(LPDIRECTDRAWSURFACE7 lpDDSurf)
    {
        if (m_lpDDSurf) {
            ASSERT(lpDDSurf == m_lpDDSurf[0]);

            if (m_dwAllocated > 1) {
                MoveMemory(&m_lpDDSurf[0], &m_lpDDSurf[1],
                           sizeof(LPDIRECTDRAWSURFACE7) * (m_dwAllocated - 1));
                m_lpDDSurf[m_dwAllocated - 1] = lpDDSurf;
            }
        }
    }
};

#else

class CVMRMixerBufferQueue
{
private:
    LPDIRECTDRAWSURFACE7    m_lpDDSurf;

public:
    CVMRMixerBufferQueue() : m_lpDDSurf(NULL)
    {};

    HRESULT InitBufferQueue(LPDIRECTDRAWSURFACE7 lpDDSurf)
    {
        DWORD dwBuffCount;
        DDSURFACEDESC2 ddSurfaceDesc;
        INITDDSTRUCT(ddSurfaceDesc);

        HRESULT hr = lpDDSurf->GetSurfaceDesc(&ddSurfaceDesc);
        if (FAILED(hr)) {
            return hr;
        }

        //
        // Overlay surfaces have these flags set, we need to remove
        // these flags prior to calling GetAttachedSurface
        //
        ddSurfaceDesc.ddsCaps.dwCaps &= ~(DDSCAPS_FRONTBUFFER |
                                          DDSCAPS_VISIBLE);

        hr = lpDDSurf->GetAttachedSurface(&ddSurfaceDesc.ddsCaps,
                                          &m_lpDDSurf);
        return hr;
    }

    LPDIRECTDRAWSURFACE7 GetNextSurface()
    {
        return m_lpDDSurf;
    }

    void FreeSurface(LPDIRECTDRAWSURFACE7 lpDDSurf)
    {
    }

    void TermBufferQueue()
    {
        //
        // Release the "attached" surface - this does not make
        // the surface go away because the front buffer still has a
        // reference on the attached surface.  Release the front buffer,
        // which is done in the allocator/presenter, releases this for real.
        //
        RELEASE(m_lpDDSurf);
    }
};

#endif


/////////////////////////////////////////////////////////////////////////////
// CVMRMixerQueue
class CVMRMixerQueue
{

private:
    HANDLE              m_hSem;     // Semaphore controlling queue "getting"
    CCritSec            m_CritSect; // Thread seriallization
    long                m_lWaiting; // Waiting for a free element

    class CSampleList;
    friend class CSampleList;

    /*  Hack to get at protected member in CVMRMediaSample */
    static CVMRMediaSample * &NextSample(CVMRMediaSample *pSample)
    {
        return pSample->m_lpMixerQueueNext;
    };

    /*  Mini list class for the free list */
    class CSampleList
    {
    public:
        CSampleList() : m_List(NULL), m_nOnList(0) {};

#ifdef DEBUG
        ~CSampleList()
        {
            ASSERT(m_nOnList == 0);
        };
#endif
        int GetCount() const;
        void AddTail(CVMRMediaSample *pSample);
        CVMRMediaSample* RemoveHead();
        CVMRMediaSample* PeekHead();

    public:
        CVMRMediaSample *m_List;
        int           m_nOnList;
    };

    CSampleList m_lFree;        // Free list

public:
    CVMRMixerQueue(HRESULT *phr);
    ~CVMRMixerQueue();
    DWORD GetSampleFromQueueNoWait(IMediaSample** lplpMediaSample);
    DWORD GetSampleFromQueueNoRemove(HANDLE hNotActive,
                                     IMediaSample** lplpMediaSample);
    BOOL  RemoveSampleFromQueue();
    DWORD PutSampleOntoQueue(IMediaSample* lpSample);

    bool CheckValid() {
        if (m_lWaiting != 0) return false;
        if (m_lFree.m_List == NULL) return false;
        if (m_lFree.m_nOnList == 0) return false;
        return true;
    }
};


/////////////////////////////////////////////////////////////////////////////
// CVideoMixerStream
class CVideoMixerStream
{
private:
    CCritSec                m_ObjectLock;  // Controls access to internals
    DWORD                   m_dwID;
    BOOL                    m_fStreamConnected;
    BOOL                    m_fActive;
    BOOL                    m_bWasActive;
    float                   m_fAlpha;
    DWORD                   m_dwZOrder;
    NORMALIZEDRECT          m_rOutputRect;
    DDCOLORKEY              m_ClrKey;
    CVMRMixerQueue          m_SampleQueue;
    AM_MEDIA_TYPE           m_mt;
    HANDLE                  m_hNotActive;
    HANDLE                  m_hActive;
    BOOL                    m_bFlushing;
    DWORD                   m_dwSurfaceFlags;

    CDeinterlaceDevice*     m_pDeinterlaceDev;
    LPDIRECTDRAWSURFACE7    m_pddsDeinterlaceDst;
    GUID                    m_DeinterlaceDevGUID;
    DXVA_DeinterlaceCaps    m_DeinterlaceCaps;
    BOOL                    m_fDeinterlaceDstTexture;
    REFERENCE_TIME          m_rtDeinterlacedFrameStart;
    REFERENCE_TIME          m_rtDeinterlacedFrameEnd;
    IMediaSample*           m_pSample;
    DWORD                   m_dwInterlaceFlags;
    RECT                    m_rcSurface;

public:
    CVideoMixerStream(DWORD dwID, HRESULT* phr);
    ~CVideoMixerStream();

    HRESULT SetStreamSample(IMediaSample* lpSample);

    IMediaSample* GetNextStreamSample() {

        AMTRACE((TEXT("CVideoMixerStream::GetNextStreamSample")));

        IMediaSample* pSample = NULL;
        {
            CAutoLock Lock(&m_ObjectLock);
            if (m_bFlushing) {

                DbgLog((LOG_TRACE, 2, TEXT("GetNextStreamSample: Flushing stream %d"), m_dwID ));

                IMediaSample* lpSampTemp;

                while (m_SampleQueue.GetSampleFromQueueNoWait(&lpSampTemp)) {

                    CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSampTemp;
                    m_SampleQueue.RemoveSampleFromQueue();

                    if (lpVMRSample->IsDXVASample()) {
                        lpVMRSample->SignalReleaseSurfaceEvent();
                    }
                    else {
                        lpVMRSample->Release();
                    }
                }
                m_pSample = NULL;
                return NULL;
            }
        }
        m_SampleQueue.GetSampleFromQueueNoRemove(m_hNotActive, &pSample);
        m_pSample = pSample;
        return pSample;
    }

    BOOL RemoveNextStreamSample() {
        AMTRACE((TEXT("CVideoMixerStream::RemoveNextStreamSample")));
        BOOL b = m_SampleQueue.RemoveSampleFromQueue();
        m_pSample = NULL;
        return b;
    }

    HANDLE GetActiveHandle() {
        AMTRACE((TEXT("CVideoMixerStream::GetActiveHandle")));
        return m_hActive;
    }

    bool CheckQValid() {
        AMTRACE((TEXT("CVideoMixerStream::CheckQValid")));
        return m_SampleQueue.CheckValid();
    }

    HRESULT BeginFlush();
    HRESULT EndFlush();

    bool CheckFlushing() {

        AMTRACE((TEXT("CVideoMixerStream::CheckFlushing")));
        CAutoLock Lock(&m_ObjectLock);
        if (m_bFlushing) {

            IMediaSample* lpSampTemp;
            if (m_SampleQueue.GetSampleFromQueueNoWait(&lpSampTemp)) {

                CVMRMediaSample* lpVMRSample = (CVMRMediaSample*)lpSampTemp;
                m_SampleQueue.RemoveSampleFromQueue();

                if (lpVMRSample->IsDXVASample()) {
                    lpVMRSample->SignalReleaseSurfaceEvent();
                }
                else {
                    lpVMRSample->Release();
                }
                return true;
            }
        }
        return false;
    }

    HRESULT SetStreamMediaType(AM_MEDIA_TYPE* pmt, DWORD dwSurfaceFlags );
    HRESULT GetStreamMediaType(AM_MEDIA_TYPE* pmt, DWORD* pdwSurfaceFlags = NULL);
    HRESULT SetStreamActiveState(BOOL fActive);
    HRESULT GetStreamActiveState(BOOL* lpfActive);
    HRESULT SetStreamColorKey(LPDDCOLORKEY lpClrKey);
    HRESULT GetStreamColorKey(LPDDCOLORKEY lpClrKey);
    HRESULT SetStreamColorKey(DWORD dwClr);
    HRESULT GetStreamColorKey(DWORD *lpdwClr);
    HRESULT SetStreamAlpha(float Alpha);
    HRESULT GetStreamAlpha(float* lpAlpha);
    HRESULT SetStreamZOrder(DWORD ZOrder);
    HRESULT GetStreamZOrder(DWORD* pdwZOrder);
    HRESULT SetStreamOutputRect(const NORMALIZEDRECT* pRect );
    HRESULT GetStreamOutputRect(NORMALIZEDRECT* pRect);

    BOOL    IsStreamConnected() {
        return m_fStreamConnected;
    }

    HRESULT CreateDeinterlaceDevice(LPDIRECTDRAW7 pDD, LPGUID lpGuid,
                                    DXVA_DeinterlaceCaps* pCaps, DWORD dwTexCaps);
    HRESULT DestroyDeinterlaceDevice();

    BOOL    IsStreamTwoInterlacedFields();
    BOOL    IsStreamInterlaced();
    BOOL    IsDeinterlaceDestATexture();
    BOOL    CanBeDeinterlaced();
    LPDIRECTDRAWSURFACE7 GetDeinterlaceDestSurface();

    HRESULT DeinterlaceStream(REFERENCE_TIME rtStart, LPRECT lprcDst,
                              LPDIRECTDRAWSURFACE7 pddDst, LPRECT lprcSrc,
                              BOOL fDestRGB);

    HRESULT DeinterlaceStreamWorker(REFERENCE_TIME rtStart, LPRECT lprcDst,
                                    LPDIRECTDRAWSURFACE7 pddDst,
                                    LPRECT lprcSrc, bool fUpdateTimes);
};



/////////////////////////////////////////////////////////////////////////////
// CVideoMixer
class CVideoMixer :
    public CUnknown,
    public IVMRMixerControlInternal,
    public IVMRMixerStream,
    public IVMRMixerBitmap
{
public:
    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void**);
    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    static void InitClass(BOOL bLoading, const CLSID *clsid);
    static DWORD WINAPI MixerThreadProc(LPVOID lpParameter);

    CVideoMixer(LPUNKNOWN pUnk, HRESULT *phr);
    virtual ~CVideoMixer();

// IVMRMixerControlInternal
public:
    STDMETHODIMP SetBackEndAllocator(IVMRSurfaceAllocator* lpAllocator,
                                     DWORD_PTR dwUserID);
    STDMETHODIMP SetBackEndImageSync(IImageSync* lpImageSync);
    STDMETHODIMP SetImageCompositor(IVMRImageCompositor* lpVMRImgCompositor);
    STDMETHODIMP SetNumberOfStreams(DWORD dwMaxStreams);
    STDMETHODIMP GetNumberOfStreams(DWORD* lpdwMaxStreams);
    STDMETHODIMP DisplayModeChanged();
    STDMETHODIMP WaitForMixerIdle(DWORD dwTimeOut);
    STDMETHODIMP SetBackgroundColor(COLORREF clr);
    STDMETHODIMP GetBackgroundColor(COLORREF* clr);
    STDMETHODIMP SetMixingPrefs(DWORD dwMixerPrefs);
    STDMETHODIMP GetMixingPrefs(DWORD* pdwMixerPrefs);

// IVMRMixerStream
public:
    STDMETHODIMP QueueStreamMediaSample(DWORD dwStreamID,
                                        IMediaSample* lpSample);

    STDMETHODIMP BeginFlush(DWORD dwStreamID);
    STDMETHODIMP EndFlush(DWORD dwStreamID);

    STDMETHODIMP SetStreamMediaType(DWORD dwStreamID, AM_MEDIA_TYPE* pmt,
                                    DWORD dwSurfFlags, LPGUID lpDeInt,
                                    DXVA_DeinterlaceCaps* lpCaps);
    STDMETHODIMP SetStreamActiveState(DWORD dwStreamID,BOOL fActive);
    STDMETHODIMP GetStreamActiveState(DWORD dwStreamID,BOOL* lpfActive);
    STDMETHODIMP SetStreamColorKey(DWORD dwStreamID, LPDDCOLORKEY lpClrKey);
    STDMETHODIMP GetStreamColorKey(DWORD dwStreamID, LPDDCOLORKEY lpClrKey);
    STDMETHODIMP SetStreamAlpha(DWORD dwStreamID,float Alpha);
    STDMETHODIMP GetStreamAlpha(DWORD dwStreamID,float* lpAlpha);
    STDMETHODIMP SetStreamZOrder(DWORD dwStreamID,DWORD Z);
    STDMETHODIMP GetStreamZOrder(DWORD dwStreamID,DWORD* pZ);
    STDMETHODIMP SetStreamOutputRect( DWORD dwStreamID,const NORMALIZEDRECT *pRect );
    STDMETHODIMP GetStreamOutputRect( DWORD dwStreamID,NORMALIZEDRECT* pRect );

// IVMRMixerBitmap
public:
    STDMETHODIMP SetAlphaBitmap( const VMRALPHABITMAP *pBmpParms );
    STDMETHODIMP UpdateAlphaBitmapParameters( PVMRALPHABITMAP pBmpParms );
    STDMETHODIMP GetAlphaBitmapParameters( PVMRALPHABITMAP pBmpParms );

    class CIIVMRImageCompositor : public IVMRImageCompositor {
    private:

            struct {
                AM_MEDIA_TYPE   mt;
                BOOL            fTexture;
            } StrmProps[MAX_MIXER_STREAMS];

            LONG            m_cRef;
            CVideoMixer*    m_pObj;

        HRESULT OptimizeBackground(
            REFERENCE_TIME rtStart,
            LPDIRECTDRAWSURFACE7 pDDSBack,
            LPRECT lpDst,
            const VMRVIDEOSTREAMINFO* ps,
            DWORD dwMappedBdrClr,
            UINT* uStart
            );

    public:

        CIIVMRImageCompositor(CVideoMixer* pObj) :
            m_cRef(0), m_pObj(pObj)
        {
            ZeroMemory(&StrmProps, sizeof(StrmProps));
        }

        ~CIIVMRImageCompositor()
        {
            for (UINT i = 0; i < MAX_MIXER_STREAMS; i++ )
            {
                FreeMediaType(StrmProps[i].mt);
            }
        }

        STDMETHODIMP_(ULONG) AddRef()
        {
            return (ULONG)++m_cRef;
        }

        STDMETHODIMP_(ULONG) Release()
        {
            return (ULONG)--m_cRef;
        }

        STDMETHODIMP QueryInterface(REFIID riid, void **ppv)
        {
            return m_pObj->QueryInterface(riid, ppv);
        }


        STDMETHODIMP InitCompositionTarget(
            IUnknown* pD3DDevice,
            LPDIRECTDRAWSURFACE7 pddsRenderTarget);

        STDMETHODIMP TermCompositionTarget(
            IUnknown* pD3DDevice,
            LPDIRECTDRAWSURFACE7 pddsRenderTarget);

        STDMETHODIMP SetStreamMediaType(
            DWORD dwStrmID,
            AM_MEDIA_TYPE *pmt,
            BOOL fTexture);

        STDMETHODIMP CompositeImage(
            IUnknown* pD3DDevice,
            LPDIRECTDRAWSURFACE7 pddsRenderTarget,
            AM_MEDIA_TYPE* pmtRenderTarget,
            REFERENCE_TIME rtStart,
            REFERENCE_TIME rtEnd,
            DWORD dwclrBkGnd,
            VMRVIDEOSTREAMINFO* pVideoStreamInfo,
            UINT cStreams
            );

        STDMETHODIMP SpecialIMC3Composite(
            LPDIRECTDRAWSURFACE7 pDDSBack,
            LPRECT lpTarget,
            VMRVIDEOSTREAMINFO* pStrmInfo,
            UINT i,
            UINT cStreams
            );
    };

private:
    friend class CIIVMRImageCompositor;
    CCritSec                m_ObjectLock;  // Controls access to internals
    DWORD_PTR               m_dwUserID;
    IVMRSurfaceAllocator*   m_pBackEndAllocator;
    IImageSync*             m_pImageSync;
    DWORD                   m_dwTextureCaps;
    LPDIRECTDRAW7           m_pDD;
    LPDIRECT3D7             m_pD3D;
    LPDIRECT3DDEVICE7       m_pD3DDevice;
    DWORD                   m_dwNumStreams;
    CVideoMixerStream**     m_ppMixerStreams;

    HANDLE                  m_hMixerIdle;
    HANDLE                  m_hThread;
    DWORD                   m_dwThreadID;
    DWORD                   m_dwCurrMonBitCount;
    DDCAPS_DX7              m_ddHWCaps;
    DWORD                   m_MixingPrefs;

    AM_MEDIA_TYPE*          m_pmt;
    CVMRMixerBufferQueue    m_BufferQueue;

    IVMRImageCompositor*    m_pImageCompositor;
    CIIVMRImageCompositor   m_ImageCompositor;

    NORMALIZEDRECT          m_rDest;
    float                   m_fAlpha;
    COLORREF                m_clrTrans;
    DWORD                   m_dwClrTransMapped;
    COLORREF                m_clrBorder;
    DWORD                   m_dwClrBorderMapped;

    // vidmem mirror of the app image
    LPDIRECTDRAWSURFACE7    m_pDDSAppImage;
    float                   m_fAppImageTexWid, m_fAppImageTexHgt;
    RECT                    m_rcAppImageSrc;

    // bitmap with system memory backup of the app image
    HBITMAP                 m_hbmpAppImage;

    // width and height of app image
    DWORD                   m_dwWidthAppImage, m_dwHeightAppImage;

    enum {APPIMG_NOIMAGE     = 0, APPIMG_DDSURFARGB32 = 1,
          APPIMG_DDSURFRGB32 = 2, APPIMG_HBITMAP      = 4};
    DWORD                   m_dwAppImageFlags;


    // local vidmem texture mirror
    LPDIRECTDRAWSURFACE7    m_pDDSTextureMirror;

    // de-interlace information
    //BOOL                    m_fOverlayRT;
    //DWORD                   m_dwInterlaceFlags;
    //DWORD                   m_dwTypeSpecificFlags;

private:
    HRESULT ValidateStream(DWORD dwStrmID) {
        if (dwStrmID >= m_dwNumStreams) {
            return E_INVALIDARG;
        }
        return S_OK;
    }
    HRESULT CreateAppImageMirror( );
    HRESULT BlendAppImage(LPDIRECTDRAWSURFACE7 pDDS, LPDIRECT3DDEVICE7 pD3DDevice);
    HRESULT CompositeStreams(LPDIRECTDRAWSURFACE7 pDDSBack, LPDIRECT3DDEVICE7 pD3DDevice,
                             REFERENCE_TIME rtStart, REFERENCE_TIME rtEnd,
                             LPDIRECTDRAWSURFACE7 *ppDDSSamples,
                             DWORD dwStrmIDs[],
                             UINT cStreams );

    HRESULT AllocateSurface(const AM_MEDIA_TYPE* pmt, DWORD* lpdwBufferCount, AM_MEDIA_TYPE** ppmt);
    void    FreeSurface();

    HRESULT AllocateTextureMirror( DWORD dwWidth, DWORD dwHeight );

    DWORD MixerThread();

    HRESULT RecomputeTargetSizeFromAllStreams(LONG* plWidth, LONG* plHeight);
};


BOOL __inline SpecialIMC3Mode(DWORD dwMixerPrefs)
{
    return (MixerPref_RenderTargetIntelIMC3 ==
                    (dwMixerPrefs & MixerPref_RenderTargetMask));
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\video\vmrallocator.cpp ===
/******************************Module*Header*******************************\
* Module Name: VMRAllocator.cpp
*
*
*
*
* Created: Tue 02/15/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>

#include "VMRenderer.h"

#if defined(CHECK_FOR_LEAKS)
#include "ifleak.h"
#endif

/******************************Public*Routine******************************\
* CVMRPinAllocator::CVMRPinAllocator
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
CVMRPinAllocator::CVMRPinAllocator(
    CVMRInputPin* pPin,
    CCritSec *pLock,
    HRESULT *phr
    ) :
    CBaseAllocator(NAME("Video Allocator"), NULL, phr, true, true),
    m_pPin(pPin),
    m_pInterfaceLock(pLock)
{
    AMTRACE((TEXT("CVMRPinAllocator::CVMRPinAllocator")));
}


/******************************Public*Routine******************************\
* NonDelegatingAddRef
*
* Overriden to increment the owning object's reference count
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP_(ULONG)
CVMRPinAllocator::NonDelegatingAddRef()
{
    AMTRACE((TEXT("CVMRPinAllocator::NonDelegatingAddRef")));
    return m_pPin->AddRef();
}

/******************************Public*Routine******************************\
* NonDelegatingQueryInterface
*
*
*
* History:
* Thu 12/14/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRPinAllocator::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    HRESULT hr = E_NOINTERFACE;
    *ppv = NULL;

    hr = CBaseAllocator::NonDelegatingQueryInterface(riid,ppv);

#if defined(CHECK_FOR_LEAKS)
    if (hr == S_OK) {
        _pIFLeak->AddThunk((IUnknown **)ppv, "VMR Allocator Object",  riid);
    }
#endif

    return hr;

}

/******************************Public*Routine******************************\
* NonDelegatingRelease
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP_(ULONG)
CVMRPinAllocator::NonDelegatingRelease()
{
    AMTRACE((TEXT("CVMRPinAllocator::NonDelegatingRelease")));
    return m_pPin->Release();
}


/******************************Public*Routine******************************\
* SetProperties
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRPinAllocator::SetProperties(
    ALLOCATOR_PROPERTIES* pRequest,
    ALLOCATOR_PROPERTIES* pActual
    )
{
    AMTRACE((TEXT("CVMRPinAllocator::SetProperties")));

    HRESULT hr = CBaseAllocator::SetProperties(pRequest, pActual);
    if (SUCCEEDED(hr)) {
        hr = m_pPin->OnSetProperties(pRequest, pActual);
    }
    else {
        DbgLog((LOG_ERROR, 1,
                TEXT("CBaseAllocator::SetProperties failed hr=%#X"), hr));
    }

    if (SUCCEEDED(hr)) {
        hr = m_pPin->m_pRenderer->OnSetProperties(m_pPin);
    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRPinAllocator::GetBuffer
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRPinAllocator::GetBuffer(
    IMediaSample **ppSample,
    REFERENCE_TIME *pStartTime,
    REFERENCE_TIME *pEndTime,
    DWORD dwFlags
    )
{
    AMTRACE((TEXT("CVMRPinAllocator::GetBuffer")));
    HRESULT hr = S_OK;
    IMediaSample *pSample = NULL;

    hr = CBaseAllocator::GetBuffer(&pSample, pStartTime, pEndTime, dwFlags);
    DbgLog((LOG_TRACE, 2, TEXT("pSample= %#X"), pSample));

    if (SUCCEEDED(hr)) {

        hr = m_pPin->OnGetBuffer(pSample, pStartTime, pEndTime, dwFlags);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 1, TEXT("CVMRPin::OnGetBuffer failed hr= %#X"), hr));
        }
    }
    else {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseAllocator::GetBuffer failed hr= %#X"), hr));
    }

    if (FAILED(hr) && pSample) {
        pSample->Release();
        pSample = NULL;
    }

    *ppSample = pSample;
    return hr;
}


/******************************Public*Routine******************************\
* CVMRPinAllocator::ReleaseBuffer
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRPinAllocator::ReleaseBuffer(
    IMediaSample *pMediaSample
    )
{
    AMTRACE((TEXT("CVMRPinAllocator::ReleaseBuffer")));
    DbgLog((LOG_TRACE, 2, TEXT("pMediaSample= %#X"), pMediaSample));

    CVMRMediaSample* pVMRSample = (CVMRMediaSample*)pMediaSample;
    LPBYTE lpSample;
    HRESULT hr = S_OK;

    if (m_pPin->m_pVidSurfs) {
        CAutoLock l(&m_pPin->m_DeinterlaceLock);
        DWORD i = pVMRSample->GetIndex();
        m_pPin->m_pVidSurfs[i].InUse = FALSE;
    }

    if (S_OK == pVMRSample->IsSurfaceLocked()) {
        hr = pVMRSample->UnlockSurface();
        if (hr == DDERR_SURFACELOST) {
            hr = S_OK;
        }
    }

    if (SUCCEEDED(hr)) {

        // Copy of base class code - put at end of the list

        CheckPointer(pMediaSample, E_POINTER);
        ValidateReadPtr(pMediaSample, sizeof(IMediaSample));
        BOOL bRelease = FALSE;
        {
            CAutoLock cal(this);

            /* Put back on the free list */

            CMediaSample **ppTail;
            for (ppTail = &m_lFree.m_List; *ppTail;
                ppTail = &((CVMRMediaSample *)(*ppTail))->Next()) {
            }
            *ppTail = (CMediaSample *)pMediaSample;
            ((CVMRMediaSample *)pMediaSample)->Next() = NULL;
            m_lFree.m_nOnList++;

            if (m_lWaiting != 0) {
                NotifySample();
            }

            // if there is a pending Decommit, then we need to complete it by
            // calling Free() when the last buffer is placed on the free list

            LONG l1 = m_lFree.GetCount();
            if (m_bDecommitInProgress && (l1 == m_lAllocated)) {
                Free();
                m_bDecommitInProgress = FALSE;
                bRelease = TRUE;
            }
        }

        if (m_pNotify) {
            m_pNotify->NotifyRelease();
        }
        // For each buffer there is one AddRef, made in GetBuffer and released
        // here. This may cause the allocator and all samples to be deleted
        if (bRelease)
        {
            Release();
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* CVMRPinAllocator::Alloc
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRPinAllocator::Alloc()
{
    AMTRACE((TEXT("CVMRPinAllocator::Alloc")));

    ASSERT(m_lAllocated == 0);

    HRESULT hr = S_OK;
    CVMRMediaSample** ppSampleList = NULL;
    LONG lToAllocate;

    lToAllocate = m_lCount;

    if (m_pPin->m_dwBackBufferCount > 1) {
        lToAllocate++;
    }

    ppSampleList = new CVMRMediaSample*[lToAllocate];
    if (!ppSampleList) {
        DbgLog((LOG_ERROR, 1, TEXT("new failed - trying to allocate %d bytes"), lToAllocate));
        return E_OUTOFMEMORY;
    }

    for (LONG i = 0; i < lToAllocate; i++) {

        ppSampleList[i] = new CVMRMediaSample(TEXT("VMRMediaSample"),
                                              this, &hr, NULL, 0);
        if (!ppSampleList[i]) {
            DbgLog((LOG_ERROR, 1, TEXT("new failed - trying to allocate %d bytes"),
                    sizeof(CVMRMediaSample)));
            DbgLog((LOG_ERROR, 1, TEXT("new failed")));
            for (LONG j = 0; j < i; j++ )
                delete ppSampleList[j];
            delete [] ppSampleList;
            return E_OUTOFMEMORY;
        }

        if (FAILED(hr)) {
            delete ppSampleList[i];
            DbgLog((LOG_ERROR, 1, TEXT("CVMRMediaSample constructor failed")));
            break;
        }

        // Add the completed sample to the available list
        m_lAllocated++;
        m_lFree.Add(ppSampleList[i]);
    }

    if (SUCCEEDED(hr)) {
        hr = m_pPin->OnAlloc(ppSampleList, lToAllocate);

        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 1, TEXT("m_pPin->OnAlloc(), hr = 0x%x"), hr));
            Free();
        }
    }

    delete [] ppSampleList;

    return hr;
}


/******************************Public*Routine******************************\
* CVMRPinAllocator::Free()
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
void
CVMRPinAllocator::Free()
{
    AMTRACE((TEXT("CVMRPinAllocator::Free")));

    ASSERT(m_lAllocated == m_lFree.GetCount());
    CVMRMediaSample *pSample;

    while (m_lFree.GetCount() != 0) {
        pSample = (CVMRMediaSample *) m_lFree.RemoveHead();
        delete pSample;
    }

    m_lAllocated = 0;
    DbgLog((LOG_TRACE,2,TEXT("All buffers free on pin#%d"), m_pPin->m_dwPinID));
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\video\vmrdeinterlace.cpp ===
/******************************Module*Header*******************************\
* Module Name: VMRDeinterlace.cpp
*
*
*
*
* Created: Wed 03/13/2002
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2002 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include "vmrenderer.h"




/******************************Public*Routine******************************\
* CVMRDeinterlaceContainer
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
CVMRDeinterlaceContainer::CVMRDeinterlaceContainer(
    LPDIRECTDRAW7 pDD,
    HRESULT* phr
    ) :
    m_pIDDVAContainer(NULL),
    m_pIDDVideoAccelerator(NULL)
{
    HRESULT hr = DD_OK;

    __try {

        CHECK_HR(hr = pDD->QueryInterface(IID_IDDVideoAcceleratorContainer,
                                          (void**)&m_pIDDVAContainer));

        GUID guid;
        DDVAUncompDataInfo UncompInfo = {sizeof(DDVAUncompDataInfo), 0, 0, 0};
        CopyMemory(&guid, &DXVA_DeinterlaceContainerDevice, sizeof(GUID));

        CHECK_HR(hr = m_pIDDVAContainer->CreateVideoAccelerator(
                                                &guid, &UncompInfo,
                                                NULL, 0,
                                                &m_pIDDVideoAccelerator,
                                                NULL));
    }
    __finally {

        if (hr != DD_OK) {
            RELEASE(m_pIDDVideoAccelerator);
            RELEASE(m_pIDDVAContainer);
            *phr = hr;
        }
    }
}

/******************************Public*Routine******************************\
* ~CVMRDeinterlaceContainer
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
CVMRDeinterlaceContainer::~CVMRDeinterlaceContainer()
{
    RELEASE(m_pIDDVideoAccelerator);
    RELEASE(m_pIDDVAContainer);
}



/******************************Public*Routine******************************\
* QueryAvailableModes
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRDeinterlaceContainer::QueryAvailableModes(
    LPDXVA_VideoDesc lpVideoDescription,
    LPDWORD lpdwNumModesSupported,
    LPGUID pGuidsDeinterlaceModes
    )
{
    // lpInput => DXVA_VideoDesc*
    // lpOuput => DXVA_DeinterlaceQueryAvailableModes*

    DXVA_DeinterlaceQueryAvailableModes qam;
    qam.Size     = sizeof(DXVA_DeinterlaceQueryAvailableModes);
    qam.NumGuids = MAX_DEINTERLACE_DEVICE_GUIDS;
    ZeroMemory(&qam.Guids[0], MAX_DEINTERLACE_DEVICE_GUIDS);

    HRESULT hr = m_pIDDVideoAccelerator->Execute(
                    DXVA_DeinterlaceQueryAvailableModesFnCode,
                    (LPVOID)lpVideoDescription, sizeof(LPDXVA_VideoDesc),
                    &qam, sizeof(qam),
                    0, NULL);

    if (hr == DD_OK) {

        DWORD NumGUIDs;

        if (pGuidsDeinterlaceModes) {
            NumGUIDs = min(*lpdwNumModesSupported, qam.NumGuids);
            for (DWORD i = 0; i < NumGUIDs; i++) {
                pGuidsDeinterlaceModes[i] = qam.Guids[i];
            }
        }
        else {
             NumGUIDs = qam.NumGuids;
        }

        *lpdwNumModesSupported = NumGUIDs;
    }

    return hr;
}


/******************************Public*Routine******************************\
* QueryModeCaps
*
*
*
* History:
* Thu 02/28/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRDeinterlaceContainer::QueryModeCaps(
    LPGUID pGuidDeinterlaceMode,
    LPDXVA_VideoDesc lpVideoDescription,
    LPDXVA_DeinterlaceCaps lpDeinterlaceCaps
    )
{
    // lpInput => DXVA_DeinterlaceQueryModeCaps*
    // lpOuput => DXVA_DeinterlaceCaps*

    DXVA_DeinterlaceQueryModeCaps qmc;
    qmc.Size = sizeof(DXVA_DeinterlaceQueryModeCaps),
    qmc.Guid = *pGuidDeinterlaceMode;
    qmc.VideoDesc = *lpVideoDescription;

    HRESULT hr = m_pIDDVideoAccelerator->Execute(
                    DXVA_DeinterlaceQueryModeCapsFnCode,
                    &qmc, sizeof(qmc),
                    lpDeinterlaceCaps, sizeof(DXVA_DeinterlaceCaps),
                    0, NULL);

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\mixer\mixerqueue.cpp ===
/******************************Module*Header*******************************\
* Module Name: mixerQueue.cpp
*
*
*
*
* Created: Thu 03/23/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#include "mixerobj.h"


int
CVMRMixerQueue::CSampleList::GetCount() const
{
    return m_nOnList;
};

void
CVMRMixerQueue::CSampleList::AddTail(
    CVMRMediaSample *pSample
    )
{
    CVMRMediaSample **ppTail = &m_List;

    while (*ppTail) {
        ppTail = &(CVMRMixerQueue::NextSample(*ppTail));
    }

    *ppTail = (CVMRMediaSample *)pSample;
    CVMRMixerQueue::NextSample(pSample) = NULL;
    m_nOnList++;
};


CVMRMediaSample*
CVMRMixerQueue::CSampleList::RemoveHead()
{
    CVMRMediaSample *pSample = m_List;
    if (pSample != NULL) {
        m_List = CVMRMixerQueue::NextSample(m_List);
        m_nOnList--;
    }
    return pSample;
};


CVMRMediaSample*
CVMRMixerQueue::CSampleList::PeekHead()
{
    return m_List;
};


CVMRMixerQueue::CVMRMixerQueue(
    HRESULT *phr
    ) :
    m_lWaiting(0)
{
    AMTRACE((TEXT("CVMRMixerQueue::CVMRMixerQueue")));

    m_hSem = CreateSemaphore(NULL, 0, 0x7FFFFFFF, NULL);
    if (m_hSem == NULL) {
        DWORD dwErr = GetLastError();
        *phr = HRESULT_FROM_WIN32(dwErr);
        return;
    }

}

CVMRMixerQueue::~CVMRMixerQueue()
{
    AMTRACE((TEXT("CVMRMixerQueue::~CVMRMixerQueue")));

    if (m_hSem) {
        CloseHandle(m_hSem);
    }
}

DWORD
CVMRMixerQueue::GetSampleFromQueueNoWait(
    IMediaSample** lplpMediaSample
    )
{
    AMTRACE((TEXT("CVMRMixerQueue::GetSampleFromQueueNoWait")));

    CAutoLock lck(&m_CritSect);
    *lplpMediaSample = (CVMRMediaSample *)m_lFree.PeekHead();

    return *lplpMediaSample != NULL;
}


DWORD
CVMRMixerQueue::GetSampleFromQueueNoRemove(
    HANDLE hNotActive,
    IMediaSample** lplpMediaSample
    )
{
    AMTRACE((TEXT("CVMRMixerQueue::GetSampleFromQueueNoRemove")));

    CVMRMediaSample *pSample = NULL;
    *lplpMediaSample = NULL;
    DWORD dwRet = 0;

    for ( ;; )
    {
        {
            // scope for lock
            CAutoLock lck(&m_CritSect);

            pSample = (CVMRMediaSample *)m_lFree.PeekHead();
            if (pSample == NULL) {
                m_lWaiting++;
            }
        }

        /* If we didn't get a sample then wait for the list to signal */

        if (pSample) {
            break;
        }

        ASSERT(m_hSem != NULL);
        ASSERT(hNotActive != NULL);

        HANDLE h[2];
        h[0] = hNotActive;
        h[1] = m_hSem;

        dwRet = WaitForMultipleObjects(2, h, FALSE, INFINITE);
        if (dwRet == WAIT_OBJECT_0) {
            break;
        }
    }

    *lplpMediaSample = pSample;
    return dwRet;
}


BOOL
CVMRMixerQueue::RemoveSampleFromQueue()
{
    AMTRACE((TEXT("CVMRMixerQueue::RemoveSampleFromQueue")));

    CAutoLock lck(&m_CritSect);
    CVMRMediaSample*pSample = m_lFree.RemoveHead();
    return pSample != NULL;
}


DWORD
CVMRMixerQueue::PutSampleOntoQueue(
    IMediaSample* lpSample
    )
{
    AMTRACE((TEXT("CVMRMixerQueue::PutSampleOntoQueue")));

    CAutoLock lck(&m_CritSect);
    DWORD dwRet = 0;

    //
    // Put this sample onto the end of the mixer queue
    //

    m_lFree.AddTail((CVMRMediaSample *)lpSample);
    if (m_lWaiting != 0) {

        ASSERT(m_hSem != NULL);
        if (!ReleaseSemaphore(m_hSem, m_lWaiting, 0)) {
            dwRet = GetLastError();
        }
        m_lWaiting = 0;
    }

    return dwRet;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\mixer\mixerstream.cpp ===
/******************************Module*Header*******************************\
* Module Name: MixerStream.cpp
*
*
*
*
* Created: Thu 03/09/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>
#include <limits.h>

#include "mixerobj.h"



/******************************Public*Routine******************************\
* CVideoMixerStream
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
CVideoMixerStream::CVideoMixerStream(
    DWORD dwID,
    HRESULT* phr
    ) :
    m_SampleQueue(phr),
    m_dwID(dwID),
    m_fStreamConnected(FALSE),
    m_fActive(false),
    m_bWasActive(false),
    m_bFlushing(false),
    m_fAlpha(1.0f),
    m_dwZOrder(0),
    m_hNotActive(NULL),
    m_hActive(NULL),
    m_dwSurfaceFlags(0),
    m_pDeinterlaceDev(NULL),
    m_pddsDeinterlaceDst(NULL),
    m_fDeinterlaceDstTexture(FALSE),
    m_rtDeinterlacedFrameStart(MAX_REFERENCE_TIME),
    m_rtDeinterlacedFrameEnd(MAX_REFERENCE_TIME)
{
    AMTRACE((TEXT("CVideoMixerStream::CVideoMixerStream")));
    ZeroStruct(m_mt);
    ZeroStruct(m_DeinterlaceDevGUID);
    ZeroStruct(m_DeinterlaceCaps);
    ZeroStruct(m_rcSurface);

    m_ClrKey.dwColorSpaceLowValue = 0xFFFFFFFF;
    m_ClrKey.dwColorSpaceHighValue = 0xFFFFFFFF;

    m_rOutputRect.left = 0.0f;
    m_rOutputRect.right = 1.0f;
    m_rOutputRect.top = 0.0f;
    m_rOutputRect.bottom = 1.0f;

    m_hActive = CreateEvent(NULL, TRUE, FALSE, NULL);
    if (!m_hActive) {
        DWORD dwErr = GetLastError();
        *phr = HRESULT_FROM_WIN32(dwErr);
        return;
    }

    m_hNotActive = CreateEvent(NULL, TRUE, TRUE, NULL);
    if (!m_hActive) {
        DWORD dwErr = GetLastError();
        *phr = HRESULT_FROM_WIN32(dwErr);
        return;
    }
}

/******************************Public*Routine******************************\
* ~CVideoMixerStream()
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
CVideoMixerStream::~CVideoMixerStream()
{
    AMTRACE((TEXT("CVideoMixerStream::~CVideoMixerStream")));

    FreeMediaType(m_mt);

    if (m_hActive) {
        CloseHandle(m_hActive);
    }

    if (m_hNotActive) {
        CloseHandle(m_hNotActive);
    }

}

/******************************Public*Routine******************************\
* SetStreamSample
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamSample(
    IMediaSample* lpSample
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamSample")));
    CAutoLock Lock(&m_ObjectLock);
    HRESULT hr = S_OK;

    if (m_fActive) {
        lpSample->AddRef();
        if (0 != m_SampleQueue.PutSampleOntoQueue(lpSample)) {
            hr = E_FAIL;
        }
    }
    else {
        hr = E_FAIL;
    }

    return hr;
}

/******************************Public*Routine******************************\
* BeginFlush
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::BeginFlush()
{
    AMTRACE((TEXT("CVideoMixerStream::BeginFlush")));
    CAutoLock Lock(&m_ObjectLock);

    ASSERT(!m_bFlushing);
    m_bFlushing = TRUE;
    return S_OK;
}

/******************************Public*Routine******************************\
* EndFlush
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::EndFlush()
{
    AMTRACE((TEXT("CVideoMixerStream::EndFlush")));
    CAutoLock Lock(&m_ObjectLock);

    ASSERT(m_bFlushing);
    m_bFlushing = FALSE;
    return S_OK;
}


/******************************Public*Routine******************************\
* SetStreamMediaType
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamMediaType(
    AM_MEDIA_TYPE* pmt,
    DWORD dwSurfaceFlags
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamMediaType")));
    CAutoLock Lock(&m_ObjectLock);

    FreeMediaType(m_mt);
    if (pmt) {
        CopyMediaType(&m_mt, pmt);
        FixupMediaType(&m_mt);
    }
    else {
        ZeroMemory(&m_mt, sizeof(m_mt));
    }

    m_fStreamConnected = (pmt != NULL);
    m_dwSurfaceFlags = dwSurfaceFlags;

    return S_OK;
}

/******************************Public*Routine******************************\
* GetStreamMediaType
*
*
*
* History:
* Tue 03/14/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamMediaType(
    AM_MEDIA_TYPE* pmt,
    DWORD* pdwSurfaceFlags
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamMediaType")));
    CAutoLock Lock(&m_ObjectLock);

    if (pmt) {
        CopyMediaType(pmt, &m_mt);
    }

    if (pdwSurfaceFlags) {
        *pdwSurfaceFlags = m_dwSurfaceFlags;
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* SetStreamActiveState
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamActiveState(
    BOOL fActive
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamActiveState")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (m_fActive != fActive) {

        if (fActive) {
            ResetEvent(m_hNotActive);
            SetEvent(m_hActive);
        }
        else {
            SetEvent(m_hNotActive);
            ResetEvent(m_hActive);
        }

        m_fActive = fActive;
    }

    return hr;
}

/******************************Public*Routine******************************\
* GetStreamActiveState
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamActiveState(
    BOOL* lpfActive
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamActiveState")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *lpfActive = m_fActive;
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamColorKey
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamColorKey(
    LPDDCOLORKEY lpClr
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    m_ClrKey = *lpClr;
    return hr;
}


/******************************Public*Routine******************************\
* GetStreamColorKey
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamColorKey(
    LPDDCOLORKEY lpClr
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamColorKey")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *lpClr = m_ClrKey;
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamAlpha
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamAlpha(
    float Alpha
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamAlpha")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    m_fAlpha = Alpha;
    return hr;
}


/******************************Public*Routine******************************\
* GetStreamAlpha
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamAlpha(
    float* pAlpha
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamAlpha")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *pAlpha = m_fAlpha;
    return hr;
}


/******************************Public*Routine******************************\
* SetStreamZOrder
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamZOrder(
    DWORD dwZOrder
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamZOrder")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    m_dwZOrder = dwZOrder;
    return hr;
}


/******************************Public*Routine******************************\
* GetStreamZOrder
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamZOrder(
    DWORD* pdwZOrder
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamZOrder")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *pdwZOrder = m_dwZOrder;
    return hr;
}


/******************************Public*Routine******************************\
* SetStreamOutputRect (was SetStreamRelativeOutputRect)
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
* Tue 05/16/2000 - nwilt - renamed to SetStreamOutputRect
*
\**************************************************************************/
HRESULT
CVideoMixerStream::SetStreamOutputRect(
    const NORMALIZEDRECT* prDest
    )
{
    AMTRACE((TEXT("CVideoMixerStream::SetStreamOutputRect")));
    CAutoLock Lock(&m_ObjectLock);

    if (ISBADREADPTR(prDest))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    HRESULT hr = S_OK;
    m_rOutputRect = *prDest;
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamOutputRect (was GetStreamRelativeOutputRect)
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::GetStreamOutputRect(
    NORMALIZEDRECT* pOut
    )
{
    AMTRACE((TEXT("CVideoMixerStream::GetStreamOutputRect")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;
    *pOut = m_rOutputRect;
    return hr;
}

/******************************Public*Routine******************************\
* CreateDeinterlaceDevice
*
*
*
* History:
* Mon 03/18/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::CreateDeinterlaceDevice(
    LPDIRECTDRAW7 pDD,
    LPGUID lpGuid,
    DXVA_DeinterlaceCaps* pCaps,
    DWORD dwTexCaps
    )
{
    AMTRACE((TEXT("CVideoMixerStream::CreateDeinterlaceDevice")));
    CAutoLock Lock(&m_ObjectLock);

    extern UINT NextPow2(UINT i);
    HRESULT hr = S_OK;

    __try {

        DestroyDeinterlaceDevice();

        CopyMemory(&m_DeinterlaceCaps, pCaps, sizeof(DXVA_DeinterlaceCaps));
        m_DeinterlaceDevGUID = *lpGuid;

        //
        // Start by trying to allocate the Deinterlace destination surfaces
        // as texture - if this fails try regular offscreen plain.
        //

        DXVA_VideoDesc VideoDesc;
        CHECK_HR(GetVideoDescFromMT(&VideoDesc, &m_mt));
        CHECK_HR(GetInterlaceFlagsFromMediaType(&m_mt, &m_dwInterlaceFlags));

        DDSURFACEDESC2 ddsd;
        INITDDSTRUCT(ddsd);
        BITMAPINFOHEADER *pHdr = GetbmiHeader(&m_mt);

        ddsd.dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT | DDSD_PIXELFORMAT;
        ddsd.dwWidth = abs(pHdr->biWidth);
        ddsd.dwHeight = abs(pHdr->biHeight);
        ddsd.ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                              DDSCAPS_TEXTURE;

        //
        // if we can color space convert we should allocate an RGB
        // destination surface
        //
        if (pCaps->VideoProcessingCaps & DXVA_VideoProcess_YUV2RGB) {

            ddsd.ddpfPixelFormat.dwFourCC = BI_RGB;
            ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
            ddsd.ddpfPixelFormat.dwRGBBitCount = 32;
            ddsd.ddpfPixelFormat.dwRBitMask = 0xff0000;
            ddsd.ddpfPixelFormat.dwGBitMask = 0x00ff00;
            ddsd.ddpfPixelFormat.dwBBitMask = 0x0000ff;

        }
        else {

            ddsd.ddpfPixelFormat.dwFourCC = pCaps->d3dOutputFormat;
            ddsd.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
            ddsd.ddpfPixelFormat.dwYUVBitCount = pHdr->biBitCount;
        }


        if (dwTexCaps & TXTR_POWER2) {

            ddsd.dwWidth = NextPow2(ddsd.dwWidth);
            ddsd.dwHeight = NextPow2(ddsd.dwHeight);
        }

        //
        // we only try to create an offscreen plain surface if
        // we failed to create a YUV texture surface.
        //
        hr = pDD->CreateSurface(&ddsd, &m_pddsDeinterlaceDst, NULL);
        if (hr != DD_OK) {

            if (!(pCaps->VideoProcessingCaps & DXVA_VideoProcess_YUV2RGB)) {

                ddsd.dwWidth = abs(pHdr->biWidth);
                ddsd.dwHeight = abs(pHdr->biHeight);
                ddsd.ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY | DDSCAPS_LOCALVIDMEM |
                                      DDSCAPS_OFFSCREENPLAIN;

                CHECK_HR(hr = pDD->CreateSurface(&ddsd, &m_pddsDeinterlaceDst, NULL));
                m_fDeinterlaceDstTexture = FALSE;
            }
        }
        else {

            m_fDeinterlaceDstTexture = TRUE;
        }

        //
        // Next create the deinterlacing device.
        //

        m_pDeinterlaceDev = new CDeinterlaceDevice(pDD, lpGuid, &VideoDesc, &hr);
        if (!m_pDeinterlaceDev || hr != DD_OK) {

            if (!m_pDeinterlaceDev) {

                hr = E_OUTOFMEMORY;
            }
            __leave;
        }

        m_rtDeinterlacedFrameStart = MAX_REFERENCE_TIME;
        m_rtDeinterlacedFrameEnd = MAX_REFERENCE_TIME;

        SetRect(&m_rcSurface, 0, 0, abs(pHdr->biWidth), abs(pHdr->biHeight));

    }
    __finally {

        if (FAILED(hr)) {

            DestroyDeinterlaceDevice();
        }

    }
    return hr;
}

/******************************Public*Routine******************************\
* DestroyDeinterlaceDevice
*
*
*
* History:
* Mon 03/18/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::DestroyDeinterlaceDevice()
{
    AMTRACE((TEXT("CVideoMixerStream::DestroyDeinterlaceDevice")));
    CAutoLock Lock(&m_ObjectLock);

    RELEASE(m_pddsDeinterlaceDst);
    delete m_pDeinterlaceDev;
    m_pDeinterlaceDev = NULL;

    ZeroStruct(m_DeinterlaceDevGUID);
    ZeroStruct(m_DeinterlaceCaps);
    ZeroStruct(m_rcSurface);

    m_rtDeinterlacedFrameStart = MAX_REFERENCE_TIME;
    m_rtDeinterlacedFrameEnd = MAX_REFERENCE_TIME;

    return S_OK;
}

/******************************Public*Routine******************************\
* IsStreamInterlaced
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVideoMixerStream::IsStreamInterlaced()
{
    AMTRACE((TEXT("CVideoMixerStream::IsStreamInterlaced")));
    CAutoLock Lock(&m_ObjectLock);

    DWORD dwInterlaceFlags = 0;

    GetInterlaceFlagsFromMediaType(&m_mt, &dwInterlaceFlags);

    if (dwInterlaceFlags) {

        if (IsSingleFieldPerSample(dwInterlaceFlags)) {
            return TRUE;
        }

        ASSERT(m_pSample);

        CVMRMediaSample* lpVMR = (CVMRMediaSample*)m_pSample;
        DWORD dwTypeSpecificFlags = lpVMR->GetTypeSpecificFlags();

        return NeedToFlipOddEven(dwInterlaceFlags, dwTypeSpecificFlags,
                                 NULL, TRUE);
    }
    return FALSE;
}

/******************************Public*Routine******************************\
* IsStreamTwoInterlacedFields
*
*
*
* History:
* Sat 04/13/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVideoMixerStream::IsStreamTwoInterlacedFields()
{
    AMTRACE((TEXT("CVideoMixerStream::IsStreamTwoInterlacedFields")));
    CAutoLock Lock(&m_ObjectLock);

    DWORD dwInterlaceFlags;
    GetInterlaceFlagsFromMediaType(&m_mt, &dwInterlaceFlags);

    CVMRMediaSample* lpVMR = (CVMRMediaSample*)m_pSample;
    DWORD dwTypeSpecificFlags = lpVMR->GetTypeSpecificFlags();

    const DWORD dwBobOrWeave = (AMINTERLACE_IsInterlaced |
                                AMINTERLACE_DisplayModeBobOrWeave);

    if ((dwInterlaceFlags & dwBobOrWeave) == dwBobOrWeave) {
        if (dwTypeSpecificFlags & AM_VIDEO_FLAG_WEAVE) {
            return FALSE;
        }
        return TRUE;
    }


    const DWORD dwBobOnly = (AMINTERLACE_IsInterlaced |
                             AMINTERLACE_DisplayModeBobOnly);
    if ((dwInterlaceFlags & dwBobOnly) == dwBobOnly) {
        if (!(AMINTERLACE_1FieldPerSample & dwInterlaceFlags)) {
            return TRUE;
        }
    }

    return FALSE;

}

/******************************Public*Routine******************************\
* IsDeinterlaceDestATexture
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVideoMixerStream::IsDeinterlaceDestATexture()
{
    AMTRACE((TEXT("CVideoMixerStream::IsDeinterlaceDestATexture")));
    CAutoLock Lock(&m_ObjectLock);
    return m_fDeinterlaceDstTexture;
}

/******************************Public*Routine******************************\
* CanBeDeinterlaced
*
*
*
* History:
* Thu 03/21/2002 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVideoMixerStream::CanBeDeinterlaced()
{
    AMTRACE((TEXT("CVideoMixerStream::CanBeDeinterlaced")));
    CAutoLock Lock(&m_ObjectLock);
    return m_pDeinterlaceDev != NULL;
}

/******************************Public*Routine******************************\
* GetDeinterlaceDestSurface
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
LPDIRECTDRAWSURFACE7
CVideoMixerStream::GetDeinterlaceDestSurface()
{
    return m_pddsDeinterlaceDst;
}


/******************************Public*Routine******************************\
* DeinterlaceStreamWorker
*
*
* work out the start and end time for this frame
* extract the reference surfaces from the saved media sample
* get the de-interlacing device to perform the Blt
* update the frame start and end times.
*
* History:
* Mon 03/25/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::DeinterlaceStreamWorker(
    REFERENCE_TIME rtStart,
    LPRECT lprcDst,
    LPDIRECTDRAWSURFACE7 pddDst,
    LPRECT lprcSrc,
    bool fUpdateTimes
    )
{
    AMTRACE((TEXT("CVideoMixerStream::DeinterlaceStreamWorker")));


    //
    // work out the start and end time for this frame
    // extract the reference surfaces from the saved media sample
    // get the de-interlacing device to perform the Blt
    //
    CVMRMediaSample* lpVMR = (CVMRMediaSample*)m_pSample;
    ASSERT(lpVMR);

    DWORD& NumBackRefSamples = m_DeinterlaceCaps.NumBackwardRefSamples;

    DWORD dwNumInSamples = lpVMR->GetNumInputSamples();
    DXVA_VideoSample* pSrcSurf = lpVMR->GetInputSamples();

    REFERENCE_TIME rtF1 = pSrcSurf[NumBackRefSamples].rtStart;
    REFERENCE_TIME rtF2 = pSrcSurf[NumBackRefSamples].rtStart +
                          pSrcSurf[NumBackRefSamples].rtEnd;
    ASSERT(rtF2 != 0);
    rtF2 /= 2;

    if (rtStart >= rtF2) {
        rtStart = rtF2;
    }
    else {
        rtStart = rtF1;
    }


    HRESULT hr = m_pDeinterlaceDev->Blt(rtStart, lprcDst, pddDst,
                                        lprcSrc, pSrcSurf, dwNumInSamples,
                                        1.0F);
#ifdef DEBUG
    if (hr != DD_OK) {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDeinterlaceDev->Blt failed hr=%#X"), hr));
    }
#endif

    if (hr == DD_OK && fUpdateTimes) {

        m_rtDeinterlacedFrameStart = rtStart;
        if (rtStart == rtF2) {
            m_rtDeinterlacedFrameEnd = pSrcSurf[NumBackRefSamples].rtEnd;
        }
        else {
            m_rtDeinterlacedFrameEnd = rtF2;
        }
    }

    return hr;
}



/******************************Public*Routine******************************\
* DeinterlaceStream
*
*
*
* History:
* Wed 03/20/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVideoMixerStream::DeinterlaceStream(
    REFERENCE_TIME rtStart,
    LPRECT lprcDst,
    LPDIRECTDRAWSURFACE7 pddDst,
    LPRECT lprcSrc,
    BOOL fDestRGB
    )
{
    AMTRACE((TEXT("CVideoMixerStream::DeinterlaceStream")));
    CAutoLock Lock(&m_ObjectLock);

    HRESULT hr = S_OK;

    if (lprcDst == NULL) {
        lprcDst = &m_rcSurface;
    }

    if (lprcSrc == NULL) {
        lprcSrc = &m_rcSurface;
    }

    //
    // Have we been given a destination surface to copy the
    // de-interlaced frame too?
    //

    if (pddDst) {

        BOOL fBltOK = TRUE;

        //
        // can we de-interlace directly into the destination surface?
        // there are stretching and color space conversion issues to
        // deal with.
        //
        DXVA_VideoProcessCaps& dwCaps = m_DeinterlaceCaps.VideoProcessingCaps;

        if (fDestRGB) {
            fBltOK &= !!(dwCaps & DXVA_VideoProcess_YUV2RGB);
        }

        if (WIDTH(lprcDst) != WIDTH(lprcSrc)) {
            fBltOK &= !!(dwCaps & DXVA_VideoProcess_StretchX);
        }

        if (HEIGHT(lprcDst) != HEIGHT(lprcSrc)) {

            if (!IsSingleFieldPerSample(m_dwInterlaceFlags) ||
                (HEIGHT(lprcDst) != (2 * HEIGHT(lprcSrc)))) {

                fBltOK &= !!(dwCaps & DXVA_VideoProcess_StretchY);
            }
        }

        if (fBltOK) {

            return DeinterlaceStreamWorker(rtStart, lprcDst, pddDst,
                                           lprcSrc, false);
        }
        else {

            //
            // if the de-interlace frame store is a texture
            // we don't want to be blt'ing from it so fail the
            // call here.
            //
            if (m_fDeinterlaceDstTexture) {
                return E_FAIL;
            }
        }
    }


    //
    // do we need to create a new de-interlaced frame?
    //

    if (rtStart <  m_rtDeinterlacedFrameStart ||
        rtStart >= m_rtDeinterlacedFrameEnd) {

        hr = DeinterlaceStreamWorker(rtStart, &m_rcSurface,
                                     m_pddsDeinterlaceDst, &m_rcSurface, true);
    }


    if (pddDst && SUCCEEDED(hr)) {

        hr = pddDst->Blt(lprcDst, m_pddsDeinterlaceDst,
                         lprcSrc, DDBLT_WAIT, NULL);
    }

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\video\vmrenderer.h ===
/******************************Module*Header*******************************\
* Module Name: VMRenderer.h
*
*
*
*
* Created: Tue 02/15/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/

#include "VMRuuids.h"
#include "alloclib.h"
#include "CVMRMediaSample.h"
#include "vmrwinctrl.h"
#include "vmrwindow.h"
#include "vmrp.h"
#include "ddva.h"
#include "videoacc.h"


class CVMRInputPin;
class CVMRFilter;
class CVMRAllocator;
class CVMRRendererMacroVision;
class CVMRDeinterlaceContainer;

extern const AMOVIESETUP_FILTER sudVMRFilter;


class CVMRDeinterlaceContainer {

public:

    CVMRDeinterlaceContainer(LPDIRECTDRAW7 pDD, HRESULT* phr);
    ~CVMRDeinterlaceContainer();

    HRESULT QueryAvailableModes(
        LPDXVA_VideoDesc lpVideoDescription,
        LPDWORD lpdwNumModesSupported,
        LPGUID pGuidsDeinterlaceModes
        );

    HRESULT QueryModeCaps(
        LPGUID pGuidDeinterlaceMode,
        LPDXVA_VideoDesc lpVideoDescription,
        LPDXVA_DeinterlaceCaps lpDeinterlaceCaps
        );

private:
    IDDVideoAcceleratorContainer*   m_pIDDVAContainer;
    IDirectDrawVideoAccelerator*    m_pIDDVideoAccelerator;
};


//
// Combination of all the VP_TV_XXX flags (w/o _WIN_VGA) gives 0x7FFF
//
#define ValidTVStandard(dw)  (dw & 0x7FFF)

//
// MacroVision implementation wrapped in a class for Video Renderer
//
class CVMRRendererMacroVision {

    public:
        CVMRRendererMacroVision(void) ;
        ~CVMRRendererMacroVision(void) ;

        BOOL  SetMacroVision(HMONITOR hMon, DWORD dwCPBits) ;
        BOOL  StopMacroVision();
        HMONITOR  GetCPHMonitor(void)   { return m_hMon; };

    private:
        DWORD       m_dwCPKey;
        HMONITOR    m_hMon;
};

/* -------------------------------------------------------------------------
** Dedicated Mixer Pin allocator class
** -------------------------------------------------------------------------
*/
class CVMRPinAllocator :
    public CBaseAllocator
{
    friend class CVMRFilter;
    friend class CVMRInputPin;

public:
    CVMRPinAllocator(CVMRInputPin* pPin, CCritSec *pLock, HRESULT *phr);

    // Overriden to delegate reference counts to the pin
    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);

    STDMETHODIMP SetProperties(
        ALLOCATOR_PROPERTIES* pRequest, ALLOCATOR_PROPERTIES* pActual);

    STDMETHODIMP GetBuffer(
        IMediaSample **ppSample, REFERENCE_TIME *pStartTime,
        REFERENCE_TIME *pEndTime, DWORD dwFlags);

    STDMETHODIMP ReleaseBuffer(IMediaSample *pMediaSample);

    //  Check all samples are returned
    BOOL CanFree() const
    {
        return m_lFree.GetCount() == m_lAllocated;
    }

private:
    void Free();
    HRESULT Alloc();

private:
    CVMRInputPin*   m_pPin;
    CCritSec*       m_pInterfaceLock;
};



//
// these values are used to do sanity checking mostly
//
#define MAX_COMPRESSED_TYPES    10
#define MAX_COMPRESSED_BUFFERS  20

typedef struct _tag_SURFACE_INFO {
    LPDIRECTDRAWSURFACE7    pSurface;
    union {
        LPVOID                  pBuffer;    // NULL if not locked
        DWORD_PTR               InUse;
    };
} SURFACE_INFO, *LPSURFACE_INFO;

typedef struct _tag_COMP_SURFACE_INFO {
    DWORD                   dwAllocated;
    LPSURFACE_INFO          pSurfInfo;
} COMP_SURFACE_INFO, *LPCOMP_SURFACE_INFO;


enum {
    AM_VIDEOACCELERATOR = 0x01,
    AM_IMEMINPUTPIN = 0x02
};


/* -------------------------------------------------------------------------
** New Renderer's input pin
** -------------------------------------------------------------------------
*/
class CVMRInputPin :
    public CBaseInputPin,
    public IPinConnection,
    public IAMVideoAccelerator,
    public IVMRVideoStreamControl
{

public:

    DECLARE_IUNKNOWN

    CVMRInputPin(DWORD dwID, CVMRFilter* pRenderer,
                 CCritSec *pLock, HRESULT *phr, LPCWSTR Name);
    virtual ~CVMRInputPin();


    // Overriden to delegate reference counts to the filter
    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,VOID **ppv);


    // IPinConnection
    //
    // This interface is implemented to allow the VMR to support dynamice
    // pin reconnections.
    //
    STDMETHODIMP DynamicQueryAccept(const AM_MEDIA_TYPE *pmt);
    STDMETHODIMP NotifyEndOfStream(HANDLE hNotifyEvent);
    STDMETHODIMP IsEndPin();
    STDMETHODIMP DynamicDisconnect();


    // IOverlay
    //
    // This interface is only added to support old applications that want to
    // know the VMR's window handle.  This interface is only obtainable when
    // the VMR is in Window'ed mode.  New applications should be written to the
    // WindowLess mode and therefore already know the window handle of the
    // playback window (because they created the thing!).
    //
    // The VMR will not allow upstream filters to connect using this interface,
    // that is the VMR should only expose the interface after a connection
    // (via IMemInputPin or IAMVideoAccelerator) has been made.  Note that
    // this interface is implemented as a nested class, this is so that we
    // we can have "proper" Set/GetColorKey functions on the IVMRPinConfig
    // interface that don't clash with the functions of the same name in this
    // interface.
    //
    class CIIOverlay : public IOverlay {
        LONG            m_cRef;
        CVMRInputPin*   m_pObj;

    public:
        CIIOverlay(CVMRInputPin* pObj) :
            m_cRef(0), m_pObj(pObj) {}

        STDMETHODIMP_(ULONG) AddRef()
        {
            return (ULONG)++m_cRef;
        }

        STDMETHODIMP_(ULONG) Release()
        {
            return (ULONG)--m_cRef;
        }

        STDMETHODIMP QueryInterface(REFIID riid, void **ppv)
        {
            return m_pObj->QueryInterface(riid, ppv);
        }

        STDMETHODIMP GetPalette(DWORD *, PALETTEENTRY**) { return E_NOTIMPL;}
        STDMETHODIMP SetPalette(DWORD, PALETTEENTRY*) { return E_NOTIMPL;}
        STDMETHODIMP GetDefaultColorKey(COLORKEY*) { return E_NOTIMPL;}
        STDMETHODIMP GetColorKey(COLORKEY*) { return E_NOTIMPL;}
        STDMETHODIMP SetColorKey(COLORKEY*) { return E_NOTIMPL;}
        STDMETHODIMP GetWindowHandle(HWND* pHwnd) {
            return m_pObj->GetWindowHandle(pHwnd);
        }
        STDMETHODIMP GetClipList(RECT*, RECT*, RGNDATA**) { return E_NOTIMPL;}
        STDMETHODIMP GetVideoPosition(RECT*, RECT*) { return E_NOTIMPL;}
        STDMETHODIMP Advise(IOverlayNotify*, DWORD) { return E_NOTIMPL;}
        STDMETHODIMP Unadvise() { return E_NOTIMPL;}
    };

    // IAMVideoAccelerator
    STDMETHODIMP GetVideoAcceleratorGUIDs(
        LPDWORD pdwNumGuidsSupported,
        LPGUID pGuidsSupported
        );

    STDMETHODIMP GetUncompFormatsSupported(
        const GUID* pGuid,
        LPDWORD pdwNumFormatsSupported,
        LPDDPIXELFORMAT pFormatsSupported
        );

    STDMETHODIMP GetInternalMemInfo(
        const GUID* pGuid,
        const AMVAUncompDataInfo* pamvaUncompDataInfo,
        LPAMVAInternalMemInfo pamvaInternalMemInfo
        );

    STDMETHODIMP GetCompBufferInfo(
        const GUID* pGuid,
        const AMVAUncompDataInfo* pamvaUncompDataInfo,
        LPDWORD pdwNumTypesCompBuffers,
        LPAMVACompBufferInfo pamvaCCompBufferInfo
        );

    STDMETHODIMP GetInternalCompBufferInfo(
        LPDWORD pdwNumTypesCompBuffers,
        LPAMVACompBufferInfo pamvaCCompBufferInfo
        );

    STDMETHODIMP BeginFrame(
        const AMVABeginFrameInfo* pamvaBeginFrameInfo
        );

    STDMETHODIMP EndFrame(
        const AMVAEndFrameInfo* pEndFrameInfo
        );

    STDMETHODIMP GetBuffer(
        DWORD dwTypeIndex,
        DWORD dwBufferIndex,
        BOOL bReadOnly,
        LPVOID* ppBuffer,
        LPLONG lpStride
        );

    STDMETHODIMP ReleaseBuffer(
        DWORD dwTypeIndex,
        DWORD dwBufferIndex
        );

    STDMETHODIMP Execute(
        DWORD dwFunction,
        LPVOID lpPrivateInputData,
        DWORD cbPrivateInputData,
        LPVOID lpPrivateOutputData,
        DWORD cbPrivateOutputData,
        DWORD dwNumBuffers,
        const AMVABUFFERINFO *pAMVABufferInfo
        );

    STDMETHODIMP QueryRenderStatus(
        DWORD dwTypeIndex,
        DWORD dwBufferIndex,
        DWORD dwFlags
        );

    STDMETHODIMP DisplayFrame(
        DWORD dwFlipToIndex,
        IMediaSample *pMediaSample
        );

    // Override ReceiveConnection to allow format changes while running
    STDMETHODIMP ReceiveConnection(IPin * pConnector, const AM_MEDIA_TYPE *pmt);

    STDMETHODIMP Disconnect();

    // connection related functions
    HRESULT BreakConnect();
    HRESULT CompleteConnect(IPin *pReceivePin);
    HRESULT SetMediaType(const CMediaType *pmt);
    HRESULT CheckMediaType(const CMediaType* mtOut);
    HRESULT DynamicCheckMediaType(const CMediaType* pmt);
    HRESULT CheckInterlaceFlags(DWORD dwInterlaceFlags);

    HRESULT OnAlloc(
        CVMRMediaSample **ppSampleList,
        LONG lSampleCount);

    HRESULT OnSetProperties(
        ALLOCATOR_PROPERTIES* pReq, ALLOCATOR_PROPERTIES* pAct);

    HRESULT AllocateSurfaceWorker(
        SURFACE_INFO* lplpDDSurf,
        DDSURFACEDESC2* lpddsd,
        DWORD* lpdwBuffCount,
        bool fInterlaced
        );

    HRESULT AllocateSurface(
        const AM_MEDIA_TYPE* cmt,
        SURFACE_INFO** lplpDDSurfInfo,
        DWORD* lpdwBackBuffer,
        DWORD* lpdwSurfFlags,
        DWORD Pool,
        AM_MEDIA_TYPE** ppmt);

    HRESULT OnGetBuffer(
        IMediaSample *pSamp,REFERENCE_TIME *pSTime,
        REFERENCE_TIME *pETime,DWORD dwFlags);

    // allocator control
    STDMETHODIMP GetAllocator(IMemAllocator **ppAllocator);
    STDMETHODIMP NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly);

    // streaming functions
    HRESULT Active();
    HRESULT Inactive();

    STDMETHODIMP BeginFlush();
    STDMETHODIMP EndFlush();
    STDMETHODIMP Receive(IMediaSample *pMediaSample);
    STDMETHODIMP EndOfStream();

    // IVMRVideoStreamControl

    // - uses p_Mixer & dwPin ID to map to the corresponding SetStreamXXX call
    STDMETHODIMP SetColorKey(DDCOLORKEY* Clr);
    STDMETHODIMP GetColorKey(DDCOLORKEY* pClr);
    STDMETHODIMP SetStreamActiveState(BOOL fActive);
    STDMETHODIMP GetStreamActiveState(BOOL* lpfActive);

    HRESULT GetWindowHandle(HWND* pHwnd);
    DWORD   GetPinID() {
        return m_dwPinID;
    }


private:
    friend class CVMRPinAllocator;
    friend class CVMRFilter;
    friend class CIIOverlay;

    void    DoQualityMessage();

    HRESULT TryDynamicReconfiguration(IPin* pConnector,const AM_MEDIA_TYPE *pmt);
    HRESULT DynamicReconfigureMEM(IPin* pConnector,const AM_MEDIA_TYPE *pmt);
    HRESULT DynamicReconfigureDVA(IPin* pConnector,const AM_MEDIA_TYPE *pmt);

    //
    // Helper functions for the IAMVideoAccelerator connection protocol
    //
    SURFACE_INFO* SurfaceInfoFromTypeAndIndex(DWORD dwTypeIdx, DWORD dwBuffIdx);
    HRESULT CheckValidMCConnection();
    void FlipDVASurface(DWORD dwFlipToIndex,DWORD dwFlipFromIndex);
    HRESULT VABreakConnect();
    HRESULT VACompleteConnect(IPin *pReceivePin,const CMediaType *pMediaType);
    HRESULT CreateVideoAcceleratorObject();
    HRESULT InitializeUncompDataInfo(BITMAPINFOHEADER *pbmiHeader);
    BOOL    IsSuitableVideoAcceleratorGuid(const GUID * pGuid);
    HRESULT AllocateVACompSurfaces(LPDIRECTDRAW7 pDDraw, BITMAPINFOHEADER *pbmiHdr);
    HRESULT AllocateMCUncompSurfaces(const CMediaType *pMediaType,
                                     LPDIRECTDRAW7 pDDraw, BITMAPINFOHEADER *pbmiHdr);


    //
    // motion comp related variables
    //
    HANDLE                          m_hDXVAEvent;
    BOOL                            m_bVideoAcceleratorSupported;
    DWORD                           m_dwBackBufferCount;
    GUID                            m_mcGuid;
    DDVAUncompDataInfo              m_ddUncompDataInfo;
    DDVAInternalMemInfo             m_ddvaInternalMemInfo;
    DWORD                           m_dwCompSurfTypes;
    LPCOMP_SURFACE_INFO             m_pCompSurfInfo;
    IDDVideoAcceleratorContainer*   m_pIDDVAContainer;
    IDirectDrawVideoAccelerator*    m_pIDDVideoAccelerator;
    IAMVideoAcceleratorNotify*      m_pIVANotify;

    //
    // DShow filter related variables
    //
    CVMRFilter*             m_pRenderer;
    CCritSec*               m_pInterfaceLock;
    CVMRPinAllocator        m_PinAllocator;
    CMediaType              m_mtNew;
    LONG                    m_lSampleSize;
    enum {DELTA_DECODE_CHECKED = 0x01, DELTA_DECODE_MODE_SET = 0x02};
    DWORD                   m_dwDeltaDecode;

    BOOL                    m_fInDFC;
    bool                    m_bDynamicFormatNeeded;
    bool                    m_bActive;
    DWORD                   m_dwPinID;
    LPDIRECTDRAWSURFACE7    m_pDDS;
    CIIOverlay              m_pIOverlay;
    DWORD                   m_RenderTransport;

    //
    // De-interlace variables, only relevant in mixing mode.
    //
    DXVA_DeinterlaceCaps    m_DeinterlaceCaps;
    GUID                    m_DeinterlaceGUID;
    BOOL                    m_DeinterlaceUserGUIDSet;
    GUID                    m_DeinterlaceUserGUID;

    // array of DDraw surfaces in allocation order, if pBuffer is non-NULL
    // then the surface is in use, the array is m_dwNumSamples big.
    SURFACE_INFO*           m_pVidSurfs;

    // array of video samples in temporal order, the array
    // is only allocated when we are de-interlacing, the array
    // is m_dwNumHistorySamples big.
    DXVA_VideoSample*       m_pVidHistorySamps;
    DWORD                   m_dwNumSamples;
    DWORD                   m_dwNumHistorySamples;
    BOOL                    m_InterlacedStream;
    REFERENCE_TIME          m_SamplePeriod;
    DWORD                   m_SampleCount;
    CCritSec                m_DeinterlaceLock;

    HRESULT                 GetStreamInterlaceProperties(
                                const AM_MEDIA_TYPE *pMT,
                                BOOL* lpIsInterlaced,
                                GUID* lpDeintGuid,
                                DXVA_DeinterlaceCaps* pCaps);

    void ReleaseAllocatedSurfaces() {

        if (m_pVidSurfs) {

            //
            // delete the surfaces in reverse order.
            //
            DWORD dwNumSamples = m_dwNumSamples - 1;
            for (DWORD i = 0; i < m_dwNumSamples; i++) {
                RELEASE(m_pVidSurfs[dwNumSamples - i].pSurface);
            }
            m_dwNumSamples = 0;
            delete [] m_pVidSurfs;
            m_pVidSurfs = NULL;
        }

        if (m_pVidHistorySamps) {
            m_dwNumHistorySamples = 0;
            delete [] m_pVidHistorySamps;
            m_pVidHistorySamps = NULL;
        }
    }


    BOOL m_FrontBufferStale;
    void FrontBufferStale(BOOL bStale) {
        if (bStale) {
            m_dwDeltaDecode = 0;
        }
        m_FrontBufferStale = bStale;
    }
    BOOL IsFrontBufferStale() {
        return m_FrontBufferStale;
    }

    BOOL m_bConnected;
    void CompletelyConnected(BOOL bConnected) {
        m_bConnected = bConnected;
    }
    BOOL IsCompletelyConnected() {
        return m_bConnected;
    }

    //
    // IPinConnection stuff
    //
    HANDLE                  m_hEndOfStream;
};



/* -------------------------------------------------------------------------
** New Renderer's filter
** -------------------------------------------------------------------------
*/
class CVMRFilter :
    public CBaseFilter,
    public CPersistStream,
    public IQualProp,
    public IQualityControl,
    public IAMFilterMiscFlags,
    public IKsPropertySet,
    public IVMRWindowlessControl,
    public IVMRMixerControl,
    public IVMRFilterConfig,
    public IVMRFilterConfigInternal,
    public IVMRMonitorConfig,
    public IVMRMixerBitmap,
    public IVMRDeinterlaceControl,
    public ISpecifyPropertyPages
{

public:

    DECLARE_IUNKNOWN
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void**);
    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    static CUnknown *CreateInstance2(LPUNKNOWN, HRESULT *);
    static void InitClass(BOOL bLoading, const CLSID *clsid);

    int NumInputPinsConnected() const;

    CVMRFilter(TCHAR *pName, LPUNKNOWN pUnk, HRESULT *phr, BOOL fDefault);
    virtual ~CVMRFilter();
    void VMRCleanUp();

    CBasePin *GetPin(int n);
    int GetPinCount();

    // Override the filter and pin interface functions
    STDMETHODIMP JoinFilterGraph(IFilterGraph *pGraph,LPCWSTR pName);
    STDMETHODIMP SetSyncSource(IReferenceClock *pClock);
    STDMETHODIMP Stop();
    STDMETHODIMP Pause();
    STDMETHODIMP Run(REFERENCE_TIME StartTime);
    STDMETHODIMP GetState(DWORD dwMSecs,FILTER_STATE *State);

    HRESULT Receive(DWORD dwPinID, IMediaSample *pMediaSample);

    // called when the filter changes state
    HRESULT Active(DWORD dwPinID);
    HRESULT Inactive(DWORD dwPinID);
    HRESULT BeginFlush(DWORD dwPinID);
    HRESULT EndFlush(DWORD dwPinID);
    HRESULT EndOfStream(DWORD dwPinID);
    HRESULT CompleteConnect(DWORD dwPinID, const CMediaType& cmt);
    HRESULT RuntimeAbortPlayback(HRESULT hr);


    // deal with connections
    HRESULT BreakConnect(DWORD dwPinID);
    HRESULT CheckMediaType(const CMediaType *);
    HRESULT SetMediaType(const CMediaType *pmt);
    HRESULT OnSetProperties(CVMRInputPin* pReceivePin);


    // IQualProp property page support
    STDMETHODIMP get_FramesDroppedInRenderer(int *cFramesDropped);
    STDMETHODIMP get_FramesDrawn(int *pcFramesDrawn);
    STDMETHODIMP get_AvgFrameRate(int *piAvgFrameRate);
    STDMETHODIMP get_Jitter(int *piJitter);
    STDMETHODIMP get_AvgSyncOffset(int *piAvg);
    STDMETHODIMP get_DevSyncOffset(int *piDev);


    // IQualityControl methods - Notify allows audio-video throttling
    STDMETHODIMP SetSink( IQualityControl * piqc);
    STDMETHODIMP Notify( IBaseFilter * pSelf, Quality q);


    // IAMFilterMiscFlags
    STDMETHODIMP_(ULONG) GetMiscFlags(void)
    {
        return AM_FILTER_MISC_FLAGS_IS_RENDERER;
    }

    // IVMRWindowlessControl
    STDMETHODIMP GetNativeVideoSize(LONG* lWidth, LONG* lHeight,
                                    LONG* lARWidth, LONG* lARHeight);
    STDMETHODIMP GetMinIdealVideoSize(LONG* lWidth, LONG* lHeight);
    STDMETHODIMP GetMaxIdealVideoSize(LONG* lWidth, LONG* lHeight);
    STDMETHODIMP SetVideoPosition(const LPRECT lpSRCRect,
                                  const LPRECT lpDSTRect);
    STDMETHODIMP GetVideoPosition(LPRECT lpSRCRect,LPRECT lpDSTRect);
    STDMETHODIMP GetAspectRatioMode(DWORD* lpAspectRatioMode);
    STDMETHODIMP SetAspectRatioMode(DWORD AspectRatioMode);

    STDMETHODIMP SetVideoClippingWindow(HWND hwnd);
    STDMETHODIMP RepaintVideo(HWND hwnd, HDC hdc);
    STDMETHODIMP DisplayModeChanged();
    STDMETHODIMP GetCurrentImage(BYTE** lpDib);

    STDMETHODIMP SetBorderColor(COLORREF Clr);
    STDMETHODIMP GetBorderColor(COLORREF* lpClr);
    STDMETHODIMP SetColorKey(COLORREF Clr);
    STDMETHODIMP GetColorKey(COLORREF* lpClr);


    // IVMRMixerControl
    STDMETHODIMP SetAlpha(DWORD dwID, float Alpha);
    STDMETHODIMP GetAlpha(DWORD dwID, float* Alpha);
    STDMETHODIMP SetZOrder(DWORD dwID, DWORD zOrder);
    STDMETHODIMP GetZOrder(DWORD dwID, DWORD* zOrder);
    STDMETHODIMP SetOutputRect(DWORD dwID, const NORMALIZEDRECT *pRect);
    STDMETHODIMP GetOutputRect(DWORD dwID, NORMALIZEDRECT *pRect);

    STDMETHODIMP SetBackgroundClr(COLORREF  clrBkg);
    STDMETHODIMP GetBackgroundClr(COLORREF* lpClrBkg);
    STDMETHODIMP SetMixingPrefs(DWORD dwRenderFlags);
    STDMETHODIMP GetMixingPrefs(DWORD* pdwRenderFlags);


    // IVMRDeinterlaceControl

    STDMETHODIMP GetNumberOfDeinterlaceModes(VMRVideoDesc* lpVideoDesc,
                                             LPDWORD lpdwNumDeinterlaceModes,
                                             LPGUID lpDeinterlaceModes);
    STDMETHODIMP GetDeinterlaceModeCaps(LPGUID lpDeinterlaceMode,
                                        VMRVideoDesc* lpVideoDesc,
                                        VMRDeinterlaceCaps* lpDeinterlaceCaps);
    STDMETHODIMP GetDeinterlaceMode(DWORD dwStreamID,
                                    LPGUID lpDeinterlaceMode);
    STDMETHODIMP SetDeinterlaceMode(DWORD dwStreamID,
                                    LPGUID lpDeinterlaceMode);
    STDMETHODIMP GetDeinterlacePrefs(LPDWORD lpdwDeinterlacePrefs);
    STDMETHODIMP SetDeinterlacePrefs(DWORD dwDeinterlacePrefs);
    STDMETHODIMP GetActualDeinterlaceMode(DWORD dwStreamID,
                                          LPGUID lpDeinterlaceMode);

    //
    // IKsPropertySet interface methods
    //
    STDMETHODIMP Set(REFGUID guidPropSet, DWORD PropID, LPVOID pInstanceData,
                     DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData);

    STDMETHODIMP Get(REFGUID guidPropSet, DWORD PropID, LPVOID pInstanceData,
                     DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData,
                     DWORD *pcbReturned);

    STDMETHODIMP QuerySupported(REFGUID guidPropSet, DWORD PropID, DWORD *pTypeSupport);

    // IVMRSurfaceAllocatorNotify
    class CIVMRSurfaceAllocatorNotify : public IVMRSurfaceAllocatorNotify {
        LONG        m_cRef;
        CVMRFilter* m_pObj;

    public:
        CIVMRSurfaceAllocatorNotify(CVMRFilter* pObj) :
            m_cRef(0), m_pObj(pObj) {}
        ~CIVMRSurfaceAllocatorNotify();

        STDMETHODIMP_(ULONG) AddRef()
        {
            return InterlockedIncrement(&m_cRef);
        }

        STDMETHODIMP_(ULONG) Release()
        {
            return InterlockedDecrement(&m_cRef);
        }

        STDMETHODIMP QueryInterface(REFIID riid, void **ppv)
        {
            return m_pObj->QueryInterface(riid, ppv);
        }

        STDMETHODIMP AdviseSurfaceAllocator(
            DWORD_PTR dwUserID,
            IVMRSurfaceAllocator* lpIVRMSurfaceAllocator
            );

        STDMETHODIMP SetDDrawDevice(LPDIRECTDRAW7 lpDDrawDevice, HMONITOR hMon);
        STDMETHODIMP ChangeDDrawDevice(LPDIRECTDRAW7 lpDDrawDevice, HMONITOR hMon);
        STDMETHODIMP RestoreDDrawSurfaces();
        STDMETHODIMP NotifyEvent(LONG EventCode, LONG_PTR lp1, LONG_PTR lp2);
        STDMETHODIMP SetBorderColor(COLORREF clr);
    };

    // IVMRImagePresenter
    class CIVMRImagePresenter : public IVMRImagePresenter {
        LONG        m_cRef;
        CVMRFilter* m_pObj;

    public:
        CIVMRImagePresenter(CVMRFilter* pObj) :
            m_cRef(0), m_pObj(pObj) {}

        STDMETHODIMP_(ULONG) AddRef()
        {
            return (ULONG)++m_cRef;
        }

        STDMETHODIMP_(ULONG) Release()
        {
            return (ULONG)--m_cRef;
        }

        STDMETHODIMP QueryInterface(REFIID riid, void **ppv)
        {
            return m_pObj->QueryInterface(riid, ppv);
        }

        STDMETHODIMP StartPresenting(DWORD_PTR dwUserID);
        STDMETHODIMP StopPresenting(DWORD_PTR dwUserID);

        STDMETHODIMP PresentImage(
            DWORD_PTR dwUserID,
            VMRPRESENTATIONINFO* lpPresInfo
            );
    };

    // IImageSyncNotifyEvent
    class CIImageSyncNotifyEvent : public IImageSyncNotifyEvent {
        LONG        m_cRef;
        CVMRFilter* m_pObj;

    public:
        CIImageSyncNotifyEvent(CVMRFilter* pObj) :
            m_cRef(0), m_pObj(pObj) {}

        STDMETHODIMP_(ULONG) AddRef()
        {
            return (ULONG)++m_cRef;
        }

        STDMETHODIMP_(ULONG) Release()
        {
            return (ULONG)--m_cRef;
        }

        STDMETHODIMP QueryInterface(REFIID riid, void **ppv)
        {
            return m_pObj->QueryInterface(riid, ppv);
        }

        STDMETHODIMP NotifyEvent(long EventCode, LONG_PTR lp1, LONG_PTR lp2);
    };

    // CPersistStream
    HRESULT WriteToStream(IStream *pStream);
    HRESULT ReadFromStream(IStream *pStream);
    int SizeMax();

    STDMETHODIMP GetClassID(CLSID *pClsid);


    // IVMRFilterConfig
    STDMETHODIMP SetImageCompositor(IVMRImageCompositor* lpVMRImgCompositor);
    STDMETHODIMP SetNumberOfStreams(DWORD dwMaxStreams);
    STDMETHODIMP GetNumberOfStreams(DWORD* lpdwMaxStreams);
    STDMETHODIMP SetRenderingPrefs(DWORD dwRenderFlags);
    STDMETHODIMP GetRenderingPrefs(DWORD* pdwRenderFlags);
    STDMETHODIMP SetRenderingMode(DWORD Mode);
    STDMETHODIMP GetRenderingMode(DWORD* pMode);

    // IVMRFilterConfigInternal
    STDMETHODIMP GetAspectRatioModePrivate(DWORD* lpAspectRatioMode);
    STDMETHODIMP SetAspectRatioModePrivate(DWORD AspectRatioMode);

    // IVMRMonitorConfig ... proxied to To the app-presenter if it supports it
    STDMETHODIMP SetMonitor( const VMRGUID *pGUID );
    STDMETHODIMP GetMonitor( VMRGUID *pGUID );
    STDMETHODIMP SetDefaultMonitor( const VMRGUID *pGUID );
    STDMETHODIMP GetDefaultMonitor( VMRGUID *pGUID );
    STDMETHODIMP GetAvailableMonitors( VMRMONITORINFO* pInfo, DWORD dwMaxInfoArraySize,
                    DWORD* pdwNumDevices );

    // IVMRMixerBitmap
    STDMETHODIMP SetAlphaBitmap( const VMRALPHABITMAP *pBmpParms );
    STDMETHODIMP UpdateAlphaBitmapParameters( PVMRALPHABITMAP pBmpParms );
    STDMETHODIMP GetAlphaBitmapParameters( PVMRALPHABITMAP pBmpParms );

    // ISpecifyPropertyPages
    STDMETHODIMP GetPages(CAUUID *pPages);

    // helper for the window manager
    IVMRWindowlessControl* GetWLControl() {
        return m_lpWLControl;
    }

    HRESULT SetAbortSignal(BOOL fAbort) {
        return m_lpISControl->SetAbortSignal(fAbort);
    }

private:

    friend class CVMRInputPin;
    friend class CIVMRWindowlessControl;
    friend class CIVMRSurfaceAllocatorNotify;
    friend class CIVMRImagePresenter;
    friend class CIImageSyncNotifyEvent;

    CVMRInputPin*               m_pInputPins[MAX_MIXER_PINS];
    CCritSec                    m_InterfaceLock;// Critical section for interfaces
    CCritSec                    m_RendererLock; // Controls access to internals
    IVMRWindowlessControl*      m_lpWLControl;
    IVMRSurfaceAllocator*       m_lpRLNotify;
    IVMRImagePresenter*         m_lpPresenter;
    IVMRImagePresenterConfig*   m_pPresenterConfig;
    IVMRMonitorConfig*          m_pPresenterMonitorConfig;
    IVMRMixerControlInternal*   m_lpMixControl;
    IVMRMixerBitmap*            m_lpMixBitmap;
    IVMRMixerStream*            m_lpMixStream;
    IImageSyncControl*          m_lpISControl;
    IImageSync*                 m_lpIS;
    IQualProp*                  m_lpISQualProp;
    DWORD_PTR                   m_dwUserID;
    DWORD                       m_VMRMode;
    BOOL                        m_VMRCreateAsDefaultRenderer;
    BOOL                        m_VMRModePassThru;
    BOOL                        m_bModeChangeAllowed;
    BOOL                        m_fInputPinCountSet;
    DWORD                       m_dwNumPins;
    CVMRRendererMacroVision     m_MacroVision;

    HMONITOR                    m_hMonitor;
    LPDIRECTDRAW7               m_lpDirectDraw;
    DDCAPS_DX7                  m_ddHWCaps;
    HRESULT                     m_hrSurfaceFlipped;
    HRESULT                     m_hr3D;

    DWORD                       m_ARMode;
    BOOL                        m_bARModeDefaultSet;
    DWORD                       m_TexCaps;
    DDPIXELFORMAT               m_ddpfMonitor;
    DWORD                       m_dwDisplayChangeMask;
    DWORD                       m_dwEndOfStreamMask;
    DWORD                       m_dwRenderPrefs;

    CRendererPosPassThru*       m_pPosition; // Support IMediaSeeking
    CVMRVideoWindow*            m_pVideoWindow;
    CVMRDeinterlaceContainer*   m_pDeinterlace;
    DWORD                       m_dwDeinterlacePrefs;

    CIVMRSurfaceAllocatorNotify m_pIVMRSurfaceAllocatorNotify;
    CIVMRImagePresenter         m_pIVMRImagePresenter;
    CIImageSyncNotifyEvent      m_pIImageSyncNotifyEvent;

    HRESULT ValidateIVRWindowlessControlState();
    HRESULT GetMediaPositionInterface(REFIID riid, void** ppv);
    HRESULT CreateDefaultAllocatorPresenter();
    HRESULT SetDDrawDeviceWorker(LPDIRECTDRAW7 lpDDrawDevice, HMONITOR hMon);
    HRESULT CreateExtraInputPins(DWORD dwNumPins);
    void DestroyExtraInputPins();
    HRESULT CreateInputPin();
    HRESULT ImageSyncInit();
    HRESULT MixerInit(DWORD dwNumStreams);
    void    AutoShowWindow();
    BOOL    ModeChangeAllowed();
    void    SetVMRMode(DWORD mode);
    BOOL    IsVPMConnectedToUs();

};
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\video\vmrdva.cpp ===
/******************************Module*Header*******************************\
* Module Name: VMRDvava.cpp
*
* VMR  video accelerator functionality
*
*
* Created: Wed 05/10/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>

#include "VMRenderer.h"
#include <malloc.h>     // for __alloca

#define VA_ERROR_LEVEL  1
#define VA_TRACE_LEVEL  2

#if defined( EHOME_WMI_INSTRUMENTATION )
#include "dxmperf.h"
#endif

/*****************************Private*Routine******************************\
* IsSuitableVideoAcceleratorGuid
*
* Check if a media subtype GUID is a video accelerator type GUID
*
* This function calls the DirectDraw video accelerator container
* to list the video accelerator GUIDs and checks to see if the
* Guid passed in is a supported video accelerator GUID.
*
* We should only do this if the upstream pin support IVideoAccleratorNotify
* since otherwise they may be trying to use the GUID without the
* video accelerator interface
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVMRInputPin::IsSuitableVideoAcceleratorGuid(
    const GUID * pGuid
    )
{
    AMTRACE((TEXT("CVMRInputPin::IsSuitableVideoAcceleratorGuid")));
    ASSERT(pGuid);

    HRESULT hr = NOERROR;
    DWORD dwNumGuidsSupported = 0, i = 0;
    LPGUID pGuidsSupported = NULL;
    BOOL bMatchFound = FALSE;
    LPDIRECTDRAW7 pDirectDraw = m_pRenderer->m_lpDirectDraw;

    if (!pDirectDraw) {
        return bMatchFound;
    }

    if (!m_pIDDVAContainer) {

        hr = pDirectDraw->QueryInterface(IID_IDDVideoAcceleratorContainer,
                                         (void**)&m_pIDDVAContainer);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                    TEXT("pDirectDraw->QueryInterface(")
                    TEXT("IID_IVideoAcceleratorContainer) failed, hr = 0x%x"),
                    hr));
            return bMatchFound;
        }
        else {
            DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
                    TEXT("pDirectDraw->QueryInterface(")
                    TEXT("IID_IVideoAcceleratorContainer) succeeded")));
        }
    }

    ASSERT(m_pIDDVAContainer);

    // get the guids supported by the vga

    // find the number of guids supported
    hr = m_pIDDVAContainer->GetVideoAcceleratorGUIDs(&dwNumGuidsSupported, NULL);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("m_pIDDVAContainer->GetVideoAcceleratorGUIDs ")
                TEXT("failed, hr = 0x%x"), hr));
        return bMatchFound;
    }
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("%d Motion comp GUIDs supported")));
    ASSERT(dwNumGuidsSupported);
    if (0 == dwNumGuidsSupported) {
        return bMatchFound;
    }

    // allocate the necessary memory
    pGuidsSupported = (LPGUID)_alloca(dwNumGuidsSupported*sizeof(GUID));

    // get the guids proposed
    hr = m_pIDDVAContainer->GetVideoAcceleratorGUIDs(&dwNumGuidsSupported,
                                                     pGuidsSupported);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("m_pIDDVAContainer->GetVideoAcceleratorGUIDs")
                TEXT(" failed, hr = 0x%x"), hr));
        return bMatchFound;
    }

    for (i = 0; i < dwNumGuidsSupported; i++) {
        if (*pGuid == pGuidsSupported[i]) {
            bMatchFound = TRUE;
            break;
        }
    }

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("%s %s suitable video accelerator GUID"),
            (LPCTSTR)CDisp(*pGuid), bMatchFound ? TEXT("is") : TEXT("is not")));

    return bMatchFound;
}

/*****************************Private*Routine******************************\
* InitializeUncompDataInfo
*
* initialize the m_ddUncompDataInfo struct
* get the uncompressed pixel format by choosing the first of all formats
* supported by the vga
*
* BUGBUG why the first?
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::InitializeUncompDataInfo(
    BITMAPINFOHEADER *pbmiHeader
    )
{
    AMTRACE((TEXT("CVMRInputPin::InitializeUncompDataInfo")));

    HRESULT hr = NOERROR;
    AMVAUncompBufferInfo amvaUncompBufferInfo;

    // find the number of entries to be proposed
    hr = m_pIVANotify->GetUncompSurfacesInfo(&m_mcGuid, &amvaUncompBufferInfo);

    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("m_pIVANotify->GetUncompSurfacesInfo failed, hr = 0x%x"),
                hr));
        return hr;
    }

    // initialize the m_ddUncompDataInfo structure
    // We choose the first pixel format since we don't care
    // provided we can make a surface (which we assume we can)
    INITDDSTRUCT(m_ddUncompDataInfo);
    m_ddUncompDataInfo.dwUncompWidth       = pbmiHeader->biWidth;
    m_ddUncompDataInfo.dwUncompHeight      = pbmiHeader->biHeight;
    m_ddUncompDataInfo.ddUncompPixelFormat = amvaUncompBufferInfo.ddUncompPixelFormat;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("Uncompressed buffer pixel format %s"),
            (LPCTSTR)CDispPixelFormat(&amvaUncompBufferInfo.ddUncompPixelFormat)));

    return hr;
}


/*****************************Private*Routine******************************\
* AllocateVACompSurfaces
*
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::AllocateVACompSurfaces(
    LPDIRECTDRAW7 pDirectDraw,
    BITMAPINFOHEADER *pbmiHeader
    )
{
    HRESULT hr = NOERROR;
    DWORD i = 0, j = 0;
    LPDDVACompBufferInfo pddCompSurfInfo = NULL;
    DDSURFACEDESC2 SurfaceDesc2;

    AMTRACE((TEXT("CVMRInputPin::AllocateVACompSurfaces")));

    ASSERT(pDirectDraw);
    ASSERT(pbmiHeader);

    // get the compressed buffer info

    // find the number of entries to be proposed
    hr = m_pIDDVAContainer->GetCompBufferInfo(&m_mcGuid, &m_ddUncompDataInfo,
                                              &m_dwCompSurfTypes, NULL);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("pIVANotify->GetCompBufferInfo failed, hr = 0x%x"), hr));
        return hr;
    }

    if (!m_dwCompSurfTypes) {
        hr = E_FAIL;
        return hr;
    }

    // allocate the necessary memory
    pddCompSurfInfo = (DDVACompBufferInfo *)_alloca(
                                sizeof(DDVACompBufferInfo) * m_dwCompSurfTypes);

    // memset the allocated memory to zero
    memset(pddCompSurfInfo, 0, m_dwCompSurfTypes*sizeof(DDVACompBufferInfo));

    // set the right size of all the structs
    for (i = 0; i < m_dwCompSurfTypes; i++) {
        pddCompSurfInfo[i].dwSize = sizeof(DDVACompBufferInfo);
    }

    // get the entries proposed
    hr = m_pIDDVAContainer->GetCompBufferInfo(&m_mcGuid,
                                              &m_ddUncompDataInfo,
                                              &m_dwCompSurfTypes,
                                              pddCompSurfInfo);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("GetCompBufferInfo failed, hr = 0x%x"), hr));
        return hr;
    }

    // Set the surface description common to all kinds of surfaces
    INITDDSTRUCT(SurfaceDesc2);
    SurfaceDesc2.dwFlags = DDSD_CAPS | DDSD_WIDTH |
                           DDSD_HEIGHT | DDSD_PIXELFORMAT;

    // allocate memory for storing comp_surface_info
    m_pCompSurfInfo = new COMP_SURFACE_INFO[m_dwCompSurfTypes + 1];
    if (!m_pCompSurfInfo) {
        hr = E_OUTOFMEMORY;
        return hr;
    }

    // memset the allocated memory to zero
    ZeroMemory(m_pCompSurfInfo, (m_dwCompSurfTypes+1)*sizeof(COMP_SURFACE_INFO));

    // allocate the compressed surfaces
    for (i = 1; i <= m_dwCompSurfTypes; i++) {

        DWORD dwAlloc = pddCompSurfInfo[i-1].dwNumCompBuffers;
        if (dwAlloc == 0) {
            continue;
        }

        ASSERT(pddCompSurfInfo[i-1].dwNumCompBuffers);

        // allocate memory for storing surface_info for surfaces of this type
        m_pCompSurfInfo[i].pSurfInfo = new SURFACE_INFO[dwAlloc];
        if (!m_pCompSurfInfo[i].pSurfInfo) {
            hr = E_OUTOFMEMORY;
            return hr;
        }

        // memset the allocated memory to zero
        ZeroMemory(m_pCompSurfInfo[i].pSurfInfo, dwAlloc*sizeof(SURFACE_INFO));

        // intialize the pddCompSurfInfo[i-1] struct
        dwAlloc = m_pCompSurfInfo[i].dwAllocated =
                                        pddCompSurfInfo[i-1].dwNumCompBuffers;

        SurfaceDesc2.ddsCaps = pddCompSurfInfo[i-1].ddCompCaps;
        SurfaceDesc2.dwWidth = pddCompSurfInfo[i-1].dwWidthToCreate;
        SurfaceDesc2.dwHeight = pddCompSurfInfo[i-1].dwHeightToCreate;
        memcpy(&SurfaceDesc2.ddpfPixelFormat,
               &pddCompSurfInfo[i-1].ddPixelFormat, sizeof(DDPIXELFORMAT));

        DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
                TEXT("SurfType=%d Buffs=%u %dx%d pixels at %d bpp"),
                i, dwAlloc, SurfaceDesc2.dwWidth, SurfaceDesc2.dwHeight,
                SurfaceDesc2.ddpfPixelFormat.dwRGBBitCount));

        // create the surfaces, storing surfaces handles for each
        for (j = 0; j < dwAlloc; j++) {

            hr = pDirectDraw->CreateSurface(
                        &SurfaceDesc2,
                        &m_pCompSurfInfo[i].pSurfInfo[j].pSurface,
                        NULL);
            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                        TEXT("Function CreateSurface failed, hr = 0x%x"), hr));
                return hr;
            }
        }
    }

    return hr;
}



/*****************************Private*Routine******************************\
* AllocateMCUncompSurfaces
*
* This function needs re-writting and possible moving into the AP object.
*
* allocate the uncompressed buffer
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::AllocateMCUncompSurfaces(
    const CMediaType *pMediaType,
    LPDIRECTDRAW7 pDirectDraw,
    BITMAPINFOHEADER *lpHdr
    )
{
    AMTRACE((TEXT("CVMRInputPin::AllocateMCUncompSurfaces")));
    HRESULT hr = NOERROR;

    AMVAUncompBufferInfo amUncompBuffInfo;
    LPDIRECTDRAWSURFACE7 pSurface7 = NULL;
    DDSCAPS2 ddSurfaceCaps;
    DWORD i = 0, dwTotalBufferCount = 0;
    SURFACE_INFO *pSurfaceInfo;
    AM_MEDIA_TYPE *pNewMediaType = NULL;


    ASSERT(pDirectDraw);
    ASSERT(lpHdr);

    __try {

        // get the uncompressed surface info from the decoder
        ZeroMemory(&amUncompBuffInfo, sizeof(AMVAUncompBufferInfo));
        hr = m_pIVANotify->GetUncompSurfacesInfo(&m_mcGuid, &amUncompBuffInfo);

        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("AllocateMCUncompSurfaces: m_pIVANotify->")
                TEXT("GetUncompSurfacesInfo failed, hr = 0x%x"), hr));
            __leave;
        }


        if (amUncompBuffInfo.dwMinNumSurfaces > amUncompBuffInfo.dwMaxNumSurfaces) {
            hr = E_INVALIDARG;
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("AllocateMCUncompSurfaces: dwMinNumSurfaces >")
                TEXT("dwMaxNumSurfaces")));
            __leave;
        }

        if (amUncompBuffInfo.dwMinNumSurfaces == 0) {
            hr = E_INVALIDARG;
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("AllocateMCUncompSurfaces: dwMinNumSurfaces == 0") ));
            __leave;
        }


        DDSURFACEDESC2 ddsd;
        INITDDSTRUCT(ddsd);
        DWORD dwSurfFlags = VMR_SF_NONE;
        GUID guidDeint;
        GUID* lpDeinterlaceGUID = NULL;

        if (m_pRenderer->m_VMRModePassThru) {

            VMRALLOCATIONINFO p;
            CHECK_HR(hr = GetImageAspectRatio(pMediaType,
                                     &p.szAspectRatio.cx,
                                     &p.szAspectRatio.cy));

            p.dwFlags = (AMAP_PIXELFORMAT_VALID | AMAP_DIRECTED_FLIP | AMAP_DXVA_TARGET);

            p.lpHdr = lpHdr;
            p.lpPixFmt = &m_ddUncompDataInfo.ddUncompPixelFormat;
            p.dwMinBuffers = amUncompBuffInfo.dwMinNumSurfaces;
            p.dwMaxBuffers = max(amUncompBuffInfo.dwMaxNumSurfaces,3);
            p.szNativeSize.cx = abs(lpHdr->biWidth);
            p.szNativeSize.cy = abs(lpHdr->biHeight);

            CHECK_HR(hr = GetInterlaceFlagsFromMediaType(pMediaType,
                                                         &p.dwInterlaceFlags));

            CHECK_HR(hr = m_pRenderer->m_lpRLNotify->AllocateSurface(
                                m_pRenderer->m_dwUserID, &p,
                                &dwTotalBufferCount, &pSurface7));
        }
        else {

            // Set the surface description common to all kinds of surfaces
            ddsd.dwFlags = DDSD_CAPS | DDSD_WIDTH |
                           DDSD_HEIGHT | DDSD_PIXELFORMAT;

            // store the caps and dimensions
            ddsd.ddsCaps.dwCaps = DDSCAPS_VIDEOMEMORY;
            ddsd.dwWidth = abs(lpHdr->biWidth);
            ddsd.dwHeight = abs(lpHdr->biHeight);

            // define the pixel format
            ddsd.ddpfPixelFormat = m_ddUncompDataInfo.ddUncompPixelFormat;

            BITMAPINFOHEADER* pTmp = GetbmiHeader(pMediaType);
            DWORD dwFourccTmp = pTmp->biCompression;
            pTmp->biCompression = ddsd.ddpfPixelFormat.dwFourCC;
            hr = GetStreamInterlaceProperties(pMediaType,
                                              &m_InterlacedStream,
                                              &guidDeint,
                                              &m_DeinterlaceCaps);
            pTmp->biCompression = dwFourccTmp;

            //
            // don't use the SUCCEEDED macro here as
            // GetStreamInterlaceProperties can return S_FALSE
            //
            if (hr == S_OK && m_InterlacedStream) {

                //
                // we need to allocate enough samples for the
                // de-interlacer and enough for the DX-VA decode operation.
                //

                dwTotalBufferCount = amUncompBuffInfo.dwMinNumSurfaces;
                dwTotalBufferCount += (m_DeinterlaceCaps.NumForwardRefSamples +
                                       m_DeinterlaceCaps.NumBackwardRefSamples);
                DbgLog((LOG_TRACE, 0, TEXT("UnComp Buffers = %d"), dwTotalBufferCount));

                m_DeinterlaceGUID = guidDeint;
                lpDeinterlaceGUID = &m_DeinterlaceGUID;

            }
            else {
                m_InterlacedStream = FALSE;
                dwTotalBufferCount = amUncompBuffInfo.dwMinNumSurfaces;

                ZeroMemory(&m_DeinterlaceCaps, sizeof(m_DeinterlaceCaps));
                ZeroMemory(&m_DeinterlaceGUID, sizeof(m_DeinterlaceGUID));
                lpDeinterlaceGUID = NULL;
            }

            for (i = 0; i < 2; i++) {

                // CleanUp stuff from the last loop
                RELEASE(pSurface7);

                switch (i) {
                case 0:
                    ddsd.ddsCaps.dwCaps &= ~DDSCAPS_OFFSCREENPLAIN;
                    ddsd.ddsCaps.dwCaps |= DDSCAPS_TEXTURE;
                    dwSurfFlags = VMR_SF_TEXTURE;
                    break;

                case 1:
                    ddsd.ddsCaps.dwCaps &= ~DDSCAPS_TEXTURE;
                    ddsd.ddsCaps.dwCaps |= DDSCAPS_OFFSCREENPLAIN;
                    dwSurfFlags = VMR_SF_NONE;
                    break;
                }

                if (dwTotalBufferCount > 1) {

                    ddsd.dwFlags |= DDSD_BACKBUFFERCOUNT;
                    ddsd.ddsCaps.dwCaps |=
                        DDSCAPS_FLIP | DDSCAPS_COMPLEX | DDSCAPS_LOCALVIDMEM;

                    ddsd.dwBackBufferCount = dwTotalBufferCount - 1;
                }
                else {
                    ddsd.dwFlags &= ~DDSD_BACKBUFFERCOUNT;
                    ddsd.ddsCaps.dwCaps &= ~(DDSCAPS_FLIP | DDSCAPS_COMPLEX);
                    ddsd.dwBackBufferCount = 0;
                }

                hr = pDirectDraw->CreateSurface(&ddsd, &pSurface7, NULL);
                if (FAILED(hr)) {
                    DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                            TEXT("Function CreateSurface failed in Video memory, ")
                            TEXT("BackBufferCount = %d, hr = 0x%x"),
                            dwTotalBufferCount-1, hr));
                }

                if (SUCCEEDED(hr)) {
                    PaintDDrawSurfaceBlack(pSurface7);
                    break;
                }
            }

            //
            // Tell the VMR's mixer about the new DX-VA connection we have just made.
            // Also, create the DX-VA/Mixer sync event.
            //
            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("AllocateMCUncompSurfaces: Could not ")
                        TEXT("create UnComp surfaces") ));
                __leave;
            }

            ASSERT(m_hDXVAEvent == NULL);
            m_hDXVAEvent = CreateEvent(NULL, TRUE, FALSE, NULL);

            if (m_hDXVAEvent == NULL) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("Could not create DX-VA sync event") ));
                hr = E_FAIL;
                __leave;
            }
        }

        //
        // create a media type for this surface.
        //
        ASSERT(pSurface7);
        CHECK_HR(hr = pSurface7->GetSurfaceDesc(&ddsd));
        CHECK_HR(hr = ConvertSurfaceDescToMediaType(&ddsd,
                                                    pMediaType,
                                                    &pNewMediaType));
        m_mtNew = *(CMediaType *)pNewMediaType;
        m_mtNew.subtype = pMediaType->subtype;

        //
        // free the temporary mediatype
        //
        DeleteMediaType(pNewMediaType);
        pNewMediaType = NULL;

        if (!m_pRenderer->m_VMRModePassThru) {

            IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
            if (lpMixStream) {

                DbgLog((LOG_TRACE, 1,
                    TEXT("Pin %d calling SetStreamMediaType on the Mixer"),
                    m_dwPinID ));

                AM_MEDIA_TYPE mtTmp;
                CHECK_HR(hr = CopyMediaType(&mtTmp, (AM_MEDIA_TYPE*)pMediaType));

                BITMAPINFOHEADER *pTmp = GetbmiHeader(&mtTmp);
                BITMAPINFOHEADER *pCnt = GetbmiHeader(&m_mtNew);

                pTmp->biCompression = pCnt->biCompression;

                hr = lpMixStream->SetStreamMediaType(m_dwPinID, &mtTmp,
                                                     dwSurfFlags,
                                                     lpDeinterlaceGUID,
                                                     &m_DeinterlaceCaps);
                FreeMediaType(mtTmp);

                if (FAILED(hr)) {
                    __leave;
                }
            }
        }


        // store the complex surface in m_pDDS
        m_pDDS = pSurface7;
        m_pDDS->AddRef();
        m_dwBackBufferCount = dwTotalBufferCount - 1;

        ASSERT(m_pCompSurfInfo && NULL == m_pCompSurfInfo[0].pSurfInfo);
        m_pCompSurfInfo[0].pSurfInfo = new SURFACE_INFO[m_dwBackBufferCount + 1];

        if (NULL == m_pCompSurfInfo[0].pSurfInfo) {
            hr = E_OUTOFMEMORY;
            DbgLog((LOG_ERROR, 1,
                    TEXT("AllocateMCUncompSurfaces: memory allocation failed") ));
            __leave;
        }

        // memset the allcated memory to zero
        ZeroMemory(m_pCompSurfInfo[0].pSurfInfo,
                   (m_dwBackBufferCount + 1) * sizeof(SURFACE_INFO));

        pSurfaceInfo = m_pCompSurfInfo[0].pSurfInfo;
        m_pCompSurfInfo[0].dwAllocated = m_dwBackBufferCount + 1;

        // initalize the m_ppUncompSurfaceList
        pSurfaceInfo->pSurface = pSurface7;


        //
        //
        //
        ddsd.ddsCaps.dwCaps &= ~(DDSCAPS_FRONTBUFFER | DDSCAPS_VISIBLE);


        for (i = 0; i < m_dwBackBufferCount; i++) {

            // Get the back buffer surface
            // New version of DirectX now requires DDSCAPS2 (header file bug)
            // Note that this AddRef's the surface so we should be sure to
            // release them

            CHECK_HR(hr = pSurfaceInfo[i].pSurface->GetAttachedSurface(
                            &ddsd.ddsCaps,
                            &pSurfaceInfo[i+1].pSurface));
        }

        //
        // fix up the de-interlace surface structures
        //
        if (!m_pRenderer->m_VMRModePassThru && m_InterlacedStream) {

            DWORD dwBuffCount = 1 +
                                m_DeinterlaceCaps.NumForwardRefSamples +
                                m_DeinterlaceCaps.NumBackwardRefSamples;
            m_pVidHistorySamps = new DXVA_VideoSample[dwBuffCount];
            if (m_pVidHistorySamps == NULL) {
                hr = E_OUTOFMEMORY;
                __leave;
            }
            ZeroMemory(m_pVidHistorySamps, (dwBuffCount * sizeof(DXVA_VideoSample)));
            m_dwNumHistorySamples = dwBuffCount;
        }

        //  Pass back number of surfaces actually allocated
        CHECK_HR(hr = m_pIVANotify->SetUncompSurfacesInfo(dwTotalBufferCount));
    }
    __finally {

        if (FAILED(hr)) {

            if (m_hDXVAEvent) {
                CloseHandle(m_hDXVAEvent);
                m_hDXVAEvent = NULL;
            }

            ReleaseAllocatedSurfaces();
            RELEASE(pSurface7);
        }
    }


    return hr;
}


/*****************************Private*Routine******************************\
* CreateVideoAcceleratorObject
*
* create the motion comp object, using the misc data from the decoder
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::CreateVideoAcceleratorObject()
{
    HRESULT hr = NOERROR;
    DWORD dwSizeMiscData = 0;
    LPVOID pMiscData = NULL;

    AMTRACE((TEXT("CVMRInputPin::CreateVideoAcceleratorObject")));

    // get the data to be passed from the decoder
    hr = m_pIVANotify->GetCreateVideoAcceleratorData(&m_mcGuid,
                                                     &dwSizeMiscData,
                                                     &pMiscData);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("m_pIVANotify->GetCreateVideoAcceleratorData failed,")
                TEXT(" hr = 0x%x"), hr));
        return hr;
    }

    // ask the vga for the motion comp object
    hr = m_pIDDVAContainer->CreateVideoAccelerator(&m_mcGuid,
                                                   &m_ddUncompDataInfo,
                                                   pMiscData,
                                                   dwSizeMiscData,
                                                   &m_pIDDVideoAccelerator,
                                                   NULL);
    //  Free motion comp data
    CoTaskMemFree(pMiscData);

    if (FAILED(hr) || !m_pIDDVideoAccelerator) {

        if (SUCCEEDED(hr)) {
            hr = E_FAIL;
        }

        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("m_pIDDVAContainer->CreateVideoAcceleratorideo ")
                TEXT("failed, hr = 0x%x"), hr));
    }

    return hr;
}


/*****************************Private*Routine******************************\
* VACompleteConnect
*
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::VACompleteConnect(
    IPin *pReceivePin,
    const CMediaType *pMediaType
    )
{
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pbmiHeader = NULL;
    DWORD dwNumUncompFormats = 0;
    LPDIRECTDRAW7 pDirectDraw = NULL;

    AMTRACE((TEXT("CVMRInputPin::VACompleteConnect")));

    ASSERT(m_pIDDVAContainer);
    ASSERT(pReceivePin);
    ASSERT(pMediaType);

    pbmiHeader = GetbmiHeader(pMediaType);
    if (!pbmiHeader) {
        DbgLog((LOG_ERROR, 1, TEXT("Could not get bitmap header from MT")));
        return E_FAIL;
    }

    if (!m_pIVANotify) {
        DbgLog((LOG_ERROR, 1, TEXT("IAMVANotify not valid")));
        return E_FAIL;
    }

    pDirectDraw = m_pRenderer->m_lpDirectDraw;
    ASSERT(pDirectDraw);

    // save the decoder's guid
    m_mcGuid = pMediaType->subtype;

    // initialize the get the uncompressed formats supported by the vga
    hr = InitializeUncompDataInfo(pbmiHeader);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("InitializeUncompDataInfo failed, hr = 0x%x"), hr));
        return hr;
    }

    // allocate compressed buffers
    hr = AllocateVACompSurfaces(pDirectDraw, pbmiHeader);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("AllocateVACompSurfaces failed, hr = 0x%x"), hr));
        return hr;
    }

    // allocate uncompressed buffers
    hr = AllocateMCUncompSurfaces(pMediaType, pDirectDraw, pbmiHeader);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("AllocateMCUncompSurfaces failed, hr = 0x%x"), hr));
        return hr;
    }

    // create the motion comp object
    hr = CreateVideoAcceleratorObject();
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("CreateVideoAcceleratorObject failed, hr = 0x%x"), hr));
        return hr;
    }

    return hr;
}

/*****************************Private*Routine******************************\
* VABreakConnect()
*
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::VABreakConnect()
{
    HRESULT hr = NOERROR;
    DWORD i = 0, j = 0;

    AMTRACE((TEXT("CVMRInputPin::VABreakConnect")));

    if (m_pCompSurfInfo) {

        for (i = 0; i < m_dwCompSurfTypes + 1; i++) {

            DWORD dwAlloc = m_pCompSurfInfo[i].dwAllocated;

            if (!m_pCompSurfInfo[i].pSurfInfo)
                continue;

            // release the compressed surfaces
            for (j = 0; j < dwAlloc; j++) {

                if (m_pCompSurfInfo[i].pSurfInfo[j].pSurface) {

                    //  Unlock if necessary
                    if (m_pCompSurfInfo[i].pSurfInfo[j].pBuffer) {

                        m_pCompSurfInfo[i].pSurfInfo[j].pSurface->Unlock(NULL);
                    }
                    m_pCompSurfInfo[i].pSurfInfo[j].pSurface->Release();
                }
            }
            delete [] m_pCompSurfInfo[i].pSurfInfo;
        }
        delete [] m_pCompSurfInfo;
        m_pCompSurfInfo = NULL;
    }
    m_dwCompSurfTypes = 0;

    if (m_hDXVAEvent) {
        CloseHandle(m_hDXVAEvent);
        m_hDXVAEvent = NULL;
    }

    RELEASE(m_pIDDVideoAccelerator);
    RELEASE(m_pIDDVAContainer);
    RELEASE(m_pIVANotify);

    return hr;
}


// -------------------------------------------------------------------------
// IAMVideoAccelerator
// -------------------------------------------------------------------------
//

/******************************Public*Routine******************************\
* GetVideoAcceleratorGUIDs
*
* pdwNumGuidsSupported is an IN OUT paramter
* pGuidsSupported is an IN OUT paramter
*
* if pGuidsSupported is NULL,  pdwNumGuidsSupported should return back with the
* number of uncompressed pixel formats supported
* Otherwise pGuidsSupported is an array of *pdwNumGuidsSupported structures
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::GetVideoAcceleratorGUIDs(
    LPDWORD pdwNumGuidsSupported,
    LPGUID pGuidsSupported)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVMRInputPin::GetVideoAcceleratorGUIDs")));

    CAutoLock cLock(m_pInterfaceLock);

    LPDIRECTDRAW7 pDirectDraw;
    pDirectDraw = m_pRenderer->m_lpDirectDraw;
    if (!pDirectDraw) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("GetVideoAcceleratorGUIDs: VMR not inialized yet!")));
        return VFW_E_WRONG_STATE;
    }

    if (!m_pIDDVAContainer) {

        hr = pDirectDraw->QueryInterface(IID_IDDVideoAcceleratorContainer,
                                         (void**)&m_pIDDVAContainer);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                    TEXT("pDirectDraw->QueryInterface(")
                    TEXT("IID_IVideoAcceleratorContainer) failed, hr = 0x%x"),
                    hr));
            return hr;
        }
        else {
            DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
                    TEXT("pDirectDraw->QueryInterface(")
                    TEXT("IID_IVideoAcceleratorContainer) succeeded")));
        }
    }

    ASSERT(m_pIDDVAContainer);

    hr = m_pIDDVAContainer->GetVideoAcceleratorGUIDs(pdwNumGuidsSupported,
                                                     pGuidsSupported);

    return hr;
}



/******************************Public*Routine******************************\
* GetUncompFormatsSupported
*
* pGuid is an IN parameter
* pdwNumFormatsSupported is an IN OUT paramter
* pFormatsSupported is an IN OUT paramter (caller should make sure to set
* the size of EACH struct)
*
* if pFormatsSupported is NULL,  pdwNumFormatsSupported should return back with
* the number of uncompressed pixel formats supported
* Otherwise pFormatsSupported is an array of *pdwNumFormatsSupported structures
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::GetUncompFormatsSupported(
    const GUID * pGuid, LPDWORD pdwNumFormatsSupported,
    LPDDPIXELFORMAT pFormatsSupported)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVMRInputPin::GetUncompFormatsSupported")));

    CAutoLock cLock(m_pInterfaceLock);

    if (!m_pIDDVAContainer) {
        hr = E_FAIL;
        return hr;
    }

    hr = m_pIDDVAContainer->GetUncompFormatsSupported((GUID *)pGuid,
                                                      pdwNumFormatsSupported,
                                                      pFormatsSupported);

    return hr;
}

/******************************Public*Routine******************************\
* GetInternalMemInfo
*
* pGuid is an IN parameter
* pddvaUncompDataInfo is an IN parameter
* pddvaInternalMemInfo is an IN OUT parameter
*
* (caller should make sure to set the size of struct)
* currently only gets info about how much scratch memory will the
* hal allocate for its private use
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::GetInternalMemInfo(
    const GUID * pGuid,
    const AMVAUncompDataInfo *pamvaUncompDataInfo,
    LPAMVAInternalMemInfo pamvaInternalMemInfo)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVMRInputPin::GetInternalMemInfo")));

    CAutoLock cLock(m_pInterfaceLock);

    if (!m_pIDDVAContainer) {
        hr = E_FAIL;
        return hr;
    }

    DDVAUncompDataInfo ddvaDataInfo;
    INITDDSTRUCT(ddvaDataInfo);

    ddvaDataInfo.dwUncompWidth       = pamvaUncompDataInfo->dwUncompWidth;
    ddvaDataInfo.dwUncompHeight      = pamvaUncompDataInfo->dwUncompHeight;
    ddvaDataInfo.ddUncompPixelFormat = pamvaUncompDataInfo->ddUncompPixelFormat;

    DDVAInternalMemInfo ddvaInternalMemInfo;
    INITDDSTRUCT(ddvaInternalMemInfo);

    //  Unfortunately the ddraw header files don't use const
    hr = m_pIDDVAContainer->GetInternalMemInfo((GUID *)pGuid,
                                               &ddvaDataInfo,
                                               &ddvaInternalMemInfo);

    if (SUCCEEDED(hr)) {
        pamvaInternalMemInfo->dwScratchMemAlloc =
        ddvaInternalMemInfo.dwScratchMemAlloc;
    }

    return hr;
}


/******************************Public*Routine******************************\
* GetCompBufferInfo
*
* pGuid is an IN parameter
* pddvaUncompDataInfo is an IN parameter
* pdwNumTypesCompBuffers is an IN OUT paramter
* pddvaCompBufferInfo is an IN OUT paramter
*
* (caller should make sure to set the size of EACH struct)
* if pddvaCompBufferInfo is NULL,  pdwNumTypesCompBuffers should return
* back with the number of types of compressed buffers
* Otherwise pddvaCompBufferInfo is an array of *pdwNumTypesCompBuffers structures
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::GetCompBufferInfo(
    const GUID * pGuid,
    const AMVAUncompDataInfo *pamvaUncompDataInfo,
    LPDWORD pdwNumTypesCompBuffers,
    LPAMVACompBufferInfo pamvaCompBufferInfo)
{
    HRESULT hr = NOERROR;

    // Stays NULL if pamvaComBufferInfo is NULL
    DDVACompBufferInfo *pddvaCompBufferInfo = NULL;

    AMTRACE((TEXT("CVMRInputPin::GetCompBufferInfo")));

    CAutoLock cLock(m_pInterfaceLock);

    if (!m_pIDDVAContainer) {
        hr = E_FAIL;
        return hr;
    }

    DDVAUncompDataInfo ddvaDataInfo;
    INITDDSTRUCT(ddvaDataInfo);
    ddvaDataInfo.dwUncompWidth       = pamvaUncompDataInfo->dwUncompWidth;
    ddvaDataInfo.dwUncompHeight      = pamvaUncompDataInfo->dwUncompHeight;
    ddvaDataInfo.ddUncompPixelFormat = pamvaUncompDataInfo->ddUncompPixelFormat;


    if (pamvaCompBufferInfo) {

        pddvaCompBufferInfo = (DDVACompBufferInfo *)
                              _alloca(sizeof(DDVACompBufferInfo) *
                                      (*pdwNumTypesCompBuffers));

        for (DWORD j = 0; j < *pdwNumTypesCompBuffers; j++) {
            INITDDSTRUCT(pddvaCompBufferInfo[j]);
        }
    }

    hr = m_pIDDVAContainer->GetCompBufferInfo((GUID *)pGuid,
                                              &ddvaDataInfo,
                                              pdwNumTypesCompBuffers,
                                              pddvaCompBufferInfo);

    if ((SUCCEEDED(hr) || hr == DDERR_MOREDATA) && pamvaCompBufferInfo) {

        for (DWORD i = 0; i < *pdwNumTypesCompBuffers; i++) {

            DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
                    TEXT("Compressed buffer type(%d) %d buffers")
                    TEXT(" width(%d) height(%d) bytes(%d)"),
                    i,
                    pddvaCompBufferInfo[i].dwNumCompBuffers,
                    pddvaCompBufferInfo[i].dwWidthToCreate,
                    pddvaCompBufferInfo[i].dwHeightToCreate,
                    pddvaCompBufferInfo[i].dwBytesToAllocate));


            pamvaCompBufferInfo[i].dwNumCompBuffers     =
                pddvaCompBufferInfo[i].dwNumCompBuffers;

            pamvaCompBufferInfo[i].dwWidthToCreate      =
                pddvaCompBufferInfo[i].dwWidthToCreate;

            pamvaCompBufferInfo[i].dwHeightToCreate     =
                pddvaCompBufferInfo[i].dwHeightToCreate;

            pamvaCompBufferInfo[i].dwBytesToAllocate    =
                pddvaCompBufferInfo[i].dwBytesToAllocate;

            pamvaCompBufferInfo[i].ddCompCaps           =
                pddvaCompBufferInfo[i].ddCompCaps;

            pamvaCompBufferInfo[i].ddPixelFormat        =
                pddvaCompBufferInfo[i].ddPixelFormat;
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* CheckValidMCConnection
*
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::CheckValidMCConnection()
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVMRInputPin::CheckValidMCConnection")));

    // if not connected, this function does not make much sense
//  if (!IsCompletelyConnected()) {
//      DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
//              TEXT("pin not connected, exiting")));
//      hr = VFW_E_NOT_CONNECTED;
//      return hr;
//  }
//
//  if (m_RenderTransport != AM_VIDEOACCELERATOR) {
//      hr = VFW_E_INVALIDSUBTYPE;
//      return hr;
//  }

    return hr;
}


/******************************Public*Routine******************************\
* GetInternalCompBufferInfo
*
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::GetInternalCompBufferInfo(
    LPDWORD pdwNumTypesCompBuffers,
    LPAMVACompBufferInfo pamvaCompBufferInfo)
{
    AMTRACE((TEXT("CVMRInputPin::GetInternalCompBufferInfo")));

    HRESULT hr = NOERROR;
    CAutoLock cLock(m_pInterfaceLock);

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
        return hr;
    }

    ASSERT(m_pIDDVAContainer);

    DDVACompBufferInfo ddvaCompBufferInfo;
    INITDDSTRUCT(ddvaCompBufferInfo);

    AMVAUncompDataInfo amvaUncompDataInfo;
    amvaUncompDataInfo.dwUncompWidth       = m_ddUncompDataInfo.dwUncompWidth;
    amvaUncompDataInfo.dwUncompHeight      = m_ddUncompDataInfo.dwUncompHeight;
    amvaUncompDataInfo.ddUncompPixelFormat = m_ddUncompDataInfo.ddUncompPixelFormat;

    hr = GetCompBufferInfo(&m_mcGuid, &amvaUncompDataInfo,
                           pdwNumTypesCompBuffers, pamvaCompBufferInfo);

    return hr;
}


/******************************Public*Routine******************************\
* BeginFrame
*
*
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::BeginFrame(
    const AMVABeginFrameInfo *pamvaBeginFrameInfo
    )
{
    AMTRACE((TEXT("CVMRInputPin::BeginFrame")));

    // BUGBUG - check surface isn't being flipped
    HRESULT hr = NOERROR;
    DDVABeginFrameInfo ddvaBeginFrameInfo;
    SURFACE_INFO *pSurfInfo;

    CAutoLock cLock(m_pInterfaceLock);

    if (!pamvaBeginFrameInfo) {
        hr = E_POINTER;
        return hr;
    }

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("BeginFrame index %d"),
            pamvaBeginFrameInfo->dwDestSurfaceIndex));

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
        return hr;
    }


    INITDDSTRUCT(ddvaBeginFrameInfo);

    pSurfInfo = SurfaceInfoFromTypeAndIndex(
                                           0xFFFFFFFF,
                                           pamvaBeginFrameInfo->dwDestSurfaceIndex);
    if (pSurfInfo == NULL) {
        hr = E_INVALIDARG;
        return hr;
    }
    ddvaBeginFrameInfo.pddDestSurface = pSurfInfo->pSurface;

    DbgLog((LOG_TRACE, 2, TEXT("BeginFrame to surface %p"), pSurfInfo->pSurface));


    ddvaBeginFrameInfo.dwSizeInputData  = pamvaBeginFrameInfo->dwSizeInputData;
    ddvaBeginFrameInfo.pInputData       = pamvaBeginFrameInfo->pInputData;
    ddvaBeginFrameInfo.dwSizeOutputData = pamvaBeginFrameInfo->dwSizeOutputData;
    ddvaBeginFrameInfo.pOutputData      = pamvaBeginFrameInfo->pOutputData;

    ASSERT(m_pIDDVideoAccelerator);
    hr = m_pIDDVideoAccelerator->BeginFrame(&ddvaBeginFrameInfo);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("m_pIDDVideoAccelerator->BeginFrame failed, hr = 0x%x"), hr));
        return hr;
    }

    return hr;
}

/******************************Public*Routine******************************\
* EndFrame
*
* end a frame, the pMiscData is passed directly to the hal
* only valid to call this after the pins are connected
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::EndFrame(
    const AMVAEndFrameInfo *pEndFrameInfo
    )
{
    AMTRACE((TEXT("CVMRInputPin::EndFrame")));
    HRESULT hr = NOERROR;

    CAutoLock cLock(m_pInterfaceLock);

    if (NULL == pEndFrameInfo) {
        hr = E_POINTER;
        return hr;
    }

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
        return hr;
    }

    ASSERT(m_pIDDVideoAccelerator);

    DDVAEndFrameInfo ddvaEndFrameInfo;
    INITDDSTRUCT(ddvaEndFrameInfo);
    ddvaEndFrameInfo.dwSizeMiscData = pEndFrameInfo->dwSizeMiscData;
    ddvaEndFrameInfo.pMiscData      = pEndFrameInfo->pMiscData;

    hr = m_pIDDVideoAccelerator->EndFrame(&ddvaEndFrameInfo);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("m_pIDDVideoAccelerator->EndFrame failed, hr = 0x%x"),
                hr));
        return hr;
    }

    return hr;
}


/*****************************Private*Routine******************************\
* SurfaceInfoFromTypeAndIndex
*
* Get surface into structure given buffer type and buffer index
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
SURFACE_INFO *
CVMRInputPin::SurfaceInfoFromTypeAndIndex(
    DWORD dwTypeIndex,
    DWORD dwBufferIndex
    )
{
    AMTRACE((TEXT("CVMRInputPin::SurfaceInfoFromTypeAndIndex")));

    LPCOMP_SURFACE_INFO pCompSurfInfo;

    // make sure that type-index is less than the number of types
    if ((DWORD)(dwTypeIndex + 1) > m_dwCompSurfTypes) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("dwTypeIndex is invalid, dwTypeIndex = %d,")
                TEXT(" m_dwCompSurfTypes = %d"),
                dwTypeIndex, m_dwCompSurfTypes));
        return NULL;
    }


    // cache the pointer to the list they are interested in
    // Add 1 to allow for uncompressed surfaces
    pCompSurfInfo = m_pCompSurfInfo + (DWORD)(dwTypeIndex + 1);
    ASSERT(pCompSurfInfo);
    if (dwBufferIndex >= pCompSurfInfo->dwAllocated) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("dwBufferIndex is invalid, dwBufferIndex = %d,")
                TEXT(" dwAllocated = %d"),
                dwBufferIndex, pCompSurfInfo->dwAllocated));
        return NULL;
    }
    ASSERT(pCompSurfInfo->dwAllocated != 0);

    // get the pointer to the next available unlocked buffer info struct
    return pCompSurfInfo->pSurfInfo + dwBufferIndex;

}

/******************************Public*Routine******************************\
* GetBuffer
*
* Cycle through the compressed buffers
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::GetBuffer(
    DWORD dwTypeIndex,
    DWORD dwBufferIndex,
    BOOL bReadOnly,
    LPVOID *ppBuffer,
    LPLONG lpStride
    )
{
    AMTRACE((TEXT("CVMRInputPin::GetBuffer")));

    HRESULT hr = NOERROR;
    LPSURFACE_INFO pSurfInfo = NULL;
    DDSURFACEDESC2 ddsd;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("Entering CVMRInputPin::GetBuffer type %d, index %d"),
            dwTypeIndex, dwBufferIndex));

    CAutoLock cLock(m_pInterfaceLock);

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
        return hr;
    }

    if (ppBuffer == NULL || lpStride == NULL) {
        hr = E_POINTER;
        return hr;
    }

    pSurfInfo = SurfaceInfoFromTypeAndIndex(dwTypeIndex, dwBufferIndex);

    if (pSurfInfo == NULL) {
        hr = E_INVALIDARG;
        return hr;
    }

    // Check buffer not already locked
    if (pSurfInfo->pBuffer != NULL) {
        hr = HRESULT_FROM_WIN32(ERROR_BUSY);
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("No more free buffers left or the decoder is releasing")
                TEXT(" buffers out of order, returning E_UNEXPECTED")));
        return hr;
    }

    //  Wait until previous motion comp operation is complete
    while (DDERR_WASSTILLDRAWING ==
           m_pIDDVideoAccelerator->QueryRenderStatus(
                pSurfInfo->pSurface,
                bReadOnly ? DDVA_QUERYRENDERSTATUSF_READ : 0)) {
        Sleep(1);
    }

    //  Now lock the surface
    INITDDSTRUCT(ddsd);

    for (; ;) {
        //  BUGBUG - check for uncompressed surfaces??
        hr = pSurfInfo->pSurface->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK, NULL);
        if (hr == DDERR_WASSTILLDRAWING) {
            DbgLog((LOG_TRACE, 1, TEXT("Compressed surface is busy")));
            Sleep(1);
        }
        else {
            break;
        }
    }

    if (dwBufferIndex == 0xFFFFFFFF && !bReadOnly) {
        //  Check if surface is being displayed
        //  BUGBUG implement
    }

    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("pSurfInfo->pSurface->Lock failed, hr = 0x%x"), hr));
        return hr;
    }

    pSurfInfo->pBuffer = ddsd.lpSurface;
    *ppBuffer = ddsd.lpSurface;
    *lpStride = ddsd.lPitch;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("leaving CVMRInputPin::GetBuffer returned 0x%8.8X"), hr));
    return hr;
}


/******************************Public*Routine******************************\
* ReleaseBuffer
*
* unlock a compressed buffer
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::ReleaseBuffer(
    DWORD dwTypeIndex,
    DWORD dwBufferIndex
    )
{
    AMTRACE((TEXT("CVMRInputPin::ReleaseBuffer")));

    HRESULT hr = NOERROR;
    LPSURFACE_INFO pSurfInfo;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("Entering CVMRInputPin::ReleaseBuffer type %d, index %d"),
            dwTypeIndex, dwBufferIndex));

    CAutoLock cLock(m_pInterfaceLock);

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
        return hr;
    }

    pSurfInfo = SurfaceInfoFromTypeAndIndex(dwTypeIndex, dwBufferIndex);
    if (NULL == pSurfInfo) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("GetInfoFromCookie failed, hr = 0x%x"), hr));
        hr = E_INVALIDARG;
        return hr;
    }
    // make sure there is a valid buffer pointer and it is the same as
    // what we have cached
    if (NULL == pSurfInfo->pBuffer) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("pBuffer is not valid, pBuffer = 0x%x, pSurfInfo->pBuffer")
                TEXT(" = 0x%x"), pSurfInfo->pBuffer, pSurfInfo->pSurface));
        hr = HRESULT_FROM_WIN32(ERROR_NOT_LOCKED);
        return hr;
    }

    //  For some reason IDirectDrawSurface7 wants an LPRECT here
    //  I hope NULL is OK
    hr = pSurfInfo->pSurface->Unlock(NULL);
    if (SUCCEEDED(hr)) {
        pSurfInfo->pBuffer = NULL;
    }
    else {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("pSurfInfo->pSurface->Unlock failed, hr = 0x%x"), hr));
    }

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("leaving CVMRInputPin::ReleaseBuffer returned 0x%8.8X"), hr));
    return hr;
}


/******************************Public*Routine******************************\
* Execute
*
* Perform a decode operation
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::Execute(
    DWORD dwFunction,
    LPVOID lpPrivateInputData,
    DWORD cbPrivateInputData,
    LPVOID lpPrivateOutputData,
    DWORD cbPrivateOutputData,
    DWORD dwNumBuffers,
    const AMVABUFFERINFO *pamvaBufferInfo
    )
{
    AMTRACE((TEXT("CVMRInputPin::Execute")));

    HRESULT hr = NOERROR;
    DWORD i = 0;
    DDVABUFFERINFO *pddvaBufferInfo = NULL;

    CAutoLock cLock(m_pInterfaceLock);

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
        return hr;
    }

    pddvaBufferInfo = (DDVABUFFERINFO *)_alloca(sizeof(DDVABUFFERINFO) * dwNumBuffers);

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Execute Function %d, %d buffers :"),
            dwFunction, dwNumBuffers));

    for (i = 0; i < dwNumBuffers; i++) {
        DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
                TEXT("    Type(%d) Index(%d) offset(%d) size(%d)"),
                pamvaBufferInfo[i].dwTypeIndex,
                pamvaBufferInfo[i].dwBufferIndex,
                pamvaBufferInfo[i].dwDataOffset,
                pamvaBufferInfo[i].dwDataSize));

        LPSURFACE_INFO pSurfInfo =
        SurfaceInfoFromTypeAndIndex(
                                   pamvaBufferInfo[i].dwTypeIndex,
                                   pamvaBufferInfo[i].dwBufferIndex);

        if (pSurfInfo == NULL) {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                    TEXT("GetInfoFromCookie failed, hr = 0x%x, i = %d"),
                    hr, i));

            hr = E_INVALIDARG;
            return hr;
        }

        INITDDSTRUCT(pddvaBufferInfo[i]);
        pddvaBufferInfo[i].dwDataOffset   = pamvaBufferInfo[i].dwDataOffset;
        pddvaBufferInfo[i].dwDataSize     = pamvaBufferInfo[i].dwDataSize;
        pddvaBufferInfo[i].pddCompSurface = pSurfInfo->pSurface;
    }

    ASSERT(m_pIDDVideoAccelerator);


    hr = m_pIDDVideoAccelerator->Execute(dwFunction,
                                         lpPrivateInputData,
                                         cbPrivateInputData,
                                         lpPrivateOutputData,
                                         cbPrivateOutputData,
                                         dwNumBuffers,
                                         pddvaBufferInfo);

    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("m_pIDDVideoAccelerator->Execute failed, hr = 0x%x"),
                hr));
        return hr;
    }

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("leaving CVMRInputPin::Execute returned 0x%8.8X"), hr));
    return hr;
}

/******************************Public*Routine******************************\
* QueryRenderStatus
*
* QueryRenderStatus of a particular (possibly a set of) macro block
* dwNumBlocks is an IN parameter
*
* pdwCookies is an IN parameter which is array (of length dwNumBlocks)
* of cookies which server as identifiers for the corresponding members of
* pddvaMacroBlockInfo
*
* pddvaMacroBlockInfo is an IN parameter which is array (of length
* dwNumBlocks) of structures only valid to call this after the pins
* are connected
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::QueryRenderStatus(
    DWORD dwTypeIndex,
    DWORD dwBufferIndex,
    DWORD dwFlags
    )
{
    AMTRACE((TEXT("CVMRInputPin::QueryRenderStatus")));

    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("Entering CVMRInputPin::QueryRenderStatus - type(%d), ")
            TEXT("buffer(%d), flags(0x%8.8X)"),
            dwTypeIndex, dwBufferIndex, dwFlags));

    CAutoLock cLock(m_pInterfaceLock);

    LPSURFACE_INFO pSurfInfo =
    SurfaceInfoFromTypeAndIndex(dwTypeIndex, dwBufferIndex);

    if (pSurfInfo == NULL) {
        hr = E_OUTOFMEMORY;
        return hr;
    }

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
        return hr;
    }

    hr = m_pIDDVideoAccelerator->QueryRenderStatus(pSurfInfo->pSurface, dwFlags);
    if (FAILED(hr) && hr != DDERR_WASSTILLDRAWING) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("m_pIDDVideoAccelerator->QueryRenderStatus")
                TEXT(" failed, hr = 0x%x"), hr));
        return hr;
    }

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("leaving CVMRInputPin::QueryRenderStatus returned 0x%8.8X"),
            hr));

    if (hr == DDERR_WASSTILLDRAWING) {
        hr = E_PENDING;
    }

    return hr;
}


/*****************************Private*Routine******************************\
* FlipDVASurface
*
* Flips our internal surface pointers to match those used by DDraw.
*
* History:
* Mon 12/04/2000 - StEstrop - Created
*
\**************************************************************************/
void
CVMRInputPin::FlipDVASurface(
    DWORD dwFlipToIndex,
    DWORD dwFlipFromIndex
    )
{
    AMTRACE((TEXT("CVMRInputPin::FlipDVASurface")));

    LPDIRECTDRAWSURFACE7 pTempSurface;

    // we should have successfully called flip by this point, swap the two
    pTempSurface = m_pCompSurfInfo[0].pSurfInfo[dwFlipToIndex].pSurface;

    m_pCompSurfInfo[0].pSurfInfo[dwFlipToIndex].pSurface =
            m_pCompSurfInfo[0].pSurfInfo[dwFlipFromIndex].pSurface;

    m_pCompSurfInfo[0].pSurfInfo[dwFlipFromIndex].pSurface = pTempSurface;
}



/******************************Public*Routine******************************\
* DisplayFrame
*
* This function needs re-writting and possible moving into the AP object.
*
* History:
* Wed 05/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::DisplayFrame(
    DWORD dwFlipToIndex,
    IMediaSample *pMediaSample)
{
    AMTRACE((TEXT("CVMRInputPin::DisplayFrame")));

#if defined( EHOME_WMI_INSTRUMENTATION )
    PERFLOG_STREAMTRACE(
        1,
        PERFINFO_STREAMTRACE_VMR_END_DECODE,
        0, 0, 0, 0, 0 );
#endif

    HRESULT hr = NOERROR;

    DWORD dwNumUncompFrames = m_dwBackBufferCount + 1;
    DWORD dwFlipFromIndex = 0, i = 0;
    SURFACE_INFO *pSurfInfo;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("Entering CVMRInputPin::DisplayFrame - index %d"),
            dwFlipToIndex));

    CAutoLock cLock(m_pInterfaceLock);

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
        return hr;
    }

    pSurfInfo = SurfaceInfoFromTypeAndIndex(0xFFFFFFFF, dwFlipToIndex);
    if (pSurfInfo == NULL) {
        hr = E_INVALIDARG;
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("dwFlipToIndex not valid")));
        return hr;
    }

    for (i = 0; i < dwNumUncompFrames; i++) {
        if (IsEqualObject(m_pCompSurfInfo[0].pSurfInfo[i].pSurface, m_pDDS)) {
            dwFlipFromIndex = i;
            break;
        }
    }

    //
    // If we are in pass thru mode it is very important that we
    // know whether a Flip completed or not.  If are in mixer mode
    // we have to be notified when the mixer has finished with the sample
    //

    if (m_pRenderer->m_VMRModePassThru) {
        m_pRenderer->m_hrSurfaceFlipped = E_FAIL;
    }
    else {
        ResetEvent(m_hDXVAEvent);
    }


    //
    // Create our temp VMR sample and intialize it from the sample
    // specified by the upstream decoder, copy across all the relevant
    // properties.
    //

    IMediaSample2 *pSample2;
    CVMRMediaSample vmrSamp(TEXT(""), (CBaseAllocator *)-1, &hr, NULL, 0, m_hDXVAEvent);

    if (SUCCEEDED(pMediaSample->QueryInterface(IID_IMediaSample2, (void **)&pSample2))) {

        AM_SAMPLE2_PROPERTIES SampleProps;
        hr = pSample2->GetProperties(sizeof(m_SampleProps), (PBYTE)&SampleProps);
        pSample2->Release();

        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                    TEXT("GetProperties on the supplied ")
                    TEXT("media sample failed hr = %#X"), hr));
            return hr;
        }

        hr = vmrSamp.SetProps(SampleProps, pSurfInfo->pSurface);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                    TEXT("SetProperties on the VMR mixer ")
                    TEXT("media sample failed hr = %#X"), hr));
            return hr;
        }
    }
    else
    {

        REFERENCE_TIME rtSTime = 0, rtETime = 0;
        if (VFW_E_SAMPLE_TIME_NOT_SET ==
                pMediaSample->GetTime(&rtSTime, &rtETime)) {

            vmrSamp.SetTime(NULL, NULL);
        }
        else {
            vmrSamp.SetTime(&rtSTime, &rtETime);
        }

        AM_MEDIA_TYPE *pMediaType;
        hr = pMediaSample->GetMediaType(&pMediaType);

        if (hr == E_OUTOFMEMORY) {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                    TEXT("Out off memory calling GetMediaType ")
                    TEXT("on the media sample")));
            return hr;
        }

        if (hr == S_OK) {

            hr = vmrSamp.SetMediaType(pMediaType);
            DeleteMediaType(pMediaType);

            if (hr != S_OK) {
                DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                        TEXT("SetMediaType on the VMR mixer ")
                        TEXT("media sample failed hr = %#X"), hr));
                return hr;
            }
        }

        vmrSamp.SetSurface(pSurfInfo->pSurface);
    }


    //
    // We do not want to hold any locks during Receive
    //
    m_pInterfaceLock->Unlock();
    hr = Receive(&vmrSamp);
    m_pInterfaceLock->Lock();


    //
    // If we are in pass thru mode a DDraw flip may have
    // occurred.  DDraw switches the memory under the pointers
    // during a flip so mimic that in our list - but only if the
    // flip actually happened.
    //

    if (m_pRenderer->m_VMRModePassThru) {

        if (m_pRenderer->m_hrSurfaceFlipped == DD_OK) {
            FlipDVASurface(dwFlipToIndex, dwFlipFromIndex);
        }
    }
    else {

        //
        // wait for the sample to be released by the mixer, but only if the
        // sample was actuall placed onto one of the mixers queues.
        //

        if (hr == S_OK) {

            m_pInterfaceLock->Unlock();
            WaitForSingleObject(m_hDXVAEvent, INFINITE);
            m_pInterfaceLock->Lock();
        }
    }


    DbgLog((LOG_TRACE, VA_TRACE_LEVEL,
            TEXT("leaving CVMRInputPin::DisplayFrame return 0x%8.8X"), hr));

#if defined( EHOME_WMI_INSTRUMENTATION )
    //
    // From BryanW:
    //
    // Seems countintertuitive, however according to StEstrop, this
    // is the way we measure the time spent in the decoder.  This happens
    // to work.
    //
    PERFLOG_STREAMTRACE(
        1,
        PERFINFO_STREAMTRACE_VMR_BEGIN_DECODE,
        0, 0, 0, 0, 0 );
#endif

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\video\vmrmacvis.cpp ===
// Copyright (c) 1997 - 1999  Microsoft Corporation.  All Rights Reserved.
//
// VRMacVis.cpp:  Video Renderer's Macrovision support code
//

#include <streams.h>
#include <windowsx.h>
#include "vmrenderer.h"

// The magic GUID for Macrovision etc enabling (from winuser.h). It has
// not been given a name there and so is used here directly.
//
static const GUID guidVidParam =
    {0x2c62061, 0x1097, 0x11d1, {0x92, 0xf, 0x0, 0xa0, 0x24, 0xdf, 0x15, 0x6e}} ;

CVMRRendererMacroVision::CVMRRendererMacroVision(void) :
    m_dwCPKey(0),
    m_hMon(NULL)
{
    DbgLog((LOG_TRACE, 5, TEXT("CVMRRendererMacroVision::CVMRRendererMacroVision()"))) ;
}


CVMRRendererMacroVision::~CVMRRendererMacroVision(void)
{
    DbgLog((LOG_TRACE, 5, TEXT("CVMRRendererMacroVision::~CVMRRendererMacroVision()"))) ;
    ASSERT(0 == m_dwCPKey  &&  NULL == m_hMon) ;
}


BOOL
CVMRRendererMacroVision::StopMacroVision()
{
    if (0 == m_dwCPKey)
    {
        DbgLog((LOG_TRACE, 3, TEXT("Copy prot key was not acquired. Nothing to release."))) ;
        return TRUE ;  // success, what else?
    }

    if (NULL == m_hMon)
    {
        DbgLog((LOG_ERROR, 0, TEXT("WARNING: No GUID available while MV bit was already set."))) ;
        return TRUE ;  // FALSE??
    }

    LONG             lRet ;
    VIDEOPARAMETERS  VidParams ;
    DEVMODE          DevMode ;
    DISPLAY_DEVICE   dd ;
    ZeroMemory(&dd, sizeof(dd)) ;
    dd.cb = sizeof(dd) ;

    HMONITOR hMon = m_hMon;
    if (NULL == hMon)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("MonitorFromWindow(0x%p, ..) returned NULL (Error: %ld)"),
                (void *)m_hMon, GetLastError())) ;
        return FALSE ;
    }

    MONITORINFOEX  mi ;
    mi.cbSize = sizeof(mi) ;
    if (! GetMonitorInfo(hMon, &mi) )
    {
        DbgLog((LOG_ERROR, 0, TEXT("GetMonitorInfo() failed (Error: %ld)"),
                GetLastError())) ;
        return FALSE ;
    }
    DbgLog((LOG_TRACE, 3, TEXT("DeviceName: '%s'"), mi.szDevice)) ;
    ZeroMemory(&DevMode, sizeof(DevMode)) ;
    DevMode.dmSize = sizeof(DevMode) ;

    ZeroMemory(&VidParams, sizeof(VidParams)) ;
    VidParams.Guid      = guidVidParam ;
    VidParams.dwCommand = VP_COMMAND_GET ;

    lRet = ChangeDisplaySettingsEx(mi.szDevice, &DevMode, NULL,
                                   CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                   &VidParams) ;
    if (DISP_CHANGE_SUCCESSFUL != lRet)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ChangeDisplaySettingsEx(_GET) failed (%ld)"), lRet)) ;
        return FALSE ;
    }

    if (! ( (VidParams.dwFlags & VP_FLAGS_COPYPROTECT) &&
            (VidParams.dwCPType & VP_CP_TYPE_APS_TRIGGER) &&
            (VidParams.dwTVStandard & VidParams.dwCPStandard) ) )
    {
        // How did we acquire CP key in teh first place?
        DbgLog((LOG_ERROR, 0,
            TEXT("Copy prot weird error case (dwFlags=0x%lx, dwCPType=0x%lx, dwTVStandard=0x%lx, dwCPStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwCPType, VidParams.dwTVStandard, VidParams.dwCPStandard)) ;
        return FALSE ;
    }

    VidParams.dwCommand    = VP_COMMAND_SET ;
    VidParams.dwFlags      = VP_FLAGS_COPYPROTECT ;
    VidParams.dwCPType     = VP_CP_TYPE_APS_TRIGGER ;
    VidParams.dwCPCommand  = VP_CP_CMD_DEACTIVATE ;
    VidParams.dwCPKey      = m_dwCPKey ;
    VidParams.bCP_APSTriggerBits = (BYTE) 0 ;  // some value
    lRet = ChangeDisplaySettingsEx(mi.szDevice, &DevMode, NULL,
                                   CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                   &VidParams) ;
    if (DISP_CHANGE_SUCCESSFUL != lRet)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ChangeDisplaySettingsEx() failed (%ld)"), lRet)) ;
        return FALSE ;
    }

    DbgLog((LOG_TRACE, 1, TEXT("Macrovision deactivated on key %lu"), m_dwCPKey)) ;
    m_hMon  = NULL ;
    m_dwCPKey = 0 ;     // no CP set now

    return TRUE ;
}


//
// This function applies Macrovision based on the input parameter dwCPBits.
// hWnd is the handle of the window in which content is played back.
//
// Returns TRUE on success and FALSE on any failure.
//
BOOL
CVMRRendererMacroVision::SetMacroVision(
    HMONITOR hMon,
    DWORD dwCPBits
    )
{
    DbgLog((LOG_TRACE, 5, TEXT("CVMRRendererMacroVision::SetMacroVision(0x%p, 0x%lx)"),
            (LPVOID)hMon, dwCPBits)) ;

    //
    // If MV is currently not set at all and the new CP bits is 0 (which happens
    // when from the Nav we reset the MV bits on start / stop of playback), we
    // don't really need to do anything -- MV not started and doesn't need to be
    // started.  So just leave queitly...
    //
    if (0 == m_dwCPKey  &&  // no key acquired so far
        0 == dwCPBits)      // MV CPBits is 0
    {
        DbgLog((LOG_TRACE, 1, TEXT("Copy prot is not enabled now and new CP bits is 0 -- so skip it."))) ;
        return TRUE ;  // we don't need to do anything, so success.
    }

    //
    // May be we need to actually do something here
    //
    LONG             lRet ;
    VIDEOPARAMETERS  VidParams ;
    DEVMODE          DevMode ;
    DISPLAY_DEVICE   dd ;
    ZeroMemory(&dd, sizeof(dd)) ;
    dd.cb = sizeof(dd) ;

    if (NULL == hMon)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("MonitorFromWindow(0x%p, ..) returned NULL (Error: %ld)"),
                (void*)hMon, GetLastError())) ;
        return FALSE ;
    }

    MONITORINFOEX  mi ;
    mi.cbSize = sizeof(mi) ;
    if (! GetMonitorInfo(hMon, &mi) )
    {
        DbgLog((LOG_ERROR, 0, TEXT("GetMonitorInfo() failed (Error: %ld)"),
                GetLastError())) ;
        return FALSE ;
    }
    DbgLog((LOG_TRACE, 3, TEXT("DeviceName: '%s'"), mi.szDevice)) ;

    ZeroMemory(&DevMode, sizeof(DevMode)) ;
    DevMode.dmSize = sizeof(DevMode) ;

    ZeroMemory(&VidParams, sizeof(VidParams)) ;
    VidParams.Guid      = guidVidParam ;
    VidParams.dwCommand = VP_COMMAND_GET ;

    lRet = ChangeDisplaySettingsEx(mi.szDevice, &DevMode, NULL,
                                   CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                   &VidParams) ;
    if (DISP_CHANGE_SUCCESSFUL != lRet)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ChangeDisplaySettingsEx(_GET) failed (%ld)"), lRet)) ;
        return FALSE ;
    }

    if (0 == VidParams.dwFlags ||
        VP_TV_STANDARD_WIN_VGA == VidParams.dwTVStandard)
    {
        DbgLog((LOG_TRACE, 1, TEXT("** Copy protection NOT required (dwFlags=0x%lx, dwTVStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwTVStandard));
        return TRUE ;
    }

    //
    // Check to see if
    // a) the device supports copy prot
    // b) CP type is APS trigger
    // c) current TV standard and CP standard have commonality.
    // If so, apply copy prot. Otherwise error.
    //
    if ( (VidParams.dwFlags & VP_FLAGS_COPYPROTECT) &&
         (VidParams.dwCPType & VP_CP_TYPE_APS_TRIGGER) &&
         (VidParams.dwTVStandard & VidParams.dwCPStandard) )
    {
        DbgLog((LOG_TRACE, 3,
            TEXT("** Copy prot needs to be applied (dwFlags=0x%lx, dwCPType=0x%lx, dwTVStandard=0x%lx, dwCPStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwCPType, VidParams.dwTVStandard, VidParams.dwCPStandard)) ;

        VidParams.dwCommand = VP_COMMAND_SET ;          // do we have to set it again??
        VidParams.dwFlags   = VP_FLAGS_COPYPROTECT ;
        VidParams.dwCPType  = VP_CP_TYPE_APS_TRIGGER ;
        VidParams.bCP_APSTriggerBits = (BYTE) (dwCPBits & 0xFF) ;

        // Check if we already have a copy prot key; if not, get one now
        if (0 == m_dwCPKey)  // no key acquired so far
        {
            // Acquire a new key (that also aplies it, so no separate Set reqd)
            VidParams.dwCPCommand = VP_CP_CMD_ACTIVATE ;
            VidParams.dwCPKey     = 0 ;
            lRet = ChangeDisplaySettingsEx(mi.szDevice, &DevMode, NULL,
                                           CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                           &VidParams) ;
            if (DISP_CHANGE_SUCCESSFUL != lRet)
            {
                DbgLog((LOG_ERROR, 0,
                    TEXT("** ChangeDisplaySettingsEx() failed (%ld) to activate copy prot"), lRet)) ;
                return FALSE ;
            }

            m_dwCPKey = VidParams.dwCPKey ;
            DbgLog((LOG_TRACE, 3, TEXT("** Copy prot activated. Key value is %lu"), m_dwCPKey)) ;
        }
        else  // key already acquired
        {
            // apply the copy prot bits specified in the content
            VidParams.dwCPCommand = VP_CP_CMD_CHANGE ;
            VidParams.dwCPKey     = m_dwCPKey ;
            DbgLog((LOG_TRACE, 5, TEXT("** Going to call ChangeDisplaySettingsEx(_SET)..."))) ;
            lRet = ChangeDisplaySettingsEx(mi.szDevice, &DevMode, NULL,
                                           CDS_VIDEOPARAMETERS | CDS_NORESET | CDS_UPDATEREGISTRY,
                                           &VidParams) ;
            if (DISP_CHANGE_SUCCESSFUL != lRet)
            {
                DbgLog((LOG_ERROR, 0,
                    TEXT("** ChangeDisplaySettingsEx() failed (%ld) to set copy prot bits (%lu)"),
                    lRet, dwCPBits)) ;
                return FALSE ;
            }
            else
                DbgLog((LOG_TRACE, 3, TEXT("** Copy prot bits (0x%lx) applied"), dwCPBits)) ;
        }
    }
    else
    {
        DbgLog((LOG_ERROR, 0,
            TEXT("** Copy prot error case (dwFlags=0x%lx, dwCPType=0x%lx, dwTVStandard=0x%lx, dwCPStandard=0x%lx"),
                VidParams.dwFlags, VidParams.dwCPType, VidParams.dwTVStandard, VidParams.dwCPStandard)) ;
        return FALSE ;
    }

    m_hMon = hMon;

    return TRUE ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\video\vmrfilter.cpp ===
/******************************Module*Header*******************************\
* Module Name: VMRFilter.cpp
*
*
*
*
* Created: Tue 02/15/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <windowsx.h>
#include <limits.h>

#ifdef FILTER_DLL
#include <initguid.h>
#endif

#include <d3d.h>
#include "VMRenderer.h"
#include "dvdmedia.h"  // for MacroVision prop set, id

#if defined(CHECK_FOR_LEAKS)
#include "ifleak.h"
#endif

#ifndef DECLSPEC_SELECTANY
#if (_MSC_VER >= 1100)
#define DECLSPEC_SELECTANY  __declspec(selectany)
#else
#define DECLSPEC_SELECTANY
#endif
#endif

EXTERN_C const GUID DECLSPEC_SELECTANY IID_IDirectDraw7 =
{
    0x15e65ec0, 0x3b9c, 0x11d2,
    {
        0xb9, 0x2f, 0x00, 0x60, 0x97, 0x97, 0xea, 0x5b
    }
};

#ifndef FILTER_DLL
#include <initguid.h>
#endif

// {565DCEF2-AFC5-11d2-8853-0000F80883E3}
DEFINE_GUID(CLSID_COMQualityProperties,
0x565dcef2, 0xafc5, 0x11d2, 0x88, 0x53, 0x0, 0x0, 0xf8, 0x8, 0x83, 0xe3);

// {A2CA6D57-BE10-45e0-9B81-7523681EC278}
DEFINE_GUID(CLSID_VMRFilterConfigProp,
0xa2ca6d57, 0xbe10, 0x45e0, 0x9b, 0x81, 0x75, 0x23, 0x68, 0x1e, 0xc2, 0x78);

// {DEE51F07-DDFF-4e34-8FA9-1BF49179DB8D}
DEFINE_GUID(CLSID_VMRDeinterlaceProp,
0xdee51f07, 0xddff, 0x4e34, 0x8f, 0xa9, 0x1b, 0xf4, 0x91, 0x79, 0xdb, 0x8d);

// Setup data

const AMOVIESETUP_MEDIATYPE
sudVMRPinTypes =
{
    &MEDIATYPE_Video,           // Major type
    &MEDIASUBTYPE_NULL          // And subtype
};

const AMOVIESETUP_PIN
sudVMRPin =
{
    L"Input",                   // Name of the pin
    TRUE,                       // Is pin rendered
    FALSE,                      // Is an Output pin
    FALSE,                      // Ok for no pins
    FALSE,                      // Can we have many
    &CLSID_NULL,                // Connects to filter
    NULL,                       // Name of pin connect
    1,                          // Number of pin types
    &sudVMRPinTypes             // Details for pins
};

// The video renderer should be called "Video Renderer" for
// compatibility with applications using FindFilterByName (e.g., Shock
// to the System 2)

const AMOVIESETUP_FILTER
sudVMRFilter =
{
    &CLSID_VideoRendererDefault, // Filter CLSID
    L"Video Renderer",           // Filter name
    MERIT_PREFERRED + 1,
    1,                          // Number pins
    &sudVMRPin                  // Pin details
};

#ifdef FILTER_DLL
const AMOVIESETUP_FILTER
sudVMRFilter2 =
{
    &CLSID_VideoMixingRenderer,
    L"Video Mixing Renderer",    // Filter name
    MERIT_PREFERRED + 2,
    1,                          // Number pins
    &sudVMRPin                  // Pin details
};

STDAPI DllRegisterServer()
{
    AMTRACE((TEXT("DllRegisterServer")));
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
    AMTRACE((TEXT("DllUnregisterServer")));
    return AMovieDllRegisterServer2( FALSE );
}

CFactoryTemplate g_Templates[] = {
    {
        L"",
        &CLSID_VideoMixingRenderer,
        CVMRFilter::CreateInstance,
        CVMRFilter::InitClass,
        &sudVMRFilter2
    },
    {
        L"",
        &CLSID_VideoRendererDefault,
        CVMRFilter::CreateInstance2,
        NULL,
        &sudVMRFilter
    }
};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);

#endif

// This goes in the factory template table to create new filter instances

CUnknown* CVMRFilter::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    AMTRACE((TEXT("CVMRFilter::CreateInstance")));

    //
    // The VMR is being created explictly via a call to CoCreateInstance
    // with the VMR's class ID.  We don't create the Allocator-Presenter object
    // during the VMR's constructor when in this mode.  This is because the
    // application may have already entered DDraw Exclusive mode.  The
    // default Allocator-Presenter won't work in this DDraw mode which would
    // cause the VMR's constructor to fail.
    //
    CUnknown* pk = new CVMRFilter(NAME("Video Mixing Renderer"),
                                  pUnk, phr, FALSE);

    return pk;
}

// create the VMR or the VR if VMR fails due to 8bpp screen mode. what
// about ddraw.dll failing to load?
//
CUnknown* CVMRFilter::CreateInstance2(LPUNKNOWN pUnk, HRESULT *phr)
{
    AMTRACE((TEXT("CVMRFilter::CreateInstance2")));

    //
    // Create the VMR as the default renderer, in this mode we
    // create the Allocator-Presenter object in the VMR's constructor.
    // Doing this provides early feedback as to whether the VMR can be used
    // in this graphics mode.
    //
    CUnknown* pk = new CVMRFilter(NAME("Video Mixing Renderer"),
                                  pUnk, phr, TRUE);

    if(*phr == VFW_E_DDRAW_CAPS_NOT_SUITABLE) {

#ifndef FILTER_DLL
        delete pk;
        *phr = S_OK;
        CUnknown* CRenderer_CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);
        return CRenderer_CreateInstance(pUnk, phr);
#else
        DbgBreak("8bpp unsupported with separate dlls");
#endif
    }

    return pk;
}


/******************************Public*Routine******************************\
* InitClass
*
*
*
* History:
* Thu 12/14/2000 - StEstrop - Created
*
\**************************************************************************/
#if defined(CHECK_FOR_LEAKS)
// the one and only g_IFLeak object.
CInterfaceLeak  g_IFLeak;

void
CVMRFilter::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
    if (bLoading) {
        DbgLog(( LOG_TRACE, 0, TEXT("VMR Thunks: Loaded") ));
        g_IFLeak.Init();
    }
    else {
        DbgLog(( LOG_TRACE, 0, TEXT("VMR Thunks: Unloaded") ));
        g_IFLeak.Term();
    }
}
#else
void
CVMRFilter::InitClass(
    BOOL bLoading,
    const CLSID *clsid
    )
{
}
#endif


/*****************************Private*Routine******************************\
* GetMediaPositionInterface
*
*
*
* History:
* Tue 03/28/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::GetMediaPositionInterface(
    REFIID riid,
    void ** ppv
    )
{
    AMTRACE((TEXT("CVMRFilter::GetMediaPositionInterface")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (m_pPosition) {
        return m_pPosition->NonDelegatingQueryInterface(riid, ppv);
    }

    HRESULT hr = S_OK;
    m_pPosition = new CRendererPosPassThru(NAME("Renderer CPosPassThru"),
                                           CBaseFilter::GetOwner(),
                                           &hr,
                                           GetPin(0));
    if (m_pPosition == NULL) {
        DbgLog((LOG_ERROR, 1,
                TEXT("CreatePosPassThru failed - no memory") ));
        return E_OUTOFMEMORY;
    }

    if (FAILED(hr)) {
        delete m_pPosition;
        DbgLog((LOG_ERROR, 1,
                TEXT("CreatePosPassThru failed, hr = 0x%x"), hr));
        return E_NOINTERFACE;
    }

    return GetMediaPositionInterface(riid,ppv);
}

/*****************************Private*Routine******************************\
* ModeChangeAllowed
*
*
*
* History:
* Fri 04/07/2000 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVMRFilter::ModeChangeAllowed()
{
    AMTRACE((TEXT("CVMRFilter::ModeChangeAllowed")));

    BOOL fRet = ((m_VMRMode & VMRMode_Windowed) &&
                  0 == NumInputPinsConnected() && m_bModeChangeAllowed);

    DbgLog((LOG_TRACE, 2, TEXT("Allowed = %d"), fRet));

    return fRet;
}

/*****************************Private*Routine******************************\
* SetVMRMode
*
*
*
* History:
* Fri 04/07/2000 - StEstrop - Created
*
\**************************************************************************/
void
CVMRFilter::SetVMRMode(
    DWORD mode
    )
{
    AMTRACE((TEXT("CVMRFilter::SetVMRMode")));

    DbgLog((LOG_TRACE, 2, TEXT("Mode = %d"), mode));

    if (m_bModeChangeAllowed) {

        m_bModeChangeAllowed = FALSE;
        m_VMRMode = mode;

        //
        // If we are going renderless get rid of the default
        // allocator-presenter.
        //
        if (mode == VMRMode_Renderless ) {
            m_pIVMRSurfaceAllocatorNotify.AdviseSurfaceAllocator(0, NULL);
        }

        ASSERT(m_pVideoWindow);

        if (m_VMRMode != VMRMode_Windowed && m_pVideoWindow) {
            m_pVideoWindow->InactivateWindow();
            m_pVideoWindow->DoneWithWindow();
            delete m_pVideoWindow;
            m_pVideoWindow = NULL;
        }
    }
    else {

        ASSERT(m_VMRMode == mode);
    }
}


/******************************Public*Routine******************************\
* NonDelegatingQueryInterface
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::NonDelegatingQueryInterface(
    REFIID riid,
    void ** ppv
    )
{
    AMTRACE((TEXT("CVMRFilter::NonDelegatingQueryInterface")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    //
    // The following 3 interfaces control the rendering mode that
    // the video renderer adopts
    //
    HRESULT hr = E_NOINTERFACE;
    *ppv = NULL;

    if (riid == IID_IVMRSurfaceAllocatorNotify) {

        if (m_VMRMode == VMRMode_Renderless ) {
            hr = GetInterface(&m_pIVMRSurfaceAllocatorNotify, ppv);
        }
    }
    else if (riid == IID_IBasicVideo || riid == IID_IBasicVideo2 ||
             riid == IID_IVideoWindow) {

        if (m_VMRMode == VMRMode_Windowed) {
            hr = m_pVideoWindow->NonDelegatingQueryInterface(riid,ppv);
        }
    }
    else if (riid == IID_IVMRWindowlessControl) {

        if (m_VMRMode == VMRMode_Windowless ) {
            hr = GetInterface((IVMRWindowlessControl *) this, ppv);
        }
        else if (m_VMRMode == VMRMode_Renderless ) {
            if (ValidateIVRWindowlessControlState() == S_OK) {
                hr = GetInterface((IVMRWindowlessControl *) this, ppv);
            }
        }
    }
    else if (riid == IID_IVMRMixerControl) {

        if (!m_VMRModePassThru && m_lpMixControl) {
            hr = GetInterface((IVMRMixerControl *) this, ppv);
        }
    }

    else if (riid == IID_IVMRDeinterlaceControl) {

        hr = GetInterface((IVMRDeinterlaceControl *)(this), ppv);
    }

    //
    // Need to sort out how to seek when we have multiple input streams
    // feeding us.  Seeking should only be allowed if all the input streams
    // are "seekable"
    //

    else if (riid == IID_IMediaPosition || riid == IID_IMediaSeeking) {

        return GetMediaPositionInterface(riid,ppv);
    }

    else if (riid == IID_IKsPropertySet) {

        hr = GetInterface((IKsPropertySet *)this, ppv);
    }

    else if (riid == IID_IAMFilterMiscFlags) {

        hr = GetInterface((IAMFilterMiscFlags *)this, ppv);
    }

    else if (riid == IID_IQualProp) {

        hr = GetInterface(static_cast<IQualProp *>(this), ppv);
    }

    else if (riid == IID_IQualityControl) {

        hr = GetInterface(static_cast<IQualityControl *>(this), ppv);
    }

    else if (riid == IID_IVMRFilterConfig) {
        hr = GetInterface(static_cast<IVMRFilterConfig *>(this), ppv);
    }

    else if (riid == IID_IVMRFilterConfigInternal) {
        hr = GetInterface(static_cast<IVMRFilterConfigInternal *>(this), ppv);
    }

    else if (riid == IID_IVMRMonitorConfig) {

        if ((m_VMRMode & VMRMode_Windowless) ||
            (m_VMRMode & VMRMode_Windowed)) {

            if (ValidateIVRWindowlessControlState() == S_OK) {
                hr = GetInterface(static_cast<IVMRMonitorConfig *>(this), ppv);
            }
        }
    }

    else if (riid == IID_IVMRMixerBitmap) {
        hr = GetInterface(static_cast<IVMRMixerBitmap *>(this), ppv);
    }

    else if (riid == IID_ISpecifyPropertyPages) {
        hr = GetInterface(static_cast<ISpecifyPropertyPages *>(this), ppv);
    }

    else if (riid == IID_IPersistStream) {
        hr = GetInterface(static_cast<IPersistStream *>(this), ppv);
    }

    else {
        hr = CBaseFilter::NonDelegatingQueryInterface(riid,ppv);

    }

#if defined(CHECK_FOR_LEAKS)
    if (hr == S_OK) {
        _pIFLeak->AddThunk((IUnknown **)ppv, "VMR Filter Object",  riid);
    }
#endif

    return hr;
}

struct VMRHardWareCaps {
    HRESULT     hr2D;
    HRESULT     hr3D;
    DWORD       dwBitDepth;
};


/*****************************Private*Routine******************************\
* D3DEnumDevicesCallback7
*
*
*
* History:
* Tue 01/16/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT CALLBACK
VMRD3DEnumDevicesCallback7(
    LPSTR lpDeviceDescription,
    LPSTR lpDeviceName,
    LPD3DDEVICEDESC7 lpD3DDeviceDesc,
    LPVOID lpContext
    )
{
    AMTRACE((TEXT("VMRD3DEnumDevicesCallback7")));
    VMRHardWareCaps* pHW = (VMRHardWareCaps*)lpContext;
    if (lpD3DDeviceDesc->deviceGUID == IID_IDirect3DHALDevice) {

        switch (pHW->dwBitDepth) {
        case 16:
            if (lpD3DDeviceDesc->dwDeviceRenderBitDepth & DDBD_16) {
                pHW->hr3D = DD_OK;
            }
            break;

        case 24:
            if (lpD3DDeviceDesc->dwDeviceRenderBitDepth & DDBD_24) {
                pHW->hr3D = DD_OK;
            }
            break;

        case 32:
            if (lpD3DDeviceDesc->dwDeviceRenderBitDepth & DDBD_32) {
                pHW->hr3D = DD_OK;
            }
            break;
        }
    }

    return (HRESULT)D3DENUMRET_OK;
}

/*****************************Private*Routine******************************\
* VMRDDEnumCallbackExA
*
*
*
* History:
* Fri 01/12/2001 - StEstrop - Created
*
\**************************************************************************/
BOOL WINAPI
VMRDDEnumCallbackExA(
    GUID *pGUID,
    LPSTR lpDriverDesc,
    LPSTR lpDriverName,
    LPVOID lpContext,
    HMONITOR  hm
    )
{
    AMTRACE((TEXT("VMRDDEnumCallbackExA")));
    LPDIRECTDRAW7 pDD = NULL;
    LPDIRECT3D7 pD3D = NULL;

    VMRHardWareCaps* pHW = (VMRHardWareCaps*)lpContext;

    __try {
        HRESULT hRet;
        CHECK_HR( hRet = DirectDrawCreateEx(pGUID, (LPVOID *)&pDD,
                                            IID_IDirectDraw7, NULL) );
        DDCAPS ddHWCaps;
        INITDDSTRUCT(ddHWCaps);
        CHECK_HR(hRet = pDD->GetCaps(&ddHWCaps, NULL));

        DDSURFACEDESC2 ddsd = {sizeof(DDSURFACEDESC2)};
        CHECK_HR(hRet = pDD->GetDisplayMode(&ddsd));

        //
        // h/w rules
        // 2D is OK provided the bit depth is greater than
        // RGB8, even if we don't have any display h/w acceleration.
        // 3D requires > RGB8 and hardware acceleration.
        //

        if (ddsd.ddpfPixelFormat.dwRGBBitCount > 8) {

            pHW->hr2D = DD_OK;

            if (!(ddHWCaps.dwCaps & DDCAPS_NOHARDWARE)) {

                pHW->dwBitDepth = ddsd.ddpfPixelFormat.dwRGBBitCount;
                CHECK_HR(hRet = pDD->QueryInterface(IID_IDirect3D7, (LPVOID *)&pD3D));
                pD3D->EnumDevices(VMRD3DEnumDevicesCallback7, lpContext);
            }
        }
    }
    __finally {
        RELEASE(pD3D);
        RELEASE(pDD);
    }

    return TRUE;
}

/*****************************Private*Routine******************************\
* BasicHWCheck
*
* In order for the VMR to operate we need some DDraw h/w and a graphics
* display mode greater than 8bits per pixel.
*
* History:
* Fri 01/12/2001 - StEstrop - Created
*
\**************************************************************************/
VMRHardWareCaps
BasicHWCheck()
{
    AMTRACE((TEXT("BasicHWCheck")));
    VMRHardWareCaps hrDDraw = {VFW_E_DDRAW_CAPS_NOT_SUITABLE,
                               VFW_E_DDRAW_CAPS_NOT_SUITABLE};

    HRESULT hr = DirectDrawEnumerateExA(VMRDDEnumCallbackExA, (LPVOID)&hrDDraw,
                                        DDENUM_ATTACHEDSECONDARYDEVICES);
    if (FAILED(hr)) {
        hrDDraw.hr2D = VFW_E_DDRAW_CAPS_NOT_SUITABLE;
        hrDDraw.hr3D = VFW_E_DDRAW_CAPS_NOT_SUITABLE;
    }

    return hrDDraw;
}


/******************************Public*Routine******************************\
* CVMRFilter::CVMRFilter
*
*
* Turn off "warning C4355: 'this' : used in base member initializer list"
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
#pragma warning(disable:4355)
CVMRFilter::CVMRFilter(
    TCHAR *pName,
    LPUNKNOWN pUnk,
    HRESULT *phr,
    BOOL fDefault
    ) :
    CBaseFilter(pName, pUnk, &m_InterfaceLock, CLSID_VideoMixingRenderer),
    CPersistStream(pUnk, phr),
    m_pIVMRSurfaceAllocatorNotify(this),
    m_pIVMRImagePresenter(this),
    m_pIImageSyncNotifyEvent(this),
    m_VMRMode(VMRMode_Windowed),
    m_VMRModePassThru(true),
    m_fInputPinCountSet(false),
    m_dwNumPins(0),
    m_bModeChangeAllowed(TRUE),
    m_lpRLNotify(NULL),
    m_lpWLControl(NULL),
    m_lpIS(NULL),
    m_lpISControl(NULL),
    m_lpMixControl(NULL),
    m_lpMixBitmap(NULL),
    m_lpMixStream(NULL),
    m_lpPresenter(NULL),
    m_pPresenterConfig(NULL),
    m_pPresenterMonitorConfig(NULL),
    m_lpISQualProp(NULL),
    m_lpDirectDraw(NULL),
    m_hMonitor(NULL),
    m_pPosition(NULL),
    m_pVideoWindow(NULL),
    m_pDeinterlace(NULL),
    m_TexCaps(0),
    m_dwDisplayChangeMask(0),
    m_dwEndOfStreamMask(0),
    m_ARMode(VMR_ARMODE_NONE), // please update CompleteConnect if you change this
    m_bARModeDefaultSet(FALSE),
    m_hr3D(DD_OK),
    m_dwRenderPrefs(0),
    m_dwDeinterlacePrefs(DeinterlacePref_NextBest),
    m_VMRCreateAsDefaultRenderer(fDefault)
{
    AMTRACE((TEXT("CVMRFilter::CVMRFilter")));
    HRESULT hr = S_OK;

    ZeroMemory(m_pInputPins, sizeof(m_pInputPins));
    ZeroMemory(&m_ddHWCaps, sizeof(m_ddHWCaps));
    ZeroMemory(&m_ddpfMonitor, sizeof(m_ddpfMonitor));

#ifdef DEBUG
    if (GetProfileIntA("VMR", "LetterBox", 0) == 1) {
        m_ARMode = VMR_ARMODE_LETTER_BOX;
    }

    if (GetProfileIntA("VMR", "APGMemFirst", 0) == 1) {
        m_dwRenderPrefs = RenderPrefs_PreferAGPMemWhenMixing;
    }
#endif

    __try
    {
        VMRHardWareCaps hrDDraw = BasicHWCheck();
        m_hr3D = hrDDraw.hr3D;
        if (FAILED(hrDDraw.hr2D)) {

            DbgLog((LOG_ERROR, 1,
                    TEXT("The machine does not have the necessary h/w to run the VMR!!")));
            *phr = hrDDraw.hr2D;
            __leave;
        }

        hr = ImageSyncInit();
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("Image Synchronization initialization FAILED!!")));
            *phr = hr;
            __leave;
        }

        hr = CreateInputPin();
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("Pin initialization FAILED!!")));
            *phr = hr;
            __leave;
        }

        m_pVideoWindow = new CVMRVideoWindow(this, &m_InterfaceLock, GetOwner(), phr);
        if (FAILED(*phr) || m_pVideoWindow == NULL) {

            DbgLog((LOG_ERROR, 1, TEXT("Can't create Video Window!!")));
            if (m_pVideoWindow == NULL) {
                *phr = E_OUTOFMEMORY;
            }
            __leave;
        }
        hr = m_pVideoWindow->PrepareWindow();
        if (FAILED(hr)) {
            *phr = hr;
            __leave;
        }

        if (m_VMRCreateAsDefaultRenderer) {
            hr = ValidateIVRWindowlessControlState();
            if (FAILED(hr)) {
                DbgLog((LOG_ERROR,1,TEXT("Unloading VMR because default AP creation failed")));
                *phr = VFW_E_DDRAW_CAPS_NOT_SUITABLE;
                __leave;
            }
        }

#ifdef DEBUG
        if (GetProfileIntA("VMR", "FrameRate", 0) == 1) {
            m_pVideoWindow->StartFrameRateTimer();
        }
#endif

    }
    __finally
    {
        if ( FAILED(hr) )
        {
            VMRCleanUp();
        }
    }
}

/*****************************Private*Routine******************************\
* VMRCleanUp
*
*
*
* History:
* Thu 04/05/2001 - StEstrop - Created
*
\**************************************************************************/
void
CVMRFilter::VMRCleanUp()
{
    //  Release passthru
    delete m_pPosition;

    //  Release the Window Manager (if we have one)
    if (m_pVideoWindow) {
        m_pVideoWindow->InactivateWindow();
        m_pVideoWindow->DoneWithWindow();
        delete m_pVideoWindow;
        m_pVideoWindow = NULL;
    }

    RELEASE(m_lpMixBitmap);
    RELEASE(m_lpMixControl);
    RELEASE(m_lpMixStream);
    RELEASE(m_lpRLNotify);
    RELEASE(m_lpPresenter);
    RELEASE(m_pPresenterConfig);
    RELEASE(m_pPresenterMonitorConfig);
    RELEASE(m_lpWLControl);
    RELEASE(m_lpIS);

    if (m_lpISControl) {
        m_lpISControl->SetEventNotify(NULL);
        m_lpISControl->SetImagePresenter(NULL, 0);
        m_lpISControl->SetReferenceClock(NULL);
        RELEASE(m_lpISControl);
    }

    RELEASE(m_lpISQualProp);

    DWORD i;
    for (i = 0; i < m_dwNumPins; i++) {
        delete m_pInputPins[i];
        m_pInputPins[i] = NULL;
    }

    for (i = m_dwNumPins; i < MAX_MIXER_PINS; i++) {
        ASSERT(m_pInputPins[i] == NULL);
    }

    SetDDrawDeviceWorker(NULL, NULL);
}


/******************************Public*Routine******************************\
* CVMRFilter::~CVMRFilter
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
CVMRFilter::~CVMRFilter()
{
    AMTRACE((TEXT("CVMRFilter::~CVMRFilter")));
    VMRCleanUp();
}


/*****************************Private*Routine******************************\
* MixerInit
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::MixerInit(
    DWORD dwNumStreams
    )
{
    AMTRACE((TEXT("CVMRFilter::MixerInit")));

    // A reference leak will occur if this function is called and m_lpMixControl, m_lpMixBitmap
    // or m_lpMixStream is not NULL.
    ASSERT((NULL == m_lpMixControl) && (NULL == m_lpMixBitmap) && (NULL == m_lpMixStream));

    HRESULT hr;

    __try {

        CHECK_HR(hr = CoCreateInstance(CLSID_VideoMixer,
                                       NULL,
                                       CLSCTX_INPROC_SERVER,
                                       IID_IVMRMixerControlInternal,
                                       (LPVOID*)&m_lpMixControl));

        CHECK_HR(hr = m_lpMixControl->QueryInterface(IID_IVMRMixerBitmap,
                                                     (LPVOID *)&m_lpMixBitmap));

        CHECK_HR(hr = m_lpMixControl->SetNumberOfStreams(dwNumStreams));
        CHECK_HR(hr = m_lpMixControl->SetBackEndImageSync(m_lpIS));

        if (m_lpRLNotify) {
            CHECK_HR(hr = m_lpMixControl->SetBackEndAllocator(m_lpRLNotify, m_dwUserID));
        }

        CHECK_HR(hr = m_lpMixControl->QueryInterface(IID_IVMRMixerStream,
                                                     (LPVOID*)&m_lpMixStream));
    }
    __finally {

        if (FAILED(hr)) {
            RELEASE(m_lpMixControl);
            RELEASE(m_lpMixBitmap);
            RELEASE(m_lpMixStream);
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* ImageSyncInit()
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::ImageSyncInit()
{
    AMTRACE((TEXT("CVMRFilter::ImageSyncInit")));
    HRESULT hr = S_OK;

    hr = CoCreateInstance(CLSID_ImageSynchronization, NULL,
                          CLSCTX_INPROC_SERVER, IID_IImageSync,
                          (LPVOID*)&m_lpIS);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("Can't create a Core Video Renderer object!!")));
        return hr;
    }


    hr = m_lpIS->QueryInterface(IID_IImageSyncControl, (LPVOID*)&m_lpISControl);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("Can't get an IID_IImageSyncControl!!")));
        return hr;
    }

    if (SUCCEEDED(hr)) {
        hr = m_lpISControl->SetImagePresenter(&m_pIVMRImagePresenter, m_dwUserID);
    }

    if (SUCCEEDED(hr)) {
        hr = m_lpISControl->SetEventNotify(&m_pIImageSyncNotifyEvent);
    }

    if (SUCCEEDED(hr)) {
        hr = m_lpIS->QueryInterface(IID_IQualProp, (LPVOID*)&m_lpISQualProp);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("Can't get an IID_IQualProp from the Image Sync!!")));
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* CreateInputPin
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
* Wed 08/22/2001 - BEllett - Changed function name.
*
\**************************************************************************/
HRESULT
CVMRFilter::CreateInputPin()
{
    // Make sure that we can create another input pin.
    ASSERT(m_dwNumPins < MAX_MIXER_PINS);

    HRESULT hr = S_OK;
    DWORD dwInputPinNum = m_dwNumPins;

    WCHAR wszPinName[32];
    wsprintfW(wszPinName, L"VMR Input%d", dwInputPinNum);
    m_pInputPins[dwInputPinNum] = new CVMRInputPin(dwInputPinNum, this, &m_InterfaceLock,
                                       &hr, wszPinName);
    if (m_pInputPins[dwInputPinNum] == NULL) {
        DbgLog((LOG_ERROR, 1,
                TEXT("Ran out of memory creating input pin!!")));
        return E_OUTOFMEMORY;
    }

    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("Unknown error occurred creating input pin!!")));
        delete m_pInputPins[dwInputPinNum];
        m_pInputPins[dwInputPinNum] = NULL;
        return hr;
    }

    m_dwNumPins++;

    return S_OK;
}


/*****************************Private*Routine******************************\
* CreateExtraInputPins
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
* Wed 08/22/2001 - BEllett - Changed function name, removed redundant code,
*                            and fixed a minor memory leak.
*
\**************************************************************************/
HRESULT
CVMRFilter::CreateExtraInputPins(
    DWORD dwNumPins
    )
{
    HRESULT hr = S_OK;

    for (DWORD i = 0; i < dwNumPins; i++) {
        hr = CreateInputPin();
        if (FAILED(hr)) {
            DestroyExtraInputPins();
            return hr;
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* DestroyExtraInputPins
*
*
*
* History:
* Wed 08/22/2001 - BEllett - Created
*
\**************************************************************************/
void
CVMRFilter::DestroyExtraInputPins()
{
    for (DWORD i = 1; i < m_dwNumPins; i++) {
        delete m_pInputPins[i];
        m_pInputPins[i] = NULL;
    }

    m_dwNumPins = 1;

    #ifdef DEBUG
    for (i = m_dwNumPins; i < MAX_MIXER_PINS; i++) {
        ASSERT(m_pInputPins[i] == NULL);
    }
    #endif DEBUG
}


/******************************Public*Routine******************************\
* CVMRFilter::GetPin
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
CBasePin*
CVMRFilter::GetPin(
    int n
    )
{
    AMTRACE((TEXT("CVMRFilter::GetPin")));
    ASSERT(n < (int)m_dwNumPins);
    return m_pInputPins[n];
}


/******************************Public*Routine******************************\
* CVMRFilter::GetPinCount()
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
int
CVMRFilter::GetPinCount()
{
    AMTRACE((TEXT("CVMRFilter::GetPinCount")));
    return m_dwNumPins;
}


/******************************Public*Routine******************************\
* CBaseMediaFilter
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetSyncSource(
    IReferenceClock *pClock
    )
{
    AMTRACE((TEXT("CVMRFilter::SetSyncSource")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = CBaseFilter::SetSyncSource(pClock);
    if (SUCCEEDED(hr)) {
        hr = m_lpISControl->SetReferenceClock(pClock);
    }

    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::Stop()
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::Stop()
{
    AMTRACE((TEXT("CVMRFilter::Stop")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    HRESULT hr = CBaseFilter::Stop();

    if (SUCCEEDED(hr)) {
        hr = m_lpISControl->EndImageSequence();
    }

    if (m_lpMixControl) {
        ASSERT(!m_VMRModePassThru);
        m_lpMixControl->WaitForMixerIdle(INFINITE);
    }
    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::Pause()
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::Pause()
{
    AMTRACE((TEXT("CVMRFilter::Pause")));

    HRESULT hr = S_OK;
    {
        CAutoLock cInterfaceLock(&m_InterfaceLock);

        int PinsConnected = NumInputPinsConnected();

        if (PinsConnected == 0) {

            m_State = State_Paused;
            return S_OK;
        }

        hr = CBaseFilter::Pause();
        if (SUCCEEDED(hr)) {

            hr = m_lpISControl->CueImageSequence();
        }
    }

    //
    //  DON'T hold the lock while doing these window operations
    //  If we do then we can hang if the window thread ever grabs it
    //  because some of these operation do SendMessage to our window
    //  (it's that simple - think about it)
    //  This should be safe because all this stuff really only references
    //  m_hwnd which doesn't change for the lifetime of this object
    //

    AutoShowWindow();
    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::Run
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::Run(
    REFERENCE_TIME StartTime
    )
{
    AMTRACE((TEXT("CVMRFilter::Run")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (m_State == State_Running) {
        NOTE("State set");
        return S_OK;
    }

    // Send EC_COMPLETE if we're not connected

    if (NumInputPinsConnected() == 0) {
        DbgLog((LOG_TRACE, 2, TEXT("No pin connection")));
        m_State = State_Running;
        NotifyEvent(EC_COMPLETE, S_OK, 0);
        return S_OK;
    }

    DbgLog((LOG_TRACE, 2, TEXT("Changing state to running")));
    HRESULT hr = CBaseFilter::Run(StartTime);
    if (SUCCEEDED(hr)) {
        hr = m_lpISControl->BeginImageSequence(&StartTime);
    }

    AutoShowWindow();

    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::GetState
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetState(
    DWORD dwMSecs,
    FILTER_STATE *State
    )
{
    AMTRACE((TEXT("CVMRFilter::GetState")));

    if (NumInputPinsConnected() == 0) {
        *State = m_State;
        return S_OK;
    }

    DWORD dwState;
    HRESULT hr = m_lpISControl->GetImageSequenceState(dwMSecs, &dwState);

    if (SUCCEEDED(hr)) {
        *State = (FILTER_STATE)dwState;
    }
    return hr;
}


/*****************************Private*Routine******************************\
* AutoShowWindow
*
* The auto show flag is used to have the window shown automatically when we
* change state. We do this only when moving to paused or running, when there
* is no outstanding EC_USERABORT set and when the window is not already up
* This can be changed through the IVideoWindow interface AutoShow property.
* If the window is not currently visible then we are showing it because of
* a state change to paused or running, in which case there is no point in
* the video window sending an EC_REPAINT as we're getting an image anyway
*
*
* History:
* Fri 04/21/2000 - StEstrop - Created
*
\**************************************************************************/
void
CVMRFilter::AutoShowWindow()
{
    AMTRACE((TEXT("CVMRFilter::AutoShowWindow")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (m_pVideoWindow) {

        ASSERT(m_VMRMode == VMRMode_Windowed);
        if( m_VMRMode & VMRMode_Windowed ) {
            HWND hwnd = m_pVideoWindow->GetWindowHWND();

            if (m_pVideoWindow->IsAutoShowEnabled() == TRUE) {
                BOOL bAbort;
                m_lpISControl->GetAbortSignal(&bAbort);
                if (bAbort == FALSE) {

                    if (IsWindowVisible(hwnd) == FALSE) {

                        NOTE("ExecutingAutoShowWindow");
                        // SetRepaintStatus(FALSE);
                        m_pVideoWindow->PerformanceAlignWindow();
                        m_pVideoWindow->DoShowWindow(SW_SHOWNORMAL);
                        m_pVideoWindow->DoSetWindowForeground(TRUE);
                    }
                }
            }
        }
    }
}


/******************************Public*Routine******************************\
* CVMRFilter::Receive
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::Receive(
    DWORD dwPinID,
    IMediaSample *pMediaSample
    )
{
    AMTRACE((TEXT("CVMRFilter::Receive")));

    if (dwPinID == 0) {

        //
        // Store the media times from this sample
        //

        if (m_pPosition) {
            m_pPosition->RegisterMediaTime(pMediaSample);
        }
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* CVMRFilter::Active
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::Active(
    DWORD dwPinID
    )
{
    AMTRACE((TEXT("CVMRFilter::Active")));

    const DWORD dwPinBit = (1 << dwPinID);
    m_dwEndOfStreamMask |= dwPinBit;

    return S_OK;
}


/******************************Public*Routine******************************\
* CVMRFilter::Inactive
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::Inactive(
    DWORD dwPinID
    )
{
    AMTRACE((TEXT("CVMRFilter::Inactive")));

    if (dwPinID == 0) {
        if (m_pPosition) {
            m_pPosition->ResetMediaTime();
        }
    }
    return S_OK;
}


/******************************Public*Routine******************************\
* CVMRFilter::BeginFlush
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::BeginFlush(
    DWORD dwPinID
    )
{
    AMTRACE((TEXT("CVMRFilter::BeginFlush")));

    HRESULT hr = m_lpISControl->BeginFlush();
    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::EndFlush
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::EndFlush(
    DWORD dwPinID
    )
{
    AMTRACE((TEXT("CVMRFilter::EndFlush")));

    if (dwPinID == 0) {
        if (m_pPosition) {
            m_pPosition->ResetMediaTime();
        }
    }

    HRESULT hr = m_lpISControl->EndFlush();
    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::EndOfStream
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::EndOfStream(
    DWORD dwPinID
    )
{
    AMTRACE((TEXT("CVMRFilter::EndofStream")));
    return m_lpISControl->EndOfStream();
}


/* -------------------------------------------------------------------------
**  deal with connections
** -------------------------------------------------------------------------
*/


/******************************Public*Routine******************************\
* CVMRFilter::BreakConnect
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::BreakConnect(
    DWORD dwPinID
    )
{
    AMTRACE((TEXT("CVMRFilter::BreakConnect")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    HRESULT hr = S_OK;
    if (NumInputPinsConnected() == 1) {

        // Now deactivate Macrovision, if it was activated
        if (m_MacroVision.GetCPHMonitor())
        {
             // clear MV from display
            m_MacroVision.SetMacroVision(m_hMonitor, 0);

            // reset CP key
            m_MacroVision.StopMacroVision();
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::CheckMediaType
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::CheckMediaType(
    const CMediaType* pmt
    )
{
    AMTRACE((TEXT("CVMRFilter::CheckMediaType")));

    if (pmt->majortype != MEDIATYPE_Video) {

        DbgLog((LOG_ERROR, 1, TEXT("CheckMediaType failed: Major Type not Video")));
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    if (pmt->subtype == MEDIASUBTYPE_RGB8) {
        DbgLog((LOG_ERROR, 1, TEXT("CheckMediaType failed: Minor Type is RGB8")));
        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    if (*pmt->FormatType() != FORMAT_VideoInfo &&
        *pmt->FormatType() != FORMAT_VideoInfo2) {

        DbgLog((LOG_ERROR, 1, TEXT("CheckMediaType failed: Format Type is not ")
                              TEXT("FORMAT_VideoInfo | FORMAT_VideoInfo2") ));

        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* CVMRFilter::RuntimeAbortPlayback
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::RuntimeAbortPlayback(
    HRESULT hr
    )
{
    HRESULT hrRet = S_FALSE;
    AMTRACE((TEXT("CVMRFilter::RuntimeAbortPlayback")));

    // A deadlock could occur if the caller holds the renderer lock and
    // attempts to acquire the interface lock.
    ASSERT(CritCheckOut(&m_RendererLock));


    // The interface lock must be held when the filter is calling
    // IsStopped().
    CAutoLock cRendererLock(&m_InterfaceLock);


    // We do not report errors which occur while the filter is stopping,
    // flushing or if the m_bAbort flag is set .  Errors are expected to
    // occur during these operations and the streaming thread correctly
    // handles the errors.

    BOOL bAbort;
    m_lpISControl->GetAbortSignal(&bAbort);

    if (!IsStopped() && !bAbort) {

        // EC_ERRORABORT's first parameter is the error which caused
        // the event and its' last parameter is 0.  See the Direct
        // Show SDK documentation for more information.

        NotifyEvent(EC_ERRORABORT, hr, 0);

        CAutoLock alRendererLock(&m_RendererLock);

        hrRet = m_lpISControl->RuntimeAbortPlayback();
    }

    return hrRet;
}



/******************************Public*Routine******************************\
* CVMRFilter::OnSetProperties
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::OnSetProperties(
    CVMRInputPin *pReceivePin
    )
{
    AMTRACE((TEXT("CVMRFilter::OnSetProperties")));
    HRESULT hr = S_OK;


    //
    // if we are processing a display change clear this pins bit in
    // the display change mask
    //
    const DWORD dwPinBit = (1 << pReceivePin->m_dwPinID);
    if (m_dwDisplayChangeMask & dwPinBit) {
        m_dwDisplayChangeMask &= ~dwPinBit;
    }
    else if (m_pVideoWindow) {

        ASSERT(m_VMRMode & VMRMode_Windowed);
        if( m_VMRMode & VMRMode_Windowed ) {
            m_pVideoWindow->SetDefaultSourceRect();
            m_pVideoWindow->SetDefaultTargetRect();
            m_pVideoWindow->OnVideoSizeChange();

            // Notify the video window of the CompleteConnect
            m_pVideoWindow->CompleteConnect();
            if (pReceivePin->m_fInDFC) {
                m_pVideoWindow->ActivateWindowAsync(TRUE);
            }
            else {
                m_pVideoWindow->ActivateWindow();
            }
        }
    }

    return hr;
}


/* -------------------------------------------------------------------------
** IVMRSurfaceAllocatorNotify
** -------------------------------------------------------------------------
*/

CVMRFilter::CIVMRSurfaceAllocatorNotify::~CIVMRSurfaceAllocatorNotify()
{
    // All of the references to this object should have been
    // released before the VMR is destroyed.
    ASSERT(0 == m_cRef);
}

/******************************Public*Routine******************************\
* CVMRFilter::AdviseSurfaceAllocator
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIVMRSurfaceAllocatorNotify::AdviseSurfaceAllocator(
    DWORD_PTR dwUserID,
    IVMRSurfaceAllocator* lpIVRMSurfaceAllocator
    )
{
    AMTRACE((TEXT("CVMRFilter::CIVMRSurfaceAllocatorNotify::AdviseSurfaceAllocator")));
    CAutoLock cInterfaceLock(&m_pObj->m_InterfaceLock);

    FILTER_STATE State;

    //
    // If the caller hasn't set the VMR's mode yet - fail.
    // The mode has to renderless, we can't have any pins connected,
    // and SetVMRMode has to have called.
    //
    BOOL fOK = ((m_pObj->m_VMRMode & VMRMode_Renderless) &&
                 0 == m_pObj->NumInputPinsConnected() &&
                 !m_pObj->m_bModeChangeAllowed);
    if (!fOK) {
        DbgLog((LOG_ERROR, 1, TEXT("SetVMRMode has not been called")));
        return VFW_E_WRONG_STATE;
    }

    // Make sure we are in a stopped state

    m_pObj->GetState(0, &State);
    if (State != State_Stopped) {
        return VFW_E_NOT_STOPPED;
    }


    HRESULT hr = S_OK;

    if (lpIVRMSurfaceAllocator) {
        lpIVRMSurfaceAllocator->AddRef();
    }

    RELEASE(m_pObj->m_lpWLControl);
    RELEASE(m_pObj->m_lpRLNotify);
    RELEASE(m_pObj->m_lpPresenter);
    RELEASE(m_pObj->m_pPresenterConfig);
    RELEASE(m_pObj->m_pPresenterMonitorConfig);

    m_pObj->m_lpRLNotify = lpIVRMSurfaceAllocator;
    m_pObj->m_dwUserID = dwUserID;

    if (m_pObj->m_lpRLNotify) {

        if (m_pObj->m_lpMixControl) {
            ASSERT(!m_pObj->m_VMRModePassThru);
            hr = m_pObj->m_lpMixControl->SetBackEndAllocator(
                                m_pObj->m_lpRLNotify,
                                m_pObj->m_dwUserID);
        }

        hr = m_pObj->m_lpRLNotify->QueryInterface(
                                    IID_IVMRImagePresenter,
                                    (LPVOID*)&m_pObj->m_lpPresenter);
        if( SUCCEEDED( hr )) {
            m_pObj->m_lpPresenter->QueryInterface(
                        IID_IVMRImagePresenterConfig,
                        (LPVOID*)&m_pObj->m_pPresenterConfig);

            m_pObj->m_lpPresenter->QueryInterface(
                        IID_IVMRMonitorConfig,
                        (LPVOID*)&m_pObj->m_pPresenterMonitorConfig);
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::SetDDrawDevice
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIVMRSurfaceAllocatorNotify::SetDDrawDevice(
    LPDIRECTDRAW7 lpDDrawDevice,
    HMONITOR hMonitor
    )
{
    AMTRACE((TEXT("CVMRFilter::CIVMRSurfaceAllocatorNotify::SetDDrawDevice")));
    CAutoLock cInterfaceLock(&m_pObj->m_InterfaceLock);
    if ( ( NULL == lpDDrawDevice ) || ( NULL == hMonitor ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("NULL device or monitor") ));
        return E_POINTER;
    }
    HRESULT hr = S_OK;
    hr = m_pObj->SetDDrawDeviceWorker(lpDDrawDevice, hMonitor);
    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::ChangeDDrawDevice
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIVMRSurfaceAllocatorNotify::ChangeDDrawDevice(
    LPDIRECTDRAW7 lpDDrawDevice,
    HMONITOR hMonitor
    )
{
    AMTRACE((TEXT("CVMRFilter::CIVMRSurfaceAllocatorNotify::ChangeDDrawDevice")));
    CAutoLock cInterfaceLock(&m_pObj->m_InterfaceLock);

    HRESULT hr = S_OK;
    hr = m_pObj->SetDDrawDeviceWorker(lpDDrawDevice, hMonitor);


    if (SUCCEEDED(hr)) {

        // The VMR can have at most MAX_MIXER_PINS input pins.
        ASSERT(MAX_MIXER_PINS == NUMELMS(m_pObj->m_pInputPins));
        IPin* apPinLocal[MAX_MIXER_PINS];
        IPin** ppPin = NULL;
        int i, iPinCount;
        const int iPinsCreated = m_pObj->GetPinCount();
        ULONG AllocSize = sizeof(IPin*) * iPinsCreated;
        ppPin = (IPin**)CoTaskMemAlloc(AllocSize);

        if (ppPin) {

            ZeroMemory(ppPin, AllocSize);

            //
            // now tell each input pin to reconnect
            //

            for (iPinCount = 0, i = 0; i < iPinsCreated; i++) {

                //
                // get IPin interface
                //

                if (hr == S_OK && m_pObj->m_pInputPins[i]->IsConnected()) {

                    hr = m_pObj->m_pInputPins[i]->QueryInterface(
                                        IID_IPin, (void**)&ppPin[iPinCount]);

                    ASSERT(SUCCEEDED(hr));
                    ASSERT(ppPin[iPinCount]);

                    apPinLocal[iPinCount] = ppPin[iPinCount];

                    iPinCount++;
                    m_pObj->m_dwDisplayChangeMask |=
                                (1 << m_pObj->m_pInputPins[i]->GetPinID());
                }
            }

            //
            // Pass our input pin array as parameter on the event, we don't free
            // the allocated memory - this is done by the event processing
            // code in the FilterGraph
            //

            if (iPinCount > 0) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("EC_DISPLAY_CHANGED sent %d pins to re-connect"),
                        iPinCount));

                // The VMR cannot access the ppPin array after it calls
                // IMediaEventSink::Notify().  It cannot access the
                // array because IMediaEventSink::Notify() can free the
                // array at any time.
                m_pObj->NotifyEvent(EC_DISPLAY_CHANGED, (LONG_PTR)ppPin,
                                    (LONG_PTR)iPinCount);
            }

            //
            // Release the IPin interfaces
            //

            for (i = 0; i < iPinCount; i++) {
                apPinLocal[i]->Release();
            }


            //
            // Tell the mixer about the display mode change.
            //

            if (SUCCEEDED(hr) && m_pObj->m_lpMixControl) {
                ASSERT(!m_pObj->m_VMRModePassThru);
                hr = m_pObj->m_lpMixControl->DisplayModeChanged();
            }

        }
        else {

            hr = E_OUTOFMEMORY;
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* SetDDrawDeviceWorker
*
*
*
* History:
* Thu 03/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::SetDDrawDeviceWorker(
    LPDIRECTDRAW7 lpDDrawDevice,
    HMONITOR hMonitor
    )
{
    AMTRACE((TEXT("CVMRFilter::SetDDrawDeviceWorker")));
    CVMRDeinterlaceContainer* pDeinterlace = NULL;
    HRESULT hr = S_OK;

    if (hMonitor != NULL) {

        MONITORINFO mi;
        mi.cbSize = sizeof(mi);
        if (!GetMonitorInfo(hMonitor, &mi)) {
            return E_INVALIDARG;
        }
    }

    if (lpDDrawDevice) {

        INITDDSTRUCT(m_ddHWCaps);
        hr = lpDDrawDevice->GetCaps((LPDDCAPS)&m_ddHWCaps, NULL);

        if (SUCCEEDED(hr)) {

            DDSURFACEDESC2 ddsd;  // A surface description structure
            INITDDSTRUCT(ddsd);

            hr = lpDDrawDevice->GetDisplayMode(&ddsd);
            if (SUCCEEDED(hr)) {
                CopyMemory(&m_ddpfMonitor, &ddsd.ddpfPixelFormat,
                           sizeof(m_ddpfMonitor));
            }
        }

        m_TexCaps = 0;
        GetTextureCaps(lpDDrawDevice, &m_TexCaps);

        if (SUCCEEDED(hr)) {

            lpDDrawDevice->AddRef();

            //
            // we now try to create the deinterlace container DX-VA
            // device.  We continue on failure (including out of memory
            // failures).
            //

            HRESULT hrT = S_OK;
            pDeinterlace = new CVMRDeinterlaceContainer(lpDDrawDevice, &hrT);
            if (FAILED(hrT) && pDeinterlace) {
                delete pDeinterlace;
                pDeinterlace = NULL;
            }
        }
        else {
            lpDDrawDevice = NULL;
        }
    }

    if (m_lpDirectDraw) {
        m_lpDirectDraw->Release();
    }

    if (m_pDeinterlace) {
        delete m_pDeinterlace;
    }

    m_lpDirectDraw = lpDDrawDevice;
    m_hMonitor = hMonitor;
    m_pDeinterlace = pDeinterlace;

    return hr;
}


/******************************Public*Routine******************************\
* SetBorderColor
*
*
*
* History:
* Thu 11/02/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIVMRSurfaceAllocatorNotify::SetBorderColor(
    COLORREF clr
    )
{
    AMTRACE((TEXT("CVMRFilter::CIVMRImagePresenter::SetBorderColor")));

    /** this interface is not needed anymore - set SetBackgroundColor below
    **/
    return S_OK;
}


/******************************Public*Routine******************************\
* CVMRFilter::RestoreDDrawSurfaces
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIVMRSurfaceAllocatorNotify::RestoreDDrawSurfaces()
{
    AMTRACE((TEXT("CVMRFilter::CIVMRImagePresenter::RestoreDDrawSurface")));

    //
    // Don't generate EC_NEED_RESTART during a display mode change !
    //
    {
        CAutoLock cInterfaceLock(&m_pObj->m_InterfaceLock);
        if (m_pObj->m_dwDisplayChangeMask) {
            return S_OK;
        }
    }

    m_pObj->NotifyEvent(EC_NEED_RESTART, 0, 0);
    return S_OK;
}



/******************************Public*Routine******************************\
* CVMRFilter::NotifyEvent
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIVMRSurfaceAllocatorNotify::NotifyEvent(
    LONG EventCode,
    LONG_PTR lp1,
    LONG_PTR lp2
    )
{
    AMTRACE((TEXT("CVMRFilter::CIVMRImagePresenter::NotifyEvent")));

    switch (EventCode) {
    case EC_VMR_SURFACE_FLIPPED:
        m_pObj->m_hrSurfaceFlipped = (HRESULT)lp1;
        break;

    default:
        m_pObj->NotifyEvent(EventCode, lp1, lp2);
        break;
    }

    return S_OK;
}



/* -------------------------------------------------------------------------
** IImageSyncPresenter
** -------------------------------------------------------------------------
*/

/******************************Public*Routine******************************\
* StartPresenting
*
*
*
* History:
* Fri 03/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIVMRImagePresenter::StartPresenting(
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CVMRFilter::CIVMRImagePresenter::StartPresenting")));
    ASSERT(m_pObj->m_lpRLNotify);
    HRESULT hr = S_OK;
    hr = m_pObj->m_lpPresenter->StartPresenting(m_pObj->m_dwUserID);
    return hr;
}

/******************************Public*Routine******************************\
* StopPresenting
*
*
*
* History:
* Fri 03/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIVMRImagePresenter::StopPresenting(
    DWORD_PTR dwUserID
    )
{
    AMTRACE((TEXT("CVMRFilter::StopPresenting")));
    ASSERT(m_pObj->m_lpRLNotify);
    HRESULT hr = S_OK;
    hr = m_pObj->m_lpPresenter->StopPresenting(m_pObj->m_dwUserID);
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::PresentImage
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIVMRImagePresenter::PresentImage(
    DWORD_PTR dwUserID,
    VMRPRESENTATIONINFO* lpPresInfo
    )
{
    AMTRACE((TEXT("CVMRFilter::PresentImage")));
    ASSERT(m_pObj->m_lpRLNotify);

    ASSERT(lpPresInfo);
    ASSERT(lpPresInfo->lpSurf);

    HRESULT hr = S_OK;
    if (lpPresInfo && lpPresInfo->lpSurf) {
        hr = m_pObj->m_lpPresenter->PresentImage(m_pObj->m_dwUserID, lpPresInfo);
    }
    else {
        hr = E_FAIL;
    }

    return hr;
}

/* -------------------------------------------------------------------------
** IImageSyncNotifyEvent
** -------------------------------------------------------------------------
*/

/******************************Public*Routine******************************\
* NotifyEvent
*
*
*
* History:
* Fri 03/10/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::CIImageSyncNotifyEvent::NotifyEvent(
    long lEventCode,
    LONG_PTR lp1,
    LONG_PTR lp2
    )
{
    AMTRACE((TEXT("CVMRFilter::CIImageSyncNotifyEvent::NotifyEvent")));
    HRESULT hr = S_OK;

    switch (lEventCode) {

    case EC_COMPLETE:
        if (m_pObj->m_pPosition) {
            m_pObj->m_pPosition->EOS();
        }

        // fall thru

    case EC_STEP_COMPLETE:
        hr = m_pObj->NotifyEvent(lEventCode, lp1, lp2);
        break;

    default:
        DbgLog((LOG_ERROR, 0,
                TEXT("Unkown event notified from the image sync object !!")));
        ASSERT(0);
        hr = E_FAIL;
        break;
    }

    return hr;
}

/* -------------------------------------------------------------------------
** IVRWindowlessControl
** -------------------------------------------------------------------------
*/

/*****************************Private*Routine******************************\
* CVMRFilter::CreateDefaultAllocatorPresenter
*
*
*
* History:
* Fri 03/03/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::CreateDefaultAllocatorPresenter()
{
    HRESULT hr = S_OK;

    hr = CoCreateInstance(CLSID_AllocPresenter, NULL,
                          CLSCTX_INPROC_SERVER,
                          IID_IVMRSurfaceAllocator,
                          (LPVOID*)&m_lpRLNotify);

    if (SUCCEEDED(hr) && m_lpMixControl) {
        ASSERT(!m_VMRModePassThru);
        hr = m_lpMixControl->SetBackEndAllocator(m_lpRLNotify, m_dwUserID);
    }

    if (SUCCEEDED(hr)) {
        m_lpRLNotify->AdviseNotify(&m_pIVMRSurfaceAllocatorNotify);
    }

    if (SUCCEEDED(hr)) {
        hr = m_lpRLNotify->QueryInterface(IID_IVMRImagePresenter,
                                          (LPVOID*)&m_lpPresenter);

    }

    if (SUCCEEDED(hr)) {

        m_lpRLNotify->QueryInterface(IID_IVMRImagePresenterConfig,
                                          (LPVOID*)&m_pPresenterConfig);

        m_lpRLNotify->QueryInterface(IID_IVMRMonitorConfig,
                                          (LPVOID*)&m_pPresenterMonitorConfig);
    }


    if (FAILED(hr)) {

        if (m_lpMixControl) {
            ASSERT(!m_VMRModePassThru);
            m_lpMixControl->SetBackEndAllocator(NULL, m_dwUserID);
        }

        RELEASE(m_lpRLNotify);
        RELEASE(m_lpPresenter);
        RELEASE(m_pPresenterConfig);
        RELEASE(m_pPresenterMonitorConfig);
    }

    return hr;
}


/*****************************Private*Routine******************************\
* ValidateIVRWindowlessControlState
*
* Checks that the filter is in the correct state to process commands via
* the WindowlessControl interface.
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::ValidateIVRWindowlessControlState()
{
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    AMTRACE((TEXT("CVMRFilter::ValidateIVRWindowlessControlState")));
    HRESULT hr = VFW_E_WRONG_STATE;

    if (m_VMRMode & (VMRMode_Windowed | VMRMode_Windowless) ) {

        hr = S_OK;
        if (!m_lpWLControl) {

            if (!m_lpRLNotify) {

                ASSERT(NumInputPinsConnected() == 0);
                hr = CreateDefaultAllocatorPresenter();
            }

            if (SUCCEEDED(hr)) {
                hr = m_lpRLNotify->QueryInterface(IID_IVMRWindowlessControl,
                                                  (LPVOID*)&m_lpWLControl);
            }

            if (SUCCEEDED(hr)) {

                m_lpWLControl->SetAspectRatioMode(m_ARMode);

                if (m_pVideoWindow) {
                    HWND hwnd = m_pVideoWindow->GetWindowHWND();
                    m_lpWLControl->SetVideoClippingWindow(hwnd);
                }
            }

            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("Can't get a WindowLess control interface !!")));
                // ASSERT(!"Can't get a WindowLess control interface !!");
            }
        }
    }
    else {

        ASSERT((m_VMRMode & VMRMode_Renderless) == VMRMode_Renderless);

        //
        // We are in renderless mode, the app should have plugged in an
        // allocator-presenter.  If it has lets see if this allocator-presenter
        // supports the IVMRWindowlessControl interface ?
        //

        if (!m_lpWLControl) {

            if (m_lpRLNotify) {

                hr = m_lpRLNotify->QueryInterface(IID_IVMRWindowlessControl,
                                                  (LPVOID*)&m_lpWLControl);
                if (SUCCEEDED(hr)) {
                    m_lpWLControl->SetAspectRatioMode(m_ARMode);
                }
            }
        }
        else {

            hr = S_OK;
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::GetNativeVideoSize
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetNativeVideoSize(
    LONG* lWidth,
    LONG* lHeight,
    LONG* lARWidth,
    LONG* lARHeight
    )
{
    AMTRACE((TEXT("CVMRFilter::GetNativeVideoSize")));

    if ( ISBADWRITEPTR(lWidth) || ISBADWRITEPTR(lHeight) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer")));
        return E_POINTER;
    }

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->GetNativeVideoSize(lWidth, lHeight,
                                               lARWidth, lARHeight);
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::GetMinIdealVideoSize
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetMinIdealVideoSize(
    LONG* lWidth,
    LONG* lHeight
    )
{
    AMTRACE((TEXT("CVMRFilter::GetMinIdealVideoSize")));

    if ( ISBADWRITEPTR(lWidth) || ISBADWRITEPTR(lHeight) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer")));
        return E_POINTER;
    }

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->GetMinIdealVideoSize(lWidth, lHeight);
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::GetMaxIdealVideoSize
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetMaxIdealVideoSize(
    LONG* lWidth,
    LONG* lHeight
    )
{
    AMTRACE((TEXT("CVMRFilter::GetMaxIdealVideoSize")));

    if ( ISBADWRITEPTR(lWidth) || ISBADWRITEPTR(lHeight) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer")));
        return E_POINTER;
    }

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->GetMaxIdealVideoSize(lWidth, lHeight);
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::SetVideoPosition
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetVideoPosition(
    const LPRECT lpSRCRect,
    const LPRECT lpDSTRect
    )
{
    AMTRACE((TEXT("CVMRFilter::SetVideoPosition")));

    if ( ISBADREADPTR(lpSRCRect) && ISBADREADPTR(lpDSTRect) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer")));
        return E_POINTER;
    }

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->SetVideoPosition(lpSRCRect, lpDSTRect);
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::GetVideoPosition
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetVideoPosition(
    LPRECT lpSRCRect,
    LPRECT lpDSTRect
    )
{
    AMTRACE((TEXT("CVMRFilter::GetVideoPosition")));

    if ( ISBADWRITEPTR(lpSRCRect) && ISBADWRITEPTR(lpDSTRect) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer")));
        return E_POINTER;
    }

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->GetVideoPosition(lpSRCRect, lpDSTRect);
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::GetAspectRatioMode
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetAspectRatioMode(
    DWORD* lpAspectRatioMode
    )
{
    AMTRACE((TEXT("CVMRFilter::GetAspectRationMode")));

    if ( ISBADWRITEPTR(lpAspectRatioMode) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer")));
        return E_POINTER;
    }

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->GetAspectRatioMode(lpAspectRatioMode);
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::SetAspectRatioMode
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetAspectRatioMode(
    DWORD AspectRatioMode
    )
{
    AMTRACE((TEXT("CVMRFilter::SetAspectRationMode")));

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->SetAspectRatioMode(AspectRatioMode);
    }

    if( SUCCEEDED(hr )) {
        m_bARModeDefaultSet = TRUE;
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::SetVideoClippingWindow
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetVideoClippingWindow(
    HWND hwnd
    )
{
    AMTRACE((TEXT("CVMRFilter::SetWindowHandle")));

    if (!IsWindow(hwnd) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid HWND")));
        return E_INVALIDARG;
    }

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->SetVideoClippingWindow(hwnd);
    }
    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::RepaintVideo
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::RepaintVideo(
    HWND hwnd,
    HDC hdc
    )
{
    AMTRACE((TEXT("CVMRFilter::RepaintVideo")));

    if (!IsWindow(hwnd) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid HWND")));
        return E_INVALIDARG;
    }

    if (!hdc) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid HDC")));
        return E_INVALIDARG;
    }

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->RepaintVideo(hwnd, hdc);
    }
    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::DisplayModeChanged
*
*
*
* History:
* Tue 02/29/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::DisplayModeChanged()
{
    AMTRACE((TEXT("CVMRFilter::DisplayModeChanged")));

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->DisplayModeChanged();
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetCurrentImage
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetCurrentImage(
    BYTE** lpDib
    )
{
    AMTRACE((TEXT("CVMRFilter::GetCurrentImage")));

    if (ISBADWRITEPTR(lpDib)) {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer")));
        return E_POINTER;
    }

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->GetCurrentImage(lpDib);
    }
    return hr;

}

/******************************Public*Routine******************************\
* CVMRFilter::SetBorderColor
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetBorderColor(
    COLORREF Clr
    )
{
    AMTRACE((TEXT("CVMRFilter::SetBorderColor")));

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->SetBorderColor(Clr);
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::GetBorderColor
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetBorderColor(
    COLORREF* lpClr
    )
{
    AMTRACE((TEXT("CVMRFilter::GetBorderColor")));

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->GetBorderColor(lpClr);
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::SetColorKey
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetColorKey(
    COLORREF Clr
    )
{
    AMTRACE((TEXT("CVMRFilter::SetColorKey")));

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->SetColorKey(Clr);
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRFilter::GetColorKey
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetColorKey(
    COLORREF* lpClr
    )
{
    AMTRACE((TEXT("CVMRFilter::GetColorKey")));

    HRESULT hr = ValidateIVRWindowlessControlState();

    if (SUCCEEDED(hr)) {
        hr = m_lpWLControl->GetColorKey(lpClr);
    }
    return hr;
}


/******************************Public*Routine******************************\
* CVMRFilter::SetAlpha
*
*
*
* History:
* Mon 04/24/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::SetAlpha(
    DWORD dwStreamID,
    float Alpha
    )
{
    AMTRACE((TEXT("CVMRFilter::SetAlpha")));

    CAutoLock lck(m_pLock);

    if (dwStreamID > m_dwNumPins) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid stream ID")));
        return E_INVALIDARG;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    return m_lpMixStream->SetStreamAlpha(dwStreamID, Alpha);
}

/******************************Public*Routine******************************\
* CVMRFilter::GetAlpha
*
*
*
* History:
* Mon 04/24/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::GetAlpha(
    DWORD dwStreamID,
    float* pAlpha
    )
{
    AMTRACE((TEXT("CVMRFilter::GetAlpha")));

    CAutoLock lck(m_pLock);

    if (ISBADWRITEPTR(pAlpha))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer")));
        return E_POINTER;
    }

    if (dwStreamID > m_dwNumPins) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid stream ID")));
        return E_INVALIDARG;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    return m_lpMixStream->GetStreamAlpha(dwStreamID, pAlpha);
}

/******************************Public*Routine******************************\
* CVMRFilter::SetZOrder
*
*
*
* History:
* Mon 04/24/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::SetZOrder(
    DWORD dwStreamID,
    DWORD ZOrder
    )
{
    AMTRACE((TEXT("CVMRFilter::SetZOrder")));

    CAutoLock lck(m_pLock);
    HRESULT hr = VFW_E_NOT_CONNECTED;

    if (dwStreamID > m_dwNumPins) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid stream ID")));
        return E_INVALIDARG;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }
    return m_lpMixStream->SetStreamZOrder(dwStreamID, ZOrder);
}

/******************************Public*Routine******************************\
* CVMRFilter::GetZOrder
*
*
*
* History:
* Mon 04/24/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::GetZOrder(
    DWORD dwStreamID,
    DWORD* pdwZOrder
    )
{
    AMTRACE((TEXT("CVMRFilter::GetZOrder")));

    CAutoLock lck(m_pLock);

    if (dwStreamID > m_dwNumPins) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid stream ID")));
        return E_INVALIDARG;
    }

    if (ISBADWRITEPTR(pdwZOrder))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetZOrder: Invalid pointer")));
        return E_POINTER;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    return m_lpMixStream->GetStreamZOrder(dwStreamID, pdwZOrder);
}

/******************************Public*Routine******************************\
* CVMRFilter::SetRelativeOutputRect
*
*
*
* History:
* Mon 04/24/2000 - GlennE - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::SetOutputRect(
    DWORD dwStreamID,
    const NORMALIZEDRECT *prDest
    )
{
    AMTRACE((TEXT("CVMRFilter::SetOutputRect")));

    CAutoLock lck(m_pLock);

    if (ISBADREADPTR(prDest))
    {
        DbgLog((LOG_ERROR, 1, TEXT("SetOutputRect: Invalid pointer")));
        return E_POINTER;
    }

    if (dwStreamID > m_dwNumPins) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid stream ID")));
        return E_INVALIDARG;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }
    return m_lpMixStream->SetStreamOutputRect(dwStreamID, prDest);
}

/******************************Public*Routine******************************\
* CVMRFilter::GetOutputRect
*
*
*
* History:
* Mon 04/24/2000 - GlennE - Created
* Tue 05/16/2000 - nwilt - renamed to GetOutputRect
*
\**************************************************************************/
HRESULT
CVMRFilter::GetOutputRect(
    DWORD dwStreamID,
    NORMALIZEDRECT* pOut
    )
{
    AMTRACE((TEXT("CVMRFilter::GetOutputRect")));

    CAutoLock lck(m_pLock);

    if (ISBADWRITEPTR(pOut))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetOutputRect: Invalid pointer")));
        return E_POINTER;
    }

    if (dwStreamID > m_dwNumPins) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid stream ID")));
        return E_INVALIDARG;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    return m_lpMixStream->GetStreamOutputRect(dwStreamID, pOut);
}


/******************************Public*Routine******************************\
* SetBackgroundClr
*
*
*
* History:
* Fri 03/02/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::SetBackgroundClr(
    COLORREF clrBkg
    )
{
    AMTRACE((TEXT("CVMRFilter::SetBackgroundClr")));

    CAutoLock lck(m_pLock);
    HRESULT hr = VFW_E_VMR_NOT_IN_MIXER_MODE;

    if (m_lpMixControl) {
        ASSERT(!m_VMRModePassThru);
        hr = m_lpMixControl->SetBackgroundColor(clrBkg);
    }

    return hr;
}

/******************************Public*Routine******************************\
* GetBackgroundClr
*
*
*
* History:
* Fri 03/02/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::GetBackgroundClr(
    COLORREF* lpClrBkg
    )
{
    AMTRACE((TEXT("CVMRFilter::GetBackgroundClr")));
    CAutoLock lck(m_pLock);

    if (ISBADWRITEPTR(lpClrBkg))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetBackgroundClr: Invalid pointer")));
        return E_POINTER;
    }

    HRESULT hr = VFW_E_VMR_NOT_IN_MIXER_MODE;

    if (m_lpMixControl) {
        ASSERT(!m_VMRModePassThru);
        hr = m_lpMixControl->GetBackgroundColor(lpClrBkg);
    }

    return hr;
}

/******************************Public*Routine******************************\
* SetMixingPrefs
*
*
*
* History:
* Fri 03/02/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::SetMixingPrefs(
    DWORD dwRenderFlags
    )
{
    AMTRACE((TEXT("CVMRFilter::SetMixingPrefs")));
    CAutoLock lck(m_pLock);

    HRESULT hr = VFW_E_VMR_NOT_IN_MIXER_MODE;

    if (m_lpMixControl) {
        ASSERT(!m_VMRModePassThru);
        hr = m_lpMixControl->SetMixingPrefs(dwRenderFlags);
    }

    return hr;
}


/******************************Public*Routine******************************\
* GetMixingPrefs
*
*
*
* History:
* Fri 03/02/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::GetMixingPrefs(
    DWORD* pdwRenderFlags
    )
{
    AMTRACE((TEXT("CVMRFilter::GetMixingPrefs")));
    CAutoLock lck(m_pLock);

    if (ISBADWRITEPTR(pdwRenderFlags))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetMixingPrefs: Invalid pointer")));
        return E_POINTER;
    }

    HRESULT hr = VFW_E_VMR_NOT_IN_MIXER_MODE;

    if (m_lpMixControl) {
        ASSERT(!m_VMRModePassThru);
        hr = m_lpMixControl->GetMixingPrefs(pdwRenderFlags);
    }

    return hr;
}


/*****************************Private*Routine******************************\
* IsVPMConnectedToUs
*
* check for the VPM - we can't frame step if it is connected to us.
*
* History:
* Wed 06/13/2001 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVMRFilter::IsVPMConnectedToUs()
{
    for (DWORD i = 0; i < m_dwNumPins; i++) {

        if (m_pInputPins[i]->m_Connected) {

            PIN_INFO Inf;
            HRESULT hr = m_pInputPins[i]->m_Connected->QueryPinInfo(&Inf);

            if (SUCCEEDED(hr)) {

                IVPManager* vpm;
                hr = Inf.pFilter->QueryInterface(IID_IVPManager,(LPVOID*)&vpm);
                Inf.pFilter->Release();

                if (SUCCEEDED(hr)) {

                    vpm->Release();
                    return TRUE;
                }
            }
        }
    }

    return FALSE;
}



/******************************Public*Routine******************************\
* Set
*
*
*
* History:
* Tue 04/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::Set(
    REFGUID guidPropSet,
    DWORD dwPropID,
    LPVOID pInstanceData,
    DWORD cbInstanceData,
    LPVOID pPropData,
    DWORD cbPropData
    )
{
    AMTRACE((TEXT("CVMRFilter::Set")));

    if (guidPropSet == AM_KSPROPSETID_FrameStep)
    {
        if (IsVPMConnectedToUs()) {
            return E_PROP_ID_UNSUPPORTED;
        }

        if (dwPropID != AM_PROPERTY_FRAMESTEP_STEP &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANCEL &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANSTEP &&
            dwPropID != AM_PROPERTY_FRAMESTEP_CANSTEPMULTIPLE)
        {
            return E_PROP_ID_UNSUPPORTED;
        }

        switch (dwPropID) {
        case AM_PROPERTY_FRAMESTEP_STEP:
            if (cbPropData < sizeof(AM_FRAMESTEP_STEP)) {
                return E_INVALIDARG;
            }

            if (0 == ((AM_FRAMESTEP_STEP *)pPropData)->dwFramesToStep) {
                return E_INVALIDARG;
            }
            else {
                CAutoLock cLock(&m_InterfaceLock);
                DWORD dwStep = ((AM_FRAMESTEP_STEP *)pPropData)->dwFramesToStep;
                return m_lpISControl->FrameStep(dwStep, 0);
            }
            return S_OK;


        case AM_PROPERTY_FRAMESTEP_CANCEL:
            {
                CAutoLock cLock(&m_InterfaceLock);
                return m_lpISControl->CancelFrameStep();
            }
            return S_OK;

        case AM_PROPERTY_FRAMESTEP_CANSTEP:
        case AM_PROPERTY_FRAMESTEP_CANSTEPMULTIPLE:
            return S_OK;
        }
    }

    if (guidPropSet != AM_KSPROPSETID_CopyProt)
        return E_PROP_SET_UNSUPPORTED;

    if (dwPropID != AM_PROPERTY_COPY_MACROVISION)
        return E_PROP_ID_UNSUPPORTED;

    if (pPropData == NULL)
        return E_INVALIDARG;

    if (cbPropData < sizeof(DWORD))
        return E_INVALIDARG ;

    if (m_MacroVision.SetMacroVision(m_hMonitor, *((LPDWORD)pPropData)))
        return NOERROR;
    else
        return VFW_E_COPYPROT_FAILED;
}

/******************************Public*Routine******************************\
* Get
*
*
*
* History:
* Tue 04/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::Get(
    REFGUID guidPropSet,
    DWORD PropID,
    LPVOID pInstanceData,
    DWORD cbInstanceData,
    LPVOID pPropData,
    DWORD cbPropData,
    DWORD *pcbReturned
    )
{
    AMTRACE((TEXT("CVMRFilter::Get")));
    return E_NOTIMPL;
}


/******************************Public*Routine******************************\
* QuerySupported
*
*
*
* History:
* Tue 04/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::QuerySupported(
    REFGUID guidPropSet,
    DWORD dwPropID,
    DWORD *pTypeSupport
    )
{
    AMTRACE((TEXT("CVMRFilter::QuerySupported")));

    if (guidPropSet != AM_KSPROPSETID_CopyProt)
        return E_PROP_SET_UNSUPPORTED ;

    if (dwPropID != AM_PROPERTY_COPY_MACROVISION)
        return E_PROP_ID_UNSUPPORTED ;

    if (pTypeSupport)
        *pTypeSupport = KSPROPERTY_SUPPORT_SET ;

    return S_OK;
}

/******************************Public*Routine******************************\
* SetImageCompositor
*
*
*
* History:
* Fri 06/23/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetImageCompositor(
    IVMRImageCompositor* lpVMRImgCompositor
    )
{
    AMTRACE((TEXT("CVMRFilter::SetImageCompositor")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    HRESULT hr = VFW_E_VMR_NOT_IN_MIXER_MODE;
    if (m_lpMixControl) {
        ASSERT(!m_VMRModePassThru);
        hr = m_lpMixControl->SetImageCompositor(lpVMRImgCompositor);
    }
    return hr;
}


/******************************Public*Routine******************************\
* SetNumberOfStreams
*
*
*
* History:
* Tue 04/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetNumberOfStreams(
    DWORD dwMaxStreams
    )
{
    AMTRACE((TEXT("CVMRFilter::SetNumberOfStreams")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    HRESULT hr = VFW_E_WRONG_STATE;

    if (m_hr3D != DD_OK) {

        DbgLog((LOG_ERROR, 1,
                TEXT("This graphics mode does not have the  necessary 3D h/w to perform mix!ing !")));

        return m_hr3D;
    }

    // preempt egregiously bad calls before passing to mixer
    if (dwMaxStreams > MAX_MIXER_STREAMS) {
        DbgLog((LOG_ERROR, 1, TEXT("Too many Mixer Streams !!")));
        return E_INVALIDARG;
    }

    if (!m_fInputPinCountSet && m_VMRModePassThru && !NumInputPinsConnected())
    {
        if (dwMaxStreams > 0) {

            hr = S_OK;
            if (dwMaxStreams > 1) {
                // We subtract one from the number of streams because the
                // first input pin has already been created in the constructor.
                hr = CreateExtraInputPins(dwMaxStreams-1);
            }

            if (SUCCEEDED(hr)) {
                hr = MixerInit(dwMaxStreams);
                if (FAILED(hr)) {
                    DbgLog((LOG_ERROR, 1,
                            TEXT("Mixer initialization FAILED!!")));

                    if (dwMaxStreams > 1) {
                        DestroyExtraInputPins();
                    }
                }
            }
        }
        else {
            DbgLog((LOG_ERROR, 1, TEXT("MaxStreams must be greater than 0")));
            hr = E_INVALIDARG;
        }
    }

    if (SUCCEEDED(hr)) {
        m_fInputPinCountSet = true;
        m_VMRModePassThru = false;
    }

    return hr;
}

/******************************Public*Routine******************************\
* GetNumberOfStreams
*
*
*
* History:
* Tue 04/11/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetNumberOfStreams(
    DWORD* pdwMaxStreams
    )
{
    AMTRACE((TEXT("CVMRFilter::GetNumberOfStreams")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if ( ISBADWRITEPTR(pdwMaxStreams) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    HRESULT hr = VFW_E_VMR_NOT_IN_MIXER_MODE;
    if (m_lpMixControl) {
        ASSERT(!m_VMRModePassThru);
        hr = m_lpMixControl->GetNumberOfStreams(pdwMaxStreams);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetRenderingPrefs
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetRenderingPrefs(
    DWORD dwRenderingPrefs
    )
{
    AMTRACE((TEXT("CVMRFilter::SetRenderingPrefs")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (dwRenderingPrefs & ~RenderPrefs_Mask) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid rendering pref specified")));
        return E_INVALIDARG;
    }


    HRESULT hr = VFW_E_WRONG_STATE;
    if (m_pPresenterConfig) {

        if (dwRenderingPrefs & RenderPrefs_PreferAGPMemWhenMixing) {
            m_dwRenderPrefs |= RenderPrefs_PreferAGPMemWhenMixing;
        }
        else {
            m_dwRenderPrefs &= ~RenderPrefs_PreferAGPMemWhenMixing;
        }

        // turn of flags that don't effect the AP object.
        dwRenderingPrefs &= ~RenderPrefs_PreferAGPMemWhenMixing;

        hr = m_pPresenterConfig->SetRenderingPrefs(dwRenderingPrefs);
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetRenderingPrefs
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetRenderingPrefs(
    DWORD* pdwRenderingPrefs
    )
{
    AMTRACE((TEXT("CVMRFilter::GetRenderingPrefs")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if ( ISBADWRITEPTR(pdwRenderingPrefs) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    HRESULT hr = VFW_E_WRONG_STATE;
    if (m_pPresenterConfig) {
        hr = m_pPresenterConfig->GetRenderingPrefs(pdwRenderingPrefs);
        if (SUCCEEDED(hr)) {
            *pdwRenderingPrefs |= m_dwRenderPrefs;
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* SetRenderingMode
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetRenderingMode(
    DWORD RenderingMode
    )
{
    AMTRACE((TEXT("CVMRFilter::SetRenderingMode")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = VFW_E_WRONG_STATE;

    if ( ( 0 == RenderingMode ) ||
         ( RenderingMode & ~(VMRMode_Mask) ) ||
         ( RenderingMode & (RenderingMode-1) ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid rendering mode") ));
        return E_INVALIDARG;
    }

    //
    // This is the only place where "pass thru" mode can be switched on
    //
    if (ModeChangeAllowed()) {

        SetVMRMode(RenderingMode);

        hr = S_OK;
        if ((RenderingMode & VMRMode_Windowless) || (RenderingMode & VMRMode_Windowed)) {
            hr = ValidateIVRWindowlessControlState();
        }

    }

    return hr;
}

/******************************Public*Routine******************************\
* GetRenderingMode
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetRenderingMode(
    DWORD* pRenderingMode
    )
{
    AMTRACE((TEXT("CVMRFilter::GetRenderingMode")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = S_OK;

    if ( ISBADWRITEPTR(pRenderingMode) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    *pRenderingMode = m_VMRMode;
    return hr;
}

/******************************Public*Routine******************************\
* GetAspectRatioModePrivate
*
*
* Called by VMRConfigInternal - no longer used
*
* History:
* Fri 01/05/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetAspectRatioModePrivate(
    DWORD* lpAspectRatioMode
    )
{
    AMTRACE((TEXT("CVMRFilter::GetAspectRatioModePrivate")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = S_OK;

    if ( ISBADWRITEPTR(lpAspectRatioMode) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    if (m_lpWLControl) {

        hr = m_lpWLControl->GetAspectRatioMode(lpAspectRatioMode);
    }
    else {
        *lpAspectRatioMode = m_ARMode;
    }
    return hr;
}


/******************************Public*Routine******************************\
* SetAspectRatioModePrivate
*
*
* Called by VMRConfigInternal - no longer used
*
* History:
* Fri 01/05/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetAspectRatioModePrivate(
    DWORD AspectRatioMode
    )
{
    AMTRACE((TEXT("CVMRFilter::SetAspectRatioModePrivate")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = S_OK;

    if (AspectRatioMode != VMR_ARMODE_NONE &&
        AspectRatioMode != VMR_ARMODE_LETTER_BOX) {

        return E_INVALIDARG;
    }

    if (m_lpWLControl) {

        hr = m_lpWLControl->SetAspectRatioMode(AspectRatioMode);
    }
    else {
        m_ARMode = AspectRatioMode;
    }

    return hr;
}

/******************************Public*Routine******************************\
* SetMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetMonitor(
    const VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CVMRFilter::SetMonitor")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    HRESULT hr = VFW_E_WRONG_STATE;
    if (m_pPresenterMonitorConfig) {
        hr = m_pPresenterMonitorConfig->SetMonitor( pGUID );
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetMonitor(
    VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CVMRFilter::GetMonitor")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if ( ISBADWRITEPTR(pGUID) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    HRESULT hr = VFW_E_WRONG_STATE;
    if (m_pPresenterMonitorConfig) {
        hr = m_pPresenterMonitorConfig->GetMonitor( pGUID );
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetDefaultMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetDefaultMonitor(
    const VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CVMRFilter::SetDefaultMonitor")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if ( ISBADREADPTR(pGUID) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    HRESULT hr = VFW_E_WRONG_STATE;
    if (m_pPresenterMonitorConfig) {
        hr = m_pPresenterMonitorConfig->SetDefaultMonitor( pGUID );
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetDefaultMonitor
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetDefaultMonitor(
    VMRGUID *pGUID
    )
{
    AMTRACE((TEXT("CVMRFilter::GetDefaultMonitor")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if ( ISBADWRITEPTR(pGUID) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    HRESULT hr = VFW_E_WRONG_STATE;
    if (m_pPresenterMonitorConfig) {
        hr = m_pPresenterMonitorConfig->GetDefaultMonitor( pGUID );
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetAvailableMonitors
*
*
*
* History:
* Tue 04/25/2000 - GlennE - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetAvailableMonitors(
    VMRMONITORINFO* pInfo,
    DWORD dwMaxInfoArraySize,
    DWORD* pdwNumDevices
    )
{
    AMTRACE((TEXT("CVMRFilter::GetAvailableMonitors")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if ( ISBADWRITEPTR(pdwNumDevices) ||
         ( (NULL != pInfo) && ISBADWRITEARRAY(pInfo,dwMaxInfoArraySize)))
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    HRESULT hr = VFW_E_WRONG_STATE;
    if (m_pPresenterMonitorConfig) {
        hr = m_pPresenterMonitorConfig->GetAvailableMonitors(pInfo,
                                                             dwMaxInfoArraySize,
                                                             pdwNumDevices);
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetAlphaBitmap
*
*
*
* History:
* Mon 05/15/2000 - nwilt - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetAlphaBitmap( const VMRALPHABITMAP *pBmpParms )
{
    AMTRACE((TEXT("CVMRFilter::SetAlphaBitmap")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    HRESULT hr = VFW_E_WRONG_STATE;

    if ( ISBADREADPTR( pBmpParms ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    if (m_lpMixBitmap) {
        hr =  m_lpMixBitmap->SetAlphaBitmap( pBmpParms );
    }
    return hr;
}

/******************************Public*Routine******************************\
* UpdateAlphaBitmapParameters
*
*
*
* History:
* Mon 10/31/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::UpdateAlphaBitmapParameters( VMRALPHABITMAP *pBmpParms )
{
    AMTRACE((TEXT("CVMRFilter::UpdateAlphaBitmap")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    HRESULT hr = VFW_E_WRONG_STATE;

    if ( ISBADWRITEPTR( pBmpParms ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    if (m_lpMixBitmap) {
        hr = m_lpMixBitmap->UpdateAlphaBitmapParameters( pBmpParms );
    }

    return hr;
}


/******************************Public*Routine******************************\
* GetAlphaBitmapParameters
*
*
*
* History:
* Mon 05/15/2000 - nwilt - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetAlphaBitmapParameters( VMRALPHABITMAP *pBmpParms )
{
    AMTRACE((TEXT("CVMRFilter::GetAlphaBitmap")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    HRESULT hr = VFW_E_WRONG_STATE;

    if ( ISBADWRITEPTR( pBmpParms ) )
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad pointer") ));
        return E_POINTER;
    }

    if (m_lpMixBitmap) {
        hr = m_lpMixBitmap->GetAlphaBitmapParameters( pBmpParms );
    }

    return hr;
}

/******************************Public*Routine******************************\
* get_FramesDroppedInRenderer
*
*
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::get_FramesDroppedInRenderer(
    int *cFramesDropped
    )
{
    AMTRACE((TEXT("CVMRFilter::get_FramesDroppedInRenderer")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = E_NOTIMPL;

    if (m_lpISQualProp) {
        hr = m_lpISQualProp->get_FramesDroppedInRenderer(cFramesDropped);
    }

    return hr;
}

/******************************Public*Routine******************************\
* get_FramesDrawn
*
*
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::get_FramesDrawn(
    int *pcFramesDrawn
    )
{
    AMTRACE((TEXT("CVMRFilter::get_FramesDrawn")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = E_NOTIMPL;

    if (m_lpISQualProp) {
        hr = m_lpISQualProp->get_FramesDrawn(pcFramesDrawn);
    }
    return hr;
}

/******************************Public*Routine******************************\
* get_AvgFrameRate
*
*
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::get_AvgFrameRate(
    int *piAvgFrameRate
    )
{
    AMTRACE((TEXT("CVMRFilter::get_AvgFrameRate")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = E_NOTIMPL;

    if (m_lpISQualProp) {
        hr = m_lpISQualProp->get_AvgFrameRate(piAvgFrameRate);
    }

    return hr;
}

/******************************Public*Routine******************************\
* get_Jitter
*
*
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::get_Jitter(
    int *piJitter
    )
{
    AMTRACE((TEXT("CVMRFilter::get_Jitter")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = E_NOTIMPL;

    if (m_lpISQualProp) {
        hr = m_lpISQualProp->get_Jitter(piJitter);
    }

    return hr;
}

/******************************Public*Routine******************************\
* get_AvgSyncOffset
*
*
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::get_AvgSyncOffset(
    int *piAvg
    )
{
    AMTRACE((TEXT("CVMRFilter::get_AvgSyncOffset")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = E_NOTIMPL;

    if (m_lpISQualProp) {
        hr = m_lpISQualProp->get_AvgSyncOffset(piAvg);
    }

    return hr;
}

/******************************Public*Routine******************************\
* get_DevSyncOffset
*
*
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::get_DevSyncOffset(
    int *piDev
    )
{
    AMTRACE((TEXT("CVMRFilter::get_DevSyncOffset")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = E_NOTIMPL;

    if (m_lpISQualProp) {
        hr = m_lpISQualProp->get_DevSyncOffset(piDev);
    }

    return hr;
}

/******************************Public*Routine******************************\
* SetSink
*
*
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetSink(
    IQualityControl * piqc
    )
{
    AMTRACE((TEXT("CVMRFilter::SetSink")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = E_NOTIMPL;

    return hr;
}

/******************************Public*Routine******************************\
* Notify
*
*
*
* History:
* Mon 05/22/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::Notify(
    IBaseFilter * pSelf,
    Quality q
    )
{
    AMTRACE((TEXT("CVMRFilter::Notify")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);
    HRESULT hr = E_NOTIMPL;

    return hr;
}

/******************************Public*Routine******************************\
* JoinFilterGraph
*
*
* Override JoinFilterGraph so that, just before leaving
* the graph we can send an EC_WINDOW_DESTROYED event
*
* History:
* Mon 11/06/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::JoinFilterGraph(
    IFilterGraph *pGraph,
    LPCWSTR pName
    )
{
    AMTRACE((TEXT("CVMRFilter::JoinFilterGraph")));

    if (m_VMRMode == VMRMode_Windowed && m_pVideoWindow) {

        // Since we send EC_ACTIVATE, we also need to ensure
        // we send EC_WINDOW_DESTROYED or the resource manager may be
        // holding us as a focus object

        if (!pGraph && m_pGraph) {

            // We were in a graph and now we're not
            // Do this properly in case we are aggregated
            IBaseFilter* pFilter;
            QueryInterface(IID_IBaseFilter,(void **) &pFilter);
            NotifyEvent(EC_WINDOW_DESTROYED, (LPARAM) pFilter, 0);
            pFilter->Release();
        }
    }

    return CBaseFilter::JoinFilterGraph(pGraph, pName);
}

/******************************Public*Routine******************************\
* GetPages
*
*
* Implement ISpecifyPropertyPages interface.
* Returns GUIDs of all supported property pages.
*
* History:
* 3/23/2001 - StRowe - Created
*
\**************************************************************************/
STDMETHODIMP CVMRFilter::GetPages(CAUUID *pPages)
{
    AMTRACE((TEXT("CVMRFilter::GetPages")));

    pPages->cElems = 3;
    pPages->pElems = (GUID *) CoTaskMemAlloc(sizeof(GUID)*(pPages->cElems));
    if (pPages->pElems == NULL)
    {
        return E_OUTOFMEMORY;
    }

    pPages->pElems[0] = CLSID_VMRFilterConfigProp;
    pPages->pElems[1] = CLSID_COMQualityProperties;
    pPages->pElems[2] = CLSID_VMRDeinterlaceProp;
    return NOERROR;
}


// CPersistStream
/******************************Public*Routine******************************\
* WriteToStream
*
*
*
* History:
* Fri 03/23/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::WriteToStream(
    IStream *pStream
    )
{
    AMTRACE((TEXT("CVMRFilter::WriteToStream")));
    VMRFilterInfo vmrInfo;

    ZeroMemory(&vmrInfo, sizeof(vmrInfo));
    vmrInfo.dwSize = sizeof(vmrInfo);

    //
    // Only write mixer info if we actually have a mixer !!
    //

    if (m_lpMixControl) {

        vmrInfo.dwNumPins = m_dwNumPins;
        for (DWORD i = 0; i < m_dwNumPins; i++) {

            GetAlpha(i, &vmrInfo.StreamInfo[i].alpha);
            GetZOrder(i, &vmrInfo.StreamInfo[i].zOrder);
            GetOutputRect(i, &vmrInfo.StreamInfo[i].rect);
        }
    }

    return pStream->Write(&vmrInfo, sizeof(vmrInfo), 0);
}

/******************************Public*Routine******************************\
* ReadFromStream
*
*
*
* History:
* Fri 03/23/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::ReadFromStream(
    IStream *pStream
    )
{
    AMTRACE((TEXT("CVMRFilter::ReadFromStream")));
    VMRFilterInfo vmrInfo;
    HRESULT hr = S_OK;

    hr = pStream->Read(&vmrInfo, sizeof(vmrInfo), 0);
    if (FAILED(hr)) {
        return hr;
    }

    if (vmrInfo.dwSize != sizeof(vmrInfo)) {
        return VFW_E_INVALID_FILE_VERSION;
    }

    //
    // zero pins means we are in "pass-thru" mode, so we
    // don't have to restore any more info.
    //

    if (vmrInfo.dwNumPins > 0) {

        hr = SetNumberOfStreams(vmrInfo.dwNumPins);
        if (FAILED(hr)) {
            return hr;
        }

        for (DWORD i = 0; i < vmrInfo.dwNumPins; i++) {

            SetAlpha(i, vmrInfo.StreamInfo[i].alpha);
            SetZOrder(i, vmrInfo.StreamInfo[i].zOrder);
            SetOutputRect(i, &vmrInfo.StreamInfo[i].rect);
        }
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* SizeMax
*
*
*
* History:
* Fri 03/23/2001 - StEstrop - Created
*
\**************************************************************************/
int
CVMRFilter::SizeMax()
{
    AMTRACE((TEXT("CVMRFilter::SizeMax")));
    return sizeof(VMRFilterInfo);
}


/******************************Public*Routine******************************\
* GetClassID
*
*
*
* History:
* Fri 03/23/2001 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetClassID(
    CLSID *pClsid
    )
{
    AMTRACE((TEXT("CVMRFilter::GetClassID")));
    return CBaseFilter::GetClassID(pClsid);
}


/******************************Public*Routine******************************\
* CompleteConnect(dwPinID)
*
*
* Notes:
*  Called by the VMR pin on connect.  We use this to override the aspect ratio
*  mode.
*
* History:
* Fri 07/12/2001 - GlennE - Created
*
\**************************************************************************/
HRESULT
CVMRFilter::CompleteConnect(
    DWORD dwPinId,
    const CMediaType& cmt
    )
{
    AMTRACE((TEXT("CVMRFilter::CompleteConnect")));


    if (NumInputPinsConnected() == 1 || dwPinId == 0) {

        //
        // set the default ASPECT ratio mode based on the input type
        //

        if (!m_bARModeDefaultSet) {

            if (cmt.FormatType() && *cmt.FormatType() == FORMAT_VideoInfo2) {

                //
                // Look for the presence of a VideoInfo format type.
                // If we find the upstream filter can propose these types
                // we don't set the aspect ratio mode becuase this filter
                // would have connected to the old renderer not the OVMixer
                // The old renderer didn't perform any aspect ratio correction
                // so we had better not too.
                //

                IPin* pReceivePin = m_pInputPins[dwPinId]->m_Connected;
                IEnumMediaTypes *pEnumMediaTypes = NULL;
                BOOL fVideoInfoAvail = FALSE;

                HRESULT hr = pReceivePin->EnumMediaTypes(&pEnumMediaTypes);
                if (FAILED(hr)) {
                    return hr;
                }

                do {

                    AM_MEDIA_TYPE* pEnumMT;
                    ULONG ulFetched;

                    hr = pEnumMediaTypes->Next(1, &pEnumMT, &ulFetched);
                    if (FAILED(hr) || ulFetched != 1) {
                        break;
                    }

                    fVideoInfoAvail = (pEnumMT->formattype == FORMAT_VideoInfo);
                    DeleteMediaType(pEnumMT);

                } while (!fVideoInfoAvail);

                pEnumMediaTypes->Release();

                if (FAILED(hr)) {
                    return hr;
                }

                if (fVideoInfoAvail) {
                    return S_OK;
                }

                //
                // reset state if set (we don't want to force Windowless
                // unless the app has set it (e.g. auto render won't set the
                // state until we play)
                //
                hr = S_OK;
                if (m_lpWLControl) {

                    hr = ValidateIVRWindowlessControlState();
                    if (SUCCEEDED(hr)) {
                        hr = m_lpWLControl->SetAspectRatioMode(VMR_ARMODE_LETTER_BOX);
                    }
                }

                //
                // if there is no lpWLControl, we set it next time
                // ValidateIVRWindowlessControlState is called
                //
                if (SUCCEEDED(hr)) {
                    m_ARMode = VMR_ARMODE_LETTER_BOX;
                }
            }
        }
    }

    return S_OK;
}


/******************************Private*Routine******************************\
* NumInputPinsConnected
*
*
* History:
* Fri 07/12/2001 - GlennE - Created
*
\**************************************************************************/
int CVMRFilter::NumInputPinsConnected() const
{
    AMTRACE((TEXT("CVMRFilter::NumInputPinsConnected")));
    int iCount = 0;
    for (DWORD i = 0; i < m_dwNumPins; i++) {
        if (m_pInputPins[i]->m_Connected) {
            iCount++;
        }
    }
    return iCount;
}



// IVMRDeinterlaceControl

/*****************************Private*Routine******************************\
* VMRVideoDesc2DXVA_VideoDesc
*
*
*
* History:
* Thu 04/25/2002 - StEstrop - Created
*
\**************************************************************************/
void
VMRVideoDesc2DXVA_VideoDesc(
    DXVA_VideoDesc* lpDXVAVideoDesc,
    const VMRVideoDesc* lpVMRVideoDesc
    )
{
    AMTRACE((TEXT("CVMRFilter::VMRVideoDesc2DXVA_VideoDesc")));

    lpDXVAVideoDesc->Size = sizeof(DXVA_VideoDesc);
    lpDXVAVideoDesc->SampleWidth = lpVMRVideoDesc->dwSampleWidth;
    lpDXVAVideoDesc->SampleHeight = lpVMRVideoDesc->dwSampleHeight;
    if (lpVMRVideoDesc->SingleFieldPerSample) {
        lpDXVAVideoDesc->SampleFormat = DXVA_SampleFieldSingleEven;
    }
    else {
        lpDXVAVideoDesc->SampleFormat = DXVA_SampleFieldInterleavedEvenFirst;
    }
    lpDXVAVideoDesc->d3dFormat = lpVMRVideoDesc->dwFourCC;
    lpDXVAVideoDesc->InputSampleFreq.Numerator   = lpVMRVideoDesc->InputSampleFreq.dwNumerator;
    lpDXVAVideoDesc->InputSampleFreq.Denominator = lpVMRVideoDesc->InputSampleFreq.dwDenominator;
    lpDXVAVideoDesc->OutputFrameFreq.Numerator   = lpVMRVideoDesc->OutputFrameFreq.dwNumerator;
    lpDXVAVideoDesc->OutputFrameFreq.Denominator = lpVMRVideoDesc->OutputFrameFreq.dwDenominator;
}


/******************************Public*Routine******************************\
* GetNumberOfDeinterlaceModes
*
*
*
* History:
* Mon 04/22/2002 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetNumberOfDeinterlaceModes(
    VMRVideoDesc* lpVideoDesc,
    LPDWORD lpdwNumDeinterlaceModes,
    LPGUID lpDeinterlaceModes
    )
{
    AMTRACE((TEXT("CVMRFilter::GetNumberOfDeinterlaceModes")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (ISBADREADPTR(lpVideoDesc)) {
        return E_POINTER;
    }

    if (ISBADWRITEPTR(lpdwNumDeinterlaceModes)) {
        return E_POINTER;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    if (!m_pDeinterlace) {
        return VFW_E_DDRAW_CAPS_NOT_SUITABLE;
    }


    DWORD dwNumModes = MAX_DEINTERLACE_DEVICE_GUIDS;
    GUID Modes[MAX_DEINTERLACE_DEVICE_GUIDS];
    DXVA_VideoDesc VideoDesc;
    VMRVideoDesc2DXVA_VideoDesc(&VideoDesc, lpVideoDesc);

    HRESULT hr = m_pDeinterlace->QueryAvailableModes(&VideoDesc, &dwNumModes,
                                                     Modes);
    if (hr == S_OK) {

        if (lpDeinterlaceModes != NULL) {
            dwNumModes = min(*lpdwNumDeinterlaceModes, dwNumModes);
            CopyMemory(lpDeinterlaceModes, Modes, dwNumModes * sizeof(GUID));
        }
    }

    *lpdwNumDeinterlaceModes = dwNumModes;

    return hr;
}

/******************************Public*Routine******************************\
* GetDeinterlaceModeCaps
*
*
*
* History:
* Mon 04/22/2002 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetDeinterlaceModeCaps(
    LPGUID lpDeinterlaceMode,
    VMRVideoDesc* lpVideoDesc,
    VMRDeinterlaceCaps* lpDeinterlaceCaps
    )
{
    AMTRACE((TEXT("CVMRFilter::GetDeinterlaceModeCaps")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (ISBADREADPTR(lpDeinterlaceMode)) {
        return E_POINTER;
    }

    if (ISBADREADPTR(lpVideoDesc)) {
        return E_POINTER;
    }

    if (ISBADWRITEPTR(lpDeinterlaceCaps)) {
        return E_POINTER;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    if (!m_pDeinterlace) {
        return VFW_E_DDRAW_CAPS_NOT_SUITABLE;
    }

    DXVA_VideoDesc VideoDesc;
    VMRVideoDesc2DXVA_VideoDesc(&VideoDesc, lpVideoDesc);
    DXVA_DeinterlaceCaps DeinterlaceCaps;

    HRESULT hr = m_pDeinterlace->QueryModeCaps(lpDeinterlaceMode,
                                               &VideoDesc, &DeinterlaceCaps);
    if (hr == S_OK) {

        lpDeinterlaceCaps->dwNumPreviousOutputFrames =
            DeinterlaceCaps.NumPreviousOutputFrames;

        lpDeinterlaceCaps->dwNumForwardRefSamples =
            DeinterlaceCaps.NumForwardRefSamples;

        lpDeinterlaceCaps->dwNumBackwardRefSamples =
            DeinterlaceCaps.NumBackwardRefSamples;

        lpDeinterlaceCaps->DeinterlaceTechnology =
            (VMRDeinterlaceTech)DeinterlaceCaps.DeinterlaceTechnology;
    }

    return hr;
}


/******************************Public*Routine******************************\
* GetActualDeinterlaceMode
*
*
*
* History:
* Mon 04/22/2002 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetActualDeinterlaceMode(
    DWORD dwStreamID,
    LPGUID lpDeinterlaceMode
    )
{
    AMTRACE((TEXT("CVMRFilter::GetActualDeinterlaceMode")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (ISBADWRITEPTR(lpDeinterlaceMode)) {
        return E_POINTER;
    }

    if (dwStreamID > m_dwNumPins) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid stream ID")));
        return E_INVALIDARG;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    *lpDeinterlaceMode = m_pInputPins[dwStreamID]->m_DeinterlaceGUID;

    return S_OK;
}

/******************************Public*Routine******************************\
* GetDeinterlaceMode
*
*
*
* History:
* Mon 04/22/2002 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetDeinterlaceMode(
    DWORD dwStreamID,
    LPGUID lpDeinterlaceMode
    )
{
    AMTRACE((TEXT("CVMRFilter::GetDeinterlaceMode")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (ISBADWRITEPTR(lpDeinterlaceMode)) {
        return E_POINTER;
    }

    if (dwStreamID > m_dwNumPins) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid stream ID")));
        return E_INVALIDARG;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    HRESULT hr = S_OK;
    if (m_pInputPins[dwStreamID]->m_DeinterlaceUserGUIDSet) {
        *lpDeinterlaceMode = m_pInputPins[dwStreamID]->m_DeinterlaceUserGUID;
    }
    else {
        *lpDeinterlaceMode = GUID_NULL;
        hr = S_FALSE;
    }

    return hr;
}

/******************************Public*Routine******************************\
* SetDeinterlaceMode
*
*
*
* History:
* Mon 04/22/2002 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetDeinterlaceMode(
    DWORD dwStreamID,
    LPGUID lpDeinterlaceMode
    )
{
    AMTRACE((TEXT("CVMRFilter::SetDeinterlaceMode")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (ISBADREADPTR(lpDeinterlaceMode)) {
        return E_POINTER;
    }

    if (dwStreamID > m_dwNumPins) {
        if (dwStreamID != 0xFFFFFFFF) {
            DbgLog((LOG_ERROR, 1, TEXT("Invalid stream ID")));
            return E_INVALIDARG;
        }
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    if (dwStreamID == 0xFFFFFFFF) {
        for (DWORD i = 0; i < m_dwNumPins; i++) {
            m_pInputPins[i]->m_DeinterlaceUserGUIDSet = TRUE;
            m_pInputPins[i]->m_DeinterlaceUserGUID = *lpDeinterlaceMode;
        }
    }
    else {
        m_pInputPins[dwStreamID]->m_DeinterlaceUserGUIDSet = TRUE;
        m_pInputPins[dwStreamID]->m_DeinterlaceUserGUID = *lpDeinterlaceMode;
    }

    return S_OK;
}


/******************************Public*Routine******************************\
* GetDeinterlacePrefs
*
*
*
* History:
* Mon 04/22/2002 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::GetDeinterlacePrefs(
    LPDWORD lpdwDeinterlacePrefs
    )
{
    AMTRACE((TEXT("CVMRFilter::GetDeinterlacePrefs")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (ISBADWRITEPTR(lpdwDeinterlacePrefs)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid pointer passed to GetDeinterlacePrefs")));
        return E_POINTER;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    *lpdwDeinterlacePrefs = m_dwDeinterlacePrefs;

    return S_OK;
}


/******************************Public*Routine******************************\
* SetDeinterlacePrefs
*
*
*
* History:
* Mon 04/22/2002 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRFilter::SetDeinterlacePrefs(
    DWORD dwDeinterlacePrefs
    )
{
    AMTRACE((TEXT("CVMRFilter::SetDeinterlacePrefs")));
    CAutoLock cInterfaceLock(&m_InterfaceLock);

    if (dwDeinterlacePrefs == 0 || (dwDeinterlacePrefs & ~DeinterlacePref_Mask)) {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid deinterlace pref specified")));
        return E_INVALIDARG;
    }

    if (!m_lpMixStream) {
        return VFW_E_VMR_NOT_IN_MIXER_MODE;
    }

    HRESULT hr = S_OK;
    switch (dwDeinterlacePrefs) {
    case DeinterlacePref_NextBest:
    case DeinterlacePref_BOB:
    case DeinterlacePref_Weave:
        m_dwDeinterlacePrefs = dwDeinterlacePrefs;
        break;

    default:
        hr = E_INVALIDARG;
    }

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\drect.cpp ===
/******************************Module*Header*******************************\
* Module Name: CVPMFilter.cpp
*
*
*
*
* Created: Tue 02/15/2000
* Author:  Glenn Evans [GlennE]
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <DRect.h>


#if 1
#include <math.h>

static double myfloor(double dNumber)
{
    return floor( dNumber );
}
static double myceil(double dNumber)
{
    return ceil( dNumber );
}
#else
// have to define my own floor inorder to avoid pulling in the C runtime
static double myfloor(double dNumber)
{
    // cast it to LONGLONG to get rid of the fraction
    LONGLONG llNumber = (LONGLONG)dNumber;

    if ((dNumber > 0) && ((double)llNumber > dNumber))
    {
        // need to push ccNumber towards zero (eg 5.7)
        return (double)(llNumber-1);
    }
    else if ((dNumber < 0) && ((double)llNumber < dNumber))
    {
        // need to push ccNumber towards zero (eg -5.7)
        return (double)(llNumber+1);
    }
    else
    {
        // numbers like 5.3 or -5.3
        return (double)(llNumber);
    }
}


// have to define my own ceil inorder to avoid pulling in the C runtime
static double myceil(double dNumber)
{
    // cast it to LONGLONG to get rid of the fraction
    LONGLONG llNumber = (LONGLONG)dNumber;

    if ((dNumber > 0) && ((double)llNumber < dNumber))
    {
        // need to push ccNumber away from zero (eg 5.3)
        return (double)(llNumber+1);
    }
    else if ((dNumber < 0) && ((double)llNumber > dNumber))
    {
        // need to push ccNumber away from zero (eg -5.3)
        return (double)(llNumber-1);
    }
    else
    {
        // numbers like 5.7 or -5.7
        return (double)(llNumber);
    }
}
#endif

// this in a way defines the error margin
#define EPSILON 0.0001

// this is a function implemented solely to handle floating point rounding errors.
// dEpsilon defines the error margin. So if a floating point number is within I-e, I+e (inclusive)
// (I is an integer, e is dEpsilon), we return its floor as I itself, otherwise we go to the
// base defintion of myfloor
static double myfloor(double dNumber, double dEpsilon)
{
    if (dNumber > dEpsilon)
        return myfloor(dNumber + dEpsilon);
    else if (dNumber < -dEpsilon)
        return myfloor(dNumber - dEpsilon);
    else
        return 0;
}

// this is a function implemented solely to handle floating point rounding errors.
// dEpsilon defines the error margin. So if a floating point number is within I-e, I+e (inclusive)
// (I is an integer, e is dEpsilon), we return its ceil as I itself, otherwise we go to the
// base defintion of myceil
static double myceil(double dNumber, double dEpsilon)
{
    if (dNumber > dEpsilon)
        return myceil(dNumber - dEpsilon);
    else if (dNumber < -dEpsilon)
        return myceil(dNumber + dEpsilon);
    else
        return 0;
}

DRect::DRect( const RECT& rc )
: m_left( rc.left )
, m_right( rc.right )
, m_top( rc.top )
, m_bottom( rc.bottom )
{
}

RECT DRect::AsRECT() const
{
    RECT rRect;

    rRect.left = (LONG)myfloor(m_left, EPSILON);
    rRect.top = (LONG)myfloor(m_top, EPSILON);
    rRect.right = (LONG)myceil(m_right, EPSILON);
    rRect.bottom = (LONG)myceil(m_bottom, EPSILON);
    return rRect;
}

DRect DRect::IntersectWith( const DRect& drect ) const
{
    return DRect(
     max( drect.m_left, m_left),   max( drect.m_top, m_top),
     min( drect.m_right, m_right), min( drect.m_bottom, m_bottom));
}

// just a helper function to scale a DRECT
void DRect::Scale( double dScaleX, double dScaleY )
{
    m_left *= dScaleX;
    m_right *= dScaleX;
    m_top *= dScaleY;
    m_bottom *= dScaleY;
}

// just a helper function, to get the letterboxed or cropped rect
// Puts the transformed rectangle into pRect.
double DRect::CorrectAspectRatio( double dPictAspectRatio, BOOL bShrink )
{
    double dWidth, dHeight, dNewWidth, dNewHeight;

    dNewWidth = dWidth = GetWidth();
    dNewHeight = dHeight = GetHeight();

    ASSERT( dWidth > 0 );
    ASSERT( dHeight > 0 );

    double dResolutionRatio = dWidth / dHeight;
    double dTransformRatio = dPictAspectRatio / dResolutionRatio;

    // shrinks one dimension to maintain the coorect aspect ratio
    if ( bShrink ) {
        if (dTransformRatio > 1.0) {
            dNewHeight = dNewHeight / dTransformRatio;
        } else if (dTransformRatio < 1.0) {
            dNewWidth = dNewWidth * dTransformRatio;
        }
    } // stretches one dimension to maintain the coorect aspect ratio
    else {
        if (dTransformRatio > 1.0) {
            dNewWidth = dNewWidth * dTransformRatio;
        } else if (dTransformRatio < 1.0) {
            dNewHeight = dNewHeight / dTransformRatio;
        }
    }

    // cut or add equal portions to the changed dimension

    m_left += (dWidth - dNewWidth)/2.0;
    m_right = m_left + dNewWidth;

    m_top += (dHeight - dNewHeight)/2.0;
    m_bottom = m_top + dNewHeight;

    return dTransformRatio;
}


/******************************Private*Routine******************************\
* ClipWith
*
* Clip a destination rectangle & update the scaled source accordingly
*
*
* History:
* Fri 04/07/2000 - GlennE - Created
*
\**************************************************************************/
void
DRect::ClipWith(const DRect& rdWith, DRect *pUpdate )
{
    // figure out src/dest scale ratios
    double dUpdateWidth  = pUpdate->GetWidth();
    double dUpdateHeight = pUpdate->GetHeight();

    double dDestWidth  = GetWidth();
    double dDestHeight = GetHeight();

    // clip destination (and adjust the source when we change the destination)

    // see if we have to clip horizontally
    if( dDestWidth ) {
        if( rdWith.m_left > m_left ) {
            double dDelta = rdWith.m_left - m_left;
            m_left += dDelta;
            double dDeltaSrc = dDelta*dUpdateWidth/dDestWidth;
            pUpdate->m_left += dDeltaSrc;
        }

        if( rdWith.m_right < m_right ) {
            double dDelta = m_right-rdWith.m_right;
            m_right -= dDelta;
            double dDeltaSrc = dDelta*dUpdateWidth/dDestWidth;
            pUpdate->m_right -= dDeltaSrc;
        }
    }
    // see if we have to clip vertically
    if( dDestHeight ) {
        if( rdWith.m_top > m_top ) {
            double dDelta = rdWith.m_top - m_top;
            m_top += dDelta;
            double dDeltaSrc = dDelta*dUpdateHeight/dDestHeight;
            pUpdate->m_top += dDeltaSrc;
        }

        if( rdWith.m_bottom < m_bottom ) {
            double dDelta = m_bottom-rdWith.m_bottom;
            m_bottom -= dDelta;
            double dDeltaSrc = dDelta*dUpdateHeight/dDestHeight;
            pUpdate->m_bottom -= dDeltaSrc;
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\video\vmrpin.cpp ===
/******************************Module*Header*******************************\
* Module Name: VMRPin.cpp
*
*
*
*
* Created: Tue 02/15/2000
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 2000 Microsoft Corporat
\**************************************************************************/
#include <streams.h>
#include <dvdmedia.h>
#include <windowsx.h>

#include "VMRenderer.h"
#if defined(CHECK_FOR_LEAKS)
#include "ifleak.h"
#endif

#include <malloc.h>     // for __alloca

#if defined( EHOME_WMI_INSTRUMENTATION )
#include "dxmperf.h"
#endif

/******************************Public*Routine******************************\
* CVMRInputPin::CVMRInputPin
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
#pragma warning(disable:4355)
CVMRInputPin::CVMRInputPin(
    DWORD dwID,
    CVMRFilter* pRenderer,
    CCritSec* pLock,
    HRESULT* phr,
    LPCWSTR pPinName
    ) :
    CBaseInputPin(NAME("New Renderer pin"), pRenderer, pLock, phr, pPinName),
    m_PinAllocator(this, pLock, phr),
    m_pInterfaceLock(pLock),
    m_pRenderer(pRenderer),
    m_bDynamicFormatNeeded(false),
    m_dwPinID(dwID),
    m_pDDS(NULL),
    m_pIOverlay(this),
    m_RenderTransport(AM_IMEMINPUTPIN),
    m_bVideoAcceleratorSupported(FALSE),
    m_bActive(false),
    m_dwBackBufferCount(0),
    m_dwCompSurfTypes(0),
    m_pCompSurfInfo(NULL),
    m_pIDDVAContainer(NULL),
    m_pIDDVideoAccelerator(NULL),
    m_pIVANotify(NULL),
    m_hEndOfStream(NULL),
    m_hDXVAEvent(NULL),
    m_dwDeltaDecode(0),
    m_fInDFC(FALSE),
    m_pVidSurfs(NULL),
    m_pVidHistorySamps(NULL),
    m_dwNumSamples(0),
    m_dwNumHistorySamples(0),
    m_DeinterlaceUserGUIDSet(FALSE),
    m_InterlacedStream(FALSE),
    m_SampleCount(0),
    m_SamplePeriod(0)
{
    AMTRACE((TEXT("CVMRInputPin::CVMRInputPin")));

    ZeroMemory(&m_mcGuid,              sizeof(m_mcGuid));
    ZeroMemory(&m_ddUncompDataInfo,    sizeof(m_ddUncompDataInfo));
    ZeroMemory(&m_ddvaInternalMemInfo, sizeof(m_ddvaInternalMemInfo));

    ZeroMemory(&m_DeinterlaceCaps,     sizeof(m_DeinterlaceCaps));
    ZeroMemory(&m_DeinterlaceGUID,     sizeof(m_DeinterlaceGUID));
    ZeroMemory(&m_DeinterlaceUserGUID, sizeof(m_DeinterlaceUserGUID));

    SetReconnectWhenActive(true);
    FrontBufferStale(FALSE);
    CompletelyConnected(FALSE);

}

/******************************Public*Routine******************************\
* CVMRInputPin::~CVMRInputPin()
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
CVMRInputPin::~CVMRInputPin()
{
    AMTRACE((TEXT("CVMRInputPin::~CVMRInputPin")));
}


/******************************Public*Routine******************************\
* AddRef, Release and QueryInterface
*
* Standard COM stuff
*
* History:
* Mon 05/01/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP_(ULONG)
CVMRInputPin::NonDelegatingAddRef()
{
    return m_pRenderer->AddRef();
}

STDMETHODIMP_(ULONG)
CVMRInputPin::NonDelegatingRelease()
{
    return m_pRenderer->Release();
}

STDMETHODIMP
CVMRInputPin::NonDelegatingQueryInterface(REFIID riid,VOID **ppv)
{
    HRESULT hr = E_NOINTERFACE;
    *ppv = NULL;

    if (riid == IID_IOverlay) {
        hr = GetInterface(&m_pIOverlay, ppv);
    }
    else if (riid == IID_IPinConnection) {
        hr = GetInterface((IPinConnection *)this, ppv);
    }
    else if (riid == IID_IAMVideoAccelerator) {
        hr = GetInterface((IAMVideoAccelerator *)this, ppv);
    }
    else if (riid == IID_IVMRVideoStreamControl) {
        hr = GetInterface((IVMRVideoStreamControl*)this, ppv);
    }
    else {
        hr = CBaseInputPin::NonDelegatingQueryInterface(riid,ppv);
    }

#if defined(CHECK_FOR_LEAKS)
    if (hr == S_OK) {
        _pIFLeak->AddThunk((IUnknown **)ppv, "VMR Pin Object",  riid);
    }
#endif

    return hr;
}


/******************************Public*Routine******************************\
* GetWindowHandle
*
*
*
* History:
* Mon 05/01/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::GetWindowHandle(
    HWND* pHwnd
    )
{
    AMTRACE((TEXT("CVMRInputPin::GetWindowHandle")));
    CAutoLock cRendererLock(&m_pRenderer->m_InterfaceLock);
    CheckPointer(pHwnd, E_POINTER);

    HRESULT hr = VFW_E_WRONG_STATE;

    if ((m_pRenderer->m_VMRMode & VMRMode_Windowed) &&
         m_pRenderer->m_pVideoWindow) {

        *pHwnd = m_pRenderer->m_pVideoWindow->GetWindowHWND();
        hr = S_OK;
    }

    return hr;
}


/******************************Public*Routine******************************\
* DynamicQueryAccept
*
* Do you accept this type chane in your current state?
*
* History:
* Tue 05/09/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::DynamicQueryAccept(
    const AM_MEDIA_TYPE *pmt
    )
{
    AMTRACE((TEXT("CVMRInputPin::DynamicQueryAccept")));
    CheckPointer(pmt, E_POINTER);

    CAutoLock cLock(m_pInterfaceLock);

    DbgLog((LOG_TRACE, 0, TEXT("CVMRInputPin::DynamicQueryAccept called")));

    //
    // I want CheckMedia type to behave as though we aren't connected to
    // anything yet - hence the messing about with m_bConnected.
    //
    CMediaType cmt(*pmt);
    BOOL bConnected = IsCompletelyConnected();
    CompletelyConnected(FALSE);
    HRESULT  hr = CheckMediaType(&cmt);
    CompletelyConnected(bConnected);

    return hr;
}

/******************************Public*Routine******************************\
* NotifyEndOfStream
*
* Set event when EndOfStream received - do NOT pass it on
* This condition is cancelled by a flush or Stop
*
* History:
* Tue 05/09/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::NotifyEndOfStream(
    HANDLE hNotifyEvent
    )
{
    AMTRACE((TEXT("CVMRInputPin::NotifyEndOfStream")));
    CAutoLock cObjectLock(m_pLock);
    m_hEndOfStream = hNotifyEvent;
    return S_OK;
}

/******************************Public*Routine******************************\
* IsEndPin
*
* Are you an 'end pin'
*
* History:
* Tue 05/09/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::IsEndPin()
{
    AMTRACE((TEXT("CVMRInputPin::IsEndPin")));
    return S_OK;
}


/******************************Public*Routine******************************\
* DynamicDisconnect
*
*
*
* History:
* Tue 05/09/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::DynamicDisconnect()
{
    AMTRACE((TEXT("CVMRInputPin::DynamicDisconnect")));
    CAutoLock cObjectLock(m_pLock);
    DbgLog((LOG_TRACE,2,TEXT("DynamicDisconnect called on Stream %d"), m_dwPinID));
    return CBasePin::DisconnectInternal();
}


/*****************************Private*Routine******************************\
* DynamicReconfigureMEM
*
* Performs a dynamic reconfiguration of the connection between the VMR and
* the filter upstream of this pin for the IMemInputPin connection protocol.
*
* History:
* Tue 05/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::DynamicReconfigureMEM(
    IPin * pConnector,
    const AM_MEDIA_TYPE *pmt
    )
{
    AMTRACE((TEXT("CVMRInputPin::DynamicReconfigureMEM")));

    CheckPointer(pmt, E_POINTER);
    CMediaType cmt(*pmt);

    CVMRPinAllocator* pAlloc = NULL;

    //
    // Can only do this if the allocator can be reconfigured
    //

    pAlloc = (CVMRPinAllocator *)m_pAllocator;
    if (!pAlloc) {
        DbgLog((LOG_ERROR, 1,
                TEXT("DynamicReconfigureMEM: Failed because of no allocator")));
        return E_FAIL;
    }


    //
    // If we are in pass thru mode just check that all the samples
    // have been returned to the allocator.  If we are in mixing mode
    // we have to wait until the mixer has finished with any samples
    // that it may have too.
    //

    if (m_dwPinID == 0 && m_pRenderer->m_VMRModePassThru) {

        if (!pAlloc->CanFree()) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("DynamicReconfigureMEM: Failed because allocator can't free")));
            return VFW_E_WRONG_STATE;
        }
    }
    else {

        //
        // TODO:  If the upstream decoder has any samples outstanding then
        // we fail this call.  If the mixer has samples outstanding then
        // we need to wait until its done with them.
        //

    }

    CompletelyConnected(FALSE);

    HRESULT hr = CheckMediaType(&cmt);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("DynamicReconfigureMEM: CheckMediaType failed")));
        return hr;
    }

    ALLOCATOR_PROPERTIES Props;
    pAlloc->Decommit();
    pAlloc->GetProperties(&Props);

    if (m_dwPinID == 0 && m_pRenderer->m_VMRModePassThru) {
        m_pRenderer->m_lpRLNotify->FreeSurface(m_pRenderer->m_dwUserID);
        m_pDDS = NULL;
    }
    else {
        ReleaseAllocatedSurfaces();
        RELEASE(m_pDDS);
    }
    FrontBufferStale(FALSE);

    SetMediaType(&cmt);

    ALLOCATOR_PROPERTIES PropsActual;
    Props.cbBuffer = pmt->lSampleSize;
    m_fInDFC = TRUE;
    hr = pAlloc->SetProperties(&Props, &PropsActual);
    m_fInDFC = FALSE;

    if (SUCCEEDED(hr)) {
        hr = pAlloc->Commit();
    }

    m_bDynamicFormatNeeded = true;
    CompletelyConnected(TRUE);

    return hr;

}


/*****************************Private*Routine******************************\
* DynamicReconfigureDVA
*
* Performs a dynamic reconfiguration of the connection between the VMR and
* the filter upstream of this pin for the IAMVideoAccelerator connection
* protocol.
*
* History:
* Tue 05/09/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::DynamicReconfigureDVA(
    IPin * pConnector,
    const AM_MEDIA_TYPE *pmt
    )
{
    AMTRACE((TEXT("CVMRInputPin::DynamicReconfigureDVA")));

    CheckPointer(pmt, E_POINTER);
    CMediaType cmt(*pmt);

    //
    // If we are in mixing mode we have to wait until the mixer has finished
    // with any samples that it may have.
    //

    if (!m_pRenderer->m_VMRModePassThru) {

        //
        // TODO:  If the upstream decoder has any samples outstanding then
        // we fail this call.  If the mixer has samples outstanding then
        // we need to wait until its done with them.
        //

    }

    CompletelyConnected(FALSE);

    HRESULT hr = CheckMediaType(&cmt);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("DynamicReconfigureDVA: CheckMediaType failed")));
        return hr;
    }

    VABreakConnect();

    if (m_dwPinID == 0 && m_pRenderer->m_VMRModePassThru) {
        m_pRenderer->m_lpRLNotify->FreeSurface(m_pRenderer->m_dwUserID);
        m_pDDS = NULL;
    }
    else {
        ReleaseAllocatedSurfaces();
        RELEASE(m_pDDS);
    }

    FrontBufferStale(FALSE);
    SetMediaType(&cmt);



    hr = VACompleteConnect(pConnector, &cmt);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, 1,
                TEXT("DynamicReconfigureDVA: CheckMediaType failed")));
    }
    else {

        // store it in our mediatype as well - this gets done in the SetProperties call
        // in the non-DXVA case.
        m_mtNew = *pmt;
    }

    CompletelyConnected(TRUE);
    return hr;

}

/*****************************Private*Routine******************************\
* TryDynamicReconfiguration
*
*
*
* History:
* Wed 03/28/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::TryDynamicReconfiguration(
    IPin * pConnector,
    const AM_MEDIA_TYPE *pmt
    )
{
    AMTRACE((TEXT("CVMRInputPin::TryDynamicReconfiguration")));

    HRESULT hr;
    if (m_RenderTransport == AM_IMEMINPUTPIN) {
        hr = DynamicReconfigureMEM(pConnector, pmt);
    }
    else {
        hr = DynamicReconfigureDVA(pConnector, pmt);
    }

    return hr;
}

/******************************Public*Routine******************************\
* CVMRInputPin::ReceiveConnection
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::ReceiveConnection(
    IPin * pConnector,
    const AM_MEDIA_TYPE *pmt
    )
{
    AMTRACE((TEXT("CVMRInputPin::ReceiveConnection")));
    CAutoLock lck(m_pLock);
    HRESULT hr = S_OK;

    ASSERT(pConnector);
    DbgLog((LOG_TRACE, 1, TEXT("ReceiveConnection called on Pin %d"), m_dwPinID));

    int iNumPinsConnected = m_pRenderer->NumInputPinsConnected();
    if (iNumPinsConnected == 0) {

        //
        // determine what renderering mode we are operating in,
        // in either WINDOWED or WINDOWLESS modes we need to create an
        // AllocatorPresenter object if we have not already done so.
        //

        if (m_pRenderer->m_VMRMode & (VMRMode_Windowed | VMRMode_Windowless) ) {

            if (m_pRenderer->m_lpRLNotify == NULL) {
                hr = m_pRenderer->ValidateIVRWindowlessControlState();
            }
        }

        if (SUCCEEDED(hr)) {
            hr = CBaseInputPin::ReceiveConnection(pConnector, pmt);

            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("ReceiveConnection failed on Pin %d reason %#X"),
                        m_dwPinID, hr));
            }
        }

    }
    else {

        if (m_Connected == pConnector) {

            CMediaType mtTmp = m_mtNew;
            hr = TryDynamicReconfiguration(pConnector, pmt);
            if (hr != S_OK) {
                //
                // If we could not reconfigure try to recover the old
                // connection state.
                //
                m_pRenderer->NotifyEvent(EC_VMR_RECONNECTION_FAILED, hr, 0);
                TryDynamicReconfiguration(pConnector, &mtTmp);
            }
        }
        else {

            hr = CBaseInputPin::ReceiveConnection(pConnector, pmt);
            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("ReceiveConnection failed on Pin %d reason %#X"),
                        m_dwPinID, hr));
            }
        }
    }

    return hr;
}

/******************************Public*Routine******************************\
* Disconnect
*
* This function implements IPin::Disconnect().  See the DirectShow
* documentation for more information on IPin::Disconnect().
*
* History:
* Tue 03/05/2001 - BEllett - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::Disconnect()
{
    AMTRACE((TEXT("CVMRInputPin::Disconnect")));
    CAutoLock cObjectLock(m_pInterfaceLock);
    return DisconnectInternal();
}

/******************************Public*Routine******************************\
* CVMRInputPin::BreakConnect(
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::BreakConnect()
{
    AMTRACE((TEXT("CVMRInputPin::BreakConnect")));
    DbgLog((LOG_TRACE, 1, TEXT("BreakConnect called on Pin %d"), m_dwPinID));

    CAutoLock cLock(m_pInterfaceLock);
    HRESULT hr = S_OK;

    IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
    if (!m_pRenderer->m_VMRModePassThru && lpMixStream) {

#ifdef DEBUG
        BOOL fActive;
        lpMixStream->GetStreamActiveState(m_dwPinID, &fActive);
        if (fActive) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("Filter connected to pin %d still ACTIVE!"), m_dwPinID));
        }
#endif
        lpMixStream->SetStreamActiveState(m_dwPinID, FALSE);
        lpMixStream->SetStreamMediaType(m_dwPinID, NULL, FALSE, NULL, NULL);
    }

    if (m_RenderTransport == AM_VIDEOACCELERATOR) {

        //
        // break the motion comp connection
        //
        hr = VABreakConnect();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("VABreakConnect failed, hr = 0x%x"), hr));
        }

    }
    else {
        ASSERT(m_pIVANotify == NULL);
        ASSERT(m_pIDDVideoAccelerator == NULL);
        RELEASE(m_pIDDVAContainer);
    }

    //
    // Release the DDraw surface being used by this pin
    //
    if (m_dwPinID == 0 && m_pRenderer->m_VMRModePassThru) {

        m_pRenderer->m_lpRLNotify->FreeSurface(m_pRenderer->m_dwUserID);
        m_pDDS = NULL;
    }
    else {
        DbgLog((LOG_TRACE, 2,
                TEXT("DDraw surface now freed on Stream %d"), m_dwPinID));
        ReleaseAllocatedSurfaces();
        RELEASE(m_pDDS);
    }
    m_dwBackBufferCount = 0;
    FrontBufferStale(FALSE);

    //
    // Tell the filter about the break connect
    //
    m_pRenderer->BreakConnect(m_dwPinID);

    //
    // Next tell the base classes
    //
    if (SUCCEEDED(hr)) {
        hr = CBaseInputPin::BreakConnect();
    }

    m_RenderTransport = AM_IMEMINPUTPIN;
    CompletelyConnected(FALSE);
    m_SamplePeriod = 0;

    return hr;
}


/******************************Public*Routine******************************\
* CVMRInputPin::CompleteConnect
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::CompleteConnect(
    IPin* pReceivePin
    )
{
    AMTRACE((TEXT("CVMRInputPin::CompleteConnect")));
    DbgLog((LOG_TRACE, 1, TEXT("CompleteConnect called on Pin %d"), m_dwPinID));

    CAutoLock cLock(m_pInterfaceLock);
    HRESULT hr = S_OK;

    // tell the owning filter
    hr = m_pRenderer->CompleteConnect(m_dwPinID, m_mt);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("m_pFilter->CompleteConnect failed, hr = 0x%x"), hr));
    }

    // call the base class
    if (SUCCEEDED(hr)) {

        hr = CBaseInputPin::CompleteConnect(pReceivePin);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1,
                    TEXT("CBaseInputPin::CompleteConnect failed, hr = 0x%x"),
                    hr));
        }
    }

    if (SUCCEEDED(hr)) {

        if (m_RenderTransport == AM_VIDEOACCELERATOR) {

            //
            // make sure the motion comp complete connect succeeds
            //
            hr = VACompleteConnect(pReceivePin, &m_mt);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1,
                        TEXT("VACompleteConnect failed, hr = 0x%x"), hr));
            }

            if (SUCCEEDED(hr)) {
                hr = m_pRenderer->OnSetProperties(this);
            }

        }
        else {

            m_bDynamicFormatNeeded = true;
        }
    }

    if (SUCCEEDED(hr)) {
        CompletelyConnected(TRUE);
    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRInputPin::SetMediaType
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::SetMediaType(
    const CMediaType *pmt
    )
{
    AMTRACE((TEXT("CVMRInputPin::SetMediaType")));
    HRESULT hr = S_OK;

    hr = CheckMediaType(pmt);

    if (SUCCEEDED(hr)) {
        hr = CBaseInputPin::SetMediaType(pmt);
    }

    if (SUCCEEDED(hr)) {

        m_SamplePeriod = GetAvgTimePerFrame(pmt);

        if (IsSuitableVideoAcceleratorGuid((LPGUID)&pmt->subtype)) {

            if (m_pIVANotify == NULL) {

                //
                // get the IHWVideoAcceleratorNotify interface from
                // the upstream pin
                //
                hr = m_Connected->QueryInterface(IID_IAMVideoAcceleratorNotify,
                                                 (void **)&m_pIVANotify);
            }

            if (SUCCEEDED(hr)) {

                ASSERT(m_pIVANotify);
                m_RenderTransport = AM_VIDEOACCELERATOR;
                DbgLog((LOG_TRACE, 2, TEXT("this is a DX VA connection")));
            }
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* CheckInterlaceFlags
*
* this function checks if the InterlaceFlags are suitable or not
*
* History:
* Sat 2/10/2001 - StEstrop - Modified from OVMixer original
*
\**************************************************************************/
HRESULT
CVMRInputPin::CheckInterlaceFlags(
    DWORD dwInterlaceFlags
    )
{
    AMTRACE((TEXT("CVMRInputPin::CheckInterlaceFlags")));
    HRESULT hr = S_OK;

    CAutoLock cLock(m_pLock);

    __try {

        if (dwInterlaceFlags & AMINTERLACE_UNUSED)
        {
            hr = VFW_E_TYPE_NOT_ACCEPTED;
            __leave;
        }

        // check that the display mode is one of the three allowed values
        if (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) != AMINTERLACE_DisplayModeBobOnly) &&
            ((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) != AMINTERLACE_DisplayModeWeaveOnly) &&
            ((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) != AMINTERLACE_DisplayModeBobOrWeave))
        {
            hr = VFW_E_TYPE_NOT_ACCEPTED;
            __leave;
        }

        // if content is not interlaced, other bits are irrelavant, so we are done
        if (!(dwInterlaceFlags & AMINTERLACE_IsInterlaced))
        {
            __leave;
        }

        // samples are frames, not fields (so we can handle any display mode)
        if (!(dwInterlaceFlags & AMINTERLACE_1FieldPerSample))
        {
            __leave;
        }

        // can handle a stream of just field1 or field2, whatever the display mode
        if (((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField1Only) ||
            ((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField2Only))
        {
            __leave;
        }

        // can handle only bob-mode for field samples
        if ((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOnly)
        {
            __leave;
        }

        // cannot handle only Weave mode or BobOrWeave mode for field samples
        if (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeWeaveOnly) ||
             ((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOrWeave))
        {
            hr = VFW_E_TYPE_NOT_ACCEPTED;
            __leave;
        }

    }
    __finally {

        // we cannot handle bob mode with an offscreen surface or if the driver can't support it
        if (SUCCEEDED(hr))
        {
            if (!m_pRenderer->m_pDeinterlace || m_pRenderer->m_VMRModePassThru) {

                LPDDCAPS_DX7 pDirectCaps = &m_pRenderer->m_ddHWCaps;
                if (pDirectCaps)
                {
                    // call NeedToFlipOddEven with dwTypeSpecificFlags=0, to pretend that the
                    // type-specific-flags is asking us to do bob-mode.

                    if (!(pDirectCaps->dwCaps2 & DDCAPS2_CANFLIPODDEVEN) &&
                         (NeedToFlipOddEven(dwInterlaceFlags, 0, NULL, TRUE)))
                    {
                        hr = VFW_E_TYPE_NOT_ACCEPTED;
                    }
                }
            }
        }
    }

    return hr;
}

/*****************************Private*Routine******************************\
* DynamicCheckMediaType
*
* this function check if the mediatype on a dynamic format change is suitable.
* No lock is taken here. It is the callee's responsibility to maintain integrity!
*
* History:
* Sat 2/10/2001 - StEstrop - Modified from the OVMixer original
*
\**************************************************************************/
HRESULT
CVMRInputPin::DynamicCheckMediaType(
    const CMediaType* pmt
    )
{
    AMTRACE((TEXT("CVMRInputPin::DynamicCheckMediaType")));

    HRESULT hr = VFW_E_TYPE_NOT_ACCEPTED;
    BITMAPINFOHEADER *pNewHeader = NULL, *pOldHeader = NULL;
    DWORD dwOldInterlaceFlags = 0, dwNewInterlaceFlags = 0, dwCompareSize = 0;
    BOOL bOld1FieldPerSample = FALSE, bNew1FieldPerSample = FALSE;
    BOOL b1, b2;

    __try {

        // majortype and SubType are not allowed to change dynamically,
        // format type can change.
        if ((!(IsEqualGUID(pmt->majortype, m_mtNew.majortype))) ||
            (!(IsEqualGUID(pmt->subtype, m_mtNew.subtype))))
        {
            __leave;
        }

        // get the interlace flags of the new mediatype
        hr = GetInterlaceFlagsFromMediaType(pmt, &dwNewInterlaceFlags);
        if (FAILED(hr))
        {
            __leave;
        }

        // get the interlace flags of the new mediatype
        hr = GetInterlaceFlagsFromMediaType(&m_mtNew, &dwOldInterlaceFlags);
        if (FAILED(hr))
        {
            __leave;
        }

        //
        // There are several bugs in the following code !!
        // We goto CleanUp but hr has not been updated with a valid error code!!
        //

        bOld1FieldPerSample = (dwOldInterlaceFlags & AMINTERLACE_IsInterlaced) &&
            (dwOldInterlaceFlags & AMINTERLACE_1FieldPerSample);
        bNew1FieldPerSample = (dwNewInterlaceFlags & AMINTERLACE_IsInterlaced) &&
            (dwNewInterlaceFlags & AMINTERLACE_1FieldPerSample);


        // we do not allow dynamic format changes where you go from 1FieldsPerSample to
        // 2FieldsPerSample or vica-versa since that means reallocating the surfaces.
        if (bNew1FieldPerSample != bOld1FieldPerSample)
        {
            __leave;
        }

        pNewHeader = GetbmiHeader(pmt);
        if (!pNewHeader)
        {
            __leave;
        }

        pOldHeader = GetbmiHeader(&m_mtNew);
        if (!pNewHeader)
        {
            __leave;
        }

        dwCompareSize = FIELD_OFFSET(BITMAPINFOHEADER, biClrUsed);
        ASSERT(dwCompareSize < sizeof(BITMAPINFOHEADER));

        if (memcmp(pNewHeader, pOldHeader, dwCompareSize) != 0)
        {
            __leave;
        }

        hr = S_OK;
    }
    __finally {}

    return hr;
}

/*****************************Private*Routine******************************\
* Special4ccCode
*
* IA44 and AI44 are 8 bits per pixel surfaces that contain 4 bits of alpha
* and 4 bits of palette index information.  They are normally used with
* DX-VA, but this surface type is useful for Line21 and teletext decoders,
* I will allow decoders to connect using this format even though it is hidden
* my DDraw device driver.  Normally we do not allow hidden 4CC surfaces to
* be created because they are almost always some form of private MoComp.
* Unllike the OVMixer the VMR does not support private MoComp interfaces.
*
* History:
* Tue 05/08/2001 - StEstrop - Created
*
\**************************************************************************/
BOOL
Special4ccCode(
    DWORD dw4cc
    )
{
    return dw4cc == '44AI' || dw4cc == '44IA';
}

/******************************Public*Routine******************************\
* CVMRInputPin::CheckMediaType
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::CheckMediaType(
    const CMediaType* pmt
    )
{
    AMTRACE((TEXT("CVMRInputPin::CheckMediaType")));

    // We assume failure - hrRet gets updated at the very end of the
    // __try block
    HRESULT hrRet = VFW_E_TYPE_NOT_ACCEPTED;

    __try {

        HRESULT hr = m_pRenderer->CheckMediaType(pmt);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 1, TEXT("CheckMediaType failed on Pin %d rc=%#X"),
                    m_dwPinID, hr));
            __leave;
        }

        if (IsCompletelyConnected()) {

            hr = DynamicCheckMediaType(pmt);
            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("CheckMediaType failed on Pin %d: ")
                        TEXT("DynamicCheckMediaType failed"),
                        m_dwPinID));
                __leave;
            }
        }
        else {

            if (m_pRenderer->m_VMRModePassThru && MEDIASUBTYPE_HASALPHA(*pmt)) {
                DbgLog((LOG_ERROR, 1,
                        TEXT("CheckMediaType failed on Pin %d: Alpha formats ")
                        TEXT("not allowed in pass thru mode"),
                        m_dwPinID));
                __leave;
            }

            if (!IsSuitableVideoAcceleratorGuid(&pmt->subtype)) {

                BITMAPINFOHEADER *pHeader = GetbmiHeader(pmt);
                if (!pHeader) {
                    DbgLog((LOG_ERROR, 1,
                            TEXT("CheckMediaType failed on Pin %d: ")
                            TEXT("could not get valid format field"),
                            m_dwPinID));
                    __leave;
                }


                // Don't accept 4CC not supported by the driver
                if (pHeader->biCompression > BI_BITFIELDS &&
                    !Special4ccCode(pHeader->biCompression)) {

                    LPDIRECTDRAW7 pDDraw = m_pRenderer->m_lpDirectDraw;
                    if (!pDDraw) {
                        DbgLog((LOG_ERROR, 1,
                                TEXT("CheckMediaType failed on Pin %d: ")
                                TEXT("could not get DDraw obj from filter"),
                                m_dwPinID));
                        __leave;
                    }

                    //
                    // We only allow the VMR to create 4CC surfaces that
                    // the driver publically advertises.  The VMR does not
                    // support any forms of mocomp other than DX-VA and HVA.
                    //

                    DWORD dwCodes;
                    BOOL bFound = FALSE;

                    hr = pDDraw->GetFourCCCodes(&dwCodes, NULL);
                    if (FAILED(hr)) {
                        DbgLog((LOG_ERROR, 1,
                                TEXT("CheckMediaType failed on Pin %d: ")
                                TEXT("GetFourCCCodes failed"),
                                m_dwPinID));
                        __leave;
                    }

                    LPDWORD pdwCodes = (LPDWORD)_alloca(dwCodes * sizeof(DWORD));
                    hr = pDDraw->GetFourCCCodes(&dwCodes, pdwCodes);
                    if (FAILED(hr)) {
                        DbgLog((LOG_ERROR, 1,
                                TEXT("CheckMediaType failed on Pin %d: ")
                                TEXT("GetFourCCCodes failed"),
                                m_dwPinID));
                        __leave;
                    }

                    while (dwCodes--) {
                        if (pdwCodes[dwCodes] == pHeader->biCompression) {
                            bFound = TRUE;
                            break;
                        }
                    }

                    if (!bFound) {
                        DbgLog((LOG_ERROR, 1,
                                TEXT("CheckMediaType failed on Pin %d: ")
                                TEXT("4CC(%4.4s) not supported by driver"),
                                m_dwPinID, &pHeader->biCompression));
                        __leave;
                    }
                }
                else {

                    if (m_pRenderer->m_VMRModePassThru) {
                        DDPIXELFORMAT* ddpfM = &m_pRenderer->m_ddpfMonitor;

                        if (pHeader->biBitCount != ddpfM->dwRGBBitCount) {

                            DbgLog((LOG_ERROR, 1,
                                    TEXT("CheckMediaType failed on Pin %d: ")
                                    TEXT("Bit depths don't match"), m_dwPinID));
                            __leave;

                        }

                        if (pHeader->biCompression == BI_BITFIELDS) {

                            const DWORD *pBitMasks = GetBitMasks(pHeader);

                            if (ddpfM->dwRBitMask != pBitMasks[0] ||
                                ddpfM->dwGBitMask != pBitMasks[1] ||
                                ddpfM->dwBBitMask != pBitMasks[2])
                            {
                                 DbgLog((LOG_ERROR, 1,
                                         TEXT("CheckMediaType failed on Pin %d: ")
                                         TEXT("Bitfields don't match"), m_dwPinID));
                                 __leave;
                            }
                        }
                    }
                }
            }
        }

        // make sure the rcSource field is valid
        const RECT* lprc = GetSourceRectFromMediaType(pmt);
        if (!lprc) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("CheckMediaType failed on Pin %d: ")
                    TEXT("Could not get a valid SRC from the media type"),
                    m_dwPinID));
            __leave;
        }

        // make sure the rcTarget field is valid
        lprc = GetTargetRectFromMediaType(pmt);
        if (!lprc) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("CheckMediaType failed on Pin %d: ")
                    TEXT("Could not get a valid DST from the media type"),
                    m_dwPinID));
            __leave;
        }

        if (*pmt->FormatType() == FORMAT_VideoInfo2) {

            VIDEOINFOHEADER2* pVIH2 = (VIDEOINFOHEADER2*)(pmt->pbFormat);
            DWORD dwInterlaceFlags = pVIH2->dwInterlaceFlags;

            hr = CheckInterlaceFlags(dwInterlaceFlags);
            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, 2,
                    TEXT("CheckMediaType failed on Pin %d: ")
                    TEXT("CheckInterlaceFlags failed reason %#X"),
                    m_dwPinID, hr));
                __leave;
            }
        }

        // If we are still here the media type is OK so updatw hrRet to
        // indicate success
        hrRet = S_OK;
    }
    __finally {}

    return hrRet;
}


/******************************Public*Routine******************************\
* CVMRInputPin::GetAllocator
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::GetAllocator(
    IMemAllocator **ppAllocator
    )
{
    AMTRACE((TEXT("CVMRInputPin::GetAllocator")));
    CAutoLock cInterfaceLock(m_pInterfaceLock);

    HRESULT hr = S_OK;

    if (m_RenderTransport == AM_VIDEOACCELERATOR) {

        *ppAllocator = NULL;
        hr = VFW_E_NO_ALLOCATOR;
    }
    else {

        ASSERT(m_RenderTransport == AM_IMEMINPUTPIN);

        //
        // Has an allocator been set yet in the base class
        //

        if (m_pAllocator == NULL) {
            m_pAllocator = &m_PinAllocator;
            m_pAllocator->AddRef();
        }

        m_pAllocator->AddRef();
        *ppAllocator = m_pAllocator;
    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRInputPin::NotifyAllocator
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::NotifyAllocator(
    IMemAllocator *pAllocator,
    BOOL bReadOnly
    )
{
    AMTRACE((TEXT("CVMRInputPin::NotifyAllocator")));

    CAutoLock cInterfaceLock(m_pInterfaceLock);

    HRESULT hr = E_FAIL;

    if (m_RenderTransport == AM_VIDEOACCELERATOR) {
        hr = S_OK;
    }
    else {

        ASSERT(m_RenderTransport == AM_IMEMINPUTPIN);

        //
        // we can only work with our own allocator
        //

        if (pAllocator != &m_PinAllocator) {
            DbgLog((LOG_ERROR, 1, TEXT("Can only use our own allocator")));
            hr = E_FAIL;
        }
        else {
            hr = S_OK;
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRInputPin::Active
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::Active()
{
    AMTRACE((TEXT("CVMRInputPin::Active")));
    DbgLog((LOG_TRACE, 1, TEXT("Active called on Pin %d"), m_dwPinID));

    HRESULT hr = S_OK;

    CAutoLock lck(m_pLock);
    m_hEndOfStream = NULL;
    FrontBufferStale(TRUE);
    m_SampleCount = 0;

    if (m_Connected) {

        IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
        if (lpMixStream) {
            hr = lpMixStream->SetStreamActiveState(m_dwPinID, true);
        }

        if (SUCCEEDED(hr)) {
            m_bActive = TRUE;
            hr = m_pRenderer->Active(m_dwPinID);
        }
    }

    hr = CBaseInputPin::Active();

    //
    // if it is a DX VA connection, this error is ok
    //

    if (m_RenderTransport == AM_VIDEOACCELERATOR && hr == VFW_E_NO_ALLOCATOR) {
        hr = S_OK;
    }


    return hr;
}


/******************************Public*Routine******************************\
* CVMRInputPin::Inactive(
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::Inactive()
{
    AMTRACE((TEXT("CVMRInputPin::Inactive")));
    DbgLog((LOG_TRACE, 1, TEXT("Inactive called on Pin %d"), m_dwPinID));

    // m_pLock and CVMRFilter::m_InterfaceLock are the same lock.
    CAutoLock lck(m_pLock);

    HRESULT hr = S_OK;
    if (m_Connected) {

        IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
        if (lpMixStream) {

            hr = lpMixStream->SetStreamActiveState(m_dwPinID, false);
        }

        if (SUCCEEDED(hr)) {
            hr = m_pRenderer->Inactive(m_dwPinID);
            m_bActive = FALSE;
        }
    }

    hr = CBaseInputPin::Inactive();

    //
    // if it is a DX VA connection, this error is ok
    //

    if (m_RenderTransport == AM_VIDEOACCELERATOR && hr == VFW_E_NO_ALLOCATOR) {
        hr = S_OK;
    }


    return hr;
}


/******************************Public*Routine******************************\
* CVMRInputPin::BeginFlush
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::BeginFlush()
{
    AMTRACE((TEXT("CVMRInputPin::BeginFlush")));

    HRESULT hr = S_OK;
    CAutoLock cRendererLock(&m_pRenderer->m_InterfaceLock);
    m_hEndOfStream = NULL;
    {
        CAutoLock cSampleLock(&m_pRenderer->m_RendererLock);
        CBaseInputPin::BeginFlush();

        IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
        if (lpMixStream) {
            hr = lpMixStream->BeginFlush(m_dwPinID);
        }

        if (SUCCEEDED(hr)) {
            hr = m_pRenderer->BeginFlush(m_dwPinID);
        }

    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRInputPin::EndFlush
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::EndFlush()
{
    AMTRACE((TEXT("CVMRInputPin::EndFlush")));

    CAutoLock cRendererLock(&m_pRenderer->m_InterfaceLock);
    CAutoLock cSampleLock(&m_pRenderer->m_RendererLock);

    HRESULT hr = S_OK;
    FrontBufferStale(TRUE);

    IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
    if (lpMixStream) {
        hr = lpMixStream->EndFlush(m_dwPinID);
    }

    if (SUCCEEDED(hr)) {
        hr = m_pRenderer->EndFlush(m_dwPinID);
    }

    if (SUCCEEDED(hr)) {
        hr = CBaseInputPin::EndFlush();
    }

    return hr;
}


/*****************************Private*Routine******************************\
* DoQualityMessage
*
* Send a quality message if required - this is the hack version
* that just passes the lateness
*
* History:
* Thu 08/24/2000 - StEstrop - Created
*
\**************************************************************************/
void
CVMRInputPin::DoQualityMessage()
{
    CAutoLock cLock(m_pInterfaceLock);

    if (m_pRenderer->m_State == State_Running &&
        SampleProps()->dwSampleFlags & AM_SAMPLE_TIMEVALID)
    {
        CRefTime CurTime;
        if (S_OK == m_pRenderer->StreamTime(CurTime))
        {
            const REFERENCE_TIME tStart = SampleProps()->tStart;
            Quality msg;
            msg.Proportion = 1000;
            msg.Type = CurTime > tStart ? Flood : Famine;
            msg.Late = CurTime - tStart;
            msg.TimeStamp = tStart;
            PassNotify(msg);
        }
    }
}

// #define DISPLAYVIDEOINFOHEADER

#if defined(DISPLAYVIDEOINFOHEADER) && defined(DEBUG)
// VIhdr2 debugging
static void DisplayVideoInfoHeader( const VIDEOINFOHEADER2& hdr, const TCHAR* pString )
{
    TCHAR temp[1000];
    TCHAR flags[1000];
    flags[0]= TEXT('\0');

    if( hdr.dwReserved1 & AMCONTROL_PAD_TO_16x9 ) {
        lstrcat( flags, TEXT("PAD_TO_16x9 " ) );
    }
    if( hdr.dwReserved1 & AMCONTROL_PAD_TO_4x3 ) {
        lstrcat( flags, TEXT("PAD_TO_4x3 ") );
    }

    wsprintf( temp, TEXT("rcSrc(%d,%d)-(%d,%d)\n rcDst:(%d,%d)-(%d,%d)\n bmiSize: %dx%d\n Aspect: %dx%d\n dwReserved=%d (%s)"),
        hdr.rcSource.left, hdr.rcSource.top, hdr.rcSource.right, hdr.rcSource.bottom,
        hdr.rcTarget.left, hdr.rcTarget.top, hdr.rcTarget.right, hdr.rcTarget.bottom,
        hdr.bmiHeader.biWidth, hdr.bmiHeader.biHeight,
        hdr.dwPictAspectRatioX, hdr.dwPictAspectRatioY, hdr.dwReserved1, flags );
    DbgAssert( temp, pString, 0 );
}
static void DisplayMediaTypeChange( IMediaSample* pSample, DWORD dwPin )
{
    AM_MEDIA_TYPE* pmt;
    if (S_OK == pSample->GetMediaType(&pmt)) {
        TCHAR Str[32];
        wsprintf(Str, TEXT("VMR pin %d"), dwPin);
        VIDEOINFOHEADER2* pInfo = (VIDEOINFOHEADER2*) (CMediaType *)(pmt)->pbFormat;
        DisplayVideoInfoHeader(*pInfo, Str);
        DeleteMediaType(pmt);
    }

}
#endif

/******************************Public*Routine******************************\
* CVMRInputPin::Receive
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::Receive(
    IMediaSample *pSample
    )
{
    AMTRACE((TEXT("CVMRInputPin::Receive")));
    DbgLog((LOG_TRACE, 2, TEXT("pSample= %#X"), pSample));

    HRESULT hr = S_OK;

#if defined( EHOME_WMI_INSTRUMENTATION )
    PERFLOG_STREAMTRACE(
        1,
        PERFINFO_STREAMTRACE_VMR_RECEIVE,
        ULONG_PTR( pSample ), 0, 0, 0, 0 );
#endif

    __try {

        {
            //
            // This function must hold the interface lock because
            // CBaseInputPin::Receive() calls CVMRInputPin::CheckMediaType()
            // and because CBaseInputPin::Receive()  uses m_bRunTimeError.
            //
            // Note that we do not use the CHECK_HR macro here as __leave
            // does not allow the destructor of the CAutoLock object
            // to execute.
            //
            CAutoLock cRendererLock(m_pInterfaceLock);
            hr = CBaseInputPin::Receive(pSample);
        }
        if (hr != S_OK) {
            __leave;
        }

#if defined(DISPLAYVIDEOINFOHEADER) && defined(DEBUG)
        // debugging code for tracking media changes from decoders
        DisplayMediaTypeChange( pSample, m_dwPinID );
#endif

        DoQualityMessage();

        if (m_dwPinID == 0) {

            // Store the media times from this sample
            if (m_pRenderer->m_pPosition) {
                m_pRenderer->m_pPosition->RegisterMediaTime(pSample);
            }
        }

        CVMRMediaSample* pVMRSample = (CVMRMediaSample*)pSample;
        if (S_OK == pVMRSample->IsSurfaceLocked()) {

            hr = pVMRSample->UnlockSurface();
            if (hr != S_OK) {
                DbgLog((LOG_ERROR, 1, TEXT("Receive hr = %#X"), hr));
            }
        }

        FrontBufferStale(FALSE);

        if (SampleProps()->dwSampleFlags & AM_SAMPLE_TYPECHANGED) {

            DbgLog((LOG_TRACE, 1,
                    TEXT("Receive %d: Media sample has AM_SAMPLE_TYPECHANGED flag"),
                    m_dwPinID));
            SetMediaType((CMediaType *)SampleProps()->pMediaType);

        }


        REFERENCE_TIME rtStart, rtEnd;
        hr = pVMRSample->GetTime(&rtStart, &rtEnd);
        BOOL fTimeValid = (hr == S_OK);
        BOOL fLiveStream = FALSE;

#ifdef DEBUG
        if( fTimeValid )
        {
            DbgLog((LOG_TIMING, 3,
                    TEXT("Received video sample timestamped %dms"),
                    (LONG)(rtStart/10000)));
        }
#endif
        switch (hr) {
        case VFW_E_SAMPLE_TIME_NOT_SET:
            fLiveStream = TRUE;
            hr = S_OK;
            break;

        case VFW_S_NO_STOP_TIME:
            fTimeValid = TRUE;
            //
            // if the stop time is not set the base classes set the stop
            // time to be the start time + 1.  This is not useful for
            // de-interlacing as we can't then determine the start
            // time of the second field.
            //
            if (!m_pRenderer->m_VMRModePassThru && m_InterlacedStream) {
                rtEnd = rtStart + m_SamplePeriod;
            }
            hr = S_OK;
            break;
        }

        //
        // Don't process the sample if we are in the middle of a display
        // change, don't queue the sample.
        //

        const DWORD dwPinBit = (1 << m_dwPinID);
        if (SUCCEEDED(hr) && !(m_pRenderer->m_dwDisplayChangeMask & dwPinBit)) {

            DWORD dwInterlaceFlags;
            GetInterlaceFlagsFromMediaType(&m_mt, &dwInterlaceFlags);
            DWORD dwTypeSpecificFlags = m_SampleProps.dwTypeSpecificFlags;


            IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
            if (lpMixStream) {

                if (m_InterlacedStream) {

                    CAutoLock l(&m_DeinterlaceLock);

                    if (m_dwNumHistorySamples > 1) {
                        MoveMemory(&m_pVidHistorySamps[0],
                                   &m_pVidHistorySamps[1],
                                    (m_dwNumHistorySamples - 1) *
                                    sizeof(DXVA_VideoSample));
                    }


                    LPDIRECTDRAWSURFACE7 pDDS;
                    pVMRSample->GetSurface(&pDDS);
                    pDDS->Release();

                    DXVA_VideoSample* lpSrcSurf = &m_pVidHistorySamps[m_dwNumHistorySamples - 1];
                    lpSrcSurf->lpDDSSrcSurface = pDDS;
                    lpSrcSurf->rtStart = rtStart;
                    lpSrcSurf->rtEnd   = rtEnd;
                    lpSrcSurf->SampleFormat = MapInterlaceFlags(dwInterlaceFlags,
                                                                dwTypeSpecificFlags);
                    //
                    // We can't generate an output frame yet if we don't have enough
                    // input frames.
                    //
                    if (m_SampleCount++ < m_DeinterlaceCaps.NumForwardRefSamples) {

                        if (pVMRSample->IsDXVASample()) {
                            pVMRSample->SignalReleaseSurfaceEvent();
                        }

                        hr = S_OK;
                        __leave;
                    }

                    DXVA_VideoSample* lpDstSurf = pVMRSample->GetInputSamples();
                    CopyMemory(lpDstSurf, m_pVidHistorySamps,
                               m_dwNumHistorySamples * sizeof(DXVA_VideoSample));

                    //
                    // Fix up the sample times
                    //
                    if (!fLiveStream) {
                        const DWORD& NBRefSamples = m_DeinterlaceCaps.NumBackwardRefSamples;
                        pVMRSample->SetTime(&lpDstSurf[NBRefSamples].rtStart,
                                            &lpDstSurf[NBRefSamples].rtEnd);
                    }
                    pVMRSample->SetNumInputSamples(m_dwNumHistorySamples);
                }

                hr = lpMixStream->QueueStreamMediaSample(m_dwPinID, pSample);
                if (FAILED(hr)) {
                    if (pVMRSample->IsDXVASample()) {
                        pVMRSample->SignalReleaseSurfaceEvent();
                    }
                }

            }
            else {

                ASSERT(m_pRenderer->m_VMRModePassThru);
                if (m_pRenderer->m_VMRModePassThru) {

                    VMRPRESENTATIONINFO m;

                    ZeroMemory(&m, sizeof(m));
                    pVMRSample->GetSurface(&m.lpSurf);

                    if (fTimeValid) {
                        m.rtStart = rtStart;
                        m.rtEnd = rtEnd;
                        m.dwFlags |= VMRSample_TimeValid;
                    }

                    m.dwInterlaceFlags = dwInterlaceFlags;
                    m.dwTypeSpecificFlags = dwTypeSpecificFlags;

                    GetImageAspectRatio(&m_mt,
                                        &m.szAspectRatio.cx,
                                        &m.szAspectRatio.cy);

                    hr = m_pRenderer->m_lpIS->Receive(&m);
                    m.lpSurf->Release();
                }
            }
        }
        else {
            if (pVMRSample->IsDXVASample()) {
                pVMRSample->SignalReleaseSurfaceEvent();
            }
        }
    }
    __finally {

        if (FAILED(hr)) {

            // A deadlock could occur if the caller holds the renderer lock and
            // attempts to acquire the interface lock.
            ASSERT(CritCheckOut(&m_pRenderer->m_RendererLock));

            // The interface lock must be held when the filter is calling
            // IsStopped() or IsFlushing().  The filter must also hold the
            // interface lock because it is using m_bRunTimeError.
            CAutoLock cInterfaceLock(&m_pRenderer->m_InterfaceLock);

            if (!m_bRunTimeError && !IsFlushing() && !IsStopped()) {
                m_pRenderer->RuntimeAbortPlayback(hr);
                m_bRunTimeError = TRUE;
            }
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRInputPin::EndOfStream
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVMRInputPin::EndOfStream()
{
    AMTRACE((TEXT("CVMRInputPin::EndOfStream")));

    CAutoLock cInterfaceLock(&m_pRenderer->m_InterfaceLock);
    CAutoLock cRendererLock(&m_pRenderer->m_RendererLock);

    if (m_hEndOfStream) {
        SetEvent(m_hEndOfStream);
        return S_OK;
    }

    // Make sure we're streaming ok

    HRESULT hr = CheckStreaming();
    if (hr != NOERROR) {
        return hr;
    }

    //
    // Remove this stream active bit in the active streams mask.
    // If there are no more active streams send EOS to the
    // image sync object.
    //
    // Otherwise we are in mixing mode (!m_VMRModePassThru)
    // so just set this mixing stream to NOT Active and
    // carry.
    //

    const DWORD dwPinBit = (1 << m_dwPinID);
    m_pRenderer->m_dwEndOfStreamMask &= ~dwPinBit;

    if (m_pRenderer->m_dwEndOfStreamMask == 0) {

        hr = m_pRenderer->EndOfStream(m_dwPinID);
    }
    else if (!m_pRenderer->m_VMRModePassThru) {

        IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
        if (lpMixStream) {
            hr = lpMixStream->SetStreamActiveState(m_dwPinID, false);
        }
    }

    if (SUCCEEDED(hr)) {
        hr = CBaseInputPin::EndOfStream();
    }

    return hr;
}


/******************************Public*Routine******************************\
* CVMRInputPin::SetColorKey
*
*
*
* History:
* Mon 10/30/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::SetColorKey(
      LPDDCOLORKEY Clr
      )
{
    AMTRACE((TEXT("CVMRInputPin::SetColorKey")));

    CAutoLock lck(m_pLock);
    HRESULT hr = VFW_E_NOT_CONNECTED;

    if (ISBADREADPTR(Clr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("SetColorKey: Invalid pointer")));
        return E_POINTER;
    }

    if (m_Connected) {
        IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
        if (lpMixStream) {
            hr = lpMixStream->SetStreamColorKey(m_dwPinID, Clr);
        }
        else hr = VFW_E_VMR_NOT_IN_MIXER_MODE;
    }
    return hr;
}

/******************************Public*Routine******************************\
* CVMRInputPin::GetColorKey
*
*
*
* History:
* Mon 10/30/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::GetColorKey(
      DDCOLORKEY* pClr
      )
{
    AMTRACE((TEXT("CVMRInputPin::GetColorKey")));

    CAutoLock lck(m_pLock);
    HRESULT hr = VFW_E_NOT_CONNECTED;
    if (ISBADWRITEPTR(pClr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetColorKey: Invalid pointer")));
        return E_POINTER;
    }

    if (m_Connected) {
        IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
        if (lpMixStream) {
            hr = lpMixStream->GetStreamColorKey(m_dwPinID, pClr);
        }
        else hr = VFW_E_VMR_NOT_IN_MIXER_MODE;
    }
    return hr;
}

/******************************Public*Routine******************************\
* SetStreamActiveState
*
*
*
* History:
* Tue 08/22/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::SetStreamActiveState(
    BOOL fActive
    )
{
    AMTRACE((TEXT("CVMRInputPin::SetStreamActiveState")));

    CAutoLock lck(m_pLock);
    HRESULT hr = VFW_E_NOT_CONNECTED;

    if (m_Connected) {
        IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
        if (lpMixStream) {
            if (m_bActive) {
                hr = lpMixStream->SetStreamActiveState(m_dwPinID, fActive);
            }
            else {
                DbgLog((LOG_ERROR, 1,
                        TEXT("Can't change active state of a stream %d - ")
                        TEXT("FILTER not active"), m_dwPinID ));
            }
        }
        else hr = VFW_E_VMR_NOT_IN_MIXER_MODE;
    }
    return hr;
}

/******************************Public*Routine******************************\
* GetStreamActiveState
*
*
*
* History:
* Tue 08/22/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::GetStreamActiveState(
    BOOL* lpfActive
    )
{
    AMTRACE((TEXT("CVMRInputPin::GetStreamActiveState")));

    CAutoLock lck(m_pLock);
    HRESULT hr = VFW_E_NOT_CONNECTED;

    if (ISBADWRITEPTR(lpfActive))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetStreamActiveState: Invalid pointer")));
        return E_POINTER;
    }

    if (m_Connected) {
        IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
        if (lpMixStream) {
            hr = lpMixStream->GetStreamActiveState(m_dwPinID, lpfActive);
        }
        else hr = VFW_E_VMR_NOT_IN_MIXER_MODE;
    }
    return hr;
}

/*****************************Private*Routine******************************\
* GetStreamInterlaceProperties
*
* Be careful when using this function.
*
* S_OK is used to indicate that lpIsInterlaced correctly reflects the
* interlace format of the stream, the stream can be de-interlaced and
* lpDeintGuid and pCaps contain valid data.
*
* S_FALSE is used to indicate that lpIsInterlaced correctly reflecst the
* interlace format of the stream, but the stream can't be de-interlaced.
*
* All other return values indicate error conditions and the streams
* format cannot be correctly determined.
*
* History:
* Mon 04/01/2002 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::GetStreamInterlaceProperties(
    const AM_MEDIA_TYPE *pMT,
    BOOL* lpIsInterlaced,
    GUID* lpDeintGuid,
    DXVA_DeinterlaceCaps* pCaps
    )
{
    HRESULT hr = S_OK;
    DXVA_DeinterlaceCaps DeinterlaceCaps;
    GUID GuidChosen = GUID_NULL;

    __try {

        DXVA_VideoDesc VideoDesc;
        CHECK_HR(hr = GetVideoDescFromMT(&VideoDesc, pMT));
        *lpIsInterlaced =
            (VideoDesc.SampleFormat != DXVA_SampleProgressiveFrame);

        if (*lpIsInterlaced) {


            //
            // If there is not a de-interlace container available, we have to
            // use Weave mode
            //
            CVMRDeinterlaceContainer* pDeInt = m_pRenderer->m_pDeinterlace;
            if (pDeInt == NULL) {
                hr = S_FALSE;
                __leave;
            }


            //
            // has the user supplied us with a mode to use?
            //
            if (m_DeinterlaceUserGUIDSet) {

                //
                // does the user actually want us to de-interlace at all?
                //
                if (m_DeinterlaceUserGUID == GUID_NULL) {
                    hr = S_FALSE;
                    __leave;
                }

                DeinterlaceCaps.Size = sizeof(DeinterlaceCaps);
                hr = pDeInt->QueryModeCaps(&m_DeinterlaceUserGUID, &VideoDesc,
                                           &DeinterlaceCaps);
                if (hr == S_OK) {
                    GuidChosen = m_DeinterlaceUserGUID;
                    __leave;
                }
            }


            //
            // Still here?  Then either the user has not given us a
            // de-interlace guid to use or the h/w doesn't like his
            // selection - either way we have to find out what the h/w
            // does like.
            //
            const DWORD MaxGuids = 16;
            GUID Guids[MaxGuids];
            DWORD dwNumModes = MaxGuids;
            DWORD i = 0;
            CHECK_HR(hr = pDeInt->QueryAvailableModes(&VideoDesc, &dwNumModes,
                                                      Guids));

            //
            // if the user hasn't supplied a de-interlace mode try the
            // best one provided by the driver.
            //
            if (!m_DeinterlaceUserGUIDSet) {

                DeinterlaceCaps.Size = sizeof(DeinterlaceCaps);
                hr = pDeInt->QueryModeCaps(&Guids[0], &VideoDesc,
                                           &DeinterlaceCaps);
                if (hr == S_OK) {
                    GuidChosen = Guids[0];
                    __leave;
                }
                //
                // we increment i here so that we don't retry this
                // mode in the fallback code below.
                //
                i = 1;
            }

            //
            // Still here? Then its time to kick in to the fallback
            // policy that was specified by the user.
            //

            if (DeinterlacePref_Weave & m_pRenderer->m_dwDeinterlacePrefs) {
                hr = S_FALSE;
                __leave;
            }

            if (DeinterlacePref_BOB & m_pRenderer->m_dwDeinterlacePrefs) {

                DeinterlaceCaps.Size = sizeof(DeinterlaceCaps);
                hr = pDeInt->QueryModeCaps((LPGUID)&DXVA_DeinterlaceBobDevice,
                                           &VideoDesc, &DeinterlaceCaps);
                if (hr == S_OK) {
                    GuidChosen = DXVA_DeinterlaceBobDevice;
                }
                __leave;
            }

            ASSERT(DeinterlacePref_NextBest & m_pRenderer->m_dwDeinterlacePrefs);

            for (; i < dwNumModes; i++) {

                DeinterlaceCaps.Size = sizeof(DeinterlaceCaps);
                hr = pDeInt->QueryModeCaps(&Guids[i], &VideoDesc,
                                           &DeinterlaceCaps);
                if (hr == S_OK) {
                    GuidChosen = Guids[i];
                    break;
                }
            }
        }
    }
    __finally {

        if (hr == S_OK && *lpIsInterlaced) {

            *lpDeintGuid = GuidChosen;
            *pCaps = DeinterlaceCaps;
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* OnSetProperties
*
*
*
* History:
* Wed 02/23/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::OnSetProperties(
    ALLOCATOR_PROPERTIES* pReq,
    ALLOCATOR_PROPERTIES* pAct
    )
{
    AMTRACE((TEXT("CVMRInputPin::OnSetProperties")));
    CAutoLock cLock(m_pInterfaceLock);

    DWORD dwNumBuffers = max(pReq->cBuffers, MIN_BUFFERS_TO_ALLOCATE);
    DWORD dwActBuffers = dwNumBuffers;
    LONG lSampleSize;
    IPin *pReceivePin = m_Connected;

    ASSERT(pReceivePin);
    ASSERT(m_RenderTransport != AM_VIDEOACCELERATOR);

    AM_MEDIA_TYPE *pNewMediaType = NULL, *pEMediaType = &m_mt;
    HRESULT hr = E_FAIL;
    LPGUID lpDeinterlaceGUID = NULL;


    //
    // Do some checks to make sure the format block is a VIDEOINFO or
    // VIDEOINFO2 (so it's a video type), and that the format is
    // sufficiently large. We also check that the source filter can
    // actually supply this type.
    //

    __try {

        if (((pEMediaType->formattype == FORMAT_VideoInfo &&
              pEMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)) ||
             (pEMediaType->formattype == FORMAT_VideoInfo2 &&
              pEMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2))) &&
              pReceivePin->QueryAccept(pEMediaType) == S_OK) {

            //
            // Temporary work around for IF09 fourcc surface
            // types.  The AVI decoder wrapper filter needs to be fixed,
            // in the mean time ignore IF09 surface types.
            //
            {
                LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pEMediaType);
                if (!lpHdr) {
                    __leave;
                }

                if (lpHdr->biCompression == MAKEFOURCC('I','F','0','9')) {
                    __leave;
                }

                if (lpHdr->biCompression == MAKEFOURCC('Y','U','V','9')) {
                    __leave;
                }

            }

            DWORD dwSurfFlags;

            if (m_pRenderer->m_VMRModePassThru) {

                SIZE AR;
                LPBITMAPINFOHEADER lpHdr = GetbmiHeader(pEMediaType);

                VMRALLOCATIONINFO p;
                CHECK_HR(hr = GetImageAspectRatio(pEMediaType,
                                                  &p.szAspectRatio.cx,
                                                  &p.szAspectRatio.cy));

                if (pEMediaType->subtype == MEDIASUBTYPE_RGB32_D3D_DX7_RT ||
                    pEMediaType->subtype == MEDIASUBTYPE_RGB16_D3D_DX7_RT) {
                    p.dwFlags = AMAP_3D_TARGET;
                }
                else {
                    p.dwFlags = AMAP_ALLOW_SYSMEM;
                }

                if (dwNumBuffers > 1) {
                    p.dwFlags |= AMAP_DIRECTED_FLIP;
                }

                p.lpHdr = lpHdr;
                p.lpPixFmt = NULL;
                p.dwMinBuffers = dwNumBuffers;
                p.dwMaxBuffers = dwNumBuffers;
                p.szNativeSize.cx = abs(lpHdr->biWidth);
                p.szNativeSize.cy = abs(lpHdr->biHeight);

                CHECK_HR(hr = GetInterlaceFlagsFromMediaType(pEMediaType,
                                                             &p.dwInterlaceFlags));

                CHECK_HR(hr = m_pRenderer->m_lpRLNotify->AllocateSurface(
                                    m_pRenderer->m_dwUserID,
                                    &p,
                                    &dwActBuffers,
                                    &m_pDDS));


                DDSURFACEDESC2 ddSurfaceDesc;
                INITDDSTRUCT(ddSurfaceDesc);
                CHECK_HR(hr = m_pDDS->GetSurfaceDesc(&ddSurfaceDesc));
                CHECK_HR(hr = ConvertSurfaceDescToMediaType(&ddSurfaceDesc,
                                                            pEMediaType,
                                                            &pNewMediaType));
#ifdef DEBUG
                m_pDDS->Lock(NULL, &ddSurfaceDesc,
                             DDLOCK_NOSYSLOCK | DDLOCK_WAIT,
                             (HANDLE)NULL);
                m_pDDS->Unlock(NULL);
                DbgLog((LOG_TRACE, 0,
                        TEXT("Created %u surfaces of type %4.4hs @%#X"),
                        ddSurfaceDesc.dwBackBufferCount + 1,
                        (lpHdr->biCompression == 0) ? "RGB " :
                        ((lpHdr->biCompression == BI_BITFIELDS) ? "BITF" :
                        (LPSTR)&lpHdr->biCompression),
                        ddSurfaceDesc.lpSurface
                        ));
#endif

            }
            else {

                GUID guidDeint;
                DWORD Pool = D3DPOOL_DEFAULT;

                hr = GetStreamInterlaceProperties(pEMediaType,
                                                  &m_InterlacedStream,
                                                  &guidDeint,
                                                  &m_DeinterlaceCaps);
                //
                // don't use the SUCCEEDED macro here as
                // GetStreamInterlaceProperties can return S_FALSE
                //
                if (hr == S_OK && m_InterlacedStream) {

                    DWORD dwRefCount = m_DeinterlaceCaps.NumForwardRefSamples +
                                       m_DeinterlaceCaps.NumBackwardRefSamples;

                    DWORD dwSampCount = 1 + dwRefCount;
                    m_pVidHistorySamps = new DXVA_VideoSample[dwSampCount];
                    if (m_pVidHistorySamps == NULL) {
                        hr = E_OUTOFMEMORY;
                        __leave;
                    }
                    ZeroMemory(m_pVidHistorySamps, (dwSampCount * sizeof(DXVA_VideoSample)));
                    m_dwNumHistorySamples = dwSampCount;

                    Pool = m_DeinterlaceCaps.InputPool;

                    DWORD dwExtraBuffNeeded = (dwNumBuffers > 1);
                    dwNumBuffers += (dwExtraBuffNeeded + dwRefCount);


                    dwSurfFlags = 1;
                    hr = AllocateSurface(pEMediaType,
                                         &m_pVidSurfs,
                                         &dwNumBuffers, &dwSurfFlags,
                                         Pool, &pNewMediaType);
                    if (FAILED(hr)) {
                        m_InterlacedStream = FALSE;
                        ZeroMemory(&m_DeinterlaceCaps, sizeof(m_DeinterlaceCaps));
                        ZeroMemory(&m_DeinterlaceGUID, sizeof(m_DeinterlaceGUID));
                        lpDeinterlaceGUID = NULL;
                    }
                    else {
                        m_DeinterlaceGUID = guidDeint;
                        lpDeinterlaceGUID = &m_DeinterlaceGUID;
                    }
                }
                else {
                    m_InterlacedStream = FALSE;
                }

                if (!m_InterlacedStream) {
                    dwSurfFlags = 0;
                    CHECK_HR(hr = AllocateSurface(pEMediaType,
                                                  &m_pVidSurfs,
                                                  &dwNumBuffers, &dwSurfFlags,
                                                  Pool, &pNewMediaType));
                }

                m_dwNumSamples = dwNumBuffers;
                dwActBuffers = dwNumBuffers;
            }
            m_mtNew = *(CMediaType *)pNewMediaType;

            //
            // free the temporary mediatype
            //
            DeleteMediaType(pNewMediaType);
            pNewMediaType = NULL;

            //
            // Get and save the size of the new sample
            //
            m_lSampleSize = m_mtNew.lSampleSize;

            //
            // make sure the decoder likes this new mediatupe
            //
            DbgLog((LOG_TRACE, 1,
                    TEXT("Pin %d calling QueryAccept on the Decoder"),
                    m_dwPinID ));

            hr = pReceivePin->QueryAccept(&m_mtNew);
            if (hr != S_OK) {
                if (hr == S_FALSE) {
                    hr = E_FAIL;
                }
                DbgLog((LOG_TRACE, 1,
                        TEXT("Decoder on Pin %d rejected media type"),
                        m_dwPinID ));
                __leave;
            }

            if (!m_pRenderer->m_VMRModePassThru) {

                IVMRMixerStream* lpMixStream = m_pRenderer->m_lpMixStream;
                if (lpMixStream) {

                    DbgLog((LOG_TRACE, 1,
                        TEXT("Pin %d calling SetStreamMediaType on the Mixer"),
                        m_dwPinID ));

                    CHECK_HR(hr = lpMixStream->SetStreamMediaType(m_dwPinID,
                                                                  pEMediaType,
                                                                  dwSurfFlags,
                                                                  lpDeinterlaceGUID,
                                                                  &m_DeinterlaceCaps));
                }
            }
        }
    }
    __finally {


        if (hr == S_OK) {


            if (m_pRenderer->m_VMRModePassThru && dwNumBuffers > 1) {
                m_dwBackBufferCount = dwActBuffers - dwNumBuffers;
            }
        }
        else  {

            DbgLog((LOG_ERROR, 1,
                    TEXT("AllocateSurfaces failed, hr = 0x%x"), hr));

            if (m_pRenderer->m_VMRModePassThru) {
                m_pRenderer->m_lpRLNotify->FreeSurface(m_pRenderer->m_dwUserID);
                m_pDDS = NULL;
            }
            else {
                ReleaseAllocatedSurfaces();
                RELEASE(m_pDDS);
            }
            FrontBufferStale(FALSE);

            if (pNewMediaType) {
                DeleteMediaType(pNewMediaType);
            }
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* OnAlloc
*
*
*
* History:
* Mon 03/13/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::OnAlloc(
    CVMRMediaSample **ppSampleList,
    LONG lSampleCount
    )
{
    AMTRACE((TEXT("CVMRInputPin::OnAlloc")));

    ASSERT(ppSampleList);
    HRESULT hr = S_OK;

    if (m_pRenderer->m_VMRModePassThru) {

        LPDIRECTDRAWSURFACE7 pBackBuffer = NULL;
        DDSURFACEDESC2 ddSurfaceDesc;
        INITDDSTRUCT(ddSurfaceDesc);

        if (!m_pDDS) {
            return E_OUTOFMEMORY;
        }

        hr = m_pDDS->GetSurfaceDesc(&ddSurfaceDesc);

        if (hr == DD_OK) {

            ddSurfaceDesc.ddsCaps.dwCaps &= ~(DDSCAPS_FRONTBUFFER |
                                              DDSCAPS_VISIBLE);

            if (lSampleCount > 1) {

                LPDIRECTDRAWSURFACE7 pDDrawSurface = m_pDDS;

                for (LONG i = 0; i < lSampleCount; i++) {

                    hr = pDDrawSurface->GetAttachedSurface(&ddSurfaceDesc.ddsCaps,
                                                           &pBackBuffer);
                    if (FAILED(hr)) {
                        break;
                    }

                    //DbgLog((LOG_TRACE, 0, TEXT("buffer %d"), i ));
                    //DumpDDSAddress(TEXT("="), pBackBuffer);

                    ppSampleList[i]->SetSurface(pBackBuffer, m_pDDS);
                    pDDrawSurface = pBackBuffer;
                }
            }
            else {

                ASSERT(lSampleCount == 1);

                //
                // Even though we only have a single sample there may well be a
                // back buffer associated with the DDraw surface.  In which case we
                // have to use it.
                //
                hr = m_pDDS->GetAttachedSurface(&ddSurfaceDesc.ddsCaps,
                                                &pBackBuffer);
                if (hr == DD_OK) {
                    ppSampleList[0]->SetSurface(pBackBuffer, m_pDDS);
                }

                //
                // No back buffer attached to this surface so just use
                // the front buffer.  We are probably in mixer mode when
                // this happens (but its not certain)
                //
                else {
                    ppSampleList[0]->SetSurface(m_pDDS);
                    hr = S_OK;
                }
            }
        }
    }
    else {

        if (!m_pVidSurfs) {
            hr = E_OUTOFMEMORY;
        }
    }
    return hr;
}






/*****************************Private*Routine******************************\
* OnGetBuffer
*
*
*
* History:
* Fri 02/25/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::OnGetBuffer(
    IMediaSample *pSample,
    REFERENCE_TIME *pStartTime,
    REFERENCE_TIME *pEndTime,
    DWORD dwFlags
    )
{
    AMTRACE((TEXT("CVMRInputPin::OnGetBuffer")));
    DbgLog((LOG_TRACE, 2, TEXT("pSample= %#X"), pSample));

    ASSERT(m_RenderTransport != AM_VIDEOACCELERATOR);

    LPBYTE lpSample;
    LPDIRECTDRAWSURFACE7 lpSurf;
    LONG lSampleSize;
    HRESULT hr = S_OK;

    CVMRMediaSample* pVMRSample = (CVMRMediaSample*)pSample;

    const DWORD dwPinBit = (1 << m_dwPinID);
    if (m_pRenderer->m_dwDisplayChangeMask & dwPinBit) {

        DbgLog((LOG_TRACE, 1, TEXT("Monitor change in progress")));
        hr = E_FAIL;
    }

    if (S_OK == hr) {

        if (m_dwPinID == 0 && m_pRenderer->m_VMRModePassThru) {

            LPDIRECTDRAWSURFACE7 lpDDrawSurface;
            hr = pVMRSample->GetSurface(&lpDDrawSurface);
            if (hr == S_OK) {

                // DumpDDSAddress(TEXT("Decoding into "), lpDDrawSurface);

                //
                // If we are in Delta Decode mode - turn off the
                // AM_GBF_NOTASYNCPOINT flag.  We are handing
                // fake DD surfaces back to the decoder which always
                // contain complete frames
                //
                if (m_dwDeltaDecode & DELTA_DECODE_MODE_SET) {
                    dwFlags &= ~AM_GBF_NOTASYNCPOINT;
                }

                //
                // Only prepare the back buffer from the front buffer
                // if the front buffer contains a valid image.
                //

                if (IsFrontBufferStale()) {
                    dwFlags &= ~AM_GBF_NOTASYNCPOINT;
                }

                hr = m_pRenderer->m_lpRLNotify->PrepareSurface(
                                                    m_pRenderer->m_dwUserID,
                                                    lpDDrawSurface,
                                                    dwFlags);
                if (hr == S_FALSE) {
                    DbgLog((LOG_TRACE, 1,
                            TEXT("Monitor change in pass thru mode")));
                    hr = E_FAIL;
                }

                //
                // The very first time we see the AM_GBF_NOTASYNCPOINT flag set
                // we have to do some checks to make sure that the AP object is
                // capable of processing the Blt from the front buffer to the
                // back buffer in an optimal manner.  This is only really
                // important if we are using FOURCC surfaces and the
                // COPY_FOURCC flag is not set.
                //
                if ((dwFlags & AM_GBF_NOTASYNCPOINT) &&
                    !(m_dwDeltaDecode & DELTA_DECODE_CHECKED)) {

                    LPBITMAPINFOHEADER lpHdr = GetbmiHeader(&m_mt);
                    if ((lpHdr->biCompression > BI_BITFIELDS) &&
                        !(m_pRenderer->m_ddHWCaps.dwCaps2 & DDCAPS2_COPYFOURCC)) {

                        m_dwDeltaDecode = DELTA_DECODE_MODE_SET;
                        hr = pVMRSample->StartDeltaDecodeState();
                    }
                    else {
                        m_dwDeltaDecode = DELTA_DECODE_CHECKED;
                    }
                }

                RELEASE(lpDDrawSurface);
            }
        }
        else {

            if (dwFlags & AM_GBF_NOTASYNCPOINT) {

                // BUGBUG Blt from the front buffer here, but we don't know
                // which buffer is the front buffer.  Anyway, if the upstream
                // decoder is doing delta decodes it would only request a single
                // buffer when it connected.  If we are in mixing mode we
                // never allocate any extra buffers the need for the Blt is
                // removed.
            }

            //
            // we circle thru the surfaces looking for one that is not
            // in use, when we find a free surface we check to see if the surface
            // is part of a de-interlace history sequnce, if it is we need to get
            // another free surface from our pool of surfaces.
            //
            CAutoLock l(&m_DeinterlaceLock);

            DWORD i;
            for (i = 0; i < m_dwNumSamples; i++) {

                if (!m_pVidSurfs[i].InUse) {

                    DWORD j = (m_dwNumHistorySamples == m_dwNumSamples);

                    for (; j < m_dwNumHistorySamples; j++) {
                        LPDIRECTDRAWSURFACE7 t =
                            (LPDIRECTDRAWSURFACE7)m_pVidHistorySamps[j].lpDDSSrcSurface;
                        if (m_pVidSurfs[i].pSurface == t) {
                            break;
                        }
                    }

                    if (m_dwNumHistorySamples == j) {
                        m_pVidSurfs[i].InUse = TRUE;
                        break;
                    }
                }
            }

            DbgLog((LOG_TRACE,2,TEXT("CVMRInputPin::OnGetBuffer(%d)"), i));

            ASSERT(i < m_dwNumSamples);
            pVMRSample->SetSurface(m_pVidSurfs[i].pSurface);
            pVMRSample->SetIndex(i);
        }
    }

    if (S_OK == hr) {

        if (dwFlags & AM_GBF_NODDSURFACELOCK) {
            lpSample = (LPBYTE)~0;
        }
        else {
            hr = pVMRSample->LockSurface(&lpSample);
        }

        if (SUCCEEDED(hr)) {

            hr = pVMRSample->SetPointer(lpSample, m_lSampleSize);
            if (m_bDynamicFormatNeeded) {

                SetMediaType(&m_mtNew);
                hr = pVMRSample->SetMediaType(&m_mtNew);
                m_bDynamicFormatNeeded = FALSE;
            }
        }
    }

    return hr;
}


/*****************************Private*Routine******************************\
* DeleteAllocatedBuffers
*
*
*
* History:
* Thu 03/14/2002 - StEstrop - Created
*
\**************************************************************************/
void
DeleteAllocatedBuffers(
    SURFACE_INFO* pVidSamps,
    DWORD dwBuffCount
    )
{
   for (DWORD i = 0; i < dwBuffCount; i++) {
       RELEASE(pVidSamps[i].pSurface);
   }

}


/*****************************Private*Routine******************************\
* AllocateSurfaceWorker
*
*
*
* History:
* Wed 02/28/2001 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::AllocateSurfaceWorker(
    SURFACE_INFO* pVidSamps,
    DDSURFACEDESC2* lpddsd,
    DWORD* lpdwBuffCount,
    bool fInterlaced
    )
{
    AMTRACE((TEXT("CVMRInputPin::AllocateSurfaceWorker")));
    LPDIRECTDRAW7 lpDD = m_pRenderer->m_lpDirectDraw;
    HRESULT hr = E_FAIL;

    DWORD dwBuffCountReq = *lpdwBuffCount;
    *lpdwBuffCount = 0;     // assume that we cannot allocate any surfaces

    DbgLog((LOG_TRACE, 1, TEXT("Using DDObj %#X to create surfaces on Pin %d"),
            lpDD, m_dwPinID));

    if (fInterlaced) {

        for (DWORD i = 0; i < dwBuffCountReq; i++) {

            hr = lpDD->CreateSurface(lpddsd, &pVidSamps[i].pSurface, NULL);
            if (hr != DD_OK) {
                DeleteAllocatedBuffers(pVidSamps, i);
                break;
            }
        }
    }
    else {

        bool fAGPMemOK = false;
        if (lpddsd->ddpfPixelFormat.dwFlags & DDPF_RGB) {
            fAGPMemOK = ((m_pRenderer->m_TexCaps & TXTR_AGPRGBMEM) == TXTR_AGPRGBMEM);
        }
        else if (lpddsd->ddpfPixelFormat.dwFlags & DDPF_FOURCC) {
            fAGPMemOK = ((m_pRenderer->m_TexCaps & TXTR_AGPYUVMEM) == TXTR_AGPYUVMEM);
        }


        if (fAGPMemOK &&
            (m_pRenderer->m_dwRenderPrefs & RenderPrefs_PreferAGPMemWhenMixing))
        {
            lpddsd->ddsCaps.dwCaps &= ~DDSCAPS_LOCALVIDMEM;
            lpddsd->ddsCaps.dwCaps |=  DDSCAPS_NONLOCALVIDMEM;

            for (DWORD i = 0; i < dwBuffCountReq; i++) {

                hr = lpDD->CreateSurface(lpddsd, &pVidSamps[i].pSurface, NULL);
                if (hr != DD_OK) {
                    DeleteAllocatedBuffers(pVidSamps, i);
                    break;
                }
            }
        }

        if (hr != DD_OK) {

            lpddsd->ddsCaps.dwCaps &= ~DDSCAPS_NONLOCALVIDMEM;
            lpddsd->ddsCaps.dwCaps |=  DDSCAPS_LOCALVIDMEM;

            for (DWORD i = 0; i < dwBuffCountReq; i++) {

                hr = lpDD->CreateSurface(lpddsd, &pVidSamps[i].pSurface, NULL);
                if (hr != DD_OK) {
                    DeleteAllocatedBuffers(pVidSamps, i);
                    break;
                }
            }
        }

        if (hr != DD_OK && fAGPMemOK) {

            DbgLog((LOG_TRACE, 1,
                    TEXT("AllocateSurface: Failed to allocate VidMem - trying AGPMem")));

            lpddsd->ddsCaps.dwCaps &= ~DDSCAPS_LOCALVIDMEM;
            lpddsd->ddsCaps.dwCaps |=  DDSCAPS_NONLOCALVIDMEM;

            for (DWORD i = 0; i < dwBuffCountReq; i++) {

                hr = lpDD->CreateSurface(lpddsd, &pVidSamps[i].pSurface, NULL);
                if (hr != DD_OK) {
                    DeleteAllocatedBuffers(pVidSamps, i);
                    break;
                }
            }

            if (hr == DD_OK) {
                DbgLog((LOG_TRACE, 1,
                        TEXT("AllocateSurface: AGPMem allocation worked !")));
            }
        }
    }

    if (SUCCEEDED(hr)) {
        *lpdwBuffCount = dwBuffCountReq;
    }

    return hr;
}


/*****************************Private*Routine******************************\
* AllocateSurface
*
* Here is some info about how we go about how we go about allocating
* surfaces when the VMR is in mixing mode.
*
* There are 3 steps to the process:
*
*   1. Convert the incomming DShow media type into a DDraw DDSURFACEDESC2
*      structure.
*   2. Get DDraw to create the surfaces - there are fallbacks relating to the
*      physical location of the memory behind the DDraw surface.
*   3. Perform a reverse mapping of the DDSURFACEDESC2 structure back into a
*      DShow media type and then paint each allocate surface black.
*
* In all case this function only succeeds if we allocate all the requested
* DDraw surfaces.
*
* History:
* Wed 03/08/2000 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVMRInputPin::AllocateSurface(
    const AM_MEDIA_TYPE* cmt,
    SURFACE_INFO** lplpDDSurfInfo,
    DWORD* lpdwBuffCount,
    DWORD* lpdwSurfFlags,
    DWORD Pool,
    AM_MEDIA_TYPE** ppmt
    )
{
    AMTRACE((TEXT("CVMRInputPin::AllocateSurface")));

    bool fInterlaced = !!*lpdwSurfFlags;
    *lpdwSurfFlags = VMR_SF_NONE;


    LPDDCAPS_DX7 lpddHWCaps = &m_pRenderer->m_ddHWCaps;
    LPBITMAPINFOHEADER lpHeader = GetbmiHeader(cmt);
    if (!lpHeader) {
        DbgLog((LOG_ERROR, 1,
                TEXT("AllocateSurface: Can't get bitmapinfoheader ")
                TEXT("from media type!!")));
        return E_INVALIDARG;
    }

    FOURCCMap amFourCCMap(&cmt->subtype);

    DDSURFACEDESC2 ddsd;
    INITDDSTRUCT(ddsd);
    ddsd.dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT | DDSD_PIXELFORMAT;
    ddsd.dwWidth = abs(lpHeader->biWidth);
    ddsd.dwHeight = abs(lpHeader->biHeight);

    // define the pixel format
    ddsd.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);

    if (lpHeader->biCompression <= BI_BITFIELDS)
    {
        DWORD dwCaps = DDCAPS_BLTSTRETCH;
        if ((dwCaps & lpddHWCaps->dwCaps) != dwCaps) {
            DbgLog((LOG_ERROR, 1, TEXT("Can't BLT_STRETCH!!")));
            return E_FAIL;
        }

        ddsd.ddpfPixelFormat.dwFourCC = BI_RGB;
        ddsd.ddpfPixelFormat.dwFlags = DDPF_RGB;
        ddsd.ddpfPixelFormat.dwRGBBitCount = lpHeader->biBitCount;

        // Store the masks in the DDSURFACEDESC
        const DWORD *pBitMasks = GetBitMasks(lpHeader);
        ASSERT(pBitMasks);
        ddsd.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
        ddsd.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
        ddsd.ddpfPixelFormat.dwBBitMask = pBitMasks[2];
    }
    else if (lpHeader->biCompression > BI_BITFIELDS &&
             lpHeader->biCompression == amFourCCMap.GetFOURCC())
    {
        DWORD dwCaps = (DDCAPS_BLTFOURCC | DDCAPS_BLTSTRETCH);
        if ((dwCaps & lpddHWCaps->dwCaps) != dwCaps) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("AllocateSurface: DDraw device can't ")
                    TEXT("BLT_FOURCC | BLT_STRETCH!!")));
            return E_FAIL;
        }

        ddsd.ddpfPixelFormat.dwFourCC = lpHeader->biCompression;
        ddsd.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
        ddsd.ddpfPixelFormat.dwYUVBitCount = lpHeader->biBitCount;

        if (Special4ccCode(lpHeader->biCompression)) {
            ddsd.ddpfPixelFormat.dwFlags |= DDPF_PALETTEINDEXED4;
        }
    }
    else
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("AllocateSurface: Supplied mediatype not suitable ")
                TEXT("for either YUV or RGB surfaces")));
        return E_FAIL;
    }

    // try designating as a texture first
    if (fInterlaced) {
        ddsd.ddsCaps.dwCaps = MapPool(Pool);
    }
    else {
        ddsd.ddsCaps.dwCaps = DDSCAPS_TEXTURE | DDSCAPS_VIDEOMEMORY;
    }

    if (MEDIASUBTYPE_ARGB32 == cmt->subtype ||
        MEDIASUBTYPE_AYUV == cmt->subtype ||
        MEDIASUBTYPE_ARGB32_D3D_DX7_RT == cmt->subtype)
    {
        ddsd.ddpfPixelFormat.dwFlags |= DDPF_ALPHAPIXELS;
        ddsd.ddpfPixelFormat.dwRGBAlphaBitMask = 0xff000000;
        ddsd.ddpfPixelFormat.dwRBitMask = 0x00ff0000;
        ddsd.ddpfPixelFormat.dwGBitMask = 0x0000ff00;
        ddsd.ddpfPixelFormat.dwBBitMask = 0x000000ff;
    }
    else if (MEDIASUBTYPE_ARGB1555 == cmt->subtype ||
             MEDIASUBTYPE_ARGB1555_D3D_DX7_RT == cmt->subtype)
    {
        ddsd.ddpfPixelFormat.dwFlags |= DDPF_ALPHAPIXELS;
        ddsd.ddpfPixelFormat.dwRGBAlphaBitMask = 0x8000;
        ddsd.ddpfPixelFormat.dwRBitMask = (0x1f<<10);
        ddsd.ddpfPixelFormat.dwGBitMask = (0x1f<< 5);
        ddsd.ddpfPixelFormat.dwBBitMask = (0x1f<< 0);
    }
    else if (MEDIASUBTYPE_ARGB4444 == cmt->subtype ||
             MEDIASUBTYPE_ARGB4444_D3D_DX7_RT == cmt->subtype)
    {
        ddsd.ddpfPixelFormat.dwFlags |= DDPF_ALPHAPIXELS;
        ddsd.ddpfPixelFormat.dwRGBAlphaBitMask = 0xf000;
        ddsd.ddpfPixelFormat.dwRBitMask = 0x0f00;
        ddsd.ddpfPixelFormat.dwGBitMask = 0x00f0;
        ddsd.ddpfPixelFormat.dwBBitMask = 0x000f;
    }

    if (MEDIASUBTYPE_D3D_DX7_RT(*cmt)) {

        //
        // deinterlacing and D3D surfaces are mutually incompatible.
        //

        if (fInterlaced) {
            return E_FAIL;
        }
        ddsd.ddsCaps.dwCaps |= DDSCAPS_3DDEVICE;
    }

    if ((m_pRenderer->m_TexCaps & TXTR_POWER2) &&
        !Special4ccCode(lpHeader->biCompression) &&
        !fInterlaced) {

        for (ddsd.dwWidth = 1;
             (DWORD)abs(lpHeader->biWidth) > ddsd.dwWidth;
             ddsd.dwWidth <<= 1);

        for (ddsd.dwHeight = 1;
             (DWORD)abs(lpHeader->biHeight) > ddsd.dwHeight;
             ddsd.dwHeight <<= 1);
    }

    //
    // Allocate the surface array;
    //
    DWORD dwBuffCount = *lpdwBuffCount;
    SURFACE_INFO* pVidSurfs = new SURFACE_INFO[dwBuffCount];
    if (pVidSurfs == NULL) {
        return E_OUTOFMEMORY;
    }
    ZeroMemory(pVidSurfs, (dwBuffCount * sizeof(SURFACE_INFO)));


    HRESULT hr = E_FAIL;

#ifdef DEBUG
    if (!fInterlaced && lpHeader->biCompression > BI_BITFIELDS &&
        GetProfileIntA("VMR", "Allow4CCTexture", 1) == 0) {

        ;
    }
    else
#endif
    {
        hr = AllocateSurfaceWorker(pVidSurfs, &ddsd,
                                   &dwBuffCount, fInterlaced);
        if (hr == DD_OK && !fInterlaced) {
            *lpdwSurfFlags = VMR_SF_TEXTURE;
        }
    }

    //
    // There are no fallbacks for interlaced content.
    //
    if (FAILED(hr) && !fInterlaced)
    {
        //
        // if alpha in stream, the surface must be a texture
        // so do not fall back to this code path
        //

        DDPIXELFORMAT* ddpfS = &ddsd.ddpfPixelFormat;
        if (ddpfS->dwRGBAlphaBitMask == 0)
        {
            //
            // If we are creating an RGB surface the pixel format
            // of the surface must match that of the current monitor.
            //

            if (ddpfS->dwFourCC == BI_RGB)
            {
                DDPIXELFORMAT* ddpfM = &m_pRenderer->m_ddpfMonitor;

                if (ddpfM->dwRGBBitCount != ddpfS->dwRGBBitCount ||
                    ddpfM->dwRBitMask    != ddpfS->dwRBitMask    ||
                    ddpfM->dwGBitMask    != ddpfS->dwGBitMask    ||
                    ddpfM->dwBBitMask    != ddpfS->dwBBitMask)
                {
                    delete [] pVidSurfs;
                    *lplpDDSurfInfo = NULL;
                    *lpdwBuffCount = 0;
                    DbgLog((LOG_ERROR, 1,
                            TEXT("AllocateSurface: RGB pixel format does not ")
                            TEXT("match monitor")));
                    return hr;
                }
            }

            ddsd.dwWidth = abs(lpHeader->biWidth);
            ddsd.dwHeight = abs(lpHeader->biHeight);
            ddsd.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_VIDEOMEMORY;
            ddsd.ddsCaps.dwCaps2 = 0;
            dwBuffCount = *lpdwBuffCount;

            hr = AllocateSurfaceWorker(pVidSurfs, &ddsd, &dwBuffCount, false);
        }
    }

    if (SUCCEEDED(hr)) {

        INITDDSTRUCT(ddsd);
        hr = pVidSurfs[0].pSurface->GetSurfaceDesc(&ddsd);

        if (SUCCEEDED(hr)) {
            hr = ConvertSurfaceDescToMediaType(&ddsd, cmt, ppmt);
        }

        if (SUCCEEDED(hr)) {

            for (DWORD i = 0; i < dwBuffCount; i++) {
                PaintDDrawSurfaceBlack(pVidSurfs[i].pSurface);
            }

        }
    }

    if (FAILED(hr)) {

        DeleteAllocatedBuffers(pVidSurfs, dwBuffCount);
        delete [] pVidSurfs;
        pVidSurfs = NULL;
        dwBuffCount = 0;
    }

    *lpdwBuffCount   = dwBuffCount;
    *lplpDDSurfInfo = pVidSurfs;

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\drect.h ===
/******************************Module*Header*******************************\
* Module Name: DRect.h
*
*
*
*
* Created: Tue 05/05/2000
* Author:  GlenneE
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#ifndef __DRect__h
#define __DRect__h

class DRect
{
public:
            DRect( double dLeft, double dTop, double dRight, double dBottom )
                : m_left( dLeft )
                , m_right( dRight )
                , m_top( dTop )
                , m_bottom( dBottom ) {};

            DRect( const RECT& rc );
            DRect() {};
            ~DRect() {};

    // trivial dependency on RECT, covers the maximal area
    RECT    AsRECT() const;

    double  GetWidth() const { return m_right-m_left;}
    double  GetHeight() const { return m_bottom-m_top; }

    bool    IsEmpty() const { return m_left <= m_right || m_top <= m_bottom; }

    DRect   IntersectWith( const DRect& prDRect1 ) const;
    void    Scale( double dScaleX, double dScaleY );
    void    ClipWith(const DRect& prdSrcRect, DRect *pRectToMirrorChangesTo );

    double  CorrectAspectRatio( double dPictAspectRatio, BOOL bShrink );

public:
    double  m_left;
    double  m_top;
    double  m_right;
    double  m_bottom;
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\khandlearray.cpp ===
// Copyright (c) 1998 - 1999  Microsoft Corporation.  All Rights Reserved.
#include <streams.h>
#include <KHandleArray.h>
#include <ddkernel.h>
#include <VPMUtil.h>


/*****************************Private*Routine******************************\
* SurfaceCounter
*
* This routine is appropriate as a callback for
* IDirectDrawSurface2::EnumAttachedSurfaces()
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
static HRESULT WINAPI
SurfaceCounter(
    LPDIRECTDRAWSURFACE7 lpDDSurface,
    LPDDSURFACEDESC2 lpDDSurfaceDesc,
    LPVOID lpContext
    )
{
    DWORD& dwCount = *((DWORD *)lpContext);
    dwCount++;

    return DDENUMRET_OK;
}

KernelHandleArray::KernelHandleArray( DWORD dwNumHandles )
: m_dwCount( 0 )
, m_pHandles( ( ULONG_PTR *) CoTaskMemAlloc( dwNumHandles * sizeof( *m_pHandles) ))
{
}

KernelHandleArray::~KernelHandleArray()
{
    if( m_pHandles ) {
        CoTaskMemFree( m_pHandles );
    }
}


/*****************************Private*Routine******************************\
* KernelHandleArray::SurfaceKernelHandle
*
*
* This routine is appropriate as a callback for
* IDirectDrawSurface2::EnumAttachedSurfaces().  The context parameter is a
* block of storage where the first DWORD element is the count of the remaining
* DWORD elements in the block.
*
* Each time this routine is called, it will increment the count, and put a
* kernel handle in the next available slot.
*
* It is assumed that the block of storage is large enough to hold the total
* number of kernel handles. The ::SurfaceCounter callback is one way to
* assure this (see above).
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT WINAPI
KernelHandleArray::SurfaceKernelHandle(
    LPDIRECTDRAWSURFACE7 lpDDSurface,
    LPDDSURFACEDESC2 lpDDSurfaceDesc,
    LPVOID lpContext
    )
{
    IDirectDrawSurfaceKernel *pDDSK = NULL;
    KernelHandleArray* pArray = (KernelHandleArray *)lpContext;
    HRESULT hr;

    AMTRACE((TEXT("::SurfaceKernelHandle")));

    // get the IDirectDrawKernel interface
    hr = lpDDSurface->QueryInterface(IID_IDirectDrawSurfaceKernel,
                                     (LPVOID *)&pDDSK);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("QueryInterface for IDirectDrawSurfaceKernel failed,")
                TEXT(" hr = 0x%x"), hr));
        goto CleanUp;
    }

    // get the kernel handle, using the first element of the context
    // as an index into the array
    ASSERT(pDDSK);
    hr = pDDSK->GetKernelHandle( &pArray->m_pHandles[ pArray->m_dwCount ] );
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("GetKernelHandle from IDirectDrawSurfaceKernel failed,")
                TEXT(" hr = 0x%x"), hr));
        goto CleanUp;
    }
    pArray->m_dwCount++;

    hr = HRESULT( DDENUMRET_OK );

CleanUp:
    // release the kernel ddraw surface handle
    RELEASE (pDDSK);
    return hr;
}

KernelHandleArray::KernelHandleArray( LPDIRECTDRAWSURFACE7 pDDSurf, HRESULT& hr )
: m_pHandles( NULL )
, m_dwCount( 0 )
{
    if( pDDSurf != NULL ) {
        // Count the attached surfaces
        m_dwCount = 1; // includes the surface we already have a pointer to
        hr = pDDSurf->EnumAttachedSurfaces((LPVOID)&m_dwCount, SurfaceCounter);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR,0, TEXT("EnumAttachedSurfaces failed, hr = 0x%x"), hr));
        } else {
            m_pHandles = ( ULONG_PTR *) CoTaskMemAlloc( m_dwCount * sizeof( *m_pHandles) );

            // Allocate a buffer to hold the count and surface handles (count + array of handles)
            // pdwKernelHandleCount is also used as a pointer to the count followed by the array
            //
            if( !m_pHandles ) {
                DbgLog((LOG_ERROR,0,
                        TEXT("Out of memory while retrieving surface kernel handles")));
            } else {
                // Initialize the array with the handle for m_pOutputSurface
                m_dwCount = 0;
                hr = SurfaceKernelHandle( pDDSurf, NULL, this );
                if (hr == HRESULT( DDENUMRET_OK ) ) {
                    hr = pDDSurf->EnumAttachedSurfaces( this, SurfaceKernelHandle);
                    if (FAILED( hr)) {
                        DbgLog((LOG_ERROR,0,
                                TEXT("EnumAttachedSurfaces failed, hr = 0x%x"), hr));
                    }
                }
            }
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\formatlist.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;
#ifndef __PixelFormatList__
#define __PixelFormatList__


class PixelFormatList
{
public:
    PixelFormatList();
    PixelFormatList( DWORD dwCount );
    PixelFormatList( const PixelFormatList& list );
    ~PixelFormatList();

    PixelFormatList& operator=( const PixelFormatList& list );

    BOOL            Reset( DWORD dwCount );
    BOOL            Truncate( DWORD dwCount );
    DWORD           GetCount() const        { return m_dwCount; }
    DDPIXELFORMAT*  GetEntries()            { return m_pEntries; }
    const DDPIXELFORMAT* GetEntries() const { return m_pEntries; }

    DDPIXELFORMAT&  operator[](int i)            { return m_pEntries[i]; }
    const DDPIXELFORMAT& operator[](int i) const { return m_pEntries[i]; }

    PixelFormatList IntersectWith( const PixelFormatList& with ) const;

    // generate the union of all of the lists
    static PixelFormatList  Union( const PixelFormatList* pLists, DWORD dwCount );

    static DWORD FindListContaining( const DDPIXELFORMAT& ddFormat, const PixelFormatList* pLists, DWORD dwCount );

private:
    BOOL            Realloc( DWORD dwCount );
    DWORD           m_dwCount;
    DDPIXELFORMAT*  m_pEntries;
};

#endif //__PixelFormatList__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\formatlist.cpp ===
#include <streams.h>
#include <ddraw.h>
#include <VPMUtil.h>
#include <FormatList.h>

PixelFormatList::PixelFormatList( DWORD dwCount )
: m_dwCount( 0 )
, m_pEntries( NULL )
{
    Reset( dwCount );
}

PixelFormatList::PixelFormatList()
: m_dwCount( 0 )
, m_pEntries( NULL )
{
}

PixelFormatList::PixelFormatList( const PixelFormatList& list )
: m_dwCount( 0 )
, m_pEntries( NULL )
{
    if( Realloc( list.GetCount())) {
        CopyArray( m_pEntries, list.m_pEntries, list.GetCount() );
    }
}

PixelFormatList::~PixelFormatList()
{
    delete [] m_pEntries;
}

BOOL PixelFormatList::Truncate( DWORD dwCount )
{
    ASSERT( dwCount <= m_dwCount );
    if( dwCount <= m_dwCount ) {
        m_dwCount = dwCount;
        return TRUE;
    } else {
        return FALSE;
    }
}

BOOL PixelFormatList::Realloc( DWORD dwCount )
{
    delete [] m_pEntries;
    m_dwCount = dwCount;
    m_pEntries = new DDPIXELFORMAT[ dwCount ];
    if( m_pEntries ) {
        return TRUE;
    } else {
        m_dwCount = 0;
        return FALSE;
    }
}

BOOL PixelFormatList::Reset( DWORD dwCount )
{
    BOOL b = Realloc( dwCount );
    if( b ) {
        ZeroArray( m_pEntries, dwCount ); 
        for( DWORD i = 0; i < dwCount; i++ ) {
            m_pEntries[i].dwSize = sizeof(DDPIXELFORMAT);
        }
        return TRUE;
    }
    return b;
}

PixelFormatList& PixelFormatList::operator =( const PixelFormatList& with )
{
    if( Realloc( with.GetCount() )) {
		CopyArray( m_pEntries, with.m_pEntries, with.GetCount());
	}
    return *this;
}

PixelFormatList PixelFormatList::IntersectWith( const PixelFormatList& with ) const
{
    // calculate the maximum number of elements in the interesection
    PixelFormatList lpddIntersectionFormats( max(GetCount(), with.GetCount() ) );
    if (lpddIntersectionFormats.GetEntries() == NULL)
    {
        return lpddIntersectionFormats;
    }

    // find the intersection of the two lists
    DWORD dwNumIntersectionEntries = 0;
    for (DWORD i = 0; i < GetCount(); i++)
    {
        for (DWORD j = 0; j < with.GetCount(); j++)
        {
            if (VPMUtil::EqualPixelFormats(m_pEntries[i], with.m_pEntries[j]))
            {
                lpddIntersectionFormats[dwNumIntersectionEntries]= m_pEntries[i];
                dwNumIntersectionEntries++;
            }
        }
    }
    // truncate the list
    lpddIntersectionFormats.Truncate( dwNumIntersectionEntries );
    return lpddIntersectionFormats;
}

    // generate the union of all of the lists
PixelFormatList PixelFormatList::Union( const PixelFormatList* pLists, DWORD dwCount )
{
    // worst case, every list is unique so max size is the sum of the sizes
    DWORD dwMaxCount=0;
    {for( DWORD i = 0; i < dwCount; i++ ) {
        dwMaxCount += pLists[i].GetCount();
    }}

    // create a new list
    PixelFormatList newList( dwMaxCount );
    if( !newList.GetEntries()) {
        return newList;
    }

    DWORD dwUniqueEntries = 0;
    // do a simple linear compare merge
    {for( DWORD i = 0; i < dwCount; i++ ) {
        const PixelFormatList& curList = pLists[i];

        // merge in every entry of the current list
        for( DWORD j=0; j < curList.GetCount(); j++ ) {
            const DDPIXELFORMAT& toFind = curList[j];

            BOOL bFound = FALSE;
            // see if it already exists
            for( DWORD k=0; k < dwUniqueEntries; k++ ) {
                if( VPMUtil::EqualPixelFormats( newList[k], toFind  ))
                {
                    bFound = TRUE;
                    break;
                }
            }
            // if not, then add it
            if( !bFound ) {
                newList[dwUniqueEntries] = toFind;
                dwUniqueEntries++;
            }
        }
    }}
    newList.Truncate( dwUniqueEntries );
    return newList;
}

DWORD PixelFormatList::FindListContaining( const DDPIXELFORMAT& toFind, const PixelFormatList* pLists, DWORD dwCount )
{
     DWORD i = 0;
     for(; i < dwCount; i++ ) {
        const PixelFormatList& curList = pLists[i];

        // merge in every entry of the current list
        for( DWORD j=0; j < curList.GetCount(); j++ ) {
            if( VPMUtil::EqualPixelFormats( curList[j], toFind  )) {
                return i;
            }
        }
    }
    return i;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\khandlearray.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;
#ifndef __KHArray__
#define __KHArray__

class KernelHandleArray
{
public:
    KernelHandleArray( DWORD dwNumHandles );
    KernelHandleArray( LPDIRECTDRAWSURFACE7 pDDSurf, HRESULT& hr );

    ~KernelHandleArray();

    DWORD       GetCount() const { return m_dwCount; };
    ULONG_PTR*  GetHandles() { return m_pHandles; };

public:
    DWORD       m_dwCount;
    ULONG_PTR*  m_pHandles;

private:
    static HRESULT WINAPI SurfaceKernelHandle(
        LPDIRECTDRAWSURFACE7 lpDDSurface,
        LPDDSURFACEDESC2 lpDDSurfaceDesc,
        LPVOID lpContext
        );
};

#endif //__KHArray__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\vbiinpin.cpp ===
//==========================================================================
//
//  Copyright (C) Microsoft Corporation, 1997 - 1998  All Rights Reserved.
//
//--------------------------------------------------------------------------


#include <streams.h>
#include <ddraw.h>
#include <VBIObj.h>
#include <VPMUtil.h>
#include <VPManager.h>
#include <VPMPin.h>


//==========================================================================
// constructor
CVBIInputPin::CVBIInputPin(TCHAR *pObjectName, CVPMFilter& pFilter, HRESULT *phr, LPCWSTR pPinName, DWORD dwPinNo )
: CBaseInputPin(pObjectName, &pFilter, &pFilter.GetFilterLock(), phr, pPinName)
, CVPMPin( dwPinNo, pFilter )
, m_pIVPObject(NULL)
, m_pIVPNotify(NULL)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("Entering CVBIInputPin::Constructor")));
    
    // create the VideoPort object

    // See combase.cpp(107) for comments on this
    IUnknown* pThisUnknown = reinterpret_cast<LPUNKNOWN>( static_cast<PNDUNKNOWN>(this) );

    m_pVideoPortVBIObject = new CVBIVideoPort( pThisUnknown, phr );
    if( !m_pVideoPortVBIObject ) {
        hr = E_OUTOFMEMORY;
    } else {
        m_pIVPObject = m_pVideoPortVBIObject;
        m_pIVPNotify = m_pVideoPortVBIObject;


        // filter lock is ok since no data is received or sent
	    hr = m_pIVPObject->SetObjectLock( &m_pVPMFilter.GetFilterLock() );
	    if (FAILED(hr))
	    {
            DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->SetObjectLock() failed, hr = 0x%x"), hr));
	    }
    }

    if (FAILED(hr)) {
        *phr = hr;
    }
    // Leaving CVBIInputPin::Constructor")));
    return;
}


//==========================================================================
// destructor
CVBIInputPin::~CVBIInputPin(void)
{
    AMTRACE((TEXT("Entering CVBIInputPin::Destructor")));
    
    delete m_pVideoPortVBIObject;
	m_pVideoPortVBIObject = NULL;
    m_pIVPNotify = NULL;
    m_pIVPObject = NULL;
}


//==========================================================================
// overriden to expose IVPVBINotify, IKsPin, and IKsPropertySet
STDMETHODIMP CVBIInputPin::NonDelegatingQueryInterface(REFIID riid, void **ppv)
{
    HRESULT hr = NOERROR;
    
    //AMTRACE((TEXT("Entering CVBIInputPin::NonDelegatingQueryInterface")));
    
    if (riid == IID_IVPVBINotify) {
        hr = GetInterface( static_cast<IVPVBINotify*>( this ), ppv);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface(IVPVBINotify*) failed, hr = 0x%x"), hr));
        }
    } else if (riid == IID_IKsPin ) {
        hr = GetInterface( static_cast<IKsPin*>( m_pVideoPortVBIObject), ppv);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 2, TEXT("m_pVideoPortVBIObject->QueryInterface(IKsPin) failed, hr = 0x%x"), hr));
        }
    } else if (riid == IID_IKsPropertySet) {
        hr = GetInterface( static_cast<IKsPropertySet*>( m_pVideoPortVBIObject), ppv);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 2, TEXT("m_pVideoPortVBIObject->QueryInterface(IKsPin) failed, hr = 0x%x"), hr));
        }
    } else {
        // call the base class
        hr = CBaseInputPin::NonDelegatingQueryInterface(riid, ppv);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 2, TEXT("CBaseInputPin::NonDelegatingQueryInterface failed, hr = 0x%x"), hr));
        }
    } 
    
    return hr;
}


//==========================================================================
// check that the mediatype is acceptable
HRESULT CVBIInputPin::CheckMediaType(const CMediaType* pmt)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::CheckMediaType")));

    // check if the videoport object likes it
    HRESULT hr = m_pIVPObject->CheckMediaType(pmt);
    return hr;
}


//==========================================================================
HRESULT CVBIInputPin::GetMediaType(int iPosition, CMediaType *pmt)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::GetMediaType")));

    HRESULT hr = m_pIVPObject->GetMediaType(iPosition, pmt);
    return hr;
}


//==========================================================================
// called after we have agreed a media type to actually set it
HRESULT CVBIInputPin::SetMediaType(const CMediaType* pmt)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::SetMediaType")));

    HRESULT hr = NOERROR;
    
    // make sure the mediatype is correct
    hr = CheckMediaType(pmt);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CheckMediaType failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    // Set the base class media type (should always succeed)
    hr = CBaseInputPin::SetMediaType(pmt);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CBaseInputPin::SetMediaType failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
// CheckConnect
HRESULT CVBIInputPin::CheckConnect(IPin * pReceivePin)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::CheckConnect")));

    HRESULT hr = NOERROR;

    // tell the videoport object 
    hr = m_pIVPObject->CheckConnect(pReceivePin);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->CheckConnect failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // call the base class
    hr = CBaseInputPin::CheckConnect(pReceivePin);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::CheckConnect failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
// Complete Connect
HRESULT CVBIInputPin::CompleteConnect(IPin *pReceivePin)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::CompleteConnect")));

    HRESULT hr = NOERROR;
    CMediaType cMediaType;
    AM_MEDIA_TYPE *pNewMediaType = NULL, *pEnumeratedMediaType = NULL;
    
    // tell the videoport object 
    hr = m_pIVPObject->CompleteConnect(pReceivePin);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pIVPObject->CompleteConnect failed, hr = 0x%x"), hr));
        goto CleanUp;
    }


    // call the base class
    hr = CBaseInputPin::CompleteConnect(pReceivePin);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CBaseInputPin::CompleteConnect failed, hr = 0x%x"), hr));
        m_pIVPObject->BreakConnect();
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
HRESULT CVBIInputPin::BreakConnect(void)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::BreakConnect")));

    HRESULT hr = NOERROR;
    
    // tell the videoport object 
    ASSERT(m_pIVPObject);
    hr = m_pIVPObject->BreakConnect();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pIVPObject->BreakConnect failed, hr = 0x%x"), hr));
    }

    // call the base class
    hr = CBaseInputPin::BreakConnect();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CBaseInputPin::BreakConnect failed, hr = 0x%x"), hr));
    }

    return hr;
}


//==========================================================================
// transition from stop to pause state
HRESULT CVBIInputPin::Active(void)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::Active")));

    HRESULT hr = NOERROR;

    // tell the videoport object 
    hr = m_pIVPObject->Active();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pIVPObject->Active failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // call the base class
    hr = CBaseInputPin::Active();

    // if it is a VP connection, this error is ok
    if (hr == VFW_E_NO_ALLOCATOR)
    {
        hr = NOERROR;
    }

    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CBaseInputPin::Active failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    return hr;
}


//==========================================================================
// transition from pause to stop state
HRESULT CVBIInputPin::Inactive(void)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::Inactive")));

    HRESULT hr = NOERROR;
    
    // tell the videoport object
    hr = m_pIVPObject->Inactive();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pIVPObject->Inactive failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // call the base class
    hr = CBaseInputPin::Inactive();

    // if it is a VP connection, this error is ok
    if (hr == VFW_E_NO_ALLOCATOR)
    {
        hr = NOERROR;
    }

    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CBaseInputPin::Inactive failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
// transition from pause to run state
HRESULT CVBIInputPin::Run(REFERENCE_TIME tStart)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::Run")));

    HRESULT hr = NOERROR;
    
    // tell the videoport object 
    hr = m_pIVPObject->Run(tStart);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pIVPObject->Run() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // call the base class
    hr = CBaseInputPin::Run(tStart);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CBaseInputPin::Run failed, hr = 0x%x"), hr));
        m_pIVPObject->RunToPause();
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
// transition from run to pause state
HRESULT CVBIInputPin::RunToPause(void)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::RunToPause")));

    HRESULT hr = NOERROR;

    // tell the videoport object 
    hr = m_pIVPObject->RunToPause();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pIVPObject->RunToPause() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
// signals start of flushing on the input pin
HRESULT CVBIInputPin::BeginFlush(void)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::BeginFlush")));

    HRESULT hr = NOERROR;

    // call the base class
    hr = CBaseInputPin::BeginFlush();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CBaseInputPin::BeginFlush() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
// signals end of flushing on the input pin
HRESULT CVBIInputPin::EndFlush(void)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::EndFlush")));

    HRESULT hr = NOERROR;
    
    // call the base class
    hr = CBaseInputPin::EndFlush();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CBaseInputPin::EndFlush() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
// called when the upstream pin delivers us a sample
HRESULT CVBIInputPin::Receive(IMediaSample *pMediaSample)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::Receive")));

    HRESULT hr = NOERROR;
    
    hr = CBaseInputPin::Receive(pMediaSample);

    return hr;
}


//==========================================================================
// signals end of data stream on the input pin
STDMETHODIMP CVBIInputPin::EndOfStream(void)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::EndOfStream")));

    HRESULT hr = NOERROR;

    // Make sure we're streaming ok

    hr = CheckStreaming();
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR, 0, TEXT("CheckStreaming() failed, hr = 0x%x"), hr));
        return hr;
    }

    // call the base class
    hr = CBaseInputPin::EndOfStream();
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR, 0, TEXT("CBaseInputPin::EndOfStream() failed, hr = 0x%x"), hr));
        return hr;
    } 

    return hr;
}


//==========================================================================
// This overrides the CBaseInputPin virtual method to return our allocator
HRESULT CVBIInputPin::GetAllocator(IMemAllocator **ppAllocator)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::GetAllocator")));

    HRESULT hr = NOERROR;

    if (!ppAllocator)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ppAllocator is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    *ppAllocator = NULL;

CleanUp:
    return hr;
} // GetAllocator


//==========================================================================
// This overrides the CBaseInputPin virtual method to return our allocator
HRESULT CVBIInputPin::NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::NotifyAllocator")));

    HRESULT hr = NOERROR;

    if (!pAllocator)
    {
        DbgLog((LOG_ERROR, 0, TEXT("ppAllocator is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

CleanUp:
    return hr;
} // NotifyAllocator


//==========================================================================
// sets the pointer to directdraw
HRESULT CVBIInputPin::SetDirectDraw(LPDIRECTDRAW7 pDirectDraw)
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::SetDirectDraw")));

    HRESULT hr = NOERROR;

    m_pDirectDraw = pDirectDraw;

    // tell the videoport object 
    hr = m_pIVPObject->SetDirectDraw(pDirectDraw);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pIVPObject->SetDirectDraw failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    return hr;
}


//==========================================================================
// this function is used to redo the whole videoport connect process, while the graph
// maybe be running.
STDMETHODIMP CVBIInputPin::RenegotiateVPParameters()
{
    CAutoLock cLock( &m_pVPMFilter.GetFilterLock() );
    AMTRACE((TEXT("Entering CVBIInputPin::RenegotiateVPParameters")));

    HRESULT hr = NOERROR;

    // tell the videoport object 
    ASSERT(m_pIVPNotify);
    hr = m_pIVPNotify->RenegotiateVPParameters();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pIVPNotify->RenegotiateVPParameters() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    //return hr;
    return NOERROR;
}

HRESULT CVBIInputPin::SetVideoPortID( DWORD dwIndex )
{
    HRESULT hr = S_OK;
    CAutoLock l(m_pLock);
    if (m_pIVPObject ) {
        hr = m_pIVPObject->SetVideoPortID( dwIndex );
    }
    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\vpinfo.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;
#ifndef __VP_INFO__
#define __VP_INFO__

// enum to specify, whether the videoport is in a stopped or running state
enum VPInfoState
{	
    VPInfoState_STOPPED,
    VPInfoState_RUNNING
};

enum VPInfoTransform
{
    VPInfoTransform_SHRINK,
    VPInfoTransform_STRETCH
};

enum VPInfoCropState
{	
    VPInfoCropState_None,
    VPInfoCropState_AtVideoPort
};

#ifndef DDVPCAPS_VBIANDVIDEOINDEPENDENT
// Indicates that the VBI and video  can  be controlled by an independent processes.
#define DDVPCAPS_VBIANDVIDEOINDEPENDENT		0x00002000l
#endif


// {0d60e9a1-09cb-4f6f-a6dd-1051debe3c3b}
DEFINE_GUID(IID_IVideoPortInfo,
0x0d60e9a1, 0x09cb, 0x4f6f, 0xa6, 0xdd, 0x10, 0x51, 0xde, 0xbe, 0x3c, 0x3b );

// we end up with header problems when including dvp.h from quartz.cpp, so we just need them for
// these forward declarations.  Its preferrable to defining the GUID twice
struct _AMVPDATAINFO;
struct _DDVIDEOPORTINFO;
struct _DDVIDEOPORTBANDWIDTH;
struct _DDPIXELFORMAT;
struct _DDVIDEOPORTCAPS;

typedef struct _AMVPDATAINFO        AMVPDATAINFO; 
typedef struct _DDVIDEOPORTINFO     DDVIDEOPORTINFO;
typedef struct _DDPIXELFORMAT       DDPIXELFORMAT;
typedef struct _DDVIDEOPORTCAPS     DDVIDEOPORTCAPS;
typedef struct _DDVIDEOPORTBANDWIDTH DDVIDEOPORTBANDWIDTH;

DECLARE_INTERFACE_(IVideoPortInfo, IUnknown)
{
    STDMETHOD (GetRectangles)       (THIS_ RECT *prcSource, RECT *prcDest ) PURE;
    STDMETHOD (GetCropState)        (THIS_ VPInfoCropState* pCropState ) PURE;
    STDMETHOD (GetPixelsPerSecond)  (THIS_ DWORD* pPixelPerSec ) PURE;
    STDMETHOD (GetVPDataInfo)       (THIS_ AMVPDATAINFO* pVPDataInfo ) PURE;
    STDMETHOD (GetVPInfo)           (THIS_ DDVIDEOPORTINFO* pVPInfo ) PURE;
    STDMETHOD (GetVPBandwidth)      (THIS_ DDVIDEOPORTBANDWIDTH* pVPBandwidth ) PURE;
    STDMETHOD (GetVPCaps)           (THIS_ DDVIDEOPORTCAPS* pVPCaps ) PURE;
    STDMETHOD (GetVPInputFormat)    (THIS_ DDPIXELFORMAT* pVPFormat ) PURE;
    STDMETHOD (GetVPOutputFormat)   (THIS_ DDPIXELFORMAT* pVPFormat ) PURE;
};


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\vbiobj.cpp ===
//==========================================================================
//
//  Copyright (C) Microsoft Corporation, 1997 - 1999  All Rights Reserved.
//
//--------------------------------------------------------------------------

#include <streams.h>
#include <ddraw.h>
#include <VBIObj.h>
#include <VPMUtil.h>
#include <vpconfig.h>
#include <ddkernel.h>
#include <KHandleArray.h>
#include <FormatList.h>

//==========================================================================
// constructor
CVBIVideoPort::CVBIVideoPort(LPUNKNOWN pUnk, HRESULT* phr)
    : CUnknown(NAME("VBI Object"), pUnk)
    , m_pDDVPContainer(NULL)
    , m_pOffscreenSurf(NULL)
    , m_pOffscreenSurf1( NULL )
    , m_bConnected(FALSE)
    , m_pIVPConfig(NULL)
    , m_VPState(VP_STATE_NO_VP)
    , m_bFilterRunning(FALSE)
    , m_Communication(KSPIN_COMMUNICATION_SOURCE)
    , m_CategoryGUID(GUID_NULL)
    , m_pDirectDraw(NULL)
    , m_dwPixelsPerSecond(0)
    , m_dwVideoPortId(0)
    , m_pVideoPort(NULL)
    , m_dwDefaultOutputFormat( 0 )
{
    AMTRACE((TEXT("CVBIVideoPort::Constructor")));

    m_Medium.Set = GUID_NULL;
    m_Medium.Id = 0;
    m_Medium.Flags = 0;   

    ZeroStruct( m_capVPDataInfo );
    ZeroStruct( m_svpInfo );
    ZeroStruct( m_vpCaps );
    ZeroStruct( m_vpConnectInfo );

    ZeroStruct( m_ddVPInputVideoFormat );
    ZeroStruct( m_ddVPOutputVideoFormat );
}


//==========================================================================
// destructor
CVBIVideoPort::~CVBIVideoPort()
{
    AMTRACE((TEXT("CVBIVideoPort::Destructor")));

    if (m_bConnected)
    {
        DbgLog((LOG_ERROR, 0, TEXT("Destructor called without calling breakconnect")));
        BreakConnect();
    }

    return;
}


//==========================================================================
// overridden to expose IVPVBINotify and IVideoPortVBIObject
STDMETHODIMP CVBIVideoPort::NonDelegatingQueryInterface(REFIID riid, void** ppv)
{
    HRESULT hr = NOERROR;
    
    if (riid == IID_IVPVBINotify) 
    {
        DbgLog((LOG_TRACE, 4, TEXT("CVBIVideoPort::NonDelegatingQueryInterface(IID_IVPVBINotify)")));
        hr = GetInterface( static_cast<IVPVBINotify*>( this ), ppv);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 0, TEXT("GetInterface(IVPVBINotify*) failed, hr = 0x%x"), hr));
        }
    } 
    else if (riid == IID_IKsPin) 
    {
        DbgLog((LOG_TRACE, 4, TEXT("CVBIVideoPort::NonDelegatingQueryInterface(IID_IKsPin)")));
        hr = GetInterface( static_cast<IKsPin*>( this ), ppv);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 0, TEXT("GetInterface(IKsPin*) failed, hr = 0x%x"), hr));
        }
    } 
    else if (riid == IID_IKsPropertySet) 
    {
        DbgLog((LOG_TRACE, 4, TEXT("CVBIVideoPort::NonDelegatingQueryInterface(IID_IKsPropertySet)")));
        hr = GetInterface( static_cast<IKsPropertySet*>( this ), ppv);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 0, TEXT("GetInterface(IKsPropertySet*) failed, hr = 0x%x"), hr));
        }
    }
    else 
    {
        DbgLog((LOG_TRACE, 4, TEXT("CVBIVideoPort::NonDelegatingQueryInterface(Other)")));
        hr = CUnknown::NonDelegatingQueryInterface(riid, ppv);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 0, TEXT("CUnknown::NonDelegatingQueryInterface failed, hr = 0x%x"), hr));
        }
    }
    return hr;
}


//==========================================================================
// sets the pointer to directdraw
STDMETHODIMP CVBIVideoPort::SetDirectDraw(LPDIRECTDRAW7 pDirectDraw)
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::SetDirectDraw")));

    HRESULT hr = NOERROR;
    m_pDirectDraw = pDirectDraw;
    return hr;
}


//==========================================================================
// sets the pointer to the lock, which would be used to synchronize calls to the object
STDMETHODIMP CVBIVideoPort::SetObjectLock(CCritSec* pMainObjLock)
{
    AMTRACE((TEXT("CVBIVideoPort::SetObjectLock")));
    HRESULT hr = NOERROR;

    if (!pMainObjLock)
    {
        DbgLog((LOG_ERROR, 0, TEXT("pMainObjLock is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }
    
    m_pMainObjLock = pMainObjLock;

CleanUp:
    return hr;
}


//==========================================================================
// check that the mediatype is acceptable
STDMETHODIMP CVBIVideoPort::CheckMediaType(const CMediaType* pmt)
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::CheckMediaType")));

    HRESULT hr = NOERROR;
    
    if  ((pmt->majortype != MEDIATYPE_Video) || (pmt->subtype != MEDIASUBTYPE_VPVBI))
    {
        hr = VFW_E_TYPE_NOT_ACCEPTED;
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
HRESULT CVBIVideoPort::GetMediaType(int iPosition, CMediaType* pmt)
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::GetMediaType")));

    HRESULT hr = S_OK;

    if (iPosition == 0)
    {
        pmt->SetType(&MEDIATYPE_Video);
        pmt->SetSubtype(&MEDIASUBTYPE_VPVBI);
        pmt->SetFormatType(&FORMAT_None);
        pmt->SetSampleSize(1);
        pmt->SetTemporalCompression(FALSE);
    }
    else if (iPosition > 0)  {
        hr = VFW_S_NO_MORE_ITEMS;
    } else { // iPosition < 0
        hr = E_INVALIDARG;
    }
    return hr;
}


//==========================================================================
// 
STDMETHODIMP CVBIVideoPort::CheckConnect(IPin*  pReceivePin)
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::CheckConnect")));

    HRESULT hr = NOERROR;
    PKSMULTIPLE_ITEM pMediumList = NULL;
    IKsPin* pIKsPin = NULL;
    PKSPIN_MEDIUM pMedium = NULL;

    hr = pReceivePin->QueryInterface(IID_IKsPin, (void** )&pIKsPin);
    if (FAILED(hr))
        goto CleanUp;

    ASSERT(pIKsPin);
    hr = pIKsPin->KsQueryMediums(&pMediumList);
    if (FAILED(hr))
        goto CleanUp;

    ASSERT(pMediumList);
    pMedium = (KSPIN_MEDIUM* )(pMediumList+1);
    SetKsMedium((const KSPIN_MEDIUM* )pMedium);

CleanUp:
    RELEASE (pIKsPin);

    if (pMediumList)
    {
        CoTaskMemFree((void*)pMediumList);
        pMediumList = NULL;
    }

    return hr;
}


//==========================================================================
// supposed to be called when the host connects with the decoder
STDMETHODIMP CVBIVideoPort::CompleteConnect(IPin* pReceivePin)
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::CompleteConnect")));
    ASSERT(!m_bConnected);

    HRESULT hr = NOERROR;

    // re-initialize variables
    m_dwPixelsPerSecond = 0;
    ZeroStruct( m_vpConnectInfo );
    ZeroStruct( m_capVPDataInfo );

    if (!m_pDirectDraw)
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pDirectDraw is NULL")));
        hr = VFW_E_VP_NEGOTIATION_FAILED;
        goto CleanUp;
    }
    
    ASSERT(m_pIVPConfig == NULL);
    RELEASE( m_pIVPConfig );
    hr = pReceivePin->QueryInterface(IID_IVPVBIConfig, (void** )&m_pIVPConfig);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,  TEXT("QueryInterface(IID_IVPVBIConfig) failed, hr = 0x%x"), hr));
        hr = VFW_E_NO_TRANSPORT;
        goto CleanUp;
    }
    ASSERT(m_pIVPConfig);
    
    // create the VP container
    ASSERT(m_pDDVPContainer == NULL);
    hr = m_pDirectDraw->QueryInterface( IID_IDDVideoPortContainer, (LPVOID* )&m_pDDVPContainer);
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR,0,  TEXT("m_pDirectDraw->QueryInterface(IID_IDDVideoPortContainer) failed, hr = 0x%x"), hr));
        hr = VFW_E_VP_NEGOTIATION_FAILED;
        goto CleanUp;
    }

    // negotiate the connection parameters
    // get/set connection info happens here
    hr = NegotiateConnectionParameters();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("NegotiateConnectionParameters failed, hr = 0x%x"), hr));
        hr = VFW_E_VP_NEGOTIATION_FAILED;
        goto CleanUp;
    }
    
    // get the decoder data parameters
    hr = GetDecoderVPDataInfo();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("GetDecoderVPDataInfo failed, hr = 0x%x"), hr));
        hr = VFW_E_VP_NEGOTIATION_FAILED;
        goto CleanUp;
    }

    hr = SetupVideoPort();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("SetupVideoPort failed, hr = 0x%x"), hr));
        hr = VFW_E_VP_NEGOTIATION_FAILED;
        goto CleanUp;
    }

    // Success!
    m_bConnected = TRUE;
    
CleanUp:
    if (FAILED(hr))
        BreakConnect();

    return hr;
}


//==========================================================================
STDMETHODIMP CVBIVideoPort::BreakConnect()
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::BreakConnect")));
    ASSERT(!m_bFilterRunning);

    HRESULT hr = NOERROR;

	if( m_bConnected ) {
		if (m_VPState == VP_STATE_RUNNING)
		{
			DbgLog((LOG_ERROR, 0, TEXT("BreakConnect called while videoport running")));
			StopVideo();
		}

		if (m_VPState == VP_STATE_STOPPED)
		{
			hr = TearDownVideoPort();
			if (FAILED(hr))
			{
				DbgLog((LOG_ERROR, 0, TEXT("TearDownVideoPort failed, hr = 0x%x"), hr));
				return hr;
			}
		}

		// release the videoport container
		RELEASE (m_pDDVPContainer);
    
		// release the IVPConfig interface
		RELEASE (m_pIVPConfig);

		// delete the output Video pixelformat
		ZeroStruct( m_ddVPOutputVideoFormat);

		// delete the input Video pixelformat 
		ZeroStruct( m_ddVPInputVideoFormat);
		m_bConnected = FALSE;
    }
    return hr;
}       


//==========================================================================
// transition from Stop to Pause.
// We do not need to to anything
STDMETHODIMP CVBIVideoPort::Active()
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::Active")));
    ASSERT(m_bConnected);
    ASSERT(!m_bFilterRunning);
    ASSERT(m_VPState != VP_STATE_RUNNING);

    HRESULT hr = NOERROR;

    if (!m_bConnected)
    {
        hr = VFW_E_NOT_CONNECTED;
        DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::Active - not connected")));
        goto CleanUp;
    }

CleanUp:
    return hr;
}


//==========================================================================
// transition (from Pause or Run) to Stop
STDMETHODIMP CVBIVideoPort::Inactive()
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::Inactive")));
    ASSERT(m_bConnected);

    HRESULT hr = NOERROR;
    
    if (!m_bConnected)
    {
        hr = VFW_E_NOT_CONNECTED;
        DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::Inactive - not connected")));
        goto CleanUp;
    }
    
    // Inactive is also called when going from pause to stop, in which case the 
    // VideoPort would have already been stopped in the function RunToPause.
    // Also, we may have been temporarily disconnected from the videoport by
    // a full screen DOS box or a DirectX game, in which case m_VPState would be
    // VP_STATE_RETRYING
    if (m_VPState == VP_STATE_RUNNING)
    {
        ASSERT(m_bFilterRunning);
        // stop the VideoPort
        hr = StopVideo();
        if (FAILED(hr)) 
        {
            DbgLog((LOG_ERROR, 0, TEXT("StopVideo failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

    m_bFilterRunning = FALSE;
    
CleanUp:
    return hr;
}


//==========================================================================
// transition from Pause to Run. We just start the VideoPort.
STDMETHODIMP CVBIVideoPort::Run(REFERENCE_TIME tStart)
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::Run")));
    UNREFERENCED_PARAMETER(tStart);
    ASSERT(m_bConnected);
    ASSERT(!m_bFilterRunning);
    ASSERT(m_VPState != VP_STATE_RUNNING);

    HRESULT hr = NOERROR;

    if (!m_bConnected)
    {
        hr = VFW_E_NOT_CONNECTED;
        DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::Run - not connected")));
        goto CleanUp;
    }

    if (m_VPState == VP_STATE_NO_VP)
    {
        hr = SetupVideoPort();
        if (FAILED(hr)) 
        {
            DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::Run - SetupVideoPort failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

    hr = StartVideo();
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR, 0, TEXT("StartVideo failed, hr = 0x%x"), hr));
		ASSERT( SUCCEEDED(hr));
        goto CleanUp;
    }

    m_bFilterRunning = TRUE;

CleanUp:
    return hr;
}


//==========================================================================
// transition from Run to Pause. We just stop the VideoPort
// Note that transition from Run to Stop is caught by Inactive
STDMETHODIMP CVBIVideoPort::RunToPause()
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::RunToPause")));
    ASSERT(m_bConnected);
    ASSERT(m_bFilterRunning);

    HRESULT hr = NOERROR;
    
    if (!m_bConnected)
    {
        hr = VFW_E_NOT_CONNECTED;
        DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::RunToPause - not connected")));
        goto CleanUp;
    }

    // We may have been temporarily disconnected from the videoport by
    // a full screen DOS box or a DirectX game, in which case m_VPState would be
    // VP_STATE_RETRYING
    if (m_VPState == VP_STATE_RUNNING)
    {
        // stop the VideoPort
        hr = StopVideo();
        if (FAILED(hr)) 
        {
            DbgLog((LOG_ERROR, 0, TEXT("StopVideo failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

    m_bFilterRunning = FALSE;

CleanUp:
    return hr;
}


//==========================================================================
STDMETHODIMP CVBIVideoPort::GetVPDataInfo(AMVPDATAINFO* pAMVPDataInfo)
{
    CAutoLock cObjectLock(m_pMainObjLock);
    AMTRACE((TEXT("CVBIVideoPort::GetVPDataInfo")));

    HRESULT hr = NOERROR;

    if (!m_bConnected)
    {
        hr = VFW_E_NOT_CONNECTED;
        DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::GetVPDataInfo - not connected")));
        goto CleanUp;
    }

    if (!pAMVPDataInfo)
    {
        hr = E_INVALIDARG;
        DbgLog((LOG_ERROR, 2, TEXT("pAMVPDataInfo is NULL")));
        goto CleanUp;
    }
    
    *pAMVPDataInfo = m_capVPDataInfo;
    
CleanUp:
    return hr;
}


//==========================================================================
// this function is used to redo the whole videoport connect process, while the graph
// maybe be running.
STDMETHODIMP CVBIVideoPort::RenegotiateVPParameters()
{
    CAutoLock cObjectLock(m_pMainObjLock);
    DbgLog((LOG_TRACE, 1, TEXT("Entering CVBIVideoPort::RenegotiateVPParameters")));
    ASSERT(m_bConnected);

    HRESULT hr = NOERROR;

    if (!m_bConnected)
    {
        hr = VFW_E_NOT_CONNECTED;
        DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::RenegotiateVPParameters - not connected")));
        goto CleanUp;
    }

    if (m_VPState == VP_STATE_RUNNING)
        StopVideo();

    if (m_VPState == VP_STATE_STOPPED)
        TearDownVideoPort();

    hr = SetupVideoPort();   // always want_vp_setup (if connected)
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR,0, TEXT("SetupVideoPort failed in RenegotiateVPParameters, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if (m_bFilterRunning)
    {
        hr = StartVideo();
        if (FAILED(hr)) 
        {
            DbgLog((LOG_ERROR,0, TEXT("StartVideo failed in RenegotiateVPParameters, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 1, TEXT("Leaving CVBIVideoPort::RenegotiateVPParameters, hr = 0x%x"), hr));

    return hr;
}


//==========================================================================
// IKsPin::Get implementation
STDMETHODIMP CVBIVideoPort::Get(REFGUID guidPropSet, DWORD dwPropID, LPVOID pInstanceData,
	DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData, DWORD* pcbReturned)
{
    HRESULT hr = S_OK;

    AMTRACE((TEXT("CVBIVideoPort::Get")));

    if (guidPropSet != AMPROPSETID_Pin)
    {
        hr = E_PROP_SET_UNSUPPORTED;
        goto CleanUp;
    }

    if ((pPropData == NULL) && (pcbReturned == NULL))
    {
        hr = E_POINTER;
        goto CleanUp;
    }

    if (dwPropID == KSPROPERTY_PIN_CATEGORY)
    {
        if (pcbReturned)
           * pcbReturned = sizeof(GUID);
        if (pPropData != NULL)
        {
            if (cbPropData < sizeof(GUID))
            {
                hr = E_UNEXPECTED;
                goto CleanUp;
            }
           * (GUID* )pPropData = m_CategoryGUID;
        }
    }
    else if (dwPropID == KSPROPERTY_PIN_MEDIUMS)
    {
        if (pcbReturned)
           * pcbReturned = sizeof (KSPIN_MEDIUM);
        if (pPropData != NULL)
        {
            if (cbPropData < sizeof(KSPIN_MEDIUM))
            {
                hr = E_UNEXPECTED;
                goto CleanUp;
            }
           * (KSPIN_MEDIUM* )pPropData = m_Medium;
        }
    }
    else
        hr = E_PROP_ID_UNSUPPORTED;

CleanUp:
    return hr;
}


//==========================================================================
//
STDMETHODIMP CVBIVideoPort::QuerySupported(REFGUID guidPropSet, DWORD dwPropID, DWORD* pTypeSupport)
{
    HRESULT hr = S_OK;

    AMTRACE((TEXT("CVBIVideoPort::QuerySupported")));

    if (guidPropSet != AMPROPSETID_Pin)
    {
        hr = E_PROP_SET_UNSUPPORTED;
        goto CleanUp;
    }

    if ((dwPropID != KSPROPERTY_PIN_CATEGORY) && (dwPropID != KSPROPERTY_PIN_MEDIUMS))
    {
        hr = E_PROP_ID_UNSUPPORTED;
        goto CleanUp;
    }

    if (pTypeSupport)
       * pTypeSupport = KSPROPERTY_SUPPORT_GET;

CleanUp:
    return hr;
}


//==========================================================================
//
STDMETHODIMP CVBIVideoPort::KsQueryMediums(PKSMULTIPLE_ITEM* pMediumList)
{
    // The following special return code notifies the proxy that this pin is
    // not available as a kernel mode connection
    HRESULT hr = S_FALSE;

    AMTRACE((TEXT("CVBIVideoPort::KsQueryMediums")));
   * pMediumList = reinterpret_cast<PKSMULTIPLE_ITEM>(CoTaskMemAlloc(sizeof(**pMediumList)));
    if (!*pMediumList) 
    {
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }
    (*pMediumList)->Count = 0;
    (*pMediumList)->Size = sizeof(**pMediumList);

CleanUp:
    return hr;
}


//==========================================================================
//
STDMETHODIMP CVBIVideoPort::KsQueryInterfaces(PKSMULTIPLE_ITEM* pInterfaceList)
{
    PKSPIN_INTERFACE pInterface;
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVBIVideoPort::KsQueryInterfaces")));

   * pInterfaceList = reinterpret_cast<PKSMULTIPLE_ITEM>(CoTaskMemAlloc(sizeof(**pInterfaceList) + sizeof(*pInterface)));
    if (!*pInterfaceList) 
    {
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }
    (*pInterfaceList)->Count = 1;
    (*pInterfaceList)->Size = sizeof(**pInterfaceList) + sizeof(*pInterface);
    pInterface = reinterpret_cast<PKSPIN_INTERFACE>(*pInterfaceList + 1);
    pInterface->Set = KSINTERFACESETID_Standard;
    pInterface->Id = KSINTERFACE_STANDARD_STREAMING;
    pInterface->Flags = 0;

CleanUp:
    return hr;
}

//==========================================================================
//
STDMETHODIMP CVBIVideoPort::KsGetCurrentCommunication(KSPIN_COMMUNICATION* pCommunication, 
    KSPIN_INTERFACE* pInterface, KSPIN_MEDIUM* pMedium)
{
    AMTRACE((TEXT("CVBIVideoPort::KsGetCurrentCommunication")));

    if (pCommunication != NULL) 
       * pCommunication = m_Communication; 

    if (pInterface != NULL) 
    {
        pInterface->Set = KSINTERFACESETID_Standard;
        pInterface->Id = KSINTERFACE_STANDARD_STREAMING;
        pInterface->Flags = 0;
    }

    if (pMedium != NULL) 
       * pMedium = m_Medium;

    return NOERROR;
}


//==========================================================================
// Called every second or two by the thread in CSurfaceWatcher m_SurfaceWatcher,
// this function checks if we have lost our DDraw surface to a full-screen DOS box
// or a DirectX game. If we have (on this call or a previous one or on a call
// to RenegotiateVPParameters), attempt to get it back.
HRESULT CVBIVideoPort::CheckSurfaces()
{
    CAutoLock cObjectLock(m_pMainObjLock);
    //AMTRACE((TEXT("CVBIVideoPort::CheckSurfaces")));

    HRESULT hr = NOERROR;

    if (!m_bConnected)
    {
        //DbgLog((LOG_TRACE, 2, TEXT("CVBIVideoPort::CheckSurfaces - not connected")));
        goto CleanUp;
    }

    // First, see if we think we have surfaces but have really lost them.
    if (m_VPState != VP_STATE_NO_VP)
    {
        //DbgLog((LOG_TRACE, 1, TEXT("CVBIVideoPort::CheckSurfaces - checking surfaces")));
        if (m_pOffscreenSurf)
        {
            hr = m_pOffscreenSurf->IsLost();
            if (hr == DDERR_SURFACELOST)
            {
                DbgLog((LOG_TRACE, 1, TEXT("CVBIVideoPort::CheckSurfaces - Surface Lost!")));
                if (m_VPState == VP_STATE_RUNNING)
                {
                    hr = StopVideo();
                    if (FAILED(hr))
                    {
                        DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::CheckSurfaces - StopVideo failed (1), hr = 0x%x"), hr));
                        goto CleanUp;
                    }
                }
                TearDownVideoPort();
            }
        }
        else
        {
            DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::CheckSurfaces - no surface!")));
            if (m_VPState == VP_STATE_RUNNING)
            {
                hr = StopVideo();
                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::CheckSurfaces - StopVideo failed (2), hr = 0x%x"), hr));
                    goto CleanUp;
                }
            }
            TearDownVideoPort();
        }
    }

    // Next, check if our state is what we need. May have been changed above, or on a previous
    // call, or on a call to RenegotiateVPParameters.
    if (m_VPState == VP_STATE_NO_VP)
    {
        DbgLog((LOG_TRACE, 1, TEXT("CVBIVideoPort::CheckSurfaces - trying to re-setup videoport")));
        hr = SetupVideoPort();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::CheckSurfaces - SetupVideoPort failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

    if ((m_VPState == VP_STATE_STOPPED) && m_bFilterRunning)
    {
        hr = StartVideo();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::CheckSurfaces - StartVideo failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }


CleanUp:
    return NOERROR;
}


//==========================================================================
// this functions negotiates the connection parameters with
// the decoder. 
// Since this function might be called during renegotiation, the
// existing connection parameters are passed in as input and if 
// possible, we try to use the same parameters.
HRESULT CVBIVideoPort::GetVideoPortCaps()
{
    AMTRACE((TEXT("CVBIVideoPort::GetVideoPortCaps")));
    HRESULT hr = NOERROR;

    // vpCaps is scratch memory, results stored in this->m_vpCaps
    ZeroStruct( m_vpCaps );

    // DDVIDEOPORTCAPS vpCaps;
    // INITDDSTRUCT( vpCaps );

    hr = VPMUtil::FindVideoPortCaps( m_pDDVPContainer, &m_vpCaps, m_dwVideoPortId );
    if (FAILED(hr) || S_FALSE == hr )
    {
        DbgLog((LOG_ERROR,0,  TEXT("m_pDDVPContainer->EnumVideoPorts failed, hr = 0x%x"), hr));
        hr = VFW_E_VP_NEGOTIATION_FAILED;
        goto CleanUp;
    }

CleanUp:
    return hr;
}

//==========================================================================
// This functions negotiates the connection parameters with the decoder. 
HRESULT CVBIVideoPort::NegotiateConnectionParameters()
{
    HRESULT hr = NOERROR;
    
    LPDDVIDEOPORTCONNECT lpddCaptureConnect = NULL;
    DWORD dwNumCaptureEntries = 0;
    LPDDVIDEOPORTCONNECT lpddVideoPortConnect = NULL;
    DWORD dwNumVideoPortEntries = 0;
    BOOL bIntersectionFound = FALSE;
    DWORD i, j;
    
    AMTRACE((TEXT("CVBIVideoPort::NegotiateConnectionParameters")));

    ASSERT(m_pIVPConfig);
    ASSERT(m_pDDVPContainer);

    // find the number of entries to be proposed by the decoder
    hr = m_pIVPConfig->GetConnectInfo(&dwNumCaptureEntries, NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("m_pIVPConfig->GetConnectInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    ASSERT(dwNumCaptureEntries);
    
    // allocate the necessary memory
    lpddCaptureConnect = (LPDDVIDEOPORTCONNECT) new BYTE [dwNumCaptureEntries*sizeof(DDVIDEOPORTCONNECT)];
    if (lpddCaptureConnect == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("NegotiateConnectionParameters : Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }
    
    // memset the allocated memory to zero
    memset(lpddCaptureConnect, 0, dwNumCaptureEntries*sizeof(DDVIDEOPORTCONNECT));
    
    // set the right size in each of the structs.
    for (i = 0; i < dwNumCaptureEntries; i++)
    {
        lpddCaptureConnect[i].dwSize = sizeof(DDVIDEOPORTCONNECT);
    }
    
    // get the entries proposed by the decoder
    hr = m_pIVPConfig->GetConnectInfo(&dwNumCaptureEntries, lpddCaptureConnect);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("m_pIVPConfig->GetConnectInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    // find the number of entries supported by the videoport
    hr = m_pDDVPContainer->GetVideoPortConnectInfo(m_dwVideoPortId, &dwNumVideoPortEntries, NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("m_pDDVPContainer->GetVideoPortConnectInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    ASSERT(dwNumVideoPortEntries);

    // allocate the necessary memory
    lpddVideoPortConnect = (LPDDVIDEOPORTCONNECT) new BYTE[dwNumVideoPortEntries*sizeof(DDVIDEOPORTCONNECT)];
    if (lpddVideoPortConnect == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("NegotiateConnectionParameters : Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // memset the allocated memory to zero
    memset(lpddVideoPortConnect, 0, dwNumVideoPortEntries*sizeof(DDVIDEOPORTCONNECT));

    // set the right size in each of the structs.
    for (i = 0; i < dwNumVideoPortEntries; i++)
    {
        lpddVideoPortConnect[i].dwSize = sizeof(DDVIDEOPORTCONNECT);
    }

    // get the entries supported by the videoport
    hr = m_pDDVPContainer->GetVideoPortConnectInfo(0, &dwNumVideoPortEntries, lpddVideoPortConnect);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("m_pDDVPContainer->GetVideoPortConnectInfo failed, hr = 0x%x"), hr));
        hr = E_FAIL;
        goto CleanUp;
    }

#ifdef DEBUG
        for (i = 0; i < dwNumCaptureEntries; i++)
            DbgLog((LOG_TRACE, 3, TEXT("lpddCaptureConnect[%d].dwFlags = 0x%x"), i, lpddCaptureConnect[i].dwFlags));
        for (j = 0; j < dwNumVideoPortEntries; j++)
            DbgLog((LOG_TRACE,3,TEXT("lpddVideoPortConnect[%d].dwFlags = 0x%x"), j, lpddVideoPortConnect[j].dwFlags));
#endif
        
        // take the first element of the intersection of the two lists and
        // set that value on the decoder
        for (i = 0; i < dwNumCaptureEntries && !bIntersectionFound; i++)
        {
            for (j = 0; j < dwNumVideoPortEntries && !bIntersectionFound; j++)
            {
                if (lpddCaptureConnect[i].dwPortWidth == lpddVideoPortConnect[j].dwPortWidth &&
                    IsEqualIID(lpddCaptureConnect[i].guidTypeID, lpddVideoPortConnect[j].guidTypeID))
                {
                    // make sure we save the right one (the one from the video port, not the one
                    // from the capture driver)
                    memcpy(&m_vpConnectInfo, (lpddVideoPortConnect+j), sizeof(DDVIDEOPORTCONNECT));
                    hr = m_pIVPConfig->SetConnectInfo(i);
                    if (FAILED(hr))
                    {
                        DbgLog((LOG_ERROR,0,TEXT("m_pIVPConfig->SetConnectInfo failed, hr = 0x%x"), hr));
                        goto CleanUp;
                    }

                    bIntersectionFound = TRUE;
                }
            }
        }

    if (!bIntersectionFound)
    {
        hr = E_FAIL;

        goto CleanUp;
    }
    
    // cleanup
CleanUp:
    delete [] lpddCaptureConnect;
    delete [] lpddVideoPortConnect;
    return hr;
}


//==========================================================================
// This functions gets various data parameters from the decoder
// parameters include dimensions, double-clock, vact etc.
// Also maximum pixel rate the decoder will output.
// This happens after the connnection parameters have been set-up
HRESULT CVBIVideoPort::GetDecoderVPDataInfo()
{
    HRESULT hr = NOERROR;
    DWORD dwMaxPixelsPerSecond = 0;
    AMVPSIZE amvpSize;
    
    AMTRACE((TEXT("CVBIVideoPort::GetDecoderVPDataInfo")));

    // set the size of the struct
    m_capVPDataInfo.dwSize = sizeof(AMVPDATAINFO);
    
    // get the VideoPort data information
    hr = m_pIVPConfig->GetVPDataInfo(&m_capVPDataInfo);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("m_pIVPConfig->GetVPDataInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    amvpSize.dwWidth = m_capVPDataInfo.amvpDimInfo.dwVBIWidth;
    amvpSize.dwHeight = m_capVPDataInfo.amvpDimInfo.dwVBIHeight;
    
    // get the maximum pixel rate the decoder will output
    hr = m_pIVPConfig->GetMaxPixelRate(&amvpSize, &dwMaxPixelsPerSecond);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("m_pIVPConfig->GetMaxPixelRate failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    m_dwPixelsPerSecond = dwMaxPixelsPerSecond;
    
CleanUp:
    return hr;
}


//==========================================================================
// Calls DDRAW to actually create the video port.
HRESULT CVBIVideoPort::CreateVideoPort()
{
    HRESULT hr = NOERROR;
    DDVIDEOPORTDESC svpDesc;
    
    AMTRACE((TEXT("CVBIVideoPort::CreateVideoPort")));

    INITDDSTRUCT( svpDesc );
    
    // fill up the fields of the description struct
    svpDesc.dwVBIWidth = m_capVPDataInfo.amvpDimInfo.dwVBIWidth;
    svpDesc.dwFieldHeight = m_capVPDataInfo.amvpDimInfo.dwFieldHeight;
    svpDesc.dwFieldWidth = m_capVPDataInfo.amvpDimInfo.dwFieldWidth;
    
    svpDesc.dwMicrosecondsPerField = m_capVPDataInfo.dwMicrosecondsPerField;
    svpDesc.dwMaxPixelsPerSecond = m_dwPixelsPerSecond;
    svpDesc.dwVideoPortID = m_dwVideoPortId;
    //DAG_TODO: need to use QueryVideoPortStatus
    svpDesc.VideoPortType.dwSize = sizeof(DDVIDEOPORTCONNECT);
    svpDesc.VideoPortType.dwPortWidth = m_vpConnectInfo.dwPortWidth;
    memcpy(&(svpDesc.VideoPortType.guidTypeID), &(m_vpConnectInfo.guidTypeID), sizeof(GUID));
    svpDesc.VideoPortType.dwFlags = 0;
    
    // if the decoder can send double clocked data and the videoport 
    // supports it, then set that property. This field is only valid
    // with an external signal.
    if (m_capVPDataInfo.bEnableDoubleClock &&
        m_vpConnectInfo.dwFlags & DDVPCONNECT_DOUBLECLOCK)
    {
        svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_DOUBLECLOCK;
    }
    
    // if the decoder can give an external activation signal and the 
    // videoport supports it, then set that property. This field is 
    // only valid with an external signal.
    if (m_capVPDataInfo.bEnableVACT && 
        m_vpConnectInfo.dwFlags & DDVPCONNECT_VACT)
    {
        svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_VACT;
    }
    
    // if the decoder can send interlaced data and the videoport 
    // supports it, then set that property.
    // !!!SJF_TODO - should we fail if the decoder can't send interlaced data?
    if (m_capVPDataInfo.bDataIsInterlaced)
    {
        svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_INTERLACED;
    }

    if (m_bHalfLineFix)
    {
        //!!!SJF_TODO - flip polarity back to normal on decoder?
        ASSERT(!m_capVPDataInfo.bFieldPolarityInverted);
        //!!!SJF_TODO - fail if videoport doesn't handle inverted polarity?
        ASSERT(m_vpConnectInfo.dwFlags & DDVPCONNECT_INVERTPOLARITY);
        DbgLog((LOG_TRACE, 3, TEXT("INVERTPOLARITY & HALFLINE")));
        
        svpDesc.VideoPortType.dwFlags |=
            (DDVPCONNECT_INVERTPOLARITY | DDVPCONNECT_HALFLINE);
    }
    
#if 0 // def DEBUG
    DbgLog((LOG_TRACE, 3, TEXT("CreateVideoPort - DDVIDEOPORTDESC")));
    DbgLog((LOG_TRACE, 3, TEXT("dwSize: %d"),svpDesc.dwSize));
    DbgLog((LOG_TRACE, 3, TEXT("dwFieldWidth: %d"),svpDesc.dwFieldWidth));
    DbgLog((LOG_TRACE, 3, TEXT("dwVBIWidth: %d"),svpDesc.dwVBIWidth));
    DbgLog((LOG_TRACE, 3, TEXT("dwFieldHeight: %d"),svpDesc.dwFieldHeight));
    DbgLog((LOG_TRACE, 3, TEXT("dwMicroseconds: %d"),svpDesc.dwMicrosecondsPerField));
    DbgLog((LOG_TRACE, 3, TEXT("dwMaxPixels: %d"),svpDesc.dwMaxPixelsPerSecond));
    DbgLog((LOG_TRACE, 3, TEXT("dwVideoPortID: %d"),svpDesc.dwVideoPortID));
    DbgLog((LOG_TRACE, 3, TEXT("dwReserved1: %d"),svpDesc.dwReserved1));
    DbgLog((LOG_TRACE, 3, TEXT("dwReserved2: %d"),svpDesc.dwReserved2));
    DbgLog((LOG_TRACE, 3, TEXT("dwReserved3: %d"),svpDesc.dwReserved3));
    DbgLog((LOG_TRACE, 3, TEXT("DDVIDEOPORTCONNECT")));
    DbgLog((LOG_TRACE, 3, TEXT("dwSize: %d"),svpDesc.VideoPortType.dwSize));
    DbgLog((LOG_TRACE, 3, TEXT("dwPortWidth: %d"),svpDesc.VideoPortType.dwPortWidth));
    DbgLog((LOG_TRACE, 3, TEXT("dwFlags: 0x%x"),svpDesc.VideoPortType.dwFlags));
    DbgLog((LOG_TRACE, 3, TEXT("GUID: 0x%x"),*((DWORD* )&svpDesc.VideoPortType.guidTypeID)));
    DbgLog((LOG_TRACE, 3, TEXT("dwReserved1: %d"),svpDesc.VideoPortType.dwReserved1));
#endif // DEBUG

    // create the videoport. The first parameter is dwFlags, reserved for 
    // future use by ddraw. The last parameter is pUnkOuter, again must be
    // NULL.
    hr = m_pDDVPContainer->CreateVideoPort(DDVPCREATE_VBIONLY, &svpDesc, &m_pVideoPort, NULL );
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR, 0, TEXT("Unable to create the video port, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
CleanUp:
    return hr;
}


//==========================================================================
// this function is used to allocate an offscreen surface to attach to the 
// videoport. 
// The allocation order it tries is just in decreasing amount of memory
// required.
// (3 buffers, single height)
// (2 buffers, single height)
// (1 buffer , single height).
HRESULT CVBIVideoPort::CreateVPSurface(void)
{
    DWORD dwMaxBuffers;
    HRESULT hr = NOERROR;
    DWORD dwCurHeight = 0, dwCurBuffers = 0;
    
    AMTRACE((TEXT("CVBIVideoPort::CreateVPSurface")));

    ASSERT(m_pDirectDraw);
    
    // we will try to allocate up to 3 buffers (unless the 
    // hardware can handle less than 3)
    dwMaxBuffers = 3;
    if (m_vpCaps.dwNumVBIAutoFlipSurfaces < dwMaxBuffers)
        dwMaxBuffers = m_vpCaps.dwNumVBIAutoFlipSurfaces;
    
    // initialize the fields of ddsdDesc
    DDSURFACEDESC2 ddsdDesc;
    INITDDSTRUCT( ddsdDesc );
    ddsdDesc.dwFlags = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH | DDSD_PIXELFORMAT;
    ddsdDesc.ddpfPixelFormat = m_ddVPOutputVideoFormat;
    ddsdDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_VIDEOMEMORY | DDSCAPS_VIDEOPORT;

    // if we're bob interleaving, the VBI surface seems to need to be doubled too, so always
    // double it (the VBI surface memory is relatively small anyways)
    ddsdDesc.dwHeight = m_dwSurfaceHeight * 2;

    ddsdDesc.dwWidth = m_dwSurfacePitch;
    DbgLog((LOG_TRACE, 3, TEXT("Surface height %d, width %d, max buffers %d"),
        ddsdDesc.dwHeight, ddsdDesc.dwWidth, dwMaxBuffers));

    // we will only try to allocate more than one buffer if the videoport 
    // is cabable of autoflipping 
    if ((m_vpCaps.dwFlags & DDVPD_CAPS) && (m_vpCaps.dwCaps & DDVPCAPS_AUTOFLIP) && dwMaxBuffers > 1)
    {
        ddsdDesc.dwFlags |= DDSD_BACKBUFFERCOUNT;
        ddsdDesc.ddsCaps.dwCaps |= DDSCAPS_COMPLEX | DDSCAPS_FLIP;
        
        for (dwCurBuffers = dwMaxBuffers; !m_pOffscreenSurf &&  dwCurBuffers >= 2; dwCurBuffers--)
        {
            ddsdDesc.dwBackBufferCount = dwCurBuffers-1;

            hr = m_pDirectDraw->CreateSurface(&ddsdDesc, &m_pOffscreenSurf, NULL);
            if (SUCCEEDED(hr))
            {
                hr = m_pOffscreenSurf->QueryInterface( IID_IDirectDrawSurface,  (VOID **)&m_pOffscreenSurf1 );
                if( SUCCEEDED( hr )) {
                    DbgLog((LOG_TRACE, 3, TEXT("allocated %d backbuffers"), ddsdDesc.dwBackBufferCount));
                    goto CleanUp;
                } else {
                    // should never fail, but just in case try again
                    ASSERT( !"VBI Surface doesn't support DDraw1" );
                    RELEASE( m_pOffscreenSurf );
                }
            }
            else
            {
                DbgLog((LOG_ERROR, 0, TEXT("failed to allocate %d backbuffers, hr = 0x%x"),
                    ddsdDesc.dwBackBufferCount, hr));
            }
        }
    }
    
    // we should only reach this point when attempt to allocate multiple
    // buffers failed or no autoflip available
    DbgLog((LOG_ERROR, 0, TEXT("Warning: unable to allocate backbuffers")));
    
    ddsdDesc.dwFlags &= ~DDSD_BACKBUFFERCOUNT;
    ddsdDesc.ddsCaps.dwCaps &= ~(DDSCAPS_COMPLEX | DDSCAPS_FLIP);
    m_svpInfo.dwVPFlags &= ~DDVP_AUTOFLIP;

    hr = m_pDirectDraw->CreateSurface(&ddsdDesc, &m_pOffscreenSurf, NULL);
    if (SUCCEEDED(hr))
    {
        hr = m_pOffscreenSurf->QueryInterface( IID_IDirectDrawSurface,  (VOID **)&m_pOffscreenSurf1 );
        if( SUCCEEDED( hr )) {
            goto CleanUp;
        } else {
            // should never fail, but just in case try again
            ASSERT( !"VBI Surface doesn't support DDraw1" );
            RELEASE( m_pOffscreenSurf );
        }
    }
    
    ASSERT(!m_pOffscreenSurf);
    DbgLog((LOG_ERROR,0,  TEXT("Unable to create offscreen surface")));

CleanUp:
    return hr;
}

//==========================================================================
// this function is used to inform the decoder of the various ddraw kernel handle
// using IVPConfig interface
HRESULT CVBIVideoPort::SetDDrawKernelHandles()
{
    HRESULT hr = NOERROR;
    IDirectDrawKernel* pDDK = NULL;
    IDirectDrawSurfaceKernel* pDDSK = NULL;
    ULONG_PTR* rgKernelHandles = NULL;
    DWORD dwCount = 0;
    ULONG_PTR ddKernelHandle = 0;
    
    AMTRACE((TEXT("CVBIVideoPort::SetDDrawKernelHandles")));

    // get the IDirectDrawKernel interface
    ASSERT(m_pDirectDraw);
    hr = m_pDirectDraw->QueryInterface(IID_IDirectDrawKernel, (LPVOID* )&pDDK);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("QueryInterface for IDirectDrawKernel failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    // get the kernel handle
    ASSERT(pDDK);
    hr = pDDK->GetKernelHandle(&ddKernelHandle);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("GetKernelHandle from IDirectDrawKernel failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    // set the kernel handle to directdraw using IVPConfig
    ASSERT(m_pIVPConfig);
    ASSERT(ddKernelHandle);
    hr = m_pIVPConfig->SetDirectDrawKernelHandle(ddKernelHandle);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("IVPConfig::SetDirectDrawKernelHandle failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    // set the VidceoPort Id using IVPConfig
    ASSERT(m_pIVPConfig);
    hr = m_pIVPConfig->SetVideoPortID(m_dwVideoPortId);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("IVPConfig::SetVideoPortID failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    {
        // should not be NULL
        ASSERT( m_pOffscreenSurf1 );

        KernelHandleArray pArray( m_pOffscreenSurf, hr );

        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,TEXT("GetKernelHandles failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        // set the kernel handle to the offscreen surface using IVPConfig
        ASSERT(m_pIVPConfig);
        hr = m_pIVPConfig->SetDDSurfaceKernelHandles( pArray.GetCount(), pArray.GetHandles() );
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,TEXT("IVPConfig::SetDDSurfaceKernelHandles failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    
        // call SetSurfaceParameters interface on IVPConfig
        ASSERT(m_pIVPConfig);
        DbgLog((LOG_TRACE, 3, TEXT("SetSurfaceParams(%d,%d,%d)"),
            m_dwSurfacePitch, m_dwSurfaceOriginX, m_dwSurfaceOriginY));
        hr = m_pIVPConfig->SetSurfaceParameters(m_dwSurfacePitch,
            m_dwSurfaceOriginX,m_dwSurfaceOriginY);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,TEXT("IVPConfig::SetSurfaceParameters failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    
CleanUp:
    // release the kernel ddraw handle
    RELEASE (pDDK);
    return hr;
}


/*****************************Private*Routine******************************\
* CVideoPortObj::NegotiatePixelFormat
*
* this function is used to negotiate the pixelformat with the decoder.
* It asks the decoder fot a list of input formats, intersects that list
* with the one the deocoder supports (while maintaining the order) and
* then calls "GetBestFormat" on that list to get the "best" input and
* output format. After that it calls "SetPixelFormat" on the decoder in
* order to inform the decoder of the decision.
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CVBIVideoPort::GetInputPixelFormats( PixelFormatList* pList )
{
    AMTRACE((TEXT("CVideoPortObj::NegotiatePixelFormat")));
    CAutoLock cObjectLock(m_pMainObjLock);

    HRESULT hr = NOERROR;
    // find the number of entries to be proposed
    DWORD dwNumProposedEntries = 0;
    hr = m_pIVPConfig->GetVideoFormats(&dwNumProposedEntries, NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetVideoFormats failed, hr = 0x%x"), hr));
        return hr;
    }
    ASSERT(dwNumProposedEntries);

    // find the number of entries supported by the videoport
    DWORD dwNumVPInputEntries = 0;
    hr = m_pVideoPort->GetInputFormats(&dwNumVPInputEntries, NULL, DDVPFORMAT_VBI);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pVideoPort->GetInputFormats failed, hr = 0x%x"), hr));
        return hr;
    }
    ASSERT(dwNumVPInputEntries);

    // allocate the necessary memory
    PixelFormatList lpddProposedFormats(dwNumProposedEntries);
    if (lpddProposedFormats.GetEntries() == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("NegotiatePixelFormat : Out of Memory")));
        hr = E_OUTOFMEMORY;
        return hr;
    }

    // get the entries proposed
    hr = m_pIVPConfig->GetVideoFormats(&dwNumProposedEntries, lpddProposedFormats.GetEntries() );
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetVideoFormats failed, hr = 0x%x"), hr));
        return hr;
    }

    // allocate the necessary memory
    PixelFormatList lpddVPInputFormats(dwNumVPInputEntries);
    if (lpddVPInputFormats.GetEntries() == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("NegotiatePixelFormat : Out of Memory")));
        hr = E_OUTOFMEMORY;
        return hr;
    }

    // get the entries supported by the videoport
    hr = m_pVideoPort->GetInputFormats(&dwNumVPInputEntries,
                                       lpddVPInputFormats.GetEntries(), DDVPFORMAT_VBI);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pVideoPort->GetInputFormats failed, hr = 0x%x"), hr));
        hr = E_FAIL;
        return hr;
    }

    *pList = lpddVPInputFormats.IntersectWith( lpddProposedFormats );

    // the number of entries in the intersection is zero!!
    // Return failure.
    if (pList->GetCount() == 0)
    {
        hr = E_FAIL;
        return hr;
    }

    // call GetBestFormat with whatever search criterion you want
    // DWORD dwBestEntry;
    // hr = GetBestFormat(lpddIntersectionFormats.GetCount(),
    //                    lpddIntersectionFormats.GetEntries(), TRUE, &dwBestEntry,
    //                    &m_ddVPOutputVideoFormat);
    // if (FAILED(hr))
    // {
    //     DbgLog((LOG_ERROR,0,TEXT("GetBestFormat failed, hr = 0x%x"), hr));
    // } else {
    //      hr = SetVPInputPixelFormat( lpddIntersectionFormats[dwBestEntry] )
    // }
    return hr;
}

HRESULT
CVBIVideoPort::GetOutputPixelFormats(
    const PixelFormatList& ddInputFormats,
    PixelFormatList* pddOutputFormats )
{
    HRESULT hr = S_OK;
    AMTRACE((TEXT("CVideoPortObj::GetOutputFormats")));

    CAutoLock cObjectLock(m_pMainObjLock);

    for (DWORD i = 0; i < ddInputFormats.GetCount(); i++)
    {
        // For each input format, figure out the output formats
        DDPIXELFORMAT* pInputFormat = const_cast<DDPIXELFORMAT*>(&ddInputFormats[i]);
        DWORD dwNumOutputFormats;
        hr = m_pVideoPort->GetOutputFormats(pInputFormat,
                                            &dwNumOutputFormats,
                                            NULL, DDVPFORMAT_VBI);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pVideoPort->GetOutputFormats failed, hr = 0x%x"),
                    hr));
            break;
        }
        ASSERT(dwNumOutputFormats);

        // allocate the necessary memory
        pddOutputFormats[i].Reset( dwNumOutputFormats );

        if (pddOutputFormats[i].GetEntries() == NULL)
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("new failed, failed to allocate memnory for ")
                    TEXT("lpddOutputFormats in NegotiatePixelFormat")));
            hr = E_OUTOFMEMORY;
            break;
        }

        // get the entries supported by the videoport
        hr = m_pVideoPort->GetOutputFormats(pInputFormat,
                                            &dwNumOutputFormats,
                                            pddOutputFormats[i].GetEntries(),
                                            DDVPFORMAT_VBI);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pVideoPort->GetOutputFormats failed, hr = 0x%x"),
                    hr));
            break;
        }
    } // end of outer for loop
    return hr;
}

HRESULT CVBIVideoPort::SetInputPixelFormat( DDPIXELFORMAT& ddFormat )
{
    HRESULT hr = NOERROR;
    // find the number of entries to be proposed
    DWORD dwNumProposedEntries = 0;
    hr = m_pIVPConfig->GetVideoFormats(&dwNumProposedEntries, NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetVideoFormats failed, hr = 0x%x"), hr));
        return hr;
    }
    ASSERT(dwNumProposedEntries);

    PixelFormatList lpddProposedFormats(dwNumProposedEntries);
    if (lpddProposedFormats.GetEntries() == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("NegotiatePixelFormat : Out of Memory")));
        hr = E_OUTOFMEMORY;
        return hr;
    }

    // get the entries proposed
    hr = m_pIVPConfig->GetVideoFormats(&dwNumProposedEntries, lpddProposedFormats.GetEntries() );
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetVideoFormats failed, hr = 0x%x"), hr));
        return hr;
    }

    // set the format the decoder is supposed to be using
    for (DWORD i = 0; i < dwNumProposedEntries; i++)
    {
        if (VPMUtil::EqualPixelFormats(lpddProposedFormats[i], ddFormat ))
        {
            hr = m_pIVPConfig->SetVideoFormat(i);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,0,
                        TEXT("m_pIVPConfig->SetVideoFormat failed, hr = 0x%x"),
                        hr));
                return hr;
            }
            // cache the input format
            m_ddVPInputVideoFormat = ddFormat;

            break;
        }
    }
    return hr;
}

//==========================================================================
HRESULT CVBIVideoPort::InitializeVideoPortInfo()
{
    HRESULT hr = NOERROR;
    RECT rcVPCrop;

    AMTRACE((TEXT("CVBIVideoPort::InitializeVideoPortInfo")));

    m_dwSurfacePitch = m_capVPDataInfo.amvpDimInfo.dwVBIWidth;
    m_dwSurfaceHeight = m_capVPDataInfo.amvpDimInfo.dwVBIHeight;
    m_dwSurfaceOriginX = m_capVPDataInfo.amvpDimInfo.rcValidRegion.left;
    m_dwSurfaceOriginY = m_capVPDataInfo.amvpDimInfo.rcValidRegion.top;
    m_bHalfLineFix = FALSE;

    // If we ask the videoport to do cropping, the bottom of the cropping
    // region MUST touch but not overlap the top of the cropping region
    // for video set by OVMIXER due to h/w limitations.
    // So, the bottom of our crop region is always dwVBIHeight (or
    // possibly dwVBIHeight+1 if certain halfline fixes are in effect,
    // see below) even if the capture driver hasn't set ValidRegion to
    // include that many lines.
    rcVPCrop.top = 0;
    rcVPCrop.left = 0;
    rcVPCrop.bottom = m_capVPDataInfo.amvpDimInfo.dwVBIHeight;
    rcVPCrop.right = m_capVPDataInfo.amvpDimInfo.dwVBIWidth;

    // Adjust for half-lines
    // Some video decoders send halflines in even or odd field.
    // Some video ports capture halflines, some don't.
    // See Video Line Numbering using VPE by smac
    if (m_vpConnectInfo.dwFlags & DDVPCONNECT_HALFLINE) // e.g. ATI videoport
    {
        if ((m_capVPDataInfo.lHalfLinesOdd == 0) &&
        (m_capVPDataInfo.lHalfLinesEven == 1))  // e.g. Brooktree decoder
        {
            // ATI All In Wonder (AIW) board
            // halfline problem
            DbgLog((LOG_TRACE, 3, TEXT("Setting up for AIW h/w")));
            m_dwSurfaceHeight++;
            rcVPCrop.bottom += 1;
            m_bHalfLineFix = TRUE;
        }
        else if (((m_capVPDataInfo.lHalfLinesOdd == -1) && (m_capVPDataInfo.lHalfLinesEven ==  0)) ||   // e.g. Philips decoder
                 ((m_capVPDataInfo.lHalfLinesOdd ==  0) && (m_capVPDataInfo.lHalfLinesEven == -1)) ||   // e.g. ? decoder
                 ((m_capVPDataInfo.lHalfLinesOdd ==  0) && (m_capVPDataInfo.lHalfLinesEven ==  0)))     // e.g. ? decoder
        {
            // no halfline problem, do nothing
        }
        else
        {
            // YIKES! We have no solution for these cases (if they even exist)!
            DbgLog((LOG_ERROR, 0,TEXT("CVBIVideoPort::InitializeVideoPortInfo: unfixable halfline problem!")));
            hr = VFW_E_VP_NEGOTIATION_FAILED;
            goto CleanUp;
        }
    }
    else    // videoport that doesn't capture halflines
    {
        if ((m_capVPDataInfo.lHalfLinesOdd == -1) &&
            (m_capVPDataInfo.lHalfLinesEven == 0))  // e.g. Philips decoder
        {
            // halfline problem
            m_dwSurfaceHeight++;
            rcVPCrop.top -= 1;
            m_bHalfLineFix = TRUE;
        }
        else if (((m_capVPDataInfo.lHalfLinesOdd ==  0) && (m_capVPDataInfo.lHalfLinesEven ==  1)) ||   // e.g. BT829 decoder
                 ((m_capVPDataInfo.lHalfLinesOdd ==  1) && (m_capVPDataInfo.lHalfLinesEven ==  0)) ||   // e.g. ? decoder
                 ((m_capVPDataInfo.lHalfLinesOdd ==  0) && (m_capVPDataInfo.lHalfLinesEven ==  0)))     // e.g. ? decoder
        {
            // no halfline problem, do nothing
        }
        else
        {
            // YIKES! We have no solution for these cases (if they even exist)!
            DbgLog((LOG_ERROR, 0,TEXT("CVBIVideoPort::InitializeVideoPortInfo: unfixable halfline problem!")));
            hr = VFW_E_VP_NEGOTIATION_FAILED;
            goto CleanUp;
        }
    }

    // Adjust if video discards lines during the VREF period
    if (m_vpConnectInfo.dwFlags & DDVPCONNECT_DISCARDSVREFDATA)
    {
        DbgLog((LOG_TRACE, 3, TEXT("VideoPort discards %d VREF lines"),
            m_capVPDataInfo.dwNumLinesInVREF));
        ASSERT(m_dwSurfaceOriginY >= m_capVPDataInfo.dwNumLinesInVREF);
        m_dwSurfaceOriginY -= m_capVPDataInfo.dwNumLinesInVREF;
        m_dwSurfaceHeight -= m_capVPDataInfo.dwNumLinesInVREF;
        rcVPCrop.bottom -= m_capVPDataInfo.dwNumLinesInVREF;
    }

    // initialize the DDVIDEOPORTINFO struct to be passed to pVideoport->StartVideo
    INITDDSTRUCT( m_svpInfo );

    m_svpInfo.dwVBIHeight = m_dwSurfaceHeight;
    // Assume we're going to be able to autoflip
    m_svpInfo.dwVPFlags = DDVP_AUTOFLIP;
    // pixelformats get filled in in NegotiatePixelFormats

#if 0   // !!!SJF_TODO - ATI says that cropping for VBI is not supported.
    // We always set h/w cropping in the Y direction if we can.
    // For VBI, we don't need to do cropping in the X direction.
    // Can the videoport crop in the Y direction?
    if ((m_vpCaps.dwFlags & DDVPD_FX) && (m_vpCaps.dwFX & DDVPFX_CROPY))
    {
        rcVPCrop.top = m_dwSurfaceOriginY;
        m_dwSurfaceHeight -= m_dwSurfaceOriginY;
        m_dwSurfaceOriginY = 0;

        m_svpInfo.rCrop = rcVPCrop;
        m_svpInfo.dwVPFlags |= DDVP_CROP;

        DbgLog((LOG_TRACE, 3, TEXT("Cropping left top:      (%d,%d)"),
            m_svpInfo.rCrop.left, m_svpInfo.rCrop.top));
        DbgLog((LOG_TRACE, 3, TEXT("Cropping bottom right:  (%d,%d)"),
            m_svpInfo.rCrop.right, m_svpInfo.rCrop.bottom));
    }
    else
    {
        if (m_bHalfLineFix)
        {
            DbgLog((LOG_ERROR, 0,TEXT("CVBIVideoPort::InitializeVideoPortInfo: can't crop to fix halfline problem!")));
            hr = VFW_E_VP_NEGOTIATION_FAILED;
            goto CleanUp;
        }
    }
#endif  // 0

    if (m_bHalfLineFix)
    {
        if (!(m_vpConnectInfo.dwFlags & DDVPCONNECT_INVERTPOLARITY))
        {
            DbgLog((LOG_ERROR, 0, TEXT("CVBIVideoPort::InitializeVideoPortInfo: can't invert polarity to fix halfline problem!")));
            hr = VFW_E_VP_NEGOTIATION_FAILED;
            goto CleanUp;
        }
    }

#if 0 // def DEBUG
    DbgLog((LOG_TRACE, 3, TEXT("m_dwSurfaceHeight:  %d"),m_dwSurfaceHeight));
    DbgLog((LOG_TRACE, 3, TEXT("m_dwSurfacePitch:   %d"),m_dwSurfacePitch));
    DbgLog((LOG_TRACE, 3, TEXT("m_dwSurfaceOriginX: %d"),m_dwSurfaceOriginX));
    DbgLog((LOG_TRACE, 3, TEXT("m_dwSurfaceOriginY: %d"),m_dwSurfaceOriginY));
#endif // DEBUG

CleanUp:

    return hr;
}


//==========================================================================
//
HRESULT CVBIVideoPort::SetupVideoPort()
{
    AMTRACE((TEXT("CVBIVideoPort::SetupVideoPort")));
    ASSERT(m_VPState == VP_STATE_NO_VP);

    HRESULT hr = NOERROR;

    // initialize variables
    ZeroStruct( m_svpInfo );
    ZeroStruct( m_vpCaps );

    // Get the Video Port caps
    hr = GetVideoPortCaps();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("GetVideoPortCaps failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // initalize the DDVideoPortInfo structure
    hr = InitializeVideoPortInfo();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("InitializeVideoPortInfo FAILED, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    // create the video port
    hr = CreateVideoPort();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CreateVideoPort failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    // negotiate the pixel format 
    hr = NegotiatePixelFormat();
    if ( FAILED( hr ))
    {
        DbgLog((LOG_ERROR, 0, TEXT("NegotiatePixelFormat Failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    // Update the m_svpInfo structure which was mostly filled in in
    // InitializeVideoPortInfo
    ASSERT(VPMUtil::EqualPixelFormats(m_ddVPInputVideoFormat, m_ddVPOutputVideoFormat));
    m_svpInfo.lpddpfVBIInputFormat = &m_ddVPInputVideoFormat;
    m_svpInfo.lpddpfVBIOutputFormat = &m_ddVPOutputVideoFormat;


    // create the offscreen surface
    hr = CreateVPSurface();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CreateVPSurface FAILED, hr = 0x%x"), hr));
        hr = VFW_E_OUT_OF_VIDEO_MEMORY;
        goto CleanUp;
    }
    
    // attach the offscreen surface to the videoport
    hr = m_pVideoPort->SetTargetSurface(m_pOffscreenSurf1, DDVPTARGET_VBI);
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR, 0, TEXT("m_pVideoPort->SetTargetSurface failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    
    // inform the decoder of the ddraw kernel handle, videoport id and surface kernel
    // handle
    hr = SetDDrawKernelHandles();
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR, 0, TEXT("SetDDrawKernelHandles failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    m_VPState = VP_STATE_STOPPED;

CleanUp:
    if (FAILED(hr))
        TearDownVideoPort();


    return hr;
}

HRESULT CVBIVideoPort::NegotiatePixelFormat()
{
    PixelFormatList ddInputVideoFormats;
    HRESULT hr = GetInputPixelFormats( &ddInputVideoFormats );
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("NegotiatePixelFormat Failed, hr = 0x%x"), hr));
    } else {
        PixelFormatList* pddOutputVideoFormats = NULL;
        if( ddInputVideoFormats.GetCount() ) {
            pddOutputVideoFormats = new PixelFormatList[ ddInputVideoFormats.GetCount() ];
            if( !pddOutputVideoFormats ) {
                hr = E_OUTOFMEMORY;
                goto CleanUp;
            }

            hr = GetOutputPixelFormats( ddInputVideoFormats, pddOutputVideoFormats );
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 0,
                        TEXT("NegotiatePixelFormat Failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
            // for every input format, figure out a table of every possible output format
            // Then we can offer a list of possible output formats.  When we need one of them, search
            // the input lists to locate it (and possibly select the conversion with the lowest bandwidth)
            PixelFormatList ddAllOutputVideoFormats = PixelFormatList::Union( pddOutputVideoFormats, ddInputVideoFormats.GetCount() );

            if( ddAllOutputVideoFormats.GetCount() > 0 ) {
			    m_ddVPOutputVideoFormat = ddAllOutputVideoFormats[ m_dwDefaultOutputFormat ];

			    DWORD dwInput = PixelFormatList::FindListContaining(
				    m_ddVPOutputVideoFormat, pddOutputVideoFormats, ddInputVideoFormats.GetCount() );
			    if( dwInput < ddInputVideoFormats.GetCount() ) {
				    hr = SetInputPixelFormat( ddInputVideoFormats[dwInput] );
			    } else {
				    // can't happen
				    hr = E_FAIL;
				    goto CleanUp;
			    }
            }
        }
    }
CleanUp:
    return hr;
}

//==========================================================================
//
HRESULT CVBIVideoPort::TearDownVideoPort()
{
    AMTRACE((TEXT("CVBIVideoPort::TearDownVideoPort")));

    // Release the DirectDraw surface
    RELEASE (m_pOffscreenSurf);
    RELEASE (m_pOffscreenSurf1);

    // release the videoport
    RELEASE (m_pVideoPort);

    m_VPState = VP_STATE_NO_VP;

    return NOERROR;
}


//==========================================================================
//
HRESULT CVBIVideoPort::StartVideo()
{
    AMTRACE((TEXT("CVBIVideoPort::StartVideo")));
    ASSERT(m_VPState == VP_STATE_STOPPED);

    HRESULT hr = NOERROR;
    DWORD dwSignalStatus;

    hr = m_pVideoPort->StartVideo(&m_svpInfo);
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR, 0, TEXT("StartVideo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    m_VPState = VP_STATE_RUNNING;

    DbgLog((LOG_TRACE, 2, TEXT("STARTVIDEO DONE!")));

    // check if the videoport is receiving a signal.
    hr = m_pVideoPort->GetVideoSignalStatus(&dwSignalStatus);
    if (hr != E_NOTIMPL)
    {
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0, TEXT("GetVideoSignalStatus() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
        else if (dwSignalStatus == DDVPSQ_NOSIGNAL)
        {
            DbgLog((LOG_ERROR, 0, TEXT("GetVideoSignalStatus() returned DDVPSQ_NOSIGNAL, hr = 0x%x"), hr));
            //goto CleanUp;   // SJF_TODO - ignore error for now
        }
    }
    //m_pVideoPort->WaitForSync(DDVPWAIT_END, 0, 0);
    
CleanUp:

    return hr;
}


HRESULT CVBIVideoPort::StopVideo()
{
    AMTRACE((TEXT("CVBIVideoPort::StopVideo")));
    ASSERT(m_VPState == VP_STATE_RUNNING);

    HRESULT hr = NOERROR;

    hr = m_pVideoPort->StopVideo();
    if (FAILED(hr)) 
    {
        DbgLog((LOG_ERROR,0, TEXT("m_pVideoPort->StopVideo failed, hr = 0x%x"), hr));
        //goto CleanUp;
        hr = NOERROR;
    }
    m_VPState = VP_STATE_STOPPED;

//CleanUp:
    return hr;
}

/******************************Public*Routine******************************\
* CVideoPortObj::SetVideoPortID
*
*
*
* History:
* Thu 09/09/1999 - GlennE - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CVBIVideoPort::SetVideoPortID( DWORD dwVideoPortId )
{
    AMTRACE((TEXT("CVideoPortObj::SetVideoPortID")));
    CAutoLock cObjectLock(m_pMainObjLock);

    HRESULT hr = S_OK;
    if ( m_dwVideoPortId != dwVideoPortId ) {
        // we can't switch ports when running
        if( m_VPState != VPInfoState_STOPPED ) {
            hr = VFW_E_WRONG_STATE;
        } else {
            if( m_pDDVPContainer ) {
                hr = VPMUtil::FindVideoPortCaps( m_pDDVPContainer, NULL, m_dwVideoPortId );
            } else {
                hr = VPMUtil::FindVideoPortCaps( m_pDirectDraw, NULL, m_dwVideoPortId );
            }
            if( hr == S_OK) {
                m_dwVideoPortId = dwVideoPortId;
            } else if( hr == S_FALSE ) {
                return E_INVALIDARG;
            }// else fail 
        }
    }
    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\vpmextern.h ===
/******************************Module*Header*******************************\
* Module Name: VPMExtern.h
*
*
*
*
* Created: Tue 05/05/2000
* Author:  GlenneE
*
* Copyright (c) 2000 Microsoft Corporation
\**************************************************************************/
#ifndef __VPMExtern__h
#define __VPMExtern__h

// this is so we can avoid including bucket loads of (incompatible) DDraw headers when building
// quartz.cpp
CUnknown* CVPMFilter_CreateInstance(LPUNKNOWN pUnk, HRESULT* phr);

extern const AMOVIESETUP_FILTER sudVPManager;

#endif //__VPMExtern__
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\vpmalloc.cpp ===
// Copyright (c) 1998 - 1999  Microsoft Corporation.  All Rights Reserved.
#include <streams.h>
#include <ddraw.h>
#include <VPManager.h>
#include <VPMPin.h>
#include <VPMUtil.h>
#include <ddkernel.h>

//
//   Flipping surface implementation
//
//   To allow decoders to hold on to surfaces for out of order decode
//   we flip directly to the surface pass on Receive rather than
//   use the default NULL target surface for Flip().
//
//   This works in the following way
//
//   The COMPinputPin::m_pDirectDrawSurface points to the FRONT buffer
//
//   When Receive is called we Flip() the front buffer and because we
//   do an explicit Flip() DirectDraw swaps the memory pointers for the
//   current Front buffer and the surface passed in which is then attached
//   to the front buffer.
//
//   The received buffer is then put at the back of the queue so (correctly)
//   the previous front buffer is now at the back of the queue to be handed
//   to the application
//
//   The allocator actually has one more buffer than was actually requested
//   so the previous front buffer won't actually be requested until the next
//   Receive and hence the previous Flip() has time to complete.
//

//  Video accelerator disable interface


///////////////////////////////////////////
// CLASS CDDrawMediaSample implemented here
///////////////////////////////////////////

// constructor
CDDrawMediaSample::CDDrawMediaSample(TCHAR *pName, CBaseAllocator *pAllocator, HRESULT *phr, LPBYTE pBuffer, LONG length,
                                     bool bKernelFlip)
: CMediaSample(pName, pAllocator, phr, pBuffer, length)
{
    AMTRACE((TEXT("CDDrawMediaSample::Constructor")));

    m_pDirectDrawSurface = NULL;
    m_dwDDrawSampleSize  = 0;
    m_bSurfaceLocked     = FALSE;
    m_bKernelLock        = bKernelFlip;
    SetRect(&m_SurfaceRect, 0, 0, 0, 0);

    memset(&m_DibData, 0, sizeof(DIBDATA));
    m_bInit = FALSE;

    return;
}

// destructor
CDDrawMediaSample::~CDDrawMediaSample(void)
{
    AMTRACE((TEXT("CDDrawMediaSample::Destructor")));

    if (m_pDirectDrawSurface)
    {
        __try {
            m_pDirectDrawSurface->Release() ;  // release surface now
        }
        __except(EXCEPTION_EXECUTE_HANDLER) {
            ;
        }
        m_pDirectDrawSurface = NULL;
    }

    if (m_bInit)
    {
        if (m_DibData.hBitmap)
        {
            EXECUTE_ASSERT(DeleteObject(m_DibData.hBitmap));
        }
        if (m_DibData.hMapping)
        {
            EXECUTE_ASSERT(CloseHandle(m_DibData.hMapping));
        }
    }

    return;
}

HRESULT CDDrawMediaSample::SetDDrawSampleSize(DWORD dwDDrawSampleSize)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVPMInputAllocator::SetDDrawSampleSize")));

    m_dwDDrawSampleSize = dwDDrawSampleSize;
    return hr;
}

HRESULT CDDrawMediaSample::GetDDrawSampleSize(DWORD *pdwDDrawSampleSize)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVPMInputAllocator::SetDDrawSampleSize")));

    if (!pdwDDrawSampleSize)
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad Arguments, pdwDDrawSampleSize = NULL")));
        hr = E_POINTER;
        goto CleanUp;
    }

    *pdwDDrawSampleSize = m_dwDDrawSampleSize;

CleanUp:
    return hr;
}

HRESULT CDDrawMediaSample::SetDDrawSurface(LPDIRECTDRAWSURFACE7 pDirectDrawSurface)
{
    HRESULT hr = NOERROR;
    AMTRACE((TEXT("CVPMInputAllocator::SetDDrawSampleSize")));

    if (pDirectDrawSurface)               // only if new surface is not NULL...
        pDirectDrawSurface->AddRef() ;    // ...add a ref count on it

    if (m_pDirectDrawSurface)             // if there was a surface already...
        m_pDirectDrawSurface->Release() ; // ... then release it now

    m_pDirectDrawSurface = pDirectDrawSurface;

    return hr;
}

HRESULT CDDrawMediaSample::GetDDrawSurface(LPDIRECTDRAWSURFACE7 *ppDirectDrawSurface)
{
    HRESULT hr = NOERROR;
    AMTRACE((TEXT("CVPMInputAllocator::SetDDrawSampleSize")));

    if (!ppDirectDrawSurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad Arguments, ppDirectDrawSurface = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    *ppDirectDrawSurface = m_pDirectDrawSurface;

CleanUp:
    return hr;
}
// overridden to expose IDirectDrawMediaSample
STDMETHODIMP CDDrawMediaSample::QueryInterface(REFIID riid, void **ppv)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CDDrawMediaSample::QueryInterface")));

    if (riid == IID_IDirectDrawMediaSample && m_pDirectDrawSurface)
    {
        hr = GetInterface(static_cast<IDirectDrawMediaSample*>(this), ppv);
#ifdef DEBUG
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface(IDirectDrawMediaSample*) failed, hr = 0x%x"), hr));
        }
#endif
    }
    else
    {
        hr = CMediaSample::QueryInterface(riid, ppv);
#ifdef DEBUG
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("CUnknown::NonDelegatingQueryInterface failed, hr = 0x%x"), hr));
        }
#endif
    }

    return hr;
}

// Implement IDirectDrawMediaSample
STDMETHODIMP CDDrawMediaSample::GetSurfaceAndReleaseLock(IDirectDrawSurface **ppDirectDrawSurface,
                                                         RECT* pRect)
{
    HRESULT hr = NOERROR;
    BYTE *pBufferPtr;

    AMTRACE((TEXT("CDDrawMediaSample::GetSurfaceAndReleaseLock")));

    // make sure the surface is locked
    if (!m_bSurfaceLocked)
    {
        DbgLog((LOG_ERROR, 4, TEXT("m_bSurfaceLocked is FALSE, can't unlock surface twice, returning E_UNEXPECTED")));
        goto CleanUp;

    }

    // make sure you have a direct draw surface pointer
    if (!m_pDirectDrawSurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface is NULL, returning E_FAIL")));
        hr = E_FAIL;
        goto CleanUp;

    }

    hr = GetPointer(&pBufferPtr);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetPointer() failed, hr = 0x%x"), hr));
        goto CleanUp;

    }

    ASSERT(m_pDirectDrawSurface);
    hr = m_pDirectDrawSurface->Unlock(NULL); // TBD: was (LPVOID)pBufferPtr);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface->Unlock failed, hr = 0x%x"), hr));
        goto CleanUp;

    }

    // Can't do this to make the 829/848 work with the ovmixer. The reason is that those
    // drivers unlock the surface just after GetBuffer (to avoid the win16 lock), however
    // there is a bunch of code in the proxy which ASSERTS for a valid pointer value
    /*
    // update the pointer value, however keep the SampleSize around
    hr = SetPointer(NULL, 0);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("SetPointer() failed, hr = 0x%x"), hr));
        goto CleanUp;

    }
    */

    if (ppDirectDrawSurface) {
        hr = m_pDirectDrawSurface->QueryInterface( IID_IDirectDrawSurface7, (VOID**)ppDirectDrawSurface );
        if( FAILED( hr )) {
            ASSERT( FALSE );
            *ppDirectDrawSurface  = NULL;
        }
    } else if (pRect) {
        *pRect = m_SurfaceRect;
    }
    m_bSurfaceLocked = FALSE;

CleanUp:
    return hr;
}

STDMETHODIMP CDDrawMediaSample::LockMediaSamplePointer(void)
{
    HRESULT hr = NOERROR;
    DWORD dwDDrawSampleSize = 0;
    DDSURFACEDESC2 ddSurfaceDesc;
    DWORD dwLockFlags = DDLOCK_WAIT;

    AMTRACE((TEXT("CDDrawMediaSample::LockMediaSamplePointer")));

    // make sure the surface is locked
    if (m_bSurfaceLocked)
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_bSurfaceLocked is TRUE, can't lock surface twice, returning E_UNEXPECTED")));
        hr = E_UNEXPECTED;
        goto CleanUp;

    }

    // make sure you have a direct draw surface pointer
    if (!m_pDirectDrawSurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface is NULL, returning E_FAIL")));
        hr = E_FAIL;
        goto CleanUp;

    }

    // set the dwSize of ddSurfaceDesc
    INITDDSTRUCT(ddSurfaceDesc);

    // lock the surface - no need to grab the win16 lock
    ASSERT(m_pDirectDrawSurface);

    //  Using DDLOCK_NOSYSLOCK caused us to get DDERR_SURFACEBUSY on some of
    //  our blts to the primary for painting the color key so we've
    //  stopped using it for now.

    IDirectDrawSurface7 *pSurface7;
    if (m_bKernelLock && SUCCEEDED(m_pDirectDrawSurface->QueryInterface(
           IID_IDirectDrawSurface7,
           (void **)&pSurface7))) {
        pSurface7->Release();
        dwLockFlags |= DDLOCK_NOSYSLOCK;
    }
    hr = m_pDirectDrawSurface->Lock(
             NULL,
             &ddSurfaceDesc,
             dwLockFlags,
             (HANDLE)NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface->Lock() failed, hr = 0x%x"), hr));
        goto CleanUp;

    }

    hr = GetDDrawSampleSize(&dwDDrawSampleSize);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetDDrawSampleSize() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    ASSERT(dwDDrawSampleSize);


    // update the pointer value
    hr = SetPointer((BYTE*)ddSurfaceDesc.lpSurface, dwDDrawSampleSize);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("SetPointer() failed, hr = 0x%x"), hr));
        goto CleanUp;

    }

    m_bSurfaceLocked = TRUE;

CleanUp:
    return hr;
}

// Set the shared memory DIB information
void CDDrawMediaSample::SetDIBData(DIBDATA *pDibData)
{
    ASSERT(pDibData);
    m_DibData = *pDibData;
    m_pBuffer = m_DibData.pBase;
    m_cbBuffer = m_dwDDrawSampleSize;
    m_bInit = TRUE;
}


// Retrieve the shared memory DIB data
DIBDATA *CDDrawMediaSample::GetDIBData()
{
    ASSERT(m_bInit == TRUE);
    return &m_DibData;
}


///////////////////////////////////////////
// CLASS CVPMInputAllocator implemented here
///////////////////////////////////////////

// constructor
CVPMInputAllocator::CVPMInputAllocator(CVPMInputPin& pPin, HRESULT *phr)
: CBaseAllocator(NAME("Video Allocator"), NULL, phr, TRUE, true)
, m_pPin( pPin )
{
    AMTRACE((TEXT("CVPMInputAllocator::Constructor")));

    //  REVIEW don't overwrite a failure code from CBaseAllocator
    return;
}

// destructor
CVPMInputAllocator::~CVPMInputAllocator()
{
    AMTRACE((TEXT("CVPMInputAllocator::Destructor")));
}

// Override this to publicise IDirectDrawMediaSampleAllocator
STDMETHODIMP CVPMInputAllocator::NonDelegatingQueryInterface(REFIID riid, void **ppv)
{
    HRESULT hr = E_NOINTERFACE;

    AMTRACE((TEXT("CVPMInputAllocator::NonDelegatingQueryInterface")));

    CAutoLock cLock( &m_pPin.GetFilter().GetFilterLock() );
    return hr;
}

STDMETHODIMP CVPMInputAllocator::SetProperties(ALLOCATOR_PROPERTIES* pRequest, ALLOCATOR_PROPERTIES* pActual)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVPMInputAllocator::SetProperties")));

    // call the base class
    hr = CBaseAllocator::SetProperties(pRequest, pActual);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseAllocator::SetProperties() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // tell the pin
    hr = m_pPin.OnSetProperties(pRequest, pActual);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pPin.AllocateSurfaces() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    return hr;
}

// called when we receive a sample
HRESULT CVPMInputAllocator::GetBuffer(IMediaSample **ppSample, REFERENCE_TIME *pStartTime,
                                     REFERENCE_TIME *pEndTime, DWORD dwFlags)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVPMInputAllocator::GetBuffer")));

    // call the base class
    IMediaSample *pSample = NULL;
    hr = CBaseAllocator::GetBuffer(&pSample,pStartTime,pEndTime,0);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseAllocator::GetBuffer() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // tell the pin
    hr = m_pPin.OnGetBuffer(&pSample, pStartTime, pEndTime, dwFlags);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pPin.OnGetBuffer() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    {
        //  REVIEW why lock?  There are no variables in the allocato
        //  accessed here
        CAutoLock cAllocatorLock(this);
        if (FAILED(hr))
        {
            if (pSample)
            {
                pSample->Release();
            }
            *ppSample = NULL;
        }
        else
        {
            ASSERT(pSample != NULL);
            *ppSample = pSample;
        }
    }
    return hr;
}


// called when the sample is released
HRESULT CVPMInputAllocator::ReleaseBuffer(IMediaSample *pSample)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CVPMInputAllocator::ReleaseBuffer")));

    // unlock the sample first
    hr = ((CDDrawMediaSample*)pSample)->GetSurfaceAndReleaseLock(NULL, NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pSample->GetSurfaceAndReleaseLock() failed, hr = 0x%x"), hr));
        // goto CleanUp;
        // if this happens we still have to release the sample to the free list, so don't bail out
    }

    {
        CAutoLock cAllocatorLock(this);

        // Copy of base class code - put at end of the list
        {
            CheckPointer(pSample,E_POINTER);
            ValidateReadPtr(pSample,sizeof(IMediaSample));
            BOOL bRelease = FALSE;
            {
                CAutoLock cal(this);

                /* Put back on the free list */

                CMediaSample **ppTail;
                for (ppTail = &m_lFree.m_List; *ppTail;
                    ppTail = &((CDDrawMediaSample *)(*ppTail))->Next()) {
                }
                *ppTail = (CMediaSample *)pSample;
                ((CDDrawMediaSample *)pSample)->Next() = NULL;
                m_lFree.m_nOnList++;

                if (m_lWaiting != 0) {
                    NotifySample();
                }

                // if there is a pending Decommit, then we need to complete it by
                // calling Free() when the last buffer is placed on the free list

                LONG l1 = m_lFree.GetCount();
                if (m_bDecommitInProgress && (l1 == m_lAllocated)) {
                    Free();
                    m_bDecommitInProgress = FALSE;
                    bRelease = TRUE;
                }
            }

            if (m_pNotify) {
                m_pNotify->NotifyRelease();
            }
            // For each buffer there is one AddRef, made in GetBuffer and released
            // here. This may cause the allocator and all samples to be deleted
            if (bRelease)
            {
                Release();
            }
        }
    }

    return hr;
}

// allocate memory for the sample
HRESULT CVPMInputAllocator::Alloc()
{
    HRESULT hr = NOERROR;
    CDDrawMediaSample **ppSampleList = NULL;
    DWORD i;
    LONG lToAllocate;

    AMTRACE((TEXT("CVPMInputAllocator::Alloc")));

    // call the base class
    hr = CBaseAllocator::Alloc();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseAllocator::Alloc() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // allocate memory for pointers

    lToAllocate = (m_pPin.m_dwBackBufferCount > 1 &&
                   !m_pPin.m_bSyncOnFill &&
                   m_pPin.m_bCanOverAllocateBuffers) ?
             m_lCount + 1 : m_lCount;

    // allocate memory for an array of pointers
    ppSampleList = new CDDrawMediaSample *[lToAllocate];
    if (!ppSampleList)
    {
        DbgLog((LOG_ERROR, 1, TEXT("new BYTE[m_lCount*sizeof(CDDrawMediaSample*)] failed")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    for (i = 0; i < (DWORD)(lToAllocate); i++)
    {
        // Create a new sample
        ppSampleList[i] = new CDDrawMediaSample(NAME("Sample"), this, (HRESULT *) &hr, NULL, (LONG) 0,
                                       DDKERNELCAPS_LOCK & m_pPin.m_pVPMFilter.KernelCaps() ?
                                       true : false);

        //  REVIEW - actually hr can't be a failure
        //  so we don't need to delete ppSampleList[i] here
        if (FAILED(hr) || ppSampleList[i] == NULL)
        {
            if (SUCCEEDED(hr))
                hr = E_OUTOFMEMORY;
            DbgLog((LOG_ERROR, 1, TEXT("new CDDrawMediaSample failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        // this cannot fail
        m_lFree.Add(ppSampleList[i]);
        m_lAllocated++;
    }

    ASSERT(m_lAllocated == lToAllocate);

    // tell the pin
    hr = m_pPin.OnAlloc(ppSampleList, lToAllocate);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pPin.OnAlloc(), hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    delete[] ppSampleList;
    return hr;
}

void CVPMInputAllocator::Free(void)
{
    CDDrawMediaSample *pSample;

    AMTRACE((TEXT("CVPMInputAllocator::Free")));

    /* Should never be deleting this unless all buffers are freed */
    //  REVIEW - might not be true if we failed to allocate a sample
    ASSERT(m_lAllocated == m_lFree.GetCount());

    /* Free up all the CMediaSamples */

    for (;;)
    {
        pSample = (CDDrawMediaSample *) m_lFree.RemoveHead();
        if (pSample != NULL)
        {
            delete pSample;
        }
        else
        {
            break;
        }
    }

    m_lAllocated = 0;

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\Win2K3\NT\multimedia\dshow\filters\image2\vpm\vpmdecimate.cpp ===
/******************************Module*Header*******************************\
* Module Name: decimate.cpp
*
* Support code for the IDecimateVideoImage and IAMVideoDecimationProperties
*
*
* Created: Thu 07/08/1999
* Author:  Stephen Estrop [StEstrop]
*
* Copyright (c) 1999 Microsoft Corporation
\**************************************************************************/
#include <streams.h>
#include <VPManager.h>
#include <VPMPin.h>
#include <VPMUtil.h>


#if 0
    #undef DBGLOG
    #define DBGLOG(_x_) OutputDebugStringA( _x_ )
#else
    #undef DBGLOG
    #define DBGLOG(_x_)
#endif

/*****************************Private*Routine******************************\
* GetVideoDecimation
*
* Try to get the IDecimateVideoImage interface from our peer filter.
*
* History:
* 05-05-99 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
CVPMInputPin::GetVideoDecimation(
    IDecimateVideoImage** lplpDVI
    )
{
    AMTRACE((TEXT("CVPMInputPin::GetVideoDecimation")));

    *lplpDVI = NULL;

    if (m_Connected == NULL || !IsConnected()) {
        return E_FAIL;
    }

    PIN_INFO PinInfo;
    HRESULT hr = m_Connected->QueryPinInfo(&PinInfo);
    if (FAILED(hr)) {
        return hr;
    }

    hr = PinInfo.pFilter->QueryInterface(IID_IDecimateVideoImage,
                                         (LPVOID*)lplpDVI);
    PinInfo.pFilter->Release();

    return hr;
}

/*****************************Private*Routine******************************\
* QueryDecimationOnPeer
*
* Check to see if the decoder connected to our input pin is happy
* to decimate to the requested size.  The decoder will return,
* S_OK if it can, S_FALSE if it can't decimate to the requested size
* and would like us to continue using the current decimation size and
* E_FAIL if it can't decimate at all or wants to stop decimating.
*
* History:
* 05-05-99 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVPMInputPin::QueryDecimationOnPeer(
    long lWidth,
    long lHeight
    )
{
    AMTRACE((TEXT("CVPMInputPin::QueryDecimationOnPeer")));

    IDecimateVideoImage* lpDVI;
    HRESULT hr = GetVideoDecimation(&lpDVI);

    if (SUCCEEDED(hr)) {

        hr = lpDVI->SetDecimationImageSize(lWidth, lHeight);
        lpDVI->Release();
    }
    return hr;
}

/*****************************Private*Routine******************************\
* ResetDecimationIfSet()
*
* Resets the decimation to the original size, but only if actually set
* in the first place.
*
* History:
* 05-05-99 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVPMInputPin::ResetDecimationIfSet()
{
    AMTRACE((TEXT("CVPMInputPin::ResetDecimationIfSet")));

    if (m_bDecimating) {

        IDecimateVideoImage* lpDVI;
        HRESULT hr = GetVideoDecimation(&lpDVI);

        if (SUCCEEDED(hr)) {
            hr = lpDVI->ResetDecimationImageSize();
            lpDVI->Release();
            m_bDecimating = FALSE;
            m_lWidth = 0L;
            m_lHeight = 0L;
        }
        else return hr;
    }

    return S_OK;
}


/*****************************Private*Routine******************************\
* Running
*
* Returns TRUE if the filter graph is in the "running" state.
*
* History:
* Wed 07/14/1999 - StEstrop - Created
*
\**************************************************************************/
BOOL
CVPMInputPin::Running()
{
    return (m_pVPMFilter.m_State == State_Running && CheckStreaming() == S_OK);
}


/*****************************Private*Routine******************************\
* TryDecoderDecimation
*
*
*
* History:
* Thu 07/08/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CVPMInputPin::TryDecoderDecimation(
    VPWININFO* pWinInfo
    )
{
    AMTRACE((TEXT("CVPMInputPin::TryDecoderDecimation")));


    ASSERT(Running());


    //
    // We only decimate on the primary pin
    //

    if (m_dwPinId != 0) {

        DBGLOG(("Can only decimate the primary pin\n"));
        DbgLog((LOG_TRACE, 1, TEXT("Can only decimate the primary pin")));
        ret